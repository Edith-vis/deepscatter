id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
924f7c0a3ff6f95cdfc3a100d7a30b7eaa9bf55e	rt-trust: automated refactoring for trusted execution under real-time constraints		Real-time systems must meet strict timeliness requirements. These systems also often need to protect their critical program information (CPI) from adversarial interference and intellectual property theft. Trusted execution environments (TEE) execute CPI tasks on a special-purpose processor, thus providing hardware protection. However, adapting a system written to execute in environments without TEE requires partitioning the code into the regular and trusted parts. This process involves complex manual program transformations that are not only laborious and intellectually tiresome, but also hard to validate and verify for the adherence to real-time constraints. To address these problems, this paper presents novel program analyses and transformation techniques, accessible to the developer via a declarative meta-programming model. The developer declaratively specifies the CPI portion of the system. A custom static analysis checks CPI specifications for validity, while probe-based profiling helps identify whether the transformed system would continue to meet the original real-time constraints, with a feedback loop suggesting how to modify the code, so its CPI can be isolated. Finally, an automated refactoring isolates the CPI portion for TEE-based execution, communicated with through generated calls to the TEE API. We have evaluated our approach by successfully enabling the trusted execution of the CPI portions of several microbenchmarks and a drone autopilot. Our approach shows the promise of declarative meta-programming in reducing the programmer effort required to adapt systems for trusted execution under real-time constraints.	application programming interface;autopilot;code refactoring;declarative programming;feedback;intellect;interference (communication);metaprogramming;program transformation;programmer;programming model;real-time clock;real-time operating system;real-time transcription;requirement;static program analysis;trusted execution technology	Yin Liu;Kijin An;Eli Tilevich	2018		10.1145/3278122.3278137	autopilot;software engineering;profiling (computer programming);drone;code refactoring;programmer;static analysis;computer science;feedback loop	SE	-55.0126887799653	53.30065107463529	54908
b2fe1526240a0e70b98442d96b80c9a47e6b873b	detecting vm live migration using a hybrid external approach		Cloud computing has become a paradigm of our time. It is not only a technical solution, but a business model to sell and rent computing power and servers. Virtual machines (VMs) are used to allow a dynamic and transparent server utilization, which is made possible by VM live migration. VM live migration allows to move VMs within and out of data centers while the VM is still running. Thus, resource usage becomes more efficient. However, VM live migration also provides an opportunity for new attack vectors, which can be used by malicious attackers. They can compromise hypervisors and afterwards steal VMs from data centers to gain control over resources. In the worst case scenario, the theft remains undetected by both system administrators and customers. In this paper, we present the first taxonomy of possible VM live migration detection approaches. There are two different monitoring approaches, i.e., internal or external monitoring, as well as different detection approaches, which correspond to the different approaches to detect migration. Moreover, we propose a hybrid external approach using delay measurement with ICMP ping and time-lag detection with the network time protocol (NTP) to detect VM live migration. We show that VM live migration can be detected by using a prototype of our hybrid external approach.	amazon elastic compute cloud (ec2);best, worst and average case;categorization;cloud computing;data center;experiment;hypervisor;machine learning;mobile ip;online shopping;ping (networking utility);programming paradigm;prototype;sensor;server (computing);system administrator;testbed;worst-case scenario	Sebastian Fiebig;Melanie Siebenhaar;Christian Gottron;Ralf Steinmetz	2013			embedded system;real-time computing;operating system	OS	-52.05999272303662	57.659051149827135	55053
35d5bc5d45ea36ca7f3f6a3bee25c7f5a793c735	dynamic device configuration in ubiquitous environments	dynamic policy specification;extensible markup language;user interface;contextual information;automatic generation;identity management;information system;crisis management;dynamic configuration	The need of devices in crisis management to be configured dynamically by detecting device characteristics i.e. polices defined by the user or organization, contextual information relevant to a given scenario etc is of paramount importance. Where such information can either be already predefined or the user is allowed to define such information via automatically generated input User Interface (UI) associated to one or more extensible markup languages. Hence, the layout of the devices and behavior will be automatically configured based on policy settings and contextual information in a dynamic manner as such information changes. We present a method that allows dynamic configuration of devices that improves information systems flexibility via realizing dynamic configuration of components and enhancing management and functionality of such devices and security issues within the environment. Moreover, as this method will provide an instant configuration of devices at runtime, the components can provide and be used with uninterrupted running ability. Keyword: Dynamic Policy specification, Identity Management, Crisis Management.		Abdullahi Arabo;Qi Shi;Madjid Merabti	2010		10.1007/978-3-642-15717-2_28	human–computer interaction;computer science;database;world wide web	HCI	-48.64483583862747	49.51706611469876	55137
104a2b01a7aefa934f4ae321b650ea8c88817820	access control for active spaces	mandatory access control;access control policy enforcement;application development;access control policy creation;dynamic change;communication devices;text;user collaboration;context information;rights amplification prevention access control active spaces software infrastructure computing devices communication devices user collaboration access control policy creation access control policy enforcement semi formal specification least privilege principle duty separation;information security;semi formal specification;application software;software infrastructure;collaboration;role based access control;active spaces;separation of duty;safety properties;physics computing;embedded systems;protection;access control policy;permission;safety;least privilege principle;duty separation;access control application software permission collaboration physics computing hardware computer science information security protection safety;computing devices;access control;computer science;rights amplification prevention;hardware	Active Spaces are physical spaces augmented with heterogeneous computing and communication devices along with supporting software infrastructure. This integration facilitates collaboration between users, and promotes greater levels of interaction between users and devices. An Active Space can be configured for different types of applications at different times. We present an access control system that automates the creation and enforcement of access control policies for different configurations of an Active Space. Our system explicitly recognizes different modes of cooperation between groups of users, and the dependence between physical and virtual aspects of security in Active Spaces. Our model provides support for both discretionary and mandatory access control policies, and uses role-based access control techniques for easy administration of users and permissions. We dynamically assign permissions to user roles based on context information. With the help of an example scenario, we show how we can create dynamic protection domains. This allows administrators and application developers the ability to customize access control policies on a need-toprotect basis. We also provide a semi-formal specification and analysis of our model and show how we preserve safety properties in spite of dynamic changes to access control permissions. We also show how our model preserves the principle of least privilege, promotes separation of duty, and prevents rights-amplification.	authorization;collaborative software;control system;formal specification;heterogeneous computing;mandatory access control;mathematical model;principle of least privilege;prototype;role-based access control;semiconductor industry;separation of duties;spaces;supervised learning;system administrator;trust (emotion);viz: the computer game	Geetanjali Sampemane;Prasad Naldurg;Roy H. Campbell	2002		10.1109/CSAC.2002.1176306	application software;discretionary access control;computer science;information security;access control;operating system;role-based access control;separation of duties;database;principle of least privilege;rapid application development;world wide web;computer security;collaboration	Security	-51.753166633466684	53.74177530887086	55243
794dedd9b9b73064f06e3bc8fcbcb1f92198b54d	towards a comprehensive model of isolation for mitigating illicit channels		The increased sharing of computational resources elevates the risk of side channels and covert channels, where an entity’s security is affected by the entities with which it is co-located. This introduces a strong demand for mechanisms that can effectively isolate individual computations. Such mechanisms should be efficient, allowing resource utilisation to be maximised despite isolation. In this work, we develop a model for uniformly describing isolation, colocation and containment relationships between entities at multiple levels of a computer’s architecture and at different granularities. In particular, we examine the formulation of constraints on co-location and placement using partial specifications, as well as the cost of maintaining isolation guarantees on dynamic systems. We apply the model to a number of established attacks and mitigations.	colocation centre;computation;computational resource;covert channel;dynamical system;entity;scope (computer science);simulation;software framework	Kevin Falzon;Eric Bodden	2016		10.1007/978-3-662-49635-0_7	simulation;computer security	Security	-51.07252419678989	49.548504439147194	55645
3fa27974cade47e98993b98798f73594b902583b	leakage-resilient layout randomization for mobile devices		Attack techniques based on code reuse continue to enable real-world exploits bypassing all current mitigations. Code randomization defenses greatly improve resilience against code reuse. Unfortunately, sophisticated modern attacks such as JITROP can circumvent randomization by discovering the actual code layout on the target and relocating the attack payload on the fly. Hence, effective code randomization additionally requires that the code layout cannot be leaked to adversaries. Previous approaches to leakage-resilient diversity have either relied on hardware features that are not available in all processors, particularly resource-limited processors commonly found in mobile devices, or they have had high memory overheads. We introduce a code randomization technique that avoids these limitations and scales down to mobile and embedded devices: Leakage-Resilient Layout Randomization (LR2). Whereas previous solutions have relied on virtualization, x86 segmentation, or virtual memory support, LR2 merely requires the underlying processor to enforce a W⊕X policy—a feature that is virtually ubiquitous in modern processors, including mobile and embedded variants. Our evaluation shows that LR2 provides the same security as existing virtualization-based solutions while avoiding design decisions that would prevent deployment on less capable yet equally vulnerable systems. Although we enforce execute-only permissions in software, LR2 is as efficient as the best-in-class virtualization-based solution.	central processing unit;code reuse;embedded system;high memory;mobile device;on the fly;software deployment;spectral leakage;x86	Kjell Braden;Lucas Davi;Christopher Liebchen;Ahmad-Reza Sadeghi;Stephen Crane;Michael Franz;Per Larsen	2016			simulation;computer science	Security	-54.889197901796344	56.75866301675124	55796
8f10c55c67ea067e9c63cefe23f07a5bd617a1df	a secure access control mechanism against internet crackers	file servers;computer network management internet authorisation computer crime file servers network operating systems telecommunication security;authorisation;network operating systems;computer crime;access control internet web server buffer overflow image restoration protection operating systems cleaning file servers electronic mail;internet;operating system;buffer overflow;computer network management;telecommunication security;performance overhead secure access control mechanism internet crackers internet servers buffer overflow attack process cleaning technique access restrictions damage minimization server control hijacking malicious code injection compacto operating system;access control	Internet servers are always in danger of being “hijacked” by various attacks like the buffer overflow attack. We propose the process cleaning technique for making an access control mechanism secure against hijacking. To minimize damages in cases where the full control of the servers is stolen, access restrictions must be imposed on the servers. However, designing a secure access control mechanism is not easy because that mechanism itself can be a security hole. Process cleaning prevents malicious code injected by a cracker from illegally removing access restrictions from a hijacked server. In this paper, we describe the access control mechanism of our Compacto operating system using process cleaning. According to the results of our experiments, process cleaning can be implemented with acceptable performance overheads.	access control;application checkpointing;best, worst and average case;buffer overflow;child process;copy-on-write;experiment;fault tolerance;internet;malware;operating system;page hijacking;plasma cleaning;spawn (computing);sputter cleaning;tomotaka takahashi;vulnerability (computing);web server	Kenichi Kourai;Shigeru Chiba	2001		10.1109/ICDSC.2001.919014	file server;the internet;buffer overflow;computer science;access control;operating system;database;distributed computing;authorization;internet privacy;computer security;server;computer network	Security	-53.58182708733092	58.32442592164949	56010
82cd830e829993725ff6b1b1999230e23c2e02b8	a petri-net based multilevel security specification model for multimedia documents	security policy;data security;computer security;information security;data engineering;computer science education;engineering management;petri net;petri nets;distributed environment;access control;biomedical imaging	With the growing need for multimedia data management, security requirements are becoming very crucial. Composing multimedia documents involves bringing together media objects that exist in various formats. These objects may reside in a distributed environment and belong to different security domains. We propose a time augmented colored-Petri Net model for multimedia document composition that allows the specification of multilevel security. The model also allows handling multiple security policies and hierarchical and pathbased protection schemes. 1.0 Introduction Recent advances in high-performance computing and networking technologies have allowed the emergence of many distributed multimedia applications in medicine, education, digital libraries, e-commerce, etc. These applications are mainly expected to use pre-composed multimedia documents. A multimedia document consist of various media types such as text, audio, image and video. These may be stored in a central archive or distributed over various servers that are interconnected by a broadband network. These objects may belong to different security domains. Each security domain represents the scope of a security policy under different security administration [1]. Composing a multimedia document from these media objects poses the challenge of enforcing multiple security policies. Need for security and access control to individual components can be easily seen in various multimedia applications. For example, a WWW site for distance learning needs to protect access to various components of a multimedia document based on the user category. A course coordinator and a registered student have access to different components of the composite course document. Another example can be drawn from a medical application. Medical records for patients will have various information, X-rays and video scans that need to be protected from unauthorized personnel. At the same time fast and efficient access to specific patient information by a physician may be very critical. Petri Net model has been found very useful in modeling concurrent computation and complex processes[2]. It has been extended in Generalized Object-Composition Petri Net (GOCPN) to model multimedia synchronization[3][4][5][6]. Several security models have been proposed and applied for developing secure computing systems[7]. Access control mechanism is broadly categorized as discretionary access control(DAC) and mandatory access control (MAC). DAC allows access restrictions that are subject to user discretion, while MAC does not. In this paper, we present a colored Petri Net based information model that extends the capability of GOCPN by allowing security specification to control access to multimedia documents at the time of presentation. We assume a simplistic model of a trusted user[8] or group of users preparing a multimedia presentation that allows viewing documents from the various security levels where users are not meant to modify the presentation unless they are at the same trusted security level group. We use the multilevel security model to classify different multimedia objects. The paper is organized as follows. In Section 2, we introduce the concept of GOCPN. In section 3, we introduce the concept of multiview model of multilevel security. In section 4, we present the proposed colored-GOCPN. In section 5 we conclude with a discussion on future research. 2.0 Petri Net models of Multimedia Petri nets have been widely used for modeling and analysis of systems that are characterized as being concurrent, asynchronous, distributed, parallel and nondeterministic[2][9]. Various factors contributing to their success include their graphical nature, the simplicity of the model and the firm mathematical foundation. It also provides modularity in design. Time intervals can be used to describe the presentation of multimedia documents. There are all together 13 possible temporal relationships between two time intervals. Little and Ghafoor[6] used the 13 temporal relationships between two time intervals to specify the synchronization among the media objects. 2.1 GOCPN Model Basic OCPN[4][6] and XOCPN have been augmented in [3] to GOCPN. GOCPN can be used to model the spatio-temporal synchronization constraints, user interaction, lip-sync operations and TAC operations. Definition: A GOCPN is a 10-tupleG = {P, T, A, AW, PO, PD, PS, POp, TF, SL }. P = {p1,p2,..,pm} is a finite set of places with .T = { t1, t2,.., tn} is a finite set of transitions with and . A = is a mapping representing arcs between places and transitions. AW: , B = {0, 1} is a weight function of arcs; It is used to determine the token flow and firing condition of the net. PO: i a mapping of places to the content set C and QoP (Quality of Presentation) set Q. PD: represents playout duration of the media object withD as the integer set. PS: represents the spatial information of the media object. POp: m 0 ≥ n 0 ≥ P T ∩ Φ = P T × { } P T × { } ∪ A B →	adjusted winner procedure;archive;authorization;categorization;computation;digital library;e-commerce;emergence;graphical user interface;information model;library (computing);mandatory access control;media object server;multilevel security;network security;object composition;parallel computing;petri net;playout;requirement;sl (complexity);server (computing);streaming media;supercomputer;synchronization (computer science);terminal access controller;video;weight function	James B. D. Joshi;Arif Ghafoor	2000			computer security model;cloud computing security;computer science;information security;database;security service;distributed computing;computer security;petri net	DB	-49.363739599446596	48.181770755934494	56132
1c55bcca25d1e46f344467d02cb2603d248ef029	a self-adaptive system for vehicle information security applications	computer architecture;cryptography;access control;vehicles;field programmable gate arrays;hardware	To provide complete vehicle information protection mechanism, this work proposes a self-adaptive system for vehicle information security applications (SAV). Different from the conventional software-based information access method, in the SAV, the access control policies are designed by the protection matrices and implemented as reconfigurable hardware modules. The information access method becomes specific and not generic, so the risks of illegal access of vehicle information can be reduced. To not only meet real-time requirements but also enhance hardware resource utilization, the cryptographic functions in the SAV are also implemented as reconfigurable hardware modules. Thus, the SAV can adapt its access control policies and cryptographic functions at runtime to different system requirements. Our experiments have also demonstrated the SAV can accelerate by up to 3.78x the processing time required by using the software-based design. Compared to the conventional embedded system design, the SAV can also reduce 27.1% of slice registers and 26.5% of slice LUTs in the Xilinx Virtex-5 XC5VLX110T FPGA.	access control;adaptive system;algorithm;challenge–response spam filtering;cryptography;embedded system;encryption;experiment;field-programmable gate array;information access;information security;protection mechanism;real-time clock;reconfigurable computing;requirement;run time (program lifecycle phase);system requirements;systems design	Chun-Hsian Huang;Huang-Yi Chen;Tsung-Fu Huang;Yao-Ying Tzeng;Peng-Yi Li;Pei-Shan Wu	2015	2015 IEEE 13th International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2015.9	embedded system;real-time computing;computer science;cryptography;access control;operating system;distributed computing;computer security	EDA	-52.13177856086342	55.79384053149552	56168
464b1e1db00074ea2c68b1c4cfd7ab7b262ada89	security analysis of information systems taking into account social engineering attacks	analytical models;security analysis;information systems;measurement;risk analysis;network security;computer model;software technical attacks;security modelling;synthetic aperture sonar;attack trees;social engineering attacks;computational modeling;synthetic aperture sonar computational modeling analytical models information systems access control measurement;attack trees security analysis risk analysis security modelling computer attacks;computer attacks;network security analysis security analysis information systems social engineering attacks software technical attacks;access control;information system;security of data;analytical model;network security analysis	The paper suggests an attack trees based approach to security analysis of information systems. The approach considers both software-technical and social engineering attacks. It extends the approach to network security analysis based on software-technical attacks which was suggested earlier by the authors of this paper. The main difference is in generalizing the suggested approach for information systems and in use of different conceptions, models and frameworks related to social-engineering attacks. In particular, we define conceptions of legitimate users and control areas. Besides, social-engineering attacks and attacks that require physical access to control areas are included to the attack trees used for security analysis. The paper also describes a security analysis toolkit based on the approach suggested and experiments with it to define the security level of information system.	attack tree;automation;component-based software engineering;experiment;file system permissions;host (network);information systems;information system;nessus vulnerability scanner;network security;network switch;networking cables;nmap security scanner;operating system;physical access;sas;sensor;social engineering (security);time complexity;wireshark;workstation	Igor V. Kotenko;Mikhail Stepashkin;Elena Doynikova	2011	2011 19th International Euromicro Conference on Parallel, Distributed and Network-Based Processing	10.1109/PDP.2011.62	computer security model;security through obscurity;security information and event management;security convergence;vulnerability;covert channel;asset;computer science;network security;data mining;internet privacy;security testing;computer security;information system	Security	-54.087517330724054	50.09388783381982	56425
48458056ccab203de5ca621e8b5e85e21c8269f1	automated decision making for active cyber defense: panel discussion	active cyber defense	"""The high growth of cyber connectivity significantly increases the potential and sophistication of cyber-attacks. New capabilities based on active cyber defense (ACD) are required to offer automated, intelligently-driven, agile, and resilient cyber defense. Both accurate """"sense-making"""" based security analytics of the system artifacts (e.g., traces, configurations, logs, incident reports, alarms and network traffic), and provably-effective """"decision-making"""" based on robust reasoning are required to enable ACD for cyber security and resiliency. In this panel session, a collection of academic, government, and national laboratory representatives will discuss current drivers and emerging research priorities for ACD technologies. Scheduled panelists include Phil Quade (NSA), Arlette Hart (FBI), Ehab Al-Shaer (UNCC), and Chris Oehmen (PNNL). The panel will focus on the impact of new emerging cyber technologies on the future of resilience and the realization of ACD technologies. Example emerging technologies include clouds/data centers, cyber-physical systems, software defined networking, and Internet of things."""	agile software development;computer security;cyber-physical system;data center;internet of things;network traffic control;sensemaking;software-defined networking;tracing (software)	Christopher S. Oehmen;Ehab Al-Shaer;Mohammad Ashiqur Rahman	2015		10.1145/2809826.2809828	simulation;engineering;internet privacy;computer security	Security	-57.287713948073964	50.23329118683599	56516
48b3a4efe9e261330f8fbe4b0b25d60831c0285d	byod manager kit: integration of administration and security tools byod		The benefits of using the BYOD (Bring Your Own Device) concept are many, but information security needs to be remodeled to ensure the basics of information. The article describes the development of a framework that integrates open-source security tools. The tools selected to compose the suite were: NetworkMiner, Universal Password Manager, Password Strength Meter, NetCalculator, jNetMap and IP Monitor. The selected software works as originally developed or integrated into the framework. Tests conducted on two networks, wired and wireless, showed that the framework reach the proposed goals.		Vin&#237;cius Lahm Perini;Maria de F&#225;tima Webber do Prado Lima	2018		10.1145/3229345.3229392	password;computer security;bring your own device;information security;software;wireless;mobile device;password strength;suite;computer science	Security	-52.981504428577104	59.52551991163243	57005
3f6e88b1eb1e06cdd742b6037c4ef61477a41aaf	dtrace: dynamic tracing in oracle solaris, mac os x, and free bsd by brendan gregg and jim mauro	software engineering;human factors;personality types;mbti	"""This book is about an operating system facility created by Sun Microsystems for analyzing system behavior and performance in real-time. The authors describe DTrace as """" observability technology """" – enabling you to look at and understand what your processors, memory and other system components are doing. DTrace provides different, more detailed insights than tools like vmstat, netstat, top and truss that administrators and developers traditionally use when getting baselines and diagnosing problems. DTrace is secure and low-overhead, and among its most powerful features, you don't have to instrument your application in advance or restart it in a debugging mode in order to use DTrace – that's the dynamic part. Part I, """" Introduction, """" includes an overview of DTrace concepts, terms and architecture and a chapter summarizing the D language. Part II, """" Using DTrace, """" starts off with a chapter called System View that includes guidelines for how to approach an undefined or poorly-defined performance issue. This chapter and other parts of the book describe and demonstrate an iterative, successive-refinement approach that often starts with standard system utilities to help ask better questions before moving to DTrace. Then there (including the nosnoopforyou.d script), the kernel, tools, and tips and tricks. The last part includes appendices on tunable variables, a D language reference, provider arguments reference, error messages and more. The book is valuable for developers and administrators using any OS that supports DTrace. That includes the operating systems in the title as well as NetBSD and some versions of Linux with the appropriate loadable kernel module. The Solaris Dynamic Tracing Guide (2008) and some other publications online cover some of the same ground, but the book really shines in its comprehensiveness as well as the problem-solving framework it demonstrates. The book has many one-liners (example command lines) that can answer specific questions, but the nature of the tool and the task rewards the patient and methodical. The only real frustration has more to do with some of the providers (system software instrumentation that DTrace taps into at runtime) than with the book itself. This is especially so for some of the network protocols. Some providers aren't available in all operating systems that support DTrace; others have """" unstable """" interfaces, meaning that DTrace scripts that worked in one OS release won't always work in a later release. It's also instructive that the Bibliography mentions publications on architecture, kernels, …"""	bsd;brendan gregg;central processing unit;communications protocol;control theory;d programming language;dtrace;debugging;error message;freebsd;iterative method;linux;loadable kernel module;netbsd;operating system;overhead (computing);problem solving;real-time web;refinement (computing);run time (program lifecycle phase);undefined behavior	Greg Cooper	2012	ACM SIGSOFT Software Engineering Notes	10.1145/2088883.2088902	myers-briggs type indicator;computer science;engineering;human factors and ergonomics;operating system;software engineering;database;computer security	OS	-57.38777019670446	54.9572506429122	57206
1036b7745fd9ef8be92c5131c66ce3a379cd1d23	an ois model for internal accounting control evaluation	model system;internal control;control structure;financial reporting;formal analysis	Internal control is an important aspect of accounting office systems. The implementation and maintenance of a control structure which protects corporate assets from theft, misuse, and fraud and permits the preparation of accurate and reliable financial reports is a result of both good business practice and legal requirements. This article presents a precedence model for specifying accounting office systems. Formal analysis procedures are formulated for evaluating the internal controls of the modeled system. The procedures establish precondition and postcondition relationships between designated control points.	osi model	Andrew D. Bailey;James H. Gerlach;R. Preston McAfee;Andrew B. Whinston	1983	ACM Trans. Inf. Syst.	10.1145/357423.357426	accounting management;computer science;programming language;control flow;internal control	Security	-53.44970007956021	46.89368461740015	57282
f0304c497cc0a24e2909a9adadedb5a18dc00b38	concurrent history-based usage control policies		The sharing of data and resources is one of the cornerstones of our society. However, this comes together with several challenges regarding the increasing need of guaranteeing security and privacy during both the access and the usage of such shared resources. Access control policies first, and usage control policies secondly, have been introduced to overcome issues related to the access and usage of resources. However, the introduction of distributed and cloud systems to share data and resources enables the concurrent and shared access to the same resources. Here we present an enhanced version of History-based Usage Control policies in which we are able to manage concurrent access and usage of resources by several subjects, whose actions may influence one another. Moreover, to ease the understanding of the proposed approach, we present a reference example where a document is shared among a set of people having different roles in a company.	access control;concurrency control;ecosystem;electromagnetically induced transparency;privacy;requirement;software release life cycle;xacml	Fabio Martinelli;Ilaria Matteucci;Paolo Mori;Andrea Saracino	2017		10.5220/0006232506570666	real-time computing;operations management;database	Security	-48.675254127226985	54.43336136154668	57338
bfbeee93134208df11bfc266a198f19ef7c9486b	a signature scheme for distributed executions based on control flow analysis	clusters;distributed executions;cloud;tpm;cfg;dfg	This article proposes a dynamic and flexible signature scheme to verify at runtime the execution of a distributed program. Extending [20], the approach relies on the analysis of a trace that represents such an execution using Control Flow Graph (CFG). This mechanism ensures the detection of flow faults that do not correspond to the CFG, i.e. that tamper the normal run of the application. Most effects of malicious code injection commonly met on distributed computing platforms such as grids are covered by this approach. The execution engine used in our signature scheme is certified with the TPM-based Certification of a Remote Resource (TCRR) protocol [5].#R##N##R##N#Our approach has been implemented in KAAPI,, a C++ middleware library to execute and schedule fine or medium size grain programs on distributed platforms. The concrete validation on two parallel programs (Fibonacci and NQueens) reveals the scalability of the approach and its relatively low overhead.	control flow analysis	Sébastien Varrette;Benoît Bertholon;Pascal Bouvry	2011		10.1007/978-3-642-25261-7_7	parallel computing;real-time computing;cloud computing;computer science;operating system;distributed computing;computer security	SE	-52.93825071663709	56.891688499526545	57341
435acad5c3b23644ab2662d79836bf70a0bf3ded	cryptographic hardware and embedded systems – ches 2012		Designers of banking security systems are faced with a difficult challenge of developing technology within a tightly constrained budget, yet which must be capable of defeating attacks by determined, well-equipped criminals. This talk will summarise banking security technologies for protecting Chip and PIN/EMV card payments, online shopping, and online banking. The effectiveness of the security measures will be discussed, along with vulnerabilities discovered in them both by academics and by criminals. These vulnerabilities include cryptographic flaws, failures of tamper resistance, and poor implementation decisions, and have led not only to significant financial losses, but in some cases unfair allocation of liability. Proposed improvements will also be described, not only to the technical failures but also to the legal and regulatory regimes which are the underlying reason for some of these problems not being properly addressed.	cryptography;embedded system;online banking;online shopping;tamper resistance;vulnerability (computing)	Emmanuel Prouff Patrick R Schaumont	2012		10.1007/978-3-642-33027-8	embedded system;cryptography;computer science	Security	-59.08919874012345	58.697260372307504	57424
81af5f46a474c21b30923203db5b1a919ebeccd9	insider threat: memory confidentiality and integrity in the cloud	humanities;technology;medical;music;confidentiality;economics;computer sciences;fiction;memory management;law;natural;social sciences;data security;art;cloud computing	The advantages of always available services, such as remote device backup or data storage, have helped the widespread adoption of cloud computing. However, cloud computing services challenge the traditional boundary between trusted inside and untrusted outside. A consumer’s data and applications are no longer in premises, fundamentally changing the scope of an insider threat. This thesis looks at the security risks associated with an insider threat. Specifically, we look into the critical challenge of assuring data confidentiality and integrity for the execution of arbitrary software in a consumer’s virtual machine. The problem arises from having multiple virtual machines sharing hardware resources in the same physical host, while an administrator is granted elevated privileges over such host. We used an empirical approach to collect evidence of the existence of this security problem and implemented a prototype of a novel prevention mechanism for such a problem. Finally, we propose a trustworthy cloud architecture which uses the security properties our prevention mechanism guarantees as a building block. To collect the evidence required to demonstrate how an insider threat can become a security problem to a cloud computing infrastructure, we performed a set of attacks targeting the three most commonly used virtualization software solutions. These attacks attempt to compromise data confidentiality and integrity of cloud consumers’ data. The prototype to evaluate our novel prevention mechanism was implemented in the Xen hypervisor and tested against known attacks. The prototype we implemented focuses on applying restrictions to the permissive memory access model currently in use in the most relevant virtualization software solutions. We envision the use of a mandatory memory access control model in the virtualization software. This model enforces the principle of least privilege to memory access, which means cloud administrators are assigned with only enough privileges to successfully perform their administrative tasks. Although the changes we suggest to the virtualization layer make it more restrictive, our solution is versatile enough to port all the functionality available in current virtualization	access control;backup;cloud computing;computer data storage;confidentiality;hypervisor;insider threat;principle of least privilege;prototype;threat (computer);virtual machine	Francisco Liberal Rocha	2015				Security	-50.833773285556234	57.997101659021446	57586
d4f18a7e4d2eecd9c6fafde77829bcb111fdc48a	information governance in nhs's npfit: a case for policy specification	trust management;electronic health record;patient confidentiality;authorisation policy;access control	PURPOSE The National Health Service's (NHS's) National Programme for Information Technology (NPfIT) in the UK with its proposed nation-wide online health record service poses serious technical challenges, especially with regard to access control and patient confidentiality. The complexity of the confidentiality requirements and their constantly evolving nature (due to changes in law, guidelines and ethical consensus) make traditional technologies such as role-based access control (RBAC) unsuitable. Furthermore, a more formal approach is also needed for debating about and communicating on information governance, as natural-language descriptions of security policies are inherently ambiguous and incomplete. Our main goal is to convince the reader of the strong benefits of employing formal policy specification in nation-wide electronic health record (EHR) projects.   APPROACH Many difficulties could be alleviated by specifying the requirements in a formal authorisation policy language such as Cassandra. The language is unambiguous, declarative and machine-enforceable, and is based on distributed constrained Datalog. Cassandra is interpreted within a distributed Trust Management environment, where digital credentials are used for establishing mutual trust between strangers.   RESULTS To demonstrate how policy specification can be applied to NPfIT, we translate a fragment of natural-language NHS specification into formal Cassandra rules. In particular, we present policy rules pertaining to the management of Clinician Sealed Envelopes, the mechanism by which clinical patient data can be concealed in the nation-wide EHR service. Our case study exposes ambiguities and incompletenesses in the informal NHS documents.   CONCLUSIONS We strongly recommend the use of trust management and policy specification technology for the implementation of nation-wide EHR infrastructures. Formal policies can be used for automatically enforcing confidentiality requirements, but also for specification and communication purposes. Formalising the requirements also reveals ambiguities and missing details in the currently used informal specification documents.	apache cassandra;authorization;confidentiality;credential;datalog;declarative programming;description;electronic health records;electronic health record (ehr) or component of ehr;information governance;natural language;nurses' health study ii activity and inactivity questionnaire;partial;policy;requirement;role-based access control;rule (guideline);specification;trust management (information system);trust management (managerial science);united states indian health service;united states public health service;benefit	Moritz Y. Becker	2007	International journal of medical informatics	10.1016/j.ijmedinf.2006.09.008	computer science;knowledge management;access control;data mining;management;computer security	SE	-49.89821114631635	52.27621323531976	57794
d1c6aeb8f8db2c6ca70f3bb3f7486bb2232cd752	access control model in object - oriented systems	encapsulation;hierarchical structure;object oriented methods;hierarchical structure discretionary access control model secure object oriented systems generalization relations aggregation relations access rights;information security;secure object oriented systems;authorisation;access rights;aggregation relations;distributed object management object oriented methods data privacy object oriented languages authorisation;object oriented programming;systems engineering and theory;object oriented system;permission;data privacy;access control object oriented modeling permission encapsulation systems engineering and theory relational databases data security information security information analysis object oriented programming;distributed object management;discretionary access control model;relational databases;access control;is a and part of relations;generalization relations;security;information analysis;object oriented languages;object oriented modeling;data security	The authors discuss a discretionary access control model to realize secure object-oriented systems. An object is manipulated only through methods supported by the object. Classes and objects are hierarchically structured in generalization (is-a) and aggregation (part-of) relations. We discuss how to authorize and inherit access rights on classes and objects in the hierarchical structure.		Keiji Izaki;Katsuya Tanaka;Makoto Takizawa	2000		10.1109/PADSW.2000.884517	computer science;information security;data mining;database;distributed computing;object-oriented programming;computer security	Robotics	-49.133804482888145	50.42027130798915	57823
2e405e140acd699d254294078aa51b4b3263c9c8	a web services security policy assistant	environmental influence;security specifications;security evaluation;domain specific preferences;context organizations security fires;policy alternatives;domain vocabularies;web services security of data;syntactic evaluation;web service;fuzzy techniques;security requirements;web services;web services security policy assistant;organizations;fires;security;security policy;web services security;security of data;context;domain specificity;domain specific preferences web services security policy assistant security specifications security requirements syntactic evaluation security evaluation policy alternatives domain vocabularies fuzzy techniques	WS-Policy (Web Services Policy) and related security specifications provide a standard way to describe the security requirements and capabilities of both web services consumers and providers. The specification of the security requirements and capabilities of a service and its consumer in policy alternatives, and their combination to find the applicable policy is difficult. Currently, security policy compatibility is difficult to achieve as the algorithm only considers the syntactic evaluation of policy alternatives, leading to inconsistent policies that required further investigation. The evaluation of the security provided by a set of policy alternatives, the related effect that policy alternatives and environmental influences have on each other is not considered. This paper presents a design of an evaluation tool that can assist administrators to determine the level of security supported by a web services security policy. The design employs domain vocabularies, fuzzy techniques and domain-specific preferences.	algorithm;causal filter;causality;firewall (computing);fuzzy cognitive map;fuzzy concept;interdependence;intrusion detection system;requirement;semiconductor industry;vocabulary;ws-policy;ws-security;web service	Tristan Lavarack;Marijke Coetzee	2010	2010 International Conference for Internet Technology and Secured Transactions		computer security model;standard of good practice;cloud computing security;web application security;security through obscurity;security information and event management;security engineering;security convergence;security policy;policy analysis;ws-policy;information security standards;data mining;security service;business;security testing;network security policy;world wide web;computer security	Security	-49.10004577302695	51.63474264629519	58189
81a455fd0b87a2ad6639762a2f3ad6b9d4cbda0e	measuring semantic integrity for remote attestation	virtual machine;semantic integration;measurement system;dynamic behaviour;consistency checking;security policy	"""Network administrators cannot guarantee the confidentiality and the integrity of Intranet data accessed by remote clients: little assurance about the integrity of remote clients can be established; an attacker may have compromised a remote client's application. We need a general notion of integrity the should consider that: a remote client can be trusted only if it executes applications in a predefined set; remote client's applications should be continuously monitored to discover if they have been attacked. The private network host SCADA devices that can be remotely administered by remote nodes inside the Intranet. Remote nodes are commodity PCs, which can also be connected to Internet or run arbitrary software. Goal: when accessing SCADA device, the integrity of the remote nodes must be assured: the remote PC should run only authorised software; the behaviour of the software should be continuously monitored. VIMS Virtual machine Integrity Measurement System (VIMS) is an architecture that implements a dynamic-based approach to integrity. The notion of integrity includes not only the correct configuration of the system and of the software it runs, but also that the remote client does not execute some malware that changes the behaviour of its applications. VIMS exploits virtualization technology to run two virtual machines (VMs) on the remote host: the Client VM: it runs the VPN client to access the SCADA network; the Assurance VM: the VM that implements remote attestation. Moreover, """" dangerous """" applications are run in a distinct VM. Introspection is a generic technique to detect intrusions. With virtualization, no need of additional hardware units: visibility: access VM's state from a lower level; robustness: introspect a VM from another VM. Kernel Integrity With virtual machine introspection, the Assurance VM can dynamically check from the """" outside """" : integrity of the kernel code (also modules); modifications to the interrupt descriptor table; modifications to the system call table; the list of running processes; the list of open files. Protecting a process from attacks that alter the intended behaviour of the process' program. We want to preserve the original semantics of the program (VPN client). Notion of process self: the program that the process executes. Based on traces of system calls: dynamic analysis: Forrest et al; static analysis: Wagner and Dean. We deduce the possible valid sequences of system calls that the process can issue from the source code: we encode them using a context-free grammar. A static tool computes …"""	apache forrest;authorization;confidentiality;context-free grammar;context-free language;encode;host (network);internet;interrupt descriptor table;intranet;introspection;malware;personal computer;semantic web;static program analysis;system call;tracing (software);trusted computing;user error;virtual machine;virtual private network;x86 virtualization	Fabrizio Baiardi;Diego Cilea;Daniele Sgandurra;Francesco Ceccarelli	2009		10.1007/978-3-642-00587-9_6	real-time computing;semantic integration;computer science;security policy;virtual machine;operating system;system of measurement;database;distributed computing;computer security	Security	-54.74662529230946	55.47214545534721	58240
a96240c69d4f8ebc728b06401bc7b9a7fb2ba491	lazytainter: memory-efficient taint tracking in managed runtimes	memory efficiency;android;taint tracking	The leakage of private information is of great concern on mobile devices since they contain a great deal of sensitive information. This has spurred interest in the use of taint tracking systems to track and monitor the flow of private information on a mobile device. Taint tracking systems impose memory overhead, as taint information must be maintained for every piece of information an application stores in memory. This memory cost is at odds with the growing number of low-end, memory-constrained devices, which makes up the majority mobile device growth in emerging markets. To make taint tracking affordable and to benefit a broader range of mobile devices, we present LazyTainter, which is a memory-efficient taint tracking system designed for managed runtimes. To implement LazyTainter, we enhanced TaintDroid with hybrid taint tracking, which combines lazy and eager tainting, to reduce memory usage with only negligible performance loss. Our experimental results demonstrate that LazyTainter can reduce heap usage by as much as 26.5% when compared to TaintDroid while imposing a negligible 1% increase in performance overhead.	android;information sensitivity;lazy evaluation;mobile device;overhead (computing);personally identifiable information;spectral leakage;taint checking;tracking system	Zheng Wei;David Lie	2014		10.1145/2666620.2666626	real-time computing;engineering;internet privacy;computer security	Mobile	-55.16781012767484	58.29481758022685	58493
9da9fe452d2fa5ad16066f52a6f11e27a04c1c6e	network structure for low level control systems designed to prevent cyber attacks	software;power generation control;power generation protection;hydroelectric power stations;interlocked protection function;cyber attack;high level control low level control system cyber attack hardware switch cyber security hydropower plant information flow natural disaster hardware module software module interlocked protection function level 1 control system industrial control network structure;hydropower plant;security of data control system synthesis disasters hydroelectric power stations industrial control power generation control power generation protection;cyber security;computer security;hardware switch;control system;information flow;critical system;control system synthesis;industrial control;natural disaster;low level control system;control system design;hardware module;software module;network structure;software switches computer security hardware turbines;high level control;switches;security of data;industrial control network structure;turbines;disasters;level 1;hardware;level 1 control system	This work presents a network structure with hardware switch for ensuring cyber security for level 1 control systems for hydropower plants. The developed modules could be also used in other systems. This paper is concentrated on identification of critical systems that must run and be protected at all times, even if the information flow to/from higher control levels is interrupted. The goal is to ensure that these critical systems are protected and in the case of manmade or natural disaster can operate in “manual” mode, without need for an expert to run them. The main goal is development of hardware and software modules that will enable interlocked protection functions for hydropower plants so that level 1 control systems cannot be compromised by cyber attack or distraction in industrial control networks. Having level 1 control systems undamaged and able to run independently of higher control levels improves resiliency and sustainability of infrastructures to mitigate the effect of attack or disasters until higher level controls are restored.	cpu cache;computer security;control system;control theory;critical systems thinking;interrupt	Ognjen Kuljaca;Jyotirmay Gadewadikar;Krunoslav Horvat	2011	2011 Proceedings of the 34th International Convention MIPRO		disaster;simulation;information flow;network switch;natural disaster;computer science;control system;cyberwarfare;computer security	Security	-57.02475774438774	51.621029134864	58586
151850814ac134d3be71625b9732c2e38562bbd0	certified in-lined reference monitoring on .net	virtual machine;data transmission security;security automata;execution monitoring;software engineering;reference monitors;system security;computer programs;symposia;program rewriting;internet;type checking;in lined reference monitoring;technical report;trusted computing base;reprints;computer science;security policy	MOBILE is an extension of the .NET Common Intermediate Language that supports certified In-Lined Reference Monitoring. Mobile programs have the useful property that if they are well-typed with respect to a declared security policy, then they are guaranteed not to violate that security policy when executed. Thus, when an In-Lined Reference Monitor (IRM) is expressed in Mobile, it can be certified by a simple type-checker to eliminate the need to trust the producer of the IRM.Security policies in Mobile are declarative, can involve unbounded collections of objects allocated at runtime, and can regard infinite-length histories of security events exhibited by those objects. The prototype Mobile implementation enforces properties expressed by finite-state security automata - one automaton for each security-relevant object - and can type-check Mobile programs in the presence of exceptions, finalizers, concurrency, and non-termination. Executing Mobile programs requires no change to existing .NET virtual machine implementations, since Mobile programs consist of normal managed CIL code with extra typing annotations stored in .NET attributes.	automaton;common intermediate language;concurrency (computer science);divergence (computer science);exception handling;information rights management;prototype;reference monitor;run time (program lifecycle phase);type system;virtual machine	Kevin W. Hamlen;J. Gregory Morrisett;Fred B. Schneider	2006		10.1145/1134744.1134748	the internet;computer science;security policy;virtual machine;technical report;trusted computing base;database;distributed computing;programming language;computer security	PL	-52.54277928367213	53.62506557666996	58757
f741ff04c602d3e323c46521216fdeff325676bc	tracing offensive values from exceptions		In debugging, techniques for tracing back offending values are extremely useful. In [1] Raphael Finkel presents us with an easily implemented and fairly useful technique. As was pointed out in [1] there has been other work in this area. In this note I would like to present a short taxonomy of the various techniques, and attempt to place Finkel's technique in its place in the hierarchy.	debugging;exception handling	Steven Gutfreund	1983	SIGPLAN Notices	10.1145/988216.988222	computer science;artificial intelligence;computer security;algorithm	PL	-60.35176045830402	54.60095829194516	59070
1bca6e5b758cdc90c131b14fdab13e969ab44c7d	tightly-coupled self-debugging software protection	anti debugging;self debugging;binary rewriting;reverse engineering	Existing anti-debugging protections are relatively weak. In existing self-debugger approaches, a custom debugger is attached to the main application, of which the control flow is obfuscated by redirecting it through the debugger. The coupling between the debugger and the main application is then quite loose, and not that hard to break by an attacker. In the tightly-coupled self-debugging technique proposed in this paper, full code fragments are migrated from the application to the debugger, making it harder for the attacker to reverse-engineer the program and to deconstruct it into the original unprotected program to attach a debugger or to collect traces. We evaluate a prototype implementation on three complex, real-world Android use cases and present the results of tests conducted by professional penetration testers.	android;control flow;copy protection;debugger;debugging;emulator;library (computing);open-source software;prototype;reverse engineering;tracing (software)	Bert Abrath;Bart Coppens;Stijn Volckaert;Joris Wijnant;Bjorn De Sutter	2016		10.1145/3015135.3015142	parallel computing;real-time computing;computer science;operating system	SE	-56.434201229550915	56.441309317106246	59072
458e6ee0ccd2fcd5edeb3b7254406f8ddd9572f0	the potential of sampling for dynamic analysis	sampling;distribution dynamics;distributed analysis;dynamic analysis	This paper presents an argument for distributing dynamic software analyses to large populations of users in order to locate bugs that cause security flaws. We review a collection of dynamic analysis systems and show that, despite a great deal of effort from the research community, their performance is still too low to allow their use in the field. We then show that there are effective sampling mechanisms for accelerating a wide range of powerful dynamic analyses. These mechanisms reduce the rate at which errors are observed by individual analyses, but this loss can be offset by the subsequent increase in test population. Nevertheless, there are unsolved issues in this domain that deserve attention if this technique is to be widely utilized.	population;sampling (signal processing);software bug;web application security scanner	Joseph L. Greathouse;Todd M. Austin	2011		10.1145/2166956.2166959	simulation;computer science;data mining;operations research	SE	-60.04567717350719	57.60878976592563	59401
6965415ff726fc1abdd2449c34bc88b647c31aa2	on integrating confidentiality and functionality in a formal method	confidentiality preserving refinement;confidentiality properties;information flow security;miracles;circus;unifying theories of programming	This paper proposes a formal method, based on Circus, for developing software systems that respect a joint specification of functionality and confidentiality attributes. We extend the semantics of Circus to capture the information that users can infer about a system’s behaviour, enabling confidentiality and functionality attributes of a system to be specified together. We represent inconsistencies between functionality and confidentiality properties as miracles, rendering insecure functionality infeasible. We present techniques for verifying that a system design’s functionality and confidentiality attributes are mutually consistent, and for ensuring that consistency is maintained by refinement steps.	confidentiality;formal methods;refinement (computing);software system;systems design;verification and validation	Michael J. Banks;Jeremy L. Jacob	2013	Formal Aspects of Computing	10.1007/s00165-013-0285-4	computer science;data mining;internet privacy;computer security	SE	-52.73772402382598	49.62813648802829	60143
876d212a2706928f51782e3e828ce7ae3a383588	an ontology regulating privacy oriented access controls		Access Control is one of the essential and traditional security weapons of data protection. In open and complex environments such as the Internet or cloud computing, the decision to grant access to a resource must ensure a secure management with a specific attention to privacy and data protection regulations. In recent years, many access control models and languages were proposed. Despite increasing legislative pressure, few of these propositions take care of privacy requirements in their specifications. In this paper we propose to enforce privacy compliance in access control policies. Based on a semantic modeling approach, specifically formal ontology, we will try to incorporate data protection legislation requirements in policies specification and implementation. This aims to abstract the complexity of legal requirements expression and to facilitate their automation and enforcement at execution level. Indeed, at run time, the interoperability of diverse information and the reference to the text law are addressed in a novel manner.	access control;care-of address;cloud computing;formal ontology;information privacy;internet;interoperability;requirement;run time (program lifecycle phase)	Maherzia Belaazi;Hanen Boussi Rahmouni;Adel Bouhoula	2015		10.1007/978-3-319-31811-0_2	data mining;internet privacy;world wide web	Security	-48.904040232578275	53.740057186097914	60472
18ea9a644da7b452e5a799fe3972efbf82ca0cca	two factor authentication using m-pin server for secure cloud computing environment	two factor authentication 2fa;authentication;authorization;m pin;first factor;cloud computing	Cloud computing is comprised of major demand from the every group of organization because of easy availability and cost effectiveness. The responsibilities of cloud service providers will become increasing more due to the great progression in every cloud computing deployment model (public, private and hybrid) and service models (SaaS, PaaS and IaaS). In this perspective, cloud computing faces multiple challenges, especially in cloud computing security at all levels (e.g., host, network, application and data levels). Authentication is the constantly the biggest concerned for IT industries to adopt cloud computing environment. The availability, performance, key logger attack, malicious insiders, outsider attacks and service disruptions explore (service hijacking) issues are the key research challenges in the cloud computing authentication level. In this aspect, traditional user name and password is not enough as a single factor (first factor). This paper has proposed a secure cloud computing framework which uses first factor as a crypt user name and password with the ATM pin as a second factor called M-pin. The proposed work focuses on a solution to the threats that are the major issues in the cloud adoption. Two Factor Authentication using M-pin Server for Secure Cloud Computing Environment	atm turbo;authentication;cloud computing security;color gradient;computer security;crypt (unix);data logger;keystroke logging;malware;password;platform as a service;software as a service;software deployment;threat (computer);user (computing)	Nitin Nagar;Ugrasen Suman	2014	IJCAC	10.4018/ijcac.2014100104	cloud computing security;cloud computing;engineering;cloud testing;utility computing;internet privacy;world wide web;computer security	Security	-49.71790800080914	58.127148488499536	60906
7937387460c274bbf40cd0cedddcdf9c20c94a00	derailer: interactive security analysis for web applications	articulo;derailer interactive security analysis for web applications;web applications;static analysis;security	Derailer is an interactive tool for finding security bugs in web applications. Using symbolic execution, it enumerates the ways in which application data might be exposed. The user is asked to examine these exposures and classify the conditions under which they occur as security-related or not; in so doing, the user effectively constructs a specification of the application's security policy. The tool then highlights exposures missing security checks, which tend to be security bugs.  We have tested Derailer's scalability on several large open-source Ruby on Rails applications. We have also applied it to a large number of student projects (designed with different security policies in mind), exposing a variety of security bugs that eluded human reviewers.	open-source software;ruby on rails;scalability;security bug;software bug;symbolic execution;web application	Joseph P. Near;Daniel O Jackson	2014		10.1145/2642937.2643012	computer security model;cloud computing security;web application security;web application;security through obscurity;security information and event management;security bug;computer science;information security;internet privacy;programming language;security testing;world wide web;computer security;static analysis	SE	-58.544111265064714	56.68996889865945	61356
15569ea2ac40c9e97ebb10897760d4a342adea1c	uncovering use-after-free conditions in compiled code	software engineering;software security;binary decompilation software security static analysis;windows system32 directory use after free conditions compiled code static analysis method binary code;binary decompilation;static analysis;algorithm design and analysis software object recognition security visualization binary codes runtime	Use-after-free conditions occur when an execution path of a process accesses an incorrectly deal located object. Such access is problematic because it may potentially allow for the execution of arbitrary code by an adversary. However, while increasingly common, such flaws are rarely detected by compilers in even the most obvious instances. In this paper, we design and implement a static analysis method for the detection of use-after-free conditions in binary code. Our new analysis is similar to available expression analysis and traverses all code paths to ensure that every object is defined before each use. Failure to achieve this property indicates that an object is improperly freed and potentially vulnerable to compromise. After discussing the details of our algorithm, we implement a tool and run it against a set of enterprise-grade, publicly available binaries. We show that our tool can not only catch textbook and recently released in-situ examples of this flaw, but that it has also identified 127 additional use-after-free conditions in a search of 652 compiled binaries in the Windows system32 directory. In so doing, we demonstrate not only the power of this approach in combating this increasingly common vulnerability, but also the ability to identify such problems in software for which the source code is not necessarily publicly available.	adversary (cryptography);algorithm;arbitrary code execution;available expression;binary code;binary file;compiler;dangling pointer;dataflow;directory (computing);flaw hypothesis methodology;maximum flow problem;microsoft windows;sensor;static program analysis;vulnerability (computing)	David Dewey;Bradley Reaves;Patrick Traynor	2015	2015 10th International Conference on Availability, Reliability and Security	10.1109/ARES.2015.61	kpi-driven code analysis;dead code;real-time computing;object code;computer science;theoretical computer science;redundant code;computer security;static program analysis;source code	SE	-56.90174227038155	56.47058507008177	61725
27bfe8312bec6f30215a8eb92180a10a7672091f	source code analysis to remove security vulnerabilities in java socket programs: a case study		This paper presents the source code analysis of a file reader server socket program (connection-oriented sockets) developed in Java, to illustrate the identification, impact analysis and solutions to remove five important software security vulnerabilities, which if left unattended could severely impact the server running the software and also the network hosting the server. The five vulnerabilities we study in this paper are: (1) Resource Injection, (2) Path Manipulation, (3) System Information Leak, (4) Denial of Service and (5) Unreleased Resource vulnerabilities. We analyze the reason why each of these vulnerabilities occur in the file reader server socket program, discuss the impact of leaving them unattended in the program, and propose solutions to remove each of these vulnerabilities from the program. We also analyze any potential performance tradeoffs (such as increase in code size and loss of features) that could arise while incorporating the proposed solutions on the server program. The proposed solutions are very generic in nature, and can be suitably modified to correct any such vulnerabilities in software developed in any other programming language. We use the Fortify Source Code Analyzer to conduct the source code analysis of the file reader server program, implemented on a Windows XP virtual machine with the standard J2SE v.7 development kit.	application security;automated code review;c++;command-line interface;computer program;connection-oriented communication;denial-of-service attack;error message;graphical user interface;java;libressl;linux;microsoft windows;naivety;network socket;norm (social);programming language;server (computing);software developer;source lines of code;static program analysis;system information (windows);virtual machine;vulnerability (computing);workbench	Natarajan Meghanathan	2013	CoRR	10.5121/ijnsa.2013.5101	computer science;operating system;secure coding;world wide web;computer security;computer network	Security	-57.00383213899993	55.76123599506751	61873
2342738aab04922f8e5128a4ea0b3e4d387d22e4	security models and information flow	bell lapadula model high level output protection information flow information sharing flow based security model security relevant causal factors interference programs security levels primitives;ducts;information systems;history;security model;information security;bell lapadula model;information technology;primitives;information security history information theory information technology laboratories protection ducts broadcasting;interference;secure communication;information sharing;high level output protection;computer security;protection;security levels;information flow;information exchange;security of data information theory;broadcasting;information theoretic;programs;flow based security model;security of data;information theory;security relevant causal factors	A theory of information flow is developed that differs from that of nondeducibility, which is seen to be a theory of information sharing. The theory is used to develop a flow-based security model (FM) and to show that the proper treatment of security-relevant causal factors in such a framework is very tricky. Using FM as a standard for comparison, an examination is made of interference, generalized noninterference, and extensions to noninterference designed to protect high-level output, and it is seen that the proper treatment of causal factors in such models requires programs to be considered as explicit input to systems. This gives a new perspective on security levels. The model of D.E. Bell and L.J. LaPadula (1973), on the other hand, more successfully models security-relevant causal information, although this success is bought at the expense of the model being vague about its primitives. This vagueness is examined with respect to the claim that the Bell-LaPadula model and noninterference are equivalent. >	causal filter;causality;fm broadcasting;high- and low-level;itu t.50;information flow;network compartment;non-interference (security);paul moskowitz;theory	John McLean	1990		10.1109/RISP.1990.63849	computer security model;duct;secure communication;information flow;information exchange;information theory;computer science;information security;theoretical computer science;data mining;interference;information technology;computer security;broadcasting;information system	Security	-54.14019876598176	51.50471086467747	61884
6079a6423e4517e37fa7277dcfc8de317b861312	a data classification method for inconsistency and incompleteness detection in access control policy sets		Access control policies may contain anomalies such as incompleteness and inconsistency, which can result in security vulnerabilities. Detecting such anomalies in large sets of complex policies automatically is a difficult and challenging problem. In this paper, we propose a novel method for detecting inconsistency and incompleteness in access control policies with the help of data classification tools well known in data mining. Our proposed method consists of three phases: firstly, we perform parsing on the policy data set; this includes ordering of attributes and normalization of Boolean expressions. Secondly, we generate decision trees with the help of our proposed algorithm, which is a modification of the well-known C4.5 algorithm. Thirdly, we execute our proposed anomaly detection algorithm on the resulting decision trees. The results of the anomaly detection algorithm are presented to the policy administrator who will take remediation measures. In contrast to other known policy validation methods, our method provides means for handling incompleteness, continuous values and complex Boolean expressions. In order to demonstrate the efficiency of our method in discovering inconsistencies, incompleteness and redundancies in access control policies, we also provide a proof-of-concept implementation.	access control;anomaly detection;boolean expression;c4.5 algorithm;data mining;decision tree;parsing;sensor;vulnerability (computing);whole earth 'lectronic link	Riaz Ahmed Shaikh;Kamel Adi;Luigi Logrippo	2016	International Journal of Information Security	10.1007/s10207-016-0317-1	computer science;data mining;database;computer security;algorithm	ML	-60.49429971119642	59.190427301078806	61955
8030fa5c6953c4753942ad254dd5809228d82d55	security path verification through joint information flow analysis		Security path verification is an effective measure for identifying design paths that can lead to security violations. However, existing techniques in this realm typically lack the flexibility in formal models for verification performance-precision tradeoffs and rely on new design languages and tools. In this paper, we propose a security path verification technique through joint information flow analysis. We formalize qualitative information flow models of different precision and complexity to enable verification performance tradeoffs. We further employ quantitative information flow metrics to assess the severity of identified security path violations. Our information flow models and security properties are described in standard HDL and property specification languages respectively, allowing verification to be performed using tools familiar to hardware designers. Experimental results show that our method is effective in identifying security vulnerabilities caused by design flaw, timing channel and hardware Trojan with verification performance benefits.		Wei Hu;Xinmu Wang;Dejun Mu	2018	2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2018.8605726	electronic engineering;computer science;hardware trojan;software engineering;information flow (information theory);mutual information;communication channel;vulnerability	EDA	-54.943275304810264	52.01569757795527	62096
23191d0b59e65b18d38c8321ca4f3241b2bb243c	a comparison between api call sequences and opcode sequences as reflectors of malware behavior		The volume of malware detected annually is increasing exponentially, and malware programs are written in such a way that they can often escape detection tools. Some are can even modify themselves and alter their appearance for each infection. Thus, for malware detection, it is important to analyze malware behavior, and application programming interface (API) call sequences and operational code (opcode) sequences usefully reflect the behavior of malware. Moreover, a hidden Markov model (HMM) is a robust learning model for malware detection. In this work, we therefore compared API call sequences and opcode sequences using the HMM learning model. The results showed that learning in API call sequences is more accurate than that of opcode sequences. We conclude that API call sequences are therefore better for malware detection.	algorithm;application programming interface;computer;hidden markov model;information system;machine learning;malware;markov chain;opcode;sensor	Saja Alqurashi;Omar Batarfi	2017	2017 12th International Conference for Internet Technology and Secured Transactions (ICITST)	10.23919/ICITST.2017.8356357	support vector machine;the internet;opcode;application programming interface;computer network;machine learning;computer science;malware;feature extraction;hidden markov model;artificial intelligence	SE	-58.14622744015811	59.89032393365218	62413
02aac2e074b50c1e2da42427b87ea7067fd15d11	concatenating unprotected internet of things network event-driven data to obtain end-user information		This research demonstrates how to monitor an Internet of Things (IoT) construct and use the data captured from the network's IoT devices to gather information about end-users in the operating environment. The purpose for this study is to expose unsophisticated capabilities that malicious entities can perform when the aggregation of the raw data created from the low-level processing operation of IoT devices is not properly protected and kept confidential. Additionally, this work is not conducting threat analysis or threat modeling in depth for the given events within the IoT network. Focus on threat mitigation will be explored in future work. However, what is explored is the capability to gather vital information pertaining to the end-users in the operating environment when there are little to no security methods enforced, thus validating the reason to employ security measures like threat mitigation techniques to protect IoT constructs. As a result, information pertaining to device network usage, end-user data services usage, smart device log information and visual images of the end-user where all capabilities that could be assessed via the raw data capture being collected from the individual IoT sub nodes.	concatenation;confidentiality;entity;high- and low-level;internet of things;malware;operating environment;smart device;threat model	Rahmira Rufus;Albert C. Esterline	2017	2017 26th International Conference on Computer Communication and Networks (ICCCN)	10.1109/ICCCN.2017.8038525	smart device;concatenation;end user;raw data;computer network;computer science;operating environment;data as a service;computer security;threat model;internet of things	Mobile	-49.74988683399545	59.44478014884194	62438
3ad90fd70851380b6aa5a0f46deb3bc0898f83f1	evolving computer intrusion scripts for vulnerability assessment and log analysis	vulnerability assessment;log analysis;agent based model;log file analysis;operating system;hacker;script kiddies;evolutionary computing	Evolutionary computation is used to construct undetectable computer attack scripts. Using a simulated operating system, we show that scripts can be evolved to cover their tracks and become difficult to detect from log file analysis.	evolutionary computation;log analysis;operating system;security hacker	Julien Budynek;Eric Bonabeau;Ben Shargel	2005		10.1145/1068009.1068331	hacker;computer science;operating system;vulnerability assessment;web log analysis software;world wide web;computer security;evolutionary computation	Arch	-59.0305823271018	60.133797268156215	62497
c13cf71bf04e6f90a0a51cc1b345fb8289bfdb83	a formal security policy for xenon	refinement;hypervisor;information flow;z;csp;information flow security;security policy;circus;open source;unifying theories of programming	The up-front choice of security policy and formalism used to model it is critical to the success of projects that seek to enforce information-flow security. This paper reports on the Xenon project's choice of policy and formalism. Xenon is a high-assurance separation hypervisor based on re-engineering the Xen open-source hypervisor. Xenon's formal policy both guides the re-engineering and serves as a basis for formal modelling. Definitions of information-flow security can be difficult to apply, because in general they are not preserved by refinement. Roscoe, Woodcock, and Wulf have defined an information-flow policy that is preserved by refinement, but it is defined in a purely event-based formalism that does not directly support refinement into state-rich implementations like hypervisor internals. Circus is a combination of Z, CSP, and Hoare and He's unifying theories of programming. Circus is suited for both event-based and state-based modelling. In this paper, we show how to define an information-flow policy in Circus that is also preserved by refinement. Because Circus retains the human-readability of Z, heuristic application of the policy to re-engineering is simplified and a larger open source community can be supported. Because Circus can easily model state-rich implementations of event-based security policies, the Xenon model can support complete policy-to-code modelling in a single language.	heuristic;hoare logic;hypervisor;open-source software;refinement (computing);semantics (computer science);theory;unifying theories of programming;xenon (processor)	John P. McDermott;Leo Freitas	2008		10.1145/1456396.1456401	real-time computing;information flow;computer science;security policy;software engineering;communicating sequential processes;database;refinement;hypervisor;programming language;computer security	Security	-54.089063234258916	53.22145384566358	63430
21dd5c2cf293c940375e308c47cc32005525c783	refinement-based design of a group-centric secure information sharing model	design process;formal specification;state machine;information sharing;formal verification;first order;model checking;linear temporal logic;system refinement;secure information sharing;access control	This paper presents a formal, state machine-based specification (stateful specification) of a group-centric secure information sharing (g-SIS) model. The stateful specification given here is a refinement of a prior specification that is given in first-order linear temporal logic (FOTL). Such FOTL specification defines authorization based solely on group operations, but gives little guidance regarding implementation. The current specification is the result of a second step in a multi-step design process that separates concerns and provides multiple opportunities to detect unintended policy characteristics. We show that our stateful specification is consistent with the prior FOTL specification by using a combination of model-checking and manual techniques.	authorization;data security;finite-state machine;first-order logic;first-order predicate;ibm notes;linear temporal logic;model checking;read-write memory;refinement (computing);state (computer science);stateful firewall;stateless protocol	Wanying Zhao;Jianwei Niu;William H. Winsborough	2012		10.1145/2133601.2133620	computer science;theoretical computer science;system requirements specification;formal specification;database;computer security;language of temporal ordering specification	SE	-52.84488477085769	51.29298458377231	63502
71eb1d2a3f22d8ae43ec4d78162baa0b9ded2222	developing integritycatalog, a software system for managing integrity-related metadata in digital repositories		Funding information ERC Starting, Grant/Award Number: 279237; European Research Council; Greek General Secretariat for Research and Technology Summary Digital repositories must periodically check the integrity of stored objects to assure users of their correctness. Prior solutions calculate integrity metadata and require the repository to store it alongside the actual data objects. To safeguard and detect damage to this metadata, prior solutions rely on widely visible media (unaffiliated third parties) to store and provide back digests of the metadata to verify it is intact. However, they do not address recovery of the integrity metadata in case of damage or adversarial attack. We introduce IntegrityCatalog, a novel software system that can be integrated into any digital repository. It collects all integrity-related metadata in a single component and treats them as first class objects, managing both their integrity and their preservation. We introduce a treap-based persistent authenticated dictionary managing arbitrary length key/value pairs, which we use to store all integrity metadata, accessible simply by object name. Additionally, IntegrityCatalog is a distributed system that includes a network protocol that manages both corruption detection and preservation of this metadata, using administrator-selected network peers with 2 possible roles. Verifiers store and offer attestations on digests and have minimal storage requirements, while preservers efficiently synchronize a complete copy of the catalog to assist in recovery in case of a detected catalog compromise on the local system. We present our approach in developing the prototype implementation, measure its performance experimentally, and demonstrate its effectiveness in real-world situations. We believe the implementation techniques of our open-source IntegrityCatalog will be useful in the construction of next-generation digital repositories.	authentication;best, worst and average case;closing (morphology);communications protocol;correctness (computer science);dnp3;data structure;dictionary;digital library;distributed computing;experiment;first-class function;holism;nikos lorentzos;open-source software;prototype;requirement;software system;tracking system;treap	Nikos Chondros;Mema Roussopoulos	2018	Softw., Pract. Exper.	10.1002/spe.2515	software system;metadata;database;computer science;meta data services;metadata repository;communications protocol;compromise;treap;authentication	Security	-53.20441840800881	58.81883197395948	63503
9310fd5551d0ddc7eb9a67152facffea89eb6faf	open industry standards for mitigating risks to global supply chains	supply chains computer crime industries globalization government policies manufacturing	Governments and large enterprises are cognizant of and appreciate the benefits of globalization. They also recognize their increasing reliance on commercial-off-the-shelf (COTS) information technology (IT) components (software and hardware) necessary to meet the needs of their business missions. As cyberattacks increase in sophistication, stealth, and severity, governments and larger enterprises are taking a more comprehensive approach to risk management and product assurance. Simply improving today's security practices is insufficient. A comprehensive approach involves understanding the practices commercial technology suppliers can employ to protect the integrity of their products and services in the global supply chain--including an understanding of how suppliers manage the risks inherent in globalized product development and manufacturing. This paper outlines the nature of the global technology supply chain, the challenges posed, and the impact on consumers. It describes the added importance of a framework for addressing these challenges based on an approach of IBM, as well as evolving industry open standards efforts to address technology supply chain risks.		A. R. Szakal;K. J. Pearsall	2014	IBM Journal of Research and Development	10.1147/JRD.2013.2285605	computer science;engineering	Robotics	-59.47116537906254	48.99547494698204	63623
636340b2259418db0eb900572902cc8b489c7238	hardware-based on-line intrusion detection via system call routine fingerprinting		We introduce a hardware-based methodology for performing on-line intrusion detection in microprocessors. The proposed method extracts fingerprints from the basic blocks of the routine executed in response to a system call and examines their validity using a Bloom filter. Implementation in hardware renders spoofing attacks, to which operating system or hypervisor-level intrusion detection methods are vulnerable, ineffective. The proposed method is evaluated using kernel rootkits which covertly modify the system call service routines of a Linux operating system running on a 32-bit x86 architecture, implemented in the Simics simulation environment, while hardware overhead is evaluated using a predictive 45nm PDK.	32-bit;basic block;bloom filter;fingerprint (computing);hypervisor;ia-32;intrusion detection system;linux;microprocessor;online and offline;operating system;overhead (computing);process design kit;rendering (computer graphics);rootkit;simics;simulation;spoofing attack;system call;x86	Liwei Zhou;Yiorgos Makris	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		intrusion detection system;embedded system;host-based intrusion detection system;kernel;real-time computing;computer science;operating system;malware;fingerprint recognition	EDA	-55.55937072915242	56.67270514066997	63783
e86b7cdf3fb40271f0558f0d46f604255ffcb767	automata-based approach to design and analyze security policies	firewalls computing;protocols;boolean functions;information systems automata theory data protection firewalls;automata protocols data structures firewalls computing boolean functions educational institutions;automata based approach firewall security policies functional discrepancy detection anomaly detection security policy completeness verification automata synthesis formal approach information system protection security policy analysis security policy design;automata;data structures	Information systems must be controlled by security policies to protect them from undue accesses. Security policies are often designed by rules expressed using informal text, which implies ambiguities and inconsistencies in security rules. Our objective in this paper is to develop a formal approach to design and analyze security policies. We propose a procedure that synthesizes an automaton which implements a given security policy. Our automata-based approach can be a common basis to analyze several aspects of security policies. We use our automata-based approach to develop three analysis procedures to: verify completeness of a security policy, detect anomalies in a security policy, and detect functional discrepancies between several implementations of a security policy. We illustrate our approach using examples of security policies for a firewall.	automaton;conformance testing;develop;firewall (computing);information systems;requirement;sensor;verification and validation	Wadie Krombi;Mohammed Erradi;Ahmed Khoumsi	2014	2014 Twelfth Annual International Conference on Privacy, Security and Trust	10.1109/PST.2014.6890953	software security assurance;computer security model;communications protocol;data structure;security engineering;computer science;security policy;theoretical computer science;concrete security;information security standards;data mining;automaton;boolean function;security testing;network security policy;computer security	Security	-52.92884540037211	51.26201799437283	64332
d23f278c8ccff677ff49732bd41bdefb889129dd	oasis: on achieving a sanctuary for integrity and secrecy on untrusted platforms	secure remote execution;instruction set extension	We present OASIS, a CPU instruction set extension for externally verifiable initiation, execution, and termination of an isolated execution environment with a trusted computing base consisting solely of the CPU. OASIS leverages the hardware components available on commodity CPUs to achieve a low-cost, low-overhead design.	central processing unit;formal verification;overhead (computing);trusted computing base	Emmanuel Owusu;Jorge Guajardo;Jonathan M. McCune;James Newsome;Adrian Perrig;Amit Vasudevan	2013		10.1145/2508859.2516678	real-time computing;computer science;operating system;distributed computing;computer security	Security	-52.981227212291046	56.1060764106303	64344
550f735afc7d45dfe0456584c47b91b568ab841f	threat-based security analysis for the internet of things	security privacy sensors actuators internet of things context medical services;threats;user trust internet of things threat based security analysis smart homes smart cities iot privacy analysis threat model;threats security internet of things;internet of things;trusted computing data privacy internet of things security of data;security	The Internet of Things (IoT) is an emerging paradigm focusing on the inter-connection of things or devices to each other and to the users. This technology is anticipated to become an integral milestone in the development of smart homes and smart cities. For any technology to be successful and achieve widespread use, it needs to gain the trust of users by providing adequate security and privacy assurance. Despite the growing interest of the research community in IoT, and the emergence of several surveys and papers addressing its architecture and its elements, we are still lacking a thorough analysis of the security and privacy properties that are required for a system where the constituent devices vary in their capabilities. In this paper we provide a threat model based on use-cases of IoT, which can be used to determine where efforts should be invested in order to secure these systems. We conclude by recommending measures that will help in providing security and assuring privacy when using IoT.	andrew appel;emergence;internet of things;privacy;programming paradigm;smart city;threat model	Ahmad Atamli-Reineh;Andrew P. Martin	2014	2014 International Workshop on Secure Internet of Things	10.1109/SIoT.2014.10	personally identifiable information;cloud computing security;privacy software;security association;human–computer interaction;information privacy;computer science;information security;internet security;internet privacy;world wide web;computer security;internet of things	Security	-49.22009473216506	56.355183089329905	64451
07f8a9ed3445ccd4bb5667864e2ec839c2f89681	security@runtime: a flexible mde approach to enforce fine-grained security policies	security policies;java security;access control;security domain specific language;obligations	In this paper, we present a policy-based approach for automating the integration of security mechanisms into Java-based business applications. In particular, we introduce an expressive Domain Specific modeling Language (Dsl), called Security@Runtime, for the specification of security configurations of targeted systems. The Security@Runtime Dsl supports the expression of authorization, obligation and reaction policies, covering many of the security requirements of modern applications. Security requirements specified in security configurations are enforced using an application-independent Policy Enforcement Point (Pep)Policy Decision Point (Pdp) architecture, which enables the runtime update of security requirements. Our work is evaluated using two systems and its advantages and limitations are discussed.	authorization;data structure;digital subscriber line;domain-specific language;domain-specific modeling;java;mathematical optimization;model-driven engineering;modeling language;requirement;run time (program lifecycle phase);scalability;xacml	Yehia Elrakaiby;Moussa Amrani;Yves Le Traon	2014		10.1007/978-3-319-04897-0_2	software security assurance;computer security model;cloud computing security;real-time computing;security through obscurity;security information and event management;security engineering;security convergence;covert channel;computer science;security policy;information security;logical security;information security standards;database;security service;security testing;network security policy;computer security	Security	-51.701581221547386	51.331983873953405	64453
4c1321e30ceafa2d4bdae5ed65c654462fbdca65	reconfigurable security support for embedded systems	protocols;reconfigurable computing;reconfigurable architectures;embedded system;computer security;computer architecture;reconfigurable architecture;data privacy;batteries;embedded system data security hardware power system security computer architecture computer security reconfigurable architectures protocols data privacy batteries;security architecture;high performance;reconfigurable hardware;intrusion detection system;power system security;hardware;data security	Embedded systems present significant security challenges due to their limited resources and power constraints. We propose a novel security architecture for embedded systems (SANES) that leverages the capabilities of reconfigurable hardware to provide efficient and flexible architectural support to both security standards and a range of attacks. This paper shows the efficiency of reconfigurable architecture to implement security primitives within embedded systems. We also propose the use of hardware monitors to detect and defend against attacks. The SANES architecture is based on three main ideas: 1) reconfigurable security primitives, 2) reconfigurable hardware monitors and 3) a hierarchy of security controllers at the primitive, system and executive level. Results are presented for a reconfigurable AES security primitive within the IPSec standard and highlight the interest of such a solution.	algorithm;computer security;embedded system;field-programmable gate array;ipsec;online and offline;performance;reconfigurable computing;type signature	Guy Gogniat;Tilman Wolf;Wayne P. Burleson	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.409	computer security model;embedded system;real-time computing;information privacy;reconfigurable computing;computer science;security service;computer security	EDA	-52.48384252596221	55.99554794234304	64565
ca1363943db3b34faee9e978090f658cfc53b073	a flexible design flow for software ip binding in fpga	field programmable gate arrays fpga;field programmable gate array;field programmable gate arrays system on a chip microprogramming security embedded systems intellectual property;hardware security;intellectual property;logic design;software security flexible design flow software intellectual property field programmable gate array system on chip design physical unclonable function hardware security;design flow;physical unclonable function;firmware;system on a chip;embedded system;proof of concept;software binding;embedded systems;software security;system on chip;cryptography;software intellectual property;secure embedded systems;system on chip cryptography field programmable gate arrays industrial property logic design;industrial property;field programmable gate arrays;microprogramming;software binding design flow firmware field programmable gate arrays fpga intellectual property physical unclonable function secure embedded systems security;security;flexible design flow;system on chip design	Software intellectual property (SWIP) is a critical component of increasingly complex field programmable gate arrays (FPGA)-based system-on-chip (SOC) designs. As a result, developers want to ensure that their Software Intellectual Property (SWIP) is protected from being exposed to or tampered with by unauthorized parties. By restricting the execution of SWIP to a single trusted FPGA platform, SWIP binding addresses developers' concerns about maintaining control of their intellectual property and the market position it affords. This work proposes a novel design flow for SWIP binding on a commodity FPGA platform lacking specialized hardcore security facilities. We accomplish this by leveraging the qualities of a Physical Unclonable Function (PUF) and a tight integration of hardware and software security features. A prototype implementation demonstrates our design flow's ability to successfully protect software by encryption using a 128 bit FPGA-unique key extracted from a PUF. Based on this proof of concept, a solution to perform secure remote software updates, a common challenge in embedded systems, is proposed to showcase the practicality and flexibility of the design flow.	128-bit;application security;authorization;design flow (eda);embedded system;encryption;field-programmable gate array;patch (computing);physical unclonable function;prototype;system on a chip;unique key	Michael A. Gora;Abhranil Maiti;Patrick Schaumont	2010	IEEE Transactions on Industrial Informatics	10.1109/TII.2010.2068303	system on a chip;embedded system;electronic engineering;computer science;engineering;information security;operating system;field-programmable gate array;computer engineering	EDA	-53.17469161521033	55.64103156036162	64683
ce3988a62b6a461d4105de5f2358ecb035b5b887	demo: cloud-based security as a service for smart iot environments	iot security;cloud;sdn;crowdsourcing	We demonstrate the first cloud-based solution for providing network security as a service in smart home IoT environments. Our solution uses Software-defined Networking (SDN) for controlling traffic flows inside the network and offloads traffic analysis tasks to a smart Cloud-based Traffic Analyzer (CbTA), which uses a crowd sourced knowledge base for detecting network threats and attacks. It is a scalable, cost-efficient, easily deployable as well as manageable solution for securing different network environments.	cloud computing;cost efficiency;crowdsourcing;home automation;knowledge base;network security;scalability;security as a service;sensor;software-defined networking;traffic analysis	Ibbad Hafeez;Aaron Yi Ding;Lauri Suomalainen;Seppo Hätönen;Valtteri Niemi;Sasu Tarkoma	2015		10.1145/2801694.2802140	cloud computing security;engineering;internet privacy;computer security;computer network	Security	-50.73002662903155	58.63431386766615	64809
26e0ff3a377b01714d8332881d0ac0a756621dd2	modeling and performance evaluation of computer systems security operation		The explosive growth in computer systems and networks has increased the role of computer security within organizations [4]. In many cases, ineffective protection against computer security treats leads to considerable damage, and even can cause an organization to be paralized. Therefore, the development of new models and methods of performance analysis of security systems seems to be very important. In this paper, we propose a model of computer security operation, and introduce its related performance measure. It is shown how the model can be applied to performance evaluation of actual systems. Finally, a technique of security system performance analysis is described and its practical implementation is discussed. We conclude with an appendix which contains technical details concerning fork-join network representation of the model, and related results.	computer security;fork (software development);performance evaluation;profiling (computer programming)	Dennis Guster;Nikolai K. Krivulin	2001	CoRR		computer security model;simulation;computer science;security testing;computer security	Security	-62.30730130405913	56.033207979994785	64994
2d59d0ad832fcae97e20a0ac630d535d7966934c	improving software security via runtime instruction-level taint checking	hardware tagging;format string;program counter;software security;buffer overflow	Current taint checking architectures monitor tainted data usage mainly with control transfer instructions. An alarm is raised once the program counter becomes tainted. However, such architectures are not effective against non-control data attacks. In this paper we present a generic instruction-level runtime taint checking architecture for handling non-control data attacks. Under our architecture, instructions are classified as either Taintless-Instructions or Tainted-Instructions prior to program execution. An instruction is called a Tainted-Instruction if it is supposed to deal with tainted data. Otherwise it is called a Taintless-Instruction. A security alert is raised whenever a Taintless-Instruction encounters tainted data at runtime. The proposed architecture is implemented on the SimpleScalar simulator. The preliminary results from experiments on SPEC CPU 2000 benchmarks show that there are a significant amount of Taintless-Instructions. We also demonstrate effective usages of our architecture to detect buffer overflow and format string attacks.	application security;buffer overflow;central processing unit;experiment;loadable kernel module;program counter;run time (program lifecycle phase);specfp;taint checking;uncontrolled format string	Jingfei Kong;Cliff Changchun Zou;Huiyang Zhou	2006		10.1145/1181309.1181313	program counter;software security assurance;parallel computing;real-time computing;buffer overflow;computer science;operating system;database;programming language	Arch	-55.731145557856166	55.99599525206116	65183
0816e8e3ee4f503586075c126bb25ee964bf164a	towards reproducible cyber-security research through complex node automation	complexity theory;cyber security ground truth data synthesis automation simulation;security of data data privacy;computer security automation data models complexity theory virtual machine monitors browsers;cyber security experiments cyber security research complex node automation privacy concerns contractual requirements data generation toolchain complex nodes;browsers;computer security;virtual machine monitors;data models;automation	Performing cyber-security experiments is challenging as access to necessary data is limited, especially at large-scale. If data is available, sharing is typically not possible due to privacy concerns and contractual requirements. Hence, reproducibility of research and comparability of results is difficult. For a prevailing empirical domain of research, this is a methodological problem. To address this problem, in this paper we propose a data generation toolchain based on automation of complex nodes - cnaf. This system is better suited for performing cyber-security experiments than related work. Especially, as our approach explicitly welcomes and leverages complexity, cnaf is capable of generating realistic data sets.	automation;communications protocol;computer security;experiment;information security;linux;malware;microsoft windows;privacy;requirement;scalability;simulation;synthetic data;toolchain;web crawler	Sebastian Abt;Reinhard Stampp;Harald Baier	2015	2015 7th International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2015.7266527	embedded system;data modeling;computer science;operating system;automation;data mining;world wide web;computer security;computer network	Robotics	-60.63182297105974	60.16485254274479	65303
83574c335dcc4809842d969e4115ca9fe154a284	automated crash filtering for arm binary programs	software;registers flow graphs security computer bugs algorithm design and analysis software;software tools program compilers program debugging program diagnostics program testing safety critical software;compiler optimization crash filtering arm binary program security related crash vulnerability static taint analysis crash filter security critical bug software testing tool;compiler optimization techniques;flow graphs;compiler optimization techniques crashes static program analyses binary analyses;static program analyses;registers;crashes;binary analyses;security;computer bugs;algorithm design and analysis	This paper aims to help to differentiate security related crashes from benign vulnerabilities, using static taint-analysis. To achieve this goal, we propose a tool named Crash Filter, which determines if a crash can be made to be exploitable or not, by analyzing ARM binary codes. We envision that the proposed analysis would help to timely fix security-critical bugs.	arm architecture;binary code;experiment;polaris office;software bug;taint checking;ver (command)	Ki-Jin Eom;Joon-Young Paik;Seong-Kyun Mok;Hyeon-Gu Jeon;Eun-Sun Cho;Dong-Woo Kim;Jaecheol Ryu	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.139	software security assurance;algorithm design;parallel computing;real-time computing;software bug;computer science;information security;operating system;database;crash;processor register;programming language;computer security	SE	-57.36889609043476	56.2750745508208	65362
72018772c21ff744f762c5500069c86fea281b30	obfuscating program control flow with intel sgx		Control flow obfuscation is a direct approach in protecting the confidentiality of program logic. However, existing works in this direction either failed to offer high confidentiality guarantees or incurred high performance overheads. In this paper, we propose CFHider, a high security and high performance control flow obfuscation technique. By leveraging program transformation and Intel Software Guard Extension (SGX) technology, CFHider hides control flow information to an opaque yet trusted execution environment, i.e., the SGX enclave. Our evaluation showed that, CFHider extensively raises the bar for reverse-engineering attacks targeting on the control flow confidentiality, and incurs a moderate performance overhead.	confidentiality;control flow;obfuscation (software);overhead (computing);program transformation;reverse engineering;trusted execution environment	Yongzhi Wang;Yulong Shen;Ke Cheng;Yibo Yang;Cuicui Su;Anter Faree	2018		10.1145/3183440.3194990	real-time computing;computer science;guard (information security);control flow;overhead (business);program transformation;cloud computing;software;obfuscation	Security	-55.219016342680035	56.468389123765704	65412
05f18c8a107f1ffb23134b4b22aafadbe137109d	covering your assets in software engineering	assets;software engineering information security computer security protection application software risk analysis availability communications technology software safety legislation;software engineering security of data;software engineering;security requirement elicitation technique;security requirements;software engineering project;security requirement elicitation technique software engineering project;security of data;security requirements assets	Many security requirements elicitation techniques implicitly assume that assets are identified on beforehand, but few actually describe how this should be done. In this paper we suggest one specific method that can be used to identify and prioritize assets in any software engineering project.	requirement;requirements elicitation;software engineering	Martin Gilje Jaatun;Inger Anne Tøndel	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.8	software security assurance;reliability engineering;reusability;security management;verification and validation;security through obscurity;software engineering process group;security information and event management;security engineering;asset;software verification;software project management;systems engineering;engineering;social software engineering;software development;requirement;software engineering;software construction;software deployment;software requirements	SE	-55.67214351779224	48.147988012187	65435
ab6938ec199280213fc092b45abd6170ec95abda	analysis of docker security		Over the last few years, the use of virtualization technologies has increased dramatically. This makes the demand for efficient and secure virtualization solutions become more obvious. Container-based virtualization and hypervisor-based virtualization are two main types of virtualization technologies that have emerged to the market. Of these two classes, container-based virtualization is able to provide a more lightweight and efficient virtual environment, but not without security concerns. In this paper, we analyze the security level of Docker, a well-known representative of container-based approaches. The analysis considers two areas: (1) the internal security of Docker, and (2) how Docker interacts with the security features of the Linux kernel, such as SELinux and AppArmor, in order to harden the host system. Furthermore, the paper also discusses and identifies what could be done when using Docker to increase its level of security.	apparmor;docker;hardening (computing);hardware virtualization;hypervisor;linux;selinux;virtual reality;x86 virtualization	Thanh Bui	2015	CoRR		operating system;world wide web;computer security	Security	-52.375200474044924	57.3647170604836	65586
05bbb7040d3dd0f29aef9e47cb738654d630f943	hacking the dbms to prevent injection attacks	web applications;injection attacks;software security;dbms self protection;security	After more than a decade of research, web application security continues to be a challenge and the backend database the most appetizing target. The paper proposes preventing injection attacks against the database management system (DBMS) behind web applications by embedding protections in the DBMS itself. The motivation is twofold. First, the approach of embedding protections in operating systems and applications running on top of them has been effective to protect this software. Second, there is a semantic mismatch between how SQL queries are believed to be executed by the DBMS and how they are actually executed, leading to subtle vulnerabilities in prevention mechanisms. The approach -- SEPTIC -- was implemented in MySQL and evaluated experimentally with web applications written in PHP and Java/Spring. In the evaluation SEPTIC has shown neither false negatives nor false positives, on the contrary of alternative approaches, causing also a low performance overhead in the order of 2.2%.	database;experiment;java;mysql;operating system;overhead (computing);php;sql;spring framework;web application security	Iberia Medeiros;Miguel Beatriz;Nuno Ferreira Neves;Miguel Correia	2016		10.1145/2857705.2857723	computer science;database;world wide web;computer security	DB	-56.64275802277644	57.791080493988844	65760
6f187dc5d9aab2843fa7189ac2acfa21968fe6cf	cyber-physical systems: closing the gap between hardware and software			closing (morphology);cyber-physical system	Marcel Caria	2016	ERCIM News		computer security;cyber-physical system;software;computer science	Arch	-50.367733168720534	47.397239609928256	65830
5568ffc9640268919bcdaf01a97e240e439272bf	an improved design of the trustworthiness authentication mechanism of iaas	iaas;trusted computing;trustworthiness authentication mechanism	By improving resource utilization, cloud computing can greatly save costs and get users considerable profit. However, security issues have emerged as one of the most significant barrier to faster and more widespread adoption of cloud computing. Therefore, this paper focused on the trustworthiness of infrastructure as a service (IaaS) and designed a role-based authentication trustworthiness mechanism to ensure that the different roles in IaaS architecture are trusted. What's more, this paper also considered the interactions between different roles in cloud environment and designed relevant validation protocols. At last, we also designed some benchmarks to evaluate the performance overhead of this mechanism and the results showed the costs can be very little to be neglected. © Springer-Verlag Berlin Heidelberg 2013.	authentication;cloud computing;trust (emotion)	Xu Wu;Xiaqing Xie;Chuanyi Liu;Chunwen Li	2012		10.1007/978-3-642-35795-4_28	internet privacy;world wide web;computer security	HCI	-48.94232848877512	57.5243104764298	65847
77044a67058731705f3fe01eda4d47ca70841f90	runtime code reuse attacks: a dynamic framework bypassing fine-grained address space layout randomization.		Fine-grained address space layout randomization has recently been proposed as a method of efficiently mitigating ROP attacks. In this paper, we introduce a design and implementation of a framework based on a runtime strategy that undermines the benefits of fine-grained ASLR. Specifically, we abuse a memory disclosure to map an application’s memory layout on-the-fly, dynamically discover gadgets and construct the desired exploit payload, and finish our goals by using virtual function call mechanism—all with a script environment at the time an exploit is launched. We demonstrate the effectiveness of our framework by using it in conjunction with a real-world exploit against Internet Explorer and other applications protected by fine-grained ASLR. Moreover, we provide evaluations that demonstrate the practicality of run-time code reuse attacks. Our work shows that such a framework is effective and fine-grained ASLR may not be as promising as first thought. Keywords-code reuse; security; dynamic; fine-grained ASLR	.net framework;address space layout randomization;code reuse;internet explorer;return-oriented programming;run time (program lifecycle phase)	Yi Zhuang;Tao Zheng;Zhitian Lin	2014			parallel computing;real-time computing;distributed computing	Security	-55.586966271487185	56.7155812877569	66288
1d5210e6490fdf8ecc6ce0135e2441d26ed43dda	a hybrid approach for proving noninterference of java programs	noninterference property checking;language based security;program diagnostics;cvj framework;functional property verification;electronic mail;standards;interactive analysis;java programs noninterference properties;code level cryptographic analysis;program verification;theorem proving java program diagnostics program verification;theorem proving;key theorem prover java programs noninterference properties hybrid approach automatic analysis interactive analysis functional property verification joana cvj framework cryptographic privacy properties e voting system noninterference property checking;hybrid approach;automatic analysis;e voting system;cryptography;key theorem prover;java cryptography privacy electronic voting standards electronic mail;program analysis;code level cryptographic analysis language based security noninterference program analysis;joana;electronic voting;privacy;noninterference;java;cryptographic privacy properties	Several tools and approaches for proving non-interference properties for Java and other languages exist. Some of them have a high degree of automation or are even fully automatic, but over approximate the actual information flow, and hence, may produce false positives. Other tools, such as those based on theorem proving, are precise, but may need interaction, and hence, analysis is time-consuming. In this paper, we propose a hybrid approach that aims at obtaining the best of both approaches: We want to use fully automatic analysis as much as possible and only at places in a program where, due to over approximation, the automatic approaches fail, we resort to more precise, but interactive analysis, where the latter involves the verification only of specific functional properties in certain parts of the program, rather than checking more intricate non-interference properties for the whole program. To illustrate the hybrid approach, in a case study we use this approach - along with the fully automatic tool Joana for checking non-interference properties for Java programs and the theorem prover KeY for the verification of Java programs - as well as the CVJ framework proposed by Kuesters, Truderung, and Graf to establish cryptographic privacy properties for a non-trivial Java program, namely an e-voting system. The CVJ framework allows one to establish cryptographic indistinguishability properties for Java programs by checking (standard) non-interference properties for such programs.	approximation algorithm;automated theorem proving;concurrency (computer science);cryptography;functional programming;imperative programming;interaction;interference (communication);java;key;non-interference (security);proof assistant	Ralf Küsters;Tomasz Truderung;Bernhard Beckert;Daniel Grahl;Michael Kirsten;Martin Mohr	2015	2015 IEEE 28th Computer Security Foundations Symposium	10.1109/CSF.2015.28	program analysis;computer science;cryptography;theoretical computer science;shape analysis;programming language;java;privacy;algorithm	PL	-53.65423990395067	51.772292979036834	66517
12d013a547792edbba695dd78664a814ca994511	model-driven trust negotiation for web services	mandatory access control;hypermedia markup languages;formal specification;service provider;authorisation;web services public key access control identity management systems protection authorization information security markup languages scalability automatic generation control;state machine;web service;discretionary access control;policy language;formal verification;internet;credential validation trust serv model driven trust negotiation system web services internet discretionary access control mandatory access control service ubiquitousness policy language state machines lifecycle management tools automated runtime enforcement tools credential retrieval;access control models;access control;trust negotiation;public key infrastructure;hypermedia markup languages internet authorisation formal verification formal specification	"""The Trust-Serv trust negotiation framework supports policy lifecycle management for Web services. T rust negotiation is an approach to access control whereby access is granted based on trust established in a negotiation between the service requester and the service provider. 1 In this negotiation, credentials — signed assertions that describe the owner's attributes — are exchanged iteratively to build trust between the negotiation participants. Credentials are typically based on standards such as X.509v3, 2 simple public key infrastructure (SPKI), 3 or Security Assertion Markup Language (SAML). 4 Trust negotiation systems avoid several problems facing traditional access control models such as DAC (discretionary access control) and MAC (mandatory access control). 5 Scalability problems arise, for example, when attempting to store identity information for each requester. Another problem is that Web service providers often do not know requesters' identities in advance because of the ubiq-uitousness of services. These problems are accentuated in Web service environments because the services typically have large, dynamic requester populations. Several issues remain to be addressed in existing trust negotiation systems. (See the """" Related Work in Trust Negotiation """" sidebar on page 46.) Specifying trust negotiation policies still requires time-consuming hand coding and low-level programming. Because policy specification and enforcement are not clearly separated, policy enforcement often requires ad hoc implementations that do not scale well. 6 Using high-level visual models to represent policies makes them easier to comprehend (and thus, to modify). It also permits information generation for controlling negotiations. In this article we describe Trust-Serv, our trust negotiation framework for Web services, which features a policy language based on state machines. It is supported by lifecycle management and automated runtime enforcement tools. Credential retrieval and validation in Trust-Serv rely on predefined Web services that provide interactions with attribute assertion authorities and public key infrastructure."""	credential;discretionary access control;hand coding;high- and low-level;hoc (programming language);interaction;low-level programming language;mandatory access control;model-driven integration;population;public key infrastructure;public-key cryptography;rust;scalability;security assertion markup language;simple public-key infrastructure;ws-trust;web service;x.509	Halvard Skogsrud;Boualem Benatallah;Fabio Casati	2003	IEEE Internet Computing	10.1109/MIC.2003.1250583	service provider;web service;the internet;formal verification;discretionary access control;computer science;access control;public key infrastructure;formal specification;database;authorization;finite-state machine;law;world wide web;computer security	Security	-50.06349028177221	54.72553036762691	66554
d26db266d82ae539a86bab90de236da432aabaae	tagubig - taming your big data		Every day we generate great amounts of data, from and to various devices, that blindly share all over the globe, over different platforms, service providers and individual users. It is not possible today for an individual to be sure that what s/he has shared is exactly what s/he wants to be shared and to whom. Individuals have no control over their Big Data (BiDa) before it is released “in the wild”. With the use of more and more devices and applications generating great amounts of individualsu0027 data, each one of us is bound to be drawn in our BiDa. On the other hand, usersu0027 personal BiDa can potentially be a useful source of information to better understand what data are used for each individualu0027s interaction profile and, when we know this, what are the most adequate measures to protect that data. Thus, we can better tame what we better know. Current access control models need to take this challenge on board because systemu0027s privacy and security controls are more likely to be compromised due to the misconfiguration or inadequate access control policies rather than the failure of cryptographic primitives or protocols. This paper presents TagUBig - Taming Your Big Data, a framework to control and improve transparency, privacy, availability and usability when users interact with applications. The framework comprises components that can face some of the European General Data Protection Regulation (GDPR) key challenges regarding personal data protection, which are introduced in the paper. A healthcare proof of concept use-case scenario is also presented together with the description and discussion of the features that have already been developed and tested. TagUBig can be used to empower individual users, foster trust and be applied in any domain that requires the best balance between availability and confidentiality in todayu0027s mobile anytime/anywhere environment.		Ana Ferreira;Joana Muchagata	2018	2018 International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2018.8585539	computer security;cryptographic primitive;service provider;access control;big data;general data protection regulation;usability;data protection act 1998;security controls;computer science	DB	-50.50556030564106	56.78572739865018	66632
68e742523f493b78111031a5a221a8cf767064f4	longkit - a universal framework for bios/uefi rootkits in system management mode.		The theoretical threat of malware inside the BIOS or UEFI of a computer has been known for almost a decade. It has been demonstrated multiple times that exploiting the System Management Mode (SMM), an operating mode implemented in the x86 architecture and executed with high privileges, is an extremely powerful method for implanting persistent malware on computer systems. However, previous BIOS/UEFI malware concepts described in the literature often focused on proof-of-concept implementations and did not have the goal of demonstrating the full range of threats stemming from SMM malware. In this paper, we present LONGKIT, a novel framework for BIOS/UEFI malware in the SMM. LONGKIT is universal in nature, meaning it is fully written in position-independent assembly and thus also runs on other BIOS/UEFI implementations with minimal modifications. The framework fully supports the 64-bit Intel architecture and is memory-layout aware, enabling targeted interaction with the operating system’s kernel. With LONGKIT we are able to demonstrate the full potential of malicious code in the SMM and provide researchers of novel SMM malware detection strategies with an easily adaptable rootkit to help evaluate their methods.	64-bit computing;authentication;bios;computer;hooking;malware;open-source software;operating system;position-independent code;prototype;rootkit;seabios;stemming;system call;unified extensible firmware interface;x86	Julian Rauchberger;Robert Luh;Sebastian Schrittwieser	2017		10.5220/0006165603460353	computer security;computer science;bios;rootkit;system management mode	Security	-54.031076517378416	56.63983525396605	66643
67dfa160dc38ae1cc9e235098c4bc4ab2ff79848	motivating security-aware energy management		This article presents a security review of energy management systems and makes the first case for security-aware energy management. The authors demonstrate how contemporary energy management systems can be misused to induce faults that break security on modern Android phones.	android	Adrian Tang;Simha Sethumadhavan;Salvatore J. Stolfo	2018	IEEE Micro	10.1109/MM.2018.032271066	real-time computing;computer engineering;software;android (operating system);computer science;energy management	Embedded	-51.094988529602844	56.1188289624456	67461
34af861760566a11f32a3af3a32fd759c47f8583	selecting appropriate counter-measures in an intrusion detection framework	libraries;idmef counter measures intrusion detection computer infrastructure intrusion circumvention software library decision support tool formal method anti correlation diams;software library;decision support tool;formal specification;software libraries security of data decision support systems formal specification software tools;software libraries;intrusion detection libraries counting circuits distributed computing law legal factors ethics computer crime computer security conferences;distributed computing;response;computer crime;intrusion detection;france;diams;law;computer networks;ethics;formal method;computer security;idmef;symposia;counting circuits;legal factors;intrusion circumvention;counter measures;decision support systems;computer infrastructure;software tools;countermeasures;correlation;anti correlation;security of data;intrusion detection computers;conferences	Since current computer infrastructures are increasingly vulnerable to malicious activities, intrusion detection is necessary but unfortunately not sufficient. We need to design effective response techniques to circumvent intrusions when they are detected. Our approach is based on a library that implements different types of counter-measures. The idea is to design a decision support tool to help the administrator to choose, in this library, the appropriate counter-measure when a given intrusion occurs. For this purpose, we formally define the notion of anti-correlation which is used to determine the counter-measures that are effective to stop the intrusion. Finally, we present a platform of intrusion detection, called DIAMS, that implements the response mechanisms presented in this paper.	component-based software engineering;decision support system;intrusion detection system;java;library (computing);overhead (computing);prolog;prototype;recovery time objective;semantics (computer science);system administrator;taxonomy (general);temporal logic	Frédéric Cuppens;Sylvain Gombault;Thierry Sans	2004	Proceedings. 17th IEEE Computer Security Foundations Workshop, 2004.	10.1109/CSFW.2004.18	anomaly-based intrusion detection system;intrusion detection system;formal methods;decision support system;computer science;theoretical computer science;countermeasure;data mining;programming language;computer security;intrusion prevention system;algorithm	Security	-58.84247227459892	54.4352451920102	67477
4415646738dab619e6f703e2798a766789156616	xss vulnerability detection using optimized attack vector repertory	grammar;web crawler xss attack vector repertory machine learning dynamic analysis;web servers;real world websites optimized attack vector repertory cross site script vulnerability detection web applications xss vulnerability detection optimal attack vector repertory optimization model machine learning algorithm;testing;会议论文;web crawler;html;machine learning;payloads;optimization;attack vector repertory;web sites learning artificial intelligence optimisation security of data;uniform resource locators;xss;html optimization payloads grammar web servers uniform resource locators testing;dynamic analysis	In order to detect the Cross-Site Script (XSS) vulnerabilities in the web applications, this paper proposes a method of XSS vulnerability detection using optimal attack vector repertory. This method generates an attack vector repertory automatically, optimizes the attack vector repertory using an optimization model, and detects XSS vulnerabilities in web applications dynamically. To optimize the attack vector repertory, an optimization model is built in this paper with a machine learning algorithm, reducing the size of the attack vector repertory and improving the efficiency of XSS vulnerability detection. Based on this method, an XSS vulnerability detector is implemented, which is tested on 50 real-world websites. The testing results show that the detector can detect a total of 848 XSS vulnerabilities effectively in 24 websites.	algorithm;cross-site scripting;machine learning;mathematical optimization;sensor;vector (malware);web application	Xiaobing Guo;Shuyuan Jin;Yaxing Zhang	2015	2015 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery	10.1109/CyberC.2015.50	cross-site scripting;payload;html;computer science;web crawler;data mining;grammar;database;dynamic program analysis;software testing;internet privacy;world wide web;computer security;web server	SE	-57.665608147918405	58.47251087770217	67496
f0d379a4bcb101207fef3653340029bba7ed54b6	formal techniques for safety-critical systems		One of the main challenges facing the software development as well as the hardware communities is that of demonstrating the correctness of built artifacts with respect to separately stated requirements. Runtime verification is a partial solution to this problem, consisting of checking actual execution traces against formalized requirements. A related activity is that of humans attempting to understand (or comprehend) what the system does when it executes, for validation purposes, or for simply operating the system optimally. For example, a key challenge in operating remote spacecraft is that ground operators must rely on the limited visibility available through spacecraft telemetry in order to assess spacecraft health and operational status. In this paper we illustrate the use of the rule-based runtime verification system LogFire for supporting such log comprehension. Specifically, LogFire is used for generating abstract events from the concrete events in logs, followed by a visualization of these abstract events using the D3 visualization framework.	abstract syntax;correctness (computer science);data validation;deadlock;digital subscriber line;high- and low-level;high-level programming language;holographic versatile card;lecture notes in computer science;list comprehension;log analysis;logic programming;requirement;rover (the prisoner);runtime verification;scala;software development;springer (tank);string (computer science);symbol (formal);thread (computing);tracing (software);type system	Cyrille Artho;Peter Csaba Ölveczky	2014		10.1007/978-3-319-17581-2	systems engineering;life-critical system;computer science	SE	-51.08583201090537	46.80045633298374	67530
198300942c9367ae287f3cb8005233606a9dce5c	how to break secure boot on fpga socs through malicious hardware		Embedded IoT devices are often built upon large system on chip computing platforms running a significant stack of software. For certain computation-intensive operations such as signal processing or encryption and authentication of large data, chips with integrated FPGAs, FPGA SoCs, which provide high performance through configurable hardware designs, are used. In this contribution, we demonstrate how an FPGA hardware design can compromise the important secure boot process of the main software system to boot from a malicious network source instead of an authentic signed kernel image. This significant and new threat arises from the fact that the CPU and FPGA are connected to the same memory bus, so that FPGA hardware designs can interfere with secure boot routines on FPGA SoCs that are without any interruption on regular SoCs. An enabling factor is that integrated hardware designs are likely bought from external partners and there is a realistic lack of security review at the system integrators. This facilitates flaws or even unwanted functionality in such hardware designs. We perform a proof of concept on a Xilinx Zynq-7000 FPGA SoC, and the threat can be generalized to other devices. We also present as effective mitigation, an easy-to-review and re-usable wrapper module which prevents any unauthorized memory access by included hardware designs.	amazon elastic compute cloud (ec2);amazon web services;authentication;authorization;black hat;booting;central processing unit;computation;computer security;design automation and test in europe;embedded system;emergent;encryption;field-programmable gate array;flash memory;hardware trojan;international federation for information processing;interrupt;jtag;kernel (operating system);local interconnect network;mpsoc;memory bus;reverse engineering;samuel ben jacob ibn jam;semiconductor intellectual property core;signal processing;software system;switzerland;system on a chip;three utilities problem;trojan horse (computing);unified extensible firmware interface;wrapping (graphics);yang	Nisha Jacob;Johann Heyszl;Andreas Zankl;Carsten Rolfes;Georg Sigl	2017	IACR Cryptology ePrint Archive	10.1007/978-3-319-66787-4_21	software system;system on a chip;memory bus;field-programmable gate array;computer hardware;software;computer science;encryption;central processing unit;compromise	Security	-53.40933857087774	55.98614770062424	67540
87ff09a94bc5d292edacc2939e755a098adb076b	mitigating the effects of internet timing faults across embedded network gateways	internet protocol;time constant;network protocol;embedded security;data stream;gateway;simulation;data management;real time data;embedded system;embedded network;timing fault;buffer overflow;predictive filter;industrial control;difference set;data flow;embedded device;timing attack	Extended Abstract Traditional embedded systems such as automobiles and industrial controls are increasingly being connected to enterprise computing facilities and the Internet. The usual approach to making such a connection is to install a gateway node which translates from Internet protocols to embedded field bus network protocols. Such connections raise obvious security concerns, because the gateway must guard against attacks on the embedded devices it serves. For our purposes, we’ll assume that typical enterprise and Internet vulnerabilities, such as buffer overflows, have already been taken care of. (Securing devices against traditional attacks is no small matter, but we are interested in uniquely embedded issues.) Beyond normal gateway functions, an Internet to embedded gateway must also prevent timing faults and timing attacks from crossing over the gateway to affect the operation of attached embedded systems. An example of timing fault propagation would be severe clumping of messages on the Internet side so that many messages arrive at the gateway all at once, disrupting embedded system operation. While a queue can reduce the loss of incoming data and mitigate network overload, it cannot necessarily protect against timing-related faults on the embedded side of the gateway. We report simulation results for several mechanisms to mitigate the effects of Internet message timing variations (whether due to faults or malicious attacks) on the performance of networked embedded systems using real-time data. Problems are caused primarily by excessive data delivery delay rather than messages being dropped from arriving clumps. This means that putting a queue in the gateway to manage arriving data clumps is typically worse than using no mitigation mechanism at all. Using a predictive filter seems intuitively better than using a queue, but finding a good generalized predictive filter is also quite difficult. We believe that managing data streams from the Internet to embedded systems will require careful attention to the nature and time constants of data flowing through the gateway. Moreover, it seems likely that each distinct data stream will need a different set of data management mechanisms and policies at the gateway. In this case, one size does not fit all, making the design of a robust gateway a difficult problem that will require careful modeling of data value behavior for every gateway built.	buffer overflow;bus bunching;bus network;care-of address;communications protocol;embedded system;enterprise software;fieldbus;internet protocol suite;malware;real-time clock;real-time data;simulation;software propagation	Philip Koopman;Justin Ray	2010		10.1007/978-3-642-12104-3_1	real-time computing;engineering;distributed computing;computer security	Embedded	-60.5153518026053	49.83019908005491	67794
a61a7fde25bbd2375f51f4b9c76dadf06b192bfe	cloud security audit for migration and continuous monitoring		Security assurance in cloud computing is one of the main barriers for wider cloud adoption. Potential cloud computing consumers like to know whether the controls in cloud environments can adequately protect critical assets migrated into the cloud. We present a cloud security audit approach to enable users' evaluate cloud service provider offerings before migration, as well as monitoring of events after migration. Our approach entails a set of concepts such as actor, goals, monitoring, conditions, evidence and assurance to support security audit activities. These concepts are considered as a language for describing the properties necessary for cloud security audit both before and after migration. Finally, a real cloud migration use case is given to demonstrate the applicability of the security audit approach.	actor model;business continuity;cloud computing security;communicating sequential processes;cryptographic service provider;information privacy;information technology security audit;refinement (computing);scott continuity;trust (emotion)	Umar Mukhtar Ismail;Shareeful Islam;Haralambos Mouratidis	2015	2015 IEEE Trustcom/BigDataSE/ISPA	10.1109/Trustcom.2015.486	information security audit;computer security model;cloud computing security;cloud computing;business;internet privacy;world wide web;computer security	DB	-49.1006229936499	56.860771631750644	67819
ea3cc15ac1050d52db47a3a77ad74a0c4dc08758	design and implementation of an efficient framework for behaviour attestation using n-call slides	remote attestation;dynamic behaviuor;trusted computing;security	We present design and implementation of behaviour based attestation of an enterprise centric application. Remote attestation is used to measure the trustworthiness of the target platform. Some of the techniques proposed in the past are hash based which are efficient but could not measure malicious behaviour of an application caused by buffer overflow attacks or misconfigured by end user. To tackle these attacks the runtime dynamic behaviour of the target application should be measured and verified. In this regard, behaviour based attestation techniques are proposed but they have problems of efficiency and verification at the challenger end. In this research, we have designed and implemented an architecture of sliding windows of system calls which reduces measurement of the application's behaviour and is successfully able to identify trustworthiness of the target application. We have reproduced the previous system calls based techniques and compared the results with our work to prove the performance improvements.	buffer overflow;microsoft windows;system call;trust (emotion);trusted computing	Roslan Ismail;Toqeer Ali Syed;Shahrulniza Musa	2014		10.1145/2557977.2558002	embedded system;direct anonymous attestation;computer science;information security;internet privacy;trustworthy computing;world wide web;computer security	Security	-55.88767934702153	58.13545371312458	67948
42fd76205c761177218d6ce89b122fe8db193ddc	chain-of-trust for microcontrollers using sram pufs: the linux case study		Many security challenges have emerged from what is defined as Internet of Things (IoT), due to the inherent permanent connection of devices involved in networks. Furthermore, IoT devices are often deployed in unattended working environment and, hence, they are prone to physical attacks. Attackers take advantages of such weaknesses to clone devices, tamper the software installed on them and extract cryptographic keys. In this paper, we propose a technique to exploit Static Random Access Memory based Phisical Unclonable Functions to have available a chain-oftrust on a microcontroller device. We prove its effectiveness in terms of reliability and required overhead by introducing a case study based on the STM32F7 device running the Linux operating system.	chain of trust;linux;microcontroller;static random-access memory	Domenico Amelino;Mario Barbareschi;Antonino Mazzeo	2016		10.1007/978-3-319-49109-7_72	embedded system;parallel computing;operating system	OS	-52.1130485332126	59.6804970010931	68060
778f87c2dc8e60054bf751c30ddc925909aa7848	a lightweight approach to specification and analysis of role-based access control extensions	role based access control;separation of duty;alloy;arbac97;separation of duties	Role-based access control is a powerful and policy-neutral concept for enforcing access control. Many extensions have been proposed, the most significant of which are the decentralised administration of role-based systems and the enforcement of constraints. However, the simultaneous integration of these extensions can cause conflicts in a later system implementation. We demonstrate how we use the Alloy language for the specification of a conflict-free role-based system. This specification provides us at the same time with a suitable basis for further analysis by the Alloy constraint analyser.	alloy (specification language);alloy analyzer;role-based access control	Andreas Schaad;Jonathan D. Moffett	2002		10.1145/507711.507714	real-time computing;computer science;role-based access control;separation of duties;computer security	Security	-51.78298990409195	51.277172250616864	68130
c1dafcf7326cf05f22d83c8b7dd5b7624982249d	the management of users, roles, and permissions in jdosecure	java virtual machine;330 wirtschaft;distributed applications;graphic user interface;java authentication and authorization service;code mobility;thread persistence	The Java Data Objects (JDO) specification proposes a transparent and database-independent persistence abstraction layer for Java. Since JDO is designed as a lightweight persistence approach, it does not provide any authentication or authorization capabilities in order to restrict user access to persistent objects. The novel security approach, JDOSecure, introduces a role-based permission system to the JDO persistence layer, which is based on the Java Authentication and Authorization Service (JAAS). However, using JAAS policy files to define appropriate permissions becomes more complex and, therefore, error-prone with an increasing number of different users and roles. Thus, JDOSecure comprises a management solution for users, roles, and permissions. It allows storing the information which is necessary for authentication and authorization in any arbitrary JDO resource. Furthermore, a Java-based administration utility with a graphical user interface simplifies the maintenance of security privileges and permissions.	abstraction layer;cognitive dimensions of notations;graphical user interface;java authentication and authorization service;java data objects;persistence (computer science)	Matthias Merz	2006		10.1145/1168054.1168067	java data objects;computer science;data access object;graphical user interface;internet privacy;world wide web;computer security;code mobility	Security	-49.97004536313457	54.03832347880665	68202
4287f117da065d5aa690be1fb9782367a673764c	the ontology of metrics for security evaluation and decision support in siem systems	security information and event management;computer network security;countermeasure decision support system metrics ontology security evaluation siem systems computer network security security information representation ontological security data representation security metrics comprehensive security evaluation countermeasure generation;countermeasure decision support;ontologies artificial intelligence;measurement ontologies cognition probability laboratories computer security;decision support systems;countermeasure decision support security information and event management ontology security metrics;ontology;ontologies artificial intelligence computer network security decision support systems;security metrics	Analysis of computer network security is a serious challenge. Many security metrics has been proposed for this purpose, but their effective use for rapid and reliable security evaluation and generation of countermeasures in SIEM systems remains an important problem. The use of ontologies for security information representation in SIEM systems contributes largely to the success of this task. However, most of works on ontological security data representation does not take into account the ontologies of security metrics. This paper proposes a new approach on using security metrics which is based on their ontological representation and serves for comprehensive security evaluation and subsequent countermeasure generation. The novelty of the proposed approach is that ontology of security metrics is viewed as a core component of a countermeasure decision support system. The proposed solutions are tested on a specific example.	computer security;data (computing);decision support system;information security;network security policy;ontology (information science);security information and event management	Igor V. Kotenko;Olga Polubelova;Igor Saenko;Elena Doynikova	2013	2013 International Conference on Availability, Reliability and Security	10.1109/ARES.2013.84	software security assurance;computer security model;standard of good practice;cloud computing security;security through obscurity;security information and event management;security engineering;security convergence;asset;computer science;knowledge management;information security;data mining;human-computer interaction in information security;security service;security testing;computer security	EDA	-56.63068133366093	48.7789349078794	68400
90264eb3d668722480008d38238357937dba28dc	log analysis using temporal logic and reconstruction approach: web server case	log analysis;web application security;digital investigation;complex event processing;network forensics;intrusion detection system	We present a post-mortem log analysis method based on Temporal Logic (TL), Event Processing Language (EPL), and reconstruction approach. After showing that the proposed method could be adapted to any misuse event or attack, we specifically investigate the case of web server misuses. To this end, we examine five different misuses on WordPress web servers, and generate corresponding log files of these attacks for forensic analysis. Then we establish attack patterns and formalize them by means of a special case of temporal logic, i.e. many sorted first order metric temporal logic (MSFOMTL). Later on, we implement these attack patterns in the EPL, and performed experimental log analysis by using a time window mechanism sliding on sorted log records to evaluate effectiveness and efficacy of our proposed method. We found that our approach is potentially capable of providing a platform where investigators can define/store/share misuse patterns using a common language while providing fast and accurate forensic analysis on large log files.	attack patterns;central processing unit;computer security;data logger;esoteric programming language;esper_(software);first-order logic;intrusion detection system;library (computing);log analysis;open-source software;security information and event management;server (computing);temporal logic;transform, clipping, and lighting;web server;wordpress	Murat Gunestas;Zeki Bilgin	2016	JDFSL	10.15394/jdfsl.2016.1377	computer science;web log analysis software;data mining;world wide web;computer security	Web+IR	-56.99084171108842	58.31054000076989	68506
f952d3c697715c0d8ad3175318738c77224418c8	trend of online flash xss vulnerabilities	actionscript;web security;adobe flash;cross site scripting	"""Flash objects are widely embedded in web pages, supporting Rich Internet Applications using ActionScript. However, according to our survey, many Flash objects are seriously exposed to Cross-site Scripting vulnerabilities as they are usually coded without proper sanitization of their inputs. This becomes a potential danger for cyber users. In this paper, we analyze XSS in online Flash and present an engine FXD (Flash XSS Detector) for automatically scrambling Flash files in web pages and checking whether or not they are vulnerable to XSS. We call vulnerable ActionScript functions """"key functions"""" and divide them into four categories by its functionality. The usability of FXD is further evaluated by disposing it in real-world websites. Our results reveal that at least 48 Flash applications in 18% of Alexa top 100 sites on the web are vulnerable to XSS. Each of these vulnerable Flash objects has been verified and confirmed of their XSS flaws. Finally, we discuss a new trend of Flash XSS, nowadays it is mainly caused by combination of key functions in different categories."""	actionscript;adobe flash;cross-site scripting;embedded system;rich internet application;sanitization (classified information);usability;web page	Qixu Liu;Yuqing Zhang;Huan Yang	2013		10.1145/2508859.2512516	cross-site scripting;actionscript;computer science;internet security;internet privacy;world wide web;computer security	Security	-57.03250745801357	60.39402444976135	68516
62cd6d4b8d1a6597e2cb5a72e00144f342f7949f	how practical is homomorphically encrypted program execution? an implementation and performance evaluation	resource allocation;secure function evaluation;encrypted circuits;software performance evaluation;encrypted circuits homomorphic encryption secret program execution secure function evaluation;software architecture;virtual machines;cryptography;software architecture homomorphical encrypted program execution homomorphic cryptography ground breaking advances cloud computing problems real world problems smart vercauteren system arbitrary programs execution nonlinear secret programs untrusted resource encrypted circuits encrypted virtual machine processor architecture read write memory access dynamic parameters nonlinear programs branch decisions rendering runtime environment program execution encrypted machine code;secret program execution;virtual machines cloud computing cryptography resource allocation software architecture software performance evaluation;encryption integrated circuit modeling registers logic gates polynomials;cloud computing;homomorphic encryption	"""Homomorphic cryptography has received a lot of attention due to potentially ground breaking advances in cryptography. However it is also surrounded by a lot of hyperbole such as """"ground breaking advances"""", """"this will solve all Cloud computing problems"""" to """"it is completely impractical"""" and """"it will never work for real world problems"""". In previous work we showed how homomorphic encryption can be used to execute arbitrary programs in encrypted space, showing that at least in theory real world problems can be computed protected by homomorphic cryptography without losing generality. In this paper we expand our work to evaluate how practical current homomorphic cryptography based on the Smart-Vercauteren system is for executing arbitrary programs on untrusted resources. For this we present the implementation of a method to compute non-linear secret programs on an untrusted resource using encrypted circuits embedded in an encrypted virtual machine. We successively show how a processor architecture using encrypted circuits can be implemented so it can support read and write memory access, dynamic parameters and non-linear programs that render branch-decisions at runtime. The system comprises the runtime environment for program execution and an assembler to generate the encrypted machine code. We present performance evaluation of the sub-components as well as the complete system. The system represents a flexible prototype for homomorphic program execution in software and system architecture."""	assembly language;cloud computing;cryptography;embedded system;homomorphic encryption;linear programming;machine code;nonlinear system;performance evaluation;prototype;run time (program lifecycle phase);runtime system;systems architecture;virtual machine	Michael B Brenner;Henning Perl;Matthew Smith	2012	2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2012.174	real-time computing;computer science;theoretical computer science;distributed computing;homomorphic secret sharing	Security	-52.794820950900075	55.8426468137351	68633
6e5abc059796d854f2433be1daba116b00d737bf	ransomware detection based on v-detector negative selection algorithm		As a new type of malicious software, ransomware is one of the biggest security threats in recent years. Inspired by biological immune system, a ransomware detection method based on V-detector negative selection algorithm with mutation optimization is proposed, which is referred to op-RDVD. The behavioral features of ransomware are extracted through dynamic analysis, such as hard disk reading and writing, the document encryption and deletion, etc. Some of benign samples are used to build the self space. The variable-sized detectors are generated both randomly and extracted from ransomware. To improve the ransomware detection accuracy and efficiency, optimize the space distribution of detectors through clone and mutation, achieving maximized coverage of non-self space and minimized overlapping among detectors. The experimental results show that our algorithm has better detection ability than that of the previous method.	artificial immune system;computer security;cyberspace;encryption;hard disk drive;malware;mathematical optimization;randomness;sandbox (computer security);selection algorithm;sensor	Tianliang Lu;Lu Zhang;Shunye Wang;Qi Gong	2017	2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)	10.1109/SPAC.2017.8304335	feature extraction;negative selection;malware;encryption;cryptography;clone (java method);detector;algorithm;ransomware;computer science	SE	-59.18870836589573	60.28403194558061	68766
47f63dd64d34194d68659c60df534856d0cd5f88	a generic filter driver for file classification in linux	hydrogen fuel cell;avr microcontroller;system management	Whenever, user has to deal with lots of files present in the system, managing and storing these files systematically is very important in order to make it easier to access them. Here comes the role of our FS Filter Driver which helps user to classify these files and check the intrusions in these files and store them in separate directories according to their file extensions. It also classifies the files which are downloaded from the Internet. Thus Driver eases the programmer's job of handling a lot of files by classifying them systematically.	filter driver;internet;linux;programmer	Pravin Dilp;Ajit Ambeka;Pramila Chawan	2011		10.1145/1980022.1980344	embedded system;computer hardware;computer science;operating system;data file	OS	-53.92384708645383	58.08260043121407	68790
29dc0b41ed6df7237a303cb70e58bc15c65da7a7	mining security-sensitive operations in legacy code using concept analysis	authorization policy enforcement;manuals;file servers;program diagnostics;policy enforcement;pattern clustering;idiomatic resource manipulation;security sensitive operation mining;lattices;software maintenance;authorisation;resource management;software systems;data mining;concolic testing;domain knowledge;directed random testing;static analysis concept analysis security sensitive operation mining legacy code authorization policy enforcement idiomatic resource manipulation candidate fingerprint pattern clustering;concept analysis;fingerprint recognition;safety critical software;candidate fingerprint;fingerprint recognition authorization file servers manuals pattern analysis resource management access control linux lattices software systems;linux;pattern analysis;authorization;access control;static analysis;software maintenance authorisation data mining pattern clustering program diagnostics safety critical software;legacy code	his paper presents an approach to statically retrofit legacy servers with mechanisms for authorization policy enforcement. The approach is based upon the obser- vation that security-sensitive operations performed by a server are characterized by idiomatic resource manipula- tions, called fingerprints. Candidate fingerprints are auto- matically mined by clustering resource manipulations using concept analysis. These fingerprints are then used to iden- tify security-sensitive operations performed by the server. Case studies with three real-world servers show that the approach can be used to identify security-sensitive opera- tions with a few hours of manual effort and modest domain knowledge.	authorization;cluster analysis;experiment;fingerprint;formal concept analysis;legacy code;mined;server (computing)	Vinod Ganapathy;Dave King;Trent Jaeger;Somesh Jha	2007	29th International Conference on Software Engineering (ICSE'07)	10.1109/ICSE.2007.54	computer science;resource management;operating system;software engineering;data mining;database;authorization;programming language;computer security	SE	-57.75276840346944	55.19803287297968	68855
66bc0e9ba9499f9781f9b6650f896ae5cff26af2	tvguarder: a trace-enable virtualization protection framework against insider threats for iaas environments	cloud security;virtualization;trace enable protection;vm image files;insider attackers	Cloud computing has a most vulnerable security concerns as virtualization. This paper presents a Traceenable Virtualization protection framework named TVGuarder, which protects IaaS user’s important data from being illegally accessed or maliciously damaged by insider attacks. A threat model is established to characterize cloud-oriented insider attacks and countermeasures are proposed in TVGuarder. First, LSM hooks in host OS kernel are leveraged to enforce that VM images could only be accessed by host virtualization service. Second, a trusted loading mechanism is proposed to prevent tampered or disguised virtualization process from being executed in Host OS. Third, a log-based back tracing mechanism is designed to record full call trace of VM operations and guarantee that only legitimate VM operations are allowed. TVGuarder has been implemented in Openstack platform and several comprehensive experiments are conducted. Experimental results show that TVGuarder can identify several important insider attacks and protect virtual machine images with only a small performance degradation. TVGuarder: A Trace-Enable Virtualization Protection Framework Against Insider Threats for IaaS Environments	call of duty: black ops;cloud computing;computer science;jing;software development	Li Lin;Shuang Li;Bo Li;Jing Zhan;Yong Zhao	2016	IJGHPC	10.4018/IJGHPC.2016100101	cloud computing security;full virtualization;virtualization;computer science;operating system;internet privacy;computer security	Security	-52.67281460316815	57.25465491911339	68879
4fed658f3bb65c40bb270760c16eee76cb92f492	khepontheweb: open access to a mobile robot on the internet	remote access;information resources;remote control;log files;web server khepontheweb open access remote access control interface netsurfer behavior khepera mobile robot log files;mobile robot;mobile robots internet robot vision systems cameras communication standards communication networks human robot interaction watches performance analysis information analysis;client server systems;graphical user interfaces telerobotics internet information resources client server systems;graphical user interfaces;internet;community networks;open access;software component;telerobotics;internet robotics	For years research has focused on ways to allow remote access via standard communication networks to unique or expensive structures. With the growth of the Internet, one finds more and more devices connected to it. Despite the fact that one may spy on other people with hundreds of cameras, it is currently possible to interact only with a few robots, which often have restricted access. To use a camera over the web, the user usually just sits and watches or sometimes has the ability to choose different camera orientation/views. With a robot, you have strong interaction. For instance, with a mobile robot equipped with an arm you can move along the floor and grasp objects. Discovering the control interface, the user has to understand rapidly the goal of the site and what the possibilities of the robot are in order to achieve them. The article analyses one year of netsurfer behavior regarding the use of KhepOnTheWeb, which was realized to demonstrate some possibilities of remote control of a Khepera mobile robot. After one year of access, we performed an analysis of the log files in order to understand the behavior of the public facing such an installation. This analysis was rather difficult because of the large amount of data involved, and specific software was developed in order to extract and present the relevant information. The goal of the project is presented, the hardware and software components of our robot installation are described, and the analysis of the web server log files is discussed. We also introduce another concept of a remote-controlled robot on the web.	internet;mobile robot	Patrick Saucy;Francesco Mondada	2000	IEEE Robot. Automat. Mag.	10.1109/100.833574	telerobotics;mobile robot;embedded system;the internet;simulation;computer science;artificial intelligence;component-based software engineering;social robot;graphical user interface;world wide web;personal robot;remote control	Robotics	-50.4397936141906	46.430202863793774	68894
3e3407a58bc63e408a8a58041e781f06baf39ad7	virtual simulation of distributed ip-based designs	client server architecture;intellectual property;design flow;client server systems;intellectual property protection;model reduction;internet;virtual machines;client server systems virtual machines industrial property java electronic design automation internet;costs intellectual property java internet protection electronic design automation and methodology productivity permission backplanes circuit simulation;nonlinear circuits;industrial property;krylov subspace;seamless transition virtual simulation distributed ip based designs design flows third party intellectual property component instantiation javacad internet based eda tool secure client server architecture cost estimation intellectual property protection;cost estimation;java;electronic design automation	To be fully successful, any IP-based design flow must address two major challenges: First, it must provide techniques that assess correctness and quality (in terms of area, speed, power, and testability) of designs containing IP components. Second, it must guarantee IP protection for both the vendor (IP provider) and designer (IP user). If the provider fully disclosed the IP component to the user, validating a design containing the component would be akin to validating a fully proprietary system. However, providers almost never grant full IP disclosure, because doing so would mean giving up the IP’s full value. Likewise, IP users do not want to fully disclose the content of their designs to IP providers. Hence, neither party ends up fully owning the information needed to carry out complete system validation. Before purchasing a component, the IP user wants a cost estimate of the area, speed, power, and testability of instantiating the component. During preliminary design exploration, approximate cost estimates, often available from standard data sheets, might suffice. But as the design is refined, the user might need far more accurate information. First, he might want an abstract functional model to test the component’s functionality within the design. Second, he might want accurate cost estimates, which he cannot obtain without at least partially knowing the component’s implementation and environment. The Virtual Socket Interface Alliance (VSIA) Virtual Simulation of Distributed IP-Based Designs Design Reuse	approximation algorithm;correctness (computer science);datasheet;function model;purchasing;simulation;software testability;verification and validation	Marcello Dalpasso;Alessandro Bogliolo;Luca Benini	1999		10.1145/309847.309866	embedded system;electronic engineering;real-time computing;electronic design automation;computer science;operating system;computer security;intellectual property;computer network	EDA	-52.823147344369204	55.186230436550055	68942
8d5d608397fa45a68a630e52b66e479765900cfe	an exploratory analysis of microcode as a building block for system defenses		Microcode is an abstraction layer used by modern x86 processors that interprets user-visible CISC instructions to hardware-internal RISC instructions. The capability to update x86 microcode enables a vendor to modify CPU behavior in-field, and thus patch erroneous microarchitectural processes or even implement new features. Most prominently, the recent Spectre and Meltdown vulnerabilities were mitigated by Intel via microcode updates. Unfortunately, microcode is proprietary and closed source, and there is little publicly available information on its inner workings. In this paper, we present new reverse engineering results that extend and complement the public knowledge of proprietary microcode. Based on these novel insights, we show how modern system defenses and tools can be realized in microcode on a commercial, off-the-shelf AMD x86 CPU. We demonstrate how well-established system security defenses such as timing attack mitigations, hardware-assisted address sanitization, and instruction set randomization can be realized in microcode. We also present a proof-of-concept implementation of a microcode-assisted instrumentation framework. Finally, we show how a secure microcode update mechanism and enclave functionality can be implemented in microcode to realize a small trusted execution environment. All microcode programs and the whole infrastructure needed to reproduce and extend our results are publicly available.	abstraction layer;central processing unit;exploratory testing;microarchitecture;microcode;reverse engineering;sanitization (classified information);trusted execution environment;x86	Benjamin Kollenda;Philipp Koppe;Marc Fyrbiak;Christian Kison;Christof Paar;Thorsten Holz	2018		10.1145/3243734.3243861	operating system;computer security;timing attack;vendor;x86;reverse engineering;instruction set;computer science;microcode;abstraction layer;complex instruction set computing	Security	-55.09841343571779	56.27238120731847	69244
3d334aeddcd1a091fcba25559bfbf9f068f73ce2	integrating attacker behavior in it security analysis: a discrete-event simulation approach	attacker behavior;modeling and simulation;it security;secure systems analysis and design	When designing secure information systems, a profound understanding of the threats that they are exposed to is indispensable. Today’s most severe risks come from malicious threat agents exploiting a variety of attack vectors to achieve their goals, rather than from random opportunistic threats such as malware. Most security analyses, however, focus on fixing technical weaknesses, but do not account for sophisticated combinations of attack mechanisms and heterogeneity in adversaries’ motivations, resources, capabilities, or points of access. In order to address these shortcomings and, thus, to provide security analysts with a tool that makes it possible to also identify emergent weaknesses that may arise from dynamic interactions of attacks, we have combined rich conceptual modeling of security knowledge with attack graph generation and discreteevent simulation techniques. This paper describes the prototypical implementation of the resulting security analysis tool and demonstrates how it can be used for an experimental evaluation of a system’s resilience against various adversaries.		Andreas Ekelhart;Elmar Kiesling;Bernhard Grill;Christine Strauss;Christian Stummer	2015	Information Technology and Management	10.1007/s10799-015-0232-6	countermeasure;security through obscurity;pre-play attack;vulnerability;covert channel;asset;computer science;security policy;data mining;modeling and simulation;internet privacy;computer security	Security	-61.7225746638081	60.06158446915557	69637
a972edc96ead3bdc555652ee47179db39abc28c8	effectively auditing iaas cloud servers	kernel;trusted cloud cloud computing trustworthiness audit remote attestation;servers cloud computing kernel hardware monitoring security;trusted computing cloud computing file servers;servers;monitoring;期刊论文;security;iaas cloud environment cloud computing cloud providers trustworthiness cloud services cloud applications physical server compromises remote attestation trusted third party cloud based ttp platform small private cloud;cloud computing;hardware	Cloud computing is broadly recognized as one of major factors in achieving more flexible, scalable, and efficient systems. However, as customers lose the direct control of their data and applications hosted by cloud providers, the trustworthiness of cloud services is a main issue that hinders the deployment of cloud applications. In this paper, we have developed a novel framework to detect compromises on physical servers in cloud services, via remote attestation with a Trusted Third Party (TTP). Furthermore, to avoid the TTP becoming a bottleneck, we have designed a cloud based TTP platform, using a small private cloud to audit large clouds. We have implemented a prototype system, and evaluated it with several common benchmarks to demonstrate its efficiency. Our experimental results show that the proposed framework is effective in detecting compromise and adds little overhead to a common IaaS cloud environment.	benchmark (computing);cloud computing;experiment;overhead (computing);prototype;scalability;sensor;software deployment;trust (emotion);trusted computing;trusted third party;user space	Chunlu Wang;Chuanyi Liu;Xiaoliang Wang;Yingfei Dong	2013	2013 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2013.6831151	panorama9;cloud computing security;kernel;cloud computing;computer science;information security;operating system;cloud testing;internet privacy;world wide web;computer security;server	Mobile	-51.67751649889637	57.67535986839074	69981
b113580aa6112d0eb88f289bcd11bc53f59e64bc	a framework introducing implications of rfid network threats to businesses		The radio frequency identification (RFID) technology is increasingly used in several industries for various business tasks (item tracking, inventory, etc.). Many types of security threats to RFID networks have been identified, but the impact of these threats on businesses remains unclear. This research aims at proposing a framework detailing the implications of RFID security threats to businesses. We followed an interpretive study to draw up the proposed framework. Based on a literature review, we established a classification of RFID usages (inventory management, payment systems, identity control, and tracking systems). A number of RFID network security threats (denial of service, spoofing, relay, etc.) were identified and explained. Consequently, a framework linking RFID threats to different types of usages in applications is proposed and explained. This framework exposes clearly the implication of every RFID threat on a specific usage of RFID regardless of the industry (healthcare, education, etc.).		Suadad Muammar;Sami Miniaoui	2017	IJBIS	10.1504/IJBIS.2017.10006283	radio-frequency identification;engineering;network security;health care;data security;tracking system;spoofing attack;computer security;payment;denial-of-service attack	Mobile	-49.57311442991152	60.15117856893281	69988
78eecb34a809f2967a8faeeb34c5d360add574d7	quantitative assessment of safety and security of system architectures for cyberphysical systems using the nfr approach	safety security monitoring wireless sensor networks communication system security wireless communication pipelines;software architecture security of data;cyberphysical systems cpss;wireless communication;monitoring;pipelines;safety;system architecture assessment cyberphysical systems cpss nonfunctional requirement nfr approach safety security;system architecture assessment quantitative assessment cyberphysical system cps nonfunctional requirement approach;security;wireless sensor networks;nonfunctional requirement nfr approach;system architecture assessment;communication system security	Cyberphysical systems (CPSs) are an integral part of modern societies since most critical infrastructures are controlled by these systems. CPSs incorporate computer-based and network-based technologies for the monitoring and control of physical processes. Two critically important properties of CPSs are safety and security. It is widely accepted that properties such as safety and security should be considered at the system design phase itself, particularly at the architectural level wherein such properties are embedded in the final system. However, safety and security are interrelated, and there seems to be a lack of techniques that consider both of them together. The nonfunctional requirement (NFR) approach is a technique that allows the simultaneous evaluation of both safety and security at the architectural level. In this paper, we apply the NFR approach to quantitatively evaluate the safety and security properties of an example CPS, i.e., an oil pipeline control system. We conclude that the NFR approach provides practical results that can be used by designers and developers to create safe and secure CPSs.	control system;embedded system;floor and ceiling functions;non-functional requirement;systems design	Nary Subramanian;Janusz Zalewski	2016	IEEE Systems Journal	10.1109/JSYST.2013.2294628	reliability engineering;wireless sensor network;computer science;systems engineering;engineering;information security;pipeline transport;computer security;wireless	Security	-56.02351037984181	49.9071789698482	70180
1e90de11a62e926a72b10776dd08d488e5ed865f	kguard: lightweight kernel protection	tecnologia electronica telecomunicaciones;tecnologias	"""interests are mainly in software and systems security, with a focus on automated software Georgios Portokalidis is a postdoctoral researcher in the department of computer Science at columbia University. He obtained his doctorate from the Vrije Universiteit in Amsterdam. His research interests are mainly around the area of systems security, but extend to network monitoring, operating systems, and virtualization elias Athanasopoulos holds a bS in physics from the University of Athens, and an mS and Phd from the University of crete. He is currently a marie curie postdoctoral fellow with columbia University. interests revolve around systems and software security and reliability. He received his Phd in 2001 from the University of Pennsylvania. Kernel exploits have become increasingly popular over the past several years. We have developed kGuard, a cross-platform system that defends the operating system (OS) against a widespread class of kernel attacks. We describe how these attacks work and how kGuard protects the kernel with only a small decrease in performance. The OS kernel is becoming an attractive target for attackers. The rising number of kernel vulnerabilities discovered and reported attest to this (see Figure 1). The reasons behind this trend are numerous. First, the number of applications running (continuously) with administrative privileges has significantly decreased, meaning that an attacker compromising such programs remotely gains only limited power over the underlying system. Additionally, programs have become harder to exploit due to the various defense mechanisms already adopted by modern OSes, such as address space layout randomization and stack smashing protection. The most interesting reason is probably that vulnerabilities such as NULL pointer dereference bugs, which were thought to be impractical, hard to exploit, and had not received significant attention by the security community, can be used with ease against the kernel to gain elevated privileges. In fact, some researchers proclaimed 2009 as """" the year of the kernel NULL pointer dereference flaw """" [2]. Last, exploiting kernel bugs has the added benefit of allowing attackers to mask their presence on the compromised systems (e.g., by hiding processes or files). Figure 1: Kernel vulnerabilities (per year) reported to NIST. Over the past decade, the distinct number of cVe identifiers assigned to kernel vulnerabilities has increased by a factor of 5. Kernel attacks are facilitated by the fact that user and kernel space (i.e., the memory area where user applications and the kernel reside, respectively), are weakly separated in modern OSes. …"""	64-bit computing;address space layout randomization;alloxytropus elias;application security;apricot kernel oil;box counting;code segment;color balance;columbia (supercomputer);computer science;conferences;curie;defense mechanisms;dereference operator;doctorate degree;entity name part qualifier - adopted;exploit (computer security);exponent bias;flaw hypothesis methodology;hypervisor;identifier;internet;kernel (operating system);lightweight kernel operating system;linux;login;personnameuse - assigned;pointer (computer programming);pointer <dog>;reside;software bug;stack buffer overflow;superuser;user space;world wide web;bypass;interest	Angelos D. Keromytis	2012	;login:		embedded system	Security	-59.78113955094989	53.67023593279799	70393
b4db0e38750d9aeb503d08540860ba2f82dcf59a	no principal too small: memory access control for fine-grained protection domains	isolation;software engineering;fine grained protection;software security;containers context permission switches pipelines software;software engineering random access storage;synthetic microbenchmarks memory access control single protection domain page table fine grained memory protection mechanism modern software engineering software components cycle accurate simulator complex out of order pipeline open source benchmarks;random access storage;architectural support for security memory protection isolation fine grained protection software security;architectural support for security;memory protection	Modern programs comprise multiple threads of execution inside a single principal -- the process -- with a single protection domain, usually a page table. We propose a hardware enforced, fine-grained memory protection mechanism to divide the process into smaller principals and multiple protection domains. Our approach supports modern software engineering better than traditional processes by enabling developers to align software components with protection mechanisms. We implemented our architecture using a cycle-accurate simulator of a complex out-of-order pipeline and evaluate our solution using open-source benchmarks and synthetic micro benchmarks designed specifically to stress our system.	access control;align (company);code page;component-based software engineering;computer architecture simulator;inter-process communication;memory management;memory protection;open-source software;overhead (computing);page table;programmer;protection mechanism;synthetic intelligence;thread (computing)	Eugen Leontie;Gedare Bloom;Bhagirath Narahari;Rahul Simha	2012	2012 15th Euromicro Conference on Digital System Design	10.1109/DSD.2012.89	software security assurance;embedded system;parallel computing;real-time computing;isolation;computer science;software development;operating system;software construction;memory protection	OS	-54.050193414269714	55.828833132368125	70725
f40c0f3f5bdf3414ba213b0315ca37b5260bc79f	asa: advanced secure architecture for preventing unauthorized access in personal computer platforms and bios	secure architecture;personal computer;secure computation;system security;cryptographic models;authentication and authorization;engineering and technology;teknik och teknologier;operating system;security architecture;security computing platforms;security	This paper proposes an architecture for Personal Computers (PC) to avoid BIOS alteration and unauthorized access to resources. This proposal is based on results obtained from study of most popular PC platforms security mechanisms. Authentication controls which are established in PC platform in order to grant operating system booting or BIOS integrity of code mechanism incorporated to secure and avoid executing disallowed code are quite easy to break. The architecture described in the present work (Advanced Secure Architecture - ASA) increase the overall information and system security since prevents an unauthorized platform booting and it provides procedures for BIOS code authentication. On the other hand, ASA overcomes the users' authentication challenge in a corporative environment as well as it offers a very flexible way to specify the Personal Computers Corporation set that a user is allowed to access.	authentication;authorization;bios;booting;operating system;personal computer;physical security	Lourdes López-Santidrián;José-Fernán Martínez;Alfonso Muñoz;Vicente Hernández;Antonio Dasilva;Ana Belén García	2007		10.1145/1352694.1352713	telecommunications;computer science;information security;operating system;software engineering;database;distributed system security architecture;internet privacy;world wide web;computer security;enterprise information security architecture;computer network	Security	-52.86405110467555	56.20338939644969	70840
03a7ecb0a3f1eff43ef7db66991ca37c7189d81c	invisimem: smart memory defenses for memory bus side channel		A practically feasible low-overhead hardware design that provides strong defenses against memory bus side channel remains elusive. This paper observes that smart memory, memory with compute capability and a packetized interface, can dramatically simplify this problem. InvisiMem expands the trust base to include the logic layer in the smart memory to implement cryptographic primitives, which aid in addressing several memory bus side channel vulnerabilities efficiently. This allows the secure host processor to send encrypted addresses over the untrusted memory bus, and thereby eliminates the need for expensive address obfuscation techniques based on Oblivious RAM (ORAM). In addition, smart memory enables efficient solutions for ensuring freshness without using expensive Merkle trees, and mitigates memory bus timing channel using constant heart-beat packets. We demonstrate that InvisiMem designs have one to two orders of magnitude of lower overheads for performance, space, energy, and memory bandwidth, compared to prior solutions.	cryptographic primitive;cryptography;encryption;memory bandwidth;memory bus;merkle tree;oblivious ram;overhead (computing);random-access memory;replay attack;side-channel attack;timing channel	Shaizeen Aga;Satish Narayanasamy	2017	2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)	10.1145/3079856.3080232	real-time computing;parallel computing;memory management;computer science;flat memory model;registered memory;conventional memory;address bus;physical address;computer memory;interleaved memory	Arch	-53.940377513754	56.30331701296003	71168
80390ecfdcba253ad54f6eef4cf1f6815d14fb75	negotiated access control	protocols access control kernel databases object recognition routing	List-oriented systems integrate protection of an object with the object; ticket oriented systems delegate this responsibiIity to the call hierarchy. We argue that there are situations where integration of protection with the object is more natural, but Iist-oriented systems, due to the static and declarative nature of access-Iists, are too weak for any sophisticated process-object interactions. To solve this, we superimpose procedural access control over the object - oriented capabiIity system model: objects may be associated with so-called access control procedures (ACP) that embody protection decisions. We define several protocols by which a process that wishes to access an object can negotiate with the ACP of the object to ensure that neither party's protection requirements are violated in the interaction.	access control list;computer;data protection directive;interaction;requirement;trojan horse (computing)	Kishore S. Swaminathan	1985	1985 IEEE Symposium on Security and Privacy	10.1109/SP.1985.10019	method;computer science;database;distributed computing;data transfer object;computer security	Security	-48.9966128010307	53.413052202400415	71361
abdd92d4e8944657b6d32cfc345559f68188d05c	rule anomaly-free mechanism of security function chaining in 5g		To meet the urgent security demands, 5G aims to deploy virtualized and programmable security services and defense potential threats in real time. With the development of network function virtualization and software-defined networking, security functions can be dynamically and flexibly chained to cope with many types of malicious attacks. Although there are a number of studies on security function chaining for the 5G, they primarily focus on the security function composition, rather than rule enforcement. In fact, the misconfiguration of rules for security functions is notably common because of the security function diversity and rule heterogeneity that causes many unexpected and serious problems. Therefore, in this paper, we propose a priority-based anomaly-free mechanism with defined security rule anomalies. To avoid misconfiguration, we also propose and implement a simply configured rule management framework with anomaly resolution. With extensive performance evaluations, we show the availability and efficiency of our proposed mechanism to resolve security rule anomalies.	anomaly detection;network function virtualization;operating-system-level virtualization;software-defined networking;transfer function	Guanwen Li;Huachun Zhou;Bohao Feng;Guanglei Li;Hongke Zhang;Teng Hu	2018	IEEE Access	10.1109/ACCESS.2018.2810834	the internet;computer science;network functions virtualization;distributed computing;chaining;enforcement	Security	-50.73278212268701	58.302326443117586	71546
a1baaf82d0581ad0924f0d40a8c789aa6e9f72d7	an approach to security-sla in cloud computing environment	databases;measurement;cloud computing security security sla security management security metrics;virtualisation cloud computing contracts grid computing security of data service oriented architecture;security measurement monitoring cloud computing quality of service databases;monitoring;quality of service;security sla cloud computing environment technological areas utility computer computational grid autonomous computing virtualization service oriented architectures general purpose security control general purpose control framework specification mechanism monitoring mechanism security management mechanism cloud environments user services security service level agreement;security;cloud computing	The lack of novel security controls for the cloud might arise from the fact that Cloud Computing is the convergence of many different technological areas, including Utility Computer, Computational Grid, Autonomous Computing, Virtualization and Service Oriented Architectures. These underlying areas have been independently addressed by existing generalpurpose security controls, but we noticed that each current cloud security control was mapped to multiple controls from the existing, general-purpose control frameworks. We also noticed a great demand for not only patterns but also specification, monitoring and security management mechanisms for cloud environments. We reason that this scenario might require a different approach, one where the specification of security controls, geared to meet the needs of services users, may be achieved through the use of Security Service Level Agreement—Security-SLA. Security may then be improved by automating the Security-SLA. Keywords-Security-SLA, Security Management, Security Metrics, Cloud Computing Security	antivirus software;cloud computing security;computation;general-purpose modeling;grid computing;quality of service;security controls;security management;security service (telecommunication);service-level agreement;service-oriented architecture;top-down and bottom-up design;type of service;video game graphics	Carlos Alberto da Silva;Paulo Lício de Geus	2014		10.1109/LATINCOM.2014.7041843	software security assurance;information security audit;computer security model;cloud computing security;itil security management;security through obscurity;sherwood applied business security architecture;security information and event management;security convergence;cloud computing;covert channel;computer science;information security;cloud testing;security service;distributed computing;utility computing;computer security;computer network	Security	-48.58609432748629	56.69366720406123	71939
44adfa896e6598b1723507060126125a0cad39a1	finding the needle: a study of the pe32 rich header and respective malware triage		Performing triage of malicious samples is a critical step in security analysis and mitigation development. Unfortunately, the obfuscation and outright removal of information contained in samples makes this a monumentally challenging task. However, the widely used Portable Executable file format (PE32 ), a data structure used by the Windows OS to handle executable code, contains hidden information that can provide a security analyst with an upper hand. In this paper, we perform the first accurate assessment of the hidden PE32 field known as the Rich Header and describe how to extract the data that it clandestinely contains. We study 964,816 malware samples and demonstrate how the information contained in the Rich Header can be leveraged to perform rapid triage across millions of samples, including packed and obfuscated binaries. We first show how to quickly identify post-modified and obfuscated binaries through anomalies in the header. Next, we exhibit the Rich Header’s utility in triage by presenting a proof of concept similarity matching algorithm which is solely based on the contents of the Rich Header. With our algorithm we demonstrate how the contents of the Rich Header can be used to identify similar malware, different versions of malware, and when malware has been built under different build environment; revealing potentially distinct actors. Furthermore, we are able to perform these operations in near real-time, less than 6.73 ms on commodity hardware across our studied samples. In conclusion, we establish that this littlestudied header in the PE32 format is a valuable asset for security analysts and has a breadth of future potential.	algorithm;binary file;central processing unit;commodity computing;data structure;executable;feature extraction;machine learning;malware;microsoft windows;operating system;real-time clock;real-time computing;sensor	George D. Webster;Bojan Kolosnjaji;Christian von Pentz;Julian Kirsch;Zachary D. Hanif;Apostolis Zarras;Claudia Eckert	2017		10.1007/978-3-319-60876-1_6	real-time computing;microsoft windows;microsoft visual studio;header;world wide web;malware;data structure;executable;portable executable;computer science;file format	Security	-58.318724034737635	60.128422494827376	72104
ab7dc2e8f2e31972a91bc8b50cae52346738f707	assurance case driven design based on the harmonized framework of safety and security requirements		Assurance (Security and Safety) Case is an approach to prove critical systems and software compliance with security and safety requirements. We propose an advanced framework named as Assurance Case Driven Design (AC DD) to improve cost-effectiveness of certification and licensing processes. AC DD is based on Claim-Argument-Evidence-Criteria (CAEC) notation and Development-Verification&Validation-Assurance Case (DVA) notation. An example of AC DD application for Functional Safety Management part of requirements of the standard IEC 61508 is considered.	big data;cloud computing;dd (unix);embedded system;internet of things;requirement	Vladimir V. Sklyar;Vyacheslav S. Kharchenko	2017			engineering	Embedded	-56.09230935096824	46.625045913680374	72303
06de7a90c03ba9281dfc2821bbdb498cc392bc68	function level control flow obfuscation for software security	security of data program control structures reverse engineering;code obfuscation computer security software security;software assembly reverse engineering heuristic algorithms algorithm design and analysis software algorithms security;computer security;software security;code obfuscation;function level shuffled version function level control flow obfuscation software security reverse engineering attacks software control flow obfuscation	Software released to the user has the risk of reverse engineering attacks. Software control flow obfuscation is one of the techniques used to make the reverse engineering of software programs harder. Control flow obfuscation, obscures the control flow of the program so that it is hard for an analyzer to decode the logic of the program. In this paper, we propose an obfuscation algorithm which obscures the control flow across functions. In our method code fragments from each function is stripped from the original function and is stored in another function. Each function will be having code fragments from different functions, thereby creating a function level shuffled version of the original program. Control flow is obscured between and within the function by this method. Experimental results indicate that the algorithm performs well against automated attacks.	algorithm;application security;control flow;reverse engineering	Vivek Balachandran;Wee Keong Ng;Sabu Emmanuel	2014	2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2014.20	software security assurance;obfuscation;real-time computing;software sizing;computer science;software construction;programming language;computer security	SE	-57.30530635828031	55.9636417569041	72580
a14f6463240fe29168ef31ad55050fa304f87778	containerleaks: emerging security threats of information leakages in container clouds		Container technology provides a lightweight operating system level virtual hosting environment. Its emergence profoundly changes the development and deployment paradigms of multi-tier distributed applications. However, due to the incomplete implementation of system resource isolation mechanisms in the Linux kernel, some security concerns still exist for multiple containers sharing an operating system kernel on a multi-tenancy container cloud service. In this paper, we first present the information leakage channels we discovered that are accessible within the containers. Such channels expose a spectrum of system-wide host information to the containers without proper resource partitioning. By exploiting such leaked host information, it becomes much easier for malicious adversaries (acting as tenants in the container clouds) to launch advanced attacks that might impact the reliability of cloud services. Additionally, we discuss the root causes of the containers' information leakages and propose a two-stage defense approach. As demonstrated in the evaluation, our solution is effective and incurs trivial performance overhead.	cloud computing;distributed computing;emergence;information leakage;information security;kernel (operating system);linux;multitenancy;multitier architecture;operating system;overhead (computing);software deployment;spectral leakage;virtual hosting	Xing Gao;Zhongshu Gu;Mehmet Kayaalp;Dimitrios Pendarakis;Haining Wang	2017	2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)	10.1109/DSN.2017.49	software deployment;virtual hosting;computer science;information leakage;resource (disambiguation);cloud computing;computer network;cloud computing security;computer security;linux kernel;communication channel	OS	-52.0068606667168	57.45963763591078	72673
1c4a60812fe042f123778dd7ba1ba523e66100d6	challenges for dynamic analysis of ios applications	dynamic analysis	Recent research indicates that mobile platforms, such as Android and Apple’s iOS increasingly face the threat of malware. These threats range from spyware that steals privacy sensitive information, such as location data or address book contents to malware that tries to collect ransom from users by locking the device and therefore rendering the device useless. Therefore, powerful analysis techniques and tools are necessary to quickly provide an analyst with the necessary information about an application to assess whether this application contains potentially malicious functionality. In this work, we focus on the challenges and open problems that have to be overcome to create dynamic analysis solutions for iOS applications. Additionally, we present two proof-of-concept implementations tackling two of these challenges. First, we present a basic dynamic analysis approach for iOS applications demonstrating the feasibility of dynamic analysis on iOS. Second, addressing the challenge that iOS applications are almost always user interface driven, we also present an approach to automatically exercise an application’s user interface. The necessity of exercising application user interfaces is demonstrated by the difference in code coverage that we achieve with (69%) and without (16%) such techniques. Therefore, this work is a first step towards comprehensive dynamic analysis for iOS applications.	android;code coverage;ibm notes;information sensitivity;lock (computer science);malware;method (computer programming);mobile device;prototype;sensor;spyware;static program analysis;telephone number;tracing (software);user interface;ios	Martin Szydlowski;Manuel Egele;Christopher Krügel;Giovanni Vigna	2011		10.1007/978-3-642-27585-2_6	computer science;internet privacy;world wide web;computer security	Security	-55.80922440506504	60.31851174697857	72688
e8e9819d0c4c76c4be51c9393d6c37796612fe67	optimal mining on security labels for decentralized information flow control	data mining;logic programming;constraint solving;np complete;genetic algorithm;policy description language;access control	Decentralized information flow control (DIFC) is a key innovation of traditional information flow control (IFC). When compared with IFC, DIFC provides new features including decentralized declassification, taint-tracking and privilege-transferring. These characteristics makeDIFCmoreapplicable than traditional IFC to thecontrol of informationflows insystems. This paper presents an optimal approach to the mining of security labels for DIFC. This approach can effectively improve DIFC’s applicability andmanageability in a wide variety of environments. We firstly design a novel policy description language to express security requirements in DIFC characterized assertions. Next, we prove that the problem of obtaining security labels fromDIFC assertions isNP-complete. Based on logic programming and genetic algorithm, the proposed approach finally outputs optimal security labels separately for different DIFC systems in both small and large-scale environments. The objectives of this paperare toaddress twopractical aspectsofDIFC: (1)howtoexpress security requirementsby using DIFC characterized assertions; (2) how to obtain optimal DIFC labels to satisfy security requirements. The experimental results show that the proposed approach is effective in implementing fine-grained information control according to practical security requirements. a 2012 Elsevier Ltd. All rights reserved.	control flow;declassification;genetic algorithm;information flow (information theory);logic programming;non-interference (security);requirement;taint checking	Zhi Yang;Lihua Yin;Shuyuan Jin;Xingyuan Chen	2012	Computers & Security	10.1016/j.cose.2012.08.002	genetic algorithm;np-complete;computer science;access control;data mining;distributed computing;logic programming;computer security	AI	-49.56801207564743	51.56789143652034	73178
f35fe60d7c4ade52d058833c8a8dc826fc07ff1a	run-time security traceability for evolving systems	security analysis;internet protocols;computer software selection and evaluation;formal verifications;cryptographic protocols;journal article;it security;formal verification;software evolution;monitoring;mathematical models;cryptography;design;keywords cryptographic protocols;requirements traceability;run time verification	Security-critical systems are challenging to design and implement correctly and securely. A lot of vulnerabilities have been found in current software systems both at the specification and the implementation levels. This paper presents a comprehensive approach for model-based security assurance. Initially, it allows one to formally verify the design models against high-level security requirements such as secrecy and authentication on the specification level, and helps to ensure that their implementation adheres to these properties, if they express a system's run-time behaviour. As such, it provides a traceability link from the design model to its implementation by which the actual system can then be verified against the model while it executes. This part of our approach relies on a technique also known as run-time verification. The extra effort for it is small as most of the computation is automated; however, additional resources at run-time may be required. If during run-time verification a security weakness is uncovered, it can be removed using aspect-oriented security hardening transformations. Therefore, this approach also supports the evolution of software since the traceability mapping is updated when refactoring operations are regressively performed using our tool-supported refactoring technique. The proposed method has been applied to the Java-based implementation Jessie of the Internet security protocol SSL, in which a security weakness was detected and fixed using our approach. We also explain how the traceability link can be transformed to the official implementation of the Java secure sockets extension that was recently made open source by Sun.		Andreas Bauer;Jan Jürjens;Yijun Yu	2011	Comput. J.	10.1093/comjnl/bxq042	software security assurance;computer security model;design;security through obscurity;formal verification;computer science;cryptography;software evolution;operating system;database;security service;security analysis;programming language;computer security;requirements traceability	Logic	-55.04686033714432	53.957004340487224	73840
09beaebf3807cf7dcbd8ad4fd0613a5ac8620d55	systematic control and management of data integrity	access;data integrity;metadata;integrable model;metadata management;policy languages;policy language;integrity;data privacy;integrated control;design;validation;access control;information system;security;data validation	Integrity has long been considered a fundamental requirement for secure computerized systems, and especially today's demand for data integrity is stronger than ever as many organizations are in-creasing their reliance on data and information systems. A number of recently enacted data privacy regulations also require high in-tegrity for personal data. In this paper, we discuss various issues concerning systematic control and management of data integrity with a primary focus on access control. We first examine some previously proposed integrity models and define a set of integrity requirements. We then present an architecture for comprehensive integrity control systems, which has its basis on data validation and metadata management. We also provide an integrity control policy language that we believe is flexible and intuitive.	access control;control system;data integrity;data validation;information privacy;information system;personally identifiable information;requirement	Ji-Won Byun;Yonglak Sohn;Elisa Bertino	2006		10.1145/1133058.1133074	design;information privacy;computer science;information security;access control;data validation;data integrity;data mining;database;metadata;computer security;information system	Security	-50.76721666146536	52.38737969429952	74350
80666a0d03f1a86d9e470a0037d478e6e53b9f65	a hardware implement of bus bridge based on single cpu and dual bus architecture	computers;dual bus architecture;single cpu;peripheral interfaces;light emitting diodes;bridges;bus bridge hardware implement;computer architecture;dual bus;peripheral interfaces computer architecture;registers;bus bridge;security;bus bridge single cpu dual bus architecture;architecture;dual bus architecture bus bridge hardware implement single cpu bus architecture;single cpu bus architecture;hardware;hardware bridges computer architecture information security data security computer security computer networks secure storage national security system buses	Single CPU dual bus architecture is a new kind of architecture aimed at reducing the security vulnerability of Von Neumann architecture, and it has been proved theoretically reasonable. In this paper, a bus bridge is implemented to bridge CPU and dual bus. The experiment is done and the result has proved that the architecture based on single CPU and dual bus is reasonable and effective.	bus (computing);central processing unit;peripheral;s-100 bus;von neumann architecture;vulnerability (computing)	Tiedong Wang;Fengjing Shao;Rencheng Sun;He Huang	2008	2008 International Symposium on Computer Science and Computational Technology	10.1109/ISCSCT.2008.106	bus;embedded system;bus error;computer architecture;parallel computing;iebus;engineering;local bus;conventional pci;system bus;control bus;back-side bus;bus network;address bus;cpu shielding	Arch	-53.36728247394869	55.88966089846511	74593
0242f50ddd7a87f0d767ec7591c2681681e72cdb	identifying dormant functionality in malware programs	analytical models;binary codes;invasive software data analysis;sockets;runtime;requirement analysis;data analysis;postal services;malware;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;binary analysis;malware analysis;performance analysis;code obfuscation;reanimator solution dormant functionality identification malware programs malicious code sandbox environment packing technique code obfuscation technique malicious behaviors dynamic malware analysis multipath technique forced execution technique;binary analysis dormant functionality malware analysis;invasive software;dormant functionality;is success;similarity function;computer architecture computational modeling registers assembly digital signal processing digital signal processing chips telecommunication control large scale integration logic educational institutions;dynamic analysis;binary analysis malware analysis dormant functionality	To handle the growing flood of malware, security vendors and analysts rely on tools that automatically identify and analyze malicious code. Current systems for automated malware analysis typically follow a dynamic approach, executing an unknown program in a controlled environment (sandbox) and recording its runtime behavior. Since dynamic analysis platforms directly run malicious code, they are resilient to popular malware defense techniques such as packing and code obfuscation. Unfortunately, in many cases, only a small subset of all possible malicious behaviors is observed within the short time frame that a malware sample is executed. To mitigate this issue, previous work introduced techniques such as multi-path or forced execution to increase the coverage of dynamic malware analysis. Unfortunately, using these techniques is potentially expensive, as the number of paths that require analysis can grow exponentially. In this paper, we propose Reanimator, a novel solution to determine the capabilities (malicious functionality) of malware programs. Our solution is based on the insight that we can leverage behavior observed while dynamically executing a specific malware sample to identify similar functionality in other programs. More precisely, when we observe malicious actions during dynamic analysis, we automatically extract and model the parts of the malware binary that are responsible for this behavior. We then leverage these models to check whether similar code is present in other samples. This allows us to statically identify dormant functionality (functionality that is not observed during dynamic analysis) in malicious programs. We evaluate our approach on thousands of real-world malware samples, and we show that our system is successful in identifying additional, malicious functionality. As a result, our approach can significantly improve the coverage of malware analysis results.	dynamic program analysis;malware analysis;obfuscation (software);sandbox (computer security);set packing	Paolo Milani Comparetti;Guido Salvaneschi;Engin Kirda;Clemens Kolbitsch;Christopher Krügel;Stefano Zanero	2010	2010 IEEE Symposium on Security and Privacy	10.1109/SP.2010.12	obfuscation;requirements analysis;binary code;computer science;operating system;cryptovirology;dynamic program analysis;malware;internet privacy;data analysis;programming language;world wide web;computer security	Security	-58.42161693196302	58.478913289337896	74699
c27a0be6a6c9637d4f78ab1444961632302c262c	le-git-imate: towards verifiable web-based git repositories		Web-based Git hosting services such as GitHub and GitLab are popular choices to manage and interact with Git repositories. However, they lack an important security feature - the ability to sign Git commits. Users instruct the server to perform repository operations on their behalf and have to trust that the server will execute their requests faithfully. Such trust may be unwarranted though because a malicious or a compromised server may execute the requested actions in an incorrect manner, leading to a different state of the repository than what the user intended. In this paper, we show a range of high-impact attacks that can be executed stealthily when developers use the web UI of a Git hosting service to perform common actions such as editing files or merging branches. We then propose le-git-imate, a defense against these attacks which provides security guarantees comparable and compatible with Gitu0027s standard commit signing mechanism. We implement le-git-imate as a Chrome browser extension. le-git-imate does not require changes on the server side and can thus be used immediately. It also preserves current workflows used in Github/GitLab and does not require the user to leave the browser, and it allows anyone to verify that the serveru0027s actions faithfully follow the useru0027s requested actions. Moreover, experimental evaluation using the browser extension shows that le-git-imate has comparable performance with Gitu0027s standard commit signature mechanism. With our solution in place, users can take advantage of GitHub/GitLabu0027s web-based features without sacrificing security, thus paving the way towards verifiable web-based Git repositories.	backdoor (computing);browser extension;commitment scheme;formal verification;gitlab;malware;overhead (computing);patch (computing);server (computing);server-side;surface web;usability testing;user interface;web 2.0;web application	Hammad Afzali;Santiago Torres-Arias;Reza Curtmola;Justin Cappos	2018		10.1145/3196494.3196523	internet privacy;verifiable secret sharing;server-side;world wide web;merge (version control);web application;computer science;internet hosting service;workflow;commit	Security	-54.78119999072323	59.27329726241806	74781
94198e7078127fe94a4f86f0c8fc9280574cc732	a multi-layer criticality assessment methodology based on interdependencies	interdependencies;risk assessment;security assessment;critical infrastructure;criticality	In this paper we propose a holistic Criticality Assessment methodology, suitable for the development of an infrastructure protection plan in a multi-sector or national level. The proposed methodology aims to integrate existing security plans and risk assessments performed in isolated infrastructures, in order to assess sector-wide or intra-sector security risks. In order to achieve this, we define three different layers of security assessments with different requirements and goals; the operator layer, the sector layer and the intra-sector or national layer. We determine the characteristics of each layer, as well as their interdependencies. In this way, existing security plans can be fully exploited in order to provide a ''shortcut'' for the development of security plans for complex inter-dependent infrastructures. A key element in the proposed methodology is the formal definition of interdependencies between different infrastructures and their respective sectors. Interdependencies between infrastructures belonging to the same or to a different sector, as well as interdependencies between different sectors, act as interfaces through which threats and their impacts occurring on different layers or different sectors, are conveyed to others. Current risk assessment methodologies fail to address effectively this issue, thus, the formalization of these interfaces and their interference is an important element for the definition of a holistic Criticality Assessment methodology.	interdependence;layer (electronics);self-organized criticality	Marianthi Theoharidou;Panayiotis Kotzanikolaou;Dimitris Gritzalis	2010	Computers & Security	10.1016/j.cose.2010.02.003	risk assessment;interdependence;computer science;critical infrastructure;computer security;criticality	Crypto	-55.019588776952325	47.547740684616144	75018
1590cd345821768508d6f38c9a83e79bf3e5d64d	safestack: automatically patching stack-based buffer overflow vulnerabilities	linux system automatic stack based buffer overflow vulnerability patching safestack computer systems buffer overflow attacks vulnerable program service oriented platforms stack based buffer overflow vulnerability diagnosis memory access virtualization protected memory regions;software reliability buffer storage linux program diagnostics security of data service oriented architecture;program diagnostics;safestack;buffer overflow attacks;buffer storage;memory access virtualization;vulnerable program;computer systems;attack prevention;protected memory regions;automatic stack based buffer overflow vulnerability patching;computer security;computer viruses;stack based buffer overflow vulnerability diagnosis;software reliability computer security computer viruses fault diagnosis;linux;buffer overflow vulnerability diagnosis;service oriented architecture;linux system;software reliability;service oriented platforms;security of data;attack prevention software reliability buffer overflow vulnerability diagnosis;fault diagnosis	Buffer overflow attacks still pose a significant threat to the security and availability of today's computer systems. Although there are a number of solutions proposed to provide adequate protection against buffer overflow attacks, most of existing solutions terminate the vulnerable program when the buffer overflow occurs, effectively rendering the program unavailable. The impact on availability is a serious problem on service-oriented platforms. This paper presents SafeStack, a system that can automatically diagnose and patch stack-based buffer overflow vulnerabilities. The key technique of our solution is to virtualize memory accesses and move the vulnerable buffer into protected memory regions, which provides a fundamental and effective protection against recurrence of the same attack without stopping normal system execution. We developed a prototype on a Linux system, and conducted extensive experiments to evaluate the effectiveness and performance of the system using a range of applications. Our experimental results showed that SafeStack can quickly generate runtime patches to successfully handle the attack's recurrence. Furthermore, SafeStack only incurs acceptable overhead for the patched applications.	address space layout randomization;computer;experiment;linux;loader (computing);memory protection;overhead (computing);prototype;service-oriented device architecture;software bug;stack buffer overflow;stack-oriented programming language;terminate (software);virtualize	Gang Chen;Hai Jin;Deqing Zou;Bing Bing Zhou;Zhenkai Liang;Weide Zheng;Xuanhua Shi	2013	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2013.25	real-time computing;buffer overflow;computer science;operating system;service-oriented architecture;computer security;linux kernel;software quality;computer virus	Security	-56.98534097303584	56.652474892819065	75271
daae837d69819ff052253fe0ce5cc1f01e979eb8	nioh: hardening the hypervisor by filtering illegal i/o requests to virtual devices		"""Vulnerabilities in hypervisors are crucial in multi-tenant clouds since they can undermine the security of all virtual machines (VMs) consolidated on a vulnerable hypervisor. Unfortunately, 107 vulnerabilitiesin KVM+QEMU and 38 vulnerabilities in Xen have been reported in 2016. The device-emulation layer in hypervisors is a hotbed of vulnerabilities because the code for virtualizing devices is complicated and requires knowledge on the device internals. We propose a """"device request filter"""", called Nioh, that raises the bar for attackers to exploit the vulnerabilities in hypervisors. The key insight behind Nioh is that malicious I/O requests attempt to exploit vulnerabilities and violate device specifications in many cases. Nioh inspects I/O requests from VMs and rejects those that do not conform to a device specification. A device specification is modeled as a device automaton in Nioh, an extended automaton to facilitate the description of device specifications. The software framework is also provided to encapsulate the interactions between the device request filter and the underlying hypervisors. The results of our attack evaluation suggests that Nioh can defend against attacks that exploit vulnerabilities in device emulation, i.e., CVE-2015-5158, CVE-2016-1568, CVE-2016-4439, and CVE-2016-7909. This paper shows that the notorious VENOM attack can be detected and rejected by using Nioh."""	automaton;emulator;hypervisor;input/output;interaction;multitenancy;performance evaluation;server (computing);software framework;virtual machine;vulnerability (computing)	Junya Ogasawara;Kenji Kono	2017		10.1145/3134600.3134648	software framework;real-time computing;computer security;virtualization;computer science;virtual machine;hypervisor;exploit;input/output;virtual device;hardening (computing)	Security	-53.87092223310098	57.04008555594203	75492
a11631bfdef88d3ee912cbb20e154d606f854efb	classification and comparison of critical infrastructure protection tools		Modeling and analysis of critical infrastructure interdependencies is a research area that has attracted considerable interest. Interdependency and risk analyses can be computationally intensive, but can also yield useful results that enhance risk assessments and offer risk mitigation alternatives. Unfortunately, many tools and methodologies are left unsupported and are forgotten soon after the projects that developed them terminate.	critical infrastructure protection	George Stergiopoulos;Efstratios Vasilellis;Georgia Lykou;Panayiotis Kotzanikolaou;Dimitris Gritzalis	2016		10.1007/978-3-319-48737-3_14	environmental resource management;risk management;business;critical infrastructure protection;critical infrastructure;risk assessment	HPC	-59.88438812312355	50.321544133396294	76450
6516077c20fba2497a8f00402e4bf60d8b21227d	a comparative study on access control models and security requirements in workflow systems		Workflow systems handle data and ressources that often require integrity preserving and may also need a high-level of confidentiality. Thus, they should be protected against unauthorized access. Organizations, use workflow management systems to manage, control and automate their business processes. Likewise, they adopt access control models to express their security needs and establish thier access control policies. Therefore, organizations have to choose a flexible access control model that corresponds to their security requirements, without sacrificing the resiliency of their workflow system. The contribution of this paper is to provide a study on access control models and comparing them according to a set of criteria and requirements that we believe are necessary to ensure security and resiliency in workflow systems.	access control;requirement	Monsef Boughrous;Hanan El Bakkali	2017		10.1007/978-3-319-76354-5_33	systems engineering;access control;workflow management system;business process;workflow;business	Security	-50.85947535769521	51.77679712932225	76520
287946c522f4c4042fa54db652ba35fa5e24244b	security of information flow in the electric power grid	security model;alternating current;satisfiability;cyber physical systems;confidentiality;information flow;power grid;electric power;facts devices	The confidentiality of information in a system can be breached through unrestricted information flow. The formal properties of non-deducibility and non-inference are often used to assess information flow in purely cyber environments. However, in a “cyber-physical system” (CPS), i.e., a system with significant cyber and physical components, physical actions may allow confidential information to be deduced or inferred. This paper conducts an information flow analysis of a CPS using formal models of confidentiality. The specific CPS under study is the advanced electric power grid using cooperating flexible alternating current transmission system (FACTS) devices. FACTS devices exchange confidential information and use the information to produce physical actions on the electric power grid. This paper shows that even if the information flow satisfies certain security models, confidential information may still be deduced by observation or inference of a CPS at its cyber-physical boundary. The result is important because it helps assess the confidentiality of CPSs.	cell-free protein synthesis;computation;confidentiality;cyber-physical system;data-flow analysis;distributed control system;high- and low-level;information flow;interaction;litecoin;observable;pipeline (computing)	Han Tang;Bruce M. McMillin	2007		10.1007/978-0-387-75462-8_4	computer science;theoretical computer science;distributed computing;smart grid;computer security	PL	-55.138959164320276	51.329280217369046	76705
340569da290505865cb2ba79a4201c7028d4d66a	process implanting: a new active introspection framework for virtualization	virtualisation operating systems computers security of data virtual machines;kernel;virtualization;active vm introspection;active vm introspection security virtualization;virtual machine monitors;malware;virtual machines;virtual machine monitors malware context switches instruction sets kernel;kvm active introspection framework virtualization virtual machine introspection security tools guest operating system hypervisor process implanting;switches;security;security of data;operating systems computers;context;virtualisation;instruction sets	"""Previous research on virtual machine introspection proposed """"out-of-box"""" approach by moving out security tools from the guest operating system. However, compared to the traditional """"in-the-box"""" approach, it remains a challenge to obtain a complete semantic view due to the semantic gap between the guest VM and the hyper visor. In this paper, we present Process Implanting, a new active VM introspection framework, to narrow the semantic gap by implanting a process from the host into the guest VM and executing it under the cover of an existing running process. With the protection and coordination from the hyper visor, the implanted process can run with a degree of stealthiest and exit gracefully without leaving negative impact on the guest operating system. We have designed and implemented a proof-of-concept prototype on KVM which leverages hardware virtualization. We also propose and demonstrate application scenarios for Process Implanting in the area of VM security."""	general-purpose markup language;hardware virtualization;hypervisor;introspection;operating system;out of the box (feature);prototype;tamper resistance;virtual machine	Zhongshu Gu;Zhui Deng;Dongyan Xu;Xuxian Jiang	2011	2011 IEEE 30th International Symposium on Reliable Distributed Systems	10.1109/SRDS.2011.26	parallel computing;real-time computing;virtualization;computer science;information security;operating system;database;distributed computing;computer security	Arch	-53.71107444182586	56.071720499532994	76745
4d5cc8924efa282d4ca5bc4d8179bde4dc886c63	a new comparison framework for information security risk analysis methodologies			information security	Anita Vorster;Les Labuschagne	2006	South African Computer Journal		information security;risk analysis (engineering);computer science;data mining;risk analysis (business)	Crypto	-56.17772389179144	49.16004519285226	76975
2f70dfc08da8977de1613b46ded858bc93136a01	automatically mining program build information via signature matching	clamav;technology audit;static binary analysis;program analysis;program provenance	"""Program build information, such as compilers and libraries used, is vitally important in an auditing and benchmarking framework for High-Performance Computing (HPC) systems. I have developed a tool to automatically extract this information using signature-based detection, a common strategy employed by anti-virus software to search for known patterns of data within the program binaries. I formulate the patterns from various """"features"""" embedded in the program binaries, and the experiment shows that my tool can successfully identify many different compilers, libraries, and their versions."""	antivirus software;binary file;compiler;digital signature;embedded system;library (computing)	Charng-Da Lu	2011		10.1145/2462029.2462036	program analysis;information technology audit;computer science;data mining;database;programming language;world wide web	SE	-58.28222649644287	55.44110059970122	77196
9335e2e7bf56f5e8ff227a4a2370caec1e4c494f	malicious behavior monitoring for android applications		Android, as a modern popular open source mobile platform, makes its security issues more prominent, especially in user privacy leakage. In this paper, we proposed a twostep model which combines static and dynamic analysis approaches. During the static analysis, permission combination matrix is used to determine whether an application has potential risks. For those suspicious applications, based on the reverse engineering, embed monitoring Smali code for those sensitive APIs such as sending SMS, accessing user location, device ID, phone number, etc. From experiments, it shows that almost 26% applications in Android market have privacy leakage risks. And our proposed method is feasible and effective for monitoring these kind of malicious behavior.	android;application programming interface;experiment;malware;mobile operating system;open-source software;reverse engineering;spectral leakage;static program analysis;taint checking;telephone number	Quan Qian;Jing Cai;Mengbo Xie;Rui Zhang	2016	I. J. Network Security		computer security;internet privacy;computer science;android (operating system)	Security	-55.96548504491938	60.356489291108616	77263
b1a3dd882d0c64bafbcf4df0408190995517fd30	bad parts: are our manufacturing systems at risk of silent cyberattacks?	cyber physical manufacturing security manufacturing systems cyberattacks catastrophic failures cyber physical models cybersecurity best practices;security and protection;security manufacturing invasive software security and protection management of computing and information systems computer aided manufacturing;quality control manufacturing processes computer crime three dimensional displays design automation;management of computing and information systems;computer aided manufacturing;security of data manufacturing systems production engineering computing;manufacturing;invasive software;security	Recent cyberattacks have highlighted the risk of physical equipment operating outside designed tolerances to produce catastrophic failures. A related threat is cyberattacks that change the design and manufacturing of a machine's part, such as an automobile brake component, so it no longer functions properly. These risks stem from the lack of cyber-physical models to identify ongoing attacks as well as the lack of rigorous application of known cybersecurity best practices. To protect manufacturing processes in the future, research will be needed on a number of critical cyber-physical manufacturing security topics.	best practice;computer security	Hamilton A. Turner;Jules White;Jaime A. Camelio;Christopher Williams;Brandon Amos;Robert Parker	2015	IEEE Security & Privacy	10.1109/MSP.2015.60	process development execution system;manufacturing operations;computer science;information security;computer-integrated manufacturing;manufacturing;computer security;computer-aided manufacturing	ML	-59.35004682425701	49.07528824681221	77449
b8625136094f8dc9c65beeb0e004da29fb26c08a	ethics aspects of embedded and cyber-physical systems	software;cyber physical systems software safety ethics stakeholders artificial intelligence ethical aspects;datorsystem;computer systems;stakeholders;cyber physical systems;ethics;engineering and technology;teknik och teknologier;software responsibility;ethical aspects artificial intelligence computational complexity decision making embedded systems;extra functional properties ethics cyber physical systems software responsibility;safety;artificial intelligence;group responsibilities ethics aspects embedded systems cyber physical domain software complexity extra functional properties intelligent systems ai based cyber physical systems decision making software human responsibility ethical responsibility;ethical aspects;extra functional properties	"""The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the """"responsibility"""" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical """"responsibility"""" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities."""	autonomous robot;autonomy;best practice;communications protocol;cyber-physical system;embedded system;information exchange;semiconductor industry;software agent;software deployment;traceability	Abhilash Thekkilakattil;Gordana Dodig-Crnkovic	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.41	ethics;stakeholder;computer science;systems engineering;engineering;knowledge management;management science;cyber-physical system;management;law;computer security	Embedded	-56.85757657103835	49.42612092090308	77977
1abd690df0d96f5655e8890ff120e959048a73b8	a framework to evaluate cyber agility	software;computer network operations cyber agility maneuvers defensive maneuvers mission success mission goals defensive cyber operation critical communication path computer network defense;computer network security;software energy consumption computer security current measurement mobile computing context;computer security;current measurement;energy consumption;mobile computing;computer network operations cyber security computer network defense;context	In this paper, we propose a framework to help evaluate the cost and utility of cyber agility maneuvers within networks that have constrained resources such as bandwidth and energy (e.g., MANETs). Many new methods of cyber agility and defensive maneuvers have been proposed; however, a framework to evaluate cost and utility of these maneuvers in the context of mission success is lacking. We outline preliminary considerations such as mission goals, operating conditions and maneuvers to be evaluated. Then, we introduce notional measures of health, security and capability and their interrelationship resulting in an initial framework design. A simple defensive cyber operation of securing a critical communication path for some time duration, both with and without the presence of a detected infection, is provided to illustrate the framework components and mission considerations that must be made before selecting a sequence of maneuvers.	defensive programming	Lisa M. Marvel;Scott E. Brown;Iulian Neamtiu;Richard E. Harang;David Harman;Brian Henz	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357414	real-time computing;simulation;engineering;computer security	Robotics	-57.39914945140496	50.01181239685828	78127
7f3782cfafc95b210af7c18c8be89e2687c9da21	towards middleware-based fault-tolerance in rfid systems	data integrity;fault tolerant;heterogeneous systems;on line testing;rfid systems;software component;on line test;middleware;rfid middleware;fault diagnosis	RFID systems are complex heterogeneous systems, consisting of hardware and software components. These systems are more and more used in many types of applications, some of which are critical and need fault-tolerance mechanisms. However, most existing work on RFID systems deal with security aspects related to data integrity and confidentiality and less with dependability aspects (fault-tolerance, reliability, etc.)  In this paper we present an overview of existing RFID middlewares and fault-tolerance approaches. We propose a global test and diagnosis approach implemented at the RFID middleware that is intended to detect and locate faulty tags and readers to allow their isolation from the system.  This work is part of the French ANR project SAFERFID (Dependability of RFID Systems)	ambiguous name resolution;component-based software engineering;confidentiality;data integrity;dependability;fault tolerance;middleware;radio-frequency identification	Minh-Duc Nguyen;Gilles Fritz;Oum-El-Kheir Aktouf;Vincent Beroulle;David Hély	2011		10.1145/1978582.1978593	embedded system;real-time computing;engineering;computer security	SE	-48.68588758668337	47.74727066953918	78681
129ed742b496b23efdf745aaf0c48958ef64d2c6	exploring multiple execution paths for malware analysis	databases;program diagnostics;operating system calls;computer worms;virtual machining;malicious code;computer viruses;single program execution;internet;operating system;malware analysis;computer virus;worm;invasive software;payloads;trojan horse;program diagnostics invasive software operating systems computers;humans;dynamic analysis tools;computer worms operating systems invasive software data security databases humans virtual machining internet payloads computer viruses;operating systems computers;multiple execution paths;dynamic analysis;operating systems;single program execution multiple execution paths malware analysis malicious code computer virus worm trojan horse operating system calls dynamic analysis tools;data security	Malicious code (or Malware) is defined as software that fulfills the deliberately harmful intent of an attacker. Malware analysis is the process of determining the behavior and purpose of a given Malware sample (such as a virus, worm, or Trojan horse). This process is a necessary step to be able to develop effective detection techniques and removal tools. Currently, Malware analysis is mostly a manual process that is tedious and time-intensive. To mitigate this problem, a number of analysis tools have been proposed that automatically extract the behavior of an unknown program by executing it in a restricted environment and recording the operating system calls that are invoked. The problem of dynamic analysis tools is that only a single program execution is observed. Unfortunately, however, it is possible that certain malicious actions are only triggered under specific circumstances (e.g., on a particular day, when a certain file is present, or when a certain command is received). In this paper, we propose a system that allows us to explore multiple execution paths and identify malicious actions that are executed only when certain conditions are met. This enables us to automatically extract a more complete view of the program under analysis and identify under which circumstances suspicious actions are carried out. Our experimental results demonstrate that many Malware samples show different behavior depending on input read from the environment. Thus, by exploring multiple execution paths, we can obtain a more complete picture of their actions.	branch (computer science);computer virus;dynamic program analysis;executable;experiment;malware analysis;microsoft windows;operating system;rewrite (programming);snapshot (computer storage);system call;trojan horse (computing)	Andreas Moser;Christopher Krügel;Engin Kirda	2007	2007 IEEE Symposium on Security and Privacy (SP '07)	10.1109/SP.2007.17	real-time computing;computer science;operating system;cryptovirology;distributed computing;computer security;computer virus;computer worm	Security	-58.19369083166861	58.38065005481389	78745
ea36d627a182459d60823a75c8c6737a698cb3ec	how secure is green it? the case of software-based energy side channels		Software-based energy measurement features in contemporary CPUs allow one to track and to limit energy consumption, e.g., for realizing green IT. The security implications of software-based energy measurement, however, are not well understood. In this article, we study such security implications of green IT. More concretely, we show that side-channel attacks can be established using software-based energy measurement at the example of a popular RSA implementation. Using distinguishing experiments, we identify a side-channel vulnerability that enables attackers to distinguish RSA keys by measuring energy consumption. We demonstrate that a surprisingly low number of sample measurements suffices to succeed in an attack with high probability. In contrast to traditional power side-channel attacks, no physical access to hardware is needed. This makes the vulnerabilities particularly serious.		Heiko Mantel;Johannes Schickel;Alexandra Weber;Friedrich Weber	2018		10.1007/978-3-319-99073-6_11	distributed computing;computer science;green computing;energy consumption;physical access;software;key (lock);vulnerability;communication channel	Crypto	-54.27674636344304	56.77985126657498	78762
59b7c11f78b1411821201199842f6244d564ee2e	fabrication attacks: zero-overhead malicious modifications enabling modern microprocessor privilege escalation	fabrication;microprocessors;fabrication attacks;privilege escalation;kernel;microprocessors trojan horses fabrication hardware embedded systems logic gates computer architecture;multiprocessing systems invasive software;trojan horses;computer architecture;embedded systems;logic gates;malicious modification;high performance microprocessors fabrication attacks zero overhead malicious modifications modern microprocessor privilege escalation hardware trojans cyber attacks embedded microprocessors;privilege escalation hardware trojans fabrication attacks microprocessors zero overhead malicious modification;hardware trojans;zero overhead;hardware	The wide deployment of general purpose and embedded microprocessors has emphasized the need for defenses against cyber-attacks. Due to the globalized supply chain, however, there are several stages where a processor can be maliciously modified. The most promising stage, and the hardest during which to inject the hardware trojan, is the fabrication stage. As modern microprocessor chips are characterized by very dense, billion-transistor designs, such attacks must be very carefully crafted. In this paper, we demonstrate zero overhead malicious modifications on both high-performance and embedded microprocessors. These hardware trojans enable privilege escalation through execution of an instruction stream that excites the necessary conditions to make the modification appear. The minimal footprint, however, comes at the cost of a small window of attack opportunities. Experimental results show that malicious users can gain escalated privileges within a few million clock cycles. In addition, no system crashes were reported during normal operation, rendering the modifications transparent to the end user.	central processing unit;clock signal;crash (computing);embedded system;excited state;hardware trojan;load (computing);microprocessor;openrisc 1200;overhead (computing);privilege escalation;simulation;software deployment;transistor;trojan horse (computing)	Nektarios Georgios Tsoutsos;Michail Maniatakos	2014	IEEE Transactions on Emerging Topics in Computing	10.1109/TETC.2013.2287186	embedded system;kernel;real-time computing;privilege escalation;logic gate;computer science;operating system;fabrication;computer security	Arch	-53.733515667476645	56.39259986303007	78831
0c51a0bf534949762d389bc333d0002935415908	improving scada security of a local process with a power grid model		Security of networks controlling smart grids is an important subject. The shift of the power grid towards a smart grid results in more distributed control functions, while intrusion detection of the control network mostly remains centrally based. Moreover, existing local (host-based) intrusion detection systems do not yet take into account the physical process itself. Therefore, this work proposes a local intrusion detection system, which considers the outcome of control commands on the physical process. Using two scenarios we explain the benefits of extending the current security measures with a local intrusion detection.	co-simulation;control function (econometrics);distributed control system;intrusion detection system;inverter (logic gate);power-line communication;remote terminal unit;simulation;smart tv;telecommunications network;threat (computer);traction substation	Justyna J. Chromik;Anne Remke;Boudewijn R. Haverkort	2016			real-time computing;engineering;data mining;computer security	Security	-57.98828701521391	51.20764748513607	78938
34cb00a5a126f5dab5406e2d820a43336a651ea1	a secure execution framework for java	java security management;security management;management guis;xml based security configuration;security architecture;security policy;configuration management;dynamic loading	The Java platform facilitates to dynamically load and execute code from remote sources which can threaten the security and integrity of a system and the privacy of its users. To address these problems, Java includes a security architecture which is based on a closed policy model. Although this model is su cient to specify arbitrary policies, it easily may become cumbersome to use and is not well-suited for administering a consistent security policy for a complete network. The Java Secure Execution Framework (JSEF) overcomes these drawbacks: it introduces higher-level abstractions which enhance the expressiveness of policy rules; it simpli es the maintenance of security con gurations; and it provides additional functionality and tools to make administration less error-prone. In JSEF we propose a hybrid policy model which supports additive and subtractive permissions with a denial-take-precedence rule to resolve conicts. Security pro les can be expressed in terms of hierarchical groups where a subgroup inherits the policy de ned by its parent. All members of a group share the same set of permissions and users can be members of an arbitrary number of groups. JSEF's administrative model supports the de nition of a network-wide policy which users can tailor to their needs but not break. At runtime JSEF enforces the de ned security policy and supports security negotiation in case of insu cient permissions. A set of graphical tools supports the user in de ning security policies and con guring JSEF.	cognitive dimensions of notations;computer security;data visualization;graphical user interface;java;naruto shippuden: clash of ninja revolution 3;order of operations;utility functions on indivisible goods	Manfred Hauswirth;Clemens Kerer;Roman Kurmanowytsch	2000		10.1145/352600.352608	software security assurance;computer security model;cloud computing security;itil security management;security management;sherwood applied business security architecture;security information and event management;security engineering;computer science;security policy;information security;operating system;database;security service;configuration management;security analysis;network security policy;computer security;enterprise information security architecture	Security	-49.82886769303804	53.8322048067053	78953
467dbf2ad1abce92cbe628a9085a9c4a77dd25c9	a suggestion for cloud environments new layer contemplating and its security factors	cloud security cloud computing cloud environment;cloud security;cloud environment;encryption;availability;secure cloud services architecture security factor cloud computing environment data processing virtual environment access control information security;authentication;authenticated encryption;it security;accidents;service oriented architecture cloud computing security of data;cloud computing availability accidents authentication encryption;service oriented architecture;security of data;cloud computing	The cloud computing environments, according to recent developments have caused the expansion of various services. Therefore the cloud computing environments led research on data processing, virtual environment, and access control. Also study on information security area is most important particular of this environment. In this paper we analyze several typical examples of cloud services and cloud systems of the existing problems were identified. In addition, the architecture of a typical component of cloud services was compared and proposed generalized form secure cloud services architecture.	access control;cloud computing;diversification (finance);general computer corporation;information security;mathematical optimization;smart device;virtual reality	Jaeik Cho;Junwon Lee;Jung-Taek Seo;Taeshik Shon	2011	2011 14th International Conference on Network-Based Information Systems	10.1109/NBiS.2011.95	cloud computing security;availability;cloud computing;computer science;service-oriented architecture;cloud testing;authentication;services computing;internet privacy;authenticated encryption;world wide web;computer security;encryption	HPC	-48.99768447280633	57.98884897515482	79092
240842588fa90653d267eaebe47cc77885dd65a7	kakute: a precise, unified information flow analysis system for big-data security		Big-data frameworks (e.g., Spark) enable computations on tremendous data records generated by third parties, causing various security and reliability problems such as information leakage and programming bugs. Existing systems for big-data security (e.g., Titian) track data transformations in a record level, so they are imprecise and too coarse-grained for these problems. For instance, when we ran Titian to drill down input records that produced a buggy output record, Titian reported 3 to 9 orders of magnitude more input records than the actual ones. Information Flow Tracking (IFT) is a conventional approach for precise information control. However, extant IFT systems are neither efficient nor complete for big-data frameworks, because theses frameworks are data-intensive, and data flowing across hosts is often ignored by IFT.  This paper presents Kakute, the first precise, fine-grained information flow analysis system for big-data. Our insight on making IFT efficient is that most fields in a data record often have the same IFT tags, and we present two new efficient techniques called Reference Propagation and Tag Sharing. In addition, we design an efficient, complete cross-host information flow propagation approach. Evaluation on seven diverse big-data programs (e.g., WordCount) shows that Kakute had merely 32.3% overhead on average even when fine-grained information control was enabled. Compared with Titian, Kakute precisely drilled down the actual bug inducing input records, a huge reduction of 3 to 9 orders of magnitude. Kakute's performance overhead is comparable with Titian. Furthermore, Kakute effectively detected 13 real-world security and reliability bugs in 4 diverse problems, including information leakage, data provenance, programming and performance bugs. Kakute's source code and results are available on https://github.com/hku-systems/kakute.	big data;computation;data security;data-flow analysis;data-intensive computing;information flow;information leakage;overhead (computing);row (database);software bug;software propagation;spectral leakage;transcutaneous electrical nerve stimulation	Jianyu Jiang;Shixiong Zhao;Danish Alsayed;Yuexuan Wang;Heming Cui;Feng Liang;Zhaoquan Gu	2017		10.1145/3134600.3134607	computer science;real-time computing;drill down;information flow (information theory);information leakage;big data;computation;extant taxon;source code	Security	-54.91766368734043	55.23732361071322	79184
ebae8dbafafaf23324222e6e404e254f3a40f24c	a new framework for ranking vulnerabilities in the clouds		Qualifying and ranking threat degrees of vulnerabilities i n cloud service are known to be full of challenges. Although there have b e n several efforts aiming to address this problem, most of them are too simple or cannot be applied into cloud infrastructure. This paper aims to propose a novel framework to qualify and rank the vulnerabilities based on their threat d egrees in cloud service. Through inputting or constructing service dependency grap h, our framework is able to generate the importance degree of each service and th e ranking list of all the vulnerabilities in cloud service. Moreover, our fra mework can be adopted not only into various cloud infrastructures, but also diffe rent categories of algorithms according to concrete requirements. To evaluate our framework, we adopt AssetRank algorithm into the framework, and present the who le design of our work. Comprehensive experiments prove the effectiveness o f our framework on qualifying and ranking vulnerabilities in cloud service.	algorithm;cloud computing;experiment;requirement;simulation;threat (computer);vulnerability (computing)	He Zhu	2016	CoRR		computer science;data mining;world wide web;computer security	Security	-49.75341048824984	57.61882619847612	79810
e9d0de4b3a5f1106854195c855b9854319fe4f2f	auditing the xss defence features implemented in web application programs	web application programs;xss attacks;xss defence feature;model adequacy checking;vulnerable code sections;web pages;cross site scripting vulnerability;source coding authoring languages flow graphs formal verification hypermedia markup languages internet java safety critical software;xss defence artefacts;vulnerability detection method;control flow graph;journal article;program source code;code auditing approach;tainted information flow graph;java based web applications;xss flaws;potentially vulnerable html output;model adequacy checking xss defence feature web application programs cross site scripting vulnerability web pages xss flaws code auditing approach program source code xss attacks potentially vulnerable html output control flow graph tainted information flow graph xss defence artefacts java based web applications false positive case filtering vulnerability detection method vulnerable code sections;drntu engineering computer science and engineering data;false positive case filtering	Cross site scripting (XSS) vulnerability is mainly caused by the failure of web applications in sanitising user inputs embedded in web pages. Even though state-of-the-art defensive coding methods and vulnerability detection methods are often used by developers and security auditors, XSS flaws still remain in many applications because of (i) the difficulty of adopting these methods, (ii) the inadequate implementation of these methods, and/or (iii) the lack of understanding of XSS problem. To address this issue, this study proposes a code-auditing approach that recovers the defence model implemented in program source code and suggests guidelines for checking the adequacy of recovered model against XSS attacks. On the basis of the possible implementation patterns of defensive coding methods, our approach extracts all such defences implemented for securing each potentially vulnerable HTML output. It then introduces a variant of control flow graph, called tainted-information flow graph, as a model to audit the adequacy of XSS defence artefacts. The authors evaluated the proposed method based on the experiments on seven Java-based web applications. In the auditing experiments, our approach was effective in recovering all the XSS defence features implemented in the test subjects. The extracted artefacts were also shown to be useful for filtering the false-positive cases reported by a vulnerability detection method and helpful in fixing the vulnerable code sections.	web application	Lwin Khin Shar;Hee Beng Kuan Tan	2012	IET Software	10.1049/iet-sen.2011.0084	cross-site scripting;computer science;web page;database;programming language;world wide web;computer security;control flow graph	SE	-57.568430071007306	57.300251840850194	79840
ecca044573a50fe99fedb942dce85763031c287f	compromising fpga socs using malicious hardware blocks		Modern FPGA System-on-Chips (SoCs) combine high performance application processors with reconfigurable hardware. This allows to enhance complex software systems with reconfigurable hardware accelerators. Unfortunately, even when state-of-the-art software security mechanisms are implemented, this combination creates new security threats. Attacks on the software are now possible through the reconfigurable hardware as these cores share resources with the processor and may contain unwanted functionality. In this paper, we discuss software protection mechanisms offered in conventional SoCs and how they can be circumvented by malicious hardware blocks. As a concrete example, we show how the malicious functionality within an IP core accesses and replaces critical memory sections. We refer to this type of attacks as hardware-assisted attacks against running software systems. We carry-out a proof-of-concept on the Xilinx Zynq device which runs a Linux OS and a software application that verifies system updates. The malicious IP core replaces the public key used to verify system updates, thus, allowing an attacker to maliciously update the FPGA SoC. Additionally, we propose a countermeasure that can be applied against such threats in the form of a security wrapper for hardware modules.	application security;authorization;automated x-ray inspection;central processing unit;copy protection;field-programmable gate array;graphic art software;hardware acceleration;input–output memory management unit;linux;memory management;operating system;protection mechanism;public-key cryptography;reconfigurable computing;semiconductor intellectual property core;software system;system on a chip	Nisha Jacob;Carsten Rolfes;Andreas Zankl;Johann Heyszl;Georg Sigl	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		embedded system;parallel computing;real-time computing;reconfigurable computing;computer science;information security;operating system;hardware architecture;field-programmable gate array	Arch	-53.65725213083426	56.07485511035701	80219
41b0b3d98ddd0d2d86f61d5822903dca48c3a1bf	rtf editor xss fuzz framework		Cross Site Scripting (XSS) is one of the most important vulnerabilities in web applications, has been in the top three position of OWASP TOP10 [1] security risks for a long time. In many web application components, RTF (Rich Text Format) Editor has a wide range of XSS attacks because of its own characteristics. With the development of XSS detection technology, Fuzz technique has become a popular approach to discover XSS in web applications except Rich Text Editor. Thus, this paper proposes a RTF Editor XSS fuzz framework, which works on a lexical based fuzz framework. This framework includes an attack vector template and a mutation engine. In this framework, we use a concept named “boundary” to build the template and use a method named “breaking boundaries” to generate mutated data. Experimental results of our fuzz framework are quite encouraging. We have run it over 12 real-world RTF Editor (including Webmail, Blog, Markdown editor, etc.) and found vulnerabilities in 8 of them. We have responsibly reported our findings to the respective developers of editors.	blog;component-based software engineering;cross-site scripting;polymorphic engine;test automation;text editor;vector (malware);web application;webmail	Jun Yang;Qiyi Tang	2017		10.1007/978-3-319-61542-4_95	web application;cross-site scripting;world wide web;computer security;computer science;rich text format;markdown	Web+IR	-56.8913948071438	59.09075083493768	80417
8a929777d7d855e4471b92b087fe1647e48fb332	role based reengineering of web applications	policy enforcement;authorisation;security management;role based access control;policy decision point;visual languages;internet;visual languages internet authorisation systems re engineering;application software access control security resource management power system management hardware computer architecture databases software tools context modeling;visual language;policy decision point role based reengineering web applications access policies security management visual language based tool metaphor oriented layer role based access control policy enforcement point;systems re engineering	We present an approach based on roles and access policies to improve security management of Web applications. The approach first identifies the roles users have in the application, and then the software resources they can access based on the assigned role. Roles and resources are then used to design access policies by means of a visual language based tool providing a metaphor-oriented layer above the well-known role based access control (RBAC) model. A network infrastructure based on a policy enforcement point (PEP) and a policy decision point (PDP) is used to enforce these policies. The proposed approach has been used in a preliminary case study.	code refactoring;common open policy service;distributed computing;java platform, enterprise edition;legacy system;reverse engineering;role-based access control;security management;server (computing);software engineer;visual language;web application;web service;whole earth 'lectronic link;xacml	Andrea De Lucia;Massimiliano Giordano;Giuseppe Polese;Giuseppe Scanniello;Genny Tortora	2005	Seventh IEEE International Symposium on Web Site Evolution	10.1109/WSE.2005.12	security management;the internet;computer access control;computer science;knowledge management;software engineering;role-based access control;database;authorization;world wide web;computer security	SE	-49.31494454127184	50.4038983517572	81025
2e4b444acfa38999eda6f4bf91baf2602e6c9623	information flow for security in control systems	software;detectors;watermarking;control systems;government;computational modeling	This paper considers the development of information flow analyses to support resilient design and active detection of adversaries in cyber physical systems (CPS). CPS security, though well studied, suffers from fragmentation. In this paper, we consider control systems as an abstraction of CPS. Here, we use information flow analysis, a well established set of methods developed in software security, to obtain a unified framework that captures and extends results in control system security. Specifically, we propose the Kullback Liebler (KL) divergence as a causal measure of information flow, which quantifies the effect of adversarial inputs on sensor outputs. We show that the proposed measure characterizes the resilience of control systems to specific attack strategies by relating the KL divergence to optimal detection. We then relate information flows to stealthy attack scenarios where an adversary can bypass detection. Finally, this article examines active detection mechanisms where a defender intelligently manipulates control inputs or the system itself to elicit information flows from an attacker's malicious behavior. In all previous cases, we demonstrate an ability to investigate and extend existing results through the proposed information flow analyses.	adversary (cryptography);application security;causal filter;control system security;data-flow analysis;fragmentation (computing);information flow (information theory);kullback–leibler divergence;unified framework	Sean Weerakkody;Bruno Sinopoli;Soummya Kar;Anupam Datta	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7799044	simulation;engineering;control system;artificial intelligence;data mining;computer security;government;computer network	Security	-55.32395436065841	52.207502391074534	81159
2941851ddb7066035eade6a8a6b3531f9a981006	an analytical model for time-driven cache attacks	lookup table;analytical model;software implementation	Cache attacks exploit side-channel information that is leaked by a microprocessor’s cache. There has been a significant amount of research effort on the subject to analyze and identify cache side-channel vulnerabilities since early 2002. Experimental results support the fact that the effectiveness of a cache attack depends on the particular implementation of the cryptosystem under attack and on the cache architecture of the device this implementation is running on. Yet, the precise effect of the mutual impact between the software implementation and the cache architecture is still an unknown. In this manuscript, we explain the effect and present an analytical model for time-driven cache attacks that accurately forecasts the strength of a symmetric key cryptosystem based on 3 simple parameters: (1) the number of lookup tables; (2) the size of the lookup tables; (3) and the length of the microprocessor’s cache line. The accuracy of the model has been experimentally verified on 3 different platforms with different implementations of the AES algorithm attacked by adversaries with different capabilities.	cpu cache;cryptosystem;experiment;lookup table;microprocessor;side-channel attack;symmetric-key algorithm	Kris Tiri;Onur Aciiçmez;Michael Neve;Flemming Andersen	2007		10.1007/978-3-540-74619-5_25	bus sniffing;pipeline burst cache;cache-oblivious algorithm;parallel computing;cache coloring;cpu cache;cache;computer science;write-once;theoretical computer science;cache invalidation;smart cache;cache algorithms;cache pollution;computer security	Arch	-54.20543158804939	55.59271744578237	81486
0a3239ae38ff62c658a962d3a8cb9d1f76c02f6f	progger: an efficient, tamper-evident kernel-space logger for cloud data provenance tracking	kernel sockets cloud computing synchronization virtual machining data security;system monitoring cloud computing security of data;conference contribution;time synchronisation cloud computing data provenance data security accountability tamper evident logging;tamper evident logging;accountability;time synchronisation;cloud computing;data provenance;data security;data activity tracking progger kernel space logger cloud data provenance tracking data security component data accountability cloud computing systems data activity audit	"""Cloud data provenance, or """"what has happened to my data in the cloud"""", is a critical data security component which addresses pressing data accountability and data governance issues in cloud computing systems. In this paper, we present Progger (Provenance Logger), a kernel-space logger which potentially empowers all cloud stakeholders to trace their data. Logging from the kernel space empowers security analysts to collect provenance from the lowest possible atomic data actions, and enables several higher-level tools to be built for effective end-to-end tracking of data provenance. Within the last few years, there has been an increasing number of proposed kernel space provenance tools but they faced several critical data security and integrity problems. Some of these prior tools' limitations include (1) the inability to provide log tamper-evidence and prevention of fake/manual entries, (2) accurate and granular timestamp synchronisation across several machines, (3) log space requirements and growth, and (4) the efficient logging of root usage of the system. Progger has resolved all these critical issues, and as such, provides high assurance of data security and data activity audit. With this in mind, the paper will discuss these elements of high-assurance cloud data provenance, describe the design of Progger and its efficiency, and present compelling results which paves the way for Progger being a foundation tool used for data activity tracking across all cloud systems."""	cloud computing;data governance;data logger;data security;end-to-end encryption;keystroke logging;l (complexity);my life as a teenage robot;os-tan;requirement;semantic web;system call;user space	Ryan K. L. Ko;Mark A. Will	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.121	cloud computing security;cloud computing;computer science;operating system;database;data security;internet privacy;world wide web	DB	-50.005333180882694	58.15630381431923	81491
481ea0c646be6d62738891071c621ef5acb938e8	justifying integrity using a virtual machine verifier	virtual machine;generators;virtual machines distributed programming linux;integrable model;integrity measurement;virtual machine verifier;distributed computing;virtual machining computer architecture distributed computing cloud computing current measurement buildings voice mail grid computing runtime environment virtual manufacturing;data mining;runtime;selinux;computer architecture;xen virtual machine system;current measurement;virtual machines;cloud computing virtual machine verifier integrity measurement distributed computing architectures false integrity clark wilson integrity model vm verifier xen virtual machine system selinux grid computing;distributed programming;force measurement;clark wilson integrity model;vm verifier;virtual machines cloud computing integrity measurement;linux;false integrity;grid computing;architecture;distributed computing architectures;cloud computing	Emerging distributed computing architectures, such as grid and cloud computing, depend on the high integrity execution of each system in the computation. While integrity measurement enables systems to generate proofs of their integrity to remote parties, we find that current integrity measurement approaches are insufficient to prove runtime integrity for systems in these architectures. Integrity measurement approaches that are flexible enough have an incomplete view of runtime integrity, possibly leading to false integrity claims, and approaches that provide comprehensive integrity do so only for computing environments that are too restrictive. In this paper, we propose an architecture for building comprehensive runtime integrity proofs for general purpose systems in distributed computing architectures. In this architecture, we strive for classical integrity, using an approximation of the Clark-Wilson integrity model as our target. Key to building such integrity proofs is a carefully crafted host system whose long-term integrity can be justified easily using current techniques and a new component, called a VM verifier, which comprehensively enforces our integrity target on VMs. We have built a prototype based on the Xen virtual machine system for SELinux VMs, and find that distributed compilation can be implemented, providing accurate proofs of our integrity target with less than 4% overhead.	approximation;clark–wilson model;cloud computing;compiler;computation;distributed computing;overhead (computing);prototype;selinux;virtual machine	Joshua Schiffman;Thomas Moyer;Christopher Shal;Trent Jaeger;Patrick D. McDaniel	2009	2009 Annual Computer Security Applications Conference	10.1109/ACSAC.2009.18	real-time computing;computer science;virtual machine;operating system;data integrity;distributed computing;computer security	Security	-51.98307194514466	57.36277431197717	81537
29aa66ce6a70ba92a6a5db31b9769cc7a833b404	integrated content-based information security for future military systems	software defined networking environment military operations security policies information protection integrity policies availability policies federated mission environments content based protection and release cross layer enforcement cpr policies;tcpip;bridges;military communication;computer security;sensitivity;software defined networking access control communication system security data security information security;chlorine;sensitivity bridges tcpip chlorine computer security military communication;telecommunication security content management military communication software defined networking	Future military operations require versatile and integrated mechanisms for enforcement of the security policies in all three domains of information protection: confidentiality, integrity and availability. We discuss challenges and use cases related to enforcement of integrity and availability policies in federated mission environments and we demonstrate how the concept of Content-based Protection and Release (CPR) can be extended to support such policies. Furthermore, we present an approach to cross-layer enforcement of the CPR policies and introduce a proof-of-concept implementation of the CPR enforcement mechanisms in a software-defined networking environment.	confidentiality;high availability;high- and low-level;information security;overhead (computing);requirement;security management;software-defined networking;unavailability	Konrad S. Wrona;Sander Oudkerk	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357614	software security assurance;computer security model;cloud computing security;security information and event management;asset;engineering;information security;information security standards;security service;internet privacy;security analysis;network access control;computer security;computer network	Security	-50.70286197777713	57.196568438979746	81727
bea1e620a8ea49db6e42f9c585e7cee84d054367	architectures et mécanismes de sécurité pour l'auto-protection des systèmes pervasifs. (security architecture and mechanisms for self-protection of pervasive systems)		Advances in pervasive system are rapidly taking us to a novel frontier in security, revealing a whole new landscape of threats. In open and dynamic environments, malicious terminals may enter a network without being detected, and various malwares may invisibly install themselves on a device. While roaming between heterogeneous networks which are adjusted for their own protection requirements, a device may also take advantage of security policy conflicts to gain unauthorized privileges. In an embedded setting including limited and often unstable computing and networking resources, denial of service attacks are somewhat easier, with little lightweight security countermeasures. Finally, these decentralized, large-scale systems make end-to-end security supervision difficult, with the risk of some sub-system security policies not being up-to-date. These threats can only be mitigated with security mechanisms which are highly adaptable to conditions and security requirements. Moreover, the administration overhead of security infrastructures usually remains high. Operations to achieve the administration become increasingly complex which would be out of control. One promising direction initiated by IBM is to extend context-awareness to the security mechanisms themselves in order to make them autonomic. In this approach, protection schemes are automatically adapted at run-time according to the actual security requirements of the environment. Our work applies autonomic computing to conventional authorization infrastructure. We illustrate that autonomic computing is not only useful for managing IT infrastructure complexity, but also to mitigate continuous software evolution problems. However, its application in pervasive systems calls for a collection of design building blocks, ranging form overall architecture to terminal OS design. In this thesis, we propose: • A three-layer abstract architecture: a three-layer self-protection architecture is applied to the framework. A lower execution space provides running environment for applications, a control plane controls the execution space, and an autonomic plane guides the control behavior of the control plane in taking into account system status, context evolution, administrator strategy and user preferences. • An attribute-based access control model: the proposed model (Generic AttributeBased Access Control) is an attribute-based access control model which improves both the policy-neutrality to specify other access control policies and flexibility to enable fine-grain manipulations on one policy. • A policy-based framework for authorization integrating autonomic computing: the policy-based approach has shown its advantages when handling complex and dynamic systems. In integrating autonomic functions into this approach, an Autonomic Security Policy Framework provides a consistent and decentralized solution to administer G-ABAC policies in large-scale distributed pervasive systems. Moreover, the integration of autonomic functions enhances user-friendliness and context-awareness. • A terminal-side access control enforcement OS: the distributed authorization policies are then enforced by an OS level authorization architecture. It is an efficient	access control;authorization;autonomic computing;context awareness;control plane;control theory;denial-of-service attack;dynamical system;embedded system;end-to-end encryption;malware;multitier architecture;operating system;overhead (computing);pervasive informatics;requirement;runtime system;software evolution;threat (computer);ubiquitous computing;usability;user (computing)	Ruan He	2010				Security	-50.3217056814018	55.71768147112183	81803
18a5335028e7802840b62a1db90c0eca4aa52bd1	my software has a vulnerability, should i worry?		(U.S) Rule-based policies to mitigate software risk suggest to use the CVSS score to measure the individual vulnerability risk and act accordingly: an HIGH CVSS score according to the NVD (National (U.S.) Vulnerability Database) is therefore translated into a “Yes”. A key issue is whether such rule is economically sensible, in particular if reported vulnerabilities have been actually exploited in the wild, and whether the risk score do actually match the risk of actual exploitation. We compare the NVD dataset with two additional datasets, the EDB for the white market of vulnerabilities (such as those present in Metasploit), and the EKITS for the exploits traded in the black market. We benchmark them against Symantec’s threat explorer dataset (SYM) of actual exploit in the wild. We analyze the whole spectrum of CVSS submetrics and use these characteristics to perform a case-controlled analysis of CVSS scores (similar to those used to link lung cancer and smoking) to test its reliability as a risk factor for actual exploitation. We conclude that (a) fixing just because a high CVSS score in NVD only yields negligible risk reduction, (b) the additional existence of proof of concepts exploits (e.g. in EDB) may yield some additional but not large risk reduction, (c) fixing in response to presence in black markets yields the equivalent risk reduction of wearing safety belt in cars (you might also die but still. . . ). On the negative side, our study shows that as industry we miss a metric with high specificity (ruling out vulns for which we shouldn’t worry).	authentication;benchmark (computing);bus (computing);emoticon;exploit (computer security);exploit kit;logic programming;metasploit;national vulnerability database;sensitivity and specificity;tudor it process assessment	Luca Allodi;Fabio Massacci	2013	CoRR			Security	-56.187300001425996	58.74218064245338	81862
ac9b77219c5d574dc2bbfa5c30d68129c91162d2	aslr on the line: practical cache attacks on the mmu		Address space layout randomization (ASLR) is an important first line of defense against memory corruption attacks and a building block for many modern countermeasures. Existing attacks against ASLR rely on software vulnerabilities and/or on repeated (and detectable) memory probing. In this paper, we show that neither is a hard requirement and that ASLR is fundamentally insecure on modern cachebased architectures, making ASLR and caching conflicting requirements (ASLR⊕Cache, or simply AnC). To support this claim, we describe a new EVICT+TIME cache attack on the virtual address translation performed by the memory management unit (MMU) of modern processors. Our AnC attack relies on the property that the MMU’s page-table walks result in caching page-table pages in the shared last-level cache (LLC). As a result, an attacker can derandomize virtual addresses of a victim’s code and data by locating the cache lines that store the page-table entries used for address translation. Relying only on basic memory accesses allows AnC to be implemented in JavaScript without any specific instructions or software features. We show our JavaScript implementation can break code and heap ASLR in two major browsers running on the latest Linux operating system with 28 bits of entropy in 150 seconds. We further verify that the AnC attack is applicable to every modern architecture that we tried, including Intel, ARM and AMD. Mitigating this attack without naively disabling caches is hard, since it targets the low-level operations of the MMU. We conclude that ASLR is fundamentally flawed in sandboxed environments such as JavaScript and future defenses should not rely on randomized virtual addresses as a building block.	arm architecture;address space layout randomization;cpu cache;cache (computing);central processing unit;countermeasure (computer);high- and low-level;javascript;linux;memory corruption;memory management unit;operating system;page table;randomized algorithm;requirement;sandbox (computer security);vulnerability (computing)	Ben Gras;Kaveh Razavi;Erik Bosman;Herbert Bos;Cristiano Giuffrida	2017			parallel computing;real-time computing;operating system	Security	-54.852846554583806	56.6671417971386	81912
2ff4956da26ef8ba40fe59d28e47f65a62ab4528	modeling security requirements through ownership, permission and delegation	formal specification;datalog security requirements modeling security requirements engineering software engineering secure tropos security requirements analysis security design pattern formal reasoning tool;software engineering;permission proposals software engineering monitoring data security protection availability authorization software systems unified modeling language;formal reasoning;security requirements;design pattern;egat;formal specification security of data;security of data;qa075 electronic computers computer science	Security requirements engineering is emerging as a branch of software engineering, spurred by the realization that security must be dealt with early on during the requirements phase. Methodologies in this field are challenging, as they must take into account subtle notions such as trust (or lack thereof), delegation, and permission; they must also model entire organizations and not only systems-to-be. In our previous work we introduced Secure Tropos, a formal framework for modeling and analyzing security requirements. Secure Tropos is founded on three main notions: ownership, trust, and delegation. In this paper, we refine Secure Tropos introducing the notions of at-least delegation and trust of execution; also, at-most delegation and trust of permission. We also propose monitoring as a security design pattern intended to overcome the problem of lack of trust between actors. The paper presents a semantic for these notions, and describes an implemented formal reasoning tool based on Datalog.	datalog;design pattern;file system permissions;requirement;requirements analysis;requirements engineering;software engineering	Paolo Giorgini;Fabio Massacci;John Mylopoulos;Nicola Zannone	2005	13th IEEE International Conference on Requirements Engineering (RE'05)	10.1109/RE.2005.43	software security assurance;computer security model;cloud computing security;reliability engineering;security through obscurity;security information and event management;security engineering;security convergence;computer science;engineering;software engineering;formal specification;database;security service;design pattern;security testing;computer security	SE	-53.87860176138031	49.80056910737547	81973
b60cc58d47e6bf7f2589fe76e8e2c3562f16c8e6	multi-run side-channel analysis using symbolic execution and max-smt	quantitative information flow;multi run security;max smt;measurement uncertainty;computational modeling;symbolic execution;channel capacity;cryptography;java cryptography concrete computational modeling channel capacity measurement uncertainty context;cryptographic functions multirun side channel analysis symbolic execution max smt satisfiability modulo theory confidential information program analysis information quantification side channel measurements model counting metrics information theoretic metrics symbolic pathfinder tool password checking function;side channel attacks;max smt side channel attacks quantitative information flow cryptography multi run security symbolic execution satisfiability modulo theories;satisfiability modulo theories;cryptography computability;context;conference proceeding;concrete;java	"""Side-channel attacks recover confidential information from non-functional characteristics of computations, such as time or memory consumption. We describe a program analysis that uses symbolic execution to quantify the information that is leaked to an attacker who makes multiple side-channel measurements. The analysis also synthesizes the concrete public inputs (the """"attack"""") that lead to maximum leakage, via a novel reduction to Max-SMT solving over the constraints collected with symbolic execution. Furthermore model counting and information-theoretic metrics are used to compute an attacker's remaining uncertainty about a secret after a certain number of side-channel measurements are made. We have implemented the analysis in the Symbolic PathFinder tool and applied it in the context of password checking and cryptographic functions, showing how to obtain tight bounds on information leakage under a small number of attack steps."""	capability maturity model;computation;confidentiality;cryptography;information leakage;information theory;nonlinear system;password;program analysis;scalability;side-channel attack;spectral leakage;symbolic execution	Corina S. Pasareanu;Quoc-Sang Phan;Pasquale Malacaria	2016	2016 IEEE 29th Computer Security Foundations Symposium (CSF)	10.1109/CSF.2016.34	real-time computing;concrete;computer science;cryptography;theoretical computer science;programming language;java;satisfiability modulo theories;computer security;symbolic trajectory evaluation;channel capacity;algorithm;statistics;measurement uncertainty	Security	-55.279416087482616	52.58362136154386	82532
0f47b0de1aa4829f8a5ea51a5425515327755880	hardening the core: understanding and detection of xnu kernel vulnerabilities		The occurrence of security vulnerabilities in kernel, especially for macOS/iOS kernel XNU, has increased rapidly in recent years. Naturally, concerns were raised due to the high risks they would lead to, which in general are much more serious than common application vulnerabilities. However, discovering XNU kernel vulnerabilities is always very challenging, and the main approach in practice is still manual analysis, which obviously is not a scalable method. In this paper, we perform an in-depth empirical study on the 406 published XNU kernel vulnerabilities to identify distinguishing characteristics of them and then leverage the features to guide our vulnerability detection, i.e., locating suspicious functions. To further improve the efficiency of vulnerability detection, we present KInspector, a new and lightweight framework to detect XNU kernel vulnerabilities by leveraging feedback-based fuzzing techniques. We thoroughly evaluate our approach on XNU with various versions, and the results turn out to be quite promising: 21 N/0-day vulnerabilities have been discovered in our experiments.	experiment;kernel (operating system);scalability;vulnerability (computing);xnu kernel;ios;macos	Xianyu Liu;Min Zheng;Aimin Pan;Quan Lu	2018	2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)	10.1109/DSN-W.2018.00014	kernel (linear algebra);scalability;theoretical computer science;distributed computing;computer science;hardening (computing);vulnerability;fuzz testing	Security	-57.680692523800715	57.599895158414704	83371
3b88f872156606db33e6e85697bdced790de8566	behavior query discovery in system-generated temporal graphs		Computer system monitoring generates huge amounts of log data that record the interaction of system entities such as processes, files, and sockets. How to query such data to better understand system behaviors and identify potential security risks and malicious behaviors becomes a challenging task for system administrators due to the dynamics and heterogeneity of the data. System monitoring data is essentially a heterogeneous temporal graph with nodes being system entities and edges being their interactions over time. Given the complexity of such graphs and intrusion tactics, it becomes time-consuming for system administrators to manually formulate useful queries in order to examine suspicious activities, attacks, and vulnerabilities in computer systems. In this work, we investigate how to query temporal graphs and treat query formulation as a discriminative temporal graph pattern mining problem. We introduce TGMiner to mine discriminative patterns from system traces, and these patterns can be taken as templates for building more complex queries. TGMiner leverages temporal information in graphs to prune graph patterns that share similar growth trend without compromising pattern quality. Experimental results on real system data show that TGMiner is 6-32 times faster than baseline methods. The discovered patterns were verified by system experts; they achieved high precision (97%) and recall (91%).	baseline (configuration management);data mining;entity;interaction;linc;malware;system administrator;system monitoring	Bo Zong;Xusheng Xiao;Zhichun Li;Zhenyu Wu;Zhiyun Qian;Xifeng Yan;Ambuj K. Singh;Guofei Jiang	2015	PVLDB	10.14778/2856318.2856320	computer science;theoretical computer science;data mining;database;world wide web	DB	-58.9244558653943	60.032842545637344	83442
caf409d2bb65bad6d2b3a3a719c7fe0909f8e6ee	towards verified, constant-time floating point operations		The runtimes of certain floating-point instructions can vary up to two orders of magnitude with instruction operands, allowing attackers to break security and privacy guarantees of real systems (\eg browsers). To prevent attacks due to such floating-point timing channels, we introduce CTFP, an efficient, machine-checked, and extensible system that transforms unsafe floating-point operations into safe, constant-time computations. CTFP relies on two observations. First, that it is possible to execute floating-point computations in constant-time by emulating them in software; and second, that most security critical applications do not require full IEEE-754 floating-point precision. We use these observations to: eliminate certain classes of dangerous values from ever reaching floating-point hardware; emulate floating-point operations on dangerous values when eliminating them would severely alter application semantics; and, leverage fast floating-point hardware when it is safe to do so. We implement the constant-time transformations with our own domain-specific language that produces LLVM bitcode. Since the transformations themselves equate to bit surgery on already complicated floating-point arithmetic, we use a satisfiability modulo theories (SMT) solver to ensure that their behavior fits our specifications. Finally, we find that CTFP neither breaks real world applications nor incurs overwhelming overhead.	algorithm;central processing unit;computation;denormal number;domain-specific language;emulator;fits;floating-point unit;heart rate variability;llvm;modulo operation;nan;operand;overhead (computing);satisfiability modulo theories;semiconductor research corporation;solver;time complexity;timing channel	Marc Andrysco;Andres Nötzli;Fraser Brown;Ranjit Jhala;Deian Stefan	2018		10.1145/3243734.3243766	computer security;operand;computation;floating point;real-time computing;software;computer science;satisfiability modulo theories;extensibility;communication channel;solver	Security	-54.50902556524737	55.913075465640944	83620
29885b5d9a6a5974743bf1882c609ec09e932347	on the automated creation of understandable positive security models for web applications	databases;network based firewall system;description language security model web application network based firewall system;security model;application software;security of data internet;information filtering;intrusion detection;data mining;law;legal factors;client server;internet;web application;law legal factors data security application software information filtering information filters data mining web server intrusion detection databases;web server;information filters;security of data;description language;data security	Web applications pose new security-related challenges since attacks on web applications strongly differ from those on client-server applications. Traditional network-based firewall systems offer no protection against this kind of attacks since they occur on the application-level. The current solution is the manual definition of large sets of filtering rules which should prevent malicious attempts from being successful. We propose a new framework which should avoid this tedious work. The basic idea is the definition of a description language for positive security models taking the particularities of web applications into account. We then present adaptive techniques which employ this description language in order to describe the valid communication to a given web application. The simplicity of the description language allows the easy identification of unintentionally incorporated vulnerabilities. Experiments for several real- world web applications demonstrate the usefulness of the proposed approach.	anti-spam techniques;client–server model;data mining;firewall (computing);interface description language;regular expression;sequential pattern mining;server (computing);temporal logic;vulnerability (computing);web application;xml	Christian Bockermann;Ingo Mierswa;Katharina Morik	2008	2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications (PerCom)	10.1109/PERCOM.2008.59	computer security model;intrusion detection system;application software;web application;web modeling;the internet;computer science;operating system;data mining;data security;web engineering;world wide web;computer security;web server;client–server model;computer network	SE	-56.920441734276274	58.53676271586007	83691
4c0ece233f7c5513fb065f793370b95905e577f2	the security pi-calculus and non-interference	distributed system;journal article;input output;non interference;picalculus;testing equivalences;computer science;distributed systems;security types;type system	The security π-calculus is a typed version of the asynchronous π-calculus in which the types, in addition to constraining the input/output behaviour of processes, have security levels associated with them. This enables us to introduce a range of typing disciplines which allow input or output behaviour, or both, to be bounded above or below by a given security level.#R##N##R##N#We define typed versions of may and must equivalences for the security π-calculus, where the tests are parameterised relative to a security level. We provide alternative characterisations of these equivalences in terms of actions in context; these describe the actions a process may perform in a given typing environment, assuming the observer is constrained by a related, but possibly different, environment.#R##N##R##N#The paper also contains non-interference results with respect to may and must testing. These show that certain form of non-interference can be enforced using our typing systems.	interference (communication);non-interference (security);π-calculus	Matthew Hennessy	2005	J. Log. Algebr. Program.	10.1016/j.jlap.2004.01.003	computer security model;input/output;type system;computer science;theoretical computer science;mathematics;distributed computing;programming language;algorithm	PL	-53.40120816541204	51.737667104365904	83773
0fe54b897806ad5c8d9777d1ed8df77a5050cd7c	managing changes with legacy security engineering processes	security engineering;control systems;formal specification;life cycle;software maintenance;security computational modeling business design methodology iec standards control systems iso standards;iso standards;secure computation;security risks;risk management;software engineering;requirements;software architecture;control system;computational modeling;iec standards;specification languages;tooling system and software engineering life cycle security engineering security risks requirements;security requirements;tooling;business;management of change;system and software engineering life cycle;specification languages formal specification management of change risk management security of data software architecture software maintenance;security;security of data;security dsml change management legacy security engineering process security knowledge asset attack security requirement architectural solution tooling environment architectural domain mapping concept security risk management risk modeling language;design methodology	Managing changes in Security Engineering is a difficult task: the analyst must keep the consistency between security knowledge such as assets, attacks and treatments to stakeholders' goals and security requirements. Research-wise the usual solution is an integrated methodology in which risk, security requirements and architectural solutions are addressed within the same tooling environment and changes can be easily propagated.	change management (engineering);requirement;risk management;security engineering;smart card;systems design	Edith Felix;Olivier Delande;Fabio Massacci;Federica Paci	2011	Proceedings of 2011 IEEE International Conference on Intelligence and Security Informatics	10.1109/ISI.2011.5984064	software security assurance;computer security model;cloud computing security;biological life cycle;software architecture;countermeasure;requirements analysis;security management;security through obscurity;security information and event management;security engineering;security convergence;design methods;asset;computer science;control system;formal specification;security service;security testing;software maintenance;computational model	SE	-55.2080743437473	48.804832833878656	83843
9834daec31968cc4c3990d4849ab7110087d9a23	determining vulnerability resolution time by examining malware proliferation rates	operating systems computers invasive software;malware operating systems computers educational institutions electronic mail;effective patch time vulnerability resolution time malware proliferation rate computer system weaknesses malware appearance malware disappearance dynamic analysis;malware trends malware patch time vulnerability resolution malware emergence;invasive software;operating systems computers	One of the ways that malware infects is by exploiting weaknesses in computer systems, often through conditions in software. When this happens, software and operating system vendors must repair these vulnerabilities by patching their software. However, vendors can release patches but cannot force users to apply them. Malware attempts to proliferate without regard to the state of the infected system; it is only once that the malware infection is stopped that we can truly say that systems are patched to eliminate that exploit. By examining appearance and disappearance of malware types, as determined through dynamic analysis of malware samples, classified by behavioral profiles correlated with a timeline of discovery dates, we can determine a more real-world average time for effective patch times, as opposed to the time it takes for a vendor to release a patch for a discovered vulnerability.	malware;operating system;timeline	Jeremy D. Seideman;Bilal Khan;Ghassen Ben Brahim	2013	2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2013.6583808	embedded system;cyber-collection;computer science;operating system;cryptovirology;internet privacy;world wide web;computer security	SE	-57.76150451241807	60.35581445786633	83982
7419499f51d1702089f20ab33dfe6ea2ce230e8d	why pcs are fragile and what we can do about it: a study of windows registry problems	access protection mechanisms windows registry software configuration computer systems fault injection;system monitoring;fault diagnosis operating systems computers configuration management system monitoring;personal communication networks application software protection operating systems data mining computerized monitoring condition monitoring fault detection robustness microcomputers;fault injection;configuration management;operating systems computers;fault diagnosis	Software configuration problems are a major source of failures in computer systems. In this paper, we present a new framework for categorizing configuration problems. We apply this categorization to Windows registry-related problems obtained from various internal as well as external sources. Although infrequent, registry-related problems are difficult to diagnose and repair. Consequently they frustrate the users. We classify problems based on their manifestation and the scope of impact to gain useful insights into how problems affect users and why PCs are fragile. We then describe techniques to identify and eliminate such registry failures. We propose health predicate monitoring for detecting known problems, fault injection for improving application, robustness, and access protection mechanisms for preventing fragility problems.	categorization;fault injection;instability;knowledge base;microsoft windows;protection mechanism;sensor;total cost of ownership;user interface	Archana Ganapathi;Yi-Min Wang;Ni Lao;Ji-Rong Wen	2004	International Conference on Dependable Systems and Networks, 2004	10.1109/DSN.2004.1311926	reliability engineering;system monitoring;real-time computing;operating system;distributed computing;configuration management;computer security;computer network	HPC	-57.27538131124956	56.52235661445387	84157
b29fdf2aec54f0f1be77d9e2996e9815a5a221ff	leveraging relocations in elf-binaries for linux kernel version identification		Identification of operating system kernel version is essential in a large number of forensic and security applications in both cloud and local environments. Prior state-of-the-art uses complex differential analysis of several aspects of kernel implementation and knowledge of kernel data structures. In this paper, we present a working research prototype codeid-elf for ELF binaries based on its Windows counterpart codeid, which can identify kernels through relocation entries extracted from the binaries. We show that relocation-based signatures are unique and distinct and thus, can be used to accurately determine Linux kernel versions and derandomize the base address of the kernel in memory (when kernel Address Space Layout Randomization is enabled). We evaluate the effectiveness of codeid-elf on a subset of Linux kernels and find that the relocations in kernel code have nearly 100% code coverage and low similarity (uniqueness) across various kernels. Finally, we show that codeid-elf, which leverages relocations in kernel code, can detect all kernel versions in the test set with almost 100% page hit rate and nearly zero false negatives. © 2018 The Author(s). Published by Elsevier Ltd on behalf of DFRWS. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	address space layout randomization;antivirus software;base address;code coverage;data structure;hit (internet);kernel (operating system);linux;microsoft windows;norsk data;operating system;prototype;relocation (computing);test set	Manish Bhatt;Irfan Ahmed	2018	Digital Investigation	10.1016/j.diin.2018.04.022	parallel computing;base address;address space layout randomization;computer science;kernel (linear algebra);data mining;relocation;code coverage;data structure;linux kernel;test set	Security	-58.50706773009627	55.55479384386432	84383
270e145fdbaeb08874409879e1d3dc0b033b72db	incremental development of rbac-controlled e-marking system using the b method	proof obligation incremental development rbac controlled e marking system b method role based access control rbac model access policy access rights incremental software development software features access rules security flaw b language model consistency reevaluation electronic marking system ems b specification consistency verification rbac specification model checking;formal specifications;energy management mathematical model authorization model checking context modeling;rbac constraints;proof obligations;model checking;proof obligations role based access control rbac formal specifications rbac constraints separation of duties role hierarchy cardinality constraints model checking;cardinality constraints;separation of duties;role hierarchy;specification languages authorisation formal specification formal verification software maintenance;role based access control rbac	Role Based Access Control (RBAC) models are access policies that associate access rights to roles of subjects on objects. The incremental development of software by adding new features and the insertion of new access rules potentially render the model inconsistent and create security flaws. This paper proposes modeling RBAC models using the B language such that it is possible to reevaluate the consistency of the models following model changes. It shows the mechanism of formalizing RBAC policies of an Electronic Marking System (EMS) using B specifications and illustrates the verification of the consistency of the RBAC specification, using model checking and proof obligations.	b-method;formal specification;formal verification;item unique identification;iterative and incremental development;model checking;role-based access control	Nasser Al-Hadhrami;Benjamin Aziz;Shantanu Sardesai;Lotfi Ben Othmane	2015	2015 10th International Conference on Availability, Reliability and Security	10.1109/ARES.2015.95	computer science;role-based access control;data mining;database;computer security	SE	-50.43190330938941	50.533045810001944	84725
395af0a0a278e84614117d0aaae96cfd5297fc16	wrappers - a mechanism to support state-based authorisation in web applications	web security;access control;security policy	The premises of this paper are 1) security is application dependent because application semantics directly influence proper protection; but 2) applications are generally too complex to be trusted to implement security as specified by the given security policy. These problems are aggravated if the application operates over time and space. This paper proposes the use of a simple program (a “wrapper”) that has enough knowledge about a specific application’s potential states and the actions that are permissible in each state. Using this knowledge, it is able to filter requests that should not reach an application at a given point.	a new kind of science;application security;authorization;firewall (computing);online shopping;parsing;trusted operating system;world wide web;wrapper library	Martin S. Olivier;Ehud Gudes	2000		10.1007/0-306-47008-X_14	computer security model;cloud computing security;security through obscurity;security information and event management;covert channel;engineering;data mining;security service;application security;security testing;world wide web;computer security	OS	-51.782644817861076	54.9312315546076	84873
2ac1846337c4a8c09bc37db69ebbf07ddf83c889	securing untrusted code via compiler-agnostic binary rewriting	belief logic;security protocols;automated security analysis	Binary code from untrusted sources remains one of the primary vehicles for malicious software attacks. This paper presents Reins, a new, more general, and lighter-weight binary rewriting and in-lining system to tame and secure untrusted binary programs. Unlike traditional monitors, Reins requires no cooperation from code-producers in the form of source code or debugging symbols, requires no client-side support infrastructure (e.g., a virtual machine or hypervisor), and preserves the behavior of even complex, event-driven, x86 native COTS binaries generated by aggressively optimizing compilers. This makes it exceptionally easy to deploy. The safety of programs rewritten by Reins is independently machine-verifiable, allowing rewriting to be deployed as an untrusted third-party service. An implementation of Reins for Microsoft Windows demonstrates that it is effective and practical for a real-world OS and architecture, introducing only about 2.4% runtime overhead to rewritten binaries.	binary code;binary file;binary recompiler;client-side;debugging;event-driven programming;formal verification;hypervisor;inline expansion;malware;microsoft windows;operating system;optimizing compiler;overhead (computing);rewriting;tame;virtual machine;x86	Richard Wartell;Vishwath Mohan;Kevin W. Hamlen;Zhiqiang Lin	2012		10.1145/2420950.2420995	real-time computing;computer science;operating system;cryptographic protocol;distributed computing;computer security	OS	-55.177024297045094	54.98085276868058	85015
af178ad46502d4efd74b6f50f6363a7c004d618c	suduta: script uaf detection using taint analysis	use after free;vulnerability analysis;taint analysis	Use-after-free UAF vulnerabilities are caused by the use of dangling pointers. Their exploitation inside script engine-hosting applications, e.g. web browsers, can even bypass state-of-the-art countermeasures. This work proposes SUDUTA Script UAF Detection Using Taint Analysis, which aims at facilitating the diagnosis of UAF bugs during vulnerability analysis and improves an existent promising technique based on dynamic taint tracking. Firstly, precise taint analysis rules are presented in this work to clearly specify how SUDUTA manages the taint state. Moreover, it shifts its analysis to on-line, enabling instrumentation code to gain access to the program state of the application. Lastly, it handles the presence of custom memory allocators that are typically utilised in script-hosting applications. Results obtained using a benchmark dataset and vulnerable applications validate these three improvements.		John Galea;Mark Vella	2015		10.1007/978-3-319-24858-5_9	taint checking;computer science;vulnerability assessment;internet privacy;world wide web;computer security	NLP	-57.23732811326969	58.09790767257398	85325
8306c31010b8587fcdf3d9522ea518445fa0848e	time-stealer: a stealthy threat for virtualization scheduler and its countermeasures	virtualization;xen;credit scheduler vulnerability;cloud computing	Third-party Cloud Computing, Amazon's Elastic Compute Cloud (EC2) for instance, provides Infrastructure as a Service (IaaS) solutions that pack multiple customer virtual machines (VMs) onto the same physical server with hardware virtualization technology. Xen is widely used in virtualization which charges VMs by wall clock time rather than resources consumed. Under this model, manipulation of the scheduler vulnerability may allow theft-of-service at the expense of other customers.#R##N##R##N#Recent research has shown that attacker's VM can consume more CPU time than fair share on Amazon EC2 in that Xen 3.x default Credit Scheduler's resolution was rather coarse. Although considerable changes have been made in Xen 4.x Credit Scheduler to improve the performance in case of such stealing attacks, we've found another alternative attack called Time-Stealer which can obtain up to 96.6% CPU cycles stealthily under some circumstances on XenServer6.0.2 platform by analyzing the source code thoroughly. Detection methods using benchmarks as well as a series of countermeasures are proposed and experimental results have demonstrated the effectiveness of these defense techniques.		Hong Rong;Ming Xian;Huimei Wang;Jiangyong Shi	2013		10.1007/978-3-319-02726-5_8	real-time computing;virtualization;cloud computing;computer science;operating system;computer security;computer network	Security	-54.487147649682896	57.51006906094936	85369
0d254e8f5effc85f53a6b1d64946db2e9a8e8177	privacy-aware access control and authorization in passive network monitoring infrastructures	privacy aware access control;mediating system;communication networks protection;computer network security;real time contextual parameters privacy aware access control passive network monitoring infrastructure communication networks protection privacy preserving authorization access control ontological model access control policies mediating system;privacy preserving authorization;network monitoring;authorisation;real time;semantic information model privacy authorisation access control passive network monitoring;iron;privacy preservation;dynamic control;ontologies artificial intelligence;access control policies;passive network monitoring infrastructure;semantic information;access control policy;monitoring;data privacy;community networks;law enforcement;cognition;ontologies;authorization;access control;ontologies artificial intelligence authorisation computer network security data privacy;semantic information model;monitoring iron authorization cognition ontologies passive networks;ontological model;passive network monitoring;real time contextual parameters;passive networks;privacy	Despite the usefulness of passive network monitoring for the operation, maintenance, control and protection of communication networks, as well as law enforcement, network monitoring activities are surrounded by serious privacy implications. In this paper, an innovative approach for privacy-preserving authorization and access control to data originating from passive network monitoring is described. The proposed framework relies on an ontological model for the specification of the access control policies, which are evaluated and enforced on a two-phase and two-stage basis by a system that intercedes between the network link and the monitoring applications. The two stages refer to controlled access regarding both the data that are disclosed to the monitoring application from the mediating system and the raw data that the mediator retrieves from the network link. On the other hand, the two phases concern respectively the execution of “static” and “dynamic” control; the former enforces the rules that are a priori applicable, grounded on the data, role and purpose semantics, while the latter evaluates the real-time contextual parameters for the adaptation of the access control procedures to the particular conditions underlying a request.	access control;authorization;data anonymization;entity;online and offline;ontology (information science);privacy;real-time clock;real-time transcription;telecommunications network;two-phase locking	Fotios Gogoulos;Anna Antonakopoulou;Georgios V. Lioudakis;Aziz S. Mousas;Dimitra I. Kaklamani;Iakovos S. Venieris	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.203	network admission control;computer access control;information privacy;computer science;network security;data mining;database;authorization;internet privacy;computer security;computer network	DB	-49.441101852285904	53.230374579231885	85566
08232426d8a1d3a85285e26abf89521dca739e0e	testing and comparing web vulnerability scanning tools for sql injection and xss attacks	mccp;performance evaluation;power efficiency;redundancy multiprocessing systems performance evaluation;redundancy;multicore processing redundancy radio frequency energy consumption decoding single event upset performance loss yarn energy efficiency computer aided instruction;multicore processors;multicore processor;multiprocessing systems;power consumption;energy delay product;multiple clustered core processor power performance trade off dependable multicore processor deep submicron technology power consumption soft errors thread level redundancy soft error detection instruction level redundancy computing performance;computer science applications;soft error	Web applications are typically developed with hard time constraints and are often deployed with security vulnerabilities. Automatic web vulnerability scanners can help to locate these vulnerabilities and are popular tools among developers of web applications. Their purpose is to stress the application from the attacker's point of view by issuing a huge amount of interaction within it. Two of the most widely spread and dangerous vulnerabilities in web applications are SQL injection and cross site scripting (XSS), because of the damage they may cause to the victim business. Trusting the results of web vulnerability scanning tools is of utmost importance. Without a clear idea on the coverage and false positive rate of these tools, it is difficult to judge the relevance of the results they provide. Furthermore, it is difficult, if not impossible, to compare key figures of merit of web vulnerability scanners. In this paper we propose a method to evaluate and benchmark automatic web vulnerability scanners using software fault injection techniques. The most common types of software faults are injected in the web application code which is then checked by the scanners. The results are compared by analyzing coverage of vulnerability detection and false positives. Three leading commercial scanning tools are evaluated and the results show that in general the coverage is low and the percentage of false positives is very high.	benchmark (computing);cross-site scripting;fault injection;hard time;relevance;sql injection;trust (emotion);vulnerability (computing);vulnerability scanner;web application	José Fonseca;Marco Vieira;Henrique Madeira	2007	13th Pacific Rim International Symposium on Dependable Computing (PRDC 2007)	10.1109/PRDC.2007.55	multi-core processor;computer architecture;parallel computing;real-time computing;computer science;operating system	SE	-57.07729724308187	56.63441222945823	85624
718bb58e58163190b11d36a447e767b85c0b3708	overcoming an untrusted computing base: detecting and removing malicious hardware automatically	software;arms race;design process;complexity theory;hardware software codesign;hardware circuit testing computer security process design runtime costs logic algorithm design and analysis privacy arm;software systems;emulation;program verification;runtime;system on a chip;system security;registers;security of data exception handling hardware software codesign program verification;exception handling;design verification;security of data;hardware;exception handler software untrusted computing base malicious hardware removal computer systems security hardware complexity hardware based security threats hybrid hardware software approach bluechip design verification phase unused circuit identification exception generation hardware	The computer systems security arms race between attackers and defenders has largely taken place in the domain of software systems, but as hardware complexity and design processes have evolved, novel and potent hardware-based security threats are now possible. This paper presents a hybrid hardware/software approach to defending against malicious hardware. We propose BlueChip, a defensive strategy that has both a design-time component and a runtime component. During the design verification phase, BlueChip invokes a new technique, unused circuit identification (UCI), to identify suspicious circuitry—those circuits not used or otherwise activated by any of the design verification tests. BlueChip removes the suspicious circuitry and replaces it with exception generation hardware. The exception handler software is responsible for providing forward progress by emulating the effect of the exception generating instruction in software, effectively providing a detour around suspicious hardware. In our experiments, BlueChip is able to prevent all hardware attacks we evaluate while incurring a small runtime overhead.	coat of arms;electronic circuit;emulator;exception handling;experiment;overhead (computing);software system	Matthew Hicks;Murph Finnicum;Samuel T. King;Milo M. K. Martin;Jonathan M. Smith	2010	2010 IEEE Symposium on Security and Privacy	10.1109/SP.2010.18	exception handling;system on a chip;hardware compatibility list;embedded system;emulation;real-time computing;design process;computer science;operating system;processor register;programming language;computer security;software system	Security	-56.670205187596615	55.61804393837021	85650
1a81add7bc14da0993cbb16c51fa595714e60ced	scanning of real-world web applications for parameter tampering vulnerabilities	parameter dependency;state aware fuzzing;in context fuzzing;parameter tampering	Web applications require exchanging parameters between a client and a server to function properly. In real-world systems such as online banking transfer, traversing multiple pages with parameters contributed by both the user and server is a must, and hence the applications have to enforce workflow and parameter dependency controls across multiple requests. An application that applies insufficient server-side input validations is however vulnerable to parameter tampering attacks, which manipulate the exchanged parameters. Existing fuzzing-based scanning approaches however neglected these important controls, and this caused their fuzzing requests to be dropped before they can reach any vulnerable code. In this paper, we propose a novel approach to identify the workflow and parameter dependent constraints, which are then maintained and leveraged for automatic detection of server acceptances during fuzzing. We realized the approach by building a generic blackbox parameter tampering scanner. It successfully uncovered a number of severe vulnerabilities, including one from the largest multi-national banking website, which other scanners miss.	client (computing);online banking;server (computing);server-side;web application;world-system	Adonis P. H. Fung;Tielei Wang;K. W. Cheung;T. Y. Wong	2014		10.1145/2590296.2590324	computer science;internet privacy;world wide web;computer security	Security	-55.14244285513136	58.76249912674763	86184
21b2da379bffca3c051351e644c63bfb4d9859ce	exploiting a thermal side channel for power attacks in multi-tenant data centers		The power capacity of multi-tenant data centers is typically oversubscribed in order to increase the utilization of expensive power infrastructure. This practice can create dangerous situations and compromise data center availability if the designed power capacity is exceeded. This paper demonstrates that current safeguards are vulnerable to well-timed power attacks launched by malicious tenants (i.e., attackers). Further, we demonstrate that there is a physical side channel --- a thermal side channel due to hot air recirculation --- that contains information about the benign tenants' runtime power usage and can enable a malicious tenant to time power attacks effectively. In particular, we design a state-augmented Kalman filter to extract this information from the side channel and guide an attacker to use its maximum power at moments that coincide with the benign tenants' high power demand, thus overloading the shared power capacity. Our experimental results show that an attacker can capture 54% of all attack opportunities, significantly compromising the data center availability. Finally, we discuss a set of possible defense strategies to safeguard the data center infrastructure against power attacks.	data center;function overloading;kalman filter;malware;maximum power transfer theorem;multitenancy;overselling;reflow soldering;side-channel attack	Mohammad A. Islam;Shaolei Ren;Adam Wierman	2017		10.1145/3133956.3133994	computer security;kalman filter;side channel attack;computer science;maximum power principle;data center;compromise	Security	-54.51997702865491	57.63258971260007	86265
cd344286f8c37b3193f33a061f7688274038ce11	ddos mitigation cloud-based service	distributed denial of service cloud based service physical security devices resource constraints management complexity ddos mitigation tools traffic verification cloud based firewalling service financial cost availability reliability self scaling network function virtualization technology nfv cloud computing;ddos;firewalling;secaas;security as a service;virtualisation cloud computing firewalls reliability;distributed denial of service;cloud computing logic gates computer crime firewalls computing computer architecture authentication;ddos cloud based service security as a service secaas firewalling distributed denial of service;cloud based service	Cloud computing has evolved over the last decade from a simple storage service for more complex ones, offering software as a service (SaaS), platforms as a service (PaaS) and most recently security as a service (SECaaS). The work presented in this paper is a response to: (1) the resource constraints in physical security devices such as firewalls or IPS/IDS, that can no more counter advanced DDOS attacks, (2) The expensive cost, management complexity and the requirement of high amount of resources on existing DDOS mitigation tools to verify the traffic. We propose a new architecture of a cloud based firewalling service using resources offered by the Cloud and characterized by: a low financial cost, high availability, reliability, self scaling and easy managing. In order to improve the efficiency of our proposal to face DDOS attacks, we deploy, configure and test our mitigation service using Network Function Virtualization technology (NFV) and other virtualization capabilities. We also detail some result and point out future work.	amazon simple storage service;cloud computing;ddos mitigation;denial-of-service attack;firewall (computing);high availability;image scaling;load balancing (computing);network function virtualization;network packet;physical security;platform as a service;security as a service;security service (telecommunication);software as a service;virtual machine;x86 virtualization	Fouad Amine Guenane;Michele Nogueira Lima;Ahmed Serhrouchni	2015	2015 IEEE Trustcom/BigDataSE/ISPA	10.1109/Trustcom.2015.531	cloud computing security;engineering;cloud testing;internet privacy;data as a service;computer security;computer network	Security	-50.12937866794227	58.000930658515124	86304
894431d48991b88acde625c0ff866938a0372991	obfuscation: the hidden malware	databases;computers;software;database system;malware computer security databases system on a chip handwriting recognition;handwriting recognition;computer security malware obfuscation packer polymorphism metamorphism;system on a chip;chip;metamorphism;computer security;intrusion detection system obfuscation malware cyberwar malware writer computer virus antimalware software thwart malware analysis polymorphic technique metamorphic technique;computer viruses;malware;polymorphism;packer;obfuscation	A cyberwar exists between malware writers and antimalware researchers. At this war's heart rages a weapons race that originated in the 80s with the first computer virus. Obfuscation is one of the latest strategies to camouflage the telltale signs of malware, undermine antimalware software, and thwart malware analysis. Malware writers use packers, polymorphic techniques, and metamorphic techniques to evade intrusion detection systems. The need exists for new antimalware approaches that focus on what malware is doing rather than how it's doing it.	antivirus software;computer virus;cyberwarfare;intrusion detection system;malware analysis	Philip O'Kane;Sakir Sezer;Kieran McLaughlin	2011	IEEE Security & Privacy	10.1109/MSP.2011.98	chip;system on a chip;polymorphism;obfuscation;computer science;cryptovirology;handwriting recognition;malware;internet privacy;metamorphism;world wide web;computer security;computer virus	Security	-58.89271944697013	59.01221997194181	86402
8beb50058a354a02f054f768f3ab57901bf46946	trust-aware access control: how recent is your transaction history?	context aware;history;computer model;statistical method;data mining;trusted computing;sensitivity;computational modeling;access control models;access control;peer to peer computing;security of data access control data mining java;computational modeling access control sensitivity history peer to peer computing proposals;proposals;security of data;trust computation process trust aware access control transaction history history aware access control models trustworthiness context aware access control models smart security services data mining techniques recency frequency and sensitivity rfs xacml rbac java run time performance rbac core model;java	Establishing trust in a subject requesting access to a sensitive resource object is fundamental in history-aware access control models. A subject's past behaviour could be used as an indication about the subject's trustworthiness. In fact, a subject's trust plays a significant role in deciding the associated access rights in, for example, context-aware access control models. Recently, there have been efforts to accommodate the subject's trust level to provide smart security services including access control. Some proposals utilise data mining techniques, whereas some incorporate statistical methods to compute the subject's trust value. Most of the models fail to identify malicious attempts from genuine subjects. In this paper, we propose a new model that bridges the gap by incorporating the concepts of Recency, Frequency and Sensitivity (RFS) in trust computation. The model is formally defined and prototyped in Java using the XACML RBAC profile and its run-time performance is investigated. The results show the model adds a significant overhead on top of the RBAC core model. However, the trust computation process could be done off-line cutting down that overhead dramatically, thus providing an affordable solution.	access control list;computation;data mining;experiment;fuzzy logic;java;malware;online and offline;overhead (computing);prototype;remote file sharing;role-based access control;trust (emotion);warez;while;xacml	Ali Ahmed;Abdullah Alnajem	2012	2012 Second International Conference on Digital Information and Communication Technology and it's Applications (DICTAP)	10.1109/DICTAP.2012.6215352	computer simulation;sensitivity;computer science;access control;database;trustworthy computing;java;computational model;world wide web;computer security	Security	-50.688725061924515	54.40564404574433	86474
321cde21fe436a926649aa6c08fb96d19b9ac310	verifying security policies using host attributes		For the formal verification of a network security policy, it is crucial to express the verification goals. These formal goals, called security invariants, should be easy to express for the end user. Focusing on access control and information flow security strategies, this work discovers and proves universal insights about security invariants. This enables secure and convenient auto-completion of host attribute configurations. We demonstrate our results in a civil aviation scenario. All results are machine-verified with the Isabelle/HOL theorem prover.	access control;automated theorem proving;correctness (computer science);formal verification;hol (proof assistant);handy board;isabelle;network security policy;sanity check;usability	Cornelius Diekmann;Stephan-Alexander Posselt;Heiko Niedermayer;Holger Kinkelin;Oliver Hanka;Georg Carle	2014		10.1007/978-3-662-43613-4_9	computer security model;security through obscurity;computer science;information security standards;database;security service;distributed computing;security testing;computer security;algorithm	Security	-52.77559041422694	51.35434417228572	86661
90f2e587256b8b3cc7651f257a8066ff9f2f544e	replayconfusion: detecting cache-based covert channel attacks using record and replay		Cache-based covert channel attacks use highly-tuned shared-cache conflict misses to pass information from a trojan to a spy process. Detecting such attacks is very challenging. State of the art detection mechanisms do not consider the general characteristics of such attacks and, instead, focus on specific communication protocols. As a result, they fail to detect attacks using different protocols and, hence, have limited coverage. In this paper, we make the following observation about these attacks: not only are the malicious accesses highly tuned to the mapping of addresses to the caches; they also follow a distinctive cadence as bits are being received. Changing the mapping of addresses to the caches substantially disrupts the conflict miss patterns, but retains the cadence. This is in contrast to benign programs. Based on this observation, we propose a novel, high-coverage approach to detect cache-based covert channel attacks. It is called ReplayConfusion, and is based on Record and deterministic Replay (RnR). After a program's execution is recorded, it is deterministically replayed using a different mapping of addresses to the caches. We then analyze the difference between the cache miss rate timelines of the two runs. If the difference function is both sizable and exhibits a periodic pattern, it indicates that there is an attack. This paper also introduces a new taxonomy of cache-based covert channel attacks, and shows that ReplayConfusion uncovers examples from all the categories. Finally, ReplayConfusion only needs simple hardware.	cpu cache;cache (computing);covert channel;deterministic algorithm;malware;sensor;timeline;trojan horse (computing)	Mengjia Yan;Yasser Shalabi;Josep Torrellas	2016	2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)		parallel computing;real-time computing;computer science;operating system;internet privacy;computer security	Arch	-55.34990620432053	55.20288031739018	86709
f0616340e3048e57002053e9d96161cb195c666e	detecting soql-injection vulnerabilities in salesforce applications	customer relationship management;sql;computer crime;sql cloud computing computer crime customer relationship management data flow analysis java program compilers;data flow analysis;program compilers;customer relationship management soql injection vulnerability detection salesforce application web attacks hackers data stealing sql injection cross site scripting xss maliciously crafted code sql query web application innocuous looking user inputs trap design taint removal and analysis platform static data flow analysis tool soql injection problem detection xml intermediate language static analysis code stac compilers apex java could computing;cloud computing;reactive power cloning java context informatics security xml;java	The two most common web-attacks used by hackers to steal data are SQL-injection and cross-site scripting (XSS). These are examples of taint vulnerabilities where maliciously crafted code (for example, a SQL query) is injected into a Web application by embedding it inside innocuous looking user inputs. We present the design of TRAP (Taint Removal and Analysis Platform), a static data-flow analysis tool to detect SOQL-injection problems in SalesForce applications. TRAP is designed to be language independent as it uses an XML intermediate language called STAC (STatic Analysis Code), on which the analysis is done. Currently, we have implemented STAC compilers for Apex and Java.	compiler;cross-site request forgery;cross-site scripting;data-flow analysis;dataflow;java;lempel–ziv–stac;sql injection;select (sql);static program analysis;surface web;taint checking;web application;xml	Amitabh Saxena;Shubhashis Sengupta;Pradeepkumar Duraisamy;Vikrant S. Kaulgud;Amit Chakraborty	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637220	customer relationship management;sql;cloud computing;computer science;data-flow analysis;database;programming language;java;world wide web	SE	-57.303410594391295	58.34789828939641	86962
7d1f3f8392c3f0eee8785a1f99d2d11a2e908d5c	sciatool: a tool for analyzing selinux policies based on access control spaces, information flows and cpns	access control spaces;colored petri nets;information flows;selinux;analysis method;security policies configuration	Although security policies configuration is crucial for operating systems to constrain applications' operations and to protect the confidentiality and integrity of sensitive resources inside the systems, it is an intractable work for security administrators to accomplish correctly and consistently solely by hands. Thus policies analysis methods are becoming research hotspots. A great deal of such researches are focused on SELinux, which is a security-enhanced module of open-source and popular Linux. Among various analysis methods for SELinux policies, those based on access control spaces, information flows and colored Petri-nets CPNs can be thought as the three most valuable methods and they can be exploited together and complementarily. In this paper, a prototype of SELinux policies Configuration Integrated Analysis Tool, i.e. SCIATool, is designed and implemented by integrating these three methods together. Test results are provided and further researches as to construct a computer-aided configuration tool for SELinux policies are discussed.	access control;selinux;spaces	Gaoshou Zhai;Tao Guo;Jie Huang	2014		10.1007/978-3-319-27998-5_19	simulation;computer science;operations management;computer security	Security	-51.85149602921333	55.05101005892902	87182
339226ac117d6e9cd1bf8c8de4b0aa44dd2ccf77	dynamic modeling for representing access control policies effect		In large databases, creating user interfaces for browsing or performing insertion, deletion or modification of data is very costly in terms of programming. In addition, each modification of an access control policy causes many potential and unpredictable side effects which cause rule conflicts or security breaches that affect the corresponding user interfaces as well. While changes to access control policies in databases are inevitable, having a dynamic system that generates interfaces according to the latest access control policies becomes increasingly valuable. Lack of such a system leads to unauthorized access to data and eventually violates the privacy of data owners. In this work, we discuss a dynamic interface that applies Role Based Access Control (RBAC) policies as the output of policy analysis and limits the amount of information that users have access to according to the policies defined for roles. This interface also shows security administrators the effect of their changes from the user’s point of view while minimizing the cost by generating the interface automatically.	authorization;database;dynamical system;privacy;role-based access control;user interface	Kambiz Ghazinour;Mehdi Ghayoumi	2015	CoRR		computer access control;computer science;role-based access control;data mining;database;computer security	Security	-51.19559034081091	52.83623583064992	87252
2d8f63797ea5c668e5904f78c8d7bc0da2d58708	windows phone 8 security	smartphones;security	The Windows Phone security model is designed from the ground up to build upon a decade of Microsoft's experience with digital security. In its first release, it establishes a foundation which supports a core set of promises for consumers & developers, spanning privacy, safety, and profitability. This talk will go deep on the key challenges that the security model tackles, & how its provisions work together in practice to enable trustworthy mobile computing. Along the way, the talk will touch on a variety of upcoming investments in the platform security roadmap for Windows Phone.	file spanning;information security;microsoft windows;mobile computing;windows phone	Geir Olsen	2012		10.1145/2381934.2381936	computer security model;cloud computing security;security through obscurity;security information and event management;engineering;security and safety features new to windows vista;security service;internet privacy;world wide web;computer security;next-generation secure computing base	Security	-50.691986867274366	60.308803740442045	87299
a66f91eb8cf0563a926a91d10d41f735311dd94c	a similarity based technique for detecting malicious executable files for computer forensics	invasive software computer crime;computer forensics;assembly instruction sequence similarity based technique malicious executable file detection computer forensics hacking tool malware;similarity assembly instruction code malicious program computer forensics;computer crime;hacking tool;malicious executable file detection;malware;similarity based technique;forensics computer hacking computer crime assembly file systems protection information science information analysis hard disks computer aided instruction;assembly instruction sequence;similarity;assembly instruction code;malicious program;tools and techniques;invasive software;false positive	With the rapidly increasing complexity of computer systems and the sophistication of hacking tools and techniques, there is a crucial need for computer forensic analysis techniques. Very few techniques exist to support forensic analysis of unknown executable files. The existing techniques primarily inspect executable files to detect known signatures or are based on metadata information. A key goal of such forensic investigation is to identify malicious executable files that hackers might have installed in a targeted system. Finding such malware in a compromised system is difficult because it is hard to identify the purpose of the fragments of executable files. In this paper, we present a similarity-based technique that analyzes targeted executable files to identify a malware present in a compromised system. The technique involves assigning a similarity value to the fragments of executable files present in a compromised hard disk against a set of source files. We present some results based on the comparison of assembly instruction sequences of well-known hacking tools with those of various executable files, and suggest various ways to reduce the false positives	antivirus software;computer forensics;executable;experiment;fragmentation (computing);hard disk drive;malware;reverse engineering;slack variable	Jun-Hyung Park;Minsoo Kim;BongNam Noh;James B. D. Joshi	2006	2006 IEEE International Conference on Information Reuse & Integration	10.1109/IRI.2006.252411	similarity;type i and type ii errors;computer science;theoretical computer science;operating system;database;malware;executable;world wide web;computer security;computer forensics	Security	-57.6868730004856	56.906734245825334	87395
5aa7a06754968b3095503b40946e29cc6a735231	a review of graph approaches to network security analytics		There is a line of research extending over the last 20+ years applying graph-based methods for assessing and improving the security of operational computer networks, maintaining situational awareness, and assuring organizational missions. This chapter reviews a number of key developments in these areas, and places them within the context of a number of complementary dimensions. These dimensions are oriented to the requirements of operational security, to help guide practitioners towards matching their use cases with existing technical approaches. One dimension we consider is the phase of security operations (prevention, detection, and reaction) to which an approach applies. Another dimension is the operational layer (network infrastructure, security posture, cyberspace threats, mission dependencies) that an approach spans. We also examine the mathematical underpinnings of the various approaches as they apply to security requirements. Finally, we describe architectural aspects of various approaches, especially as they contribute to scalability and performance.		Steven Noel	2018		10.1007/978-3-030-04834-1_16	data science;mission assurance;cyberspace;scalability;network security;operations security;use case;situation awareness;analytics;computer science	Theory	-57.280200308566954	49.56804694335872	87475
da8a949f9c9f1df3a38f12c2cac97b789c705465	a survey of machine and deep learning methods for internet of things (iot) security		The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention. It is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020. On the one hand, IoT play a crucial role in enhancing several real-life smart applications that can improve life quality. On the other hand, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems introduced new security challenges. Implementing security measures, such as encryption, authentication, access control, network security and application security, for IoT devices and their inherent vulnerabilities is ineffective. Therefore, existing security methods should be enhanced to secure the IoT system effectively. Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory curiosity to practical machinery in several important applications. Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems. The goal of this work is to provide a comprehensive survey of ML /DL methods that can be used to develop enhanced security methods for IoT systems. IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed. We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method. We discuss the opportunities and challenges involved in applying ML/DL to IoT security. These opportunities and challenges can serve as potential future research directions.	access control;application security;artificial intelligence;authentication;deep learning;encryption;fastest;internet of things;machine learning;network security;real life;secure communication;smart device;software deployment	Mohammed Ali Al-Garadi;Amr Mohamed;Abdulla K. Al-Ali;Xiaojiang Du;Mohsen Guizani	2018	CoRR		access control;computer security;software deployment;network security;multidisciplinary approach;encryption;application security;computer science;secure communication;authentication	Security	-50.490704113547764	60.086943189312485	87503
440cb4e37690ef9e2fc1a30fd19317721ca068f7	game theoretic approach for cost-benefit analysis of malware proliferation prevention		Many existing research efforts in the field of malware proliferation aim at modelling and analysing its spread dynamics. Many malware dissemination models are based on the characteristics of biological disease spread in human populations. In this work, we utilise game theory in order to extend two very commonly used malware spread models (SIS and SIR) by incorporating defence strategies against malware proliferation. We consider three different security mechanisms, “patch”, “removal” and “patch and removal” on which our model is based. We also propose a cost-benefit model that describes optimal strategies the defender could follow when cost is taken into account. Lastly, as a way of illustration, we apply our models on the well studied Code-Red worm.	game theory;malware	Theodoros Spyridopoulos;George C. Oikonomou;Theodore Tryfonas;Mengmeng Ge	2013		10.1007/978-3-642-39218-4_3	simulation;theoretical computer science;computer security	ML	-61.77871432368015	60.17287901103945	87775
81fb65e1a704befc97427036f5eb030287468efc	recovering and analyzing program behaviors from testing traces			tracing (software)	Macario Polo;Francisco P. Romero;José Angel Olivas	2010				SE	-59.30787319310752	55.39386008511413	88112
d0a8b942339283124a36323271b255959293a8ac	cloud security engineering: theory, practice and future research		The eleven papers in this special issue address security and privacy concerns associated with cloud computing. This special issue is dedicated to the identification of techniques that enable security mechanisms to be engineered and implemented in cloud services and cloud systems. A key focus is on the integration of theoretical foundations with practical deployment of security strategies that make cloud systems more secure for both end users and providers – enabling end users to increase the level of trust they have in cloud service providers – and conversely for cloud service providers to provide greater guarantees to end users about the security of their services and data.		Kim-Kwang Raymond Choo;Omer F. Rana;Muttukrishnan Rajarajan	2017	IEEE Trans. Cloud Computing	10.1109/TCC.2016.2582278	software deployment;end user;computer security;security engineering;distributed computing;cloud computing;management science;computer science;cloud computing security	DB	-49.12126994634396	56.30289176919461	88563
1e672717102d5475ccdb8f3d0f56a469e55877d3	ensuring operating system kernel integrity with osck	verification;sistema operativo;system core;haute performance;data race;acces concurrent;rootkit detection;securite informatique;nucleo sistema;integrite;integridad;noyau systeme;safety properties;approche deterministe;system security;sistema de deteccion de intrusiones;deterministic approach;computer security;noyau systeme exploitation;acceso simultaneo;integrity;operating system;data races;seguridad informatica;estructura datos;enfoque determinista;nucleo de sistema operativo;intrusion detection systems;alto rendimiento;integrity checking;systeme exploitation;structure donnee;source code;operating system kernels;security;high performance;data structure;systeme detection intrusion	Kernel rootkits that modify operating system state to avoid detection are a dangerous threat to system security. This paper presents OSck, a system that discovers kernel rootkits by detecting malicious modifications to operating system data. OSck integrates and extends existing techniques for detecting rootkits, and verifies safety properties for large portions of the kernel heap with minimal overhead. We deduce type information for verification by analyzing unmodified kernel source code and in-memory kernel data structures.  High-performance integrity checks that execute concurrently with a running operating system create data races, and we demonstrate a deterministic solution for ensuring kernel memory is in a consistent state. We introduce two new classes of kernel rootkits that are undetectable by current systems, motivating the need for the OSck API that allows kernel developers to conveniently specify arbitrary integrity properties.	data structure;in-memory database;invariant (computer science);kernel (operating system);operating system;overhead (computing);rootkit;sensor;software deployment;virtual machine	Owen S. Hofmann;Alan M. Dunn;Sangman Kim;Indrajit Roy;Emmett Witchel	2011		10.1145/1950365.1950398	sysfs;intrusion detection system;embedded system;verification;data structure;computer science;operating system;race condition;kernel preemption;deterministic system;computer security;source code	Arch	-56.12611689983035	54.528286135632776	89186
3c4e907c07944cd55e800b4e55918adf8cb2a683	scalable architectural support for trusted software	fine grained memory compartment;software;microprocessors;trusted platform module;opensparc platform;trusted software;enhanced microprocessor hardware;hardware protection application software virtual machine monitors computer architecture virtual machining information security operating systems scalability microprocessors;secure persistent storage scalable architectural support trusted software bastion hardware software architecture security critical software modules enhanced microprocessor hardware enhanced hypervisor software fine grained memory compartment opensparc platform;secure storage;proof of concept;chip;virtual machine monitors;computer architecture;software architecture;safety critical software;software architecture microprocessor chips safety critical software secure storage;secure persistent storage;hardware software architecture;enhanced hypervisor software;bastion;security;scalable architectural support;microprocessor chips;hardware;security critical software modules	We present Bastion, a new hardware-software architecture for protecting security-critical software modules in an untrusted software stack. Our architecture is composed of enhanced microprocessor hardware and enhanced hypervisor software. Each trusted software module is provided with a secure, fine-grained memory compartment and its own secure persistent storage area. Bastion is the first architecture to provide direct hardware protection of the hypervisor from both software and physical attacks, before employing the hypervisor to provide the same protection to security-critical OS and application modules. Our implementation demonstrates the feasibility of bypassing an untrusted commodity OS to provide application security and shows better security with higher performance when compared to the Trusted Platform Module (TPM), the current industry state-of-the-art security chip. We provide a proof-of-concept implementation on the OpenSPARC platform.	application security;bastion;hypervisor;microprocessor;multi-compartment model;opensparc;operating system;persistence (computer science);software architecture;trusted platform module	David Champagne;Ruby B. Lee	2010	HPCA - 16 2010 The Sixteenth International Symposium on High-Performance Computer Architecture	10.1109/HPCA.2010.5416657	software security assurance;chip;embedded system;software architecture;computer architecture;parallel computing;storage hypervisor;computer science;information security;operating system;trusted platform module;proof of concept	Arch	-53.616379956446785	56.114609829853194	89202
14f1e54355f368b94105ec759bd55c4197f920eb	towards a comprehensive complexity assessment of rbac models			role-based access control	Johannes Prescher;Siegfried Schefer-Wenzl;Anne Baumgraß;Mark Strembeck;Jan Mendling	2014	EMISA Forum		systems engineering;role-based access control;computer science	NLP	-54.32084759737232	48.11947471350552	89216
abe84a403a1f6668e9a3a4c941b29f0954eb81c3	mutated policies: towards proactive attribute-based defenses for access control		Recently, both academia and industry have recognized the need for leveraging real-time information for the purposes of specifying, enforcing and maintaining rich and flexible authorization policies. In such a context, security-related properties, a.k.a., attributes, have been recognized as a convenient abstraction for providing a well-defined representation of such information, allowing for them to be created and exchanged by different independently-run organizational domains for authorization purposes. However, attackers may attempt to compromise the way attributes are generated and communicated by recurring to hacking techniques, e.g., forgery, in an effort to bypass authorization policies and their corresponding enforcement mechanisms and gain unintended access to sensitive resources as a result.  In this paper, we propose a novel technique that allows for enterprises to pro-actively collect attributes from the different entities involved in the access request process, e.g., users, subjects, protected resources, and running environments. After the collection, we aim to carefully select the attributes that uniquely identify the aforementioned entities, and randomly mutate the original access policies over time by adding additional policy rules constructed from the newly-identified attributes. This way, even when attackers are able to compromise the original attributes, our mutated policies may offer an additional layer of protection to deter ongoing and future attacks. We present the rationale and experimental results supporting our proposal, which provide evidence of its suitability for being deployed in practice.	access control;authorization;design rationale;entity;mtd-f;randomness;real life;real-time data;software deployment	Carlos E. Rubio-Medrano;Josephine Lamp;Adam Doupé;Ziming Zhao;Gail-Joon Ahn	2017		10.1145/3140549.3140553	access control;hacker;data mining;authorization;enforcement;computer security;abstraction;engineering;compromise	Security	-51.152832299419806	57.57932615104911	89349
8d80783dc6b3f87bbf78412a5d94c014798e1de8	attack-test and verification systems, steps towards verifiable anomaly detection		Botnet, network malware and anomaly detection algorithms are hard to evaluate and compare against each other due to different data sets. In some cases overspecialization on known malware gives high detection rates due to unknown artifacts in the training data set. This may lead to new malware being unnoticed on a network, because the detection algorithm has not been optimized for this case. Our proposal is a new and work-in-progress approach to generate parametricized and randomized testing data sets on the fly. We plan to couple this with the an automatic verification system to assess the quality of detection algorithms without internal knowledge of their working. We hope to encourage discussion to enhance the draft of our idea and especially to go into more detail on our work in progress.	anomaly detection;botnet;formal verification;malware;on the fly;randomized algorithm;test set	Marcel Fourné;Dominique Petersen;Norbert Pohlmann	2013			verifiable secret sharing;anomaly detection;real-time computing;computer science	Security	-59.30599032732388	56.995636973044746	89431
2132af3c21969d5234dcf64da42b8571ae199cd8	penetration testing tool for web services security	ws security;web services cloud computing cryptography program testing service oriented architecture software performance evaluation sql;sql;software performance evaluation;penetration testing tool;ws addressing spoofing;program testing;cryptography;web services;simple object access protocol xml security testing servers standards;soapaction spoofing;service oriented architecture;soap based web services;soapaction spoofing attacks automated penetration testing tool xml based soap web services security service oriented architectures cloud interfaces federated identity management egovernment millitary services web services attacks denial of service attacks encrypted messages sql injection cross site scripting ws attacker ws addressing spoofing attacks;penetration testing tool soap based web services ws security ws addressing spoofing soapaction spoofing;cloud computing	XML-based SOAP Web Services are a widely used technology, which allows the users to execute remote operations and transport arbitrary data. It is currently adapted in Service Oriented Architectures, cloud interfaces, management of federated identities, eGovernment, or millitary services. The wide adoption of this technology has resulted in an emergence of numerous - mostly complex - extension specifications. Naturally, this has been followed by a rise in large number of Web Services attacks. They range from specific Denial of Service attacks to attacks breaking interfaces of cloud providers [1], [2] or confidentiality of encrypted messages [3]. By implementing common web applications, the developers evaluate the security of their systems by applying different penetration testing tools. However, in comparison to the wellknown attacks as SQL injection or Cross Site Scripting, there exist no penetration testing tools for Web Services specific attacks. This was the motivation for developing the first automated penetration testing tool for Web Services called WS-Attacker. In this paper we give an overview of our design decisions and provide evaluation of four Web Services frameworks and their resistance against WS-Addressing spoofing and SOAPAction spoofing attacks.	broadcast signal intrusion;confidentiality;denial-of-service attack;emergence;encryption;existential quantification;federated identity;information security;jensen's inequality;penetration test;plug-in (computing);soap;sql injection;security assertion markup language;service-oriented architecture;single sign-on;spoofing attack;surface web;test automation;ws-addressing;ws-security;web application;web service;wrapping (graphics);xml signature	Christian Mainka;Juraj Somorovsky;Jörg Schwenk	2012	2012 IEEE Eighth World Congress on Services	10.1109/SERVICES.2012.7	web service;web application security;web development;web modeling;engineering;ws-policy;services computing;internet privacy;ws-i basic profile;world wide web;computer security	SE	-50.6269262703249	59.17337710806493	89536
59276a9805dd20426c841d2f13c8b83f9a65b51d	apk-dfs: an automatic interaction system based on depth-first-search for apk		Android is paid more and more attention by many mobile phone manufacturers and software vendors. Due to defects of the Android and the huge potential economic benefits, there are more and more malicious codes. The majority of malicious applications will exhibit malicious behavior only if they interact with users. However, there is not a mature solution to traverse APKs automatically currently. By studying and analyzing the framework of Android system, we design and implement a system called APK-DFS which can traverse APKs automatically. This system can extract and recognize views in UI pages, and interact with these views via depth-first-search algorithm layer by layer; it establishes a UI storage stack and a UI trash can; it can also generate strings with specified format for views which require text input. We evaluate the system by testing it with APKs downloaded from Android markets. The results show that APK-DFS can simulate real users to trigger views in APKs effectively. For APK-DFS, in 30 min the average of effective trigger rate is 91%, and the average number of views that can be triggered in 50 events is 32.58. Compared with Monkey and PUMA, APK-DFS is the best one.		Jing Tao;Qiqi Zhao;Pengfei Cao;Zheng Wang;Yan Zhang	2017		10.1007/978-3-319-65482-9_29	computer science;distributed file system;traverse;operating system;distributed computing;breadth-first search;mobile phone;android (operating system);software	NLP	-60.31748422773138	56.851292664273835	89548
f99b2beebde60b7e62b25f7b64666bbd847053a3	modeling and assessment of systems security		Information technology (IT) is a crucial resource and enabler in almost every part of our society. However, there are severe risks associated with IT that may substantially decrease the potential benefits. To handle these risks, it is essential to be able to judge the security posture of systems. This requires the ability to perform security assessments. However, since security is an abstract, subjective, and non-tangible property, proper security assessment of non-trivial systems is hard. Currently, there is a lack of methods for efficient, reliable, and valid security assessments. In this paper, problems relating to the structural assessment of system security are addressed. In structural security assessments, the security of systems is quantified based on the security qualities of and interrelations between sub-systems.	computer security;poor posture	Jonas Hallberg;Johan E. Bengtsson;Niklas Hallberg	2008			security analysis;information technology;computer security;business;security information and event management	Security	-56.11741425530258	48.96635280312465	90198
3822ffd82487457ea60d5d6ebd87d3104132a84a	an event-driven architecture for fine grained intrusion detection and attack aftermath mitigation	national security;software metrics;decision support;real time system metrics;windows management instrumentation interface;instruments;emergency service;subject verb object multipoint monitoring;intrusion detection;window manager;computer architecture;protection;software architecture;formal verification;false positive rate;impact analysis;unauthorized accesses;windows management instrumentation interface event driven architecture intrusion detection attack aftermath mitigation unauthorized accesses decision support subject verb object multipoint monitoring verification modules impact analysis real time system metrics;systems analysis;verification modules;computer displays;performance analysis;intrusion detection computer architecture computer displays emergency services data security national security protection performance analysis real time systems instruments;attack aftermath mitigation;security of data;event driven architecture;subject verb object;effective action;systems analysis formal verification real time systems security of data software architecture software metrics;emergency services;real time systems;data security	In today's computing environment, unauthorized accesses and misuse of critical data can be catastrophic to personal users, businesses, emergency services, and even national defense and security. To protect computers from the ever-increasing threat of intrusion, we propose an event-driven architecture that provides fine grained intrusion detection and decision support capability. Within this architecture, an incoming event is scrutinized by the subject-verb-object multipoint monitors. Deviations from normal behavior detected by SVO monitors will trigger different alarms, which are sent to subsequent fusion and verification modules to reduce the false positive rate. The system then performs impact analysis by studying real-time system metrics, collected through the Windows management instrumentation interface. We add to the system the capability to assist the administrator in taking effective actions to mitigate the aftermath of an intrusion	authorization;computer;devs;decision support system;event-driven architecture;half-life 2: episode one;intrusion detection system;microsoft windows;multipoint ground;real-time computing;real-time operating system;real-time transcription;simulation;sparse voxel octree	Jianfeng Peng;Chuan Feng;Haiyan Qiao;Jerzy W. Rozenblit	2007	14th Annual IEEE International Conference and Workshops on the Engineering of Computer-Based Systems (ECBS'07)	10.1109/ECBS.2007.18	intrusion detection system;embedded system;software architecture;systems analysis;effective action;host-based intrusion detection system;real-time computing;decision support system;formal verification;false positive rate;computer science;national security;operating system;software engineering;data security;computer security;intrusion prevention system;software metric	SE	-58.42377611684989	54.59093459658968	90439
cb85f14d3c9685cad65c95087f8e8f505eab24a7	acoustic denial of service attacks on hdds		Among storage components, hard disk drives (HDDs) have become the most commonly-used type of nonvolatile storage due to their recent technological advances, including, enhanced energy efficacy and significantly-improved areal density. Such advances in HDDs have made them an inevitable part of numerous computing systems, including, personal computers, closed-circuit television (CCTV) systems, medical bedside monitors, and automated teller machines (ATMs). Despite the widespread use of HDDs and their critical role in real-world systems, there exist only a few research studies on the security of HDDs. In particular, prior research studies have discussed how HDDs can potentially leak critical private information through acoustic or electromagnetic emanations. Borrowing theoretical principles from acoustics and mechanics, we propose a novel denial-of-service (DoS) attack against HDDs that exploits a physical phenomenon, known as acoustic resonance. We perform a comprehensive examination of physical characteristics of several HDDs and create acoustic signals that cause significant vibrations in HDDs internal components. We demonstrate that such vibrations can negatively influence the performance of HDDs embedded in real-world systems. We show the feasibility of the proposed attack in two real-world case studies, namely, personal computers and CCTVs.	acoustic coupler;acoustic cryptanalysis;closed-circuit television;denial-of-service attack;embedded system;existential quantification;halting problem;hard disk drive;mission critical;non-volatile memory;personal computer;personally identifiable information;resonance;volatile memory;vulnerability (computing);world-system	Mohammad Shahrad;Arsalan Mosenia;Liwei Song;Mung Chiang;David Wentzlaff;Prateek Mittal	2017	CoRR		computer security;computer engineering;computer science;exploit;denial-of-service attack;phenomenon	Security	-50.99451105669288	59.99921637693722	90790
ab048433feb14f7bd8946a6f8fa377af45744cda	sam: security adaptation manager	adaptive security;misuse based intrusion detection;bismuth;performance;intrusion detection;attack detection;protection;adaptive management;stackguard compiler;attack detection sam security adaptation manager adaptive security performance protection stackguard compiler misuse based intrusion detection;security adaptation manager;security of data;sam	In the trade-o s between security and performance, it seems that security is always the loser. If we allow for adaptive security, we can at least ensure that security and performance are treated somewhat equally. Using adaptive security, we can allow a system to exist in a less secure, more performant state until it comes under attack. We the adapt the system to a more secure, less performant implementation. In this paper, we introduce the Security Adaptation Manager, or SAM. We describe SAM and how we have implemented SAM to take advantage of the di erent protection strengths o ered by the StackGuard compiler. Using SAM to provide StackGuard-based adaptive security provides a form of misuse-based intrusion detection, capable of detecting known and novel attacks.	buffer overflow protection;compiler;intrusion detection system;naruto shippuden: clash of ninja revolution 3;poor posture;sam;secure state;sensor	Heather M. Hinton;Crispin Cowan;Lois M. L. Delcambre;Shawn Bowers	1999		10.1109/CSAC.1999.816047	software security assurance;computer security model;intrusion detection system;countermeasure;security through obscurity;security information and event management;covert channel;performance;asset;security bug;computer science;bismuth;internet privacy;security testing;world wide web;computer security	Security	-55.43141588510257	55.47328932731222	90842
84e09073691dfd2817b8d2415a99c2e36724d2c2	using information-flow methods to analyze the security of cyber-physical systems	computers;formal security models;automobiles;nondeducibility;observers;cyber physical systems;modal logic;computational modeling;cyber physical systems information exchange computational modeling computer security;security cybersecurity information flow security system confidentiality system integrity cyber physical systems cpss formal security models nondeducibility modal logic;cpss;system integrity;cybersecurity;cats;security;information flow security;system confidentiality	Securing information flow is essential to methods that must ensure confidentiality, but information-flow disruption is equally important because it points to an integrity vulnerability. A proposed security model addresses both aspects, accounting for cyber-physical systems' unique confidentiality and integrity vulnerabilities.	confidentiality;cyber-physical system;denial-of-service attack;vulnerability (computing)	Gerry Howser;Bruce M. McMillin	2017	Computer	10.1109/MC.2017.112	modal logic;countermeasure;asset;computer science;information security;security service;internet privacy;cyber-physical system;computational model;computer security	Security	-55.232571614306096	51.25814139735304	91269
15130439800bd2e8bfc0a3080cefc9eb870fc4ca	a taxonomy of time and state attacks	programming language semantics;exceptions security taxonomy vulnerability classification attacks patterns concurrency stability lock signals;exceptions;software packages pattern classification programming language semantics security of data software engineering;signals;vulnerability;swimlane diagrams time attacks state attacks software classifications software packages concurrent programming semantics abstraction layers tree hierarchy code level flaws;classification;software engineering;stability;concurrency;attacks;taxonomy;lock;pattern classification;patterns;security;security of data;taxonomy kernel security databases abstracts vegetation servers;software packages	"""Software classifications have been created with the purpose of keeping track of attack patterns as well as providing a history of incidents for software packages. This article focuses on one single class of such attacks, conventionally known as """"Time and State"""" attacks. We offer a method of analyzing the anatomy of such attacks by reasoning about vulnerabilities using """"swimlane"""" diagrams annotated with some semantics of concurrent programming, such as the notions of traces and stability. We summarize our conclusions with a taxonomy based on abstraction layers, implying thereby some form of tree hierarchy where vulnerabilities inherit properties from the upper layers and share code-level flaws on the lower layers. This approach allows us to classify attacks by what they share in common, which is different from other classification attempts."""	abstraction layer;attack patterns;computer scientist;concurrent computing;diagram;evolutionary taxonomy;linearizability;lock (computer science);swim lane;taxonomy (general);time of check to time of use;tracing (software);tree structure;vulnerability (computing)	Horia V. Corcalciuc	2012	2012 Seventh International Conference on Availability, Reliability and Security	10.1109/ARES.2012.30	computer science;theoretical computer science;data mining;database	SE	-58.302341742119246	54.00480742899629	91275
6b9e8c500d72e842ededaff219e266ecf80fcfe8	vm-based security overkill: a lament for applied systems security research	vm;virtual machine;security properties;virtualization;isolation;system security	Virtualization has seen a rebirth for a wide variety of uses; in our field, systems security researchers routinely use it as a standard tool for providing isolation and introspection. Researchers' use of virtual machines has reached a level of orthodoxy that makes it difficult for the collective wisdom to consider alternative approaches to protecting computation. We suggest that many scenarios exist where virtual machines do not provide a suitable tool or appropriate security properties. We analyze the use of virtual machines in the systems security space and we highlight other work that questions the current (ab)uses of virtualization.  The takeaway message of this paper is that 'self-protection' mechanisms still represent an interesting and viable path of research. At some point, hypervisors (or whatever the lowest layer of software, firmware, or programmable hardware is) must rely on detection and protection mechanisms embedded within themselves.	computation;embedded system;firmware;hypervisor;introspection;protection mechanism;the binding of isaac: rebirth;virtual machine	Sergey Bratus;Michael E. Locasto;Ashwin Ramaswamy;Sean W. Smith	2010		10.1145/1900546.1900554	computer security model;cloud computing security;full virtualization;real-time computing;simulation;security through obscurity;computer science;virtual machine;security testing;computer security	Arch	-52.76314408758557	57.21155284318848	91373
73dcd4a5313b0e8371708f0802e910e91ff5c0f1	on the increasing importance of constraints	virtual university;access control	In this paper, we examine how the addition of rolebased access control (RBAC) model features affect the complexity of the RBAC constraint models. Constraints are used in RBAC models to constrain the assignment of permissions and principals to roles (among other things). Historically, it was assumed that the role assignments would change rather infrequently, so only a few constraints were necessary. Given new RBAC features, such as context-sensitive roles, the complexity of the restrictions that can be required is increasing because the role definitions may depend on application state. As application state changes, so do the role assignments. We examine the RBAC constraint problem using an example of a virtual university. We propose RBAC model features for simplifying the representation of constraints given our experience with this example.	access control list;context-sensitive grammar;role-based access control;state (computer science)	Trent Jaeger	1999		10.1145/319171.319175	engineering management;human–computer interaction;knowledge management	NLP	-50.19276627347386	50.4859551141891	91659
b81fe28ef5f5f1fb93eac89096abda26d14170db	making the best use of cybersecurity economic models	cybersecurity economic model;decision making cybersecurity economic model disparate model;investments;security function;disparate model;economic model;vulnerability;security and privacy cybersecurity economic models vulnerability security function;economic models;computer security;computer security information security mathematical model investments monitoring virtual manufacturing packaging protection cryptography loss measurement;security and privacy;organizations;cybersecurity;security of data;security of data decision making;data models	This article describes an analysis of several representative cybersecurity economic models, where the authors seek to determine whether each model's underlying assumptions are realistic and useful. They find that many of the assumptions are the same across disparate models, and most assumptions are far from realistic. They recommend several changes so that the predictions from economic models can be more relevant and useful.	computer security;cyber security standards	Rachel Rue;Shari Lawrence Pfleeger	2009	IEEE Security & Privacy	10.1109/MSP.2009.98	computer science;economic model;data mining;computer security	Security	-48.810706064256735	58.21673483217223	91937
58ea12d2475757e4c6f6ac7290b61f5871ac90ea	towards a distributed, self-organising approach to malware detection in cloud computing		Cloud computing is an increasingly popular platform for both industry and consumers. The cloud presents a number of unique security issues, such as a high level of distribution and system homogeneity, which require special consideration. In this paper we introduce a resilience architecture consisting of a collection of self-organising resilience managers distributed within the infrastructure of a cloud. More specifically we illustrate the applicability of our proposed architecture under the scenario of malware detection. We describe our multi-layered solution at the hypervisor level of the cloud nodes and consider how malware detection can be distributed to each node.	centralisation;cloud computing;high-level programming language;hypervisor;malware;self-organization;synergy	Michael R. Watson;Noor-ul-Hassan Shirazi;Angelos K. Marnerides;Andreas Mauthe;David Hutchison	2013		10.1007/978-3-642-54140-7_19	cloud computing security;embedded system;cloud computing;computer science;operating system;distributed computing;world wide web;computer security;computer network	HPC	-48.34728575086087	56.549698130383526	91983
231161a780e9ee310ec5a232684ef984d0a7b273	mcdb: using multi-clouds to ensure security in cloud computing	databases;data integrity;service provider;security of data cloud computing data integrity data models data privacy;cloud computing security computational modeling data models databases polynomials servers;secure computation;single cloud;polynomials;data model;servers;computational modeling;database as a service cloud computing single cloud multi clouds cloud storage data integrity;data privacy;multi clouds;mcdb model cloud computing security multiclouds database model data availability data integrity malicious insiders malicious outsiders cloud services data security data privacy multiclouds service providers;security;cloud storage;security of data;database as a service;cloud computing;data models;data security	Security is considered to be one of the most critical aspects in a cloud computing environment due to the sensitive and important information stored in the cloud for users. Users are wondering about attacks on the integrity and the availability of their data in the cloud from malicious insiders and outsiders, and from any collateral damage of cloud services. These issues are extremely significant but there is still much room for security research in cloud computing. This paper focuses more on the issues related to the data security and privacy aspects in cloud computing, such as data integrity, data intrusion, service availability. It proposes a Multi-clouds Database Model (MCDB) which is based on Multi-clouds service providers instead of using single cloud service provider such as in Amazon cloud service. In addition, it will discuss and present the architecture of the proposed MCDB model and describe its components and layers. The results and implementation for the new proposed model will be analyzed, in relation to addressing the security factors in cloud computing, such as data integrity, data intrusion, and service availability.	amazon elastic compute cloud (ec2);cloud computing;data integrity;data security;database model;malware	Mohammed Abdullatif Alzain;Ben Soh;Eric Pardede	2011	2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2011.133	service provider;cloud computing security;data modeling;cloud computing;information privacy;data model;computer science;information security;cloud testing;data integrity;database;security service;utility computing;data security;internet privacy;computational model;computer security;server;polynomial	DB	-48.85752864114672	58.23679307784792	91991
008e1b85875702cc6f67768680efdc701b608e55	security assurance aggregation for it infrastructures	security assurance aggregation;information security;security of data information technology;information technology;security assurance aggregation security assurance security assurance assessment;indexing terms;system security;information security communication system security power system security information systems aggregates availability testing operating systems workstations cryptography;it security;general methods;emergent properties;complex system;security assurance;complex systems;security assurance assessment;it infrastructures;complex systems security assurance aggregation it infrastructures information security;information system;security of data;assessment	In the development of more extensive information systems, IT security becomes increasingly important. The need for a tool to measure current security assurance level is therefore vital in order to maintain and improve the overall security of deployed systems. In this paper, we discuss several security assurance aspects and the role of aggregation in this context. Then, we introduce a general method to combine security assurance information into system wide values. This method takes into account the fact that the relations in complex systems are non-linear and also the appearance of emergent properties. Furthermore, using patterns to simplify the process of the system security assurance assessment is presented as an enhancement.	complex systems;emergence;entity;information system;interaction;nonlinear system;operations security;real-time clock	Nguyen Pham;Michel Riguidel	2007	2007 Second International Conference on Systems and Networks Communications (ICSNC 2007)	10.1109/ICSNC.2007.75	software security assurance;computer security model;cloud computing security;complex systems;security through obscurity;index term;security information and event management;security engineering;security convergence;asset;computer science;information security standards;security service;internet privacy;security testing;computer security;information system;educational assessment;emergence	DB	-55.35715665761452	49.32447450992934	92352
996079c235a354232127a80a99e0a8e35c7394b3	runtime countermeasures for code injection attacks against c and c++ programs	memory safety;code injection;code injection attack;countermeasures;c;gain control;evaluation framework	The lack of memory safety in C/C++ often leads to vulnerabilities. Code injection attacks exploit these vulnerabilities to gain control over the execution flow of applications. These attacks have played a key role in many major security incidents. Consequently, a huge body of research on countermeasures exists. We provide a comprehensive and structured survey of vulnerabilities and countermeasures that operate at runtime. These countermeasures make different trade-offs in terms of performance, effectivity, compatibility, etc., making it hard to evaluate and compare countermeasures in a given context. We define a classification and evaluation framework on the basis of which countermeasures can be assessed.	code injection;compatibility of c and c++;countermeasure (computer);memory safety;run time (program lifecycle phase);vulnerability (computing)	Yves Younan;Wouter Joosen;Frank Piessens	2012	ACM Comput. Surv.	10.1145/2187671.2187679	code injection;memory safety;automatic gain control;real-time computing;computer science;countermeasure;distributed computing;computer security	Security	-56.01443477169367	54.23737654792849	92387
0cae60d67b9129824d3b2e6a656cb5c8d9a3d489	secure remote reconfiguration of fpgas	004;cosic;fpga cryptography security remote configuration	This paper presents a solution for secure remote reconfiguration of FPGAs. Communicating the bitstream has to be done in a secure manner to prevent an attacker from reading or altering the bitstream. We propose a setup in which the FPGA is the single device in the system’s zone-of-trust. The result is an FPGA architecture that is divided into a static and a dynamic region. The static region holds the communication, security and reconfiguration facilities, while the dynamic region contains the targeted application.	bitstream;field-programmable gate array	Nele Mentens;Jo Vliegen;An Braeken;Abdellah Touhafi;Karel Wouters;Ingrid Verbauwhede	2010			embedded system;real-time computing;computer science;distributed computing	Arch	-53.105195637939666	55.92478244415083	92469
29f2978f6f1b6df06f83f938ef906e601ede1bf3	a study of malcode-bearing documents	intrusion detection;sandbox diversity;n gram;data format;statistical model;content analysis;object oriented;computer science	By exploiting the object-oriented dynamic composability of modern document applications and formats, malcode hidden in otherwise inconspicuous documents can reach third-party applications that may harbor exploitable vulnerabilities otherwise unreachable by network-level service attacks. Such attacks can be very selective and difficult to detect compared to the typical network worm threat, owing to the complexity of these applications and data formats, as well as the multitude of document-exchange vectors. As a case study, this paper focuses on Microsoft Word documents as malcode carriers. We investigate the possibility of detecting embedded malcode in Word documents using two techniques: static content analysis using statistical models of typical document content, and run-time dynamic tests on diverse platforms. The experiments demonstrate these approaches can not only detect known malware, but also most zero-day attacks. We identify several problems with both approaches, representing both challenges in addressing the problem and opportunities for future research.	composability;embedded system;experiment;malware;microsoft word for mac;sensor;statistical model;threat (computer);unreachable memory	Wei-Jen Li;Salvatore J. Stolfo;Angelos Stavrou;Elli Androulaki;Angelos D. Keromytis	2007		10.1007/978-3-540-73614-1_14	computer science;internet privacy;world wide web;computer security	Security	-57.798011079282446	59.63465567796309	92545
d8fab072de742eb4b3aeb812ada1fb2bd7a5e280	the generation of xss attacks developing in the detect detection		In recent years, the web security events emerge in endlessly, web security has been widely concerned. Cross-site scripting (XSS) attack is one of the most foremost threats which using malicious scripts injected into Web applications and executing the scripts in the client browsers. Moreover, attacker could also combine other means of attack with XSS vulnerabilities to do further attacks, which would lead to disclosure of user privacy and even property damage. Common detect detection methods include black-box testing and white-box testing. Black-box testing scans faster while it can not locate the specific codes which cause the vulnerabilities. White-box audit tools can locate the specific codes while it spends lots of time to analyze all codes. We propose a novel approach to locate the vulnerabilities which combines Fuzzing test and dynamic taint analysis, and design system prototype, then verification and testing.	cross-site scripting	Baojiang Cui;Yang Wei;Songling Shan;Jinxin Ma	2016		10.1007/978-3-319-49106-6_33	cross-site scripting;web application;computer security;distributed computing;taint checking;computer science;internet security;scripting language;audit;fuzz testing	NLP	-57.57208913368329	58.99107961669038	92658
7751cc647815af66f325327e424cf9672132ae55	enforcing generalized refinement-based noninterference for secure interface composition		Information flow security has been considered as a critical requirement on complicated component-based software. The recent efforts on the compositional information flow analyses were limited on the expressiveness of security lattice and the efficiency of compositional enforcement. Extending these approaches to support more general security lattices is usually nontrivial because the compositionality of information flow security properties should be properly treated. In this work, we present a new extension of interface automaton. On this interface structure, we propose two refinement-based security properties, adaptable to any finite security lattice. For each property, we present and prove the security condition that ensures the property to be preserved under composition. Furthermore, we implement the refinement algorithms and the security condition decision procedure. We demonstrate the usability and efficiency of our approach with in-depth case studies. The evaluation results show that our compositional enforcement can effectively reduce the verification cost compared with global verification on composite system.	algorithm;automaton;component-based software engineering;decision problem;expect;hybrid system;information flow;information flow (information theory);lattice-based access control;proof assistant;recursive definition;refinement (computing);usability	Cong Sun;Ning Xi;Jianfeng Ma	2017	2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2017.118	theoretical computer science;software system;principle of compositionality;computer security model;software;enforcement;usability;computer science;information flow (information theory);concrete security;distributed computing	Security	-52.657087277390595	49.54370916678607	92734
006f571d030e8a11eb6a4ee51ec08275b572f6a2	towards preserving information flow security on architectural composition of cyber-physical systems		A key challenge of component-based software engineering is to preserve extra-functional properties such as security when composing the software architecture from individual components. Previous work in this area does not consider specific characteristics of cyber-physical systems like asynchronous message passing, real-time behavior, or so-called feedback composition with two-way communication. Thereby, a composition of secure components might lead to insecure architectures with undetected information leaks. In this paper, we address the preservation of information flow security on composition of cyber-physical systems, taking the above characteristics into account. We refine security policies during the architectural decomposition, and outline a compositional verification approach that checks the security of individual components against their refined policies. On composition of secure components, our approach preserves security and thereby enables the design of secure software architectures. We give a proof of concept using a component-based software architecture of a cyber-manufacturing system.	cyber-physical system;information flow	Christopher Gerking;David Schubert	2018		10.1007/978-3-030-00761-4_10	systems engineering;message passing;proof of concept;information flow (information theory);cyber-physical system;computer science;security policy;asynchronous communication;software architecture;software;distributed computing	Logic	-52.86945189006737	49.6565527743473	93247
85042977e3192cbc9defb65cec888417d974698d	access mediation in a message passing kernel	mandatory access control;mandatory security policy;control systems;kernel;interprocess communication;tcsec;basic system abstractions;discretionary access mediation;segments;discretionary access control;reference monitor;trusted computing;computer architecture;system evaluation;servers;information flow;operating system;monitoring;tmach kernel;mediation;servers mandatory access meditation trusted mach kernel information flow message passing kernel discretionary access mediation between tasks interprocess communication tmach kernel controlled sharing segments trusted systems reference monitor basic system abstractions trusted computing base operating system mandatory access control port access rights mac mandatory security policy bell and la padula model dac discretionary access control tcsec trusted computer system evaluation criteria;trusted systems;mandatory access meditation;controlled sharing;trusted mach kernel;mac;message passing kernel access control centralized control communication system control control systems mediation computer architecture monitoring operating systems;message passing;message passing kernel;bell and la padula model;dac;centralized control;access control;trusted computing base;communication system control;between tasks;security of data operating systems computers;security policy;security of data;operating systems computers;port access rights;trusted computer system evaluation criteria;operating systems	The authors describe how mandatory and discretionary access mediation are performed in the trusted mach (TMach) kernel, a system that uses message passing as its primary means of communication both between tasks and with the kernel. As a consequence, control of interprocess communication in the TMach kernel is a central concern whereas controlled sharing of segments is the central focus in trusted systems with more traditional architectures. The TMach kernel is not a complete trusted system. It is a reference monitor of basic system abstractions, providing a small, well-controlled base on which the rest of a trusted computing base and operating system can be constructed. The TMach kernel provides simple and elegant mandatory access control for port access rights. The TMach kernel's MAC (mandatory access control) mechanisms clearly control the flow of information according to a mandatory security policy based on a Bell and La Padula model. DAC (discretionary access control) mechanisms are provided in the TMach kernel to implement TCSEC (trusted computer system evaluation criteria) requirements and to support DAC in servers to be built on the kernel. >	kernel (operating system);message passing	Martha A. Branstad;Homayoon Tajalli;F. Mayer;D. Dalva	1989		10.1109/SECPRI.1989.36278	message passing;kernel;real-time computing;information flow;discretionary access control;computer science;security policy;control system;access control;operating system;trusted computing base;distributed computing;mediation;trustworthy computing;computer security;server;inter-process communication	Vision	-52.3027214131872	54.172502235635164	93249
3078a59772d768539a80cc0d26a2495dafc3f2c0	securing industrial control systems with a simulation-based verification system	verification;parallel discrete event simulation;industrial control system	Today's quality of life is highly dependent on the successful operation of many large-scale industrial control systems. To enhance their protection against cyber-attacks and operational errors, we develop a simulation-based verification framework with cross-layer verification techniques that allow comprehensive analysis of the entire ICS-specific stack, including application, protocol, and network layers.	control system;simulation	Dong Jin;Ying Ni	2014		10.1145/2601381.2601411	verification and validation of computer simulation models;real-time computing;verification;simulation;software verification;computer science;high-level verification;runtime verification;intelligent verification;functional verification;computer engineering	Logic	-55.901386223590904	49.91922369253994	93419
488903b64d5121360b171567bbac7698e48d37e5	re-establishing trust in compromised systems: recovering from rootkits that trojan the system call table	distributed system;confiance;systeme reparti;psychologie sociale;securite informatique;computer security;confidence;sistema repartido;confianza;seguridad informatica;psicologia social;social psychology	We introduce the notion of re-establishing trust in compromised systems, specifically looking at recovering from kernel-level rootkits. An attacker that has compromised a system will often install a set of tools, known as a rootkit, which will break trust in the system as well as serve the attacker with other functionalities. One type of rootkit is a kernel-level rootkit, which will patch running kernel code with untrusted kernel code. Specifically, current kernel-level rootkits replace trusted system calls with trojaned system calls. Our approach to recover from these type of rootkits is to extract the system call table from a known-good kernel image and reinstall the system call table into the running kernel. Building on our approach to current generation rootkits, we discuss future generation rootkits and address how to recover from them.	algorithm;honeypot (computing);kernel (operating system);linux;operating system;rootkit;strips;system call;trojan horse (computing);trusted system;user space	Julian B. Grizzard;John G. Levine;Henry L. Owen	2004		10.1007/978-3-540-30108-0_23	simulation;computer science;artificial intelligence;operating system;database;distributed computing;confidence;computer security;algorithm	Security	-54.40103640154465	58.32988945971749	93471
dc1c53aa38d3c35658644c42e30d09ca71a10728	patterns transform architectures	libraries;software;expert systems;pattern;catalogs;program transformation;pattern transform architecture;security pattern catalog;books;software pattern;expert knowledge dissemination;computer architecture;software architecture;software security;software architecture expert systems knowledge engineering security of data;security pattern architecture transformation;security oriented program transformation;transforms;security catalogs computer architecture books libraries transforms software;expert knowledge;security oriented program transformation pattern transform architecture software pattern expert knowledge dissemination program transformation security pattern catalog;transformation;security;architecture;security of data;knowledge engineering	Software patterns have been used to guide developers and to disseminate expert knowledge. But patterns can also be thought of as program transformations. Security patterns are architectural. Therefore, program transformations derived from those patterns transform architecture. This paper describes how we used a catalog of security patterns to produce a catalog of security-oriented program transformations. These transformations can be used to make architectural changes that make systems more secure. This paper is a first example of applying patterns to actively transform architectures.	program transformation;software system;vulnerability (computing)	Munawar Hafiz;Paul Adamczyk;Ralph E. Johnson	2011	2011 Ninth Working IEEE/IFIP Conference on Software Architecture	10.1109/WICSA.2011.39	transformation;software architecture;behavioral pattern;architectural pattern;computer science;information security;architecture;software engineering;knowledge engineering;data mining;database;pattern	SE	-59.368563945500405	54.34878168979849	93854
46025dbd87c3ebaf7845131f02468e21e954af5d	a verification framework for access control in dynamic web applications	security modeling and analysis;security engineering;security analysis;security model;software maintenance and evolution;model transformation and composition;role based access control;thesis;source transformation;testing and verification;model driven engineering;intensional programming;imperative programming;general intensional programming system gipsy;access control;formal analysis;context;type system;reverse engineering	This paper proposes a security analysis framework for dynamic web applications. A reverse engineering process is performed over a dynamic web application to extract a role-based access control security model. A formal analysis is applied on the recovered model to check access control security properties. This framework can be used to verify that a dynamic web application conforms to access control polices specified by a security engineer.	dynamic web page;reverse engineering;role-based access control;security engineering;web application	Manar H. Alalfi;James R. Cordy;Thomas R. Dean	2009		10.1145/1557626.1557643	computer security model;web application security;imperative programming;model-driven architecture;web modeling;type system;security engineering;computer science;access control;software engineering;role-based access control;database;security service;security analysis;programming language;network access control;reverse engineering	Security	-52.171167168375476	51.52978120239291	93890
d0ff7bb8b154d4f263a9e84408d42ecc4308d3fa	aligning abac policies with information security policies using controlled vocabulary		Attribute-based Access Control (ABAC) policies are based on mutually processable policy attributes. Assigned permissions in such policies need to be reflected or combined with organisational constraints. Best practice in information security dictates having the operational need to access a particular information artifact independent from the function of the specific application systems. Consequently, any policy regulating the behaviour towards information access must adhere to a minimum degree of mutual semantic expressiveness to be combined and processed with the matching ABAC policy. We show how to detect policy attribute conflicts between ABAC policies and information access policies by means of controlled vocabulary and Semantic Web technologies.	access control;best practice;binary search algorithm;common open policy service;controlled vocabulary;information access;information security;medical privacy;prototype;resource description framework;response time (technology);semantic web;xacml	Raik Kuhlisch;Sören Bittins	2016			information security;controlled vocabulary;business;knowledge management	Security	-50.23364053822747	51.45688117938488	94158
5681517002dcde5c2bb2b9268052b64a5ebbb45d	detecting the run time attacks in the cloud with an evidence collection based approach	software;virtualization;control virtual machine cloud security;virtual machining;binary codes;computer architecture;servers;monitoring;virtualisation cloud computing security of data virtual machines;virtual machine run time attack detection cloud evidence collection based approach security threats large scale virtualization network traffic monitoring logging method virtual infrastructure performance overhead;期刊论文;monitoring software servers virtualization virtual machining binary codes computer architecture	As the impacts of security threats are amplified and spread quickly in the cloud, especially with the attribute of large-scale virtualization. Most of researches focus on monitoring the network traffic. However, these methods don't check how the attack happened and what damage the attack caused for the virtual infrastructure. This paper presents a logging method to analyze the potential attacks out of VM and a prototype was implemented. The experimental results show that this method can detect the real world attacks effectively and the performance overhead is acceptable.	cloud computing;network traffic control;overhead (computing);prototype;run time (program lifecycle phase);sensor;z/vm	Jie Lin;Chuanyi Liu;Zhichun Ning;Binxing Fang	2014	2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2014.7175790	cloud computing security;binary code;full virtualization;real-time computing;virtualization;cloud computing;computer science;virtual machine;operating system;hardware virtualization;computer security;server	DB	-54.84291954770102	57.166534222517484	94291
18676ac38f257c22511cc394eee0bbde15eab8f5	on the effectiveness of heterogeneous-isa program state relocation against return-oriented programming	academiccomputer science discipline;sriskanda;ucsddissertations;computer science on the effectiveness of heterogeneous isa program state relocation against return oriented programming university of california;san diego dean tullsen shamasunder	As computer software grow larger in size and complexity, there is an ever increasing concern over security. In an age where software controls almost everything, from the cars we drive to the airplanes we fly in, this concern is valid now more than ever. Attackers are evolving new ways to exploit vulnerabilities in software everyday, while the computer security community struggles to keep up. One of the most prominent of these attack methods is code reuse attacks - specifically return-oriented programming and its variants. Traditionally, defense techniques have mostly either been at the hardware level or in the software layer. While these defenses have their own strengths and weaknesses, a layer of abstraction that has mostly been unexplored is the architecture. Computer architecture lies at the boundary of hardware and software, where we can harness the strengths of both layers. This work explores the potential security benefit that we can extract from decoupling the architectural state that the system presents to the software, from the micro-architectural state it maintains in hardware. Recent research has shown the potential for heterogeneous-ISA chip multiprocessors to provide both performance and energy benefits. We propose Heterogeneous-ISA Program State Relocation, an architecture based on heterogeneous-ISA computing that randomizes the ISA a program executes on, and couple that with a defense mechanism that dynamically randomizes the program state. We describe the proposed architecture, our implementation of it, and perform a thorough evaluation of its potential as an effective defense technique	relocation (computing);return-oriented programming	Sriskanda Shamasunder	2015			software security assurance;computing;real-time computing;simulation;engineering;computer security	HCI	-54.98797359895271	56.130138398556625	94386
1e4e600216e6af241be68692ab603ec8d77effe8	monitoring smart grid operations and maintaining mission assurance through adaptive computer network defenses	adaptive computing	We present adaptive computer network defenses with a focus on Smart Grid operations. We model Smart Grid network domains in the MESA-ExtendSim simulator and continuously measure mission assurance indicators (security properties) to gauge the network’s mission state. When thresholds are reached, a binary integer optimization problem is solved to identify appropriate host and network defenses (security controls) given parameters (attacker classes) and constraints (cost and mission assurance bounds). The solution is used to actuate defense mechanisms in the simulation. We present mission assurance indicators in an UI before and after defense actuation to gauge defensive effectiveness.	grid network;mathematical optimization;mission assurance;optimization problem;security controls;simulation;user interface	Daniel Bilar;James Solderitsch;Elvis Hovor	2011		10.1145/2179298.2179317	embedded system;engineering;distributed computing;computer security	Metrics	-58.261537963290046	51.94527392046452	94496
c0839053fcfa2d33521af4b769613dc0f9c54820	a car hacking experiment: when connectivity meets vulnerability	computers;standards;vehicles security computers ports computers monitoring safety standards;safety critical software automotive electrics computer crime driver information systems embedded systems internet mobile computing;monitoring;interconnected vehicles car hacking experiment modern embedded systems vulnerability analysis internet mobile application open vehicle monitoring system autonomous driving safety critical components real life driving scenarios all electric car attack scenarios control systems onboard systems;safety;ports computers;vehicles;security	Interconnected vehicles are a growing commodity providing remote access to onboard systems for monitoring and controlling the state of the vehicle. Such features are built to facilitate and strengthen the owner's knowledge about its car but at the same time they impact its safety and security. Vehicles are not ready to be fully connected as various attacks are currently possible against their control systems. In this paper, we analyse possible attack scenarios on a recently released all-electric car and investigate their impact on real life driving scenarios. We leverage our findings to change the behaviour of safety critical components of the vehicle in order to achieve autonomous driving using an Open Vehicle Monitoring System. Furthermore, to demonstrate the potential of our setup, we developed a novel mobile application able to control such vehicle systems remotely through the Internet. We challenge the current state-of-the-art technology in today's vehicles and provide a vulnerability analysis on modern embedded systems.	as-interface;android;autonomous car;control system;embedded system;internet;mobile app;protection mechanism;real life;remote desktop software;reversing: secrets of reverse engineering;run time (program lifecycle phase);sensor;user interface	Sasan Jafarnejad;Lara Codeca;Walter Bronzi;Raphaël Frank;Thomas Engel	2015	2015 IEEE Globecom Workshops (GC Wkshps)	10.1109/GLOCOMW.2015.7413993	embedded system;simulation;computer science;information security;computer security	Mobile	-52.7969757658675	58.88780267047867	95231
0cf409442d962cd630233637a30c35d73c8f788b	patchdroid: scalable third-party security patches for android devices	authentication;virtual machine introspection;reverse engineering	Android is currently the largest mobile platform with around 750 million devices worldwide. Unfortunately, more than 30% of all devices contain publicly known security vulnerabilities and, in practice, cannot be updated through normal mechanisms since they are not longer supported by the manufacturer and mobile operator. This failure of traditional patch distribution systems has resulted in the creation of a large population of vulnerable mobile devices.  In this paper, we present PatchDroid, a system to distribute and apply third-party security patches for Android. Our system is designed for device-independent patch creation, and uses in-memory patching techniques to address vulnerabilities in both native and managed code. We created a fully usable prototype of PatchDroid, including a number of patches for well-known vulnerabilities in Android devices. We evaluated our system on different devices from multiple manufacturers and show that we can effectively patch security vulnerabilities on Android devices without impacting performance or usability. Therefore, PatchDroid represents a realistic path towards dramatically reducing the number of exploitable Android devices in the wild.	android;in-memory database;mobile device;patch (computing);prototype;scalability;usability;vulnerability (computing)	Collin Mulliner;Jon Oberheide;William K. Robertson;Engin Kirda	2013		10.1145/2523649.2523679	computer science;operating system;authentication;internet privacy;world wide web;computer security;reverse engineering	Security	-54.37967675616506	59.778625407871814	95240
45bde648b7a6a480528fb97363c4d4bd855c12e6	java mobile code dynamic verification by bytecode modification for host confidentiality	bytecode modification;dynamic verification;host confidentiality;mobile code;information flow;exception handling	In this paper we present a novel dynamic verification approach to protect the local host confidentiality from malicious Java mobile code. In our approach we use Bytecode Modification to add the verification function to the Java mobile code’s class files before the local JVM executes them. Thus the verification work is done when the host JVM executes the modified class files. By this way our approach could achieve higher verification precision because the verification is done in runtime. Furthermore our approach can deal with the information flow in exception handling, which makes our approach more practicable.	code mobility;confidentiality;data security;exception handling;information flow;java;java bytecode;localhost;overhead (computing);prototype;software portability;software verification	Dan Lu;Yoshitake Kobayashi;Ken Nakayama;Mamoru Maekawa	2008	I. J. Network Security		exception handling;real-time computing;information flow;computer science;operating system;runtime verification;programming language	SE	-55.133346950716465	54.862740783375244	95560
34e8e4dbde847f30691abc124eb967b706dc8980	automated analysis of privacy requirements for mobile apps		Mobile apps have to satisfy various privacy requirements. Notably, app publishers are often obligated to provide a privacy policy and notify users of their apps’ privacy practices. But how can a user tell whether an app behaves as its policy promises? In this study we introduce a scalable system to help analyze and predict Android apps’ compliance with privacy requirements. We discuss how we customized our system in a collaboration with the California Office of the Attorney General. Beyond its use by regulators and activists our system is also meant to assist app publishers and app store owners in their internal assessments of privacy requirement compliance. Our analysis of 17,991 free Android apps shows the viability of combining machine learning-based privacy policy analysis with static code analysis of apps. Results suggest that 71% of apps tha lack a privacy policy should have one. Also, for 9,050 apps that have a policy, we find many instances of potential inconsistencies between what the app policy seems to state and what the code of the app appears to do. In particular, as many as 41% of these apps could be collecting location information and 17% could be sharing such with third parties without disclosing so in their policies. Overall, each app exhibits a mean of 1.83 potential privacy requirement inconsistencies.	android;app store;machine learning;privacy policy;requirement;scalability;static program analysis	Sebastian Zimmeck;Ziqi Wang;Lieyong Zou;Roger Iyengar;Bin Liu;Florian Schaub;Shomir Wilson;Norman M. Sadeh;Steven M. Bellovin;Joel R. Reidenberg	2016			data mining;world wide web	Security	-55.267323741033955	59.746085292229886	96389
2a35ff18b5d04336f9d52396b947fda991625032	the state of the art in critical infrastructure protection: a framework for convergence	national security;policy making;modelizacion;homeland security;raisonnement base sur cas;razonamiento fundado sobre caso;systeme protection;pedestrian safety;sistema critica;poison control;behavioral analysis;modeling and simulation;reseau interconnecte;injury prevention;critical infrastructures;systeme critique;simulation;complex structure;safety literature;traffic safety;injury control;sistema reactivo;home safety;modelisation;critical infrastructure protection cip framework;injury research;safety abstracts;critical system;human factors;seguridad nacional;analyse comportementale;occupational safety;safety;reactive system;systeme reactif;protection system;safety research;accident prevention;analisis conductual;violence prevention;bicycle safety;infrastructure protection;case based reasoning;modelling and simulation;sistema proteccion;critical infrastructure;poisoning prevention;red interconectada;modeling;falls;interconnected power system;behavior analysis;ergonomics;suicide prevention;securite nationale;critical infrastructure protection	The protection of critical infrastructure systems has recently become a major concern for many countries. This is due to the effect of these systems on the every day life of all citizens and the high possibility of disruption because of their complex structure and hidden interdependencies, which subsequently attracts the attention of many researchers and scientists. The investigations of researchers have encompassed issues of national security, policy making, infrastructure system organization, and behavior analysis and modeling. In this paper, we look into the latter subject and explore the attempts that have been made. Based on the available schemes and the requirements of this area, we propose a five dimensional framework that introduces the major research necessities in this field. Among the various available schemes, we study ten of the most recently developed and/or influential systems. A comparison of these schemes based on the features of our proposed framework is made. The comparison allows us to conclude our examination with the identification of current research strengths, and guidelines for future work.	critical infrastructure protection;denial-of-service attack;interdependence;requirement	Ali A. Ghorbani;Ebrahim Bagheri	2008	IJCIS	10.1504/IJCIS.2008.017438	homeland security;case-based reasoning;simulation;systems modeling;reactive system;computer science;engineering;suicide prevention;human factors and ergonomics;national security;injury prevention;critical infrastructure;generalized complex structure;operations research;computer security	Metrics	-62.39495511660454	55.98514662680425	96515
1be738fd8f0fc1779573df813680fa5e7a1ba0ed	the design of a policy-based attack-resilient intrusion tolerant system		In order to identify and reduce the chance of vulnerability, a novel policy-based intrusion tolerant system (ITS) is studied in this paper. The suggested scheme quantifies the vulnerability level first, and then applies it to decide the candidate of the next rotation based on a policy. Experiments using CSIM 20 proved that it has enough capability to hide the VM rotation pattern which attackers are generally interested in and reduces the data leakage of the system greatly in spite of increasing the number of exposures.	cdma subscriber identity module;cns disorder;dental intrusion;experiment;extravasation;spectral leakage	Jungmin Lim;Yongjoo Shin;Seokjoo Doo;Hyunsoo Yoon	2013		10.1007/978-94-007-6996-0_45	reliability engineering;leakage (electronics);spite;intrusion;vulnerability;business	Security	-60.14433050631231	58.45224690074085	96729
c7ddfc6bb1f576c833471e534a5818ae02b746b1	an intelligent information sharing control system for dynamic collaborations	collaborative work;information privacy;collaborative system;privacy preservation;web service;information sharing;control system;control architecture;collaborative systems;sharing control policy;intelligent adaptation;information need;dynamic adaptation;user interaction	Information sharing is a basic requirement in Collaborative Working Environment (CWE), yet privacy of the owner of shared information needs special attention. Personal information and shared information coexist in enterprise-based users, teams, and their activities. Distributed and dynamic collaborations in CWE are a challenge for privacy preservation due to lack of trust among users and thus require an intelligent sharing control policy. Our system intelligently monitors and analysis status of collaborating users, plans sharing control activities according to changing collaborative relationships, user interactions, and context conditions which help in dynamic adaptation of sharing control policy. We present an intelligent sharing control architecture, its implementation, and discussion using Web services and an intelligent context sharing messenger application.	coexist (image);collaborative working environment;common weakness enumeration;control system;information needs;interaction	Ahmad Kamran Malik;Schahram Dustdar	2010		10.1145/1943628.1943658	knowledge management;business;internet privacy;world wide web	HCI	-48.40227167605694	53.58307975127446	96806
b83a21807d4002123dcc22bfbed0317d05c7a0c5	fpga-based remote-code integrity verification of programs in distributed embedded systems	software;ubiquitous and pervasive computing;field programmable gate array;protocols;distributed embedded system;reconfigurable computing;distributed processing;software protection dynamic update embedded systems reconfigurable computing;embedded system;computer architecture;embedded systems;ubiquitous computing distributed processing electronic engineering computing embedded systems field programmable gate arrays formal verification;formal verification;software security;monitoring;hardware field programmable gate arrays security software protocols computer architecture monitoring;code integrity fpga based remote code integrity verification distributed embedded systems networked embedded systems pervasive computing ubiquitous computing software security remote code integrity verification reconfigurable computing;ubiquitous computing;design verification;electronic engineering computing;field programmable gate arrays;dynamic update;security;software protection;reconfigurable hardware;embedded device;hardware	The explosive growth of networked embedded systems has made ubiquitous and pervasive computing a reality. However, there are still a number of new challenges to its widespread adoption that include scalability, availability, and, especially, security of software. Among the different challenges in software security, the problem of remote-code integrity verification is still waiting for efficient solutions. This paper proposes the use of reconfigurable computing to build a consistent architecture for generation of attestations (proofs) of code integrity for an executing program as well as to deliver them to the designated verification entity. Remote dynamic update of reconfigurable devices is also exploited to increase the complexity of mounting attacks in a real-word environment. The proposed solution perfectly fits embedded devices that are nowadays commonly equipped with reconfigurable hardware components that are exploited to solve different computational problems.	application security;bitstream;code integrity;computational problem;embedded system;fits;online and offline;overhead (computing);reconfigurable computing;scalability;ubiquitous computing	Cataldo Basile;Stefano Di Carlo;Alberto Scionti	2012	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2011.2106493	embedded system;real-time computing;reconfigurable computing;computer science;distributed computing;ubiquitous computing;field-programmable gate array	Embedded	-52.26050166085938	55.88648948136063	96868
6f546215728fa94b76344c35cb32253bd9f82bd3	imf: inferred model-based fuzzer		Kernel vulnerabilities are critical in security because they naturally allow attackers to gain unprivileged root access. Although there has been much research on finding kernel vulnerabilities from source code, there are relatively few research on kernel fuzzing, which is a practical bug finding technique that does not require any source code. Existing kernel fuzzing techniques involve feeding in random input values to kernel API functions. However, such a simple approach does not reveal latent bugs deep in the kernel code, because many API functions are dependent on each other, and they can quickly reject arbitrary parameter values based on their calling context. In this paper, we propose a novel fuzzing technique for commodity OS kernels that leverages inferred dependence model between API function calls to discover deep kernel bugs. We implement our technique on a fuzzing system, called IMF. IMF has already found 32 previously unknown kernel vulnerabilities on the latest macOS version 10.12.3 (16D32) at the time of this writing.	application programming interface;experiment;kernel (operating system);kernel panic;operating system;software bug;superuser;tracing (software);macos	HyungSeok Han;Sang Kil Cha	2017		10.1145/3133956.3134103	internet privacy;kernel (linear algebra);computer security;computer science;source code;fuzz testing	Security	-56.59963824146843	57.776137959791825	96930
ff661571ad1ba89537617d6876c5e876764471e7	physical attack protection with human-secure virtualization in data centers	servers software cryptography sensor systems virtual machining;software;sensor systems;moving target defense;virtual machining;virtualisation cloud computing computer centres embedded systems security of data virtual machines;physical attack detection sensor physical attack protection human secure virtualization data center cloud computing data security cyber physical security defense;computer centres;embedded systems;data center;servers;physical attacks;virtual machines;cryptography;security of data;virtualisation;moving target defense physical attacks data center;cloud computing	Cloud computing-based data centers, which hold a large amount of customer data, are vulnerable to physical attacks and insider threats. Current protection and defense mechanisms for security of data held in data centers are either completely physical (sensors, barriers, etc.) or completely cyber (firewalls, encryption, etc.). In this paper we propose a novel cyber-physical security defense for cloud computing-based data centers against physical attacks. In our system, physical sensors detect an impending physical/human attack which triggers cyber defenses to protect or mitigate the attack. The key to the cyber defenses is that in cloud computing data centers the data is loosely coupled with the underlying physical hardware, and can be moved/migrated to other physical hardware in the presence of an attack. In this paper we propose a model for coupling such cyber defenses with physical attack-detection sensors. We further describe a preliminary architecture for building such a system with today's cloud computing infrastructure.	broadcast delay;cloud computing;data center;encryption;firewall (computing);hardening (computing);insider threat;loose coupling;physical security;sensor;server (computing);virtual machine	Jakub Szefer;Pramod A. Jamkhedkar;Yu-Yuan Chen;Ruby B. Lee	2012	IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN 2012)	10.1109/DSNW.2012.6264664	data center;cloud computing;computer science;cryptography;operating system;distributed computing;internet privacy;computer security;computer network	Security	-51.586357362331746	57.61599951482614	97202
5c79e3282d45f3836c60f89b93ff2512c507dd7b	flowfox: a web browser with flexible and precise information flow control	web security;information flow;web browser architecture	We present FlowFox, the first fully functional web browser that implements a precise and general information flow control mechanism for web scripts based on the technique of secure multi-execution. We demonstrate how FlowFox subsumes many ad-hoc script containment countermeasures developed over the last years. We also show that FlowFox is compatible with the current web, by investigating its behavior on the Alexa top-500 web sites, many of which make intricate use of JavaScript.  The performance and memory cost of FlowFox is substantial (a performance cost of around 20% on macro benchmarks for a simple two level policy), but not prohibitive. Our prototype implementation shows that information flow enforcement based on secure multi-execution can be implemented in full-scale browsers. It can support powerful, yet precise policies refining the same-origin-policy in a way that is compatible with existing websites.	full scale;hoc (programming language);information flow (information theory);javascript;non-interference (security);prototype;same-origin policy;top500	Willem De Groef;Dominique Devriese;Nick Nikiforakis;Frank Piessens	2012		10.1145/2382196.2382275	web service;ajax;web application security;web development;web application;web modeling;information flow;web analytics;web mapping;web-based simulation;web design;comet;web standards;computer science;web api;web navigation;web page;internet security;database;internet privacy;client-side scripting;web 2.0;world wide web;computer security;web server	Security	-55.96915300604254	58.7391221394004	97263
b8eca73a2ffa131d25ff25923060230a6b5f26af	proof linking: an architecture for modular verification of dynamically-linked mobile code	java bytecode;java virtual machine;dynamic linking;software engineering;software verification and validation;model checking;mobile code;modular verification;assume guarantee reasoning;filter based analysis	Security flaws are routinely discovered in commercial implementations of mobile code systems such as the Java Virtual Machine (JVM). Typical architectures for such systems exhibit complex interdependencies between the loader, the verifier, and the linker, making them difficult to craft, validate, and maintain. This reveals a software engineering challenge that is common to all mobile code systems in which a static verification phase is introduced before dynamic linking. In such systems, one has to articulate how loading, verification, and linking interact with each other, and how the three processes should be organized to address various security issues.We propose a standard architecture for crafting mobile code verifiers, based on the concept of proof linking. This architecture modularizes the verification process and isolates the dependencies among the loader, verifier, and linker. We also formalize the process of proof linking and establish properties to which correct implementations must conform. As an example, we instantiate our architecture for the problem of Java bytecode verification and assess the correctness of this instantiation. Finally, we briefly discuss alternative mobile code verification architectures enabled by our modularization.	code mobility;correctness (computer science);dynamic linker;java bytecode;java virtual machine;linker (computing);software engineering;universal instantiation	Philip W. L. Fong;Robert D. Cameron	1998		10.1145/288195.288317	model checking;verification and validation;real-time computing;software verification;computer science;software engineering;distributed computing;programming language;functional verification	SE	-54.094895286077175	53.19767994472517	97359
768c8ecad710a936a7df80b644a7552c2fd17be6	an empirical study of natural language parsing of privacy policy rules using the sparcle policy workbench	empirical study;usability evaluation;policy;legal issues;social and legal issues;policy implementation;natural language parsing;privacy policy;design and implementation;natural language;design;usability;security;privacy	Today organizations do not have good ways of linking their written privacy policies with the implementation of those policies. To assist organizations in addressing this issue, our human-centered research has focused on understanding organizational privacy management needs, and, based on those needs, creating a usable and effective policy workbench called SPARCLE. SPARCLE will enable organizational users to enter policies in natural language, parse the policies to identify policy elements and then generate a machine readable (XML) version of the policy. In the future, SPARCLE will then enable mapping of policies to the organization's configuration and provide audit and compliance tools to ensure that the policy implementation operates as intended. In this paper, we present the strategies employed in the design and implementation of the natural language parsing capabilities that are part of the functional version of the SPARCLE authoring utility. We have created a set of grammars which execute on a shallow parser that are designed to identify the rule elements in privacy policy rules. We present empirical usability evaluation data from target organizational users of the SPARCLE system and highlight the parsing accuracy of the system with the organizations' privacy policies. The successful implementation of the parsing capabilities is an important step towards our goal of providing a usable and effective method for organizations to link the natural language version of privacy policies to their implementation, and subsequent verification through compliance auditing of the enforcement logs.	alewife (multiprocessor);effective method;human-readable medium;natural language;parsing;privacy policy;usability;workbench;xml	Carolyn Brodie;Clare-Marie Karat;John Karat	2006		10.1145/1143120.1143123	design;privacy policy;usability;computer science;knowledge management;information security;data mining;database;natural language;privacy;computer security	Security	-51.619811459706575	52.30752931427148	97387
1c29d66714154edae201cee3dac3b189180f57c3	increased security through open source	secure computation;securite informatique;software systems;software engineering;embedded system;computer security;article letter to editor;seguridad informatica;logiciel libre;software libre;computers and society;open source software;open source	In this paper we discuss the impact of open source on both the security and transparency of a software system. We focus on the more technical aspects of this issue, combining and extending arguments developed over the years. We stress that our discussion of the problem only applies to software for general purpose computing systems. For embedded systems, where the software usually cannot easily be patched or upgraded, different considerations may apply.	open-source software	Jaap-Henk Hoepman;Bart Jacobs	2007	Commun. ACM	10.1145/1188913.1188921	software security assurance;long-term support;computing;computer science;package development process;backporting;social software engineering;component-based software engineering;software development;software design description;operating system;software engineering;software construction;database;software walkthrough;software analytics;software deployment;software requirements;software quality;software system;avionics software;software peer review	Crypto	-57.73820223247454	46.55261467047423	97437
fa19cd8dc69834772e6370e4adca4e5b89d21adc	computer security - esorics 2000		This paper presents an approach enabling a smart card issuer to verify that a new applet securely interacts with already downloaded applets. A security policy has been defined that associates levels to applet attributes and methods and defines authorized flows between levels. We propose a technique based on model checking to verify that actual information flows between applets are authorized. We illustrate our approach on applets involved in an electronic purse running on Java enabled smart cards.	applet;authorization;computer security;issuing bank;java;model checking;smart card	Gerhard Goos;Jan van Leeuwen	2000		10.1007/10722599	distribution;embedded system;computer access control;computer science;control system;access control;operating system;role-based access control;programming language;java;computer security	Security	-51.79071937195225	54.39403441643109	97609
97189739190ee87d67244b7aa546d28033d580fb	an exploration of some security issues within the bacnet protocol		Building automation systems control a range of services, commonly heating, ventilation and air-conditioning. BACnet is a leading protocol used to transmit data across building automation system networks, for the purpose of reporting and control. Security is an issue in BACnet due to its initial design brief which appears to be centred around a centralised monolithic command and control architecture. With the advent of the Internet of Things, systems that were isolated are now interconnected. This interconnectivity is problematic because whilst security is included in the BACnet standard, it is not implemented by vendors of building automation systems. The lack of focus on security can lead to vulnerabilities in the protocol being exploited with the result that the systems and the buildings they control are open to attack. This paper describes two proof-of-concept protocol attacks on a BACnet system, proves one attack using experimentation and the other attack through simulation. The paper contextualises a range of identified attacks using a threat model based on the STRIDE threat taxonomy.	bacnet	Matthew Peacock;Michael N. Johnstone;Craig Valli	2017		10.1007/978-3-319-93354-2_12	building automation;automation;computer security;threat model;information system;design brief;architecture;computer science;stride;bacnet	Crypto	-50.82322944373988	56.66464631241449	97786
095c1153a64ede0494835b8d42057a955a118ae7	tucupi: a flexible workflow system based on overridable constraints	fexibility;workflow system;rbac;access control models;workflow;constraints	This work presents the idea and a prototype of workflow systems whose definition is based on constraints. The flexibility is reached through the less rigid definition of workflow definitions - the workflow is defined as a set of pre and post conditions of activities, which are selected dynamically as the process instance unfolds. The workflow system besides dispatching activities that have all their preconditions fulfilled to be executed, also helps users to decide which activity to chose through what if scenarios. The system also includes an access control model which not only represents which users have the authority to chose and execute the activities but also the authority to override the constraints. In particular, overriding constraints is itself an activity and thus may have pre and post conditions defined in other constraints. The paper present Tucupi, a prototype of such constraint based WFMS.	access control;precondition;prototype;what if	Jacques Wainer;Fábio de Lima Bezerra;Paulo Barthelmess	2004		10.1145/967900.968003	workflow;real-time computing;computer science;knowledge management;role-based access control;database;computer security;workflow management system;workflow engine;workflow technology	DB	-48.96788144962569	52.52277649232196	98024
13571411dfb4d29b7b1d34dc65e677c02485f742	an autonomous agent-based framework for self-healing power grid	financial network;transportation networks;reliable power grid;sensors;agent based;secure selfhealing power grid;web services fault diagnosis fault tolerant computing multi agent systems power engineering computing power grids power system reliability power system security;failure detection;web service;data mining;information network;industrial network;power system faults;business network;failure detection power grid autonomous web service hierarchal self healing framework;multi agent systems;fault tolerant computing;power engineering computing;autonomous agent;engines;web services;failure diagnosis technique;multiagent framework;power grid;cognitive planning cycle;power generation;autonomous web service;power system reliability;power grids;autonomous agent based framework;power system protection;cascading failure reduction;hierarchal self healing framework;critical infrastructure;business networks;power grids computer science web services power generation sensor arrays power system faults power system protection intelligent sensors communication system control performance analysis;power system security;multiagent framework autonomous agent based framework secure selfhealing power grid reliable power grid financial network industrial network business network cascading failure reduction failure diagnosis technique autonomous web service cognitive planning cycle;fault diagnosis	Reliable, secure and robust power grid network is a necessity for crucial financial, industrial and business networks. Since national electrical grid, telecommunication, information networks and transportation networks are interdependent critical infrastructures, having an agent-based self-healing framework to reduce cascading failures through the networks and finding reasonable solution for potential faults — would be an essential asset. In response to this need we propose a self-healing framework that employs advanced failure diagnosis techniques along with autonomous web services to provide temporary recovery solutions. Furthermore, it provides a cognitive planning cycle to find ultimate corrective solutions as well as evaluation service to verify the effectiveness and performance of the final solution.	agent-based model;autonomous agent;autonomous robot;coherence (physics);grid network;intelligent agent;interdependence;multi-agent system;reconfigurability;simulation;software agent;software diagnosis;web service;while	Zeinab Noorian;Hadi Hosseini;Mihaela Ulieru	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346576	web service;real-time computing;computer science;artificial intelligence;multi-agent system;business networking;computer security	Robotics	-57.663722114597014	51.18507348519394	98146
323f3ce5bf6ecfc81e425da1d78a547a6844beb1	improving the dependability of sensornets	hazards;maintenance engineering;wireless sensor networks hazards maintenance engineering;wireless sensor networks maintenance engineering monitoring temperature sensors reliability hazards;unacceptable hazards sensornets wireless sensor networks wsn cyber physical systems unpredictable physical environment run time key dependability properties maintenance;wireless sensor networks	Wireless Sensor Networks (WSNs) are being developed and deployed in a wide range of Cyber-Physical systems, some of which must be dependable, e.g. in assisted living facilities where their failure could lead to an accident. In this paper, it is shown that the state of the art approaches do not meet the needs of dependability that these applications require. The main reason is an issue is the unpredictable physical environment in which they operate. Currently there is little emphasis on how these systems behave when failures occur, instead authors emphasise average case performance. Consequently there is little understanding of how and why systems fail and the possible consequences e.g. a system hazard. In this paper simulated tests are used at run-time to check key dependability properties of the system. The results of these tests are used to plan maintenance, thus ensuring available and reliable operation, and determining when the system is at risk of subjecting people to unacceptable hazards such that appropriate steps can be taken. Our approach has been show to perform with 15% less time at risk than the current state-of-the art.	best, worst and average case;cyber-physical system;dependability;simulation;systems design	Mark Louis Fairbairn;Iain Bate;John A. Stankovic	2013	2013 IEEE International Conference on Distributed Computing in Sensor Systems	10.1109/DCOSS.2013.80	maintenance engineering;embedded system;wireless sensor network;hazard;computer science;dependability;computer security;computer network	Embedded	-55.96540028707308	46.86282223637756	98217
a17221dd8a9bcd717813773b7546e17125f26464	aspfuzz: a state-aware protocol fuzzer based on application-layer protocols	protocols;software vulnerability testing;software vulnerability testing fuzzing;computer network security;http servers aspfuzz state aware protocol fuzzer application layer protocols constant malicious attacks network connected software systems software vulnerabilities development phase anomalous messages protocol states pop3 servers;software systems;automatic generation;systems software;fuzzing;protocols servers syntactics authorization software systems;transport protocols;hypermedia;servers;network servers;network connectivity;syntactics;internetworking;authorization;message authentication;transport protocols computer network security hypermedia internetworking message authentication network servers systems software	In the face of constant malicious attacks to network-connected software systems, software vulnerabilities need to be discovered early in the development phase. In this paper, we present AspFuzz, a state-aware protocol fuzzer based on the specifications of application-layer protocols. AspFuzz automatically generates anomalous messages that exploit possible vulnerabilities. The key observation behind AspFuzz is that most of the previously reported attack messages violate the strict specifications of application-layer protocols. For example, they do not conform to the rigid format or syntax required of each message. In addition, some attack messages ignore the protocol states and have incorrect orders of messages. AspFuzz automatically generates a large number of anomalous messages that deliberately violate the specifications of application-layer protocols. It then sends the generated messages in both anomalous orders and correct orders. To demonstrate the effectiveness of AspFuzz, we conducted experiments with POP3 and HTTP servers. With AspFuzz, we can discover 20 reported and 1 previously unknown vulnerabilities for POP3 servers and 25 reported vulnerabilities for HTTP servers.	experiment;hypertext transfer protocol;software system;vulnerability (computing)	Takahisa Kitagawa;Miyuki Hanaoka;Kenji Kono	2010	The IEEE symposium on Computers and Communications	10.1109/ISCC.2010.5546704	message authentication code;communications protocol;fuzz testing;computer science;network security;operating system;authorization;world wide web;computer security;transport layer;server;computer network;software system	Security	-54.28721098047564	54.00437085329124	98240
4d63fe15466b04e91b5ac1b178145440f6928619	dynamic cross domain information sharing: a concept paper on flexible adaptive policy management	information systems;policies;life cycles;information sharing;sensitivity;information flow;information exchange;on the fly;algorithms;context dependent;cross domain information sharing;information need;security;security policy;management;dynamic policy management;policy management;modification	Information exchange across domains is essential for today's asymmetric warfare environment to make mission-critical information available to war fighters, no matter where it exists and when it becomes available. Dissemination of new information needs to carefully balance the need-to-know by consumers with the responsibility-to-share by providers. The right amount of sharing, governed by policies defining what information can cross domain boundaries, when, and under what circumstances, is highly context-dependent and dynamic. Dynamic management of those policies is a key challenge. This paper describes the design of concepts and services to support dynamic lifecycle management and deconfliction of policies governing cross domain information flows. We describe how the design provides scalable, on-the-fly reconfiguration of both local and cross domain security policies while confining sensitive policy information to their respective local domains.	context-sensitive language;distributed computing;information exchange;information needs;mission critical;need to know;network-centric warfare;next-generation network;prototype;scalability;security engineering	Michael Atighetchi;Jonathan Webb;Partha P. Pal;Joseph P. Loyall;Azer Bestavros;Michael J. Mayhew	2010		10.1145/1866898.1866913	knowledge management;operations management;business;computer security	DB	-50.75764499935449	49.29971461470142	98408
2b5f49cb4444a0d974e09c6d9782318dff01fe62	a novel automatic severity vulnerability assessment framework		—Security vulnerabilities play an important role in network security. With the development of the network and the increasing number of vulnerabilities, many Quantitative Vulnerability Assessment Standards (QVAS) was proposed in order to enable professionals to prioritize the most important vulnerabilities with limited energy. However, it is difficult to apply QVAS manually due to the large number of vulnerabilities and lack of information. In order to address these problems, an Automatic Security Vulnerability Assessment Framework (ASVA) is proposed, which can automatically apply any QVAS to special Vulnerability Databases. ASVA obtain values of the metrics of a QVAS with new features of Text Mining; assign these values to a formula of QVAS and finally compute the severity values of the vulnerabilities. New features proposed in ASVA are special combinations of metrics of QVAS, so that consider the influence of metrics each other and improve the accuracy of Text Mining. Based on ASVA, CVSS as a QVAS is applied to a representative Vulnerability Database. The results show that ASVA reduces the cost and period of the application of QVAS and promotes the standardization of security vulnerability management.	network security;text mining;vulnerability (computing);vulnerability database;vulnerability management	Tao Wen;Yuqing Zhang;Ying Dong;Gang Yang	2015	JCM	10.12720/jcm.10.5.320-329	computer science;data mining;computer security	Security	-60.881536784387634	55.996689156446365	98506
0c0292c4756e8b50e80ee8368bceb354eb18527d	high coverage detection of input-related security faults		Improperly bounded program inputs present a major class of program defects. In secure applications, these bugs can be exploited by malicious users, allowing them to overwrite buffers and execute harmful code. In this paper, we present a high coverage dynamic technique for detecting software faults caused by improperly bounded program inputs. Our approach is novel in that it retains the advantages of dynamic bug detection, scope and precision; while at the same time, relaxing the requirement that the user specify the input that exposes the bug. To implement our approach, inputs are shadowed by additional state that characterize the allowed bounds of input-derived variables. Program operations and decision points may alter the shadowed state associated with input variables. Potentially hazardous program sites, such as an array references and string functions , are checked against the entire range of values that the user might specify. The approach found several bugs including two high-risk security bugs in a recent version of OpenSSH.	comparison of programming languages (string functions);openssh;security bug;sensor;software bug;stored-program computer;variable shadowing	Eric Larson;Todd M. Austin	2003				Security	-56.850828010067275	55.97779766361211	98673
284e63d8c1aba2f31dbfd3e0af58ce66c9649c63	end-to-end enforcement of erasure and declassification	control systems;language based security;computer languages;memory management;erasure;lattices;information security;government;declassification;runtime;conference paper;computer security;noninterference erasure declassification information flow language based security expressive security policies;servers;information flow;voting;expressive security policies;technical report;computer science;security;information security data security control systems runtime computer languages voting government computer security computer science medical diagnostic imaging;noninterference;medical diagnostic imaging;reactive power;data security	Declassification occurs when the confidentiality of information is weakened; erasure occurs when the confidentiality of information is strengthened, perhaps to the point of completely removing the information from the system. This paper shows how to enforce erasure and declassification policies. A combination of a type system that controls information flow and a simple runtime mechanism to overwrite data ensures end-to-end enforcement of policies. We prove that well-typed programs satisfy the semantic security condition noninterference according to policy. We extend the Jif programming language with erasure and declassification enforcement mechanisms and use the resulting language in a large case study of a voting system.	confidentiality;declassification;end-to-end encryption;end-to-end principle;imperative programming;jpeg;non-interference (security);programmer;programming language;provable security;requirement;semantic security;type system	Stephen Chong;Andrew C. Myers	2008	2008 21st IEEE Computer Security Foundations Symposium	10.1109/CSF.2008.12	information flow;voting;computer science;information security;technical report;theoretical computer science;database;data security;computer security;government;memory management	Security	-53.467150471231186	52.63068796660383	99037
64a499719de15dfad7d893eee8631ef6524c35c6	overhead analysis and evaluation of approaches to host-based bot detection	trigger mechanism;information sources;detection approach;impact factor;detection accuracy;期刊论文;analysis and evaluation;bot detections;behavior analysis	Host-based bot detection approaches discover malicious bot processes by signature comparison or behavior analysis. Existing approaches have low performance which has become a bottleneck blocking its wider deployment. Among the impact factors of performance, overhead is a crucial one. Many host-based bot detection approaches with high detection accuracy are not used practically because of their high overheads. For the development of host-based bot detection, unveiling the factors affecting the overhead is very significant. First, this paper classifies the typical approaches of host-based bot detection proposed in recent years by several metrics, information sources, interception mechanisms on host, intercepted system calls, trigger mechanisms, and correlation engine. Second, based on our analyses of aims and implementations of detection approaches, we identify three major factors affecting the overhead of approaches, namely, interception mechanism on host, type, and number of system calls intercepted and correlation engine. Third, we evaluate the influence of these factors via various experiments on real systems. Finally, based on the experiments, we propose several suggestions which are able to significantly decrease the overhead of host-based bot detection approaches.		Yuede Ji;Qiang Li;Yukun He;Dong Guo	2015	IJDSN	10.1155/2015/524627	behaviorism;real-time computing;simulation;computer security	Logic	-57.8160705181988	60.0496369709891	99266
43445bbda074eed707d613c4bc5d8a7aebcafab4	forensics framework for cloud computing		The popularity of cloud computing has been on the rise in recent years, as cloud resources are not only shared by many users but can be allocated on demand. A recent survey reports success of the cyber criminals in using cloud computing technology for fraudulent activities, due to its essential characteristics and the lack of suitable digital forensic techniques for the cloud environment. While mitigating cloud crime, investigators face several challenges and issues dealing with cloud forensics. In this paper, the challenges faced by forensic investigators are highlighted. Most of the research work deals with the identification of challenges in cloud forensics and the proposed solutions reported in literature depends on Cloud Service Provider (CSP) for forensic investigation. The dependence on CSP includes the collection of data for the forensics process and there may be a chance of altering data that affects the entire investigation process. For mitigating the dependency on CSP, a new model for collecting forensic evidence outside the cloud environment is developed. © 2017 Elsevier Ltd. All rights reserved.	cloud computing;computer forensics;cybercrime	M. Edington Alex;Ravi Kishore	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.02.006	cloud computing security;engineering;internet privacy;world wide web;computer security	Security	-49.60562723344075	58.37686957682299	99288
1f5777c2b50e506f8332f1393760000bf78ce92c	verifying abstract information flow properties in fault tolerant security devices	developpement logiciel;calculateur embarque;fault tolerant;traitement flux donnee;informacion incompleta;graph flow;securite informatique;metodo formal;methode formelle;flux donnee;flujo datos;interpretacion abstracta;partial information;flow graphs;flujo grafo;formal method;information flow properties;computer security;incomplete information;information flow;security devices;fault tolerant system;desarrollo logicial;flot graphe;seguridad informatica;data flow processing;software development;information incomplete;boarded computer;graphe flux;sistema tolerando faltas;systeme tolerant les pannes;graphe fluence;information system;interpretation abstraite;data flow;abstract interpretation;grafo fluencia;calculador embarque;systeme information;fluence graph;embedded software;sistema informacion	The verification of information flow properties of security devices is difficult because it involves the analysis of schematic diagrams, artwork, embedded software, etc. In addition, a typical security device has many modes, partial information flow, and needs to be fault tolerant. We propose a new approach to the verification of such devices based upon checking abstract information flow properties expressed as graphs. This approach has been implemented in software, and successfully used to find possible paths of information flow through security devices.	control flow;data-flow analysis;diagram;documentation;embedded software;embedded system;fault tolerance;graph (discrete mathematics);hardware description language;information flow;information flow (information theory);linkage (software);model checking;prototype;schematic;statistical model;vhdl	Tim McComb;Luke Wildman	2006		10.1007/11901433_34	fault tolerance;formal methods;computer science;theoretical computer science;software engineering;database;algorithm	Security	-54.64667119478727	51.76756718783786	99294
a7eaecd24476ad0c85e8b79357c9bd29d3053bb8	armhex: a framework for efficient dift in real-world socs		Security in embedded systems remains a major concern. Untrustworthy authorities use a wide range of software attacks. This demo introduces ARMHEx, a practical solution targeting DIFT (Dynamic Information Flow Tracking) implementations on ARM-based SoCs. DIFT is a solution that consists in tracking the dissemination of data inside the system and allows to enforce some security properties. In this demo, we show an implementation of ARMHEx on Xilinx Zynq SoC. Especially, we show how the required information for DIFT is recovered with the help of traces produced by CoreSight components, static analysis and instrumentation.		Muhammad Abdul Wahab;Pascal Cotret;Mounir Nasr Allah;Guillaume Hiet;Vianney Lapotre;Guy Gogniat	2017	2017 27th International Conference on Field Programmable Logic and Applications (FPL)	10.23919/FPL.2017.8056799	computer science;implementation;real-time computing;software;embedded system;information flow (information theory);coprocessor;instrumentation	EDA	-53.086256141537625	55.32186067560592	99409
d5ac73fc265a9e819ea412cd22ae5272f6b71ad1	an xacml extension for business process-centric access control policies	xacml;control systems;information systems;corporate modelling;information security;model driven business process access control xacml;business process centric access control policy;authorisation;role based access control;extensible access control markup language;business communication;data mining;separation of duty;access control information security control systems communication system security insurance information systems data security protection business communication customer profiles;business process model;protection;access control policy;business activity;extensible access control markup language xacml business process centric access control policy administrative controls business activity corporate regulation legal regulation business process model role based access control duty access control;business data processing;business;unified modeling language;process control;model driven;administrative controls;access control;legal regulation;markup language;duty access control;corporate regulation;context;insurance;customer profiles;business process;corporate modelling authorisation business data processing;communication system security;data security	Administrative controls exist to ensure that business activities are correctly managed and controlled according to corporate and legal regulations. With many organisations reliant on complex IT solutions these controls relate to functionality of software. In this paper we present an extension for business process models to express administrative controls, such as role-based, mandatory or dynamic separation of duty access control policies on the abstraction level of business process models. A model-driven approach is applied to generate platform-specific policies. As an example we utilise the eXtensible Access Control Markup Language (XACML).	abstraction layer;access control;business process;markup language;model-driven architecture;platform-specific model;xacml	Christian Wolter;Christian Weiss;Christoph Meinel	2009	2009 IEEE International Symposium on Policies for Distributed Systems and Networks	10.1109/POLICY.2009.21	database;business;computer security	Arch	-50.48682167020791	51.33237959718832	99450
05f9e468a2e0d9b6274e1750436df75f3fd67461	what is intransitive noninterference?	electrical capacitance tomography;process algebra security of data data privacy;information security;modified purge function;algebra information security laboratories europe read only memory multilevel systems interference electrical capacitance tomography automation;interference;multilevel systems;information flow;algebra;data privacy;intransitive noninterference;downgraders;process algebra intransitive noninterference information flow downgraders modified purge function determinism data security data privacy;europe;determinism;process algebra;read only memory;security of data;data security;automation	The term “intransitive noninterference” refers to the information flow properties required of systems like downgraders, in which it may be legitimate for information to flow indirectly between two users but not directly. We examine the usual definition of this property in terms of a modified purge function, and show that this is a distinctly weaker property than an alternative we derive from considerations	loop unrolling;non-interference (security)	A. W. Roscoe;M. H. Goldsmith	1999		10.1109/CSFW.1999.779776	process calculus;information flow;computer science;information security;theoretical computer science;automation;database;interference;data security;computer security;read-only memory;algorithm;determinism	Security	-53.03633136515196	51.79699209883723	99497
7e8604212695c7c833a1dc474626af68c405a95e	very short intermittent ddos attacks in an unsaturated system		We present a new class of low-volume application layer DDoS attack–Very Short Intermittent DDoS (VSI-DDoS). Such attack sends intermittent bursts (tens of milliseconds duration) of legitimate HTTP requests to the target website with the goal of degrading the quality of service (QoS) of the system and damaging the long-term business of the service provider. VSI-DDoS attacks can be especially stealthy since they can significantly impair the target system performance while the average usage rate of all the system resources is at a moderate level, making it hard to pinpoint the root-cause of performance degradation. We develop a framework to effectively launch VSI-DDoS attacks, which includes three phases: the profiling phase in which appropriate HTTP requests are selected to launch the attack, the training phase in which a typical Service Level Agreement (e.g., (95^{th}) percentile response time u003c1 s) is used to train the attack parameters, and the attacking phase in which attacking scripts are generated and deployed to distributed bots to launch the actual attack. To evaluate such VSI-DDoS attacks, we conduct extensive experiments using a representative benchmark web application under realistic cloud scaling settings and equipped with some popular state-of-the-art IDS/IPS systems (e.g., Snort), and find that our attacks are able to effectively cause the long-tail latency problem of the benchmark website while escaping the radar of those DDoS defense tools.	benchmark (computing);cns;denial-of-service attack;elegant degradation;experiment;image scaling;long tail;multitier architecture;quality of service;response time (technology);service-level agreement;snort;web application	Huasong Shan;Qingyang Wang;Qiben Yan	2017		10.1007/978-3-319-78813-5_3	latency (engineering);real-time computing;service provider;response time;service-level agreement;cloud computing;quality of service;profiling (computer programming);computer science;denial-of-service attack	Security	-56.72305660847628	60.16011374746216	99686
899593e3f05090c7a7c15ae5c497fbc8bd8d7f97	expert systems for information security management and audit. implementation phase issues	information security;information security audit information security fuzzy expert systems;web based application module expert systems information security management information security audit security operations information security tools information protection tools;information security audit;security of data expert systems internet;fuzzy expert systems;information security expert systems organizations standards intelligent systems computers	Auditing of information security constitutes a key part of security operations taken inside organizations. Often information security problems must be addressed as quickly as possible. The purposes of this work are to provide an insight to information security management and suggest some of solutions of developing expert system. This paper discusses the development of an application, which is based on international standards on information security and protection tools. The expert system is accompanied by web-based application module, which serves as an instrument for solving various security-related problems.	expert system;information security;security management;web application	Maksat Kanatov;Lyazzat Atymtayeva;Bagdat Yagaliyeva	2014	2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)	10.1109/SCIS-ISIS.2014.7044702	information security audit;computer security model;standard of good practice;certified information security manager;cloud computing security;web application security;certified information systems security professional;security through obscurity;information security management system;security information and event management;security convergence;asset;computer science;knowledge management;threat;information security;information security standards;data mining;human-computer interaction in information security;security service;security analysis;security testing;computer security;information security management	EDA	-55.20430628260143	49.475248462670265	100296
4b30352ae5216b297d7e3ea29d654c882017789e	an evaluation of hp-ux (unix) for database protection using the european itsec	tcsec;security evaluation criteria;database security;orange book;white book;itsec;unix;operating system security	This paper describes an evaluation of the effectiveness of two versions of Hewlett Packard’s UNIX operating system, HP-UX, to protect a sensitive database set up under the ORACLE Data Base Management System, using Version 1 .O of the European Information Technology Security Evaluation Criteria (ITSEC) as the basis for the evaluation. An outline of these criteria is given, along with mention of the US Trusted Computer System Evaluation Criteria (TCSEC) for comparison purposes. The rcscarch project reported in this paper was aimed at determining the level of effort required to perform such an evaluation and also the rclcvancc of the ITSEC to commercial environments where information systems security, incorporating authenticity, inrcgrity and privacy, arc of paramount concern. Two succcssivc releases of the HP-UX operating system were found to be markedly different when evaluated from the ITSEC point of view, with the latter version being quite effective in maintaining security parameters. It was also concluded that evaluations are time consuming but can have positive implications for commercial systems developers.	a/ux;database;itsec;information security;information system;linc;management system;operating system;trusted computer system evaluation criteria;unix	William J. Caelli;Anthony W. Rhodes;N. C. Russell	1992	Computers & Security	10.1016/0167-4048(92)90012-G	computer science;database;unix;world wide web;computer security	Security	-51.00695855366708	54.534246615207394	100471
112daad9598822b8ede0d0da5bc7a0cf5a617fc8	tamper resistant secure digital silo for log storage in critical infrastructures		Tamper resistant secure data storage is necessary to store event logs in critical environments, as it enables trustworthy evidence collection during an incident, and subsequently allows investigators to analyze attack behaviour, impact of the incident, source of attacks, risk factors, and if necessary it should also offer the procurement of admissible proof at trial. Recent advancements in hardware based security allows us to build such storage mechanisms, and cope with the advanced threats. In this paper, we describe the existing problems in secure storage of logs, and generate requirements to address those problems. Finally, we present our solution with commercial off-the-shelf (COTS) hardware based security technologies, which assures that the system is practical and suitable for integration with current systems. In order to show the feasibility of design, we also implement the solution using open source platforms.	secure digital;silo;tamper resistance	Khan Ferdous Wahid;Helmut Kaufmann;Kevin Jones	2016		10.1007/978-3-319-71368-7_19	distributed computing;silo;computer security;trustworthiness;computer science;tamper resistance;procurement;computer data storage	Crypto	-51.1514327481219	59.312351239910036	101319
447533ee7f985bbfe01a3abf5e155f2c0669e8a7	cps: stateful policy enforcement for control system device usage	scada;policy;control system	Networked control systems used in energy, manufacturing, and transportation combine large, vulnerable attack surfaces with far overprovisioned privileges. Often, compromising a single computer or user account is sufficient to give an attacker free reign over physical machinery. Significant reduction of attack surface size is an ongoing problem, so we shift our focus to reducing the privileges granted to system operators and embedded controllers. To this end, we introduce C2, an enforcement mechanism for policies governing the usage of electromechanical devices. In presenting C2, we address two basic problems: (i.) How should a policy for physical device usage be expressed and enforced? This is a challenging question, as the safe usage of physical devices is dependent on mechanical limitations and the behavior of nearby devices. (ii.) What actions should be taken if a physical machine is issued an operation that violates the policy? C2 takes measures to ensure unsafe behaviors are not caused when denying slightly erroneous yet legitimate operations. We evaluate C2 against six representative control systems, and show that it can efficiently perform policy checks with less than 3.7% overhead, while not introducing new unsafe behaviors into a control system.	attack surface;control system;embedded system;overhead (computing);peripheral;state (computer science);sysop;user (computing)	Stephen E. McLaughlin	2013		10.1145/2523649.2523673	real-time computing;simulation;computer science;control system;operating system;computer security;scada	Security	-53.86858703402596	54.51646954285247	101397
76f8964837a1dac67559fd9e5843e4ec3f7bf51a	towards automated bounded model checking of api implementations		We introduce and demonstrate the viability of a novel technique for verifying that implementations of application program interfaces (APIs) are bug free. Our technique applies a new abstract interpretation to extract an underlying model of API usage, and then uses this to synthesise a set of verifiable program fragments. These fragments are evaluated using CBMC and any potentially spurious property violation is presented to a domain expert user. The user’s response is then used to refine the underlying model of the API to eliminate false positives. The refinement-analysis process is repeated iteratively. We demonstrate the viability of the technique by showing how it can find an integer underflow within Google’s Brotli, an underflow that has been shown to lead directly to allow remote attackers to execute arbitrary code in CVE 2016-1968.	abstract interpretation;arbitrary code execution;brotli;common vulnerabilities and exposures;data mining;formal grammar;formal verification;information extraction;iterative method;model checking;open-source software;program synthesis;refinement (computing);regular expression;subject-matter expert;usage data;user interface;verification and validation	Daniel M Neville;Andrew Malton;Martin Brain;Daniel Kroening	2016			model checking;implementation;automated proof checking;theoretical computer science;bounded function;computer science	SE	-55.44122841467797	53.18420308796151	101578
f1bd018d758d9fad618b5aea94da7c74ae9a1de9	access control and applications on trusted systems	information systems;authorisation;access control licenses information systems operating systems security kernel graphical user interfaces control systems certification;access control policy;commercial off the shelf;open access;network license mechanism trusted systems trusted automated information systems access control off the shelf applications;access control;information system;software reliability authorisation information systems;software reliability	Most current trusted automated information systems do not allow changes to or extensions of the access control policy implemented by the system vendor. This closed approach to access control can restrict the operation of site applications and commercial off-the-shelf applications on trusted systems. This paper presents a flexible, open access control framework that provides relief f r o m these restrictions. A network license mechanism i s used to illustrate the problem and the applicability of the framework.	access control;information system;trusted operating system;trusted system	Michael V. Joyce	1992		10.1109/CSAC.1992.228223	computer access control;discretionary access control;computer science;access control;operating system;trusted network connect;role-based access control;database;world wide web;computer security;information system	OS	-51.18436359932485	52.93032345995526	101922
7fdb842336e905df1043a2f347351a22b2e244eb	cache attacks enable bulk key recovery on the cloud		Cloud services keep gaining popularity despite the security concerns. While non-sensitive data is easily trusted to cloud, security critical data and applications are not. The main concern with the cloud is the shared resources like the CPU, memory and even the network adapter that provide subtle side-channels to malicious parties. We argue that these side-channels indeed leak fine grained, sensitive information and enable key recovery attacks on the cloud. Even further, as a quick scan in one of the Amazon EC2 regions shows, high percentage -55%of users run outdated, leakage prone libraries leaving them vulnerable to mass surveillance. The most commonly exploited leakage in the shared resource systems stem from the cache and the memory. High resolution and the stability of these channels allow the attacker to extract fine grained information. In this work, we employ the Prime and Probe attack to retrieve an RSA secret key from a co-located instance. To speed up the attack, we reverse engineer the cache slice selection algorithm for the Intel Xeon E5-2670 v2 that is used in our cloud instances. Finally we employ noise reduction to deduce the RSA private key from the monitored traces. By processing the noisy data we obtain the complete 2048-bit RSA key used during the decryption.	amazon elastic compute cloud (ec2);cpu cache;central processing unit;cloud computing;information sensitivity;key (cryptography);key escrow;library (computing);network interface controller;noise reduction;platform as a service;public-key cryptography;reverse engineering;selection algorithm;signal-to-noise ratio;spectral leakage;tracing (software);trusted operating system	Mehmet Sinan Inci;Berk Gülmezoglu;Gorka Irazoqui Apecechea;Thomas Eisenbarth;Berk Sunar	2016		10.1007/978-3-662-53140-2_18	real-time computing;internet privacy;computer security	Security	-53.68805439244899	56.41534029477193	102148
1b2803de0657864ceeccc36ff0ea8d1920e0fc08	clorexpa: cloud resilience via execution path analysis	cloud computing management;resilience;safety and security issues in clouds;performance security trade offs;execution path analysis	Despite the increasing interest around cloud concepts, current cloud technologies and services related to security are not mature enough to enable a more widespread industrial acceptance of cloud systems. Providing an adequate level of resilience to cloud services is a challenging problem due to the complexity of the environment as well as the need for efficient solutions that could preserve cloud benefits over other solutions. In this paper we provide the architectural design, implementation details, and performance results for a customizable resilience service solution for cloud guests. This solution leverages execution path analysis. In particular, we propose an architecture that can trace, analyze and control live virtual machine activity as well as intervened code and data modifications-possibly due to either malicious attacks or software faults. Execution path analysis allows the virtual machine manager (VMM) to trace the VM state and to prevent such a guest from reaching faulty states. We evaluated the effectiveness and performance trade-off of our prototype on a real cloud test bed. Experimental results support the viability of the proposed solution.	path analysis (statistics)	Roberto Di Pietro;Flavio Lombardi;Matteo Signorini	2014	Future Generation Comp. Syst.	10.1016/j.future.2012.05.010	cloud computing security;parallel computing;real-time computing;cloud computing;operating system;cloud testing;database;distributed computing;computer security;psychological resilience	Arch	-52.704170209189435	56.84135377026085	102162
5c909d94db6d8bd41b964f2045771df4892fcf20	conceptual systems security requirements analysis: aerial refueling case study		In today’s highly interconnected and technology-reliant environment, cybersecurity is no longer limited to traditional computer systems and IT networks, as a number of highly publicized attacks have occurred against complex cyber-physical systems such as automobiles and airplanes. While numerous vulnerability analysis and architecture analysis approaches are in use, these approaches are often focused on realized systems with limited solution space. A more effective approach for understanding security and resiliency requirements early in the system development is needed. One such approach, system-theoretic process analysis for security (STPA-Sec), addresses the cyber-physical security problem from a systems viewpoint at the conceptual stage when the solution trade-space is largest rather than merely examining components and adding protections during production, operation, or sustainment. This paper uniquely provides a detailed and independent evaluation of STPA-Sec’s utility for eliciting, defining, and understanding security and resiliency requirements for a notional next generation aerial refueling platform.	aerial photography;computer security;conceptual system;cyber-physical system;feasible region;next-generation network;physical security;requirement;requirements analysis;theory	Martin Trae Span;Logan O. Mailloux;Robert F. Mills;William Young	2018	IEEE Access	10.1109/ACCESS.2018.2865736	architecture;systems engineering;notional amount;vulnerability assessment;distributed computing;computer science;requirements analysis	SE	-58.18619183721209	49.38491933838521	102196
5f9e8983d6f9ec3818ec70dfe9304fff9350ff42	design and implementation of a field inspection management system based on wireless sensor networks		Various errors and failures occur every day in the plant field. However these errors have been managed manually by field inspector. In this paper, we present a design and implementation of a field inspection management system based on wireless sensor networks. This system works on a portable embedded device. To develop the field inspection management system, we analyzed work tasks and process in the plant field. In addition, we propose security measures for preventing information stealing and alteration in the embedded system. Through this system, we can manage effectively error information collected in the field.	management system	Shin-Hyeong Choi;Hyoung-Keun Park	2014	IJDSN	10.1155/2014/410856	embedded system;real-time computing;simulation	Mobile	-49.158628352728726	47.19814527487678	102260
14ddf7484ad4244da4dad9873393e366b1d7e3be	autonomic trust management in cloud-based and highly dynamic iot applications	trusted computing cloud computing internet of things;biological system modeling;mape k trust internet of things cloud networks iot cloud ecosystem smart homes;internet of things;monitoring;ecosystems;mape k feedback control loop highly dynamic iot applications highly dynamic internet of things cloud computing physical objects intelligent services iot devices iot cloud ecosystems autonomic trust management framework;cloud computing security biological system modeling monitoring internet of things ecosystems scalability;scalability;security;cloud computing	In this paper, we propose an autonomic trust management framework for cloud based and highly dynamic Internet of Things (IoT) applications and services. IoT is creating a world where physical objects are seamlessly integrated in order to provide advanced and intelligent services for human-beings in their day-to-day life style. Therefore, trust on IoT devices plays an important role in IoT based services and applications. Cloud computing has been changing the way how provides are looking into these issues. Many studies have proposed different techniques to address trust management although non of them addresses autonomic trust management in cloud based highly dynamic IoT systems. To our understanding, IoT cloud ecosystems help to solve many of these issues while enhancing robustness and scalability. On this basis, we came up with an autonomic trust management framework based on MAPE-K feedback control loop to evaluate the level of trust. Finally, we presents the results that verify the effectiveness of this framework.	autonomic computing;cloud computing;control system;ecosystem;feedback;internet of things;scalability;trust management (information system)	Suneth Namal;Hasindu Gamaarachchi;Gyu Myoung Lee;Tai-Won Um	2015	2015 ITU Kaleidoscope: Trust in the Information Society (K-2015)	10.1109/Kaleidoscope.2015.7383635	engineering;internet privacy;world wide web;computer security	Mobile	-48.40640566127636	56.15756253008974	102344
b507d7a308913aa80b56f53a4ff99d85e3e4c184	enforcing information hiding in interface specifications: a client-aware checking approach	jml language;runtime assertion checking;aspectjml language;information hiding;interface specification languages	Information hiding is an established principle that controls which parts of a module are visible to non-privileged and privileged clients (e.g., subclasses). This aids maintenance because hidden implementation details can be changed without affecting clients. The benefits of information hiding apply not only to code but also to other artifacts, such as specifications. Unfortunately, contemporary formal interface specification languages and their respective runtime assertion checkers (RACs) are inconsistent with information hiding rules because they check assertions in an overly-dynamic manner on the supplier side. We explain how overly-dynamic RACs compromise information hiding and how our client-aware checking technique allows these RACs to use the privacy information in specifications, which promotes information hiding.	assertion (software development);common access card	Henrique Rebêlo;Gary T. Leavens	2015		10.1145/2735386.2736750	computer science;theoretical computer science;database;programming language;information hiding	SE	-52.48818807600164	53.52491224755076	102367
72f61476c17a6c7fe5750d2acd02c58263152a59	quantitative security risk assessment and management for railway transportation infrastructures	railways;cost benefit evaluation;return on investment;quantitative approaches;risk analysis;transport infrastructure;procedural modeling;transport system;computer network;development tool;mathematical model;security;quantitative method;cost benefit analysis;critical infrastructure protection	Scientists have been long investigating procedures , models and tools for the risk analysis in several domains, from econ omics to computer networks. This paper presents a quantitative method and a too l for the security risk assessment and management specifically tailored to the context of railway transportation systems, which are exposed to threat s anging from vandalism to terrorism. The method is based on a reference mathe tical model and it is supported by a specifically developed tool. The too l all ws for the management of data, including attributes of attack scenarios a nd effectiveness of protection mechanisms, and the computation of results, includi ng r sk and cost/benefit indices. The main focus is on the design of physica l protection systems, but the analysis can be extended to logical threats as well . The cost/benefit analysis allows for the evaluation of the return on investme nt, which is a nowadays important issue to be addressed by risk analysts.	computation;genetic algorithm;it risk management;logical security;mathematical optimization;omics;protection mechanism;table (database);threat (computer);traffic collision avoidance system	Francesco Flammini;Andrea Gaglione;Nicola Mazzocca;Concetta Pragliola	2008		10.1007/978-3-642-03552-4_16	return on investment;risk analysis;quantitative research;computer science;systems engineering;engineering;cost–benefit analysis;information security;mathematical model;transport engineering;procedural modeling;computer security	AI	-57.2581877466996	48.73076089433396	102469
4e4303ac23684034f0ba7f2aefa75d18fc660e41	iot security techniques based on machine learning: how do iot devices use ai to enhance security?		The Internet of things (IoT), which integrates a variety of devices into networks to provide advanced and intelligent services, has to protect user privacy and address attacks such as spoofing attacks, denial of service (DoS) attacks, jamming, and eavesdropping. We investigate the attack model for IoT systems and review the IoT security solutions based on machine-learning (ML) techniques including supervised learning, unsupervised learning, and reinforcement learning (RL). ML-based IoT authentication, access control, secure offloading, and malware detection schemes to protect data privacy are the focus of this article. We also discuss the challenges that need to be addressed to implement these ML-based security schemes in practical IoT systems.	access control;attack model;authentication;denial-of-service attack;information privacy;internet of things;machine learning;malware;radio jamming;reinforcement learning;spoofing attack;supervised learning;unsupervised learning	Liang Xiao;Xiaoyue Wan;Xiaozhen Lu;Yanyong Zhang;Jiqiang Wu	2018	IEEE Signal Processing Magazine	10.1109/MSP.2018.2825478	access control;computer science;computer security;theoretical computer science;unsupervised learning;malware;reinforcement learning;spoofing attack;attack model;information privacy;denial-of-service attack	Security	-50.039912472407515	60.1942105670428	102571
fc49c2b5f70d1256e5166e9336e7d06b1cb22a91	a unified model for system security engineering support	analytical models;nist;security of data information management risk management;risk management;controls systems security engineering model threat risk requirement;security unified modeling language context risk management nist analytical models;control tailoring system security engineering support cyber systems cyber threat cyber requirements security controls architectural aspects data management cognitive challenge system security engineering process information management threat modeling risk assessment security requirement development control tracking;unified modeling language;security;context	In the course of performing their duties, system security engineers must develop a detailed understanding of cyber systems, the missions those systems support, the associated cyber threat, and the risk the threat poses to mission. They use this information to specify and track cyber requirements, security controls, and the architectural aspects that allow the controls to be coordinated and implemented across the cyber environment. When attempted manually, the process of gathering, interrelating, verifying, querying, analyzing, sharing, and reusing this information can be an overwhelming data management and cognitive challenge. While models exist that focus on isolated portions of the system security engineering process, this paper puts forward a unified model as a first step towards a common platform to manage this information. The model facilitates the development of analytics to assist with activities such as threat modeling, risk assessment, security requirements development, and control tracking and tailoring.	common platform;computer security;requirement;risk assessment;security controls;security engineering;threat model;unified model;verification and validation	Thomas Llansó;Patrick Engebretson	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.681	computer security model;cloud computing security;unified modeling language;itil security management;countermeasure;security management;security through obscurity;nist;security information and event management;security engineering;security convergence;vulnerability;risk management;asset;computer science;threat;information security;software engineering;database;security service;security analysis;security testing;management;computer security;information security management	SE	-56.37793329361805	49.071481321076575	102576
981380c75305854d6a22a6b0208e27e5b5050ce2	physical intrusion games—optimizing surveillance by simulation and game theory	game theory;surveillance;cyber physical systems;computer security;games surveillance game theory cyber physical systems computer security;games;security surveillance risk analysis intrusion detection	The protection of cyber-physical networks is a topic of increasing importance. The evolution of IT (cyber) systems that control and supervise the underlying physical system has grown over decades, whereas security has not become a concern until quite recently. Advanced persistent threats (APTs) have proven to be a difficult but significant challenge for practitioners. This paper adopts a game-theoretic modeling of APTs and applies it to the (sub) problem of physical intrusion in an infrastructure. The gap between defining a good theoretical model and practically instantiating it is considered in particular. The model description serves to illustrate what is needed to put it into practice. The main contribution of this paper is the demonstration of how simulation, physical understanding of an infrastructure, and theoretical methods can be combined toward a practical solution to the physical intrusion avoidance problem. Numerical results are given to show how the physical intrusion game is being set up, and how the results obtained from its analysis can be interpreted and used for an optimized defense.	game theory;instance (computer science);optimizing compiler;simulation	Stefan Rass;Ali Alshawish;Mohamed Amine Abid;Stefan Schauer;Quanyan Zhu;Hermann de Meer	2017	IEEE Access	10.1109/ACCESS.2017.2693425	intrusion detection system;games;game theory;simulation;computer science;artificial intelligence;cyber-physical system;computer security	ML	-58.29735948595609	49.45557710381426	102805
44ec9629a72f23d52730b42b2af96bd614978f9d	geometric interpretation of policy specification	shadow mapping;policy resolution policy specification policy conflict;resolution strategy;formal specification;lattices;policy resolution;authorisation;default behavior;computational geometry;formal geometric interpretation;policy specification;firewall rules formal geometric interpretation policy specification resolution strategy default behavior;policy conflict;magnetic resonance;information management;solid modeling;desktop publishing;classification algorithms;management information systems;system testing;formal specification authorisation computational geometry;fires;security;firewall rules;conferences;magnetic resonance solid modeling desktop publishing conferences system testing information management management information systems	"""The actual implementation of a policy on real devices must be done by providing a """"set of rules"""". Nevertheless, no extensive studies were performed to completely model this crucial process. This paper provides a formal geometric interpretation of the policy specification focusing on the role of three factors: the detection, the resolution and the default behavior. The resulting model allows for the definition of new resolution strategies and the definition of """"morphisms"""" between rule sets where conflicts are managed using different resolution methods. Additionally, it provides a mean to classify conflicts and anomalies for the """"generic"""" resolution strategy. The effectiveness of the theory is proven by means of experimental results."""		Cataldo Basile;Alberto Cappadonia;Antonio Lioy	2008	2008 IEEE Workshop on Policies for Distributed Systems and Networks	10.1109/POLICY.2008.36	simulation;computer science;data mining;computer security	DB	-53.04087689660952	50.92916147246302	102968
e03989540a24f3aeeddb3e19c721223a23e85ed7	a tool set for the evaluation of security and reliability in smart grids		Fluctuating energy resources and security flaws in ICT used for power networks threaten the stability of the system. This requires an in-depth analysis of smart grid technologies which are used for balancing out supply and demand. We present a tool set that supports the analy- sis and evaluation of various smart grid scenarios with respect to their security relevance.		Joël Chinnow;Jakob Tonn;Karsten Bsufka;Thomas Konnerth;Sahin Albayrak	2012		10.1007/978-3-642-38030-3_3	reliability engineering;engineering;environmental resource management;computer security	NLP	-57.03260058444742	50.055756857911085	103031
9bf05d0540ad9bfc70a43b78d15e429f2b44cdf6	passivity framework for modeling, mitigating, and composing attacks on networked systems	network security;cyber physical systems;passivity	Cyber-physical systems (CPS) consist of a tight coupling between cyber (sensing and computation) and physical (actuation and control) components. As a result of this coupling, CPS are vulnerable to both known and emerging cyber attacks, which can degrade the safety, availability, and reliability of the system. A key step towards guaranteeing CPS operation in the presence of threats is developing quantitative models of attacks and their impact on the system and express them in the language of CPS. Traditionally, such models have been introduced within the framework of formal methods and verification. In this talk, we present a control-theoretic modeling framework. We demonstrate that the control-theoretic approach can capture the adaptive and time-varying strategic interaction between the adversary and the targeted system. Furthermore, control theory provides a common language in which to describe both the physical dynamics of the system, as well as the impact of the attack and defense. In particular, we provide a passivity-based approach for modeling and mitigating jamming and wormhole attacks. We demonstrate that passivity enables composition of multiple attack and defense mechanisms, allowing characterization of the overall performance of the system under attack. Our view is that the formal methods and the control-based approaches are complementary.	adversary (cryptography);computation;control theory;cyber-physical system;formal methods;radio jamming;threat (computer)	Radha Poovendran	2014		10.1145/2566468.2566470	real-time computing;simulation;engineering;computer security	Security	-55.604031943464804	51.69126790920194	103622
7d7fab92a8082017882eea8d516e0fbbb8dcb5ea	evaluating the effectiveness of current anti-rop defenses		Recently, many defenses against the offensive technique of return-oriented programming (ROP) have been developed. Prominently among them are kBouncer, ROPecker, and ROPGuard which all target legacy binary software while requiring no or only minimal binary code rewriting. In this paper, we evaluate the effectiveness of these Anti-ROP defenses. Our basic insight is that all three only analyze a limited number of recent (and upcoming) branches in an application’s control flow on certain events. As a consequence, an adversary can perform dummy operations to bypass all employed heuristics. We show that it is possible to generically bypass kBouncer, ROPecker, and ROPGuard with little extra effort in practice. In the cases of kBouncer and ROPGuard on Windows, we show that all required code sequences can already be found in the executable module of a minimal 32-bit C/C++ application with an empty main() function. To demonstrate the viability of our attack approaches, we implemented several proof-of-concept exploits for recent vulnerabilities in popular applications; e. g., Internet Explorer 10 on Windows 8.	32-bit;adversary (cryptography);binary code;c++;central processing unit;control flow;debugging;dummy variable (statistics);entry point;executable;internet explorer;microsoft windows;overhead (computing);profiling (computer programming);return-oriented programming;rewriting;sensor	Felix Schuster;Thomas Tendyck;Jannik Pewny;Andreas Maaß;Martin Steegmanns;Moritz Contag;Thorsten Holz	2014		10.1007/978-3-319-11379-1_5	binary code;computer science;real-time computing;offensive;software;theoretical computer science;binary number;rewriting	Security	-56.240196412415614	55.95596669862166	103876
56a03fd143c1530317bf317bf584fc4fad0270a0	what's different about security in a public cloud?	cloud security;software maintenance;data center;dos attack	Most of the problems facing the designers of a public cloud are extensions of what we face in any data center: detecting and preventing intrusions, coping with DoS attacks, and keeping the various services largely isolated from one another. There are some new challenges: how to control the behavior of customers when your privacy guarantees prevent you from looking too closely at what they are doing, how to protect them from network based attacks when you don't know what kind of traffic is normal, and how to guarantee them resources when the behavior of others sharing the hardware is unpredictable. There are also some new advantages: centrally managing software maintenance can assure that patches are installed promptly, and scale permits a permanent staff of experienced trouble shooters to handle what would be rare problems for any individual customer.	cloud computing;dos;data center;sensor;software maintenance	Charlie Kaufman	2011		10.1145/2046660.2046668	cloud computing security;data center;computer science;operating system;internet privacy;software maintenance;world wide web;computer security;denial-of-service attack	Networks	-51.50948820800533	58.412525713847096	103931
8f8434b3c992f104ed4b69f3343af76ed39906c4	a logical high-level framework for critical infrastructure resilience and risk assessment	saturn;analytical models;security of data critical infrastructures failure analysis risk analysis;logical framework;risk analysis;critical infrastructures;biological system modeling;automated reasoning;failure analysis;resilience;high level modelling logical framework critical infrastructure resilience risk assessment accidental failures failure impacts infrastructure dependency stakeholders;roads;electricity analytical models roads resilience biological system modeling saturn cognition;cognition;risk assessment;electricity;critical infrastructure;security of data;analytical model	Critical Infrastructures (CIs) play crucial roles in modern societies and our reliance on their proper functioning even in the face of accidental failures and deliberate targeted attacks makes their protection of paramount importance. A notable characteristic of CIs is their interdependencies that may exist at many levels and facets of the infrastructure, and which may sometimes lead to unforeseen and unexpected interactions. In particular, the underlying dependencies may induce domino effects in the propagation of failure impacts with devastating consequences and pose serious threats. Thus, technologies that provide new insights and visibility into the infrastructure dependencies, helping stakeholders to understand root causes and to predict the propagation of failure impacts are valuable for the assessment of risks and the engineering of resilience into the infrastructure. This paper presents a logical framework for the high-level modelling of CI dependencies along with analytical tools for automated reasoning about resilience properties of CIs.	analytical engine;automated reasoning;business rules engine;confidentiality;decision support system;drools;error-tolerant design;high- and low-level;information leakage;information sensitivity;interaction;interdependence;logic level;logic programming;logical framework;natural language;risk assessment;risk management;software propagation;spectral leakage;state space;system of systems;vulnerability (computing);wildfly	Sadie Creese;Michael Goldsmith;Adedayo Adetoye	2011	2011 Third International Workshop on Cyberspace Safety and Security (CSS)	10.1109/CSS.2011.6058564	reliability engineering;systems engineering;engineering;computer security	SE	-57.55608788780039	49.223640076926024	104070
15383cc826157e08af29f72095a1ebc8779d594c	guest editorial special issue on secure control of cyber-physical systems		THE integration of computation, communication, and control units has led to the birth and rapid development of a new generation of engineering systems, the cyber-physical systems (CPSs), which have been increasingly used in fields ranging from aerospace, automobile, industrial process control to energy, healthcare, manufacturing, and transportation, where secure operation is one of the key concerns. These CPSs are often distributed in nature with a hierarchical structure, and likely to be attacked due to diverse motivations, such as economic reasons (e.g., reducing or not paying electricity charge), or terrorism (e.g., threatening people by controlling electricity and other life-critical resources). By exploiting the sensing, networking, and computation capabilities, the new generation CPSs is able to connect the cyber space and the physical space in an unprecedented manner. However, such connections also provide rich opportunities for adversaries to launch potential malicious attacks. Secure data transmission is typically taken for granted in early research in CPSs. The control and systems community has played an important role in the analysis and design of CPSs, addressing issues related to data imperfection and its effect on closed-loop system performance. The assumed data imperfection models, such as packet drops, delays, quantization, etc., however, are inadequate to characterize the possibility that the communicated data may not be the true data collected by sensors or calculated by controllers, and may instead have been modified by attackers. In July 2010, the report of Stuxnet, a control system malware targeting Supervisory Control and Data Acquisition systems in power grids, has raised new questions and research challenges of secure control of CPSs. The classical defense approaches, such as secure detection, estimation, and robust control, aim to identify system abnormities and design strategies under the assumption that these system abnormalities under certain types of malicious attacks are either benign or random. However, different from randomly taking attack actions, smart attackers can design strategies specifically to exploit vulnerabilities of the CPSs. Some recent works investigated how to detect and identify attack actions against the consensus algorithm in power systems and wireless control networks, respectively. These methods, however, rely on the assumption that the system model is noise-free. In a noisy environment, it is much harder to detect and identify the malicious behavior since it may be indistinguishable from the environmental noise. As a result, these approaches should be rethought	chandra–toueg consensus algorithm;computation;control system;control unit;cyber-physical system;cyberspace;data acquisition;ibm power systems;mit engineering systems division;malware;network packet;randomness;robust control;sensor;stuxnet	Peng Cheng;Ling Shi;Bruno Sinopoli	2017	IEEE Trans. Control of Network Systems	10.1109/TCNS.2017.2667233	process control;cyber-physical system;computer security;aerospace;ranging;engineering	Security	-57.57995619497142	52.13745125132847	104194
1640d7070d629058016ca22ffe37964b6551aa1e	towards an ontology-based risk assessment in collaborative environment using the semanticlife	ontologies risk management collaboration computer networks data security computer viruses computer bugs hardware semantic web information management;groupware;personal information management;semantic web groupware ontologies artificial intelligence personal information systems risk management security of data;organizational security ontology based risk assessment collaborative environment semanticlife computer systems computer networks security measures semantic web personal information management system user interaction events;risk management;computer systems;decision maker;semantic web technology;ontologies artificial intelligence;computer networks;semanticlife;collaborative environment;risk factors;security measures;personal information systems;personal information management system;organizational security;semantic web;risk assessment;user interaction events;legacy system;user interaction;security of data;ontology based risk assessment	The rise in interconnectivity in the last few years has made computer systems and networks more vulnerable to threats as they are accessed by an ever increasing number of users. Nowadays organizations are lacking proper security measures and means to calculate risk assessment for their assets. Legacy systems in organizations are facing different kind of risks like viruses, bugs and system failure causing damages to hardware and software resulting in data loss. The ultimate challenge in many organizations is to assess their risk factors for their computers and networks. There is no way to completely overcome the threat that an organization might have. The goal is to calculate risks, so that problems resulting from them could be minimized and to fill the gap between business entities (like a project, a role) and organization infrastructure using semantic Web technologies. SemanticLIFE is a personal information management system which gathers the user interaction events and correlates those by using ontologies. In this paper the ontology-based risk assessment in the context of the organizational security, a fundamental issue for planners and decision makers in the IT field, is explored using SemanticLIFE tool	computer virus;entity;information management system (ims);interconnectedness;legacy system;ontology (information science);personal information management;personally identifiable information;risk assessment;risk factor (computing);semantic web;software bug;threat (computer)	Mansoor Ahmed;Amin Andjomshoaa;Tho Manh Nguyen;A Min Tjoa	2007	The Second International Conference on Availability, Reliability and Security (ARES'07)	10.1109/ARES.2007.152	computer science;knowledge management;data mining;world wide web	SE	-60.92749018495741	51.224907388058305	104272
59132c85f029331c26251949b82daf9354e9426a	tool support for achieving qualitative security assessments of critical infrastructures - the essaf framework for structured qualitative analysis	critical infrastructure;qualitative analysis	Devices that are designed for the use in critical infrastructures demand a high level of security. Therefore, a consideration of cyber threats and security mechanisms should be done in an early state, at best at the product’s design phase. In this paper, we present a security assessment method in addition to a support tool that allows the involved participants to conduct security assessments in a reproducible and standardized way. Special for our method is the focus on the collaboration of different domain experts at various abstraction levels, which is typical for critical infrastructure device assessments.	high-level programming language;threat (computer)	Hanh Quyen Nguyen;Friedrich Köster;Michael Klaas;Walter Brenner;Sebastian Obermeier;Markus Brändle	2009			computer network;database;flat file database;management science;computer science;critical infrastructure;object model;dissemination;graphical user interface	Security	-55.368433694067235	48.42400427631191	104568
b10403d9c1e7f27a06d991465837f18981f536b2	boxing clever with iommus	virtual machine;memory management unit;iommu;block device;input output;fault isolation;high performance;virtualisation	Input/Output Memory Management Units (IOMMUs) have been touted as the solution to many problems in virtualisation security. Used naïvely, they can improve fault isolation and reduce the amount of trusted code. We contend that it is possible to do better.  In this paper, we introduce page boxing, a novel abstraction that allows untrusted virtual machines to manage data without having access to its contents. We illustrate how this can be used with an IOMMU to create a confidential end-to-end channel between disks and virtual machines. Unlike alternative approaches, we avoid the use of encryption, which gives the potential for high performance.	boxing;confidentiality;end-to-end encryption;fault detection and isolation;input/output;input–output memory management unit;virtual machine	Grzegorz Milos;Derek Gordon Murray	2008		10.1145/1456482.1456489	iommu;input/output;embedded system;real-time computing;memory management unit;device file;computer hardware;computer science;virtual machine;computer security;fault detection and isolation	OS	-53.74909815808889	55.87040861867113	104616
3183cecda14ec95820424eaff16fc9dff2bb54a4	weak behavioral equivalences for verifying secure and performance-aware component-based systems	security analysis;performance evaluation;component based systems;system performance;functional dependency;numerical analysis;quality of service;equivalence checking	Component-based systems are characterized by several orthogonal requirements, ranging from security to quality of service, which may demand for the use of opposite strategies and interfering mechanisms. To achieve a balanced tradeoff among these aspects, we have previously proposed the use of a predictive methodology, which encompasses classical tools such as the noninterference approach to security analysis and standard performance evaluation techniques. The former tool, which is based on equivalence checking, is used to reveal functional dependencies among component behaviors, while the latter tool, which relies on reward-based numerical analysis, is used to study the quantitative impact of these dependencies on the system performance. In order to strengthen the relation between these two different analysis techniques we advocate the use of performance-aware notions of behavioral equivalence as a formal means for detecting functional and performance dependencies and then pinpointing the metrics at the base of a balanced tradeoff. 1 Trading Security with Performance One of the major issues in the design of modern computing systems is trading dependability aspects with the expected quality of service [16, 10, 15]. A balanced tradeoff is particularly hard to accomplish when the dependability aspect of interest is security and the system under analysis requires the interaction of several, possibly untrusted components performing their activities in wide-area, public networks. As an example, it is commonly recognized that lightweight securing infrastructures like those employed for access control in the setting of the IEEE 802.11 standard for wireless local area networks [26] are able to mitigate the impact of the securing mechanisms on quality of service parameters, such as system throughput and response time, still preserving to a specific extent the properties for which they are introduced. Examples such as this emphasize the importance of integrating the different qualitative and quantitative views of a system in order to understand whether a reasonable balance can be achieved between the satisfaction of security requirements and the expected quality of service. However, foundational approaches to the analysis of secure and performance-aware systems have not successfully joined with the aim of assessing a balanced qualitative and quantitative profile of these systems. Different aspects of a system behavior are usually dealt with heterogeneous analysis techniques that are applied separately. These techniques consider different descriptions of the software architecture, without a clear comprehension of how to validate mutually such descriptions, how to combine the results obtained through the various analysis techniques and, most importantly, how to evaluate the correlation among such results. On the other hand, an integrated view of these aspects can be at the base of a predictive methodology combining functional verification and quantitative analysis, with the aim of guiding the system design towards the desired tradeoff among security and performance. For component-based systems, in [4] we have introduced a predictive methodology that can be used in the early stages of the system design to estimate the impact of untrusted components on the system security and performance, thus providing the base for balancing functional and nonfunctional aspects of system behavior. From the modeling standpoint, the methodology relies on formal architectural description languages, which represent a useful aid for the design of effective and efficient software applications. In fact, they provide support for the rigorous specification of systems together with related automated analysis techniques of functional properties and performance measures. From the analysis standpoint, the methodology relies on the application of two phases based on formal tools for the verification of functional interferences among system components and the estimate of the metrics that quantitatively characterize these interferences, respectively. In the first phase, the functional verification is performed through the noninterference approach to information flow analysis [14], which is widely recognized as a valid support to the investigation of several different aspects of security [19]. In the second phase, the quantitative analysis is conducted through standard numerical techniques [23]. For example, this methodology can be used for studying the influence of faults/events triggered by nontrusted components upon the behavior of other components performing security-critical applications [24]. In this paper we extend the methodology of [4] in order to bridge the gap between its two phases, i.e. between the functional noninterference analysis and the nonfunctional performance-oriented analysis. This is accomplished by means of performance-aware notions of behavioral equivalence to be used during noninterference analysis, which make it possible to study both functional and nonfunctional undesired dependencies and, as a consequence, to pinpoint directly the metrics that guide the performance evaluation towards the desired tradeoff. Such an approach can be profitably employed also by those designers who are not familiar with the formal approaches underlying the methodology and are not interested in going into the technicalities of the related ingredients. Moreover, the employed analysis techniques are sufficiently general to represent a valid tool for the study of many dependability aspects – not only security, but also, e.g., safety and reliability – and, therefore, for the assessment of the performability profile of component-based software systems. The revised methodology is noninterference analysis with component disabled with component enabled model qual./quant. begin with component disabled with component enabled model YES they cannot be avoided NO	access control;approximation algorithm;component-based software engineering;context-aware pervasive systems;covert channel;data-flow analysis;dependability;formal equivalence checking;functional dependency;information leakage;non-interference (security);numerical analysis;performance evaluation;quality of service;relevance;requirement;response time (technology);sensor;software architecture;software system;spectral leakage;systems design;throughput;turing completeness;world-system	Alessandro Aldini;Marco Bernardo	2008		10.1007/978-3-642-10248-6_10	reliability engineering;quality of service;numerical analysis;computer science;theoretical computer science;formal equivalence checking;computer performance;functional dependency;security analysis;computer security	SE	-54.02268968598859	50.98116225360233	104910
8941acca42b26b39d822f3702f416ea7d09a46aa	semantic system for attacks and intrusions detection	intrusion detection mechanisms;web attack;computer security;semantic rules;inference mechanism;information system;ontology	The increasing development of information systems complicate task of protecting against threats. They have become vulnerable to malicious attacks that may affect the essential properties such as confidentiality, integrity and availability. Then the security becomes an overriding concern. Securing a system begins with prevention methods that are insufficient to reduce the danger of attacks, that must be accomplished by intrusion and attack detection systems. In this paper, a method for detecting web application attacks is proposed. Unlike methods based on signatures, the proposed solution is a technique based on ontology. It describes the Web attacks, the HTTP request, and the application using semantic rules. The system is able to detect effectively the sophisticated attacks by analysing user requests. The semantic rules allow inference about the ontologies models to detect complex variations of web attacks. The ontologies models was developed using description logics which was based Web Ontology Language (OWL). The proposed system is able to be installed on an HTTP server. Semantic System for Attacks and Intrusions Detection		Abdeslam El Azzouzi;Kamal Eddine El Kadiri	2015	IJDCF	10.4018/IJDCF.2015100102	anomaly-based intrusion detection system;computer science;ontology;internet privacy;world wide web;computer security;information system	Security	-60.81167371611156	58.83037277208374	104914
35b0d53931ccdf10e50e6bb74d50693bc6349045	using abuse frames to bound the scope of security problems	systems analysis formal specification security of data;formal specification;frame problem;systems analysis;security requirements;system development;scope security problem abuse frames security threat system development security protection security requirements full system description;process model;security of data;security protection systems engineering and theory counting circuits terminology joining processes	Security problems arise from the concern for protecting assets from security threats. In a systems development process, the security protection of a system is specified by security requirements, identified from the analysis of the threats to the system. However, as it is often not possible to obtain a full system description until late in the RE process, a security problem often has to be described in the context of a bounded scope, that is, one containing only the domains relevant to some part of the functionality of the full system. By binding the scope of a security problem, it can be described more explicitly and precisely, thereby facilitating the identification and analysis of threats, which in turn drive the elicitation and elaboration of security requirements. In this poster, we elaborate on an approach we developed based on abuse frames and suggest how it can provide a means for structuring and bounding the scope security problems.	requirement;software development process;threat (computer)	Luncheng Lin;Bashar Nuseibeh;Darrel C. Ince;Michael Jackson	2004	Proceedings. 12th IEEE International Requirements Engineering Conference, 2004.	10.1109/RE.2004.54	software security assurance;computer security model;cloud computing security;reliability engineering;systems analysis;countermeasure;security through obscurity;frame problem;security information and event management;security engineering;security convergence;covert channel;asset;computer science;systems engineering;engineering;information security;software engineering;process modeling;formal specification;security service;security analysis;security testing;network security policy;computer security	SE	-55.55010797482853	48.23609384670161	105060
85adc84eb4a2d1753c11c0360751ffdda2c2c661	blind format string attacks		Although Format String Attacks(FSAs) are known for many years there is still a number of applications that have been found to be vulnerable to such attacks in the recent years.According to the CVE database, the number of FSA vulnerabilities is stable over the last 5 years, even as FSA vulnerabilities are assumingly easy to detect. Thus we can assume, that this type of bugs will still be present in future. Current compiler-based or system-based protection mechanisms are helping to restrict the exploitation this kind of vulnerabilities, but are insu cient to circumvent an attack in all cases. Currently FSAs are mainly used to leak information such as pointer addresses to circumvent protection mechanisms like Address Space Layout Randomization (ASLR). So current attacks are also interested in the output of the format string. In this paper we present a novel method for attacking format string vulnerabilities in a blind manner. Our method does not require any memory leakage or output to the attacker. In addition, we show a way to exploit format string vulnerabilities on the heap, where we can not bene t from direct destination control, i. e. we can not place arbitrary addresses onto the stack, as is possible in stack-based format string.	address space layout randomization;common vulnerabilities and exposures;compiler;memory leak;nx bit;pointer (computer programming);printf format string;protection mechanism;software bug;spectral leakage;stack-oriented programming language;uncontrolled format string	Fatih Kiliç;Thomas Kittel;Claudia Eckert	2014		10.1007/978-3-319-23802-9_23	computer security;compiler;computer network;computer science;scanf format string;restrict;vulnerability	Security	-56.662303515987674	57.22326120910233	105083
5251b17f30e05045ee0f7ec48475b87bca47f717	transforming commodity security policies to enforce clark-wilson integrity	reference monitor;malware;forensics;data provenance	Modern distributed systems are composed from several off-the-shelf components, including operating systems, virtualization infrastructure, and application packages, upon which some custom application software (e.g., web application) is often deployed. While several commodity systems now include mandatory access control (MAC) enforcement to protect the individual components, the complexity of such MAC policies and the myriad of possible interactions among individual hosts in distributed systems makes it difficult to identify the attack paths available to adversaries. As a result, security practitioners react to vulnerabilities as adversaries uncover them, rather than proactively protecting the system's data integrity. In this paper, we develop a mostly-automated method to transform a set of commodity MAC policies into a system-wide policy that proactively protects system integrity, approximating the Clark-Wilson integrity model. The method uses the insights from the Clark-Wilson model, which requires integrity verification of security-critical data and mediation at program entrypoints, to extend existing MAC policies with the proactive mediation necessary to protect system integrity. We demonstrate the practicality of producing Clark-Wilson policies for distributed systems on a web application running on virtualized Ubuntu SELinux hosts, where our method finds: (1) that only 27 additional entrypoint mediators are sufficient to mediate the threats of remote adversaries over the entire distributed system and (2) and only 20 additional local threats require mediation to approximate Clark-Wilson integrity comprehensively. As a result, available security policies can be used as a foundation for proactive integrity protection from both local and remote threats.	approximation algorithm;clark–wilson model;data integrity;distributed computing;interaction;mandatory access control;operating system;selinux;system integrity;ubuntu;virtual machine;vulnerability (computing);web application	Divya Muthukumaran;Sandra Julieta Rueda;Nirupama Talele;Hayawardh Vijayakumar;Jason Teutsch;Trent Jaeger	2012		10.1145/2420950.2420991	computer science;operating system;malware;internet privacy;forensic science;world wide web;computer security	Security	-53.0822438633354	57.76547587739969	105138
e7ccc3ffa313cda4c6476e4a5c373698b5a82750	relating admissibility standards for digital evidence to attack scenario reconstruction	admissibility;electronic crime;evidence graph;network attack scenario;digital evidence;forensics	Attackers tend to use complex techniques such as combining multi-step, multi-stage attack with anti-forensic tools to make it difficult to find incriminating evidence and reconstruct attack scenarios that can stand up to the expected level of evidence admissibility in a court of law. As a solution, we propose to integrate the legal aspects of evidence correlation into a Prolog based reasoner to address the admissibility requirements by creating most probable attack scenarios that satisfy admissibility standards for substantiating evidence. Using a prototype implementation, we show how evidence extracted by using forensic tools can be integrated with legal reasoning to reconstruct network attack scenarios. Our experiment shows this implemented reasoner can provide pre-estimate of admissibility on a digital crime towards an attacked network.	admissible heuristic;prolog;prototype;requirement;semantic reasoner	Changwei Liu;Anoop Singhal;Duminda Wijesekera	2014	JDFSL	10.15394/jdfsl.2014.1180	engineering;data mining;forensic engineering;computer security	Security	-61.77392195940484	59.73956864470877	105216
7cca3d88bc3fe77debcb7a95c2f11b184173ccab	semantic-based authorization architecture for grid	conflict detection;policy conflict analysis;globus security;large scale;semantic web;decision process;authorization;security policy	There are a few issues that still need to be covered regarding security in the Grid area. One of them is authorization where there exist good solutions to define, manage and enforce authorization policies in Grid scenarios. However, these solutions usually do not provide Grid administrators with semantic-aware components closer to the particular Grid domain and easing different administration tasks such as conflict detection or resolution. This paper defines a proposal based on Semantic Web to define, manage and enforce security policies in a Grid scenario. These policies are defined by means of semantic-aware rules which help the administrator to create higher-level definitions with more expressiveness. These rules also permit performing added-value tasks such as conflict detection and resolution, which can be of interest in medium and large scale scenarios where different administrators define the authorization rules that should be followed before accessing a resource in the Grid. The proposed solution has been also tested providing some reasonable response times in the authorization decision process.	authorization	Juan Manuel Marín Pérez;Jorge Bernal Bernabé;Jose M. Alcaraz Calero;Félix J. García Clemente;Gregorio Martínez Pérez;Antonio F. Gómez-Skarmeta	2011	Future Generation Comp. Syst.	10.1016/j.future.2010.07.008	semantic grid;computer science;security policy;semantic web;data mining;database;authorization;computer security	Arch	-48.29139273687857	52.423497090082385	105947
c41eb9371b58b5ec74a00916899564a850747b05	a model-checking approach to analysing organisational controls in a loan origination process	organisational control;resource manager;revocation;separation of duty;erp system;delegation;separation;model checking;access control	Demonstrating the safety of a system (ie. avoiding the undesired propagation of access rights or indirect access through some other granted resource) is one of the goals of access control research, e.g. [1-4]. However, the flexibility required from enterprise resource management (ERP) systems may require the implementation of seemingly contradictory requirements (e.g. tight access control but at the same time support for discretionary delegation of workflow tasks and rights).To aid in the analysis of safety problems in workflow-based ERP system, this paper presents a model-checking based approach for automated analysis of delegation and revocation functionalities. This is done in the context of a real-world banking workflow requiring static and dynamic separation of duty properties.We derived information about the workflow from BPEL specifications and ERP business object repositories. This was captured in a SMV specification together with a definition of possible delegation and revocation scenarios. The required separation properties were translated into a set of LTL-based constraints. In particular, we analyse the interaction between delegation and revocation activities in the context of dynamic separation of duty policies.	access control;business process execution language;business object;erp;enterprise relationship management;enterprise resource planning;model checking;requirement;software propagation	Andreas Schaad;Volkmar Lotz;Karsten Sohr	2006		10.1145/1133058.1133079	delegation;model checking;computer science;knowledge management;access control;resource management;separation of duties;database;computer security	Security	-51.36369385796841	51.23726588077168	106352
170e2a11dd2d7fd508300c348671f6177049867e	extending .net security to unmanaged code	unmanaged code;sandboxing;net security	The number of applications that are downloaded from the Internet and executed on-the-fly is increasing every day. Unfortunately, not all of these applications are benign, and, often, users are unsuspecting and unaware of the intentions of a program. To facilitate and secure this growing class of mobile code, Microsoft introduced the .NET framework, a new development and runtime environment where machine-independent byte-code is executed by a virtual machine. An important feature of this framework is that it allows access to native libraries to support legacy code or to directly invoke the Windows API. Such native code is called unmanaged (as opposed to managed code). Unfortunately, the execution of unmanaged native code is not restricted by the .NET security model, and, thus, could provide the attacker with a mechanism to completely circumvent the framework’s security mechanisms if the user decides to grant execute permission to the .NET application. The approach described in this paper uses a sandboxing mechanism to prevent an attacker from executing malicious, unmanaged code that is not permitted by the security policy. Our sandbox is implemented as two security layers, one on top of the Windows API and one in the kernel. Also, managed and unmanaged parts of an application are automatically separated and executed in two different processes. This ensures that potentially unsafe code can neither issue system calls not permitted by the .NET security policy nor tamper with the memory of the .NET runtime. Our proof-of-concept implementation is transparent to applications and secures unmanaged code with a generally acceptable performance penalty. To the best of our knowledge, the presented architecture and implementation is the first solution to secure unmanaged code in .NET.	.net framework;algorithm;application programming interface;byte;code access security;code mobility;internet;legacy code;library (computing);machine code;malware;memory corruption;microsoft windows;prototype;runtime system;sandbox (computer security);system call;virtual machine	Patrick Klinkoff;Engin Kirda;Christopher Krügel;Giovanni Vigna	2007	International Journal of Information Security	10.1007/s10207-007-0031-0	.net framework;code access security;computer science;redundant code;sandbox;database;distributed computing;blittable types;computer security;managed code	Security	-54.46947329102226	57.995629511834416	106628
b9c6991967791ab8fee8fe866c5ead74eb0a708c	the cross space transmission of cyber risks in electric cyber-physical systems	aerospace electronics power system stability power system faults dispatching couplings control systems;harm assessment electric cyber physical systems smart grid cyber risks power system faults cross space linkage interfaces existing form;electric cyber physical systems;smart grid;power system faults;smart substation simulation environment cross space transmission cyber risk electric cyber physical system collaborative work security risk power system fault cross space linkage interface cross space conduction mechanism field ecps test environment;substation protection cyber physical systems groupware power engineering computing power system faults power system reliability power system security security of data smart power grids substation automation;existing form;cross space linkage interfaces;harm assessment;cyber risks	The electric cyber-physical systems (ECPS) realize the deep integration and collaborative work between the cyber space and power system. But there also appeared a new security risk that the power system faults caused by cyber risks could seriously harm the ECPS stable operation. In order to explain the impact of cyber risks on ECPS, the following meaningful works have been done in this paper: firstly, the cyber risks and the cross space linkage interfaces have been clearly analyzed to elucidate the cross space conduction mechanism of cyber risks; Then, the existing form of cyber risks in power system and its harm have been assessed; finally, a field ECPS test environment has been constructed based on the 110kv smart substation simulation environment. A variety of power system faults caused by cyber risks have been simulated and its harm has been assessed.	cyber-physical system;cyberspace;deployment environment;linkage (software);simulation;traction substation	Yufei Wang;Zhi Yan;Jing Wang	2015	2015 11th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2015.7378175	reliability engineering;simulation;engineering;computer security	EDA	-57.96233568515001	51.03460926683273	106685
0a43977969290f58626fd957bf07b4a053c0addd	measuring similarity for security vulnerabilities	databases;software;national vulnerability database;vulnerability management ontology;vulnerability classification;information security;vulnerability mitigation;availability;similarity calculation;security vulnerabilities;authentication;software engineering security of data;software engineering;similarity measurement;information security ontologies data security databases national security information retrieval conference management knowledge management software measurement mathematical model;mathematical models;sun;mathematical model;ontologies;vulnerability similarity measurement;vulnerability patching;vulnerability patching similarity measurement security vulnerabilities software vulnerabilities information security vulnerability similarity measurement vulnerabilities structural hierarchy mathematical models national vulnerability database vulnerability management ontology similarity calculation vulnerability classification vulnerability mitigation;similarity measure;security of data;vulnerabilities structural hierarchy;software vulnerabilities	As the number of software vulnerabilities increases year by year, software vulnerability becomes a focusing point in information security. This paper proposes a vulnerability similarity measurement to compare different vulnerabilities according to a set of criteria. Our approach is based on the structural hierarchy of vulnerabilities, and the similarity is defined using established mathematical models. The National Vulnerability Database and the Ontology of Vulnerability Management provide the information necessary for the similarity calculation. The similarity measurement can be used in many areas of vulnerability management, such as vulnerability classification, mitigation, and patching.	information security;mathematical model;national vulnerability database;patch (computing);vulnerability (computing);vulnerability management	Ju An Wang;Linfeng Zhou;Minzhe Guo;Hao Wang;Jairo Camargo	2010	2010 43rd Hawaii International Conference on System Sciences	10.1109/HICSS.2010.269	vulnerability management;vulnerability;computer science;information security;mathematical model;data mining;world wide web;computer security	SE	-56.163706455088324	47.77895667755405	106776
ca5c4ff113b7c7bee61b4bed1b8788da55299db7	deepdroid: dynamically enforcing enterprise policy on android devices.		It is becoming a global trend for company employees equipped with mobile devices to access company’s assets. Besides enterprise apps, lots of personal apps from various untrusted app stores may also be installed on those devices. To secure the business environment, policy enforcement on what, how, and when certain apps can access system resources is required by enterprise IT. However, Android, the largest mobile platform with a market share of 81.9%, provides very restricted interfaces for enterprise policy enforcement. In this paper, we present DeepDroid, a dynamic enterprise security policy enforcement scheme on Android devices. Different from existing approaches, DeepDroid is implemented by dynamic memory instrumentation of a small number of critical system processes without any firmware modification. DeepDroid can be easily deployed on various smartphone platforms with a wide range of Android versions. Moreover, based on the context information extracted from Binder interception, a fine-grained policy can be enforced. We develop a prototype of DeepDroid and test it on various smartphones and Android versions. The experimental results show that DeepDroid can effectively enforce enterprise resource access policies with negligible performance overhead.	android;critical system;dynamic enterprise;file binder;firmware;memory management;mobile device;overhead (computing);prototype;smartphone;system call	Xueqiang Wang;Kun Sun;Yuewu Wang;Jiwu Jing	2015		10.14722/ndss.2015.23263	real-time computing;internet privacy;computer security	Security	-54.87914355042412	58.482633991547374	106793
6f49fbe21753ebdca2bff4da581cced7f0419864	identifying devices of the internet of things using machine learning on clock characteristics		The number of devices of the so-called Internet of Things (IoT) is heavily increasing. One of the main challenges for operators of large networks is to autonomously and automatically identify any IoT device within the network for the sake of computer security and, subsequently, being able to better protect and secure those.		Pascal J. Oser;Frank Kargl;Stefan Lüders	2018		10.1007/978-3-030-05345-1_36	operator (computer programming);computer security;computer science;internet of things	HCI	-50.77077598664981	59.65736729186139	106812
590a8fd02b79bfc60add1680b47797b8f659ab31	sa3: automatic semantic aware attribution analysis of remote exploits		Web services have been greatly threatened by remote exploit code attacks, where maliciously crafted HTTP requests are used to inject binary code to compromise web servers and web applications. In practice, besides detection of such attacks, attack attribution analysis, i.e., to automatically categorize exploits or to determine whether an exploit is a variant of an attack from the past, is also very important. In this paper, we present SA, an exploit code attribution analysis which combines semantic analysis and statistical analysis to automatically categorize a given exploit code. SA extracts semantic features from an exploit code through data anomaly analysis, and then attributes the exploit to an appropriate class based on our statistical model derived from a Markov model. We evaluate SA over a comprehensive set of shellcode collected from Metasploit and other polymorphic engines. Experimental results show that SA is effective and efficient. The attribution analysis accuracy can be over 90% in different parameter settings with false positive rate no more than 4.5%. To our knowledge, SA is the first work combining semantic analysis with statistical analysis for exploit code attribution analysis.	anomaly detection;binary code;categorization;database normalization;exploit (computer security);markov chain;markov model;metasploit;shellcode;statistical model;web application;web server;web service	Deguang Kong;Donghai Tian;Peng Liu;Dinghao Wu	2011		10.1007/978-3-642-31909-9_11	web service;web application;data mining;shellcode;web server;statistical model;markov model;exploit;computer science;compromise	Security	-58.12825108649285	59.598656889467854	106859
b634f4f4ff14c87952ba2713faad763753d34684	time-traveling forensic analysis of vm-based high-interaction honeypots		Honeypots have proven to be an effective tool to capture computer intrusions (or malware infections) and analyze their exploitation techniques. However, forensic analysis of compromised honeypots is largely an ad-hoc and manual process. In this paper, we propose Timescope, a system that applies and extends recent advances in deterministic record and replay to high-interaction honeypots for extensible, fine-grained forensic analysis. In particular, we propose and implement a number of systematic analysis modules in Timescope, including contamination graph generator, transient evidence recoverer, shellcode extractor and break-in reconstructor, to facilitate honeypot forensics. These analysis modules can “travel back in time” to investigate various aspects of computer intrusions or malware infections during different execution time windows. We have developed Timescope based on the open-source QEMU virtual machine monitor and the evaluation with a number of real malware infections shows the practicality and effectiveness of Timescope.	client honeypot;dhrystone;hoc (programming language);honeypot (computing);hypervisor;ibm notes;malware;microsoft windows;open-source software;prototype;randomness extractor;reconstructor;run time (program lifecycle phase);shellcode;virtual machine	Deepa Srinivasan;Xuxian Jiang	2011		10.1007/978-3-642-31909-9_12	operating system;virtualization;shellcode;honeypot;malware;hypervisor;extensibility;extractor;computer science;graph	Security	-56.350850419617345	57.81119980761004	106961
63c796707e69d8efe6ee32e84aada8db0a00dd9c	man-in-the-middle attacks on auto-updating software	man in the middle attack	Many software packages today have the ability to perform automatic self-updates, typically via the Internet. Updates, in the form of executable files, are downloaded and then run, with the intent of “patching” an existing application. This presents a new security risk since there is no established standard for a protocol that performs the update process. This often leads developers to use proprietary schemes that have not been vetted for vulnerabilities. In this paper we analyze several software applications that have an auto-update feature. We also present two generic types of man-in-the-middle attacks that can subvert Hypertext Transfer Protocol (HTTP) downloads, which many auto-updating applications use, and show how these attacks can be tailored to exploit specific updating processes. In addition, we review some countermeasures, including Microsoft's Authenticode∗ technology. © 2007 Alcatel-Lucent.	code signing;countermeasure (computer);firefox;hypertext transfer protocol;internet explorer;javascript;malware;man-in-the-middle attack;microsoft windows;patch (computing);vulnerability (computing);winpcap;windows update	Bjoern M. Luettmann;Adam C. Bender	2007	Bell Labs Technical Journal	10.1002/bltj.20255	man-in-the-middle attack;telecommunications;computer science;engineering;operating system;internet privacy;world wide web;computer security;computer network	Security	-55.19585716533533	59.85725738224877	107098
8a0cd28363c8d88d175e618a081b7c426ff2f88d	risk-aware virtual resource management for multitenant cloud datacenters	lattices;rbac risk aware virtual resource management multitenant cloud datacenter virtualization feature cloud computing resource utilization big data application information leakage role based access control;resource management;risk management;vulnerability;virtualisation authorisation big data cloud computing computer centres resource allocation virtual machines;computer security;sensitivity;rbac;estimation;big data;virtual resources cloud computing rbac risk assessment vulnerability security;risk assessment;access control;cloud computing access control computer security sensitivity resource management big data bipartite graph risk management;security;bipartite graph;virtual resources;cloud computing	The multitenancy and virtualization features of cloud computing enhance resource utilization and lower the cloud provider's total cost of hosting customer data for big data applications. However, cloud computing has many security challenges that are exacerbated by virtual resource sharing. In particular, sharing resources among potentially untrusted tenants can increase the risk of information leakage due to vulnerability of virtual resources causing side channel attacks or virtual machine escape. For big data applications, an access control policy such as role-based access control (RBAC) can be used to control data sharing among cloud customers. This article aims to develop efficient risk-aware virtual resource assignment mechanisms for the cloud's multitenant environment. The authors present two resource assignment heuristics, including a scalable solution, and compare their relative performance.	big data;cloud computing;heuristic (computer science);information leakage;multitenancy;role-based access control;scalability;side-channel attack;spectral leakage;virtual machine escape	Abdulrahman Almutairi;Arif Ghafoor	2014	IEEE Cloud Computing	10.1109/MCC.2014.63	cloud computing security;risk assessment;estimation;big data;bipartite graph;cloud computing;risk management;sensitivity;vulnerability;computer science;information security;access control;resource management;lattice;role-based access control;database;world wide web;computer security	HPC	-50.12634586355051	57.57457135269538	107520
97aff6ee865fefad37eb9ea015dd9a889ff254d6	on-chip data security against untrustworthy software and hardware ips in embedded systems		State-of-the-art system-on-chip (SoC) field programmable gate arrays (FPGAs) integrate hard powerful ARM processor cores and the reconfigurable logic fabric on a single chip in addition to many commonly needed high performance and high-bandwidth peripherals. The increasing reliance on untrustworthy third-party IP (3PIP) cores, including both hardware and software in FPGA-based embedded systems has made the latter increasingly vulnerable to security attacks. Detection of trojans in 3PIPs is extremely difficult to current static detection methods since there is no golden reference model for 3PIPs. Moreover, many FPGA-based embedded systems do not have the support of security services typically found in operating systems. In this paper, we present our run-time, low-cost, and low-latency hardware and software based solution for protecting data stored in on-chip memory blocks, which has attracted little research attention. The implemented memory protection design consists of a hierarchical top-down structure and controls memory access from software IPs running on the processor and hardware IPs running in the FPGA, based on a set of rules or access rights configurable at run time. Additionally, virtual addressing and encryption of data for each memory help protect confidentiality of data in case of a failure of the memory protection unit, making it hard for the attacker to gain access to the data stored in the memory. The design is implemented and tested on the Intel (Altera) DE1-SoC board featuring a SoC FPGA that integrates a dual-core ARM processor with reconfigurable logic and hundreds of memory blocks. The experimental results and case studies show that the protection model is successful in eliminating malicious IPs from the system without need for reconfiguration of the FPGA. It prevents unauthorized accesses from untrusted IPs, while arbitrating access from trusted IPs generating legal memory requests, without incurring a serious area or latency penalty.	arm architecture;authorization;confidentiality;data security;embedded system;encryption;field-programmable gate array;information privacy;mpu-401;memory protection;multi-core processor;operating system;peripheral;reconfigurable computing;reference model;run time (program lifecycle phase);system on a chip;top-down and bottom-up design	SreeCharan Gundabolu;Xiaofang Wang	2018	2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2018.00122	system on a chip;embedded system;computer hardware;field-programmable gate array;virtual address space;encryption;data security;software;arm architecture;memory protection;computer science	Arch	-53.56552115297507	56.04160087024827	107532
5fed58229c221113fba95eb4ae4e44be67a94b92	automatic characterization of exploitable faults: a machine learning approach		Characterizing the fault space of a cipher to filter out a set of faults potentially exploitable for fault attacks (FA), is a problem with immense practical value. A quantitative knowledge of the exploitable fault space is desirable in several applications, such as security evaluation, cipher construction and implementation, design, testing of countermeasures, and so on. In this paper, we investigate this problem in the context of block ciphers. The formidable size of the fault space of a block cipher mandates the use of an automation strategy to solve this problem, which should be able to characterize each individual fault instance quickly. On the other hand, the automation strategy is expected to be applicable to most of the block cipher constructions. Existing techniques for automated fault attacks do not satisfy both of these goals simultaneously, and hence are not directly applicable in the context of exploitable fault characterization. In this paper, we present a supervised machine learning assisted automated framework, which successfully addresses both of the criteria mentioned. The key idea is to extrapolate the knowledge of some existing FAs on a cipher to rapidly figure out new attack instances. Experimental validation of this idea on two state-of-the-art block ciphers - PRESENT and LED - establishes that our approach is able to provide fairly good accuracy in identifying exploitable fault instances at a reasonable cost. Utilizing this observation, we propose a statistical framework for exploitable fault space characterization, which can provide an estimate of the success rate of an attacker corresponding to the given fault model and fault location. The framework also returns test vectors leading toward successful attacks. As a potential application, the effect of different S-Boxes on the fault space of a cipher is evaluated utilizing the framework.	algorithm;block cipher;countermeasure (computer);differential fault analysis;extrapolation;fault (technology);fault model;feedback arc set;hash function;introduction to algorithms;linear algebra;machine learning;overhead (computing);public-key cryptography;s-box;stream cipher;supervised learning	Sayandeep Saha;Dirmanto Jap;Sikhar Patranabis;Debdeep Mukhopadhyay;Shivam Bhasin;Pallab Dasgupta	2017	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2018.2868245	cipher;automation;fault model;block cipher;machine learning;computer science;artificial intelligence;countermeasure	Security	-60.61860479483425	52.451827595909755	107984
3c585aa3ffdec397f7a7df468e11427be1d37d0a	information security training customized by risk profile			information security	Shuting Xu;Peter Meso;Yi Ding	2016			reliability engineering;risk analysis;computer security	Crypto	-55.9741022882785	49.166180970633164	108518
ff4b85571f2849e1cc9ba6138c85f13daefae7ce	the air gap: scada's enduring security myth	enduring security myth;critical system;security strategy;air gap	Attempting to use isolation as a security strategy for critical systems is unrealistic in an increasingly connected world.	air gap (networking);critical systems thinking	Eric Byres	2013	Commun. ACM	10.1145/2492007.2492018	simulation;computer security	Security	-57.664592896854316	50.8730775882736	108580
bb40fad338d02e4fa122b23b021d402f22e951d9	both sides now: thinking about cloud security	virtualization;virtualization software;security of data cloud computing;safety net cloud security cloud computing;internet web technologies;computer security;internet;security and privacy;web services;cloud computing internet web services computer security privacy virtualization;virtualization software internet web technologies cloud computing cybersecurity security and privacy;cybersecurity;privacy;cloud computing	Will cloud computing be our undoing or will it be our safety net?	cloud computing security	Hilarie Orman	2016	IEEE Internet Computing	10.1109/MIC.2016.17	web service;cloud computing security;web application security;privacy software;the internet;virtualization;cloud computing;computer science;cloud testing;internet security;security service;utility computing;internet privacy;privacy;world wide web;computer security	Metrics	-49.359888175771125	58.16576173674595	108823
6662816b76542076318f59c05fe81a31cc47e512	fork bomb attack mitigation by process resource quarantine	random access memory;kernel;memory management;servers;linux;weapons	A fork bomb attack is a denial of service attack. An attacker generates many processes rapidly, exhausting the resources of the target computer systems. There are several previous work to detect and remove the processes that cause fork bomb attacks. However, the operating system with the previous methods have the risks to terminate inappropriate processes that do not fork bomb processes. In this paper, we propose a new method that named process resource quarantine. With the proposed method, the operating systems don't terminate the detected fork bomb processes. Instead of the termination, the operating systems make resource limitations for the detected processes and inspect them periodically. We implemented the proposed method on Linux kernel and executed several evaluation experiments. The results show that the proposed method is effective for fork bomb attacks mitigation.	brute-force search;denial-of-service attack;experiment;fork bomb;javaserver pages;linux;operating system;overhead (computing);terminate (software)	Gaku Nakagawa;Shuichi Oikawa	2016	2016 Fourth International Symposium on Computing and Networking (CANDAR)	10.1109/CANDAR.2016.0124	real-time computing;engineering;operating system;computer security	Security	-56.39699738022855	56.54732879075574	108906
be706a195fc433d545c63fb90cf0890005c65e82	on software standards and solutions for a trusted internet of things		We discuss a high-level model for software applications and services that can support a minimal set of human-centric trust management capabilities. We outline the unique set of challenges we must address if we are to attain a level of trust that will be required for a robust deployment of an IoT. We discuss the role of standards and how we can maximize the effectiveness of standards and device and service certification. We suggest a set of solutions for trust management that can support the unique security, safety, and privacy requirements of a robust IoT. Prominent among these solutions is the use of an older approach for access control, viz. the reference monitor, and blockchain technologies that can record trust and policy graphs and trust-related attributes for IoT devices and supporting services. An open, but governed trust blockchain can serve as a universal trusted oracle.	access control;bitcoin;high- and low-level;internet of things;reference monitor;requirement;software deployment;trust management (information system);viz: the computer game	David Paul Maher	2018			computer science;software engineering;knowledge management;software;internet of things	Security	-48.99006858200811	56.578725929662504	109149
0fe64c17082becb92b7fecd4ef200b9b60f828bb	a server- and browser-transparent csrf defense for web 2.0 applications	cross site request forgery;black box approach;service provider;web application security;state violation attack;source code;invariant	Cross-Site Request Forgery (CSRF) vulnerabilities constitute one of the most serious web application vulnerabilities, ranking fourth in the CWE/SANS Top 25 Most Dangerous Software Errors. By exploiting this vulnerability, an attacker can submit requests to a web application using a victim user's credentials. A successful attack can lead to compromised accounts, stolen bank funds or information leaks. This paper presents a new server-side defense against CSRF attacks. Our solution, called jCSRF, operates as a serverside proxy, and does not require any server or browser modifications. Thus, it can be deployed by a site administrator without requiring access to web application source code, or the need to understand it. Moreover, protection is achieved without requiring web-site users to make use of a specific browser or a browser plug-in. Unlike previous server-side solutions, jCSRF addresses two key aspects of Web 2.0: extensive use of client-side scripts that can create requests to URLs that do not appear in the HTML page returned to the client; and services provided by two or more collaborating web sites that need to make cross-domain requests.	authentication;client–server model;common weakness enumeration;credential;cross-site request forgery;html;information security;javascript;plug-in (computing);proxy server;server (computing);server-side;web 2.0;web application;web server	Riccardo Pelizzi;R. Sekar	2011		10.1145/2076732.2076768	service provider;web service;web application security;web development;comet;computer science;operating system;invariant;internet privacy;cross-site request forgery;world wide web;computer security;web server;mashup;source code	Security	-54.621888663904436	59.884238111716634	109183
94e9d8fd25668d1690575b9ca3b96c2bde10a5ad	a plant-wide industrial process control security problem		Industrial control systems are a vital part of the critical infrastructure. The potentially large impact of a failure makes them attractive targets for adversaries. Unfortunately, simplistic approaches to intrusion detection using protocol analysis or näıve statistical estimation techniques are inadequate in the face of skilled adversaries who can hide their presence with the appearance of legitimate actions. This paper describes an approach for identifying malicious activity that involves the use of a path authentication mechanism in combination with state estimation for anomaly detection. The approach provides the ability to reason conjointly over computational structures, and operations and physical states. The well-known Tennessee Eastman reference problem is used to illustrate the efficacy of the approach.	anomaly detection;authentication;code refactoring;computation;control system;estimation theory;forge;intrusion detection system;malware;proxy server;whole earth 'lectronic link	Thomas Richard McEvoy;Stephen D. Wolthusen	2011		10.1007/978-3-642-24864-1_4	control system security;computer security model;control engineering;computer security	Security	-60.29808638675665	60.44754626371677	109461
b9fe18201c4deedc212a899a978e253f8b85c14c	a portable user-level approach for system-wide integrity protection	clones;php;flaws;access control;measurements;security	In this paper, we develop an approach for protecting system integrity from untrusted code that may harbor sophisticated malware. We develop a novel dual-sandboxing architecture to confine not only untrusted, but also benign processes. Our sandboxes place only a few restrictions, thereby permitting most applications to function normally. Our implementation is performed entirely at the user-level, requiring no changes to the kernel. This enabled us to port the system easily from Linux to BSD. Our experimental results show that our approach preserves the usability of applications, while offering strong protection and good performance. Moreover, policy development is almost entirely automated, sparing users and administrators this cumbersome and difficult task.	bsd;data integrity;linux;malware;open-source software;redundancy (engineering);sandbox (computer security);software portability;system integrity;usability;user space	Wai-Kit Sze;R. Sekar	2013		10.1145/2523649.2523655	embedded system;computer science;information security;access control;operating system;cloning;world wide web;computer security;measurement	Security	-54.36360599662947	58.14328907171667	110008
0f20db96cc36954d2fd2f65ae2a96b5a4d691707	towards protected mpsoc communication for information protection against a malicious noc		Multiprocessor System-on-Chip (MPSoC) design is based on the integration of several thirdparty Intellectual Property (IP) cores. Some of those IPs may include Trojans, extra hardware that can be triggered during operation time in order to perform an attack. Network-on-Chip (NoC), the communication IP of MPSoCs, can include Trojans that spy, modify and constrain the sensitive communication inside the chip. Although previous works address the malicious NoC threat, finding secure and efficient solutions is still a challenge. In this work, we propose a novel and secure network interface which implements a tunnel-based protocol that enables the secure exchange of sensitive data even in the presence of a malicious NoC. We test our technique with synthetic traffic as well as in several real application scenarios, and show that it is a secure and efficient solution.	mpsoc;malware;multiprocessing;network interface;network on a chip;operation time;synthetic intelligence;trojan horse (computing)	Martha Johanna Sepúlveda;Andreas Zankl;Daniel Florez;Georg Sigl	2017		10.1016/j.procs.2017.05.139	mpsoc;chip;real-time computing;multiprocessing;computer science;information protection policy;network on a chip;network interface	Security	-53.42894816557596	55.8755653966049	110022
8dbf978b4ea6ed918eb06542b2134d01ca936dbc	mrkip: rootkit recognition with kernel function invocation pattern	dynamic analysis;data mining	Existing mechanisms tracing user-level activities such as system calls and APIs can be circumvented by the kernel-level rootkits. In this paper, a novel system, MrKIP, is proposed to recognize rootkits based on their kernel-level activities. Our scheme semiautomatically generates suitable locations for analysts to implement checkpoints, which are used to profile kernel-space activities. Then, collected rootkits are executed in an emulator with these checkpoints for behavior profiling. The collected behaviors are clustered and used for model construction. The constructed model can be used to recognize new variants of rootkit families. Our scheme differs from conventional tracers due to its ability to cover kernel-space malware and the whole-system scope. In addition, monitoring at the kernel level raises high barrier for malware to evade, since all tasks are eventually executed through the basic kernel functions.	emulator;kernel (operating system);malware;rootkit;system call;user space	Chi-Wei Wang;Chong Kuan Chen;Chia-Wei Wang;Shiuh-Pyng Shieh	2015	J. Inf. Sci. Eng.			Security	-56.804052763553216	58.05266576135339	110241
821345ff312cd22bdab43d110f4bf2ebae82cc2a	trusted platform modules in cyber-physical systems: on the interference between security and dependability		Cyber physical systems are the key innovation driver for many domains such as automotive, avionics, industrial process control, and factory automation. However, their interconnection potentially provides adversaries easy access to sensitive data, code, and configurations. If attackers gain control, material damage or even harm to people must be expected. To counteract data theft, system manipulation and cyber-attacks, security mechanisms must be embedded in the cyber physical system. Adding hardware security in the form of the standardized Trusted Platform Module (TPM) is a promising approach. At the same time, traditional dependability features such as safety, availability, and reliability have to be maintained. To determine the right balance between security and dependability it is essential to understand their interferences. This paper supports developers in identifying the implications of using TPMs on the dependability of their system.We highlight potential consequences of adding TPMs to cyber-physical systems by considering the resulting safety, reliability, and availability. Furthermore, we discuss the potential of enhancing the dependability of TPM services by applying traditional redundancy techniques.	accessibility;application security;avionics;cyber-physical system;data theft;dependability;embedded system;interconnection;interference (communication);record sealing;reliability engineering;requirement;trust anchor;trusted computing;trusted platform module	Andrea Höller;Ronald Toegl	2018	2018 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)	10.1109/EuroSPW.2018.00026	cyber-physical system;automation;reliability engineering;computer science;data theft;computer network;redundancy (engineering);process control;hardware security module;trusted platform module;dependability	Security	-56.138927084988374	50.8680153191217	110615
914716b5151430a33f47868fa88202533ca83849	security analysis of open building automation systems	security analysis;network security;building automation;embedded networks;security requirements;building automation systems;security;communication service	With the integration of security-critical services into Building Automation Systems (BAS), the demands on the underlying network technologies increase rapidly. Relying on physically isolated networks and on “Security by Obscurity”, as it is still common today, is by no means an adequate solution. To be reliable and robust against malicious manipulations, the used communication services must support advanced security mechanisms that counteract potential security threats. This paper identifies important security requirements and challenges within the building automation domain. Based on this analysis, state-of-the-art technologies are carefully examined. Finally, an outlook on advanced security concepts is given.	automation;bacnet;broadcast auxiliary service;cryptography;denial-of-service attack;domain-specific language;knx (standard);key (cryptography);key management;key server (cryptographic);lonworks;microsoft outlook for mac;multi-function printer;requirement;secure communication;security through obscurity;server (computing);single point of failure	Wolfgang Granzer;Wolfgang Kastner	2010		10.1007/978-3-642-15651-9_23	software security assurance;control system security;computer security model;cloud computing security;security through obscurity;security information and event management;security engineering;security convergence;building automation;covert channel;asset;computer science;systems engineering;engineering;information security;network security;security service;security analysis;security testing;network access control;network security policy;computer security;computer network	Security	-50.7062017584732	56.81537179736216	110884
4fef8b9106b0518092f34b235a4767a06f4e5571	forensic application-fingerprinting based on file system metadata	digital forensics;event reconstruction;application fingerprinting;digital investigation;event reconstruction application fingerprinting digital investigation digital forensics;fingerprint recognition hard disks electronic mail file systems digital forensics;meta data;automatic action reconstruction forensic application file system metadata digital evidence extraction digital evidence acquisition automatic event reconstruction forensic event reconstruction automatic file system fingerprint computation ntfs timestamps;meta data digital forensics	While much work has been invested in tools for aquisition and extraction of digital evidence, there are only few tools that allow for automatic event reconstruction. In this paper, we present a generic approach for forensic event reconstruction based on digital evidence from file systems. Our approach applies the idea of fingerprinting to changes made by applications in file system metadata. We present a system with which it is possible to automatically compute file system fingerprints of individual actions. Using NTFS timestamps as an example, we show that with our approach it is possible to automatically reconstruct actions performed by different applications even if the set of files accessed by those actions overlap.	android;digital data;disk image;encase;fingerprint (computing);html;human-readable medium;list of toolkits;machine learning;mobile app;operating system;parsing;prototype;regular expression;smartphone;the sleuth kit;user (computing);xml;xslt;ios	Sven Kalber;Andreas Dewald;Felix C. Freiling	2013	2013 Seventh International Conference on IT Security Incident Management and IT Forensics	10.1109/IMF.2013.20	computer science;database;internet privacy;world wide web;design rule for camera file system	OS	-57.01935724680971	59.49740249246954	111010
cdf3031266488e22e596fe54be30614d46c58e7a	resilience, a key property of infrastructure cps	energy measurement resilience tutorials cyber physical systems computer security;cyber security testbed infrastructure cps information network control strategy design energy network security threats cyber physical systems deter networking;cyber physical systems;computer security;security of data control engineering computing control system synthesis cyber physical systems;resilience;energy measurement;tutorials	The information network plays a crucial role in the stability of infrastructure CPS. The adoption of measurements and networked control technologies provide timely measurements that can be used to design control strategies for the stability of the energy network during a failure or a fault. However, these technologies have also significantly increased the exposure to novel security threats and risks. This tutorial will present case studies for methodological security and resiliency assessment for infrastructure cyber-physical systems on the DETER networking and cyber security testbed.	computer security;cyber-physical system;testbed	Alefiya Hussain	2016	2016 American Control Conference (ACC)	10.1109/ACC.2016.7525320	control system security;computer security model;cloud computing security;simulation;security information and event management;asset;computer science;engineering;security service;security analysis;cyber-physical system;network access control;network security policy;computer security;psychological resilience;information security management;computer network	EDA	-57.08319166450077	50.613783045807295	111106
cc1f7fde8794c3d16b732c63f9e55aae9c76b0ee	slot games for detecting timing leaks of programs		In this paper we describe a method for verifying secure information flow of programs, where apart from direct and indirect flows a secret information can be leaked through covert timing channels. That is, no two computations of a program that differ only on high-security inputs can be distinguished by low-security outputs and timing differences. We attack this problem by using slot-game semantics for a quantitative analysis of programs. We show how slot-games model can be used for performing a precise security analysis of programs, that takes into account both extensional and intensional properties of programs. The practicality of this approach for automated verification is also shown.	computation;covert channel;formal verification;game semantics;game theory;information theory;intensional logic;interference (communication);memory leak;non-interference (security);observable;refinement (computing);slot 1;timing channel;verification and validation	Aleksandar Dimovski	2013		10.4204/EPTCS.119.15	simulation;computer science;distributed computing;programming language;computer security;algorithm	Security	-54.41914487344835	52.31382660185897	111189
36ac9fb3baff2fb259afb44536def89e1d969048	reverse engineering of database security policies		Security is a critical concern for any database. Therefore, database systems provide a wide range of mechanisms to enforce security constraints. These mechanisms can be used to implement part of the security policies requested of an organization. Nevertheless, security requirements are not static, and thus, implemented policies must be changed and reviewed. As a first step, this requires to discover the actual security constraints being enforced by the database and to represent them at an appropriate abstraction level to enable their understanding and reenginering by security experts. Unfortunately, despite the existence of a number of techniques for database reverse engineering, security aspects are ignored during the process. This paper aims to cover this gap by presenting a security metamodel and reverse engineering process that helps security experts to visualize and manipulate security policies in a vendor-independent manner.		Salvador Martínez Perez;Valerio Cosentino;Jordi Cabot;Frédéric Cuppens	2013		10.1007/978-3-642-40173-2_37	software security assurance;computer security model;cloud computing security;countermeasure;security through obscurity;security information and event management;security engineering;covert channel;asset;computer science;security policy;information security standards;data mining;database;security service;security testing;world wide web;computer security	DB	-51.804768109123835	52.276766128545006	111496
72aeb5b3ed0f8fff20cc0d408a7ffb34ac3498d0	proclick: a framework for testing clickjacking attacks in web applications	proxy;iframe;ui redressing;clickjacking;proclick;x frame options	Clickjacking attacks are an emerging threat on the web. An attacker application presents a User Interface (UI) element of a target application out of context, such as hiding sensitive UI element by making it transparent to the end user. The user is tricked to click on the hidden element out of context. These attacks can cause severe damages such as compromising webcams and posting unintended messages. A large number of websites are still vulnerable to clickjacking and have no minimal protection at the server side (e.g., frame busting, X-Frame-Options header). Further, client-side defense techniques have been ineffective to deal with sophisticated clickjacking attack types and suffer from performance issues. This paper presents a proxy-level framework, ProClick, to detect clickjacking attacks. ProClick examines the content of requests and response pages at the proxy level to detect clickjacking attacks. We evaluate the proposed approach with a set of legitimate and malicious websites. The results indicate that our approach has low false positive and false negative rates. The overhead imposed by the proposed approach is also very negligible.	applet;clickjacking;client-side;drag and drop;framekiller;javascript;malware;overhead (computing);sensor;server (computing);server-side;user interface;web application;webcam	Hossain Shahriar;Vamshee Krishna Devendran;Hisham M. Haddad	2013		10.1145/2523514.2523538	computer science;internet privacy;clickjacking;world wide web;computer security	Security	-55.46189868050706	60.4183629530414	111529
0b7966a31a222446f204290aa490768e6541a8ef	principled sampling for anomaly detection		Anomaly detection plays an important role in protecting computer systems from unforeseen attack by automatically recognizing and filter atypical inputs. However, it can be difficult to balance the sensitivity of a detector – an aggressive system can filter too many benign inputs while a conservative system can fail to catch anomalies. Accordingly, it is important to rigorously test anomaly detectors to evaluate potential error rates before deployment. However, principled systems for doing so have not been studied – testing is typically ad hoc, making it difficult to reproduce results or formally compare detectors. To address this issue we present a technique and implemented system, Fortuna, for obtaining probabilistic bounds on false positive rates for anomaly detectors that process Internet data. Using a probability distribution based on PageRank and an efficient algorithm to draw samples from the distribution, Fortuna computes an estimated false positive rate and a probabilistic bound on the estimate’s accuracy. By drawing test samples from a well defined distribution that correlates well with data seen in practice, Fortuna improves on ad hoc methods for estimating false positive rate, giving bounds that are reproducible, comparable across different anomaly detectors, and theoretically sound. Experimental evaluations of three anomaly detectors (SIFT, SOAP, and JSAND) show that Fortuna is efficient enough to use in practice — it can sample enough inputs to obtain tight false positive rate bounds in less than 10 hours for all three detectors. These results indicate that Fortuna can, in practice, help place anomaly detection on a stronger theoretical foundation and help practitioners better understand the behavior and consequences of the anomaly detectors that they deploy. As part of our work, we obtain a theoretical result that may be of independent interest: We give a simple analysis of the convergence rate of the random surfer process defining PageRank that guarantees the same rate as the standard, second-eigenvalue analysis, but does not rely on any assumptions about the link structure of the web.	algorithm;anomaly detection;fortuna (prng);hoc (programming language);pagerank;rate of convergence;soap;sensor;software deployment	Brendan Juba;Christopher Musco;Fan Long;Stelios Sidiroglou;Martin C. Rinard	2015			data mining;computer security;algorithm	Security	-59.77708921935706	59.57442162188776	112032
c408ff4c0305dce3ac1198d58cb3f4f974405e99	a cloud-based architecture for home network system	scaling home network system cloud based architecture virtual machine security isolation;software;virtual machine;servers home appliances security computer architecture home automation software sensors;sensors;home automation cloud computing data privacy file servers;home appliances;security isolation;dynamic scaling cloud based architecture home network system hns lite house cloud service provider multitenant saas based solution security privacy violation failure propagation insufficient resource demand virtual home server;computer architecture;servers;scaling;security;home network system;cloud based architecture;home automation	Managing a home server within individual house is a major obstacle to practical use of home network system (HNS). Delegating the home server to a cloud is a promising approach. However, the conventional multitenant SaaS-based solution has the following risks among different households: security/privacy violation, failure propagation and insufficient resource demand. In this paper, we propose a novel cloud-based architecture for the home network system that achieves security isolation, fault isolation and resource isolation. Specifically, we first create a virtual home server for every household using IaaS. On top of every virtual home server, we then create additional virtual machines, each of which contains a single service or application. Finally, using dynamic scaling, we allocate resources needed for individual virtual home servers. Based on the idea, we construct the proposed architecture by three layers: HNS Lite, House Cloud and Service Provider.	adobe flash lite;error detection and correction;fault detection and isolation;hardware virtualization;home server;image scaling;multitenancy;server (computing);software as a service;software propagation;virtual machine;virtual private server;x86 virtualization	Satoshi Takatori;Shinsuke Matsumoto;Sachio Saiki;Seiki Tokunaga;Junho Lee;Masahide Nakamura	2014	2014 IEEE 6th International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2014.125	embedded system;home automation;scaling;computer science;sensor;virtual machine;information security;operating system;world wide web;computer security;server	HPC	-51.377801817753046	57.151343570241536	112186
70ae295b9a7696f2d0c2fdb3a7a53f0d0e0a9320	using replicated execution for a more secure and reliable web browser		Modern web browsers are complex. They provide a high-performance and rich computational environment for web-based applications, but they are prone to numerous types of security vulnerabilities that attackers actively exploit. However, because major browser platforms differ in their implementations they rarely exhibit the same vulnerabilities. In this paper we present Cocktail, a system that uses three different off-the-shelf web browsers in parallel to provide replicated execution for withstanding browserbased attacks and improving browser reliability. Cocktail mirrors inputs to each replica and votes on browser states and outputs to detect potential attacks, while continuing to run. The net effect of Cocktail’s architecture is to shift the security burden of the system from complex browsers to a simplified layer of software. We demonstrate that Cocktail can withstand real-world browser exploits and reliability issues, such as browser crashes, while adding only 31.5% overhead to page load latency times on average, and remaining compatible with popular web sites.	browser exploit;computation;overhead (computing);vulnerability (computing);web application	Hui Xue;Nathan Dautenhahn;Samuel T. King	2012			web page;comet (programming);implementation;software;world wide web;architecture;computer science;the internet;exploit;client-side scripting	Security	-55.17037311441375	59.584028819017405	112428
d0796aba433656b273c12e79f8144bd99861438d	scap benchmark for cisco router security configuration compliance	security automation scap benchmark xccdf oval security compliance;nist;policy compliance evaluation scap benchmark cisco router security configuration compliance information security management security content automation protocol vulnerability measurement;security benchmark testing automation operating systems nist;security of data business data processing formal specification;security;benchmark testing;operating systems;automation	Information security management is time-consuming and error-prone. Apart from day-to-day operations, organizations need to comply with industrial regulations or government directives. Thus, organizations are looking for security tools to automate security management tasks and daily operations. Security Content Automation Protocol (SCAP) is a suite of specifications that help to automate security management tasks such as vulnerability measurement and policy compliance evaluation. SCAP benchmark provides detailed guidance on setting the security configuration of network devices, operating systems, and applications. Organizations can use SCAP benchmark to perform automated configuration compliance assessment on network devices, operating systems, and applications. This paper discusses SCAP benchmark components and the development of a SCAP benchmark for automating Cisco router security configuration compliance.	benchmark (computing);cognitive dimensions of notations;information security;operating system;router (computing);security content automation protocol;security management	Chit Nyi Nyi Hlyne;Pavol Zavarsky;Sergey Butakov	2015	2015 10th International Conference for Internet Technology and Secured Transactions (ICITST)	10.1109/ICITST.2015.7412104	computer security model;standard of good practice;cloud computing security;reliability engineering;embedded system;certified information systems security professional;security information and event management;engineering;security service;computer security	OS	-55.14587870822915	50.643609623792656	112451
245ce0e8acc88a095f8e1564e93fb29a65d59616	chaff bugs: deterring attackers by making software buggier.		Sophisticated attackers find bugs in software, evaluate their exploitability, and then create and launch exploits for bugs found to be exploitable. Most efforts to secure software attempt either to eliminate bugs or to add mitigations that make exploitation more difficult. In this paper, we introduce a new defensive technique called chaff bugs, which instead target the bug discovery and exploit creation stages of this process. Rather than eliminating bugs, we instead add large numbers of bugs that are provably (but not obviously) non-exploitable. Attackers who attempt to find and exploit bugs in software will, with high probability, find an intentionally placed non-exploitable bug and waste precious resources in trying to build a working exploit. We develop two strategies for ensuring non-exploitability and use them to automatically add thousands of non-exploitable bugs to real-world software such as nginx and libFLAC; we show that the functionality of the software is not harmed and demonstrate that our bugs look exploitable to current triage tools. We believe that chaff bugs can serve as an effective deterrent against both human attackers and automated Cyber Reasoning Systems (CRSes).	application security;exploit (computer security);prototype;software bug;with high probability	Zhenghao Hu;Yu Hu;Brendan Dolan-Gavitt	2018	CoRR		chaff;computer security;computer science;software;exploit	Security	-58.35031921049245	57.52182727433263	112708
af96b385f5ee3f06aea9dd2e5e59d2ffe3f5d437	winsend: windows secure neighbor discovery	security and protection;neighbor discovery protocol ndp;network interface card;ipv6 security and protection;cryptographically generated addresses cga;user interface;data transmission systems;computer networks;send implementation;operating system;neighbor discovery;object oriented methods computer science;computer network protocols;article;space application	Neighbor Discovery Protocol (NDP) is an essential protocol in IPv6 suite, but it is known to be vulnerable to critical attacks. Thus, SEcure Neighbor Discovery (SEND) is proposed to counter NDP security threats. Unfortunately, operating systems lack the sophisticated implementations for SEND. There is limited success with SEND implementation for Linux and BSD, and no implementation for Windows families. Therefore, the majority of the users are not secured with SEND. In this paper, we will introduce an implementation of SEND for Windows families (WinSEND). WinSEND is a user-space application which provides the protection for NDP in Windows. It has direct access to Network Interface Card (NIC) and efficiently handles NDP messages by using Winpcap. WinSEND works as a service with easy user interface to set the security parameters for selected NIC.	bsd;linux;microsoft windows;network interface controller;operating system;random access;secure neighbor discovery;user interface;user space;winpcap	Hosnieh Rafiee;Ahmad AlSa'deh;Christoph Meinel	2011		10.1145/2070425.2070469	neighbor discovery protocol;computer science;network interface controller;user interface;world wide web;computer security;computer network	Security	-53.66107753950303	59.314950399648396	112940
69f14e29f8db3b8ea147389211c31177ce5b9e8a	surreptitiously weakening cryptographic systems		Revelations over the past couple of years highlight the importance of understanding malicious and surreptitious weakening of cryptographic systems. We provide an overview of this domain, using a number of historical examples to drive development of a weaknesses taxonomy. This allows comparing different approaches to sabotage. We categorize a broader set of potential avenues for weakening systems using this taxonomy, and discuss what future research is needed to provide sabotage-resilient cryptography.	categorization;cryptography;malware;taxonomy (general)	Bruce Schneier;Matt Fredrikson;Tadayoshi Kohno;Thomas Ristenpart	2015	IACR Cryptology ePrint Archive			Security	-61.315037658587464	57.70700091249528	113013
e061a811595dea5a9a1a630db96e432caa40dd61	discovery of c++ data structures from binaries	hypervisor;z;circus refinement;csp;source code;program analysis;information flow security;data structure;open source;intermediate representation	This extended abstract presents the techniques to identify C++ data structures in binary executables. With respect to automated tools, this is a largely open problem and generally requires significant manual intervention, inspection, and tracing to establish. The techniques for manual evaluation of C++ data structures are well known, but tedious. Because of this manual handling, the results are error prone and sensitive to the time available and experience of the analyst. All of our work is accomplished using the ROSE compiler infrastructure.  ROSE is an open source compiler infrastructure that handles source code, and also binary executables. Uniquely ROSE handles binary executables much like source code, parsing them to identify and represent their internal parts in an intermediate representation (IR), disassembling the appropriate segments containing instructions, defining a number of standard forms of program analysis, and permitting users to define there own specialized forms of analysis. The work to reconstruct C++ data structures is part of larger work that reconstructs all the data used in the binary more generally.	c++;cognitive dimensions of notations;compiler;data structure;executable;intermediate representation;manual handling of loads;open-source software;parsing;program analysis;rose;tracing (software)	Daniel Quinlan;Cory Cohen	2010		10.1145/1852666.1852743	real-time computing;computer science;operating system;database	PL	-57.0543621519278	55.238780574425554	113054
30808164e0c0837b6be9ad5323e6e1cde477961b	architecting cyber defense: a survey of the leading cyber reference architectures and frameworks		The rapid development of cyber threats and intelligence challenges the traditional design of static cyber defense platforms. This paper discusses the need for an agile structure to inform the development of cybersecurity solutions that are not only widely adaptable to unknown threats, specific business practices, and technical requirements, but are also efficiently translatable to products. It employs a systems engineering approach in the evaluation of several Reference Architectures for cyber defense that were gathered from the both the public and private sector. The Northrop Grumman Cyber Defense Reference Architecture is introduced in this paper to go beyond basic cyber hygiene by focusing on cognitive tasks through functional implementations of advanced analytics and automation. The limitations of frameworks, design patterns, and security control checklists in comparison to reference architectures are also discussed.	agile software development;computer security;cyber hygiene;design pattern;reference architecture;requirement;systems engineering;threat (computer)	Risa Savold;Natalie Dagher;Preston Frazier;Dennis McCallam	2017	2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud)	10.1109/CSCloud.2017.37	computer science;automation;implementation;computer security;reference architecture;agile software development;software design pattern;cloud computing;security controls;analytics	SE	-57.07146682599191	49.550509374059544	113082
c23221facd684d23f599f19a8afc2abaf659d0d9	security challenges in embedded systems	embedded system;computer security;embedded systems;security;communication system security	Embedded systems security is a significant requirement in emerging environments, considering the increasing deployment of embedded systems in several application domains. The large number of deployed embedded systems, their limited resources and their increasing complexity render systems vulnerable to an increasing number of threats. Additionally, the involvement of sensitive, often private, information and the expectation for safe and dependable embedded platforms lead to strong security requirements, even legal ones, which require new technologies for their provision. In this article, we provide an overview of embedded security issues, used methods and technologies, identifying important challenges in this emerging field.	embedded system;requirement;software deployment;threat (computer)	Dimitrios N. Serpanos;Artemios G. Voyiatzis	2013	ACM Trans. Embedded Comput. Syst.	10.1145/2435227.2435262	computer security model;cloud computing security;embedded system;real-time computing;security through obscurity;security information and event management;asset;computer science;information security;security service;distributed computing;security testing;computer security	Embedded	-50.869002183458505	56.53938194189711	113206
c8850de84006aa645f84253819df8fa4781c1d68	verification of temporal-epistemic properties of access control systems	t technology general;za information resources;qa75 electronic computers computer science;qa76 computer software	Verification of access control systems against vulnerabilities has always been a challenging problem in the world of computer security. The complication of security policies in largescale multi-agent systems increases the possible existence of vulnerabilities as a result of mistakes in policy definition. This thesis explores automated methods in order to verify temporal and epistemic properties of access control systems. While temporal property verification can reveal a considerable number of security holes, verification of epistemic properties in multi-agent systems enable us to infer about agents’ knowledge in the system and hence, to detect unauthorized information flow. This thesis first presents a framework for knowledge-based verification of dynamic access control policies. This framework models a coalition-based system, which evaluates if a property or a goal can be achieved by a coalition of agents restricted by a set of permissions defined in the policy. Knowledge is restricted to the information that agents can acquire by reading system information in order to increase time and memory efficiency. The framework has its own model-checking method and is implemented in Java and released as an open source tool named PoliVer. In order to detect information leakage as a result of reasoning, the second part of this thesis presents a complimentary technique that evaluates access control policies over temporal-epistemic properties where the knowledge is gained by reasoning. We will demonstrate several case studies for a subset of properties that deal with reasoning about knowledge. To increase the efficiency, we develop an automated abstraction refinement technique for evaluating temporal-epistemic properties. For the last part of the thesis, we develop a sound and complete algorithm in order to identify information leakage in Datalog-based trust management systems.	access control;algorithm;authorization;computer security;control system;datalog;file system permissions;information leakage;java;model checking;multi-agent system;open-source software;refinement (computing);spectral leakage;system information (windows);trust management (information system);vulnerability (computing)	Masoud Koleini	2012			simulation;computer science;theoretical computer science;data mining	AI	-54.12346582738308	52.61705220394697	113400
741f229964f6323ade49d1629ce382c5d4147a4f	verifying compliance of trusted programs	mandatory access control;policy enforcement;system security;access control models	In this paper, we present an approach for verifying that trusted programs correctly enforce system security goals when deployed. A trusted program is trusted to only perform safe operations despite have the authority to perform unsafe operations; for example, initialization programs, administrative programs, root network daemons, etc. Currently, these programs are trusted without concrete justification. The emergence of tools for building programs that guarantee policy enforcement, such as security-typed languages (STLs), and mandatory access control systems, such as user-level policy servers, finally offers a basis for justifying trust in such programs: we can determine whether these programs can be deployed in compliance with the reference monitor concept. Since program and system policies are defined independently, often using different access control models, compliance for all program deployments may be difficult to achieve in practice, however. We observe that the integrity of trusted programs must dominate the integrity of system data, and use this insight, which we call the PIDSI approach, to infer the relationship between program and system policies, enabling automated compliance verification. We find that the PIDSI approach is consistent with the SELinux reference policy for its trusted programs. As a result, trusted program policies can be designed independently of their target systems, yet still be deployed in a manner that ensures enforcement of system security goals.	computer security;control system;daemon (computing);emergence;mandatory access control;reference monitor;selinux;trusted operating system;user space;verification and validation	Sandra Julieta Rueda;Dave King;Trent Jaeger	2008			real-time computing;simulation;computer science;computer security	Security	-53.828468002575505	53.81782676886094	113443
c5d8911c4229318e088e561aabf94182b28218aa	insider threats in emerging mobility-as-a-service scenarios		Mobility as a Service (MaaS) applies the everything-asa-service paradigm of Cloud Computing to transportation: a MaaS provider offers to its users the dynamic composition of solutions of different travel agencies into a single, consistent interface. Traditionally, transits and data on mobility belong to a scattered plethora of operators. Thus, we argue that the economic model of MaaS is that of federations of providers, each trading its resources to coordinate multi-modal solutions for mobility. Such flexibility comes with many security and privacy concerns, of which insider threat is one of the most prominent. In this paper, we follow a tiered structure — from individual operators to markets of federated MaaS providers — to classify the potential threats of each tier and propose the appropriate countermeasures, in an effort to mitigate the problems.	cloud computing;countermeasure (computer);experiment;insider threat;modal logic;multitier architecture;privacy;programming paradigm;provisioning;small;service-oriented architecture;service-oriented infrastructure;software deployment;stack machine;tracing (software)	Franco Callegati;Saverio Giallorenzo;Andrea Melis;Marco Prandini	2017	CoRR		computer science;authentication;internet privacy;world wide web;computer security	Security	-48.58239727980188	57.3764716575489	113508
34a3d95f968e934af4493d1b63cd87137ac54f68	system security requirements analysis: a smart grid case study	smart grid;system of systems security requirements analysis	One of the main concerns in development and operation of mission-critical systems is system security. It is of critical importance to properly specify and implement system security requirements. In this paper, we apply a system security requirements analysis method to elicit, specify, categorize, and prioritize the system security requirements on the smart grid as a complex system-of-systems case study. In particular, we apply the Security Quality Requirements Engineering (SQUARE) method as a representative system security requirements analysis method. The main contributions of this research are the smart grid customer domain security requirements specification and its analysis from the system-of-systems perspective. We elicited a large proportion of system and system-of-systems vulnerabilities and requirements, and used them to specify secure smart grid intersystem interactions. © 2013 Wiley Periodicals, Inc. Syst Eng 17: 77–88, 2014	categorization;complex system;computer security;interaction;john d. wiley;mission critical;requirement;requirements analysis;requirements engineering;software requirements specification;system of systems;vulnerability (computing)	Nauman Zafar;Edin Arnautovic;Ali H. Diabat;Davor Svetinovic	2014	Systems Engineering	10.1002/sys.21252	computer security model;cloud computing security;reliability engineering;requirements analysis;software requirements specification;requirements management;security information and event management;economics;security engineering;systems engineering;engineering;logical security;system requirements specification;security service;smart grid;non-functional testing;security testing;computer security;non-functional requirement	SE	-54.672165063285206	48.106806268949235	113581
907747eb642dd6d6485a625c403f38fb7bfb1dcf	fine-grained access control via policy-carrying data		We address the problem of associating access policies with datasets and how to monitor compliance via policy-carrying data. Our contributions are a formal model in first-order logic inspired by normative multi-agent systems to regulate data access, and a computational model for the validation of specific use cases and the verification of policies against criteria. Existing work on access policy identifies roles as a key enabler, with which we concur, but much of the rest focusses on authentication and authorization technology. Our proposal aims to address the normative principles put forward in Berners-Lee’s bill of rights for the internet, through human-readable but machine-processable access control policies.		Julian Padget;Wamberto Weber Vasconcelos	2018	ACM Trans. Internet Techn.	10.1145/3133324	computer science;the internet;data mining;access control;privacy policy;data access;data sharing;authentication;action language;computer access control	Security	-49.04885602228955	53.485118449472786	113616
ada4fc3d8567e3d5c2ec2dc058e182886775ebbf	secure monitoring for identity federations and distributed systems	protocols;standards organizations;security of data internet;accounting;internet secure monitoring identity federations distributed systems generic user accounts security issues system administrators external third parties;testing;servers;one time passwords identity federations distributed systems monitoring security accounting;internet;monitoring;monitoring security organizations protocols standards organizations servers testing;organizations;distributed systems;identity federations;security;security of data;one time passwords	Generic user accounts are a traditional method used to test the behavior of complex applications and services. But their use tends to raise several security issues and considerations that must be addressed. When this kind of accounts are used inside the organization, system administrators can provide mechanisms to mitigate their impact on security, but when the accounts must be shared with external third-parties, they become more difficult to manage and security is usually forgotten in order to make things work.	distributed computing;federated identity;system administrator;user (computing)	Miguel Macías Enguídanos;Jaime Pérez Crespo	2012	2012 IEEE 36th Annual Computer Software and Applications Conference Workshops	10.1109/COMPSACW.2012.23	communications protocol;the internet;computer science;organization;information security;operating system;software testing;internet privacy;one-time password;world wide web;computer security;server	EDA	-51.5557806655295	58.15740907211056	113687
ece20a41b6ecb34f1c004d52b764bb115d4e8a39	a dynamical implementation of the stockholm resilience center 'safe operating space' model			dynamical system	Jack Horner	2010			simulation;psychological resilience;distributed computing;computer science	HPC	-58.09802816761987	51.70421162730315	113813
15921484ef80b0dfb6629f6fae7b5c9b8c8877e7	killed by proxy: analyzing client-end tls interce.		To filter SSL/TLS-protected traffic, some antivirus and parental-control applications interpose a TLS proxy in the middle of the host’s communications. We set out to analyze such proxies as there are known problems in other (more matured) TLS processing engines, such as browsers and common TLS libraries. Compared to regular proxies, client-end TLS proxies impose several unique constraints, and must be analyzed for additional attack vectors; e.g., proxies may trust their own root certificates for externally-delivered content and rely on a custom trusted CA store (bypassing OS/browser stores). Covering existing and new attack vectors, we design an integrated framework to analyze such client-end TLS proxies. Using the framework, we perform a thorough analysis of eight antivirus and four parentalcontrol applications for Windows that act as TLS proxies, along with two additional products that only import a root certificate. Our systematic analysis uncovered that several of these tools severely affect TLS security on their host machines. In particular, we found that four products are vulnerable to full server impersonation under an active man-in-the-middle (MITM) attack out-of-the-box, and two more if TLS filtering is enabled. Several of these tools also mislead browsers into believing that a TLS connection is more secure than it actually is, by e.g., artificially upgrading a server’s TLS version at the client. Our work is intended to highlight new risks introduced by TLS interception tools, which are possibly used by millions of users.	antivirus software;library (computing);man-in-the-middle attack;microsoft windows;operating system;out of the box (feature);root certificate;server (computing);transport layer security	Xavier de Carné de Carnavalet;Mohammad Mannan	2016			internet privacy;computer security;computer science	Security	-55.13200354522877	59.760188894776306	114109
4940684105d6c57783f77a99e690334b80abf84f	study of hardware trojans based security vulnerabilities in cyber physical systems		The dependability of Cyber Physical Systems (CPS) solely lies in the secure and reliable functionality of their backbone, the computing platform. Security of this platform is not only threatened by the vulnerabilities in the software peripherals, but also by the vulnerabilities in the hardware internals. Such threats can arise from malicious modifications to the integrated circuits (IC) based computing hardware, which can disable the system, leak information or produce malfunctions. Such modifications to computing hardware are made possible by the globalization of the IC industry, where a computing chip can be manufactured anywhere in the world. In the complex computing environment of CPS such modifications can be stealthier and undetectable. Under such circumstances, design of these malicious modifications, and eventually their detection, will be tied to the functionality and operation of the CPS. So it is imperative to address such threats by incorporating security awareness in the computing hardware design in a comprehensive manner taking the entire system into consideration. In this paper, we present a study in the influence of hardware Trojans on closed-loop systems, which form the basis of CPS, and establish threat models. Using these models, we perform a case study on a critical CPS application, gas pipeline based SCADA system. Through this process, we establish a completely virtual simulation platform along with a hardware-in-the-loop based simulation platform for implementation and testing.	computer hardware;cyber-physical system;dependability;hardware trojan;hardware-in-the-loop simulation;imperative programming;integrated circuit;internet backbone;internet of things;peripheral;scalability;security awareness;threat model;trojan horse (computing);vulnerability (computing)	Karthikeyan Lingasubramanian;Ranveer Kumar;Nagendra Babu Gunti;Thomas H. Morris	2018	2018 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2018.8326180	chip;computer hardware;computer science;cyber-physical system;software;threat model;security awareness;integrated circuit;dependability;scada	EDA	-56.68666518456417	52.168132638264375	114848
1e485c628089bf2515d38814cae8f13057f30383	trade-off analysis of misuse case-based secure software architectures: a case study	information system;software architecture	Based on the threat-driven architectural design of secure information systems, this paper introduces an approach for the tradeoff analysis of secure software architectures in order to determine the effects of security requirements on the system. We use a case study on a payroll information system (PIS) to show the approach from misuse case identification through the architecture tradeoff analysis. In the case study, we discuss how to make tradeoff between security and availability with respect to the number of servers present.	architecture tradeoff analysis method;data security;information system;misuse case;requirement;sequence diagram;software requirements specification;system information (windows)	Joshua J. Pauli;Dianxiang Xu	2005			software engineering;distributed computing;computer security	Security	-54.919976623954135	48.877779594006704	115203
c1295d4273e7876c6e8f44db90aea81a90363b33	a grammar for specifying usage control policies	communications society;control systems;authorisation;logic;lalr 1 grammar;cots operating system usage control policies access control control systems logic specification lalr 1 grammar;operating systems computers authorisation;usage control;control system;operating system;permission;usage control policies;control system synthesis;mathematical model;cots operating system;access control authorization communication system control permission communications society computer science mathematical model control system synthesis logic control systems;authorization;access control;computer science;logic specification;communication system control;operating systems computers	Usage control goes beyond traditional access control, addressing its limitations related to attribute mutability and continuous usage permission validation. The recently proposed UCONABC model establishes an underlying mathematical framework to deal with the new needs of security and control systems. That model was only described by a logic specification, and this paper proposes implementing it as an LALR(1) grammar, which is defined here. The proposed grammar is then used for representing common access and usage control scenarios, showing its expressiveness and usefulness. The proposed grammar is being incorporated into a file usage control mechanism implemented on a COTS operating system.	control system;digital rights management;digital-to-analog converter;expressive power (computer science);immutable object;information privacy;lalr parser;operating system;role-based access control	Rafael Teigao;Carlos Maziero;Altair Olivo Santin	2007	2007 IEEE International Conference on Communications	10.1109/ICC.2007.232	real-time computing;computer science;control system;operating system;database;authorization;adaptive grammar;computer security	Robotics	-52.6903391503267	52.262531690800415	115573
27eace6b51d7f29d8b1c72dff69ec2ccfb735ba3	methodology and framework for development of smart grid control		To better serve customers, operators need to identify ways to improve the reliability of their electrical service. This paper provides a methodology and framework for the development of new control architectures based on uncertainty management and self-reconfigurability. We designed an architecture for Smart Grid able to integrate the standard control strategy with safety and security aspects. A case study presents details on how the current methods for the assessment of the system security can be applied on the proposed architecture.		Gheorghe Florea;Radu Dobrescu;Oana Chenaru;Mircea Eremia;Lucian Toma	2015		10.1007/978-3-319-30337-6_29	architecture;systems engineering;operator (computer programming);smart grid;computer science	Robotics	-54.55061492245695	47.21860530098787	115867
3f461f11a7f08bc1eff9d2535cfad3c37c3382cf	systematically eradicating data injection attacks using security-oriented program transformations	security engineering;program transformation;design and implementation;secure system;source code	Injection attacks and their defense require a lot of creativity from attackers and secure system developers. Unfortunately, as attackers rely increasingly on systematic approaches to find and exploit a vulnerability, developers follow the traditional way of writing ad hoc checks in source code. This paper shows that security engineering to prevent injection attacks need not be ad hoc. It shows that protection can be introduced at different layers of a system by systematically applying general purpose security-oriented program transformations. These program transformations are automated so that they can be applied to new systems at design and implementation stages, and to existing ones during maintenance.	program transformation	Munawar Hafiz;Paul Adamczyk;Ralph E. Johnson	2009		10.1007/978-3-642-00199-4_7	engineering;distributed computing;world wide web;computer security	Logic	-57.968198532336054	57.277739312290734	115949
e901a418704ab9376eaccaca821aa6bea146043c	chainiac: proactive software-update transparency via collectively signed skipchains and verified builds		Software-update mechanisms are critical to the security of modern systems, but their typically centralized design presents a lucrative and frequently attacked target. In this work, we propose CHAINIAC, a decentralized softwareupdate framework that eliminates single points of failure, enforces transparency, and provides efficient verifiability of integrity and authenticity for software-release processes. Independent witness servers collectively verify conformance of software updates to release policies, build verifiers validate the source-to-binary correspondence, and a tamper-proof release log stores collectively signed updates, thus ensuring that no release is accepted by clients before being widely disclosed and validated. The release log embodies a skipchain, a novel data structure, enabling arbitrarily out-of-date clients to efficiently validate updates and signing keys. Evaluation of our CHAINIAC prototype on reproducible Debian packages shows that the automated update process takes the average of 5 minutes per release for individual packages, and only 20 seconds for the aggregate timeline. We further evaluate the framework using real-world data from the PyPI package repository and show that it offers clients security comparable to verifying every single update themselves while consuming only one-fifth of the bandwidth and having a minimal computational overhead.	aggregate data;centralized computing;conformance testing;data structure;debian;formal verification;overhead (computing);patch (computing);prototype;python package index;reliability engineering;single point of failure;software repository;tamper resistance;timeline;verification and validation	Kirill Nikitin;Eleftherios Kokoris-Kogias;Philipp Jovanovic;Linus Gasser;Nicolas Gailly;Ismail Khoffi;Justin Cappos;Bryan Ford	2017			overhead (computing);computer security;single point of failure;computer science;key (lock);software;real-time computing;timeline;transparency (graphic);data structure;server	Security	-53.8350885083322	59.11402450814518	116236
3dd042eb99e166630b1cf4782d302ce6b7e9204e	evidence-based security configurations for cloud datastores		Cloud systems offer a diversity of security mechanisms with potentially complex configuration options. So far, security engineering has focused on achievable security levels, but not on the costs associated with a specific security mechanism and its configuration. Through a series of experiments with a variety of cloud datastores conducted over the last years, we gained substantial knowledge on how one desired quality like security can have a significant impact on other system qualities like performance. In this paper, we report on select findings related to security-performance trade-offs for three prominent cloud datastores, focusing on data in transit encryption, and propose a simple, structured approach for making trade-off decisions based on factual evidence gained through experimentation. Our approach allows to rationally reason about security trade-offs.	cloud computing;cloud storage;encryption;experiment;security engineering	Frank Pallas;David Bermbach;Steffen Müller;Stefan Tai	2017		10.1145/3019612.3019654	management science;computer security model;cloud computing;security through obscurity;security engineering;software security assurance;cloud computing security;computer security;business;security information and event management;security service	Security	-49.58201048801587	56.56360438145855	116352
72a274815b3a37e0bba60add439ef9dda65ae591	a comparative framework for risk analysis methods	information security;risk analysis;risk management;risk assessment;automated risk analysis approaches;risk monitoring	The past dccadc has shown the importance of information sccuri ty, with special emphasis on network security. disaster recovery and risk n~anagcnumt. A number of automated approaches for the facilitation of a risk analysis study have appeared on the software market. Organizations today fact the difficult task not only of cxccuting a risk analysis study, but also of xlecting a method that will best suit their requircmcnts.	disaster recovery;floor and ceiling functions;it risk management;information security;network security	Jan H. P. Eloff;Les Labuschagne;Karin P. Badenhorst	1993	Computers & Security	10.1016/0167-4048(93)90056-B	risk assessment;risk management tools;risk analysis;it risk management;risk management;computer science;information security;it risk;data mining;risk management information systems;risk analysis;computer security;factor analysis of information risk	ML	-56.73760485681171	49.029666160584185	116466
6d01e72f05c4394ce738255bb42e8fd68ce71b8c	measuring security	software metrics;software performance evaluation;security of data;organisational aspects	The field of computer and communications security begs for a foundational science to guide system design and to reveal the safety, security, and possible fragility of the complex systems we depend on today. To achieve this goal, we must devise suitable metrics for objectively comparing and evaluating the security of system designs and organizations.	communications security;complex systems;computer;systems design	Salvatore J. Stolfo;Steven M. Bellovin;David Evans	2011	IEEE Security & Privacy	10.1109/MSP.2011.56	software security assurance;information security audit;computer security model;standard of good practice;security information and event management;security engineering;computer science;information security;security service;security testing;computer security;software metric	Security	-56.99394486412914	48.600775113274054	116494
42b9616441aef0f79bb9d562dd04ef33e9345aa3	labels and event processes in the asbestos operating system	mandatory access control;software;sistema operativo;controle acces;evaluation performance;performance evaluation;red www;logiciel;securite;methode noyau;evaluacion prestacion;performance;reseau web;flujo informacion;serveur reseau;flux information;information flow;network servers;operating system;telecommunication system;metodo nucleo;secure web servers;safety;process abstractions;world wide web;logicial;design;kernel method;systeme exploitation;systeme telecommunication;sistema telecomunicacion;access control;security;seguridad;labels;inter process communication	Asbestos, a new operating system, provides novel labeling and isolation mechanisms that help contain the effects of exploitable software flaws. Applications can express a wide range of policies with Asbestos's kernel-enforced labels, including controls on interprocess communication and system-wide information flow. A new event process abstraction defines lightweight, isolated contexts within a single process, allowing one process to act on behalf of multiple users while preventing it from leaking any single user's data to others. A Web server demonstration application uses these primitives to isolate private user data. Since the untrusted workers that respond to client requests are constrained by labels, exploited workers cannot directly expose user data except as allowed by application policy. The server application requires 1.4 memory pages per user for up to 145,000 users and achieves connection rates similar to Apache, demonstrating that additional security can come at an acceptable cost.		Steve Vandebogart;Petros Efstathopoulos;Eddie Kohler;Maxwell N. Krohn;Cliff Frey;David Ziegler;M. Frans Kaashoek;Robert Tappan Morris;David Mazières	2007	ACM Trans. Comput. Syst.	10.1145/1314299.1314302	embedded system;kernel method;design;information flow;performance;computer science;information security;access control;operating system;distributed computing;computer security	OS	-52.58686332066855	54.48268488023796	117233
33efbda80686ad9321bf9ee2dba658b063e5470d	secure mmu: architectural support for memory isolation among virtual machines	secure mmu;physical memory page allocation;storage allocation;virtual machine;virtual machine monitor;virtualization;memory management;authorisation;resource allocation;virtual machining;resource management;hypervisor;mapping change verification;unauthorized access;cotenant virtual machine;virtual machine monitors;virtual machines;registers;hardware rooted memory isolation;nested paging support;cryptography;secure hardware mechanism;guest virtual machines;address translation mechanism;virtualisation authorisation cloud computing resource allocation storage allocation virtual machines virtual storage;cotenant virtual machine guest virtual machines address translation mechanism secure mmu unauthorized access nested paging support virtualization hypervisor physical memory page allocation resource management secure hardware mechanism mapping change verification hardware rooted memory isolation cloud computing;program processors;virtual machine monitors virtual machining hardware memory management registers program processors cryptography;virtual storage;virtualisation;cloud computing;hardware	In conventional virtualized systems, a hypervisor can access the memory pages of guest virtual machines without any restriction, as the hypervisor has a full control over the address translation mechanism. In this paper, we propose Secure MMU, a hardware-based mechanism to isolate the memory of guest virtual machines from unauthorized accesses even from the hypervisor. The proposed mechanism extends the current nested paging support for virtualization with a small hardware cost. With Secure MMU, the hypervisor can flexibly allocate physical memory pages to virtual machines for resource management, but update nested page tables only through the secure hardware mechanism, which verifies each mapping change. With the hardware-rooted memory isolation among virtual machines, the memory of a virtual machine in cloud computing can be securely protected from a compromised hypervisor or co-tenant virtual machines.	authorization;cloud computing;computer data storage;hypervisor;memory management unit;memory protection;page table;paging;second level address translation;virtual machine	Seongwook Jin;Jaehyuk Huh	2011	2011 IEEE/IFIP 41st International Conference on Dependable Systems and Networks Workshops (DSN-W)	10.1109/DSNW.2011.5958816	parallel computing;real-time computing;virtualization;temporal isolation among virtual machines;storage hypervisor;computer science;virtual machine;virtual memory;resource management;operating system;hardware virtualization;distributed computing;hypervisor;computer security;computer network	Arch	-53.11876553137683	56.02460249015471	117395
362b81ac479f9f84fed7308b9f5a5f0875ffd648	evaluation of approaches for modeling of security in data warehouses		A Data Warehouse (DW) is a complex system that facilitates decision makers for the fulfillment of strategic, informational and decisional needs by extracting and integrating data from heterogeneous sources. They are complex due to the kind of problems they are built to solve. Due to the sensitive data contained in the DW it is important to assure the security of the DWs from the early stages of the life cycle of its development starting from requirements analysis to implementation and maintenance so that unauthorized attempts cannot access the DW. Traditionally, security was not considered as an important element in modeling of DWs. This survey paper gives a review of the DW security attempts at various abstraction levels like requirements, conceptual, logical, and physical modeling. Further, evaluation of various approaches for modeling security in DWs has been presented. This may help the designer, while selecting the good approach for DW design considering the security aspect as well.	authorization;complex system;dreamwidth;principle of abstraction;requirement;requirements analysis	Krishna Khajaria;Manoj Kumar	2011		10.1007/978-3-642-22714-1_2	systems engineering;engineering;data mining;computer security	Security	-55.223941418624264	48.40963442532334	117554
e19c1080a989ef71295ece8be297170157ec8247	musec: sonification of alarms generated by a siem		The information generated by a network monitoring system is overwhelming. Monitoring is imperative but very difficult to accomplish due to several reasons. More so for the case of non tech-savvy home users. Security Information Event Management applications generate alarms that correlate multiple occurrences on the network. These events are classified accordingly to their risk. An application that allows the sonification of events generated by a Security Information Event Management can facilitate the security monitoring of a home network by a less tech-savvy user by allowing him to just listen to the result of the sonification of such events.	computer;imperative programming;internet;ossim;security information and event management;sensor;server (computing);smartphone;sonification;the times	Luís Sousa;António Pinto	2017		10.1007/978-3-319-61118-1_5	real-time computing;network security;network monitoring;sonification;computer science	Security	-62.71861384285036	58.11773100118573	117669
668d423488fef64f5ba52fce2b86805dc2d44df6	ontological approach toward cybersecurity in cloud computing	information exchange;cybersecurity;ontology;cloud computing	Widespread deployment of the Internet enabled building of an emerging IT delivery model, i.e., cloud computing. Albeit cloud computing-based services have rapidly developed, their security aspects are still at the initial stage of development. In order to preserve cybersecurity in cloud computing, cybersecurity information that will be exchanged within it needs to be identified and discussed. For this purpose, we propose an ontological approach to cybersecurity in cloud computing. We build an ontology for cybersecurity operational information based on actual cybersecurity operations mainly focused on non-cloud computing. In order to discuss necessary cybersecurity information in cloud computing, we apply the ontology to cloud computing. Through the discussion, we identify essential changes in cloud computing such as data-asset decoupling and clarify the cybersecurity information required by the changes such as data provenance and resource dependency information.	cloud computing;computer security;coupling (computer programming);software deployment	Takeshi Takahashi;Youki Kadobayashi;Hiroyuki Fujiwara	2010		10.1145/1854099.1854121	cloud computing security;information exchange;cloud computing;computer science;ontology;data mining;world wide web;computer security	HPC	-48.908626157289305	54.64098984452547	117736
97b80fcd3bbb02afef779953f2ed80ad1c826ff9	cloud computing security--trends and research directions	software;third party authorities;trusted computing cloud computing security enterprise applications vulnerabilities virtualization infrastructure software platform identity management access control data integrity confidentiality privacy legal compliance cloud service provider third party authorities;cloud computing data privacy access control software authentication law;data integrity;service provider;cloud service provider;cloud computing security;software platform;authorisation;authentication;computer crime;law;confidentiality;identity management;survey cloud computing security trusted computing data integrity confidentiality;trusted computing;vulnerabilities;data privacy;security and privacy;data privacy authorisation cloud computing computer crime data integrity;access control;point of view;enterprise applications;security;survey;legal compliance;virtualization infrastructure;privacy;cloud computing	Cloud Computing is increasingly becoming popular as many enterprise applications and data are moving into cloud platforms. However, a major barrier for cloud adoption is real and perceived lack of security. In this paper, we take a holistic view of cloud computing security - spanning across the possible issues and vulnerabilities connected with virtualization infrastructure, software platform, identity management and access control, data integrity, confidentiality and privacy, physical and process security aspects, and legal compliance in cloud. We present our findings from the points of view of a cloud service provider, cloud consumer, and third-party authorities such as Govt. We also discuss important research directions in cloud security in areas such as Trusted Computing, Information Centric Security and Privacy Preserving Models. Finally, we sketch a set of steps that can be used, at a high level, to assess security preparedness for a business application to be migrated to cloud.	access control;business software;cloud computing security;computer security;confidentiality;data integrity;enterprise software;file spanning;high-level programming language;holism;identity management;trusted computing	Shubhashis Sengupta;Vikrant S. Kaulgud;Vibhu Saujanya Sharma	2011	2011 IEEE World Congress on Services	10.1109/SERVICES.2011.20	cloud computing security;cloud computing;cloud testing;business;internet privacy;world wide web;computer security	Security	-49.13203789588441	57.182385396961855	117851
b10f1322995245ee11e519fd2e73e4a54150f1e9	investigating cyber-physical attacks against iec 61850 photovoltaic inverter installations	protocols;iec standards ip networks inverters object oriented modeling protocols density estimation robust algorithm;inverters;photovoltaic generators cyber physical attacks iec 61850 photovoltaic inverter installations smart grid communication standards malware havex blackenergy industrial control systems ics man in the middle attacks nescor cyber security power utility automation inverter based distributed energy resource devices;iec standards;density estimation robust algorithm;ip networks;photovoltaics smart grid security iec 61850 man in the middle attack;object oriented modeling;power system security distributed power generation invasive software invertors photovoltaic power systems power system control	Cyber-attacks against Smart Grids have been found in the real world. Malware such as Havex and BlackEnergy have been found targeting industrial control systems (ICS) and researchers have shown that cyber-attacks can exploit vulnerabilities in widely used Smart Grid communication standards. This paper addresses a deep investigation of attacks against the manufacturing message specification of IEC 61850, which is expected to become one of the most widely used communication services in Smart Grids. We investigate how an attacker can build a custom tool to execute man-in-the-middle attacks, manipulate data, and affect the physical system. Attack capabilities are demonstrated based on NESCOR scenarios to make it possible to thoroughly test these scenarios in a real system. The goal is to help understand the potential for such attacks, and to aid the development and testing of cyber security solutions. An attack use-case is presented that focuses on the standard for power utility automation, IEC 61850 in the context of inverter-based distributed energy resource devices; especially photovoltaics (PV) generators.	bagoes;computer security;control system;experiment;malware;man-in-the-middle attack;penetration test;power inverter;solar inverter;systemverilog;testbed;threat model	BooJoong Kang;Peter Maynard;Kieran McLaughlin;Sakir Sezer;Filip Andren;Christian Seitl;Friederich Kupzog;Thomas I. Strasser	2015	2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA)	10.1109/ETFA.2015.7301457	embedded system;communications protocol;real-time computing;computer science;engineering;operating system;computer security;computer network;scada	EDA	-56.970750762356964	52.07154814456711	118347
b5f8027846dd4f2251552afb14840f6c759cf83b	leveraging the serverless architecture for securing linux containers		Linux containers present a lightweight solution to package applications into images and instantiate them in isolated environments. Such images may include vulnerabilities that can be exploited at runtime. A vulnerability scanning service can detect these vulnerabilities by periodically scanning the containers and their images for potential threats. When a threat is detected, an event may be generated to (1) quarantine or terminate the compromised container(s) and optionally (2) remedy the vulnerability by rebuilding a secure image. We believe that such event-driven process is a great fit to be implemented in a serverless architecture. In this paper we explore the design of an automated threat mitigation architecture based on OpenWhisk and Kubernetes.	artificial intelligence;automated threat;event-driven programming;image;lxc;linux;machine learning;peer-to-peer;quarantine (computing);run time (program lifecycle phase);terminate (software);threat (computer);vulnerability (computing);vulnerability scanner	Nilton Bila;Paolo Dettori;Ali Kanso;Yuji Watanabe;Alaa Youssef	2017	2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW)	10.1109/ICDCSW.2017.66	operating system;architecture;computer security;vulnerability;computer science	SE	-55.15808419721462	57.53597747762757	118854
f68b07a1a9f7817828b0264599c86c00627a176e	formalising policies for insider-threat detection: a tripwire grammar		The threat that organisations face from within is growing significantly, as it has been widely demonstrated by the harm that insiders have caused recently. For many years the security community has invested in barriers and perimeters, of increasing sophistication, designed to keep those with malign intent outside of the organisations’ information infrastructures. But assuming that one can keep the threat out of an organisation is simply not a practical stance to adopt. In our research we are concerning ourselves with how technology might be deployed to help with the detection of insider threats both automatically and in support of human-led mechanisms. This paper describes our recent research into how we might support threat detection when actions taken can be immediately determined as of concern. In particular we capture actions that fall into one of two categories: those that violate a policy which is specifically crafted to describe behaviours that should be avoided; or those that exhibit behaviours which follow a pattern of a known insider-threat attack. We view these concerning actions as something that we can design and implement tripwires within a system to detect. We then orchestrate these tripwires in conjunction with an anomaly detection system. We present a review of the security policies organisation apply and a grammar to describe tripwires. We further validate our grammar by formalising the most common tripwires for both categories. Our aim is to provide a single framework for unambiguously capturing tripwires, alongside a library of existing ones in use. Therefore, tripwires may be used to map experiences regardless of the heterogeneity of the security tools and practices deployed.	anomaly detection;insider threat;threat (computer)	Ioannis Agrafiotis;Arnau Erola;Michael Goldsmith;Sadie Creese	2017	JoWUA			Security	-59.753844944391794	59.36231243717946	118978
3a987e8d6affa9a8a1728b9326f9affb8e217a6d	abstract code injection - a semantic approach based on abstract non-interference		Code injection attacks have been the most critical security risks for almost a decade. These attacks are due to an interference between an untrusted input (potentially controlled by an attacker) and the execution of a string-to-code statement, interpreting as code its parameter. In this paper, we provide a semantic-based model for code injection parametric on what the programmer considers safe behaviors. In particular, we provide a general (abstract) non-interference-based framework for abstract code injection policies, i.e., policies characterizing safety against code injection w.r.t. a given specification of safe behaviors. We expect the new semantic perspective on code injection to provide a deeper knowledge on the nature itself of this security threat. Moreover, we devise a mechanism for enforcing (abstract) code injection policies, soundly detecting attacks, i.e., avoiding false negatives.	code injection;non-interference (security);statistical interference	Samuele Buro;Isabella Mastroeni	2018		10.1007/978-3-319-73721-8_6	theoretical computer science;computer science;internet security;code injection;programmer;parametric statistics	SE	-54.264512516547214	53.033388310866165	119295
0ff9371fd3888576a66f44e956f9c10316d12219	undangle: early detection of dangling pointers in use-after-free and double-free vulnerabilities	vulnerability analysis;early detection	Use-after-free vulnerabilities are rapidly growing in popularity, especially for exploiting web browsers. Use-after-free (and double-free) vulnerabilities are caused by a program operating on a dangling pointer. In this work we propose early detection, a novel runtime approach for finding and diagnosing use-after-free and double-free vulnerabilities. While previous work focuses on the creation of the vulnerability (i.e., the use of a dangling pointer), early detection shifts the focus to the creation of the dangling pointer(s) at the root of the vulnerability. Early detection increases the effectiveness of testing by identifying unsafe dangling pointers in executions where they are created but not used. It also accelerates vulnerability analysis and minimizes the risk of incomplete fixes, by automatically collecting information about all dangling pointers involved in the vulnerability. We implement our early detection technique in a tool called Undangle. We evaluate Undangle for vulnerability analysis on 8 real-world vulnerabilities. The analysis uncovers that two separate vulnerabilities in Firefox had a common root cause and that their patches did not completely fix the underlying bug. We also evaluate Undangle for testing on the Firefox web browser identifying a potential vulnerability.	c dynamic memory allocation;dangling pointer;firefox;pointer (computer programming);vulnerability (computing)	Juan Caballero;Gustavo Grieco;Mark Marron;Antonio Nappa	2012		10.1145/2338965.2336769	memory safety;computer science;vulnerability assessment;internet privacy;world wide web;computer security	SE	-57.337948691220724	57.6766113821262	119437
4087a2739fda21eaaf5e251b1b272ba14a312097	collaborative task execution with originator data security for weak devices		This paper presents a secure framework for dispatching and completing tasks in a network of weak embedded devices, such as sensors. The framework allows a device to dispatch tasks to other remote devices so that the remote devices can utilise their idle resources to help the execution of the tasks. The framework also ensures that the secure data of the originating devices will not be disclosed with the tasks that are dispatched to the helping devices. The framework is implemented with TinyOS and MICAz motes for evaluation. The results show that the framework achieves the desired security with little overhead and is feasible to weak devices.	data security	Sobit Bahadur Thapa;Qijun Gu	2016	IJSNet	10.1504/IJSNET.2016.10000139	embedded system;real-time computing;wireless sensor network;computer science;operating system;distributed computing;data security;collaboration	Crypto	-51.98126809540471	56.33027582040426	119632
24b0371669130b5f1ac406fc8e306e927d39169a	expressive policy analysis with enhanced system dynamicity	policy analysis;system dynamics;policies;dynamic system;satisfiability;conference paper;authorization;formal analysis;security	Despite several research studies, the effective analysis of policy based systems remains a significant challenge. Policy analysis should at least (i) be expressive (ii) take account of obligations and authorizations, (iii) include a dynamic system model, and (iv) give useful diagnostic information. We present a logic-based policy analysis framework which satisfies these requirements, showing how many significant policy-related properties can be analysed, and we give details of a prototype implementation.	dynamical system;prototype;requirement	Robert Craven;Jorge Lobo;Jiefei Ma;Alessandra Russo;Emil C. Lupu;Arosha K. Bandara	2009		10.1145/1533057.1533091	simulation;computer science;information security;policy analysis;dynamical system;data mining;authorization;system dynamics;computer security;satisfiability	Security	-51.313977608162894	51.36569075216529	119757
cc9261a5fdf773f7bba2ebe66d498c2006fcc0a5	propolis: provisioned analysis of data-centric processes	finite state transition system;analysis result;online shopping application;hypothetical modification scenario;different hypothetical modification;transition system;data-centric process-based application;provisioned analysis;underlying database;process control;data-centric process	We consider in this demonstration the (static) analysis of data-centric process-based applications, namely applications that depend on an underlying database and whose control is guided by a finite state transition system. We observe that analysts of such applications often want to do more than analyze a specific instance of the application’s process control and database. In particular they want to interactively test and explore the effect on analysis results of different hypothetical modifications applied to the application’s transition system and to the underlying database. To that end, we propose a demonstration of PROPOLIS, a system for PROvisioned PrOcess anaLysIS, namely analysis of data-centric processes under hypothetical modification scenarios. Our solution is based on the notion of a provisioned expression (which in turn is based on the notion of data provenance), namely an expression that captures, in a compact way, the analysis result with respect to all possible combinations of scenarios, and allows for their exploration at interactive speed. We will demonstrate PROPOLIS in the context of an online shopping application, letting participants play the role of analysts.	database;interactivity;online shopping;state transition table;static program analysis;transition system	Daniel Deutch;Yuval Moskovitch;Val Tannen	2013	PVLDB	10.14778/2536274.2536301	simulation;artificial intelligence;data mining;database	DB	-52.35447923907665	47.59722202188158	119772
1e105bc5ffc11c898ab5949664faa439b8f37e8e	architectural support for run-time validation of control flow transfer	runtime hardware counting circuits control systems data security information filtering information filters protection information security computer interfaces;run time validation;microarchitecture;bloom filter;program counter;branch prediction;computer architecture;machine instruction level;blind folded instruction;control flow;speculative execution;cascading bloom filter;control flow transfer;cascading bloom filter run time validation control flow transfer microarchitecture blind folded instruction machine instruction level;program compilers;security of data computer architecture instruction sets program compilers;security of data;instruction sets	Current micro-architecture blindly uses the address in the program counter to fetch and execute instructions without validating its legitimacy. Whenever this blind-folded instruction sequencing is not properly addressed at a higher level by system, it becomes a vulnerability of control data attacks, today's dominant and most critical security threats. To remedy it, this paper proposes a micro-architectural mechanism to validate control flow transfer at run-time at machine instruction level. It is proposed to have a hardware table consisting of legitimate indirect branches and their target pairs (IBPs) to aid the validation. The IBP table is implemented in the form of a cascading Bloom filter to store the security information as well as to enable fast validating. Based on a key observation that branch prediction unit existing in most speculative-execution processors already provides a portion of the control flow validation, our scheme activates the validation only on indirect branch mis-predictions. Because of the Bloom filter and the rarity of mis-predictions of indirect branches, the validation incurs moderate storage overhead and little performance penalty.	avg;bit array;bloom filter;branch (computer science);branch predictor;call stack;central processing unit;control flow;elegant degradation;filter design;full scale;indirect branch;instruction cycle;internet;machine code;mesa;microarchitecture;multi-core processor;netbsd gzip / freebsd gzip;overhead (computing);pointer (computer programming);program counter;speculative execution;vortex;bzip2	Yixin Shi;Sean Dempsey;Gyungho Lee	2006	2006 International Conference on Computer Design	10.1109/ICCD.2006.4380863	program counter;embedded system;electronic engineering;parallel computing;real-time computing;microarchitecture;computer science;bloom filter;operating system;instruction set;programming language;control flow;indirect branch;algorithm;branch predictor;speculative execution	Arch	-55.563631209916004	56.27230947548709	119800
d34dd38d0a8b637ceb1c27acd8b2a95379dc4ce6	on the fundamentals of analysis and detection of computer misuse	service provider;publikationer;konferensbidrag;artiklar;rapporter;information system	Most computerized information systems we use in our everyday lives provide very little protection against hostile manipulation. At the same time, there is a rapidly increasing dependence on services provided by these computer systems and networks, and security is thus not only an interesting and challenging research discipline but has indeed developed into a critical issue for society. This thesis presents research focused on the fundamental technical issues of computer misuse, aimed at manual analysis and automatic detection. The objective is to analyze and understand the technical nature of security threats and, on the basis of this, develop efficient generic methods that can improve the security of existing and future systems. The work is performed from the perspective of system and information owners, a different approach compared to the many previous studies that focus on system developers only. The analysis is based mainly on empirical data from student experiments but also uses data from a security analysis, data recorded from a network server and data produced for an intrusion detection evaluation project. Throughout this work, systematic categorization of data has been used as the main method for data analysis. The results of this work include new findings about the behavior of so-called insider attackers, a dangerous but sometimes neglected security threat. For systems that include commercial off-the-shelf components, underlying causes of system vulnerabilities are identified and discussed, a systematic procedure for vulnerability remediation is developed and a risk management strategy is proposed. Furthermore, the aspects of computer misuse that are fundamental for automatic detection are identified and analyzed in detail. The efficiency and usability of a generic expert system tool for automatic misuse detection is verified empirically. A general database format for documenting attack types and for automatically updating detection tools is outlined.	categorization;computer;experiment;expert system;information system;intrusion detection system;misuse detection;risk management;server (computing);software documentation;usability	Ulf Lindqvist	1999			computer science;data mining;world wide web;computer security	Security	-62.10730972673965	56.24403085384448	119919
ed90af0250a31c7ef55ceac487c06786d15c966c	analyse de code et processus d'évaluation des composants sécurisés contre l'injection de faute. (code analysis and certification process of secure hardware against fault injection)		Secure hardware such as smartcards is a special kind of hardware that provides security properties. In order to ensure security against a broad range of powerful attackers, strict regulations have been adopted, such as Common Criteria and the EMVCo specification. Dedicated laboratories known as ITSEF evaluate the security requirements of secure hardware. Part of this evaluation assesses the robustness of secure hardware against fault injection attacks (attacks performed with specialized equipment such as lasers and electromagnetic injectors, that result in a modification of the behavior of the program). In this thesis, we propose an end-to-end approach connecting the two parts of the evaluation process against fault injection : code review, and physical penetration testing. Code review can be aided by using code analyzers, so we provide a study of the state of the art regarding such tools, starting with those from the related field of fault tolerance. As a result, we find that no tool covers the specific needs of ITSEF evaluators. We then tackle the specific problem of determining which faults can be implemented on a targeted secure hardware using fault model inference. This new method introduces the key notion of probabilistic fault model, where a probability is associated to the various kinds of faults as a function of the parameters of the attack equipment. Our approach is backed up by experiments on several pieces of hardware and attack equipments. Next, we describe CELTIC, our dynamic binary code analyzer, able to simulate fault injection, and designed to meet the needs of the evaluators, such as the ability to easily add new instruction sets. CELTIC can use the probabilistic fault models to determine which faults can be injected, and to compute new metrics that assist the evaluator into rating the robustness of the secure hardware. Lastly, we present our work on multiple fault attacks, where an attacker has the ability to inject several faults over the course of a single execution of the code on hardware. This attack implies huge combinatorics, which makes the simulation by tools and the processing of the results more complex. Thus, we explore several complementary approaches to handle this complexity and extend the metrics of robustness. We also detail the implementation of a just in time compiler for fault injection, which allows to drastically improve the performances of CELTIC. We conclude with a report on the usage of CELTIC at the ITSEF, and a discussion on the future of fault injection. We describe the emergence of increasingly sophisticated attack equipment, and the accordingly tailored countermeasures. Our final word discusses the possibility for future applications of fault injection attacks to Internet of Things devices.		Louis Dureuil	2016				Security	-60.58655915755896	52.41286428135927	119983
b14d48221090729354a2353a8263aac8db567d4c	real world evaluation of a novel security testing environment for vehicular control units via can networks		Due to the introduction of networked entertainment and safety features in modern cars, vehicular communication systems are no closed networks anymore. As research demonstrated, based on these new attack surfaces existing safety and functional tests cannot fully satisfy security needs of modern cars. With this work we introduce an application called CAN Communication Tester (CAN-CT) which addresses this problem for the Controller Area Network (CAN). CAN-CT is an application that makes use of hacking attacks to systematically inject, replay and invalidate messages. We show that we can successfully spoof messages, suppress all communication on the bus and transition electronic control units (ECUs) into error states. CAN-CT is capable of learning from the traf®c on the bus and executes targeted attacks. By attacking an ECU the same way a hacker would, we are able to examine the implementation of protection mechanisms in an intuitive yet effective way. Furthermore this approach allows us to test the proper working of possible attack detection techniques as well. Using Hardware-in-the-Loop Systems (HiLs) we tested CAN-CT with actual state of the art ECUs. We revealed vulnerabilities like lacks in the plausibility checking of messages or completely omitted examinations of the frame structure. Those  ̄aws opened up serious threats to hackers. In exploiting those vulnerabilities we showed that we were able to take over message IDs owned by another ECU and hence achieve targeted manipulations. Revealing weaknesses in real-world ECUs allowed us to demonstrate the applicability and impact of applications like CAN-CT for automotive systems. Our results highlight the need for security tests to complement traditional testing environments.	can bus;engine control unit;functional testing;hardware-in-the-loop simulation;phone hacking;plausibility structure;protection mechanism;security testing	Jürgen Wurzinger;Peter Priller;Ales Kolar;Markus Nager	2016			security testing;computer security;engineering	Security	-52.912604546496844	59.09595814864432	120019
c2a1ac26d3e8181574257d42a4c110cfd5fe0809	cyber-physical security via geometric control: distributed monitoring and malicious attacks	graph theory;power generation control;monitoring security control systems noise generators control theory power generation;distributed identification monitor design cyber physical system security transportation networks industrial processes critical infrastructures external malicious attack strategy design system failures geometric control theory graph theory system theory centralized attack detection design power generator system group attack strategy design centralized identification monitor design distributed attack detection design;centralised control;distributed control;security of data;power system security;security of data centralised control distributed control graph theory power generation control power system security	Cyber-physical systems are ubiquitous in power systems, transportation networks, industrial processes, and critical infrastructures. These systems need to operate reliably in the face of unforeseen failures and external malicious attacks. This paper summarizes and extends our results on the security of cyber-physical systems based on geometric control theory: (i) we propose a mathematical framework for cyber-physical systems, attacks, and monitors; (ii) we characterize fundamental monitoring limitations from system-theoretic and graph-theoretic perspectives; and (iii) we design centralized and distributed attack detection and identification monitors. Finally, we design an attack strategy for a group of power generators to physically compromise the functionality of other generators. Novel contributions include a more general framework, the design of novel centralized and distributed identification monitors, and the attack design case study.	centralized computing;control theory;cyber-physical system;graph theory;ibm power systems;malware;monitor (synchronization);nonlinear system;physical security	Fabio Pasqualetti;Florian Dörfler;Francesco Bullo	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426257	control system security;real-time computing;engineering;graph theory;mathematics;distributed computing;computer security	Embedded	-57.32809590293671	51.291498886471594	120108
487c4e7b24d46f38d5e6e41e148d58b398f79025	security level determination using branes for contextual based global processing: an architecture	security branes.;global contextual processing;contextual processing security	This paper presents the basics of a new paradigm that allows generators and consumers of global contextual information to determine an appropriate security level needed for contextual information. Security levels have a direct correlation with confidence in the integrity of contextual data and thus their processing. The new approach is based on the concept of branes, which can be used to map different security levels of a collection of data points in some space. It turns out that different branes offer different classification capabilities and computational challenges. The data are described according to their information context and to their security requirements. Because the internet inherently does not have good security, the creation of this model has necessitated the development of new methods for securing contextual information as it migrates around the web.		Greg Vert;Evangelos Triantaphyllou	2009			opcode;computer security;microprocessor;computer science;computer security model;digital signal processing;x86;macro instruction;preprocessor;central processing unit	Arch	-51.84687831904874	55.74799990140811	120111
7753f8b0a38be13475a22a37a4fe04ae37aca848	high-level synthesis for run-time hardware trojan detection and recovery	design rules high level synthesis run time hardware trojan detection integrated circuit development process intellectual property cores golden ip;detection and recovery;high level synthesis;ip;invasive software hardware software codesign integrated circuit design;trojan horses ip networks payloads hardware integrated circuits educational institutions schedules;design for security;hardware trojan;run time;high level synthesis hardware trojan detection and recovery design for security run time ip	Current Integrated Circuit (IC) development process raises security concerns about hardware Trojan which are maliciously inserted to alter functional behavior or leak sensitive information. Most of the hardware Trojan detection techniques rely on a golden (trusted) IC against which to compare a suspected one. Hence they cannot be applied to designs using third party Intellectual Property (IP) cores where golden IP is unavailable. Moreover, due to the stealthy nature of hardware Trojan, there is no technique that can guarantee Trojan-free after manufacturing test. As a result, Trojan detection and recovery at run time acting as the last line of defense is necessary especially for mission-critical applications. In this paper, we propose design rules to assist run-time Trojan detection and fast recovery by exploring diversity of untrusted third party IP cores. With these design rules, we show the optimization approach to minimize the cost of implementation in terms of the number of different IP cores used by the implementation.	hardware trojan;high- and low-level;high-level synthesis;information sensitivity;integrated circuit;mathematical optimization;mission critical;name binding;run time (program lifecycle phase);scheduling (computing);semiconductor intellectual property core;trojan horse (computing);trust (emotion)	Xiaotong Cui;Kun Ma;Liang Shi;Kaijie Wu	2014	2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2593069.2593150	internet protocol;embedded system;real-time computing;computer science;engineering;operating system;high-level synthesis;computer security;computer network	EDA	-56.588285546764276	55.585305251221705	120472
29cb65ea1f9f68a51bf51a756da95735c7366b5b	dynamic policy conflict analysis for collaborative web services	web services semantics collaboration context security accuracy linearity;semantic temporal logic dynamic policy conflict analysis collaborative web services policy based management control rules restrictions;linearity;temporal logic;collaboration;service management;semantics;web services security of data service oriented architecture temporal logic;dynamic policy conflict analysis;web service;restrictions;control rules;dynamic conflict analysis;collaborative web services;accuracy;policy based management;web services management;web services;semantic temporal logic;service oriented architecture;security;security of data;context;dynamic conflict analysis policy based management web services management temporal logic	Policy-based management can simplify web service management by establishing policies to control various activities involved in service governance and provision. Administrators and users use policies to define control rules and restrictions, and to configure application environments. When collaboration is necessary between web services for a specific task, various management requirements from individual services may have conflicts. Some conflicts are static. Some conflicts are dynamic, which are difficult to detect and resolve. The situation is even worse when the collaboration is a one-time event. To detect and resolve potential dynamic conflicts between web services in a collaborative setting, especially between web services from different administrative domains, a semantic temporal logic is proposed and used in this paper to analyze dynamic policy conflicts. An implementation and resultant experiments are also discussed.	experiment;network service provider;prototype;requirement;resultant;temporal logic;web service	Zhengping Wu;Yuanyao Liu	2010	2010 International Conference on Network and Service Management	10.1109/CNSM.2010.5691220	web service;computer science;knowledge management;ws-policy;data mining;database;semantics;services computing;law	SE	-48.79731284539128	52.966342556847096	120862
048787d3a729acccf98842dd71ee01c59554a489	graphbad: a general technique for anomaly detection in security information and event management		The reliance on expert knowledge –required for analysing security logs and performingrnsecurity audits– has created an unhealthy balance where many computerrnusers are not able to correctly audit their security configurations and react to potentialrnsecurity threats. The decreasing cost of IT and the increasing use of technologyrnin domestic life is exacerbating this problem where small companies and home ITrnusers are not able to afford the price of experts for auditing their systems configuration.rnIn this paper we present GraphBAD, a graph-based analysis tool able to analysernsecurity configurations in order to identify anomalies that could lead to potentialrnsecurity risks. GraphBAD, which does not require any prior domain knowledge,rngenerates graph-based models from security configuration data and, by analysingrnsuch models, is able to propose mitigation plans that can help computer users inrnincreasing the security of their systems. A large experimental analysis, conducted onrnboth publicly available (the well-known KDD dataset) and synthetically generatedrntesting sets (file system permissions), demonstrates the ability of GraphBAD inrncorrectly identifying security configurations anomalies and suggesting appropriaternmitigation plans.	anomaly detection;security information and event management	Simon Parkinson;Mauro Vallati;Andrew Crampton;Shirin Sohrabi	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4433	computer science;data mining;distributed computing;domain knowledge;anomaly detection;graph;audit;file system permissions;security information and event management	Security	-60.69627508832496	59.724416871833434	121229
368243e3ef9b06a48c8802084c4b2264c6315c2a	partitions and principles for secure operating systems	computer performance evaluation;software event monitor;technical report;computer science;operating systems	As part of the general goal of providing secure computer systems, the design of verifiably secure operating systems is one of the most important tasks. This paper addresses the problem by defining security in terms of a model and proposing a set of principles which should be satisfied. Four key operating system partitions are identified: user interface functions, user invoked services, background services, and the security kernel. Principles are then defined to insure that interface functions provide a safe initial environment for executing user programs, user called services are confined, background services have no access to user information, and the security kernel adequately protects stored information.	operating system;user interface	Gregory R. Andrews	1975		10.1145/800181.810311	secure by design;embedded operating system;computer science;theoretical computer science;distributed computing;user interface;computer security;secure by default	Security	-52.269798983041035	53.98167828965928	121282
ec8a25d9c39e1137d9fb5117180778c4d4902725	preserving integrity and confidentiality of a directed acyclic graph model of provenance	acyclic graph model;different compartment;acyclic graph;provenance database;access control model;path-based access control;provenance owner;compartment-based access control;provenance graph;preserving integrity;different key;digital signature;directed acyclic graph;access control	This paper describes how to preserve integrity and confidentiality of a directed acyclic graph (DAG) model of provenance database. We show a method to preserve integrity by using digital signature where both of the provenance owner and the process executors (i.e. contributors) sign the nodes and the relationships between nodes in the provenance graph so that attacks to integrity can be detected by checking the signatures. To preserve confidentiality of the nodes and edges in the provenance graph we propose an access control model based on paths on the provenance graph because an auditor who need to audit a result normally need to access all nodes that have causal relationship with the result (i.e. all nodes that have a path to the result). We also complement the path-based access control with a compartment-based access control where each node is classified into compartments and the auditor is not allowed to access the nodes included in a compartment that can not be accessed by him/her (because of the sensitivity of the compartment). We implement the path-based access control by encrypting the nodes and later store encrypted encryption’s keys in the children of the nodes. The compartment-based access control is implemented by encrypting the nodes in different compartments with different keys. We developed a prototype of the model and performed experiments to measure the overhead of digital signature and the double encryptions.	access control;antivirus software;causality;confidentiality;directed acyclic graph;encryption;experiment;multi-compartment model;overhead (computing);prototype	Amril Syalim;Takashi Nishide;Kouichi Sakurai	2010			computer science;internet privacy;world wide web;computer security	Security	-52.14754751184841	54.20958714266652	121384
667a2996fe2a7c0b3290488678c086e6ff0c4a65	bridemaid: an hybrid tool for accurate detection of android malware	mobile;android;testing;security	This paper presents BRIDEMAID, a framework which exploits an approach static and dynamic for accurate detection of Android malware. The static analysis is based on n-grams matching, whilst the dynamic analysis is based on multi-level monitoring of device, app and user behavior. The framework has been tested against 2794 malicious apps reporting a detection accuracy of 99,7% and a negligible false positive rate, tested on a set of 10k genuine apps.	android;grams;malware;n-gram;static program analysis;while	Fabio Martinelli;Francesco Mercaldo;Andrea Saracino	2017		10.1145/3052973.3055156	computer science;information security;internet privacy;world wide web;computer security;android	Security	-57.37070100591714	59.677005362952386	121768
805348c1c6211d7ca424a07b5e3a555493262d46	adaptive modelling for security analysis of networked control systems		Incomplete information about connectivity and functionality of elements of networked control systems is a challenging issue in applying model-based security analysis in practice. This issue can be addressed by modelling techniques providing inherent mechanisms to describe incomplete information. We present and exemplary demonstrate a new, ontology-based method to adaptively model and analyse networked control systems from a security perspective. Our method allows modelling different parts of the system with different levels of detail. We include a formalism to handle incomplete information by applying iterative extension and iterative refinement of the model where necessary. By using machine-based reasoning on an ontology model of the system, security-relevant information is deduced. During this process, non-obvious attack vectors are identified using a structural analysis of the model and by connecting the model to vulnerability information.	bayesian network;control system;iterative and incremental development;iterative method;iterative refinement;level of detail;ontology (information science);refinement (computing);semantics (computer science);structural analysis;vulnerability (computing)	Jan Wolf;Felix Wieczorek;Frank Schiller;Gerhard Hansch;Norbert Wiedermann;Martin Hutle	2016			complete information;iterative refinement;ontology;theoretical computer science;network security;security analysis;data mining;formalism (philosophy);computer science;vulnerability;control system	AI	-53.20142210664454	49.003272064854926	121982
7a0cdc6a29b230908df2c54e584af62a7eed8d52	cuda leaks: a detailed hack for cuda and a (partial) fix	paper;tesla c2050;nvidia geforce gt 640;gpu;cuda;gpgpu;registers;nvidia;algorithms;computer science;security;information leakage	Graphics processing units (GPUs) are increasingly common on desktops, servers, and embedded platforms. In this article, we report on new security issues related to CUDA, which is the most widespread platform for GPU computing. In particular, details and proofs-of-concept are provided about novel vulnerabilities to which CUDA architectures are subject. We show how such vulnerabilities can be exploited to cause severe information leakage. As a case study, we experimentally show how to exploit one of these vulnerabilities on a GPU implementation of the AES encryption algorithm. Finally, we also suggest software patches and alternative approaches to tackle the presented vulnerabilities.	algorithm;cuda;embedded system;experiment;graphics processing unit;information leakage;linux;operating system;patch (computing);shared memory;spectral leakage;vulnerability (computing)	Roberto Di Pietro;Flavio Lombardi;Antonio Villani	2016	ACM Trans. Embedded Comput. Syst.	10.1145/2801153	embedded system;parallel computing;computer science;information security;theoretical computer science;operating system;processor register;general-purpose computing on graphics processing units	Security	-53.981872955458535	56.37525612388264	122021
3fbd57854e1561e1b976d72ca82bdf22d7739242	privacy leakage attacks in browsers by colluding extensions		Browser Extensions (BE) enhance the core functionality of the Browser and provide customization to it. Browser extensions enjoy high privileges, sometimes with the same privileges as Browser itself. As a consequence, a vulnerable or malicious extension might expose Browser and system resources to attacks. This may put Browser resources at risk of unwanted operations, privilege escalation etc. BE can snoop on web applications, launch arbitrary processes, and even access files from host file system. In addition to that, an extension can even collude with other installed extensions to share objects and change preferences. Although well-intentioned, extension developers are often not security experts. Hence, they might end up writing vulnerable code. In this paper we present a new attacks via Browser extensions. In particular, the attack allows two malicious extensions to communicate and collaborate with each other in such a way to achieve a malicious goal. We identify the vulnerable points in extension development framework as: (a) object reference sharing, and (b) preference overriding. We illustrate the effectiveness of the proposed attack using various attack scenarios. Furthermore, we provide a proof-of-concept illustration for web domains including Banking u0026 shopping. We believe that the scenarios we use in use-case demonstration underlines the severity of the presented attack. Finally, we also contribute an initial framework to address the presented attack.	bugzilla;client-side;efficient xml interchange;firefox;recommender system;spectral leakage;xpcom	Anil Saini;Manoj Singh Gaur;Vijay Laxmi;Tushar Singhal;Mauro Conti	2014		10.1007/978-3-319-13841-1_15	computer security	Crypto	-54.67443822393378	59.71482009680816	122045
0eebb25d7a56e2cd1bb1dde1af7ceb8a41e264d8	streamlining management of multiple cloud services	measurement;contracts;law;data privacy;ontologies;cloud computing	With the increase in the number of cloud services and service providers, manual analysis of Service Level Agreements (SLA), comparison between different service offerings and conformance regulation has become a difficult task for customers. Cloud SLAs are policy documents describing the legal agreement between cloud providers and customers. SLA specifies the commitment of availability, performance of services, penalties associated with violations and procedure for customers to receive compensations in case of service disruptions. The aim of our research is to develop technology solutions for automated cloud service management using Semantic Web and Text Mining techniques. In this paper we discuss in detail the challenges in automating cloud services management and present our preliminary work in extraction of knowledge from SLAs of different cloud services. We extracted two types of information from the SLA documents which can be useful for end users. First, the relationship between the service commitment and financial credit. We represented this information by enhancing the existing Cloud service ontology proposed by us in our previous research. Second, we extracted rules in the form of obligations and permissions from SLAs using modal and deontic logic formalizations. For our analysis, we considered six publicly available SLA documents from different cloud computing service providers.	centralized computing;cloud computing;conformance testing;deontic logic;modal logic;privacy policy;semantic web;text mining	Aditi Gupta;Sudip Mittal;Karuna Pande Joshi;Claudia Pearce;Anupam Joshi	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0070	service provider;cloud computing;information privacy;computer science;ontology;operating system;database;world wide web;computer security;measurement	HPC	-48.73974730359028	51.97724468397888	122256
7e564242772ad55f3151f331024638e0c94675b1	security crash test - practical security evaluations of automotive onboard it components		Modern vehicles consist of many interconnected, software-based IT components which are tested very carefully for correct functional be havior to avoid safety problems, e.g. that the brakes suddenly stop working. Ho wever, in contrast to safety testing systematic testing against potential security gaps is not y et a common procedure within the automotive domain. This however could eventually enable a malicious entity to be able to attack a safety -critical IT component or even the whole vehicle. Several real-world demonstra tions have already shown that this risk is not only academic theory [1] . Facing this challenge, the paper at hand first introduces some potential automotive security attacks and some important automotive security threats. It then explains in more detail how to identify and evaluate potential security threats for a ut motive IT components based on theoretical security analyses and practica l security testing. Lastly, we propose “automotive security evaluation assurance levels” (ASEAL) which define up to four discrete security testing levels.	algorithm;penetration test;requirement;security testing	Stephanie Bayer;Thomas Enderle;Dennis Kengo Oka;Marko Wolf	2014			crash test;computer security;automotive industry;engineering	Security	-59.04091535154206	49.266360728306	122308
660a28ffc99da171232c5408b93b33bb5c6ba038	visualization of automated compliance monitoring and reporting	automated compliance monitoring;standards organizations;dashboard it compliance it risk management is security visualization;is security;risk management;internal control;data visualisation;visualization;monitoring;automated compliance reporting;proactive supervision;management information systems data visualisation;dashboard;compliance management;unified modeling language;data visualization;process control;it system support;management information systems;organizations;monitoring data visualization unified modeling language organizations standards organizations process control;it compliance;interactive user interface;it risk management;computational strengths automated compliance monitoring automated compliance reporting compliance management it system support proactive supervision;computational strengths;business process	Compliance management is a critical financial and legal subject for organizations. It is operationally implemented by embedding internal controls into business processes and their supporting IT systems. Challenges arise from the complexity of real-life processes and systems, their continuous monitoring and the timely communication of thereby detected problems. In order to realize effective and efficient monitoring, the responsible persons must be supported by suitable compliance software. This compliance software should enable the responsible persons to get both high-level information regarding the overall compliance status and low-level information regarding possible problems. Furthermore, it should not be limited to passive reporting components for compliance management, but also allow for interactive user interfaces, which facilitate the proactive supervision of tasks. The aim of this work is to encourage the responsible persons to analyze and explore compliance information through their appropriate visualization. Thus, unique and valuable human strengths, such as lateral thinking, can be used aside from the computational strengths of compliance software during control monitoring.	business process;graphical user interface;high- and low-level;lateral thinking;real life	Thorben Sandner;Matthias Kehlenbeck;Michael H. Breitner	2010	2010 Workshops on Database and Expert Systems Applications	10.1109/DEXA.2010.77	unified modeling language;visualization;it risk management;computer science;organization;knowledge management;data mining;database;business process;internal control;computer security;data visualization;dashboard	SE	-56.78868240612462	49.45094166316196	122634
aee2abea46257767b79ff74b5a26627df9259abe	a generic access control model based on ontology	information systems;ontologies artificial intelligence authorisation cost reduction;waste materials;information security;authorisation;prototypes;cost reduction generic knowledge ontology based access control prototype system efficiency enhancement;cost reduction;ontologies artificial intelligence;permission;heuristic algorithms;composition algorithm access control ontology;access control models;ontologies;access control;access control ontologies permission prototypes knowledge engineering information analysis costs information security waste materials information systems;information analysis;ontology;algorithm design and analysis;composition algorithm;knowledge engineering	In this paper, we mainly analyze the generic knowledge of access control method, and propose an ontology-based access control model which can describe different access control models. The paper details the formal description of access control ontologies, and proposes the composition algorithm which is based on access ontology. At last we give a prototype system which uses this model, the practice proves that the access control model can enhance the development efficiency and reduce the costs.	algorithm;computer access control;ontology (information science);prototype	Zhen-Wu Wang	2010	2010 IEEE International Conference on Wireless Communications, Networking and Information Security	10.1109/WCINS.2010.5541795	algorithm design;computer science;knowledge management;ontology;information security;access control;knowledge engineering;ontology;data mining;database;prototype;authorization;data analysis;computer security;process ontology;information system	DB	-48.96402137225026	51.247418033140676	122671
015be4441997586a346a4f6aedfd8d32c8612d16	a provenance-aware access control framework with typed provenance	software;xacml;sun xacml implementation provenance aware access control framework typed provenance model directed graph historical information data items provenance aware systems pas policy languages complex provenance graph layered architecture abstract layer tpm interpreters abstract provenance types provenance aware policy specification policy enforcement physical representations attribute based access control frameworks;access control semantics computer architecture abstracts software object oriented modeling;semantics;xacml typed provenance model provenance aware systems access control framework opm prov dm;computer architecture;provenance aware systems;prov dm;typed provenance model;abstracts;xml authorisation directed graphs formal specification;access control;opm;access control framework;object oriented modeling	Provenance is a directed graph that captures historical information about data items in Provenance-Aware Systems (PAS). A variety of access control models and policy languages specific to PAS have been recently discussed in literature. However, it is still not clear how to efficiently specify provenance-aware access control policies and how to effectively enforce these policies with respect to complex provenance graph that can only be captured at run-time. To this end, we design and implement a provenance-aware access control framework with a layered architecture that features an abstract layer, including a Typed Provenance Model (TPM) and a set of TPM interpreters. TPM includes a set of abstract provenance types enabling efficient specification of provenance-aware policies. New provenance types can be composed of extant ones for specifying new policies. TPM interpreters can be integrated to enable the policy enforcement with respect to provenance graphs in different physical representations. By treating provenance types as special attributes, the proposed framework enables an adoption of provenance-aware access control in existing attribute-based access control frameworks, such as XACML-compliant ones. We implement the proposed framework by extending SUN's XACML implementation and show that it facilitates the specification of provenance-aware policies in XACML with minor extensions. We also analyze the performance of the proposed framework.	access control;context-aware pervasive systems;directed graph;overhead (computing);prototype;run time (program lifecycle phase);trusted platform module;xacml	Lianshan Sun;Jaehong Park;Dang Nguyen;Ravi S. Sandhu	2016	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2015.2410793	computer science;access control;operating system;database;semantics;programming language;world wide web;computer security	Security	-48.73791838115062	51.05019012819199	122735
0f374f5672e523314af780bfe613309014e0bc13	organizational patterns for security and dependability: from design to application	organizational patterns;socio technical systems;dependable systems;dependability;security	Designing secure and dependable IT systems requires a d ep analysis of organizational as well as social aspects of the environment where the system will operate. Domain experts and analysts often face security and dependability (S&D) issues they have already encountered before. These concerns require the design of S&D patterns to faci lit te designers when developing IT systems. This article presents our experience in designing S &D organizational patterns, which we have gained in the course of an industry lead EU project . We use an agent-goal-oriented modeling framework (i.e., the SI* framework) to analyze organizational settings join tly with technical functionalities. We demonstrate how this framework can assist domain experts and analysts in designing S&D patterns from their experience, valid ating them by proof-of-concept implementations, and applying them to increase the security level of the system.	dependability;software design pattern	Yudistira Dwi Wardhana Asnar;Fabio Massacci;Ayda Saïdane;Carlo Riccucci;Massimo Felici;Alessandra Tedeschi;Paul El Khoury;Keqin Li;Magali Seguran;Nicola Zannone	2011	IJSSE	10.4018/jsse.2011070101	computer science;knowledge management;information security;sociotechnical system;dependability;computer security	Security	-55.36197782716576	48.405652013683884	122792
67dd49ea944de8926bf67452848c3dad5f866072	an improved rbac model and its application	permission access control information security management information systems technology management authorization information management genetics application software licenses;computers;roles access control technology;authorisation;permission assignment;management information systems authorisation;model rbac;improved rbac model;system security;computational modeling;rbac;permission;information management;model;management information systems;authorization;information system;management information system;role assignment;role assignment improved rbac model system security management information system roles access control technology permission assignment	In this paper, it is proposed the improved RBAC model based on traditional RBAC. The improved RBAC model adds restrictions on the role assignment for the user and introduces user group, it improves the system security and flexibility, reducing the complexity of the permission assignment. The improved RBAC model can be easily applied to other information systems, now it has practical significance in the management information system.	management information system;role-based access control	Zi Zhang;Ting-lei Huang	2009	2009 Third International Conference on Genetic and Evolutionary Computing	10.1109/WGEC.2009.203	computer science;management information systems;database;authorization;world wide web;computer security	EDA	-49.03383749804897	51.3179100233371	123145
3c08ed6cd599bf8119181369fca6c1505e99f9da	using timing-based side channels for anomaly detection in industrial control systems	anomaly detection;programmable logic controllers;industrial control systems;modification attacks;side channels	The critical infrastructure, which includes the electric power grid, railroads and water treatment facilities, is dependent on the proper operation of industrial control systems. However, malware such as Stuxnet has demonstrated the ability to alter industrial control system parameters to create physical effects. Of particular concern is malware that targets embedded devices that monitor and control system functionality, while masking the actions from plant operators and security analysts. Indeed, system security relies on guarantees that the assurance of these devices can be maintained throughout their lifetimes. This paper presents a novel approach that uses timing-based side channel analysis to establish a unique device fingerprint that helps detect unauthorized modifications of the device. The approach is applied to an Allen Bradley ControlLogix programmable logic controller where execution time measurements are collected and analyzed by a custom anomaly detection system to detect abnormal behavior. The anomaly detection system achieves true positive rates of 0.978–1.000 with false positive rates of 0.033–0.044. The test results demonstrate the feasibility of using timing-based side channel analysis to detect anomalous behavior in programmable logic controllers. Published by Elsevier B.V.	anomaly detection;authorization;control system;critical infrastructure protection;device fingerprint;embedded system;malware;programmable logic device;run time (program lifecycle phase);side-channel attack;stuxnet	Stephen Dunlap;Jonathan Butts;Juan Lopez;Mason Rice;Barry E. Mullins	2016	IJCIP	10.1016/j.ijcip.2016.07.003	anomaly detection;industrial control system;real-time computing;telecommunications;computer science;engineering;programmable logic controller;computer security	Security	-57.036579302050065	52.60707361570737	123240
7c96f972b2a9f96a39312cceb1de9cc4bc13d12b	oauth 2.0 token introspection		This specification defines a method for a protected resource to query#N#an OAuth 2.0 authorization server to determine the active state of an#N#OAuth 2.0 token and to determine meta-information about this token.#N#OAuth 2.0 deployments can use this method to convey information about#N#the authorization context of the token from the authorization server#N#to the protected resource.	introspection;oauth	Justin Richer	2015	RFC	10.17487/RFC7662	computer science;database;computer security;computer network	HCI	-50.747195219941176	55.23949235965414	123350
2a797414e3085f50227ba1de7df0dc5f965e5de2	a cyber-physical experimentation environment for the security analysis of networked industrial control systems	articles in periodicals and books	Although many studies address the security of Networked Industrial Control Systems (NICS), today we still lack an efficient way to conduct scientific experiments that measure the impact of attacks against both the physical and the cyber parts of these systems. This paper presents an innovative framework for an experimentation environment that can reproduce concurrently physical and cyber systems. The proposed approach uses an emulation testbed based on Emulab to recreate cyber components and a real-time simulator, based on Simulink, to recreate physical processes. The main novelty of the proposed framework is that it provides a set of experimental capabilities that are missing from other approaches, e.g. safe experimentation with real malware, flexibility to use different physical processes. The feasibility of the approach is confirmed by the development of a fully functional prototype, while its applicability is proven through two case studies of industrial systems from the electrical and chemical domain.	control system;emulator;experiment;malware;prototype;real-time clock;simulation;simulink;testbed	Béla Genge;Christos Siaterlis;Igor Nai Fovino;Marcelo Masera	2012	Computers & Electrical Engineering	10.1016/j.compeleceng.2012.06.015	simulation;telecommunications;computer science;engineering;electrical engineering;artificial intelligence;operating system;computer security	Embedded	-56.93905565060521	52.016061538669916	123381
290fe60773c8b17999e09cb3550de2fee792a692	risksoap: on the relationship between systems safety and the risk sa provision capability	uberlingen accident risk situation awareness sa provision risksoap risksoap capability sa degradation safety awareness relationship safety drift;safety accidents sociotechnical systems aircraft process control sensors companies	It is generally accepted that there is a relation between safety and awareness. Yet, there is no quantitative evidence for this relationship because the correlated entities are difficult to be quantified. This paper responds to this challenge by measuring the “risk situation awareness (SA) provision (RiskSOAP) capability.” According to the complex sociotechnical system design and development, there is an inherent capability of each system part to provide its agent with SA about the presence of system threats and vulnerabilities, possibly leading to accidents. This capability is called herein “risk SA” and stems from the number, type, and characteristics of the elements that shape the system parts; laying the foundation for the emergence of risk SA on a system level. Under this notion, this paper adopts the RiskSOAP methodology as a means to quantify the different states of a system in terms of its RiskSOAP capability, using the Überlingen mid-air collision accident as a case study. The case study results showed that the RiskSOAP capability degrades while the system is headed to the accident state. This is attributed to the presence of flaws in the system involved in the Überlingen accident. This study also offers insight to the limitations of the proposed methodology and suggests the future work to overcome them.	awareness;emergence;entity;sociotechnical system;systems design;vulnerability (computing)	Maria Mikela Chatzimichailidou;Ioannis M. Dokas	2018	IEEE Systems Journal	10.1109/JSYST.2016.2614953	process control;collision;sociotechnical system;situation awareness;computer science;laying;vulnerability;reliability engineering	SE	-55.101012041001034	46.7963669700099	123641
813321fe9fedda4fe0bb178b7059ccb710415b0d	jitsu: just-in-time summoning of unikernels	article	Network latency is a problem for all cloud services. It can be mitigated by moving computation out of remote datacenters by rapidly instantiating local services near the user. This requires an embedded cloud platform on which to deploy multiple applications securely and quickly. We present Jitsu, a new Xen toolstack that satisfies the demands of secure multi-tenant isolation on resource-constrained embedded ARM devices. It does this by using unikernels: lightweight, compact, single address space, memory-safe virtual machines (VMs) written in a high-level language. Using fast shared memory channels, Jitsu provides a directory service that launches unikernels in response to network traffic and masks boot latency. Our evaluation shows Jitsu to be a power-efficient and responsive platform for hosting cloud services in the edge network while preserving the strong isolation guarantees of a type-1 hypervisor.	arm architecture;address space;application binary interface;bsd;cloud computing;computation;directory service;documentation;embedded system;high- and low-level;high-level programming language;hypervisor;memory safety;multitenancy;network traffic control;shared memory;unikernel;virtual machine;x86	Anil Madhavapeddy;Thomas Leonard;Magnus Skjegstad;Thomas Gazagnaire;David Sheets;David J. Scott;Richard Mortier;Amir Chaudhry;Balraj Singh;Jon Ludlam;Jon A Crowcroft;Ian M. Leslie	2015			embedded system;real-time computing;computer science;operating system;database;distributed computing;computer security;computer network	Networks	-52.86250246955333	56.73268914052207	124158
c2d2bdd75585dece39bb9be31fd641c01e10b4bb	discovering application-level insider attacks using symbolic execution	insider attack;text;formal model;symbolic execution;model checking	This paper presents a technique to systematically discover insider attacks in applications. An attack model where the insider is in the same address space as the process and can corrupt arbitrary data is assumed. A formal technique based on symbolic execution and model-checking is developed to comprehensively enumerate all possible insider attacks corresponding to a given attack goal. The main advantage of the technique is that it operates directly on the program code in assembly language and no manual effort is necessary to translate the program into a formal model. We apply the technique to security-critical segments of the OpenSSH application.	address space;assembly language;attack model;authentication;code segment;enumerated type;mathematical model;model checking;openssh;symbolic execution	Karthik Pattabiraman;Nithin Nakka;Zbigniew T. Kalbarczyk;Ravishankar K. Iyer	2009		10.1007/978-3-642-01244-0_6	model checking;computer science;operating system;database;distributed computing;computer security	SE	-55.6192113241092	54.08201959618624	124291
82338b42f2df90a16b33d9cb7964d2dea3837b8e	systems design of cybersecurity in embedded systems	computers;measurement;system analysis and design;computer security;computer architecture;cryptography	Mission critical embedded systems should be capable of performing intended functions with resiliency against cyberattacks. The methodology of design-for-cybersecurity is now widely recognized, in which the effects of cybersecurity, or lack thereof, on system objectives must be determined. However, developers are often challenged by the difficulty of analyzing a system-under-design without complete specifics. In this paper, we describe a systems design approach, which incrementally models the cybersecurity architecture, components, and interfaces of an embedded system for analysis and demonstration. We have applied this approach to analyze the mission resiliency of an avionic computer being developed and demonstrate its operations in a scenario when the system is under attack.	bayesian network;computer security;embedded system;experiment;mission critical;programming tool;systems design	Michael Vai;David Whelihan;Nicholas Evancich;Kyung Joon Kwak;Jincheng Li;M. Britton;J. Foley;M. Lynch;Douglas Schafer;J. DeMatteis	2016	2016 IEEE High Performance Extreme Computing Conference (HPEC)	10.1109/HPEC.2016.7761615	embedded system;engineering;computer security;computer engineering	EDA	-56.50419804309183	50.334812716510164	124564
3ca938c990c684ec4e29d2d132bf2e5ef9c2f771	beyond full abstraction: formalizing the security guarantees of low-level compartmentalization		Compartmentalization is widely regarded as good security-engineering practice: if we break up a large software system into mutually distrustful components that run with minimal privileges, restricting their interactions to conform to well-defined interfaces, we can limit the damage caused by lowlevel attacks such as control-flow hijacking. But the formal guarantees provided by such low-level compartmentalization have seen surprisingly little investigation. We propose a new property, secure compartmentalization, that formally characterizes the security guarantees provided by lowlevel compartmentalization and clarifies its attacker model. We rationally reconstruct the secure compartmentalization property starting from the well-established notion of fully abstract compilation, by identifying and lifting three important limitations that make standard full abstraction unsuitable for compartmentalization. The connection to full abstraction allows us to prove secure compartmentalization for language implementations by adapting established proof techniques; we illustrate this for a simple unsafe imperative language with procedures and a compiler from this language to a compartmentalized abstract machine.	abstract machine;capability-based addressing;compcert;compartmentalization (information security);compiler;control flow;denotational semantics;high- and low-level;imperative programming;interaction;lambda lifting;network compartment;sandbox (computer security);security engineering;software system;whole earth 'lectronic link;phpmyadmin	Yannis Juglaret;Catalin Hritcu;Arthur Azevedo de Amorim;Benjamin C. Pierce	2016	CoRR		real-time computing;computer science;database;programming language	Security	-54.26080622321947	53.488496392823485	125089
c9fcebd2cc4b4d52940b791fb1cbc88dfc2baa8b	realization of fgac model using xacml policy specification	databases;standards organizations;fine grained access control;xml authorisation business data processing data protection query processing;policy specification language;extensible access control markup language;policy decision point;policy evaluation procedure fgac model realization xacml policy specification enterprise applications database protection query modification algorithms software development languages distributed computing environments standard fgac profile specification fgac authorization techniques web 2 0 computing environments standard based fine grained access control;computational modeling;authorization;access control;organizations;policy administration point;policy decision point fine grained access control authorization extensible access control markup language policy specification language policy administration point;access control organizations computational modeling databases standards organizations	FGAC model has been adopted by enterprise applications, for the protection of their databases. Most of these deployments are not only limited in purpose but are dependent upon various other factors including query modification algorithms and software development languages. These factors have not only limited their applicability for distributed computing environments but have also affected their widespread adoption and acceptance. Moreover, due to the absence of standard FGAC profile specification, existing FGAC authorization techniques become unsuitable for advance applications such as Web 2.0 and cannot be deployed across various platforms, thus fall short of flexibility and customizability. As a result, there is an increasing demand for standard based FGAC specification that could be easily fit into majority of computing environments. In this paper, we bring forth a policy specification (profile) for FGAC model. Our proposed specification is not restricted to database applications only; rather it is generic and flexible enough to be applied on every type of application. It explicates the ways in which organizations would be able to implement standard based fine-grained access control for nearly every application. We present the case-study - a realization of FGAC model based on the proposed policy specification followed by a complete dryrun of policy evaluation procedure.	access control;algorithm;authorization;bespoke;case preservation;confidentiality;database;distributed computing;enterprise software;extensibility;requirement;software deployment;software developer;software development;specification language;system administrator;web 2.0;xacml	Muhammad Awais Shibli;Rahat Masood;Umme Habiba	2015	2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2015.7176199	computer science;organization;access control;operating system;software engineering;data mining;database;authorization;programming language;computational model;world wide web;computer security;computer network	SE	-50.230341358949524	51.2854076086165	125434
6ca8a7352038e5216a947d9f1b5ece37ead815b9	toward a target function of an information security management system	feedback mechanism;plan do check act;2 textrm nd order management system;management system;information security;security of data business continuity discrete event systems feedback information management;iso standards;isms;business continuity management system;policy implementation;actuators;pdca cycle standards;companies;automata iso standards actuators companies process control;dynamic policy implementation;information security management system;balance system;automata;static dynamic policies;control system;discrete event system;feedback;economic impact;business continuity;iso iec 27001;information management;information security management;discrete event systems;process control;next generation;bcms target function information security management system computer science dynamic policy implementation discrete event system advanced management system plan do check act pdca cycle standards iso iec 27001 isms business continuity management system;1 textrm st order management system;control loop;computer science;advanced management system;security of data;2 textrm nd order management system static dynamic policies control loop 1 textrm st order management system balance system;target function;bcms;business continuity management	The limits of traditional (static) policies are well-known in many areas of computer science and information security, and are extensively discussed in the literature. Although some flexibility has been achieved with the introduction of dynamic policies, these efforts have only addressed a fraction of the requirements necessary to secure today's enterprises. Currently, no feedback mechanisms are in place to evaluate the effectiveness or economic impacts of static or dynamic policy implementation. Here, we address the requirement for feedback and present a policy for the next generation. This is a policy that includes a dynamic feedback response to the effectiveness of changes. The structure of this new type of policy, called a ``management system'', is borrowed from discrete event system (DES) theory and functions as a control loop. A management system consists of four elements (control system, sensor, controller, and actuator) that are involved in a control law. Two types of management system can be defined. A simple management system (1$^\textrm{st}$ order management system) responds to and regulates only perturbations. An advanced management system (2$^\textrm{nd}$ order management system) has an overarching target function that influences the controller. This target function is usually economically oriented. Finally, we compare our new type of policy with two management systems that follows the Plan-Do-Check-Act (PDCA cycle) model. We investigate the two PDCA cycle standards ISO/IEC 27001 (Information Security Management System, ISMS) and BS 25999 (Business Continuity Management System, BCMS). We also show that the new type of policy can be applied to management systems based on a PDCA cycle.	business continuity planning;computer science;control system;feedback;iso/iec 27001:2013;information security;optimal control;order management system;perturbation theory;requirement;scott continuity;security management	Wolfgang Boehmer	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.154	information security management system;computer science;control system;operating system;feedback;database;computer security;computer network	DB	-50.221184922941795	52.087667360498365	125493
e844ac92bbfdc6a8425c70fea087269c30fa3a67	vulnerability modeling and analysis for critical infrastructure protection applications	railway infrastructure;uml profiles;physical vulnerability assessment	Effective critical infrastructure protection requires methodologies and tools for the automated evaluation of the vulnerabilities of assets and the efficacy of protection systems. This paper presents a modeling language for vulnerability analysis in critical infrastructure protection applications. The language extends the popular Unified Modeling Language (UML) to provide vulnerability and protection modeling functionality. The extended language provides an abstract representation of concepts and activities in the infrastructure protection domain that enables model-to-model transformations for analysis purposes. The application of the language is demonstrated through a use case that models vulnerabilities and physical protection systems in a railway station. & 2013 Elsevier B.V. All rights reserved.	critical infrastructure protection;unified modeling language;vulnerability (computing)	Stefano Marrone;Roberto Nardone;Annarita Tedesco;Pasquale D'Amore;Valeria Vittorini;Roberto Setola;Francesca De Cillis;Nicola Mazzocca	2013	IJCIP	10.1016/j.ijcip.2013.10.001	reliability engineering;systems engineering;engineering;vulnerability assessment;computer security	SE	-54.62468966818149	48.17318251824301	125635
0306a9e3434f1989da9cff6e216a912614e07391	towards blockchain-based identity and access management for internet of things in enterprises		With the Internet of Things (IoT) evolving more and more, companies active within this area face new challenges for their Identity and Access Management (IAM). Namely, general security, resource constraint devices, interoperability, and scalability cannot be addressed anymore with traditional measures. Blockchain technology, however, may act as an enabler to overcome those challenges. In this paper, general application areas for blockchain in IAM are described based on recent research work. On this basis, it is discussed how blockchain can address IAM challenges presented by IoT. Finally, a corporate scenario utilizing blockchain-based IAM for IoT is outlined to assess the applicability in practice. The paper shows that private blockchains can be leveraged to design tamper-proof IAM functionality while maintaining scalability regarding the number of clients and transactions. This could be useful for enterprises to prevent single-point-of-failures as well as to enable transparent and secure auditing u0026 monitoring of security-relevant events.	bitcoin;identity management;internet of things	Martin Nuss;Alexander Puchta;Michael Kunz	2018		10.1007/978-3-319-98385-1_12	internet privacy;computer security;computer science;access control;scalability;interoperability;identity management;audit;blockchain;internet of things	Networks	-48.50368830851451	55.67652319239936	125676
d5a3f6a9639e4040e1b3bb9a61c9a3ade9e89993	feature-chain based malware detection using multiple sequence alignment of api call			application programming interface;malware;multiple sequence alignment	Hyunjoo Kim;Jong-Hyun Kim;Jung-Tai Kim;Ikkyun Kim;Tai-Myung Chung	2016	IEICE Transactions		multiple sequence alignment;computer science;internet privacy;world wide web;computer security	ML	-57.07803715994888	58.77439923744048	125732
cb83b49c0fdfa028bae619cb5f84e769ab41f49a	trust-based formal delegation framework for enterprise social networks		Collaborative environments raise major challenges to secure them. These challenges increase when it comes to the domain of Enterprise-Social-Networks (ESNs) as ESNs aim to incorporate the social technologies in an organization setup while asserting greater control of information security. In this context, the security challenges have taken a new shape as an ESN may not be limited to the boundaries of a single organization and users from different organizations can collaborate in a common federated environment. In this paper, we address the problem of the authorization's delegation in federated collaborative environments like ESNs. In contrast to traditional XML based languages, such as XACML, our approach is based on event-calculus, a temporal logic programming formalism. Further, the traditional approaches are either user-centric or organization-centric. However, the domain of ESN requires to bridge the gap between them and the proposed framework deals with this challenge. In order to enhance the delegation scheme, we have proposed a behavior monitoring mechanism, that permits to assess principals' trust level within the federated collaborative environment. We evaluate our trust computing approach based on simulated principals' behaviors and discuss the obtained results.	access control;authorization;autonomy;echo state network;enterprise social networking;event calculus;federated architecture;information security;logic programming;real-time clock;semantics (computer science);social network;temporal logic;xacml;xml	Ahmed Bouchami;Olivier Perrin;Ehtesham Zahoor	2015	2015 IEEE Trustcom/BigDataSE/ISPA	10.1109/Trustcom.2015.366	knowledge management;database;business;computer security	Web+IR	-48.36754229014594	53.46960323928701	125955
6c0de1dce1dcd1b48c5bf37bbde6c2a69ca2040b	security challenges in cloud computing: state-of-art	cloud security;ddos defence mechanisms;availability;ddos attacks;distributed dos;denial of service;taxonomy;cloud computing;data security	Cloud computing platform provides on-demand access of services, and these services can also be customised, which enables the customers to use these services as per their requirement and they also need to pay according to their uses. Recent advancements in the field of cloud computing and internet technologies have attracted the organisations to shift their businesses on cloud. However, moving data and applications to a third party services provider also raises critical concern for security and privacy. Availability of cloud services is one of the most important security issues which directly affect the business of the cloud service providers and also its customers. Distributed denial of service (DDoS) attack on cloud is the root cause that challenges the availability of cloud services. This paper presents taxonomy of security issues in cloud, taxonomy of DDoS attacks in cloud, and taxonomy of DDoS defence mechanisms in cloud environment. We have also discussed, analysed, and compared some well-known metho...	cloud computing	Kriti Bhushan;B. B. Gupta	2017	IJBDI	10.1504/IJBDI.2017.10002912	cloud computing security;cloud computing;cloud testing;business;services computing;internet privacy;computer security;computer network	HPC	-49.789675669423225	58.43982480026988	126005
37e916cdcab61cf0f56954b16f4f1db67a5ef687	verifying information flow control over unbounded processes	policy enforcement;information flow control;communication channels	Decentralized Information Flow Control (DIFC) systems enable programmers to express a desired DIFC policy, and to have the policy enforced via a reference monitor that restricts interactions between system objects, such as processes and files. Current research on DIFC systems focuses on the referencemonitor implementation, and assumes that the desired DIFC policy is correctly specified. The focus of this paper is an automatic technique to verify that an application, plus its calls to DIFC primitives, does indeed correctly implement a desired policy. We present an abstraction that allows a model checker to reason soundly about DIFC programs that manipulate potentially unbounded sets of processes, principals, and communication channels. We implemented our approach and evaluated it on a set of real-world programs.	information flow;interaction;model checking;non-interference (security);programmer;reference monitor	William R. Harris;Nicholas Kidd;Sagar Chaki;Somesh Jha;Thomas W. Reps	2009		10.1007/978-3-642-05089-3_49	real-time computing;computer science;distributed computing;computer security;channel	PL	-53.985500930676345	53.337352864570455	126121
994d128be6f614bed0006afbc87954c7f692cb51	hardware-assisted fine-grained code-reuse attack detection	会议论文;code reuse attack;control flow integrity;indirect branch tracing	Code-reuse attacks have become the primary exploitation technique for system compromise despite of the recently introduced Data Execution Prevention technique in modern platforms. Different from code injection attacks, they result in unintended control-flow transfer to victim programs without adding malicious code. This paper proposes a practical scheme named as CFIGuard to detect code-reuse attacks on user space applications. CFIGuard traces every branch execution by leveraging hardware features of commodity processors, and then validates the traces based on fine-grained control flow graphs. We have implemented a prototype of CFIGuard on Linux and the experiments show that it only incurs around 2.9 % runtime overhead for a set of typical server applications.	central processing unit;code injection;code reuse;control flow;experiment;linux;malware;overhead (computing);prototype;server (computing);tracing (software);user space	Pinghai Yuan;Qingkai Zeng;Xuhua Ding	2015		10.1007/978-3-319-26362-5_4	computer science;operating system;distributed computing;computer security	Security	-55.12636029026259	56.759974984264915	126145
1a778c8592defb5feea97dfb9639d53f87e9a93e	current trend of end-users' behaviors towards security mechanisms				Yasser M. Hausawi	2016		10.1007/978-3-319-39381-0_13		Crypto	-49.18030541081848	56.21681480456044	126165
f1111738686594657a92fd8f92bf216b12211698	alidrone: enabling trustworthy proof-of-alibi for commercial drone compliance		Commercial use of Unmanned Aerial Vehicles (UAVs), or drones, promises to revolutionize the way in which consumers interact with retail services. However, the further adoption of UAVs has been significantly impeded by an overwhelming public outcry over the privacy implications of drone technology. While lawmakers have attempted to establish standards for drone use (e.g., No-Fly-Zones (NFZs)), at present a general technical mechanism for policy enforcement eludes state-of-the-art drones. In this work, we propose that Proof-of-Alibi (PoA) protocols should serve as the basis for enforcing drone privacy compliance. We design and implement AliDrone, a trustworthy PoA protocol that enables individual drones to prove their compliance with NFZs to a third party Auditor. AliDrone leverages trusted hardware to produce cryptographically-signed GPS readings within a secure enclave, preventing malicious drone operators from being able to forge geo-location information. AliDrone features an adaptive sampling algorithm that reacts to NFZ proximity in order to minimize the processing cost. Through laboratory benchmarks and field studies, we demonstrate that AliDrone provides strong assurance of geo-location while imposing an average of 1.5% overhead on CPU utilization and 0.3% of memory consumption. AliDrone thus enables the further proliferation of drone technology through the introduction of a trustworthy and accountable compliance mechanism.	adaptive sampling;aerial photography;algorithm;central processing unit;fly-by-wire;forge;geolocation;hardware restriction;overhead (computing);sampling (signal processing);trustworthy computing;unmanned aerial vehicle	Tianyuan Liu;Avesta Hojjati;Adam M. Bates;Klara Nahrstedt	2018	2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2018.00086	cpu time;computer security;operator (computer programming);trustworthiness;distributed computing;global positioning system;drone;enforcement;audit;computer science;alibi	Mobile	-50.442170274283185	56.47902490209815	126587
3a30cf86b5c625e0b3c91490a867c43bf697ae27	single-level integrity and confidentiality protection for distributed shared memory multiprocessors	multiprocessor interconnection networks;protocols;architectural support;splash 2 application single level integrity confidentiality protection distributed shared memory multiprocessors multiprocessor computer systems sensitive data customer record credit card number financial data data stealing data tampering data integrity architectural support software based attack hardware based attack point to point based interconnection network performance overhead cryptographic operation;data integrity;point to point;point to point based interconnection network;data tampering;radiation detectors;authentication;confidentiality protection;customer record;credit card number;system on a chip;interconnection network;financial data;data stealing;multiprocessor interconnection networks cryptography data integrity data privacy distributed shared memory systems;data privacy;cryptography;performance overhead;cryptography radiation detectors security authentication coherence system on a chip protocols;distributed shared memory systems;splash 2 application;coherence;dis tributed shared memory;sensitive data;distributed shared memory multiprocessors;cryptographic operation;data confidentiality;single level integrity;security;distributed shared memory;hardware based attack;credit cards;multiprocessor computer systems;software based attack	Multiprocessor computer systems are currently widely used in commercial settings to run critical applications. These applications often operate on sensitive data such as customer records, credit card numbers, and financial data. As a result, these systems are the frequent targets of attacks because of the potentially significant gain an attacker could obtain from stealing or tampering with such data. This provides strong motivation to protect the confidentiality and integrity of data in commercial multiprocessor systems through architectural support. Architectural support is able to protect against software-based attacks, and is necessary to protect against hardware-based attacks. In this work, we propose architectural mechanisms to ensure data confidentiality and integrity in Distributed Shared Memory multiprocessors which utilize a point-to-point based interconnection network. Our approach improves upon previous work in this area, mainly in the fact that our approach reduces performance overheads by significantly reducing the amount of cryptographic operations required. Evaluation results show that our approach can protect data confidentiality and integrity in a 16-processor DSM system with an average overhead of 1.6% and a maximum of only 7% across all SPLASH-2 applications.	algorithm;authentication;central processing unit;confidentiality;cryptography;data integrity;distributed shared memory;encryption;interconnection;multi-level cell;multiprocessing;overhead (computing);point-to-point protocol;run time (program lifecycle phase);uniprocessor system	Brian Rogers;Chenyu Yan;Siddhartha Chhabra;Milos Prvulovic;Yan Solihin	2008	2008 IEEE 14th International Symposium on High Performance Computer Architecture	10.1109/HPCA.2008.4658636	system on a chip;distributed shared memory;parallel computing;coherence;information privacy;computer science;cryptography;information security;operating system;data integrity;authentication;distributed computing;computer security;computer network	Arch	-53.383441893211476	55.84667080212282	126883
02755be5d5f2c99eabbc0b67363c5222c66a73b5	cybersecurity situational awareness taxonomy		Ensuring cost-efficient cybersecurity for a networked system is a challenging task. In this task, cybersecurity situational awareness is a cornerstone to ensure that systems are protected in a meaningful way. However, cybersecurity situational awareness can be built in various ways. Firstly, several monitoring and analysing techniques can be applied, and secondly, a time window for the usage of situational awareness varies from short-term operational to long-term strategic decision making. Understanding differences and purposes of these aspects is an essential part to research and develop cybersecurity situational awareness. In this paper, we build a taxonomy of cybersecurity situational awareness. The taxonomy categorises terminology, makes it possible to recognise missing areas, and to understand the area in a uniform way. Moreover, the taxonomy helps to select the most effective techniques to be used in a specific situation awareness implementation.	computer security;cost efficiency;high- and low-level;security awareness;taxonomy (general);vii	Antti Evesti;Teemu Kanstrén;Tapio Frantti	2017	2017 International Conference On Cyber Situational Awareness, Data Analytics And Assessment (Cyber SA)	10.1109/CyberSA.2017.8073386	terminology;situation awareness;computer security;risk analysis (business);knowledge management;engineering;analytics	SE	-57.24749759255939	49.58943428940083	126925
9730d01b17e937c5e85f6af93652653533e32b97	a hijacker's guide to communication interfaces of the trusted platform module	trusted platform module;trusted computing;embedded systems;simple hardware attacks;security	In this paper, we analyze the communication of trusted platform modules and their interface to the hosting platforms. While trusted platform modules are considered to be tamper resistant, the communication channel between these modules and the rest of the trusted platform turns out to be comparatively insecure. It has been shown that passive attacks can bemounted against TPMs and their bus communicationwith fairly inexpensive equipment, however, similar active attacks have not been reported, yet. We pursue the idea of an active attack and show how the communication protocol of the LPC bus can be actively manipulated with basic and inexpensive equipment. Moreover, we show how our manipulations can be used to circumvent the security mechanisms, e.g. the chain of trust, provided by modern trusted platforms. In addition, we demonstrate how the proposed attack can be extended to manipulate communication buses on embedded systems. © 2012 Elsevier Ltd. All rights reserved.	adversary (cryptography);authorization;bus (computing);chain of trust;channel (communications);cold boot attack;communications protocol;desktop computer;embedded system;emulator;file spanning;interaction;lpc;locality of reference;low pin count;one-to-one (data model);personal computer;physical access;plaintext;reboot (computing);soldering;tamper resistance;trust (emotion);trusted platform module	Johannes Winter;Kurt Dietrich	2013	Computers & Mathematics with Applications	10.1016/j.camwa.2012.06.018	embedded system;direct anonymous attestation;hengzhi chip;information security;trusted network connect;trusted platform module;trustworthy computing;world wide web;computer security	Security	-51.680545533584436	58.51040147452269	127004
95b8d57f1de2e4a056df0e8bfbae703f11c6d9f5	reconciling ihe-atna profile with a posteriori contextual access and usage control policy in healthcare environment	ihe atna;radiology;integrating the healthcare enterprise;healthcare environment;standards organizations;node authentication access control mechanism contextual access usage control policy healthcare environment ihe atna profile illegal access violation detection security policy model healthcare enterprise integration framework audit trail atna log record;usage control policy;authorisation;audit access control model ihe atna;security policy model;atna log record;ihe atna profile;access control mechanism;access control model;records management;illegal access;context access control organizations medical services radiology standards organizations;usage control;access control policy;medical services;contextual access;medical information systems;access control models;violation detection;node authentication;access control;organizations;point of view;records management authorisation health care medical information systems;security policy;audit;context;audit trail;healthcare enterprise integration framework;health care	Traditional access control mechanisms prevent illegal access by controlling access right before executing an action; they belong to a class of a priori security solutions and, from this point of view, they have some limitations, like inflexibility in unanticipated circumstances. By contrast, a posteriori mechanisms enforce policies not by preventing unauthorized access, but rather by deterring it. Such access control needs evidence to prove violations. Evidence is derived from one or several log records, which trace each user's actions. Efficiency of violation detection mostly depends on the compliance of log records with the access control policy. In order to develop an efficient method for finding these violations, we propose restructuring log records according to a security policy model. We illustrate our methodology by applying it to the healthcare domain, taking care of the IHE (Integrating the healthcare enterprise) framework, particularly its basic security profile, ATNA (Audit Trail and Node Authentication). This profile defines log records established on the analysis of common health practice scenarios. We analyze and establish how ATNA log records can be refined in order to be integrated into an a posteriori access and usage control process, based on an expressive and contextual security policy like the OrBAC policy.	ambiguous name resolution;authentication;authorization;care-of address;computer security model;control system;converge;information system;organisation-based access control;software deployment;trust (emotion)	Hanieh Azkia;Nora Cuppens-Boulahia;Frédéric Cuppens;Gouenou Coatrieux	2010	2010 Sixth International Conference on Information Assurance and Security	10.1109/ISIAS.2010.5604060	computer access control;data mining;database;business;computer security	Security	-49.83301059315332	52.39210260959001	127420
f5d8950ed83e727820b96ceaeb7818f6861179ba	a fake timing attack against behavioural tests used in embedded iot m2m communications		Interconnected embedded machines in the Internet of Things (IoT) play a key role for collecting and managing data from the real environment. These machines adopt Machine-to-Machine (M2M) networks in order to exchange information. Securing this information is therefore essential. However, these machines have reduced capabilities giving the opportunity to be easily compromised. IoT trust agents in embedded machines can use timing-based behavioural tests in order to trust each other. However, attackers can use powerful systems to subvert the network by launching a fake timing attack. This attack consists of mimicking the timing behaviours of real embedded machines. In this work, we present a detection algorithm for detecting this attack and also detecting forged embedded machines based on virtual and emulated systems. This will allow IoT embedded machines to create trusted M2M communications.	algorithm;embedded system;emulator;internet of things;machine to machine;sensor	Valerio Selis;Alan Marshall	2017	2017 1st Cyber Security in Networking Conference (CSNet)	10.1109/CSNET.2017.8241991	timing attack;virtual machining;distributed computing;internet of things;computer science	Embedded	-52.405299040810995	57.11814531087588	127523
499645d694bcd80f7dfe987d1a9bc6d802a270c4	venerability and protection tool surveys of industrial control system		The rapid development of the Internet has also accelerated the growth of the Internet of Things, IOT. The isolated systems have been transformed to open ones by the key infrastructures of IOT which has been made the operation of the entire system more convenient. But relatively, the security of key infrastructure will face unprecedented threats. Therefore, it is necessary to establish a safe and secure way for the Industrial Control Systems, ICS, to operate through remote control. In other words, it is necessary to understand in depth the tools that can protect the country's economy and security of the system and prevent attackers from invading the ICS system or avoiding at-tacks on ICS systems. This study will explore the current tools and technologies used to discover ICS system vulnerabilities and provide alternative methods to protect SCADA system security.		Kuan-Chu Lu;I-Hsien Liu;Jung-Shian Li	2018	2018 Sixth International Symposium on Computing and Networking Workshops (CANDARW)	10.1109/CANDARW.2018.00099		Arch	-51.27005962233824	60.29104338936523	127777
30026238efeea0e37fece2012a9b4ab12be9cccf	web service-based business process development, threat modeling and security assessment tool	web service-based business process;security assessment tool;xml;web services;security threat modeling;business process development;web service;business data processing;threat modeling;protocol;security of data;computer science;computer architecture;business;security;business process	A business process is a collection of related structures and activities, undertaken by organizations in order to achieve certain business goals. The Web services-based business processes with a new set of protocols bring a new set of security challenges. As security has become an essential component for all software, several security solutions for XML and Web services have been proposed. In general, a security threat model is an organized representation of relevant threats, attacks, and vulnerabilities to a system. In this context, security threat modeling is an engineering technique which can be used to shape the Web service-based business processes with security requirements. The topic of security threat modeling in business process is becoming increasingly important to industry. This tutorial strives to reflect recent trends in research and developments of business processes integration and management with security concerns. In addition this tutorial will cover the fundamental concepts of security threat modeling from the perspectives of Web service-based business process. This tutorial will also address the common practices and related tools/procedures for addressing the security vulnerabilities, especially in XML attacks. A research prototype of security assessment will also be presented and demonstrated in the tutorial.	business process;prototype;requirement;threat model;vulnerability (computing);web service;world wide web;xml	Jianxin Li;Teodor Sommestad;Patrick C. K. Hung;Xiang Li	2008	2008 IEEE Congress on Services Part II (services-2 2008)	10.1109/ICWS.2008.150	software security assurance;computer security model;web service;cloud computing security;web application security;critical security studies;security through obscurity;sherwood applied business security architecture;security information and event management;security engineering;security convergence;asset;computer science;artifact-centric business process model;threat;information security;database;security service;security testing;law;world wide web;computer security;business process modeling	Security	-56.865449413747946	47.72766699716183	128017
1d7f3c8a6885e823feb6fc0f3fbd6580a5b8ffcc	computing the leakage of information-hiding systems	information hiding;part of book or chapter of book;information leakage	We address the problem of computing the information leakage of a system in an efficient way. We propose two methods: one based on reducing the problem to reachability, and the other based on techniques from quantitative counterexample generation. The second approach can be used either for exact or approximate computation, and provides feedback for debugging. These methods can be applied also in the case in which the input distribution is unknown. We then consider the interactive case and we point out that the definition of associated channel proposed in literature is not sound. We show however that the leakage can still be defined consistently, and that our methods extend smoothly.	approximation algorithm;automaton;computation;debugging;feedback;information leakage;prism (surveillance program);reachability;smoothing;spectral leakage	Miguel E. Andrés;Catuscia Palamidessi;Peter van Rossum;Geoffrey Smith	2010		10.1007/978-3-642-12002-2_32	real-time computing;computer science;theoretical computer science;programming language;information hiding;algorithm	AI	-55.29066280718166	52.85069067021725	128177
8c66e7957794bcf628552c516f06c889de492e04	cybertwitter: using twitter to generate alerts for cybersecurity threats and vulnerabilities	software;data mining;computer security;ontologies;twitter;knowledge based systems	In order to secure vital personal and organizational system we require timely intelligence on cybersecurity threats and vulnerabilities. Intelligence about these threats is generally available in both overt and covert sources like the National Vulnerability Database, CERT alerts, blog posts, social media, and dark web resources. Intelligence updates about cybersecurity can be viewed as temporal events that a security analyst must keep up with so as to secure a computer system. We describe CyberTwitter, a system to discover and analyze cybersecurity intelligence on Twitter and serve as a OSINT (Open-source intelligence) source. We analyze real time information updates, in form of tweets, to extract intelligence about various possible threats. We use the Semantic Web RDF to represent the intelligence gathered and SWRL rules to reason over extracted intelligence to issue alerts for security analysts.	blog;computer security;dark web;national vulnerability database;open-source intelligence;real-time computing;semantic web rule language;social media;vulnerability (computing);web resource	Sudip Mittal;Prajit Kumar Das;Varish Mulwad;Anupam Joshi;Timothy W. Finin	2016	2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1109/ASONAM.2016.7752338	computer science;ontology;artificial intelligence;knowledge-based systems;data mining;internet privacy;web intelligence;world wide web;computer security	AI	-61.085738360994185	58.938933561206696	128537
3e1327b983af1c0af04705ca0e7d59745d6088e4	security service level agreement measurement in cloud: a proof of concept implementation		Security concerns of cloud computing mainly originate from outsourced data and computation on which data owners do not have full control. Recent works in both industry and academia documented these concerns well and described both technical and non-technical measures to address these concerns. Many of the suggestions to address security concerns are in the form of physical audits by experts and certifications from standard groups for compliance. Unlike the performance measurement in cloud, security measurement is not matured and except solutions which address these concerns in part, there is no comprehensive mechanism which looks everything user wants to know about cloud. This paper introduces a notion of service level agreement from security perspective and proposes to monitor the cloud environment for run time compliance. Monitoring is done by a third party on end user's behalf by collecting credible evidence in the form of events, logs and measurement snapshots. Through this collected evidence the third party can answer to user security concerns stated in the form of SLA for compliance. We do a proof-of-concept implementation of security measurement with few sample service level agreements.	cloud computing;computation;requirement;run time (program lifecycle phase);service-level agreement;snapshot (computer storage);trusted third party	Himanshu Dogra;Sudhakar Verma;Neminath Hubballi;Mayank Swarnkar	2017	2017 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)	10.1109/ANTS.2017.8384139	proof of concept;computer security;end user;service-level agreement;audit;cloud computing;server;service level;security service;business	Embedded	-50.53683497929206	57.68926181908967	128678
1d34548f6ec223b7b10ebf5c41c62d394f6d753d	patching vulnerabilities with sanitization synthesis	program diagnostics;fiber amplifier;approximation method;input variables;automatic generation;automata;internet;impedance matching;sanitization synthesis;string analysis automata sanitization synthesis;automata theory;approximation methods;doped fiber amplifiers automata impedance matching reachability analysis security approximation methods input variables;vulnerability signatures automata based static string analysis techniques automatic sanitization statement generation vulnerable web application patching security sensitive functions;security of data automata theory internet program diagnostics;string analysis;security;security of data;doped fiber amplifiers;reachability analysis	We present automata-based static string analysis techniques that automatically generate sanitization statements for patching vulnerable web applications. Our approach consists of three phases: Given an attack pattern we first conduct a vulnerability analysis to identify if strings that match the attack pattern can reach the security-sensitive functions. Next, we compute vulnerability signatures that characterize all input strings that can exploit the discovered vulnerability. Given the vulnerability signatures, we then construct sanitization statements that 1) check if a given input matches the vulnerability signature and 2) modify the input in a minimal way so that the modified input does not match the vulnerability signature. Our approach is capable of generating relational vulnerability signatures (and corresponding sanitization statements) for vulnerabilities that are due to more than one input.	antivirus software;automata theory;sanitization (classified information);string (computer science);vulnerability (computing);web application	Fang Yu;Muath Alkhalaf;Tevfik Bultan	2011	2011 33rd International Conference on Software Engineering (ICSE)	10.1145/1985793.1985828	impedance matching;the internet;computer science;information security;theoretical computer science;automata theory;distributed computing;automaton;computer security	SE	-58.715145064335395	58.66559699872662	128782
b93d658f8bddea1dc615424d062cc949432dbe5b	usable privacy-aware logging for unstructured log entries	privacy preserving auditing;privacy aware logging;redacted logfiles;usable privacy;logging framework	Log files are a basic building block of computer systems. They typically contain sensitive data, for example, information about the internal structure of a service and its users. Additionally, log records are usually unstructured in the sense that sensitive data will not occur in every entry and not always occur at defined positions within a record. To mitigate the threat of illicit access to log files, we propose a flexible framework for the creation of privacy-preserving log records. A crucial step is the annotation of sensitive data, by using arbitrary labels, during the development of a system. These labels are mapped to redaction filters to form a redaction policy. Thus, we can create two parallel log streams. One log stream contains fully redacted log entries. It, hence, does not contain any sensitive information and is intended for everyday use. The second stream contains the original entires. Here, confidentiality must be ensured. Our framework fosters privacy by default principles and can support selective disclosure of relevant data. We developed an implementation of our solution for logback, one of the major logging frameworks in Java, and successfully evaluated its applicability.	confidentiality;data logger;encoder;encryption;information sensitivity;java;privacy by design;requirement	Christof Rath	2016	2016 11th International Conference on Availability, Reliability and Security (ARES)	10.1109/ARES.2016.1	computer science;web log analysis software;internet privacy;world wide web;computer security	DB	-54.660650130783445	59.29634673053042	129057
497fbda92820ac86f17d5b750e7588d4effb19fc	reduction method of threat phrases by classifying assets	common criteria;security requirements;security policy;reduction method;intrusion detection system	  Evaluation has been the traditional means of providing assurance. The Common Criteria (CC) defines a Protection Profile (PP)  that defines the security environments and specifies the security requirements and protections of the product to be evaluated.  The security environments consist of assumptions, threats, and organizational security policies, so the editor of the PP must  describe the threats for the PP. In this paper, we propose a new method for the description of the threats for the PP by introducing  the concept of the assets protected by Target of Evaluations (TOE), and show some merits by applying that concept to the Network-based  Intrusion Detection System (NIDS).    		Tai-Hoon Kim;Dong Chun Lee	2004		10.1007/978-3-540-24707-4_118	intrusion detection system;security management;security information and event management;computer science;security policy;data mining;database;computer security	NLP	-54.68567686253145	48.183660630531925	129240
548f0cce467ca771eea41a687e7c1f1aab2a1b88	incorporating constraints to software system survivability specification and proof	formal specification;theorem proving constraint handling formal specification inference mechanisms object oriented programming;logic;software systems;inference mechanisms;object oriented programming;theorem proving;constraint software systems survivability logic;constraint;reasoning software system survivability specification component based approaches model driven approaches software engineering survivability compliance specification survivability compliance verification constraint annotated logic user requirements formal design constraint domain proof carrying survivability logic;constraint handling;survivability;cognition software systems security context resilience fault tolerance	In component-based and model-driven approaches for software engineering, any software components or subsystems acquired from external sources must meet a user's criteria to ascertain that they will not compromise the survivability properties of the existing systems. In this paper, we study survivability compliance specification and verification in a proof-carrying scenario: a user defines survivability requirements for a software system to be acquired or linked to the existing systems. The system provider compiles a proof, which is sent to the user who simply needs to check it. We present a new formalism, i.e., a constraint annotated logic in which arbitrary user requirements and constraints for system survivability features can be represented and reasoned. We provide a formal design of a constraint domain and extend a proof-carrying survivability logic so that user-defined constraints can be enforced by prohibiting logical inferences that would violate these constraints. In our model, the interplay between a constraint domain and the logical reasoning process is directly supported by the logic rules. Experiments and analysis show that the proposed model is a powerful formalism in reasoning hybrid domains between users' constrained requirements and system survivability properties.	component-based software engineering;experiment;floor and ceiling functions;logical framework;model-driven architecture;proof-carrying code;requirement;semantics (computer science);software system;user requirements document	Yanjun Zuo	2012	2012 Sixth International Symposium on Theoretical Aspects of Software Engineering	10.1109/TASE.2012.17	constraint logic programming;software requirements specification;computer science;theoretical computer science;formal specification;constraint;programming language;logic	SE	-52.56511588929325	49.45552133647589	129342
fc3266ff624373afe136cb22147df4d2f3e1687f	distributed partial order reduction for security protocols	distributed state space generation;security protocols;state space;partial order reduction;security protocol	We describe a distributed partial order reduction algorithm for security protocols. Some experimental results using an implementation of the algorithm in the distributed μCRL toolset are also reported.	algorithm;partial order reduction	Muhammad Torabi Dashti;Anton Wijs;Bert Lisser	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2007.10.022	computer security model;partial order reduction;real-time computing;computer science;state space;theoretical computer science;cryptographic protocol;distributed computing;distributed system security architecture	Logic	-48.42191055383946	48.3881870772054	129395
dbb1fdf637a6041d1bbc3500b360c3fd427971a9	on modular and fully-abstract compilation - technical appendix		Secure compilation studies compilers that generate target-level components that are as secure as their source-level counterparts. Full abstraction is the most widely-proven property when defining a secure compiler. A compiler is modular if it allows different components to be compiled independently and then to be linked together to form a whole program. Unfortunately, many existing fully-abstract compilers to untyped machine code are not modular. So, while fully-abstractly compiled components are secure from malicious attackers, if they are linked against each other the resulting component may become vulnerable to attacks. This paper studies how to devise modular, fully-abstract compilers. It first analyses the attacks arising when compiled programs are linked together, identifying security threats that are due to linking. Then, it defines a compiler from an object-based language with method calls and dynamic memory allocation to untyped assembly language extended with a memory isolation mechanism. The paper provides a proof sketch that the defined compiler is fully-abstract and modular, so its output can be linked together without introducing security violations. This paper uses colours to distinguish elements of different languages; please print this in colour.	assembly language;color;compiler;denotational semantics;machine code;memory management;memory protection;object-based language	Marco Patrignani;Dominique Devriese;Frank Piessens	2016	CoRR		parallel computing;computer science;theoretical computer science;compiler construction;programming language;functional compiler	PL	-54.5830988967325	53.83194939393531	129456
6c018a5a34fdc29c2964edb080940d7f7eb6bd4d	designing safety-critical computer systems	systems analysis security of data ubiquitous computing safety systems risk management;pervasive computing power engineering computing application software automotive engineering ubiquitous computing electronic components prosthetics design engineering power engineering and energy risk management;risk management;safety systems;risk reduction;systems analysis;risk reduction safety critical computer systems design ubiquitous computer system developers safety critical applications steer by wire automotive systems powered prosthetics computer based systems systematic design;system development;ubiquitous computing;security of data	"""40 Computer Designing Safety-Critical Computer Systems T he ubiquitous computer is firmly established as the electronic component of choice for designing systems that control safety-critical applications. Such applications can be found everywhere: aircraft fly-by-wire controls, oil and chemical processing, hospital life-support systems, manufacturing robotics, and countless other commercial and industrial applications. As this century matures, developers will increasingly exploit computing's power in safety-critical applications that directly touch us all: steer-by-wire automotive systems, automated air-and surface-traffic control, powered prosthetics, and so on. However, these computer-based systems raise the ongoing concern that they might fail and cause harm. Indeed, past computer failures have produced catastrophic results, most famously the notorious Therac 25, a therapeutic computer system intended to heal but which inadvertently killed and maimed patients before being forced off the market. 1 The safety of computer-based systems is of long-standing and continuing interest to computing professionals. As research continues in this area, proposed system concepts and architectures— deemed safe by their developers—have been found to be impractical for real-life engineering applications that can place lives, property, or the environment at risk. Such dependable, seemingly safe, concepts and structures fail in practice for three primary reasons: Their originators or users • have an incomplete understanding of what makes a system """" safe, """" • fail to consider the larger system into which the implemented concept is to be embedded, or • ignore single points of failure that will make the safe concept unsafe when put into practice. Reviewing the fundamental definitions and concepts of system safety provides a framework for addressing these shortcomings. Exploring the systematic design of safety-critical computer systems in engineering practice helps to show how engineers can verify that these designs will be safe. The notion of safety is most likely to come to mind when we drive a car, fly on an airliner, or take an elevator ride. In each case, we are concerned with the threat of a mishap, which the US Department of Defense defines as an unplanned event or series of events that result in death, injury, occupational illness , damage to or loss of equipment or property, or damage to the environment. 3 The mishap risk assesses the impact of a mishap in terms of two primary concerns: its potential severity and the probability of its occurrence. 3 For example , an airliner crash would affect an individual more severely than an automobile fender-bender, …"""	computer;electronic component;embedded system;fly-by-wire;mind;real life;reliability engineering;robotics;single point of failure;system safety;therac-25;ubiquitous computing	William R. Dunn	2003	IEEE Computer	10.1109/MC.2003.1244533	embedded system;systems analysis;computing;risk management;system of systems;computer science;operating system;software engineering;absolute risk reduction;system safety;computer security;ubiquitous computing;software system;computer engineering;systems design	SE	-59.5897774898664	48.81522566699612	129480
a8dde9e8e10e7fc7a477d85cbfb68511ee659772	a revised taxonomy of data collection mechanisms with a focus on intrusion detection	reliability engineering;data collection mechanisms;data collection taxonomy intrusion detection;availability;data collection;security of data data acquisition;intrusion detection;data engineering;log data quality;computer security;guidelines;taxonomy;datavetenskap datalogi;datavetenskap;terminology;taxonomy intrusion detection terminology guidelines availability computer security data security computer science data engineering reliability engineering;detection engine;log data quality data collection mechanisms intrusion detection detection engine;computer science;data acquisition;security of data;data security	Surprisingly few data collection mechanisms have been used for intrusion detection, and most systems rely on network and system call data as input to the detection engine. Even though the quality of log data is vital to the detection process and heavily dependent on the collection mechanism, no extensive survey or taxonomy has been conducted within the detection field. In this paper, we propose a revised taxonomy which provides a unified terminology and a framework in which data collection mechanisms can be systematically inspected, evaluated, and compared. Since the taxonomy is derived from existing mechanisms, it also provides a useful overview of different types of mechanisms. The paper also suggests areas within data collection where additional work is required.	intrusion detection system;system call;taxonomy (general)	Ulf Larson;Erland Jonsson;Stefan Lindskog	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.38	computer science;data mining;database;computer security;data collection	DB	-61.77677312001743	55.9741205687043	129558
27aada78fb46dd965ec4c8a6f3128c7ae9663448	a formal model for isolation management in cloud infrastructure-as-a-service	isolation;virtual resource management;cloud computing	Datacenters for cloud infrastructure-as-a-service (IaaS) consist of a large number of heterogeneous virtual resources, such as virtual machines (VMs) and virtual local area networks (VLANs). It takes a complex process to manage and arrange these virtual resources to build particular computing environments. Misconfiguration of this management process increases possibility of security vulnerability in this system. Moreover, multiplexing virtual resources of disjoint customers upon same physical hardware leads to several security concerns, such as cross-channel and denial-of-service attacks. Trusted Virtual Datacenter (TVDc) is a commerical product which informally presents a process to manage strong isolation among these virtual resources in order to mitigate these issues. In this paper, we formally represent this TVDc management model. We also develop an authorization model for the cloud administrative-user privilege management in this system.	authorization;cloud computing;data center;denial-of-service attack;multiplexing;privilege (computing);privilege management infrastructure;virtual machine;vulnerability (computing)	Khalid Zaman Bijon;Ram Krishnan;Ravi S. Sandhu	2014		10.1007/978-3-319-11698-3_4	real-time computing;simulation;temporal isolation among virtual machines;isolation;cloud computing;computer science;operating system;computer security	OS	-50.090021416767705	56.93633430775621	129576
17930e2ac405a919d24807d2cabcb740f6aa45e9	anti-counterfeit techniques: from design to resign	dna supply chains integrated circuits foundries hardware reliability taxonomy;counterfeit ics;supply chain management integrated circuit design;electronic component supply chain anticounterfeit techniques counterfeit electronic components;supply chain vulnerabilities;avoidance mechanisms;design for anti counterfeits;avoidance mechanisms counterfeit ics supply chain vulnerabilities design for anti counterfeits	The emerging threat of counterfeit electronic components has become a major challenge over the past decade. To address this growing concern, a suite of tests for the detection of such parts has been created. However, due to the large test time and cost, it is fairly difficult to implement them. Moreover, the presence of different types of counterfeits in the supply chain - recycled, remarked, overproduced, out-of-spec/defective, cloned, forged documentation, and tampered - makes the detection even more challenging. In this paper, we present a detailed taxonomy of counterfeit types to analyze the vulnerabilities in the electronic component supply chain. We then present the state of knowledge on anti-counterfeit technologies to help prevent counterfeit components from ever entering into the supply chain and to provide capabilities for easy detection.	documentation;electronic component;spec#	Ujjwal Guin;Domenic J. Forte;Mark Mohammad Tehranipoor	2013	2013 14th International Workshop on Microprocessor Test and Verification	10.1109/MTV.2013.28	computer security	SE	-59.07728617520705	58.641407931655806	129587
68af355b3abd930e2d516bed44725d4c45aeda1d	lachouti: kernel vulnerability responding framework for the fragmented android devices		The most criticized problem in the Android ecosystem is fragmentation, i.e., 24,093 Android devices in the wild are made by 1,294 manufacturers and installed with extremely customized operating systems. The existence of so many different active versions of Android makes security updates and vulnerability responses across the whole range of Android devices difficult. In this paper, we seek to respond to the unpatched kernel vulnerabilities for the fragmented Android devices. Specifically, we propose and implement LaChouTi, which is an automated kernel security update framework consisting of cloud service and end application update. LaChouTi first tracks and identifies the exposed vulnerabilities according to the CVE-Patch map for the target Android kernels. Then, it generates differential binary patches for the identified results. Finally, it pushes and applies the patches to the kernels. We evaluate LaChouTi using 12 Nexus Android devices that have different Android versions, different kernel versions, different series and different manufacturers, and find 1922 unpatched kernel vulnerabilities in these devices. The results show that: (1) the security risk of unpatched vulnerabilities caused by fragmentation is serious; and (2) the proposed LaChouTi is effective in responding to such security risk. Finally, we implement LaChouTi on new commercial devices by collaborating with four internationally renowned manufacturers. The results demonstrate that LaChouTi is effective for the manufacturersâ security updates.	android;cloud computing;common vulnerabilities and exposures;ecosystem;fork (software development);fragmentation (computing);kernel (operating system);operating system;patch (computing)	JingZheng Wu;Mutian Yang	2017		10.1145/3106237.3117768	kernel (linear algebra);real-time computing;computer science;cloud computing;android (operating system);nexus (standard);computer security;fragmentation (computing);vulnerability	Security	-54.79951017471704	58.6287479118064	129774
a01b9a8ade8000041e08ddac748e33aaf0132423	compliance management for p2p systems		Compliance management for peer-to-peer networks describes a process ensuring that content inside the network is distributed and stored in a way that does not violate user defined preferences. Several use cases, ranging from file-sharing networks to distributed computing and content delivery networks, can be enhanced with compliance management. To our knowledge there are no existing peer-to-peer architectures which allow for compliance management. In this paper we propose an architecture, which utilizes policy-based routing and storage as well as a categorization of content in order to provide compliance management. We implement a prototype and evaluate it through simulations to show that compliance management in peer-to-peer networks is actually feasible.	benchmark (computing);categorization;content delivery network;digital distribution;distributed computing;file sharing;hypothetical protein;microsoft outlook for mac;peer-to-peer;prototype;routing;simulation;whitelist	Alexander Schneider;Martin Mauve	2017	2017 23rd Asia-Pacific Conference on Communications (APCC)	10.23919/APCC.2017.8303961	real-time computing;computer science;architecture;cryptography;categorization;use case;ranging	DB	-50.59225796082687	55.37176571190621	129815
d9eab0ff175af19df46e560e3a9e15f272d7b91a	a rule-set approach to formal modeling of a trusted computer system	trusted computing	This article describes a rule-set approach to formal modeling of a trusted computer system. A finite state machine models the access operations of the trusted system while a separate rule set expresses the system's trust policies. A powerful feature of this approach is its ability to fit several widely differing trust policies easily within the same model. The paper shows how this approach to modeling relates to general ideas of access control. Departing from the traditional abstractness of discussions of formal models, the paper also relates this approach to the implementation of real systems by connecting the rule set of the model to the system operations of a UNIX System V system. This gives high confidence that a real system could clearly derive from the elements of the formal model instead of additionally depending on numerous design and policy decisions not addressed in the model. Neither are the trust policies left largely to the imagination of the reader-the rule base has detailed specifications of the mandatory access control policy of UNIX System V/IVILS, a version of the Clark-Wilson integrity policy, and two supporting policies that implement roles. A fundamental point established by the work reported in this article is that formal modeling can be moved considerably closer to implementation of real systems, a fact that has great beneficial impact on the possibility of building high assurance trusted systems.	algorithm;computer;finite-state machine;linc;mandatory access control;mathematical model;rule-based system;trusted computing base;trusted system	Leonard J. LaPadula	1994	Computing Systems		direct anonymous attestation;computer science;trusted network connect;trusted computing base;trusted platform module;trustworthy computing;trusted service manager	Security	-51.83980516971477	50.60123262233146	129820
eb758f78f582f259a2386a8d99721b70603751e3	experience with evaluating human-assisted recovery processes	undo redo recovery tool human assisted failure recovery internet class server system enterprise class server system dependability benchmarking dependability related metrics e mail services;program diagnostics;humans benchmark testing costs computer science internet web server electronic mail quality of service databases availability;human computer interaction;electronic mail;human computer interaction system recovery program diagnostics network servers electronic mail;user study;system evaluation;network servers;system recovery;failure recovery;quantitative evaluation	We describe an approach to quantitatively evaluating human-assisted failure-recovery tools and processes in the environment of modern Internetand enterprise-class server systems. Our approach can quantify the dependability impact of a single recovery system, and also enables comparisons between different recovery approaches. The approach combines aspects of dependability benchmarking with human user studies, incorporating human participants in the system evaluations yet still producing typical dependability-related metrics as results. We illustrate our methodology via a case study of a system-wide undo/redo recovery tool for e-mail services; our approach is able to expose the dependability benefits of the tool as well as point out areas where its behavior could use improvement.	dependability;email;server (computing);undo	Aaron B. Brown;Leonard Chung;William Kakes;Calvin Ling;David A. Patterson	2004	International Conference on Dependable Systems and Networks, 2004	10.1109/DSN.2004.1311910	reliability engineering;real-time computing;simulation;computer science;operating system;distributed computing;computer security	SE	-61.173605671435425	55.355206996788084	130494
c9797c1c7c6d0dbcd674c669a60f2b068d6210b5	forensics investigation challenges in cloud computing environments	computers;digital forensics;virtualization;computer forensics;information retrieval;forensic challenges cloud computing forensics investigation security virtualization;business owner cloud computing entity sharing cyber theft computer forensic investigation data access tpm hypervisor multifactor authentication cloud service provider policy digital forensic investigation trusted computing;media;trusted computing;computational modeling;forensic challenges;web services;cloud computing computers digital forensics computational modeling media ieee xplore;ieee xplore;security;web services cloud computing computer forensics information retrieval trusted computing;cloud computing;forensics investigation	Cloud computing discusses about sharing any imaginable entity such as process units, storage devices or software. The provided service is utterly economical and expandable. Cloud computing attractive benefits entice huge interest of both business owners and cyber thefts. Consequently, the “computer forensic investigation” step into the play to find evidences against criminals. As a result of the new technology and methods used in cloud computing, the forensic investigation techniques face different types of issues while inspecting the case. The most profound challenges are difficulties to deal with different rulings obliged on variety of data saved in different locations, limited access to obtain evidences from cloud and even the issue of seizing the physical evidence for the sake of integrity validation or evidence presentation. This paper suggests a simple yet very useful solution to conquer the aforementioned issues in forensic investigation of cloud systems. Utilizing TPM in hypervisor, implementing multi-factor authentication and updating the cloud service provider policy to provide persistent storage devices are some of the recommended solutions. Utilizing the proposed solutions, the cloud service will be compatible to the current digital forensic investigation practices; alongside it brings the great advantage of being investigable and consequently the trust of the client.	cloud computing;cloud computing security;computer forensics;hypervisor;microsoft lumia;multi-factor authentication;persistence (computer science);privacy;software deployment;trusted platform module	Mohsen Damshenas;Ali Dehghantanha;Ramlan Mahmod;Solahuddin bin Shamsuddin	2012	Proceedings Title: 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec)	10.1109/CyberSec.2012.6246092	cloud computing security;computer science;internet privacy;world wide web;computer security	HPC	-49.37729904016663	58.759116053916266	130615
8a8b5aa52a0f1b9ebd2d208f4931afabf332aeb9	review of existing analysis tools for selinux security policies: challenges and a proposed solution		Access control policy management is an increasingly hard problem from both the security point of view and the verification point of view. SELinux is a Linux Security Module (LSM) implementing a mandatory access control mechanism. SELinux integrates user identity, roles, and type security attributes for stating rules in security policies. As SELinux policies are developed and maintained by security administrators, they often become quite complex, and it is important to carefully analyze them in order to have high assurance of their correctness. There are many existing analysis tools for modeling and analyzing SELinux policies with the goal of answering specific safety and functionality questions. In this paper, we identify and highlight current gaps in these existing tools for SELinux policy analysis, and propose new tools and technologies with the potential to lead to significant improvements. The proposed solution includes adopting a certified access control policy language such as ACCPL (A Certified Access Core Policy Language). ACCPL comes with formal proofs of important properties, and our proposed solution includes adopting it to facilitate various analyses and proof of reasonability properties. ACCPL is general, and our goal is to design a certified domain-specific policy language based on it, specialized to our task.	correctness (computer science);linux security modules;mandatory access control;point of view (computer hardware company);selinux;type enforcement;usability	Amir Eaman;Bahman Sistany;Amy P. Felty	2017		10.1007/978-3-319-59041-7_7	systems engineering;engineering;data mining;management science	Security	-51.541187900280924	52.49938896840335	130660
607f490f943411b7eb5f59f06a13616a43cf13c2	a survey on securing the virtual cloud	information systems applications incl internet;software engineering programming and operating systems;computer communication networks;special purpose and application based systems;computer system implementation;computer systems organization and communication networks	The paper presents a survey and analysis of the current security measures implemented in cloud computing and the hypervisors that support it. The viability of an efficient virtualization layer has led to an explosive growth in the cloud computing industry, exemplified by Amazon’s Elastic Cloud, Apple’s iCloud, and Google’s Cloud Platform. However, the growth of any sector in computing often leads to increased security risks. This paper explores these risks and the evolution of mitigation techniques in open source cloud computing. Unlike uniprocessor security, the use of a large number of nearly identical processors acts as a vulnerability amplifier: a single vulnerability being replicated thousands of times throughout the computing infrastructure. Currently, the community is employing a diverse set of techniques in response to the perceived risk. These include malware prevention and detection, secure virtual machine managers, and cloud resilience. Unfortunately, this approach results in a disjoint response based more on detection of known threats rather than mitigation of new or zero-day threats, which are often left undetected. An alternative way forward is to address this issue by leveraging the strengths from each technique in combination with a focus on increasing attacker workload. This approach would make malicious operation time consuming and deny persistence on mission time-scales. It could be accomplished by incorporating migration, non-determinism, and resilience into the fabric of virtualization.	amazon elastic compute cloud (ec2);amplifier;central processing unit;cloud computing;google cloud platform;hypervisor;malware;nondeterministic algorithm;open-source software;operation time;persistence (computer science);system migration;uniprocessor system;virtual machine;x86 virtualization;icloud	Robert Denz;Stephen Taylor	2013	Journal of Cloud Computing: Advances, Systems and Applications	10.1186/2192-113X-2-17	cloud computing security;simulation;cloud computing;computer science;operating system;cloud testing;distributed computing;utility computing;computer security	Security	-53.10375568248685	57.28788891436636	130680
d01dba138cb7adc22f80c62c607570478fdc1391	can maturity models support cyber security?	information security;computer security;capability maturity model;aerospace electronics;organizations;adaptation models;conference proceeding	We are living in a cyber space with an unprecedented rapid expansion of the space and its elements. All interactive information is processed and exchanged via this space. Clearly a well-built cyber security is vital to ensure the security of the cyber space. However the definitions and scopes of both cyber space and cyber security are still not well-defined and this makes it difficult to establish sound security models and mechanisms for protecting this space. Out of existing models, maturity models offer a manageable approach for assessing the security level of a system or organization. The paper first provides a review of various definitions of cyber space and cyber security in order to ascertain a common understanding of the space and its security. The paper investigates existing security maturity models, focusing on their defining characteristics and identifying their strengths and weaknesses. Finally, the paper discusses and suggests measures for a sound and applicable cyber security model.	capability maturity model;computer security;cyberspace;entity;quantitative structure–activity relationship	Ngoc Thien Le;Doan B. Hoang	2016	2016 IEEE 35th International Performance Computing and Communications Conference (IPCCC)	10.1109/PCCC.2016.7820663	computer security model;cloud computing security;simulation;security through obscurity;security information and event management;security convergence;covert channel;asset;computer science;organization;information security;human-computer interaction in information security;security service;security analysis;security testing;computer security;capability maturity model	Security	-57.66421951914925	47.923790825956885	130989
3537ed87a6882bbe7bac9676843c083985c05da5	a posteriori defensive programming: an annotation toolkit for dos-resistant component-based architectures	distributed application;components;component based systems;annotations;aspect oriented programming;denial of service;source code;dos attacks;dos attack	Denial-of-Service (DoS) attacks are a major concern for modern distributed applications. They exploit weakness in the software in order to make it unavailable to well-behaved users. Building DoS resistant software is still an issue. Solutions relying on the use of annotations have been proposed. Nevertheless, they require modifying the source code of the application, and must thus be applied at design time. In this paper, we propose an annotation toolkit that allows building DoS resistant component-based systems. The solution we propose does not require any modification of the source code of the application. Moreover it can be applied at deployment time. Its implementation relies on the use of Aspect-Oriented Programming techniques together with Java 1.5 annotations.	aspect-oriented programming;component-based software engineering;defensive programming;denial-of-service attack;distributed computing;software deployment	Valerio Schiavoni;Vivien Quéma	2006		10.1145/1141277.1141688	computer science;operating system;database;programming language;world wide web;computer security;denial-of-service attack	SE	-55.1885452786405	58.07966929883712	131554
8966ff306c2d0367edef8b30586949e6a22939a2	constrained role-based delegation		Delegation is a proIIlIsmg alternative to traditional role administration paradigms in role-based systems. It empowers users to exercise discretion in how they use resources as it is in discretionary access control (DAC). Unlike the anarchy of DAC, in role-based access control (RBAC) higher-level organizational policies can be specified on roles to regulate user's action. Delegations and revocations are thus governed by these authorization policies. In this paper, we propose a policy approach for specifying and enforcing delegation authorizations. We present a mechanism for constructing authorization policies using a set of rules. Our rule-based language is flexible and powerful to specify and enforce authorization constraints. In addition, rules can also be used to define the exceptions for future actions and resolve possible conflicts.	anarchy;authorization;delegation (computer security);discretionary access control;role-based access control;rule-based system	Longhua Zhang;Gail-Joon Ahn	2003			delegation;computer science;knowledge management;access control;computer security	Security	-48.86767346852475	53.00119354654157	131624
81abcf63297fb3b0cd855679c35176bfe5bc70d5	metricon 2.0	financial management;particle measurements;bridges;data security particle measurements bridges roads financial management data analysis velocity measurement;data analysis;roads;building security in;security metric;software development life cycle;velocity measurement;software development life cycle building security in security metrics;security metrics;data security	The authors look at the recent Metricon 2.0 conference and discuss its highlights. In particular, the conference focused on the importance of metrics, especially as they apply to security.		John Steven;Gunnar Peterson	2007	IEEE Security & Privacy Magazine	10.1109/MSP.2007.171	software security assurance;computer security model;financial management;security information and event management;computer science;data mining;data security;systems development life cycle;data analysis;computer security	EDA	-57.39619848092758	47.75319985752846	131734
cbae22665d69a4ea560952ba0e6c28956596e536	towards scalable, fine-grained, intrusion-tolerant data protection models for healthcare cloud	triggerable data file structure cloud computing cprbac active auditing scheme verification monitors data proteciton;auditing;authorisation;triggerable data file structure;active auditing scheme;role based access control;cprbac;data proteciton;data violation intrusion tolerant data protection models healthcare cloud computing fine grained data protection models healthcare industry confidential health data privacy data ownership data security robust data protection framework cloud based privacy aware role based access control model triggerable data file structure active auditing scheme data traceability healthcare system resource access authorization;access control policy;servers medical services cloud computing monitoring access control computer architecture;data privacy;healthcare system;medical information systems;security and privacy;intrusion tolerance;defense mechanism;access control;quality of service;data protection;medical information systems auditing authorisation cloud computing data privacy health care;conference proceeding;verification monitors;cloud computing;health care	Despite cloud computing has been widely adopted by most industries, the healthcare industry still reveals a slow development in cloud-based solution due to the raising of user fear that their confidential health data or privacy would leak out in the cloud. To allay users' concern of data control, data ownership, security and privacy, we propose a robust data protection framework which is surrounded by a chain of protection schemes from access control, monitoring, to active auditing. The framework includes three key components which are Cloud-based Privacy-aware Role Based Access Control (CPRBAC) model, Triggerable Data File Structure (TDFS), and Active Auditing Scheme (AAS) respectively. Our schemes address controllability, trace ability of data and authorize access to healthcare system resource. Data violation against access control policies can be proactively triggered to perform corresponding defense mechanisms. Our goal is to bring benefits of cloud computing to healthcare industries to assist them improve quality of service and reduce the cost of overall healthcare.	cloud computing;confidentiality;information privacy;quality of service;role-based access control	Lingfeng Chen;Doan B. Hoang	2011	2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2011.19	cloud computing security;database;business;internet privacy;computer security	DB	-49.98440787397122	57.8058458411199	131848
9101167dff83b9b34b042c7d194e1825963f5bab	"""trust management and security in the future communication-based """"smart"""" electric power grid"""	distributed system;trust management;junctions;assembly;smart grids;power engineering computing;supervisory control and data acquisition;scada system;power grids;electric power;peer to peer computing;relays;security of data;power system security	New standards and initiatives in the U.S. electric power grid are moving in the direction of a smarter grid. Media attention has focused prominently on smart meters in distribution systems, but big changes are also occurring in the domains of protection, control, and Supervisory Control and Data Acquisition (SCADA) systems. These changes promise to enhance the reliability of the electric power grid and to allow it to safely operate closer to its limits, but there is also a real danger concerning the introduction of network communication vulnerabilities to so-called cyber attacks. This article advocates the use of a reputation-based trust management system as one method to mitigate such attacks. A simulated demonstration of the potential for such systems is illustrated in the domain of backup protection systems. The simulation results show the promise of this proposed technique.	backup;data acquisition;simulation;smart meter;trust management (information system);trust management (managerial science)	Jose Fadul;Kenneth M. Hopkinson;Christopher Sheffield;James T. Moore;Todd R. Andel	2011	2011 44th Hawaii International Conference on System Sciences	10.1109/HICSS.2011.459	embedded system;computer science;distributed computing;smart grid;world wide web;computer security;scada	EDA	-57.867625567739346	50.9225017080621	131898
caad9afd03df66510767435640600c659bc4ef44	identifying os kernel objects for run-time security analysis	runtime objects;swinburne;kernel data structures;operating systems	As dynamic kernel runtime objects are a significant source of security and reliability problems in Operating Systems (OSes), having a complete and accurate understanding of kernel dynamic data layout in memory becomes crucial. In this paper, we address the problem of systemically uncovering all OS dynamic kernel runtime objects, without any prior knowledge of the OS kernel data layout in memory. We present a new hybrid approach to uncover kernel runtime objects with nearly complete coverage, high accuracy and robust results against generic pointer exploits. We have implemented a prototype of our approach and conducted an evaluation of its efficiency and effectiveness. To demonstrate our approach’s potential, we have also developed three different proof-of-concept OS security tools using it.	computer data storage;data structure;kernel (operating system);operating system;pointer (computer programming);prototype;system dynamics	Amani S. Ibrahim;James H. Hamlyn-Harris;John Grundy;Mohamed Almorsy	2012		10.1007/978-3-642-34601-9_6	procfs;real-time computing;computer science;theoretical computer science;operating system;process management;kernel preemption;tree kernel;configfs	Security	-55.97879689511898	54.797330818149504	131940
8faf40232d901240d13264d67cb5c414c5f0f829	access control policy combining: theory meets practice	xacml;theory and practice;linear constraint;access control policy;access controls;policy evaluation;automata theory;security;languages;policy combination	Many access control policy languages, e.g., XACML, allow a policy to contain multiple sub-policies, and the result of the policy on a request is determined by combining the results of the sub-policies according to some policy combining algorithms (PCAs). Existing access control policy languages, however, do not provide a formal language for specifying PCAs. As a result, it is difficult to extend them with new PCAs. While several formal policy combining algebras have been proposed, they did not address important practical issues such as policy evaluation errors and obligations; furthermore, they cannot express PCAs that consider all sub-policies as a whole (e.g., weak majority or strong majority). We propose a policy combining language PCL, which can succinctly and precisely express a variety of PCAs. PCL represents an advancement both in terms of theory and practice. It is based on automata theory and linear constraints, and is more expressive than existing approaches. We have implemented PCL and integrated it with SUN's XACML implementation. With PCL, a policy evaluation engine only needs to understand PCL to evaluate any PCA specified in it.	access control;algorithm;automata theory;formal language;printer command language;xacml	Ninghui Li;Qihua Wang;Wahbeh H. Qardaji;Elisa Bertino;Prathima Rao;Jorge Lobo;Dan Lin	2009		10.1145/1542207.1542229	computer science;information security;automata theory;data mining;database;computer security	Security	-52.07390105460417	50.86158071979158	132403
f693bd471328f6deb387465c8790cb39636f8e6e	verifiable assume-guarantee privacy specifications for actor component architectures	first order linear temporal logic;privacy policy;safety and liveness properties;assume guarantee specifications;static analysis	Many organizations process personal information in the course of normal operations. Improper disclosure of this information can be damaging, so organizations must obey privacy laws and regulations that impose restrictions on its release or risk penalties. Since electronic management of personal information must be held in strict compliance with the law, software systems designed for such purposes must have some guarantee of compliance. To support this, we develop a general methodology for designing and implementing verifiable information systems. This paper develops the design of the History Aware Programming Language into a framework for creating systems that can be mechanically checked against privacy specifications. We apply this framework to create and verify a prototypical Electronic Medical Record System (EMRS) expressed as a set of actor components and first-order linear temporal logic specifications in assume-guarantee form. We then show that the implementation of the EMRS provably enforces a formalized Health Insurance Portability and Accountability Act (HIPAA) policy using a combination of model checking and static analysis techniques.	first-order predicate;formal verification;health insurance portability and accountability act;information system;linear temporal logic;model checking;personally identifiable information;privacy law;programming language;software system;static program analysis	Claiborne Johnson;Thomas MacGahan;John Heaps;Kevin Baldor;Jeffery von Ronne;Jianwei Niu	2017		10.1145/3078861.3078873	privacy policy;model checking;verifiable secret sharing;computer science;data mining;computer security;software system;information system;health insurance portability and accountability act;privacy laws of the united states;real-time computing;personally identifiable information	Security	-52.78008327574638	51.97746039885461	132741
e286689f46fdb389e89a349e203326ee403ee256	certs: a comparative evaluation method for risk management methodologies and tools	software metrics;risk management computer security costs risk analysis computer science resource management engineering management decision making government standards development;risk analysis;decentralized computing;evaluation method;government;resource management;risk management;theses;comparison;systems management;software metrics security of data;computer security;standards development;thesis;systems analysis;risk;engineering management;risk management tools;certs;data processing security;risk management tools certs risk management methodologies decentralized computing;organizations;computer science;methodology;management;security of data;standardization;risk management methodologies	R e advent of deceniralized computing and an increasingly important role for information as a resource has prompted the development of a variety of methoak and tools for managing the risk exposure of a computer system As a result of the diversity of risk management tools currently available, there is no effective means of determining which of the took would be most suitable for any given organization's situation A new technique is proposed to efectively and objectively evaluate these tools for suitability and to establish a means of comparison of the tools among each other.	computer;risk management	William M. Garrabrants;Alfred W. Ellis;Lance J. Hoffman;Magdi N. Kamel	1990		10.1109/CSAC.1990.143783	systems analysis;systems management;risk management tools;risk analysis;risk management;computer science;knowledge management;resource management;methodology;risk;standardization;government	SE	-56.86142114847709	48.71702473188533	132866
bae44c9fad6e8bbab258e9630e396936d4535291	information security management: an information security retrieval and awareness model for industry	model specification;information security;body of knowledge;information security awareness;information security management;information security vulnerabilities;information security threats;information security risk;article	The purpose of this paper is to present a conceptual view of an Information Security Retrieval and Awareness (ISRA) model that can be used by industry to enhance information security awareness among employees. A common body of knowledge for information security that is suited to industry and that forms the basis of this model is accordingly proposed. This common body of knowledge will ensure that the technical information security issues do not overshadow the non-technical human-related information security issues. The proposed common body of knowledge also focuses on both professionals and low-level users of information. The ISRA model proposed in this paper consists of three parts, namely the ISRA dimensions (non-technical information security issues, IT authority levels and information security documents), information security retrieval and awareness, and measuring and monitoring. The model specifically focuses on the non-technical information security that forms part of the proposed common body of knowledge because these issues have, in comparison with the technical information security issues, always been neglected. a 2008 Elsevier Ltd. All rights reserved.	certified information systems security professional;high- and low-level;information security awareness;security management	Elmarie Kritzinger;E. Smith	2008	Computers & Security	10.1016/j.cose.2008.05.006	information security audit;computer security model;standard of good practice;certified information security manager;cloud computing security;critical security studies;security through obscurity;information security management system;security information and event management;security convergence;asset;computer science;knowledge management;threat;information security;body of knowledge;information security standards;data mining;human-computer interaction in information security;security service;security analysis;security testing;computer security;specification;information security management	AI	-54.69298719295349	48.452206995957724	132994
8b571df57cab28eb22ea33969b0f34e3de6d2ff6	dynamic information flow control architecture for web applications	dynamic information;information flow;source code;access control;flow control;database management system	In typical Web applications, the access control at the database management system is not effective due to the dependency on application behavior. That is, once the information is retrieved, a careless application can easily leak the information to undesirable parties. In addition, database accounts are often shared for multiple Web users in order to allow connection pooling. We propose DIFCA-J (Dynamic Information Flow Control Architecture for Java), to keep track of and control fine-grained information propagation through execution of the program. DIFCA-J allows controlling the information flow at run-time, without needing to modify the source code of the target application or the Java VMs.	information flow;non-interference (security);web application	Sachiko Yoshihama;Takeo Yoshizawa;Yuji Watanabe;Michiharu Kudo;Kazuko Oyanagi	2007		10.1007/978-3-540-74835-9_18	information flow;computer science;access control;flow control;database;distributed computing;world wide web;computer security;source code	Arch	-53.132876655592355	54.3415959532027	133082
27237721f194d7bf6e1543591513c9447e51fc7f	a semantic data validation service for web applications	reported web security vulnerability;semantic data;web security vulnerability;vulnerabilities;web application attack;semantic web;web application vulnerability;validation service;on the fly;web page;web development project;data tampering;e-commerce;sql injection;web application;web system;data validation;web development;web pages;e commerce;web security	An Input validation can be a critical issue. Typically, a little attention is paid to it in a web development project, because overenthusiastic validation can tend to cause failures in the software, and can also break the security upon web applications such as an unauthorized access to data. Now, it is estimated the web application vulnerabilities (such as XSS or SQL injection) for more than two thirds of the reported web security vulnerabilities. In this paper, we start with a case study of the bypassing data validation and security vulnerabilities such as SQL injection and then go on to discuss the merits of a number of common data validation techniques. We also review the different solutions to date to provide data validation techniques in ecommerce applications. From this analysis, a new data validation service which is based upon semantic web Technologies, has been designed and implemented to prevent the web security vulnerabilities at the application level and to secure the web system even if the input validation modules are bypassed. Our semantic architecture consists of the following components: RDFa annotation for elements of web pages, interceptor, RDF extractor, RDF parser, and data validator. The experimental results of the pilot study indicate that the proposed data validation service might provide a detection, and prevention of some web application attacks.	authorization;cross-site scripting;data validation;e-commerce;global variable;interceptor pattern;internet security;rdfa;randomness extractor;resource description framework;sql injection;semantic web;semantic architecture;validator;vulnerability (computing);web application;web development;web page	Shadi Aljawarneh;Faisal Alkhateeb;Eslam Al Maghayreh	2010	JTAER		e-commerce;web service;web application security;web development;web application;web modeling;data web;web analytics;sql injection;web design;vulnerability;web standards;computer science;operating system;data validation;social semantic web;web page;linked data;data mining;internet security;database;web intelligence;world wide web;computer security;mashup	SE	-57.416975391955575	59.015555551310676	133278
3181b251ca9f8af4ed41c49ef6f5b03bd95eef77	senx: sound patch generation for security vulnerabilities		Many techniques have been proposed for automatic patch generation and the overwhelming majority of them rely on the quality of test suites to prove the correctness of the patches that they generate. However, the quality of test suites is usually undesirable and hence the quality of the patches is ill-suited for security vulnerabilities. To address this, we propose an approach that generates patches by following the proved working strategy utilized by human developers in fixing security vulnerabilities, which relies on a sound analysis of the nature of a vulnerability rather than the quality of test suites for the correctness of the patches. In this paper, we present the design of our approach to fixing buffer overflow and integer overflow vulnerabilities. It is enabled by the combination of two novel techniques: loop analysis and symbolic expression translation. They mimic the analysis performed by human developers to develop patches for buffer overflows and integer overflows. To ensure the safety of our patches, the two techniques are built on top of sound dataflow analysis, coupled with concolic execution. We have implemented a prototype called Senx using this approach. Our evaluation on Senx shows that the two techniques are effective and applicable to a myriad of different programs. Our evaluation shows that the patches generated by Senx successfully fix 33 of 42 real-world buffer overflows and integer overflows from a variety of 11 applications including various tools or libraries for manipulating graphics/media files, a programming language interpreter, a relational database engine, a collection of programming tools for creating and managing binary programs, and a collection of basic file, shell, and text manipulation tools.	apl;automatic bug fixing;buffer overflow;concolic testing;correctness (computer science);data-flow analysis;database engine;dataflow;exception handling;graphics;integer overflow;interpreter (computing);library (computing);machine code;mesh analysis;programming language;programming tool;prototype;relational database;symbolic computation;test suite;vulnerability (computing)	Zhen Huang;David Lie	2017	CoRR		real-time computing;theoretical computer science;integer overflow;buffer overflow;dataflow;correctness;computer science;concolic testing;relational database;interpreter;vulnerability	SE	-57.5703100895883	55.79689836426949	133287
bb774e44e4ba09d404ffe018900f5395610582e0	security and privacy in cloud computing	privacy cloud security;cloud;security of data cloud computing data privacy;cloud privacy cloud computing cloud security;malware;big data;cryptography;cloud computing cryptography privacy malware big data;security;privacy;cloud computing	Cloud computing is a technology based on internet, where a pool of shared resources, called the cloud, and data centers maintain and store the client data. Cloud providers like Google, Microsoft and Amazon enables users to use these resources without acquiring them explicitly or physically. This research paper outlines what cloud computing is, services it provides, itu0027s various types, principles of security and highlights green data centers. Also, it analyses the key security issues that envelopes its market today with safety measures, to serve server providers and enterprises in the best way possible.	cloud computing	Zahir Tari	2014	IEEE Cloud Computing	10.1109/MCC.2014.20	cloud computing security;privacy software;big data;cloud computing;computer science;information security;operating system;internet privacy;world wide web;computer security	Security	-49.75865091335353	58.663895782657384	133565
8eb96524214c25f88f9d18b697fc9a86b5e11aea	necomatter: curating approach for sharing cyber threat information	web;cyber threat information;curation service	In this paper, we design and implement a novel system for connecting cyber threat information. The objective is to improve the information and its analysis results with machine intelligence assisted by human intelligence. This paper illustrates the system named NECOMAtter based on these assumptions, and summarizes our contributions in order to develop actionable knowledge.	artificial intelligence;domain driven data mining	Takuji Iimura;Daisuke Miyamoto;Hajime Tazaki;Youki Kadobayashi	2014		10.1145/2619287.2619306	engineering;internet privacy;world wide web;computer security	AI	-61.898590400259096	59.26427604344383	133974
2df04923970037d4cc515fffeaaea11f0d1dbf0b	pift: efficient dynamic information flow tracking using secure page allocation	control flow validation;program validation;security attacks	Dynamic information flow tracking (DIFT) has been an effective security countermeasure for both low-level memory corruptions and high-level semantic attacks. However, many software approaches suffers from large performance degradation and hardware approaches have great logic and storage overhead. In this paper, we propose a flexible, efficient, and light-weight approach to perform DIFT based on secure page allocation, PIFT. Instead of associating each data value with a taint tag, we aggregate data according to their taints, i.e., putting data with different attributes in different types of memory pages. Our approach is a compile-aided process that allows the compiler to allocate trusted/untrusted information into different memory pages. Our implementation and analysis show that the memory overhead is little, and the approach can protect critical information, like return address, indirect jump address, and system call arguments, from being overwritten by malicious data.	aggregate data;compiler;elegant degradation;high- and low-level;information flow;overhead (computing);return statement;system call;taint checking	Juan Carlos Martínez Santos;Yunsi Fei;Zhijie Jerry Shi	2009		10.1145/1631716.1631722	computer science;database;world wide web;computer security	Security	-55.407207066981385	56.00645301670774	134074
eee019a46ddc9d024f02fe155b6b21240a101d97	banishing misaligned incentives for validating reports in bug-bounty platforms		Bug-bounty programs have the potential to harvest the efforts and diverse knowledge of thousands of white hat hackers. As a consequence, they are becoming increasingly popular as a key part of the security culture of organizations. However, bug-bounty programs can be riddled with myriads of invalid vulnerability-report submissions, which are partially the result of misaligned incentives between white hats and organizations. To further improve the effectiveness of bug-bounty programs, we introduce a theoretical model for evaluating approaches for reducing the number of invalid reports. We develop an economic framework and investigate the strengths and weaknesses of existing canonical approaches for effectively incentivizing higher validation efforts by white hats. Finally, we introduce a novel approach, which may improve efficiency by enabling different white hats to exert validation effort at their individually optimal levels.	bug bounty program;theory	Aron Laszka;Mingyi Zhao;Jens Grossklags	2016		10.1007/978-3-319-45741-3_9	computer security;white hat;computer science;strengths and weaknesses;security culture;incentive;crowdsourcing;economics of security	Web+IR	-60.79039635550049	55.91980879972791	134240
6d9fa75ba5d89fc88604d3ff6efc652aa5001330	noninterference for free	fully abstract compilation;logical relations;secure compilation;dependency;information flow;parametricity;polymorphism;security;noninterference	The dependency core calculus (DCC) is a framework for studying a variety of dependency analyses (e.g., secure information flow). The key property provided by DCC is noninterference, which guarantees that a low-level observer (attacker) cannot distinguish high-level (protected) computations. The proof of noninterference for DCC suggests a connection to parametricity in System F, which suggests that it should be possible to implement dependency analyses in languages with parametric polymorphism. We present a translation from DCC into Fω and prove that the translation preserves noninterference. To express noninterference in Fω, we define a notion of observer-sensitive equivalence that makes essential use of both first-order and higher-order polymorphism. Our translation provides insights into DCC's type system and shows how DCC can be implemented in a polymorphic language without loss of the noninterference (security) guarantees available in DCC. Our contributions include proof techniques that should be valuable when proving other secure compilation or full abstraction results.	compiler;computation;data security;denotational semantics;first-order predicate;high- and low-level;non-interference (security);parametric polymorphism;parametricity;system f;turing completeness;type system	William J. Bowman;Amal G Ahmed	2015		10.1145/2784731.2784733	dependency;polymorphism;information flow;computer science;information security;theoretical computer science;parametricity;programming language;computer security;algorithm	PL	-54.18963683039151	52.941603758332406	134293
0177ed9efc18d59762504f9bf5bc35c82b14a503	can you handle the headaches? analyzing and optimizing the effectiveness of the incident management process	process support;systems and applications	Abstract Recovering from incidents in a timely appropriate manner is vital to maintaining operational efficiency, controlling costs, and keeping users happy and productive. A key to quick recovery is having an incident management process in place. An analysis of the incident management process can offer insight into how effectively the process supports problem detection and isolation and systems restoration. An analysis of the incident management process can contribute to systems and application resilience, the capacity to keep failures from dramatically affecting users.		Laurence J. Wolf	2004	Information Systems Security	10.1201/1086/44797.13.5.20041101/84905.3	computer science;computer security;incident management	DB	-59.78122208935882	50.03948308015935	134334
228f251875788dfda26c22267579042f326e173e	pricl: creating a precedent a framework for reasoning about privacy case law		We introduce PriCL: the first framework for expressing and automatically reasoning about privacy case law by means of precedent. PriCL is parametric in an underlying logic for expressing world properties, and provides support for court decisions, their justification, the circumstances in which the justification applies as well as court hierarchies. Moreover, the framework offers a tight connection between privacy case law and the notion of norms that underlies existing rule-based privacy research. In terms of automation, we identify the major reasoning tasks for privacy cases such as deducing legal permissions or extracting norms. For solving these tasks, we provide generic algorithms that have particularly efficient realizations within an expressive underlying logic. Finally, we derive a definition of deducibility based on legal concepts and subsequently propose an equivalent characterization in terms of logic satisfiability.	acid;algorithm;application security;artificial intelligence;big data;cathode ray tube;color layout descriptor;compactflash;complement (complexity);data system;decibel;digital rights management;health insurance portability and accountability act;information exchange;logic programming;p3p;privacy policy;privacy-enhancing technologies;schmidt decomposition;springer (tank);tree (data structure)	Michael Backes;Fabian Bendun;Jörg Hoffmann;Ninja Marnau	2015		10.1007/978-3-662-46666-7_18	computer science;artificial intelligence;data mining;mathematics;computer security;algorithm	AI	-50.2356475641311	51.286735999350384	134467
2e0c7dacfbc61ab4b2723cc1940cc559e4940887	enforcing drm policies across applications	policy enforcement;digital rights management;usage control;middleware;access control;digital right management	In this paper we present Trishul-UCON (T-UCON), a DRM system based on the UCON_ABC model. T-UCON is designed to be capable of enforcing not only application-specific policies, as any existing software-based DRM solution does, but also DRM policies across applications. This is achieved by binding the DRM policy only to the content it protects with no relations to the application(s) which will use this content. Furthermore, to guarantee that the policy is continuously enforced, we designed T-UCON as a JVM-based middleware that mediates the usage requests of any Java application to the protected content. Each request is granted or denied according to the content policy. We illustrate the unique features of T-UCON by using typical examples of DRM policies such as the pay-per-use and the use only N times scenarios. Preliminary results on the overhead of our solution are also provided.	algorithm;digital rights management;java;middleware;overhead (computing)	Srijith Krishnan Nair;Andrew S. Tanenbaum;Gabriela Gheorghe;Bruno Crispo	2008		10.1145/1456520.1456535	business;internet privacy;world wide web;computer security	Metrics	-50.69979345991083	55.58792983979678	134903
9637b9795027c0331a8d39fdff6e10cf37515c21	an event-driven, inclusionary and secure approach to kernel integrity		In this paper we address the problem of protecting computer systems against stealth malware. The problem is important because the number of known types of stealth malware increases exponentially. Existing approaches have some advantages for ensuring system integrity but sophisticated techniques utilized by stealthy malware can thwart them. We propose Runtime Kernel Rootkit Detection (RKRD), a hardwarebased, event-driven, secure and inclusionary approach to kernel integrity that addresses some of the limitations of the state of the art. Our solution is based on the principles of using virtualization hardware for isolation, verifying signatures coming from trusted code as opposed to malware for scalability and performing system checks driven by events. Our RKRD implementation is guided by our goals of strong isolation, no modifications to target guest OS kernels, easy deployment, minimal infrastructure impact, and minimal performance overhead. We developed a system prototype and conducted a number of experiments which show that the performance impact of our solution is negligible.	antivirus software;event-driven programming;experiment;kernel (operating system);malware;operating system;overhead (computing);prototype;rootkit;scalability;software deployment;stealth;system integrity	Satyajit Grover;Divya Naidu Kolar Sunder;Samuel O. Moffatt;Michael E. Kounavis	2008			kernel (linear algebra);microprocessor;control theory;computer network;control theory;programmable logic controller;computer science;response time;output device;self-tuning	Security	-54.71473245826254	56.67029497009115	135028
4b09e73a26dc80cc827abd286d8581133e1dd9bc	activity theory guided role engineering	distributed system;risk management;rbac;financial institutions;activity theory;role engineering	Roles are convenient and powerful concept for facilitating access to distributed systems and enforcing access management polices. RBAC is one the most widely used role engineering models in enterprises. Several threats arise due to insecure and inefficient design of roles when social and interaction dynamics in an organizational setting are ignored. Activity theory is one of the most applied and researched theories in context of understanding human actions, interactions with environments and dynamics against different social entities. The paper, first, presents overview of role-engineering and activity theory. Then the paper presents different methods in which activity theory can be applied for efficient and secure role-engineering processes. A case study, carried out at a US-based midsize financial institution, is also presented to demonstrate 1) how traditional role-engineering processes give way to threats and 2) how using activity theory models (2 used in this paper) can mitigate risks in role-engineering process.		Manish Gupta	2008			engineering;knowledge management;operations management;management science	AI	-49.27160404714907	52.8732338095479	135224
37ea54247bb3bedd356f5171ee5f8e1a83662dfc	an online approach for kernel-level keylogger detection and defense		Keyloggers have been studied for many years, but they still pose a severe threat to information security. Keyloggers can record highly sensitive information, and then transfer it to remote attackers. Previous solutions suffer from limitations in that: 1) Most methods focus on user-level keylogger detection; 2) Some methods need to modify OS kernels; 3) Most methods can be bypassed when the OS kernel is compromised. In this paper, we present LAKEED, an online defense against the kernel-level keylogger by utilizing the hardware assisted virtualization technology. Our system is compatible with the commodity operating system, and it can protect the running OS transparently. The basic idea of our approach is to isolate the target kernel extension that may contain the keylogger from keyboard drivers’ execution environment and then monitor their potential interactions. By comparing the runtime information with the execution baseline that is obtained by the offline analysis, the keylogger can be identified. The evaluation shows that LAKEED can defeat kernel-level keyloggers effectively with low performance overhead.	baseline (configuration management);event (computing);information security;information sensitivity;interaction;kernel (operating system);keystroke logging;lightweight kernel operating system;loadable kernel module;online and offline;overhead (computing);paging;protection ring;run time (program lifecycle phase);user space;x86 virtualization	Donghai Tian;Xiaoqi Jia;Junhua Chen;Changzhen Hu	2017	J. Inf. Sci. Eng.		kernel (linear algebra);computer science;distributed computing;keystroke logging;theoretical computer science	Security	-54.95374792985482	57.26583535461088	135326
be8ca90a58f5d90624a9bfe15d6df3552dd2734d	design of cyber security for critical infrastructures: a case for a schizoid design approach		In this invited talk, we argue that designing cyber security of critical infrastructure requires a spilt-personality approach to design as opposed to design for correctness or for performance. Designing a functionally correct system, or a performance constrained system is fundamentally different in the sense that such design requires us to build models and to systematically refine models towards implementation such that correctness is preserved between refinements, and performance optimizations are introduced during refinements. Designing systems with cyber-security properties requires us to not only build models from theoretical principles, but also require modeling possible behaviors of an adversary. Modeling adversarial behavior is akin to test-driven model refinement, and hence not so different from certain approaches used when our goal is functionally correct design. However, for cyber-physical systems, we often need to detect an ongoing cyber attack since safe guards for cyber security often depend on assumptions which can be invalidated e.g., insider attacks may invalidate perimeter security assumptions. Detecting ongoing attacks requires detecting behavioral anomalies in the physical system under cyber control --- thus requiring us to build models from data. Machine learning approaches could be used to build such models. This we view as a schizoid approach --- since the designer has to not only model the system from physical principles, he/she also has to build nominal behavioral models from data. While arguing this point of view, we introduce a virtual SCADA supervisory control and data acquisition laboratory we have built to help design cyber security of critical systems. The majority of this talk focuses on describing this software based virtual laboratory called VSCADA. Most of this research is published in [8,11] and summarized here for the sake of exposition to the present audience.	computer security	Avik Dayal;Yi Deng;Sandeep K. Shukla	2015		10.1007/978-3-319-24126-5_3	simulation;computer science;engineering;distributed computing;computer security	EDA	-59.582319834192624	57.13907331225168	135346
402391053eb0aa28c5d5878368a9131c99fb5faa	protecting infrastructure assets from real-time and run-time threats		Real-time availability with integrity is a crucial security requirement for critical infrastructure assets – delays in reporting device states or computations may result in equipment damage, perhaps even catastrophic failure. However, it is also necessary to address malicious software-based threats. Trusted computing (TC) is a security paradigm that enables application platforms to enforce the integrity of execution targets. A TC architecture can be combined with a real-time access control system to help protect against real-time availability and malware threats. However TC architectures offer only static (load-time) protection, so it is still necessary to address the possibility of run-time (execution) attacks. This paper focuses on the protection afforded by TC platforms to critical infrastructure assets. The paper defines a threat model, analyzes vulnerabilities, proposes services and tools that guarantee realtime availability with integrity, and demonstrates how they can be used to protect communications of an IEC61850-90-5-compliant substation automation system in an electricity grid. Also, it discusses the impact of run-time attacks on TC-compliant critical infrastructure assets.	access control;algorithm;computation;computer architecture;control system;jenkins;loader (computing);malware;programming paradigm;real-time clock;real-time transcription;run time (program lifecycle phase);sensor;structural load;threat (computer);threat model;traction substation;trusted computing	Jonathan Jenkins;Mike Burmester	2013		10.1007/978-3-642-45330-4_7	security management;critical infrastructure;firm-specific infrastructure	Security	-53.16312250390673	57.00935051705402	135414
f568b4a6c567b97ce6d32922001b69d548576c0d	a data movement policy framework for improving trust in the cloud using smart contracts and blockchains		Trust in the cloud is still a problem. Most are in agreement that 'transparency' is key to cloud trust, but transparency applies to a variety of cloud operations, which is why cloud trust research is diverse. Widely publicized breaches recently had to do with third parties. Untrusted third parties and data movement are closely related. There are valid use cases to duplicate data for redundancy, but this typically happens behind closed doors. We see that as a problem; there are no mechanisms that we know of to police or track data as it gets copied or moves between clouds. We are proposing an approach to cloud trust that leverages the innovative blockchain technology to help increase transparency and also reduce the problem of depending on TTPs. By using a consumer belief model tailored to the cloud we also show the relevance of consumer policies in trust with regards to their data. We propose to use smart contracts as the vehicle for the policies and a belief / recommendation model to help guide us to a successful outcome.	bitcoin;cloud computing;digital currency;ethereum;private network;relevance;smart contract	Stephen S. Kirkman	2018	2018 IEEE International Conference on Cloud Engineering (IC2E)	10.1109/IC2E.2018.00054	computer security;redundancy (engineering);doors;use case;transparency (graphic);blockchain;cloud computing;business	SE	-50.102113349391246	58.81298629192374	135597
c95277efd1d134ab45d746d222077563d54a8066	secure logging for auditable file system using separate virtual machines	file system logging;virtual machine;virtual machining;logging virtual machine;system monitoring;virtual machine monitors;operating system;malware;virtual machines;auditable file system;file system;virtual machines file organisation security of data system monitoring;file systems virtual machining information systems web pages frequency distributed processing application software computer science operating systems hardware;secure logging;virtual machines auditable file system file system logging;linux;on disk structure;security;working virtual machine;security of data;file systems;reading and writing;operating systems;hardware;working virtual machine secure logging auditable file system malware on disk structure operating system logging virtual machine;file organisation	Auditable file system is used to track the usage of the file system including the operations like read and write. Auditable file system keeps the trails of users’ action and the trails are kept faithfully for future auditing. However, as the logs are still kept within the same file system, it will be quite vulnerable to be exposed as malware penetrating the system. Even with the file system hiding the logs, the skillful attacker can still analyze the on-disk structure to get and modify the logs. Thus the logs should be kept separate from the working system. Virtual machines can provide such separation as virtual machines can hold the whole operating system while still keep the system apart from the metal hardware. We propose a method of secure logging for auditable file system using a logging virtual machine. The logs are kept in another virtual machine safely. Even the working virtual machine is broken; the logs are not exposed to the outside. By the isolation provided by virtual machines, the logs can be kept safe and valid. The high privileged user can not modify the logs contents, or forge the logs and data to keep consistency, or pretend to be another user for doing un-authorized actions. We have done several works as well as a prototype system to show the feasibility of such approach. Experiments show that the logging virtual machine will not bring too much overhead.	authorization;experiment;forge;hard disk drive;malware;operating system;overhead (computing);prototype;virtual machine	Siqin Zhao;Kang Chen;Weimin Zheng	2009	2009 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2009.32	computer hardware;computer science;virtual machine;information security;operating system;database;distributed computing	OS	-53.534547877253544	58.1127131753692	135605
5aa58a0e50d171d88b4904d6f8f899949dfb8ccc	security through diversity: are we there yet?	memory management;testing and debugging;runtime environment;computer crime;software engineering;compilers;computer security;software architecture;prediction methods;testing and debugging system issues software engineering compilers programming languages error handling and recovery;internet;system issues;error handling and recovery;program processors;computer security program processors computer crime software architecture runtime environment memory management prediction methods internet;programming languages	Because most software attacks rely on predictable behavior on the target platform, mass distribution of identical software facilitates mass exploitation. Countermeasures include moving-target defenses in general and biologically inspired artificial software diversity in particular. Although the concept of software diversity has interested researchers for more than 20 years, technical obstacles prevented its widespread adoption until now. Massive-scale software diversity has become practical due to the Internet (enabling distribution of individualized software) and cloud computing (enabling the computational power to perform diversification). In this article, the authors take stock of the current state of software diversity research. The potential showstopper issues are mostly solved; the authors describe the remaining issues and point to a realistic adoption path.	cloud computing;diversification (finance);software bug	Per Larsen;Stefan Brunthaler;Michael Franz	2014	IEEE Security & Privacy	10.1109/MSP.2013.129	software architecture;compiler;real-time computing;the internet;computer science;theoretical computer science;computer security;software metric;memory management	Security	-59.155385147808516	57.02301943393982	135888
bba50da7c43a29207bc1a7904548e8c5ffc39e38	separating hypervisor trusted computing base supported by hardware	hardware extension;trusted computing base;virtualisation	In this paper we explore how recent advances in virtualisation support for commodity hardware could be utilised to reduce the Trusted Computing Base (TCB) and improve the code separation of a hypervisor. To achieve this, we reassess on the definition of the TCB and illustrate how segregation of different code blocks could be enforced by hardware protection mechanisms. We argue that many software-based efforts in TCB reduction and separation can benefit from utilising those hardware capabilities.	algorithm;code::blocks;commodity computing;hypervisor;protection mechanism;trusted computing base	Carl Gebhardt;Chris I. Dalton;Allan Tomlinson	2010		10.1145/1867635.1867648	embedded system;real-time computing;storage hypervisor;computer science;operating system;trusted computing base	Arch	-53.41552715277269	55.97570952993695	136094
104e29743b98ea97d73ce9558e839e0a6e90113f	android ion hazard: the curse of customizable memory management system	dos;static taint analysis;android ion;information leakage	ION is a unified memory management interface for Android that is widely used on virtually all ARM based Android devices. ION attempts to achieve several ambitious goals that have not been simultaneously achieved before (not even on Linux). Different from managing regular memory in the system, ION is designed to share and manage memory with special constraints, e.g., physically contiguous memory. Despite the great flexibility and performance benefits offered, such a critical subsystem, as we discover, unfortunately has flawed security assumptions and designs. In this paper, we systematically analyze ION related vulnerabilities from conceptual root causes to detailed implementation decisions. Since ION is often customized heavily for different Android devices, the specific vulnerabilities often manifest themselves differently. By conducting a range of runtime testing as well as static analysis, we are able to uncover a large number of serious vulnerabilities on the latest Android devices (e.g., Nexus 6P running Android 6.0 and 7.0 preview) such as denial-of-service and dumping memory from the system and arbitrary applications (e.g., email content, passwords). Finally, we offer suggestions on how to redesign the ION subsystem to eliminate these flaws. We believe that the lessons learned can help guide the future design of similar memory management subsystems.	android;cryptographic hash function;denial-of-service attack;email;glossary of computer graphics;information leakage;information sensitivity;linux;management interface;management system;memory management;operating system;password;spectral leakage;static program analysis;taint checking;vulnerability (computing)	Hang Zhang;Dongdong She;Zhiyun Qian	2016		10.1145/2976749.2978320	real-time computing;simulation;disk operating system;computer science;computer security	Security	-54.91691185133361	56.811899272334	136126
dee9a0648cc433977f31a90ca57f3b3d8109e29b	a complete framework for kernel trace analysis	complete framework;kernel trace analysis;trace analysis;kernel;formal specification;kernel trace abstraction;authoring languages;kernel engines linux probes intrusion detection;intrusion detection;probes;pattern detection;engines;host based trace kernel trace analysis complete framework pattern specification pattern detection kernel trace abstraction scripting language network trace;pattern specification;pattern recognition;host based trace;security of data authoring languages formal specification;intrusion detection pattern recognition trace analysis;linux;network trace;security of data;scripting language	This paper presents a complete framework for the specification and the detection of patterns as well as the abstraction of kernel traces. We propose a declarative, and easy-to-use scripting language, for the pattern specification. The compiled patterns are then fed-to a detection engine which analyzes the traces, and gradually communicates with an output module to warn the administrator about the underlying problems executing on the system. We consider that our approach is general enough to be used with any kind of traces (network or host-based) or even combined traces. Moreover, the proposed language can describe efficiently patterns related to different types of domains like security, performance, and abstraction.	compiler;computer performance;computer security;declarative programming;kernel (operating system);scripting language;tracing (software)	H. Waly;Béchir Ktari	2011	2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE)	10.1109/CCECE.2011.6030698	intrusion detection system;kernel;real-time computing;computer science;theoretical computer science;operating system;formal specification;scripting language;programming language;linux kernel	HPC	-58.07987314828563	53.97987638619818	136201
3fde8221ede6dbad44423cf97c94268475203eed	information-flow security for interactive programs	interactive imperative programs;programming language semantics;language based security;language semantics imperative programming languages language based security conditions interactive imperative programs strategy based information flow security conditions;security of data interactive systems programming language semantics;language based security conditions;programming language;information security computer languages interactive systems computer science research initiatives protection web server graphical user interfaces protocols encoding;language semantics;information flow;strategy based information flow security conditions;technical report;computer science;interactive systems;security of data;imperative programming languages;type system;data security	Interactive programs allow users to engage in input and output throughout execution. The ubiquity of such programs motivates the development of models for reasoning about their information-flow security, yet no such models seem to exist for imperative programming languages. Further, existing language-based security conditions founded on noninteractive models permit insecure information flows in interactive imperative programs. This paper formulates new strategy-based information-flow security conditions for a simple imperative programming language that includes input and output operators. The semantics of the language enables a fine-grained approach to the resolution of nondeterministic choices. The security conditions leverage this approach to prohibit refinement attacks while still permitting observable nondeterminism. Extending the language with probabilistic choice yields a corresponding definition of probabilistic noninterference. A soundness theorem demonstrates the feasibility of statically enforcing the security conditions via a simple type system. These results constitute a step toward understanding and enforcing information-flow security in real-world programming languages, which include similar input and output operators	batch processing;caml;computation;halting problem;imperative programming;information flow;input/output;interactivity;jpeg;language-based security;non-interference (security);nondeterministic algorithm;observable;programming language;refinement (computing);server (computing);type system;world-system	Kevin R. O'Neill;Michael R. Clarkson;Stephen Chong	2006	19th IEEE Computer Security Foundations Workshop (CSFW'06)	10.1109/CSFW.2006.16	computer security model;information flow;type system;computer science;technical report;theoretical computer science;database;data security;programming language;algorithm	PL	-53.29662472339475	52.93047622782263	136344
d407368b02ea1a24b472664e0d833be5f4de7b5c	a network protocol reverse engineering method based on dynamic taint propagation similarity		Automatic network protocol reverse engineering is very important for many network applications such as fuzz testing and intrusion detection. Since sequences alignment on network traces is limited by the lack of semantic information, recent researches focus on dynamic taint analysis. But current dynamic taint based methods need heuristics rules to handle different network protocols which make them too complex to run automatically and efficiently. Our approach is inspired by the observation that different fields of network protocol message are processed in different execution path of the binary application, while the bytes of same message field are processed by highly similar instructions sequence. After analyzing the similarity of dynamic taint propagation and adjusting boundaries according to keywords and separators, we can identify the field boundaries not only accurately but also fully automatically. Evaluated by real-world protocol implementations (FTP, HTTP, DNS, etc.), the result shows our method is more accurate and simpler than exist methods.	communications protocol;reverse engineering;software propagation;taint checking	Weiming Li;Meirong Ai;Bo Jin	2016		10.1007/978-3-319-42291-6_58	computer science;theoretical computer science;database;distributed computing	Security	-58.798680534046994	55.75103375140934	136545
5470e4c04176815f5d10289254059db8073f2e07	state estimation for energy theft detection in microgrids	state estimation;companies;smart grid energy theft detection microgrids smart meter measurement bias weighted least square state estimation energy thieves;current measurement;vectors;smart meters current measurement microgrids voltage measurement vectors state estimation companies;microgrids;smart power grids distributed power generation least squares approximations power system state estimation smart meters;voltage measurement;smart meters	In traditional power networks, energy theft is a significant problem that causes severe financial losses to utility companies and legitimate users, jeopardizes system stability, and enables other illegal activities. Recently, governments and utility companies propose the Smart Grid as the next generation electric network to improve the current grid's efficiency, reliability, and security. In the Smart Grid, smart meters are deployed at users' premises to facilitate data collection, system control, etc. However, smart meters are vulnerable to cyber attacks, thus enabling easier energy pilfering. In this paper, we model the amount of energy stolen by a smart meter as a measurement bias, and propose an energy theft detection algorithm based on state estimation. In particular, our algorithm employs weighted least squares (WLS) state estimation, and can identify all the energy thieves in the system. We conduct extensive simulations in IEEE 13-bus and 123-bus test systems to validate our algorithm.	algorithm;least squares;microgrid;next-generation network;simulation;smart meter	Sergio Salinas;Changqing Luo;Weixian Liao;Pan Li	2014	9th International Conference on Communications and Networking in China	10.1109/CHINACOM.2014.7054266	vector space;smart grid;computer security	EDA	-50.77054976253239	59.43047476035384	136850
9f9a8f17d730e0f3bf018f7de11ec8d77eb4d58b	runtime protection via dataflow flattening	software architecture data encapsulation data flow analysis data flow graphs security of data;data hiding;memory management unit;data flow graphs;runtime software protection data security computer architecture inspection data analysis memory management application software automata embedded software;data encapsulation;software architecture;information flow;technology and engineering;security software protection data hiding obfuscation;data flow analysis;obfuscation;security;software protection;security of data;spec cpu2006 benchmark suite dataflow flattening data location hiding dataflow graph static dataflow analysis dynamic data tracking data oriented analogue control flow flattening techniques information flow protection c program compiling memory management unit stack based variables	Software running on an open architecture, such as the PC, is vulnerable to inspection and modification. Since software may process valuable or sensitive information, many defenses against data analysis and modification have been proposed. This paper complements existing work and focuses on hiding data location throughout program execution. To achieve this, we combine three techniques: (i) periodic reordering of the heap, (ii) migrating local variables from the stack to the heap and (iii) pointer scrambling. By essentially flattening the dataflow graph of the program, the techniques serve to complicate static dataflow analysis and dynamic data tracking. Our methodology can be viewed as a data-oriented analogue of control-flow flattening techniques. Dataflow flattening is useful in practical scenarios like DRM, information-flow protection, and exploit resistance. Our prototype implementation compiles C programs into a binary for which every access to the heap is redirected through a memory management unit. Stack-based variables may be migrated to the heap, while pointer accesses and arithmetic may be scrambled and redirected. We evaluate our approach experimentally on the SPEC CPU2006 benchmark suite.	benchmark (computing);control flow;data-flow analysis;dataflow;digital rights management;dynamic data;encryption;experiment;heap (data structure);information sensitivity;local variable;memory management unit;open architecture;personal computer;pointer (computer programming);prototype;real life	Bertrand Anckaert;Mariusz H. Jakubowski;Ramarathnam Venkatesan;Chit Wei Saw	2009	2009 Third International Conference on Emerging Security Information, Systems and Technologies	10.1109/SECURWARE.2009.44	software architecture;parallel computing;real-time computing;information flow;obfuscation;memory management unit;computer science;information security;binary heap;operating system;data-flow analysis;heap overflow;information hiding;computer security	SE	-55.56401828156728	55.693909778013754	137087
b75c40375251ca1b1cec5085e266c1735d45f88b	policy management using access control spaces	role based access control;access control policy;access control models;access control;authorization mechanisms;policy management	We present the concept of an access control space and investigate how it may be useful in managing access control policies. An access control space represents the permission assignment state of a subject or role. For example, the set of permissions explicitly assigned to a role defines its specified subspace, and the set of constraints precluding assignment to that role defines its prohibited subspace. In analyzing these subspaces, we identify two problems: (1) often a significant portion of an access control space has unknown assignment semantics, which indicates that the policy is underspecified; and (2) often high-level assignments and constraints that are easily understood result in conflicts, where resolution often leads to significantly more complex specifications. We have developed a prototype system, called Gokyo, that computes access control spaces. Gokyo identifies the unknown subspace to assist system administrators in developing more complete policy specifications. Also, Gokyo identifies conflicting subspaces and enables system administrators to resolve conflicts in a variety of ways in order to preserve the simplicity of constraint specification. We demonstrate Gokyo by analyzing a Web server policy example and examine its utility by applying it to the SELinux example policy. Even for the extensive SELinux example policy, we find that only eight additional expressions are necessary to resolve Apache administrator policy conflicts.	access control;authorization;categorization;dvd region code;exception handling;file system permissions;high- and low-level;prototype;regular expression;selinux;server (computing);system administrator;web server;world wide web	Trent Jaeger;Xiaolan Zhang;Antony Edwards	2003	ACM Trans. Inf. Syst. Secur.	10.1145/937527.937528	computer access control;computer science;access control;role-based access control;data mining;database;computer security	Security	-52.26189156506153	53.64824006993136	137177
bfcb784c80ceb29cd49a5fe88cd0b3c5737adca6	a classification of delegation schemes for attribute authority	access control policy;access control	Recently assertions have been explored as a generalisation of certificates within access control. Assertions are used to link arbitrary attributes (e.g. roles, security clearances) to arbitrary entities (e.g. users, resources). These attributes can then be used as identifiers in access control policies to refer to groups of users or resources. In many applications attribute management does not happen within the access control system. External entities manage attribute assignments and issue assertions that are then used in the access control system. Some approaches also allow for the delegation of attribute authority, in order to spread the administrative workload. In such systems the consumers of attribute assertions issued by a delegated authority need a delegation verification scheme. In this article we propose a classification for schemes that allow to verify delegated authority, with a focus on attribute assertion. Using our classification, one can deduce some advantages and drawbacks of different approaches to delegated attribute assertion.	access control;assertion (software development);certificate authority;control system;entity;identifier;public key certificate;statistical classification	Ludwig Seitz;Erik Rissanen;Babak Sadighi Firozabadi	2006		10.1007/978-3-540-75227-1_11	delegation;computer science;access control;data mining;database;computer security	Security	-48.35152493694851	53.61862603317988	137198
d45f7395561cff0e07a4e6cb170535cdc82a9cc7	windows memory forensics	combat;securite informatique;computer security;combate;forensic science;police scientifique;seguridad informatica;ciencia forense;fighting	This paper gives an overview of all known “live” memory collection techniques on a Windows system, and freely available memory analysis tools. Limitations and known anti-collection techniques will also be reviewed. Analysis techniques will be illustrated through some practical examples, drawn from past forensics challenges. This paper is forensics-oriented, but the information provided information will also be of interest to malware analysts fighting against stealth rootkits.	computer data storage;hard coding;internet;malware;memory forensics;metasploit;microsoft windows;operating system;out of the box (feature);rootkit;shutdown (computing);software deployment;stealth	Nicolas Ruff	2007	Journal in Computer Virology	10.1007/s11416-007-0070-0	computer science;forensic science;operations research;paiting;computer security	Security	-57.1011264106679	54.59554247560122	137299
5f9e15928647b03597bd7ece12634d7f2fba3cfa	towards an open, trusted digital rights management platform	mandatory access control;virtual machine;mandatory access controls;drm;security management;digital rights management;open architecture;trusted computing;information flow;operating system;virtual machines;use case;trusted computing platform;digital right management;open source	Trusted computing has received criticism from those who fear it will be used by influential market forces to exert power over the software used on consumer platforms. This paper describes an open architecture for digital rights management (DRM) enforcement on trusted computing platforms that empowers the consumer to select their operating-system and applications, including open-source options, without weakening the strength of the security functions. A key component in the architecture is a security manager that enforces mandatory access controls on shared devices, restricted information flows between virtual machines, and DRM policy on protected objects. The paper describes two use-cases: a DRM scenario with protected media content and remote home-working on sensitive medical data.	access control;complex network;digital rights management;open architecture;open platform;open-source software;trust anchor;trusted computing;trusted operating system;virtual machine	Andrew Cooper;Andrew P. Martin	2006		10.1145/1179509.1179525	direct anonymous attestation;engineering;trusted network connect;internet privacy;world wide web;computer security	Security	-50.890638513130206	58.615482325123814	137330
638ad3ca6a36f3028bbb1119e678f85cb9c5b97d	an encryption approach to secure modification and deletion for flash-based storage	reliability;performance evaluation;encryption;encryption reliability flash memories performance evaluation file systems;erasing reliability encryption strategy and key esk security module modification security flash based storage data management security magnetic disk flash memory information security;storage management cryptography flash memories;flash memories;file systems;key management reliable erasing flash memory encryption strategy	Reliable erasing of data from storage devices is a critical component of secure data management and is well understood for magnetic disks. However, flash memory has unusual electronic limitations that make in-place updating impossible. Many secure deletion techniques have been proposed to improve both information security and erasing reliability. This paper investigates secure modification further. First, a formal definition of the levels of reliable erasing over flash-based systems is introduced. Then, an encryption strategy and key (ESK) security module are implemented. This module encrypts confidential files and forces all the generated keys and other relevant information of each file to be stored in the same blocks. Consequently, when securely modifying or deleting files, the ESK module erases as few blocks as possible. Experimental results show that the proposed module can improve the level of information safety and can reduce the number of page copies and block erases due to reliable erasing.	cipher;confidentiality;data erasure;disk storage;encryption;flash memory;garbage collection (computer science);in-place algorithm;information security;key management;sanitization (classified information)	Rize Jin;Hyung-Ju Cho;Tae-Sun Chung	2014	IEEE Transactions on Consumer Electronics	10.1109/TCE.2014.7027340	flash file system;computer science;reliability;database;filesystem-level encryption;on-the-fly encryption;internet privacy;computer security;encryption	Security	-49.07080673048965	60.435413224327135	137520
471c7375dac2003f80b293ee24067a8cf74e7dda	guide: graphical user interface fingerprints physical devices		Nowadays, the number of visible physical devices exposed on the Internet is dynamically increasing and they play a crucial role for bridging between the cyber space and the physical world, such as network printer, Webcam, and industrial control devices. Discovering these devices brings about the deep understanding on these devices' characteristics and help secure device security in the cyber space. A device fingerprint is a prerequisite of device discovery in the Internet. However, today's online device search depends on keywords of packet head fields and the keyword collection is done manually. This impedes an accurate and large-scale device discovery, due to high human efforts and inevitable human errors, as well as the difficulty of keeping keywords complete and updated. To address this problem, we propose GUIDE, a framework to automatically generate device fingerprints based on webpages embedded in these devices. In order to demonstrate how GUIDE works, we also develop its prototype system and provide a case study which discover surveillance devices in the cyber space.	bridging (networking);cyberspace;device fingerprint;embedded system;graphical user interface;human error;internet;network packet;printer (computing);prototype;webcam	Qiang Li;Xuan Feng;Zhi Li;Haining Wang;Limin Sun	2016	2016 IEEE 24th International Conference on Network Protocols (ICNP)	10.1109/ICNP.2016.7784468	simulation;operating system;multimedia;world wide web	Mobile	-52.37356187024292	60.291165912888566	137718
2f7e3fb8e49d1cf731115eac2968c3f6af4f47b5	efficient, context-aware privacy leakage confinement for android applications without firmware modding	android;context aware policy;privacy leakage;bytecode rewriting	As Android has become the most prevalent operating system in mobile devices, privacy concerns in the Android platform are increasing. A mechanism for efficient runtime enforcement of information-flow security policies in Android apps is desirable to confine privacy leakage. The prior works towards this problem require firmware modification (i.e., modding) and incur considerable runtime overhead. Besides, no effective mechanism is in place to distinguish malicious privacy leakage from those of legitimate uses. In this paper, we take a bytecode rewriting approach. Given an unknown Android app, we selectively insert instrumentation code into the app to keep track of private information and detect leakage at runtime. To distinguish legitimate and malicious leaks, we model the user's decisions with a context-aware policy enforcement mechanism. We have implemented a prototype called Capper and evaluated its efficacy on confining privacy-breaching apps. Our evaluation on 4723 real-world Android applications demonstrates that Capper can effectively track and mitigate privacy leaks. Moreover, after going through a series of optimizations, the instrumentation code only represents a small portion (4.48% on average) of the entire program. The runtime overhead introduced by Capper is also minimal, merely 1.5% for intensive data propagation.	android;firmware;internet privacy;malware;mobile device;modding;operating system;overhead (computing);personally identifiable information;prototype;rewriting;run time (program lifecycle phase);software propagation;spectral leakage	Mu Zhang;Heng Yin	2014		10.1145/2590296.2590312	real-time computing;computer science;internet privacy;computer security;android	Security	-55.53213261281503	58.0096027639948	137727
6bbae83fd5f3143d19f70e5a314bb847c9598b3a	precrime to the rescue: defeating mobile malware one-step ahead	server application;profile guided optimization;operating system kernel	Prior mobile malware defensive means is usually retroactive, which may either lead to high false negatives or can hardly recover systems states from malware activities. PreCrime is a proactive malware detection scheme that detects and stops malware activities from happening. PreCrime creates mirrors of a mobile device in a resource-rich and trusted cloud, which speculatively executes multiple likely user operations concurrently to detect potential tampering and information leakage. Our preliminary evaluation shows that PreCrime introduces small performance overhead on smartphones and feasible delay during speculative execution on the cloud.	cloud computing;emulator;information leakage;mathematical optimization;mobile device;mobile malware;multi-core processor;online and offline;overhead (computing);proactive parallel suite;smartphone;spectral leakage;speculative execution;virtual machine	Cheng Tan;Haibo Li;Yubin Xia;Binyu Zang;Cheng-Kang Chu;Tieyan Li	2014		10.1145/2637166.2637224	engineering;cryptovirology;internet privacy;world wide web;computer security	Arch	-55.138519441123286	57.2888201554281	137806
9797b52a0e77cc5b8ed89848fc33b0f06854a0b9	security enhancement of java remote method invocation	computer languages;java remote method invocation security;information security;java authentication communication system security authorization information security network servers computer languages production systems performance gain performance loss;authorisation;authentication;authentication service;performance of systems;computer system;satisfiability;secure communication;remote procedure calls authorisation java;computer system security enhancement remote procedure call object oriented environment kerberos authentication service authorization service java remote method invocation security secure rmi secure communication;remote procedure call;object oriented environment;secure rmi;network servers;it security;object oriented;authorization service;remote method invocation;performance gain;security enhancement;java authentication and authorization service;production systems;authorization;performance loss;kerberos;remote procedure calls;communication system security;java	Java remote method invocation is an implementation of remote procedure call in object oriented environment. However, its security level can be regarded as very low. By using additional technologies: Kerberos and Java authentication and authorization service, one can greatly improve Java remote method invocation security. These enhancements are called secure RMI. It is shown that by using secure RMI three conditions of secure communication can be satisfied, namely: integrity, confidentiality and authentication. In modern computer systems there is also a requirement for authorization. It is handled by secure RMI as well. Finally, performance of system build by using secure RMI is studied	confidentiality;java authentication and authorization service;java remote method invocation;kerberos;remote procedure call;secure communication;subroutine	Dominik Zalewski	2006	2006 International Conference on Dependability of Computer Systems	10.1109/DEPCOS-RELCOMEX.2006.47	computer science;internet privacy;remote procedure call;world wide web;computer security	EDA	-52.33944547363479	53.13619763199021	138203
649a6cbd35e8d5807eeb173f0b3b796ef2bbce83	the role of physical layer security in iot: a novel perspective	key management;physical layer security;internet of things;device configuration;body area networks;wireless sensor networks	This paper deals with the problem of securing the configuration phase of an Internet of Things (IoT) system. The main drawbacks of current approaches are the focus on specific techniques and methods, and the lack of a cross layer vision of the problem. In a smart environment, each IoT device has limited resources and is often battery operated with limited capabilities (e.g., no keyboard). As a consequence, network security must be carefully analyzed in order to prevent security and privacy issues. In this paper, we will analyze the IoT threats, we will propose a security framework for the device initialization and we will show how physical layer security can effectively boost the security of IoT systems.	internet of things;network security;privacy;smart environment	Tommaso Pecorella;Luca Brilli;Lorenzo Mucchi	2016	Information	10.3390/info7030049	computer security model;cloud computing security;wireless sensor network;security information and event management;security association;computer science;key management;internet security;security service;internet privacy;security testing;computer security;internet of things;computer network	Security	-49.782843838231	60.059126586776465	138250
e09f334b27571d8356e33449b83323ac2100dfeb	cpu bugs, cpu backdoors and consequences on security	sistema operativo;virtual machine;virtual machine monitor;microprocessor;emulateur;securite informatique;machine virtuelle;proof of concept;computer security;operating system;seguridad informatica;systeme exploitation;microprocesseur;emulador;maquina virtual;microprocesador;emulator	In this paper, we present the security implications of x86 processor bugs or backdoors on operating systems and virtual machine monitors. We will not try to determine whether the backdoor threat is realistic or not, but we will assume that a bug or a backdoor exists and analyze the consequences on systems. We will show how it is possible for an attacker to implement a simple and generic CPU backdoor in order—at some later point in time—to bypass mandatory security mechanisms with very limited initial privileges. We will explain practical difficulties and show proof of concept schemes using a modified Qemu CPU emulator. Backdoors studied in this paper are all usable from the software level without any physical access to the hardware.	backdoor (computing);central processing unit;emulator;operating system;physical access;software bug;virtual machine;x86	Loïc Duflot	2008	Journal in Computer Virology	10.1007/s11416-008-0109-x	embedded system;real-time computing;computer science;virtual machine;operating system;hypervisor;programming language;proof of concept;computer security	Security	-55.637498802030755	55.011130585988944	138622
a3614f8122ea377cb6a85e0751bd0702587f1931	a data-driven cyber-physical detection and defense strategy against data integrity attacks in smart grid systems	generators;smart power grids distributed control phasor measurement power system transient stability;phasor measurement units lead real time systems power system stability smart grids coherence generators;data driven cyber physical detection attack mitigation pmu data corruption power system telltale physical couplings cyber corruption flocking based modeling paradigm geographically distributed phasor measurement units real time data distributed control transient stability smart grid systems data integrity attacks defense strategy;smart grids;lead;coherence;power system stability;smart grid systems data driven data integrity attacks deep belief networks;phasor measurement units;real time systems	I consider a cyber-physical perspective to the problem of detecting and defending against data integrity attacks in smart grid systems. In this paper, the problem of transient stability with distributed control using real-time data from geographically distributed Phasor Measurement Units (PMUs) is studied via a flocking-based modeling paradigm. I demonstrate how cyber corruption can be identified through the effective use of telltale physical couplings within the power system. I also develop a data-driven real-time cyber-physical detection and defense strategy with distributed control using real-time data from PMUs. The proposed strategy leverages the physical coherence to probe and detect PMU data corruption and estimate the true information values for attack mitigation.	computer simulation;cyber-physical system;data integrity;deep learning;distributed control system;flocking (behavior);grid systems corporation;phasor;power management unit;programming paradigm;real-time clock;real-time data;real-time transcription;sensor;threat model	Jin Wei	2015	2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2015.7418280	embedded system;real-time computing;engineering;computer security	Embedded	-57.552521540461	51.610502108675945	138715
32b4a74cfbbd93acc3306f3addcd3ed1a4e3aa8d	secure autonomous uavs fleets by using new specific embedded secure elements	wireless communication;smart cards;cryptography;proposals;unmanned aerial vehicles;wireless sensor networks	Unmanned Aerial Vehicles (UAVs) fleets are becoming more apparent in both military and civilian applications. However security of these systems still remains unsatisfactory if a strong adversary model with a high attack potential (i.e. the adversary has capabilities and knowledge to capture a UAV, to perform side-channel or fault injection or other physical, software or combined attacks in order to gain access to some secret data like cryptographic keys, mission plan, etc.) is considered. The aim of this position paper is to draw security requirements for this kind of adversaries and to propose theoretical solutions based on an embedded Secure Element (SE) that could help to accommodate these requirements. Finally, our proposal on how to use these SEs to secure Autonomous UAVs fleets is presented.	adversary (cryptography);adversary model;aerial photography;autonomous system (internet);embedded system;fault injection;google wallet;key (cryptography);requirement;side-channel attack;unmanned aerial vehicle	Raja Naeem Akram;Pierre-François Bonnefoi;Serge Chaumette;Konstantinos Markantonakis;Damien Sauveron	2016	2016 IEEE Trustcom/BigDataSE/ISPA	10.1109/TrustCom.2016.0116	embedded system;simulation;engineering;computer security	Security	-51.09377090610231	56.52654054705358	138989
fda85ee45163aeebd7c3f0103c887d952f448d34	using semantic web technologies to specify constraints of rbac	owl;security management;owl rbac constraint semantic web;role based access control;secure communication;semantic web technology;semantic web permission owl access control power generation computer security power system security energy management information security authorization;constraint;rbac;distributed environment;web ontology language;secure system;semantic web	Role-based access control (RBAC) models have generated a great interest in the security community as a powerful and generalized approach to security management. One of important aspects in RBAC is constraints that constrain what components in RBAC are allowed to do. There are lots of research have been achieved to specify constraints for secure system developers. However more work is need urgently to met requirements for interoperability of machine and people understandable constraints specification in open and distributed environment. In this paper we propose another approach to specify constraints using Semantic Web technologies. The Web Ontology Language (OWL) specification of basic RBAC components and constraints are described in detail.	role-based access control;semantic web	Di Wu;Jian Lin;Yabo Dong;Miaoliang Zhu	2005		10.1109/PDCAT.2005.247	web application security;semantic web rule language;data web;computer science;semantic web;social semantic web;role-based access control;semantic web stack;database;web ontology language;world wide web;owl-s;computer security	AI	-49.40417245092902	49.72776868642676	139067
ae59881f809a7601db1144a4234c6944c5a47dbf	automating mac spoofer evidence gathering and encoding for investigations		Following up on the previous work, we elaborate on the details of the design and implementation of the live and dead digital evidence gathering and its encoding into Forensic Lucid by the corresponding MAC Spoofer Analyzer’s (MSA’s) components in an actual operational environment. We monitor over a 1000 analyst-managed computers on the Faculty’s network to help network system administrators in daily network security monitoring. The common Forensic Lucid evidence encoding format represents a consistent evidence representation and allows specification of reasoning functions over the evidence in a context-oriented manner.		Serguei A. Mokhov;Michael J. Assels;Joey Paquet;Mourad Debbabi	2014		10.1007/978-3-319-17040-4_11	computer science;artificial intelligence;data mining	NLP	-62.67549057797073	58.178442440217104	139245
f27442920572feb69777490710a900a0be64a66c	secured action authorization for industrial mobile robots		The increased deployment of mobile robots in industry poses higher risks for safety issues and damage of production material caused by abnormal robot behavior. Abnormal behavior can be caused by issues such as operational errors or security weaknesses. Security weaknesses entail attacks that might cause serious harm for humans and production material. One possibility to mitigate such attacks is action authorization. In this paper, we propose an authorization mechanism for actuator actions on mobile robots to prevent adversaries from executing false commands on a robot. The mechanism uses a ticketing system and relies on sensor data as well as plausibility checks. The tickets are issued to specific actuators to authorize the requested action. The sensor data adds to the understanding of the current context and the plausibility checks are used to check that specific actions are allowed to be performed in a given order. Security is further supported by secure elements that protect confidential data from being revealed.	algorithm;authorization;computation;confidentiality;correctness (computer science);cryptography;issue tracking system;machine learning;malware;mobile robot;overhead (computing);plausibility structure;sanity check;sensor;software deployment	Sarah Haas;Thomas Ulz;Christian Steger	2018	2018 IEEE Industrial Cyber-Physical Systems (ICPS)	10.1109/ICPHYS.2018.8390810	control engineering;software deployment;computer security;authorization;behavior-based robotics;robot;mobile robot;engineering;robot kinematics;server	Robotics	-56.2863233397133	51.09298273431306	139670
91e6c53806ebec716660f37088e4341479f38c54	an abstract reduction model for computer security risk	algebraic specification;risk analysis;risk management;computer network;computer security;rewrite systems;normal form	This paper presents an approach for decision making under security risks in a computer network environment. The proposed method relies on a many sorted algebraic signature and on a rewriting system. This latter is shown to be terminating and yielding a normal form, called the risk analysis equation, that models the cost-benefit balance. Furthermore, a gradual algebraic resolution of the risk analysis equation is described. This formalism helps security analysts to automate the selection of the optimal security solutions that minimize the residual risk.	a-normal form;abstract interpretation;beta normal form;computer security;confluence;it risk management;international federation for information processing;linear algebra;rewriting;selection algorithm;semantics (computer science)	Mohamed Hamdi;Noureddine Boudriga	2004		10.1007/1-4020-8143-X_1	computer security model;risk analysis;risk management;computer science;theoretical computer science;computer security	Security	-51.82050942031596	48.92031093164382	139772
815e8021f79a460c9e5d25f4aecdb2942412c01c	tiriac: a trust-driven risk-aware access control framework for grid environments	trust;insider attack;risk;access control;obligations;behavior uncertainty	The infrastructure provided by a Grid enables researchers to collaboratively solve various research problems through sharing their resources and establishing virtual organizations (VOs). However, the distributed and dynamic nature of a Grid VO is a challenge for access control systems. All users in a VO have responsibilities which correspond to their rights. While they should be able to make use of all VO resources, irresponsibility and permission misuse (insider attack) impose costs and losses on the affected resources. Hence, the history of users’ behavior and the possibility of misuse need to be considered in the resource providers’ risk management process. In this paper, we propose the TIRIAC framework for Grid access control. TIRIAC is the first trust-driven risk-aware access control framework which uses obligations to seamlessly monitor users andmitigate risks. In the TIRIAC framework, trust evaluation and risk management are added to the base Grid access control services. Thereafter, site administrators can explicitly specify users’ responsibilities in form of obligations alongside access control rules. In addition, obligation-specific policies can be specified to mitigate risks according to their severity. We study the adoption of our framework by the European Grid Infrastructure (EGI), and demonstrate its superiority in comparison with the related work using multiple criteria. Moreover, we evaluate the performance of the framework and demonstrate its scalability in simulation experiments. © 2015 Elsevier B.V. All rights reserved.	access control;control system;egi;experiment;grid computing;risk management;scalability;simulation;virtual organization (grid computing)	Sadegh Dorri Nogoorani;Rasool Jalili	2016	Future Generation Comp. Syst.	10.1016/j.future.2015.03.003	computer science;knowledge management;access control;risk;database;distributed computing;trustworthy computing;computer security	Security	-48.43835260968691	53.039001899877306	139799
1b2ba83014ea9fea801c30411776ccd898bad152	a logical specification and analysis for selinux mls policy	multi level security;policy analysis;policy compliance;selinux	The SELinux mandatory access control (MAC) policy has recently added a multi-level security (MLS) model which is able to express a fine granularity of control over a subject's access rights. The problem is that the richness of this policy makes it impractical to verify, by hand, that a given policy has certain important information flow properties or is compliant with another policy. To address this, we have modeled the SELinux MLS policy using a logical specification and implemented that specification in the Prolog language. Furthermore, we have developed some analyses for testing the properties of a given policy as well an algorithm to determine whether one policy is compliant with another. We have implemented these analyses in Prolog and compiled our implementation into a tool for SELinux MLS policy analysis, called PALMS. Using PALMS, we verified some important properties of the SELinux MLS reference policy, namely that it satisfies the simple security condition and *-property defined by Bell and LaPadula [2].	algorithm;bell–lapadula model;compiler;mandatory access control;multilevel security;prolog;selinux	Boniface Hicks;Sandra Julieta Rueda;Luke St. Clair;Trent Jaeger;Patrick D. McDaniel	2007		10.1145/1266840.1266854	computer science;policy analysis;database;computer security;algorithm	Security	-52.05403546813574	51.293480909084174	139879
d67fabdd7e65c2551c2c86f201a67c7f7a143373	comparative analysis of mobile app reverse engineering methods on dalvik and art		The runtime system for the Android platform has changed to ART. ART differs from previously used Dalvik in that it is to be a runtime environment for the application’s machine code. As a result, ART does not execute Dalvik bytecode through an interpreter but executes the machine code itself, leading to high performance and many other benefits. This change in runtime system also has many implications for mobile security. While we can anticipate with certainty the resurgence of modified malicious activity or malicious applications previously used with Dalvik or the emergence of completely new structures of malicious techniques, we can no longer ascertain the feasibility of the analysis techniques and analysis tools used against these malicious applications that operated in Dalvik. To combat future potential malicious techniques for ART, we must first have a clear understanding of ART and, with this foundation, to effectively and accurately utilize the correct analysis technique. Thus, this paper serves to introduce an analysis on the operating method and architecture of ART and, based on this information, address the executable feasibility of the analysis techniques in ART. Furthermore, we present the test results of running these analysis tools and techniques in ART.	android;dynamic program analysis;emergence;emulator;executable;independence day: resurgence;interpreter (computing);machine code;malware;mobile app;mobile security;reverse engineering;runtime system;smoothing;static program analysis	Geonbae Na;Jongsu Lim;Kyoungmin Kim;Jeong Hyun Yi	2016	J. Internet Serv. Inf. Secur.		computer engineering;database;computer science;reverse engineering	Security	-56.818530855083914	53.84918322491268	139936
4dc4bc988c1f419ed697c881ef5f5043d88c8076	sql-injection security evolution analysis in php	authorization level;authorization data security information security application software lab on a chip runtime pattern analysis computer security relational databases flow graphs;user needs;web sites authorisation configuration management flowcharting internet relational databases software prototyping sql;sql injection security vulnerability evolution analysis;software prototyping;authorisation;sql;publicly available bulletin board;vulnerability analysis;flowcharting;relational database;control flow graph;internet;sql injection;inter procedural control flow graph;web sites;php;web software evolution;software package;sql injection attack;relational databases;relational database access;configuration management;software package sql injection security vulnerability evolution analysis php web sites relational database access web software evolution authorization level inter procedural control flow graph sql injection attack publicly available bulletin board	Web sites are often a mixture of static sites and programs that integrate relational databases as a back-end. Software that implements Web sites continuously evolve to meet ever-changing user needs. As a Web sites evolve, new versions of programs, interactions and functionalities are added and existing ones are removed or modified. Web sites require configuration and programming attention to assure security, confidentiality, and trustiness of the published information. During evolution of Web software, from one version to the next one, security flaws may be introduced, corrected, or ignored. This paper presents an investigation of the evolution of security vulnerabilities as detected by propagating and combining granted authorization levels along an inter-procedural control flow graph (CFG) together with required security levels for DB accesses with respect to SQL-injection attacks. The paper reports results about experiments performed on 31 versions of phpBB, that is a publicly available bulletin board written in PHP, version 1.0.0 (9547 LOC) to version 2.0.22 (40663 LOC) have been considered as a case study. Results show that the vulnerability analysis can be used to observe and monitor the evolution of security vulnerabilities in subsequent versions of the same software package. Suggestions for further research are also presented.	authorization;confidentiality;control flow graph;evolution;experiment;interaction;php;relational database;sql injection;source lines of code;trust (emotion);vulnerability (computing)	Ettore Merlo;Dominic Letarte;Giuliano Antoniol	2007	2007 9th IEEE International Workshop on Web Site Evolution	10.1109/WSE.2007.4380243	web application security;security through obscurity;sql injection;relational database;computer science;operating system;data mining;database;programming language;world wide web	SE	-57.26827520196424	56.55022172561274	140267
0bb7a7939ba6f20014c66cd7597673f842cc9945	xdomain: cross-border proofs of access	trust management;access control policy;logic based access control;distributed authorization;access control	A number of research systems have demonstrated the benefits of accompanying each request with a machine-checkable proof that the request complies with access-control policy - a technique called proof-carrying authorization. Numerous authorization logics have been proposed as vehicles by which these proofs can be expressed and checked. A challenge in building such systems is how to allow delegation between institutions that use different authorization logics. Instead of trying to develop the authorization logic that all institutions should use, we propose a framework for interfacing different, mutually incompatible authorization logics. Our framework provides a very small set of primitives that defines an interface for communication between different logics without imposing any fundamental constraints on their design or nature. We illustrate by example that a variety of different logics can communicate over this interface, and show formally that supporting the interface does not impinge on the integrity of each individual logic. We also describe an architecture for constructing authorization proofs that contain components from different logics and report on the performance of a prototype proof checker.	authorization;automated proof checking;prototype	Lujo Bauer;Limin Jia;Michael K. Reiter;David Swasey	2009		10.1145/1542207.1542216	computer science;access control;database;distributed computing;computer security	Security	-51.32203376149814	50.852252215088306	140300
ebe5276c3d1c7d7f363e33847ac707b4e473a9f4	n-version obfuscation	tamper resistance;software security;obfuscation;reverse engineering	Although existing for decades, software tampering attack is still a main threat to systems, such as Android, and cyber physical systems. Many approaches have been proposed to thwart specific procedures of tampering, e.g., obfuscation and self-checksumming. However, none of them can achieve theoretically tamper-proof without the protection of hardware circuit. Rather than proposing new tricks against tampering attacks, we focus on impeding the replication of software tampering via program diversification, and thus pose a scalability barrier against the attacks. Our idea, namely N-version obfuscation (NVO), is to automatically generate and deliver same featured, but functionally nonequivalent software copies to different machines or users.  In this paper, we investigate such an idea on Android platform. We carefully design a candidate NVO solution for networked apps, which leverages a Message Authentication Code (MAC) mechanism to generate the functionally nonequivalent diversities. Our evaluation result shows that the time required for breaking such a software system increases linearly with respect to the number of software versions. In this way, attackers would suffer great scalability issues, considering that an app can have millions of users. With minimal NVO costs, effective tamper-resistant security can therefore be established.	android;anti-tamper software;diversification (finance);electronic circuit;message authentication code;national virtual observatory;scalability;software system;software versioning;tamper resistance	Hui Xu;Yangfan Zhou;Michael R. Lyu	2016		10.1145/2899015.2899026	engineering;internet privacy;world wide web;computer security	Security	-55.29201309674681	56.90428248296588	140332
fede6057fd5550a325565517c8588e63ddd34e0e	aspect-oriented specification of threat-driven security requirements	developpement logiciel;threats;behavioral analysis;securite;aspect oriented software development;analyse fonctionnelle;punto ejecucion;orientado aspecto;concern separation;functional analysis;estudio caso;desarrollo logicial;security requirements;separation preoccupation;analyse comportementale;security threats;software development;safety;etude cas;separacion preocupacion;mitigation;analisis conductual;aspect oriented;point execution;functional requirement;seguridad;use case;oriente aspect;threat mitigation;pointcut;analisis funcional	This paper presents an aspect-oriented approach to integrated specification of functional and security requirements based on use-case-driven software development. It relies on explicit identification of security threats and threat mitigations. We first identify security threats with respect to use-case-based functional requirements in terms of security goals and the STRIDE category. Then, we suggest threat mitigations for preventing or reducing security threats. To capture the crosscutting nature of threats and mitigations, we specify them as aspects that encapsulate pointcuts and advice. This provides a structured way for separating functional and security concerns and for analysing the interaction between them.	aspect-oriented software development;category theory;functional requirement;misuse case;pointcut;requirements analysis;software requirements specification;threat model	Dianxiang Xu;Vivek Goel;Kendall E. Nygard;W. Eric Wong	2008	IJCAT	10.1504/IJCAT.2008.017725	software security assurance;computer security model;functional analysis;use case;reliability engineering;countermeasure;simulation;security through obscurity;aspect-oriented programming;security information and event management;security engineering;asset;computer science;engineering;software development;security service;security testing;computer security;functional requirement	Security	-53.71114570251906	47.217281172815305	140490
0a39db1dcacba04ef83c4c2ddeee3542ebbe1c02	managing access rights for terminated employees	adaptive security;access lists.;password;access control	A recurring security scenario involves the problem of removing the access rights of an employee upon employee termination. A solution is presented in the form of procedures and an infrastructure. Operationally, sensors track security-related user operations (e.g. password use and object accesses) to determine the true access rights associated with a user. Security administrators combine that information with recorded access controls and invoke actuators to perform actions necessary to remove the complete access rights of a user.	access control;password;sensor	Dennis Heimbigner	2004			computer science;computer security;computer network;access control	Security	-50.48226677907642	53.76656898755129	140646
8e5b8584edba67a08e7c094b2b7bb0db2ccbb9fc	mtags: augmenting microkernel messages with lightweight metadata	mandatory security;master thesis;interaction verification;tag;information flow;clouds;dependability;research projects;europe	In this work we propose mTags, an efficient mechanism that augments microkernel interprocess messages with lightweight metadata to enable the development of new, system-wide functionality without requiring modification of the application source code. As such it is well suited for systems with a large legacy code base or third-party applications like phone and tablet applications.  We explored mTags in a variety of different contexts in local and distributed system scenarios. For example, we detail use cases in areas including messaging-induced deadlocks and mode propagation. To demonstrate that mTags is technically feasible and practical, we implemented it in a commercial microkernel and executed multiple sets of standard benchmarks on two different computing architectures. The results clearly demonstrate that mTags has only negligible overhead and strong potential for many applications.	deadlock;distributed computing;legacy code;microkernel;overhead (computing);software propagation;tablet computer	Augusto Born de Oliveira;Ahmad Saif Ur Rehman;Sebastian Fischmeister	2012	Operating Systems Review	10.1145/2331576.2331587	real-time computing;information flow;computer science;operating system;dependability;distributed computing;programming language;computer security	OS	-52.650383377310476	56.404933270119415	140758
5f6adc73a5842c4c8bdaae789288a11105e4a4d9	finding your way in the testing jungle: a learning approach to web security testing	online learning;cross site scripting;vulnerability scanner	Black-box security testing of web applications is a hard problem. The main complication lies in the black-box assumption: The testing tool has limited insight into the workings of server-side defenses. This has traditionally led commercial as well as research vulnerability scanners toward heuristic approaches, such as testing each input point (e.g. HTTP parameter) with a short, predefined list of effective test payloads to balance between coverage and performance.   We take a fresh approach to the problem of security testing, casting it into a learning setting. In our approach, the testing algorithm has available a comprehensive database of test payloads, such that if the web application's defenses are broken, then with near certainty one of the candidate payloads is able to demonstrate the vulnerability. The question then becomes how to efficiently search through the payload space to find a good candidate. In our solution, the learning algorithm infers from a failed test---by analyzing the website's response---which other payloads are also likely to fail, thereby pruning substantial portions of the search space.   We have realized our approach in XSS Analyzer, an industry-level cross-site scripting (XSS) scanner featuring 500,000,000 test payloads. Our evaluation on 15,552 benchmarks shows solid results: XSS Analyzer achieves >99% coverage relative to brute-force traversal over all payloads, while trying only 10 payloads on average per input point. XSS Analyzer also outperforms several competing algorithms, including a mature commercial algorithm---featured in IBM Security AppScan Standard V8.5---by a far margin. XSS Analyzer has recently been integrated into the latest version of AppScan (V8.6) instead of that algorithm.	algorithm;black box;canonical account;confidentiality;cross-site scripting;database;heuristic;hypertext transfer protocol;information leakage;internet security;packet analyzer;sql injection;security appscan;security testing;server-side;spectral leakage;test automation;tree traversal;web application;web framework;web testing	Omer Tripp;Omri Weisman;Lotem Guy	2013		10.1145/2483760.2483776	cross-site scripting;simulation;computer science;engineering;world wide web;computer security	Security	-58.302667663015896	57.546373982325115	141062
944c44d0c818db6564c97b0f638018404b5cd5f1	a privacy-aware semantic model for provenance management		The history of data has a crucial importance almost in every scientific application. In order to trust the correctness of data, the ability to determine the origin of data becomes an important issue. Provenance information summarizes the origin of items, the history of the ownership of items and the actions performed on them. Ensuring that data is kept safe from corruption or illegal accesses and detecting privacy breaches on data should be achieved by integrating provenance concepts with security concepts. Information such as an individuals infectious disease history is highly sensitive and should not be revealed to an unauthorized user. This historical data needs privacy. We propose a privacy-aware provenance management model by creating policies and querying provenance data to detect policy violations. We illustrate our proposed model by integrating it with infectious disease and vaccination domains.	access control;authorization;correctness (computer science);ontology (information science);privacy;sensor;traceability	Özgü Can;Dilek Yilmazer	2014		10.1007/978-3-319-13674-5_16	database;internet privacy;world wide web	DB	-51.292835600716856	52.98283310610144	141192
a83a1b4a66cb4abc5e65453e2664a68917a4bcaa	prefetch side-channel attacks: bypassing smap and kernel aslr	timing attacks;aslr;kernel vulnerabilities	Modern operating systems use hardware support to protect against control-flow hijacking attacks such as code-injection attacks. Typically, write access to executable pages is prevented and kernel mode execution is restricted to kernel code pages only. However, current CPUs provide no protection against code-reuse attacks like ROP. ASLR is used to prevent these attacks by making all addresses unpredictable for an attacker. Hence, the kernel security relies fundamentally on preventing access to address information. We introduce Prefetch Side-Channel Attacks, a new class of generic attacks exploiting major weaknesses in prefetch instructions. This allows unprivileged attackers to obtain address information and thus compromise the entire system by defeating SMAP, SMEP, and kernel ASLR. Prefetch can fetch inaccessible privileged memory into various caches on Intel x86. It also leaks the translation-level for virtual addresses on both Intel x86 and ARMv8-A. We build three attacks exploiting these properties. Our first attack retrieves an exact image of the full paging hierarchy of a process, defeating both user space and kernel space ASLR. Our second attack resolves virtual to physical addresses to bypass SMAP on 64-bit Linux systems, enabling ret2dir attacks. We demonstrate this from unprivileged user programs on Linux and inside Amazon EC2 virtual machines. Finally, we demonstrate how to defeat kernel ASLR on Windows 10, enabling ROP attacks on kernel and driver binary code. We propose a new form of strong kernel isolation to protect commodity systems incuring an overhead of only 0.06-5.09%.	address space layout randomization;amazon elastic compute cloud (ec2);binary code;central processing unit;code injection;code page;code reuse;control flow;discrete logarithm;executable;file system permissions;kernel (operating system);linux;microsoft windows;modern operating systems;operating system;overhead (computing);paging;prefetch input queue;privilege (computing);protection ring;return-oriented programming;user space;virtual machine;windows 10;x86	Daniel Gruss;Clémentine Maurice;Anders Fogh;Moritz Lipp;Stefan Mangard	2016		10.1145/2976749.2978356	real-time computing;timing attack;computer science;operating system;computer security	Security	-55.13247695765955	56.90320854532187	141201
2fcd8159fff2ca312726670418e5f5def1eee249	spandex: secure password tracking for android		This paper presents SpanDex, a set of extensions to Android’s Dalvik virtual machine that ensures apps do not leak users’ passwords. The primary technical challenge addressed by SpanDex is precise, sound, and efficient handling of implicit information flows (e.g., information transferred by a program’s control flow). SpanDex handles implicit flows by borrowing techniques from symbolic execution to precisely quantify the amount of information a process’ control flow reveals about a secret. To apply these techniques at runtime without sacrificing performance, SpanDex runs untrusted code in a data-flow sensitive sandbox, which limits the mix of operations that an app can perform on sensitive data. Experiments with a SpanDex prototype using 50 popular Android apps and an analysis of a large list of leaked passwords predicts that for 90% of users, an attacker would need over 80 login attempts to guess their password. Today the same attacker would need only one attempt for all users.	android;control flow;dataflow;ibm notes;login;password;prototype;run time (program lifecycle phase);sandbox (computer security);symbolic execution;uc browser;virtual machine	Landon P. Cox;Peter Gilbert;Geoffrey Lawler;Valentin Pistol;Ali Razeen;Bi Wu;Sai Cheemalapati	2014			computer science;operating system;internet privacy;world wide web;computer security	Security	-55.703207812646475	57.954510036086894	141383
3f7aa864754ece749d2efc51f4ff5a70c6e24d7d	assessing the security properties of software obfuscation	software;computer crime;software engineering;computer security;security of data reverse engineering;validity properties;cryptography;computer security cryptography computer crime validation software engineering;reverse engineering security properties software obfuscation;validation;cybersecurity;obfuscation;security;cybersecurity security obfuscation validity properties cryptography software	The battle between software obfuscation and reverse engineering has been ongoing for decades. Yet the degree of security that obfuscation actually guarantees remains unclear. Obfuscation's security properties and challenges to achieving a valid security property are evaluated.	obfuscation (software);reverse engineering	Hui Xu;Michael R. Lyu	2016	IEEE Security & Privacy	10.1109/MSP.2016.112	software security assurance;computer security model;security through obscurity;obfuscation;security engineering;security bug;computer science;cryptography;information security;internet privacy;security analysis;security testing;world wide web;computer security	Security	-58.807103020129205	56.409696865545655	141491
20b9240e4a79ef117e1267dfb16ea78593908487	monitoring personal data transfers in the cloud	databases;data transfer databases monitoring program processors process control servers data privacy;auditing cloud computing security accountability compliance data tracking;auditing;personal data transfer monitoring openstack open source iaas implementation personal data handling data processors cloud infrastructure services cloud platform cloud software data localization data controllers cloud service consumers eu data protection directive data storage data processing cloud computing;data communication;public domain software cloud computing data communication data protection;public domain software;servers;monitoring;data privacy;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;process control;compliance;data tracking;data protection;security;accountability;program processors;data transfer;cloud computing	Cloud computing brings a number of compliance risks to organisations because physical perimeters are not clearly delimited. Many regulations relate to the location of the data processing (and storage), including the EU Data protection directive. A major problem for cloud service consumers, acting as data controllers, is how to demonstrate compliance to data transfer constraints. We address the lack of tools to support accountable data localization and transfer across cloud software, platform and infrastructure services, usually run by data processors. In this paper we design a framework for automating the collection of evidence that obligations with respect to personal data handling are being carried out in what concerns personal data transfers. We experiment our approach in the Open Stack open source IaaS implementation, showing how auditors can verify whether data transfers were compliant.	business rules engine;central processing unit;cloud computing;data protection directive;delimiter;directive (programming);open-source software;personally identifiable information;platform as a service;software as a service	Anderson Santana de Oliveira;Jakub Sendor;Alexandr Garaga;Kateline Jenatton	2013	2013 IEEE 5th International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2013.52	cloud computing;tracking system;computer science;information security;operating system;process control;database;data protection act 1998;audit;public domain software;world wide web;computer security;server	DB	-49.994536075235295	57.2189328613031	141615
3ca5880e4fe23ec2ee8025ff6c121ebb5348c6fc	detecting privileged side-channel attacks in shielded execution with déjà vu	transactional synchronization extensions;software guard extension;side channel detection	Intel Software Guard Extension (SGX) protects the confidentiality and integrity of an unprivileged program running inside a secure enclave from a privileged attacker who has full control of the entire operating system (OS). Program execution inside this enclave is therefore referred to as shielded. Unfortunately, shielded execution does not protect programs from side-channel attacks by a privileged attacker. For instance, it has been shown that by changing page table entries of memory pages used by shielded execution, a malicious OS kernel could observe memory page accesses from the execution and hence infer a wide range of sensitive information about it. In fact, this page-fault side channel is only an instance of a category of side-channel attacks, here called privileged side-channel attacks, in which privileged attackers frequently preempt the shielded execution to obtain fine-grained side-channel observations. In this paper, we present Deja Vu, a software framework that enables a shielded execution to detect such privileged side-channel attacks. Specifically, we build into shielded execution the ability to check program execution time at the granularity of paths in its control-flow graph. To provide a trustworthy source of time measurement, Deja Vu implements a novel software reference clock that is protected by Intel Transactional Synchronization Extensions (TSX), a hardware implementation of transactional memory. Evaluations show that Deja Vu effectively detects side-channel attacks against shielded execution and against the reference clock itself.	confidentiality;control flow graph;déjà vu;information sensitivity;intel developer zone;linux;operating system;page fault;page table;paging;run time (program lifecycle phase);sensor;side-channel attack;software framework;transactional synchronization extensions;transactional memory	Sanchuan Chen;Xiaokuan Zhang;Michael K. Reiter;Yinqian Zhang	2017		10.1145/3052973.3053007	real-time computing;computer science;operating system;computer security	Security	-55.2032601827323	55.56599158110808	141648
c0215b7271f370dfc368a14fedf2a7e1aadcdc79	self-protecting multi-cloud applications	virtual machining;security of data cloud computing data integrity data protection;probes;security monitoring cloud computing probes adaptation models virtual machining privacy;monitoring;software as a service self protecting multicloud applications cloud services security breaches data integrity user privacy multicloud application lifecycle security security assurance mechanisms advanced monitoring musa security assurance platform;adaptation models;security;privacy;cloud computing	The rise and variety of cloud services and their growing availability has enabled the creation of multi-cloud applications that take advantage of cloud service combinations. These applications need to avoid security breaches and preserve data integrity and user privacy in the whole service composition. The MUSA framework arises as a global solution to support the security of the whole multi-cloud application lifecycle by providing advanced monitoring and security assurance mechanisms in multi-cloud environments. The MUSA security assurance platform will be offered as Software as a Service and will include monitoring, enforcement, and notification services to make the multi-cloud applications more secure than ever, ensuring the satisfaction of all the involved actors.	cloud computing;component-based software engineering;confidentiality;data access;data integrity;information privacy;information security;operation time;secure by design;security controls;service composability principle;service-level agreement;software as a service	Antonio M. Ortiz;Erkuden Rios;Wissam Mallouli;Eider Iturbe;Edgardo Montes de Oca	2015	2015 IEEE Conference on Communications and Network Security (CNS)	10.1109/CNS.2015.7346880	software security assurance;computer security model;cloud computing security;security through obscurity;security information and event management;cloud computing;asset;computer science;threat;information security;human-computer interaction in information security;security service;data security;internet privacy;security analysis;security testing;privacy;world wide web;computer security;computer network	DB	-48.61078085348135	56.761560371427	141818
b9ccbfe233d03d78b68022b724543c0466c0f85f	checkmate: automated synthesis of hardware exploits and security litmus tests		"""Recent research has uncovered a broad class of security vulnerabilities in which confidential data is leaked through programmer-observable microarchitectural state. In this paper, we present CheckMate, a rigorous approach and automated tool for determining if a microarchitecture is susceptible to specified classes of security exploits, and for synthesizing proof-of-concept exploit code when it is. Our approach adopts """"microarchitecturally happens-before"""" (µhb) graphs which prior work designed to capture the subtle orderings and interleavings of hardware execution events when programs run on a microarchitecture. CheckMate extends µhb graphs to facilitate modeling of security exploit scenarios and hardware execution patterns indicative of classes of exploits. Furthermore, it leverages relational model finding techniques to enable automated exploit program synthesis from microarchitecture and exploit pattern specifications. As a case study, we use CheckMate to evaluate the susceptibility of a speculative out-of-order processor to Flush+Reload cache side-channel attacks. The automatically synthesized results are programs representative of Meltdown and Spectre attacks. We then evaluate the same processor on its susceptibility to a different timing side-channel attack: Prime+Probe. Here, CheckMate synthesized new exploits that are similar to Meltdown and Spectre in that they leverage speculative execution, but unique in that they exploit distinct microarchitectural behaviors—speculative cache line invalidations rather than speculative cache pollution—to form a side-channel. Most importantly, our results validate the CheckMate approach to formal hardware security verification and the ability of the CheckMate tool to detect real-world vulnerabilities."""		Caroline Trippel;Daniel Lustig;Margaret Martonosi	2018	2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)	10.1109/MICRO.2018.00081	computer hardware;hardware security module;real-time computing;speculative execution;cache;computer science;cpu cache;exploit;side channel attack;microarchitecture;checkmate	Arch	-55.262450080421885	54.69573124595185	141898
e2ca3287fcae72ed7413b7c0cd684f8fcca93455	exploiting dynamic scheduling for vm-based code obfuscation	virtualization;uncertainty;virtual machining;runtime;dynamic scheduling;instruction sets	Code virtualization built upon virtual machine (VM) technologies is emerging as a viable method for implementing code obfuscation to protect programs against unauthorized analysis. State-of-the-art VM-based protection approaches use a fixed scheduling structure where the program follows a single, static execution path for the same input. Such approaches, however, are vulnerable to certain scenarios where the attacker can reuse knowledge extracted from previously seen software to crack applications using similar protection schemes. This paper presents DSVMP, a novel VM-based code obfuscation approach for software protection. DSVMP brings together two techniques to provide stronger code protection than prior VM-based schemes. Firstly, it uses a dynamic instruction scheduler to randomly direct the program to execute different paths without violating the correctness across different runs. By randomly choosing the program execution paths, the application exposes diverse behavior, making it much more difficult for an attacker to reuse the knowledge collected from previous runs or similar applications to perform attacks. Secondly, it employs multiple VMs to further obfuscate the relationship between VM bytecode and their interpreters, making code analysis even harder. We have implemented DSVMP in a prototype system and evaluated it using a set of widely used applications. Experimental results show that DSVMP provides stronger protection with comparable runtime overhead and code size when compared to two commercial VM-based code obfuscation tools.	authorization;copy protection;correctness (computer science);obfuscation (software);overhead (computing);prototype;randomness;scheduling (computing);static program analysis;virtual machine	Kaiyuan Kuang;Zhanyong Tang;Xiaoqing Gong;Dingyi Fang;Xiaojiang Chen;Tianzhang Xing;Guixin Ye;Jie Zhang;Zheng Wang	2016	2016 IEEE Trustcom/BigDataSE/ISPA	10.1109/TrustCom.2016.0101	parallel computing;real-time computing;computer science;distributed computing	Security	-55.86015416244898	56.47880212750087	141978
efcf01be655d60f110f2cf50bfeb79c818e3f5c3	a security types preserving compiler in haskell		The analysis of information flow has become a popular technique for ensuring the confidentiality of data. An end-to-end confidentiality policy guarantees that private data cannot be inferred by the inspection of public data. A security property that ensures a kind of confidentiality is the noninterference property, which can be enforced by the use of security type systems where types correspond to security levels. In this paper we show the development of a compiler (written in Haskell) between a simple imperative language and semi-structured machine code, which preserves the property of noninterference. The compiler is based on the use of typed abstract syntax (implemented in terms of Haskell GADTs and type-level functions) to encode the security type system of both the source and target language. This makes it possible to use Haskell’s type checker to verify two things: that programs in both languages satisfy the security property, and that the compiler is correct by construction (in the sense that it preserves noninterference).	compiler;haskell	Cecilia Manzino;Alberto Pardo	2014		10.1007/978-3-319-11863-5_2	parallel computing;compiler correctness;computer science;compiler construction;database;bootstrapping;programming language;functional compiler	PL	-54.52495287936184	53.82960243754027	142009
5b8e1411adfd2939045f8bff76a0267372107997	a framework for secure information flow analysis in web applications	security databases arrays computer science servers aggregates browsers;secure information flow;security of data data integrity graph theory internet;database annotation web applications security secure information flow program dependence graph;web applications security;annotation tasks secure information flow analysis web applications personal information integrity policies confidentiality policies security background security by construction minimal developer effort web application code extended program dependence graph epdg generic security enforcement rules insecure information flows php web applications;database annotation;program dependence graph	Huge amounts of data and personal information are being sent to and retrieved from web applications on daily basis. Every application has its own confidentiality and integrity policies. Violating these policies can have broad negative impact on the involved company's financial status, while enforcing them is very hard even for the developers with good security background. In this paper, we propose a framework that enforces security-by-construction in web applications. Minimal developer effort is required, in a sense that the developer only needs to annotate database attributes by a security class. The web application code is then converted into an intermediary representation, called Extended Program Dependence Graph (EPDG). Using the EPDG, the provided annotations are propagated to the application code and run against generic security enforcement rules that were carefully designed to detect insecure information flows as early as they occur. As a result, any violation in the data's confidentiality or integrity policies is reported. As a proof of concept, two PHP web applications, Hotel Reservation and Auction, were used for testing and validation. The proposed system was able to catch all the existing insecure information flows at their source. Moreover and to highlight the simplicity of the suggested approaches vs. Existing approaches, two professional web developers assessed the annotation tasks needed in the presented case studies and provided a very positive feedback on the simplicity of the annotation task.	confidentiality;information flow;php;personally identifiable information;positive feedback;program dependence graph;web application;web developer;world wide web	Ralph Adaimy;Wassim El-Hajj;Ghassen Ben Brahim;Hazem M. Hajj;Haïdar Safa	2015	2015 IEEE 29th International Conference on Advanced Information Networking and Applications	10.1109/AINA.2015.218	web application security;web development;web modeling;computer science;operating system;information security standards;database;security service;world wide web;computer security;computer network	SE	-56.71130047033804	58.67974037796894	142181
ba7e595ead8197226bda4785df77342323018fbe	visualization of atm usage patterns to detect counterfeit cards usage	macquarie university institutional repository;automatic teller machine;digital forensics;researchonline;digital forensics cybercrime visualization;digital repository;macquarie university;inference mechanisms;computer crime;data visualisation;data visualization asynchronous transfer mode humans reconnaissance visualization cameras monitoring;visualization;monitoring;visualization technique;data visualization;abductive reasoning;humans;digital assets atm usage pattern visualization counterfeit card usage detection automatic teller machines fund withdrawal cybercriminal element card cloning card skimming abductive reasoning capabilities visualization rule set refinement cash out phase illegal operation;reconnaissance;automatic teller machines;cameras;asynchronous transfer mode;cybercrime;inference mechanisms automatic teller machines computer crime data visualisation	People relish the flexibility of being able access their monetary assets when and where they need them. The abundance of cards able to withdraw funds from Automatic Teller Machines (ATMs) has not gone unnoticed by the cyber criminal element. Means for skimming and cloning cards exist and the market continues to grow. While the methods for obtaining access to another's funds vary greatly, there are cases in which visualization of a class of card-present fraud can combine the visualization with the powerful abductive reasoning capabilities of the human mind to help identify the threat. As part of a defense-in-depth strategy, this can contribute to the evolution and refinement of rule sets that facilitate the detection of the crime prior to the cash-out phase of the illegal operation. This paper discusses card-present fraud and provides an example of how visualization techniques, coupled with human abductive reasoning, can be used to guide the evolution of analytical tools to help protect our digital assets.	atm turbo;abductive reasoning;cybercrime;digital asset;general protection fault;mind;refinement (computing)	Ben Reardon;Kara Nance;Stephen McCombie	2012	2012 45th Hawaii International Conference on System Sciences	10.1109/HICSS.2012.638	visualization;abductive reasoning;computer science;artificial intelligence;marketing;operating system;software engineering;asynchronous transfer mode;data mining;database;management;world wide web;computer security;data visualization;statistics	Visualization	-59.32125891184582	58.11956942529903	142182
97121243efb44ef329717091ca985bca3081bd59	a multi-layer secure prevention scheme for improving e-commerce security	security of data electronic commerce;e commerce;maintenance engineering;testing;event detection;security requirement;computer hacking;mlsps e commerce security requirement event detection security event;security event;personal data security risk multilayer secure prevention scheme e commerce security electronic commerce business transaction behavior network intrusion system security vulnerability virus attack malicious users security requirement security testing security event detection procedure mlsps scheme data recording technology event detection technology;testing event detection maintenance engineering organizations computer hacking;organizations;mlsps	In the information and network age, e-commerce is an important system for business transaction behavior. However, the network intrusion, malicious users, virus attack and system security vulnerabilities have continued to threaten the operation of the e-commerce, making e-commerce security encounter serious test. How to improve e-commerce security has become a topic worthy of further exploration. Combining security requirement, routine security testing and security event detection procedure, this paper proposes the Multi-Layer Secure Prevention Scheme (MLSPS). First layer of MLSPS is the well-defined security requirement. Second layer of MLSPS is the routine security testing procedure. Third layer of MLSPS is the security event detection procedure. Applying data recording and event detection technologies timely discovers the abnormal security event. MLSPS can enhance the e-commerce security and effectively reduce e-commerce personal data security risk.	computer security;data security;e-commerce;e-commerce payment system;intrusion detection system;personally identifiable information;security testing;software bug;vulnerability (computing);whole earth 'lectronic link	Sen-Tarng Lai;Fang-Yie Leu;William C. Chu	2014	2014 Eighth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2014.73	software security assurance;information security audit;computer security model;maintenance engineering;cloud computing security;countermeasure;security through obscurity;security information and event management;security engineering;security convergence;covert channel;asset;security bug;computer science;organization;information security;security service;software testing;data security;internet privacy;security analysis;security testing;network security policy;world wide web;computer security	Security	-59.075577416334426	59.54638414745978	142351
bfa21a66bdfd4b959b159979efebec2999aa699e	identification of bot commands by run-time execution monitoring	protocols;common api calls;run time execution monitoring;user level hooking bot command identification run time execution monitoring internet common api calls;bot command identification;intrusion detection;data mining;servers;runtime protocols application software protection telecommunication traffic internet computer security computerized monitoring laboratories computer science;internet;engines;monitoring;malware;success rate;invasive software;correlation;botnet;botnet intrusion detection malware;user level hooking;timing	Botnets pose serious threats to the Internet. In spite of substantial efforts to address the issue, botnets are dramatically spreading. Bots in a botnet execute commands under the control of the botnet owner or controller. A first step in protecting against botnets is identification of their presence, and activities. In this paper, we propose a method of identifying the high-level commands executed by bots. The method uses run- time monitoring of bot execution to capture and analyze run- time call behavior. We find that bots have distinct behavior patterns when they perform pre-programmed bot commands. The patterns are characterized by sequences of common API calls at regular intervals. We demonstrate that commands aiming to achieve the same result have very similar API call behavior in bot variants, even when they are from different bot families. We implemented and evaluated a prototype of our method. Run-time monitoring is accomplished by user-level hooking. In the experiments, the proposed method successfully identified the bot commands being executed with a success rate of 97%. The ability of the method to identify bot commands despite the use of execution obfuscation is also addressed.	application programming interface;botnet;computation;control flow;experiment;high- and low-level;hooking;internet;network packet;network traffic control;private network;prototype;system call;tracing (software);user space;video game bot	Younghee Park;Douglas S. Reeves	2009	2009 Annual Computer Security Applications Conference	10.1109/ACSAC.2009.37	intrusion detection system;communications protocol;real-time computing;the internet;bot herder;computer science;operating system;malware;botnet;world wide web;computer security;correlation;server	Security	-58.404828583417064	59.74952210561809	142751
39311b44541a68d7351cb893bc88949a1bb6812a	automatic vulnerability detection for weakness visualization and advisory creation	vulnerability detection;network security;vulnerability analysis;security analytics;attack graph	The detection of vulnerabilities in computer systems and computer networks as well as the representation of the results are crucial problems. The presented method tackles the problem with an automated detection and an intuitive representation. For detecting vulnerabilities the approach uses a logical representation of preconditions and postconditions of vulnerabilities. Thus an automated analytical function could detect security leaks on a target system. The gathered information is used to provide security advisories and enhanced diagnostics for the system. Additionally the conditional structure allows us to create attack graphs to visualize the network structure and the integrated vulnerability information. Finally we propose methods to resolve the identified weaknesses whether to remove or update vulnerable applications and secure the target system. This advisories are created automatically and provide possible solutions for the security risks.	complex systems;conditional (computer programming);data model;human-readable medium;postcondition;precondition;sensor;vulnerability (computing)	Marian Gawron;Aragats Amirkhanyan;Feng Cheng;Christoph Meinel	2015		10.1145/2799979.2799986	vulnerability management;security information and event management;vulnerability;asset;computer science;network security;vulnerability assessment;data mining;internet privacy;computer security	Security	-61.97677857115046	60.35306908754258	142794
119e6209d85dde560d6081551a51f45b121bea7c	research on proof-carrying code for untrusted-code security	kernel;host system;programming language;fast proof validator;safe behavior;filters;software systems;internal data structures;formal semantics;system performance;power method;theorem proving;assembly;intrinsic behavior;theorem proving safety critical software security of data computational linguistics type theory programming theory;programming theory;logic programming;safety critical software;type theory;proof carrying code;safety rules;safety;mobile code;performance gain;computational linguistics;pcc;formal safety proof;safety logic programming operating systems kernel power system security software systems system performance performance gain filters assembly;foreign code;foreign code proof carrying code untrusted code security software systems interaction mobile code intrinsic behavior untrusted programs host system internal data structures system performance safety rules formal semantics type theory programming language theory pcc safe behavior formal safety proof fast proof validator;data structure;untrusted code security;security of data;power system security;programming language theory;operating systems;untrusted programs;software systems interaction	A powerful method of interaction between two software systems is through mobile code. By allowing code to be installed dynamically and then executed, a host system can provide a flexible means of access to its internal resources and services. There are many problems to be solved before such uses of untrusted code can become practical. For this position paper, we will focus on the problem of how to establish guarantees about the intrinsic behavior of untrusted programs. Of particular interest are the following: (1) How can the host system ensure that the untrusted code will not damage it, for example, by corrupting internal data structures? (2) How can the host ensure that the untrusted code will not use too many resources (such as CPU, memory, and so forth) or use them for too long a time period?; and, (3) How can the host make these assurances without undue effort and deleterious effect on overall system performance? Our position is that the theory of programming languages, including formal semantics, type theory, and applications of logic, are critical to solving the untrusted-code security problem. To illustrate the possibilities of programming language theory, we will briefly describe one rather extreme but promising example, which is proof-carrying code (PCC).	central processing unit;code mobility;data structure;portable c compiler;programming language theory;proof-carrying code;semantics (computer science);software system;type theory	George C. Necula;Peter Lee	1997		10.1109/SECPRI.1997.601335	kernel;data structure;power iteration;code access security;computer science;theoretical computer science;computational linguistics;operating system;formal semantics;sandbox;assembly;distributed computing;automated theorem proving;locally testable code;programming language theory;programming language;logic programming;computer security;type theory;software system	PL	-53.8934598263181	52.64465167921161	142819
f8908006b0c5cd6546881d2b4a68d97fdbe3defd	a theoretical q-learning temporary security repair	software architecture machine learning q learning security repair;q learning;extended parameter testing theoretical q learning temporary security repair software security temporary repair mechanism data analysis security diagnostic;software architecture;machine learning;software connectors security maintenance engineering detectors software architecture abstracts;software architecture data analysis learning artificial intelligence security of data;security;repair	This research summarizes the first attempt to incorporate Q-learning algorithm in software security. The Q-learning method is embedded as part of the software itself to provide a security mechanism that has ability to learn by itself to develop a temporary repair mechanism. The results of the experiment express that given the right parameters and the right setting the Q-learning approach rapidly learns to block all malicious actions. Data analysis on the Q-values produced by the software can provide security diagnostic as well. A larger scale experiment with extended parameter testing is expected to be seen in the future work.	algorithm;application security;embedded system;q-learning	Arisoa S. Randrianasolo;Larry D. Pyeatt	2014	2014 IEEE Symposium on Computational Intelligence in Cyber Security (CICS)	10.1109/CICYBS.2014.7013370	software security assurance;computer security model;reliability engineering;verification and validation;security information and event management;security engineering;systems engineering;engineering;backporting;software reliability testing;software development;logical security;software construction;software testing;security testing;resource-oriented architecture;computer security;enterprise information security architecture	Security	-57.18679296292021	47.521333678910324	143000
c3edbee5940641cc0eb4af363acd160951490a2d	defending return-oriented programming based on virtualization techniques	hypervisor based security;hardware assisted virtualization;return oriented programming	ABSTRACT#R##N##R##N#Over the past few years, return-oriented programming (ROP) has drawn great attention of both academia and industry. Because of its Turing completeness, ROP reuses short instruction sequences already present in the victim program's address space to perform arbitrary computation. Hence, it can successfully bypass state-of-the-art code integrity check mechanisms. In this paper, we look into using virtualization technologies to defeat return-oriented programming. We design and implement HyperCropII, a virtualization-based automatic runtime approach to defend such attacks. ROP attackers extract short instruction sequences ending in ret called “gadgets” and craft stack content to “chain” these gadgets together. We observe that a key characteristic of ROP is to fill the stack with plenty of addresses that are within the range of the program's libraries. Accordingly, we inspect the content of the stack to see if a potential ROP attack exists and quarantine the damages for further security purposes. We have implemented a proof-of-concept system based on the open source Xen hypervisor. The evaluation results exhibit that our solution is effective and efficient. Copyright © 2013 John Wiley & Sons, Ltd.		Xiaoqi Jia;Rui Wang;Jun Jiang;Shengzhi Zhang;Peng Liu	2013	Security and Communication Networks	10.1002/sec.693	real-time computing;computer science;operating system;computer security	Crypto	-57.36297691016179	56.16929861887187	143012
9f08d770b0ca07f5db8145e26c8b10a868967e36	data-delineation in software binaries and its application to buffer-overrun discovery	libraries;data delineation analysis software security codesonar x86 defect detection tool static analysis memory safety violation detection buffer overrun discovery software binary dda;registers layout benchmark testing approximation methods libraries accuracy optimization;layout;accuracy;buffer overrun detection;registers;binary analysis;mobile advertisements;software tools program diagnostics security of data;optimization;approximation methods;buffer overrun detection reverse engineering data delineation binary analysis static analysis;static analysis;data delineation;mobile devices;benchmark testing;reverse engineering	Detecting memory-safety violations in binaries is complicated by the lack of knowledge of the intended data layout, i.e., the locations and sizes of objects. We present lightweight, static, heuristic analyses for recovering the intended layout of data in a stripped binary. Comparison against DWARF debugging information shows high precision and recall rates for inferring source-level object boundaries. On a collection of benchmarks, our analysis eliminates a third to a half of incorrect object boundaries identified by an IDA Pro-inspired heuristic, while retaining nearly all valid object boundaries.  In addition to measuring their accuracy directly, we evaluate the effect of using the recovered data for improving the precision of static buffer-overrun detection in the defect-detection tool CodeSonar/x86. We demonstrate that CodeSonar's false-positive rate drops by about 80% across our internal evaluation suite for the tool, while our approximation of CodeSonar's recall only degrades about 25%.	approximation;benchmark (computing);binary file;buffer overflow;dwarf;debugging;heuristic;interactive disassembler;memory safety;precision and recall;software bug;stripped binary;x86	Denis Gopan;Evan Driscoll;Ducson Nguyen;Dimitri Naydich;Alexey Loginov;David Melski	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering	10.1109/ICSE.2015.36	layout;benchmark;real-time computing;computer science;operating system;data mining;mobile device;database;accuracy and precision;processor register;static analysis;reverse engineering	SE	-57.16207631381271	57.09044021472446	143020
ac09aeb36eef82732dbf3aad859944ae33cbf27f	context-aware deep learning-driven framework for mitigation of security risks in byod-enabled environments		The proliferation of smart phones and ubiquitous Internet access enable the emergence of BYOD (Bring Your Own Device) as an effective policy to increase efficiency and productivity in the workplace. The adoption of BYOD, however, gives rise to a number of security threats, including sensitive information infiltration and exfiltration, DoS attacks and privacy violation. This work proposes a framework to address precisely this issue. The main focus of the paper is on exploring the viability of BYOD in supporting collaboration among team members, in a heterogeneous mobile computing environments. The basic tenet of this work is to leverage artificial neural networks (ANN) and decision tree (DT) machine learning (ML) techniques to identify any attempts for access to sensitive information by nonlegitimate users and to facilitate the framework to baffle their access, in order to protect the data. The goal becomes even more challenging, incorporating the demands for low latency and high accuracy of the framework. The main contributions of the include the formulation of the BYOD unauthorized access control problem, a framework that uses ANN and DT ML techniques to detect anomalous behaviors and to identify unauthorized access to resources on BYOD devices. The proposed security techniques are implemented and evaluated, using a real dataset.	access control;artificial neural network;authorization;bring your own device;decision tree;deep learning;emergence;information sensitivity;internet access;intranet;machine learning;mobile computing;smartphone	Daniel Petrov;Taieb Znati	2018	2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)	10.1109/CIC.2018.00032	internet access;artificial intelligence;computer security;computer science;access control;computer vision;information sensitivity;bring your own device;latency (engineering);decision tree;mobile computing;denial-of-service attack	DB	-50.00697127732656	59.86162809665319	143121
ff84fa4564e9040fa3a66bddf34cff9443c1d1a5	static analysis of the disassembly against malicious code obfuscated with conditional jumps	unsafe executable detection;program diagnostics;conditional jump;malicious codes;information science;application software;information technology;program control structures;disassembly conditional jump obfuscation malicious codes;computer applications;computer networks;program diagnostics invasive software program control structures;malicious code;disassembly;computer security;data analysis;reverse analysis;conditional jump obfuscation;pattern matching;code obfuscation;invasive software;obfuscation;unsafe executable detection static program analysis malicious code computer security conditional jump obfuscation disassembly algorithm reverse analysis;static analysis;information analysis;application software computer security information technology pattern matching data analysis computer applications military computing computer networks information science information analysis;static program analysis;disassembly algorithm;military computing	With the application of information technology and network, malicious codes have become a main threat to the computer security. In order to avoid being analyzed statically, malicious codes resort to various obfuscation techniques to hide themselves. Conditional jumps obfuscation is just such a kind of technique. In this paper, we introduce four forms of conditional jumps obfuscation which could confuse both of the two commonly used disassembly algorithms. Their basic idea is that two elaborate constructed conditional jump instructions are semantically equivalent to one unconditional jump. We propose a modified algorithm to crack the obfuscation. And we implement our idea in our reverse analysis tool Radux (Reverse Analysis for Detecting Unsafe eXecutables). Last we compare the disassembly output of Radux with objdump and IDApro. Relevant tests show that our implementation is effective.	algorithm;branch (computer science);code;computer security;disassembler;obfuscation (software);objdump;static program analysis	Chao Dai;Jianmin Pang;Rongcai Zhao;Xiaojun Ma	2008	Seventh IEEE/ACIS International Conference on Computer and Information Science (icis 2008)	10.1109/ICIS.2008.18	computer science;theoretical computer science;distributed computing;computer security	Security	-59.18056658407393	54.95469359565003	143151
1c78c321237e2a612b2baaed8bdaa29cc3eae2a7	measuring name system health		Modern critical infrastructure assets are exposed to security threats arising from their use of IP networks and the Domain Name System (DNS). This paper focuses on the health of DNS. Indeed, due to the increased reliance on the Internet, the degradation of DNS could have significant consequences for the critical infrastructure. This paper describes the Measuring Naming System (MeNSa), a framework designed to provide a formal methodology, metrics and tools for evaluating DNS health. Additionally, it proposes a process for aggregating health and security metrics to provide potential threat indicators. Results from a scenario-based experiment demonstrate the utility of the framework and aggregation metrics.	critical infrastructure protection;elegant degradation;internet protocol suite;requirement	Emiliano Casalicchio;Marco Caselli;Alessio Coletta;Salvatore Di Blasi;Igor Nai Fovino	2012		10.1007/978-3-642-35764-0_12	engineering;environmental resource management;data mining;computer security	Security	-57.52302245590011	49.92969709471378	143185
7abfc9b9a22f787a9487a1b14935720a87896fbb	damn: a debugging and manipulation tool for android applications	debugging;code analysis;android;reverse engineering	Mobile developers tend to use source code obfuscation to protect their code against reverse engineering. Unfortunately, some developers rely on the idea that obfuscated applications also provide additional security. But that is not the case since mistakes in design are still present and can be used for arbitrary attacks. However, manually analyzing such obfuscated applications is time consuming for researchers due to the complexity of the generated code.  Our debugging and manipulation tool (DAMN) offers a new way of investigating Android applications, including obfuscated ones. It combines static source code reversing with dynamic manipulation techniques to get rid of obfuscation penalties and supports the investigator during the analyzing process. DAMN can display the reversed source code, pause any application at any given time and allows to manipulate its state. All those features make DAMN a powerful reversing and analyzing tool for manual investigations of obfuscated Android applications.	android;debugging;obfuscation (software);reversing: secrets of reverse engineering	Gerald Schoiber;René Mayrhofer;Michael Hölzl	2016		10.1145/3007120.3007161	obfuscation;real-time computing;computer science;operating system;debugging;world wide web;computer security;reverse engineering;android	SE	-57.15151574887035	57.38057243537916	143625
25bf25d6b8a01ed0118a2057bf57a58edf887ff4	measured responses to cyber attacks using schmitt analysis: a case study of attack scenarios for a software-intensive system	scada cyber attacks schmitt analysis attack scenarios software intensive system coercive actions kinetic attacks safety critical system quantitative aspects qualitative aspects control systems subway systems legal algorithm dcs;internet safety critical software computer crime;computer crime;use of force;internet;international law;safety critical software;computer aided software engineering terrorism law control systems legal factors algorithm design and analysis kinetic theory weapons embedded software software safety;kinetics	In this paper we address the development of measured responses to coercive actions. We demonstrate, via a case study of kinetic and cyber attacks on a safety-critical software-intensive system, the application of the Schmitt Analysis to the question of whether the attacks have risen to the level of a “use of force” under international law, taking into account both the quantitative and qualitative aspects of the attacks.	schmitt trigger	James Bret Michael;Thomas C. Wingfield;Duminda Wijesekera	2003		10.1109/CMPSAC.2003.1245406	international law;the internet;simulation;engineering;forensic engineering;law;computer security;kinetics	NLP	-57.27930127433866	49.01135346895598	143673
b2e84e6b065d001047b833cdfcd13b2f5706fa78	detecting cross-site scripting vulnerability using concolic testing	vulnerability detection;web application testing;authorisation;system monitoring;computer crime;cross site scripting web application testing concolic testing vulnerability detection web program analysis;system monitoring authorisation computer crime internet java program testing software tools;concolic testing;internet;web program analysis;program testing;cross site scripting vulnerability detection nontrivial jsp web applications malicious string inputs conditional copy xss attack detection techniques vulnerabilities exploitation application code input output dependencies test cases concolic testing tools language translation xss vulnerabilities detection two phase technique user system resources unauthorized access information stealing malicious script web based attack;software tools;monitoring runtime testing java html instruments browsers;cross site scripting;java	Cross-Site Scripting (XSS) attack is a type of Web-based attack wherein a malicious script is executed (from an immediate injection or from a stored source) to steal information or gain unauthorized access to user/system resources. We propose a two-phase technique to detect XSS vulnerabilities and prevent XSS attacks. In the first phase, we translate the Web application to a language for which recently developed concolic testing tools are available. Our translation also identifies input and output variables that are used to generate test cases for determining input/output dependencies in the application. Dependencies indicate vulnerabilities in the application that can be potentially exploited when the application is deployed. In the second phase, based on the input/output dependencies determined in the first phase, we appropriately (automatically) instrument the application code by including monitors. The monitors check exploitation of vulnerabilities at runtime. In addition to being both as efficient and effective as the available XSS attack detection techniques, our two-phase method is also capable of identifying XSS vulnerabilities that occur due to (a) conditional copy (of inputs to outputs) and (b) construction of malicious string inputs from the concatenation of singularly benign inputs. We present a prototype implementation of our framework and demonstrate its effectiveness using non-trivial JSP Web applications.	authorization;concatenation;concolic testing;cross-site scripting;emoticon;input/output;javaserver pages;machine translation;monitor (synchronization);norm (social);prototype;run time (program lifecycle phase);sensor;test case;two-phase commit protocol;two-phase locking;unit testing;web application	Michelle Ruse;Samik Basu	2013	2013 10th International Conference on Information Technology: New Generations	10.1109/ITNG.2013.97	cross-site scripting;system monitoring;the internet;computer science;operating system;database;authorization;programming language;java;world wide web;computer security;concolic testing;web testing	Security	-56.96763880350579	58.174235828705626	144038
ee4039186db0ba85e447d5b8bb3af5bd4d425522	situational awareness based risk-adapatable access control in enterprise networks		As the computing landscape evolves towards distributed architectures such as Internet of Things (IoT), enterprises are moving away from traditional perimeter based security models toward so called “zero trust networking” (ZTN) models that treat both the intranet and Internet as equally untrustworthy. Such security models incorporate risk arising from dynamic and situational factors, such as device location and security risk level risk, into the access control decision. Researchers have developed a number of risk models such as RAdAC (Risk Adaptable Access Control) to handle dynamic contexts and these have been applied to medical and other scenarios. In this position paper we describe our ongoing work to apply RAdAC to ZTN. We develop a policy management framework, FURZE, to facilitate fuzzy risk evaluation that also defines how to adapt to dynamically changing contexts. We also consider how enterprise security situational awareness (SSA) which describes the potential impact to an organisations mission based on the current threats and the relative importance of the information asset under threat can be incorporated into a RAdAC	access control;big data;cloud computing;criticality matrix;financial risk modeling;internet of things;intranet;perimeter;scott continuity;software-defined networking	Brian Lee;Roman Vanickis;Franklin Rogelio;Paul Jacob	2017		10.5220/0006363404000405	knowledge management;computer security;computer network	Security	-50.798377662347015	49.33197765633788	144317
2be52e5a011d956ff082218881a9bb878965d3d6	cloud security architecture and implementation - a practical approach		While cloud computing provides lower Infrastructure cost, higher agility and faster delivery, it also presents higher operational and security risks for business critical assets, but a well-designed solution and security architecture will keep businesses safe during and after migrating their assets to the cloud. This paper has researched and identified best security practices and how to improve a security architecture in a cloud environment.	cloud computing security;computer security	Max Farnga	2018	CoRR		enterprise information security architecture;computer security;architecture;cloud computing;computer science;cloud computing security	Arch	-49.43190591713139	57.504604525122346	144561
a55250bad8e06d8ee241ebd749f728855f2e7319	validation of it-security measurement tools	automatic control;measurement tool;availability;size measurement;scientific validation;inspection;formal verification security of data;protection;it security measurement tools;it security;formal verification;area measurement;area measurement inspection privacy protection availability security automatic control scalability size measurement;scalability;scientific validation it security measurement tools;security;security of data;privacy	Different norms demand the measurment of IT-security. But how the measurement should be carried out, is not part of the norms. To compare the results of the different methods and tools with each other, it is necessary to validate the measuring tools. The scientific validation of measuring tools in the area of IT-security raises many questions that have not been discussed not to mention answered.		Ruedi Baer;Martin Dietrich	2006	First International Conference on Availability, Reliability and Security (ARES'06)	10.1109/ARES.2006.142	reliability engineering;computer science;data mining;computer security	HPC	-57.09708637994062	48.2055081607557	144565
ef060244f1df41688ea6ea4ee68326c986a155e8	insecure by design: using human interface devices to exploit scada systems		Modern Supervisory Control and Data Acquisition (SCADA) systems which are used by the electric utility industry to monitor and control electric power generation, transmission and distribution, are recognized today as critical components of the electric power delivery infrastructure. SCADA systems are large, complex and incorporate increasingly large numbers of widely distributed components. Cyber-attacks usually target valuable infrastructures assets, taking advantage of architectural/technical vulnerabilities or even weaknesses in the defense systems. Even though novel intrusion detection systems are being implemented and used for defending cyber-attacks certain vulnerabilities of SCADA systems can still be exploited. In this article we present an attack scenario based on a Human Interface Device (HID) device which is used as a means of communication/exploitation tool to compromise SCADA systems. The attack, which is a normal series of commands that are sent from the HID to the PLC cannot be detected through current intrusion detection mechanisms.	application programming interface;authorization;data acquisition;download;human interface device;intrusion detection system;network packet;programming tool;usb;workstation	Grigoris Tzokatziou;Leandros A. Maglaras;Helge Janicke	2015			embedded system;real-time computing;engineering;computer security;scada	Security	-53.07513974963082	59.79526769802891	144934
dc7de9249763461150e85058b0901d9faf9a6171	security in innovative new operating systems	security properties;kernel;spin project innovative new operating systems security performance enhancement exokernel project fluke project fox project scout project;innovative new operating systems;testing;spin project;mechanical factors;exokernel project;computerized monitoring;protection;operating system;scout project;authorization;computer science;performance enhancement;fox project;switches;security of data operating systems computers;security;operating systems protection switches kernel context aware services computer science computerized monitoring mechanical factors testing authorization;article;fluke project;security of data;operating systems computers;operating systems;context aware services	The Reference Monitor Concept [l] is an abstraction describing properties that must be satisfied by a mechanism enforcing a policy regulating access to information. Those properties are: tamperproof, always invoked, and small enough to be subjected to analysis and testing, the completeness of which can be a.ssured. It is realized by the creation of a reference validation mechanism which uses an authorization database to validate access by users, or their surrogates, viz. processes, to information in the form of data. Traditional approaches to constructing reference validation mechanisms have combined hardware and software mechanisms to create protection domains [8]. The reference validation mechanism must create a domain for its own execution that satisfies both the requirements for tamperproofness and non-bypassability. Otherwise, the mechanism is not conceptually conplete. It 1s impossible to demonstrate that a mechanism is tamperproof if it can be bypassed and the underlying resources upon which it depends can be manipulated. Similarly, a mechanism ca.nnot he called non-bypassable, if it is subject to tampering which might permit detours around the validation checks. In traditional operating systems, whether or not they contain a reference validat,ion mechanism, enca.psulation of privileged mechanisms is costly. Context switches between the external domain and that containing the operating system or reference validation mechanism are required. The result is a performance penalty.		Cynthia E. Irvine	1997		10.1109/SECPRI.1997.601334	embedded system;embedded operating system;kernel;simulation;network switch;computer science;information security;operating system;software testing;authorization;computer security	Arch	-51.96092731518399	53.783066699305664	144968
164a7c8521c0e2734ebda97a5b7eecc202e03795	a library for removing cache-based attacks in concurrent information flow systems	publikationer;konferensbidrag;artiklar;rapporter	Information-flow control (IFC) is a security mechanism conceived to allow untrusted code to manipulate sensitive data without compromising confidentiality. Unfortunately, untrusted code might exploit some covert channels in order to reveal information. In this paper, we focus on the LIO concurrent IFC system. By leveraging the effects of hardware caches (e.g., the CPU cache), LIO is susceptible to attacks that leak information through the internal timing covert channel. We present a resumption-based approach to address such attacks. Resumptions provide fine-grained control over the interleaving of thread computations at the library level. Specifically, we remove cache-based attacks by enforcing that every thread yield after executing an “instruction,” i.e., atomic action. Importantly, our library allows for porting the full LIO library— our resumption approach handles local state and exceptions, both features present in LIO. To amend for performance degradations due to the library-level thread scheduling, we provides two novel primitives. First, we supply a primitive for securely executing pure code in parallel. Second, we provide developers a primitive for controlling the granularity of “instructions”; this allows developers to adjust the frequency of context switching to suit application demands.	cpu cache;central processing unit;clock rate;computation;concurrency (computer science);confidentiality;context switch;covert channel;forward error correction;haskell;information flow;linearizability;local variable;network switch;non-interference (security);programmer;scheduling (computing);thread (computing)	Pablo Buiras;Amit A. Levy;Deian Stefan;Alejandro Russo;David Mazières	2013		10.1007/978-3-319-05119-2_12	parallel computing;real-time computing;computer science;programming language;computer security	OS	-54.92311243554592	54.81459212038374	145071
14e3762622d4ab6b3241da32b71fee78ace52b69	editorial: trust and security must become a primary design concern in embedded computing		As I write this editorial, a lot has been happening around us. Apple’s secure enclave processor firmware has been decrypted; face recognition–based secure identification of iPhone X has been hacked, with relatively inexpensive masks, apparently; the Uber data breach compromised the privacy of 57 million people; the Equifax breach compromised even a larger number of people; and new Android Trojan malware were discovered in the Google Play store. These are but a few examples that have been published in the media. A lot more is happening and being suppressed. News reports suggest that Uber might have paid hackers to suppress a data breach. Other reports indicate that even an Indian telecom provider might have paid hackers for similar reasons. In India, a cloud of suspicion over electronic voting machines, popularly known as EVMs, have gathered after a few reports surfaced on all votes automatically going to a specific party. Even today, reports of that sort of compromise are coming in, as there is a hotly contested regional election taking place in India today. While the Election Commission of India has denied any such possibilities, they have not been forthcoming in offering experts to open these EVM machines and probe the hardware, firmware, and possible attack surfaces, leaving a section of politicians and the public suspicious. Given that Twitter bots and social media bots have been unleashed by the millions to sway public opinions, creating and propagating fake news and challenging the normal democratic processes, it is a scary new world that we are faced with today. Continually extending our digital footprint and moving all political, business, financial, social, and transactional activities to the digital world in search of efficiency, are we not exposing ourselves to an unknown future? Why are these relevant to embedded computing? This is a journal of embedded computing, and in my editorial comments, I always seem to be obsessed with cyber security over all other challenges germane to embedded computing. Is it intentional to attract more submissions in the embedded security domain? My answer is that, subconsciously, possibly, but there is a good logical reason for this fear and concern. Furthermore, most devices that we find vulnerable, the same devices that affect our lives and society, are embedded computing devices—be it mobile phones, voting machines, automotives, avionic controls, Internet of Things (IoT)-based automation, sensors and control systems in utilities, or medical devices such as pacemakers or insulin pumps. While a large-scale data breach usually concerns IT systems, even there we saw a tangled web of cyber physical sensor network security affecting IT security. Take, for example, the Target data breach. The network for HVAC system monitoring was breached and became the conduit to propagate malware to point-of-sales machines, which led to the stealing of credit card information while being swiped for authorization. Compounding these vulnerabilities and mounting threats, insider threats are also increasing through social engineering and other human-centric processes. A high-privilege system administrator might compromise individuals unless the system is designed to be robust against insider attacks. We have evolved our IT systems with the assumption of trusted central authority, or a trusted third party, and only became aware of the large percentage of internal attack incidents in major breaches.	android;artificial cardiac pacemaker;authorization;computer security;control system;data breach;digital footprint;evms;embedded system;facial recognition system;firmware;insider threat;internet of things;malware;mobile phone;network security;play store;point of sale;sensor;social engineering (security);social media;system administrator;system monitoring;the sims;transaction processing;trojan horse (computing);trusted operating system;trusted third party	Sandeep K. Shukla	2018	ACM Trans. Embedded Comput. Syst.	10.1145/3173385	real-time computing;computer engineering;computer science	Security	-52.67889000293115	59.83106912345851	145268
f653803ad757dd3a1a34857354eb7e79e3e35da6	identifying false data injection attacks in industrial control systems using artificial neural networks		Cyber-attacks on Industrial Control Systems (ICS) are growing in recent years. Existing IT-security technologies are not sufficient enough to protect the ICS from the novel attacks. Among several attack types on industrial networks, False Data Injection Attacks (FDIA) are considered as an important class of cyber-attacks against ICS. FDIA injects forged measurement into the control system in hope of misguiding the control algorithm. This abnormal behavior of a single control device or a sensor value in a plant can lead to a huge loss to the company or a disaster in plant environment. Hence, a prior identification of these injected attacks is very important. In this paper, we give an overview about different possible cyber-attacks on ICS followed by the importance and challenges in identifying FDIA w.r.t other attack types. A simulated ICS use case is developed to generate the sensor and actuator signals. An attack injection tool is developed and used to simulate the attacks on to the ICS network. The generated data with injected attacks is used to train and test the performance of the Artificial Neural Networks (ANN) for identifying FDIA. The evaluation of performance parameters shows promising detection accuracies.	algorithm;artificial neural network;backpropagation;control system;deep learning;network architecture;neural networks;sensor;simulation;software propagation;supercomputer;supervised learning;test set	Sasanka Potluri;Christian Diedrich;Girish Kumar Reddy Sangala	2017	2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2017.8247663	actuator;control engineering;real-time computing;engineering;industrial control system;artificial neural network;control system;attack model	Robotics	-57.427301505816075	52.19326868017931	145666
4b6a46ba0fb4c3e9381b8796c48a3c2c28816ce4	poster: bgpcoin: a trustworthy blockchain-based resource management solution for bgp security		Origin authentication is one of the most concentrated and advocated BGP security approach against IP prefix hijacking. However, the potential risk of centralized authority abuse and the fragile infrastructure may lead a sluggish deployment of such BGP security approach currently. We propose BGPCoin, a trustworthy blockchain-based Internet resource management solution which provides compliant resource allocations and revocations, and a reliable origin advertisement source. By means of a smart contract to perform and supervise resource assignments on the tamper-resistant Ethereum blockchain, BGPCoin yields significant benefits in the secure origin advertisement and the dependable infrastructure for object repository compared with RPKI. We demonstrate through an Ethereum prototype implementation that the deployment incentives and increased security are technically and economically viable.	authentication;bitcoin;border gateway protocol;centralized computing;design by contract;ethereum;experiment;prototype;resource public key infrastructure;scalability;smart contract;software deployment;tamper resistance;trustworthy computing	Qianqian Xing;Baosheng Wang;Xiaofeng Wang	2017		10.1145/3133956.3138828	ip hijacking;software deployment;resource management;the internet;computer security;internet privacy;computer network;smart contract;computer science;resource allocation;incentive;authentication	Security	-50.16342794106685	59.26611595140522	145895
c3e242a7662bfd2ba78027db5f1e5efaad86c1e8	insights on formal methods in cybersecurity	nist;frequency modulation;formal methods;software engineering;computer security;cybersecurity formal methods;computational modeling;formal methods cybertrust security cybersecurity;security of data formal verification;cybertrust;cybersecurity;security;frequency modulation software engineering computer security computational modeling nist	Seven experts weigh in on the current use and practice of formal methods in cybersecurity.	computer security;formal methods	Jeffrey M. Voas;Kim Schaffer	2016	Computer	10.1109/MC.2016.131	computer security model;frequency modulation;formal methods;nist;computer science;information security;software engineering;computational model;computer security	Logic	-56.628506117959155	48.36992854981037	145963
91800c3554505daa2edaaae2f71068e1759df7b2	using smart for customized monitoring of windows services	user interface;network security;operating system;situation awareness;remote monitoring;intrusion detection system	We focus on examining and working with an important category of computer software called Services, which are provided as a part of newer Microsoft Windows operating systems. A typical Windows user transparently utilizes many of these services but is frequently unaware of their existence. Since some services have the potential to create significant problems when they are executing, it is important for a system administrator to identify which services are running on the network, the types of processing done by each service, and any interrelationships among the various services. This information can then be used to improve the overall integrity of both the individual computer where a questionable service is running and in aggregate an entire network of computers. NCSA has developed an application called SMART (Services Monitoring And Reporting Tool) that can be used to identify and display all services currently running in the network. A commercial program called Hyena remotely monitors the services on all computers attached to the network and exports this information to SMART. SMART produces various outputs that the system administrator can analyze and then determine appropriate actions to take. In particular, SMART provides a color coordinated user interface to quickly identify and classify both potentially hazardous services and also unknown services.	aggregate data;browsing;computer;graphical user interface;microsoft windows;national center for supercomputing applications;operating system;smart;security management;system administrator	Gregory Pluta;Larry Brumbaugh;William Yurcik	2006	CoRR		intrusion detection system;embedded system;situation awareness;telecommunications;computer science;network security;operating system;security and safety features new to windows vista;services computing;user interface;world wide web;computer security;computer network;rmon	OS	-62.76346877681574	57.68452384151793	146043
073cb438f8570fb8c9f93bc79889b2b1aa9a8029	attacking the bitlocker boot process	trusted computing	We discuss five attack strategies against BitLocker, which target the way BitLocker is using the TPM sealing mechanism. BitLocker is a disk encryption feature included in some versions of Microsoft Windows. It represents a state-of-the-art design, enhanced with TPM support for improved security. We show that, under certain assumptions, a dedicated attacker can circumvent the protection and break confidentiality with limited effort. Our attacks neither exploit vulnerabilities in the encryption itself nor do they directly attack the TPM. They rather exploit sequences of actions that Trusted Computing fails to prevent, demonstrating limitations of the technology.	bitlocker;confidentiality;disk encryption;microsoft windows;record sealing;trusted computing;trusted platform module	Sven Türpe;Andreas Poller;Jan Steffan;Jan-Peter Stotz;Jan Trukenmüller	2009		10.1007/978-3-642-00587-9_12	computer science;internet privacy;trustworthy computing;world wide web;computer security	Security	-54.28833045358827	59.48995126687647	146196
dfc451f504738adfe41f735095055b1ff75859a7	guest editors' introduction: security and trust in embedded-systems design	trust;security properties;software measurement;information security;security design;secure computation;multimedia systems;embedded system;computer networks;process design;embedded systems;cryptographic algorithm;design technique;embedded system design;design and implementation;cryptography;design security trust embedded systems;design;functional requirement;security;information leakage;embedded computing;communication system security;hardware;hardware cryptography embedded system information security embedded computing software measurement multimedia systems computer networks communication system security process design	Security and trust have become important considerations in the design of virtually all modern embedded systems. The requirements of secure and trusted design are unique: Secure design emphasizes information leakage (or prevention thereof) and dependable behavior. Even strong cryptographic algorithms are of little use if the underlying processor can be tricked into releasing cryptographic keys. This leads to unique design techniques such as design and implementation of boundaries for logical and physical protection, design of protected storage and secure-computing primitives, runtime measurement and reporting of security properties, and implementation of side-channel-resistant hardware and software. Eventually, the embedded-system designer must cope with security as yet another requirement in addition to existing functional requirements, performance, power, and cost. This special issue presents six articles that address various critical aspects of secure embedded-systems design.	algorithm;cryptography;dependability;embedded system;functional requirement;information leakage;key (cryptography);side-channel attack;spectral leakage;systems design;yet another	Patrick Schaumont;Anand Raghunathan	2007	IEEE Design & Test of Computers	10.1109/MDT.2007.188	process design;embedded system;design;computer science;cryptography;information security;distributed computing;software measurement;computer security;functional requirement;computer engineering	Security	-51.79079706254292	59.658049509532546	146204
49870c237d6fe4c6c5d7808420364e21fb6ff208	on quantitative security policies	potential enforcement;execution monitor;quantitative security policy;actual enforcement compute;policy violation;unsafe execution;security violation;enforcement mechanism;formal framework;execution speed	We introduce a formal framework to specify and enforce quantitative security policies. The framework consists of: (i) a stochastic process calculus to express the measurable space of computations in terms of Continuous Time Markov Chains; (ii) a stochastic modal logic (a variant of CSL) to represent the bound constraints on execution speed; (iii) two enforcement mechanisms of our quantitative security policies: potential or actual. The potential enforcement computes the probability of policy violations, thus providing a sort of static evaluation of the policy. This supports the user to accept/discard a component when the probability of the security violation is below/above a suitable chosen threshold. The actual enforcement computes the deviation of the execution speed from the acceptable rate. This supports the run-time systems by driving the execution monitor to abort unsafe executions.	computation;markov chain;modal logic;process calculus;stochastic process;type enforcement	Pierpaolo Degano;Gian Luigi Ferrari;Gianluca Mezzetti	2011		10.1007/978-3-642-23178-0_3	parallel computing;real-time computing;computer science;operating system;distributed computing;computer security;algorithm	Logic	-53.89222618182701	52.01131345848162	146313
713d4073d7228a2f2ba4d3ec4d145e8e6ee4f761	defending against malicious peripherals with cinch		Malicious peripherals designed to attack their host computers are a growing problem. Inexpensive and powerful peripherals that attach to plug-and-play buses have made such attacks easy to mount. Making matters worse, commodity operating systems lack coherent defenses, and users are often unaware of the scope of the problem. We present Cinch, a pragmatic response to this threat. Cinch uses virtualization to attach peripheral devices to a logically separate, untrusted machine, and includes an interposition layer between the untrusted machine and the protected one. This layer regulates interaction with devices according to user-configured policies. Cinch integrates with existing OSes, enforces policies that thwart real-world attacks, and has low overhead.	coherence (physics);computer;malware;operating system;overhead (computing);peripheral;plug and play	Sebastian Angel;Riad S. Wahby;Max Howald;Joshua B. Leners;Michael Spilo;Zhen Sun;Andrew J. Blumberg;Michael Walfish	2016			embedded system;operating system;computer security	Security	-53.959941237240244	56.85721121414198	146615
0287d44233ea8a16bc02bf59de9729ccfb0bb157	novel analytical modelling-based simulation of worm propagation in unstructured peer-to-peer networks	thesis or dissertation;computer networks security measures;peer to peer architecture computer networks;agent based model;seir model;computer crimes prevention;peer to peer;analytical model		agent-based model;analytical engine;gnutella;holism;peer-to-peer file sharing;performance evaluation;programming paradigm;simulation;software propagation	Hani Sayyaf Alharbi	2017			simulation;computer science;world wide web;computer security	EDA	-61.99595703498049	60.14988042819012	146620
b15e942e526e4a03ecd0af31cbdf9b43bf81a829	deemon: detecting csrf with dynamic analysis and property graphs		Cross-Site Request Forgery (CSRF) vulnerabilities are a severe class of web vulnerabilities that have received only marginal attention from the research and security testing communities. While much effort has been spent on countermeasures and detection of XSS and SQLi, to date, the detection of CSRF vulnerabilities is still performed predominantly manually.  In this paper, we present Deemon, to the best of our knowledge the first automated security testing framework to discover CSRF vulnerabilities. Our approach is based on a new modeling paradigm which captures multiple aspects of web applications, including execution traces, data flows, and architecture tiers in a unified, comprehensive property graph. We present the paradigm and show how a concrete model can be built automatically using dynamic traces.Then, using graph traversals, we mine for potentially vulnerable operations. Using the information captured in the model, our approach then automatically creates and conducts security tests, to practically validate the found CSRF issues. We evaluate the effectiveness of Deemon with 10 popular open source web applications. Our experiments uncovered 14 previously unknown CSRF vulnerabilities that can be exploited, for instance, to take over user accounts or entire websites.	cross-site request forgery;cross-site scripting;experiment;marginal model;open-source software;programming paradigm;security testing;sensor;tracing (software);user (computing);web application	Giancarlo Pellegrino;Martin Johns;Simon Koch;Michael Backes;Christian Rossow	2017		10.1145/3133956.3133959	internet privacy;web application;world wide web;computer security;cross-site scripting;architecture;computer science;internet security;vulnerability assessment;security testing;cross-site request forgery;vulnerability	Security	-57.59066883575309	59.747937616415925	146680
b2d2dc85cc8827eefb38dd01004d9703178ee453	a rapid and scalable method for android application repackaging detection		Nowadays the security issues of Android applications (apps) are more and more serious. One of the main security threats come from repackaged apps. There already are some researches detecting repackaged apps using similarity measurement. However, so far, all the existing techniques for repackaging detection are based on code similarity or feature (e.g., permission set) similarity evaluation. In this paper, we propose a novel approach called ImageStruct that applies image similarity technique to locate and detect the changes coming from repackaging effectively. ImageStruct performs a quick repackaging detection by considering the similarity of images in target apps. The intuition behind our approach is that the repackaged apps still need to maintain the ”look and feel” of the original apps by including the original images, even they might have their additional code included or some of the original code removed. To prove the effectiveness and evaluate the reliability of our approach, we carry out the compare experiments between ImageStruct and the code based similarity scores of AndroGuard. The results demonstrate that ImageStruct is not only with good performance and scalability, but also able to resistant to code obfuscation.		Sibei Jiao;Yao Cheng;Lingyun Ying;Purui Su;Dengguo Feng	2015		10.1007/978-3-319-17533-1_24	android (operating system);obfuscation (software);scalability;repackaging;computer security;look and feel;computer science;permission;intuition	SE	-57.317495498587114	59.322523436215725	146906
51948240e4191179ce76a6dab4a6a28e36e18aa4	supor: precise and scalable sensitive user input detection for android apps		While smartphones and mobile apps have been an essential part of our lives, privacy is a serious concern. Previous mobile privacy related research efforts have largely focused on predefined known sources managed by smartphones. Sensitive user inputs through UI (User Interface), another information source that may contain a lot of sensitive information, have been mostly neglected. In this paper, we examine the possibility of scalably detecting sensitive user inputs from mobile apps. In particular, we design and implement SUPOR, a novel static analysis tool that automatically examines the UIs to identify sensitive user inputs containing critical user data, such as user credentials, finance, and medical data. SUPOR enables existing privacy analysis approaches to be applied on sensitive user inputs as well. To demonstrate the usefulness of SUPOR, we build a system that detects privacy disclosures of sensitive user inputs by combining SUPOR with off-the-shelf static taint analysis. We apply the system to 16,000 popular Android apps, and conduct a measurement study on the privacy disclosures. SUPOR achieves an average precision of 97.3% and an average recall of 97.3% for sensitive user input identification. SUPOR finds 355 apps with privacy disclosures and the false positive rate is 8.7%. We discover interesting cases related to national ID, username/password, credit card and health information.	android;application programming interface;attribute–value pair;context-sensitive grammar;credential;data structure;discovery system;encode;email;hilbert–huang transform;hypertext transfer protocol;ibm notes;information retrieval;information sensitivity;information source;json;method (computer programming);mobile app;nsakey;natural language processing;parsing;password;privacy;propagation constant;refinement (computing);sensor;smartphone;software development kit;software propagation;static program analysis;taint checking;thread-local storage;user (computing);user interface;vocabulary	Jianjun Huang;Zhichun Li;Xusheng Xiao;Zhenyu Wu;Kangjie Lu;Xiangyu Zhang;Guofei Jiang	2015			operating system;internet privacy;world wide web;computer security	Security	-56.614537210124986	59.34137117950802	147006
0ee0322d4ce28c96f556945f513011ae201f4797	breakapp: automated, flexible application compartmentalization		Developers of large-scale software systems may use third-party modules to reduce costs and accelerate release cycles, at some risk to safety and security. BREAKAPP exploits module boundaries to automate compartmentalization of systems and enforce security policies, enhancing reliability and security. BREAKAPP transparently spawns modules in protected compartments while preserving their original behavior. Optional high-level policies decouple security assumptions made during development from requirements imposed for module composition and use. These policies allow fine-tuning trade-offs such as security and performance based on changing threat models or load patterns. Evaluation of BREAKAPP with a prototype implementation for JavaScript demonstrates feasibility by enabling simplified security hardening of existing systems with low performance overhead.	compartmentalization (information security);high- and low-level;javascript;network compartment;overhead (computing);prototype;requirement;software system;threat model	Nikos Vasilakis;Ben Karel;Nick Roessler;Nathan Dautenhahn;André DeHon;Jonathan M. Smith	2018			computer science;compartmentalization (psychology);computer security	Security	-54.170066091849634	56.992067035866725	147065
01859485507ed533b8cd3d4966f875c2ca43cce9	traps and pitfalls: practical problems in system call interposition based security tools	power method;side effect	System call interposition is a powerful method for regulating and monitoring application behavior. In recent years, a wide variety of security tools have been developed that use this technique. This approach brings with it a host of pitfalls for the unwary implementer that if overlooked can allow his tool to be easily circumvented. To shed light on these problems, we present the lessons we learned in the course of several design and implementation cycles with our own system call interposition-based sandboxing tool. We first present some of the problems and pitfalls we encountered, including incorrectly replicating OS semantics, overlooking indirect paths to resources, race conditions, incorrectly subsetting a complex interface, and side effects of denying system calls. We then present some practical solutions to these problems, and provide general principles for avoiding the difficulties we encountered.	operating system;race condition;sandbox (computer security);system call;usb implementers forum	Tal Garfinkel	2003			computer science;computer security;system call;sandbox (computer security);semantics	OS	-57.68014756448755	57.33713580306489	147172
8e65eb25dc1a2b045192f554037385d81bac042a	a cyber-physical systems-based checkpoint model for structural controllability		The protection of critical user-centric applications, such as Smart Grids and their monitoring systems, has become one of the most cutting-edge research areas in recent years. The dynamic complexity of their cyber-physical systems (CPSs) and their strong interdependences with power systems are bringing about a significant increase in security problems that may be exploited by attackers. These security holes may, for example, trigger the disintegration of the structural controllability properties due to the problem of nonlocality, affecting, sooner or later, the provision of the essential services to end-users. One way to address these situations could be through automatic checkpoints in charge of inspecting the healthy status of the control network and its critical nature. This inspection can be subject to special mechanisms composed of trustworthy cyber-physical elements capable of detecting structural changes in the control and activating restoration procedures with support for warning. This is precisely the aim of this paper, which presents a CPSs-based checkpoint model with the capacity to manage heterogeneous replications that help ensure data redundancy, thereby guaranteeing the validity of the checkpoints. As a support to this study, a theoretical and practical analysis is addressed to show the functionality of the approach in real contexts.	activating function;application checkpointing;cell cycle checkpoints;circuit restoration;cyber-physical system;data redundancy;genetic heterogeneity;ibm power systems;interdependence;quantum nonlocality;sensor;transaction processing system;vulnerability (computing)	Cristina Alcaraz;Javier López	2018	IEEE Systems Journal	10.1109/JSYST.2017.2740719	control network;computer science;electric power system;real-time computing;controllability;smart grid;cyber-physical system;quantum nonlocality;network topology;data redundancy	Embedded	-56.83548387657389	51.10029371584729	147241
a40fa6629e9c33381dbf11cd0ded5438e9b42aa6	report: functional security testing closing the software - security testing gap: a case from a telecom provider	software security;security testing	To offer successful products and services in the telecom business requires to show that the specified security is implemented as expected. Functional security testing is suitable for this purpose as it bridges the gap between software and security testing. In this paper we describe the aspects of such a functional security testing approach. Further we provide evidence for a practical application of our approach and show the benefits we found.	application security;closing (morphology);security testing	Albin Zuccato;Clemens Kögler	2009		10.1007/978-3-642-00199-4_16	software security assurance;information security audit;computer security model;standard of good practice;cloud computing security;reliability engineering;security through obscurity;security information and event management;security engineering;systems engineering;information security;security service;application security;software testing;business;security testing;computer security	Security	-56.74884460623491	47.68166779590579	147599
b25abeff08e450ce9ea76296b38edc73f5b5cf97	multi-variant program execution for vulnerability detection and analysis	vulnerability detection;process monitoring;error rate;multi variant execution	Software vulnerabilities continue to be a major threat. Although significant advances have been made to reduce such vulnerabilities, there are still vulnerabilities that have eluded these techniques, and unfortunately the attackers have also become more sophisticated, employing more devious methods. Moreover, a huge amount of new code is written every year, so that even though the error rate may be decreasing, the overall number of vulnerabilities is still increasing. For example, the number of buffer errors listed in the National Vulnerabilities Database increased from 398 in 2007 to 563 in the year 2008 [7].	threat (computer);vulnerability (computing)	Todd Jackson;Christian Wimmer;Michael Franz	2010		10.1145/1852666.1852708	vulnerability management;real-time computing;computer science;distributed computing;secure coding;computer security	Security	-59.72031943295446	56.823250579862936	148383
e677bc110eb3e16ba40ac622f2af838aa947ff72	architectures for practical security	virtual machine;insider attack;input output;operating system;lessons learned;code size;systems and applications;architectures;system architecture;security policy;source code analysis	"""Few of the system architectures for security proposed for the past four decades (e.g., fine-grain domains of protection, virtual machines) have made a significant difference on client-side security. In this presentation, I examine some of the reasons for this and some of the lessons learned to date. Focus on client-side security is warranted primarily because it is substantially more difficult to achieve than server security in practice, since clients interact with human users directly. I argue that system and application partitioning to meet user security needs is now feasible, and that special focus must be placed on how to design and implement trustworthy communication, not merely secure channels, between system partitions.  Two forms of partitioning system and network components are described. The first, which is inspired by Lampson's Red/Green separation idea [1], partitions system resources instead of """"virtualizing"""" them, and switches between partitions only under (human) user control exercised via a trusted path. Neither operating systems nor applications can escape their partition or transfer control to other partitions behind the user's back [2] as a consequence of malware or insider attacks. Trustworthy communication among system and network partitions, which can be established only via network communication, goes beyond firewalls, guards and filters. The extent to which one partition accepts input from or outputs to another depends on the accountability of, and trust established with, the input provider and output receiver. It also depends on input-rate throttling and output propagation control, which often require establishing some degree of control over remote communication end points.  The second form of partitioning separates programmer-selected, security-sensitive code blocks from untrusted operating system code, applications and devices, and provides strong guarantees of data secrecy and integrity, as well as execution integrity, to an external entity via attestation [3]. Again, the key criterion for the separation and isolation of sensitive code partitions from untrusted code is the ability to establish trustworthy communication between security-sensitive and untrusted code; e.g., the security-sensitive code accepts only input whose validity it can verify in its own partition, and provides output only in areas that are legitimately accessible to untrusted code. The design of security-sensitive code partitions relies on source code analysis for modularity, where module input/output control -- not just security-policy isolation and code size minimization -- is a property of interest. Several applications of security-sensitive code isolation are illustrated."""	client-side;code::blocks;control theory;data flow diagram;firewall (computing);input/output;malware;network switch;operating system;programmer;server (computing);software propagation;static program analysis;trust (emotion);trusted path;trustworthy computing;user interface;virtual machine	Virgil D. Gligor	2010		10.1145/1809842.1809845	input/output;real-time computing;code access security;computer science;security policy;virtual machine;distributed computing;computer security;systems architecture	Security	-53.610766063521	57.925277074983995	148489
3d7b80647cbc536df6ef56a8638bba09a90dcc54	a bottom-up approach to applying graphical models in security analysis		Graphical models have emerged as a widely adopted approach to conducting security analysis for computer and network systems. The power of graphical models lies in two aspects: the graph structure can be used to capture correlations among security events, and the quantitative reasoning over the graph structure can render useful triaging decisions when dealing with the inherent uncertainty in security events. In this work we leverage these powers afforded by graphical model in security analysis. Given that the analyst is the intended user of the model, the most difficult task for research in this area is to understand the real world constraints under which security analysts must operate with. Those constraints dictate what parameters are realistically obtainable to use in the designed graphical models, and what type of reasoning results can be useful to analysts. We present how we use this bottom-up approach to design customized graphical models for enterprise network intrusion analysis. In this work, we had to design specific graph generation algorithms based on the concrete security problems at hands, and customized reasoning algorithms to use the graphical model to yield useful tools for analysts.	graphical model;top-down and bottom-up design	Xinming Ou	2016		10.1007/978-3-319-46263-9_1	leverage (finance);data mining;enterprise private network;security analysis;intrusion;top-down and bottom-up design;qualitative reasoning;concrete security;graphical model;computer science	ML	-61.69348981815435	59.70723988914928	148755
d944e57d9e29bb4931cb5c3735e6ef998758b090	towards automated security policy enforcement in multi-tenant virtual data centers	virtual networks;virtualization;trusted computing;data center;trusted virtual domain;security policy;virtual data center	Virtual data centers allow the hosting of virtualized infrastructures (networks, storage, machines) that belong to several customers on the same physical infrastructure. Virtualization theoretically provides the capability for sharing the infrastructure among different customers. In reality, however, this is rarely (if ever) done because of security concerns. A major challenge in allaying such concerns is the enforcement of appropriate customer isolation as specified by high-level security policies. At the core of this challenge is the correct configuration of all shared resources on multiple machines to achieve this overall security objective. To address this challenge, this paper presents a security architecture for virtual data centers based on virtualization and Trusted Computing technologies. Our architecture aims at automating the instantiation of a virtual infrastructure while automatically deploying the corresponding security mechanisms. This deployment is driven by a global isolation policy, thus guarantees overall customer isolation across all resources. We have implemented a prototype of the architecture based on the Xen hypervisor.	computer security;data center;hardware virtualization;high- and low-level;hypervisor;multitenancy;prototype;software deployment;trusted computing;universal instantiation;virtual private cloud	Serdar Cabuk;Chris I. Dalton;Konrad Eriksson;Dirk Kuhlmann;HariGovind V. Ramasamy;Gianluca Ramunno;Ahmad-Reza Sadeghi;Matthias Schunter;Christian Stüble	2010	Journal of Computer Security	10.3233/JCS-2010-0376	data center;virtualization;computer science;security policy;operating system;trusted network connect;trustworthy computing;computer security;computer network	Security	-50.84952197253138	57.10699660410143	148758
899ac1d1bcbd65b2ef5b48c65fea482d82ce4da4	the irreversible march of technology	new online service;capable device;security task;additional risk;irreversible march;enhanced functionality;adequate safeguard;greater burden;continual basis;security provision;new advance	The ongoing advancement of technology delivers numerous benefits, with enhanced functionality, more capable devices, and new online services all being made available to users on continual basis. At the same time, however, each new advance has the potential to introduce additional risk, with the consequence that users can quickly find themselves exposed if they do not maintain adequate safeguards and awareness. This paper considers some of the security challenges facing end-users, and the extent to which these have evolved alongside changes in the underlying technologies. The discussion reveals that while some aspects of security provision have clearly changed, this does not necessarily result in a situation that actually benefits the user. Indeed, they may find themselves facing a greater burden in terms of security tasks or complexity, or alternatively being underserved by protection options that no longer match the activities they are undertaking.		Steven Furnell	2009	Inf. Sec. Techn. Report	10.1016/j.istr.2010.04.002	simulation;computer security	HCI	-49.86318168471207	48.295587628508585	148797
0924585ae8e44144834dbed82a2c23d786c6fa4e	detection mechanism of fdi attack feature based on deep learning		At present, with the continuous optimization of grid standards in power system, the degree of convergence of information and communication technologies has become increasingly closer. However, it has also led to the exposure of important infrastructures in the smart grid, especially to the advanced measurement systems in smart metering communication systems. And the most typical type of attacks is False data injection (FDI). Therefore, consumer-centric communication devices, such as Phaser Measurement Units (PMUs) and smart meters, provide powerful support for data acquisition and transmission. As these devices facilitate the acquisition, transmission and consumption of power system data through the integration of communications, some malicious users initiate attacks against measured data in the meter for their own or other economic intention. This kind of attack behavior, on the one hand, affects the availability of meter data. On the other hand, it seriously undermines the authenticity and confidentiality of the measurement data itself. Therefore, in this paper, we proposed attack recognition mechanism based on Deep Belief Network to extract attack features. Our aim is to study the FDI attack behavior and accurately extract the relevant features of the behavior, and provide an effective criterion for the accurate identification of attack behavior in the smart grid. At the same time, through the optimization of the number of nerve cells and the number of layers in each layer of the deep neural network to ensure the real-time detection, the security defense system of the power grid is further enhanced.		Qiang Pu;Hao Qin;Hu Han;Yuanyi Xia;Zhihao Li;Kejun Xie;Wenqing Wang	2018	2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/SmartWorld.2018.00297	computer science;grid;communications system;computer network;electric power system;smart grid;deep learning;data acquisition;deep belief network;artificial intelligence;convergence (routing)	Security	-50.92588264698719	59.94901912248573	149038
0dbb129a8297312710a141a373bb1a123621f998	all your ifcexception are belong to us	error recovery;reliability;programming language design;not a values;availability;public labels;servers standards security context availability calculus data structures;ifcexception fine grained dynamic information flow control public labels delayed exceptions information flow error recovery error handling mechanisms not a values data flow standard exception model fundamental soundness property noninterference property full scale language nav robust software components;navs;system recovery;delayed exceptions;error handling;data flow analysis;exception handling;dynamic information flow control;navs dynamic information flow control fine grained labeling availability reliability error recovery exception handling programming language design public labels delayed exceptions not a values;fine grained labeling;system recovery data flow analysis error handling software reliability;software reliability	Existing designs for fine-grained, dynamic information-flow control assume that it is acceptable to terminate the entire system when an incorrect flow is detected-i.e, they give up availability for the sake of confidentiality and integrity. This is an unrealistic limitation for systems such as long-running servers. We identify public labels and delayed exceptions as crucial ingredients for making information-flow errors recoverable in a sound and usable language, and we propose two new error-handling mechanisms that make all errors recoverable. The first mechanism builds directly on these basic ingredients, using not-a-values (NaVs) and data flow to propagate errors. The second mechanism adapts the standard exception model to satisfy the extra constraints arising from information flow control, converting thrown exceptions to delayed ones at certain points. We prove that both mechanisms enjoy the fundamental soundness property of non-interference. Finally, we describe a prototype implementation of a full-scale language with NaVs and report on our experience building robust software components in this setting.	compiler;component-based software engineering;confidentiality;dataflow;error message;exception handling;full scale;interference (communication);invariant (computer science);non-interference (security);prototype;robustness (computer science);schedule (computer science);software propagation;storage violation;terminate (software);tracing (software)	Catalin Hritcu;Michael Greenberg;Ben Karel;Benjamin C. Pierce;J. Gregory Morrisett	2013	2013 IEEE Symposium on Security and Privacy	10.1109/SP.2013.10	exception handling;real-time computing;computer science;database;computer security	Security	-54.30629261358342	53.82456615228456	149250
96e4f22c02791efc5a79fe1d606d86d1e853e03b	switchblade: enforcing dynamic personalized system call models	modelo dinamico;system call models;modelizacion;sistema operativo;mise a jour;system call interposition;dynamic model;customization;personnalisation;simultaneidad informatica;ejecucion programa;vulnerability;probabilistic approach;program execution;dynamical system;actualizacion;modelisation;systeme dynamique;aleatorizacion;vulnerabilite;concurrency;vulnerabilidad;operating system;enfoque probabilista;execution programme;approche probabiliste;modele dynamique;secure system;personalizacion;randomisation;systeme exploitation;sistema dinamico;false positive;randomization;taint analysis;security;modeling;simultaneite informatique;updating;probability of detection	System call interposition is a common approach to restrict the power of applications and to detect code injections. It enforces a model that describes what system calls and/or what sequences thereof are permitted. However, there exist various issues like concurrency vulnerabilities and incomplete models that restrict the power of system call interposition approaches. We present a new system, SwitchBlade, that uses randomized and personalized fine-grained system call models to increase the probability of detecting code injections. However, using a fine-grain system call model, we cannot exclude the possibility that the model is violated during normal program executions. To cope with false positives, SwitchBlade uses on-demand taint analysis to update a system call model during runtime.	code injection;concurrency (computer science);existential quantification;personalization;randomized algorithm;sensor;switchblade;system call;taint checking	Christof Fetzer;Martin Süßkraut	2008		10.1145/1352592.1352621	randomization;taint checking;real-time computing;systems modeling;concurrency;type i and type ii errors;vulnerability;computer science;information security;dynamical system;statistical power;computer security;algorithm	OS	-56.186108391540444	54.12569138710168	149254
564615b581475e800de4b9e2c1a8149f24b1419c	extending the noninterference version of mls for sat	assured pipeline;securite;security policy model;accesibilidad;sistema informatico;computer system;sistema n niveles;satisfiability;controle;covert channel;non interference;multilevel systems power system modeling pipelines certification power system security access control signal analysis computer applications trademarks protection;type enforcement access control assured pipeline covert channel analysis multilevel security noninterference security policy model;covert channel analysis;accessibility;systeme n niveaux;safety;multilevel system;control;systeme informatique;access control;securite multiniveaux;machine etat fini;security policy;type enforcement;finite state machine;multilevel security;accessibilite;noninterference;check;securidad	A noninterference formulation of MLS applicable to the Secure Ada® Target (SAT) Abstract Model is developed. An analogous formulation is developed to handle the SAT type enforcement policy. Unwinding theorems are presented for both MLS and Multidomain Security (MDS) and the SAT Abstract Model is shown to satisfy both MLS and MDS. Generalizations and extensions are also considered.	access control;ada;computer security;covert channel;dick smith (software);interference (communication);john the ripper;loop unrolling;non-interference (security);principle of abstraction;type enforcement	J. Thomas Haigh;William D. Young	1986	IEEE Transactions on Software Engineering	10.1109/TSE.1987.226478	check;covert channel;telecommunications;computer science;engineering;security policy;access control;accessibility;finite-state machine;computer security;algorithm;scientific control;satisfiability	SE	-52.75523622355793	51.416711470834464	149298
444c580ae82ab28fdc15c84cd5b7b49e73566c06	on the security of open source software	security vulnerabilities;computer security;code review;proprietary software;open source software	With the rising popularity of so-called 'open source' software there has been increasing interest in both its various benefits and disadvantages. In particular, despite its prominent use in providing many aspects of the Internet's basic infrastructure, many still question the suitability of such software for the commerce-oriented Internet of the future. This paper evaluates the suitability of open source software with respect to one of the key attributes that tomorrow's Internet will require, namely security. It seeks to present a variety of arguments that have been made, both for and against open source security and analyses in relation to empirical evidence of system security from a previous study. The results represent preliminary quantitative evidence concerning the security issues surrounding the use and development of open source software, in particular relative to traditional proprietary software.	open-source software	Christian Payne	2002	Inf. Syst. J.	10.1046/j.1365-2575.2002.00118.x	software security assurance;computer security model;cloud computing security;security through obscurity;code review;security information and event management;computer science;backporting;social software engineering;software development;software engineering;security service;software technical review;internet privacy;software walkthrough;software deployment;world wide web;computer security;software peer review	SE	-57.77995249423569	46.73021552154345	149310
028b49466fc2a70a447403f67269e69a5ed57bab	on the difficulty of validating voting machine software with software	self-attesting machine;diebold accuvote-ts voting software;underlying operating system;humanly verifiable voting machine;pioneer code;software-based attestation;voting machine;pioneer framework;grub bootloader;voting machine software;current state	We studied the notion of human verification of software-based attestation, which we base on the Pioneer framework. We demonstrate that the current state of the art in software-based attestation is not sufficiently robust to provide humanly verifiable voting machine integrity in practice. We design and implement a selfattesting machine based on Pioneer and modify, and in some cases, correct the Pioneer code to make it functional and more secure. We then implement it into the GRUB bootloader, along with several other modifications, to produce a voting machine that authenticates and loads both the Diebold AccuVote-TS voting software as well as its underlying operating system. Finally, we implement an attack on the system that indicates that it is currently impractical for use and argue that as technology advances, the attack will likely become more effective.	algorithm;authentication;booting;captcha;diebold 10xx;formal verification;operating system	Ryan W. Gardner;Sujata Garera;Aviel D. Rubin	2007			computer science;theoretical computer science;data mining;computer security	Security	-58.88865768193392	56.791214060031095	149911
b90f5efb4e0b4a9ff4b43e49175c7caa996c6612	voronoi diagrams for automated argumentations among internet of things		This work introduces a novel approach to display and arbitration of machine to machine abstract argumentation for Internet of Things devices, which does not require human intervention. The proposed model is a hybrid between weighted Dung style argumentation frameworks and competitive facility placement Voronoi games. It can accommodate weights of arguments and attack relations to depict weighted argumentation frameworks, as well as a set of premises for dynamic argumentation frameworks. Included is a visualization tool for the strength of attacks and strength of arguments and a discussion on computational challenges of the paradigm.	argumentation framework;computation;internet of things;machine to machine;programming paradigm;voronoi diagram	Ellie Lovellette;Henry Hexmoor	2016	Multiagent and Grid Systems	10.3233/MGS-160256	database;internet privacy;world wide web	AI	-49.5848017212532	47.01449825224763	150054
83be4340fcacbdbb6679e73dc4be8412d3b66fc2	towards shared security through distributed separation of concerns	separation of concerns;distributed systems;security	When considering distributed enterprise applications interacting with data, one can rarely omit its security concerns that must enforce data integrity and prevent users from disallowed actions. Current trends of application design tend to deal with permissions internally in each particular interacting application, although certain knowledge from the consumer application perspective is needed. This unfortunately leads to restated knowledge that fails to correlate in time, once a particular interacting application evolves or changes. This paper, considers how an convenient security sharing should look like in distributed enterprise system. Next, it puts the ideal case next to the context of existing approaches, which it surveys.	data integrity;enterprise software;enterprise system;interaction;separation of concerns	Tomás Cerný;Michal Trnka;Michael J. Donahoo	2016		10.1145/2987386.2987394	computer science;data mining;distributed computing;computer security	Security	-50.44213455420421	53.440165330378754	150116
26b73628981a58088e65b9bbeffc1a5daab5e61d	analysing information integrity requirements in safety critical systems		Organizations’ assets are subject to different threats; which are addressed, usually, by different security solutions. Nonetheless i* modeling language was not developed with security in mind, which motivated the development of other languages (e.g., SI*) that focused on capturing the security requirements (e.g., privacy) of the system-to-be, but far less attention has been paid for capturing information integrity requirements. Capturing information integrity requirements represents an important need for safety critical systems, where depending on incorrect or inconsistent information may lead to disasters and loss of humans’ lives (e.g., Air Traffic Control Management Systems). In this paper we present a novel methodology for developing safety critical systems that extends i*/ SI* modeling languages with the required concepts and primitives for modeling and analyzing the requirements of safety critical systems, with a special emphasis on information integrity requirements.	management system;modeling language;privacy;requirement;threat (computer)	Mohamad Gharib;Paolo Giorgini	2013			modeling language;air traffic control;management system;life-critical system;systems engineering;engineering	Security	-55.885366763030504	47.29979855140787	150118
bf6f48c8367c5da6a4dad0438d63317d941810b1	cultural exploration of attack vector preferences for self-identified attackers		The examination of digital events through the prism of a quantitatively represented cultural framework allows for a new perspective on existing cyber security issues and events. When the cultural framework is applied to a large set of data, simple statistical analysis can be applied, allowing the researchers to quantify, characterize, and model specific aspects of human behavior.	assertion (software development);baseline (configuration management);behavioral analytics;code coverage;cognition;computer security;interaction;maple;population;sword art online: progressive;thomas j. watson research center;value (ethics);vector (malware)	Charmaine Sample;Jennifer Cowley;Steve Hutchinson	2017	2017 11th International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2017.7956551	data mining;cultural diversity;software;computer science	Visualization	-62.12519726785061	57.90948573963073	150130
7387ba6113e033eaba653e78e18c567d12a32987	ifcaas: information flow control as a service for cloud security	vulnerability detection;cloud applications;information flow control;saas security;static analysis	"""With the maturity of service-oriented architecture (SOA) and Web technologies, web services have become critical components of Software as a Service (SaaS) applications in cloud ecosystem environments. Most SaaS applications leverage multi-tenant data stores as a back end to keep and process data with high agility. Although these technologies promise impressive benefits, they put SaaS applications at risk against novel as well as prevalent attack vectors. This security risk is further magnified by the loss of control and lack of security enforcement over sensitive data manipulated by SaaS applications. An effective solution is needed to fulfill several requirements originating in the dynamic and complex nature of such applications. Inspired by the rise of Security as a Service (SecaaS) model, this paper introduces """"Information Flow Control as a Service (IFCaaS)"""". IFCaaS lays the foundation of cloud-delivered IFC-based security analysis and monitoring services. As an example of the adoption of the IFCaaS, this paper presents a novel framework that addresses the detection of information flow vulnerabilities in SaaS applications. Our initial experiments show that the framework is a viable solution to protect against data integrity and confidentiality violations leading to information leakage."""	benchmark (computing);capability maturity model;cloud computing security;confidentiality;data integrity;data store;data-flow analysis;ecosystem;end-to-end principle;experiment;holism;industry foundation classes;information flow;information leakage;multitenancy;nosql;non-interference (security);program slicing;requirement;run time (program lifecycle phase);security as a service;service-oriented architecture;service-oriented device architecture;software as a service;spectral leakage;stealth;structured query language interface;virtual machine manager;web service	Marwa Elsayed;Mohammad Zulkernine	2016	2016 11th International Conference on Availability, Reliability and Security (ARES)	10.1109/ARES.2016.27	cloud computing security;engineering;security service;internet privacy;world wide web;computer security	Security	-49.78155193517524	57.540321334763895	150202
9c0a05778f153279b485e8cee0585fa64f31071c	a risk analysis approach for biometric authentication technology	biometric authentication;risk analysis	Current approaches for risk analysis of biometric authentication technology are limited to enrollment and identification/verification processes with biometric algorithms mainly considered as black-boxes, only. This paper presents a systematic approach for a holistic security risk analysis of biometric authentication technology based on the high-level component & process model for integrated security risk analysis of biometric authentication technology, also proposed here. The processes and components used within this model are introduced together with a comprehensive terminology for biometric authentication technology especially developed for the research area of IT security biometrics. Biometric authentication risk matrices are used to show that single possible risk effect classes can be identified. A discussion on the enabled possibilities for risk analysis shows the significant advantage of this integrated approach for holistic security risk analysis of biometric authentication technology in comparison to other approaches.	algorithm;authentication;biometrics;black box;high- and low-level;holism;it risk management;process modeling	Arslan Brömme	2006	I. J. Network Security		risk analysis;computer science;data mining;internet privacy;computer security;biometrics	Security	-55.57494365881643	48.84074748136744	150569
001328674b88f3d5fb09ea640bcb8d1b6a93106a	security types for dynamic web data	security properties;process migration;type system	We describe a type system for the Xdπ calculus of Gardner and Maffeis. An Xdπ-network is a network of locations, where each location consists of both a data tree (which contains scripts and pointers to nodes in trees at different locations) and a process, for modelling process interaction, process migration and interaction between processes and data. Our type system is based on types for locations, data and processes, expressing security levels. A tree can store data of different security level, independently from the security level of the enclosing location. The access and mobility rights of a process depend on the security level of the “source” location of the process itself, i.e. of the location where the process was in the initial network or where the process was created by the activation of a script. The type system enjoys type preservation under reduction (subject reduction). In consequence of subject reduction we prove the following security properties. In a well-typed Xdπ-network, a process P whose source location is of level h can copy data of security level at most h and update data of security level less than h. Moreover, the process P can only communicate data and go to locations of security level equal or less than h.	goto;process migration;subject reduction;type system	Mariangiola Dezani-Ciancaglini;Silvia Ghilezan;Jovanka Pantovic	2006		10.1007/978-3-540-75336-0_17	process migration;type system;computer science;data mining;database;programming language;computer security	Security	-52.47646059793997	53.58910531021916	150673
9c15235735f06fd5cd708345b6694525238a82f4	detecting hardware-assisted virtualization		Virtualization has become an indispensable technique for scaling up the analysis of malicious code, such as for malware analysis or shellcode detection systems. Frameworks like Ether, ShellOS and an ever-increasing number of commercially-operated malware sandboxes rely on hardware-assisted virtualization. A core technology is Intel’s VTx, which — compared to software-emulated virtulization — is believed to be stealthier, especially against evasive attackers that aim to detect virtualized systems to hide the malicious behavior of their code. We propose and evaluate low-level timing-based mechanisms to detect hardware-virtualized systems. We build upon the observation that an adversary can invoke hypervisors and trigger context switches that are noticeable both in timing and in their side effects on caching. We have locally trained and then tested our detection methodology on a wide variety of systems, including 240 PlanetLab nodes, showing a high detection accuracy. As a real-world evaluation, we detected the virtualization technology of more than 30 malware sandboxes. Finally, we demonstrate how an adversary may even use these detections to evade multi-path exploration systems that aim to explore the full behavior of a program. Our results show that VT-x is not sufficiently stealthy for reliable analysis of malicious code.	adversary (cryptography);context switch;emulator;hardware-assisted virtualization;high- and low-level;hypervisor;image scaling;malware analysis;network switch;planetlab;sandbox (computer security);sensor;shellcode	Michael Brengel;Michael Backes;Christian Rossow	2016		10.1007/978-3-319-40667-1_11	real-time computing;computer science;internet privacy;computer security	Security	-54.7725500247804	56.96251705658276	150736
adc364482656b79f8387d9845935e047a116b3ef	e-voting attacks and countermeasures	e voting attacks xilinx fpga board hardware trojan tampers malicious back doors security challenges electronic voting systems;invasive software field programmable gate arrays government data processing;electronic voting field programmable gate arrays trojan horses cryptography hardware nominations and elections delays;security e voting hardware spyware hardware trojan;hardware spyware;hardware trojan;security;e voting	Electronic voting (e-voting) systems have been inuse since the 1960s. E-voting offers many advantages compared to other voting techniques. However, it also introduces many security challenges. As it may contain malicious back-doors that can affect system dependability. In this work, we present one of e-voting challenges where the hardware Trojan tampers results totally. We implement an e-voting machine as a case study on XilinxFPGA board. Then, we inject a hardware Trojan to tamper voting results. The attack depends mainly on the unused bits. We provide a protection technique and show its overhead. Furthermore, we introduce other attacks and protection scenarios. We compare between our selected protection techniques and others techniques. Finally, we illustrate that our chosen protection technique incurs negligible power overhead, whereas the average area and delay overheads are 4% and 10%, respectively.	commitment ordering;countermeasure (computer);dependability;hardware trojan;overhead (computing);trojan horse (computing)	M. Tarek Ibn Ziad;Amr Al-Anwar;Yousra Alkabani;M. Watheq El-Kharashi;Hassan Bedour	2014	2014 28th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2014.53	embedded system;computer science;information security;internet privacy;computer security	EDA	-54.78784955597631	56.81432074397613	150833
5b19a52de4fac7751ba379f77e63558cf1c234b7	android: static analysis using similarity distance	humanoid robot;cluster algorithm;program diagnostics;androids;compressors smart phones humanoid robots androids java algorithm design and analysis clustering algorithms;smart phone;smart phones;computer crime;android;humanoid robots;compressors;similarity;diffing android static analysis similarity;clustering algorithms;static analysis android application product tampering product piracy java source code android bytecode customized similarity distance change indicator obfuscator automatic extraction injected malware code release cycle;invasive software;source code;static analysis;source coding computer crime invasive software java program diagnostics;diffing;algorithm design;algorithm design and analysis;source coding;java	As Android applications become increasingly ubiquitous, we need algorithms and tools to protect applications from product tampering and piracy, while facilitating valid product updates. Since it is easy to derive Java source code from Android byte code, Android applications are particularly vulnerable to tampering. This paper presents an algorithm, based on a customized similarity distance, which returns a value between 0 and 1, which can serve as a change indicator. Potential applications of the algorithm include 1) to determine if obfuscators, applied by developers, are protecting their code from piracy, 2) to determine if an Android application is infected with malware, facilitating the automatic extraction of the injected malware, and 3) to identify valid code updates and releases as part of the code release cycle.	algorithm;android;byte;malware;obfuscation (software);software release life cycle;static program analysis	Anthony Desnos	2012	2012 45th Hawaii International Conference on System Sciences	10.1109/HICSS.2012.114	embedded system;algorithm design;real-time computing;computer science;humanoid robot;artificial intelligence;operating system;database;programming language;world wide web;computer security;source code	SE	-56.96530154788504	59.34731337899841	150874
608eda039e3ebfabe26f1eaef3203f25acaf319d	developing secure cloud applications: a case study	security of data cloud computing computer centres contracts;security xml monitoring virtual machining queueing analysis cloud computing;mosaic platform secure cloud applications security loss perception cloud provider prospective infrastructures as a services iaas cloud datacenter service level agreements cloud adoption security mechanisms security requirements application design process security guarantees cloud platforms	Today the main limit to Cloud adoption is related to the perception of a security loss the users have. Indeed, the existing solutions to provide security are mainly focused on Cloud Provider prospective in order to securely integrate frameworks and Infrastructures as a Services (IaaS) in a Cloud datacenter. There is no way to monitor and evaluate the provided security. In fact, Service Level Agreements mainly focus on performance related terms and no guarantees are given for security mechanisms. Users are interested in tools to verify and monitor the implemented security requirements. On the other side, developers need tools to deploy Cloud application offering measurable security grants to end users. In this paper we will propose an approach to implement security mechanisms as components in the application design process. We modeled security interactions according to the specific threat, the specific security requirements and user/application capabilities trying to improve security and enable a Service Provider to offer security guarantees to customers. The approach has been designed to fit with different Cloud platforms, but to demonstrate its applicability, we will present a case study on the mOSAIC Platform.	cloud computing;data center;fits;interaction;internet;ncsa mosaic;prospective search;requirement;service-level agreement;software as a service;threat (computer);user requirements document;vulnerability (computing)	Ermanno Battista;Valentina Casola;Nicola Mazzocca;Massimo Ficco;Massimiliano Rak	2013	2013 15th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2013.63	software security assurance;computer security model;cloud computing security;web application security;security through obscurity;security information and event management;security engineering;cloud computing;covert channel;asset;logical security;operating system;cloud testing;human-computer interaction in information security;security service;application security;internet privacy;security testing;network security policy;world wide web;computer security	Security	-48.95038340990726	56.93523944855164	150883
4b1f8c3aaa8eebd71ea50bbc9bfe66cd3c33c6a7	assessing procedural risks and threats in e-voting: challenges and an approach	multiple instance;threat actions;security analysis;procedural security;modeling;e voting	Performing a good security analysis on the design of a system is an essential step in order to guarantee a reasonable level of protection. However, different attacks and threats may be carried out depending on the operational environment in which the system is used, i.e. the procedures that define how to operate the systems. We are interested in reasoning about the security of e-Voting procedures, namely on the risks and attacks that can be carried out during an election. Our focus is more on people and organizations than on systems and technologies. In this paper we describe some ongoing work that we are carrying out within the ProVotE project (a project sponsored by the Autonomous Province of Trento to switch to e-Voting for local elections) to analyze and (possibly) improve procedural security of electronic elections. To do so, we are providing models of the Italian electoral laws using the UML and we are developing a custom methodology for analyzing threats from the models. Our reasoning approach is based on asset mobility, asset values and existence of multiple instances.	model checking;procedural programming;requirement;threat (computer);unified modeling language	Komminist Weldemariam;Adolfo Villafiorita;Andrea Mattioli	2007		10.1007/978-3-540-77493-8_4	public relations;actuarial science;asset;political science;computer security	AI	-56.12238587534274	49.13162382900313	151042
b33ec07a47b01281c658f430148dde39aeaf20da	information-flow analysis for covert-channel identification in multilevel secure operating systems	multilevel secure operating systems;information analysis operating systems law legal factors information security educational institutions computer interfaces;nondiscretionary security policy;information security;flow path;secure xenix covert channel identification multilevel secure operating systems information flow flow path flow condition nondiscretionary security policy trusted computing base information flow analysis illegal flow;secure information flow;law;covert channel;legal factors;information flow;secure xenix;covert channel identification;operating system;information flow analysis;trusted computing base;security of data operating systems computers;computer interfaces;security policy;information analysis;security of data;operating systems computers;multilevel security;operating systems;flow condition;illegal flow	Given an information flow consisting of the flow path and the flow condition under which the flow takes place, the problem of determining whether the information flow is legal is considered; that is, whether the flow complies with the underlying nondiscretionary security policy of a trusted computing base (TCB). It is shown that the proposed approach to information-flow analysis has the advantage of eliminating the possibility of generating false illegal flow, namely flows that are identified by the analysis process to be illegal but which, in reality, are legal. Without eliminating false illegal flows from analysis, automated tools for secure information-flow analysis would be of limited use in this area because manual work would still be needed. Finally, it is shown how to apply this information-flow analysis approach to Secure XENIX and how information-flow analysis can help reduce the amount of effort for information-flow integration within TCB programs. >	covert channel;multilevel security	Jingsha He;Virgil D. Gligor	1990		10.1109/CSFW.1990.128194	computer science;distributed computing;internet privacy;computer security	Security	-52.90934118546314	52.156470923172876	151142
8e58db5def7e10e7e442236df7c4ec01da024e1f	artificial intelligence based malware analysis		Artificial intelligence methods have often been applied to perform specific functions or tasks in the cyber– defense realm. However, as adversary methods become more complex and difficult to divine, piecemeal efforts to understand cyber–attacks, and malware–based attacks in particular, are not providing sufficient means for malware analysts to understand the past, present and future characteristics of malware. In this paper, we present the Malware Analysis and Attributed using Genetic Information (MAAGI) system. The underlying idea behind the MAAGI system is that there are strong similarities between malware behavior and biological organism behavior, and applying biologically inspired methods to corpora of malware can help analysts better understand the ecosystem of malware attacks. Due to the sophistication of the malware and the analysis, the MAAGI system relies heavily on artificial intelligence techniques to provide this capability. It has already yielded promising results over its development life, and will hopefully inspire more integration between the artificial intelligence and cyber–defense communities.	adversary (cryptography);artificial intelligence;ecosystem;malware analysis;text corpus	Avi Pfeffer;Brian E. Ruttenberg;Lee Kellogg;Michael Howard;Catherine Call;Alison O'Connor;Glenn Takata;Scott Neal Reilly;Terry Patten;Jason Taylor;Robert Hall;Arun Lakhotia;Craig Miles;Daniel Scofield;Jared Frank	2017	CoRR		artificial intelligence;world wide web;computer security	AI	-61.48190358183042	58.070184059373176	151356
a03df96afd6fb53de79c210d1bf2abacc5da69b6	generic unpacking method based on detecting original entry point		In this paper, we focus on the problem of the unpacking of packed executables in a generic way. That is, we do not assume specific knowledge about the algorithms used to produce the packed executable to do the unpacking (i.e. we do not extract/create a reverse algorithm). In general, when launched, a packed executable will first reconstruct the code of the original program, write it down someplace in memory and then transfer the execution to that original code by assigning the Extended Instruction Pointer (EIP) to the so-called Original Entry Point (OEP) of the program. Accordingly, if we had a way to accurately identify that transfer event in the execution flow and thus the OEP, we could more easily extract the original code for analysis (cf. by inspecting the remaining code after the OEP was reached). We then propose an effective generic unpacking method based on the combination of two novel OEP detection techniques, one relying on the incremental measurement of the entropy of the information stored in the memory space assigned to the unpacking process, and the other on the incremental searching and counting of potential Windows API calls in that same memory space.	entry point	Ryoichi Isawa;Masaki Kamizono;Daisuke Inoue	2013		10.1007/978-3-642-42054-2_74	theoretical computer science;distributed computing	NLP	-61.51115647801365	51.96763016582782	151441
54d2cc25daaedf8ee84db467ea9b58af7d710395	a discuss of computer security strategy models	chinese wall model;lattices;information security;integrable model;availability;security of data data privacy;biological system modeling;confidentiality;computer security;computational modeling biological system modeling lattices computer security availability machine learning;bell lapadula confidentiality model;computational modeling;integrity;machine learning;data privacy;clark wilson integrity model;model;computer security strategy model;biba integrity model;chinese wall model computer security strategy model bell lapadula confidentiality model biba integrity model clark wilson integrity model;security of data;model computer security confidentiality integrity availability	From the three basic character of the computer security: confidentiality, integrity, availability, the paper studies the Bell-Lapadula confidentiality model, the Biba integrity model, the Clark-Wilson integrity model and Chinese wall Model. This paper also studies the relation among three models of the Bell-Lapadula model, the Biba model and he Clark-Wilson model, studies the relation and distinguishes between the Bell-Lapadula model and the China Wall model from the point of the information security.	bell–lapadula model;biba model;chinese wall;clark–wilson model;computer security model;confidentiality;futures studies;information security	Ming-Xin Yang;Li-Na Yuan;Zhi-Xia Yang	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580588	computer security model;availability;confidentiality;computer science;information security;lattice;data mining;internet privacy;computational model;computer security	DB	-48.71135236570055	58.34063267423134	151497
ee25e356285c6a1c6cb921e92a7d3b1a292e1c2e	security strategy of campus network data center in cloud environment		In the campus network security strategy, the traditional university data center only considers traffic safety as the consideration factor, in the cloud computing environment, the security model of the virtualization data center is transformed from 2d to 3d. This paper proposes four security strategies and designs the security and equipment deployment of campus network data center under the cloud environment, thus improving the security of campus network data center in the cloud environment.	data center	Ge Suhui;Wan Quan;Sun Wenhui	2018		10.1007/978-3-030-00012-7_27	software deployment;virtualization;computer science;computer security model;data center;campus network;cloud computing;computer network;distributed computing	ML	-49.180943745242864	58.01837391999863	151589
be5985ffc8950f123ba8d0a8d88e3b8f6dcc732e	detecting fraud using modified benford analysis		Large enterprises frequently enforce accounting limits to reduce the impact of fraud. As a complement to accounting limits, auditors use Benford analysis to detect traces of undesirable or illegal activities in accounting data. Unfortunately, the two fraud fighting measures often do not work well together. Accounting limits may significantly disturb the digit distribution examined by Benford analysis, leading to high false alarm rates, additional investigations and, ultimately, higher costs. To better handle accounting limits, this paper describes a modified Benford analysis technique where a cut-off log-normal distribution derived from the accounting limits and other properties of the data replaces the distribution used in Benford analysis. Experiments with simulated and real-world data demonstrate that the modified Benford analysis technique significantly reduces false positive errors.	experiment;interpretation (logic);mathematical model;sensor;simulation;synthetic intelligence;tracing (software)	Christian Winter;Markus Schneider;York Yannikos	2011			engineering;forensic engineering;operations research;computer security	Security	-61.86681027005222	53.733356352187144	151621
7ebb2ebb76edcbe6db401667cf93bfaaecb2c6ae	server-side detection of malware infection	cell phone;mobile;incentive compatibility;service provider;post mortem;detection;it security;fraud;malware;anti virus;retroactive;incentive compatible;infection;audit	We review the intertwined problems of malware and online fraud, and argue that the fact that service providers often are nancially responsible for fraud causes a relative lack of incentives for clients to manage their own security well. This suggests the need for a server-side tool to determine the security posture of clients before letting them transact.  We introduce an exceedingly lightweight audit mechanism to address this need -- permitting for post-mortem infection analysis -- and prove its security properties based on standard cryptographic hardness assumptions. We describe a deployment architecture that aligns the incentives of participants in order to facilitate quick adoption and widespread use of the technology. Our approach is exible enough to protect even low-end computing devices like mobile handsets, which future malware will target heavily, but whose power and bandwidth limitations result in poor effectiveness for traditional anti-virus solutions.  A contribution of independent potential value is the enabling of a centralized analysis of malware-related events, which promises to extend the power of detection in comparison to what today's decentralized paradigm allows.	antivirus software;centralized computing;cryptographic hash function;cryptography;malware;mobile phone;poor posture;programming paradigm;server-side;software deployment	Markus Jakobsson;Ari Juels	2009		10.1145/1719030.1719033	incentive compatibility;computer science;internet privacy;world wide web;computer security	Security	-50.23705050471967	59.56864896726801	151692
013793bcb376df9e77344d87ab166d584f7c7b6b	automatic exploit generation for buffer overflow vulnerabilities		Buffer overflow vulnerabilities are widely found in software. Finding these vulnerabilities and identifying whether these vulnerabilities can be exploit is very important. However, it is not easy to find all of the buffer overflow vulnerabilities in software programs, and it is more difficult to find and exploit these vulnerabilities in binary programs. This paper proposes a method and a corresponding tool that automatically finds buffer overflow vulnerabilities in binary programs, and then automatically generate exploit for the vulnerability. The tool uses symbolic execution to search the target software and find potential buffer overflow vulnerabilities, then try to bypass system protection by choosing different exploiting method according to the different level of protections. Finally, the exploit of software vulnerability is generated using constraint solver. The method and tool can automatically find vulnerabilities and generate exploits for three kinds of protection: without system protection, with address space layout randomization protection, and with stack non-executable protection.	address space layout randomization;buffer overflow;executable;solver;symbolic execution;vulnerability (computing)	Luhang Xu;Weixi Jia;Wei Dong;Yongjun Li	2018	2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)	10.1109/QRS-C.2018.00085	address space layout randomization;real-time computing;software quality;software;symbolic execution;vulnerability (computing);exploit;buffer overflow;constraint satisfaction problem;computer science	SE	-57.54993230243051	55.952668686441136	151704
422c2d83a959df1f7c3e99b8a2c77772d8b2e7c3	opaque control-flow integrity		A new binary software randomization and ControlFlow Integrity (CFI) enforcement system is presented, which is the first to efficiently resist code-reuse attacks launched by informed adversaries who possess full knowledge of the inmemory code layout of victim programs. The defense mitigates a recent wave of implementation disclosure attacks, by which adversaries can exfiltrate in-memory code details in order to prepare code-reuse attacks (e.g., Return-Oriented Programming (ROP) attacks) that bypass fine-grained randomization defenses. Such implementation-aware attacks defeat traditional fine-grained randomization by undermining its assumption that the randomized locations of abusable code gadgets remain secret. Opaque CFI (O-CFI) overcomes this weakness through a novel combination of fine-grained code-randomization and coarsegrained control-flow integrity checking. It conceals the graph of hijackable control-flow edges even from attackers who can view the complete stack, heap, and binary code of the victim process. For maximal efficiency, the integrity checks are implemented using instructions that will soon be hardware-accelerated on commodity x86-x64 processors. The approach is highly practical since it does not require a modified compiler and can protect legacy binaries without access to source code. Experiments using our fully functional prototype implementation show that O-CFI provides significant probabilistic protection against ROP attacks launched by adversaries with complete code layout knowledge, and exhibits only 4.7% mean performance overhead on current hardware (with further overhead reductions to follow on forthcoming Intel processors). I. MOTIVATION Code-reuse attacks (cf., [5]) have become a mainstay of software exploitation over the past several years, due to the rise of data execution protections that nullify traditional codeinjection attacks. Rather than injecting malicious payload code directly onto the stack or heap, where modern data execution protections block it from being executed, attackers now ingeniously inject addresses of existing in-memory code fragments (gadgets) onto victim stacks, causing the victim process to execute its own binary code in an unanticipated order [38]. With a sufficiently large victim code section, the pool of exploitable gadgets becomes arbitrarily expressive (e.g., Turing-complete) [20], facilitating the construction of arbitrary attack payloads without the need for code-injection. Such payload construction has even been automated [34]. As a result, code-reuse has largely replaced code-injection as one of the top software security threats. Permission to freely reproduce all or part of this paper for noncommercial purposes is granted provided that copies bear this notice and the full citation on the first page. Reproduction for commercial purposes is strictly prohibited without the prior written consent of the Internet Society, the first-named author (for reproduction of an entire paper only), and the author’s employer if the paper was prepared within the scope of employment. NDSS ’15, 8–11 February 2015, San Diego, CA, USA Copyright 2015 Internet Society, ISBN 1-891562-38-X http://dx.doi.org/10.14722/ndss.2015.23271 This has motivated copious work on defenses against codereuse threats. Prior defenses can generally be categorized into: CFI [1] and artificial software diversity [8]. CFI restricts all of a program’s runtime control-flows to a graph of whitelisted control-flow edges. Usually the graph is derived from the semantics of the program source code or a conservative disassembly of its binary code. As a result, CFIprotected programs reject control-flow hijacks that attempt to traverse edges not supported by the original program’s semantics. Fine-grained CFI monitors indirect control-flows precisely; for example, function callees must return to their exact callers. Although such precision provides the highest security, it also tends to incur high performance overheads (e.g., 21% for precise caller-callee return-matching [1]). Because this overhead is often too high for industry adoption, researchers have proposed many optimized, coarser-grained variants of CFI. Coarse-grained CFI trades some security for better performance by reducing the precision of the checks. For example, functions must return to valid call sites (but not necessarily to the particular site that invoked the callee). Unfortunately, such relaxations have proved dangerous—a number of recent proof-of-concept exploits have shown how even minor relaxations of the control-flow policy can be exploited to effect attacks [6, 11, 18, 19]. Table I summarizes the impact of several of these recent exploits. Artificial software diversity offers a different but complementary approach that randomizes programs in such a way that attacks succeeding against one program instance have a very low probability of success against other (independently randomized) instances of the same program. Probabilistic defenses rely on memory secrecy—i.e., the effects of randomization must remain hidden from attackers. One of the simplest and most widely adopted forms of artificial diversity is Address Space Layout Randomization (ASLR), which randomizes the base addresses of program segments at loadtime. Unfortunately, merely randomizing the base addresses does not yield sufficient entropy to preserve memory secrecy in many cases; there are numerous successful derandomization attacks against ASLR [13, 26, 36, 37, 39, 42]. Finer-grained diversity techniques obtain exponentially higher entropy by randomizing the relative distances between all code points. For example, binary-level Self-Transforming Instruction Relocation (STIR) [45] and compilers with randomized code-generation (e.g., [22]) have both realized fine-grained artificial diversity for production-level software at very low overheads. Recently, a new wave of implementation disclosure attacks [4, 10, 35, 40] have threatened to undermine fine-grained artificial diversity defenses. Implementation disclosure attacks exploit information leak vulnerabilities to read memory pages of victim processes at the discretion of the attacker. By reading the TABLE I. OVERVIEW OF CONTROL-FLOW INTEGRITY BYPASSES CFI [1] bin-CFI [50] CCFIR [49] kBouncer [33] ROPecker [7] ROPGuard [16] EMET [30] DeMott [12] Feb 2014 / Göktaş et al. [18] May 2014 / / / Davi et al. [11] Aug 2014 / / / / / Göktaş et al. [19] Aug 2014 / / Carlini and Wagner [6] Aug 2014 / / in-memory code sections, attackers violate the memory secrecy assumptions of artificial diversity, rendering their defenses ineffective. Since finding and closing all information leaks is well known to be prohibitively difficult and often intractable for many large software products, these attacks constitute a very dangerous development in the cyber-threat landscape; there is currently no well-established, practical defense. This paper presents Opaque CFI (O-CFI): a new approach to coarse-grained CFI that strengthens fine-grained artificial diversity to withstand implementation disclosure attacks. The heart of O-CFI is a new form of control-flow check that conceals the graph of abusable control-flow edges even from attackers who have complete read-access to the randomized binary code, the stack, and the heap of victim processes. Such access only affords attackers knowledge of the intended (and therefore nonabusable) edges of the control-flow graph, not the edges left unprotected by the coarse-grained CFI implementation. Artificial diversification is employed to vary the set of unprotected edges between program instances, maintaining the probabilistic guarantees of fine-grained diversity. Experiments show that O-CFI enjoys performance overheads comparable to standard fine-grained diversity and non-opaque, coarse-grained CFI. Moreover, O-CFI’s control-flow checking logic is implemented using Intel x86/x64 memory-protection extensions (MPX) that are expected to be hardware-accelerated in commodity CPUs from 2015 onwards. We therefore expect even better performance for O-CFI in the near future. Our contributions are as follows: • We introduce O-CFI, the first low-overhead code-reuse defense that tolerates implementation disclosures. • We describe our implementation of a fully functional prototype that protects stripped, x86 legacy binaries without source code. • Analysis shows that O-CFI provides quantifiable security against state-of-the-art exploits—including JITROP [40] and Blind-ROP [4]. • Performance evaluation yields competitive overheads of just 4.7% for computation-intensive programs. II. THREAT MODEL Our work is motivated by the emergence of attacks against fine-grained diversity and coarse-grained control-flow integrity. We therefore introduce these attacks and distill them into a single, unified threat model. A. Bypassing Coarse-Grained CFI Ideally, CFI permits only programmer-intended control-flow transfers during a program’s execution. The typical approach is to assign a unique ID to each permissible indirect controlflow target, and check the IDs at runtime. Unfortunately, this introduces performance overhead proportional to the degree of the graph—the more overlaps between valid target sets of indirect branch instructions, the more IDs must be stored and checked at each branch. Moreover, perfect CFI cannot be realized with a purely static control-flow graph; for example, the permissible destinations of function returns depend on the calling context, which is only known at runtime. Fine-grained CFI therefore implements a dynamically computed shadow stack, incurring high overheads [1]. To avoid this, coarse-grained CFI implementations resort to a reduced-degree, static approximation of the control-flow graph, and merge identifiers at the cost of reduced security. For example, bin-CFI [49] and CCFIR [50] use at most three IDs per branch, and omit shadow stacks. Recent work has demonstrated that these optimizations open exploitable	address space layout randomization;application security;approximation;base address;binary code;binary file;categorization;central processing unit;closing (morphology);code injection;code point;code reuse;common flash memory interface;compiler;computation;control flow graph;control-flow integrity;davi;disassembler;diversification (finance);emergence;enhanced mitigation experience toolkit;entropy (information theory);exploit (computer security);graph (discrete mathematics);hardware acceleration;identifier;in-memory database;indirect branch;information security;intel mpx;international standard book number;loader (computing);maximal set;overhead (computing);overhead code;ptc integrity;performance evaluation;programmer;prototype;randomized algorithm;relocation (computing);return-oriented programming;run time (program lifecycle phase);shadow stack;traverse;threat model;turing completeness;x86	Vishwath Mohan;Per Larsen;Stefan Brunthaler;Kevin W. Hamlen;Michael Franz	2015			computer security;opacity;computer science;control-flow integrity	Security	-56.13273330749861	56.100077205149994	151946
d98f36e81a8df3c87d67ccc1c8d6be445c25a135	pragmatic solutions to make e-mail security work		The concepts for secure e-mail are available for quite some time. Nevertheless only few users have adopted them. The classical concept of end-to-end e-mail security provides maximum theoretical security. But the effort to implement and enforce it at every client has limited the spreading of security and therefore the overall benefit. Centralized e-mail security overcomes this problem. A gateway between the internal and the public network provides security where it is needed – in the internet. This presentation reflects aspects like standards, integration, security policy, central virus detection, implementation efforts, and key-recovery as well as business requirements like reduced administration costs and optimized workflow.	business requirements;centralized computing;email encryption;end-to-end encryption;end-to-end principle;internet;requirement	Henning Seemann	2003		10.1007/978-3-322-84982-3_19	public relations;computer science;management science;computer security	Security	-48.776352208949525	55.491108603344024	152249
a7e46de3d021076f01e62cdd839e20be9192f287	comparison of sql injection detection and prevention tools based on attack type and deployment requirements	tool;detection;comparison;prevention;sql injection;sql injection attacks	SQL injection is a type of attack which the attacker adds Structured Query Language code to a web form input box to gain access or make changes to data. SQL injection vulnerability allows an attacker to flow commands directly to a web application's underlying database and destroy functionality or confidentiality. Researchers have proposed different tools to detect and prevent this vulnerability. In this paper we present all SQL injection attack types and also different tools which can detect or prevent these attacks. Finally we compared these tools against attack types and deployment requirements. Keyword: SQL Injection Attacks, detection, prevention, tool, comparison.	code injection;confidentiality;form (html);language code;query language;requirement;sql injection;software deployment;web application	Atefeh Tajpour;Maslin Masrom;Mohammad JorJor Zadeh Shooshtari;Hossein Rouhani Zeidanloo	2010			preventive healthcare;sql injection;computer science;database;world wide web;computer security	Security	-57.36962207337141	58.828674219607755	152260
525fb146f7f73ba425bb7e806d1f9f9e9b9ad2e4	quantifying information flow for dynamic secrets	quantitative information flow;history;gain function;measurement;probabilistic programming language information flow dynamic secrets information leakage probabilistic systems interactive systems;vulnerability;automata;probabilistic logic history measurement context adaptation models security automata;dynamic secret;probabilistic programming;vulnerability dynamic secret quantitative information flow probabilistic programming gain function;probabilistic logic;adaptation models;security;context;probability cryptography high level languages interactive systems	A metric is proposed for quantifying leakage of information about secrets and about how secrets change over time. The metric is used with a model of information flow for probabilistic, interactive systems with adaptive adversaries. The model and metric are implemented in a probabilistic programming language and used to analyze several examples. The analysis demonstrates that adaptivity increases information flow.	adversary (cryptography);approximation algorithm;authorization;best, worst and average case;case-based reasoning;diagram;dynamic secrets;game theory;information flow (information theory);information theory;interference (communication);misuse case;non-interference (security);programming language;section 508 amendment to the rehabilitation act of 1973;simulation;spectral leakage;time complexity	Piotr Mardziel;Mário S. Alvim;Michael W. Hicks;Michael R. Clarkson	2014	2014 IEEE Symposium on Security and Privacy	10.1109/SP.2014.41	vulnerability;computer science;information security;theoretical computer science;machine learning;data mining;automaton;probabilistic logic;computer security;measurement	Security	-55.124246691044114	52.155036032254124	152385
081247e854b61812d5a5f2879a6c7ff7df55e26a	poster: hidden in plain sight: a filesystem for data integrity and confidentiality		A filesystem capable of curtailing data theft and ensuring file integrity protection through deception is introduced and evaluated. The deceptive filesystem transparently creates multiple levels of stacking to protect the base filesystem and monitor file accesses, hide and redact sensitive files with baits, and inject decoys onto fake system views purveyed to untrusted subjects, all while maintaining a pristine state to legitimate processes. Our prototype implementation leverages a kernel hot-patch to seamlessly integrate the new filesystem module into live and existing environments. We demonstrate the utility of our approach with a use case on the nefarious Erebus ransomware. We also show that the filesystem adds no I/O overhead for legitimate users.	confidentiality;data integrity;data theft;input/output;overhead (computing);prototype;stacking	Anne Kohlbrenner;Frederico Araujo;Teryl Taylor;Marc Ph. Stoecklin	2017		10.1145/3133956.3138841	computer security;sight;internet privacy;data theft;deception;computer science;confidentiality;data integrity;ransomware	Security	-54.87312858443012	58.25408205702386	152440
0431aa6485840dff45710de29a565b45f572fc4b	commitment issues in delegation process	federated systems;delegation;commitment;access control;saml	Delegation is a powerful mechanism to provide flexi ble and dynamic access control decisions. Delegation is particularly useful in federated environments where multiple systems, with their own security autonomy, are connected under one common federation. Although man y delegation schemes have been studied, current model s do not seriously take into account the issue of delega tion commitment of the involved parties. In order to add ress this issue, this paper introduces a new mechanism t o help parties involved in the delegation process to expre ss commitment constraints, perform the commitments and track the committed actions. This mechanism looks a t two different aspects: pre-delegation commitment and po stdelegation commitment. In pre-delegation commitment , this mechanism enables the involved parties to expr ess the delegation constraints and address those constraint . The post-delegation commitment phase enables those part ies to inform the delegator and service providers how t he commitments are conducted. This mechanism utilises a modified SAML assertion structure to support the proposed delegation and constraint approach .	access control;expr;flexible-fuel vehicle;security assertion markup language	Quan Pham;Jason Reid;Adrian McCullagh;Ed Dawson	2008			delegation;computer science;access control;internet privacy;federated architecture;computer security	AI	-48.837935133556975	53.49214025612833	152456
63984cb03334bd7de06c993e5a71bb8dd49c5745	behavior analysis for safety and security in automotive systems	automotive security;security monitoring;predictive security analysis;security modeling and simulation;connected car;complex event processing;process discovery	The connection of automotive systems with other systems such as road-side units, other vehicles, and various servers in the Internet opens up new ways for attackers to remotely access safety relevant subsystems within connected cars. The security of connected cars and the whole vehicular ecosystem is thus of utmost importance for consumer trust and acceptance of this emerging technology. This paper describes an approach for on-board detection of unanticipated sequences of events in order to identify suspicious activities. The results show that this approach is fast enough for in-vehicle application at runtime. Several behavior models and synchronization strategies are analyzed in order to narrow down suspicious sequences of events to be sent in a privacy respecting way to a global security operations center for further in-depth analysis.	connected car;ecosystem;internet;on-board data handling;run time (program lifecycle phase);security operations center	Roland Rieke;Marc Seidemann;Elise Kengni Talla;Daniel Zelle;Bernhard Seeger	2017	2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)	10.1109/PDP.2017.67	computer security model;cloud computing security;simulation;security through obscurity;security information and event management;asset;computer science;complex event processing;operating system;database;security service;distributed computing;internet privacy;security testing;business process discovery;computer security;computer network	SE	-52.625240824569076	58.81416418482443	152474
b2ca498540a6001dd23146d9c8805839f2a5f557	understanding contention-based channels and using them for defense	intelligent eavesdropper contention based channels microarchitectural resources caches predictors information leak security domains defenses microarchitectural side channels information theory mathematical abstraction bucket model networking communication capacity microarchitectural covert channels performance counters aes hardware memory buses bandwidths measurement kvm based heavy weight virtualization light weight operating system level isolation channel capacities covert channel eavesdropping attacks static adversaries;security of data cache storage computer architecture information theory microprocessor chips;receivers microarchitecture synchronization clocks radiation detectors hardware probes	Microarchitectural resources such as caches and predictors can be used to leak information across security domains. Significant prior work has demonstrated attacks and defenses for specific types of such microarchitectural side and covert channels. In this paper, we introduce a general mathematical study of microarchitectural channels using information theory. Our conceptual contribution is a simple mathematical abstraction that captures the common characteristics of all microarchitectural channels. We call this the Bucket model and it reveals that microarchitectural channels are fundamentally different from side and covert channels in networking. We then quantify the communication capacity of several microarchitectural covert channels (including channels that rely on performance counters, AES hardware and memory buses) and measure bandwidths across both KVM based heavy-weight virtualization and light-weight operating-system level isolation. We demonstrate channel capacities that are orders of magnitude higher compared to what was previously considered possible. Finally, we introduce a novel way of detecting intelligent adversaries that try to hide while running covert channel eavesdropping attacks. Our method generalizes a prior detection scheme (that modeled static adversaries) by introducing noise that hides the detection process from an intelligent eavesdropper.	covert channel;eve;image noise;information theory;microarchitecture;operating system;sensor;third-party software component	Casen Hunger;Mikhail Kazdagli;Ankit Singh Rawat;Alexandros G. Dimakis;Sriram Vishwanath;Mohit Tiwari	2015	2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA)	10.1109/HPCA.2015.7056069	parallel computing;real-time computing;computer science;operating system;computer security;computer network	Arch	-54.42204002716686	56.609806435466794	152642
b09ccf2886d7b70ca6c40e11d403b6e6092fab83	interpreted formalisms for configurations		Imprecise and incomplete specification of system configurations threatens safety, security, functionality, and other critical system properties and uselessly enlarges the configuration spaces to be searched by configuration engineers and auto-tuners. To address these problems, this paper introduces interpreted formalisms based on real-world types for configurations. Configuration values are lifted to values of real-world types, which we formalize as subset types in Coq. Values of these types are dependent pairs whose components are values of underlying Coq types and proofs of additional properties about them. Real-world types both extend and further constrain machine-level configurations, enabling richer, proof-based checking of their consistency with real-world constraints. Tactic-based proof scripts are written once to automate the construction of proofs, if proofs exist, for configuration fields and whole configurations. Failures to prove reveal real-world type errors. Evaluation is based on a case study of combinatorial optimization of Hadoop performance by meta-heuristic search over Hadoop configurations spaces.	apache hadoop;combinatorial optimization;coq (software);critical system;heuristic;mathematical optimization	Chong Tang;Kevin J. Sullivan;Jian Xiang;Trent Weiss;Baishakhi Ray	2017	CoRR		discrete mathematics;mathematics;mathematical proof;combinatorial optimization;rotation formalisms in three dimensions;scripting language;critical system	PL	-52.361547954666726	47.692387942549985	152716
5981f7300f89fa0a2fe015260248aa02b2dca4f8	a static software birthmark based on use-define chains for detecting the theft of java programs	software;semantics preserving transformation software birthmark dataflow analysis use define chain;flow graphs;resilience;cryptography;software algorithms;switches;software java resilience flow graphs switches cryptography software algorithms;java	Software birthmarking is a new technique used to detect the theft of programs. In the technique, a software birthmark is the inherent invariable features of a program that can be used to identify the program. Some typical semantics-preserving transformations will have a significant impact on order and frequency of instructions in programs. By introducing dataflow analysis techniques, dependencies of instructions that define or use variables in programs are established. The relations between these instructions can reduce the effect of semantics-preserving transformations such as shuffle stack operation, add fake exception, change switch statements and encrypt string in SmokeScreen. Classes are compared by the optimal matching algorithm. Thus a novel method of software birthmarking based on use-define chains is presented.	algorithm;data-flow analysis;dataflow;encryption;java;malware;optimal matching;program comprehension;sensor;static program analysis	Xin Xie;Fenlin Liu;Bin Lu;Tao Zhao;Hanning Li	2011	Proceedings of the International Conference on Security and Cryptography		real-time computing;computer science;cryptography;backporting;theoretical computer science;software framework;software development;software construction;distributed computing;java;computer security;psychological resilience;software system	SE	-57.312399512371854	55.88153510635572	152978
8573b1270cda6ef748ba4721c72a50fb7fcb5d1b	iot privacy and security challenges for smart home environments	smart home;internet of things;cybersecurity	Often the Internet of Things (IoT) is considered as a single problem domain, with proposed solutions intended to be applied across a wide range of applications. However, the privacy and security needs of critical engineering infrastructure or sensitive commercial operations are very different to the needs of a domestic Smart Home environment. Additionally, the financial and human resources available to implement security and privacy vary greatly between application domains. In domestic environments, human issues may be as important as technical issues. After surveying existing solutions for enhancing IoT security, the paper identifies key future requirements for trusted Smart Home systems. A gateway architecture is selected as the most appropriate for resource-constrained devices, and for high system availability. Two key technologies to assist system auto-management are identified. Firstly, support for system auto-configuration will enhance system security. Secondly, the automatic update of system software and firmware is needed to maintain ongoing secure system operation.	application domain;auto-configuration;firmware;home automation;internet of things;privacy;problem domain;requirement;smart card	Huichen Lin;Neil W. Bergmann	2016	Information	10.3390/info7030044	computer science;internet privacy;world wide web;computer security;internet of things	Security	-49.618287803828444	59.6835852922303	153298
440174f658dee9b21d5d5d28ecf76302c136b17d	vam-aas: online cloud services security vulnerability analysis and mitigation-as-a-service	vulnerability mitigation;vulnerability analysis;swinburne;saas security	Cloud computing introduces a new paradigm shift in service delivery models. However, the potential benefits reaped from the adoption of this model are threatened by public accessibility of the cloud-hosted services and sharing of resources. This increases the possibility of malicious service attacks. Existing cloud platforms do not provide a means to validate the security of offered cloud services. Moreover, the public accessibility of cloud services increases the potential for exploitation of newly discovered vulnerabilities that usually take a long time to discover and to mitigate. We introduce VAM-aaS, Vulnerability Analysis and Mitigation as-a-service, as a novel, integrated, and online cloudbased security vulnerability analysis and mitigation service. VAM-aaS performs online service analysis to pinpoint new vulnerabilities and weaknesses. It then uses this information to generate security control configuration scripts to block these discovered security holes at runtime. Our approach is based on a new vulnerability signature and mitigation-actions specification approach. We introduce our approach, describe key implementation details, and describe an evaluation of our prototype on a set of .NET benchmark applications.	accessibility;antivirus software;benchmark (computing);cloud computing;itil;invariant (computer science);malware;object constraint language;online service provider;open-source software;plug-in (computing);programming paradigm;prototype;run time (program lifecycle phase);security controls;sensitivity and specificity;vulnerability (computing);web application	Mohamed Almorsy;John Grundy;Amani S. Ibrahim	2012		10.1007/978-3-642-35063-4_30	vulnerability management;cloud computing security;countermeasure;security through obscurity;security information and event management;vulnerability;responsible disclosure;computer science;vulnerability assessment;security service;internet privacy;world wide web;computer security	Security	-51.722911132821274	58.234995204432366	153433
d0fbeab5c580c58f41cae9759ed113946d0e919f	security operations centers for information security incident management	information security;information security monitoring;information security incidents;internet of things;security operations center	At present information security (IS) incidents have become not only more numerous and diverse but also more damaging and disruptive. Preventive controls based on the IS risk assessment results decrease the majority but not all the IS incidents. Therefore, an IS incident management system is necessary for rapidly detecting IS incidents, minimizing loss and destruction, mitigating the vulnerabilities that were exploited and restoring the Internet of Things infrastructure (IoTI), including its IT services. These systems can be implemented on the basis of a Security Operations Center (SOC). Based on the related works a survey of the existing SOCs, their mission and main functions is given. The SOCs' classification as well as the key indicators of IS incidents in IoTI are proposed. Some serious first-generation SOCs' limitations are defined. This analysis leads to the main area of further research launched by the author.	computer security incident management;digital rights management;information security;internet of things;risk assessment;security operations center;sensor;system on a chip	Natalia G. Miloslavskaya	2016	2016 IEEE 4th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2016.26	information security audit;cloud computing security;countermeasure;security management;problem management;security through obscurity;security information and event management;security convergence;human–computer interaction;covert channel;asset;computer science;threat;information security;security service;internet privacy;security testing;world wide web;computer security;internet of things;information security management;computer network	DB	-57.29835869464441	50.15839135740065	153572
4a1f97438a28ecf8cb08bf7b8752386c8ec6aa1c	on blockchain security and relevant attacks		The blockchain technology witnessed a wide adop­tion and a swift growth in recent years. This ingenious distributed peer-to-peer design attracted several businesses and solicited several communities beyond the financial market. There are also multiple use cases built around its ecosystem. However, this backbone introduced a lot of speculation and has been criticized by several researchers. Moreover, the lack of legislations perceived a lot of attention. In this paper, we are concerned in analyzing blockchain networks and their development, focusing on their security challenges. We took a holistic approach to cover the involved mechanisms and the limitations of Bitcoin, Ethereum and Hyperledger networks. We expose also numerous possible attacks and assess some countermeasures to dissuade vulnerabilities on the network. For occasion, we simulated the majority and the re-entrancy attacks. The purpose of this paper is to evaluate Blockchain security summarizing its current state. Thoroughly showing threatening flaws, we are not concerned with favoring any particular blockchain network.	bitcoin;countermeasure (computer);deep-level transient spectroscopy;ecosystem;ethereum;holism;internet backbone;malware;peer-to-peer;scalability;simulation;solidity;swift (programming language)	Joanna Moubarak;Eric Filiol;Maroun Chamoun	2018	2018 IEEE Middle East and North Africa Communications Conference (MENACOMM)	10.1109/MENACOMM.2018.8371010	computer security;financial market;speculation;multiple use;blockchain;business;vulnerability	Security	-61.13764206654132	57.639408566652	153618
719b537a23dbfa865da5debbde45bbfa2f75728a	state-based usage control enforcement with data flow tracking using system call interposition	performance measure;policy enforcement;state based usage control enforcement;system calls;data protection regulations state based usage control enforcement data flow tracking system call interposition data dissemination;system call interposition;authorisation;enforcement;information dissemination authorisation;sockets;data mining;control systems operating systems information security access control monitoring data security protection sockets measurement middleware;reference monitor;usage control;monitoring system;data flow tracking;information flow;operating system;enforcement usage control access control operating systems system calls reference monitor information flow;information dissemination;process control;writing;access control;data protection regulations;data flow;data protection;data dissemination;containers;data models;operating systems	Usage control generalizes access control to what happens to data in the future. We contribute to the enforcement of usage control requirements at the level of system calls by also taking into account data flow: Restrictions on the dissemination of data, for instance, as stipulated by data protection regulations, of course relate not to just one file containing the data, but likely to all copies of that file as well. In order to enforce the dissemination restrictions on all copies of the sensitive data item, we introduce a data flow model that tracks how the content of a file flows through the system (files, network sockets, main memory). By using this model, the existence of potential copies of the data is reflected in the state of the data flow model. This allows us to enforce the dissemination restrictions by relating to the state rather than all sequences of events that possibly yield copies. Generalizing this idea, we describe how usage control policies can be expressed in a related state-based manner. Finally, we present an implementation of the data flow model and state-based policy enforcement as well as first encouraging performance measurements.	access control;assembly language;computer data storage;data flow diagram;data item;dataflow architecture;high- and low-level;information privacy;network socket;overhead (computing);requirement;system call	Matús Harvan;Alexander Pretschner	2009	2009 Third International Conference on Network and System Security	10.1109/NSS.2009.51	data modeling;data flow diagram;real-time computing;information flow;computer science;access control;operating system;process control;database;data protection act 1998;authorization;writing;computer security;dissemination	DB	-52.60936115182725	53.89135395650918	153761
7c8e1ec50513ed4391777dbcd3088e49db90740a	a policy deployment model for the ponder language	distribution;enabling;distributed object management computer network management telecommunication security specification languages object oriented languages;distributed services;policy enforcement;information model;ponder language;object oriented language;information security;mixed policy environments;resource management;instantiation;structuring ideas;runtime;large scale networks;specification language;system security;disabling;policy language;policy deployment model;large scale;general purpose deployment model;object oriented system;object oriented;specification languages;unloading;policy based management;policy basic types policy deployment model ponder language security management large scale networks distributed services general purpose deployment model mixed policy environments object oriented system instantiation distribution enabling disabling unloading deletion policy enforcement agent domains run time support structuring ideas object oriented languages;computer network management;policy enforcement agent;distributed object management;telecommunication security;domains;run time support;object oriented modeling resource management runtime quality management educational institutions information security large scale systems computer network management data security specification languages;security;security policy;management;object oriented languages;object oriented modeling;policy basic types;quality management;management policy;large scale systems;deletion;data security	Policies are rules that govern the choices in behaviour of a system. Security policies define what actions are permitted or not permitted, for what or for whom, and under what conditions. Management policies define what actions need to be carried out when specific events occur within a system or what resources must be allocated under specific conditions. There is considerable interest in the use of policies for the security and management of large-scale networks and distributed services. Existing policy work has focussed on specification, information models and application-specific policy enforcement. We address the important goal of providing a general-purpose deployment model for policies that is independent of the underlying policy enforcement mechanisms and can be employed in mixed policy environments. In this paper, we present a deployment model that is object-oriented and addresses the instantiation, distribution and enabling of policies as well as the disabling, unloading and deletion of policies. The model defines objects for policies, for domains, and for policy enforcement agent and outlines the interactions needed between them. The model also caters for changes in the memberships of domains since such changes also effect policy enforcement. The model forms part of the runtime support for Ponder; a new policy language that combines structuring ideas from object-oriented languages with a common set of policy basic types.	general-purpose markup language;information model;instance (computer science);interaction;software deployment	Naranker Dulay;Emil C. Lupu;Morris Sloman;Nicodemos Damianou	2001		10.1109/INM.2001.918064	computer science;information security;policy analysis;database;object-oriented programming;computer security	PL	-49.39000998311957	50.519879668747926	153770
3aec3e3cb59b278a7179d0fda09d002a0ed08c53	exploiting sdn approach to tackle cloud computing security issues in the atc scenario		Cloud Computing has been receiving great attention in the last few years due to the benefits it provides in terms of flexibility, scalability, virtualization and service provision. Nevertheless, many companies remain reluctant to such a cutting-edge technology due to the serious security issues affecting virtualized environments, especially in critical application scenarios where high safety and dependability levels are required. This work is aimed at discussing and presenting the main security threats for cloud computing infrastructures, as well as proposing a novel architecture in charge of reacting to security attacks in Infrastructure as a Service platforms. The basic idea is to migrate the attacked virtual appliance and to reconfigure the network by means of Software Defined Networking approach. The paper presents the architecture we have in mind and that will be deployed and validated against a real world distributed Air Traffic Control system, for which missing dependability and security targets would result in huge business and human losses.	advanced transportation controller;cloud computing security;control system;dependability;scalability;software-defined networking;virtual appliance	Gabriella Carrozza;Vittorio Manetti;Antonio Marotta;Roberto Canonico;Stefano Avallone	2013		10.1007/978-3-642-38789-0_5	cloud computing security	Security	-49.80203682516927	56.060878069716225	153786
f18c437096024ecdeed2792c5eaf880793599a80	an improved semi-global alignment algorithm for masquerade detection		Masquerading is a security attack in which an intruder assumes the identity of a legitimate user. Semi-global alignment algorithm has been the best of known dynamic sequence alignment algorithm for detecting masqueraders. Though, the algorithm proves better than any other pairwise sequence alignment algorithms such as local and global alignment algorithms, however, the problem of false positive and false negative have not been reduced to the barest minimum. Many previous works on masquerade detection using sequence alignment have difficulty at choosing the scoring system on which the algorithms base their optimal scores on. Hence, they resolved to assuming (or picking) a set of scores which they referred to as a unique scoring function for their experiment. In this work, an improved semi-global alignment called Crosssemiglobal algorithm, is designed to improve the efficiency of masquerade detection. In the previous pair-wise algorithms, a fix value is always assumed as the gaps score. In Cross-semiglobal algorithm, the scoring function on which the algorithms based their scores is constructed from legitimate users’ sequence of commands. This principle was implemented using platform independent C/C++ framework. The designed was tested using a systematically generated ASCII coded sequence audit data from Windows and UNIX operating systems as simulations for standard non-intrusive and intrusion data. The result shows a reduction in false positive rate from 7.7% using semi-global alignment to 5.4% using cross-semiglobal. The detection efficiency was also improved by 7.7%.	algorithm;align (company);c++;global serializability;intrusion detection system;microsoft windows;operating system;plug-in (computing);scoring functions for docking;semiconductor industry;sensor;sequence alignment;simulation;unix	Adesina Simon Sodiya;Olusegun Folorunso;Saidat Adebukola Onashoga;Omoniyi Paul Ogunderu	2011	I. J. Network Security		computer science;theoretical computer science;data mining;world wide web	Comp.	-56.046143744546065	58.92779157313519	153888
59450e1829c06f204424838b1e663d6de013e9ec	intrusion detection through dynamic software measurement	software measurement;executive function;real time;software systems;intrusion detection;theoretical foundation	The thrust of this paper is to present a new real-time approach to detect aberrant modes of system behavior induced by abnormal and unauthorized system activities. The theoretical foundation for the research program is based on the study of the software internal behavior. As a software system is executing, it will express a set of its many functionalities as sequential events. Each of these functionalities has a characteristic set of modules that it will execute. In addition, these module sets will execute with clearly defined and measurable execution profiles. These profiles change as the executed functionalities change. Over time, the normal behavior of the system will be defined by profiles. An attempt to violate the security of the system will result in behavior that is outside the normal activity of the system and thus result in a perturbation in the normal profiles. We will show, through the real-time analysis of the Linux kernel, that we can detect very subtle shifts in the behavior of a system.	authorization;intrusion detection system;linux;real-time clock;real-time computing;software measurement;software system;thrust	Sebastian G. Elbaum;John C. Munson	1999			embedded system;real-time computing;computer science;computer security	SE	-57.86034490040332	53.85118378459337	153951
b245342cf6b1d06e2d080ca20ac0cfa9870f0970	automatically exploiting potential component leaks in android applications	androids;androids humanoid robots receivers smart phones malware mobile communication;potential component leaks;smart phones;receivers;automatic potential component leak exploitation android applications pcleaks tool intercomponent communication vulnerabilities icc vulnerabilities data flow analysis google play store pcleaksvalidator;humanoid robots;malware;mobile communication;pcleaks;data flow analysis;smart phones android operating system data flow analysis invasive software	We present PCLeaks, a tool based on inter-component communication (ICC) vulnerabilities to perform data-flow analysis on Android applications to find potential component leaks that could potentially be exploited by other components. To evaluate our approach, we run PCLeaks on 2000 apps randomly selected from the Google Play store. PCLeaks reports 986 potential component leaks in 185 apps. For each leak reported by PCLeaks, PCLeaksValidator automatically generates an Android app which tries to exploit the leak. By manually running a subset of the generated apps, we find that 75% of the reported leaks are exploitable leaks.	android;control flow graph;data-flow analysis;dataflow;inter-process communication;malware;memory leak;play store;randomness;taint checking	Li Li;Alexandre Bartel;Jacques Klein;Yves Le Traon	2014	2014 IEEE 13th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2014.50	embedded system;engineering;internet privacy;computer security	SE	-56.80051895016744	59.35414805268046	154480
0cadfd029b7aa4ca1be113338c56b50082e11cfa	cross-layer data-centric usage control		Usage control is concerned with what happens to data after access has been granted. In the literature, usage control models have been defined on the grounds of events that, somehow, are related to data. Within the system, data (e.g. “a picture”) may exist in form of different representations, possibly located at different layers of abstraction (e.g. a file, a set of pixels in a window, a Java object, a memory region, etc...). In order to protect data, one must observe and control the usage of all its different representations. This research proposes a usage control model and a language that capture the distinction between data and representations of data. In this framework, policies can constraint the usage of single representations (e.g., delete file1.jpg after thirty days) as well as all representations of the same data (e.g., if file2.jpg is a copy of file1.jpg, also delete file2.jpg), even at different layers of abstraction (e.g. if a process is rendering the content of file1.jpg in a window, close the window and kill the process). The core contribution of this work is the formalization and implementation of the first generic model that integrates usage control and cross-layer data flow tracking, and it is presented in the first part of this work. The second part addresses the problem of refining the precision of the framework by augmenting the data flow tracking component with additional information about the system. In particular, this dissertation analyzes three approaches that leverage, respectively, information about structure of data, amount of data and results from static information flow analysis. All the solution are formalized, implemented and evaluated, and represent the second major contribution of this work.	abstraction layer;control theory;data-flow analysis;dataflow;java;pixel	Enrico Lovat	2014			pixel;data mining;database;abstraction;specification language;database-centric architecture;java;computer science	SE	-52.617233625404154	53.66158759410739	154576
c84849a0822902947978f621a64781724059532a	dependability analysis of smart distribution grid architectures considering various failure modes		The future smart distribution grid will be consisting of new components and technologies with enhanced capability whose failure behaviour can not be determined with certainty. In studying the reliability of these distribution grids, it is important to look into various possible failure semantics of the new components and how would they possibly affect the reliability of the distribution grid. This paper aims to investigate/study how the various failure modes of the new components affect the reliability of distribution grids. The focus is on (limited to) reliability evaluation of the feeder protection function of next generation distribution grids considering omission and value type failure semantics. A generic and modular modeling framework based on a stochastic activity networks is used to model the distribution grid. An IEC61850 based automation/substation communication network (SCN) is considered. And, for illustration, different scenarios with different SCN architectures are investigated.		Tesfaye Amare;Bjarne E. Helvik	2018	2018 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2018.8571706	grid;automation;reliability engineering;telecommunications network;failure semantics;value type;modular design;circuit breaker;computer science;dependability	HPC	-54.91942553475294	46.6948949982387	154867
a39a02b6d5f18f96389b626c128dc0c89a226c77	divide and conquer - towards a notion of risk model encapsulation		The criticality of risk management is evident when considering the information society of today, and the emergence of Future Internet technologies such as Cloud services. Information systems and services become ever more complex, heterogeneous, dynamic and interoperable, and many different stakeholders increasingly rely on their availability and protection. Managing risks in such a setting is extremely challenging, and existing methods and techniques are often inadequate. A main difficulty is that the overall risk picture becomes too complex to understand without methodic and systematic techniques for how to decompose a large scale risk analysis into smaller parts. In this chapter we introduce a notion of risk model encapsulation to address this challenge. Encapsulation facilitates compositional risk analysis by hiding internal details of a risk model. This is achieved by defining a risk model interface that contains all and only the information that is needed for composing the individual risk models to derive the overall risk picture. The interface takes into account possible dependencies between the risk models. We outline a method for compositional risk analysis, and demonstrate the approach by using an example on information security from the petroleum industry.	bottom-up parsing;cloud computing;emergence;encapsulation (networking);financial risk modeling;future internet;heterogeneous computing;it risk management;information security;information system;interoperability;platform as a service;risk assessment;self-organized criticality;top-down and bottom-up design	Atle Refsdal;Øyvind Rideng;Bjørnar Solhaug;Ketil Stølen	2014		10.1007/978-3-319-07452-8_14	risk management tools;engineering;operations management;data mining;computer security	ML	-54.92017230306357	47.39769597818163	155022
43f89337e570f36686acdda3dcd0b7885a963557	amandroid: a precise and general inter-component data flow analysis framework for security vetting of android apps	security vetting;information leakage;android application;icc;points-to analysis;vulnerable app;malware;validation	We present a new approach to static analysis for security vetting of Android apps and a general framework called Amandroid. Amandroid determines points-to information for all objects in an Android app component in a flow and context-sensitive (user-configurable) way and performs data flow and data dependence analysis for the component. Amandroid also tracks inter-component communication activities. It can stitch the component-level information into the app-level information to perform intra-app or inter-app analysis. In this article, (a) we show that the aforementioned type of comprehensive app analysis is completely feasible in terms of computing resources with modern hardware, (b) we demonstrate that one can easily leverage the results from this general analysis to build various types of specialized security analyses—in many cases the amount of additional coding needed is around 100 lines of code, and (c) the result of those specialized analyses leveraging Amandroid is at least on par and often exceeds prior works designed for the specific problems, which we demonstrate by comparing Amandroid’s results with those of prior works whenever we can obtain the executable of those tools. Since Amandroid’s analysis directly handles inter-component control and data flows, it can be used to address security problems that result from interactions among multiple components from either the same or different apps. Amandroid’s analysis is sound in that it can provide assurance of the absence of the specified security problems in an app with well-specified and reasonable assumptions on Android runtime system and its library.	android;context-sensitive grammar;data dependency;data-flow analysis;dataflow;dependence analysis;emoticon;executable;image stitching;inter-process communication;interaction;runtime system;source lines of code;static program analysis	Fengguo Wei;Sankardas Roy;Xinming Ou;Robby	2014	ACM Trans. Priv. Secur.	10.1145/3183575	computer science;malware;internet privacy;world wide web;computer security	Security	-55.067500511508186	54.113341471492824	155088
5708078e73972ae9aca0ad6cacfef2fe7ea4f9f2	pcfire: towards provable preventative control-flow integrity enforcement for realistic embedded software	arm executables;program logic;proof assistant;control flow integrity;hol;interactive theorem proving	Control-Flow Integrity (CFI) is an important safety property of software, particularly in embedded and safety-critical systems, where CFI violations have led to patient deaths and can render cars remotely controllable by attackers. Previous techniques for CFI may reduce the robustness of embedded and safety-critical systems, as they handle CFI violations by stopping programs. In this work, we present PCFIRE, a preventative approach to CFI that prevents the root-causes of CFI violations to allow recovery, and enables programmers to specify robust recovery actions by providing CFI via source-code safety-checks. PCFIRE's CFI can be formally proved automatically, and supports realistic features of embedded software such as hardware and I/O access. We showcase PCFIRE by providing, and automatically proving, CFI for: benchmark programs, text utilities containing I/O, and embedded programs with sensor inputs and hardware outputs on the Raspberry Pi single-board computer.	arm architecture;benchmark (computing);compiler;control-flow integrity;embedded software;embedded system;input/output;programmer;provable security;raspberry pi 3 model b (latest version);single-board computer	Jiaqi Tan;Hui Jun Tay;Utsav Drolia;Rajeev Gandhi;Priya Narasimhan	2016	2016 International Conference on Embedded Software (EMSOFT)	10.1145/2968478.2968492	embedded system;real-time computing;computer science;theoretical computer science;operating system;software engineering;distributed computing;proof assistant;programming language	Embedded	-54.92854503956146	53.75283811626469	155187
14c2bff476fb2589f4dfcb4f4c87af7aa5317aee	a memory-deduplication side-channel attack to detect applications in co-resident virtual machines		Virtualization offers the possibility of hosting services of multiple customers on shared hardware. When more than one Virtual Machine (VM) run on the same host, memory deduplication can save physical memory by merging identical pages of the VMs. However, this comes at the cost of leaking information between VMs. Based on that, we propose a novel timing-based side-channel attack that allows to identify software versions running in co-resident VMs or on the host. Our attack tests for the existence of memory pages in co-resident VMs that are unique among all versions of the respective software. Our evaluation results indicate that with few repetitions of our attack we can precisely identify software versions within reasonable time frames.	binary file;computer data storage;data deduplication;executable;memory management;microsoft windows;openvms;operating system;page (computer memory);random-access memory;side-channel attack;software versioning;upstream (software development);virtual machine;vulnerability (computing)	Jens Lindemann;Mathias Fischer	2018		10.1145/3167132.3167151	virtualization;software;internet hosting service;side channel attack;software versioning;real-time computing;cloud computing;virtual machine;data deduplication;computer science	Security	-54.8190024253765	56.18814196908395	155210
698203753c10670de8d37ae147cce8ef84f88368	using aspect oriented programming to enforce privacy preserving communication in distributed systems		Unauthorized access to personal information represents one of the most important challenges faced by network application developers. The privacy-preserving concept has arisen from the usage of database resources, which sometimes leads to the sharing of personal identifying information (PII). Adding or updating privacy and security concerns in system applications represents a difficult task for system developers because they need to track all program code to detect where privacy and security methods should be inserted. At the same time, they have to define which piece of code needs to be applied for different privacy and security policies. All of these concerns accumulate in the problem of scattering and tangling of system software. A widely-suggested but under-used solution to these problems is that of Aspect Oriented Programming (AOP). This paper proposes a new system for enforcing privacy-preserving concepts in order to ensure safe communication between distributed system nodes through the use of AOP. The idea based on the use of a smart server node called a judgment node (JN) to deal with data forwarding between the distributed system's nodes. Cryptographic algorithms are adopted in this work as a tool controlled by the JN to ensure the integrity of the transmitted data. We will present a novel approach which divides the data into portions with each part encrypted depending on the key of the authorized node used to process it. We use AOP characteristics for dealing with all of these concerns through the addition and removal of code dynamically to ensure a high level of performance. We use AOP as a core tool to modularize the privacy and security concerns, and to increase the clarity, maintainability and reusability of system software.	algorithm;aspect-oriented programming;authorization;distributed computing;download;encryption;high-level programming language;johnson–nyquist noise;operand forwarding;personally identifiable information;privacy;server (computing)	A. A. Thulnoon;Brett Lempereur;Qi Shi;D. Al-Jumeily	2017		10.1145/3018896.3065828	maintainability;aspect-oriented programming;node (networking);computer science;encryption;personally identifiable information;security policy;system software;distributed computing;reusability	Security	-51.587533546627405	53.63134569215076	155425
9fd852a937fd0d9ae22ed5081c267d9174ed96b0	semantics of the password-capability system.	security model;secure computation;operational semantics;system security;computer viruses;efficient implementation;operating system	The increasing problems of hacking and computer viruses have demonstrated the need for more secure computer systems. Conventional operating systems such as Unix, Linux, and Windows have not proved very satisfactory in dealing with such security problems. The capability paradigm seems to offer scope for more flexible computer system security but suffered from various implementation disadvantages. Password-capabilities allow for efficient implementation and offer scope for many security benefits. The Password-Capability System provides a simple, compact probabilistic security model. The operational semantics of the system are presented here.	capability-based security;computer security;computer virus;linux;microsoft windows;operating system;operational semantics;password;programming paradigm;semantics (computer science);unix	Dan Mossop;Ronald Pose	2005			computer security model;computer science;theoretical computer science;database;security service;distributed computing	Security	-52.320098623813145	55.151567468839346	155481
89d2bc625848e028935efb56824f7188880d183d	end-to-end policy monitoring and enforcement for service-oriented architecture		A service-oriented architecture (SOA)-based application is composed of a number of distributed and loosely-coupled services which are interconnected to accomplish a more complex functionality. The main security challenge in SOA is that we cannot trust the participating services in a service composition to behave as expected all the time. Moreover, the chain of all services involved in an end-to-end invocation may not be visible to the clients. As a result, any violation of the client's policies could remain undetected. To address these challenges in SOA, we propose the following contributions. First, we propose a new end-to-end security architecture for SOA based on a dynamic composite trust model. To maintain the dynamic trust, we designed a trusted-third party service called trust manager component, which collects and processes feedbacks from the actual execution of services. Second, we developed an end-to-end inter-service policy monitoring and enforcement framework (PME framework), which is able to dynamically intercept the interactions between services at runtime and react to the potentially malicious activities according to the client's policies. Third, we design an intra-service policy monitoring and enforcement framework based on taint analysis mechanism to monitor the flow of information within services and detect and prevent information disclosure attacks. These two frameworks together can provide an end-to-end visibility and security in SOA. Finally, we have extensively studied the correctness and performance of the proposed security frameworks based on a realistic SOA case study in a cloud environment. All experimental studies validate that the practicality and effectiveness of the presented solutions.	client-side;computer security;correctness (computer science);end-to-end encryption;end-to-end principle;experiment;fault tolerance;high availability;interaction;multi-core processor;run time (program lifecycle phase);soa security;scalability;server-side;service composability principle;service-oriented architecture;taint checking;testbed;trusted third party;visual intercept	Mehdi Azarmi;Bharat K. Bhargava	2017	2017 IEEE 10th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2017.17	enterprise information security architecture;computer science;architecture;service-oriented architecture;taint checking;enforcement;cloud computing;computer security;end-to-end principle;oasis soa reference model;distributed computing	SE	-52.07896663529492	57.36315116821677	155482
28569bfa42ce7281da8093c7b9cbc24f4c1a090d	detection of malicious transactions in dbms	security of data transaction processing database management systems;database management systems;information infrastructure;database security;data access;database security malicious transaction detection dbms database management systems;data security protection information security authentication cryptography transaction databases intrusion detection database systems availability face detection;transaction processing;database management system;security of data;data security	A major difficulty faced by organizations is the protection of data against malicious access or corruption. Database management systems (DBMS) are a key component in the information infrastructure of most organizations and represent the ultimate layer in preventing unauthorized data accesses. Several mechanisms needed to protect data, such as authentication, user privileges, encryption, and auditing, have been implemented in commercial DBMS. However, typical database security mechanisms are not able to detect and handle many data security attacks. In fact, malicious transactions executed by unauthorized users that may gain access to the database by exploring system vulnerabilities and unauthorized database transactions executed by authorized users cannot be detected and stopped by typical security mechanisms. In this paper we propose a new mechanism for the detection of malicious transactions in DBMS. The paper presents a practical example of the implementation of the proposed mechanism in the Oracle 10g DBMS and evaluates the mechanism using the TPC-C benchmark.	authentication;authorization;benchmark (computing);data security;database security;database transaction;encryption;ibm tivoli storage productivity center;malware;vulnerability (computing)	Marco Vieira;Henrique Madeira	2005	11th Pacific Rim International Symposium on Dependable Computing (PRDC'05)	10.1109/PRDC.2005.31	information infrastructure;cloud computing security;data access;security information and event management;database transaction;transaction processing;rollback;database tuning;computer science;information security;data administration;database;security service;online transaction processing;data security;internet privacy;distributed database;computer security;database testing	DB	-48.84095771525528	60.206699304447326	155722
013fafcf27513ccb1d941f4afda698c43f802660	computer security training recommender for developers		Vulnerable code may cause security breaches in software systems resulting in loss of confidential data and financial losses for the organizations. Software developers must be given proper training to write secure code. Conventional training methods do not take the code written by the developers over time into account, which makes these training sessions less effective. We propose a Computer Security Training Recommender to help identify focused and narrow areas in which developers need training. The proposed recommender system leverages the power of static analysis techniques to suggest the most appropriate training topics for different software developers; moreover it utilizes public vulnerability repositories to suggest community accepted solutions to different security problems. This paper presents an architecture of the proposed recommender system and a proof-of-concept case study. We found that vulnerabilities, flagged in source code by static analysis tools, can be mapped to relevant articles in a vulnerability repository. Hence, the mitigation strategies given in such articles may be used as a resource to train individual software developers. Preliminary empirical evaluation shows that the proposed system is promising.	computer security;confidentiality;recommender system;software developer;software system;static program analysis;vulnerability (computing)	Muhammad Nadeem;Edward B. Allen;Byron J. Williams	2014			computer science;multimedia;world wide web	SE	-59.87942549899747	55.824706730074375	155741
2c556a0f3fea022c6f5aed2e9850a776cc28743f	a multilevel security model for a distributed object-oriented system	distributed system;security properties;multilevel systems object oriented modeling information security labeling communication system security data security runtime access control power system security computer networks;modelling possibilities;multilevel security model;information security;security of data distributed processing object oriented programming;distributed processing;distributed object oriented system;object oriented programming;runtime;multilevel systems;computer networks;information flow;distributed objects;security threats;object based distributed systems;security attacks;access control;object paradigm;modelling decisions;information flow security;security of data;object oriented modeling;multilevel security;labeling;power system security;modelling decisions multilevel security model distributed object oriented system security attacks object based distributed systems information flow security object paradigm security threats modelling possibilities security properties multilevel secure object model;multilevel secure object model;object model;communication system security;data security	multilevel security, information flow, object model It often suggested that distributed computing will be the major trend in computer systems during the next decade. However, distributed systems are vulnerable to a number of security attacks. In this paper we look at the security problems of object-based distributed systems, and propose a model based on labeling for multilevel security. The purpose of this model is to preserve the information flow security in a distributed object-oriented system.	computer security;distributed computing;distributed object;multilevel security;object-based language	Vijay Varadharajan;Stewart Black	1990		10.1109/CSAC.1990.143753	computer security model;labeling theory;security through obscurity;information flow;object model;security engineering;security convergence;covert channel;computer science;information security;access control;theoretical computer science;concrete security;information security standards;distributed computing;data security;object-oriented programming;security testing;computer security	Security	-53.01557609771833	50.264394749575395	155825
0c991d1897bf4c97cc6d6d6cc1333bf217f38c1c	formal modeling and analysis of a secure mobile-agent system	analytical models;simulation based analysis;security model;formal model;malicious platform attack detection;eeos;mobile agents;distributed computing;mobile agent technology;colored petri net model;object oriented programming;extended elementary object system eeos;formal method;theorem proving;mobile agent security;mobile agent system;client server;formal verification;security of data formal verification mobile agents object oriented programming petri nets;extended elementary object system;mutual authentication;mobile communication;colored petri net;mathematical model;eeos formal modeling secure mobile agent system distributed computing paradigm extended elementary object system object oriented technology petri nets malicious platform attack detection graphical formal method colored petri net model simulation based analysis;secure mobile agent system;distributed computing paradigm;object oriented technology;petri nets;mobile agent;mobility model;petri net;security;object oriented modeling security mobile agents protection earth observing system analytical models client server systems distributed computing area measurement petri nets;security of data;object oriented modeling;formal modeling;security extended elementary object system eeos formal method mobile agent petri nets;model simulation;graphical formal method	As a recently emerging distributed computing paradigm, mobile-agent technology attracts great interests because of its salient merits. However, it also brings significant security concerns, among which the security problems between a mobile agent and its platforms are of primary importance. While protecting a platform (platform or host security) can benefit from the security measures in a traditional client-server system, protecting a mobile agent (mobile-agent or code security) has not been met in traditional client-server systems and is a new area emerging with mobile-agent technology. Mobile-agent security is also believed to be the most difficult in the security areas of a mobile-agent system. Several methods are proposed to provide protection or detection mechanisms for mobile-agent security. However, many of them either lack an intuitive formal approach to formally model and analyze the system or lack security consideration for mobility - the most distinct characteristic of a mobile agent. In this paper, we extended the original elementary object system (EOS), which applies object-oriented technology to Petri nets, in several aspects because the original EOS cannot fully support the features of mobile-agent system and security modeling. Based on the extended EOS (EEOS), we developed a formal model for a generic secure mobile-agent system. This model supports not only strong mobility but also secure mobility of a mobile agent. Mutual authentication between a mobile agent and its hosting platform is accomplished in this model. Meanwhile, a security mechanism is presented for the detection of malicious platform attacks to mobile-agent code or execution flow during the mobile-agent execution. Using an intuitively graphical formal method to model, simulate, and analyze a secure mobile-agent system distinguishes this paper from other works on mobile-agent security. This paper also introduces how to translate our EEOS model to a colored Petri net (CPN) model and presents the simulation of a sample mobile-agent system model in Design/CPN. Different from the mathematical or theorem-proving analysis methods used by other mobile-agent system and mobility models, we used simulation-based analysis to verify several characteristics including boundedness, liveness, concurrence, and security of the system. Compared with other analysis methods, simulation-based analysis is generally more intuitive and more widely used in industry to solve real problems.	client–server model;coloured petri net;distributed computing;eos;formal language;formal methods;graphical user interface;liveness;mobile agent;mutual authentication;programming paradigm;server (computing);simulation	Lu Ma;Jeffrey J. P. Tsai	2008	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2007.909552	computer security model;security through obscurity;formal methods;covert channel;computer science;information security;theoretical computer science;distributed computing;distributed system security architecture;security testing;network access control;computer security;petri net	Security	-52.881517389221116	50.51825990248935	156108
1db14e3f10ab1456b1a97a62feeac5f126e4ca90	information leakage detection in distributed systems using software agents	distributed system;watermarking;covert channel attacks;kernel;colored linux;selected works;software agent;mobile agents;distributed processing;leak detection software agents information security tagging access control mechanical factors protection linux watermarking computerized monitoring;information laundering;information leakage detection;selinux;software agents;security mechanisms;covert channel;watermarking algorithms;monitoring;permission;security classification;bepress;linux;access control;mobile agent;distributed systems;mobile agent based approach;security;watermarking distributed processing mobile agents security of data;information leakage;mobile agent based approach information leakage detection distributed systems software agents covert channel attacks security mechanisms selinux information laundering colored linux watermarking algorithms security classification;security of data;operating systems	Covert channel attacks utilize shared resources to indirectly transmit sensitive information to unauthorized parties. Current security mechanisms such as SELinux rely on tagging the filesystem with access control properties. However, such mechanisms do not provide strong protection against information laundering via covert channels. Colored Linux [20], an extension to SELinux, utilizes watermarking algorithms to “color” the contents of each file with their respective security classification to enhance resistance to information laundering attacks. In this paper, we propose a mobile agent-based approach to automate the process of detecting and coloring receptive hosts' filesystems and monitoring the colored filesystem for instances of potential information leakage. Implementation details and execution results are included to illustrate the merits of the proposed approach.	access control;agent-based model;algorithm;authorization;covert channel;distributed computing;graph coloring;information leakage;information sensitivity;linux;mobile agent;selinux;sensor;software agent;spectral leakage	Yung-Chuan Lee;Stephen Bishop;Hamed Okhravi;Shahram Rahimi	2009	2009 IEEE Symposium on Intelligent Agents	10.1109/IA.2009.4927510	computer science;information security;software agent;operating system;internet privacy;world wide web;computer security;computer network	Security	-52.25789461431917	59.46775811373252	156118
6caf5259595bf5bb4825eac48a11861eb5e5eb86	security issues with bacnet value handling		Building automation systems, or building management systems, control services such as heating, airconditioning and security access in facilities. A common protocol used to transmit data regarding the status of components is BACnet. Unfortunately, whilst security is included in the BACnet standard, it is rarely implemented by vendors of building automation systems. This lack of attention to security can lead to vulnerabilities in the protocol being exploited with the result that the systems and the buildings they control can be compromised. This paper describes a proof-of-concept protocol attack on a BACnet system and examines the potential of modeling the basis of the attack.	addendum;adversary (cryptography);adversary model;authentication;bacnet;city of heroes;experiment;formal proof;testbed;tracing (software);vulnerability (computing);while	Matthew Peacock;Michael N. Johnstone;Craig Valli	2017		10.5220/0006263405460552	computer security;building automation;computer science;bacnet	Security	-51.11789538505953	57.056039011449236	156146
eb5862393362224b7c5eabc8f4a4a0f70dd55b80	largen: automatic signature generation for malwares using latent dirichlet allocation	system design implementation intrusion detection system automated threat rule generation latent dirichlet allocation;malware security resource management context internet protocols semantics	As the quantity and complexity of network threats grow, Intrusion Detection Systems (IDSs) have become critical for securing networks. Achieving computer network intrusion detection with these IDSs requires high-level information technology and security expertise because malicious traffic has to be rigorously analyzed and the appropriate IDS rules written to effectively detect vulnerabilities that may potentially be exploited. However, incorrect IDS rules may produce numerous false positives, thereby degrading the performance of the IDS, and even worse, paralyzing the network. In this paper, we present a novel approach that exploits the Latent Dirichle Allocation (LDA) algorithm to generate IDS rules. Our proposed method, called LDA-based Automatic Rule  Generation (LARGen), automatically performs an analysis of the malicious traffic and extracts the appropriate attack signatures that will be used for IDS rules. LARGen first extracts multiple signature strings embedded in network flows. Then, the flows are classified based on the extracted signature strings, and key content strings for malicious traffic are identified through the LDA inferential topic model. Those key content strings are the core of an IDS rule that can detect malicious traffic. We study the effectiveness of LDA in the context of network attack signature generation via extensive experiments with real network trace data, consisting of both benign and malicious traffic. Experimental results confirm that threat rules generated from LARGen accurately detect every cyber attack with high accuracy.	algorithm;antivirus software;embedded system;experiment;high- and low-level;inferential programming;intrusion detection system;latent dirichlet allocation;linear discriminant analysis;malware;topic model	Suchul Lee;Sungho Kim;Sungil Lee;Jaehyuk Choi;Hanjun Yoon;Dohoon Lee;Jun-Rak Lee	2018	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2016.2609907	latent dirichlet allocation;computer science;topic model;cyber-attack;flow network;malware;false positive paradox;data mining;intrusion detection system;exploit	Security	-59.70863100078576	60.35152557317209	156299
5dfd647f9a012e484639fc9b8bea07f11af602f1	proactive insider-threat detection - against confidentiality in sensitive pervasive applications	monitoring;insider threats	The primary objective of this research is to mitigate insider threats against sensitive information stored in an organization’s computer system, using dynamic forensic mechanisms to detect insiders’ malicious activities. Among various types of insider threats, which may break confidentiality, integrity, or availability, this research is focused on the violations of confidentiality with privilege misuse or escalation in sensitive applications. We identify insider-threat scenarios and then describe how to detect each threat scenario by analyzing the primitive user activities, we implement our detection mechanisms by extending the capabilities of existing software packages. Since our approach can proactively detect the insider’s malicious behaviors before the malicious action is finished, we can prevent the possible damage proactively. In this particular paper the primary sources for our implementation are from the Windows file system activities, the Windows Registry, the Windows Clipboard system, and printer event logs and reports. However, we believe our approaches for countering insider threats can be also applied to other computing environments.	computer;confidentiality;cyber insider threat;information sensitivity;malware;microsoft windows;pervasive informatics;primary source;printer (computing);privilege escalation	Joon Sung Park;Jaeho Yim;Jason Hallahan	2009		10.5220/0002004203930398	computer science;internet privacy;computer security;computer network	Security	-53.20302384942891	57.69984650785855	156449
a9503cf2e1354965618ee929bacab37ea4763169	testing android malware detectors against code obfuscation: a systematization of knowledge and unified methodology		The authors of mobile-malware have started to leverage program protection techniques to circumvent anti-viruses, or simply hinder reverse engineering. In response to the diffusion of anti-virus applications, several researches have proposed a plethora of analyses and approaches to highlight their limitations when malware authors employ program-protection techniques. An important contribution of this work is a systematization of the state of the art of anti-virus apps, comparing the existing approaches and providing a detailed analysis of their pros and cons. As a result of our systematization, we notice the lack of openness and reproducibility that, in our opinion, are crucial for any analysis methodology. Following this observation, the second contribution of this work is an open, reproducible, rigorous methodology to assess the effectiveness of mobile anti-virus tools against code-transformation attacks. Our unified workflow, released in the form of an open-source prototype, comprises a comprehensive set of obfuscation operators. It is intended to be used by anti-virus developers and vendors to test the resilience of their products against a large dataset of malware samples and obfuscations, and to obtain insights on how to improve their products with respect to particular classes of code-transformation attacks.	antivirus software;malware;obfuscation (software);open-source software;openness;prototype;reverse engineering;sensor	Mila Dalla Preda;Federico Maggi	2016	Journal of Computer Virology and Hacking Techniques	10.1007/s11416-016-0282-2	simulation;engineering;data mining;computer security	Security	-60.72146324085345	56.479357445533815	156867
a8dc128b355d08141088462ddbdf8d589602b172	introducing abuse frames for analysing security requirements	data privacy formal specification security of data systems analysis formal verification computer crime;formal specification;computer crime;formal verification;data privacy;systems analysis;security requirements;data privacy abuse frames system security requirement analysis jackson problem frames security vulnerability malicious user;problem frame;security of data;information security computer security design engineering protection computer science mission critical systems internet automation systems engineering and theory engineering management	We are developing an approach using Jackson's Problem Frames to analyse security problems in order to determine security vulnerabilities. We introduce the notion of an anti-requirement as the requirement of a malicious user that can subvert an existing requirement. We incorporate anti-requirements into so-called abuse frames to represent the notion of a security threat imposed by malicious users in a particular problem context. We suggest how abuse frames can provide a means for bounding the scope of security problems in order to analyse security threats and derive security requirements.	jackson;problem frames approach;requirement;security hacker;vulnerability (computing)	Luncheng Lin;Bashar Nuseibeh;Darrel C. Ince;Michael Jackson;Jonathan D. Moffett	2003		10.1109/ICRE.2003.1232791	software security assurance;computer security model;cloud computing security;systems analysis;countermeasure;security through obscurity;security information and event management;security engineering;security convergence;information privacy;covert channel;formal verification;asset;security bug;computer science;information security;logical security;formal specification;security service;data security;internet privacy;security analysis;programming language;security testing;network security policy;world wide web;computer security	Security	-55.512922855541476	48.36379867555105	156911
7fbf236ce1f143cc5cffa12735c423f7a93271c0	open problems in robotic anomaly detection		Failures in robotics can have disastrous consequences that worsen rapidly over time. This, the ability to rely on robotic systems, depends on our ability to monitor them and intercede when necessary, manually or autonomously. Prior work in this area surveys intrusion detection and security challenges in robotics, but a discussion of the more general anomaly detection problems is lacking. As such, we provide a brief insight-focused discussion and frameworks of thought on some compelling open problems with anomaly detection in robotic systems. Namely, we discuss non-malicious faults, invalid data, intentional anomalous behavior, hierarchical anomaly detection, distribution of computation, and anomaly correction on the fly. We demonstrate the need for additional work in these areas by providing a case study which examines the limitations of implementing a basic anomaly detection (AD) system in the Robot Operating System (ROS) 2 middleware. Showing that if even supporting a basic system is a significant hurdle, the path to more complex and advanced AD systems is even more problematic. We discuss these ROS 2 platform limitations to support solutions in robotic anomaly detection and provide recommendations to address the issues discovered.	anomaly detection;autonomous robot;autonomous system (internet);autonomy;computation;edge case;intrusion detection system;middleware;on the fly;point of interest;report;robot operating system;trustworthy computing	Ritwik Gupta;Zachary T. Kurtz;Sebastian Scherer;Jonathon M. Smereka	2018	CoRR		control engineering;engineering;anomaly detection;on the fly;computation;invalid data;robot;intrusion detection system;middleware;robotics;distributed computing;artificial intelligence	AI	-51.49799393731416	46.622243238749085	156963
7c220df2ed4118d0df9a038b86049da0e4a37492	in-execution malware detection using task structures of linux processes	program diagnostics;kernel;low level system specific feature in execution malware detection linux process process kernel structure run time analysis executing program behavior process classification malicious process benign process processing overhead operating system kernel linux kernel module time series analysis linux task structure;training;time series invasive software linux operating system kernels program diagnostics task analysis;time series;proof of concept;accuracy;operating system;malware;time series analysis;malware kernel time series analysis accuracy training linux feature extraction;feature extraction;task analysis;timing analysis;invasive software;linux;operating system kernels;malware detection	In this paper, we present a novel framework -- it uses the information in kernel structures of a process -- to do run-time analysis of the behavior of an executing program. Our analysis shows that classifying a process as malicious or benign -- using the information in kernel structures of a process -- is not only very accurate but also has very low processing overheads; as a result, this lightweight framework can be incorporated within operating system kernel. To provide a proof-of-concept of our thesis, we design and implement our system as a kernel module in Linux. We perform the time series analysis of 118 parameters of Linux task structures and pre-process them to come up with a minimal features' set of 11 features. Our analysis show that these features have remarkably different values for benign and malicious processes; as a result, a number of classifiers operating on these features provide 93% detection accuracy with 0% false alarm rate within 100 milliseconds. Last but not the least, we justify that it is very difficult for a crafty attacker to evade these low-level system specific features.	analysis of algorithms;embedded system;high- and low-level;kernel (operating system);linux;loadable kernel module;malware;operating system;preprocessor;statistical classification;superuser;time series	Farrukh Shahzad;Sohail Bhatti;Muhammad Shahzad;Muddassar Farooq	2011	2011 IEEE International Conference on Communications (ICC)	10.1109/icc.2011.5963012	embedded system;real-time computing;computer science;operating system;time series;statistics	Embedded	-59.594906696578	58.7861978954482	157050
3b06b5f9088e25d64ecf0f0223846b850aced283	a comparison of trusted x security policies, architectures, and interoperability	software reliability graphical user interfaces open systems security of data;trusted computing;system evaluation;graphical user interfaces;x window system;open systems;trusted computer systems evaluation criteria trusted x security policies interoperability x window system compartmented mode workstation security policies;security policy;software reliability;security of data;workstations security prototypes computer architecture electrical equipment industry displays keyboards mice protocols supercomputers;multilevel security	During the past several years, interest in architectures for multi-level secure versions of the X Window System (X) has grown dramatically, primarily in the Compartmented Mode Workstation (CM W ) community. The architectures and security policies implemented i n existing CMWs are similar to each other, although they differ in certain key details. Alternatives to the current approaches are being investigated. Most notably, a TRW-led team of researchers has designed and prototyped a trusted X implementation aimed a t the Trusted Computer Systems Evaluation Criteria (TCSEC) B3 level. The architecture and security policies adopted b y this implementation differ radically from those of al l the existing CMWs. One of X’s greatest achievements is that it provides seamless interoperability among all X implementations in a distributed heterogeneous environment. Unfortunately, the divergen,ce of security policies enforced b y trusted X implementations has virtually eliminated X interoperability among these systems. This paper surveys the architectures and security policies implemented in existing C M W s and the T R W prototype, identifies areas of commonality and divergence, and notes areas where interoperability can be achieved.	interoperability;multilevel security;prototype;seamless3d;trusted computer system evaluation criteria;workstation;x window system	Jeffrey Picciotto;Jeremy Epstein	1992		10.1109/CSAC.1992.228225	computer security model;cloud computing security;covert channel;computer science;security policy;logical security;operating system;trusted computing base;graphical user interface;database;security service;data security;distributed system security architecture;open system;trustworthy computing;world wide web;computer security;software quality	Security	-51.72572958605752	55.08027744566917	157137
2458d97c411bc0e9758d1d307facee221c2293f3	text-mining and pattern-matching based prediction models for detecting vulnerable files in web applications		The proliferation of technology has empowered the web applications. At the same time, the presences of Cross-Site Scripting (XSS) vulnerabilities in web applications have become a major concern for all. Despite the many current detection and prevention approaches, attackers are exploiting XSS vulnerabilities continuously and causing significant harm to the web users. In this paper, we formulate the detection of XSS vulnerabilities as a prediction model based classification problem. A novel approach based on text-mining and pattern-matching techniques is proposed to extract a set of features from source code files. The extracted features are used to build prediction models, which can discriminate the vulnerable code files from the benign ones. The efficiency of the developed models is evaluated on a publicly available labeled dataset that contains 9408 PHP labeled (i.e. safe, unsafe) source code files. The experimental results depict the superiority of the proposed approach over existing ones.	algorithm;cross-site scripting;document object model;feature extraction;machine learning;php;pattern matching;sql injection;sensor;software development process;software engineer;text mining;web application	Mukesh Kumar Gupta;Mahesh Chandra Govil;Girdhari Singh	2018	J. Web Eng.		data mining;predictive modelling;web application;pattern matching;computer science;text mining	SE	-58.019162278801616	59.39764211035361	157222
03718cfe7c14cca945ca930c86768b3032c9d7cf	evaluation of jif and joana as information flow analyzers in a model-driven approach		Checking for information leaks in real-world applications is a difficult task. IFlow is a model-driven approach which allows to develop information flow-secure applications using intuitive modeling guidelines. It supports the automatic generation of partial Java code while also providing the developer with the ability to formally verify complex information flow properties. To simplify the formal verification, we integrate an automatic Java application information flow analyzer, allowing to check simple noninterference properties. In this paper, we evaluate both Jif and Joana as such analyzers to determine the best suiting information flow control tool in the context of, but not limited to the IFlow approach.	information flow;jpeg;model-driven architecture	Kuzman Katkalov;Peter Fischer;Kurt Stenzel;Nina Moebius;Wolfgang Reif	2012		10.1007/978-3-642-35890-6_13	spectrum analyzer;theoretical computer science;information flow (information theory);java;formal verification;computer science	Arch	-52.769461891517786	49.18460263981395	157310
dab2287738537dbb36ae7cf13728771af1b50e89	malware analysis method using visualization of binary files	malware analysis;malware visualization;malware detection;malware similarity	Malware authors have been generating and disseminating malware variants through various ways, such as reusing modules or using automated malware generation tools. With the help of the malware generation techniques, the number of malware keeps increasing every year. Therefore, new malware analysis techniques are needed to reduce malware analysis overheads. Recently several malware visualization methods were proposed to help malware analysts. In this paper, we proposed a novel method to visually analyze malware by transforming malware binary information into image matrices. Our experimental results show that the image matrices of malware can effectively classify malware families.	binary file;malware analysis	Kyoung-Soo Han;Jae Hyun Lim;Eul Gyu Im	2013		10.1145/2513228.2513294	asprox botnet;cyber-collection;computer science;cryptovirology;internet privacy;world wide web;computer security	SE	-58.80378304784029	59.202624300305516	157533
67d76ed96dd2d99ed4b7c4ecf252d39a29acb480	automated verification of security chains in software-defined networks with synaptic		Software-defined networks provide new facilities for deploying security mechanisms dynamically. In particular, it is possible to build and adjust security chains to protect the infrastructures, by combining different security functions, such as firewalls, intrusion detection systems and services for preventing data leakage. It is important to ensure that these security chains, in view of their complexity and dynamics, are consistent and do not include security violations. We propose in this paper an automated strategy for supporting the verification of security chains in software-defined networks. It relies on an architecture integrating formal verification methods for checking both the control and data planes of these chains, before their deployment. We describe algorithms for translating specifications of security chains into formal models that can then be verified by SMT1 solving or model checking. Our solution is prototyped as a package, named Synaptic, built as an extension of the Frenetic family of SDN programming languages. The performances of our approach are evaluated through extensive experimentations based on the CVC4, veriT, and nuXmv checkers.	algorithm;automatic programming;complexity;control plane;experiment;firewall (computing);formal verification;forwarding plane;frenetic;interaction;intrusion detection system;markov chain;model checking;performance;programming language;prototype;response time (technology);satisfiability modulo theories;software deployment;software-defined networking;spectral leakage;synapse;synaptic package manager;verification and validation	Nicolas Schnepf;Remi Badonnel;Abdelkader Lahmadi;Stephan Merz	2017	2017 IEEE Conference on Network Softwarization (NetSoft)	10.1109/NETSOFT.2017.8004195	logical security;computer security model;security testing;theoretical computer science;formal methods;software security assurance;formal verification;network access control;computer science;distributed computing;security service	Security	-53.432784052379425	53.246711887928775	157935
17e977baa6694a93005e53f4b58850715a127fc5	challenges in cloud computing		Though cloud computing is considered mature for practical application, there is a need for more research. The identified challenges primarily concern client-cloud interaction and cloud interoperability. As to the former one, we highlight the needs of clients, contracting and legal aspects, and missing foundations as necessary fields of investigation. For the latter one clouds are considered to constitute repositories of services, so the challenge is to realize web-scale, service-oriented, distributed computing.	cloud computing	Klaus-Dieter Schewe;Károly Bósa;Harald Lampesberger;Ji Ma;Mariam Rady;Boris Vleju	2011	Scalable Computing: Practice and Experience		cloud computing security;computer science;data mining;utility computing;internet privacy;world wide web	HPC	-48.71539200253999	55.55925602042823	157945
8eba199ea6f5249f3021f17c61c253f50227782c	wasp: protecting web applications using positive tainting and syntax-aware evaluation	databases;security and protection;syntax aware evaluation;computer society;web based attacks;performance evaluation;web application sql injection preventer wasp positive tainting syntax aware evaluation software systems internet web based attacks;information security;security and protection protection mechanisms;application software;sql;protection mechanisms;software systems;runtime;positive tainting;protection;protection databases application software computer society internet runtime data security information security software systems performance evaluation;wasp;internet;web application sql injection preventer;sql injection;runtime monitoring;false positive;security;empirical evaluation;security of data;sql internet security of data;dynamic tainting;data security	Many software systems have evolved to include a Web-based component that makes them available to the public via the Internet and can expose them to a variety of Web-based attacks. One of these attacks is SQL injection, which can give attackers unrestricted access to the databases that underlie Web applications and has become increasingly frequent and serious. This paper presents a new highly automated approach for protecting Web applications against SQL injection that has both conceptual and practical advantages over most existing techniques. From a conceptual standpoint, the approach is based on the novel idea of positive tainting and on the concept of syntax-aware evaluation. From a practical standpoint, our technique is precise and efficient, has minimal deployment requirements, and incurs a negligible performance overhead in most cases. We have implemented our techniques in the Web application SQL-injection preventer (WASP) tool, which we used to perform an empirical evaluation on a wide range of Web applications that we subjected to a large and varied set of attacks and legitimate accesses. WASP was able to stop all of the otherwise successful attacks and did not generate any false positives.	database;internet;overhead (computing);requirement;sql injection;software deployment;software system;web application;world wide web	William G. J. Halfond;Alessandro Orso;Panagiotis Manolios	2008	IEEE Transactions on Software Engineering	10.1109/TSE.2007.70748	sql;application software;the internet;sql injection;type i and type ii errors;computer science;information security;operating system;database;data security;world wide web;computer security;software system	SE	-57.33643990967985	57.66103339670956	158069
5e92e32002fa1383ce4bc2702d25050e93b43768	formally secure compilation of unsafe low-level components (extended abstract)		We propose a new formal criterion for secure compilation, providing strong security guarantees for components written in unsafe, low-level languages with C-style undefined behavior. Our criterion goes beyond recent proposals, which protect the trace properties of a single component against an adversarial context, to model dynamic compromise in a system of mutually distrustful components. Each component is protected from all the others until it receives an input that triggers an undefined behavior, causing it to become compromised and attack the remaining uncompromised components. To illustrate this model, we demonstrate a secure compilation chain for an unsafe language with buffers, procedures, and components, compiled to a simple RISC abstract machine with built-in compartmentalization. The protection guarantees offered by this abstract machine can be achieved at the machine-code level using either software fault isolation or tag-based reference monitoring. We are working on machine-checked proofs showing that this compiler satisfies our secure compilation criterion.	abstract machine;adversary (cryptography);compiler;fault detection and isolation;high- and low-level;machine code;network compartment;sandbox (computer security);tag system;undefined behavior	Guglielmo Fachini;Catalin Hritcu;Marco Stronati;Ana Nora Evans;Théo Laurent;Arthur Azevedo de Amorim;Benjamin C. Pierce;Andrew Tolmach	2017	CoRR		abstract machine;compiler;theoretical computer science;mathematical proof;software;adversarial system;computer science;distributed computing;undefined behavior;fault detection and isolation;compromise	Security	-54.49613525558745	53.63286019941496	158365
806cff343d76cc5e0d8cbfcad780b53d149d4f87	provenance-based auditing of private data use	legislation;data processing;good practice;law enforcement;private data;provenance;data protection;audit;data protection act	Across the world, organizations are required to comply with regulatory frameworks dictating how to manage personal information. Despite these, several cases of data leaks and exposition of private data to unauthorized recipients have been publicly and widely advertised. For authorities and system administrators to check compliance to regulations, auditing of private data processing becomes crucial in IT systems. Finding the origin of some data, determining how some data is being used, checking that the processing of some data is compatible with the purpose for which the data was captured are typical functionality that an auditing capability should support, but difficult to implement in a reusable manner. Such questions are so-called provenance questions, where provenance is defined as the process that led to some data being produced. The aim of this paper is to articulate how data provenance can be used as the underpinning approach of an auditing capability in IT systems. We present a case study based on requirements of the Data Protection Act and an application that audits the processing of private data, which we apply to an example manipulating private data in a university.	authorization;data protection act 1998;data protection act, 2012;information privacy;personally identifiable information;requirement;system administrator	Rocío Aldeco-Pérez;Luc Moreau	2008			data governance;data quality;engineering;data mining;database;data protection act 1998;computer security;machine-readable data	DB	-50.831393012969926	52.48951342817052	158418
ccb94cebe0a07a6a3b5516dffc95fcb34b652f1f	recovery of data integrity under multi-tier architectures	concurrency control restrictions;graph theory;data integrity;database transaction level;transaction processing data integrity database management systems graph theory security of data software architecture;database management systems;multilayer dependency graph data integrity recovery multitier service architecture database transaction level concurrency control restrictions attack recovery problem;multitier service architecture;software architecture;attack recovery problem;multilayer dependency graph;data integrity recovery;transaction processing;security of data	Recovery from attacks has been extensively studied at the database transaction level and the application level in recent years. To recover compromised database transactions, compensating and redoing the compromised database transactions need to be conducted under the concurrency control restrictions. Under a multi-tier service architecture, at the application level, attack recovery has more restrictions introduced by either control dependencies among application activities or application specifications. Thus, the multi-tier service architecture introduces more challenges to the attack recovery problem. In this study, the authors describe the recovery problems with a multi-layer dependency graph (MLDG). They also describe the techniques of damage assessment and recovery based on an MLDG.	concurrency (computer science);concurrency control;data integrity;database transaction;dependence analysis;layer (electronics);multitier architecture	Meng Yu;Wanyu Zang;Peng Liu	2010	IET Information Security	10.1049/iet-ifs.2009.0264	software architecture;database transaction;transaction processing;rollback;distributed transaction;computer science;graph theory;data integrity;database;distributed computing;online transaction processing;serializability;computer security;transaction processing system	DB	-52.981657000681764	49.96464967396429	158422
b98255c593833149b6833697cef9ff0b142b459b	an empirical study on the correctness of formally verified distributed systems		Recent advances in formal verification techniques enabled the implementation of distributed systems with machine-checked proofs. While results are encouraging, the importance of distributed systems warrants a large scale evaluation of the results and verification practices.  This paper thoroughly analyzes three state-of-the-art, formally verified implementations of distributed systems: Iron-Fleet, Verdi, and Chapar. Through code review and testing, we found a total of 16 bugs, many of which produce serious consequences, including crashing servers, returning incorrect results to clients, and invalidating verification guarantees. These bugs were caused by violations of a wide-range of assumptions on which the verified components relied. Our results revealed that these assumptions referred to a small fraction of the trusted computing base, mostly at the interface of verified and unverified components. Based on our observations, we have built a testing toolkit called PK, which focuses on testing these parts and is able to automate the detection of 13 (out of 16) bugs.	adversary (cryptography);binary file;cache (computing);causal consistency;correctness (computer science);distributed computing;exception handling;fail-safe;formal verification;linearizability;programmer;public-key cryptography;safety engineering;sanity check;software bug;solver;test case;toolchain;trusted computing base;verification and validation;z3 (computer)	Pedro Fonseca;Kaiyuan Zhang;Xi Wang;Arvind Krishnamurthy	2017		10.1145/3064176.3064183	theoretical computer science;distributed computing;programming language	OS	-58.76863806874265	56.40283940265587	158758
2048844248e727e55ed522abaf49191fbf9301f8	modelling the security of smart cards by hard and soft types for higher-order mobile embedded resources	smart card;linear types;higher order;process calculus;smart cards;intuitionistic logic;higher order process passing;nested locations;copyable and non copyable resources;security;embedded software;type system	We provide a type system inspired by affine intuitionistic logic for the calculus of Higher-Order Mobile Embedded Resources (Homer), resulting in the first process calculus combining affine linear (non-copyable) and non-linear (copyable) higher-order mobile processes, nested locations, and local names. The type system guarantees that linear resources are neither copied nor embedded in non-linear resources during computation. We exemplify the use of the calculus by modelling a simplistic e-cash Smart Card system, the security of which depends on the interplay between (linear) mobile hardware, embedded (non-linear) mobile processes, and local names. A purely linear calculus would not be able to express that embedded software processes may be copied. Conversely, a purely non-linear calculus would not be able to express that mobile hardware processes cannot be copied.	ambient calculus;computation;computer hardware;congruence of squares;effect system;embedded software;embedded system;exemplification;intuitionistic logic;mobile agent;mobile computing;mobile security;nonlinear system;process calculus;smart card;substructural type system;type system;ubiquitous computing	Mikkel Bundgaard;Thomas T. Hildebrandt;Jens Chr. Godskesen	2007	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2007.09.011	smart card;real-time computing;computer science;information security;theoretical computer science;distributed computing;programming language	PL	-53.099511655506966	50.99123134124586	158807
20d6d5fd6da7ae91b8ffca6b130f9ff54a7030b3	e-commerce authentication: an effective countermeasures design model	authentication;security;electronic commerce;requirements analysis;secure electronic transactions set;user requirements;satisfiability;life cycle;requirement analysis;e commerce	Existing authentication models for e-commerce systems take into account satisfying legitimate user requirements described in security standards. Yet, the process of introducing countermeasures to block malicious user requirements is ad hoc and relies completely on the security designer expertise. This leads to expensive implementation life cycles if defects related to the design model were discovered during the system-testing phase. In this paper, we describe an authentication countermeasures design model for ecommerce systems. This model includes effective countermeasures against all known malicious user requirements and attacks. The described model is preventive in nature and can be used with other authentication models or can be implemented as a stand-alone module for e-commerce systems.	access control;authentication;authorization;common object request broker architecture;countermeasure (computer);e-commerce;flowchart;high- and low-level;hoc (programming language);malware;requirement;security hacker;system testing;systems design;user requirements document	Victor D. Sawma;Robert L. Probert	2003			e-commerce;user requirements document;computer science;secure electronic transaction;computer security;authentication;countermeasure;requirements analysis	Security	-54.907983538336374	49.04131972961552	159107
98ea1d7bffd6ab4ac199e57d6a2d4b9694e4a793	tzslicer: security-aware dynamic program slicing for hardware isolation		To address security issues related to information leakage, microprocessor designers and manufacturers such as ARM and Intel have introduced hardware isolation-based technologies to support secure software execution. However, utilizing such technologies often requires significant efforts to design new applications or refactor existing applications to adhere to the usage protocols. Developers also need to clearly distinguish code sections that can manipulate sensitive data and relocate them to the secure execution environment. These processes can be laborious and error-prone, since over-protection can result in poor application performance and high resource usage, and under-protection may cause exploitable security vulnerabilities. In this paper, we introduce TZSlicer, a framework to automatically identify code that must be protected based on a sensitive variable list provided by developers. TZSlicer automatically identifies code sections that can process sensitive data, extracts those sections from the original program, and creates harness in the original and extracted code sections so that they can interface with each other. We develop a prototype of TZSlicer to support slicing of C programs at function, code block, and code line levels. Also, we identify optimization opportunities to improve the context switching overhead of TZSlicer via applying loop unrolling and variable renaming. We evaluate TZSlicer using seven real-world programs, and the evaluation results indicate that TZSlicer is effective in protecting sensitive data without incurring significant runtime and resource usage overheads.	arm architecture;block (programming);code refactoring;cognitive dimensions of notations;context switch;information leakage;loop unrolling;mathematical optimization;microprocessor;overhead (computing);program slicing;prototype;spectral leakage;vulnerability (computing)	Mengmei Ye;Jonathan Sherman;Witawas Srisa-an;Sheng Wei	2018	2018 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)	10.1109/HST.2018.8383886	context switch;loop unrolling;computer hardware;program slicing;real-time computing;information leakage;code refactoring;software;slicing;computer science;overhead (business)	Arch	-54.95705292402149	55.962955382150696	159124
ebba428745e6a22fec625355a656ea2b0eb30b1a	secure mobile software development with vulnerability detectors in static code analysis		The security threats to mobile application are growing explosively. Mobile app flaws and security defects could open doors for hackers to easily attack mobile apps. Secure software development must be addressed earlier in the development lifecycle rather than fixing the security holes after attacking. Early eliminating against possible security vulnerability will help us increase the security of our software, and militate the consequence of damages of data loss caused by potential malicious attacking. However, many software developer professionals lack the necessary security knowledge and skills at the development stage and Secure Mobile Software Development (SMSD) is not yet well represented in current computing curriculum. In this paper we present a static security analysis approach with open source FindSecurityBugs plugin for Android Studio IDE. We categorized the common mobile vulnerability for developers based on OWASP mobile security recommendations and developed detectors to meet the SMSD needs in industry and education.	android studio;categorization;hands-on computing;ibm notes;malware;mobile app;mobile security;open-source software;plug-in (computing);sensor;software developer;software development;software release life cycle;static program analysis;vulnerability (computing)	Xianyong Meng;Kai Qian;Dan Chia-Tien Lo;Prabir Bhattacharya;Fan Wu	2018	2018 International Symposium on Networks, Computers and Communications (ISNCC)	10.1109/ISNCC.2018.8531071	computer security;android (operating system);static program analysis;software;software development;security analysis;vulnerability (computing);sql injection;vulnerability;computer science	SE	-59.682165871345774	55.85360976773859	159139
1e9c24864a3496703bd76fd84d6e660319c0d441	monitoring and alarm management for system and network security a web-based comprehensive approach	network security	In this work we propose a computer platform that aims to unify the tasks of monitoring, diagnosing, error detection, alarm management and intrusion detection associated with the administration of a computer network and related critical services. As main objective, we intend to develop a user-intuitive program that does not require specialized computer skills from the operators in order to assume full responsibility for the system. Open-source solutions were used, whenever possible, namely for server operating systems, application development tools, database engine and integrated Web solution. The project started by studying the existing solutions, exploring their strengths and shortcomings and iteratively defining the specific requirements to be implemented. The development phase was conceptually divided in three different levels: the agents and connectors collecting the data from the different areas being monitored; the database engine, cataloguing the information and the Web Interface (Security Portal) that allows the management of all functionalities and guarantees the operationability of the solution. An alarm management tool should also be developed permitting, according to programmed warnings for certain malfunctions, trigger the warning messages through the pre-defined medium – E-Mail, SMS (short message service) or IM (instant messaging), using a Unified Messaging (UM) solution. According to the defined specifications, the solution to be implemented was designed and a functional analysis was created. Finally the projected solution was implemented and applied to a case study – the Department of Fisheries Inspection from the General-Directorate of Fisheries and Aquiculture. The preliminary results from the reliability and userfriendliness tests were very positive and a decision was made to move into the production phase. The platform was developed in line with current accessibility requirements and can be operated / consulted by users with disabilities.	accessibility;database engine;error detection and correction;instant messaging;intrusion detection system;network security;operating system;programming tool;requirement;server (computing);usability;web application;world wide web	João Afonso;Edmundo Monteiro;Carlos Ferreira	2005				DB	-62.82884009391644	57.57776891150238	159706
008e7949d50fb75c58b61c9d17daa86c1bc5c964	secure delegation for distributed object environments	application development;sdm;distributed objects;remote method invocation;distributed object environments;security policy;java	SDM is a Secure Delegation Model for Javabased distributed object environments. SDM extends current Java security features to support secure remote method invocations that may involve chains of delegated calls across distributed objects. The framework supports a control API for application developers to specify mechanisms and security policies surrounding simple or cascaded delegation. Delegation may also be disabled and optionally revoked. These policies may be controlled explicitly in application code, or implicitly via administrative tools.	application programming interface;distributed object;java remote method invocation	Nataraj Nagaratnam;Doug Lea	1998			real-time computing;computer science;database;distributed computing;distributed object	PL	-49.7372380080015	53.973297402051585	160109
c9efac82e4459d63877ae6435169eb4ae0dc6fb0	a conceptual model for computer security risk analysis	information systems;risk analysis;risk management;conceptual model;computer security;computer security risk analysis prototypes information systems protection risk management information analysis information security military computing accreditation;disclosure risk;information system;networked systems;security of data information systems risk management;anssr computer security risk analysis information systems disclosure risk analysis of networked systems security risks;security of data	Risk analysis is required by a number of organizations to provide a basis for deciding which safeguards to implement to protect information systems. A variety of risk analysis techniques and tools have been developed. Each technique or tool is based, implicitly or explicitly, on a conceptual model of risk. The high-level conceptual model of disclosure risk for information systems used in the Analysis of Networked Systems Security Risks (ANSSR) prototype is presented. >	computer security;it risk management	Deborah J. Bodeau	1992		10.1109/CSAC.1992.228233	computer security model;standard of good practice;certified information security manager;risk factor;security management;risk analysis;security information and event management;it risk management;security convergence;vulnerability;risk management;asset;threat;it risk;data mining;risk management information systems;risk analysis;security analysis;computer security;information system;information security management;factor analysis of information risk	Security	-55.18604905380767	49.178875820401856	160353
040345d71d3366d2d34e4f15646c40f76e922293	research on active controllable defense model based on zero-pdr model	databases;analytical models;network information security;personal computers;network information security problem solving;active controllable defense network information security pdr model zero pdr model;information security;personal computer;application software;information security protection data security computer security power system security application software databases computer science computer viruses humans;network security;application server;biological system modeling;trojan horses;unpredictable network security threat analysis;trojan attack active controllable defense model zero pdr model unpredictable network security threat analysis personal computers application servers classical pdr protection model network information security problem solving;computer security;protection;active controllable defense model;computer viruses;computational modeling;pdr model;zero pdr model;classical pdr protection model;active controllable defense;trojan attack;invasive software;humans;application servers;computer science;power system security;timing attack;modeling and analysis;data security	In the face of more and more complex and unpredictable network security threats, although an increasing number of security products have been deployed in personal computers, application servers and networks, we are still in a passive embarrassment. How to detect and response to network security threats immediately before threats occur or reach the target system is a key issue to solve current security threats. Based on further study of classical PDR protection model and analysis of current network security threats, idea of solving network information security problems is changed from passive protection to the active controllable defense, and Zero-PDR model based on Trojan attack characteristic is proposed. Active Controllable Defense model based on Zero-PDR model is further proposed, which can avoid Trojan attack and the first time attack effectively.	application server;design review (u.s. government);information security;network security;personal computer;threat (computer);trojan horse (computing);zero	Kehe Wu;Tong Zhang;Fei Chen	2010	2010 Third International Symposium on Intelligent Information Technology and Security Informatics	10.1109/IITSI.2010.140	simulation;security through obscurity;asset;engineering;internet privacy;computer security	Security	-61.23794928510003	59.64284453614596	160554
d141187e380d7dc0a743e58b0a31c942a4056930	security attack analysis using attack patterns	databases;software;object recognition;companies;servers companies security logic gates databases object recognition software;servers;logic gates;validation attack analysis attack pattern contextual goal model prototype;security;security of data;smart grid scenario security attack analysis socio technical systems stss software systems comprehensive attack knowledge repository security breaches capec attack patterns	Discovering potential attacks on a system is an essential step in engineering secure systems, as the identified attacks will determine essential security requirements. The prevalence of Socio-Technical Systems (STSs) makes attack analysis particularly challenging. These systems are composed of people and organizations, their software systems, as well as physical infrastructures. As such, a thorough attack analysis needs to consider strategic (social and organizational) aspects of the involved people and organizations, as well as technical aspects affecting software systems and the physical infrastructure, requiring a large amount of security knowledge which is difficult to acquire. In this paper, we propose a systematic approach to efficiently leverage a comprehensive attack knowledge repository (CAPEC) in order to identify realistic and detailed attack behaviors, avoiding severe repercussions of security breaches. In particular, we propose a systematic method to model CAPEC attack patterns, which has been applied to 102 patterns, in order to semi-automatically select and apply such patterns. Using the CAPEC patterns as part of a systematic and tool-supported process, we can efficiently operationalize attack strategies and identify realistic alternative attacks on an STS. We validate our proposal by performing a case study on a smart grid scenario.	attack model;attack patterns;holism;multistage amplifier;physical computing;prototype;requirement;run time (program lifecycle phase);semiconductor industry;sociotechnical system;software evolution;software system	Tong Li;Elda Paja;John Mylopoulos;Jennifer Horkoff;Kristian Beckers	2016	2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2016.7549303	countermeasure;logic gate;computer science;engineering;information security;operating system;cognitive neuroscience of visual object recognition;data mining;database;world wide web;computer security;server	Security	-56.74645856753883	49.58406433983684	160673
14f7749d089e5b083642d45f04aad5ffc3f00111	the evolution of information assurance	data integrity;information assurance;storage area networks business enterprises information assurance system administrators electronic information local area networks distributed architectures sans replication techniques;robotics and automation availability software design application software space technology containers hardware information retrieval computer errors time factors;security of data;data integrity security of data	M odern business enterprises realize that information is their most important asset. Its importance and ever-increasing volume have led enterprises to focus their attention on the container for this precious resource, namely storage, and on ensuring the availability and integrity of their information. The information assurance discipline integrates several techniques developed over many years for assuring the integrity and availability of stored information. At the highest level, information assurance consists of the following activities: • creating multiple copies of information; • migrating the copies between different storage types; • managing the consistency of these copies, especially in light of the intermittent connectivity between them; and • replacing the information in one copy with information taken from another. Techniques for achieving these ends encompass various aspects of system, hardware, and software design, as well as the development of function-specific applications. TIMELINE A temporal approach provides a structure for describing the increasing number of available information assurance techniques and the growth in their complexity—a trend that has paralleled the increasing importance of the information itself. Using a timeline helps to put information assurance's progress into perspective. The timeline presented here is divided into several eras based on the specific information assurance techniques employed, and it extends about five years into the future. No specific dates are associated with this timeline because it is not intended to be historically accurate. It does not imply that any specific technique is obsolete—in some variation, system administrators still use all these techniques. Mainframes This era covers the primitive data centers beloved of 1950s science fiction films, in which rows of reel-to-reel tape drives whirred and squealed as they processed information. In such systems, often the only method of information assurance involved copying information to and from the tape drives. This era saw the terms backup and restore coined for creating a copy and retrieving data from it, respectively. Usually, all system use ceased during the backup process, which meant system administrators tended to perform backups only at the beginning or end of the working day. Performing a restore could take hours or days, and it often required trial and error with several different tape volumes. This cumbersome and mostly manual process was subject to operator errors that were often discovered too late to prevent information loss. The storage industry provided tape for use in this process because it was more rugged, easier to transport and store …	backup and restore;computer hardware;data center;information assurance;mainframe computer;rugged computer;software design;system administrator;tape drive;timeline	Roger Cummings	2002	IEEE Computer	10.1109/MC.2002.1106181	software security assurance;information engineering;computer science;information security;operating system;software engineering;data integrity;data mining;database;automated information system;computer security;information security management;software quality analyst	DB	-60.08936984645987	49.29435407803894	161050
14e51709779527f9114d80f7ac0c8389933a547d	building a side channel based disassembler	side channel analysis;hidden markov model;prior knowledge;power consumption;embedded processor	For the last ten years, side channel research has focused on extracting data leakage with the goal of recovering secret keys of embedded cryptographic implementations. For about the same time it has been known that side channel leakage contains information about many other internal processes of a computing device. In this work we exploit side channel information to recover large parts of the program executed on an embedded processor. We present the first complete methodology to recover the program code of a microcontroller by evaluating its power consumption only. Besides well-studied methods from side channel analysis, we apply Hidden Markov Models to exploit prior knowledge about the program code. In addition to quantifying the potential of the created side channel based disassembler, we highlight its diverse and unique application scenarios.	algorithm;computer;cryptography;disassembler;embedded system;hidden markov model;markov chain;pic microcontroller;reverse engineering;side-channel attack;spectral leakage;theory	Thomas Eisenbarth;Christof Paar;Björn Weghenkel	2010	Trans. Computational Science	10.1007/978-3-642-17499-5_4	real-time computing;simulation;engineering;computer security	Crypto	-53.394299487137225	55.29872988074465	161228
3d67d3fdbd59a5a4a5b51b956d63e3b41cc81c46	enforcing mandatory access control in commodity os to disable malware	mandatory access control;operating systems computers authorisation invasive software;protocols;os level information flow;authorisation;intrusion detection;journal;os level information flow access controls operating system invasive software;information flow;access controls;operating system;malware;malware protocols operating systems access control usability;invasive software;access control;windows mandatory access control enforcement commodity os commercial operating system malware programs mac systems mac enforcement approach tracer intrusion detection suspected intruder detection suspected intruder tracing suspected intruder restricting security label configuration critical malware behavior blocking remote attacker;usability;operating systems computers;operating systems	Enforcing a practical Mandatory Access Control (MAC) in a commercial operating system to tackle malware problem is a grand challenge but also a promising approach. The firmest barriers to apply MAC to defeat malware programs are the incompatible and unusable problems in existing MAC systems. To address these issues, we manually analyze 2,600 malware samples one by one and two types of MAC enforced operating systems, and then design a novel MAC enforcement approach, named Tracer, which incorporates intrusion detection and tracing in a commercial operating system. The approach conceptually consists of three actions: detecting, tracing, and restricting suspected intruders. One novelty is that it leverages light-weight intrusion detection and tracing techniques to automate security label configuration that is widely acknowledged as a tough issue when applying a MAC system in practice. The other is that, rather than restricting information flow as a traditional MAC does, it traces intruders and restricts only their critical malware behaviors, where intruders represent processes and executables that are potential agents of a remote attacker. Our prototyping and experiments on Windows show that Tracer can effectively defeat all malware samples tested via blocking malware behaviors while not causing a significant compatibility problem.	antivirus software;blocking (computing);executable;experiment;grand challenges;intrusion detection system;malware;mandatory access control;microsoft windows;operating system;sensor;software incompatibility;tracing (software);usability	Zhiyong Shan;Xin Wang;Tzi-cker Chiueh	2012	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2012.36	intrusion detection system;embedded system;communications protocol;information flow;usability;computer science;access control;operating system;cryptovirology;malware;authorization;computer security	Security	-55.631167006041245	57.95397974387399	161296
d9a4ddf0d5c862f45b12c082b842e35d54d64bc8	an attack on smc-based software protection	distributed system;systeme reparti;securite informatique;computer security;sistema repartido;seguridad informatica;code binaire;codigo binario;software protection;binary code	Self-modifying codes (SMC) refer to programs that intentionally modify themselves at runtime, causing the runtime code to differ from the static binary representation of the code before execution. Hence SMC is an effective method to obstruct software disassembling. This paper presents a method which circumvents the SMC protection, thus improving the performance of disassembling. By disabling the write privilege to the code section, an access violation exception occurs when an SMC attempts to execute. Intercepting this exception allows the attacker to determine and thus compromise the SMC and generate equivalent static code. Our experiments demonstrate that it is viable and efficient.	binary number;byte;counter (digital);disassembler;effective method;exception handling;experiment;real-time transcription;run time (program lifecycle phase);segmentation fault;self-modifying code;static library	Yongdong Wu;Zhigang Zhao;Tian Wei Chui	2006		10.1007/11935308_25	binary code;real-time computing;telecommunications;computer science;operating system;computer security;algorithm	SE	-55.89058855302274	55.58893895609986	161303
3c9aaf797976c1b9ccf62c24858526493cf54872	business policy modeling and enforcement in databases		Database systems are the central information repositories for businesses and are subject to a wide array of policies, rules and requirements. The spectrum of business level constraints implemented within database systems has expanded from classical access control to include auditing, usage control, privacy management, and records retention. The lack of a systematic mechanism of integrating and reasoning about such a diverse set of policies manifested as database level constraints makes corporate policy management a chaotic process. In this paper we propose a general purpose policy modeling and constraint management framework that can integrate numerous aspects of business level requirements within database systems. Our proposed solution relies on a finite state modeling language for business level policies, in which users can declaratively express rules related to the normal workflow of a business process as well as specifying any undesirable states of business objects contained in a database system. The proposed system is then able to translate these policies into low level temporal integrity constraints that prevent policy violations and ensure that business objects and artifacts follow their mandated lifecycles. A formal layer for reasoning allows policy makers to discover unenforceable and conflicting policies, providing the basis to guarantee compliance for a wide array of rules that may need to be enforced on complex business objects stored in relational database systems.	access control;business object;business process;data integrity;digital rights management;modeling language;relational database;requirement	Ahmed A. Ataullah;Frank Wm. Tompa	2011	PVLDB		business process;theory of constraints;computer science;relational database management system;database;modeling language;business object;access control;workflow;data integrity	DB	-51.02439121660244	51.837527902138966	161468
ada44c1bbbf39bf1df2a1d0e92e4161ae8ec6d03	an automatic inference of minimal security types		Type-based information-flow analyses provide strong end-toend confidentiality guarantees for programs. Yet, such analyses are not easy to use in practice, as they require all information containers in a program to be annotated with security types, which is a tedious and error-prone task — if done manually. In this article, we propose a new algorithm for inferring such security types automatically. We implement our algorithm as an Eclipse plug-in, which enables software engineers to use it for verifying confidentiality requirements in their programs. We experimentally show our implementation to be effective and efficient. We also analyze theoretical properties of our security-type inference algorithm. In particular, we prove it to be sound, complete, minimal, and of linear time-complexity in the size of the program analyzed.	algorithm;cognitive dimensions of notations;confidentiality;eclipse;experiment;plug-in (computing);requirement;software engineer;time complexity;type inference;verification and validation	Dominik Bollmann;Steffen Lortz;Heiko Mantel;Artem Starostin	2015		10.1007/978-3-319-26961-0_24	computer science;theoretical computer science;operating system;data mining;database;computer security	SE	-55.36320777276675	53.34634059846341	161608
1f9a8b04205ef91adfb06678e7bf11902a0aeb9c	the making of a spam zombie army: dissecting the sobig worms	spam;electronic mail;sobig;computer viruses;worm;attack;infect;electronic mail computer viruses;unsolicited commercial e mail relaying spam zombie army sobig worms sobig e ad 2003 06 25 mass mailing worm spammers spam;unsolicited electronic mail uniform resource locators computer worms security military computing world wide web cryptography	of this year, and there is strong evidence that spammers use infected computers to relay unsolicited commercial email. Like its predecessors, Sobig.E is unremarkable in many ways. It's a piece of malicious code that targets Microsoft Windows operating systems. Written in Microsoft Visual C++, it makes use of threads, its ex-ecutable is compressed with either UPX or TeLock, it collects email addresses by harvesting files (such as Windows Address Book [WAB], Outlook Express mailbox [DBX], HTM, HTML, Mail message [EML], or text [TXT]), and attempts to infect new systems by sending them an infected email message or by copying itself to an open network share. The worm also includes its own simple mail transport protocol (SMTP) engine, spoofs its emails' source address, en-crypts and decrypts text strings as needed, and creates a mutual exclusion object (mutex) on infected systems to ensure they are not infected more than once. A more curious characteristic is that the worm is programmed to stop infecting new systems after 14 July 2003. Note that the worm does not terminate itself; other functionality, explained next, continues to execute. In fact, all previous variants of Sobig, except the first (Sobig.A), have a built-in date after which they stop propagating (see Table 1). From the continued release of new versions of Sobig with built-in propagation-termination dates, we can surmise that a single individual or organization with access to the worm's source code is responsible for all the variants. With Sobig.D, the worm also started making use of a built-in list of network time protocol (NTP) servers to obtain the current date and time, upon which it makes time-based decisions. This is likely an attempt to enforce the time restrictions on infected systems that have the incorrect time. Sobig also includes an upgrade mechanism. Sobig variants A–C downloaded files hosted at geocities. com from static embedded URLs. The downloaded files contained other URLs that pointed to files that Sobig downloaded and executed. By controlling the Geocities-hosted file contents, the worm author could direct the worm to download and execute files located anywhere on the Internet. This mechanism's weakness is that the pointing to Geocities are ELIAS LEVY Symantec O n 25 June 2003, a new mass-mailing worm emerged. We'd hardly think it worth noting except for a few important details: The worm was highly successful at infecting computer systems, is the fifth revision of a worm that first raised …	belief propagation;c++;canonical account;computer;download;elias levy;email;embedded system;emotion markup language;html;internet;malware;microsoft outlook for mac;microsoft windows;mutual exclusion;operating system;relay;software propagation;spamming;terminate (software);upx;yahoo! geocities	Elias Levy	2003	IEEE Security & Privacy	10.1109/MSECP.2003.1219071	spam;attack;computer science;spamming;internet privacy;world wide web;computer security;computer virus;computer worm	Security	-55.93558655916083	59.50081855771725	161960
cbaf684b5bfdbfd921d8b261e5ff525965f2b5b1	fmvea for safety and security analysis of intelligent and cooperative vehicles		Safety and security are two important aspects in the analysis of cyber-physical systems (CPSs). In this short paper, we apply a new safety and security analysis method to intelligent and cooperative vehicles, in order to examine attack possibilities and failure scenarios. The method is based on the FMEA technique for safety analysis, with extensions to cover information security. We examine the feasibility and efficiency of the method, and determine the next steps for developing the combined analysis method.	systems architecture	Christoph Schmittner;Zhendong Ma;Paul Smith	2014		10.1007/978-3-319-10557-4_31	construction engineering;transport engineering;computer security	Robotics	-54.53414731914172	48.670421009277334	162178
18af4f11a1a4e59ca4c191c3e8dcb51a8e2b54a0	an adaptive android security extension against privilege escalation attacks		Android is the world's most popular mobile platform. Nevertheless, in spite of continuous efforts on its permission system, it is still incapable of resisting privilege escalation attacks, specially, the confused deputy attacks on numerous poor-designed applications. Worse yet, most existing security solutions become costly or rigid in recent Android dynamic permission environment. In this paper, we proposed a flexible and efficient security extension to Android middleware for protecting the vulnerable privileged applications from being abused by malwares in the dynamic permission scenario. Our framework maintains fresh permission states of applications at runtime and enforces access control on inter-component communications conservatively by checking the capability differences between applications, so as to provide more precise and temperate protection for applications. Moreover, we also introduced an efficient cache mechanism together with an optimized proactive updating method for decisions, which contributes significantly to improving the inspection efficiency. Finally, experimental results reveal that our framework is effective and adaptable in defending against confused deputy attacks on applications with negligible overhead and limited impact on application usability.	access control;android;confused deputy problem;middleware;mobile operating system;overhead (computing);privilege escalation;protection mechanism;run time (program lifecycle phase);usability;whitelist	Yang Xu;Guojun Wang;Ju Ren;Yaoxue Zhang	2017	2017 IEEE International Symposium on Parallel and Distributed Processing with Applications and 2017 IEEE International Conference on Ubiquitous Computing and Communications (ISPA/IUCC)	10.1109/ISPA/IUCC.2017.00116	computer security;confused deputy problem;human–computer interaction;access control;privilege escalation;spite;android (operating system);malware;permission;computer science;middleware	SE	-55.19408517121406	57.46571055933943	162301
605d7b6721d46c8edbca63453d340a37f67c2ee5	system service call-oriented symbolic execution of android framework with applications to vulnerability discovery and exploit generation		Android Application Framework is an integral and foundational part of the Android system. Each of the 1.4 billion Android devices relies on the system services of Android Framework to manage applications and system resources. Given its critical role, a vulnerability in the framework can be exploited to launch large-scale cyber attacks and cause severe harms to user security and privacy. Recently, many vulnerabilities in Android Framework were exposed, showing that it is vulnerable and exploitable. However, most of the existing research has been limited to analyzing Android applications, while there are very few techniques and tools developed for analyzing Android Framework. In particular, to our knowledge, there is no previous work that analyzes the framework through symbolic execution, an approach that has proven to be very powerful for vulnerability discovery and exploit generation. We design and build the first system, Centaur, that enables symbolic execution of Android Framework. Due to some unique characteristics of the framework, such as its middleware nature and extraordinary complexity, many new challenges arise and are tackled in Centaur. In addition, we demonstrate how the system can be applied to discovering new vulnerability instances, which can be exploited by several recently uncovered attacks against the framework, and to generating PoC exploits.	android;application framework;exploit (computer security);middleware;symbolic execution	Lannan Luo;Qiang Zeng;Chen Cao;Kai Chen;Jian Liu;Limin Liu;Neng Gao;Min Yang;Xinyu Xing;Peng Liu	2017		10.1145/3081333.3081361	real-time computing;android (operating system);computer science;middleware;exploit;vulnerability;symbolic execution	Mobile	-51.27953995474486	58.36730479008247	162565
1f0cc52ed27a2622587d3cd3b9eb904e421d13bf	taintscope: a checksum-aware directed fuzzing tool for automatic software vulnerability detection	digital signal processing;program diagnostics;instruments;safety critical software program diagnostics program testing;computer crashes;telecommunication control;logic;software tools computer architecture computational modeling registers assembly digital signal processing digital signal processing chips telecommunication control large scale integration logic;testing;profiles techniques;dynamic taint analysis;fuzzing;assembly;computer architecture;computational modeling;symbolic execution;real world application;large scale integration;program testing;monitoring;registers;chromium;safety critical software;control flow;cve identifiers taintscope checksum aware directed fuzzing tool automatic software vulnerability detection fuzz testing automatic fuzzing system dynamic taint analysis symbolic execution techniques checksum based integrity checks branch profiling techniques x86 binary level secunia ocert;integrity checking;digital signal processing chips;software tools;symbolic execution fuzzing dynamic taint analysis;security;concrete	Fuzz testing has proven successful in finding security vulnerabilities in large programs. However, traditional fuzz testing tools have a well-known common drawback: they are ineffective if most generated malformed inputs are rejected in the early stage of program running, especially when target programs employ checksum mechanisms to verify the integrity of inputs. In this paper, we present TaintScope, an automatic fuzzing system using dynamic taint analysis and symbolic execution techniques, to tackle the above problem. TaintScope has several novel contributions: 1) TaintScope is the first checksum-aware fuzzing tool to the best of our knowledge. It can identify checksum fields in input instances, accurately locate checksum-based integrity checks by using branch profiling techniques, and bypass such checks via control flow alteration. 2) TaintScope is a directed fuzzing tool working at X86 binary level (on both Linux and Window). Based on fine-grained dynamic taint tracing, TaintScope identifies which bytes in a well-formed input are used in security-sensitive operations (e.g., invoking system/library calls) and then focuses on modifying such bytes. Thus, generated inputs are more likely to trigger potential vulnerabilities. 3) TaintScope is fully automatic, from detecting checksum, directed fuzzing, to repairing crashed samples. It can fix checksum values in generated inputs using combined concrete and symbolic execution techniques. We evaluate TaintScope on a number of large real-world applications. Experimental results show that TaintScope can accurately locate the checksum checks in programs and dramatically improve the effectiveness of fuzz testing. TaintScope has already found 27 previously unknown vulnerabilities in several widely used applications, including Adobe Acrobat, Google Picasa, Microsoft Paint, and ImageMagick. Most of these severe vulnerabilities have been confirmed by Secunia and oCERT, and assigned CVE identifiers (such as CVE-2009-1882, CVE-2009-2688). Corresponding patches from vendors are released or in progress based on our reports.	byte;checksum;common vulnerabilities and exposures;control flow;identifier;imagemagick;linux;microsoft paint;patch (computing);picasa;sensor;symbolic execution;taint checking;vulnerability (computing);well-formed element;x86	Tielei Wang;Tao Wei;Guofei Gu;Wei Zou	2010	2010 IEEE Symposium on Security and Privacy	10.1109/SP.2010.37	embedded system;chromium;real-time computing;fuzz testing;concrete;computer science;information security;operating system;digital signal processing;assembly;programming language;control flow;computer security;logic	Security	-57.094416223338214	56.30050699500706	162581
9820a7be1f708e67127446b6eeae28f86fd8a0e2	relational access control with bivalent permissions in a social web/collaboration architecture	content management;databases;bivalent permissions;permission checking;groupware;deme architecture;collaborative work;performance test;access control permission collaboration service oriented architecture content management collaborative work robots relational databases xml testing;relational access control;authorisation;deme web site relational access control bivalent permissions social web collaboration architecture web content management framework bivalent relation object access control xml access control deme architecture permission checking;xml access control;social factors;collaboration;deme web site;social web;collaboration architecture;testing;xml authorisation groupware internet software architecture web sites;software architecture;permissions;content management access control social factors collaborative work permissions social web applications;internet;permission;model building;social web applications;access control models;robots;web content management framework;web sites;xml;relational databases;access control;bivalent relation object access control;organizations;service oriented architecture;social factor;context	We describe an access control model that has been implemented in the web content management framework “Deme” (which rhymes with “team”). Access control in Deme is an example of what we call “bivalent relation object access control” (BROAC). This model builds on recent work by Giunchiglia et al. on relation-based access control (RelBAC), as well as other work on relational, flexible, fine-grained, and XML access control models. We describe Deme's architecture and review access control models, motivating our approach. BROAC allows for both positive and negative permissions, which may conflict with each other. We argue for the usefulness of defining access control rules as objects in the target database, and for the necessity of resolving permission conflicts in a social Web/collaboration architecture. After describing how Deme access control works, including the precedence relations between different permission types in Deme, we provide several examples of realistic scenarios in which permission conflicts arise, and show how Deme resolves them. Initial performance tests indicate that permission checking scales linearly in time on a practical Deme website.	access control;file system permissions;list of content management frameworks;programming paradigm;seamless3d;social collaboration;web content management system;xml	Todd R. Davies;Mike D. Mintz	2010	2010 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2010.5478523	robot;social web;software architecture;the internet;xml;model building;content management;relational database;computer science;organization;knowledge management;access control;service-oriented architecture;database;software testing;authorization;management;world wide web;collaboration	Security	-49.764733130807656	50.85754606514412	162689
58c753ecc0cc128bbdaec2448a573d4364e50e61	exploring attack graph for cost-benefit security hardening: a probabilistic approach	vulnerability analysis;security management;security hardening;risk assessment;attack graph;security metrics	The increasing complexity of today’s computer systems, together with the rapid emergence of novel vulnerabilities, make security hardening a formidable challenge for security administrators. Although a large variety of tools and techniques are available for vulnerability analysis, the majority work at system or network level without explicit association with human and organizational factors. This article presents a middleware approach to bridge the gap between system-level vulnerabilities and organization-level securitymetrics, ultimately contributing to cost-benefit security hardening. In particular, our approach systematically integrates attack graph, a commonly used effective approach to representing and analyzing network vulnerabilities, and Hidden Markov Model (HMM) together, for exploring the probabilistic relation between system observations and states. More specifically, we modify and apply dependency attack graph to represent network assets and vulnerabilities (observations), which are then fed to HMM for estimating attack states, whereas their transitions are driven by a set of predefined cost factors associated with potential attacks and countermeasures. A heuristic searching algorithm is employed to automatically infer the optimal security hardening through cost-benefit analysis. We use a synthetic network scenario to illustrate our approach and evaluate its performance through a set of simulations. a 2012 Elsevier Ltd. All rights reserved.	emergence;heuristic;hidden markov model;markov chain;middleware;search algorithm;simulation;synthetic intelligence	Shuzhen Wang;Zonghua Zhang;Youki Kadobayashi	2013	Computers & Security	10.1016/j.cose.2012.09.013	vulnerability management;computer security model;risk assessment;security management;vulnerability;computer science;vulnerability assessment;data mining;computer security	Security	-62.01882456917088	60.22174631075921	162715
387578124a28e2ec5b7cc370158cf1ac68eeae14	mitigating event confidentiality violations in smart grids: an information flow security-based approach	security smart grids topology educational institutions safety physical layer availability;smart power grids;security cyber physical systems distributed control distributed detection logic power system protection power system security;smart power grids power system protection power system security;power system protection;cyber event confidentiality violation mitigation power system security power system protection self obfuscating systems availability attacks integrity attacks cyber commands physical interconnections cyber controllers information flow security based approach smart grids;power system security	Modern smart grids, by and large, merge physical interconnections and cyber controllers. Invariably, this tight coupling results in cyber commands manifesting in the physical layer as observable changes, leading to possible disclosure of sensitive system settings. Thus, cyber event confidentiality of the smart grid is violated. Attacks on confidentiality can ultimately lead to integrity and availability attacks; with adequate knowledge of the system topology, internal settings, and how the physical layer responds to cyber commands, a malicious adversary gains knowledge to attack the system. This work shows how to develop self-obfuscating systems based on information flow security properties that can mitigate event confidentiality violations in smart grids.	adversary (cryptography);algorithm;confidentiality;controller (computing);cyber-physical system;feasible region;information flow;observable;overhead (computing);smart tv;theory	Thoshitha T. Gamage;Thomas P. Roth;Bruce M. McMillin;Mariesa L. Crow	2013	IEEE Transactions on Smart Grid	10.1109/TSG.2013.2243924	real-time computing;engineering;electrical engineering;internet privacy;power-system protection;computer security	Security	-57.18306125037093	51.40703137114435	162754
4800f6a2a81e4ad9f776bc7db710a71442b69519	smashclean: a hardware level mitigation to stack smashing attacks in openrisc	computer architecture;malware;registers;lenses;security;hardware	Buffer overflow and stack smashing have been one of the most popular software based vulnerabilities in literature. There have been multiple works which have used these vulnerabilities to induce powerful attacks to trigger malicious code snippets or to achieve privilege escalation. In this work, we attempt to implement hardware level security enforcement to mitigate such attacks on OpenRISC architecture. We have analyzed the given exploits [5] in detail and have identified two major vulnerabilities in the exploit codes: memory corruption by non-secure memcpy() and return address modification by buffer overflow. We have individually addressed each of these exploits and have proposed a combination of compiler and hardware level modification to prevent them. The advantage of having hardware level protection against these attacks provides reliable security against the popular software level countermeasures.	c string handling;code;compiler;exploit (computer security);linux;malware;memory corruption;memory management;memory protection;openrisc;privilege escalation;return statement;stack buffer overflow	Manaar Alam;Debapriya Basu Roy;Sarani Bhattacharya;Vidya Govindan;Rajat Subhra Chakraborty;Debdeep Mukhopadhyay	2016	2016 ACM/IEEE International Conference on Formal Methods and Models for System Design (MEMOCODE)	10.1109/MEMCOD.2016.7797764	embedded system;real-time computing;computer science;information security;lens;malware;processor register;computer security	Security	-55.62496503338963	56.4042430727954	162879
e5d155abafe7d7b05e6db7ce1176cf8c99b95ece	hardening java’s access control by abolishing implicit privilege elevation		While the Java runtime is installed on billions of devices and servers worldwide, it remains a primary attack vector for online criminals. As recent studies show, the majority of all exploited Java vulnerabilities comprise incorrect or insufficient implementations of access-control checks. This paper for the first time studies the problem in depth. As we find, attacks are enabled by shortcuts that short-circuit Java's general principle of stack-based access control. These shortcuts, originally introduced for ease of use and to improve performance, cause Java to elevate the privileges of code implicitly. As we show, this creates many pitfalls for software maintenance, making it all too easy for maintainers of the runtime to introduce blatant confused-deputy vulnerabilities even by just applying normally semantics-preserving refactorings. How can this problem be solved? Can one implement Java's access control without shortcuts, and if so, does this implementation remain usable and efficient? To answer those questions, we conducted a tool-assisted adaptation of the Java Class Library (JCL), avoiding (most) shortcuts and therefore moving to a fully explicit model of privilege elevation. As we show, the proposed changes significantly harden the JCL against attacks: they effectively hinder the introduction of new confused-deputy vulnerabilities in future library versions, and successfully restrict the capabilities of attackers when exploiting certain existing vulnerabilities. We discuss usability considerations, and through a set of large-scale experiments show that with current JVM technology such a faithful implementation of stack-based access control induces no observable performance loss.	access control;benchmark (computing);best, worst and average case;code refactoring;comparison of privilege authorization features;confused deputy problem;dacapo;experiment;exploit (computer security);hardening (computing);java class library;job control language;observable;overhead (computing);privilege (computing);privilege escalation;software maintenance;stack-oriented programming language;usability;vector (malware);vector graphics	Philipp Holzinger;Ben Hermann;Johannes Lerch;Eric Bodden;Mira Mezini	2017	2017 IEEE Symposium on Security and Privacy (SP)	10.1109/SP.2017.16	java applet;computer security;computer science;java api for xml-based rpc;java annotation;jar;real time java;java concurrency;strictfp;java	Security	-56.25092250863088	57.091252815675034	163152
a26d349e2e347afab51c970b6d9d6dc2b7a38879	analyzing integrity protection in the selinux example policy	policy making;policy analysis;satisfiability;access control models;trusted computing base	In this paper , we presentan approachfor analyzing the integrity protectionin theSELinuxexamplepolicy. The SELinux examplepolicy is intendedas an examplefrom whichadministratorscustomizeto createapolicy for their site’s securitygoals,but the complexity of the modelandsizeof the policy make this quite complex. Our aim is to provide anaccesscontrolmodelto expresssitesecuritygoalsandresolve themagainstthe SELinux policy. Ultimately, we aim to definea minimal trustedcomputingbase(TCB) that satisfiesClarkWilson integrity, by first testingfor themorerestrictive Bibaintegrity policy andresolvingconflictsusingClarkWilson semantics.Our policy analysistool, Gokyo, implementsthe following approach:(1) it representsthe SELinux examplepolicy andour integrity goals;(2) it identifiesconflictsbetweenthem;(3) it estimatestheresolutionsto theseconflicts;and(4) providesinformation for decidingupona resolution. Using Gokyo, we deriveaproposalfor aminimalTCB for SELinuxincludes 30 subjecttypes,and we identify the work remaining to ensurethat TCB is integrity-protected.Our analysis is performedon theSELinuxexamplepolicy for Linux 2.4.19.	authorization;data integrity;linux security modules;selinux;trusted computing base;unix	Trent Jaeger;Reiner Sailer;Xiaolan Zhang	2003			computer science;policy analysis;operating system;trusted computing base;data mining;database;computer security;satisfiability	Security	-51.50327223768188	53.31025798714377	163190
e6b9d46a7659b83d27877b4224a5174d6be4f00b	just in time hashing		In the past few years billions of user passwords have been exposed to the threat of offline cracking attempts. Such brute-force cracking attempts are increasingly dangerous as password cracking hardware continues to improve and as users continue to select low entropy passwords. Key-stretching techniques such as hash iteration and memory hard functions can help to mitigate the risk, but increased key-stretching effort necessarily increases authentication delay so this defense is fundamentally constrained by usability concerns. We introduce Just in Time Hashing (JIT), a client side key-stretching algorithm to protect user passwords against offline brute-force cracking attempts without increasing delay for the user. The basic idea is to exploit idle time while the user is typing in their password to perform extra key-stretching. As soon as the user types in the first character(s) of their password our algorithm immediately begins filling memory with hash values derived from the character(s) that the user has typed thus far. We conduct a user study to guide the development of JIT e.g. by determining how much extra key-stretching could be performed during idle cycles or how many consecutive deletions JIT may need to handle. Our security analysis demonstrates that JIT can substantially increase guessing costs over traditional key-stretching algorithms with equivalent (or less) authentication delay. Specifically an empirical evaluation using existing password datasets demonstrates that JIT increases guessing costs by nearly an order of magnitude in comparison to standard key-stretching techniques with comparable delay. We provide a proof-of-concept implementation of a Just in Time Hashing algorithm by modifying Argon2.	algorithm;argon2;authentication;brute-force attack;client-side;cryptographic hash function;iteration;just-in-time compilation;key stretching;online and offline;password cracking;usability testing	Benjamin Harsha;Jeremiah Blocki	2018	2018 IEEE European Symposium on Security and Privacy (EuroS&P)	10.1109/EuroSP.2018.00033	computer science;client-side;real-time computing;theoretical computer science;exploit;password;memory management;hash function;password cracking;idle;authentication	Security	-55.35907062579721	58.00871444472147	163197
76bd8177cad9ce0bcc09da9739fd7384fbf0f7f0	integrating access control into uml for secure software modeling and analysis	mandatory access control;uml;role based access control;secure software engineering;sensitivity levels;access control;constraints;use case and class diagram;modeling and analysis	Access control models are often an orthogonal activity when designing, implementing, and deploying software applications. Role-based access control (RBAC) which targets privileges based on responsibilities within an application and mandatory access control (MAC) that emphasizes the protection of information via security tags are two dominant approaches in this regard. The integration of access control into software modeling and analysis is often loose and significantly lacking, particularly when security is such a high-priority concern in applications. This article presents an approach to integrate RBAC and MAC into use-case, class, and sequence diagrams of the unified modeling language (UML), providing a cohesive approach to secure software modeling that elevates security to a first-class citizen in the process. To insure that a UML design with security does not violate RBAC or MAC requirements, design-time analysis checks security constraints whenever a new UML element is added or an existing UML element is modified, while post-design analysis checks security constraints across the entire design for conflicts and inconsistencies. These access control extensions and security analyses have been prototyped within a UML tool. DOI: 10.4018/jsse.2010102001 IGI PUBLISHING This paper appears in the publication, International Journal of Secure Software Engineering, Volume 1, Issue 1 edited by Khaled M. Khan © 2010, IGI Global 701 E. Chocolate Avenue, Hersh y PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.igi-global.com ITJ 5591 2 International Journal of Secure Software Engineering, 1(1), 1-19, January-March 2010 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. engineers to jointly model their application’s functional and security requirements and constraints, augmented with analyses that insures the access control model characteristics, capabilities, and constraints that are being utilized are not violated. Note that despite the existence of parallels between security and elements in UML, direct support for security specification is not provided (OMG). For access control, we leverage: role-based access control (RBAC) that focuses on user responsibilities via roles (Sandhu et al., 1996; Ting, 1988) with constraints to restrict behavior (Ferraiolo et al., 2001); and, mandatory access control (MAC) that defines classifications for objects and clearances for subjects (Bell & La Padula, 1975) with access based on the relationship between subjects and objects (Biba, 1977; Osborn et al., 2000). For security, RBAC is a flexible approach to grant/revoke permissions to/from users via roles, while MAC controls information flow (read/write on objects) for highly secure systems. Both models are augmented in this approach with lifetime constraints that determine a temporal window of activity for privileges. This article details a practical approach that integrates RBAC and MAC into UML for secure software modeling and analysis with a two-fold emphasis. First, UML requirements definition (use case diagram) and design (class and sequence diagrams) are extended with visual and non-visual security capabilities and constraints for MAC, lifetime, and RBAC. Second, security modeling is augmented with analyses via the checking of security constraints. The design-time analysis checks these constraints as the application is created and changed as a result of every action taken by an engineering/ designer. The post-design analysis (akin to a compile) checks these constraints across the entire application at a particular increment. Both the modeling and analysis capabilities have been programmatically integrated into Borland’s UML design tool Together Architect (2009). The snapshots of the implementation illustrate the examples in the article. This work goes beyond our prior efforts (Doan et al., 2004a; Doan et al., 2004b) by collectively bringing all of the security extensions to UML along with their respective analyses into one context that clearly demonstrates the capabilities and potential of the work in total. The work presented herein contrasts with other efforts on security for UML. The work of Shin and Ahn (2000) and Ray et al. (2003) simply uses UML to represent MAC and/or RBAC systems, as opposed to explicitly extending UML with RBAC and MAC. UMLsec (Jurjens, 2002a, 2002b) focuses on multi-level security (MAC) of message in sequence/state diagrams and is similar to our work on MAC extension. SecureUML (Lodderstedt et al., 2002) introduces new meta-model components and authorization constraints expressed for RBAC that involve meta-model changes. Lastly, Alghathbar and Wijesekera (2003a) incorporate security into use cases, similar to our approach. The main difference between our approach and others is one of comprehensiveness; we are doing RBAC, MAC, constraints, and lifetimes for temporal access, which combines many features of the aforementioned work with other capabilities that they do not provide. This remainder of this article is organized as follows. Section 2 provides brief background on UML and access control models. Section 3 introduces security extensions to UML with a focus on changes to use case, class, and sequence diagrams, and support for security constraints. Section 4 presents the subsequent security analyses. Section 5, compares and contrasts our approach with other researchers’ work. Finally, Section 6 concludes the article and discusses ongoing research.	authorization;compiler;design tool;electronic article surveillance;fax;first-class citizen;intel technology journal;linear algebra;mandatory access control;metamodeling;multilevel security;parallels desktop for mac;requirement;role-based access control;sequence diagram;software engineering;uml tool;umlsec;unified modeling language;uniform resource identifier;use case diagram;word lists by frequency	Thuong Doan;Steven A. Demurjian;Laurent D. Michel;Solomon Berhe	2010	IJSSE	10.4018/jsse.2010102001	software security assurance;unified modeling language;real-time computing;computer access control;uml tool;computer science;access control;applications of uml;role-based access control;database;network access control;node;computer security	Security	-52.32339880326284	53.150152326016105	163386
c6c6a5fb940b7dfd14200dcfd0c1c163a8a58a6b	attacks on java card 3.0 combining fault and logical attacks	java card 3;java card;logical attack;fault injection;combined attack	Java Cards have been threatened so far by attacks using ill-formed applications which assume that the application bytecode is not verified. This assumption remained realistic as long as the bytecode verifier was commonly executed off-card and could thus be bypassed. Nevertheless it can no longer be applied to the Java Card 3 Connected Edition context where the bytecode verification is necessarily performed on-card. Therefore Java Card 3 Connected Edition seems to be immune against this kind of attacks. In this paper, we demonstrate that running ill-formed application does not necessarily mean loading and installing ill-formed application. For that purpose, we introduce a brand new kind of attack which combines fault injection and logical tampering. By these means, we describe two case studies taking place in the new Java Card 3 context. The first one shows how ill-formed applications can still be introduced and executed despite the on-card bytecode verifier. The second example leads to the modification of any method already installed on the card into any malicious bytecode. Finally we successfully mount these attacks on a recent device, emphasizing the necessity of taking into account these new threats when implementing Java Card 3 features.	fault injection;java card;java virtual machine	Guillaume Barbu;Hugues Thiebeauld;Vincent Guerin	2010		10.1007/978-3-642-12510-2_11	java card;real-time computing;java concurrency;computer science;operating system;openpgp card;computer security	SE	-55.104822798703964	55.39091447361123	163604
9d8e5c07784b165bd93f1700cd37faebe8aadbef	report: extensibility and implementation independence of the .net cryptographic api	smart card;net;cryptographic algorithm;cryptography	When a vulnerability is discovered in a cryptographic algorithm, or in a specific implementation of that algorithm, it is important that software using that algorithm or implementation is upgraded quickly. Hence, modern cryptographic libraries such as the .NET crypto libraries are designed to be extensible with new algorithms. In addition, they also support algorithm and implementation independent use. Software written against these libraries can be implemented such that switching to a new crypto algorithm or implementation requires very little effort. This paper reports on our experiences with the implementation of a number of extensions to the .NET cryptographic framework. The extensions we consider are smart card based implementations of existing algorithms. We evaluate the extensibility of the libraries, and the support for implementation independence. We identify several problems with the libraries that have a negative impact on these properties, and we propose solutions. The main conclusion of the paper is that extensibility and implementation independence can be substantially improved with only minor changes. These changes maintain backwards compatibility for client code.	.net framework;algorithm;application programming interface;backward compatibility;cryptography;encryption;extensibility;fxcop;library (computing);microsoft cryptoapi;microsoft windows;smart card	Pieter Philippaerts;Cédric Boon;Frank Piessens	2009		10.1007/978-3-642-00199-4_9	cryptographic primitive;smart card;real-time computing;computer science;cryptography;theoretical computer science;operating system;database;distributed computing;programming language;computer security;algorithm;statistics;net	Security	-54.92953551765027	58.25340358609493	163822
6fb56f7326df28cfad463fce54061ac6413797c2	multi-run security	publikationer;konferensbidrag;artiklar;rapporter	This paper explores information-flow control for batch-job programs that are allowed to be re-run with new input provided by the attacker. We argue that directly adapting two major security definitions for batch-job programs, termination-sensitive and termination-insensitive noninterference, to multi-run execution would result in extremes. While the former readily scales up to multiple runs, its enforcement is typically over-restrictive. The latter suffers from insecurity: secrets can be leaked in their entirety by multiple runs of programs that are secure according to batch-job termination-insensitive noninterference. Seeking to avoid the extremes, we present a framework for specifying and enforcing multirun security in an imperative language. The policy framework is based on tracking the attacker’s knowledge about secrets obtained by multiple program runs. Inspired by previous work on robustness, the key ingredient of our type-based enforcement for multi-run security is preventing the dangerous combination of attacker-controlled data and secret data from affecting program termination.	batch processing;imperative programming;non-interference (security)	Arnar Birgisson;Andrei Sabelfeld	2011		10.1007/978-3-642-23822-2_21	data mining;distributed computing;computer security	Security	-54.43931708797258	53.470283018440405	163842
60837f1a694e806e5512cc3af3fe9172f9f05ed6	misuse patterns for cloud computing	virtual machine;monitoring;security;misuse patterns;cloud computing	Cloud Computing is a new computing structure that allows providers to deliver services on demand by means of virtualization. We are studying some security attacks in cloud computing by describing them in the form of misuse patterns. A misuse pattern describes how an information misuse is performed from the point of view of the attacker. It defines the environment where the attack is performed, how the attack is performed, countermeasures to stop it, and how to find forensic information to trace the attack once it happens. We are building a catalog of misuse patterns and we present here two of them: Resource Usage Monitoring (complete) and Malicious Virtual Machine Creation (partially). We discuss also the value of having such a catalog.	cloud computing;misuse case;virtual machine	Keiko Hashizume;Eduardo B. Fernández;Nobukazu Yoshioka	2011		10.1145/2524629.2524644	cloud computing security;cloud computing;computer science;internet privacy;world wide web;computer security	Security	-51.57406535630418	58.39437034560978	164051
8f9396d42ec9a733be8f9059ceef3e4957103130	leveraging semantic signatures for bug search in binary programs	dynamic malware analysis;virtual machine introspection	"""Software vulnerabilities still constitute a high security risk and there is an ongoing race to patch known bugs. However, especially in closed-source software, there is no straightforward way (in contrast to source code analysis) to find buggy code parts, even if the bug was publicly disclosed.  To tackle this problem, we propose a method called Tree Edit Distance Based Equational Matching (TEDEM) to automatically identify binary code regions that are """"similar"""" to code regions containing a reference bug. We aim to find bugs both in the same binary as the reference bug and in completely unrelated binaries (even compiled for different operating systems). Our method even works on proprietary software systems, which lack source code and symbols.  The analysis task is split into two phases. In a preprocessing phase, we condense the semantics of a given binary executable by symbolic simplification to make our approach robust against syntactic changes across different binaries. Second, we use tree edit distances as a basic block-centric metric for code similarity. This allows us to find instances of the same bug in different binaries and even spotting its variants (a concept called vulnerability extrapolation). To demonstrate the practical feasibility of the proposed method, we implemented a prototype of TEDEM that can find real-world security bugs across binaries and even across OS boundaries, such as in MS Word and the popular messengers Pidgin (Linux) and Adium (Mac OS)."""	adium;antivirus software;basic block;binary code;binary file;compiler;edit distance;executable;extrapolation;fork (software development);linux;machine code;microsoft word for mac;operating system;paste;patch (computing);preprocessor;prototype;security bug;software bug;software system;sound amplification by stimulated emission of radiation;static program analysis;symbolic computation;vulnerability (computing)	Jannik Pewny;Felix Schuster;Lukas Bernhard;Thorsten Holz;Christian Rossow	2014		10.1145/2664243.2664269	computer science;theoretical computer science;operating system;database;world wide web;computer security	Security	-57.0970709591078	55.84368034495357	164137
5ae6c70f770ca454adc7f51abd0788f1d9664771	an experiment in distributed internet address management using blockchains		The current system to manage the global pool of IP addresses is centralized in five transnational organizations, the Regional Internet Registries (RIRs). Each of these RIRs manage the address pool for a large number of countries. Because the RIRs are private organizations, they are subject to the legal framework of the country where they are based. This configuration results in a jurisdictional overflow from the legal framework of the countries where the RIR is based to all the countries that the RIRs are serving (the countries served by the RIRs de facto become subjects of the legal system of the country where the RIR is hosted). The situation is aggravated by the deployment of new security techniques such as the Resource Public Key Infrastructure (RPKI) and BGP security (BGPsec), that enable enforcement of allocations by the RIRs. In this paper we present InBlock, a blockchain-based distributed governance body aimed to provide de-centralized management of IP addresses. InBlock also aims to fulfil the same objectives as the current IP address allocation system, namely, uniqueness, fairness, conservation, aggregation, registration and minimized overhead. InBlock is implemented as a Decentralized Autonomous Organization, i.e., as a set of blockchain’s smart contracts in Ethereum. Any entity may request an allocation of addresses to the InBlock registry by solely performing a (crypto)currency transfer to the InBlock. The fee required, along with the annual renewal fee, serves as a mechanism to deter stockpiling and other wasteful practices. As with any novel technology, there are many open questions about the usage of blockchains to build an IP address registry. For this reason, we believe that practical experimentation is required in order to have hands-on experiences about such a system. We propose to conduct an experiment on distributed address management using InBlock as a starting point to inform future directions in this area.	address pool;autonomous robot;bitcoin;border gateway protocol;call to arms;case preservation;centralized computing;coat of arms;decentralized autonomous organization;entity;ethereum;experience;experiment;fairness measure;hands-on computing;ianal;internet access;internet censorship circumvention;overhead (computing);resource public key infrastructure;smart contract;software deployment;traceability	Stefano Angieri;Alberto García-Martínez;Bingyang Liu;Zhiwei Yan;Chuang Wang;Marcelo Bagnulo	2018	CoRR		uniqueness;computer network;computer security;computer science;address pool;software deployment;enforcement;the internet;currency;decentralized autonomous organization;corporate governance	Security	-50.05073042797378	59.32651375855109	164234
9e166ad6aac682c2b7214ffe4e3b522975d75902	checking integrity via cops and banana: the e-commerce case study	security properties;electronic commerce;e commerce;mobile ambients;control flow analysis;static analysis;process algebra	We consider two different approaches to security issues. In the first one bisimulation equivalences (dynamic verifications) are exploited to verify non-interference security properties on a CCS-like process algebra calculus. In the second approach control flow analysis (static analysis) is applied to verify security properties in Mobile Ambient calculus. We analyze how a simple electronic commerce case study can be modeled and its integrity verified using the two techniques. The tools CoPS and Banana are used to perform the computations.	ambient calculus;bisimulation;computation;control flow analysis;data-flow analysis;e-commerce payment system;interference (communication);non-interference (security);process calculus;static program analysis	Chiara Braghin;Carla Piazza	2004	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2004.02.013	e-commerce;process calculus;computer science;theoretical computer science;distributed computing;programming language;computer security;static analysis;control flow analysis	Security	-52.95855522449571	51.14197391341125	164434
26743568d55402859177aa20f0a24bac0e72e1d9	on locating malicious code in piggybacked android apps		To devise efficient approaches and tools for detecting malicious packages in the Android ecosystem, researchers are increasingly required to have a deep understanding of malware. There is thus a need to provide a framework for dissecting malware and locating malicious program fragments within app code in order to build a comprehensive dataset of malicious samples. Towards addressing this need, we propose in this work a tool-based approach called HookRanker, which provides ranked lists of potentially malicious packages based on the way malware behaviour code is triggered. With experiments on a ground truth of piggybacked apps, we are able to automatically locate the malicious packages from piggybacked Android apps with an accuracy@5 of 83.6% for such packages that are triggered through method invocations and an accuracy@5 of 82.2% for such packages that are triggered independently.	android;antivirus software;ecosystem;experiment;ground truth;malware;sensor	Li Li;Daoyuan Li;Tegawendé F. Bissyandé;Jacques Klein;Haipeng Cai;David Lo;Yves Le Traon	2017	Journal of Computer Science and Technology	10.1007/s11390-017-1786-z	computer security;computer science;distributed computing;malware;android (operating system);ground truth	Security	-57.70890114932089	60.01428796659115	164580
2ba7b6cdbd9ea2f1d9953569758431d956ca4c14	a detection and measurement approach for memory leaked objects in java programs			java	Qiao Yu;Shujuan Jiang;Yingqi Liu	2015	IEICE Transactions		computer science;internet privacy;programming language;world wide web;computer security;memory leak	SE	-56.81671201846268	58.28104320755689	164635
3b7133a6183c6cf76ef26f60c686aef14f440737	a concept for monitoring self-transforming code using memory page access control management	paged storage;memory management;decoding;authorisation;real time;transform coding authorisation decoding invasive software paged storage;transform coding;memory page access control management self transforming code monitoring antivirus software code transformation algorithm malware plaintext reverse transformation algorithm unsuspicious looking block malware transformation polymorphic malware obfuscation decoding encoding malware detection systems nonintrusive lightweight method;nx bit;operating system;monitoring;malware;polymorphism;code obfuscation;memory manager;polymorphic code;invasive software;linux;access control;obfuscation;encoding;malware detection;malware decoding encoding monitoring operating systems linux;operating systems;nx bit malware detection polymorphic code obfuscation memory manager	Current antivirus software still focuses on using signature based algorithms on file content level to detect malware. Unfortunately, there is a simple way to circumvent this detection method: The malware author applies a code transformation algorithm (e.g. a packing or encryption scheme) to his malware plaintext and saves the reverse transformation algorithm along with the unsuspicious looking block of transformed mal-ware. Malware, which is obfuscated in that way, is called polymorphic malware. We call the transformation of the plaintext to the transformed malware as encoding and the reverse operation as decoding. Although current malware detection systems adopted and implemented several techniques to counter this, these methods are mostly either unreliable or suffer heavy performance drawbacks. We present a non-intrusive and lightweight method to monitor any executable code in real-time, which allows efficient detection of polymorphic malware.	access control;algorithm;antivirus software;component-based software engineering;encryption;executable;linux;malware;microsoft windows;operating system;overhead (computing);page (computer memory);paging;plaintext;prototype;real-time clock;set packing;virtual machine;warez	Christian Maaser;Harald Baier	2011	2011 Carnahan Conference on Security Technology	10.1109/CCST.2011.6095942	real-time computing;computer science;operating system;cryptovirology;computer security	Security	-55.32986608290738	55.93545798262118	164708
b4e831534cf1692cc52ed9b5056377c5380c6694	physical access control administration using building information models	timely access;staff access;current dependency;building information model;critical infrastructure;complex environment;central role;physical access control system;physical access control administration;human administrator;security administrator;physical access control;access control;usability	Physical access control systems play a central role in the protection of critical infrastructures, where both the provision of timely access and preserving the security of sensitive areas are paramount. In this paper we discuss the shortcomings of existing approaches to the administration of physical access control in complex environments. At the heart of the problem is the current dependency on human administrators to reason about the implications of the provision or the revocation of staff access to an area within these facilities. We demonstrate how utilising Building Information Models (BIMs) and the capabilities they provide, including 3D representation of a facility and path-finding, may reduce the incidents of errors made by security administrators.	access control;algorithm;building information modeling;control system;information model;linkage (software);pathfinding;physical access;prototype;the australian;usability;visualization (graphics)	Nimalaprakasan Skandhakumar;Farzad Salim;Jason Reid;Ed Dawson	2012		10.1007/978-3-642-35362-8_19	public relations;physical access;engineering;transport engineering;computer security	Security	-58.027067416648826	48.910193268552455	164911
641b4ad7fd71da16d98840ecc05669817a7bfac4	session abstract	conference proceedings;design;reliability;reliability; testing; and fault-tolerance	Three soft-error experts from industry will discuss the way their companies understand the impact of soft-errors on electronic systems, whether they consider soft-errors as an already existing or upcoming risk, whether they use or intent to introduce countermeasures and which are the best suited ones for their applications.	countermeasure (computer);soft error	Michael Nicolaidis	2006	24th IEEE VLSI Test Symposium	10.1109/VTS.2006.79		Embedded	-59.1954952485194	47.60768538497723	164980
3d79fb927b2daf530ec25dbc698dec9c5e709a01	analyzing recent trends in enterprise identity management	market research access control cloud computing communities computational modeling mobile communication;idm enterprise identity management literature analysis scientific community access control;004 informatik;cloud computing authorisation;ddc 004	Recent data breaches caused by highly-privileged insiders (e.g. the NSA/Snowden case) as well as the proliferation of mobile and cloud applications in enterprises imposes new challenges for Identity Management. To cope with these challenges, business analysts have predicted a variety of trends for enterprise Identity Management. In this paper, we conduct a thorough literature analysis to examine to which extent the scientific community seizes upon these trends and identify major research areas therein. Results show that despite the analysts' predictions, research stagnates for attribute-based access control and privileged user management, while for cloud-based IdM and bring your own device it corresponds to the analysts' forecast.	access control;bring your own device;cloud computing;data breach;identity management;snowden	Michael Kunz;Matthias Hummer;Ludwig Fuchs;Michael Netter;Günther Pernul	2014	2014 25th International Workshop on Database and Expert Systems Applications	10.1109/DEXA.2014.62	computer science;artificial intelligence;data mining;database;internet privacy;world wide web;computer security	DB	-49.45812836903759	58.37576142675413	165164
62424482d16744bbe461d89863a5e739151daba3	provably secure programming languages for remote evaluation	provable security;programming language;design criteria;client server systems;computer logic;active network;internet;remote terminals;safety;data processing security;programming languages	Abstract : Remote evaluation and dynamically extensible systems pose serious safety and security risks. Programming language design has a major role in overcoming some of these risks. Important research areas include designing suitable languages for remote evaluation, identifying appropriate security and safety properties for them, and developing provably sound logics for reasoning about the properties in the context of separate compilation and dynamic linking.	provable security;remote evaluation	Dennis M. Volpano	1996	ACM Comput. Surv.	10.1145/242224.242453	fourth-generation programming language;active networking;declarative programming;the internet;computer science;extensible programming;operating system;provable security;database;distributed computing;programming paradigm;inductive programming;fifth-generation programming language;programming language;computer security	PL	-52.63018258678932	52.79301472781681	165285
62251ffe59e4fcbfef0f7675452b704c2f340e8d	dsvd: an effective low-overhead dynamic software vulnerability discoverer	optimisation;instruments;dsvd;irrelevant api filter;specint2006 benchmarks;dynamic software vulnerability discoverer;runtime;dynamic taint analysis;runtime overhead;software reliability application program interfaces invasive software optimisation;vulnerability discovery;software security;registers;basic block handling;application program interfaces;optimizations;x86 executables;hardware change;invasive software;runtime optimization registers security program processors instruments;optimization;source code;discovery rules;low overhead vulnerability discovery system;software security dynamic taint analysis vulnerability discovery;security;software reliability;malware detection;program processors;runtime overhead dsvd dynamic software vulnerability discoverer dynamic taint analysis malware detection source code discovery rules low overhead vulnerability discovery system x86 executables hardware change controlled taint specint2006 benchmarks optimizations irrelevant api filter basic block handling;controlled taint	Dynamic taint analysis based software vulnerability and malware detection is an effective method to detect a wide range of vulnerabilities. Unfortunately, existing systems suffer from requirement of source code, high overhead or shortage of discovery rules, which limit their usage. This paper proposes a low-overhead vulnerability discovery system called DsVD (Dynamic Software Vulnerabilities Discoverer). DsVD works on X86 executables and does not need any hardware change. A new taint state called controlled-taint is introduced to detect more types of vulnerabilities. Our experiments show that DsVD can effectively detect various software vulnerabilities. DsVD incurs very low overhead, only 3.1 times on average forSPECINT2006 benchmarks. With some optimizations such as Irrelevant API Filter and Basic Block Handling, it can reduce runtime overhead by a factor of 4-11 times.	application programming interface;basic block;benchmark (computing);central processing unit;code coverage;discovery system;effective method;executable;experiment;malware;overhead (computing);relevance;static program analysis;taint checking;vulnerability (computing);x86	Zhuo Wang;Zhushou Tang;Kan Zhou;Ruoyu Zhang;Zhengwei Qi;Haibing Guan	2011	2011 Tenth International Symposium on Autonomous Decentralized Systems	10.1109/ISADS.2011.56	software security assurance;real-time computing;computer science;information security;operating system;database;distributed computing;processor register;computer security;software quality;source code	Arch	-57.18765549244093	56.19076060357393	165313
063f68ed7a2f605624886c62c46413795bdd9376	on-the-fly inlining of dynamic security monitors	publikationer;konferensbidrag;artiklar;rapporter	Language-based information-flow security considers programs that manipulate pieces of data at different sensitivity levels. Securing information flow in such programs remains an open challenge. Recently, considerable progress has been made on understanding dynamic monitoring for secure information flow. This paper presents a framework for inlining dynamic information-flow monitors. A novel feature of our framework is the ability to perform inlining on the fly. We consider a source language that includes dynamic code evaluation of strings whose content might not be known until runtime. To secure this construct, our inlining is done on the fly, at the string evaluation time, and, just like conventional offline inlining, requires no modification of the hosting runtime environment. We present a formalization for a simple language to show that the inlined code is secure: it satisfies a noninterference property. We also discuss practical considerations and preliminary experimental results.	computation;data security;experiment;information flow (information theory);inline expansion;javascript;mashup (web application hybrid);non-interference (security);on the fly;online and offline;overhead (computing);runtime system;scalability	Jonas Magazinius;Alejandro Russo;Andrei Sabelfeld	2010		10.1007/978-3-642-15257-3_16	real-time computing;computer science;operating system;database;computer security	PL	-56.08825725659146	57.46705137082289	165457
18eda04fe2255280159fd40107acb440abf200eb	when good components go bad: formally secure compilation despite dynamic compromise		We propose a new formal criterion for evaluating secure compilation schemes for unsafe languages, expressing end-to-end security guarantees for software components that may become compromised after encountering undefined behavior---for example, by accessing an array out of bounds. Our criterion is the first to model dynamic compromise in a system of mutually distrustful components with clearly specified privileges. It articulates how each component should be protected from all the others---in particular, from components that have encountered undefined behavior and become compromised. Each component receives secure compilation guarantees---in particular, its internal invariants are protected from compromised components---up to the point when this component itself becomes compromised, after which we assume an attacker can take complete control and use this component's privileges to attack other components. More precisely, a secure compilation chain must ensure that a dynamically compromised component cannot break the safety properties of the system at the target level any more than an arbitrary attacker-controlled component (with the same interface and privileges, but without undefined behaviors) already could at the source level. To illustrate the model, we construct a secure compilation chain for a small unsafe language with buffers, procedures, and components, targeting a simple abstract machine with built-in compartmentalization. We give a careful proof (mostly machine-checked in Coq) that this compiler satisfies our secure compilation criterion. Finally, we show that the protection guarantees offered by the compartmentalized abstract machine can be achieved at the machine-code level using either software fault isolation or a tag-based reference monitor.	abstract machine;bounds checking;compiler;component-based software engineering;coq (software);end-to-end principle;fault detection and isolation;invariant (computer science);machine code;network compartment;reference monitor;sandbox (computer security);undefined behavior	Carmine Abate;Arthur Azevedo de Amorim;Roberto Blanco;Ana Nora Evans;Guglielmo Fachini;Catalin Hritcu;Théo Laurent;Benjamin C. Pierce;Marco Stronati;Andrew Tolmach	2018		10.1145/3243734.3243745	cryptography;compiler;component-based software engineering;abstract machine;theoretical computer science;real-time computing;undefined behavior;computer science;principle of least privilege;reference monitor;compromise	Security	-54.436215655673344	53.64595097611924	165655
1cfe8c22fc281fe43d41284c3ce68c98c4360736	malware detection by static checking and dynamic analysis of executables			executable;malware;static program analysis	Deepti Vidyarthi;S. P. Choudhary;Subrata Rakshit;C. R. Suthikshn Kumar	2017	IJISP	10.4018/IJISP.2017070103	computer science;computer security;malware;executable	Security	-57.36778697504594	58.281993682972995	166302
d29aac98c93b7bde82def796fae0ccd83238d547	chizpurfle: a gray-box android fuzzer for vendor service customizations		"""Android has become the most popular mobile OS, as it enables device manufacturers to introduce customizations to compete with value-added services. However, customizations make the OS less dependable and secure, since they can introduce software flaws. Such flaws can be found by using fuzzing, a popular testing technique among security researchers.This paper presents Chizpurfle, a novel """"gray-box"""" fuzzing tool for vendor-specific Android services. Testing these services is challenging for existing tools, since vendors do not provide source code and the services cannot be run on a device emulator. Chizpurfle has been designed to run on an unmodified Android OS on an actual device. The tool automatically discovers, fuzzes, and profiles proprietary services. This work evaluates the applicability and performance of Chizpurfle on the Samsung Galaxy S6 Edge, and discusses software bugs found in privileged vendor services."""	android;application programming interface;black box;emulator;fault coverage;gray box testing;heuristic (computer science);mobile device;operating system;overhead (computing);reverse engineering;software bug;type signature	Antonio Ken Iannillo;Roberto Natella;Domenico Cotroneo;Cristina Nita-Rotaru	2017	2017 IEEE 28th International Symposium on Software Reliability Engineering (ISSRE)	10.1109/ISSRE.2017.16	humanoid robot;gray box testing;computer science;software bug;operating system;android (operating system);software;vendor;source code;fuzz testing	Security	-54.87209946680236	59.40327854535313	166415
e17b26e38f64df0710a6316200755a0b4c438199	modeling attack process of advanced persistent threat		Advanced Persistent Threat (APT) with deep concealment has become one of the most serious network attacks. Modeling APT attack process can facilitate APT analysis and detection. However, existed modeling approaches neither reflects APT attack dynamically nor takes human factor into consideration. In order to achieve this, we propose a Targeted Complex Attack Network (TCAN) model for APT attack process. Compared with current models, our model addresses human factor by conducting two-layer network structure. Besides, our model introduces time domain to expand the traditional attack graph into dynamic attack network. Whats more, we propose dynamic evolution rules based on complex network theory and characteristics of the actual attack scenarios. Our simulation results show that the model can express the process of attack effectively.		Wei-na Niu;Xiaosong Zhang;Keqin Li;Guowu Yang;Ruidong Chen	2016		10.1007/978-3-319-49148-6_32	advanced persistent threat;complex network;time domain;distributed computing;computer science;graph	Security	-62.41292398652218	60.05793106512154	166473
7147be13c55f00daa49478d5af3adc601bd574bb	creating objects in the flexible authorization framework	creating object;improper information leak;dynamical creation;flexible authorization framework;it system;access control;secure it system;information flow control model;data processing;information flow result;access control policy;data protection;information flow	Access control is a crucial concern to build secure IT systems and, more specifically, to protect the confidentiality of information. However, access control is necessary, but not sufficient. Actually, IT systems can manipulate data to provide services to users. The results of a data processing may disclose information concerning the objects used in the data processing itself. Therefore, the control of information flow results fundamental to guarantee data protection. In the last years many information flow control models have been proposed. However, these frameworks mainly focus on the detection and prevention of improper information leaks and do not provide support for the dynamical creation of new objects. In this paper we extend our previous work to automatically support the dynamical creation of objects by verifying the conditions under which objects can be created and automatically associating an access control policy to them. Moreover, our proposal includes mechanisms tailored to control the usage of information once it has been accessed.	access control;authorization;confidentiality;control flow;information privacy;information security;non-interference (security);verification and validation	Nicola Zannone;Sushil Jajodia;Duminda Wijesekera	2006			information flow;confidentiality;data processing;information processing;computer science;access control;data mining;data protection act 1998;world wide web;computer security;information protection policy;information system	Security	-51.499018475968256	52.29517151423587	166634
5f18e03ac6670da673e44d65692edd8c2598f49b	building secure systems: from threats to security patterns	analytical models;security restriction;security analysis;two dimensions;security pattern;system security;metamodel;metamodel security pattern security restriction security analysis;unified modeling language;secure system;reliable systems;reliable systems security patterns;authorization;software reliability;unified modeling language object oriented modeling analytical models authorization software reliability;security patterns;security of data;object oriented modeling	We present an approach using two dimensions to propagate security restrictions: along the lifecycle and along the architectural levels. We believe that this double propagation can be very effective for security. This approach can also facilitate the security analysis of the system.	metamodeling;model-driven engineering;model-driven integration;software propagation	Eduardo B. Fernández;Sergio Mujica	2010	2010 XXIX International Conference of the Chilean Computer Science Society	10.1109/SCCC.2010.36	software security assurance;computer security model;cloud computing security;reliability engineering;security through obscurity;security information and event management;security engineering;security convergence;covert channel;asset;computer science;database;security service;security testing;computer security	SE	-54.74138159451633	49.05408481699708	166694
c903407ceae9feceb2a439cba6cf335105581b50	predictable configuration management in a randomized scheduling framework	time triggered;service provider;component based software;agent technology;quality of service;configuration management;random times	Configuration management is an essential part of system administration and component based software configuration. Autonomous configuration is becoming more important with the emergence of agent technology and heterogeneous nomadic environments. One important issue in configuration management is security, as the services provided by a system is often publicly available. This article addresses security in configuration management systems and proposes strategies for increasing security by randomized scheduling of actions constrained by a set of precedence relations. The special class of time-triggered policies is security-enhanced by adding randomized time-offsets and granularity reductions. These strategies makes it more difficult for malicious parties to detect and exploit configuration patterns resulting in a reduced quality of service and ultimately a damaged system.	autonomous robot;cfengine;configuration management;denial-of-service attack;emergence;knowledge-based configuration;quality of service;randomized algorithm;scheduling (computing);system administrator;threat (computer);tree accumulation	Mark Burgess;Frode Eika Sandnes	2001		10.3990/2.25	service provider;configuration management;configuration management database;real-time computing;quality of service;software configuration management;computer science;operating system;distributed computing;configuration management;configuration item;management;computer security;computer network	Embedded	-51.92624415772722	57.50995531192138	166710
8c7b4b1db83ad31af1e781ee7d508635c8c1066f	virtual machine based security architecture	virtual machine;virtual machine monitor;system reliability;kernel;reliability;driver reliability;driver functionality;performance evaluation;hypervisor layer;reference validation mechanism;virtual machine monitors;kernel memory management;monitoring;virtual machines;device drivers;security architecture;hypervisor layer virtual machine security architecture reference validation mechanism device driver driver reliability driver functionality kernel memory management;virtual machines device drivers operating systems computers security of data;driver circuits;driver circuits monitoring kernel virtual machine monitors security reliability performance evaluation;security;security of data;operating systems computers;device driver	In this paper a new approach based on using reference validation mechanism to improve system reliability is proposed. Since device drivers are the main cause of system failure, they are chosen as case study. Thus by improving driver reliability, security of the whole system is improved. To monitor driver functionality and also manage kernel memory, lightweight hypervisor layer is used, and reference validation mechanism is implemented in this layer.	computer security;data validation;device driver;hypervisor;kernel (operating system);virtual machine	Elahe Borghei;Reza Azmi;Alireza Ghahremanian;Hamed Nemati	2011	2011 World Congress on Internet Security (WorldCIS-2011)		embedded system;real-time computing;computer science;operating system	Arch	-54.112089882340626	56.645129155719516	167027
e5c823e8c0b4ec3b0648a525bc135310d67b5ec9	runtime verification of linux kernel modules based on call interception	verification;runtime analysis;kernel driver circuits instruments linux runtime binary codes resource management;kernel;instruments;runtime verification;fault simulation;program verification device drivers linux operating system kernels;linux kernel module;resource manager;resource management;binary codes;program verification;runtime;runtime analysis system runtime verification linux kernel module call interception device driver shadow state technique kedr framework;device drivers;kernel module;runtime analysis system;fault simulation kernel module driver verification call interception binary instrumentation;shadow state technique;driver circuits;driver;kernel method;linux;binary instrumentation;operating system kernels;device driver;kedr framework;call interception	Verification of Linux kernel modules and especially device drivers is a critically important task. However, due to the special nature of the kernel operation, it is very challenging to perform runtime analysis of particular kernel modules of interest without adverse influence on the rest of the kernel. Methods and tools for addressing this challenge are the main subject of this paper. The basic method for low-influence runtime analysis of interacting software modules is call interception. Shadow state techniques represent another method. In this paper, we discuss these methods including three different approaches to implement call interception. Conclusions are made about the most suitable ways for runtime analysis of kernel modules. Finally, we present KEDR framework, an extensible runtime analysis system for Linux kernel modules, which deploys these approaches to perform different types of analysis. The system can be used by the developers of kernel modules and, in particular, may be useful for building automated driver verification systems.	analysis of algorithms;device driver;interaction;kernel (operating system);linux;linux;loadable kernel module;memory leak;runtime verification;simulation;software bug	Vladimir V. Rubanov;Eugene A. Shatokhin	2011	2011 Fourth IEEE International Conference on Software Testing, Verification and Validation	10.1109/ICST.2011.20	sysfs;embedded system;kernel method;hybrid kernel;binary code;procfs;kernel;real-time computing;verification;computer science;resource management;operating system;runtime verification;epoll;kernel preemption;linux kernel	Embedded	-57.696357920605884	53.825553453597784	167151
526d4d8f9a5b6bf30ee2f5ceda710e246bf610fd	access control capability assessment method based on security entropy	classificatory access control model;security entropy;direct unauthorized access;right about access;information entropy;indirectly unauthorized access	In this paper, we propose analysis methods based on security entropy to overcome the problem of quantitative analysis, after going through the study of access control capability assessment for computer information system. At First, we computed the uncertainty how system determine irregular access behavior using the security entropy theory. Next, we defined the security theorem of classificatory information system, and proposed the standard of access control capability. Finally, we analyzed the typical access control models using the methods, and compared security and applicability of them. It proved that the method is appropriate for security quantitative analysis of access control model and for the evaluation of access control capability in information system.	access control;management information system	Tianwei Che;Jianfeng Ma;Na Li;Chao Wang	2014	JCP	10.4304/jcp.9.12.2804-2808	computer security model;computer access control;physical access;covert channel;asset;discretionary access control;computer science;access control;theoretical computer science;logical security;role-based access control;data mining;security testing;network access control;computer security;statistics;entropy	Security	-55.14107091296418	49.250118367093314	167157
61778c15ce7e11051fa79ec359d912eca941329d	security extensions for integrity and confidentiality in embedded processors	intellectual property;performance;embedded system;embedded systems;system design;cost effectiveness;design;embedded processor;secure processors;embedded computing	With current trends toward embedded computer systems’ ubiquitous accessibility, connectivity, diversification, and proliferation, security becomes a critical issue in embedded computer systems design and operation. Embedded computer systems are subjected to both software and physical attacks aimed at subverting system operation, extracting key secrets, or intellectual property theft. We propose several cost-effective architectural extensions suitable for mid-range to high-end embedded processors. These extensions ensure the integrity and confidentiality of both instructions and data, introducing low performance overhead (1.86% for instructions and 14.9% for data).	accessibility;central processing unit;computer;confidentiality;diversification (finance);embedded system;overhead (computing);systems design	Austin Rogers;Aleksandar Milenkovic	2009	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2009.06.002	embedded system;design;embedded operating system;parallel computing;real-time computing;performance;computer science;operating system;distributed computing;intellectual property	EDA	-51.784453171450245	56.00908976800625	167631
7857c88a380055d83a1a291c056185dbf944169e	rectify: black-box intrusion recovery in paas clouds		Web applications hosted on the cloud are exposed to cyberattacks and can be compromised by HTTP requests that exploit vulnerabilities. Platform as a Service (PaaS) offerings often provide a backup service that allows restoring application state after a serious attack, but all valid state changes since the last backup are lost. We propose Rectify, a new approach to recover from intrusions on applications running in a PaaS. Rectify is a service designed to be deployed alongside the application in a PaaS container. It does not require modifications to the software and the recovery can be performed by a system administrator. Machine learning techniques are used to associate the requests received by the application to the statements issued to the database. Rectify was evaluated using three widely used web applications - Wordpress, LimeSurvey and MediaWiki - and the results show that the effects of malicious requests can be removed whilst preserving the valid application data.	black box;machine learning;mediawiki;platform as a service;remote backup service;state (computer science);system administrator;tag cloud;vulnerability (computing);web application;while;wordpress	David R. Matos;Miguel L. Pardal;Miguel Correia	2017		10.1145/3135974.3135978	black box (phreaking);computer security;web application;rollback;system administrator;software;cloud computing;exploit;backup;computer science	Security	-54.660727395864576	58.46151519524653	167663
6835152f0ea02713ee6dbe159603f426aacf456c	mining on someone else's dime: mitigating covert mining operations in clouds and enterprises		Covert cryptocurrency mining operations are causing notable losses to both cloud providers and enterprises. Increased power consumption resulting from constant CPU and GPU usage from mining, inflated cooling and electricity costs, and wastage of resources that could otherwise benefit legitimate users are some of the factors that contribute to these incurred losses. Affected organizations currently have no way of detecting these covert, and at times illegal miners and often discover the abuse when attackers have already fled and the damage is done. In this paper, we present MineGuard, a tool that can detect mining behavior in real-time across pools of mining VMs or processes, and prevent abuse despite an active adversary trying to bypass the defenses. Our system employs hardware-assisted profiling to create discernible signatures for various mining algorithms and can accurately detect these, with negligible overhead (< 0.01%), for both CPU and GPU-based miners. We empirically demonstrate the uniqueness of mining behavior and show the effectiveness of our mitigation approach(≈ 99.7% detection rate). Furthermore, we characterize the noise introduced by virtualization and incorporate it into our detection mechanism making it highly robust. The design of MineGuard is both practical and usable and requires no modification to the core infrastructure of commercial clouds or enterprises.	adversary (cryptography);algorithm;antivirus software;central processing unit;computer cooling;cryptocurrency;dual independent map encoding;error detection and correction;graphics processing unit;hardware performance counter;hardware virtualization;hypervisor;malware;multiplexing;openvms;operating system;overhead (computing);real-time computing;real-time locating system;sensor;shutdown (computing);software deployment;superuser;type signature;user space	Rashid Tahir;Muhammad Huzaifa;Anupam Das;Mohammad Ahmad;Carl A. Gunter;Fareed Zaffar;Matthew Caesar;Nikita Borisov	2017		10.1007/978-3-319-66332-6_13	computer science;computer security;internet privacy;cloud computing;cryptocurrency;covert	Security	-54.65258976143058	57.35346498574547	167857
5bbf0448ac5d06d60b840b777d3116a706f39710	systematical vulnerability detection in browser validation mechanism	dynamic analysis systematical vulnerability detection browser validation mechanism unverified assumptions rich web applications client side applications security issues unauthentic data unauthentic scripts;web pages;taint;dom;origin;false negative;testing;browsers;online front ends;servers;graphical user interfaces;internet;engines;taint validation origin dom;security of data internet online front ends;graphic user interface;validation;false positive;security;browsers web pages security servers graphical user interfaces engines testing;security of data;scripting language;dynamic analysis	At present, the complexity of input and unverified assumptions about other components of the rich web applications is a problem requesting much more attention. Most client-side applications are designed without the full consideration of input validation. These issues can cause a new class of web threats. To deal with the security issues above, we classify and highlight a new class of vulnerabilities which is described as the browser input validation vulnerability. This class of vulnerability arises from unsafe usage of unauthentic data or scripts. These elements can be inserted in the frame and be executed in the scripting language engine of the browsers to make an assault. To systematically discover the vulnerabilities of this class, in this paper, we propose and implement one combination of dynamic analysis and comparison technique. By using several vulnerabilities as testing cases, the techniques are light-weight, efficient, and have low rate of false positive and false negative.		Chufeng Zeng;Qingxian Wang	2011		10.1109/CIS.2011.188	computer science;information security;operating system;graphical user interface;internet privacy;world wide web;computer security	Arch	-57.11020531885393	58.371291645901955	167952
2aa5738ad5a0c61877b20fbc9e5a765f88a55258	eos: exactly-once e-service middleware		Today's web-based E-services do not handle system failures well. One of the most prominent examples is unintentional purchase of multiple copies of the same item (e.g., a DVD) in an online store. This may happen when the user sees a browser timeout for the final “checkout” (“place order”) request caused by a short outage or overload of the network or the backend servers (typically during peak load). Whereas the request may have been successfully albeit slowly processed, the user may attempt to send the check-out request once again, e.g., by hitting the browser “refresh” button, unintentionally buying another copy of the same item. Another example is a home-banking application deployed by one of the biggest German banks. This application uses a so-called PIN/TAN security procedure. Each user is identified by a personal identification number (PIN). The bank hands over a list of transaction numbers (TANs) to each user. A TAN must be provided for each home-banking transaction to be accepted. For security reasons each TAN can be used only once. The following problem may arise (and has indeed happened to customers). After the first attempt to issue a money transfer order the user perceives a long delay resulting in an error message stating “this page is currently not available”. The user re-submits the request and the “resurrected” application responds with: “A TAN was used twice. Your TAN list has been frozen. Please contact your nearest branch office if you would like to have your TANs reactivated again”. Such phenomena occur because the “stateless” interaction paradigm of the web puts the burden of managing sessions, and in particular handling failures, on application programs. Unfortunately, failure handling logic can be fairly complex, and application programs often make errors when responding to errors. In particular, they may simply forget actions already taken, not only after a successful execution but also after a system failure, so that they cannot guarantee exactly-once execution. In contrast, our approach aims to place failure handling logic into a generic Internet middleware framework so that failures are masked from application programs (and users). Application programs are thus relieved from handling message timeouts and other exceptions caused by system failures. Based on the conceptual work in [2], we have developed a prototype system, coined EOS, that uses Microsoft’s IE5 browser on the client side and the popular Apache/PHP middleware as the middle tier of three-tier Web applications. With our specific modifications to the IE5 environment and the PHP servlet engine, the EOS prototype guarantees exactly-once execution for all requests. Our modifications are transparent to the application programs: no changes are required to servlet programs (i.e., PHP scripts) and no failure handling code is required by these programs other than application-level exceptions such as “item out of stock” etc. and dealing with back end transaction aborts. As a result, all business requests, including those with non-idempotent effects, are processed such that their effects occur exactly once. This guarantee includes messages seen by applications and users as well as data updates issued to backend servers. In addition to [2], conceptual work on recovery guarantees for Internet applications includes [3,5,7]. However, to our knowledge, our prototype is the first work that provides an implemented solution.	client-side;downtime;e-services;eos;error message;idempotence;identifier;java servlet;load profile;middleware;money;multitier architecture;online banking;online shopping;php;personal identification number;point of sale;programming paradigm;prototype;stateless protocol;web application	German Shegalov;Gerhard Weikum;Roger S. Barga;David B. Lomet	2002		10.1016/B978-155860869-6/50104-9	real-time computing;computer science;database;programming language;world wide web;computer security	OS	-53.15703984902134	60.33064717939624	168370
af38bb6b7c6446ce18910e9647326da9d6477a29	lightweight modeling and analysis of security concepts	security engineering;early experience;information security management;dsml;risk assessment;modeling and analysis	Modeling results from risk assessment and the selection of safeguards is an important activity in information security management. Many approaches for this activity focus on an organizational perspective, are embedded in heavyweight processes and tooling and require extensive preliminaries. We propose a lightweight approach introducing SeCoML – a readable language on top of an established methodology within an open framework. Utilizing standard tooling for creation, management and analysis of SeCoML models our approach supports security engineering and integrates well in different environments. Also, we report on early experiences of the language’s use.	embedded system;information security;risk assessment;security engineering;security management	Jörn Eichler	2011		10.1007/978-3-642-19125-1_10	computer security model;security information and event management;systems engineering;engineering;knowledge management;management science	SE	-55.31211398509258	48.68871560321448	168639
178fc755cef313f3231f1fba183570c02d5e471f	trustlite: a security architecture for tiny embedded devices	macquarie university institutional repository;researchonline;digital repository;routing;macquarie university;datacenter;hashing;multipath;ecmp	Embedded systems are increasingly pervasive, interdependent and in many cases critical to our every day life and safety. Tiny devices that cannot afford sophisticated hardware security mechanisms are embedded in complex control infrastructures, medical support systems and entertainment products [51]. As such devices are increasingly subject to attacks, new hardware protection mechanisms are needed to provide the required resilience and dependency at low cost.  In this work, we present the TrustLite security architecture for flexible, hardware-enforced isolation of software modules. We describe mechanisms for secure exception handling and communication between protected modules, enabling seamless interoperability with untrusted operating systems and tasks. TrustLite scales from providing a simple protected firmware runtime to advanced functionality such as attestation and trusted execution of userspace tasks. Our FPGA prototype shows that these capabilities are achievable even on low-cost embedded systems.	computer security;embedded system;exception handling;field-programmable gate array;firmware;interdependence;interoperability;operating system;pervasive informatics;protection mechanism;prototype;seamless3d;trusted execution technology;user space	Patrick Koeberl;Steffen Schulz;Ahmad-Reza Sadeghi;Vijay Varadharajan	2014		10.1145/2592798.2592824	multipath propagation;data center;routing;real-time computing;digital library;hash function;equal-cost multi-path routing;computer science;operating system;distributed computing;computer security	OS	-51.25834952173877	56.58512589886947	168731
ea44caa7834ca0452480554b0e98459a9abe3c03	system-on-chip security assurance for iot devices: cooperations and conflicts		Security is a critical component for computing devices targeted towards Internet-of-Things applications. Unfortunately, IoT security assurance is a challenging enterprise, involving cooperation and conflicts among a variety of stakeholders working in concert with a variety of architecture and design collateral generated across various points in a complex design life-cycle. Furthermore, the long life and aggressive energy/performance needs of IoT applications bring in new challenges to security designs. In this paper we discuss some of the challenges, the current industrial practice to address them, some gaping holes in the state of the practice, and potential research directions to address them.	computer security;emergence;power management;system on a chip;validator	Sandip Ray	2017	2017 IEEE Custom Integrated Circuits Conference (CICC)	10.1109/CICC.2017.7993611	architecture;systems engineering;system on a chip;control engineering;collateral;software security assurance;computer security;internet of things;engineering	EDA	-56.16462519595818	51.06862990473086	168772
079460eeab2b9d3d9b390a3b432c6a7e734b1e62	modular protections against non-control data attacks	c language;data encapsulation;data integrity;formal logic;formal specification;program compilers;programming language semantics;security of data;yarra programmers;compiler;critical data types;data integrity requirements;data structures;language based security;local reasoning;modular protections;non control data attacks;pointers;program logic;runtime system;semantics;hoare logic;control-flow integrity;data isolation;frame rule;language-based security;non-control data attack	This paper introduces Yarra, a conservative extension to C to protect applications from non-control data attacks. Yarra programmers specify their data integrity requirements by declaring critical data types and ascribing these critical types to important data structures. Yarra guarantees that such critical data is only written through pointers with the given static type. Any attempt to write to critical data through a pointer with an invalid type (perhaps because of a buffer overrun) is detected dynamically. We formalize Yarra's semantics and prove the soundness of a program logic designed for use with the language. A key contribution is to show that Yarra's semantics are strong enough to support sound local reasoning and the use of a frame rule, even across calls to unknown, unverified code. We evaluate a prototype implementation of a compiler and runtime system for Yarra by using it to harden four common server applications against known non-control data vulnerabilities. We show that Yarra defends against these attacks with only a negligible impact on their end-to-end performance.	bounds checking;buffer overflow;compiler;control flow;control-flow integrity;data integrity;data structure;end-to-end encryption;end-to-end principle;executable space protection;feedback;frame language;function pointer;hardening (computing);ibm notes;interprocedural optimization;library (computing);microsoft windows;need to know;overhead (computing);password;pointer (computer programming);programmer;protection mechanism;prototype;requirement;return-oriented programming;return-to-libc attack;runtime system;server (computing);source lines of code;virtual method table	Cole Schlesinger;Karthik Pattabiraman;Nikhil Swamy;David Walker;Benjamin G. Zorn	2011	2011 IEEE 24th Computer Security Foundations Symposium	10.3233/JCS-140502	parallel computing;computer science;data integrity;database;programming language	Security	-54.614015196219825	54.203703093301925	168881
02ffbcbced98288c6bb4fa27ecec9e13938dd6fd	secure robotics	reliability;surges;robots	Security is an under-studied problem within robotics and Internet of Things. Part of the reason for this is that currently most robots and IoT devices remain in the lab at all times. Recent trends show more robots and IoT devices moving “out into the wild” with no humans to protect them. This creates vulnerabilities beyond the well known and well studied network/internet based threat. These threats include external network, local network, software, physical access, tricking the artificial intelligence, and intellectual property theft. This document discribes the above and shows our current work towards detection and mitigation.	artificial intelligence;internet of things;malware;physical access;robot;robotics;threat (computer);whole earth 'lectronic link	Daniel M. Lofaro	2016	2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2016.7734049	robot;simulation;computer science;artificial intelligence;reliability;internet privacy;computer security	Robotics	-52.121114548702074	60.27653271950916	169184
1549603c34a13c6a8bebc99bcb103c19fab411c4	controlling the dissemination and disclosure of healthcare events		Information is central to healthcare: for proper care, information must be shared. Modern healthcare is highly collaborative, involving interactions between users from a range of institutions, including primary and secondary care providers, researchers, government and private organisations. Each has specific data requirements relating to the service they provide, and must be informed of relevant information as it occurs. Personal health information is highly sensitive. Those who collect/hold data as part of the care process are responsible for protecting its confidentiality, in line with patient consent, codes of practice and legislation. Ideally, one should receive only that information necessary for the tasks they perform—on a need-to-know basis. Healthcare requires mechanisms to strictly control information dissemination.Many solutions fail to account for the scale and heterogeneity of the environment. Centrally managed data services impede the local autonomy of health institutions, impacting security by diminishing accountability and increasing the risks/impacts of incorrect disclosures. Direct, synchronous (request-response) communication requires an enumeration of every potential information source/sink. This is impractical when considering health services at a national level. Healthcare presents a data-driven environment highly amenable to an event-based infrastructure, which can inform, update and alert relevant parties of incidents as they occur. Event-based data dissemination paradigms, while efficient and scalable, generally lack the rigorous access control mechanisms required for health infrastructure. This dissertation describes how publish/subscribe, an asynchronous, push-based, manyto-many middleware communication paradigm, is extended to include mechanisms for actively controlling information disclosure. We present Interaction Control: a data-control layer above a publish/subscribe service allowing the definition of context-aware policy rules to authorise information channels, transform information and restrict data propagation according to the circumstances. As dissemination policy is defined at the broker-level and enforced by the middleware, client compliance is ensured. Although policy enforcement involves extra processing, we show that in some cases the control mechanisms can actually improve performance over a general publish/subscribe implementation. We build Interaction Control mechanisms into integrated database-brokers to provide a rich representation of state; while facilitating audit, which is essential for accountability. Healthcare requires the sharing of sensitive information across federated domains of administrative control. Interaction Control provides the means for balancing the competing concerns of information sharing and protection. It enables those responsible for information to meet their data management obligations, through specification of fine-grained disclosure policy. To Amar, Charlene, Richelle and Jessica	access control;asynchronous i/o;authorization;code;confidentiality;control system;information sensitivity;information source;interaction;middleware;need to know;privacy policy;programming paradigm;publish–subscribe pattern;request–response;requirement;scalability;software propagation	Jatinder Singh	2010			internet privacy;access control;health care;data management;information sensitivity;information sharing;dissemination;government;data as a service;computer science	Security	-49.66857047428333	52.205060582087235	169228
1628c2ea590656aa8ab27f49328922dd18485fe3	modeling of dynamic trust contracts for industry 4.0 systems		Due to their close relation to physical and virtual entities (humans, machines, processes, etc.) including their changing state and context, modern cyber-physical and IoT systems exhibit a high degree of architectural dynamicity. While sharing of data among all the entities of the system is the key driver to the efficiency of the system, it is at the same time necessary to effectively control which data are shared, with whom, and in which context so as to prevent potential misuse. The problem however is that traditional methods to security and privacy, which typically rely on rigid hierarchies, cannot easily cope with the high degree of architectural dynamicity. In this paper, we outline an approach to ensure security and privacy on the architectural level in systems with dynamic architectures. In particular, we focus on a) data tracking using data flows and data processing described in system architectures, b) descriptions of dynamic sharing scenarios including decision derivation based on the current situation, and c) a runtime analysis platform that regulates data exchange. We ground the approach and illustrate it in the Industry 4.0 setting, as this is the domain in which we apply our approach as part of our project Trust 4.0, but we believe it can be used in other applications domains as well.	analysis of algorithms;computer security;emoticon;entity;industry 4.0;privacy	Rima Al Ali;Robert Heinrich;Petr Hnetynka;Adrian Juan Verdejo;Stephan Seifermann;Maximilian Walter	2018		10.1145/3241403.3241450	systems engineering;computer science;industry 4.0;tracking system;hierarchy;data exchange;data processing;internet of things	Security	-49.06820013571791	54.29710254094038	169335
4ad082371112a866ca526a67d1c9303449afa438	wide-area situational awareness for critical infrastructure protection	context awareness;control systems;availability;critical infrastructures;critical infrastructure protection cybersecurity situational awareness context awareness;situational awareness;monitoring;wasa defense solutions wide area situational awareness critical infrastructure protection wasa methodological framework;grippers;computer security context awareness integrated circuits complex networks monitoring knowledge management control systems;cybersecurity;security;integrated circuits;context;critical infrastructure protection	Despite successive attempts to protect critical infrastructures against incidents and malicious threats by using traditional situational awareness solutions, the complex and critical nature of these infrastructures makes this adaptation difficult. For this reason, experts are reconsidering the topic of Wide-Area Situational Awareness (WASA) to provide monitoring of performance at all times from anywhere while ensuring dynamic prevention and response services. Given the novelty of this new research field, a WASA methodological framework together with a set of requirements for awareness construction are presented in this paper in order to help in the development and commissioning of future WASA defense solutions.	critical infrastructure protection;malware;requirement	Cristina Alcaraz;Javier López	2013	Computer	10.1109/MC.2013.72	situation awareness;availability;computer science;knowledge management;control system;information security;management science;computer security	Security	-57.26173651020708	50.89339467981936	169359
5875a75a88f60c6bdb0535e5741eaaba93c75330	common approach to functional safety and system security in building automation and control systems	life cycle;product life functional safety system security building automation control systems modern automated buildings;system security;productive life;control system;building management systems;secure system;communication protocol;automation automatic control control systems communication system security data security protocols buildings computer security health and safety computer network reliability	Building automation and control systems (BACS) are an important part of modern automated buildings. More and more they are also responsible for functions affecting people 's safety, security and health. Thus the respective technology is supposed to work reliably, securely, safely and efficiently. The two important features of such a BACS are functional safety and system security (short safety and security) of both the network nodes and the communication protocols. Up to now little effort has been made to specify a life cycle for a safe and secure BACS that defines requirements for the different stages of the product life of a BACS. Special focus is related to the commonalities between the development of safety and security systems to benefit from these commonalities in development.	access control;computer security;control system;data integrity;it risk management;new product development;overhead (computing);requirement;secure communication;synergy	Thomas Novak;Albert Treytl;Peter Palensky	2007	2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007)	10.1109/EFTA.2007.4416910	software security assurance;control system security;computer security model;cloud computing security;reliability engineering;biological life cycle;communications protocol;building management system;countermeasure;security through obscurity;security information and event management;security engineering;asset;computer science;systems engineering;engineering;control system;security service;security testing;network access control;computer security;computer network	EDA	-56.540100350463625	50.02929587083909	169916
5059dcadda420a869171d672f55f840800e1dfda	property verification for generic access control models	security properties;combinatorial covering array;automated test case generation generic access control model security property verification specification language model checker combinatorial covering array;model checker;generic access control model;formal specification;authorisation;government;program verification;specification language;software assurance access control modeling combinatorial testing;automated test case generation;access control ubiquitous computing government protection;program testing;combinatorial testing;specification languages;access control models;ubiquitous computing;covering array;access control;software assurance;security property verification;modeling;specification languages authorisation formal specification program testing program verification;conferences	To formally and precisely capture the security properties that access control should adhere to, access control models are usually written to bridge the rather wide gap in abstraction between policies and mechanisms. In this paper, we propose a new general approach for property verification for access control models. The approach defines a standardized structure for access control models, providing for both property verification and automated generation of test cases. The approach expresses access control models in the specification language of a model checker and expresses generic access control properties in the property language. Then the approach uses the model checker to verify these properties for the access control models and generates test cases via combinatorial covering array for the system implementations of the models.	access control;conformance testing;model checking;separation of mechanism and policy;specification language;temporal logic;test case	Vincent C. Hu;D. Richard Kuhn;Tao Xie	2008	2008 IEEE/IFIP International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2008.22	specification language;computer science;access control;theoretical computer science;formal specification;database;programming language;ubiquitous computing;government	SE	-52.506471393827134	50.676024165385016	169942
b45df4d7740491a46f3897b74b580f91b3087eba	approach to enhance the efficiency of security operation centers to heterogeneous ids landscapes		Critical infrastructures include large scale environments with different platforms and / or platform generations. The maintenance in- terval of such large scaled, distributed systems to patch vulnerabilities increases with the amount of entities. IDS are necessary to protect the vulnerable system / entity until the patch will be applied to the dis- tributed entity. This paper presents an approach to separate the IDS manager from the rest of an IDS by a standardized IDS parameteri- zation independent of its scope (host based or network based IDS) and vendor. The exchange of the parameterization was integrated via commu- nication modules in three open source IDS to demonstrate the common applicability of the format. An enhanced IDS model of the IETF will be illustrated.		Björn-C. Bösch	2012		10.1007/978-3-642-41485-5_1	theoretical computer science;data mining;distributed computing	Crypto	-50.15080138822647	55.33905982667454	170046
020f55a4bb2a0ab606d3e7909d823ed939e1e93c	fine-grained access-control for the puppet configuration language	complex input language;design pattern;xacml policy;decent authorisation;configuration input;existing tool;system configuration tool;puppet configuration language;it infrastructure;fine-grained authorisation;puppet tool;fine-grained access-control	System configuration tools automate the configuration and management of IT infrastructures. However these tools fail to provide decent authorisation on configuration input. In this paper we apply fine-grained authorisation of individual changes on a complex input language of an existing tool. We developed a prototype that extracts meaningful changes from the language used in the Puppet tool. These changes are authorised using XACML. We applied this approach successfully on realistic access control scenarios and provide design patterns for developing XACML policies.	access control;authorization;design pattern;prototype;system configuration;xacml	Bart Van Brabant;Joris Peeraer;Wouter Joosen	2011			computer science;database;world wide web	SE	-48.9054498983205	49.62384573938312	170129
86a3304c507198c1fcfe995371cb61ed864c5680	service security requirement profiles for telecom: how software engineers may tackle security	formal specification;information security;risk analysis;availability;telecommunication security formal specification security of data;development process;software engineering;security requirement profile;resilience;security requirements;telecommunication security;privacy information security resilience availability risk analysis;holistic security requirement;security of data;business oriented security requirement profiles service security requirement profiles telecom software engineers security requirement engineering;privacy;security requirement profile holistic security requirement service security requirement;service security requirement	Security requirement engineering for services is in practice frequently performed by security non-experts. For them the security requirements and their dependencies are not directly known. To mitigate this, the paper suggests the usage of a business oriented security requirement profiles (e.g. VoIP, IP-TV...) containing information security, privacy, fraud/abuse, resilience and assurance requirements. The criteria and the creation process for such reusable and adaptable profiles are shown. Then the requirement profiles are set in context with a development process. We show how to stepwise adjust the profile to the actual service needs at development stages where the budget and knowledge are available. Finally, experiences from real projects are presented.	emoticon;iptv;information security;requirement;requirements engineering;software engineer;stepwise regression	Albin Zuccato;Nils Daniels;Cheevarat Jampathom	2011	2011 Sixth International Conference on Availability, Reliability and Security	10.1109/ARES.2011.81	software security assurance;information security audit;computer security model;standard of good practice;cloud computing security;reliability engineering;itil security management;security through obscurity;security information and event management;security engineering;security convergence;covert channel;asset;information security;software engineering;security service;business;security testing;network security policy;computer security	SE	-55.522842268711926	48.04503764846973	170307
6a7e3a7e2d8d222142b0745ce46724771c8316e2	unixvisual: a visualization tool for teaching the unix permission model	visualization;security	This paper describes UNIXvisual, which helps students learn access control in UNIX. UNIXvisual is aimed both at novice users, who need only to control access to their own files, and students of computer security, who need a deeper and more comprehensive understanding. UNIXvisual allows students to analyze permission settings without the need for a special environment. It allows a student to trace the value and effect of credentials within an executing process. It also provides a mechanism for instructors to give quizzes UNIXvisual gives instructors flexibility in covering the material by supporting self-study, lowers the overhead required for teaching access control by running under an ordinary user account, and enhances learning by leveraging visualization. UNIXvisual is available for download and runs on the Linux and MacOS platforms.	access control;computer security;credential;download;file system permissions;linux;overhead (computing);unix;user (computing)	Man Wang;Jean Mayo;Ching-Kuang Shene;Steve Carr;Chaoli Wang	2016		10.1145/2899415.2925479	simulation;visualization;human–computer interaction;computer science;information security;operating system;software engineering;programming language;world wide web	Security	-54.015330644756325	58.66215484827296	170319
d6121fa02255455ee2a60f7bf21d049f2d8d3ae6	talos: no more ransomware victims with formal methods	malware;mobile;ransomware;security;model checking;android	Ransomware is a very effective form of malware that is recently spreading out on an impressive number of workstations and smartphones. This malware blocks the access to the infected machine or to the files located in the infected machine. The attackers will restore the machine and files only after the payment of a certain amount of money, usually given in the form of bitcoins. Commercial solutions are still ineffective to recognize the last variants of ransomware, and the problem has been poorly investigated in literature. In this paper we discuss a methodology based on formal methods for detecting ransomware malware on Android devices. We have implemented our method in a tool named Talos. We evaluate the method, and the obtained results show that Talos is very effective in recognizing ransomware (accuracy of 0.99) even when it is obfuscated (accuracy still remains at 0.99).	android;antivirus software;bitcoin;botnet;computer aided verification;fm broadcasting;formal methods;malware;mobile app;model checking;money;obfuscation (software);rootkit;sensor;smartphone;surround sound;temporal logic;workstation	Aniello Cimitile;Francesco Mercaldo;Vittoria Nardone;Antonella Santone;Corrado Aaron Visaggio	2017	International Journal of Information Security	10.1007/s10207-017-0398-5	model checking;computer security;formal methods;computer science;android (operating system);malware;ransomware;workstation	Security	-58.00102048583289	58.871406353428654	170383
a6ec0bdded544131c3ab902e7a21e94ef324b320	support for discretionary role based access control in acl-oriented operating systems	discretionary role;access control;acl-oriented operating system;operating system;role based access control	‘Ilie iml~lemrlil.at,ioli of discr&ionary role-lmscd it<‘cess cY)ntrol nic~c&anisnis in standard operat,ing syst)ems like [inix suffers from t#he inahilit,y of t,hta systclii t,o allow a user t,o r&rict, his processes’ cont,rol over his own ohjtct~s. Hy cxploit,ing t,he user’s a~t‘ss right,s tro,jan horses, possibly hidden in down1oadetl (~x(~cutabI(~ corit,enl,, (‘an u~itlcrrriine t tic access c-0111.rol policy l,o perform t.heir malicious t,asks. This paper present,s an approach t.o restrict the rights of procPssr,s l)y switching bct,wccn hicrarcliically organized user drfiued subdomains with simple system calls. ‘JI~~w doniains can be used t,o implenient certain disc,rr,t iona.ry role based access control policies.	html application;operating system;role-based access control;system call	Christian Friberg;Achim Held	1997		10.1145/266741.266763	computer security	Security	-52.31474821830178	54.46446823240646	170652
5cfa823790970ac98b60272dde92ec0c3c437ec1	data loss prevention based on data-driven usage control	user interfaces application program interfaces business data processing operating systems computers security of data;windows api data driven usage control inadvertent data disclosure corporate information security data loss prevention systems confidential data monitoring access improper handling complex security policies cardinal constraints temporal constraints event execution uc4win microsoft windows operating systems fine grained policy based protection data loss related event detection data loss related event control individual function calls function call interposition techniques;usage control;microsoft windows security;dynamic data flow tracking data loss prevention usage control microsoft windows security;dynamic data flow tracking;security monitoring business data models kernel context containers;data loss prevention	Inadvertent data disclosure by insiders is considered as one of the biggest threats for corporate information security. Data loss prevention systems typically try to cope with this problem by monitoring access to confidential data and preventing their leakage or improper handling. Current solutions in this area, however, often provide limited means to enforce more complex security policies that for instance specify temporal or cardinal constraints on the execution of events. This paper presents UC4Win, a data loss prevention solution for Microsoft Windows operating systems that is based on the concept of data-driven usage control to allow such a fine-grained policy-based protection. UC4Win is capable of detecting and controlling data-loss related events at the level of individual function calls. This is done with function call interposition techniques to intercept application calls to the Windows API in combination with methods to track the flows of confidential data through the system.	application programming interface;confidentiality;data loss prevention software;information security;microsoft windows;operating system;sensor;spectral leakage;visual intercept	Tobias Wüchner;Alexander Pretschner	2012	2012 IEEE 23rd International Symposium on Software Reliability Engineering	10.1109/ISSRE.2012.10	reliability engineering;real-time computing;computer science;operating system;security and safety features new to windows vista;data mining;data security;windows rally;computer security;next-generation secure computing base	Arch	-52.72402536877221	54.232227274722376	170736
3a065f1e9e50503c09e7b174bb8a6f6fb280ebbe	accessminer: using system-centric models for malware protection	anomaly based detector;model generation;large scale;real world application;false positive rate;operating system;malware;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;system call malware anomaly based detector;access control;false positive;building model;system call;intrusion detection system	Models based on system calls are a popular and common approach to characterize the run-time behavior of programs. For example, system calls are used by intrusion detection systems to detect software exploits. As another example, policies based on system calls are used to sandbox applications or to enforce access control. Given that malware represents a significant security threat for today's computing infrastructure, it is not surprising that system calls were also proposed to distinguish between benign processes and malicious code.  Most proposed malware detectors that use system calls follows program-centric analysis approach. That is, they build models based on specific behaviors of individual applications. Unfortunately, it is not clear how well these models generalize, especially when exposed to a diverse set of previously-unseen, real-world applications that operate on realistic inputs. This is particularly problematic as most previous work has used only a small set of programs to measure their technique's false positive rate. Moreover, these programs were run for a short time, often by the authors themselves.  In this paper, we study the diversity of system calls by performing a large-scale collection (compared to previous efforts) of system calls on hosts that run applications for regular users on actual inputs. Our analysis of the data demonstrates that simple malware detectors, such as those based on system call sequences, face significant challenges in such environments. To address the limitations of program-centric approaches, we propose an alternative detection model that characterizes the general interactions between benign programs and the operating system (OS). More precisely, our system-centric approach models the way in which benign programs access OS resources (such as files and registry entries). Our experiments demonstrate that this approach captures well the behavior of benign programs and raises very few (even zero) false positives while being able to detect a significant fraction of today's malware.	access control;experiment;interaction;intrusion detection system;malware;operating system;sensor;system call	Andrea Lanzi;Davide Balzarotti;Christopher Krügel;Mihai Christodorescu;Engin Kirda	2010		10.1145/1866307.1866353	intrusion detection system;simulation;type i and type ii errors;false positive rate;computer science;access control;cryptovirology;malware;world wide web;computer security	Security	-58.24368316814683	59.965988383049684	171032
2ea12220d3b0e283c183a0c928d728acf80c6aaf	evaluating damages caused by information systems security incidents		As organizations adopt increasingly sophisticated information systems, the challenge of protecting those systems becomes enormous. Accordingly, the single critical decision security managers have to make is the amount an organization is willing to spend on security measures to protect assets of the organization. To arrive at this decision, security mangers need to know explicitly about the assets of their organizations, the vulnerability of their information systems to different threats, and their potential damages. Each threat and vulnerability must be related to one or more of the assets requiring protection. This means that prior to assessing damages we need to identify assets. Logical and physical assets can be grouped into five categories: 1) InformationDocumented (paper or electronic) data or intellectual property used to meet the mission of an organization, 2) SoftwareSoftware applications and services that process, store, or transmit information, 3) HardwareInformation technology physical devices considering their replacement costs, 4) PeopleThe people in an organization who posses skills, knowledge, and experience that are difficult to replace and, 5) SystemsInformation systems that process and store information (systems being a combination of information, software, and hardware assets and any host, client, or server being considered a system). Various units of value or metrics for valuation of assets may be used. The common metric is monetary, which is generally used for data that represent money where the threat is direct financial theft or fraud. Some assets are difficult to measure in absolute terms but can be measured in relative ways, for example information. The value of information can be measured as a fraction or percentage of total budget, assets, or worth of a business in relative fashion. Assets may also be ranked by sensitivity or	information security;information system;money;need to know;server (computing);threat (computer);value (ethics)	Fariborz Farahmand;Shamkant B. Navathe;Gunter P. Sharp;Philip H. Enslow	2004		10.1007/1-4020-8090-5_7	risk analysis;forensic engineering;computer security	Security	-61.34930803710189	50.008973803151775	171087
96c4320c708aab257f985e70638e429cc001d3c6	engineering safe and secure cyber-physical systems - the specification pearl approach			cyber-physical system	Roman Gumzej	2016		10.1007/978-3-319-28905-2		Logic	-50.37124240504188	47.414909205191904	171171
ade48449bca10f978ab3ee5f6fe447cf2a6ff633	trusted mission operation - concept and implementation		Small unmanned vehicles support many mission critical tasks. However, the provenance of these systems is usually not known, devices may be deployed in contested environments, and operators are often not computer system experts. Yet, the benefits of these systems outweigh the risks, and critical tasks and data are delegated to these systems without a sound basis for assessing trust. This paper describes an approach that can determine an operator’s trust in a mission system and applies continuous monitoring to indicate if the performance is within a trusted operating region. In an early prototype we (a) define a multi-dimensional trusted operating region for a given mission, (b) monitor the system in-mission, and (c) detect when anomalous effects put the mission at risk.	computation;computer;cyber resilience;embedded system;emergence;emoticon;formal methods;mission critical;overhead (computing);prototype;requirement;runtime verification;software transactional memory;unmanned aerial vehicle	Aaron Paulos;Partha P. Pal;Shane S. Clark;Kyle Usbeck;Patrick Hurley	2017		10.1007/978-3-319-67531-2_28	real-time computing;operator (computer programming);mission critical;computer science;continuous monitoring	OS	-57.130016730711255	53.50915059078882	171248
25e4443660ed5a5c9e8094cfd40653c786dd2e5e	semantics-preserving dissection of javascript exploits via dynamic js-binary analysis	malicious javascript;exploit analysis	JavaScript exploits impose a severe threat to computer security. Once a zero-day exploit is captured, it is critical to quickly pinpoint the JavaScript statements that uniquely characterize the exploit and the payload location in the exploit. However, the current diagnosis techniques are inadequate because they approach the problem either from a JavaScript perspective and fail to account for “implicit” data flow invisible at JavaScript level, or from a binary execution perspective and fail to present the JavaScript level view of exploit. In this paper, we propose JScalpel, a framework to automatically bridge the semantic gap between the JavaScript level and binary level for dynamic JS-binary analysis. With this new technique, JScalpel can automatically pinpoint exploitation or payload injection component of JavaScript exploits and generate minimized exploit code and a Proof-of-Vulnerability (PoV). Using JScalpel, we analyze 15 JavaScript exploits, 9 memory corruption exploits from Metasploit, 4 exploits from 3 different exploit kits and 2 wild exploits and successfully recover the payload and a minimized exploit for each of the exploits.	computer security;dataflow;exploit (computer security);exploit kit;javascript;memory corruption;metasploit;zero-day (computing)	Xunchao Hu;Aravind Prakash;Jinghan Wang;Rundong Zhou;Yao Cheng;Heng Yin	2016		10.1007/978-3-319-45719-2_12	computer science;operating system;internet privacy;world wide web	Security	-56.14002066467084	56.96436095320215	171486
6f131299621c933c281633abfd9bed49d49e83c3	graph-based specification of access control policies	policy verification;conflict detection;access control list;graphical constraints;graph transformation;access control policy;access control;security;security policy;consistency	Graph-based specification formalisms for access control (AC) policies combine the advantages of an intuitive visual framework with a rigorous semantical foundation that allows the detailed comparison of different policy models. A security policy framework specifies a set of (constructive) rules to build the system states and sets of positive and negative (declarative) constraints to specify wanted and unwanted substates. Several models for AC (e.g. role-based, lattice-based or an access control list) can be specified in this framework. The framework is used for an accurate analysis of the interaction between policies and of the behavior of their integration with respect to the problem of inconsistent policies. Using formal properties of graph transformations, it is possible to systematically detect inconsistencies between constraints, between rules and between a rule and a constraint and lay the foundation for their resolutions.	access control	Manuel Koch;Luigi V. Mancini;Francesco Parisi-Presicce	2005	J. Comput. Syst. Sci.	10.1016/j.jcss.2004.11.002	computer science;security policy;information security;access control;theoretical computer science;data mining;database;consistency;algorithm	DB	-52.6999821301761	50.96183525724464	171685
b94be5d714466b3102676cfd5fc8019829d344ee	distributed platform for the analysis of cryptographic algorithms	protocols;industries;computer architecture;servers;graphical user interfaces;cryptography;context	Data protection and information security have always been intricate problems of the majority of software applications which have been deployed throughout the Internet. Consequently, a substantial effort has been put into the creation and development of a wide variety of solutions to tackle this very issue. The aim of this paper is to offer a means of performance measurement and security validation for some of the encryption algorithms which are extensively used in today's industry (DES, 3DES, AES, etc.), as well as some hash functions. Therefore, the evaluation platform takes on the above mentioned algorithms from two very divergent perspectives: one of them focuses mainly on CPU vs. GPU performance issues, whereas the latter tackles the problem of randomness of the encrypted results by comparison to several strict criteria. In order to achieve these goals, the platform provides a graphical user interface which eases interactions such as: tests selection, worker attachment or removal, events logging, input provision and output analysis. The proposed solution represents an evaluation platform that performs a wide range of tests on hash and symmetric key algorithms in order to deduce their performance and behavior on multiple architectures, as well as various NIST tests, on different environments.	attachments;central processing unit;encryption;graphical user interface;graphics processing unit;hash function;information security;interaction;privacy;randomness;symmetric-key algorithm;triple des	Vlad-Cosmin Ozunu;Cezar-Costin Pirvu;Catalin Adrian Leordeanu;Valentin Cristea	2016	2016 10th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS)	10.1109/CISIS.2016.139	simulation;computer science;theoretical computer science;world wide web	DB	-49.176702797724744	59.640481126886094	171782
4b99fbe18fe4a8cd1d797ed073fb92fb71bd2dcf	security assurance for smart contract		Currently, Bitcoin and Ethereum are the two most popular cryptocurrency systems, especially Ethereum. It permits complex financial transactions or rules through scripts, which is called smart contracts. Since Ethereum smart contracts hold millions of dollars, their execution correctness is crucial against attacks which aim at stealing the assets. In this paper, we proposed a security assurance method for smart contract source code to find potential security risks. It contains two main functions, the first is syntax topological analysis of smart contract invocation relationship, to help developers to understand their code structure clearly; the second is logic risk (which may lead to vulnerabilities) detection and location, and label results on topology diagram. For developers' convenience, we have built a static analysis tool called SASC to generate topology diagram of invocation relationship and to find potential logic risks. We have made an evaluation on 2,952 smart contracts, experiment results proved that our method is intuitive and effective.	bitcoin;correctness (computer science);cryptocurrency;diagram;ethereum;scripting language;smart contract;static program analysis	Ence Zhou;Song Hua;Bingfeng Pi;Jun Sun;Yashihide Nomura;Kazuhiro Yamashita;Hidetoshi Kurihara	2018	2018 9th IFIP International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2018.8328743	diagram;computer security;distributed computing;correctness;source code;smart contract;computer science;scripting language;cryptocurrency;software security assurance;financial transaction	SE	-57.89769809421143	58.303994233670956	172240
f45b27663bf5d4670449b9dbb68e1b6a778a876b	html validation for php web applications		A wide range of websites in World Wide Web are deemed invalid as they do not adhere to the HTML standards defined under W3C. Websites which are not well-formed may cause performance degradation for some applications and poses compatibility issues with some browsers. Furthermore, it is harder to render a malformed webpage using state of the art web browsers. To validate a HTML page, a wide range of HTML document validation tools have been developed to validate HTML pages but these tools is not effective in a realm of dynamic web applications such as PHP due to its diversified and complex nature. These tools typically analyze PHP in a static manner which failed to provide meaningful accurate validation on real world applications. In this paper, we present a novel tool for validating dynamic PHP web application in a robust manner which takes into consideration the syntax as well as operation of PHP application.	html;php;web application	Chee Sheen Chan;Jer Lang Hong	2014	Austr. J. Intelligent Information Processing Systems		html;web accessibility initiative;computer science;database;internet privacy;client-side scripting;world wide web	Web+IR	-57.45161089354936	57.79241596199586	172341
9b6ef07fee4771fd774b597b3d1679e88306d4ef	quantitative information flow as network flow capacity	verification;lenguaje programacion;valgrind;entrada salida;reachability;maximum flow;measurement;langage c;programming language;traitement flux donnee;implicit flows;implicit flow;performance;securite informatique;branching;ejecucion programa;satisfiability;memcheck;program execution;confidentiality;input output;computer security;information flow;c language;flujo red;lines of code;marcador;pointer;information flow analysis;execution programme;ramificacion;asequibilidad;seguridad informatica;theory;data flow processing;control flow;langage programmation;atteignabilite;pointeur;ramification;information disclosure;analyse information;network flow;security;security policy;tainting;information analysis;languages;flot reseau;privacy;minimum cut;dynamic analysis;lenguaje c;entree sortie	"""We present a new technique for determining how much information about a program's secret inputs is revealed by its public outputs. In contrast to previous techniques based on reachability from secret inputs (tainting), it achieves a more precise quantitative result by computing a maximum flow of information between the inputs and outputs. The technique uses static control-flow regions to soundly account for implicit flows via branches and pointer operations, but operates dynamically by observing one or more program executions and giving numeric flow bounds specific to them (e.g., """"17 bits""""). The maximum flow in a network also gives a minimum cut (a set of edges that separate the secret input from the output), which can be used to efficiently check that the same policy is satisfied on future executions. We performed case studies on 5 real C, C++, and Objective C programs, 3 of which had more than 250K lines of code. The tool checked multiple security policies, including one that was violated by a previously unknown bug."""	c++;control flow;flow network;maximum flow problem;minimum cut;objective-c;pointer (computer programming);reachability;software bug;source lines of code	Stephen McCamant;Michael D. Ernst	2008		10.1145/1375581.1375606	input/output;maximum flow problem;verification;flow network;pointer;information flow;confidentiality;minimum cut;branching;performance;computer science;security policy;information security;theoretical computer science;distributed computing;dynamic program analysis;ramification;data analysis;programming language;control flow;reachability;privacy;source lines of code;theory;algorithm;measurement;satisfiability	PL	-54.682358223528155	52.13071912337964	172374
f626f59875a7e4619f9fc4998c619c18318b9775	a formal model for unix setuid	kernel;trademarks;formal model;application software;unix setuid;protection access control operating systems kernel computer architecture hardware security application software computer interfaces trademarks;gemsos formal security policy model;discretionary access control;computer architecture;protection;discretionary access control formal model unix setuid set user identification gemsos architecture gemsos formal security policy model bell and lapadula model gemsos dac;gemsos architecture;access control;gemsos dac;computer interfaces;security;security policy;set user identification;security of data;operating systems computers;bell and lapadula model;unix;unix operating systems computers security of data;operating systems;hardware	The UNIX setuid mechanism is described in the context of the GEMSOS architecture. Motivation for modeling setuid is given. Modeling and policy requirements for the control of the setuid mechanism are presented. The GEMSOS formal security policy model is compared with the Bell and LaPadula model(1). The Bell and LaPadula model is shown to not admit the actions of a setuid mechanism. Features of the GEMSOS DAC model are described that represent the actions of the UNIX setuid mechanism while limiting their negative effect on the DAC policy.	bell–lapadula model;computer security model;requirement;setuid;unix	Timothy E. Levin;S. J. Padilla;Cynthia E. Irvine	1989		10.1109/SECPRI.1989.36279	embedded system;application software;kernel;discretionary access control;computer science;security policy;information security;access control;setuid;operating system;unix;programming language;computer security	Security	-52.59874203310472	51.43740548003011	172376
d7012be0a5394643d6686f7ab221b04cdfeb9f98	middleware-based security for future in-car networks		Each year, car manufacturers are competing to provide new and trendy automotive features for safety, driving assistance and infotainment. For this purpose, today’s cars take advantage of powerful electronic platforms and embed more and more sophisticated connected services. More than just ensuring their role of a safe transportation mean, which remains nonetheless their primary function, cars have seen an extension of their paradigm towards the driving pleasure and the infotainment domain. Thus, they process large amounts of sensitive data, e.g., personal information, industrial secrets; they are increasingly tethered to the external environment via smartphones, Internet or other road-side units; and like the consumer electronics world , they will very soon host downloadable and on-the-fly installable Third-Party Applications (TPAs). However, the car pervasive computerization exposes them to unintentional programming bugs and to common security attacks targeting not only the data they contain but also their own integrity. Today, traditional automotive technologies cannot protect against any of these threats. Without any countermeasures, these security vulnerabilities could lead to unfortunate consequences: lawsuits, damages to the enterprise reputation, loss of billions of dollars, driving discomfort or even worse, endangering the life of the car passengers. The transition towards Ethernet/Internet Protocol (IP)-based on-board communications and mature security protocols could be a first, but not sufficient, step to respond to these security and privacy issues. This thesis is in line with this evolution and focuses on the design and implementation of an automotive IP-based security middleware leveraging local and distributed information flow techniques in order to protect the car against on-board and external threats. Unlike previous automotive approaches, security is defined and enforced at the middleware level. This approach allows to abstract the security interfaces and simplify its maintenance and verification. A suitable modularization eases the fulfillment of all security and functional requirements. A security architecture for middleware was developed within this thesis leveraging hardware security platforms. The middleware provides mechanisms for on-board and external secure communication channels as well as dedicated security decisionand enforcement-points. In addition to just providing strong security between two on-board electronic platforms, an authorization model based on decentralized information flow control was further developed and integrated into the middleware layer. The model enforces label-based policies in order to follow the propagation of data of interest within the whole car and to safely and securely integrate untrustworthy use cases like smartphones or TPAs. An advanced approach based on dynamic data flow tracking was also investigated and coupled to the previous model. It provides mechanisms for deeper introspection and finer control of the TPA. Then, a proof-of-concept implementation demonstrates the feasibility of the developed	authorization;cp/m;computer security;dataflow;dynamic data;functional requirement;internet protocol suite;introspection;middleware;non-interference (security);on-board data handling;personally identifiable information;pervasive informatics;privacy;programming paradigm;secure communication;smartphone;software bug;software propagation;vulnerability (computing)	Alexandre Bouard	2014			architecture;access control;embedded system;information flow (information theory);authorization;isolation techniques;automotive industry;middleware;engineering;data flow diagram	Security	-52.820781897894605	58.823268353222524	172405
fd4837b2f0a3d544af36125cf405b67c2c0e3e2c	towards building an automated security compliance tool for the cloud	openstack;cloud audit;cloud control matrix ccm;security engines standards servers cloud computing ports computers manuals;trusted computing;business data processing;application program interfaces;cloud control matrix ccm security compliance cloud audit openstack;openstack cloud platform automated security compliance tool cloud computing platform enterprise environment governmental regulations business requirements trust auditing information asct data collection mechanisms cloudaudit api vulnerability scanning log analysis manual entry;security compliance;security of data;trusted computing application program interfaces business data processing cloud computing security of data;cloud computing	Security, especially security compliance, is a major concern that is slowing down large scale adoption of cloud computing in the enterprise environment. Governmental regulations, business requirements and trust are among the reasons why enterprises require certain levels of security compliance from cloud providers. So far, security compliance or auditing information has been generated manually by security specialists. This involves manual data collection and assessment, which is slow and expensive. Thus, there is a need for an automated security compliance tool (ASCT) to verify and express the compliance of various cloud providers. Such a tool can reduce the human intervention and eventually reduce the cost and time by verifying the compliance automatically. Also, the tool will enable transparency of the cloud vendors to the customers which in turn will help grow confidence on the cloud vendors. Having these goals in mind, we have developed an architecture to build an ASCT for a cloud computing platform. We have also outlined four possible approaches to achieve this automation. These possible four approaches refer to four data collection mechanisms to collect data from the cloud systems and these are: API, vulnerability scanning, log analysis and manual entry. Finally, we have implemented a proof-of-concept prototype of this ASCT based on the proposed architecture. The prototype is integrated with OpenStack cloud platform and the results are exposed using the CloudAudit API.	application programming interface;business requirements;cloud computing;google cloud platform;high- and low-level;log analysis;prototype;requirement;security controls;systems architecture;user interface;verification and validation;virtual machine;vulnerability scanner	Kazi Wali Ullah;Abu Shohel Ahmed;Jukka Ylitalo	2013	2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2013.195	cloud computing security;cloud computing;engineering;cloud testing;internet privacy;world wide web;computer security	SE	-50.08795755798897	57.43509805539577	172443
ca5387daeec60fb4f9f4809812b72016e4b482b8	modeling multilevel entities using single level objects	object oriented database systems;multilevel security	An earlier paper by Jajodia and Kogan [5] introduced an approach for building multilevel secure object-oriented database systems based on a secure message filtering mechanism. Under this approach each object has a unique security level and, therefore, multilevel objects are not supported. In the present paper, we discuss an approach, based on composite objects, that allows multilevel entities to be represented in terms of single level objects. The main qualifying aspect of our approach is that the object interfaces can be provided to users as if multilevel objects were directly supported.	entity	Elisa Bertino;Sushil Jajodia	1993		10.1007/3-540-57530-8_27	theoretical computer science;database;distributed computing	Vision	-48.70436835138761	50.34238393225001	172591
53dc14aea6b6141727c1234e088777f5d2f3878f	virtual machine security challenges: case studies		Currently Virtual Machines (VMs) have many applications and their use is growing constantly as the hardware gets more powerful and usage more regulated allowing for scaling, monitoring, portability, security applications and many other uses. There are many types of virtualization techniques that can be employed on many levels from simple sandbox to full fledged streamlined managed access. While scaling, software lifecycles and diversity are just some of security challenges faced by VM developers the failure to properly implement those mechanisms may lead to VM escape, host access, denial of service and more. There are many exploits found in the last couple of years which were fixed on latest versions but some systems are still running them and vulnerable as presented, mostly to host based attacks and some have dramatic consequences.	bios;denial-of-service attack;executable;image scaling;sandbox (computer security);software portability;virtual machine	Amjad Rehman;Sultan Alqahtani;Ayman Altameem;Tanzila Saba	2014	Int. J. Machine Learning & Cybernetics	10.1007/s13042-013-0166-4	real-time computing;engineering;operating system;computer security	Security	-53.56200395557551	57.12704534355644	172618
c4281d6767936f1853d31e838da8e436ecf4c554	detection of security and dependability threats: a belief based reasoning approach	belief networks;runtime information security resilience condition monitoring mechanical factors event detection uncertainty software systems software measurement web services;system monitoring belief networks program verification security of data;detect potential violation;time measurement;belief based reasoning;security detection;probability density function;security and dependability;system monitoring;security and dependability threat;everest monitoring framework;program verification;data mining;runtime;qa75 electronic computers computer science;belief graph security and dependability threat s d threat belief based reasoning approach verification measure security detection proactive monitoring approach detect potential violation everest monitoring framework event resoning toolkit;monitoring;belief graph;proactive monitoring approach;verification measure;cognition;runtime monitoring;belief based reasoning approach;s d threat;event resoning toolkit;security;belief based reasoning runtime monitoring security and dependability;security of data	Monitoring the preservation of security and dependability (S&D) properties during the operation of systems at runtime is an important verification measure that can increase system resilience. However it does not always provide sufficient scope for taking control actions against violations as it only detects problems after they occur. In this paper, we describe a proactive monitoring approach that detects potential violations of S&D properties, called “threats”, and discuss the results of an initial evaluation of it.	aggregate data;computation;dependability;run time (program lifecycle phase);threat (computer);while	Davide Lorenzoli;George Spanoudakis	2009	2009 Third International Conference on Emerging Security Information, Systems and Technologies	10.1109/SECURWARE.2009.55	system monitoring;probability density function;cognition;computer science;information security;data mining;computer security;time	SE	-58.769208528907384	53.9885495595468	172633
cb2d74c9baf0e2ad6787f64f0f6b5f0473be20a3	java application's packet eavesdropper for content delivery network	client server system;application software;authorisation;filters;client server systems;client server system java application packet eavesdropper jape content delivery network dns redirection url modification access control packet interception technology windows 2000 location aware features;object oriented programming;computer networks;cdn jape java packet interception;network servers;windows 2000;internet;logic programming;java applet;object oriented programming java client server systems authorisation internet network servers;location aware features;bandwidth;cdn;java application packet eavesdropper;url modification;access control;location awareness;content delivery network;uniform resource locators;java filters hardware application software network servers bandwidth uniform resource locators logic devices logic programming computer networks;packet interception technology;logic devices;packet interception;jape;hardware;java;dns redirection	DNS redirection and URL modification are two major ways to carry out dynamic replica selections in CDN. However, the two ways may overload DNS servers or dispatchers, and exhaust the network bandwidth while there are a large number of incoming requests. Meanwhile, the modification of DNS servers for DNS redirection harms the compatibility and troubles the management. Moreover, the two ways do not give local administrators the flexibility to customize accesses to foreign CDN applications. In the paper we propose Java Application's Packet Eavesdropper (JAPE) for CDN to improve DNS redirection and URL modification, and for local administrators to control the accesses. JAPE utilizes packet interception technologies for Java objects to process packets. Besides, objects in JAPE are Java application rather than Java applet, which not only keeps the inherent portability but also has the flexibility to use various Java libraries for creating other applications not limited to CDN. We implement JAPE in Windows 2000 and develop a CDN application with an object doing DNS redirection and URL modification. The application with location-aware features can locally resolve clients' requests toward a virtual host name and redirect them to a nearby server customized by local administrators according to the movements of clients. It proves that JAPE for CDN can free DNS servers from modifications, alleviate DNS servers' and dispatchers' loads, conserve the network bandwidth, and permit local administrators to customize the accesses.	access control;computer;content delivery network;dns hijacking;digital distribution;java applet;library (computing);location awareness;microsoft windows;network packet;redirection (computing);requirement;server (computing);software portability;url redirection;virtual hosting	Tzu-Chi Huang;Ce-Kuen Shieh;Yu-Ben Miao	2005	19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)	10.1109/AINA.2005.229	dns hijacking;application software;the internet;telecommunications;computer science;access control;operating system;database;distributed computing;authorization;programming language;object-oriented programming;java;logic programming;world wide web;computer security;bandwidth;java applet;computer network	Metrics	-53.49079703176418	58.46628409072469	172751
3c56aca60ff297f6dc56b59e0aa3230f98b21252	addressing web locator fragility: a case for browser extensions		Web locators uniquely identify elements on the Web Content. They are heavily used in different scenarios, from Web harvesting to Web testing and browser extensions. Locators' Achilles heel is their fragility upon Website upgrades. This work tackles locator fragility in the context of browser extensions. We introduce regenerative locator, i.e. traditional structure-based locators which are supplemented with contingency data from the target node. The aim: keeping browser extensions up and running for as long as possible. Eight case studies are analysed by considering real Website upgrades taken from Wayback Machine. Figures indicate a 70% success in regenerating broken locators without interrupting extension functioning.	browser extension;interrupt;online locator service;wayback machine;web content;web scraping;web testing;world wide web	Iñigo Aldalur;Oscar Díaz	2017		10.1145/3102113.3102124	robustness (computer science);world wide web;web testing;computer science;fragility;client-side scripting	Web+IR	-55.39889720146297	59.663063581152116	172912
a58e5388358da913ede1ac7ca0807c66fb871f00	policert: secure and flexible tls certificate management	ssl;public log servers;tls;public key certificate;certificate validation;security policy;public key infrastructure	The recently proposed concept of publicly verifiable logs is a promising approach for mitigating security issues and threats of the current Public-Key Infrastructure (PKI). Although much progress has been made towards a more secure infrastructure, the currently proposed approaches still suffer from security vulnerabilities, inefficiency, or incremental deployment challenges.  In this paper we propose PoliCert, a comprehensive log-based and domain-oriented architecture that enhances the security of PKI by offering: a) stronger authentication of a domain's public keys, b) comprehensive and clean mechanisms for certificate management, and c) an incentivised incremental deployment plan. Surprisingly, our approach has proved fruitful in addressing other seemingly unrelated problems such as TLS-related error handling and client/server misconfiguration.	authentication;client–server model;ecosystem;emoticon;exception handling;forge;formal verification;global serializability;interoperability;legacy system;public key infrastructure;server (computing);software deployment;tcp global synchronization;transport layer security;vulnerability (computing)	Pawel Szalachowski;Stephanos Matsumoto;Adrian Perrig	2014		10.1145/2660267.2660355	certificate policy;computer science;certificate signing request;x.509;certificate server;authorization certificate;public key certificate;internet privacy;transport layer security;root certificate;world wide web;computer security;certificate authority	Security	-51.560495698175416	58.704617661834895	172964
7009140a93b685f0a445eb1dcbdcd759ac28b60a	s3b: software-defined secure server bindings		For decades, request-routing protocols operating at multiple layers of the network stack have been a staple of Internet services. Commonly deployed request-routing techniques use the requestoru0027s IP address as an identifier of the client. For instance, using DNS as a request-routing protocol, the local DNS resolveru0027s IP address is used as a surrogate identifier of the client in order to assign the client to the closest server. While such coarse associations may be acceptable for performance-centric purposes, they are not appropriate in settings that require fine-grained, enforceable bindings of clients to servers – e.g., to ensure that malicious clients are unable to bypass their bindings and issue their request to a server of their choosing. In this paper, we propose S3B (Software-defined Secure Server Bindings), a protocol that provides precise and enforceable client-server assignments. S3B uses a server module to assign clients unique access keys. Using HTTP redirection with the key encrypted as an additional domain label, the name server is able to distribute precise server assignments specific to each client. In addition, the server module maintains an access control list to enforce these assignments. As an implementation of the S3B protocol, we have developed an HTTP/S prototype and deployed it to Amazon AWS. Our performance evaluation suggests that our prototype introduces no discernible overhead for client requests. To evaluate S3Bu0027s effectiveness as a security appliance, we developed an application to isolate clients suspected as spiders, capable of virtually immediate containment once detected.	access control list;access key;amazon web services;client–server model;encryption;hypertext transfer protocol;identifier;overhead (computing);performance evaluation;protocol stack;prototype;routing;server (computing);url redirection	William Koch;Azer Bestavros	2018	2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2018.00050	access control list;computer network;protocol stack;access control;url redirection;the internet;web server;computer science;name server;server	Security	-53.732659957278635	58.64263081071317	173086
bb8e3d72a6f7d161e6e64c121a108c1e481522f4	picasso: lightweight device class fingerprinting for web clients	authentication;device fingerprinting;canvas fingerprinting	In this work we present Picasso: a lightweight device class fingerprinting protocol that allows a server to verify the software and hardware stack of a mobile or desktop client. As an example, Picasso can distinguish between traffic sent by an authentic iPhone running Safari on iOS from an emulator or desktop client spoofing the same configuration. Our fingerprinting scheme builds on unpredictable yet stable noise introduced by a client's browser, operating system, and graphical stack when rendering HTML5 canvases. Our algorithm is resistant to replay and includes a hardware-bound proof of work that forces a client to expend a configurable amount of CPU and memory to solve challenges. We demonstrate that Picasso can distinguish 52 million Android, iOS, Windows, and OSX clients running a diversity of browsers with 100% accuracy. We discuss applications of Picasso in abuse fighting, including protecting the Play Store or other mobile app marketplaces from inorganic interactions; or identifying login attempts to user accounts from previously unseen device classes.	algorithm;android;central processing unit;desktop computer;emulator;fingerprint (computing);graphical user interface;html5;interaction;login;microsoft windows;mobile app;operating system;play store;proof-of-work system;safari (web browser);server (computing);user (computing);ios;macos	Elie Bursztein;Artem Malyshev;Tadek Pietraszek;Kurt Thomas	2016		10.1145/2994459.2994467	engineering;internet privacy;world wide web;computer security	Security	-55.026492108304886	60.28298800129816	173404
8bb37abb03ef8dd31b63798753481c35682fbf34	a study on composite system vulnerability through cc analysis	composite;common criteria analysis;evaluate;composite product guidelines;interconnected systems information security operating systems guidelines multimedia systems protection hardware information analysis application software manufacturing;composite system vulnerability;evaluate common criteria composite;common criteria;cc version 3 0 composite system vulnerability common criteria analysis secure protection composite product guidelines cc analysis;cc version 3 0;secure protection;cc analysis;security of data large scale systems;security of data;large scale systems	In this study, CC Version 3.0 is analyzed to propose a method and a set of standards for evaluating vulnerability of the composite system for conducting the serviceable range per composite product class and TOE analysis, secure protection and guidelines for composite product.	compositing;intrusion detection system	Jaegu Song;Seoksoo Kim	2008	2008 International Conference on Multimedia and Ubiquitous Engineering (mue 2008)	10.1109/MUE.2008.58	composite number;computer security	DB	-55.09052259445328	49.32090010229798	173407
4df88162559e8144f87b5f51f20d2199a55065f1	plc guard: a practical defense against attacks on cyber-physical systems	software;trusted computing cyber physical systems engineering workstations programmable controllers security of data;engineering workstation cyber physical system plc guard intercept traffic utility distribution network classic accat guard programmable logic controller protection graphical abstraction graphical summarization trusted device plc guard prototype miniature packaging plant;visualization;malware;workstations software visualization production malware conferences;workstations;production;conferences	Modern societies critically depend on cyberphysical systems that control most production processes and utility distribution networks. Unfortunately, many of these systems are vulnerable to attacks, particularly advanced ones. While researchers are investigating sophisticated techniques in order to counter these risks, there is a need for solutions that are practical and readily deployable. In this paper, we adapt the classic ACCAT Guard concept to the protection of programmable logic controllers (PLCs), which are an essential ingredient of existing cyber-physical systems. A PLC Guard intercepts traffic between a, potentially compromised, engineering workstation and a PLC. Whenever code is transferred to a PLC, the guard intercepts the transfer and gives the engineer an opportunity to compare that code with a previous version. The guard supports the comparison through various levels of graphical abstraction and summarization. By operating a simple and familiar interface, engineers can approve or reject the transfer using a trusted device that is significantly harder to subvert by attackers. We developed a PLC Guard prototype in order to reify our ideas on how it should be designed. In this paper, we describe the guard's design and its implementation. In order to arrive at realistic PLC code examples, we implemented a miniature packaging plant as well as attacks on it.	automatic summarization;cyber-physical system;graphical user interface;programmable logic device;prototype;workstation	Jan-Ole Malchow;Daniel Marzin;Johannes Klick;Robert Kovacs;Volker Roth	2015	2015 IEEE Conference on Communications and Network Security (CNS)	10.1109/CNS.2015.7346843	guard;embedded system;real-time computing;visualization;workstation;telecommunications;computer science;operating system;malware;computer security;computer network	Embedded	-53.20030235376147	59.885300171910316	173432
e2df6bd656de4256ec4174f90d32a29cdd093793	a combined static and dynamic analysis approach to detect malicious browser extensions		Ill-intentioned browser extensions pose an emergent security risk and have become one of the most common attack vectors on the Internet due to their wide popularity and high privilege. Once installed, malicious extensions are executed and attempt to compromise a victim’s browser. To detect malicious browser extensions, security researchers have put forward several techniques. These techniques primarily concentrate on the usage of API calls by malicious extensions, imposing restricted policies for extensions, andmonitoring extension’s activities. In this paper, we propose a machine-learning-based approach to detect malicious extensions. We apply static and dynamic techniques to analyse an extension for extracting features. The analysis process extracts features from the source codes including JavaScript codes, HTML pages, and CSS files and the execution activities of an extension. To guarantee the robustness of the features, a feature selection method is then applied to retain the most relevant features while discarding low-correlated features. The detection models based on machine-learning techniques are subsequently constructed by leveraging these features. As can be seen from evaluation results, our detection model, containing over 4,600 labelled extension samples, is able to detect malicious extensions with an accuracy of 96.52% in validation set and 95.18% in test set, with a false positive rate of 2.38% in validation set and 3.66% in test set.	application programming interface;browser extension;cascading style sheets;code;emergence;feature selection;html;javascript;machine learning;test set	Yao Wang;Wan-Dong Cai;Pin Lyu;Wei Shao	2018	Security and Communication Networks	10.1155/2018/7087239	robustness (computer science);real-time computing;computer network;the internet;computer science;false positive rate;javascript;feature selection;source code;test set;compromise	Security	-57.72097585330926	59.708318251327036	173621
8f2dfd370068ec5fe03a4aa2d0325bad13c1fbda	specifying and enforcing the principle of least privilege in role-based access control	enforcement;role based access control;principle of least privilege;weight	The principle of least privilege in role-based access control (RBAC) is an important area of research. There are two crucial issues related to it: the specification and the enforcement. We believe that existing least privilege specification schemes are not comprehensive enough and few of the enforcement methods are likely to scale well. In this paper, we formally define the basic principle of least privilege and present different variations, called the δ-approx principle of least privilege and the minimizing-approx principle of least privilege. Since there may be more than one result to enforce the same principle of least privilege, we introduce the notation about weights of permission and role to optimize the results. Then we prove that all least privilege problems are NP-complete. As an important contribution of the paper, we show the principle of least privilege problem can be reduced to minimal cost set covering (MCSC) problem. We can borrow the existing solutions of MCSC to solve the principle of least privilege problems. Finally, different algorithms are designed to solve the proposed least privilege problems. Experiments on performance study prove the superiority of our algorithms.	approximation algorithm;experiment;john d. wiley;np-completeness;principle of least privilege;role-based access control;software engineering	Xiaopu Ma;Ruixuan Li;Zhengding Lu;Jianfeng Lu;Meng Dong	2011	Concurrency and Computation: Practice and Experience	10.1002/cpe.1731	computer science;role-based access control;principle of least privilege;weight;computer security;algorithm;privilege level	Security	-50.086976654058994	49.450561091399265	173681
e86adba278716325a486c57877c34cc9c898663d	real-time security & dependability monitoring: make it a bundle	fault and intrusion tolerance real time monitoring event collection event correlation;security of data fault tolerant computing;real time sec dep monitoring facility real time security dependability monitoring monitoring process building block;monitoring sensors security business random access memory real time systems correlation	Security & Dependability (SEC&DEP) monitoring has definitely become a number one priority, since it is understood that it is the pre-requisite for allowing system operation to continue also in the presence of faults and/or attacks. Since effective remediation requires that the right actions be taken at the right time, in order for SEC&DEP monitoring to be really useful, the results of the monitoring process must be made available in a timely fashion, i.e. in (near) real-time. A plethora of technologies exists, that individually represent a (potentially) effective building block of a real-time SEC&DEP monitoring facility, but - regrettably - they very much lack integration. We claim that a significant advancement in the convergence of such technologies is needed. While recently some achievements have been made, much is yet to be done. In this paper, we briefly review the current State Of The Art (SOTA) of technologies that can be used to implement a real-time SEC&DEP monitoring facility, with two objectives: 1) perform a gap analysis, i.e. point out the major limitations of such technologies, and 2) identify the main avenues towards effective SEC&DEP monitoring.	dependability;gap analysis;make;real-time clock;real-time transcription	Luigi Coppolino;Salvatore D'Antonio;Valerio Formicola;Luigi Romano	2014	2014 International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2014.6987018	embedded system;real-time computing;security information and event management;engineering;computer security	EDA	-59.723842011467006	50.199453164097285	174451
c3407b18b527c1bce4188f9309b1e03e3e10ccc5	practical keystroke timing attacks in sandboxed javascript		Keystrokes trigger interrupts which can be detected through software side channels to reconstruct keystroke timings. Keystroke timing attacks use these side channels to infer typed words, passphrases, or create user fingerprints. While keystroke timing attacks are considered harmful, they typically require native code execution to exploit the side channels and, thus, may not be practical in many scenarios. In this paper, we present the first generic keystroke timing attack in sandboxed JavaScript, targeting arbitrary other tabs, processes and programs. This violates same-origin policy, HTTPS security model, and process isolation. Our attack is based on the interrupt-timing side channel which has previously only been exploited using native code. In contrast to previous attacks, we do not require the victim to run a malicious binary or interact with the malicious website. Instead, our attack runs in a background tab, possibly in a minimized browser window, displaying a malicious online advertisement. We show that we can observe the exact inter-keystroke timings for a user’s PIN or password, infer URLs entered by the user, and distinguish different users time-sharing a computer. Our attack works on personal computers, laptops and smartphones, with different operating systems and browsers. As a solution against all known JavaScript timing attacks, we propose a fine-grained permission model.	binary file;byte;comparison of javascript frameworks;desktop computer;event (computing);fingerprint;https;interrupt;laptop;machine code;malware;mobile device;online advertising;operating system;password;personal computer;process isolation;sim lock;same-origin policy;sandbox (computer security);side-channel attack;smartphone;time-sharing;tracing (software)	Moritz Lipp;Daniel Gruss;Michael Schwarz;David Bidner;Clémentine Maurice;Stefan Mangard	2017		10.1007/978-3-319-66399-9_11	distributed computing;interrupt;timing attack;keystroke logging;javascript;machine code;computer science;side channel attack;exploit;passphrase	Security	-55.33976376342014	60.05044432127843	174491
2288a4b604c2982d8546d48f7d559d3cfab6bf62	access control management using extended rbac model		The protection of data in information systems against improper disclosure or modification is an important requirement of each system. Nowadays the information systems of enterprises are more and more open, more information is easy accessible for the users, so it is important to better protect the confidential information. The paper presents a software tool for managing the security of enterprise information system on the access control level from the point of view of security administrator. The security administrator who is responsible for information system security will obtain a tool that facilitate the management of one of security aspects, namely the management of access control of users to data stored in a system. However, the application developers can also use such tool to define the access control rules for application elements created on the conception level.	role-based access control	Aneta Poniszewska-Maranda	2012		10.1007/978-3-642-27446-6_3	role-based access control	Robotics	-51.0282657129184	52.18465741098752	174616
f935df16a59fc024561203ace058d473fd895ed1	reverse engineering of dynamic parallel program behavior from execution traces	execution traces;parallel program;trace driven simulation;finite state machine;reverse engineering	Trace-driven simulation has been used widely for architectural exploitation in electronic system-level (ESL) designs for complex SoCs (system-on-chips). Most often the trace files are provided by third parties without source code. This makes it difficult to process and manipulate the trace files, e.g. to identify the region of interest (ROI), for efficient and more focused simulations. It is thus necessary to deduce high-level structures and patterns in the trace to facilitate such manipulations. This can be viewed as a reverse engineering process to derive the dynamic control flow of the original program from its execution trace. Furthermore, after the high-level structure is manipulated, it is also important to generate a new trace from the resultant structure that preserves the characteristics of the original trace for effective trace-driven simulations. The problem becomes even more difficult if the trace was generated from a parallel program because of the complex interactions between the multiple threads of executions. In this paper, a novel scheme to reverse-engineering the program execution trace is proposed, which can obtain the high-level dynamic control structure of the original parallel program as well as regenerate a similar trace from the derived structure, all without referencing the source code. The effectiveness of the proposed scheme is evaluated and verified with extensive experiments.	algorithm;control flow;electronic system-level design and verification;experiment;finite-state machine;high- and low-level;interaction;level structure;lock (computer science);lossy compression;online and offline;parallel computing;region of interest;resultant;reverse engineering;semaphore (programming);simulation;tracing (software);vectored i/o	Shin-Chieh Tsai;Chiu-Ping Chang;Chung-Ta King	2016	2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/ICPADS.2016.0142	parallel computing;real-time computing;computer science;operating system;distributed computing;finite-state machine;programming language;reverse engineering	SE	-55.51496454989567	54.23747517765263	174777
e7552d7d97809b65a57f2a24866b7df942c49987	authentication bypass and remote escalated i/o command attacks	scada;control systems;ethernet ip;remote code execution	The Common Industrial Protocol (CIP) is a widely used Open DeviceNet Vendors Association (ODVA) standard [14]. CIP is an application-level protocol for communication between components in an industrial control setting such as a Supervisory Control And Data Acquisition (SCADA) environment. We present exploits for authentication and privileged I/O in a CIP implementation. In particular, Allen Bradley's implementation of CIP communications between its programming software and Programmable Logic Controllers (PLCs) is the target of our exploits. Allen Bradley's RSLogix 5000 software supports programming and centralized monitoring of Programmable Logic Controllers (PLCs) from a desktop computer. In our test bed, ControlLogix EtherNet/IP Web Server Module (1756-EWEB) allows the PLC Module (5573-Logix) to be programmed, monitored and controlled by RSLogix 5000 over an Ethernet LAN. Our vulnerability discovery process included examination of CIP network traffic and reverse engineering the RSLogix 5000 software. Our findings have led to the discovery of several vulnerabilities in the protocol, including denial-of-service attacks, but more significantly and recently the creation of an authentication bypass and remote escalated privileged I/O command exploit. The exploit abuses RSLogix 5000's use of hard-coded credentials for outbound communication with other SCADA components. This paper provides a first public disclosure of the vulnerability, exploit development process, and results.	authentication;centralized computing;common industrial protocol;credential;data acquisition;david w. bradley;denial-of-service attack;desktop computer;devicenet;ethernet/ip;exploit (computer security);hard coding;input/output;network packet;programmable logic device;programming tool;reverse engineering;testbed;web server	Ryan Grandgenett;William R. Mahoney;Robin A. Gandhi	2015		10.1145/2746266.2746268	embedded system;real-time computing;computer science;computer security	Security	-53.44550635941821	59.2630515666285	175093
ffdf072addd5326f52f22699ad2443fca720c15f	dynamic combination of authentication factors based on quantified risk and benefit	quantified risk;multiple factors authentication;qsbac;usability;quantified benefit	By combining multiple factors during authentication, a service can provide better assurance of security. However, the users are likely to feel inconvenient, or even discard the service. This paper, therefore, addresses this issue and introduces a novel method, referred to as the Quantified riSk and Benefit adaptive Authentication Factors combination (QSBAF). QSBAF balances the requirements for both security and usability in the authentication of an information system and improves the system’s ability to respond quickly to emerging risky events. In QSBAF, the authentication factors can be dynamically combined on the basis of quantified risk, benefit measurements, and combination policies. Furthermore, QSBAF provides an adaptive mechanism, which is driven by history data to justify the measurements of risk and benefit. In this paper, we use the online banking system as a typical scenario to demonstrate the usage of QSBAF. We also implement a prototype of QSBAF to evaluate the performance of its feasibility in real application scenarios. Copyright © 2013 John Wiley & Sons, Ltd.	authentication;china internet network information center;han unification;information system;john d. wiley;online banking;prototype;requirement;usability	Weili Han;Chen Sun;Chenguang Shen;Chang Lei;Sean Shen	2014	Security and Communication Networks	10.1002/sec.729	usability;computer science;data mining;computer security	Security	-48.77422753797085	59.175073240035815	175101
13d53504843e97613af03f72922c927729bec379	on partitioning secret data based on concept of functional safety	guessing difficulty;database partitioning;functional safety;renyi entropy	It is frequently reported that large volumes of secret data stored online, such as passwords and PINs, leak out. Since most of these incidents resulted from potential vulnerabilities, such as human error, bugs and intentional misconduct, it was not easy to eliminate the underlying causes. In this paper, we focus on the concept of functional safety where the goal is to ensure that systems work correctly in a worst case scenario, such as in the situations referred to above. Our goal is to minimize the impact of information leakage. In this paper, we first present some metrics for evaluating the security of a cloud system where the secret data of several users have been compromised. We also propose a partitioning method to store secret data on the cloud system more securely, thereby making it possible to diminish the impact on the secret data of other users.		Seira Hidano;Shinsaku Kiyomoto	2015		10.1007/978-3-319-31875-2_10	rényi entropy;computer science;data mining;internet privacy;functional safety;computer security;algorithm;statistics	Logic	-60.20863241342074	57.93352407950311	175213
b1bc0b97a19d6e51de23ad12f12cb64a39a96d8b	goalkeeper: comprehensive process enforcement from the hypervisor		Abstract Controlling when and how a process runs is essential to the security of a system. In virtualized environments, an out-of-guest approach to process control is attractive because it allows fine-grained in-guest inspection and enforcement from the relative safety of the hypervisor, which makes in-guest misconfiguration by users or deliberate interference by malware more difficult. However, prior work in this area is incomplete, either lacking policy enforcement, missing certain types of malicious code due to insufficient coverage, or being unable to scale to many simultaneous guests. This work introduces Goalkeeper , a hypervisor-based security system that focuses on asynchronous, stateless, and lightweight Virtual Machine Introspection (VMI) techniques to enforce comprehensive guest process security policies at scale across tens to hundreds of guests per hypervisor. Running beneath each guest, Goalkeeper uses policy rules to ensure only whitelisted guest processes are allowed to execute, and terminates policy violators using a customizable set of VMI-based process termination techniques. In an evaluation across a population of 100 Linux virtual desktops, Goalkeeper is shown to catch malicious code that is missed by prior work while imposing a comparable performance overhead.	hypervisor	Micah Bushouse;Douglas S. Reeves	2018	Computers & Security	10.1016/j.cose.2017.11.020	computer security;stateless protocol;enforcement;hypervisor;virtual desktop;malware;computer science;population;security policy;asynchronous communication	Security	-55.70460078812135	57.66008209259078	175272
7acd737255f3873aaabd0c61fa7a39ea0101c950	using the structure of b+-trees for enhancing logging mechanisms of databases	digital forensics;database log;sarbanes oxley act;database forensics;indexation;tree structure;access control;b tree;database management system	Today's database management systems implement sophisticated access control mechanisms to prevent unauthorized access and modifications. This is, as an example, an important basic requirement for SOX (Sarbanes--Oxley Act) compliance, whereby every past transaction has to be traceable at any time. However, malicious database administrators may still be able to bypass the security mechanisms to make hidden modifications to the database.  In this paper we define a novel signature of a B+-Tree, a widely-used storage structure in database management systems, and propose its utilization for supporting the logging in databases. This additional logging mechanism is especially useful in combination with forensic techniques that directly target the underlying tree-structure of an index. The applicability of the approach is demonstrated by proposing techniques for applying this signature in the context of digital forensics on B+-Trees.	access control;authorization;b+ tree;control system;database;login;traceability;tree structure	Peter Kieseberg;Sebastian Schrittwieser;Lorcan Morgan;Martin Mulazzani;Markus Huber;Edgar R. Weippl	2011		10.1145/2095536.2095588	database transaction;engineering;data mining;database;world wide web;database testing	DB	-48.44795051800348	60.14977756984237	175477
7a073259f8aaea6542852b3010ffd6d7547eeb9d	automatic multi-step signature derivation from taint graphs	electronic mail;standards;intrusion detection;correlation;context;timing	An increasing number of attacks use advanced tactics, techniques and methods to compromise target systems and environments. Such multi-step attacks are often able to bypass existing prevention and detection systems, such as Intrusion Detection Systems (IDSs), firewalls and anti-virus solutions. These security systems either use an anomaly-based or a signature-based detection approach. For systems that utilize a signature-based approach, it is relevant to use precise detection signatures to identify attacks. The creation of signatures is often complex and time consuming, especially for multi-step attacks. In this paper, we propose a signature derivation approach that automatically creates multi-step detection signatures from taint graphs. The approach uses the recorded log events of an attack and the event attribute tainting approach to correlate the events and to create a taint graph. This graph, which provides comprehensive details about the attack, is then used to derive a precise multi-step detection signature. Therewith, this approach can reduce the needed time to create a multi-step signature as well as the complexity of this process. For the evaluation of the proposed approach, we simulated a multi-step attack with real world attack tools and methods. Based on the recorded log events and the implemented signature derivation system we automatically derived a multi-step detection signature that describes all relevant events and their relations.	anomaly detection;antivirus software;firewall (computing);step detection;taint checking;type signature	Martin Ussath;Feng Cheng;Christoph Meinel	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850076	anomaly-based intrusion detection system;computer science;data mining;world wide web;computer security	Security	-59.04774022179085	58.99081779690086	175657
3166bc1d8fc104a7dab75114435d4cfcb2582017	scalable surveillance software architecture	video surveillance;airports;conference paper;computer architecture;protection;large scale;software architecture;information processing;software algorithms;power generation;software architecture video surveillance cameras protection airports power generation information processing large scale systems software algorithms computer architecture;cameras;large scale systems	Video surveillance is a key technology for enhanced protection of facilities such as airports and power stations from various types of threat. Networks of thousands of IP-based cameras are now possible, but current surveillance methodologies become increasingly ineffective as the number of cameras grows. Constructing software that efficiently and reliably deals with networks of this size is a distributed information processing problem as much as it is a video interpretation challenge. This paper demonstrates a software architecture approach to the construction of large scale surveillance network software and explores the implications for instantiating surveillance algorithms at such a scale. A novel architecture for video surveillance is presented, and its efficacy demonstrated through application to an important class of surveillance algorithms.	algorithm;closed-circuit television;component-based software engineering;distributed computing;fault tolerance;information processing;scalability;software architecture;threat (computer);while	Henry Detmold;Anthony R. Dick;Katrina E. Falkner;David S. Munro;Anton van den Hengel;Ronald Morrison	2006	2006 IEEE International Conference on Video and Signal Based Surveillance	10.1109/AVSS.2006.101	electricity generation;embedded system;software architecture;computer vision;simulation;information processing;computer science;computer security;monitoring and surveillance agents	Robotics	-57.38321010809322	51.214604567362514	175690
6b017fc0bdb1e2495a5c964395114e83ed7028a7	real-time remote attestation with privacy protection	system configuration;real time;tpm;privacy protection;property attestation;measurement freshness	How to ensure the freshness of measurement and protect the concrete system configuration from leaking are two major challenges faced by existing remote attestation solutions. This paper proposes a new attestation architecture, called RTRA, to resolve these problems. In RTRA the real-time state of the attester is collected and reported. And the privacy about the attester's binary configuration is protected through extending traditional property-based remote attestation architecture. Compared with existing property attestation architecture, RTRA is more scalable and secure since a unique proxy who is trusted totally to protect the whole configuration from leaking is not needed anymore.	real-time transcription;trusted computing	Aimin Yu;Dengguo Feng	2010		10.1007/978-3-642-15152-1_8	direct anonymous attestation;computer science;internet privacy;world wide web;computer security	Security	-52.18763904104003	56.73738718023996	175839
82f9963e5cc2eb1e8e9363152c7cadbe0fdbefdc	an economical security architecture for multi-cloud application deployments in federated environments		Contemporary multi-cloud application deployments require increasingly complex security architectures, especially within federated environments. However, increased complexity often leads to higher efforts and raised costs for managing and securing those applications. This publication establishes an economical and comprehensive security architecture that is readily instantiable, pertinent to concrete users’ requirements, and builds upon up-to-date protocols and software. We highlight its feasibility by applying the architecture within the CYCLONE innovation action, deploying federated Bioinformatics applications within a cloud production environment. At last, we put special emphasis on the reduced management efforts to highlight the economic benefit of following our approach.		Mathias Slawik;Begüm Ilke Zilci;Axel Küpper;Yuri Demchenko;Fatih Turkmen;Christophe Blanchet;Jean-François Gibrat	2016		10.1007/978-3-319-61920-0_7	distributed computing;enterprise information security architecture;architecture;computer science;systems engineering;cloud computing;software;computer security;development environment	Crypto	-48.91230222150993	55.50672458089314	176246
772296168f89ae7cb959c7cf264c4b31999a4f3c	an execution model for multilevel seccure workflows	execution model;multilevel seccure workflows	Workflow management systems (WFMS) support the modeling and coordinated execution of processes within an organization. To coordinate the execution of the various activities (or tasks) in a workflow, task dependencies are specified among them. In a multilevel secure (MLS) workflow, tasks may belong to different security levels. Ensuring the task dependencies from the tasks at higher security levels to those at lower security level (high-to-low dependencies) may compromise security. In this paper, we consider such MLS workflows and show how they can be executed in a secure and correct manner. Our approach is based on semantic classification of the task dependencies that examines the source of the task dependencies. We classify the high-to-low dependencies in several ways: conflicting versus conflict-free, result-independent versus result-dependent, strong versus weak, and abortive versus non-abortive. We propose algorithms to automatically redesign the workflow and demonstrate that only a small subset among all the types of high-to-low dependencies requires to be executed by trusted subjects and all other types can be executed without compromising security.	algorithm;multilevel security	Vijayalakshmi Atluri;Wei-kuang Huang;Elisa Bertino	1997			real-time computing;computer science;database;distributed computing	Security	-49.510071716067344	53.03716716783265	176426
adcb4ee4bf23fee2443a02337c344e180874f434	byod security: a new business challenge	businesses security challenges byod security information technology byod policies bring your own device policies risk awareness it security concerns;byod security framework byod byod security;companies;mobile handsets companies access control cloud computing monitoring;monitoring;security of data business data processing;mobile handsets;access control;cloud computing	Bring Your Own Device (BYOD) is a rapidly growing trend in businesses concerned with information technology. BYOD presents a unique list of security concerns for businesses implementing BYOD policies. Recent publications indicate a definite awareness of risks involved in incorporating BYOD into business, however it is still an underrated issue compared to other IT security concerns. This paper focuses on two key BYOD security issues: security challenges and available frameworks. A taxonomy specifically classifying BYOD security challenges is introduced alongside comprehensive frameworks and solutions which are also analysed to gauge their limitations.	bring your own device;business requirements;cybercrime;defense in depth (computing);malware;mobile operating system	Kathleen Downer;Maumita Bhattacharya	2015	2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)	10.1109/SmartCity.2015.221	cloud computing security;cloud computing;computer science;access control;operating system;internet privacy;computer security	EDA	-49.4935740359006	58.29653259739152	176519
531d101c8d3592193af01e78e2a8b504d3a85a7a	dynamic emulation based modeling and detection of polymorphic shellcode at the network level	cpu emulation;optimization technique;polymorphic shellcode;intrusion detection;wang lanjia duan haixin li xing 入侵检测 cpu 网络安全 计算机技术 dynamic emulation based modeling and detection of polymorphic shellcode at the network level;polymorphism;detection algorithm;dynamic behavior	It is a promising way to detect polymorphic shellcode using emulation method. However, previous emulation-based approaches are limited in their performance and resilience against evasions. A new enhanced emulation-based detection approach is proposed, including an automaton-based model of the dynamic behavior of polymorphic shellcode and a detection algorithm, the detection criterion of which is derived from that model and ensures high detection accuracy. The algorithm also contains several optimization techniques, highly improving the running performance and the resilience against detection evasion shellcode. We have implemented a prototype system for our approach. The advantages of our algorithm are validated by the experiments with real network data, polymorphic shellcode samples generated by available polymorphic engines and hand-crafted detection evasion shellcode.	algorithm;automaton;emulator;evasion (network security);experiment;mathematical optimization;prototype;shellcode	Lanjia Wang;Hai-Xin Duan;Xing Li	2008	Science in China Series F: Information Sciences	10.1007/s11432-008-0150-x	intrusion detection system;polymorphism;real-time computing;simulation;computer science;distributed computing	Security	-59.69306857665812	58.95044563585107	176666
9fa5780f2775979e29d558530f8f757de2387606	south african small and medium-sized enterprises' reluctance to adopt and use cloud-based business intelligence systems: a literature review	data mining;business;europe;security;africa;asia;cloud computing	The research work in this paper focused on cloud security challenges that prevented South African small and medium-sized enterprises from adopting and using various cloud-based business intelligence systems. The study conducted a literature review on 39 publications which were meticulously extracted from various electronic databases. Only 7 publications (5 journal articles, 1 conference proceeding, and 1 report) focused on security as a challenge to adoption of cloud-based services and BI systems by small and medium-sized enterprises. The results of the literature review indicated that security threats and vulnerabilities in various cloud deployments and services, and mistrust of cloud service providers by small and medium-sized enterprises were the main security challenges to adoption of cloud-based BIs by small and medium-sized enterprises in South Africa. The study also established that standard tools used by large business enterprises were unavailable or inapplicable to small and medium-sized enterprises which intended to adopt and utilise cloud-based BI systems.	cloud computing security;database;distrust	Moses Moyo;Marianne Loock	2016	2016 11th International Conference for Internet Technology and Secured Transactions (ICITST)	10.1109/ICITST.2016.7856706	cloud computing security;marketing;business;commerce	DB	-49.3243452919375	58.52716952160224	176777
2d02d228ad4cdeba2481a5f17306e7e51f055aee	transformation of type graphs with inheritance for ensuring security in e-government networks	model transformation;graph transformation;e government type graph with inheritance;security	E-government services usually process large amounts of confidential data. Therefore, security requirements for the communication between components have to be adhered in a strict way. Hence, it is of main interest that developers can analyze their modularized models of actual systems and that they can detect critical patterns. For this purpose, we present a general and formal framework for critical pattern detection and user-driven correction as well as possibilities for automatic analysis and verification at meta-model level. The technique is based on the formal theory of graph transformation, which we extend to transformations of type graphs with inheritance within a type graph hierarchy. We apply the framework to specify relevant security requirements. The extended theory is shown to fulfil the conditions of a weak adhesive HLR category allowing us to transfer analysis techniques and results shown for this abstract framework of graph transformation. In particular, we discuss how confluence analysis and parallelization can be used to enable parallel critical pattern detection and elimination.	anti-grain geometry;application domain;confidentiality;confluence;critical pair (logic);digital subscriber line;e-government;embedded system;file synchronization;formal methods;graph rewriting;hidden line removal;meta-object facility;metamodeling;modeling language;network security;parallel computing;pattern recognition;requirement;synchronization (computer science)	Frank Hermann;Hartmut Ehrig;Claudia Ermel	2009		10.1007/978-3-642-00593-0_22	computer science;information security;theoretical computer science;critical graph;algorithm;graph rewriting	Logic	-52.6946189557082	49.80109193708329	177289
43c11d6f62c210341d8662ffac81a4589e2d45b6	risk assessment for cloud-based it systems	owasp;iso iec 2700x;risk management;google app engine;cloud computing	The use of Cloud Computing services is an attractive option to improve IT systems to achieve rapidly and elastically provisioned capability, and also to offer economic benefits. However, companies see security as a major concern in migrating to the Cloud. To bring clarity in Cloud security, this paper presents a systematic approach to manage the risks and analyzes the full range of risk in Cloud Computing solutions. Furthermore, as a study case, Google App Engine Platform is assessed based on ISO/IEC 27002 and OWASP Top 10 Risk List in this paper. Knowing the risks of Cloud solutions, companies can execute well-informed decisions on going into the Cloud and build their Cloud solutions in a secure way, relying on a robust e-trust relationship. tion (Mell & Granc, 2009). A Cloud is the type of parallel and distributed system consisting of a collection of inter-connected and virtualized computers that are dynamically provisioned and presented as one or more unified computing resources based upon the service level agreements established through negotiation between service provider and service user (Buyya, Yeo, Venugopal, Broberg, & Brandic, 2009). However, the security standards for Cloud Computing forms slowly, if without cautious understanding the know-how and the risk evaluation when we adapt the systems based on Cloud structures, it will become a disaster. Not all risks of Cloud Computing can be addressed on a global level. Individual risks arise at different Cloud solutions. Before going into Clouds, a company needs to know the specific of the individual Cloud providers. Therefore, DOI: 10.4018/jghpc.2011040101 2 International Journal of Grid and High Performance Computing, 3(2), 1-13, April-June 2011 Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. it will be very helpful if research institutes will analyze and publish individual risk profiles after intensive analysis. This paper performed such an analysis for the Google Cloud Platform (called “Google App Engine”) for industry as a reference first. This analysis is based on the security domains of ISO/IEC 27002 Standard (International Organization for Standardization, 2007) and OWASP Top 10 (OWASP, 2010) risks in web application to check if using the Google Platform can alleviate these risks.	cloud computing security;computer;distributed computing;fabric computing;google app engine;google cloud platform;google data centers;iso/iec 27002;internet;parallel computing;risk assessment;service-level agreement;web application	Yuyu Chou;Jan Oetting	2011	IJGHPC	10.4018/jghpc.2011040101	cloud computing security;cloud computing;risk management;computer science;operating system;cloud testing;internet privacy;world wide web;computer security	HPC	-48.95881483867053	56.86042283162816	177580
9d20932ecfdcf814c26d60ee3913eca0d5973fd5	a new approach to security system development	application environment;multiphase methodology;physical implementation;security mechanism;security system;initial preliminary analisys;security specification;new security system;existing security system;new approach;security system development;hardware;control systems;information analysis;authorization;information security;process design;risk analysis;access control	The development of a security system is generally performed through a multiphase methodology, starting from the initial preliminary analisys of the application environment, up to the physical implementation of the security mechanisms. In this framework, we propose a new approach for the development of security systems based on the reuse of existing security specifications. In the paper we illustrate how reusable specifications can be built by analyzing existing security systems, and how they can be used to develop new security systems not from scratch.		Silvana Castano;Giancarlo Martella;Pierangela Samarati	1994			software security assurance;control system security;information security audit;computer security model;standard of good practice;cloud computing security;process design;countermeasure;security through obscurity;risk analysis;security information and event management;covert channel;asset;computer science;information security;access control;security service;authorization;security analysis;data analysis;security testing;network access control;computer security;information security management	Security	-55.08053670862863	49.0220737753276	177590
4219b4b4bd23cf62e544a7047d9b843e36115ee8	quantum computing and cloud computing: humans trusting humans via machines	computers;trust;bepress selected works;component;e trust;cloud computing probabilistic logic component e trust quantum computing computational modeling ethics trust;trusted computing cloud computing ethical aspects object oriented methods quantum computing;ethics;computational modeling;societal trust quantum computing cloud computing abstraction level object oriented model important ethical concern identification;quantum computing component trust e trust cloud computing;probabilistic logic;quantum computing;quantum computing cloud computing computers ethics probabilistic logic computational modeling;cloud computing	In this paper we use Levels of Abstraction and an object-oriented model of trust to analyze quantum computing and cloud computing to identify important ethical concerns. The method of Levels of Abstraction aids in identifying broad social concerns of both methods of computation. Both methods of computation have the potential to deeply impact societal trust of computing.	cloud computing;computation;quantum computing;trust (emotion)	Frances S. Grodzinsky;Marty J. Wolf;Keith W. Miller	2011	2011 IEEE International Symposium on Technology and Society (ISTAS)	10.1109/ISTAS.2011.7160598	cloud computing;computer science;theoretical computer science;end-user computing;distributed computing;soft computing;utility computing;unconventional computing	Arch	-48.33534854692552	57.3872558873616	177658
8db3e0c64896bfd8ff2046146512420b4599df33	taming the costs of trustworthy provenance through policy reduction		Provenance is an increasingly important tool for understanding and even actively preventing system intrusion, but the excessive storage burden imposed by automatic provenance collection threatens to undermine its value in practice. This situation is made worse by the fact that the majority of this metadata is unlikely to be of interest to an administrator, instead describing system noise or other background activities that are not germane to the forensic investigation. To date, storing data provenance in perpetuity was a necessary concession in even the most advanced provenance tracking systems in order to ensure the completeness of the provenance record for future analyses. In this work, we overcome this obstacle by proposing a policy-based approach to provenance filtering, leveraging the confinement properties provided by Mandatory Access Control (MAC) systems in order to identify and isolate subdomains of system activity for which to collect provenance. We introduce the notion of minimal completeness for provenance graphs, and design and implement a system that provides this property by exclusively collecting provenance for the trusted computing base of a target application. In evaluation, we discover that, while the efficacy of our approach is domain dependent, storage costs can be reduced by as much as 89% in critical scenarios such as provenance tracking in cloud computing data centers. To the best of our knowledge, this is the first policy-based provenance monitor to appear in the literature.	backdoor (computing);cloud computing;correctness (computer science);data center;mandatory access control;system administrator;tracking system;trusted computing base;trustworthy computing	Adam M. Bates;Dave Tian;Grant Hernandez;Thomas Moyer;Kevin R. B. Butler;Trent Jaeger	2017	ACM Trans. Internet Techn.	10.1145/3062180	data mining;perpetuity;metadata;tracking system;computer science;obstacle;mandatory access control;cloud computing;trusted computing base;provenance	OS	-51.35938329232504	53.29141825807088	177714
492ff6e0b279fe984d2bf4da904f8a7d27270122	multi objective optimization of vpn design by linear programming with risks models		Optimal design of IPsec-based virtual private networks (VPN), in general, depends on multiple factors and parame- ters, such as the VPNu0027s architectural model, hardware and software setups and the technical platform solutions, network topo- logy models, modes of the tunnelu0027s operation, levels of the Open Systems Interconnection (OSI) model, encryption/decryption algorithms, modes of cipher operation, security protocols, security associations and key management techniques, connectivity modes, parameters of security algorithms, computer architectures, the number of tunnels in the VPN, and other factors. This paper presents an innovative approach to using methods of linear programming with risks to solve a multi objective optimiza- tion problem of VPN design. In particular, it describes the proposed conceptual VPN design model, VPN information security space, index of effectiveness for multi objective optimization, a new classification of scales, a system-based approach to risks and mathematical modeling of a risk, a hierarchy of scripts and a theorem of description of passwords, VPN design optimization process and particular procedures, sets of legal and illegal VPN design methods, and a VPN design optimization algorithm based on multi objective optimization by linear programming with risks models. The proposed and developed VPN design optimization algorithm was tested by developing specific VPN design methods for various types of VPN users.	linear programming;mathematical optimization;virtual private network	Alexander Uskov;Nataliya Serdyukova;Vladimir I. Serdyukov;Colleen Heinemann;Adam Byerly	2016	KES Journal	10.3233/KES-160342	mathematical optimization;simulation	Theory	-55.21632871346934	50.1094729037637	177767
36e81b745b1122de2440be3a25920860f8287147	blockchain-based tls notary service		The Transport Layer Security (TLS) protocol is a de facto standard of secure client-server communication on the Internet. Its security can be diminished by a variety of attacks that leverage on weaknesses in its design and implementations. An example of a major weakness is the public-key infrastructure (PKI) that TLS deploys, which is a weakest-link system and introduces hundreds of links (i.e., trusted entities). Consequently, an adversary compromising a single trusted entity can impersonate any website. Notary systems, based on multi-path probing, were early and promising proposals to detect and prevent such attacks. Unfortunately, despite their benefits, they are not widely deployed, mainly due to their long-standing unresolved problems. In this paper, we present Persistent and Accountable Domain Validation (PADVA), which is a next-generation TLS notary service. PADVA combines the advantages of previous proposals, enhancing them, introducing novel mechanisms, and leveraging a blockchain platform which provides new features. PADVA keeps notaries auditable and accountable, introduces service-level agreements and mechanisms to enforce them, relaxes availability requirements for notaries, and works with the legacy TLS ecosystem. We implemented and evaluated PADVA, and our experiments indicate its efficiency and deployability.	adversary (cryptography);bitcoin;client–server model;domain-validated certificate;ecosystem;entity;experiment;internet;public key infrastructure;public-key cryptography;requirement;server (computing);service-level agreement;transport layer security	Pawel Szalachowski	2018	CoRR		leverage (finance);implementation;computer security;transport layer security;adversary;public key infrastructure;the internet;computer science;blockchain;de facto standard	Security	-51.55328921221367	58.79755248476256	178410
57c8cf9e263071b9b9cfd99fd541d3bd1c3eeff7	modeling system threat probabilities using mixed-radix multiple-valued logic decision diagrams		Design for security has become an area of increasing importance. This includes securing systems from both natural and intentional threats. Extremely large and complex systems can have an accordingly large number of threat scenarios, thus simply listing the threats and devising countermeasures for each is ineffective and inefficient. The components of a large system may also have various states of failure, which cannot be captured by contemporary binary system models. To address this problem, we describe a threat cataloging methodology whereby a large number of threats can be efficiently cataloged and analyzed for common features. This allows countermeasures to be formulated that address a large number of threats that share common features. The methodology utilizes Mixed-Radix Multiple-Valued Logic for describing the state of a large system and a multiple-valued decision diagram (MDD) for the threat catalog and analysis.	complex systems;countermeasure (computer);it risk management;influence diagram;model-driven engineering;scalability;threat (computer);tree (data structure)	Theodore W. Manikas;Mitchell A. Thornton;David Y. Feinstein	2015	Multiple-Valued Logic and Soft Computing		simulation;data mining;computer security	Security	-61.82462506732273	59.67866126364589	178684
4e13c979628b7b2ec1a98feb044be3c78ef672e3	a formal approach for identity management in federated web services	web service;temporal logic of actions;service model;service provider;system security;identity management	The objective of the proposed work is to formally specify and implement a federated web service model in which the identity management problem and security features are analyzed. The identity provider assigns equal priority to all registered services of different capability and security domains on mutual trust. The service requester may contact any other service provider inside and outside of its own capability and security domain. The service Id and the service session time are the two important factors on which the federated system security during any session are focused. The federated system with heterogeneous services is formally specified using Temporal Logic of Actions (TLA) and verified. The model is implemented using different types of clients and the performance in terms of latency is measured.	identity management;identity provider;temporal logic of actions;web services discovery;web service	S. Chandrasekaran;C. Dinesh;Kartic Ramesh;Al. Murugappan	2007			boom;computer science;computer network;database;web service;nozzle;drum;electrical conduit;mechanical engineering	Web+IR	-48.626194547760186	54.19404844090329	178703
3b8c53529263f4f50280d8a70ffaf7ed6bba506c	desiging a logical security framework for e-commerce system based on soa		Rapid increases in information technology also changed the existing markets and transformed them into emarkets (e-commerce) from physical markets. Equally with the e-commerce evolution, enterprises have to recover a safer approach for implementing E-commerce and maintaining its logical security. SOA is one of the best techniques to fulfill these requirements. SOA holds the vantage of being easy to use, flexible, and recyclable. With the advantages, SOA is also endowed with ease for message tampering and unauthorized access. This causes the security technology implementation of E-commerce very difficult at other engineering sciences. This paper discusses the importance of using SOA in E-commerce and identifies the flaws in the existing security analysis of E-commerce platforms. On the foundation of identifying defects, this editorial also suggested an implementation design of the logical security framework for SOA supported E-commerce system.	authorization;e-commerce payment system;logical security;requirement;service-oriented architecture	Ashish Kr. Luhach;Sanjay K. Dwivedi;C. K. Jha	2014	CoRR		world wide web;computer security;oasis soa reference model	Security	-51.00828800584359	59.56348630859667	178707
1e664310882cca7037da56cb8441049df6495125	chucky: exposing missing checks in source code for vulnerability discovery	anomaly detection;vulnerabilities;static analysis	Uncovering security vulnerabilities in software is a key for operating secure systems. Unfortunately, only some security flaws can be detected automatically and the vast majority of vulnerabilities is still identified by tedious auditing of source code. In this paper, we strive to improve this situation by accelerating the process of manual auditing. We introduce Chucky, a method to expose missing checks in source code. Many vulnerabilities result from insufficient input validation and thus omitted or false checks provide valuable clues for finding security flaws. Our method proceeds by statically tainting source code and identifying anomalous or missing conditions linked to security-critical objects.In an empirical evaluation with five popular open-source projects, Chucky is able to accurately identify artificial and real missing checks, which ultimately enables us to uncover 12 previously unknown vulnerabilities in two of the projects (Pidgin and LibTIFF).	data validation;libtiff;open-source software;vulnerability (computing)	Fabian Yamaguchi;Christian Wressnegger;Hugo Gascon;Konrad Rieck	2013		10.1145/2508859.2516665	anomaly detection;vulnerability;computer science;data mining;secure coding;world wide web;computer security;static analysis	Security	-58.66089042036757	57.414463619993455	178810
4f6a91c64df38cce88069ca9806a063cdc62bd4c	an embedded hypervisor for safety-relevant automotive e/e-systems	safety relevant automotive e e systems safety relevant automotive software virtual machines memory management unit less embedded hypervisor iso 26262 automotive safety standard isolated virtual electronic control units real time operating system electrical system electronic system trusted computing base microkernel based hypervisors autosar standard automotive embedded software;virtual machine monitors hardware random access memory automotive engineering program processors computer architecture;virtual machines automotive electronics embedded systems iso standards operating systems computers road safety	The number of future automotive embedded software applications and their complexity is still rising. Additional non-functional requirements such as safety, portability, maintainability and efficiency compound this trend. The AUTOSAR standard gives flexible and efficient mechanisms to build systems of software components but also involves high configuration effort. When considering safety, the standard has some weaknesses preventing the realization of full separation between software partitions of mixed integrity. Virtualisation seems to be a promising technology allowing one to merge multiple safety-relevant sub-systems onto a single hardware platform and to implement strong separation. Microkernel based hypervisors exhibit a small Trusted Computing Base and serve as the most reliable and robust component within the system. This paper describes and evaluates a microkernel approach to isolate safety-relevant automotive software virtual machines by using a Memory Management Unit less embedded hypervisor. For our analysis, safety mechanisms were implemented with a separation kernel. We present a concept, based upon the ISO 26262 automotive safety standard and its safety assumptions, in order to support isolated virtual electronic control units within a real-time environment. Our final goal is to prevent virtual machines from propagating faults between each other. We evaluate our solution by porting some production automotive software to a hypervisor using a paravirtualised AUTOSAR basic software and a Real-Time Operating System. Our benchmarks are based on state-of-the-art automotive hardware and show that the approach is feasible even with less hardware support for virtualisation.	autosar;application domain;automotive software;benchmark (computing);component-based software engineering;embedded hypervisor;embedded software;embedded system;engine control unit;functional requirement;legacy system;memory management unit;memory protection;microkernel;non-functional requirement;real-time operating system;real-time transcription;separation kernel;software portability;trusted computing base;virtual machine	Dominik Reinhardt;Gary Morgan	2014	Proceedings of the 9th IEEE International Symposium on Industrial Embedded Systems (SIES 2014)	10.1109/SIES.2014.6871203	embedded system;electronic control unit;real-time computing;storage hypervisor;operating system	Embedded	-54.64279452180631	50.27963801467313	178833
1fa7fe7085814bfeada583caaa8aafbdbeac62f6	leaps: learning-based proactive security auditing for clouds		Cloud security auditing assures the transparency and accountability of a cloud provider to its tenants. However, the high operational complexity implied by the multi-tenancy and self-service nature, coupled with the sheer size of a cloud, imply that security auditing in the cloud can become quite expensive and non-scalable. Therefore, a proactive auditing approach, which starts the auditing ahead of critical events, has recently been proposed as a promising solution for delivering practical response time. However, a key limitation of such approaches is their reliance on manual efforts to extract the dependency relationships among events, which greatly restricts their practicality and adoptability. In this paper, we propose a fully automated approach, namely LeaPS, leveraging learning-based techniques to extract dependency models from runtime events in order to facilitate the proactive security auditing of cloud operations. We integrate LeaPS to OpenStack, a popular cloud platform, and perform extensive experiments in both simulated and real cloud environments that show a practical response time (e.g., 6 ms to audit a cloud of 100,000 VMs) and a significant improvement (e.g., about 50% faster) over existing proactive approaches.		Suryadipta Majumdar;Yosr Jarraya;Momen Oqaily;Amir Alimohammadifar;Makan Pourzandi;Lingyu Wang;Mourad Debbabi	2017		10.1007/978-3-319-66399-9_15	leaps;accountability;computer security;distributed computing;computer science;cloud computing;audit;response time;cloud computing security;transparency (graphic)	DB	-50.4860799923579	57.44224336731792	178917
46f05e6293ae0bcf9ae353e44fa137e51fc89bad	a software flaw taxonomy: aiming tools at security	software security evaluation;security flaw;modern software;model checking technology;security problem;current high-priority security threat;software security flaw;available information;suitable taxonomy;software flaw taxonomy;security flaw taxonomy;buffer overflows;static analysis tools;software security;static analysis;model checking;testing;buffer overflow	Although proposals were made three decades ago to build static analysis tools to either assist software security evaluations or to find security flaws, it is only recently that static analysis and model checking technology has reached the point where such tooling has become feasible. In order to target their technology on a rational basis, it would be useful for tool-builders to have available a taxonomy of software security flaws organizing the problem space. Unfortunately, the only existing suitable taxonomies are sadly out-of-date, and do not adequately represent security flaws that are found in modern software.In our work, we have coalesced previous efforts to categorize security problems as well as incident reports in order to create a security flaw taxonomy. We correlate this taxonomy with available information about current high-priority security threats, and make observations regarding the results. We suggest that this taxonomy is suitable for tool developers and to outline possible areas of future research.	flaw hypothesis methodology;taxonomy (general)	Sam Weber;Paul A. Karger;Amit M. Paradkar	2005		10.1145/1083200.1083209	software security assurance;computer security model;reliability engineering;security through obscurity;security information and event management;security engineering;buffer overflow;security bug;computer science;engineering;data mining;application security;programming language;security testing;computer security	Crypto	-59.87912918821525	54.642285042449316	179149
3633b598e9a8318f716f829aef5c6258bae9eb6a	sok: a study of using hardware-assisted isolated execution environments for security	isolated execution environments;security;hardware	Hardware-assisted Isolated Execution Environments (HIEEs) have been widely adopted to build effective and efficient defensive tools for securing systems. Hardware vendors have introduced a variety of HIEEs including system management mode, Intel management engine, ARM TrustZone, and Intel software guard extensions. This SoK paper presents a comprehensive study of existing HIEEs and compares their features from the security perspective. Additionally, we explore both defensive and offensive use scenarios of HIEEs and discuss the attacks against HIEE-based systems. Overall, this paper aims to give an essential checkpoint of the state-of-the-art systems that use HIEEs for trustworthy computing.	arm architecture;application checkpointing;intel active management technology;intel developer zone;systems management;trustworthy computing	Fengwei Zhang;Hongwei Zhang	2016		10.1145/2948618.2948621	real-time computing;engineering;operating system;computer security	Security	-52.8763941727675	56.607515156866725	179205
ce08731215a49f9759aabf38cabb4fb3cbf709e3	bridging the data gap: data related challenges in evaluating large scale collaborative security systems		Data-sharing approaches such as collaborative security have been successfully applied to systems addressing multiple classes of cyber security threats. In spite of these results, scale presents a major challenge to further advances: collaborative security systems are designed to operate at a large scale (Internetor ISP-scale), and obtaining and sharing traces suitable for experimentation is difficult. We illustrate these challenges via an analysis of recently proposed collaborative systems. We argue for the development of simulation techniques designed specifically to address these challenges and sketch one such technique, parameterized trace scaling, which expands small traces to generate realistic large scale traces sufficient for analyzing collaborative security systems.	bridging (networking);computer security;experiment;image scaling;lock (computer science);network security;prototype;simulation;tracing (software)	John Sonchack;Adam J. Aviv;Jonathan M. Smith	2013			computer science;data mining;database;world wide web	Security	-60.65315490629994	60.21034068953228	179216
bbf2fa57437ee906f420d1b757f22cb36e3c7f54	trusted system construction	encapsulation;computers;commercial off the shelf software;trusted system construction;control systems;graphical user interfaces software packages security of data data encapsulation software reusability;x windowing system;commercial off the shelf software trusted system construction cots components software wrappers data encapsulation data security operational effectiveness x windowing system;risk management;software wrappers;security open systems encapsulation java electronic switching systems control systems risk management performance analysis computers military computing;data encapsulation;cots components;graphical user interfaces;x window system;software reusability;performance analysis;electronic switching systems;operational effectiveness;open systems;security;security of data;software packages;military computing;java;data security	Any system constructed today is likely to be constructed from COTS components. Encapsulation of these components using software wrappers promises to enable trusted systems to be constructed. These systems are complex and it is difficult to impose security without compromising operational effectiveness. The key problem which this paper addresses is to analyse encapsulations of COTS components to demonstrate the system is both secure and usable. Any foundation must be able to deal with the conflicting requirements of operational effectiveness and security especially with respect to COTS components. The approach is illustrated using the X	requirement;trusted system	Colin O'Halloran	1999		10.1109/CSFW.1999.779768	embedded system;encapsulation;risk management;computer science;information security;operating system;graphical user interface;data security;open system;programming language;java;computer security	Security	-54.84413831872566	49.37015089009085	179454
be403328ce93b678f0eaf5aa7a6a855e205dd18e	vimm: runtime integrity measurement of a virtualized operating system	operating system	This paper discusses the design of the Virtualization Integrity Measurement Monitor (VIMM) framework, which aims to provide runtime integrity measurement of a virtualized guest OS. Kernel memory and additional hardware state changes are constantly monitored and aggregated into a combined guest OS state, which is reported to a Trusted Platform Module (TPM), thus providing a trusted integrity measurement in runtime. This measurement can then be used for data protection (sealing of secret keys) and remote attestation based on the runtime integrity of the guest OS.	operating system	Chun Hui Suen	2010	J. UCS	10.3217/jucs-016-04-0554	virtualization;embedded system;computer science;operating system;trusted platform module	Metrics	-52.76345875615161	56.68307208002876	179581
1d8ca9c5680afd5b8fbea7b4c828d361f48a10b4	web services security assessment: an authentication-focused approach		Web services may be able to publish easily their functions to the rest of the web world. At the same time they suffer by several security pitfalls. Currently, there is limited research on how the proposed web-services security countermeasures affect performance and applicability. In this paper, we introduce the threats/attacks vs. web-services authentication, present the most widely used security method for protecting it, and identify the threats/attacks tackled by those methods. Moreover, we evaluate the web service authentication mechanism proposed in these implementations, not only on a theoretical level (by taking into consideration all the security issues of the implementing authentication sub-mechanisms), but also in a laboratory environment (by conducting extensive experiments). Finally we demonstrate the trade-offs between sophisticated web-service security methods and their performance.	authentication;experiment;information security;ws-security;web service;world wide web	Yannis Soupionis;Miltiadis Kandias	2012		10.1007/978-3-642-30436-1_49	computer security model;cloud computing security;web application security;security through obscurity;security information and event management;asset;information security;security service;distributed system security architecture;internet privacy;security testing;network access control;world wide web;computer security	Security	-50.082019704732886	58.09351436694203	179658
00f8a36674703b60f2e10c09e4a37bac84e6220a	an analysis and comparison of clustered password crackers	john the ripper;cluster;password cracking;beowulf;cisilia;secure computation;comparative analysis;parallel computer;password authentication	Password policies alone do not stand a chance of securing computer systems which rely on the use of secretbased, password authentication methods. The enforcement of “strong” passwords via pro-active password strengthening utilities and password cracking tools should be employed by system administrators to reduce the number of “weak” passwords in a computer system. With the availability of low-cost computer and networking hardware, clustered solutions for large computational tasks, such as password cracking, are no longer restricted to larger organisations. John the Ripper and Cisilia are two open-source password cracking programs which have the ability to run in a clustered environment. This paper intends to make a comparison of John the Ripper to Cisilia in a clustered environment utilising the OpenMosix and Beowulf styles of parallel computation. Unfortunately, due to problems with Cisilia an in-depth comparative analysis could not be performed, but the analysis of the John the Ripper results does highlight some issues in regards to clustered password cracking.	authentication;clusterknoppix;computation;computer;john the ripper;key stretching;networking hardware;open-source software;parallel computing;password cracking;password strength;qualitative comparative analysis;system administrator	Christian Frichot	2004			networking hardware;password;computer security;password policy;enforcement;password cracking;computer science;password authentication protocol;secure multi-party computation	Security	-49.22536356231328	59.60883116384901	179765
7310ea204f21747a144106169562633dc93ab2a9	e-forensics steganography system for secret information retrieval	stego key;secrecy;information systems;autonomic agent;information retrieval;information hiding;data embedding;journal article;steganography;autonomous agent;data extraction;secret information hiding;autonomic agent steganography secret information hiding data embedding stego key data extraction secrecy information systems;the australian standard research classification 280000 information computing and communication sciences	Steganography is the art and science of hiding information. This paper introduces e-Forensics as a novel technique for extracting secret information electronically creatively. We propose an e-Forensics system capable of detecting or extracting secret information using generic steganalytic algorithms. The system is based on an agent computing approach where the autonomic agent would traverse several websites and detect steganographic communication. If steganographic activity was detected it would report back to the concerned authority. A conceptual overview of the system, as well as its design layout is presented. An illustrative example clarifies system's functionality and performance. performance.	information retrieval;steganography	Vidyasagar Potdar;Muhammad Arsalan Khan;Elizabeth Chang;Mihaela Ulieru;Paul R. Worthington	2005	Advanced Engineering Informatics	10.1016/j.aei.2005.04.003	computer science;artificial intelligence;autonomous agent;steganography;internet privacy;information hiding;world wide web;computer security;information system;statistics	Web+IR	-62.092486098261	59.1448437403417	179833
60108acbf8da1bc3ca897e21c1e022cd32f1b891	comparing requirements from multiple jurisdictions	health information information systems pervasive system distributed system data breach notification requirement metrics legal landscape formalization watermark practice business analysts system developers perceived businesses costs perceived businesses risks u s state data breach notification laws financial information;law measurement watermarking organizations;watermarking;financial data processing;formal specification;information systems;measurement;watermarking business data processing financial data processing formal specification government policies information systems transaction processing ubiquitous computing;law;business data processing;health information;government policies;system development;ubiquitous computing;organizations;information system;transaction processing	Increasingly, information systems are becoming distributed and pervasive, enabling organizations to deliver services remotely to individuals and to share and store personal information worldwide. However, system developers face significant challenges in identifying and managing the many laws that govern their services and products. To address this challenge, we investigate a method to codify, analyze, and trace relationships among requirements from different regulations that share a common theme of data breach notification. To measure gaps and overlaps between regulations, we applied previously validated requirements metrics. Our findings include a formalization of the legal landscape using operational constructs for high- and low-watermark practices, which business analysts and system developers can use to reason about compliance trade-offs based on perceived businesses costs and risks. We discovered and validated these constructs using five U.S. state data breach notification laws that govern transactions of financial and health information of state residents.	cyber-security regulation;data breach;high-water mark (computer security);information system;personally identifiable information;pervasive informatics;requirement;security breach notification laws	David G. Gordon;Travis D. Breaux	2011	2011 Fourth International Workshop on Requirements Engineering and Law	10.1109/RELAW.2011.6050272	public relations;data mining;business;computer security	SE	-51.45381584582893	50.16717587846856	179840
56da98d4db0a778646ee445bd2fdbc2848f869af	securing energy metering software with automatic source code correction	power meters;program diagnostics;power system measurement;user privacy violation energy metering software security automatic source code correction power meters energy consumption monitoring cost savings web interface web applications cyber attacks application source code vulnerability removal open source energy metering applications;public domain software;wireless application protocol software browsers temperature measurement databases monitoring energy measurement;internet;data privacy;power consumption;program compilers;computerised monitoring;source coding computerised monitoring data privacy internet power consumption power meters power system measurement program compilers program diagnostics public domain software;source coding	Industry is using power meters to monitor the consumption of energy and achieving cost savings. This monitoring often involves energy metering software with a web interface. However, web applications often have vulnerabilities that can be exploited by cyber-attacks. We present an approach and a tool to solve this problem by analyzing the application source code and automatically inserting fixes to remove the discovered vulnerabilities. We demonstrate the use of the tool with two open source energy metering applications in which it found and corrected 17 vulnerabilities. By looking in more detail into some of these vulnerabilities, we argue that they are very serious, leading to the following impacts: violation of user privacy, counter the benefits of energy metering, and serve as entering points for attacks on other user software.	cross-site scripting;end-user development;malware;open-source software;sql injection;uninterruptible power supply;user interface;vulnerability (computing);web application	Iberia Medeiros;Nuno Ferreira Neves;Miguel Correia	2013	2013 11th IEEE International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2013.6622969	embedded system;computer science;world wide web;computer security	SE	-56.67530050399227	59.08977849942768	179967
319fb57f645c74237c4eca2d2aa6b874fd3db122	spiral^sra: a threat-specific security risk assessment framework for the cloud		Conventional security risk assessment approaches for cloud infrastructures do not explicitly consider risk with respect to specific threats. This is a challenge for a cloud provider because it may apply the same risk assessment approach in assessing the risk of all of its clients. In practice, the threats faced by each client may vary depending on their security requirements. The cloud provider may also apply generic mitigation strategies that are not guaranteed to be effective in thwarting specific threats for different clients. This paper proposes a threat-specific risk assessment framework which evaluates the risk with respect to specific threats by considering only those threats that are relevant to a particular cloud client. The risk assessment process is divided into three phases which have inter-related activities arranged in a spiral. Application of the framework to a cloud deployment case study shows that considering risk with respect to specific threats leads to a more accurate quantification of security risk. Although our framework is motivated by risk assessment challenges in the cloud it can be applied in any network environment.	cloud computing;requirement;risk assessment;software deployment;threat (computer)	Armstrong Nhlabatsi;Jin B. Hong;Dong Seong Kim;Rachael Fernandez;Noora Fetais;Khaled M. Khan	2018	2018 IEEE International Conference on Software Quality, Reliability and Security (QRS)	10.1109/QRS.2018.00049	risk management;risk analysis (engineering);software deployment;cloud computing;business;risk assessment;authentication;server	SE	-49.916217969075376	57.278261239045285	180087
fef19900c41c65c2161f2505cf9bab4f5708a7bb	integrating a security plug-in with the openup/basic development process	security plug in software security software development process;unified process;security plug in;sustainable software security process security plug in openup basic development process software development;software engineering security of data;sustainable software security process;software development process;development process;software engineering;programming information security best practices computer security process design software systems costs availability information science performance evaluation;software security;lessons learned;software development;datavetenskap datalogi;computer science;openup basic development process;security of data	In this paper we present a security plug-in for the OpenUP/Basic development process. Our security plug-in is based on a structured unified process for secure software development, named S3P (sustainable software security process). This process provides the formalism required to identify the causes of vulnerabilities and the mitigation techniques that prevent these vulnerabilities. We also present the results of an expert evaluation of the security plug-in. The lessons learned from development of the plug-in and the results of the evaluation will be used when adapting S3P to other software development processes.	application security;openup;plug-in (computing);semantics (computer science);software development;touchstone file;unified process	Shanai Ardi;Nahid Shahmehri	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.132	software security assurance;computer security model;security through obscurity;computer science;systems engineering;unified process;software engineering;secure coding;security testing;goal-driven software development process;computer engineering	SE	-55.26377473294256	48.62456584376576	180122
dcfbcaa17c3787acce9e3da478ab23144dc64ce2	improving the evaluation of shoulder surfing attacks		Taking authentication methods' resilience against shoulder surfing attacks into account has become a necessity when evaluating novel textual and graphical schemes. Researchers are often quick to declare their new method safe against these attacks, while paying little attention to how the obtained results were measured and whether they are comparable to those of other methods. In this work, we highlight these issues and develop a solution: an ensemble of vulnerability metrics assessing methods' susceptibility to shoulder surfing attacks. We believe our approach provides insight into how shoulder surfing experiments could be improved in the future.	authentication;experiment;graphical user interface	Leon Bosnjak;Bosnjak Brumen	2018		10.1145/3227609.3227687	shoulder surfing;data mining;computer science;psychological resilience;vulnerability;authentication	HCI	-61.30032522991952	56.52126655471444	180546
d5a987799cb15edf19edc6ab0e2c12f2a647a056	considerations towards a cyber crime profiling system	casey certainty scale;integrity classification scheme;digital forensics;finite state machines computer crime data integrity;management system;data integrity;integrable model;availability;computer crime;null;law legal factors military computing digital forensics automata computer security computer crime nasa us government availability;law;cyber crime profiling system;computer security;automata;legal factors;finite state machines;integrity aware forensic evidence management system;casey certainty scale cyber crime profiling system digital evidence integrity aware forensic evidence management system integrity classification scheme finite state automaton;finite state automaton;digital evidence;nasa;us government;military computing	The field of digital forensics is faced with a number of challenges, given the constant growth in technologies. The reliability and integrity associated with digital evidence from disparate sources is also a perpetual challenge, requiring considerable human interpretation in the reconstruction of any particular sequence of events. In this paper we present a framework for an integrity-aware forensic evidence management system (FEMS). In an effort to automate the analysis process, this system would provide investigators with a holistic view of the forensic evidence at hand; thereby providing insights into the quality of investigative inferences. The Biba integrity model is incorporated to preserve the integrity of digital evidence, while Casey's Certainty Scale is chosen as the integrity classification scheme. A finite state automaton (FSA) is used to model the behaviour of the FEMS. In so doing, cyber crime profiling is achieved.	biba model;cellular automaton;cybercrime;finite-state machine;holism	Kweku Kwakye Arthur;Martin S. Olivier;Hein S. Venter;Jan H. P. Eloff	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.107	simulation;engineering;forensic engineering;computer security	DB	-54.91751746383118	50.109249128005764	180983
1b8ba6e7c04eacbd78ef10ed0b14ec6ee3ed77f4	vnida: building an ids architecture using vmm-based non-intrusive approach	virtual machine;virtual machine monitor;security policies;authorisation;system resource;unauthorized access prevention;intrusion detection;system performance;software architecture;security policies intrusion detection system unauthorized access prevention system resource detection evasion intrusion containment virtual machine monitor intrusion detection domain;virtual machines;intrusion containment;buildings intrusion detection prototypes data security monitoring data mining computer architecture computer science open source software software engineering;security policy;intrusion detection domain;detection evasion;intrusion detection system;virtual machines authorisation software architecture	Intrusion detection system (IDS) has been introduced and broadly applied to prevent unauthorized access to system resource and data for several years. However, many problems are still not well resolved in most of IDS, such as detection evasion, intrusion containment. In order to resolve these problems, we propose a novel flexible architecture VNIDA which is based on virtual machine monitor (VMM) and has no-intrusive behavior to target system after studying popular IDS architectures. In this architecture, a separate intrusion detection domain (IDD) is added to provide intrusion detection services for all virtual machines. Specially, an IDD helper is introduced to take response to the intrusions according to the security policies. Moreover, event sensors and IDS stub, as the core components of IDS, are separately isolated from target systems, so strong reliability is also achieved in this architecture. To show the feasibility of the VNIDA, we implement a prototype based on the proposed architecture. Based on the prototype, we employed some rootkits to evaluate our VNIDA, and the results shows that VNIDA has the ability to detect them efficiently, even some potential intrusions. In addition, system performance evaluation also shows that VNIDA only introduce less than 1.25% extra overhead.	authorization;evasion (network security);hypervisor;intrusion detection system;overhead (computing);performance evaluation;prototype;rootkit;sensor;virtual machine manager	Xiantao Zhang;Qi Li;Sihan Qing;Huanguo Zhang	2008	First International Workshop on Knowledge Discovery and Data Mining (WKDD 2008)	10.1109/WKDD.2008.135	anomaly-based intrusion detection system;intrusion detection system;real-time computing;computer science;security policy;virtual machine;operating system;computer performance;computer security;intrusion prevention system	Security	-54.046472065995836	57.06214694929001	180992
b42abdd897ebf9541f0e2929665d7fe679fb3246	virtual structures and heterogeneous nodes in dependency graphs for detecting metamorphic malware	databases;polip metamorphic malware virtual structures heterogeneous nodes dependency graphs malicious programs code patterns malware code obfuscation techniques reference graph database graph matching np hard problem binary programs evol metamorphic malware;metamorphism dependency graphs floyd warshal malware;binary trees;malware registers databases automata data models moon binary trees;automata;virtualisation graph theory invasive software optimisation pattern recognition;malware;registers;moon;data models	The traditional way to identify malicious programs is to compare the code body with a set of previously stored code patterns, also known as signatures, extracted from already identified malware code. To nullify this identification process, the malware developers can insert in their creations the ability to modify the malware code when the next contamination process takes place, using obfuscation techniques. One way to deal with this metamorphic malware behavior is the use of dependency graphs, generated by surveying dependency relationships among code elements, creating a model that is resilient to code mutations. Analog to the signature model, a matching procedure that compares these graphs with a reference graph database is used to identify a malware code. Since graph matching is a NP-hard problem, it is necessary to find ways to optimize this process, so this identification technique can be applied. Using dependency graphs extracted from binary code, we present an approach to reduce the size of the reference dependency graphs stored on the graph database, by introducing a node differentiation based on its features. This way, in conjunction with the insertion of virtual paths, it is possible to build a virtual clique used to identify and dispose of less relevant elements of the original graph. The use of dependency graph reduction also produces more stable results in the matching process. To validate these statements, we present a methodology for generating these graphs from binary programs and compare the results achieved with and without the proposed approach in the identification of the Evol and Polip metamorphic malware.	antivirus software;binary code;clique (graph theory);coefficient;experiment;graph database;graph isomorphism problem;graph reduction;malware;matching (graph theory);power supply unit (computer);requirement;sensor;subgraph isomorphism problem;topological sorting	Gilbert Breves Martins;Rosiane de Freitas;Eduardo Souto	2014	2014 IEEE 33rd International Performance Computing and Communications Conference (IPCCC)	10.1109/PCCC.2014.7017069	data modeling;binary tree;computer science;natural satellite;theoretical computer science;operating system;distributed computing;automaton;malware;processor register;world wide web;computer security	SE	-58.14473000942879	55.82803120068692	181220
e0d69add9bd812a166cee25f0ef9ee7f97d7a8a5	on the deployment of dynamic taint analysis for application communities	dynamic taint analysis;0-day attack detection;software security;application community;computer science	Although software-attack detection via dynamic taint analysis (DTA) supports high coverage of program execution, it prohibitively degrades the performance of the monitored program. This letter explores the possibility of collaborative dynamic taint analysis among members of an application community (AC): instead of full monitoring for every request at every instance of the AC, each member uses DTA for some fraction of the incoming requests, thereby loosening the burden of heavyweight monitoring. Our experimental results using a test AC based on the Apache web server show that speedy detection of worm outbreaks is feasible with application communities of medium size (i.e., 250–500). key words: Dynamic taint analysis, 0-day attack detection, application community, software security	application security;digital television adapter;server (computing);software deployment;taint checking;web server;zero-day (computing)	Hyung Chan Kim;Angelos D. Keromytis	2009	IEICE Transactions		software security assurance;simulation;telecommunications;computer science;differential thermal analysis;computer security	Security	-56.745922450418966	59.57641084233579	181321
43905ed3969af8c32d1ef55e48bda60f22d1098d	remote attestation on program execution	remote attestation;trusted platform module;trusted computing;execution environment;program dependency;source code	Remote attestation provides the basis for one platform to establish trusts on another. In this paper, we consider the problem of attesting the correctness of program executions. We propose to measure the target program and all the objects it depends on, with an assumption that the Secure Kernel and the Trusted Platform Module provide a secure execution environment through process separation. The attestation of the target program begins with a program analysis on the source code or the binary code in order to find out the relevant executables and data objects. Whenever such a data object is accessed or a relevant executable is invoked due to the execution of the target program, its state is measured for attestation. Our scheme not only testifies to a program's execution, but also supports fine-granularity attestations and information flow checking.	binary code;correctness (computer science);executable;program analysis;trusted computing;trusted platform module	Liang Gu;Xuhua Ding;Robert H. Deng;Bing Xie;Hong Mei	2008		10.1145/1456455.1456458	real-time computing;direct anonymous attestation;computer science;operating system;trusted platform module;trustworthy computing;computer security;source code	Security	-55.00314805993038	54.70236252496353	181347
c99725b79c10dd9e96f8a05f28b84c10d09a116e	a framework for evaluating the end-to-end trustworthiness		Trustworthiness of software and services is a key concern for their use and adoption by organizations and endusers. Trustworthiness evaluation is an important task to support both providers and consumers in making informed decisions, i.e., for selecting components from a software marketplace. Most of the literature evaluates trustworthiness by focusing on a single dimension (e.g., from the security perspective) while there are limited contributions towards multifaceted and end-to-end trustworthiness evaluation. Our analysis reveals that there is a lack of a comprehensive framework for comparative, multifaceted end-to-end trustworthiness evaluation, which takes into account different layers of abstractions of both the system topology and its trustworthiness. In this paper, we provide a framework for end-to-end trustworthiness evaluation using computational approaches, which is based on aggregating certified trustworthiness values for individual components. The resulting output supports in defining trustworthiness requirements for a software component to be developed and eventually integrated within a system, as well as obtaining trustworthiness evidences for a composite system before the actual deployment. Thereby it supports the designer in analyzing the end-to-end trustworthiness. An application example illustrates the application of the framework.	component-based software engineering;eclipse process framework;end-to-end principle;it risk management;mechatronics;precondition;requirement;software deployment;software development;software trustworthiness;systems design;trust (emotion)	Nazila Gol Mohammadi;Torsten Bandyszak;Costas Kalogiros;Michalis Kanakakis;Thorsten Weyer	2015	2015 IEEE Trustcom/BigDataSE/ISPA	10.1109/Trustcom.2015.429	reliability engineering;engineering;knowledge management;computer security	Mobile	-55.186219761468465	47.677551618654185	181536
6c4f055f1d818d3784fe1b719e60c40f518fee1d	inferring java security policies through dynamic sandboxing	policy language;security policy;computer security;principle of least privilege.;java;policy inference	Complex enterprise and server-level applications are often written in Java because of its reputation for security. The Java policy language allows users to specify very fine-grained and complex security policies. However, this expressiveness makes it difficult to determine the correct policy with respect to the principle of least privilege. We describe a method for automatically learning the minimum security policy called dynamic sandboxing . A minimal sandbox (security policy) is inferred by observing program execution and expressed in the standard Java policy language. The minimum policy stops Java exploits and learning the policy does not cripple performance, allowing applications to run normally during training.	java;principle of least privilege;sandbox (computer security);server (computing)	Hajime Inoue	2005			computer security model;database;information security standards;security through obscurity;computer security;cloud computing security;software security assurance;business;java;security information and event management;security service	Security	-55.71379034200406	57.92629379864884	181560
c4380e0722ba8e843db635f8c42db53adfe2ec1e	covert and deniable communications		At the first Information Hiding Workshop in 1996 we tried to clarify the models and assumptions behind information hiding. We agreed the terminology of cover text and stego text against a background of the game proposed by our keynote speaker Gus Simmons: that Alice and Bob are in jail and wish to hatch an escape plan without the fact of their communication coming to the attention of the warden, Willie. Since then there have been significant strides in developing technical mechanisms for steganography and steganalysis, with new techniques from machine learning providing ever more powerful tools for the analyst, such as the ensemble classifier. There have also been a number of conceptual advances, such as the square root law and effective key length. But there always remains the question whether we are using the right security metrics for the application. In this talk I plan to take a step backwards and look at the systems context. When can stegosystems actually be used? The deployment history is patchy, with one being Trucrypt's hidden volumes, inspired by the steganographic file system. Image forensics also find some use, and may be helpful against some adversarial machine learning attacks (or at least help us understand them). But there are other contexts in which patterns of activity have to be hidden for that activity to be effective. I will discuss a number of examples starting with deception mechanisms such as honeypots, Tor bridges and pluggable transports, which merely have to evade detection for a while; then moving on to the more challenging task of designing deniability mechanisms, from leaking secrets to a newspaper through bitcoin mixes, which have to withstand forensic examination once the participants come under suspicion. We already know that, at the system level, anonymity is hard. However the increasing quantity and richness of the data available to opponents may move a number of applications from the deception category to that of deniability. To pick up on our model of 20 years ago, Willie might not just put Alice and Bob in solitary confinement if he finds them communicating, but torture them or even execute them. Changing threat models are historically one of the great disruptive forces in security engineering. This leads me to suspect that a useful research area may be the intersection of deception and forensics, and how information hiding systems can be designed in anticipation of richer and more complex threat models. The ever-more-aggressive censorship systems deployed in some parts of the world also raise the possibility of using information hiding techniques in censorship circumvention. As an example of recent practical work, I will discuss Covertmark, a toolkit for testing pluggable transports that was partly inspired by Stirmark, a tool we presented at the second Information Hiding Workshop twenty years ago.	adversarial machine learning;alice and bob;bitcoin;ensemble learning;gustavus simmons;honeypot (computing);internet censorship circumvention;key size;metcalfe's law;security engineering;software deployment;steganalysis;steganographic file system;steganography;threat model;tor messenger;truecrypt;vorticity confinement;while	Ross Anderson	2018		10.1145/3206004.3206023	computer security;theoretical computer science;information hiding;deception;computer science;alice and bob;steganographic file system;threat model;honeypot;adversarial machine learning;covert	Security	-61.379862790126765	57.83413361537172	181797
3a2a9c1f37c1c430992dc3142c4ed6d68a2596aa	controlling data flow with a policy-based programming language for the web		It has become increasingly easy to write Web applications and other distributed programs by orchestrating invocations to remote third-party services. Increasingly, these third-party services themselves invoke other services and so on, making it difficult for the original application developer to anticipate where his/her data will end up. This may lead to privacy breaches or contractual violations. In this paper, we explore a simple distributed programming language that allows a web service provider to infer automatically where user data will travel to, and the developer to impose statically-checkable constraints on acceptable routes. For example, this may provide confidence that company data will not flow to a competitor, or that privacy-sensitive data goes through an anonymizer before being sent further out.	approximation;data flow diagram;dataflow architecture;distributed computing;entity;higher-order function;internet privacy;policy-based design;programming language;spectral leakage;type system;web application;web service;world wide web	Thierry Sans;Iliano Cervesato;Soha Hussein	2013		10.1007/978-3-642-41488-6_15	computer science;data mining;database;world wide web	PL	-55.03532282946527	58.533432692628246	181866
8e74140a35d30d5ec8a4a415485e8276ad4bd30b	simulating attack behaviors in enterprise networks	computational modeling security analytical models markov processes mathematical model sensors;cybersim cyber attack behavior simulation cyber security fight through technologies attack behavior analysis large scale enterprise networks;business data processing;security of data business data processing digital simulation;security of data;digital simulation	Research works on cyber security have shifted from simply hardening the networked systems to enabling fight-through technologies where the system is resilient to sophisticated attacks. A much-needed effort in this new premise is a better understanding of how attackers might behave within a well-protected network. Attack behavior analysis can benefit from automated simulations for large-scale enterprise networks. This work reviews existing efforts on attack behavior modeling and simulation, leading to the discussion of CyberSim, a modular system for cyber attack behavior simulation.	behavior model;computer security;simulation	Stephen Moskal;Derek Kreider;Lydia Hays;Ben Wheeler;Shanchieh Jay Yang;Michael E. Kuhl	2013	2013 IEEE Conference on Communications and Network Security (CNS)	10.1109/CNS.2013.6682726	simulation;internet privacy;computer security;computer network	Security	-62.42848673391846	60.26400201463135	181958
a59e727e2dd96d6c1fc596661bb4b4fa578a084b	managing business compliance using model-driven security management	information security;identity and access management;security management;it security;levels of abstraction;service oriented architecture;security policy;business process modelling	Compliance with regulatory and governance standards is rapidly becoming one of the hot topics of information security today. This is because, especially with regulatory compliance, both business and government have to expect large financial and reputational losses if compliance cannot be ensured and demonstrated. One major difficulty of implementing such regulations is caused the fact that they are captured at a high level of abstraction that is business-centric and not IT centric. This means that the abstract intent needs to be translated in a trustworthy, traceable way into compliance and security policies that the IT security infrastructure can enforce. Carrying out this mapping process manually is time consuming, maintenance-intensive, costly, and error-prone. Compliance monitoring is also critical in order to be able to demonstrate compliance at any given point in time. The problem is further complicated because of the need for business-driven IT agility, where IT policies and enforcement can change frequently, e.g. Business Process Modelling (BPM) driven Service Oriented Architecture (SOA). Model Driven Security (MDS) is an innovative technology approach that can solve these problems as an extension of identity and access management (IAM) and authorization management (also called entitlement management). In this paper we will illustrate the theory behind Model Driven Security for compliance, provide an improved and extended architecture, as well as a case study in the healthcare industry using our OpenPMF 2.0 technology.		Ulrich Lang;Rudolf Schreiner	2008		10.1007/978-3-8348-9283-6_24	computer security model;standard of good practice;certified information security manager;cloud computing security;itil security management;certified information systems security professional;security management;security through obscurity;sherwood applied business security architecture;security information and event management;security convergence;asset;computer science;knowledge management;security policy;information security;service-oriented architecture;security service;security analysis;network security policy;computer security;business process modeling;enterprise information security architecture;information security management	Crypto	-50.5334395272691	51.471146168043056	181980
0488c9ee6acc169db6e78afd1793c5e1689290c4	towards a trust-manager service for hybrid clouds		Cloud computing changed recently business view regar ding their Information System through an on-demand provisioning of computi ng resources. Recent discussions about data security requirements in clo ud computing environment tend to conflict with other requirement including u sability and economic. In hybrid clouds that combine private and public clouds sage, private clouds are able both to externalize resources and invoke servi c s from public cloud when needed. However, in such specific inter-cloud envir onment risks arise. Indeed, private clouds aren’t sufficiently assured about ho w credible is the data computed by these resources they entrusted. This is du e to clouds autonomy preservation, difference in control policy definitions an d lack of transparency in clouds. In this position paper, we tend to propose an approach to help private cloud selecting a trustworthy public cloud service. The idea consists in a trust manager as a service that bases the decision-making on the private cloud past invocation analysis Keywords-component: Cloud computing, data credibility, trust managemen t, hybrid cloud, SLA	cloud computing;data security;information system;provisioning;requirement;service-level agreement	Fatma Ghachem;Nadia Bennani;Chirine Ghedira;Parisa Ghodous	2012		10.1007/978-3-642-38333-5_9	position paper;information system;cloud computing;usability;data security;internet privacy;transparency (graphic);cloud computing security;provisioning;computer security;computer science	Web+IR	-48.47165466629306	54.898254976842715	182108
ccc7bf251f61a230d86ce58488b53d92a5627087	owleye: an advanced detection system of web attacks based on hmm		Nowdays web services plays an important part in our daily life, and the security of web servers and applications has become one of the key topics in cyber security. Web request query strings(queries) are responsible for passing parameters to the referenced resources, thus vulnerable of being manipulated by attackers to retrive sensitive data and even losing full control of victims. In this paper, we propose OwlEye, a hybrid attack detection sensor based on Hidden Markov Model(HMM). It's designedtodefenseagainstweb-layercode-injectionattacks, such as SQL-injection and cross scripting. Its innovative bidirectory scoring architecture design offers the advantage of utilizing both benign and malicious traffic in model training, thus has acheived a satisfying detection rate at an acceptable false positive rate.	anomaly detection;cognitive dimensions of notations;computer security;film-type patterned retarder;hidden markov model;markov chain;query string;sql injection;sensor;spectrogram;uniform resource identifier;waf;web server;web service;zero-day (computing)	Xin Liu;J. Wojciech;Xiaokang Zhou;Qingguo Zhou	2018	2018 IEEE 16th Intl Conf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00044	architecture;false positive rate;web server;web service;query string;scripting language;data modeling;hidden markov model;computer science;distributed computing	Security	-57.800226934408045	59.4327880245158	182450
39e4ebc6955320e3c6710b9b3852d2b2e9a3d642	security-aware modeling and analysis for hw/sw partitioning		The rising wave of attacks on communicating embedded systems has exposed their users to risks of information theft, monetary damage, and personal injury. Through improved modeling and analysis of security, we propose that these flaws could be mitigated. Since HW/SW partitioning, one of the first phases, impacts future integration of security into the system, this phase would benefit from supporting modeling security abstractions and security properties, providing designers with useful partitioning feedback obtained from a security	embedded system;equivalence partitioning;shattered world	Letitia W. Li;Florian Lugou;Ludovic Apvrille	2017		10.5220/0006119603020311	computer science;systems engineering;computer engineering	EDA	-54.57636229321953	49.97747537705397	182468
26a720f77b57ca6954759a821ee7a9d9a749ea0a	role hierarchies and constraints for lattice-based access controls	mandatory access control;role based access control;access control	Role-based access control (RBAC) is a promising alternative to traditional discretionary and mandatory access controls. In RBAC permissions are associated with roles, and users are made members of appropriate roles thereby acquiring the roles' permissions. In this paper we formally show that latticebased mandatory access controls can be enforced by appropriate con guration of RBAC components. Our constructions demonstrate that role hierarchies and constraints are required to effectively achieve this result. We show that variations of the lattice-based ?-property, such as write-up (liberal ?-property) and no-write-up (strict ?-property), can be easily accommodated in RBAC. Our results attest to the exibility of RBAC and its ability to accommodate di erent policies by suitable con guration of role hierarchies and constraints.	copy-on-write;lattice model (finance);lattice-based access control;mandatory access control;naruto shippuden: clash of ninja revolution 3;role hierarchy;role-based access control	Ravi S. Sandhu	1996		10.1007/3-540-61770-1_28	computer science;access control;role-based access control;computer security	Security	-50.36601514804719	50.56548971462409	182917
bd45d4ad5a456621f5f38fd25268be236e93ed8d	resilient distribution grids — cyber threat scenarios and test environment	control systems;radiation detectors;smart grids;servers;security;voltage measurement	"""With the advent of the smart grid, a highly connected and communicative power grid, many new threats have to be considered, and new concepts for the grid to """"fail smartly"""" in the inevitable event of security intrusion are needed. This paper reviews a collection of possible cyber threat scenarios as well as outlines of counter measures to different aspects of the communication infrastructure and components of a future power grid. These scenarios aim to define a test framework to future solutions for resilient distribution grid operation. To allow the evaluation of the effects of possible counter measures to these threats a specialised test environment is presented."""	computer security;deployment environment;microsoft outlook for mac;simulation;test automation;threat (computer)	Elisabeth Drayer;Jan Hegemann;Stefan Gehler;Martin Braun	2016	2016 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2016.7856193	real-time computing;simulation;engineering;computer security	HPC	-58.07275954937642	50.71131567452592	183149
92b1b8187047c84817b7925774c41c8efb96a784	anomalous path detection with hardware support	internet access;anomaly detection;anomalous path;real time embedded system;dynamic program;monitoring granularity;embedded system;control flow monitoring;hardware support;control flow;time lag;power grid;near real time;critical infrastructure;intrusion detection system	Embedded systems are being deployed as a part of critical infrastructures and are vulnerable to malicious attacks due to internet accessibility. Intrusion detection systems have been proposed to protect computer systems from unauthorized penetration. Detecting an attack early on pays off since further damage is avoided and in some cases, resilient recovery could be adopted. This is especially important for embedded systems deployed in critical infrastructures such as Power Grids etc. where a timely intervention could save catastrophes. An intrusion detection system monitors dynamic program behavior against normal program behavior and raises an alert when an anomaly is detected. The normal behavior is learnt by the system through training and profiling.However, all current intrusion detection systems are purely software based and thus suffer from large performance degradation due to constant monitoring operations inserted in application code. Due to the potential performance overheads, software based solutions cannot monitor program behavior at a very fine level of granularity, thus leaving potential security holes as shown in the literature. Another important drawback of such methods is that they are unable to detect intrusions in near real time and the time lag could prove disastrous in real time embedded systems. In this paper, we propose a hardware-based approach to verify program execution paths of target applications dynamically and to detect anomalous executions. With hardware support, our approach offers multiple advantages over software based solutions including minor performance degradation, much stronger detection capability (a larger variety of attacks get detected) and zero-latency reaction upon an anomaly for near real time detection and thus much better security.	accessibility;anomaly detection;authorization;central processing unit;elegant degradation;embedded system;incidence matrix;intrusion detection system;malware;pipeline (computing);profiling (computer programming);real-time clock;real-time computing;uninterruptible power supply;vulnerability (computing)	Tao Zhang;Xiaotong Zhuang;Santosh Pande;Wenke Lee	2005		10.1145/1086297.1086305	intrusion detection system;embedded system;host-based intrusion detection system;anomaly detection;parallel computing;real-time computing;internet access;computer science;operating system;critical infrastructure;control flow;computer security;intrusion prevention system	Security	-56.864749100020575	56.63225889083259	183457
8939e0e611c628e6e3ff15408134cdc70da4d07b	dynamic responsibilities assignment in critical electronic institutions - a context-aware solution for in crisis access right management	databases;context aware;context computer architecture databases monitoring permission business;multi agent system;real time;heterogeneous environment;red project dynamic responsibilities assignment critical electronic institutions context aware solution crisis access right management critical it infrastructures incident infrastructure multiagent system communication channel critical architecture dynamic;computer architecture;software architecture;multi agent systems;monitoring;permission;ubiquitous computing multi agent systems security of data software architecture;business;dynamic response;ubiquitous computing;communication channels;electronic institution;security of data;context	Nowadays critical IT infrastructures constitute the pillars of our economy. Being able to react quickly and in real time is a crucial challenge for the security officers in charge of maintaining those infrastructures operationally. Our state of the art in this field has highlighted that many architectures exist to dynamically support the reaction after the detection of an incident infrastructure. Those architectures are mostly elaborated based on a multi-agent system approach that offers the possibility to work in a decentralized and heterogeneous environment. However, in the meantime, we have observed that those architectures are based on a static assignment of functions to agents and that, as a consequence, isolating an agent or breaking the communication channel between two of them could create serious damage on the management of the crisis. In this paper, we propose an innovative approach for making the assignment of functions to agents in the critical architecture dynamic. Our approach exploits the concept of agent responsibility that we assign dynamically to those agents depending on the crisis type and severity. Simultaneously we explain the dynamic assignment of the access rights necessary to perform the obligation linked to these new responsibilities. This dynamic assignment of responsibilities is illustrated based on the architecture defined in the ReD project.	channel (communications);multi-agent system;real-time computing	Cédric Bonhomme;Christophe Feltus;Michaël Petit	2011	2011 Sixth International Conference on Availability, Reliability and Security	10.1109/ARES.2011.43	simulation;engineering;knowledge management;computer security	EDA	-48.76890608807397	51.90782741569346	183742
7317b9519f62a7c88e85e71ee0b4a9c303b7c29e	christopher alexander's fifteen properties: toward developing evaluation metrics for security visualizations	security of data data visualisation;cyber analysts;security informatics;clocks;evaluation of security visualizations;information visualization;visual patterns;living structure properties;security data visualizations;data visualisation;visualization;shape;image color analysis;data visualization;evaluation metrics;security informatics security visualizations evaluation of security visualizations information visualization security intelligence;security;visualization specific properties;security of data;context;visualization specific properties evaluation metrics security data visualizations cyber analysts living structure properties visual patterns security related visualizations;security visualizations;data visualization security shape clocks image color analysis visualization context;security intelligence;security related visualizations	The objective of security data visualizations is to help cyber analysts to perceive trends and patterns, and gain insights into security data. Sound and systematic evaluations of security data visualizations are rarely performed, in part due to the lack of proper quantitative and qualitative measures. In this paper, we present a novel evaluation approach for security visualization based on Christopher Alexander's fifteen properties of living structures. Alexander's fifteen properties are derived from various visual patterns that appear in nature. Each property represents the guidelines for good design. We believe that using these fundamental properties have the potential for building a more robust evaluation. Each property offers essential qualities that enable better analytical reasoning. We demonstrate how to use Alexander's properties to evaluate security related visualizations. We derive a set of visualization-specific properties for evaluation, developed based on Alexander's original properties.		Ziyad Alshaikh;Abdulrahman Alarifi;Mansour Alsaleh	2013	2013 IEEE International Conference on Intelligence and Security Informatics	10.1109/ISI.2013.6578847	visualization;shape;computer science;data mining;internet privacy;world wide web;computer security;data visualization;statistics	Visualization	-57.90768737488482	47.81083162694188	183822
7e05580c91f040709ce7eea47d582c7aab727e23	research and implementation of a role-based trustworthiness mechanism for iaas	security of data cloud computing;cloud computing trustworthiness mechanism trusted computing;validation protocols role based trustworthiness mechanism cloud computing infrastructure as a service iaas architecture cloud environment;protocols cloud computing public key computational modeling computer architecture;security of data;cloud computing	Despite the advantages brought by cloud computing, security issues have emerged as one of the most significant barrier to faster and more widespread adoption of it. Therefore, this paper focused on the trustworthiness of infrastructure as a service (IaaS) and proposed a role-based trustworthiness mechanism to ensure that the different roles in IaaS architecture are trusted. What's more, this paper also considered the interactions between different roles in cloud environment and designed relevant validation protocols. Our experiments also show that this trustworthiness mechanism is practical in terms of performance.	cloud computing security;experiment;interaction;trust (emotion)	Xu Wu;Xiaqing Xie;Chunwen Li	2012	2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2012.6664419	cloud computing security;cloud computing;computer science;operating system;distributed computing;internet privacy;computer security	SE	-48.36068226339158	56.83778786926454	184170
1fc9644de34245f172a69c9b9083c2607bed2ae6	an experimental and industrial experience: avoiding denial of service via memory profiling	detectors;yarn;memory management;application software;java virtual machine;virtual machining;memory leaks;computer crime;leak detection;profiles techniques;garbage collection;compaction;java applet;computer crime memory management yarn java security application software leak detection compaction virtual machining detectors;denial of service;security;java;open source	Poor memory management leads to memory leaks, which cause significant performance degradation and failure of software. If ignored, such leaks can potentially cause security breaches and holes in applications. The present study shows that memory leaks can be exploited to cause Denial of Service (DoS) of applications. The ultimate goal of this study is to introduce a security profiling technique that can be used to identify security holes in software. We instrument memory leaks in a Java applet using an open source memory profiler based on Java Virtual Machine Profiler Interface (JVMPI). The results show that it is crucial to perform memory profiling prior to application deployment in order to avoid DoS and vulnerability exploits.	algorithm;computer security;database server;denial-of-service attack;elegant degradation;java applet;java virtual machine;management information system;megabyte;memory footprint;memory leak;memory management;open-source software;profiling (computer programming);semiconductor;sensor;server (computing);software deployment;vulnerability (computing);web application	Saeed Abu-Nimeh;Suku Nair;Marco F. Marchetti	2006	IEEE International Conference on Computer Systems and Applications, 2006.	10.1109/AICCSA.2006.205083	compaction;embedded system;detector;application software;computer science;information security;operating system;database;garbage collection;programming language;java;computer security;denial-of-service attack;memory leak;java applet;memory management	SE	-54.5990652367034	57.02243781852777	184234
972458f60cb44adb3f5ad1534b10cc59895f735a	inadequacies of current risk controls for the cloud	software;vulnerability authentication information insider monitoring security threat;current risk controls;threat;cloud environment;encryption;information security;sensors;security of data cloud computing;authentication;vulnerability;mitigating information security;monitoring;monitoring cloud computing software access control sensors encryption;cascade attacks;access control;cloud environment current risk controls mitigating information security cascade attacks;security;security of data;information;cloud computing;insider	In this paper we describe where current risk controls (as documented in ISO27001/27002) for mitigating information security risks are likely to be inadequate for use in the cloud. Such an analysis could provide a rationale for prioritizing protection research, and the work presented here is part of a larger exercise designed to identify the potential for cascade attacks in the cloud, and those areas most likely to be targeted based on both an understanding of threat motivations and likely areas of vulnerability.	cloud computing;design rationale;information security	M. Auty;Sadie Creese;Michael Goldsmith;Paul Hopkins	2010	2010 IEEE Second International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2010.49	information;cloud computing;vulnerability;computer science;sensor;threat;information security;access control;authentication;internet privacy;computer security;encryption;computer network	SE	-50.41354487070476	57.760694848661124	184655
f794adefe2b01f1d8a32807a16891dbbd72a2a4a	tron: process-specific file protection for the unix operating system	discretionary access control;operating system	The file protection mechanism provided in UNIX is insufficient for current computing environments. While the UNIX file protection system attempts to protect users from attacks by other users, it does not directly address the agents of destruction— executing processes. As computing environments become more interconnected and interdependent, there is increasing pressure and opportunity for users to acquire and test non–secure, and possibly malicious, software. We introduce TRON, a process–level discretionary access control system for UNIX. TRON allows users to specify capabilities for a process’ access to individual files, directories, and directory trees. These capabilities are enforced by system call wrappers compiled into the operating system kernel. No privileged system calls, special files, system administrator intervention, or changes to the file system are required. Existing UNIX programs can be run without recompilation under TRON–enhanced UNIX. Thus, TRON improves UNIX security while maintaining current standards of flexibility and openness.	compiler;control system;directory (computing);discretionary access control;interdependence;kernel (operating system);openness;operating system;protection mechanism;system administrator;system call;tron;unix security	Andrew Berman;Virgil Bourassa;Erik Selberg	1995			unix signal;unix architecture;embedded system;real-time computing;group identifier;resolv.conf;discretionary access control;computer science;kernel panic;operating system;fstab;unix file types;unix filesystem;file descriptor;streams;everything is a file;time of check to time of use;tmpdir;working directory	OS	-53.845707400125576	57.65118627783128	184706
5f57decd378536120072c6a52694ee03d6c00d0d	certikos: a certified kernel for secure cloud computing	verification;regression testing;resource manager;web servers;bugs;operating system;runtime monitoring;design;linux;software design;security;information leakage;cloud computing	Though attractive as a model for elastic on-demand service, cloud computing solutions based on existing hypervisors cannot guarantee that the provider will service a user's requests correctly, and will not leak sensitive information to unauthorized parties. We introduce CertiKOS (Certified Kit Operating System), a hypervisor architecture that leverages formal certification to ensure correctness and counter information leakage in cloud computing. CertiKOS isolates guest applications not only from each other but from provider-controlled resource management mechanisms. The kernel's API gives untrusted, provider-supplied management software control over allocation and delegation of resources such as memory and I/O devices, but prohibits management code from accessing a guest's memory or other resources while in use, or from interfering with a guest's execution except through clean resource revocation. CertiKOS represents an effort to apply recent advances in certified software design to a ground-up design of a modular and evolvable certified kernel. Through machine-checkable proof certificates and runtime monitoring, CertiKOS aims to offer users the assurance of correct and leak-free execution of their cloud services.	application programming interface;authorization;cloud computing;correctness (computer science);hypervisor;information leakage;information sensitivity;input/output;kernel (operating system);operating system;software design;spectral leakage	Liang Gu;Alexander Vaynberg;Bryan Ford;Zhong Shao;David Costanzo	2011		10.1145/2103799.2103803	real-time computing;computer science;operating system;computer security	OS	-52.576874173330765	57.794806186491414	184744
93a98378a0ddd60ccf99f975158d6833f038acb7	uml modelling of design patterns for wireless sensor networks		Wireless Sensor Network (WSN) systems are deployed to monitor specific phenomena. The design of WSNs is prone to errors and debugging and is very challenging due to the complex interactions of software components in a sensor node. This paper presents a set of UML patterns that can be used as a basis for software design of WSN systems. The UML patterns are used to capture the design components, the application flow, the components’ behaviour, and the interaction between the components and the application design. The design patterns for WSNs are justified by applying them to the WSN-RFID application that integrates RFIDs and sensor nodes in order to support authenticated point-to-point communication with a sensor node.	authentication;component-based software engineering;debugging;design pattern;interaction;point-to-point protocol;point-to-point (telecommunications);sensor node;software design;unified modeling language	John Khalil Jacoub;Ramiro Liscano;Jeremy S. Bradbury;Jared Fisher	2013			embedded system;real-time computing;applications of uml	Mobile	-51.11024020329084	47.80069006803284	184794
5354a53721ef6900fac63847ecedcd031e94488f	a shift in security modeling paradigms	security model	Models of the external syst,em interface of a computer have been successfully used to describe confidentiality requirements. This pa.per discusses the use of an external-interfa,ce model t1la.t supports the external consistency objective of Cla.rk and \,+Ylson as well as internal structura.1 constra.int,s needed t,o meet identified externa.l-int.erface requirementSs. These internal constraints identify a. vendor-supplied “Integrity Trusted Computing Base” tl1a.t handles informal proofs called “pedigrees.” The increa.sing use of external-interface models, which this work illust,ra.tes, represents a paradigm shift in t#he construction of security models.	confidentiality;programming paradigm;requirement;trusted computing base	James G. Williams	1993		10.1145/283751.283780	computer security model;computer science;management science;computer security	SE	-53.83769797751969	49.50723701116875	184836
4c2b42e905c263ab3ee7615e172f4a8e7232f8db	a microkernel virtual machine: : building security with clear interfaces	virtual machine;language based security;kernel;programming language;frameworks;software engineering;interface;security architecture;stack inspection;access control;java	In this paper we propose a novel microkernel-based virtual machine (µKVM), a new code-based security framework with a simple and declarative security architecture. The main design goals of the µKVM are to put a clear, inviolable programming interface between different codebases or security components, and to limit the size of the trusted codebase in the spirit of a microkernel. Security policies are enforced solely on the interface because all data must explicitly pass through the inviolable interface. The architecture of the µKVM effectively removes the need for expensive runtime stack inspection, and applies the principle of least privilege to both library and application code elegantly and efficiently. We have implemented a prototype of the proposed µKVM. A series of benchmarks show that the prototype preserves the original functionality of Java and compares favorably with the J2SDK performance-wise.	application programming interface;benchmark (computing);call stack;computer security;java development kit (jdk);microkernel;principle of least privilege;prototype;virtual machine	Xiaoqi Lu;Scott F. Smith	2006		10.1145/1134744.1134754	software security assurance;computer security model;embedded system;kernel;real-time computing;computer science;virtual machine;access control;software framework;operating system;trusted computing base;interface;programming language;java;enterprise information security architecture	OS	-54.47773135373651	54.67076307343411	185112
b61abcaf846febc251870546ebb018e9f9c4af79	a survey on access control deployment		Access control is a security aspect whose requirements evolve with technology advances and, at the same time, contemporary social contexts. Multitudes of access control models grow out of their respective application domains such as healthcare and collaborative enterprises; and even then, further administering means, human factor considerations, and infringement management are required to effectively deploy the model in the particular usage environment. This paper presents a survey of access control mechanisms along with their deployment issues and solutions available today. We aim to give a comprehensive big picture as well as pragmatic deployment details to guide in understanding, setting up and enforcing access control in its real world application.	access control;control system;criticality matrix;enterprise relationship management;enterprise resource planning;human factors and ergonomics;information system;requirement;software deployment;usability	Vivy Suhendra	2011		10.1007/978-3-642-27189-2_2	management science;software deployment;access control;business	Security	-49.20584468428078	56.05744753043138	185249
03f4b494d47b402d6e84decbf4e96694ad94d5ef	a risk assessment method for smartphones		Smartphones are multi-purpose ubiquitous devices, which face both, smartphone-specific and typical security threats. This paper describes a method for risk assessment that is tailored for smartphones. The method does not treat this kind of device as a single entity. Instead, it identifies smartphone assets and provides a detailed list of specific applicable threats. For threats that use application permissions as the attack vector, risk triplets are facilitated. The triplets associate assets to threats and permission combinations. Then, risk is assessed as a combination of asset impact and threat likelihood. The method utilizes user input, with respect to impact valuation, coupled with statistics for threat likelihood calculation. Finally, the paper provides a case study, which demonstrates the risk assessment method in the Android platform.	android;application programming interface;best practice;blackberry;compiler;dictionary;emoticon;knowledge society;microsoft windows;mobile security;multi-purpose viewer;quality of results;risk assessment;smartphone;symbian;threat (computer);value (ethics);vector (malware);vulnerability (computing);windows phone;ios	Marianthi Theoharidou;Alexios Mylonas;Dimitris Gritzalis	2012		10.1007/978-3-642-30436-1_36	internet privacy;world wide web;computer security	Security	-54.67116581573033	60.39152892510295	185304
0ad1e5c3f578d23c03caa8d4e5fda5803ed878b9	information flow control for event handling and the dom in web browsers	instruments;in production browser engine information flow control event handling dom web browsers lax security model javascript sensitive data leakage ifc document object model event handling mechanism browser engine formal models webkit;formal models;standards;lattices;event handling;dom;information flow control;browsers instruments security standards lattices monitoring context;ifc;browsers;online front ends;document object model;web browsers;internet;monitoring;in production browser engine;event handling mechanism;security of data internet java online front ends;lax security model;webkit;browser engine;javascript;security;security of data;context;java;sensitive data leakage	Web browsers routinely handle private information. Owing to a lax security model, browsers and JavaScript in particular, are easy targets for leaking sensitive data. Prior work has extensively studied information flow control (IFC) as a mechanism for securing browsers. However, two central aspects of web browsers - the Document Object Model (DOM) and the event handling mechanism - have so far evaded thorough scrutiny in the context of IFC. This paper advances the state-of-the-art in this regard. Based on standard specifications and the code of an actual browser engine, we build formal models of both the DOM (up to Level 3) and the event handling loop of a typical browser, enhance the models with fine-grained taints and checks for IFC, prove our enhancements sound and test our ideas through an instrumentation of WebKit, an in-production browser engine. In doing so, we observe several channels for information leak that arise due to subtleties of the event loop and its interaction with the DOM.	document object model;event (computing);event loop;information flow (information theory);javascript;non-interference (security);personally identifiable information;webkit	Vineet Rajani;Abhishek Bichhawat;Deepak Garg;Christian Hammer	2015	2015 IEEE 28th Computer Security Foundations Symposium	10.1109/CSF.2015.32	browser security;document object model;computer science;information security;database;internet privacy;programming language;world wide web;computer security	Security	-56.75565250297596	58.158104773845245	185568
5eef2c0d4ce9f7787718df1c127024815ec0fbf5	towards a tamper-resistant kernel rootkit detector	virtual machine;intrusion detection;tamper resistance;xen virtual machine;monitoring system;operating system;linux;kernel rootkit	A variety of tools and architectures have been developed to detect security violations to Operating System kernels. However, they all have fundamental flaw in the design so that they fail to discover kernel-level attack. Few hardware solutions have been proposed to address the outstanding problem, but unfortunately they are not widely accepted. This paper presents a software-based method to detect intrusion to kernel. The proposed tool named XenKIMONO, which is based on Xen Virtual Machine, is able to detect many kernel rootkits in virtual machines with small penalty to the system's performance. In contrast with the traditional approaches, XenKIMONO is isolated with the kernel being monitored, thus it can still function correctly even if the observed kernel is compromised. Moreover, XenKIMONO is flexible and easy to deploy as it absolutely does not require any modification to the monitored systems.	algorithm;flaw hypothesis methodology;kernel (operating system);operating system;rootkit;tamper resistance;virtual machine	Anh-Quynh Nguyen;Yoshiyasu Takefuji	2007		10.1145/1244002.1244070	intrusion detection system;embedded system;real-time computing;computer science;virtual machine;operating system;computer security;tamper resistance;linux kernel	OS	-54.80545964380369	57.16498371015532	185587
0bf4aadfc5f361f3002b163c7d74c3d695df5dba	a methodology and tool for investigation of artifacts left by the bittorrent client	xml format;bittorrent protocol;cybercrime;forensics investigation	The BitTorrent client application is a popular utility for sharing large files over the Internet. Sometimes, this powerful utility is used to commit cybercrimes, like sharing of illegal material or illegal sharing of legal material. In order to help forensics investigators to fight against these cybercrimes, we carried out an investigation of the artifacts left by the BitTorrent client. We proposed a methodology to locate the artifacts that indicate the BitTorrent client activity performed. Additionally, we designed and implemented a tool that searches for the evidence left by the BitTorrent client application in a local computer running Windows. The tool looks for the four files holding the evidence. The files are as follows: *.torrent, dht.dat, resume.dat, and settings.dat. The tool decodes the files, extracts important information for the forensic investigator and converts it into XML format. The results are combined into a single result file.	artifact (software development);bittorrent;client (computing);cybercrime;download;human-readable medium;internet;microsoft windows;operating system;video;xml notepad;xml editor	Algimantas Venckauskas;Vacius Jusas;Kestutis Paulikas;Jevgenijus Toldinas	2016	Symmetry	10.3390/sym8060040	bittorrent;bittorrent protocol encryption;computer science;bittorrent tracker;internet privacy;world wide web;computer security	Metrics	-54.88593522758955	60.248756008244776	185611
882791f23adbb1ea29c54937a71828e9fe468469	end-to-end java security performance enhancements for oracle sparc servers	aes;java security;rsa;specweb2005;jvm intrinsics;sha;jsse;java cryptography performance;sparc processors	In this paper we investigate the performance of cryptographic operations, when used in Java applications. We demonstrate the advantage of using built-in hardware accelerator for cryptographic operations on SPARC servers. In particular, we demonstrate the advantage of hardware cryptographic instructions invoked via AES and SHA intrinsics, implemented in the Java Virtual Machine (JVM), over the more traditional Java Native Interface (JNI) calls. For the purpose of our study, we modified the SPECweb2005 benchmark by adding modern banking requirements, and created a new workload which we call the End-to-End Java Security (EEJS) workload. Using the workload, we compare different Java Cryptographic Service Providers (CSPs) and arrive at the conclusion that hardware cryptography has significant performance advantage for Java applications. With the EEJS workload, we also identify several enhancements applicable to the Java Secure Socket Extension (JSSE).	benchmark (computing);byte;canonical account;cipher;cryptographic service provider;cryptography;encryption;hardware acceleration;intrinsic function;java development kit (jdk);java virtual machine;mathematical optimization;out of the box (feature);performance evaluation;performance tuning;rsa (cryptosystem);randomized algorithm;requirement;sparc	Luyang Wang;Pallab Bhattacharya;Yao-Min Chen;Shrinivas Joshi;James Cheng	2016		10.1145/2851553.2851577	advanced encryption standard;sha-1;java card;parallel computing;real-time computing;jsr 94;java concurrency;computer science;operating system;strictfp;embedded java;real time java;java;scala;java applet;non-blocking i/o	Security	-54.23032387183061	57.45129426636713	185696
eba838f176424d69c9642c7ef21e7bcb57e734ec	developing secure data warehouses with a uml extension	computacion informatica;multidimensional conceptual modeling;conceptual model;confidentiality;ciencias basicas y experimentales;secure data warehouses;information management;unified modeling language;data warehouses;uml extension;data warehouse;grupo a;database management system;on line analytical processing	Data Warehouses (DWs), Multidimensional (MD) Databases, and On-Line Analytical Processing Applications are used as a very powerful mechanism for discovering crucial business information. Considering the extreme importance of the information managed by these kinds of applications, it is essential to specify security measures from the early stages of the DW design in the MD modeling process, and enforce them. In the past years, some proposals for representing main MD modeling properties at the conceptual level have been stated. Nevertheless, none of these proposals considers security issues as an important element in its model, so they do not allow us to specify confidentiality constraints to be enforced by the applications that will use these MDmodels. In this paper, we will discuss the specific confidentiality problems regarding DWs as well as present an extension of the Unified Modeling Language for specifying security constraints in the conceptual MD modeling, thereby allowing us to design secure DWs. One key advantage of our approach is that we accomplish the conceptual modeling of secure DWs independently of the target platform where the DW has to be implemented, allowing the implementation of the corresponding DWs on any secure commercial database management system. Finally, we will present a case study to show how a conceptual model designed with our approach can be directly implemented on top of Oracle 10g. r 2006 Elsevier B.V. All rights reserved.	confidentiality;database;dreamwidth;molecular dynamics;online analytical processing;unified modeling language	Eduardo Fernández-Medina;Juan Trujillo;Rodolfo Villarroel;Mario Piattini	2007	Inf. Syst.	10.1016/j.is.2006.07.003	unified modeling language;confidentiality;computer science;artificial intelligence;conceptual model;operating system;data warehouse;data mining;database;computer security	DB	-54.84463855783541	48.202580644760744	185717
c06b622e09ab3ddbed909e06176821aa977d29c5	architecture support for dynamic integrity checking	computers and information processing;software;computer security computers and information processing computer architecture;trusted platform module;baseline processor architecture support dynamic integrity checking trusted platform module general purpose computer system security platform authentication tpm architectures runtime integrity checking time of check time of use malicious code execution sensitive data leak toctou attacks superscalar pipeline program dynamic execution traces cycle accurate simulator;measurement system;semiconductor device measurement;semiconductor devices;cryptography computer architecture software semiconductor device measurement system on a chip pipelines;system on a chip;chip;computer security;trusted computing;computer architecture;trusted computing computer architecture;cryptography;pipelines;information processing;integrity checking;time of use	A trusted platform module (TPM) enhances the security of general purpose computer systems by authenticating the platform at boot time. Security can often be compromised due to the presence of vulnerabilities in the trusted software that is executed on the system. Existing TPM architectures do not support runtime integrity checking and this allows attackers to exploit these vulnerabilities to modify the program after it has been verified (at time of check or TOC) but before the time of its use (at time of use or TOU) to trigger unintended program behavior, such as the execution of malicious code or the leaking of sensitive data. In this paper, we present a dynamic integrity checker (DIC) to improve security by thwarting TOCTOU attacks. The paper makes four contributions. First, we show how to integrate the integrity checker module with a superscalar pipeline. Second, we present an architecture for dynamic integrity checking by monitoring the dynamic execution traces of the program. Third, we present several optimizations to reduce performance impact without compromising the security of the system. Finally, we evaluate the proposed scheme using a cycle-accurate simulator. Results indicate that the proposed technique enhances security against the TOCTOU attacks with 8% performance overhead and 2.52% area overhead over a baseline processor.	authentication;baseline (configuration management);basic block;best, worst and average case;booting;cpu cache;compile time;compiler;computer architecture simulator;computer data storage;digital differential analyzer;file verification;malware;mathematical optimization;optical disc authoring;out-of-order execution;overhead (computing);superscalar processor;terms of service;time of check to time of use;tracing (software);trusted platform module;vulnerability (computing)	Arun K. Kanuparthi;Mohamed Zahran;Ramesh Karri	2012	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2011.2166960	chip;system on a chip;embedded system;real-time computing;information processing;computer science;cryptography;trusted platform module;computer security	Security	-54.37482540479248	55.5663269363692	185825
2ccf60b94f4d0426157526c3c7f94e4d0f1eed99	social networking sites security: quo vadis	social networking sites security;defense strategies;electronic mail;encryption;information security;web services social networking sites security information security defense strategies attack vectors facebook;web service;attack vectors;web services;social networking online;facebook;web services security of data social networking online;facebook privacy encryption electronic mail;security;survey social networking sites security;social networking sites;survey;security of data;privacy	Social networking sites have been studied extensively within the past five years, especially in the area of information security. Within this paper we discuss these emerging web services both regarding possible attack vectors as well as defense strategies. Our results suggest that a gap between attack and defense strategies exists. Furthermore we found that research focuses mainly on Facebook, while scant attention is paid to other social networking sites.	information security;web service	Markus Huber;Martin Mulazzani;Edgar R. Weippl	2010	2010 IEEE Second International Conference on Social Computing	10.1109/SocialCom.2010.166	web service;computer science;information security;internet privacy;world wide web;computer security	DB	-48.65553872843263	59.52858327020205	185832
60f5621585225ee0f766e845a807d9e7615bcd7e	applications of the oriented permission role-based access control model	information security;application software;authorisation;role based access control;separation of duty;computing;computer applications;oriented permission role based access control model;permission;access control;ad hoc oriented permission role based access control model;ad hoc;context modeling;permission access control information security computer applications application software context modeling	Role-based access control and role hierarchies have been the subject of considerable research in recent years. In this paper, we consider three useful applications of a new role-based access control model that contains a novel approach to permissions and permission inheritance: one is to illustrate that the new model provides a simpler and more natural way to implement BLP model using role-based techniques; a second application is to make it possible to define separation of duty constraints on two roles that have a common senior role and for a user to be assigned to or activate the senior role; finally, we describe how a single hierarchy in the new model can support the distinction between role activation and permission usage. In short, the oriented permission model provides ways of implementing a number of useful features that have previously required ad hoc and inelegant solutions.	append;hoc (programming language);java;role hierarchy;role-based access control;xacml	Liang Chen;Jason Crampton	2007	2007 IEEE International Performance, Computing, and Communications Conference	10.1109/PCCC.2007.358918	computing;application software;discretionary access control;computer science;information security;access control;role-based access control;internet privacy;computer applications;world wide web;computer security;computer network	SE	-49.46073357159329	50.66832838598938	185965
93b1943d5a8e149c0c4b0fd8dc116d57ab9f3cdd	a multi-level ddos mitigation framework for the industrial internet of things		The Industrial Internet of Things is growing fast. But the rapid growth of IIoT devices raises a number of security concerns, because the IIoT device is weak in defending against malware, and the method of managing a large number of IIoT devices is awkward and inconvenient. This article proposes a multi-level DDoS mitigation framework (MLDMF) to defend against DDoS attacks for IIoT, which includes the edge computing level, fog computing level, and cloud computing level. Software defined networking is used to manage a large number of IIoT devices and to mitigate DDoS attacks in IIoT. Experimental results show the effectiveness of the proposed framework.	cloud computing;ddos mitigation;denial-of-service attack;edge computing;fog computing;internet of things;malware;software-defined networking	Qiao Yan;Wenyao Huang;Xupeng Luo;Qingxiang Gong;Fei Richard Yu	2018	IEEE Communications Magazine	10.1109/MCOM.2018.1700621	computer network;cloud computing;industrial internet;computer science;software-defined networking;ddos mitigation;malware;edge computing;denial-of-service attack	Metrics	-50.75842631461442	58.57958638321905	186322
45c6edf2756fce231f1b4631610c76a8781fa61e	on quantitative dynamic data flow tracking	usage control;information flow;runtime monitoring	We present a non-probabilistic model for dynamic quantitative data flow tracking. Estimations of the amount of data stored in a particular representation at runtime - a file, a window, a network packet - enable the adoption of fine-grained policies which authorize or prohibit partial leaks of data. We prove the correctness of the estimations, provide an implementation that we evaluate w.r.t. precision and performance, and analyze one instantiation at the OS level.	correctness (computer science);dataflow;dynamic data;network packet;operating system;run time (program lifecycle phase);statistical model;universal instantiation	Enrico Lovat;Johan Oudinet;Alexander Pretschner	2014		10.1145/2557547.2557551	real-time computing;computer science;data mining;database	OS	-54.11409373123093	52.91666322877874	186352
2197d6150f6014e19c6642046b908fe1862611f4	virtual machine introspection: observation or interference?	xen vm monitoring system;virtual machine;virtual machine monitor;intrusion monitoring;attack analysis virtual machine monitoring virtual machine introspection intrusion monitoring;virtual machine introspection technique;virtual machine monitoring;system monitoring;attack analysis;virtual machines system monitoring;monitoring system;virtual machines;xen vm monitoring system virtual machine introspection technique;virtual machining interference virtual manufacturing hardware virtual machine monitors condition monitoring operating systems security computerized monitoring switches;virtual machine introspection	As virtualization becomes increasingly mainstream, virtual machine introspection techniques and tools are evolving to monitor VM behavior. A survey of existing approaches highlights key requirements, which are addressed by a new tool suite for the Xen VM monitoring system.	interference (communication);introspection;requirement;virtual machine	Kara L. Nance;Matt Bishop;Brian Hay	2008	IEEE Security & Privacy	10.1109/MSP.2008.134	embedded system;full virtualization;real-time computing;temporal isolation among virtual machines;computer science;virtual machine;operating system;hardware virtualization	Security	-54.43107290251875	56.98198451833647	186423
50974d079bf35a368db002bcdac6c21b62015992	open-source applications of tcpa hardware	bob;application development;certification;openca certification authority open source application tcpa hardware alice trust computation ubiquitous computing linux apache ssl web server;certificate authority;authorisation;trusted computing;internet;open source software hardware application software pervasive computing linux web server certification computer security software standards protocols;authorisation open systems internet ubiquitous computing linux certification;ubiquitous computing;linux;open systems;open source	How can Alice trust computation occurring at Bob's computer? Since it exists and is becoming ubiquitous, the current-generation TCPA/TCG hardware might enable a solution. When we started investigating this technology, the specification of the TCG software stack was not publicly available, and an implementation is still not; so, we designed and built an open-source platform based on Linux and commercially available TCPA/TCG hardware which would allow us to address the problem of trusting computation. Within the limits of TCPA/TCG hardware security, our solution balances what Alice needs to do to make trust judgments against what Bob needs to do to keep his system running. Furthermore, we describe how we use our platform to harden three sample open-source applications: Apache SSL Web servers, OpenCA certification authorities, and (with SELinux) compartmented attestation to balance privacy with DRM. To our knowledge, our project remains the only open-source TCPA/TCG platform in existence, and is also enabling trusted computing applications developed by our user community (enforcer.sourceforge.net reports over 1100 sourcecode downloads so far).	alice and bob;certificate authority;computation;digital rights management;linux;open world;open-source software;openca;public-key cryptography;replay attack;selinux;sourceforge;time of check to time of use;transport layer security;trust (emotion);trusted computing;trusted platform module;virtual community;vulnerability (computing);web application;x.509	John Marchesini;Sean W. Smith;Omen Wild;Joshua Stabiner;Alex Barsamian	2004	20th Annual Computer Security Applications Conference	10.1109/CSAC.2004.25	the internet;computer science;operating system;authorization;open system;certification;trustworthy computing;rapid application development;world wide web;computer security;certificate authority;ubiquitous computing;linux kernel	Security	-52.417040093164026	58.49806281810373	186736
d94eacd0871062a07c116accfe90d9c82705bfc2	mining mutation testing simulation traces for security and testbench debugging		Unspecified design functionality can be modified by Hardware Trojans to leak information. Existing methods capable of detecting these Trojans require that unspecified functionality already be characterized, and suggest a manual ad-hoc process to enumerate “don't care” conditions potentially containing security vulnerabilities. Prior work has shown the potential of mutation testing to uncover testbench holes and highlight unspecified functionality, but requires tedious manual analysis of undetected faults to gain useful insight. This work provides the missing link required to fully automate characterization of unspecified functionality and can formally prove the absence of Trojans. Our approach is to mine simulation traces generated during mutation testing to produce assertions characterizing verification holes or unspecified functionality. These assertions can be fed directly to Trojan detection methods making securing unspecified functionality a completely automated process. Our trace mining technique is able to identify unspecified Wishbone bus functionality in a Trojan-free UART core and verify the functionality is benign, while flagging the same functionality in a Trojan-infected version of the design.	assertion (software development);debugging;don't-care term;enumerated type;hoc (programming language);list of code lyoko episodes;malware;mining simulator;mutation testing;sensor;simulation;test bench;tracing (software);trojan horse (computing);vulnerability (computing);wishbone (computer bus)	Nicole Fern;Kwang-Ting Cheng	2017	2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1109/ICCAD.2017.8203847	trojan;computer science;real-time computing;debugging;universal asynchronous receiver/transmitter;hardware trojan;mutation testing;wishbone;countermeasure	EDA	-58.41083927942963	57.73240328088375	186881
5e74a3c557f4f61952e47813ef20a24db22a8016	rpids: raspberry pi ids — a fruitful intrusion detection system for iot	raspberry pi;iot;intrusion detection;raspberry pi intrusion detection iot snort;snort;distributed system rpids raspberry pi ids iot internet of things ip address security privacy trustworthiness intrusion detection architecture commodity device commodity single board computers snort open source intrusion detection system resource constrained devices;security of data internet of things microcomputers	Our technology keeps advancing towards a future where everything is connected together. The Internet of Things (IoT) goal is to make every device accessible from the Internet. Even the most common electrical appliances, such as ovens, light bulbs, will have their own IP address,, will be reachable remotely. While this enhanced connectivity will definitely improve our quality of life, it also raises serious security, privacy, trustworthiness questions, the resource constrained nature of IoT entities makes traditional security techniques impractical. In this paper, we propose an intrusion detection architecture for the IoT. We discuss the feasibility of employing a commodity device as the core component of the architecture. In particular, we evaluated the performance of the Raspberry Pi, one of the most used commodity single-board computers, while running Snort, a widely known, open source Intrusion Detection System (IDS). Our experiments show that our proposed architecture based on resource constrained devices, such as the Raspberry Pi, can effectively serve as IDS in a distributed system such as IoT.	bluetooth;central processing unit;distributed computing;entity;experiment;home automation;internet of things;intrusion detection system;load balancing (computing);multi-core processor;network traffic control;open-source software;privacy;random-access memory;raspberry pi 3 model b (latest version);single-board computer;snort;suricata;trust (emotion)	Alessandro Sforzin;Félix Gómez Mármol;Mauro Conti;Jens-Matthias Bohli	2016	2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)	10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0080	intrusion detection system;embedded system;human–computer interaction;computer science;operating system;computer security;internet of things;intrusion prevention system;computer network	Security	-51.37880831155381	57.64013080814898	187802
17302d126e8f6b06101f66c39f883b2f337c3490	a privacy-preserving defense mechanism against request forgery attacks	authorisation;deref prototype privacy preserving defense mechanism request forgery attack web application attacker triggers client browser target web site fine grained access control client authentication privacy preserving checking two phase checking hashing blind signature privacy protection proof of concept prototype firefox wordpress 2 0;client server systems;web security;browsers forgery access control authentication privacy prototypes protocols;privacy preservation;privacy protection;implementation and experimentation;proof of concept;online front ends;data privacy;implementation and experimentation request forgery web security;cryptography;web sites;request forgery;defense mechanism;blind signature;access control;web sites authorisation client server systems cryptography data privacy online front ends	One top vulnerability in today's web applications is request forgery, in which an attacker triggers an unintentional request from a client browser to a target website and exploits the client's privileges on the website. To defend against a general class of cross-site and same-site request forgery attacks, we propose DeRef, a practical defense mechanism that allows a website to apply fine-grained access control on the scopes within which the client's authentication credentials can be embedded in requests. One key feature of DeRef is to enable privacy-preserving checking, such that the website does not know where the browser initiates requests, while the browser cannot infer the scopes being configured by the website. DeRef achieves this by using two-phase checking, which leverages hashing and blind signature to make a trade-off between performance and privacy protection. We implement a proof-of-concept prototype of DeRef on Fire Fox and Word Press 2.0. We also evaluate our DeRef prototype and justify its performance overhead in various deployment scenarios.	access control;authentication;blind signature;credential;cross-site cooking;cross-site request forgery;cryptographic hash function;embedded system;overhead (computing);privacy;prototype;real life;software deployment;two-phase commit protocol;web application	Ben S. Y. Fung;Patrick P. C. Lee	2011	2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2011.10	computer science;internet privacy;cross-site request forgery;world wide web;computer security	Security	-54.68361768435022	59.806743637512724	187955
a52892f231c57674668157a8253371b41e0a1df6	reverse proxy framework using sanitization technique for intrusion prevention in database	internet;sql;database management systems;query processing;security of data;internet;sql code;sql injection attacker;sql query;sql statement;url;web application;web based attacks;application layer attack;confidential information;cross site scripting attack;data redirector program;data security;database attack;database security;illegal approaches;intrusion prevention;proxy server;real-time transaction;reverse proxy framework;sanitization technique;transaction services;unauthorized approaches;cross site scripting attack;data sanitization;database security;sql attack;sql injection;security threats	With the increasing importance of the internet in our day-to-day life, data security in web application has become very crucial. Ever increasing online and real time transaction services have led to manifold rise in the problems associated with the database security. Attacker uses illegal and unauthorized approaches to hijack the confidential information like username, password and other vital details. Hence the real-time transaction requires security against web based attacks. SQL injection and cross site scripting attack are the most common application layer attack. The SQL injection attacker pass SQL statement through a web application’s input fields, URL or hidden parameters and get access to the database or update it. The attacker take a benefit from user provided data in such a way that the user’s input is handled as a SQL code. Using this vulnerability an attacker can execute SQL commands directly on the database. SQL injection attacks are most serious threats which take user’s input and integrate it into SQL query. Reverse Proxy is a technique which is used to sanitize the users’ inputs that may transform into a database attack. In this technique a data redirector program redirects the user’s input to the proxy server before it is sent to the application server. At the proxy server, data cleaning algorithm is triggered using a sanitizing application. In this framework we include detection and sanitization of the tainted information being sent to the database and innovate a new prototype.	algorithm;application server;authorization;confidentiality;cross-site scripting;data security;database security;denial-of-service attack;internet;intrusion detection system;password;plasma cleaning;prototype;proxy server;real-time web;reverse proxy;sql injection;sanitization (classified information);select (sql);sensor;server (computing);url redirection;user (computing);web application;web server	Vrushali Randhe;Archana Chougule;Debajyoti Mukhopadhyay	2013	CoRR		data transformation services;business intelligence markup language;sql injection;computer science;query by example;user-defined function;data mining;autocommit;database;internet privacy;world wide web;computer security	Security	-57.35350144656669	59.06952870264314	188185
143d54f60c34415e09b1f0bd7fd2fef66f89e0ce	keynote speaker 3: can the cloud be secured…?	application program interfaces;cloud computing;fraud;security of data;user interfaces;api;accountability;availability;cloud security;cloud services infrastructures;confidentiality;fraud detection capabilities;integrity;interfaces	Summary form only given. The criminals continue to leverage new technologies for financial and non-financial benefits by avoiding detection and improving the effectiveness of their activities. The Cloud services infrastructures are actively being targeted because of the limitation in the fraud detection capabilities. Although, some Cloud providers strive to ensure security is well integrated into their service models, however, it is critical for consumers to understand the security implications associated with the usage, management, orchestration and monitoring of Cloud services. Reliance on a weak set of interfaces and APIs exposes organizations to a variety of security issues related to confidentiality, integrity, availability and accountability. However, this raises a plethora of questions concerning Cloud security.	cloud computing security;confidentiality;platform as a service;web service	Charles A. Shoniregun	2013	International Conference on Information Society (i-Society 2013)	10.1109/WorldCIS.2015.7359401	cloud computing security;engineering;internet privacy;world wide web;computer security	SE	-49.87714282940022	57.99595212706618	188198
1bea679253f58e86e41fdf1599911a2eebd1247c	towards automated penetration testing for cloud applications		The development of cloud applications raises several security concerns due to the lack of control over involved resources. Security testing is fundamental to identify the existing security issues and is particularly powerful when carried out by means of penetration testing techniques. Unfortunately, penetration testing requires a deep knowledge of the possible attacks and of the available hacking tools and is very energy demanding. In this paper, we present a methodology that allows to easily carry out a coarse-grained security evaluation of a cloud application by automating the set-up and execution of penetration tests. The methodology relies on the knowledge of the application architecture and on the availability of a catalogue including security-related data collected from multiple sources and properly correlated.	applications architecture;cloud computing;exploit (computer security);penetration test;security testing;semantics (computer science);software as a service;system under test	Valentina Casola;Alessandra De Benedictis;Massimiliano Rak;Umberto Villano	2018	2018 IEEE 27th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)	10.1109/WETICE.2018.00012	hacker;penetration test;computer engineering;distributed computing;computer science;security testing;applications architecture;penetration (firestop);cloud computing	SE	-50.98131406244554	56.37312814680953	188253
62ec9bcb707b3bbe4583dde1c60c335a617e6a0a	towards a formalised representation for the technical enforcement of privacy level agreements	interoperability formalised representation technical enforcement privacy level agreements cloud providers data protection practices ontology based model software tools pla ontology high level policies operational policies policy enforcement tools;policy enforcement;assurance;privacy policy;programmable logic arrays ontologies engines data models data privacy privacy monitoring;software tools data protection ontologies artificial intelligence open systems;privacy level agreement	Privacy Level Agreements (PLAs) are likely to be increasingly adopted as a standardized way for cloud providers to describe their data protection practices. In this paper we propose an ontology-based model to represent the information disclosed in the agreement to turn it into a means that allows software tools to use and further process that information for different purposes, including automated service offering discovery and comparison. A specific usage of the PLA ontology is presented, showing how to link high level policies to operational policies that are then enforced and monitored. Through this established link, cloud users gain greater assurance that what is expressed in such agreements is actually being met, and thereby can take this information into account when choosing cloud service providers. Furthermore, the created link can be used to enable policy enforcement tools to add semantics to the evidence they produce; this mainly takes the form of logs that are associated with the specific policy of which execution they provide evidence. Furthermore, the use of the ontology model allows a means of enabling interoperability among tools that are in charge of the enforcement and monitoring of possible violations to the terms of the agreement.	cloud computing;end-user computing;exploit (computer security);high-level programming language;information privacy;interoperability;modeling language;programmable logic array;software system	Michela D'Errico;Siani Pearson	2015	2015 IEEE International Conference on Cloud Engineering	10.1109/IC2E.2015.72	privacy software;information privacy;privacy by design;computer science;data mining;database;computer security	SE	-51.26809166411415	50.39506851832576	188399
485769b6e94cf9ef83ce2157e253e03f94b165d9	tcc (tracer-carrying code): a hash-based pinpointable traceability tool using copy&paste		In software development, it is crucially important to effectively capture, record and maintain traceability links in a lightweight way. For example, we often would like to know “what documents (rationale) a programmer referred to, to write this code fragment”, which is supposed to be solved by the traceability links. Most of previous work are retrospective approaches based on information retrieval techniques, but they are likely to generate many false positive traceability links; i.e., their accuracy is low. Unlike retrospective approaches, this paper proposes a novel lightweight prospective approach, which we call TCC (tracer-carrying code). TCC uses a hash value as a tracer (global ID), widely used in distributed version control systems like Git. TCC automatically embeds a TCC tracer into source code as a side-effect of users’ copy&paste operation, so users have no need to explicitly handle tracers (e.g., users have no need to copy&pastes URLs). TCC also caches the referred original text into Git repository. Thus, users can always view the original text later by simply clicking the tracer, even after its URL or file path is changed, or the original text is modified or removed. To show the feasibility of our TCC approach, we developed several TCC prototype systems for Emacs editor, Google Chrome browser, Chrome PDF viewer, and macOS system clipboard. We applied them to the development of a simple iPhone application, which shows a good result; our TCC is quite effective and useful to establish and maintain pinpointable traceability links in a lightweight way. Also several important findings are obtained.	clipboard (computing);control system;design rationale;distributed version control;eclipse;google chrome;hash function;information retrieval;integrated development environment;programmer;prospective search;prototype;requirements traceability;software development;theory of cryptography conference;xcode;emacs	Katsuhiko Gondow;Yoshitaka Arahori;Koji Yamamoto;Masahiro Fukuyori;Ryuichi Umekawa	2018		10.5220/0006837102550266	data mining;traceability;database;computer science;hash function	SE	-55.30426422557645	59.12734112678091	188702
69f031e05cdda7014c07f721523483bc7b665c99	on security issues in embedded systems: challenges and solutions	information security;embedded system;computer security;embedded systems;information and computer security	Ensuring security in embedded systems translates into several design challenges, imposed by the unique features of these systems. These features make the integration of conventional security mechanisms impractical, and require a better understanding of the whole security problem. This paper provides a unified view on security in embedded systems, by introducing first the implied design and architectural challenges. It then surveys and discusses the currently proposed security solutions that address these challenges, drawing from both current practices and emerging research, and identifies some open research problems that represent the most interesting areas of contribution.	care-of address;embedded system;endeavour (supercomputer);mathematical optimization;open research;operating environment;program optimization;requirement;software development process;systems development life cycle;threat model;usability	Lyes Khelladi;Yacine Challal;Abdelmadjid Bouabdallah;Nadjib Badache	2008	IJICS	10.1504/IJICS.2008.018515	software security assurance;computer security model;cloud computing security;security through obscurity;security information and event management;security engineering;computer science;information security;security service;distributed computing;internet privacy;security testing;computer security	EDA	-50.91016783561768	56.20189687565089	189113
edb5fd6c0d52569d5f31f6d7ac411d813f6d7a11	an argument for the role-based access control model	graph transformation systems;specification;role based access control;methodology	ly, traditional mandatory access controls provide strong guarantees for the separation of information based on its confidentiality or integrity characteristics. However, these models also require that many important system functions be placed into trusted subjects that operate outside of the constraints of the policy model. Hence, the security of the entire system typically devolves to the security of the trusted subjects, and these systems frequently require many trusted subjects for normal operation. Furthermore, mechanisms for limiting these trusted subjects to least privilege are typically coarse-grained and must be provided separately from the ordinary mandatory access control mechanism. A different form of mandatory access control known as Type Enforcement [3] (TE) offers several advantages over the traditional model. Security labels are not required to form a partial order, so intransitive relationships can be defined to support protected subsystems and assured pipelines. The security policy logic is defined through a set of separate tables, so the security policy can be easily customized. Controls over program execution and changes in access rights (domains) are explicitly defined in the TE tables, so no separate mechanism is required for this purpose. No trusted subjects that can operate outside of the constraints of the TE tables are needed, since the tables can be configured to grant exactly those access rights that are required for privileged subjects. Users and individual programs can be easily limited to least privilege through the definition of domains and domain transitions. However, TE also has its limitations. Since the security policy logic is defined through tables and there are no implicit relationships among labels, it would be cumbersome to express a complex BLP or Biba lattice using TE, and it is more difficult to verify that TE tables provide the same guarantees for the separation of information. TE also does not directly address dynamic security policy requirements, which are often needed in real-world environments. Since no single model is likely to meet all user's needs, operating systems must be flexible in their support for security policies. Policy flexibility requires a mandatory access control architecture that provides clean separation of policy from enforcement and well-defined interfaces for obtaining policy decisions. In order to support dynamic security policy requirements, this architecture must provide a mechanism for supporting policy changes and in particular for revoking permissions, including permissions that are Copyright is held by the author/owner(s). SACMAT’01, May 3-4, 2001, Chantilly, Virginia, USA ACM 1-58113-350-2/01/00005.	confidentiality;mandatory access control;pipeline (computing);principle of least privilege;privilege (computing);requirement;role-based access control;table (database);trusted operating system;type enforcement	David F. Ferraiolo	2001		10.1145/373256.378405	computer science;theoretical computer science;methodology;role-based access control;database;computer security;specification	Security	-52.15693735519733	53.96038728170725	189140
4d4231ad076246b19b9946f24dc72b7fc134b9ab	hidden safety requirements in large-scale systems	management of computing and information systems;public policy issues;computers and society;security and protection;computers in other systems 1. three accidents;public policy	To avoid hidden safety problems in future large scale systems, we must be able to identify the crucial assumptions underlying the development of their components and to enunciate straightforward rules for safe component interconnection. Keyword Codes: K.4.1; K.6.5; J.7	interconnection	Carl E. Landwehr	1994			interconnection;information system;public policy;network security policy;business;data mining	OS	-51.2554774942666	52.09186691543259	190265
5d1c21e36d3f6d81c873bdea0960a749fea714f4	formalisation and implementation of the xacml access control mechanism	xacml;case tools;pbac;formal semantics;qa75 electronic computers computer science	We propose a formal account of XACML, an OASIS standard adhering to the Policy Based Access Control model for the specification and enforcement of access control policies. To clarify all ambiguous and intricate aspects of XACML, we provide it with a more manageable alternative syntax and with a solid semantic ground. This lays the basis for developing tools and methodologies which allow software engineers to easily and precisely regulate access to resources using policies. To demonstrate feasibility and effectiveness of our approach, we provide a software tool, supporting the specification and evaluation of policies and access requests, whose implementation fully relies on our formal development.	access control;formal methods;programming tool;software engineer;xacml	Massimiliano Masi;Rosario Pugliese;Francesco Tiezzi	2012		10.1007/978-3-642-28166-2_7	computer science;data mining;database;computer security	SE	-51.838554856446784	51.31955066406446	190346
6fe627a24c5939bae46f4202ff2a578c6d9fc1c8	a model implementing certified reputation and its application to tripadvisor	trusted computing certification travel industry;tripadvisor trust models trust managements;trust managements;trust models;tripadvisor;trust models certified reputation tripadvisor reputation model backward compatibility;social network services context google html proposals reliability theory	Many real-life reputation models suffer from classical drawbacks making the systems where they are used vulnerable to users' misbehavior. TripAdvisor is a good example of this problem. Indeed, despite its popularity, the weakness of its reputation model is resulting in loss of credibility and growth of legal disputes. In this paper, we propose a reputation model abstractly considering service providers, users and feedbacks, and implementing the theoretical notion of certified reputation to concretely define a strategy to normalize feedback scores towards reliable values. We apply the model to the case of TripAdvisor, by proposing a solution to improve its dependability not increasing invasiveness nor reducing usability of the system. Moreover, it fully guarantees backward compatibility. In the context of project activities, we are in progress to fully implement the system and validate it on real-life data.	backward compatibility;dependability;human factors and ergonomics;real life;reputation system;scientific literature;trust (emotion);usability;vulnerability (computing)	Francesco Buccafurri;Gianluca Lax;Serena Nicolazzo;Antonino Nocera	2015	2015 10th International Conference on Availability, Reliability and Security	10.1109/ARES.2015.26	public relations;business;internet privacy;computer security	SE	-49.022669077383696	58.791814206971175	190847
f0131c30c53aff8671602fc4d235d66c3de4e59d	using policy enforcement graphs in a separation-based high assurance architecture	system security managers;graph theory;separation based high assurance architecture design;policy enforcement;security safety critical multienclave system;formal specification;information security data security multilevel systems computer security communication system security access control safety guidelines availability authentication;security policy specification;information access;computer systems;system security;security safety critical multienclave system policy enforcement graphs separation based high assurance architecture design computer systems security policy specification system security managers procedural engineering approach inter enclave multi policy paradigm information access multiple independent levels of security and safety;multiple independent levels of security and safety;formal verification;procedural engineering approach;system design;policy enforcement graphs;security of data formal specification formal verification graph theory;inter enclave multi policy paradigm;security policy;security of data	As the use of computer systems becomes more commonly employed, managing security becomes more complex. One fundamental key to effective enforcement of security standards is the support of security policies. We present a novel graph-based approach to the specification of security policies and verification of designs that enforce the policies. This methodology provides system security managers with a procedural engineering approach that will ensure that security policy enforcement is addressed during the process of refining of the high-level system design down to a low-level implementation. We present an inter-enclave multi-policy paradigm using Policy Enforcement Graphs for information access of the Multiple Independent Levels of Security and Safety (MILS) approach to high assurance system design for security-and safety-critical multi-enclave systems. Our methodology is structured and allows for policy evolution development.	authorization;high- and low-level;information access;multiple independent levels of security;programming paradigm;security engineering;systems design	Luay A. Wahsheh;Jim Alves-Foss	2007	2007 IEEE International Conference on Information Reuse and Integration	10.1109/IRI.2007.4296618	software security assurance;computer security model;standard of good practice;cloud computing security;security through obscurity;security information and event management;security engineering;security convergence;covert channel;formal verification;asset;computer science;security policy;information security;graph theory;information security standards;formal specification;security service;programming language;security testing;network security policy;computer security;systems design	EDA	-53.63524481331504	50.10737622105104	190888
76ae548e50119751abadc241e64656092d77795f	security assurance guidance for third-party ip	threat model;security assurance;security development lifecycle;commercial off-the-shelf (cots);ip development	System OEMs are increasingly adopting the motto “Trust but verify” when it comes to their supply chains. After several public incidents in which trusted vendors unknowingly provided vulnerable components, OEMs are requesting evidence of security assurance before integrating components into their products. It can be problematic for semiconductor vendors to provide such evidence since their products often contain 3 rd party components that are typically treated as black boxes. Moreover, asking 3 rd party vendors to provide such evidence for their components is equally problematic due to the many integration unknowns and a lack of applicable literature on security assurance for standalone technologies. We address these issues by defining a security process and relationship between semiconductor vendors and trusted 3 rd party component providers and a practical methodology to produce standardized quality security assurance evidence. We provide example applications of the methodology using several open source components.		Brent Sherman;Mike Borza;Brian Rosenberg;Charles Qi	2017	J. Hardware and Systems Security	10.1007/s41635-017-0002-5	computer security;computer network	Security	-51.35622334238962	59.205374160111504	190975
3f882980527f6bd386d5321b7207783f9940515a	adaptive exception monitoring agents for management by exceptions	financial management;management strategy;monitoring system;information processing;database management system	Management by exceptions (MBE) is an effective management strategy in many domains. It suggests that managers focus on important jobs (e.g., planning and decision-making) without being involved in the tedious monitoring of exceptions (e.g., a critical item whose current status violates some regulations). Once an exception is detected, the managers are notified to respond to the exception promptly. Therefore, exception monitoring is the key to realize the idea of MBE. An exception monitoring system should detect exceptions in a timely manner for the managers. It should also control the extra loading it incurs to related information servers (e.g., database management systems) and the Intranet, which are fundamental backbones for information processing in businesses. In this paper, a multiagent paradigm Adaptive Agents for Management by Exceptions (AAMBE) is proposed for exception monitoring. The agents adapt to the environment by learning to work together to achieve timely detection of exceptions. An experi...	exception handling	Rey-Long Liu;Meng-Jung Shih;Yu-Fen Kao	2001	Applied Artificial Intelligence	10.1080/08839510151087338	information processing;computer science;knowledge management;data mining;computer security	AI	-49.889730503989135	52.59901632559239	191182
0fbcf21ef30c5b29cf384a22d322c3f252d58b99	management of heterogeneous security access control configuration using an ontology engineering approach	best practice;security requirements;ontology engineering;access control;security policy;configuration management;ontology	Management of heterogeneous enterprise security mechanisms is complex and requires a security administrator to have deep knowledge of each security mechanism's configuration. Effective configuration may be hampered by poor understanding and/or management of the enterprise security policy which, in turn, may unnecessarily expose the enterprise to known threats. This paper argues that knowledge about detailed security configuration, enterprise-level security requirements including best practice recommendations and their relationships can be modelled, queried and reasoned over within an ontology-based framework. A threat-based approach is taken to structure this knowledge. The management of XMPP application-level and firewall-level access control configuration is investigated.	access control;best practice;firewall (computing);ontology engineering;requirement;threat (computer)	William M. Fitzgerald;Simon N. Foley	2010		10.1145/1866898.1866903	software security assurance;computer security model;standard of good practice;cloud computing security;itil security management;countermeasure;security through obscurity;sherwood applied business security architecture;security information and event management;security engineering;security convergence;asset;systems engineering;knowledge management;information security;security service;business;security testing;network security policy;computer security;enterprise information security architecture	Security	-51.752186492562544	52.28696568414785	191355
aef70c6c305eec9df96e2b58a593bd60ba66c16a	how formal analysis and verification add security to blockchain-based systems		Blockchain is an integrated technology to ensure keeping record and process transactions with decentralized manner. It is thought as the foundation of future decentralized ecosystem, and collects much attention. However, the maturity of this technology including security of the fundamental protocol and its applications is not enough, thus we need more research on the security evaluation and verification of Blockchain technology This tutorial explains the current status of the security of this technology, its security layers and possibility of application of formal analysis and verification.	bitcoin;capability maturity model;ecosystem	Shin'ichiro Matsuo	2017	2017 Formal Methods in Computer Aided Design (FMCAD)	10.23919/FMCAD.2017.8102228	systems engineering;theoretical computer science;computer science;formal methods;blockchain;domain-specific language;formal verification;computer security	Security	-56.166331283078215	50.38132001134335	191497
c22dc96795d8ba12e8adfbe96c8f294e044eb009	security specifications	specification languages;security of data	This paper gives a security and specification-oriented semantics for systems. The semantic model is derived from that for the trace model of Hoare’s Communicating Sequential Processes[Ho85] and is used to define various security concepts, such as multi-level secure system, trusted users and integrity. We indicate how implementations of secure systems may be derived from their specifications.	communicating sequential processes;computer security;emoticon;hoare logic;jim woodcock;multilevel security;recursion	Jeremy L. Jacob	1988		10.1109/SECPRI.1988.8094	computer security model;covert channel;computer science;database;security service;programming language;security testing;computer security	Security	-52.75259778201507	51.254192924745745	191515
09182bfa80ad7323aed99184c83d94630c4f2851	approaching secure industrial control systems	cost evaluation technique;security assessment scheme;passenger tyres secure industrial control systems security programme security cost estimation security assessment scheme cost evaluation technique information security assurance activities polish manufacturer commercial tyres;security of data costing industrial control production engineering computing production management;polish manufacturer;security cost estimation;information security assurance activities;secure industrial control systems;security programme;commercial tyres;passenger tyres	The paper presents a systematic approach to secure industrial control systems based on establishing a business case followed by the development of a security program. To support these two fundamental activities we propose a new method for security cost estimation and a security assessment scheme. In the paper we explain the cost evaluation technique and illustrate it with a case study concerning the assessment of the cost of information security assurance activities in a division of a Polish manufacturer of passenger and commercial tires. We further present the steps of our security assessment scheme and demonstrate how they integrate with the overall approach to protecting industrial control systems.	authorization;computer security;control system;horner's method;iso/iec 27001:2013;information security;nist sp 800-90a;security controls;security management;system administrator	Rafal Leszczyna	2015	IET Information Security	10.1049/iet-ifs.2013.0159	software security assurance;control system security;standard of good practice;security management;security information and event management;security engineering;information security;security service;computer security;information security management	Security	-56.03323793609972	48.64328378499725	191880
2279de37014ec7e6364261588b988c502c515bc2	quantitative analysis of information leakage in service-oriented architecture-based web services		Purpose#R##N##R##N##R##N##R##N##R##N#Any computing architecture cannot be designed with complete confidentiality. As a result, at any point, it may leak the information. So, it is important to decide leakage threshold in any computing architecture. To prevent leakage more than the predefined threshold, quantitative analysis is helpful. This paper aims to provide a method to quantify information leakage in service-oriented architecture (SOA)-based Web services.#R##N##R##N##R##N##R##N##R##N#Design/methodology/approach#R##N##R##N##R##N##R##N##R##N#To visualize the dynamic binding of SOA components, first, the orchestration of components is modeled. The modeling helps to information-theoretically quantify information leakage in SOA-based Web services. Then, the paper considers the non-interference policy in a global way to quantify information leakage. It considers not only variables which interfere with security sensitive content but also other architectural parameters to quantify leakage in Web services. To illustrate the attacker’s ability, a strong threat model has been proposed in the paper.#R##N##R##N##R##N##R##N##R##N#Findings#R##N##R##N##R##N##R##N##R##N#The paper finds that information leakage can be quantified in SOA-based Web services by considering parameters that interfere with security sensitive content and information theory. A hypothetical case study scenario of flight ticket booking Web services has been considered in the present paper in which leakage of 18.89 per cent information is calculated.#R##N##R##N##R##N##R##N##R##N#Originality/value#R##N##R##N##R##N##R##N##R##N#The paper shows that it is practically possible to quantify information leakage in SOA-based Web services. While modeling the SOA-based Web services, it will be of help to architects to identify parameters which may cause the leakage of secret contents.	information leakage;service-oriented architecture;service-oriented device architecture;spectral leakage;web service	Kushal Anjaria;Arun Mishra	2017	Kybernetes	10.1108/K-07-2016-0178	internet privacy;world wide web;computer security	Web+IR	-54.4403168991825	51.419611875132	192033
e47aab2ba4b974d7b42a557dfe2c299cbe5e6a05	simulating a proposed information delivery system	databases;analytical models;delivery system;application software;information retrieval;design optimization;costs hardware data security information retrieval application software databases throughput analytical models delay design optimization;hardware design;simulation analysis;technical report;throughput;hardware;data security	This paper describes the results of a simulation analysis of hardware designs for a proposed data delivery system. The system is to serve clients of a large accounting firm. Once the required hardware components were identified, and their system parameters and response times estimated, the design of such a system required selection of components in a way to optimize specific performance characteristics. Simulation was used to understand the performance of the system, and to help with decisions on the components to be used.	simulation	Eugenio M. Alvarez;Paul R. Mitchell;Walter M. Callahan;Peter Hoefer;Raymond Telerole	1996		10.1145/256562.256935	hardware compatibility list;throughput;application software;multidisciplinary design optimization;computer science;systems engineering;technical report;theoretical computer science;data mining;hardware architecture;data security;world wide web	Mobile	-52.59567491977582	46.870327250689584	192216
fb968f0eacdfad8196d6edbc01e387e5888eb8b4	building forensics in: supporting the investigation of digital criminal activities (invited talk)		Logging mechanisms that capture detailed traces of user activity, including creating, reading, updating, and deleting (CRUD) data, facilitate meaningful forensic analysis following a security or privacy breach. However, software requirements often inadequately and inconsistently state âwhatâ user actions should be logged, thus hindering meaningful forensic analysis. In this talk, we will explore a variety of techniques for building a software system that supports forensic analysis. We will discuss systematic heuristics-driven and patterns-driven processes for identifying log events that must be logged based on user actions and potential accidental and malicious use, as described in natural language software artifacts. We then discuss systematic process for creating a black-box test suite for verifying the identified log events are logged. Using the results of executing the black-box test suite, we propose and evaluate a security metric for measuring the forensic-ability of user activity logs.	authentication;black box;black-box testing;create, read, update and delete;error-tolerant design;heuristic (computer science);malware;natural language;privacy law;requirement;software requirements;software system;test suite;tracing (software)	Laurie A. Williams	2017		10.1145/3121252.3127582	software system;forensic science;natural language;software requirements;software;systematic process;test suite;computer security;engineering	Security	-58.94389400821748	57.256310221856495	192244
2b3500f66c38e138f40b303eaa00449c2b470fe9	secure, dynamic and distributed access control stack for database applications		In database applications, access control security layers are mostly developed from tools provided by vendors of database management systems and deployed in the same servers containing the data to be protected. This solution conveys several drawbacks. Among them we emphasize: 1) if policies are complex, their enforcement can lead to performance decay of database servers; 2) when modifications in the established policies implies modifications in the business logic (usually deployed at the client-side), there is no other possibility than modify the business logic in advance and, finally, 3) malicious users can issue CRUD expressions systematically against the DBMS expecting to identify any security gap. In order to overcome these drawbacks, in this paper we propose an access control stack characterized by: most of the mechanisms are deployed at the client-side; whenever security policies evolve, the security mechanisms are automatically updated at runtime and, finally, client-side applications do not handle CRUD expressions directly. We also present an implementation of the proposed stack to prove its feasibility. This paper presents a new approach to enforce access control in database applications, this way expecting to contribute positively to the state of the art in the	access control;business logic;call stack;client-side;create, read, update and delete;database server;run time (program lifecycle phase)	Óscar Mortágua Pereira;Diogo Domingues Regateiro;Rui L. Aguiar	2015		10.18293/SEKE2015-49	software architecture;sql;computer science;information security;access control;software engineering;database;world wide web;computer security	DB	-55.476481477267264	57.60464572809353	192253
b46072917da6e659b6adee55af5412d7ce908807	detect kernel-mode rootkits via real time logging & controlling memory access		Modern malware and spyware platforms attack existing antivirus solutions and even Microsoft PatchGuard. To protect users and business systems new technologies developed by Intel and AMD CPUs may be applied. To deal with the new malware we propose monitoring and controlling access to the memory in real time using Intel VT-x with EPT. We have checked this concept by developing MemoryMonRWX, which is a bare-metal hypervisor. MemoryMonRWX is able to track and trap all types of memory access: read, write, and execute. MemoryMonRWX also has the following competitive advantages: fine-grained analysis, support of multi-core CPUs and 64-bit Windows 10. MemoryMonRWX is able to protect critical kernel memory areas even when PatchGuard has been disabled by malware. Its main innovative features are as follows: guaranteed interception of every memory access, resilience, and low performance degradation.	64-bit computing;antivirus software;bare machine;central processing unit;elegant degradation;hypervisor;kernel (operating system);kernel patch protection;malware;microsoft windows;multi-core processor;protection ring;rootkit;second level address translation;spyware;windows 10	Igor Korkin;Satoshi Tanda	2017	CoRR		embedded system;real-time computing;computer hardware	Security	-54.6951949460708	56.88362855368044	192254
360f7dda1045515cc6b7158279933678a4f00c64	a study on strengthening security awareness programs based on an rfid access control system for inside information leakage prevention	information security;rfid;access control;security training;security awareness	Systematic security policies and plans of many organizations or enterprises can be degraded due to user’s inattention and unconcern. Therefore, it is very important to guide establishing security policies through the education for users. However, existing security awareness program has problems that is not reflect for different user’s security level and not evaluation of the security policy that is established and implemented, because it use educating for users in the form of a cluster education on uniform contents. Thus in this study, we proposed a strengthening security awareness program using an intensive training method for users based on detecting violations of the established security policy. For detecting violation of established security policy, we use a physical access control method by RFID that protects data from an information system accessed by unauthorized persons through physical ways for visual checking. The strengthening security awareness program proposed in this study increases security levels for the users who have low security awareness levels and can intercept potential leakage paths of important information through improving minimum security levels in organizations or enterprises.	access control;authorization;control system;futures studies;information leakage;information security;information system;logical security;physical access;radio-frequency identification;security awareness;security management;sensor;spectral leakage;teaching method;visual intercept	Kyong-Ho Choi;Dong-Hwi Lee	2013	Multimedia Tools and Applications	10.1007/s11042-013-1727-y	radio-frequency identification;information security audit;computer security model;standard of good practice;cloud computing security;countermeasure;security through obscurity;security information and event management;security convergence;covert channel;asset;computer science;information security;access control;logical security;information security standards;security service;internet privacy;security analysis;security testing;network security policy;computer security;information security management;computer network	Security	-48.71133560951073	59.944058782804134	192340
74e07da84971bddc0fb5eca866a306cda26fa448	security and trust requirements engineering	developpement logiciel;modelizacion;4 2 analysis;multiagent system;protocole transmission;orientado agente;securite informatique;specification;exigence usager;metodo formal;methode formelle;exigencia usuario;oriente agent;agent logiciel;software engineering;formal method;software development methodology;software agents;computer security;modelisation;refinement method;protocolo transmision;criptografia;desarrollo logicial;user requirement;cryptography;security requirements;requirement engineering;seguridad informatica;software development;case tool;genie logiciel;cryptographie;agent oriented;methode raffinement;sistema multiagente;design and verification techniques for agent systems;modeling;metodo afinamiento;ingenieria informatica;systeme multiagent;security protocol;transmission protocol	Integrating security concerns throughout the whole software development process is one of today’s challenges in software and requirements engineering research. A challenge that so far has proved difficult to meet. The major difficulty is that providing security does not only require to solve technical problems but also to reason on the organization as a whole. This makes the usage of traditional software engineering methologies difficult or unsatisfactory: most proposals focus on protection aspects of security and explicitly deal with low level protection mechanisms and only an handful of them show the ability of capturing the high-level organizational security requirements, without getting suddenly bogged down into security protocols or cryptography algorithms. In this paper we critically review the state of the art in security requirements engineering and discuss the motivations that led us to propose the Secure Tropos methodology, a formal framework for modelling and analyzing security, that enhances the agent-oriented software development methodology i*/Tropos. We illustrate the Secure Tropos approach, a comprehensive case study, and discuss some later refinements of the Secure Tropos methodology to address some of its shortcomings. Finally, we introduce the ST-Tool, a CASE tool that supports our methodology.	algorithm;computer security;computer-aided software engineering;cryptography;high- and low-level;protection mechanism;requirement;requirements analysis;requirements engineering;software development process	Paolo Giorgini;Fabio Massacci;Nicola Zannone	2005		10.1007/11554578_8	software security assurance;computer security model;cloud computing security;security through obscurity;formal methods;security engineering;computer science;cryptography;software development;requirements engineering;security testing;computer security;specification	Security	-53.75790983095799	47.2210026559374	192497
56b8ada666f1d4547e7ad2b02138e6ae316a0c97	automated detection, exploitation, and elimination of double-fetch bugs using modern cpu features		Double-fetch bugs are a special type of race condition, where an unprivileged execution thread is able to change a memory location between the time-of-check and time-of-use of a privileged execution thread. If an unprivileged attacker changes the value at the right time, the privileged operation becomes inconsistent, leading to a change in control flow, and thus an escalation of privileges for the attacker. More severely, such double-fetch bugs can be introduced by the compiler, entirely invisible on the source-code level. We propose novel techniques to efficiently detect, exploit, and eliminate double-fetch bugs. We demonstrate the first combination of state-of-the-art cache attacks with kernel-fuzzing techniques to allow fully automated identification of double fetches. We demonstrate the first fully automated reliable detection and exploitation of double-fetch bugs, making manual analysis as in previous work superfluous. We show that cache-based triggers outperform state-of-the-art exploitation techniques significantly, leading to an exploitation success rate of up to 97%. Our modified fuzzer automatically detects double fetches and automatically narrows down this candidate set for double-fetch bugs to the exploitable ones. We present the first generic technique based on hardware transactional memory, to eliminate double-fetch bugs in a fully automated and transparent manner. We extend defensive programming techniques by retrofitting arbitrary code with automated double-fetch prevention, both in trusted execution environments as well as in syscalls, with a performance overhead below 1%.		Michael Schwarz;Daniel Gruss;Moritz Lipp;Clémentine Maurice;Thomas Schuster;Anders Fogh;Stefan Mangard	2018		10.1145/3196494.3196508	race condition;parallel computing;computer security;compiler;real-time computing;computer science;cache;defensive programming;thread (computing);exploit;fuzz testing;transactional memory	Security	-55.772637808717214	56.63103141566031	192603
28ae7e9cdcfd1199bd2bce69d958d70feb157af9	mojave: a recommendation system for software upgrades		Software upgrades are frequent. Unfortunately, many of the upgrades either fail or misbehave. We argue that many of these failures can be avoided for new users of each upgrade by exploiting the characteristics of the upgrade and feedba ck from the users that have already installed it. To demonstrat e that this can be achieved, we build Mojave, the first recommendation system for software upgrades. Mojave leverages data from the existing and new users, machine learning, and static and dynamic source analyses. For each new user, Mojave computes the likelihood that the upgrade will fail for him/her. Based on this value, Mojave recommends for or against the upgrade. We evaluate Mojave for two real upgrade problems with the OpenSSH suite. Initial results show that it provides accurate recommendations.	machine learning;openssh;recommender system	Rekha Bachwani;Olivier Crameri;Ricardo Bianchini	2012			real-time computing;software;recommender system;upgrade;computer science	OS	-59.96889846582661	57.96226795021878	192830
b29e0dd466ea32d4baf00887f2601c2e5f0b41b1	enhancing optimistic access controls with usage control	usage control;access control policy;access controls;aspect oriented programming;access control;article;software process	With the advent of agile programming, lightweight software processes are being favoured over the highly formalised approaches of the past. Likewise, access control may benefit from a less prescriptive approach with an increasing reliance on users to behave ethically. These ideals correlate with optimistic access controls. However, ensuring that users behave in a trustworthy manner may require more than optimistic access controls. This paper investigates the possibility of enhancing optimistic access controls with usage control to ensure that users conduct themselves in a trustworthy manner. Usage control enables finer-grained control over the usage of digital objects than do traditional access control policies and models. Further to ease the development and maintenance of usage control measures, it is posited that it is completely separated from the application logic by using aspect-oriented programming.	access control	Keshnee Padayachee;Jan H. P. Eloff	2007		10.1007/978-3-540-74409-2_10	aspect-oriented programming;computer science;access control;database;distributed computing;computer security;software development process	HCI	-50.39402611249774	53.42464505691012	193068
17ba09206024fe263309263c5c28768cc38dfc11	tuple spaces for self-coordination of web services	tuple space;web service;self coordination;control tuple	This paper presents an approach that supports the selfcoordination of Web services. Coordination is a designerdriven operation where, for instance, the designer clearly indicates the actions that the Web services have to perform in case of conflicts. In this paper, a different approach is adopted. Web services are enhanced with mechanisms, which allow them to coordinate themselves during run-time. These mechanisms are encoded using control tuples that Web services post on tuple spaces. Web services consult a tuple space and consume the control tuples that are relevant to their coordination work.	centralized computing;composite video;run time (program lifecycle phase);service-oriented modeling;superuser;tuple space;web service;world wide web	Zakaria Maamar;Djamal Benslimane;Chirine Ghedira;Qusay H. Mahmoud;Hamdi Yahyaoui	2005		10.1145/1066677.1067053	web service;computer science;tuple space;data mining;database;world wide web	Web+IR	-48.78327262427063	52.36671061682519	193136
cace414b8b0fd9e6602e4992c5d8d8254c59d9cb	android database attacks revisited	android security;database;malware;program analysis	Many Android apps (applications) employ databases for managing sensitive data, thus, security of their databases is a concern. In this paper, we systematically study attacks targeting databases in benign Android apps. In addition to studying database vulnerabilities accessed from content providers, we define and study a new class of database vulnerabilities. We propose an analysis framework to find such vulnerabilities with a proof-of-concept exploit. Our analysis combines static dataflow analysis, symbolic execution with models for handling complex objects such as URIs and dynamic testing. We evaluate our analysis on popular Android apps, successfully finding many database vulnerabilities. Surprisingly, our analyzer finds new ways to exploit previously reported and fixed vulnerabilities. Finally, we propose a fine-grained protection mechanism extending the manifest to protect against database attacks.	android;data-flow analysis;database;dataflow;dynamic testing;protection mechanism;symbolic execution;uniform resource identifier;vulnerability (computing)	Behnaz Hassanshahi;Roland H. C. Yap	2017		10.1145/3052973.3052994	program analysis;computer science;malware;internet privacy;world wide web;computer security	Security	-56.581437212662365	58.19554957634044	193223
ad44240a078e522bcbfb7d7a10851e679fbee3cb	formal modeling of active network nodes using pvs	formal specification;formal model;refinement;active network;information flow;separation kernel;prototype verification system;data isolation	Active Networks are a new type of networks where all elements are programmable. Active packets can contain fragments of code to be executed on intermediate nodes they pass through. Active nodes provide the necessary environment and resources for the packets to be processed. In giving the users the capability to program the network as they desire, there is an issue of security risks. This paper presents a formal model for an active node that can be used to specify and verify the correct operation of the node. The model is used to verify that scenarios where privacy of data is violated or functionality of a node is compromised never occur. The proposed model is generic to any type of active node and is written using the Prototype Verification System (PVS).	active networking;mathematical model;node (computer science);privacy;prototype verification system	Cindy Kong;Perry Alexander;Darryl D. Dieckman	2000		10.1145/349360.351130	active networking;real-time computing;information flow;isolation;computer science;theoretical computer science;formal specification;refinement;programming language;computer security	EDA	-53.81787593674227	53.15401034683423	193887
06c472db919f3e8816291719a358e1eabec9ed75	information flow tracking meets just-in-time compilation	information flow;dynamic language security;javascript	Web applications are vulnerable to cross-site scripting attacks that enable data thefts. Information flow tracking in web browsers can prevent communication of sensitive data to unintended recipients and thereby stop such data thefts. Unfortunately, existing solutions have focused on incorporating information flow into browsers’ JavaScript interpreters, rather than just-in-time compilers, rendering the resulting performance noncompetitive. Few users will switch to a safer browser if it comes at the cost of significantly degrading web application performance.  We present the first information flow tracking JavaScript engine that is based on a true just-in-time compiler, and that thereby outperforms all previous interpreter-based information flow tracking JavaScript engines by more than a factor of two. Our JIT-based engine (i) has the same coverage as previous interpreter- based solutions, (ii) requires reasonable implementation effort, and (iii) introduces new optimizations to achieve acceptable performance. When evaluated against three industry-standard JavaScript benchmark suites, there is still an average slowdown of 73% over engines that do not support information flow, but this is now well within the range that many users will find an acceptable price for obtaining substantially increased security.	benchmark (computing);compiler;cross-site scripting;information flow;javascript engine;just-in-time compilation;web application	Christoph Kerschbaumer;Eric Hennigan;Per Larsen;Stefan Brunthaler;Michael Franz	2013	TACO	10.1145/2541228.2555295	parallel computing;real-time computing;information flow;computer science;unobtrusive javascript;operating system;database;javascript;programming language;world wide web	Security	-55.76232966900273	58.396170802627324	194019
768c32bea91e2ff948420af704a8cd182e568163	a next-generation platform for analyzing executables	static analysis;high level language;explicit memory;intermediate representation;scripting language;pattern matching	In recent years, there has been a growing need for tools that an analyst can use to understand the workings of COTS components, plugins, mobile code, and DLLs, as well as memory snapshots of worms and virus-infected code. Static analysis provides techniques that can help with such problems; however, there are several obstacles that must	code mobility;computer virus;dynamic-link library;executable;plug-in (computing);snapshot (computer storage);static program analysis	Thomas W. Reps;Gogul Balakrishnan;Junghee Lim;Tim Teitelbaum	2007		10.1007/978-0-387-44599-1_3	input/output;compiler;dynamic load testing;internationalization and localization;computer science;artificial intelligence;expression;theoretical computer science;component-based software engineering;operating system;explicit memory;pattern matching;mobile agent;database;distributed computing;scripting language;data analysis;programming language;intermediate language;high-level programming language;computer security;static analysis;algorithm	Security	-57.12518259751396	54.296056104072846	194022
d788c19222afa47ec4e8a346721c7da615a025d1	a security architectural pattern for risk management of industry control systems within critical national infrastructure	security architectural pattern;risk management;critical national infrastructure;sabsa;article;business requirements;industry control systems	SCADA and ICS security have been focusing on addressing issues such as vulnerability discovery and intrusion detection within critical national infrastructure. Less attention has been paid to architectural solutions to the cyber security risks from an information assurance perspective. Security controls are not always traced back to the business requirements. This paper presents a holistic end-to-end view of the requirements, medium to high severity risks and proposes a generic security architectural pattern to address them. The architectural pattern is developed based on the Sherwood Applied Business Security Architecture (SABSA) top two layers, contextual and conceptual, which are responsible for understanding the business requirements and development of a concept architecture and strategy. Moreover, this research is motivated by industrial practices and has reflected the recent changes of GCHQ’s mission. This research Copyright © 201X Inderscience Enterprises Ltd.	architectural pattern;business requirements;computer security;control system;end-to-end principle;holism;information assurance;intrusion detection system;requirement;risk management;security controls;sherwood applied business security architecture;wiki	Andy Wood;Ying He;Leandros A. Maglaras;Helge Janicke	2017	IJCIS	10.1504/IJCIS.2017.10009242	systems engineering;engineering;software engineering;critical infrastructure;computer security	Security	-57.25694105736651	49.671313223979844	194115
02efa237283fe301e83686264d660f36c219046b	taxonomy of attacks for agent-based smart grids	generators;power systems;smart grid;smart grids;cyber physical systems cps;agents;cyber detection scheme taxonomy of attacks agent based smart grids critical infrastructure cyber physical systems large scale environment distributed environment dynamic environment attack classification national science foundation workshop cyber physical process information flow direction security feature cyber physical causality cyber attack detection scheme;taxonomy smart grids mathematical model security equations generators load modeling;taxonomy;mathematical model;software agents grid computing security of data;agents cyber physical systems cps security smart grid critical infrastructure taxonomy power systems;critical infrastructure;security;load modeling	Being the most important critical infrastructure in Cyber-Physical Systems (CPSs), a smart grid exhibits the complicated nature of large scale, distributed, and dynamic environment. Taxonomy of attacks is an effective tool in systematically classifying attacks and it has been placed as a top research topic in CPS by a National Science Foundation (NSG) Workshop. Most existing taxonomy of attacks in CPS are inadequate in addressing the tight coupling of cyber-physical process or/and lack systematical construction. This paper attempts to introduce taxonomy of attacks of agent-based smart grids as an effective tool to provide a structured framework. The proposed idea of introducing the structure of space-time and information flow direction, security feature, and cyber-physical causality is innovative, and it can establish a taxonomy design mechanism that can systematically construct the taxonomy of cyber attacks, which could have a potential impact on the normal operation of the agent-based smart grids. Based on the cyber-physical relationship revealed in the taxonomy, a concrete physical process based cyber attack detection scheme has been proposed. A numerical illustrative example has been provided to validate the proposed physical process based cyber detection scheme.	agent-based model;causality;cyber-physical system;numerical analysis;requirement;taxonomy (general);twisted nematic field effect	Jiankun Hu;Hemanshu Roy Pota;Song Guo	2014	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2013.301	computer science;distributed computing;smart grid;world wide web;computer security;taxonomy	Security	-62.3017244166139	60.10406417705971	194140
903702cea3119fda92e3a87b48912d03089f7c44	prec: practical root exploit containment for android devices	host intrusion detection;android;malware;root exploits;dynamic analysis	Application markets such as the Google Play Store and the Apple App Store have become the de facto method of distributing software to mobile devices. While official markets dedicate significant resources to detecting malware, state-of-the-art malware detection can be easily circumvented using logic bombs or checks for an emulated environment. We present a Practical Root Exploit Containment (PREC) framework that protects users from such conditional malicious behavior. PREC can dynamically identify system calls from high-risk components (e.g., third-party native libraries) and execute those system calls within isolated threads. Hence, PREC can detect and stop root exploits with high accuracy while imposing low interference to benign applications. We have implemented PREC and evaluated our methodology on 140 most popular benign applications and 10 root exploit malicious applications. Our results show that PREC can successfully detect and stop all the tested malware while reducing the false alarm rates by more than one order of magnitude over traditional malware detection algorithms. PREC is light-weight, which makes it practical for runtime on-device root exploit detection and containment.	algorithm;app store;emulator;interference (communication);library (computing);malware;mobile device;play store;sensor;system call	Tsung-Hsuan Ho;Daniel Joseph Dean;Xiaohui Gu;William Enck	2014		10.1145/2557547.2557563	engineering;internet privacy;world wide web;computer security	Security	-56.308908048978076	59.50683955630148	194459
4afe46e92e0d1647e40ffa9a67201a6b9060ad59	discovering, quantifying, and displaying attacks	computer science logic in computer science;computer science cryptography and security;68q60	In the design of software and cyber-physical systems, security is often perceived as a qualitative need, but can only be attained quantitatively. Especially when distributed components are involved, it is hard to predict and confront all possible attacks. A main challenge in the development of complex systems is therefore to discover attacks, quantify them to comprehend their likelihood, and communicate them to non-experts for facilitating the decision process. To address this three-sided challenge we propose a protection analysis over the Quality Calculus that (i) computes all the sets of data required by an attacker to reach a given location in a system, (ii) determines the cheapest set of such attacks for a given notion of cost, and (iii) derives an attack tree that displays the attacks graphically. The protection analysis is first developed in a qualitative setting, and then extended to quantitative settings following an approach applicable to a great many contexts. The quantitative formulation is implemented as an optimisation problem encoded into Satisfiability Modulo Theories, allowing us to deal with complex cost structures. The usefulness of the framework is demonstrated on a national-scale authentication system, studied through a Java implementation of the framework. 1998 ACM Subject Classification: F.3.1, Specifying and Verifying and Reasoning about Programs.	attack tree;authentication;complex systems;cyber-physical system;formal specification;java;mathematical optimization;modulo operation;satisfiability modulo theories	Roberto Vigo;Flemming Nielson;Hanne Riis Nielson	2016	Logical Methods in Computer Science	10.2168/LMCS-12(4:5)2016	computer science;theoretical computer science;data mining;mathematics;computer security;algorithm	Logic	-52.43344784492795	47.9442669260146	194568
81beade377e83260b934640c52f6f7dbc93efc86	preventing brute force attacks against stack canary protection on networking servers	software libraries;netwoking server security buffer overflow prevention;client server systems;servers force libraries standards proposals instruction sets layout;c language;internet;cryptography;software libraries c language client server systems cryptography internet linux;linux distribution brute force attack prevention stack canary protection networking servers buffer overflow aslr nonexecutable web servers stack smashing protector technique ssp technique shared library preloading gnu distribution standard c library;linux	The buffer overflow is still an important problem despite the various protection methods developed and widely used on most systems (Stack-Smashing Protector, ASLR and Non-eXecutable). Most of these techniques rely on keeping secret some key information needed by the attackers to build the exploit. Unfortunately, the architecture of most Web servers allows attacker to implement brute force attacks that can be exploited to obtain those secrets by mean of brute force attacks, and eventually break into the server. We propose a modification of the stack-smashing protector (SSP) technique which eliminates brute force attacks against the canary. The technique is not intrusive, and can be applied by just pre-loading a shared library. The overhead is almost negligible. The technique has been tested on several web servers and on a complete GNU/Linux distribution by patching the standard C library. We expect that the strategy presented in this paper will become a standard technique on both desktop and servers.	ansi c;address space layout randomization;brute force;brute-force attack;brute-force search;buffer overflow protection;byte;c standard library;desktop computer;exec (system call);exploit (computer security);gnu c library;library (computing);linux;mcgurk effect;operating system;overhead (computing);parallel computing;samba tng;server (computing);stack buffer overflow;system image;web server	Hector Marco-Gisbert;Ismael Ripoll	2013	2013 IEEE 12th International Symposium on Network Computing and Applications	10.1109/NCA.2013.12	computer science;cryptography;operating system;world wide web;computer security;linux kernel;server;computer network	Arch	-54.55676970394229	58.58349196308291	194730
2a1dccb9c24cf88db2968ae548620ccbdb062b2f	modeling the symptomatic fixes archetype in enterprise computer security	computer security information security software systems computer networks educational institutions computational modeling application software protection intrusion detection mechanical engineering;system dynamics modeling;system modeling;system dynamics;system modeling symptomatic fixes archetype modeling enterprise computer security decision making security risk mitigation system dynamics model human factors;security of data business data processing decision making human factors;system security;computer security;security risk mitigation;system dynamics model;human factors;symptomatic fixes archetype modeling;business data processing;enterprise computer security;enterprise system;risk mitigation;security of data	To support decision-making for security-risk mitigation and the appropriate selection of security countermeasures, we propose a system dynamics model of the security aspects of an enterprise system. We developed such an executable model, incorporating the concept of archetypes. We present here one archetype for computer security, namely symptomatic fixes (or shifting the burden). Using simulation, we show one instance of how this archetype can be used for recognizing and diagnosing typical situations, as well as for fixing problems. The global effects of changes and behavioral trends are examined, and other instances of symptomatic fixes in security are described as well	computer security;enterprise system;executable;simulation;system dynamics	Shalom N. Rosenfeld;Ioana Rus;Michel Cukier	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.62	computer security model;risk management;computer science;systems engineering;engineering;knowledge management;human factors and ergonomics;software engineering;fixes that fail;database;system dynamics;computer security	Arch	-55.395186554539485	48.814092535059245	194757
1d77fc297b798189640262c948d9e4a7578dd069	rambo: run-time packer analysis with multiple branch observation	malware;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;malware unpacking multi path exploration;unpacking;multi path exploration	Run-time packing is a technique employed by malware authors in order to conceal (e.g., encrypt) malicious code and recover it at run-time. In particular, some run-time packers only decrypt individual regions of code on demand, re-encrypting them again when they are not running. This technique is known as shifting decode frames and it can greatly complicate malware analysis. The first solution that comes to mind to analyze these samples is to apply multi-path exploration to trigger the unpacking of all the code regions. Unfortunately, multi-path exploration is known to have several limitations, such as its limited scalability for the analysis of real-world binaries. In this paper, we propose a set of domain-specific optimizations and heuristics to guide multi-path exploration and improve its efficiency and reliability for unpacking binaries protected with shifting decode frames.	code on demand;encryption;executable compression;heuristic (computer science);malware analysis;mind;scalability;set packing	Xabier Ugarte-Pedrero;Davide Balzarotti;Igor Santos;Pablo García Bringas	2016		10.1007/978-3-319-40667-1_10	simulation;computer science;theoretical computer science;computer security	Security	-56.43283155946365	56.40059428657972	195225
acbe23c628edd3af874070c994b5860b2d2e22c2	introduction of a hybrid monitor to cyber-physical systems		Computing and technology have vastly changed since the introduction of firewall technology in 1988. The internet has grown from a simple network of networks to a cyber and physical entity that encompasses the entire planet. Cyber-physical systems(CPS) now control most of the day to day operations of human civilization from autonomous cars to nuclear energy plants. While phenomenal, this growth spurt has created new security threats. These are threats that cannot be blocked by a firewall for they are not only cyber but cyber-physical. In light of these new cyber-physical threats, this text proposes a security measure that promises to enhance the security of cyber-physical systems. Using theoretical cyber, physical, and cyber-physical attack scenarios, this text will highlight the need for some sort of monitor in cyber-physical systems as an extra security measure. Additionally, this text will illustrate the efficiency of said monitor using a Shannon entropy proof, and a multiple security domain nondeducibility(MSDND) proof.	autonomous car;cyber-physical system;entropy (information theory);firewall (computing);human height;internet;shannon (unit)	Julius C. Aguma;Bruce McMillin	2018	CoRR		entropy (information theory);security measure;the internet;computer security;computer science;cyber-physical system;sort;firewall (construction);security domain	Security	-51.407172954463356	60.28676541460044	195292
2bcbc69bd7f1b997e3931678a1bc5932aa0a5cfd	approach of the secure communication mechanism for the off-site live virtual machine migrations	cloud computing;live virtual machine migration;secure communication mechanism	The virtual machines of cloud computing platform deployed in the enterprise need remote off-site live migration, but the bandwidth and WAN security factors could cause communication delay and can not penetrate the firewalls two-way, at the same time system has the shortcomings of counterfeiting and vulnerable during communication, so we need a new structure and the communication mechanism of live migration to ensure migration safe and reliable. This paper designs the off-site live migration structure for confidentiality, integrity and penetration requirements, and puts forward a new secure communications protocol underlying SUDP to discuss the authentication and messaging security.	secure communication;virtual machine	Xinnian Wang;Yanlin Chen	2011		10.1007/978-3-642-23777-5_123	computer science;distributed computing;computer security;computer network	OS	-48.340121316886645	58.119537933261476	195577
b852dfbb97b79b5ccf0449955d43171e697a8cac	toward an automated attack model for red teams	xml invasive software simulation unified modeling language;simulation;red teams;vulnerabilities red teams xml;vulnerabilities;xml automated attack model red teams system vulnerabilities proactive security services malicious attack simulation uml based use cases sequence diagrams state chart diagrams;unified modeling language;computer hacking information security terrorism computer security privacy computational modeling computer simulation communication system security wireless networks wireless application protocol;xml;invasive software;use case	To better understand system vulnerabilities, proactive security services use red teams that simulate malicious attacks. The authors contend that an attack model with UML-based use cases, sequence and state chart diagrams, and XML would best help red teams achieve attack automation.	attack model;diagram;malware;proactive parallel suite;simulation;unified modeling language;xml	Helayne T. Ray;Raghunath Vemuri;Hariprasad R. Kantubhukta	2005	IEEE Security & Privacy Magazine	10.1109/MSP.2005.111	use case;unified modeling language;attack;xml;vulnerability;computer science;internet privacy;world wide web;computer security	Security	-61.06830116107647	60.421431006537816	195606
3e1407602b64bcdfd14ca2fe645779b7d5d95250	enpublic apps: security threats using ios enterprise and developer certificates	enterprise certificate;private apis;ios	"""Compared with Android, the conventional wisdom is that iOS is more secure. However, both jailbroken and non-jailbroken iOS devices have number of vulnerabilities. For iOS, apps need to interact with the underlying system using Application Programming Interfaces (APIs). Some of these APIs remain undocumented and Apple forbids apps in App Store from using them. These APIs, also known as """"private APIs"""", provide powerful features to developers and yet they may have serious security consequences if misused. Furthermore, apps which use private APIs can bypass the App Store and use the """"Apple's Enterprise/Developer Certificates"""" for distribution. This poses a significant threat to the iOS ecosystem. So far, there is no formal study to understand these apps and how private APIs are being encapsulated. We call these iOS apps which distribute to the public using enterprise certificates as """"enpublic"""" apps. In this paper, we present the design and implementation of iAnalytics, which can automatically analyze """"enpublic"""" apps' private API usages and vulnerabilities. Using iAnalytics, we crawled and analyzed 1,408 enpublic iOS apps. We discovered that: 844 (60%) out of the 1408 apps do use private APIs, 14 (1%) apps contain URL scheme vulnerabilities, 901 (64%) enpublic apps transport sensitive information through unencrypted channel or store the information in plaintext on the phone. In addition, we summarized 25 private APIs which are crucial and security sensitive on iOS 6/7/8, and we have filed one CVE (Common Vulnerabilities and Exposures) for iOS devices."""	android;app store;application programming interface;common vulnerabilities and exposures;ecosystem;information sensitivity;plaintext;undocumented feature;ios	Min Zheng;Hui Xue;Yulong Zhang;Tao Wei;John C. S. Lui	2015		10.1145/2714576.2714593	internet privacy;world wide web;computer security	Security	-54.840212276770814	60.32730689537998	195962
18c4a40db5af5d0f1d9d068335a867272f813311	self-hiding behavior in android apps: detection and characterization		"""Applications (apps) that conceal their activities are fundamentally deceptive; app marketplaces and end-users should treat such apps as suspicious. However, due to its nature and intent, activity concealing is not disclosed up-front, which puts users at risk. In this paper, we focus on characterization and detection of such techniques, e.g., hiding the app or removing traces, which we call """"self hiding behavior"""" (SHB). SHB has not been studied per se - rather it has been reported on only as a byproduct of malware investigations. We address this gap via a study and suite of static analyses targeted at SH in Android apps. Specifically, we present (1) a detailed characterization of SHB, (2) a suite of static analyses to detect such behavior, and (3) a set of detectors that employ SHB to distinguish between benign and malicious apps. We show that SHB ranges from hiding the app's presence or activity to covering an app's traces, e.g., by blocking phone calls/text messages or removing calls and messages from logs. Using our static analysis tools on a large dataset of 9,452 Android apps (benign as well as malicious) we expose the frequency of 12 such SH behaviors. Our approach is effective: it has revealed that malicious apps employ 1.5 SHBs per app on average. Surprisingly, SH behavior is also employed by legitimate (""""benign"""") apps, which can affect users negatively in multiple ways. When using our approach for separating malicious from benign apps, our approach has high precision and recall (combined F-measure = 87.19%). Our approach is also efficient, with analysis typically taking just 37 seconds per app. We believe that our findings and analysis tool are beneficial to both app marketplaces and end-users."""	activity recognition;android;blocking (computing);experiment;f1 score;malware;precision and recall;sensor;static program analysis;system host board;tracing (software);user experience	Zhiyong Shan;Iulian Neamtiu;Raina Samuel	2018	2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)	10.1145/3180155.3180214	internet privacy;real-time computing;static program analysis;computer science;android (operating system);malware	SE	-56.587303358415596	60.26080456390086	196263
1381a34b36a65433df6ceac6ecbfdc2634cd32e4	critical information infrastructures security	computer communication networks;data security	Critical infrastructure systems (CIS) are complex large-scale systems which in turn require highly sophisticated supervisory control systems to ensure that high performance can be achieved and maintained under adverse conditions. The global CIS Real-Time Control (RTC) need of operating in adverse conditions involves, with a high probability, sensor and actuator malfunctions (faults). This problem calls for the use of an on-line Fault Detection and Isolation (FDI) system able to detect such faults. This paper proposes a FDI mechanism that extends the classical Boolean fault signature matrix concept taking into account several fault signal properties to isolate faults in CIS. To exemplify the proposed FDI scheme in CIS, the Barcelona drinking water network is used as a case study.	control system;exemplification;fault detection and isolation;fault tolerance;online and offline;real-time transcription	Josef Kittler;John C. Mitchell;Moni Naor	2014		10.1007/978-3-319-31664-2	information security audit;computer security model;cloud computing security;security through obscurity;security information and event management;security convergence;covert channel;asset;information security;security service;security analysis;network access control;network security policy;computer security;information security management;computer network	AI	-57.122679198908145	51.47938455950143	196420
e379517c3e6ed568f41014538c067195518dd407	droidalarm: an all-sided static analysis tool for android privilege-escalation malware	malware transformation;android;capability leaks;privilege escalation attack;static analysis	Since smartphones have stored diverse sensitive privacy information, including credit card and so on, a great deal of malware are desired to tamper them. As one of the most prevalent platforms, Android contains sensitive resources that can only be accessed via corresponding APIs, and the APIs can be invoked only when user has authorized permissions in the Android permission model. However, a novel threat called privilege escalation attack may bypass this watchdog. It's presented as that an application with less permissions can access sensitive resources through public interfaces of a more privileged application, which is especially useful for malware to hide sensitive functions by dispersing them into multiple programs. We explore privilege-escalation malware evolution techniques on samples from Android Malware Genome Project. And they have showed great effectiveness against a set of powerful antivirus tools provided by VirusTotal. The detection ratios present different and distinguished reduction, compared to an average 61% detection ratio before transformation. In order to conquer this threat model, we have developed a tool called DroidAlarm to conduct a full-spectrum analysis for identifying potential capability leaks and present concrete capability leak paths by static analysis on Android applications. And we can still alarm all these cases by exposing capability leak paths in them.	android;antivirus software;authorization;capability-based security;full-spectrum light;malware;privilege escalation;smartphone;static program analysis;threat model;virustotal;watchdog timer	Yibing Zhongyang;Zhi Xin;Bing Mao;Li Xie	2013		10.1145/2484313.2484359	computer science;cryptovirology;internet privacy;world wide web;computer security;static analysis;android	Security	-56.49348485532925	58.41442185033501	196509
5726c7976bf7d48d267347ffdeb0edd0a47335c8	reconciling objects and multilevel security (panel).	multilevel security	Introduction: We describe here an approach to integrating multilevel security with object-oriented database management systems (DBMSs) based on the SODA (Secure Object-oriented DAtabase) security model [4]. We concern ourselves here with multilevel security (MLS) policy which is characterized by a partially ordered set (SC, 2). where SC is a set of classifications with partial ordering, 5. For 11 and 12 in SC, if 11 < 12, we say I2 dominates 11. The active subjects in the system are assigned elements of SC indicating their perceived trustworthiness. We refer to this as the classification level of the subject. Information can flow from a subject with classification level 11 to a subject with classification level 12 if 11 I 12.	database;dominator (graph theory);multilevel security;trust (emotion)	Thomas F. Keefe	1993		10.1145/165854.165916	computer science	DB	-49.54465176708413	49.11143000991381	196781
b77621b2f3da8b4b6308e3443e91f5c818afd49b	on the feasibility of deploying software attestation in cloud environments	verification;cloud;toctou cloud security hypervisor verification attestation;cloud environments toctou attacks virtual machines xswat verifier environmental parameters threat model xswat system cloud computing platforms timing based software attestation xen software attestation;hypervisor;attestation;virtual machine monitors jitter timing hardware kernel ports computers;security;virtual machines cloud computing security of data;toctou	We present XSWAT (Xen SoftWare ATtestation), a system that makes use of timing based software attestation to verify the integrity of cloud computing platforms. We believe that ours is the first instance of a system that uses this attestation technique in a cloud environment and results obtained indicate the feasibility of its deployment. An overview of the XSWAT system and the associated threat model, along with a study of cloud environment impacts on performance, is presented. Environmental parameters include types of interconnects between the XSWAT verifier and measurement agent as well as the number of concurrently executing virtual machines on the platform being verified. Conversely, we also study the impact of XSWAT execution using well known system benchmarks and find this to be insignificant, thereby strengthening the case for XSWAT. We also discuss novel XSWAT mechanisms for addressing TOCTOU attacks.	cloud computing;electrical connection;software deployment;threat model;time of check to time of use;virtual machine	Abhrajit Ghosh;Angelo Sapello;Alexander Poylisher;Cho-Yu Jason Chiang;Ayumu Kubota;Takashi Matsunaka	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.27	embedded system;verification;cloud computing;computer science;information security;operating system;time of check to time of use;hypervisor;computer security	Embedded	-52.9431933854054	56.92312390411205	197038
2f69a33c76e9853eb7c98ebfb6d93b7c85077e29	transforming graphical system models to graphical attack models	research outputs;research publications	Manually identifying possible attacks on an organisation is a complex undertaking; many different factors must be considered, and the resulting attack scenarios can be complex and hard to maintain as the organisation changes. System models provide a systematic representation of organisations that helps in structuring attack identification and can integrate physical, virtual, and social components. These models form a solid basis for guiding the manual identification of attack scenarios. Their main benefit, however, is in the analytic generation of attacks. In this work we present a systematic approach to transforming graphical system models to graphical attack models in the form of attack trees. Based on an asset in the model, our transformations result in an attack tree that represents attacks by all possible actors in the model, after which the actor in question has obtained the asset.	attack tree;computer graphics;denial-of-service attack;graphical model;graphical user interface;human factors and ergonomics;risk assessment;sequence diagram;social engineering (security);type system;umlsec	Marieta Georgieva Ivanova;Christian W. Probst;René Rydhof Hansen;Florian Kammüller	2015		10.1007/978-3-319-29968-6_6	simulation;engineering;data mining;computer security	Security	-55.74268658579848	49.40887993957039	197064
3b8b1c69f017a802b1e20adc352a58600af9abd6	a formal approach to automatic testing of security policies specified in xacml		Nowadays, security policies are the key point of every modern infrastructure. The specification and testing of such policies are the fundamental steps in the development of a secure system. To address both challenges, we propose a framework that automatically generates test sequences to validate the conformance of a security policy. The functional behavior of the system is specified using a formal description technique based on Extended Finite-State Machines (EFSMs), while security requirements are specified using XACML. We develop specific algorithms to integrate the security rules into the functional system specification. In this way, we obtain a complete specification of the secured system. Then, automatic test generation is performed using a dedicated tool called TestGen-IF which was developed in our laboratory. This generation is based on the security properties as test objectives. Finally, a case study is presented to demonstrate the reliability of our framework.	xacml	Mohamed H. E. Aouadi;Khalifa Toumi;Ana R. Cavalli	2014		10.1007/978-3-319-17040-4_25	internet privacy;computer security;computer network	SE	-52.294951600052336	50.64715634026835	197080
0c36e606b84b0fe7b5824d1c9cf2d0eb70e770eb	reflections on the self-service cloud computing project		Modern cloud computing infrastructures use virtual machine monitors (VMMs) that often include a large and complex administrative domain with privileges to inspect client VM state. Attacks against or misuse of the administrative domain can compromise client security and privacy. Moreover, these VMMs provide clients inflexible control over their own VMs, as a result of which clients have to rely on the cloud provider to deploy useful services, such as VM introspection-based security tools.	administrative domain;amiga reflections;anomaly detection;cloud computing;computation;hypervisor;introspection;intrusion detection system;openvms;privilege (computing);prototype;sql server compact;superuser;virtual machine	Vinod Ganapathy	2015		10.1007/978-3-319-26961-0_4	computer science;operating system;internet privacy;world wide web;computer security	Security	-50.61208784709407	58.130906358430295	197354
f3c6e55d0f95a9a84e29b3c6ee8822633715ada7	a quantitative approach for inexact enforcement of security policies	runtime enforcement;safety;security usability tradeoff	A run-time enforcement mechanism is a program in charge of ensuring that all the traces of a system satisfy a given security policy. Following Schneider’s seminal work, there have been several approaches defining what kind of policies can be automatically enforced, and in particular, non-safety properties cannot be correctly and transparently enforced. In this paper, we first propose to build an enforcement mechanism using an abstract notion of selector. We then propose to quantify the inexact enforcement of a non-safety property by an enforcement mechanism, by considering both the traces leading to a non-secure output by this mechanism and the secure traces not output, thus formalizing an intuitive notion of security/usability tradeoff. Finally, we refine this notion when probabilistic and quantitative information is known about the traces. We illustrate all the different concepts with a running example, representing an abstract policy dealing with emergency situations.		Peter Drábik;Fabio Martinelli;Charles Morisset	2012		10.1007/978-3-642-33383-5_19	reliability engineering;computer science;data mining;computer security	Security	-53.84593213174632	52.09188614341478	197410
243bce677d84b403b43f0d7a2613f09fb0169719	mobileinsight: extracting and analyzing cellular network information on smartphones	dns;measurement;performance;mobile web;ipv6;cdn;ipv4;cellular	We design and implement MobileInsight, a software tool that collects, analyzes and exploits runtime network information from operational cellular networks. MobileInsight runs on commercial off-the-shelf phones without extra hardware or additional support from operators. It exposes protocol messages on both control plane and (below IP) data plane from the 3G/4G chipset. It provides in-device protocol analysis and operation logic inference. It further offers a simple API, through which developers and researchers obtain access to low-level network information for their mobile applications. We have built three showcases to illustrate how MobileInsight is applied to cellular network research.	application programming interface;chipset;control plane;forwarding plane;high- and low-level;mobile app;programming tool;smartphone	Yuanjie Li;Chunyi Peng;Zengwen Yuan;Jiayao Li;Haotian Deng;Tao Wang	2016		10.1145/2973750.2973751	embedded system;mobile web;performance;computer science;operating system;ipv6;world wide web;domain name system;measurement;computer network	Mobile	-53.69801802955331	60.23178119809666	197512
21452a9fba8274510b8c9d6b03ad549476947be3	towards improving mental models of personal firewall users	context information;configuration;article;mental model;usable security;firewall	Windows Vista's personal firewall provides its diverse users with a basic interface that hides many operational details. However, our study of this interface revealed that concealing the impact of network context on the security state of the firewall results in mental models that are unclear about the protection provided by the firewall resulting in an inaccurate understanding of the firewall configuration. We developed a prototype to support more contextually complete mental models through inclusion of network context information. Results from our initial evaluation of the prototype support our approach of improving user understanding of underlying system states by revealing hidden context, while considering the tension between complexity of the interface and security of the system.	firewall (computing);mental model;microsoft windows;personal firewall;prototype	Fahimeh Raja;Kirstie Hawkey;Konstantin Beznosov	2009		10.1145/1520340.1520712	application firewall;firewall;internet security;internet privacy;configuration;world wide web;computer security	HCI	-53.92382871083085	60.23863051790087	197572
9d6afb266668fef1e53bacdd94a7bd95decaaa3e	enabling security-aware virtual machine placement in iaas clouds	measurement;virtual machining;computer security;virtual machine monitors;servers;cloud computing	Infrastructure as a Service (IaaS) facilitates the provisioning of virtual machines (VMs) in cloud computing platform for disjoint customers in a highly scalable, flexible, and cost-efficient fashion. However, introducing new VMs to a physical server where vulnerable VM already exists could lead to potential security risks to the new ones. Furthermore, even the physical server itself could be compromised by attackers through one of these vulnerable VMs. Therefore, VM placement could bring great impact over the security level of the whole cloud. In this paper, we first quantify the security risks of cloud environments based on virtual machine vulnerabilities and placement schemes. Based on our security evaluation, we present a novel VM placement algorithm that can minimize the cloud's overall security risks by considering the connections among VMs. According to the experimental results, our approach can greatly improve the survivability of most VMs and the entire cloud. The computing costs and deployment costs of our techniques are also practical.	algorithm;cloud computing;cost efficiency;provisioning;scalability;server (computing);software deployment;tag cloud;virtual machine	Xuebiao Yuchi;Sachin Shetty	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357666	cloud computing security;embedded system;engineering;operating system;computer security	HPC	-50.30086915542569	57.57801052468511	197575
9c625ecf2c760e700adbde36ef79a0e9e4cf7dd0	in cloud we trust: risk-assessment-as-a-service		Cloud computing is an emerging paradigm that allows adoption of on-demand services in a cost-effective way. Migrating services to the Cloud also means been exposed to new threats and vulnerabilities, thus, resulting in a modified assessment of risk. Assessing risk in the Cloud remains an open research issue, as it requires a given level of trust of the Cloud service provider for providing assessment data and implementing controls. This paper surveys existing knowledge, regarding risk assessment for the Cloud, and highlights the requirements for the design of a cloud-targeted method that is offered as a service, which is also in compliance with the specific characteristics of the Cloud.	cloud computing;open research;programming paradigm;requirement;risk assessment	Marianthi Theoharidou;Nikolaos Tsalis;Dimitris Gritzalis	2013		10.1007/978-3-642-38323-6_7	service provider;cloud computing;computer security;open research;risk assessment;cloud computing security;vulnerability;business	SE	-49.21941855316365	57.05150540915456	197593
0ee2d01b186d713fe35bba58c19a10ac4f1ac60e	a software-hardware architecture for self-protecting data	information flow tracking;policy languages;trusted computing;self protecting data;security;architecture	We propose a software-hardware architecture, DataSafe, that realizes the concept of self-protecting data: data that is protected by a given policy whenever it is accessed by any application -- including unvetted third-party applications. Our architecture provides dynamic instantiations of secure data compartments (SDCs), with hardware monitoring of the information flows from the compartment using hardware policy tags associated with the data at runtime. Unbypassable hardware output control prevents confidential information from being leaked out. Unlike previous hardware information flow tracking systems, DataSafe software architecture bridges the semantic gap by supporting flexible, high-level software policies for the data, seamlessly translating these policies to efficient hardware tags at runtime. Applications need not be modified to interface to these software-hardware mechanisms. DataSafe architecture is designed to prevent illegitimate secondary dissemination of protected plaintext data by authorized recipients, to track and protect data derived from sensitive data, and to provide lifetime enforcement of the confidentiality policies associated with the sensitive data.	authorization;confidentiality;high- and low-level;multi-compartment model;plaintext;run time (program lifecycle phase);software architecture;system monitor;tracking system	Yu-Yuan Chen;Pramod A. Jamkhedkar;Ruby B. Lee	2012		10.1145/2382196.2382201	reference architecture;computer science;information security;architecture;hardware architecture;database;world wide web;computer security;data architecture	Security	-52.64566249979286	55.04420911475	197754
333079d0c0f69ef8e8b4fed5ec9b6de6c5e609fd	a formal tls handshake model in lnt		Testing of network services represents one of the biggest challenges in cyber security. Because new vulnerabilities are detected on a regular basis, more research is needed. These faults have their roots in the software development cycle or because of intrinsic leaks in the system specification. Conformance testing checks whether a system behaves according to its specification. Here model-based testing provides several methods for automated detection of shortcomings. The formal specification of a system behavior represents the starting point of the testing process. In this paper, a widely used cryptographic protocol is specified and tested for conformance with a test execution framework. The first empirical results are presented and discussed.	computer security;conformance testing;cryptographic protocol;cryptography;formal specification;memory leak;model-based testing;software development process;transport layer security	Josip Bozic;Lina Marsso;Radu Mateescu;Franz Wotawa	2018	CoRR	10.4204/EPTCS.268.1	formal specification;software development process;theoretical computer science;real-time computing;computer science;conformance testing;cryptographic protocol;system requirements specification	SE	-56.107728579681435	53.22725328419342	198146
83474f5a4514b7af4eab64065a245727955c4b46	policy/mechanism separation in hydra	design principle;policy;resource allocation;protection;paging;operating system;scheduling;mechanism	The extent to which resource allocation policies are entrusted to user-level software determines in large part the degree of flexibility present in an operating system. In Hydra the determination to separate mechanism and policy is established as a basic design principle and is implemented by the construction of a kernel composed (almost) entirely of mechanisms. This paper presents three such mechanisms (scheduling, paging, protection) and examines how external policies which manipulate them may be constructed. It is shown that the policy decisions which remain embedded in the kernel exist for the sole purpose of arbitrating conflicting requests for physical resources, and then only to the extent of guaranteeing fairness.	consciousness;embedded system;fairness measure;hydra (chess);kernel (operating system);operating system;paging;scheduling (computing);separation of mechanism and policy;user space	Roy Levin;Ellis S. Cohen;William M. Corwin;Fred J. Pollack;William A. Wulf	1975		10.1145/800213.806531	real-time computing;mechanism;resource allocation;computer science;operating system;distributed computing;separation of mechanism and policy;scheduling;computer security;paging	OS	-52.642293492778855	55.58277116874033	198170
5f010dae38b54015adfa6e42b7e042fe923e9d93	polygraph: automatically generating signatures for polymorphic worms	databases;protocols;availability;web and internet services;obfuscated code;return addresses;digital signatures;false negative;digital signatures invasive software string matching protocols;intrusion detection;signature generation system polygraph polymorphic worms multiple disjoint content substrings multiple invariant substrings payload protocol framing return addresses obfuscated code automatic generation intrusion detection systems;automatic generation;telecommunication traffic;col;monitoring;multiple invariant substrings;polygraph;signature generation system;polymorphism;intrusion detection systems;invasive software;payloads;ip networks;payload;protocol framing;false positive;string matching;payloads intrusion detection telecommunication traffic web and internet services ip networks protocols availability databases data security monitoring;multiple disjoint content substrings;polymorphic worms;data security	It is widely believed that content-signature-based intrusion detection systems (IDS) are easily evaded by polymorphic worms, which vary their payload on every infection attempt. In this paper, we present Polygraph, a signature generation system that successfully produces signatures that match polymorphic worms. Polygraph generates signatures that consist of multiple disjoint content substrings. In doing so, Polygraph leverages our insight that for a real-world exploit to function properly, multiple invariant substrings must often be present in all variants of a payload; these substrings typically correspond to protocol framing, return addresses, and in some cases, poorly obfuscated code. We contribute a definition of the polymorphic signature generation problem; propose classes of signature suited for matching polymorphic worm payloads; and present algorithms for automatic generation of signatures in these classes. Our evaluation of these algorithms on a range of polymorphic worms demonstrates that Polygraph produces signatures for polymorphic worms that exhibit low false negatives and false positives.	algorithm;antivirus software;bounce address;framing (world wide web);intrusion detection system;obfuscation (software);substring	James Newsome;Brad Karp;Dawn Xiaodong Song	2005	2005 IEEE Symposium on Security and Privacy (S&P'05)	10.1109/SP.2005.15	intrusion detection system;payload;real-time computing;computer science;world wide web;computer security	Security	-58.56008602006538	59.885726062529166	198301
9ce3af30f96b2c3f38f9fbe52930a4b2e77d9d96	automated generation of colluding apps for experimental research		Colluding apps bypass the security measures enforced by sandboxed operating systems such as Android. App collusion can be a real threat in cloud environments as well. Research in detecting and protecting against app collusion requires a variety of colluding apps for experimentation. Presently the number of (real or manually crafted) apps available to researchers is very limited. In this paper we propose a system called Application Collusion Engine (ACE) to automatically generate combinations of colluding and non-colluding Android apps to help researchers fairly evaluate different collusion detection and protection methods. Our initial implementation includes a variety of components that enable the system to create more than 5,000 different colluding and non-colluding app sets. ACE can be extended with more functional components to create even more colluding apps. To show the usefulness of our system, we have applied different risk evaluation and collusion detection methods to the created set of colluding apps.	ace;android;covert channel;expectation propagation;experiment;external storage;mobile app;operating system;sandbox (computer security);sensor;threat (computer);transmitter	Jorge Blasco;Thomas M. Chen	2017	Journal of Computer Virology and Hacking Techniques	10.1007/s11416-017-0296-4	collusion;malware;cloud computing;internet privacy;android (operating system);computer security;sandbox (computer security);computer science	Security	-57.575535943197934	59.90619454168381	198410
e9b32a3afcb5332bd53864ebdacdd82bce933c8a	seeing through the same lens: introspecting guest address space at native speed		Software-based MMU emulation lies at the heart of outof-VM live memory introspection, an important technique in the cloud setting that applications such as live forensics and intrusion detection depend on. Due to the emulation, the software-based approach is much slower compared to native memory access by the guest VM. The slowness not only results in undetected transient malicious behavior, but also inconsistent memory view with the guest; both undermine the effectiveness of introspection. We propose the immersive execution environment (ImEE) with which the guest memory is accessed at native speed without any emulation. Meanwhile, the address mappings used within the ImEE are ensured to be consistent with the guest throughout the introspection session. We have implemented a prototype of the ImEE on Linux KVM. The experiment results show that ImEE-based introspection enjoys a remarkable speed up, performing several hundred times faster than the legacy method. Hence, this design is especially useful for realtime monitoring, incident response and high-intensity introspection.	address space;algorithm;cloud computing;computer security incident management;emulator;introspection;intrusion detection system;linux;memory management unit;prototype;speedup	Siqi Zhao;Xuhua Ding;Wen Xu;Dawu Gu	2017			computer security;address space;computer science;internet privacy	Security	-54.784743533481404	57.34911610815598	198596
2433632a4091de03fd9538ac38a842db63ded7f4	automatic testing of program security vulnerabilities	databases;libraries;software;manuals;software testing;test automation;information security;application software;sql;automatic testing;test generation method;format string bug;sql program debugging program testing security of data;automatic testing automation information security buffer overflow application software libraries java engines databases data security;cross site scripting security testing vulnerabilities buffer overflow sql injection format string bug;program security;engines;structured query language;program testing;vulnerabilities;buffer overflow;program security testing;sql injection;test generation;widespread exploitation;structured query language program security widespread exploitation program security testing test generation method sql injection format string bug cross site scripting;program debugging;security testing;security;security of data;cross site scripting;java;data security;automation	Vulnerabilities in applications and their widespread exploitation through successful attacks are common these days. Testing applications for preventing vulnerabilities is an important step to address this issue. In recent years, a number of security testing approaches have been proposed. However, there is no comparative study of these work that might help security practitioners select an appropriate approach for their needs. Moreover, there is no comparison with respect to automation capabilities of these approaches. In this work, we identify seven criteria to analyze program security testing work. These are vulnerability coverage, source of test cases, test generation method, level of testing, granularity of test cases, testing automation, and target applications. We compare and contrast prominent security testing approaches available in the literature based on these criteria. In particular, we focus on work that address four most common but dangerous vulnerabilities namely buffer overflow, SQL injection, format string bug, and cross site scripting. Moreover, we investigate automation features available in these work across a security testing process. We believe that our findings will provide practical information for security practitioners in choosing the most appropriate tools.	buffer overflow;cross-site scripting;libressl;printf format string;sql injection;security testing;test case;uncontrolled format string;vulnerability (computing)	Hossain Shahriar;Mohammad Zulkernine	2009	2009 33rd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2009.191	vulnerability management;test strategy;sql;security through obscurity;security bug;computer science;information security;operating system;database;programming language;secure coding;security testing;world wide web;computer security	SE	-57.72704830744714	56.85954016777694	198854
d06494ec3479f073d81b2be0b8d05885779b86c4	white-box cryptography revisited: space-hard ciphers	trojans;mass surveillance;decomposition;drm;code lifting;pay tv;key extraction;white box cryptography;malware;space hard cipher	The need for software security in untrusted environments is ever increasing. White-box cryptography aims to ensure the security of cryptographic algorithms when the attacker has full access to their implementations. However, there is no secure white-box implementation of standard block ciphers such as DES and AES known to date: All published techniques have been practically broken. In this paper, we revisit white-box cryptography and propose a family of white-box secure block ciphers SPACE with several novel features. The design of SPACE is such that the key-extraction security in the white box reduces to the well-studied problem of key recovery for block ciphers (AES in our example) in the standard black-box setting. Moreover, to mitigate code lifting, we introduce the notion of space hardness. It measures the difficulty of compressing the white-box implementation of a cipher, and quantifies security against code lifting by the amount of code that needs to be extracted from the implementation by a white-box attacker to maintain its functionality. SPACE includes several variants with different white-box code sizes. Therefore, it is applicable to a wide range of environments and use cases. One of the variants called N-SPACE can be implemented with different code sizes while keeping the cipher itself unchanged.  SPACE offers a high level of space hardness: It is difficult to find a compact but still functional representation of SPACE given its white-box implementation. This property has several useful consequences for applications. First, it gets more challenging for a DRM attacker (e.g. in a pay TV setting) to scale a code-lifting attack and to distribute the break. Moreover, this paves the way for mass-surveillance resistant cryptography: If a large proportion of users dedicates a significant part of their computers' storage (e.g. HDD) to white-box SPACE implementations, it will be much more complex or even infeasible for governmental agencies to deal with the keys of all users simultaneously due to the limited storage available, forcing them to focus on targeted attacks instead. This consequence is especially important given Snowden's revelations on the extent of the mass surveillance practice by NSA and GCHQ. Finally, the usage of SPACE ciphers can mitigate the damage of having malware in security-critical systems such as networks processing top-secret data: As those are typically insulated from the Internet, the capacity of the communication channel from inside to outside the system is often limited, making it infeasible for Trojans to transmit the necessary key material.	algorithm;application security;black box;block cipher;channel (communications);computer;cryptography;digital rights management;function representation;hard disk drive;high-level programming language;key escrow;lambda lifting;malware;snowden;trojan horse (computing);white box (software engineering);whole earth 'lectronic link	Andrey Bogdanov;Takanori Isobe	2015		10.1145/2810103.2813699	related-key attack;computer science;theoretical computer science;s-box;malware;internet privacy;decomposition;computer security	Security	-51.15488207067201	56.86003199218585	198925
210bdf31675144a3d406eb5a20c85f4aa8ec2c38	tracer: enforcing mandatory access control in commodity os with the support of light-weight intrusion detection and tracing	mandatory access control;intrusion detection;information flow;operating system;malware;compatibility;access control;usability	Enforcing a practical Mandatory Access Control (MAC) in a commercial operating system to tackle malware problem is a grand challenge but also a promising approach. The firmest barriers to apply MAC to defeat malware programs are the incompatible and unusable problems in existing MAC systems. To address these issues, we start our work by analyzing the technical details of 2,600 malware samples one by one and performing experiments over two types of MAC enforced operating systems. Based on the preliminary studies, we design a novel MAC model incorporating intrusion detection and tracing in a commercial operating system, named Tracer, in order to disable malware on hosts while offering good compatibility to existing software and good usability to common users who are not system experts. The model conceptually consists of three actions: detecting, tracing and restricting suspected intruders. One novelty is that it leverages light-weight intrusion detection and tracing techniques to automate security label configuration that is widely acknowledged as a tough issue when applying a MAC system in practice. The other is that, rather than restricting information flow as a traditional MAC does, it traces intruders and restricts only their critical malware behaviors, where intruders represent processes and executables that are potential agents of a remote attacker. Our prototyping and experiments on Windows show that Tracer can effectively defeat all malware samples tested via blocking malware behaviors while not causing a significant compatibility problem.	blocking (computing);executable;experiment;grand challenges;intrusion detection system;malware;mandatory access control;microsoft windows;operating system;sensor;tracing (software);usability	Zhiyong Shan;Xin Wang;Tzi-cker Chiueh	2011		10.1145/1966913.1966932	intrusion detection system;information flow;usability;computer science;access control;operating system;cryptovirology;distributed computing;malware;compatibility;computer security	Security	-55.56263449585351	57.92977439309249	199001
1ed0fa77f37e3c6aec262b2358fc34c9c871537b	hijacking activity technology analysis and research in android system		Since Android is open, as many as people begin to pay close attention to Android, such as the program developer, the users. In this paper, on the basis of an Android application program, we expound the basic characteristics of the Activity, Including the life cycle of Activity. According to the characteristics of the Activity, we focus on explaining the management mechanism and the switch bug of the Activity. At the end we describe the exploits of the Activity and finish the Activity hijack.		Yunlong Ren;Yue Li;Fangfang Yuan;Fangjiao Zhang	2013		10.1007/978-3-662-43908-1_6	computer security;android (operating system);exploit;computer science	Theory	-61.1541550272439	54.85709381479578	199133
f31e3ef8a52bb6bf4c133c14be985b651ade565e	appwrapping providing fine-grained security policy enforcement per method unit in android		Enterprise mobility management (EMM) solution is widely used to securely protect confidential information stored on an individual's smartphone, while increasing the efficiency because of BYOD policy. The application wrapping (Appwrapping) technology is one way to be applied EMM solutions, by modifying binary applications without the original source code. In the past, Appwrapping was performed to control permissions or APIs to protect privacy on Android. This method is applied collectively to the whole section, not a specific section of the app, so it is difficult to control the section (flow) desired by the user or the manager. In addition, system overhead can occur because the control is applied to the whole section of the app. In this paper, we propose a method to insert an additional security policy code at a certain interval position in the intermediate code of a binary app, so that it can be controlled at a specific interval rather than the whole interval of the app. The proposed method extracts and saves the security policy intermediate code and the related file in advance and then adds the security policy code to the specific method on the intermediate code of the specific activity acquired by decompiling the target app. Finally, the additional security policy code is modified to avoid errors caused by the additional code. We create an automation tool for performance verification, experiment with five commercial office apps, and confirm that the apps work properly with the added EMM security functions.	android;bring your own device;confidentiality;decompiler;overhead (computing);smartphone;wrapping (graphics)	Sung-Hoon Lee;Seung-Hyun Kim;Soo-Hyung Kim;Seung-Hun Jin	2017	2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2017.25	information security;computer science;real-time computing;automation;enterprise mobility management;specific activity;source code;android (operating system);enforcement;computer security;security policy	SE	-55.171387925556985	58.556748681093126	199231
c399fbba1c987939bce9e08604929df314e13823	application of artificial intelligence technology in computer network security		Since the 21st century, the degree of informatization has been greatly accelerated, which has brought great convenience to people’s life. Moreover the problem of computer network security has become a crucial point in the development of information technology. How to protect network security and safeguard their own rights and interests are the problems faced by network security. Artificial intelligence technology is also developing with the progress of information technology. This study proposed the application of artificial intelligence in computer safety protection by combining artificial intelligence with computer network security. Artificial intelligence based Trojan horse detection model was established and tested. The experimental results demonstrated that the proposed artificial intelligence model could accurately and rapidly detect out Trojan horse program, with a low false alarm rate and missing alarm rate, suggesting favorable performance. This work provides a reference for the application of artificial intelligence technology in computer network security.	applications of artificial intelligence;computer security;information processing;network security policy;nonlinear system;security management;trojan horse (computing)	Jialiang Zhang	2018	I. J. Network Security		computer security;network security;computer science	AI	-51.184056765554566	60.24573296949833	199244
d8caad73e021a51b7bbf074a25c8369bb3542a3b	the vaccine framework for building dlp systems		Conventional Data Leakage Prevention (DLP) systems suffer from the following major drawback: Privacy policies that define what constitutes data leakage cannot be seamlessly defined and enforced across heterogeneous forms of communication. Administrators have the dual burden of: (1) manually selfinterpreting policies from handbooks to specify rules (which is error-prone); (2) extracting relevant information flows from heterogeneous communication protocols and enforcing policies to determine which flows should be admissible. To address these issues, we present the Verifiable and ACtionable Contextual Integrity Norms Engine (VACCINE), a framework for building adaptable and modular DLP systems. VACCINE relies on (1) the theory of contextual integrity to provide an abstraction layer suitable for specifying reusable protocolagnostic leakage prevention rules and (2) programming language techniques to check these rules against correctness properties and to enforce them faithfully within a DLP system implementation. We applied VACCINE to the Family Educational Rights and Privacy Act and Enron Corporation privacy regulations. We show that by using contextual integrity in conjunction with verification techniques, we can effectively create reusable privacy rules with specific correctness guarantees, and check the integrity of information flows against these rules. Our experiments in emulated enterprise settings indicate that VACCINE improves over current DLP system design approaches and can be deployed in enterprises involving tens of thousands of actors.	abstraction layer;cognitive dimensions of notations;correctness (computer science);data loss prevention software;digital light processing;emulator;experiment;formal verification;information leakage;privacy act (canada);privacy policy;programming language;spectral leakage;systems design	Yan Shvartzshnaider;Zvonimir Pavlinovic;Thomas Wies;Lakshminarayanan Subramanian;Prateek Mittal;Helen Nissenbaum	2017	CoRR		data mining;computer security;implementation;privacy policy;privacy law;computer science;communications protocol;correctness;modular design;abstraction layer;systems design	Security	-52.68215129991367	51.992440655718134	199637
25e8930dd98a3d9cff1c7154b2874148da597724	detecting covert timing channels with time-deterministic replay		This paper presents a mechanism called timedeterministic replay (TDR) that can reproduce the execution of a program, including its precise timing. Without TDR, reproducing the timing of an execution is difficult because there are many sources of timing variability – such as preemptions, hardware interrupts, cache effects, scheduling decisions, etc. TDR uses a combination of techniques to either mitigate or eliminate most of these sources of variability. Using a prototype implementation of TDR in a Java Virtual Machine, we show that it is possible to reproduce the timing to within 1.85% of the original execution, even on commodity hardware. The paper discusses several potential applications of TDR, and studies one of them in detail: the detection of a covert timing channel. Timing channels can be used to exfiltrate information from a compromised machine; they work by subtly varying the timing of the machine’s outputs, and it is this variation that can be detected with TDR. Unlike prior solutions, which generally look for a specific type of timing channel, our approach can detect a wide variety of channels with high accuracy. Disciplines Computer Engineering | Computer Sciences Comments 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI), Broomfield, CO, October 2014. Author(s) Ang Chen, W. Brad Moore, Hanjun Xiao, Andreas Haeberlen, Linh T.X. Phan, Micah Sherr, and Wenchao Zhou This conference paper is available at ScholarlyCommons: http://repository.upenn.edu/cis_papers/796 Detecting Covert Timing Channels with Time-Deterministic Replay	commodity computing;computer engineering;computer science;covert channel;entity–relationship model;heart rate variability;interrupt;java virtual machine;my life as a teenage robot;preemption (computing);prototype;replay attack;scheduling (computing);sensor;time-domain reflectometer;timing channel	Ang Chen;W. Brad Moore;Hanjun Xiao;Andreas Haeberlen;Linh T. X. Phan;Micah Sherr;Wenchao Zhou	2014			embedded system;real-time computing;computer hardware;computer science	OS	-54.3363989992871	55.314320467179186	199690
bafd2e88f2352bd44962dd82dd8c03bc5fbf698e	implementing chain of custody requirements in database audit records for forensic purposes		During forensic database investigations, audit records become a crucial evidential element; particularly, when certain events can be attributed to insider activity. However, traditional reactive forensic methods may not be suitable, urging the adoption of proactive approaches that can be used to ensure accountability through audit records whilst satisfying Chain of Custody (CoC) requirements for forensic purposes. In this paper, role segregation, evidence provenance, event timeliness and causality are considered as CoC requirements in order to implement a forensically ready architecture for the proactive generation, collection and preservation of database audit records that can be used as digital evidence for the investigation of insider activity. Our proposal implements triggers and stored procedures as forensic routines in order to build a vector-clock-based timeline for explaining causality in transactional events recorded in audit tables. We expect to encourage further work in the field of proactive digital forensics and forensic readiness; in particular, for justifying admissibility of audit records under CoC restrictions.	case preservation;causality;data manipulation language;database audit;database forensics;database trigger;gentoo linux;malware;requirement;sql;stored procedure;timeline;vector clock;while	Denys A. Flores;Arshad Jhumka	2017	2017 IEEE Trustcom/BigDataSE/ICESS	10.1109/Trustcom/BigDataSE/ICESS.2017.299	architecture;database audit;computer security;data mining;computer science;chain of custody;digital forensics;computer forensics;audit trail;digital evidence;audit	Security	-61.27706559258265	53.74715558239387	199788
3b0cdd6a64cbd79d208f5db40fa2f713fd038b2d	multilevel security and quality of protection		Constraining how information may flow within a system is at the heart of many protection mechanisms and many security policies have direct interpretations in terms of information flow and multilevel security style controls. However, while conceptually simple, multilevel security controls have been difficult to achieve in practice. In this paper we explore how the traditional assurance measures that are used in the network multilevel security model can be re-interpreted and generalised to provide the basis of a framework for reasoning about the quality of protection provided by a secure system configuration.	multilevel security;protection mechanism;security controls;system configuration	Simon N. Foley;Stefano Bistarelli;Barry O'Sullivan;John Herbert;Garret Swart	2006		10.1007/978-0-387-36584-8_8	security analysis	Security	-53.87633397062832	49.830428555910665	199881
58b8353967a22216e0b4d1004e84c4db283c4d4b	aggregating cvss base scores for semantics-rich network security metrics	computer network security;common vulnerability scoring system cvss base score aggregation semantics rich network security metrics security solutions effectiveness evaluation network vulnerabilities individual score semantics dependency relationships;measurement semantics authentication equations mathematical model vectors	A network security metric is desirable in evaluating the effectiveness of security solutions in distributed systems. Aggregating CVSS scores of individual vulnerabilities provides a practical approach to network security metric. However, existing approaches to aggregating CVSS scores usually cause useful semantics of individual scores to be lost in the aggregated result. In this paper, we address this issue through two novel approaches. First, instead of taking each base score as an input, our approach drills down to the underlying base metric level where dependency relationships have well-defined semantics. Second, our approach interprets and aggregates the base metrics from three different aspects in order to preserve corresponding semantics of the individual scores. Finally, we confirm the advantages of our approaches through simulation.	computer security;distributed computing;experiment;network security;simulation	Pengsu Cheng;Lingyu Wang;Sushil Jajodia;Anoop Singhal	2012	2012 IEEE 31st Symposium on Reliable Distributed Systems	10.1109/SRDS.2012.4	reliability engineering;computer science;theoretical computer science;network security;data mining;database;computer security;cvss	Security	-60.56350032538495	59.15552080869615	199996
