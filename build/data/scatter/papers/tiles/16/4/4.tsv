id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
00a5101406ecbe7aa85f2d4470a6cce5ddcaaa06	screen reader for windows based on speech output	graphic user interface	By analyzing this problem, this classification of blind computer users and of performances of technical aids does not appear entirely accurate. In fact, we can find a number of blind persons who prefer speech synthesis even though they are good Braille readers since, once they become practiced users, they appreciate the superior possibilities of effectiveness in interacting with the machine, and their hands free from reading tasks.	interaction;microsoft windows;performance;speech synthesis;user (computing)	Paolo Graziani;Bruno Breschi	1994		10.1007/3-540-58476-5_110	10-foot user interface;wallpaper;human–computer interaction;computer hardware;computer science;z-order;multimedia;multiple document interface	ML	-48.50179315928638	-43.26780272170074	42892
62ac9df32ba3fe42324ee99691e14c777a7cfdb3	a practical set of culture dimensions for global user-interface development	user interface development;cultural difference;interfase usuario;social interaction;interaction sociale;user interface;data collection;relacion hombre maquina;man machine relation;conducta social;interaccion social;social behavior;expert opinion;comportement social;interface utilisateur;user interface design;relation homme machine;cultural dimension	User-interface design is influenced by cultural differences. Cultures around the world have different patterns of social behavior and interaction that have led anthropologists and scientists of communication to develop culture models whose dimensions describe these differences. This paper describes an effort to collect expert opinion about these cultural dimensions and how they influence user-interface design. The goal was to determine the most important dimensions. Data collected from over 50 experts in the field of user-interface design are presented in this survey. This paper is an edited extract of a much longer thesis by one of the authors [Baumgartner].	compiler;content management system;diagram;internationalization and localization;list of toolkits;recommender system;semiconductor industry;software design;the magical number seven, plus or minus two;thomas baumgartner;user interface design;value (ethics)	Aaron Marcus;Valentina-Johanna Baumgartner	2004		10.1007/978-3-540-27795-8_26	user interface design;social relation;hofstede's cultural dimensions theory;human–computer interaction;social behavior;computer science;artificial intelligence;user interface;data collection	HCI	-60.99720886718087	-49.36750151841361	43065
056c9b76eb314776a2e1e143e1986fc5984b6a73	a comparison of speech and gui input for navigation in complex visualizations on mobile devices	speech input;user evaluation;mobile device;web service;modality;mobile interfaces;visualizer;graphic user interface;multimodal;network management	Mobile devices are ubiquitously used to access web applications. Multimodal mobile interfaces can offer advantages over less flexible approaches, in both usability and range of features. In this study we consider applying speech input to a web-based network management service. The key issue we are interested in is how to perform suitable multidimensional search through web-based interface on mobile devices. We present results from a pilot user evaluation, focusing on the comparison of a novel speech input method with the existing manual (GUI, Graphical User Interface) input for AT&T's Visualizer management service, on an iPhone. Speech input was experimentally shown to be as effective, more efficient, and preferred over GUI input by most users. We foresee that a multimodal approach may be preferable for many applications on mobile devices.	experiment;graphical user interface;input method;mobile device;multimodal interaction;usability;web application	Rui Zhang;Stephen C. North;Eleftherios Koutsofios	2010		10.1145/1851600.1851665	network management;web service;mobile search;mobile web;human–computer interaction;computer science;operating system;multimodal interaction;mobile device;graphical user interface;multimedia;world wide web	HCI	-49.57735767659832	-40.25530590060907	43166
4bf6725bd9d0acba2e7724adea09b559a71c82c0	a taxonomy in robot-assisted training: current trends, needs and challenges		In this paper, we present a taxonomy in Robot-Assisted Training; a growing body of research in Human-Robot Interaction which focuses on how robotic agents and devices can be used to enhance user's performance during a cognitive or physical training task. The proposed taxonomy includes a set of parameters that characterize such systems, in order to highlight the current research trends and needs for the design, development and evaluation of Robot-Assisted Training systems. Towards this direction, we review related taxonomies in Human Robot Interaction, as well as recent works and applications in Robot-Assisted Training. The motivation of this research is to identify and discuss issues and challenges, focusing on the personalization aspects of a Robot-Assisted Training system.	evolutionary taxonomy;human–robot interaction;personalization;robot	Konstantinos Tsiakas;Vangelis Karkaletsis;Fillia Makedon	2018		10.1145/3197768.3197787	personalization;human–computer interaction;training system;robot;computer science;cognition;human–robot interaction	HCI	-56.614312962011255	-49.51829931216867	43534
1299978e9c1adef9cd1adab064e411e167789f0b	peerassist: a p2p platform supporting virtual communities to assist independent living of senior citizens	social networking;elderly;peer to peer	This paper describes the system architecture and status of PeerAssist, an Ambient Assisted Living (AAL) project that aims at designing, implementing, and demonstrating a flexible Peer-to Peer (P2P) platform, which will allow elderly people (not necessarily familiar with information technology) to build virtual communities dynamically based on interests and needs they share. The PeerAssist technology platform will facilitate establishing on demand ad-hoc communities with friends, family, neighbors, caregivers, etc. The community building and the P2P interaction is achieved using information extracted from peer roles and profiles, context that describes the overall user environment, and the specific request initiated or service provided by a peer, all of which are represented semantically in a machine understandable form. An end-user request (query) is first represented semantically and then routed through the network in order to find semantically matching peers. PeerAssist will find many applications including (but not limited to): i) peer-driven organization of social activities (such as going out, going to the movies, etc.), ii) soliciting peer help with housekeeping and other daily activities, iii) allowing caregivers and family members to receive alerts if certain periodic home activities of the elderly are interrupted. The selected peer-topeer platform exploits the system’s intelligence to provide connectivity at the network level optimized to efficiently serve the objectives of the system.	atm adaptation layer;focus group;graphical user interface;hoc (programming language);interrupt;peer-to-peer;routing;systems architecture;the movies;touchscreen;virtual community	Nikos I. Passas;Michael Fried;Elias S. Manolakos	2012		10.1007/978-3-642-35395-6_4	simulation;multimedia;world wide web;social network	HCI	-56.5834211208717	-43.700109714786336	43556
6ae2510b2675e9f1c8811a28423ade7fe6db2a75	haptic human–robot collaboration: comparison of robot partner implementations in terms of human-likeness and task performance	continuous human-likeness scale;feedback model;task performance;haptic human-robot collaboration;continuous scale;feedforward model;closer interaction;continuous bilateral information;proposed measure;robot partner implementation;different implementation;haptic interaction partner;physical human-robot interaction	In the past, working spaces of humans and robots were strictly separated, but recent developments have sought to bring robots into closer interaction with humans. In this context, physical human–robot interaction represents a major challenge, as it is based on continuous bilateral information and energy exchanges which result in a mutual adaptation of the partners. To address the challenge of designing robot collaboration partners, making them as human-like as possible is an approach often adopted. In order to compare different implementations with each other, their degree of human-likeness on a continuous scale is required. So far, the human-likeness of haptic interaction partners has only been studied in the form of binary choices. In this paper, we first introduce methods that allow measuring the human-likeness of haptic interaction partners on a continuous scale. In doing so, two subjective rating methods are proposed and correlated with a task performance measure. To demonstrate the applicability and validity of the proposed measures, they are applied to a joint kinesthetic manipulation task and used to compare two different implementations of a haptic interaction partner: a feedforward model based on force replay, and a feedback model. This experiment demonstrates the use of the proposed measures in building a continuous human-likeness scale and the interpretation of the scale values achieved for formulating guidelines for future robot implementations.	bilateral filter;experiment;feedforward neural network;futures studies;haptic technology;humans;human–robot interaction;interaction design;nonlinear system;r. daneel olivaw;robot	Daniela Feth;Raphaela Groten;Angelika Peer;Martin Buss	2011	PRESENCE: Teleoperators and Virtual Environments	10.1162/pres_a_00042	simulation;human–computer interaction;artificial intelligence	Robotics	-49.40993607527354	-52.02554546088374	43988
e7c6f5238ed9c4fd681aa076a36936d38964fc89	viability of magazines for stimulating social interactions in nursing homes		Social isolation and loneliness have a strong negative impact on health and happiness. The correlation is present at all ages, but the risk of loneliness and isolation is particularly high in later life and when transitioning to residential care settings, where keeping in touch with the family, making new friends and integrating with the community in a new social context can be very challenging. In this note we report on our preliminary studies on the opportunity and feasibility of using custom, printed magazines for increasing feelings of connectedness and promoting meaningful interactions in nursing homes. The content and layout for the magazine are generated in an automatic or semi-automatic way and emphasize aspects that could lead to discovering connections or starting conversations. Initial findings point to the potential for such a magazine and lead to content guidelines that we elaborate in the paper.	interaction	Valentina Caforio;Marcos Báez;Fabio Casati	2017		10.1007/978-3-319-67687-6_6	social isolation;loneliness;social connectedness;social environment;computer science;feeling;happiness;nursing	ML	-59.699168892582975	-39.9079911985453	44017
16993b40790797f1c4a36e9128386e7c7e0253b4	europe leads the way in assistive robots for the elderly		Purpose#R##N##R##N##R##N##R##N##R##N#This paper aims to provide details of European research projects and product developments involving robots that can assist the ageing population.#R##N##R##N##R##N##R##N##R##N#Design/methodology/approach#R##N##R##N##R##N##R##N##R##N#Following an introduction, the role of assistive robots and research into the nature of the human–robot interaction are considered. The paper then discusses a selection of European research projects and a number of companies producing or developing assistive robots. Finally, brief conclusions are drawn.#R##N##R##N##R##N##R##N##R##N#Findings#R##N##R##N##R##N##R##N##R##N#In recognition of the fact that the growing, ageing population has needs that place an unsustainable burden on carers and healthcare providers, Europe is investing heavily in assistive robots. Many European Union-funded, collaborative projects have been conducted and several continue today which build on the extensive body of earlier research. Significant progress is being made, and assistive robot research has moved on from purely technological developments to field trials involving real people in realistic environments. Several products exist or are at an advanced stage of development and have often benefited or arisen from these projects. Europe is in a very strong position to capitalise on this emerging market opportunity.#R##N##R##N##R##N##R##N##R##N#Originality/value#R##N##R##N##R##N##R##N##R##N#This provides a detailed insight into European assistive robot development activities.	assistive technology;microsoft forefront;nl (complexity);new product development;robot;software deployment;the quality of life	Robert Bogue	2017	Industrial Robot	10.1108/IR-02-2017-0041	simulation;engineering;artificial intelligence;mechanical engineering	Robotics	-61.858813384069826	-42.217673719361144	44189
ab510976a2198e15d0f15e985305a5548865c373	virtual reality and its uses: a systematic literature review	overview;virtual reality;systematic literature review	Virtual reality (VR) has challenged the way we perceive the world and user experience is being explored to achieve an immersive and effective experience. However, the commercial effects and impact of this technology lacks sufficient research. It is hence uncertain which role virtual reality has in information systems nowadays. This systematic literature review (SLR) focuses on the commercial impact of virtual reality and which field of study this technology is most used. To answer this question, a reference manual was used from literature review protocol standards and carried out. Results show that VR systems have a wide specter of applications and a significant potential for revolutionizing our everyday life in the digital world.	information system;systematic review;user experience;virtual reality	Kristina Berntsen;Ricardo Colomo Palacios;Eduardo Herranz	2016		10.1145/3012430.3012553	artificial reality;simulation;human–computer interaction;engineering;multimedia	HCI	-61.98316970728584	-44.098533331417904	44199
32f979945f00b34a6f052ee793388830dd663f38	taking email to task: the design and evaluation of a task management centered email tool	ethnography;user study;system design;task management	Email has come to play a central role in task management, yet email tool features have remained relatively static in recent years, lagging behind users? evolving practices. The Taskmaster system narrows this gap by recasting email as task management and embedding task-centric resources directly in the client. In this paper, we describe the field research that inspired Taskmaster and the principles behind its design. We then describe how user studies conducted with ?live? email data over a two-week period revealed the value of a task-centric approach to email system design and its potential benefits for overloaded users.	email;field research;function overloading;systems design;usability testing	Victoria Bellotti;Nicolas Ducheneaut;Mark Howard;Ian Smith	2003		10.1145/642611.642672	computer science;knowledge management;multimedia;ethnography;world wide web;systems design	HCI	-60.66080005155553	-42.03065825763131	44285
e82d8ee86533073cc5877380f6c0687d05e7963a	toward electroencephalographic profiling of player motivation: a survey		Understanding and profiling player motivation complements and extends research on gameflow, player profiling, and game artificial intelligence, which helps us design entertaining games. However, automated identification of a player’s motive profile remains an open challenge. An emerging technology that shows promise as a novel technique for identifying cognitive phenomena is electroencephalography (EEG). This paper begins with a survey of literature applying EEG to measure cognitive characteristics relevant to player motivation types. Then we present conceptual models that link motivation theory to mental states that can be identified using EEG including emotion, risk-taking, and social attitudes. We conclude this paper by examining the research challenges associated with using EEG to validate these models.	artificial intelligence (video games);electroencephalography;experiment;mental state;pc game;simulation;theory	Xuejie Liu;Kathryn E. Merrick;Hussein A. Abbass	2018	IEEE Transactions on Cognitive and Developmental Systems	10.1109/TCDS.2017.2726083	conceptual model;human–computer interaction;machine learning;artificial intelligence;motif (music);computer science;emerging technologies;profiling (computer programming);electroencephalography;motivation theory;multimedia;cognition;cognitive neuroscience of visual object recognition	HCI	-57.17669450677994	-46.265866612901945	44412
2ee10d046eba6a361f65158f135de2d55f925654	identification of web usability problems and interaction patterns with the realeyes-ianalyzer	tratamiento automatico;mouse;sistema interactivo;interfase usuario;empirical study;navegacion informacion;web usability;mammalia;usability testing;red www;user interface;usability study;navigation information;reseau web;information browsing;vertebrata;rodentia;raton;systeme conversationnel;automatic processing;internet;interactive system;souris;interaction pattern;utilisabilite;user interface evaluation;world wide web;interface utilisateur;web browsing;eye tracking;usabilidad;traitement automatique;usability;automatic data processing	The focus of our paper is on managing and representing the huge amount of performance data coming from quantitative usability studies which are considered an important source needed to specify usability problems. The developed RealEYES-iAnalyzer is a tool which supports the evaluator of an interactive system by automatic data-processing and provides an expressive and effective data-playback. We carried out an empirical study with 36 test participants using the RealEYES-iAnalyzer during a web-browsing session. The measurement results show different patterns of mouse-/gaze behaviour and allowed us to draw hypotheses about the phenomenology of interaction problems.	web usability	Karina Oertel;Oliver Hein	2003		10.1007/978-3-540-39929-2_6	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;usability;human–computer interaction;computer science;database;multimedia;heuristic evaluation;world wide web;usability lab;usability inspection	HCI	-62.03934415926586	-48.79380267929785	44563
1849ee5bdbc576f8ad117241d345752fdfa22147	communityboard 2: mediating between speakers and an audience in computer network discussions	pragmatics;semantics;computer network;agent communication languages	Discussions on computer networks have become increasingly popular. People subscribe to several mailing lists and/or Usenet newsgroups. Discussions using these media are convenient because users are able to express their opinions at any time at the office or home. However, there are few methods that sufficiently support a user’s understanding of what is being discussed or support a sharing of opinions in the discussion group. Thus, it is necessary to make agents that support discussions on computer networks. In discussions on networks, it is often difficult to grasp the outline of a discussion, because there are many messages with various topics and their relations are not obvious. Providing tools that consider only a single participant’s viewpoint does not seem to work well. This is because a discussion is built up by all participants in the discussion group. Let us suppose that a participant wants to post two messages; one is about a romantic movie and the other is about a horror movie. Also suppose that most of the other participants want to read his opinion on the romantic movie but do not want to read his opinion on the horror movie. In this case, it is better that he posts the one on the horror movie at a different discussion group. This example demonstrates that discussion supporting-agents should mediate between speakers’ demand (what they want to talk about and how they want to talk about it) and an audience’s demand (what kind of messages they want to listen to). In this paper, we describe a social meeting system called CommunityBoard 2. Our system visualizes a discussion structure by displaying persons, topics, and the importance of messages in an integrated manner. The visualization is designed to direct a writer’s attention to a discussion group where other participants would want to read his/her opinion. This facilitates understanding in discussions and assists with further discussions.	usenet	Shigeo Matsubara;Takeshi Ohguro;Fumio Hattori	1999		10.1145/301136.301239	natural language processing;computer science;semantics;pragmatics	HCI	-57.6511568125555	-39.43822040391766	44576
378d3c304f778c494742b44392613a56a64fc008	where is “here” in nested environments? location accessibility from different sources	spatial mental modes;spatial information source;environment switching;spatial scales;information sources;spatial scale;best practice;map learning;spatial updating;spatial information	Abstract In nested environments, “here” can be different places, depending on the spatial scale. Although people mentally update surrounding locations as they move (spatial updating) does location accessibility (of “here”) change as a function of environment scale and information source? Participants learned two environments, a room nested within a campus, either through navigation or via maps. After updating with respect to one environment their knowledge of both environments was tested. People more accurately represented and accessed proximal environment (room) following navigation and remote environment (campus) after map learning. These results have implications for best practice in representing environments of different scales.		A. Reyyan Bilge;Holly A. Taylor	2010	Spatial Cognition & Computation	10.1080/13875861003754009	simulation;spatial ecology;data mining;spatial analysis;communication;best practice	HCI	-56.88397408855855	-41.04380004942419	44861
0ef3e6b4fb37b8d38e7b6c5231942b11b7b2c701	drawing the city: differing perceptions of the urban environment	location based services;urban environment;urban informatics;location based service;mobile apps;cities;statistical analysis;correlated data	In building location-based services, it is important to present information in ways that fit with how individuals view and navigate the city. We conducted an adaptation of the 1970s Mental Maps study by Stanley Milgram in order to better understand differences in people's views of the city based on their backgrounds and technology use. We correlated data from a demographic questionnaire with the map data from our participants to perform a first-of-its-kind statistical analysis on differences in hand-drawn city maps. We describe our study, findings, and design implications for location-based services.	location-based service;map;milgram experiment;the stanley parable	Frank Bentley;Henriette Cramer;William A. Hamilton;Santosh Basapur	2012		10.1145/2207676.2208282	simulation;computer science;location-based service;multimedia	HCI	-56.715930636536314	-41.05628374934241	45125
5e3814997537c1582076bfbf9f43e2912ae65d27	enlightening a co-located community with a semi-public notification system	notification systems;notification system;lessons learned;awareness;public space;ubiquitous displays	This work seeks to strengthen interaction within a research community through a centrally-located physical device that presents online presence information in a semi-public space. The device uses a map metaphor to represent a set of connected labs. As people move within the lab, those who wish to interact with lab users can use the display to guide their interaction approaches, by supporting educated guesses as to arrivals, departures, and work patterns. The paper reports on the lessons learned about the device's characteristics, and provides anecdotes and observations on ways in which this type of device can improve communication and enhance community.	notification system;peripheral;presence information;semiconductor industry	Goldie B. Terrell;D. Scott McCrickard	2006		10.1145/1180875.1180879	simulation;awareness;human–computer interaction;multimedia;world wide web	HCI	-56.37405469980854	-41.69289095019835	45653
348a4ce546b16fe9c6b26d9a31de99c1dc30b654	pirates: proximity-triggered interaction in a multi-player game	social interaction;handheld computer;proximity;physical environment;wireless computer games;handheld computers;computer game	We show how proximity-sensing technology can be integrated into computer game design to provide richer game experiences in social settings. To explore the theme of proximity-triggered interaction, we have constructed Pirates! -- a multi-player, wireless computer game for handheld computers, played throughout a physical environment. The players' physical locations in the environment trigger game events.	computer;mobile device;pc game;sid meier's pirates!;video game design	Jennica Falk;Peter Ljungstrand;Staffan Björk;Rebecca Hansson	2001		10.1145/634067.634140	video game design;game design;social relation;simulation;human–computer interaction;computer science;game mechanics;game art design;game developer;multimedia;game design document;distance;video game development	HCI	-56.27555149574418	-39.83613646790582	45853
1452f604db8b2d390ff90d85a035d40204ab0819	investigating communicative feedback phenomena across languages and modalities	jamforande sprakvetenskap och lingvistik;general language studies and linguistics	This thesis deals with human communicative behaviour related to feedback, analysed across languages (Italian and Swedish), modalities (auditory versus visual) and different communicative situations (human-human versus human-machine dialogues). The aim of this study is to give more insight into how humans use communicative behaviour related to feedback and at the same time to suggest a method to collect valuable data that can be useful to control facial and head movements related to visual feedback in synthetic conversational agents. The study of human communicative behaviour necessitates the good quality of the materials under analysis, the support of reliable software packages for the audio-visual analysis and a specific coding scheme for the annotation of the phenomena under observation. The materials used for the investigations presented in this thesis span from spontaneous conversations video recorded in real communicative situations, and semi-spontaneous dialogues obtained with different eliciting techniques, such as map-task and information-seeking scenarios, to a specific corpus of controlled interactive speech collected by means of a motion capture system. When motion caption is used it is possible to register facial and head movements with a high degree of precision, so as to obtain valuable data useful for the implementation of facial displays in talking heads. A specific coding scheme has been developed, tested and used to annotate feedback. The annotation has been carried out with the support of different available software packages for audio-visual analysis. The procedure followed in this thesis involves initial analyses of communicative phenomena in spontaneous human-human dialogues and human-machine interaction, in order to learn about regularities in human communicative behaviour that could be transferred to talking heads, then, for the sake of reproduction in talking heads, the investigation includes more detailed analyses of data collected in a lab environment with a novel acquisition set-up that allows capturing the dynamics of facial and head movements. Finally the possibilities of transferring human communicative behaviour to a talking face are discussed and some evaluation paradigms are illustrated. The idea of reproducing human behaviour in talking heads is based on the assumption that the reproduction of facial displays related to communicative phenomena such as turn management, feedback production and expression of emotions in embodied conversational agents, might result in the design of advanced systems capable of effective multi-modal interactions with humans.	categorization;computer;continuation;dialog system;dyadic transformation;eset nod32 antivirus;embodied agent;feedback;human–computer interaction;information seeking;interrupt;meadow;modal logic;modality (human–computer interaction);motion capture;pervasive informatics;programming paradigm;regular expression;semiconductor industry;smoothing;speech synthesis;spontaneous order;synthetic intelligence;unfolding (dsp implementation)	Loredana Cerrato	2007			psychology;natural language processing;linguistics;communication	HCI	-52.20491640874299	-47.362072469079735	46009
230c3900260df1c8342fc333120689737bb24c4f	designing for the living room: long-term user involvement in a living lab	living lab;long term user study;participatory design;domestic domain	Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants' motivation, establishment of a trust relationship, and the coordination of collaboration.	living lab	Corinna Ogonowski;Benedikt Ley;Jan Heß;Lin Wan;Volker Wulf	2013		10.1145/2470654.2466205	simulation;human–computer interaction;computer science;knowledge management;living lab	HCI	-60.95187744459941	-40.830569041136656	46358
3da979fcef6b025a8cb0acf7f6615ab6392d7f45	homer: an interactive system for home based stroke rehabilitation		Delivering long term, unsupervised stroke rehabilitation in the home is a complex challenge that requires robust, low cost, scalable, and engaging solutions. We present HOMER, an interactive system that uses novel therapy artifacts, a computer vision approach, and a tablet interface to provide users with a flexible solution suitable for home based rehabilitation. HOMER builds on our prior work developing systems for lightly supervised rehabilitation use in the clinic, by identifying key features for functional movement analysis, adopting a simplified classification assessment approach, and supporting transferability of therapy outcomes to daily living experiences through the design of novel rehabilitation artifacts. A small pilot study with unimpaired subjects indicates the potential of the system in effectively assessing movement and establishing a creative environment for training.	computer vision;experience;interactivity;scalability;tablet computer	Aisling Kelliher;Jinwoo Choi;Jia-Bin Huang;Thanassis Rikakis;Kris M. Kitani	2017		10.1145/3132525.3134807	human–computer interaction;transferability;simulation;rehabilitation;computer science;stroke	HCI	-50.463125601567555	-45.90251583597438	46441
b81a2004f790b515efb4eb801761b981c159bb77	mobile cognition: balancing user support and learning	spatially aware mobile devices;mobile eye tracking;mobile decision making;mobile cognition	People engage in mobile decision-making on a daily basis. Spatially aware mobile devices have the potential to support users in spatio-temporal decision situations by augmenting their cognitive abilities or compensating for their deficiencies. In many cases though, this technology has a negative impact on people's spatial learning of the environment, such as during wayfinding. In this position paper we argue that mobile cognition must strive for solutions that find the right balance between immediate goals and longer-term objectives such as spatial learning.	cognition;mobile device	Martin Raubal	2015		10.1145/2786567.2794321	simulation;multimedia	HCI	-57.8160011252434	-51.5720343741342	46467
6f1d10213d9fb0f2034fbefba4f44dabd99fa618	five enablers for mobile 2.0	location based computing;mobile device;internet commons;squirrel system invisible computing mobile 2 0 web 2 0 in situ computing;mobile computing internet;internet technology;browser based internet technology;internet;mobile 2 0;network connectivity;squirrel system;invisible computing;web 2 0;mobile 2 0 location based computing internet commons browser based internet technology web 2 0;in situ computing;mobile computing;liquid crystal displays context awareness pervasive computing calendars computer networks text recognition cameras organizing world wide web computer displays	Web 2.0 is a collection of browser-based Internet technologies that enables anyone with an inexpensive computer and a decent network connection to join what the author calls the Internet Commons - a place where users can create elaborate multimedia expressions of their thoughts, opinions, and feelings, as well as link to and comment on those creations. Mobile 2.0 is being heralded as a successor to Web 2.0, extending its capabilities to mobile devices while coping with their limitations and leveraging the opportunities of location-based computing.	internet;mobile 2.0;mobile device;web 2.0;web application	William G. Griswold	2007	Computer	10.1109/MC.2007.346	mobile search;the internet;mobile web;computer science;operating system;mobile device;multimedia;internet privacy;mobile computing;web 2.0;world wide web;computer security	HCI	-53.79187931098532	-40.68567482505782	46602
503e3155f100a9f6c9648bd3b39b986e37c8ecf8	tell me what you see, i will tell you what you remember	gaze data;recall;visual memory;learner modeling	Recommender systems usually rely on users' preferences. Nevertheless, there are many situations (e-learning, e-health) where recommendations should rather be based on their memory. So as to infer in real time and with low involvement what has been memorized by users, we propose in this paper to establish a link between gaze features and visual memory. We designed a user experiment where 24 subjects had to remember 72 images. In the meantime, we collected 18,643 fixation points. Among other metrics, our results show a strong correlation between the relative path angles and the memorized items.	recommender system;tell-tale;windows me	Florian Marchal;Sylvain Castagnos;Anne Boyer	2016		10.1145/2930238.2930265	computer vision;computer science;communication;social psychology	AI	-48.38810884395556	-51.42075593645776	46604
ebc67a9a4636fc2c13d2aa1298d05d4dcb05f6af	usability of educational software for visual impairment: a question of viewpoint	interfase usuario;vision disorder;user interface;blind;educational software;user assistance;consejo;assistance utilisateur;conseil;asistencia usuario;utilisabilite;visual impairment;interface utilisateur;council;usabilidad;educational technology;trouble vision;trastorno vision;usability;ciego;national research council;aveugle	The Italian National Research Council's Institute for Educational Technology and the David Chiossone Institute for the Blind have carried out a joint study that seeks to define criteria for evaluating the suitability of educational software in meeting the needs of the visually impaired. This study devotes due consideration to the particular educational context and to the needs of individual students, seen in a positive light as potentialities rather than limits. As a result, we have been able to define a series of characteristics related to analysis and method.	usability;viewpoint	Silvia Dini;Lucia Ferlino;Cristina Martinoli	2004		10.1007/978-3-540-27817-7_84	educational technology;simulation;usability;human–computer interaction;computer science;artificial intelligence;operating system;multimedia;educational software;user interface;computer security	HCI	-61.96615246528076	-48.49400965095758	46623
049cee57344bd7a951e31c77a54efff8048edc9c	beyond a visuocentric way of a visual web search clustering engine: the sonification of whatsonweb	search engine;usability evaluation;sonification;graph drawing;information visualization;accessibility;spatial representation;web search;usability;clustered data;digital divide	It is widely accepted that spatial representation is processed by an amodal system. Recent studies show that blind subjects have a better motion ability than sighted people in performing spatial exploration guided only by auditory cues. The sonification method offers an effective tool able to transmit graphic information, overcoming the digital divide risen by a visuocentric modality in which contents are conveyed. We present a usability evaluation aiming at investigate the interaction differences between both blind and sighted users while surfing WhatsOnWeb, a search engine that displays the information by using graph-drawing methods on semantically clustered data. We compare the visual presentation of three different layouts with the sonificated ones, demonstrating both qualitatively and quantitatively that blind and sighted users perform with no significant differences the interaction. These results remark that the digital divide could be decreased by going beyond the visuocentric way of the commonly adopted visual content representation.	cluster analysis;graph drawing;modality (human–computer interaction);sonification;usability;web search engine	Maria Laura Mele;Stefano Federici;Simone Borsci;Giuseppe Liotta	2010		10.1007/978-3-642-14097-6_56	computer vision;computer science;multimedia;world wide web	HCI	-48.760860276728614	-43.74085983979409	46741
bd0ff74036379221d9eab2bd194563c43ac25efc	effects of the display angle on social behaviors of the people around the display: a field study at a museum	social behavior;public display;museum;field study;display angle	In this paper, we investigate through a field study how the angles (horizontal, tilted, and vertical angles) of displays deployed in a public space (at a museum) impact the social behaviors of the people around the display. In the field study, we collected both quantitative and qualitative data of more than 700 museum visitors over a period of approximately three months. Findings of our study include the following: (1) the horizontal and vertical display angles have a higher honeypot effect, i.e., people interacting with a display attract other people, than the tilted display angle, (2) the vertical display angle, compared to the horizontal and tilted display angles, attracts several people to the display and encourages them to stay in the display space and share the space for a short period of time (88 seconds on average), and as a result, people frequently enter and leave the space with a display, and (3) display angles closer to the horizontal promotes the side-by-side arrangement, and display angles closer to the vertical promotes the L-shaped arrangement of F-formation. The findings in our study help design a public display deployed in museums and other public spaces.	field research;honeypot (computing);interaction	Junko Ichino;Kazuo Isoda;Tetsuya Ueda;Reimi Satoh	2016		10.1145/2818048.2819938	social science;simulation;social behavior;multimedia;sociology;field research	HCI	-55.84970719004837	-42.21185830021078	46845
ce37bc6b6508050ca5b5efae52bce0ba94f2bbfb	flexible shortcuts: designing a new speech user interface for command execution	hierarchical structure;evaluation method;speech user interface;functional structure;time achievement graph;probabilistic formulation;command and control;continuous keyword input;point of view;effective interaction	"""This paper proposes a new speech user interface for command execution called """"Flexible Shortcuts."""" With this approach, users can select any commands by using """"continuous keyword input,"""" a voice input method using a series of keywords related to the command. Keywords are defined by a hierarchically structured command set, called the """"functional structure."""" Two kinds of interactions are designed to support user-friendliness and effectiveness: interaction for exploration and interaction for the resolution of ambiguity. A probabilistic formulation for this approach is also considered. An experiment and objective evaluation method are designed so that the new interface for command execution can be compared with the conventional """"command and control"""" interface. A comparative experiment to measure the efficiency and usability is also conducted and reported in this paper. Experimental results show that the proposed approach is superior to the conventional approach from both objective and subjective points of view."""	input method;interaction;usability;user interface	Teppei Nakano	2008		10.1145/1358628.1358729	command and control;speech recognition;human–computer interaction;computer science;theoretical computer science;operating system;database;world wide web;interaction technique	HCI	-48.672641521227064	-44.78467050838554	46849
cb4121a5372f25fe1888f084ac76585041d7bd1e	adaptation rules for accessible media player interface	usixml;multimedia;standards;adaptation rules;maria;model based approach;model driven development;requirements;accessibility;graphical editor	The constant increase of multimedia content like video on the Web does not entail an equitable increase of the accessibility of this content. This fact provokes that elderly people or people with some kind of disability are excluded of the access to this Web content. This exclusion is due to the fact that the Web user agent that provides the content does not offer alternative content that allows users with disabilities to access it. In the case of a media player, this user agent has to provide control for access this alternative content such as caption or audio description. So, the access to alternative content should be assured to the user with disabilities in accordance with their access needs. Because of these facts, the motivation of this research work arises. The contribution of this research work aims to provide a model-based design solution which includes adaptation rules for accessible media player following accessibility standards.	accessibility;audio description;user agent;web content;world wide web	Maria Y González;Lourdes Moreno;Paloma Martínez	2014		10.1145/2662253.2662258	requirements analysis;simulation;human–computer interaction;web accessibility initiative;computer science;artificial intelligence;accessibility;multimedia;world wide web	HCI	-51.93683130047778	-40.77206080239099	46912
49df006f0abfee9327cba481a00c739400cd5127	on the evaluation of personal knowledge management solutions: evaluating tools of the x-cosim semantic desktop	personal knowledge management	In this paper, we present preliminary work on the evaluation of tool extensions we built based on our semantic desktop framework X-COSIM. We discuss different experiments for evaluating tools of a semantic desktop and present our tool extensions COSIMail, COSIFile, and SAM. We explain in detail the setup of a laboratory study designed to gain summative results that enable a comparison of our tools to conventional desktop counterparts with respect to user effectiveness, efficiency, and satisfaction.	desktop computer;experiment;personal knowledge management;sam;semantic desktop	Thomas Franz	2008			engineering drawing;database;mathematical knowledge management;semantic desktop;personal knowledge management;computer science;abrasion (geology);production tubing;personal information management;personal information manager	HCI	-62.71537771258559	-39.70994956693349	47062
a31ee20a2ec1fb9cc49384711b2d1b36df85f549	wireless tilt mouse: providing mouse-type access for computer users with spinal cord injuries or disabilities	assistive interfaces;human computer interaction;spinal cord injury;graphic user interface	Interaction with computers (e.g. those with Internet browsers and graphic user interfaces, etc.) nowadays almost requires some form of cursor control, like a mouse provides. However, the traditional mouse is not always the best alternative for all users. To provide a better option for users with spinal cord injuries or severe disabilities an inexpensive wireless head tilt mouse has been constructed to provide easy access to the regular functions of a computer mouse.	accessibility;computer mouse;cursor (databases);user (computing);user interface	Ferrol Rawson Blackmon;Michael Weeks	2008		10.1145/1389586.1389678	simulation;human–computer interaction;computer science;graphical user interface	HCI	-48.48911829854504	-41.47560288948691	47173
f183558925c8fbee1dd7c72d85ed014ee47799ff	multi-sensory emotiplant: multimodal interaction with augmented plants	multisensory interaction;multimodality;impaired people;augmented plant	Plants are live beings with often underestimated sensory and communicative abilities. In this paper, we sensitize to these natural abilities and we show how they can be extended through technology. To these purpose, we propose a framework for multisensory augmented plants and we present the design of three different augmented plants that are able to communicate with humans through different modalities. The three systems aim at bridging the communication gap between plants and humans, with a particular focus on cognitive or sensory impaired people.	bridging (networking);multimodal interaction	Leonardo Angelini;Maurizio Caon;Stefania Caparrotta;Omar Abou Khaled;Elena Mugellini	2016		10.1145/2968219.2968266	simulation;multimedia	HCI	-53.502985311450466	-45.03748532550942	47201
a10da540379fa340dda5fb52622501361e96813c	thermogame: video game interaction system that offers dynamic temperature sensation to users	social networking;enhanced museum experience;video game;interactive system;edutainment;new genres of entertainment technology	Today, many researchers reports studies about haptic, tactile or tangible art and entertainment. Particularly about temperature sensation, few interaction system has ever been presented because of it does not have good responsiveness. In this study, we shall design the video game interaction system that uses temperature sensation to users. First of all we investigate the relation of the rapidity of temperature change and user response time by using prototyped controller. Our game controller can offer temperature to users dynamically according to game situations. As a result, It was able to propose a basis of interaction system to take the temperate sensation to the game interaction.	game controller;haptic technology;response time (technology);responsiveness	Tetsuaki Baba;Kumiko Kushiyama;Kouki Doi	2010		10.1145/1836845.1836900	game design;simulation;human–computer interaction;game art design;multimedia;game design document;game testing;social network	HCI	-50.77950166034509	-38.099247836728765	47274
428b0923b281c00f3755fe56c0541b685fedbbf6	enhancing care homes with assistive video technology for distributed caregiving	qualitative research;spatial layouts;video monitoring;care homes;people with dementia;caregivers	Dementia care is becoming increasingly important in Japan as the elderly population grows. Care homes are designed so that caregivers can easily observe and subsequently respond to the needs of people with dementia. However, the layout of care homes can become overly restrictive for residents, for example, by not providing intermediate spaces where people can spontaneously interact and initiate conversations. We present a case study that explores the implementation of video monitoring in two purpose-built care homes in which we were asked to help overcome the blind spots presented by the layout. We collected data both before and after the implementation of the video monitoring in order to understand its effect. The balance between people’s sense of security and the concerns about loss of privacy through video monitoring is well established. However, we found that video monitoring had a beneficial effect on both the caregivers and the residents if implemented sensitively. Furthermore, the implementation of video monitoring could support the design of more beneficial care home layouts. In conclusion, we propose that the sensitive implementation of video monitoring be considered alongside design of the physical layout of care homes.	brick (electronics);care-of address;external validity;integrated circuit layout;privacy;semiconductor industry;word-sense disambiguation	Taro Sugihara;Tsutomu Fujinami;Rachel M Jones;Kozo Kadowaki;Masaya Ando	2014	AI & SOCIETY	10.1007/s00146-014-0560-9	simulation;qualitative research	HCI	-59.2074398262686	-51.26828995502589	47319
50676ecc9314ccbfec602a4ebb6f24762d7697bd	designing and evaluating sociability in online video games	online game;video game;sociability;online community;massively multiplayer online games;social networks;user experience;game experience;player experience	The emergence of Online Video Games has led to new ways of socializing with friends. Nowadays a good online game is also associated with the pleasure of socializing and interaction with other players. One cannot play such a game solitarily in a meaningful sense without interacting with the other players. However, there are still no integrated ways of designing and evaluating the inherent sociability of online video games, nor are there methods or guidelines for designing and evaluating social user experiences. Designers of online video games are often left to use their intuition and experience, many times leading to design failures.  This workshop aims to further the understanding of designing for sociability and evaluating such designs for online video games. The goal is to exact a framework for the design of sociability structures in online games, and identify methods of effective evaluation of those structures that are practical and can be applied in the industry. With the wide reach of online video games, the time is ripe to codify and integrate the methods that have been developed for designing and evaluating social player experiences. The results will then be turned into a methodological framework that enables online video game designers to select appropriately existing methods and tools to design and evaluate systematically the social player experience of their online computer game prototypes and products.	emergence;experience;interaction;massively multiplayer online role-playing game;norm (social);pc game;socialization;video clip;video game developer	Georgios Christou;Effie Lai-Chong Law;David Geerts;Lennart E. Nacke;Panayiotis Zaphiris	2013		10.1145/2468356.2479656	video game design;game design;user experience design;simulation;human–computer interaction;turns, rounds and time-keeping systems in games;computer science;game mechanics;game art design;game developer;multimedia;video game development;social network;online participation	HCI	-60.00212707364783	-44.23232327705162	47601
c730fac643b10d8c3ca13fd1eae83f44f9386715	space connection - a multiplayer collaborative biofeedback game to promote empathy in teenagers: a feasibility study		Biofeedback videogames are physiologically driven games that offer opportunities to individually improve emotional self-regulation and produce mental and physical health benefits. To investigate the feasibility of a novel collaborative multiplayer methodology, we created Space Connection, a videogame to promote empathy in teenagers. Space Connection depicts a futuristic adventure aboard a spaceship in which players have to jointly use their powers to solve a set of physics-based puzzles. The game relies on the use of physiological self-regulation to activate the playing partner powers. Using a low-cost brain computer interface and a respiration rate sensor we provided players with two game powers, namely telekinesis and timemanipulation which are mapped to changes in attention and relaxation. In this paper we describe the game mechanics in three different scenarios: i) the cryogenic room, ii) the space ship corridor and iii) the cargo hold. Finally, we performed a feasibility study with 10 users (aged 22.2 ± 5.6) to evaluate the game experience. Results revealed high scores in enjoyment and empathy but low scores on interface control. Our preliminary data supports the use of novel biofeedback strategies combined with videogames to promote positive emotions and incentive collaboration and teamwork.	brain–computer interface;game mechanics;graphical user interface;graphics;homeostasis;linear programming relaxation;playtest;spaceship (cellular automaton)	John Edison Muñoz Cardona;A. Gonçalves;Taian Vieira;D. Cró;Yoram Chisik;Sergi Bermúdez i Badia	2016		10.5220/0005948400880097	psychology;simulation;multimedia;social psychology	HCI	-56.26676011585621	-48.37094510842178	47656
a89a26e92af13498bb5bdea48884ce4c425f4099	enhancing web accessibility via the vox portal and a web-hosted dynamic htmlvoxml converter	browsing;web accessibility;visually impaired users;speech;accessibility;world wide web;structure;voxml	Interactive voice browsers offer an alternative paradigm that enables both sighted and visually impaired users to access the World Wide Web. In addition to the desktop PC, voice browsers afford ubiquitous mobile access to the World Wide Web using a wide range of consumer devices. This technology can facilitate a safe, `hands-free' browsing environment which is of importance both to car drivers and various mobile and technical professionals. By providing voice-mediated access, information providers can reach a wider audience and leverage existing investment in their World Wide Web content. In this paper we describe the Vox Portal, a scaleable VoxML client, and a World Wide Web Server-hosted dynamic HTML⋚VoxML converter.	vox;web accessibility	Stuart Goose;Mike Newman;Claus Schmidt;Laurent Hue	2000	Computer Networks	10.1016/S1389-1286(00)00036-0	web service;structure;web development;framing;web mapping;web-based simulation;web design;web accessibility initiative;web standards;computer science;speech;accessibility;web navigation;web accessibility;web page;multimedia;internet privacy;web intelligence;web 2.0;world wide web;web server	Web+IR	-50.55352527839901	-39.96968134355966	47799
0c110707dfa07e2d9d6115d15d3ea9f46aa366ef	a framework for creating cultural interactive guides		The use of mobile technologies and Augmented Reality are necessary in all modern museum applications in which is required an active participation of the visitor. Many systems have been defined for this aim, but each one offers contents that has been strictly selected in the design phase. In this work, we present a platform to define and make programs that can be used for assisting a visitor by providing a particular interaction chosen during the visit.	augmented reality;biological anthropology;interactivity;mobile device;smartglasses;usability	Antonio Sorgente;Antonio Calabrese;Gianluca Coda;Paolo Vanacore;Francesco Mele	2017			engineering	HCI	-55.88421513222958	-38.632355735997564	47909
22fdb3df07dc87ea3aa3d467abea8dbc553d9eb4	checkpoint exercise: training with virtual actors in virtual worlds	virtual world;evaluation result;computer avatar;second life;checkpoint exercise;virtual actor;user interacts	We have implemented a checkpoint exercise in Second Life where the user interacts with several computer avatars in a team based activity. We describe the experience and the implementation of our solution and show some evaluation results.	application checkpointing;second life;transaction processing system;virtual actor	Dusan Jan;Eric Chance;Dinesh Rajpurohit;David DeVault;Anton Leuski;Jackie Morie;David R. Traum	2011		10.1007/978-3-642-23974-8_59	simulation;human–computer interaction;multimedia	Web+IR	-51.74104107882838	-44.73306563206148	47983
28eab91a585ab3f9a043429c980717c07c934788	demonstration of a reading coach that listens	speech interfaces;continuous speech recognition;children;non readers;speech interfaces for children	"""The coach assists motivation by responding to the child’s Project LISTEN stands for """"Literacy Innovation that reading with supportive spoken feedback, and by reducing Speech Technology ENables."""" We will demonstrate a the frustration that unassisted reading poses for struggling prototype automated reading coach that displays text on a readers. screen, listens to a child read it aloud, and helps where FUNCTIONS OF SPEECH RECOGNIZER needed. We have tested successive prototypes of the coach We adapted CMU’s connected speech recognizer to listen on several dozen second graders. [1] reports implemento children read. The listening capability required by the tation details and evaluation results. Here we summarize its coach differs from conventional speech recognition, where functionality, the issues it raises in human-computer interthe task is to guess what the speaker said. Instead, the action, and how it addresses them. We are redesigning the coach knows the text the speaker is supposed to read, and coach based on our experience, and will demonstrate its must perform the following three related functions to successor at UIST ’95. provide the reading assistance described above."""	acm symposium on user interface software and technology;finite-state machine;prototype;speech recognition;speech technology	Jack Mostow;Alexander G. Hauptmann;Steven F. Roth	1995		10.1145/215585.215665	speech recognition;computer science;multimedia	NLP	-51.12722742041981	-43.970182189257706	48096
d16d1af294073d3c851f073f29e20686047d281d	speech-based disclosure systems: effects of modality, gender of prompt, and gender of user	speech user interface;interface design;information gathering;text to speech;voice user interface	Disclosure of personal information is valuable to individuals, governments, and corporations. This experiment explores the role interface design plays in maximizing disclosure. Participants (N = 100) were asked to disclose personal information to a telephone-based speech user interface (SUI) in a 3 (recorded speech vs. synthesized speech vs. text-based interface) by 2 (gender of participant) by 2 (gender of voice) between-participants experiment (with no voice manipulation in the text conditions). Synthetic speech participants exhibited significantly less disclosure and less comfort with the system than text-based or recorded-speech participants. Females were more sensitive to differences between synthetic and recorded speech. There were significant interactions between modality and gender of speech, while there were no gender identification effects. Implications for the design of speech-based information-gathering systems are outlined.	interaction;modality (human–computer interaction);personally identifiable information;speech synthesis;synthetic intelligence;text-based (computing);text-based user interface	Clifford Nass;Erica Robles;Charles Heenan;Hilary Bienstock;Marissa Treinen	2003	I. J. Speech Technology	10.1023/A:1022378312670	speech recognition;computer science;interface design;multimedia;speech synthesis	HCI	-51.37252289370927	-46.66384716355845	48260
02d8b5bde0524c7210e62b113ea73b09846270f3	designing interactivity in media interfaces: a communications perspective	customization;modality;digital media;user experience;perceptual bandwidth;interactivity;user enagement;online sources	Interactivity has become ubiquitous in the digital media landscape. Numerous interactive tools are designed, tested, deployed and evaluated. Yet, we do not have generalizable knowledge about the larger concept of interactivity and its psychological impact on user experience. As a first step toward a theory of interface interactivity, this paper identifies three species of interactivity corresponding to three central elements of communication - source, medium, and message. Interactivity situated in any of these three loci of communication can provide cues and affordances that operate either individually or together to capture users' attention and determine the nature and depth of their processing of online content as well as contribute to their perceptions, attitudes and behavioral intentions. This paper discusses psychological mechanisms by which the three classes of interactivity tools affect users, with the specific purpose of drawing out design implications and outlining UI challenges for strategic development of interactive interfaces.	communication source;digital media;interactivity;situated;theory;user experience;user interface;web content	S. Shyam Sundar;Qian Xu;Saraswathi Bellur	2010		10.1145/1753326.1753666	user experience design;human–computer interaction;computer science;digital media;multimedia;interactivity;world wide web	HCI	-58.31511541501696	-38.431812159354635	48389
e5d096f147ee11ae4b6656775580d959353f3a79	cross cultural issues in user interface design	computadora;environnement social;interfase usuario;ergonomia aplicada;ergonomie conception;medio cultural;milieu culturel;user interface;ordinateur;relacion hombre maquina;hombre;man machine relation;computer;cultural environment;medio ambiente social;human;crosscultural study;estudio transcultural;interface utilisateur;user interface design;relation homme machine;applied ergonomics;etude transculturelle;social environment;homme		user interface design	Ying K. Leung;Kevin Cox	1997			user interface design;social environment;user experience design;simulation;human–computer interaction;computer science;engineering;operating system;user interface	HCI	-60.83686429375772	-49.231543088062	48402
8db449ba7bef121b3981c6274cac495b844d2171	intergenerational context as an emphasis for design	expanding knowledge in the information and computing sciences;l000 social sciences;journal article;ageing and older people;information and computing sciences not elsewhere classified	As populations age across the developed world [18], attention is turning to ways of preserving the quality of life for the growing number of people experiencing an extended old age [22]. Information and communication technologies have great potential for supporting older people to maintain their independence and standard of living [2]. Attempts to make computer-based technologies more accessible to older users have mostly adopted functional approaches, redesigning or adapting user interfaces to reconcile human changes to physical and cognitive abilities [17]. Whilst this approach towards functional accessibility is important and significant in its own right, it struggles to address some of the contextual issues that underlie the meaningful and socially embedded use of such technologies [9]. Contextual issues can undermine the usefulness of functional accessibility when, for example, older people choose not to adopt information and communication technologies at all, seeing them as irrelevant [14] or offering no benefits [11, 16] to their social context. In this special issue, we consider universal access in relation to the inclusion of older people and explore the accessibility of computer-based technologies in its broadest sense, emphasising the social and motivational aspects of use rather than the functional concerns at the interface. The papers explore notions of accessibility, not only from the perspective of redesigning existing technologies to improve access but also investigating the purposeful creation of technology to best meet broader needs and aspirations. In addition to extending ideas of accessibility, the papers also broaden the way older people are typically considered in age-related research. Rather than being characterised as frail and impaired, older people in these papers are active and engaged, seeking opportunities for interactions with the wider community. Specifically, the papers focus on the importance of the intergenerational context as an emphasis for the design of innovative technologies.	accessibility;cognition;embedded system;interaction;population;relevance;the quality of life;user interface;while	Dave Harley;Frank Vetere;Geraldine Fitzpatrick;Sri Hastuti Kurniawan	2011	Universal Access in the Information Society	10.1007/s10209-011-0228-x	management science	HCI	-62.13270908042921	-41.821552571797575	48499
bd2ecf859d210a10f92d3c0643bec7547fba89c7	personalized alert notifications and evacuation routes in indoor environments	software;female;pedestrian safety;poison control;computer graphics;injury prevention;adolescent;male;safety literature;traffic safety;injury control;maps as topic;home safety;injury research;safety abstracts;human factors;mobile emergency systems;adult;occupational safety;safety;safety research;accident prevention;violence prevention;humans;bicycle safety;questionnaires;young adult;disaster planning;poisoning prevention;communication;falls;ergonomics;suicide prevention;alert notification systems;disasters;evacuation routes	The preparedness phase is crucial in the emergency management process for reaching an adequate level of readiness to react to potential threats and hazards. During this phase, emergency plans are developed to establish, among other procedures, evacuation and emergency escape routes. Information and Communication Technologies (ICT) can support and improve these procedures providing appropriate, updated and accessible information to all people in the affected zone. Current emergency management and evacuation systems do not adapt information to the context and the profile of each person, so messages received in the emergency might be useless. In this paper, we propose a set of criteria that ICT-based systems could achieve in order to avoid this problem adapting emergency alerts and evacuation routes to different situations and people. Moreover, in order to prove the applicability of such criteria, we define a mechanism that can be used as a complement of traditional evacuation systems to provide personalized alerts and evacuation routes to all kinds of people during emergency situations in working places. This mechanism is composed by three main components: CAP-ONES for notifying emergency alerts, NERES for defining emergency plans and generating personalized evacuation routes, and iNeres as the interface to receive and visualize these routes on smartphones. The usability and understandability of proposed interface has been assessed through a user study performed in a fire simulation in an indoor environment. This evaluation demonstrated that users considered iNeres easy to understand, to learn and to use, and they also found very innovative the idea to use smartphones as a support for escaping instead of static signals on walls and doors.	complement system proteins;digitorenocerebral syndrome;hazard (computer architecture);how true feel alert right now;interface device component;personalization;simulation;smartphone;usability testing;walls of a building;message;notification	Ignacio Aedo;Shuxin Yu;Paloma Díaz;Pablo Acuña;Teresa Onorati	2012		10.3390/s120607804	questionnaire;disaster;simulation;young adult;engineering;suicide prevention;human factors and ergonomics;injury prevention;computer graphics;computer security	HCI	-59.19108684840665	-51.86810025003844	48727
c30ecbe6088e488a980425e22eb933563b4e8fb4	player-centered game environments: assessing player opinions, experiences, and issues	interfase usuario;empirical study;game theory;methode empirique;user interface;metodo empirico;focus group;empirical method;divertissement;teoria juego;theorie jeu;game development;immersion;preferencia;interface utilisateur;preference;inmersion;jeu ordinateur;computer games;280104 computer human interaction;game playing;700199 computer software and services not elsewhere classified;entertainment	Game developers have identified, explored and discu ssed many of the key issues that arise for players interacting in game w orlds. However, there is a need to assess the thoughts and opinions of game-pl ay rs on these issues, through structured, empirical studies. This paper r epo ts the results of two player-centered studies aimed at investigating thes e is ues from the player’s perspective. The first study, a focus group, suppor ts some of the issues identified by game developers; consistency, intuiti veness and freedom of expression, and identifies new issues; immersion an d physics. The second study, a questionnaire, examined the relationship o f these issues to game-type preference and game-playing experience. This paper re resents important initial exploratory research that supplements the existing literature by focusing on the player’s perspective and exploring which issues and context have the most impact on player enjoyment.	focus group;immersion (virtual reality);interaction;ues (cipher)	Penelope Sweetser;Daniel M. Johnson	2004		10.1007/978-3-540-28643-1_40	game theory;simulation;human–computer interaction;computer science;artificial intelligence;multimedia;empirical research;computer security	HCI	-60.92803556449848	-48.45420591632416	48746
be90880d777d61959281af3c648b34bf244c4d28	colorodor : odor broadens the color identification of the blind		It is difficult for the blind to perceive colors, so they identify with colors much less in their daily lives. Our research is exploring new interactions to help them recognize colors. ColorOdor is an interactive device that can help the blind identify colors through corresponding odors. This article is mainly used to define the connection between color and odor for the blind and thus broaden their cognition of colors through user research. We hope that our research can broaden novel interactions between individuals with disabilities and their environments.	cognition;color;interaction;user research	Shuai Li;Jing Chen;Mengda Li;Jie Lin;Guanyun Wang	2017		10.1145/3027063.3053186	human–computer interaction;user research;odor;cognition;computer science	HCI	-53.22107159578511	-44.862610558718984	48838
d1959999e38e79e960c75a818a97897566af50f6	adaptive visualization interface that manages user's cognitive load based on interaction characteristics	hci characteristics;interface efficiency;visualization evaluation methods;situation awareness interfaces;monitoring system interfaces;safety critical interfaces;web interfaces;cognitive load;adaptive visualization;user adaptive interfaces	Efficiency of visualization interfaces in terms of their users' decisions speed and accuracy in safety-critical areas is extremely important as late or wrong reaction on displayed information may cause at least financial losses (not to mention the damage to human health and/or environment). Users of such systems can be overloaded with the displayed information and therefore it can take them more time to make a decision. In this paper, a novel visualization interface is presented, that can detect its user's cognitive overload and adapt the amount of information to be displayed and its visualization according to user's current cognitive capabilities. Results provided by the conducted user study have demonstrated that such adaptation technique benefits visualization interface efficiency.	function overloading;information visualization;usability testing	Anatoly Yelizarov;Dennis Gamayunov	2014		10.1145/2636240.2636844	user interface design;human–computer interaction;computer science;multimedia;user interface;world wide web	HCI	-48.66836208243356	-47.12536362201302	48866
61917aa27490f6e2e5d96f0c59f9805e8b6db5f1	attention design: eight issues to consider	atencion;visual displays;relacion hombre maquina;qa0076 computer software;hombre;man machine relation;percepcion;attention;ecran visualisation;pantalla visualizacion;feedback loop;attention aware systems;cognition;human;computer aid;working memory;cognicion;asistencia ordenador;relation homme machine;display screen;perception;qa0075 electronic computers computer science;vision;assistance ordinateur;qz psychology;homme	In HCI research there is a body of work concerned with the development of systems capable of reasoning about users’ attention and how this might be most effectively guided for specific applications. We present eight issues relevant to this endeavour: What is attention? How can attention be measured? How do graphical displays interact with attention? How do knowledge, performance and attention interact? What is working memory? How does doing two things at a time affect attention? What is the effect of artificial feedback loops on attention? Do attentional processes differ across tasks? For each issue we present design implications for developing attention–aware systems, and present a general discussion focussing on the dynamic nature of attention, tasks (number, nature and variety), level of processing, nature of the display, and validity of measures. In conclusion, we emphasise the need to adopt a dynamic view of attention and suggest that attention is a more complex phenomenon than some designers may have realised; however, embracing the multi-faceted nature of attention provides a range of design opportunities yet to be explored. 2005 Elsevier Ltd. All rights reserved.	business process;context-aware pervasive systems;endeavour (supercomputer);faceted classification;feedback;graphical user interface;human–computer interaction;infographic	Sharon Wood;Richard Cox;Peter C.-H. Cheng	2006	Computers in Human Behavior	10.1016/j.chb.2005.12.007	psychology;cognitive psychology;vision;simulation;cognition;attention;computer science;artificial intelligence;working memory;feedback loop;attention restoration theory;perception;social psychology	HCI	-54.62585920416058	-45.43364963764548	48897
ca5bfa9553fad2e7f1d73713d8f479c900cdc356	"""a high-level """"tasking"""" interface for uninhabited combat air vehicles"""	3d illustrations;visual presentation techniques;interatctive 3d animation;agents;3d user interfaces	The HCI debate over direct manipulation vs. automated agents shows a fundamental: humans want to remain in charge even if they don’t want to (or can’t) make every action and decision themselves. We have been exploring a middle road through the development of “tasking interfaces” to enable human operators to flexibly “call plays” (that is, stipulate plans) at various levels, leaving the remainder to be fleshed out by a planning system.	direct manipulation interface;human–computer interaction;user interface	C. A. Miller;Michael J. S. Pelican;Robert P. Goldman	1998		10.1145/291080.291122	simulation;human–computer interaction;computer science;artificial intelligence;software agent;multimedia	AI	-50.572372392506644	-47.680510044842734	49109
2d4fcbed2eae237eedb4c757964066ec855a95f7	what makes a good format: frameworks for evaluating the effect of graphic risk formats on consumers' risk-related behavior.	health education;risk assessment;humans;communication;audiovisual aids;risk taking	The format in which risk information is presented has a fundamental influence on the quality of risk communication with health consumers. Graphic formats might enhance the risk communication process, but we know little about how these formats affect risk-related behavior. Based on a review of literature within and outside the medical domain, we present four useful frameworks for evaluating the effects of graphic format on risk-related behavior.		Andrea Hartzler;Jason N. Doctor;Fredric M. Wolf	2005	AMIA ... Annual Symposium proceedings. AMIA Symposium		human–computer interaction;computer science;marketing;multimedia	Arch	-62.520064437138146	-50.23122018501554	49111
b462f5995565629c9cfc22c67900ccce53a81d51	a preliminary exploration of group social engagement level recognition in multiparty casual conversation		Sensing human social engagement in dyadic or multiparty conversation is key to the design of decision strategies in conversational dialogue agents to decide suitable strategies in various human machine interaction scenarios. In this paper we report on studies we have carried out on the novel research topic about social group engagement in non-task oriented (casual) multiparty conversations. Fusion of hand-crafted acoustic and visual cues was used to predict social group engagement levels and was found to achieve higher results than using audio and visual cues separately.		Yuyun Huang;Emer Gilmartin;Benjamin R. Cowan;Nick Campbell	2016		10.1007/978-3-319-43958-7_8	psychology;human–computer interaction;communication;social psychology	HCI	-52.90913877344563	-48.83982265188056	49405
2a7641210137e4a706f8f4c22344947643ad5b9f	characterizing the diversity in users' perceptions	usability testing;multi dimensional scaling;repertory grid technique;user profile;user profiling;repertory grid;field study	This paper proposes a novel approach to modeling the diversity in users’ perceptions, based on a mixture of qualitative and quantitative techniques: the Repertory Grid Technique and Multi-Dimensional Scaling. The proposed method can be used for identifying diverse user groups that can inspire a range of personas, or for selecting subjects for field studies and usability tests. In a case study we explored the perceptions of product creators and end users towards an innovative product in its early design stage.	multidimensional scaling;persona (user experience);repertory grid;scalability;usability testing	Evangelos Karapanos;Jean-Bernard Martens	2007		10.1007/978-3-540-74796-3_50	usability;multidimensional scaling;human–computer interaction;computer science;knowledge management;world wide web;field research	HCI	-60.54029973211821	-46.448887696865135	49550
59495448dc3f42e26aaaf86e94fc3fb04fd04b09	5th limb: development of augmented expression system using extra limb	wearable system;augmented expression;human sensing technology;artificial limb	"""Technology for augmenting expressions is actively researched in fields such as social media, entertainment, and arts. It is being established as a business. Dancing to videos that are programmed in advance is one example. This method effectively augments the expressions in dancing; however, it is difficult to improvise. Although it can be interactive, it requires large-scale devices such as motion captures or a large number of cameras. The purpose of this study is to develop a wearable device that augments expressions and evaluate the effectiveness of this device for augmentation of expressions. The shape of this device is identical to the tail of an animal. The shape of the device changes using information from the body of the wearer and acts as a """"5th"""" limb. It then augments the expressions of the wearer. The required information for changing shape includes back muscle tension, gait, and angle of the arm. This information is collected through measurements and estimates of bioelectrical signals, sole pressure, and angles of the arms. The device estimates the emotions and behavior of the user. In the experiments, the device is attached to a performer. The values of the sensor and the motions of the device are measured. Hence, it is confirmed that the device moves when it detects the behavior of the performer. In other words, the device mirrors the behavior of the people who use the system. Therefore, this system augments the expression of performers. In conclusion, a wearable device for augmenting expressions is developed, and it is considered that this system can augment the expression of performers on stage."""	coat of arms;experiment;social media;wearable technology	Shori Kano;Rintaro Takashima;Yasunari Asakura;Ryoichiro Shiraishi	2017		10.1145/3041164.3041208	computer vision;simulation;engineering;communication	HCI	-49.20096491979757	-50.552647779528364	49663
7a49e53cd26f342da5b9a5fdfa50bec9e6c615e3	modeling cognitive processes from multimodal signals		Multimodal signals allow us to gain insights into internal cognitive processes of a person, for example: speech and gesture analysis yields cues about hesitations, knowledgeability, or alertness, eye tracking yields information about a person's focus of attention, task, or cognitive state, EEG yields information about a person's cognitive load or information appraisal. Capturing cognitive processes is an important research tool to understand human behavior as well as a crucial part of a user model to an adaptive interactive system such as a robot or a tutoring system. As cognitive processes are often multifaceted, a comprehensive model requires the combination of multiple complementary signals. In this workshop at the ACM International Conference on Multimodal Interfaces (ICMI) conference in Boulder, Colorado, USA, we discussed the state-of-the-art in monitoring and modeling cognitive processes from multi-modal signals.	cognition;electroencephalography;eye tracking;interactivity;mechatronics;modal logic;multimodal interaction;robot;user modeling	Felix Putze;Jutta Hild;Akane Sano;Enkelejda Kasneci;Erin Solovey;Tanja Schultz	2018		10.1145/3242969.3265861	user modeling;alertness;human–computer interaction;eye tracking;electroencephalography;cognitive load;gesture;computer science;cognition	Robotics	-54.18529176151171	-46.36970008296846	49734
50a487110781b4cc16bc4050bcb90b85023f65cc	evaluating ubiquitous media usability challenges: content transfer and channel switching delays	woz;channel switching delay;user studies;simulated environment;content transfer;mobile media	As ubiquitous media is developing rapidly, new HCI challenges emerge. In this paper, we address usability issues related to the transfer of content between fixed and mobile devices, as well as channel switching delays on mobile devices. We first provide an extensive review of the field. We then evaluate four relatively novel approaches for initiating a transfer of video content from a mobile phone to a TV screen. Seen from a user’s point of view, familiarity and comfort are found to be important decision factors when selecting a preference among the proposed methods. Furthermore, we identify a threshold level above which people appear to be annoyed when switching between TV channels on a mobile device, and investigate factors that may influence the perceived acceptability of such delay.	digital video;human–computer interaction;mobile device;mobile phone;point of view (computer hardware company);usability	Alexandre Fleury;Jakob Schou Pedersen;Lars Bo Larsen	2011		10.1007/978-3-642-21708-1_46	multimedia;internet privacy;computer security	HCI	-54.81846930230523	-42.31905058958293	49816
25bef54bfdb74213b694139cf1d5812974e752fa	effect of expressive lights on human perception and interpretation of functional robot		Because appearance-constrained robots lack expressiveness, human users often find it hard to understand their behavior and intentions. To address this, expressive lights are considered to be an effective means for such robots to communicate with people. However, existing studies mainly focus on specific tasks or goals, leaving the knowledge of how expressive lights affect peopleu0027s perception still unknown. In this pilot study, we investigate such a question by using a Roomba robot. We designed two light expressions, namely, green and low-intensity (GL) and red and high-intensity (RH). We used open-ended questions to evaluate peopleu0027s perception and interpretation of the robot, which showed different light expressions as a way to communicate. Our findings reveal that simple light expressions can allow people to construct rich and complex interpretations of a robotu0027s behavior, and such interpretations are heavily biased by the design of expressive lights.	expressive power (computer science);nonlinear gameplay;robot	Sichao Song;Seiji Yamada	2018		10.1145/3170427.3188547	robot;human–computer interaction;perception;roomba;expressivity;color psychology;computer science;expression (mathematics)	HCI	-51.112553825256335	-50.1837718240464	49841
a8104af2aa105bbe75a84c04eb5de72298ae3675	are you embarrassed?: the impact of robot types on emotional engagement with a robot	tele operated robot;emotional communication;embarrassment;autonomous robot;social presence	The objective of this study is to examine the effect of robot types on emotional communication between a person and a robot. We executed a 2 (robot types: an autonomous robot vs. a tele-operated robot) within-participants experiment (N=36). Participants were interviewed with either autonomous robot interviewers or tele-operated robot interviewers, and asked how much they felt social presence of robot interviewers and embarrassment toward robot interviewers. Participants felt more social presence to tele-operated robots than autonomous robots. Moreover, participants felt more embarrassment when they were interviewed with tele-operated robots than autonomous robots.	autonomous robot;social presence theory;television	Jung-Ju Choi;Yunkyung Kim;Sonya S. Kwak	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2559798	simulation;social robot;personal robot	Robotics	-51.96556682173205	-50.594992951003654	49853
68a211390c10e3d98b3ed23d85f975b777078e13	improving request compliance through robot affect	robot affect;human robot interaction	This paper describes design and results of a human robot interaction study aimed at determining the extent to which affective robotic behavior can influence participants' compliance with a humanoid robot’s request in the context of a mock up search and rescue setting. The results of the study argue for inclusion of affect into robotic systems, showing that nonverbal expressions of negative mood (nervousness) and fear by the robot improved the participants' compliance with its request to evacuate, causing them to respond earlier and faster.	humanoid robot;human–robot interaction;mock object	Lilia V. Moshkina	2012			human–robot interaction;simulation;computer science;artificial intelligence;social robot	Robotics	-51.826695078886495	-50.80548598382057	49905
b59eb0d8ff8140b578ba934b02ee12226d21b1c0	scenarios in the wild: experiences with a contextual requirements discovery method	software tool;tool support;mobile computer;requirements elicitation;contextual inquiry;lessons learned;navigation system;mobile computing;scenarios	[Context and motivation] A number of ethnographic approaches are available to gather requirements where they emerge, i.e. in the workplace of future system users. [Question/problem] Most of these approaches do not provide guidance and software tool support for on-site analysts. [Principal ideas/results] In this paper we present a tool-supported contextual method that combines key benefits of contextual inquiry and scenario-based techniques. It aims to improve guidance and support for on-site analysts performing a contextual requirements discovery. [Contribution] We applied this method in the Austrian Alps to discover stakeholder's requirements for a ski tour navigation system. This paper reports on this inquiry and analyses its results. Moreover, we discuss lessons learned and conclusions.	requirement	Norbert Seyff;Florian Graf;Neil A. M. Maiden;Paul Grünbacher	2009		10.1007/978-3-642-02050-6_13	simulation;computer science;systems engineering;engineering;knowledge management;contextual inquiry;requirements elicitation;mobile computing	Vision	-62.60604005137437	-44.822220212257776	49932
aac6e2843816e9fa764af1fd4d593b3b126dfab8	evolving a social visualization design aimed at increasing participation in a class-based online community	online communities;social comparison;online community;social visualization;participation	The paper describes the evolution of the design of a motivational social visualization. The visualization shows the contributions of users to an online community to encourage social comparison and more participation. The newest design overcomes shortcomings in the previous two, by using more attractive appearance of the graphic elements in the visualization, better clustering algorithm and by giving up the largely unused in the previous design user customization options. The visualization integrates more information in one view, and uses an improved user clustering approach for representing graphically their different levels of contribution. A case study of the new design with a group of 32 students taking a class on Ethics and Computer Science is presented. The results show that the visualization had a significant effect on participation with respect to two activities (logging into the community and rating resources).	algorithm;cluster analysis;computer science;online community	Julita Vassileva;Lingling Sun	2008	Int. J. Cooperative Inf. Syst.	10.1142/S0218843008001932	simulation;human–computer interaction;social comparison theory;computer science;multimedia;online participation	HCI	-59.574873888669245	-46.60585619669295	50161
0d4b532c761f8b3565181f877bb790819aadaa12	patterns in video games analysis - application of eye-tracker and electrodermal activity (eda) sensor		The aim of the article is to propose a method for evaluating player’s experience during gameplay using an eye-tracker and galvanic skin response sensor. The method is based on using data obtained from the game, in the light of patterns in game design. The article presents a preliminary, qualitative study, along with an exemplary interpretation of the gameplay of the Hidden Object Puzzle Adventure (HOPA) game.	eye tracking;sensor	Iwona Grabska-Gradzinska;Jan K. Argasinski	2018		10.1007/978-3-319-91262-2_54	artificial intelligence;computer science;machine learning;simulation;user experience design;skin conductance;eye tracking;qualitative research;game design;adventure	HCI	-56.97111882115215	-46.338236982908185	50303
821de734ce4d833a85c804076978ba7d45eec950	user acceptance of 'smart products': an empirical investigation		Smart Products pose a new class of IT artifacts based on sensors, ID-tags, haptic user interfaces, and other technologies usually subsumed under the notion of 'ubiquitous computing'. Such devices differ in many ways from traditional computers, e.g., with regard to their physical shape, computing power, and interaction paradigms. While a substantial body of literature already exists on underlying technological design challenges, only few researchers have attempted to quantitatively explore factors influencing user acceptance of Smart Products. Against this background, the present study is concerned with the use of Smart Products in a kitchen environment. Based on the Unified Theory of Acceptance and Use of Technology (UTAUT), we develop and empirically test a structural model of technology acceptance including five moderating factors. Our results indicate high overall acceptance of the proposed scenarios, corroborate the applicability of the UTAUT model for smart home environments, and confirm significant effects for two moderators.	computer;haptic technology;home automation;programming paradigm;sensor;smart products;ubiquitous computing;user interface	Peter Mayer;Dirk Volland;Frédéric Thiesse;Elgar Fleisch	2011				HCI	-58.8495111198859	-48.68321619731753	50390
2232903691ec3a9d6723f6af693d03e8f468e154	enriching mixed reality systems with mobile applications		Mixed reality systems immerse users into environments where reality is bridged with virtual worlds. The proliferation of augmented reality compatible devices constitutes a useful means to overcome application limitations. The research presented in this paper focuses on the enhancement of mixed reality environments using mobile applications by altering the virtual parts of mixed reality environments, enriching application functionality, promoting social interaction and facilitating user-generated storytelling authoring and narration. The presented ongoing work builds upon a green screen mixed reality application which can be used in combination with one or more augmented reality application instances, showcasing the benefits of employing mobile augmented reality applications to complement MR systems.		Giannis Drossis;Constantine Stephanidis	2018		10.1007/978-3-319-92279-9_32	multimedia;human–computer interaction;social relation;storytelling;mixed reality;metaverse;narrative;computer science;augmented reality	HCI	-55.83567070950554	-38.16595164201393	50410
2f7488d321c644cf0c66ba42f91ce808410635fe	sharing multimedia content with interactive public displays: a case study	community;design process;social capital;information content;information sharing;information encountering;interactive public displays;success factor;public display;public space;evaluation;adoption	"""Plasma Posters are large screen, digital, interactive poster-boards situated in public spaces, designed to facilitate informal content sharing within teams, groups, organizations and communities. While interest i interactive community poster boards has grown recently, few successful examples have been reported. In this paper we describe an ongoing installation of Plasma Posters within our organization, and report qualitative and quantitative data from 20 months of use showing the Posters have become an integral part of information sharing, complementing email and Web-based sharing. Success factors include our design process, the reliability and flexibility of the technology and the social setting of our organization. We briefly describe three external installations of the Plasma Poster Network in public places. We then reflect on content posting as """"information staging"""" and the ways in which the public space itself becomes part of the """"interface"""" to content."""	disk staging;email;floor and ceiling functions;plasma display;situated;world wide web	Elizabeth F. Churchill;Lester Nelson;Laurent Denoue;Jonathan Helfman;Paul Murphy	2004		10.1145/1013115.1013119	community;design process;self-information;social capital;human–computer interaction;engineering;knowledge management;evaluation;multimedia;management	HCI	-56.574595129427784	-38.358989372616634	50468
e9fabe59f51613ca6ac0199a8609e0d5d06c3cfe	the personalized context-aware mobile advertisement system using a novel approaching detection method over cellular networks	context aware;cellular networks;positioning method;fingerprinting database;ad targeting;mobile advertisement	With the rapid development of smartphones and personal tablet computers, it brings a greatly growing rate of ubiquitous applications for location-based services (LBS). One famous LBS is the mobile advertisement. A mobile advertisement system brings benefits and opportunities among users, service providers, and advertisers. In this paper, we propose a personalized context-aware mobile advertisement system (PCA-MAS) over cellular networks, which contains two new techniques called (i) approaching detection method (ADM) and (ii) context-aware ad targeting method (CAADTM). ADM can find some point of interests that a user is approaching; CAADTM pushes advertisements that satisfy user’s requirement based on the user’s context, that is, user’s profile, current time, current position, and so on. Our experimental results show that (i) ADM has the good hit rate to determine those point of interests that a user is approaching within the 150-m radius of the approaching range, and (ii) CAADTM has the good hit rate of finding appropriate advertisements that a user prefers through the favorite content table filtering, the annoying content table filtering, and the advertisement clicking feedback. Copyright © 2013 John Wiley & Sons, Ltd.	john d. wiley;location-based service;personalization;smartphone;tablet computer	Chung-Ming Huang;Shih Yang Lin;Tsung-Han Hsieh	2015	Softw., Pract. Exper.	10.1002/spe.2208	cellular network;computer science;engineering;operating system;internet privacy;world wide web	Mobile	-51.46555953111497	-41.44897595829651	50546
c944a76550f144959668a0a017a1130fc6b39f8a	a vibration tactile aesthetic to enhance the realism of interactive game avatar		This study proposes a new method to augment the realism of avatar by using tactile vibration and facial expression. Currently, interactive game still lack of interactivity and immersiveness. In this paper, we create an avatar with some intelligence and emotional features in order to support the realism of avatar. Our approach based on mapping the 2D valence emotion diagram to particular magnitude vibration. We also consider the duration of vibration and the acceleration time that occurred during vibration. Through the experiment we succeed for classifying and mapping into two emotion states: angry and happy. Furthermore, our result has proven to differentiate in detail the emotion levels of angry. The result also compared to the previous result and we have obtained 35% until 55% better than the previous avatar in term of human perception that involved into avatar. This result is believed as well to enhance the interactivity and immersiveness of interactive game for overall.	avatar (computing);diagram;interactivity	Ahmad Hoirul Basori;Abdullah Bade;Mohd Shahrizal Sunar;Daut Daman;Nadzari Saari	2009	JDCTA		simulation;computer science;multimedia	HCI	-49.29977592962015	-49.560308947952315	50630
f54627eb6a4e095a561df865deef07c1ce9ac8af	personality, attitudes, and bonding in conversations		This paper investigates how the personality and attitudes of intelligent agents could be designed to most effectively promote bonding. Observational data are collected from a series of conversations, and a measure of bonding is adapted and verified. The effects of personality and dispositional attitudes on bonding are analyzed, and we find that attentiveness and excitement are more effective at promoting bonding than traits like attractiveness and humour.	intelligent agent	Natasha Jaques;Yoo Lim Kim;Rosalind W. Picard	2016		10.1007/978-3-319-47665-0_37	intelligent agent;social psychology;observational study;attractiveness;personality;computer science	NLP	-56.77539661577101	-48.90883472418269	50704
0e990a8ef2c5c5588de83a32e84655612a8e364d	design guidelines for effective recommender system interfaces based on a usability criteria conceptual model: results from a college student population	commerce electronique;interfase usuario;preferencia individual;electronic commerce;comercio electronico;user interface;conceptual model;recommandation;college students;useful information;informacion util;comportement consommateur;user preferences;cuestionario;enquete;recommender system;design guideline;comportamiento consumidor;utilisabilite;individual preference;recomendacion;recommendation;interface utilisateur;consumer behavior;preference individuelle;design guidelines;encuesta;questionnaire;usabilidad;usability;survey;recommender systems;information utile;electronic trade	With the retail electronic commerce being a major global shopping phenomenon, retailers need to develop additional tools to improve their sales. One such tool is a Recommender System through which the shopping page recommends products to the shoppers using their past Web shopping and product search behavior. While recommender systems are common, few studies exist regarding their usability and user preferences. In this study, a structured survey concerning what recommender systems should contain and how this content should be presented was administered on one hundred and thirty one college-aged online shoppers. Results indicate participants prefer specific recommender content. Price, image and names of products are identified as essential information while product promotions, customer ratings and feedback are identified as secondary types of information. Shoppers preferred short and relevant recommender information, with a maximum of three recommendations on one page. Future studies may explore differences in preference of recommender systems based on different product types.	e-commerce;recommender system;usability;user (computing)	A. Ant Ozok;Quyin Fan;Anthony F. Norcio	2010	Behaviour & IT	10.1080/01449290903004012	questionnaire;usability;human–computer interaction;computer science;engineering;conceptual model;user interface;world wide web;statistics;recommender system	HCI	-60.84510703511442	-48.6602771315986	50752
4f22b72b48121a4ec76610952d0e152b89167911	liquidtext: active reading through multitouch document manipulation	visualization;active reading;multitouch input	Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers' activities. Most computer based active reading support has sought to better replicate the affordances of paper. Instead, this dissertation seeks to go past paper by proposing a more flexible, fluid document representation, controlled through gesture and multitouch input. Formative evaluations revealed details about modern active reading behavior and early reactions to the prototype system. I discuss how these will inform the next design iteration, and current plans for a comparative study against other media.	gesture recognition;iteration;multi-touch;prototype;self-replicating machine	Craig S. Tashman	2010		10.1145/1753846.1753895	visualization;human–computer interaction;computer science;multimedia;world wide web	HCI	-53.27467324984742	-42.1206332469096	50797
004135a590f2a828f933d4cead23165f4d0a750f	a leader-follower turn-taking model incorporating beat detection in musical human-robot interaction	analytical models;robotic musicianship;rhythm;acoustic input leader follower turn taking model musical human robot interaction musical hri beat detection analysis turn taking scheme haile robotic percussionist fluid interaction improvisatory jam session human machine dynamic interaction musical input analysis;machine listening;leader follower paradigm;music acoustic signal detection acoustic signal processing human robot interaction;human robot interaction;leader follower paradigm robotic musicianship human robot interaction machine listening beat detection;lead;robots;beat detection;humans lead robots rhythm analytical models context;humans;context	This paper describes the implementation of a leader-follower model in a musical HRI based on beat detection analysis and a novel turn taking scheme. The project enables Haile, a robotic percussionist, to fluidly interact with humans in the context of an improvisatory jam session. The long-term goal of this work is to facilitate dynamic interactions between humans and machines that will lead to novel and inspiring musical outcomes.	beat detection;haile (robot);human–robot interaction;jam;robot	Gil Weinberg;Brian Blosser	2009	2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1514095.1514149	human–robot interaction;robot;lead;simulation;computer science;artificial intelligence;rhythm;beat detection	Robotics	-51.8032799320174	-48.17178964527089	50834
13a488b8256e643366fcf950ba410db932854c38	effects of adaptivity and other external variables on mobile service adoption	interface design;mobile handsets;system adoption;adaptive behavior;information system;user interfaces;external variables;technology acceptance model;great role;user interface;external variable;system external variables;mobile service adoption;mobile service adaptivity;reservation computer systems;mobile computing;adaptive feature;mobile reservation system	This paper explores user interface between user and information systems in system adoption. Acceptance of a system is defined as a function of perceived usefulness and perceived ease of use. There are several external variables that have an impact on perceived usefulness and perceived ease of use. Therefore the content and interface design of every single application should be addressed accordingly to enhance users intention to use the system. The paper proposes that adding adaptive features into systems may be one of the approaches to address this phenomenon. We identified external variables including adaptive behavior impacting acceptance of mobile reservation system through three prototypes.	adaptive behavior;information system;usability;user interface	Ebru Polat;Nuri Basoglu;Tugrul U. Daim	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.689	simulation;human–computer interaction;engineering;multimedia	Robotics	-57.63394944704334	-45.191112227200854	50880
6bdc8e3524f82faac78d34c3aa9b15c77f149434	automatic detection of affect and cognitive load from multimodal information	human computer interaction;intelligent tutoring system;data fusion;machine learning;phd doctorate;cognitive load measurement;affective computing		multimodal interaction	M. Sazzad Hussain	2013			natural language processing;computer science;artificial intelligence;multimedia	HCI	-53.16507704472736	-46.16754231262561	50892
2235dd8bcaae8584d251bf06b622066f16916dde	iterative process of design and evaluation of icons for interactive tv menu	etude utilisateur;document iconographique;iterative process;interfase usuario;proceso concepcion;representation graphique;design process;user interface;television digital;user study;estudio usuario;digital television;icon usability;interactive tv;television interactive;proceso iterativo;processus iteratif;information appliance;evaluation criteria;indexation;television numerique;utilisabilite;grafo curva;interface utilisateur;user interface design;evaluation;evaluacion;iconographic document;usabilidad;interactive television;usability;graphics;processus conception;documento iconografico	This paper shows an iterative process of design and evaluation of icons for future interactive TV services. In doing the RNRT (French National Network of Research in Telecommunications) iTV project, we tried to generate icons easy to identify, associate and memorise for 32 categories and services of our iTV system. Through an iterative process, the Multiple Index Approach was applied until an acceptable icon set was achieved. In addition to existing evaluation criteria such as the intuitiveness, associativeness, preference and suitability with subjective certainty of users, we emphasised the importance of the learnability measured by recall tests. As a conclusion, we propose a methodology of icon design and evaluation for information appliances that integrate unfamiliar features with common users.		Dokshin Lim;Carole Bouchard;Améziane Aoussat	2006	Behaviour & IT	10.1080/01449290500167832	simulation;human–computer interaction;computer science;operating system;multimedia;interactive television;world wide web	HCI	-61.88035485636986	-48.23058471423891	50906
3c6348164221b7f001a46559f394e94983ed081b	a primer of picture-aided navigation in mobile systems	handheld device;mobile systems	The goal of this paper is to present a new concept regarding the way of explaining itineraries based on pictures in mobile sy stems. Instead of presenting a map, or a list of words, an original method is pr oposed based on a picture database and handheld devices. Knowing the exact po sition of the user, the system will sent him regularly pictures of the way where to go. This system is especially targeted not for drivers but for pede strians essentially in tourist cities. In order to reach this objective, pictures were taken along each street both ways. Thus, a picture database was built for which the more common query is to compute the minimum path for going from one p lace to another. The result format is initially presented as a sequence of nodes and edges; then this sequence is transformed into a sequence of pictures . Those pictures are then sent to the user according to his position and his pace. In order to help the user, the pictures are decorated with arrows. This presentation is based on two prototypes mad e within a FrenchArgentinean collaboration. Key-words: GIS, images, explaining itineraries, Location-base d Services, Physical Hypermedia	geographic information system;hypermedia;image;mobile device;primer	Robert Laurini;Silvia E. Gordillo;Françoise Milleret-Raffort;Sylvie Servigne;Gustavo Rossi;Nan Wang;Andres Fortier	2008		10.1007/978-3-540-68566-1_34	simulation;computer science;multimedia;communication	DB	-50.73635099091741	-40.485603847398906	51235
96140aad50a2b32a61ce922813dd1e620c1cee6d	privacy concerns and behaviors of people with visual impairments	wearable technology;visually impaired people;privacy	Various technologies have been developed to help make the world more accessible to visually impaired people, and recent advances in low-cost wearable and mobile computing are likely to drive even moreadvances. However, the unique privacy and security needs of visually impaired people remain largely unaddressed. We conducted an exploratory user study with 14 visually impaired participants to understand the techniques they currently use for protecting privacy, their remaining privacy concerns,and how new technologies may be able to help. The interviews explored privacy not only in the physical world (e.g., bystanders overhearing private conversations) and the online world (e.g., determining if a URL is legitimate), but also in the interface between the two (e.g. bystanders `shoulder-surfing' data from screens). The study revealed serious concerns that are not adequately solved by current technology, and suggested new directions for improving the privacy of this significant fraction of the population.	mobile computing;privacy;usability testing;wearable computer	Tousif Ahmed;Roberto Hoyle;Kay Connelly;David J. Crandall;Apu Kapadia	2015		10.1145/2702123.2702334	computer science;internet privacy;privacy;wearable technology;world wide web;computer security	HCI	-57.22913733929314	-42.624084023909234	51310
c2878f05e5ea2f74a32816b4d383a1129f877114	what do audiences do when they sit and listen?		Speech anxiety (SA) training may help subjects improve their skills on keeping audiences interested in the speech and on managing calm or restless audiences. Attention and lack of attention during speeches are displayed through several nonverbal cues. Such and other nonverbal behaviors can also spread throughout a group and engage whole audiences. The current study is an inquiry into the nonverbal markers of attention and lack of attention during lectures (e.g. note taking, eye gaze towards the speaker, conduct with electronic devices such as mobile phones or laptops). Additionally, the study tries to identify nonverbal behaviors that are diffused and their spatial and time diffusion characteristics. 37 university students at the Ilmenau University of Technology have been observed during a 40-minutes lecture. A quantitative content analysis is conducted to identify patterns of behaviors depicting attention and inattention. Afterwards a qualitative content analysis is carried out to identify contagious behaviors and their spreading characteristics. The findings are used to design virtual audiences (VA) whose members react to each other or display observable audience responses (OAR) and will be implemented into training scenarios for training university students against SA.		Ana-Despina Tudor;Sandra Poeschl;Nicola Döring	2013	Studies in health technology and informatics	10.3233/978-1-61499-282-0-120		HCI	-54.41541189448099	-49.40620879157991	51390
6cc5c5f341ced8a9220eb8a5d54673d3e4ad63be	students' investigations with physical activity data devices	own mini-studies;data collection tool;data investigation;high-school student;design experiment;poster report;commercial physical activity monitoring;physical activity;physical activity data device	Through a design experiment, we explored the potential for a suite of commercial physical activity monitoring devices to be used as data collection tools. Two pairs of high-school students were asked to engage in a week-long set of data investigations of physical activity that culminated in the design and implementation of their own mini-studies. This poster reports on those mini-studies, the challenges associated with the technologies used, and the supports that needed to be introduced.		Victor R. Lee;Maneksha DuMont	2010			human–computer interaction;engineering;data mining;computer engineering	HCI	-62.06698009086257	-44.40306510827138	51556
12b00c2a824b3177dbec44ccfc77f6d857353634	designing and observing human-robot interactions for the study of social development and its disorders	design principle;human computer interaction;social communication;symbiosis;rubber;social sciences;autism;human robot interaction communications technology humanoid robots ontologies autism cities and towns rubber mood symbiosis birth disorders;mobile robots;social development;human robot interaction;birth disorders;social disorders;mobile robots man machine systems human computer interaction social sciences;developmental disorders;remedial applications human robot interaction social development developmental disorders;humanoid robots;developmental disorder;social communication human robot interaction social development social disorders keepon unconstrained playroom ontological understanding;cities and towns;communications technology;ontologies;remedial applications;mood;man machine systems;keepon;unconstrained playroom;ontological understanding	This paper describes the design principle of our robot, Keepon, and reports the longitudinal observation of the interactions between the robot and children with developmental disorders. The robot, Keepon, is a small (12cm tall), simple (like a yellow snowman), soft (made of silicone rubber), creature-like robot, which was designed for studies on human social development and possible remedies for developmental disorders. We observed how children with developmental disorders interacted with the robot in an unconstrained playroom for more than a year (over 500 child-sessions). From these observations, we found that the children changed their ontological understanding of the robot, and consequently their way of interaction, as the interaction unfolded. We conclude that the robot's rather predictable responses gave the children a relaxed mood for spontaneous play, from which social communication with the robot and with another person would naturally emerge.	inter-process communication;interaction;keepon;play store;robot;spontaneous order	Hideki Kozima;Cocoro Nakagawa;Yuriko Yasuda	2005	2005 International Symposium on Computational Intelligence in Robotics and Automation	10.1109/CIRA.2005.1554252	human–robot interaction;simulation;autism;computer science;artificial intelligence;symbiosis	Robotics	-55.0256262552239	-50.664862476892715	51582
6c0d8bde6f8a2d86f9f8416fa6c67e5bc864f10c	special issue on personal interactive (tv) environments	interactive tv	Today’s changing TV environments require to consider the related shifts in user needs and behaviours. The demand for being mobile and having personalized access to information and entertainment anywhere and anytime for example, clearly shows that developers of interactive TV services find themselves confronted with new exciting challenges. Thus, both traditional broadcast TV and interactive TV need to understand the users in such a networked multimedia world. In this special issue topical research on interactivity, multimediality, personalization, and recommendation systems from both a technical and a user-centred viewpoint is presented. A combination of innovative systems, developed architectures, applied algorithms, and methodologies will be discussed. Moreover, new interaction concepts supporting personalized consumption and exchange of TV content for multi-user environments will be investigated and new concepts evolving from Web 2.0 for mobile networks will be highlighted. All articles underline the important challenges for the future development and design of personalized and interactive TV based systems and services. In the first article, Pablo Cesar, Dick C.A. Bulterman, and Jack Jansen present a TV viewing system which uses secondary screens for content control, enrichment and sharing. The system allows the users to control the viewed content (to choose the content and the device), add, e.g. a voice annotation to the content and share the annotation and the selected part of the content with others. The article also summarizes initial business analysis and user testing results. Elena Vildjiounaite et al. and Regina Bernhaupt et al. in their following two articles also address this need for more	anytime algorithm;broadcast television systems;business analysis;freedom of information laws by country;gene ontology term enrichment;interactivity;multi-user;personalization;recommender system;regina;user research;web 2.0	Marianna Obrist	2009	Multimedia Systems	10.1007/s00530-009-0160-6	telecommunications;computer science;interactive television	HCI	-52.593709558851536	-40.19804394167565	51655
8383ef0de0e2b78e9ea1536b7cc8efe449d6c734	watch out! - user-centered feedback design for a v2x-smartphone app		Mobility is a fast developing, technological and simultaneously human field of research. V2X-technology is one major contributor that will influence the behavior, efficiency and safety of traffic participants. To include all participating members of traffic, we developed a V2X-smartphone application to empower vulnerable road user to be part of the technological integration. With a two-tiered research approach, we focused on both, the iconography and the feedback design of that application. One key finding of the presented work is a clear recommendation of combined features (color, size and geometrical form) for rear-end collision scenarios. The article concludes with practical recommendations that facilitate visualization-varieties from a users’ perspective.	color;mobile app;smartphone	Teresa Schmidt;Ralf Philipsen;Dzenan Dzafic;Martina Ziefle	2017		10.1007/978-3-319-58466-9_33	multimedia;human–computer interaction;computer science	HCI	-55.866442904233914	-39.745816632976194	51749
2b79c3a737c3768344d1a8792d7cdd87767fb62b	fingers, veins and the grey pound: accessibility of biometric technology	biometrics;user preferences;system performance;accessibility;usability;older users;fingerprint verification	Motivation -- Fingerprint verification systems are the most widely used biometric technology, however several studies suggest that their performance deteriorates when older individuals use the technology. This research investigated both the accessibility and acceptability of biometric technology for an older population.  Research approach -- A fingerprint and a vein system were tested with a group of 36 participants, with a mean age of 65.7 years. Participants used both devices and both objective performance data and subjective measures of opinion were collected.  Findings -- The vein system performed significantly better than the fingerprint system, and was preferred by the majority of participants.  Research implications -- The relationship between user preference and device performance is complex however, and could not be fully explained through this evaluation.  Take away message -- The elderly are poorly represented in studies investigating biometric technology, though this research suggests that vein systems are a technology that could accommodate this demographic.	accessibility;biometrics;fingerprint;status message (instant messaging)	Chris Riley;Heather McCracken;Kathy Buckner	2007		10.1145/1362550.1362580	fingerprint verification competition;simulation;usability;computer science;engineering;accessibility;computer performance;world wide web;computer security;biometrics	HCI	-57.691194326063915	-45.21614921706438	51785
ccbfb394d5d6a4319ccb94f1de77350b4c05d701	comparing efficacy of web design of university websites: mixed methodology and first results for russia and the usa	large web spaces;human computer interaction;heat maps;web design;interface;eye tracking;usability	Understanding the mechanisms of visual perception is important in the context of both media research and its applications in design practice. Within the functional approach to interface design, eye tracking is an established method to analyze interface efficacy. At the same time, in today's media design, many rules have been established by practitioners and remain untested. In this mixed-method study, we combine web crawling, web analytics and heat map analysis based on eye tracking, and qualitative usability analysis of composite-graphic model of a website. We check whether eye tracking test results (numeric data and heat map analysis) correlate to usability of key pages of a large website, as measured qualitatively according to recommendations of leading design literature. Among large web spaces, university website clusters represent a special type and suit well for our analysis, as they unite very different publics and are multi-task. We elaborate and pre-test the methodology on three sites of leading universities in the USA and Russia (Harvard University, Moscow State University and St.Petersburg State University). Our results suggest that there is no direct link between design-based elements of page usability and numeric eye tracking data, but heat maps show correlation with design quality; this means we need to continue checking the suggested methodology on larger number of assessors.	color vision;computer multitasking;eye tracking;functional approach;heat map;human factors and ergonomics;inline linking;level of measurement;map analysis;usability;web analytics;web crawler;web design;web presence	Svetlana S. Bodrunova;Alexandr V. Yakunin;Artyom A. Smolin	2016		10.1145/3014087.3014113	web usability;web modeling;web design;human–computer interaction;computer science;multimedia;world wide web	HCI	-62.38612836029956	-48.04074064520421	51850
cb326be5a8d78b681ed8f6f2a67c16735211f2b8	studying multi-user settings for pervasive games	user study;test bed;multi user;multi user settings;pervasive game;mobile interaction techniques;social behaviour;pervasive applications;mobile interaction	Whenever a pervasive game has to be developed for a group of children an appropriate multi-user setting has to be found. If the pervasive game does not support the children with an adequate multi-user setting, unintended situations can emerge, such as a single user can dominate the game while the other users are bored and disinterested. In our research we approach that problem by investigating various multi-user settings that are characterized by a different distribution of interaction devices. We describe three multi-user settings, a pervasive game which we used as a test bed, and a user study with 18 children to find out how the multiuser settings influence the children's social behaviour as expressed by the level of activity for all group members, the off-task behaviour and the level of task-related conversations.	multi-user;pervasive informatics;testbed;usability testing	Karin Bee;Elisabeth André	2009		10.1145/1613858.1613891	simulation;mobile interaction;human–computer interaction;social behavior;computer science;operating system;multimedia;testbed	HCI	-54.36927772214434	-43.461235598076165	51921
dcb41a25b29a94e5e0ac586e111b41f97fec5590	urgent mobile tool for hearing impaired, language dysfunction and foreigners at emergency situation	mobile;context of use;accessibility;human centred design;human computer interface	This paper introduces a mobile application that allows deaf, language dysfunctioned, or non-native language users to report emergencies. An earlier version (booklet) was designed for hearing impaired person to be able to communicate with others without speaking. The current smart phone application allows calls to be made from a remote location. The screen transitions application follows the dialogue models used by emergency services. Users interact with the dialogues by tapping on icons or pictograms instead of using text messages. Evaluation by deaf people and a non-native speaker found that it was about three times quicker to report an emergency using this tool than it was by using text messages.	mobile app;pictogram;smartphone	Naotsune Hosono;Hiromitsu Inoue;Miwa Nakanishi;Yutaka Tomita	2014		10.1145/2628363.2633568	speech recognition;human–computer interaction;computer science;accessibility;operating system;mobile technology;multimedia;world wide web	HCI	-50.9122801615113	-44.01476449133728	51927
b109e6101f39e8c4d6f45bda708b8700da2a93a2	empathy: interactions with emotive robotic drawers	human robot interactions;video prototyping;wizard of oz experiment;interactive furniture;interaction design	The role of human-robot interaction is becoming more important as everyday robotic devices begin to permeate into our lives. In this study, we video-prototyped a user's interactions with a set of robotic drawers. The user and robot each displayed one of five emotional states - angry, happy, indifferent, sad, and timid. The results of our study indicated that the participants of our online questionnaire preferred empathetic drawers to neutral ones. They disliked robotic drawers that displayed emotions orthogonal to the user's emotions. This showed the importance of displaying emotions, and empathy in particular, when designing robotic devices that share our living and working spaces.	human–robot interaction;robot	Brian K. Mok;Stephen Yang;David Sirkin;Wendy Ju	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2563720	simulation;wizard of oz experiment;computer science;interaction design	Robotics	-51.94837873645696	-49.412688990139976	51975
6cdf63aa38eb54e3bebbc53b92a434fd200b7351	computer supported cooperative work	human resources	This paper explores the use of social awareness support as a potential solution to alleviate informal care al, and emotional load habitually associated with their duties. This is a preliminary contribution of the Vienna University of Technology to TOPIC project that is currently under development. In this paper we report on relevant literature, identify and consider technological and interaction challenges, and suggest mobile and ubiquitous computing for ambient solutions. We illustrate our approach by presenting briefly a prototype from our pre-study before concluding the paper.	computer-supported cooperative work;prototype;ubiquitous computing	Myriam Lewkowicz	2017		10.1007/978-3-319-17885-1_100175	economics;human resources;management	HCI	-61.697926005181486	-40.65129048448529	51996
67b032b6cf0211307d5b3b836f8fe8db7ef5c410	interaction design for supporting communication between chinese sojourners	culture shock;human computer interaction;design recommendations;computer mediated communication;interaction design;cross cultural communication	In our global village, distance is not a barrier anymore for traveling. People experience new cultures and face accompanying difficulties in order to live anywhere. Social support can help these sojourners to cope with difficulties, such as culture shock. In this paper, we investigate how computer-mediated communication (CMC) tools can facilitate social support when living physically separated from loved-ones in different cultures. The goal is to understand the design considerations necessary to design new CMC tools. We studied communication practices of Chinese sojourners living in the Netherlands and the use of a technology probe with a novel video communication system. These results led to recommendations which can help designers to design interactive communication tools that facilitate communication across cultures. We conclude the paper with an interactive communication device called Circadian, which was designed based on these recommendations. We experienced the design recommendations to be abstract enough to leave space for creativity while providing a set of clear requirements which we used to base design decisions upon.	computer-mediated communication;global village (telecommunications);interaction design;requirement;social support	Martijn ten Bhömer;Elise van den Hoven	2011	Personal and Ubiquitous Computing	10.1007/s00779-011-0482-1	culture shock;simulation;human–computer interaction;computer science;communication design;cross-cultural communication;interaction design;computer-mediated communication	HCI	-58.85215500475665	-40.41500353448591	52299
63dccc3a57fce8cae23bf8c9c8ef52bdf6bd383f	using spatial and temporal contrast for fluent robot-human hand-overs	robot sensing systems;fluency;human interaction;human robot interaction;receivers;observational study;trajectory;humans robot sensing systems robot kinematics receivers timing trajectory;fluency robot human hand overs;humans;communicative potential spatial contrast temporal contrast fluent robot human hand over robot human interaction human human interaction robot herb hand over action hand over pose unambiguous transition;robot human hand overs;robot kinematics;timing	For robots to get integrated in daily tasks assisting humans, robot-human interactions will need to reach a level of fluency close to that of human-human interactions. In this paper we address the fluency of robot-human hand-overs. From an observational study with our robot HERB, we identify the key problems with a baseline hand-over action. We find that the failure to convey the intention of handing over causes delays in the transfer, while the lack of an intuitive signal to indicate timing of the hand-over causes early, unsuccessful attempts to take the object. We propose to address these problems with the use of spatial contrast, in the form of distinct hand-over poses, and temporal contrast, in the form of unambiguous transitions to the hand-over pose. We conduct a survey to identify distinct hand-over poses, and determine variables of the pose that have most communicative potential for the intent of handing over. We present an experiment that analyzes the effect of the two types of contrast on the fluency of hand-overs. We find that temporal contrast is particularly useful in improving fluency by eliminating early attempts of the human.	baseline (configuration management);experiment;human–robot interaction;robot	Maya Cakmak;Siddhartha S. Srinivasa;Min Kyung Lee;Sara B. Kiesler;Jodi Forlizzi	2011	2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1957656.1957823	human–robot interaction;computer vision;interpersonal relationship;simulation;computer science;artificial intelligence;trajectory;observational study;robot kinematics	Robotics	-50.27494080147583	-51.037730379288966	52337
ef63557d64397bdad0534704784330208759257c	using semantics to automatically generate speech interfaces for wearable virtual and augmented reality applications	speech maintenance engineering visualization speech recognition semantics face;semantics;speech;maintenance engineering;visualization;speech recognition;face;wearable devices augmented reality ar automatic user interface generation semantics speech virtual reality vr	This paper presents a framework for automatically generating speech-based interfaces for controlling virtual and augmented reality (AR) applications on wearable devices. Starting from a set of natural language descriptions of application functionalities and a catalog of general-purpose icons, annotated with possible implied meanings, the framework creates both vocabulary and grammar for the speech recognizer, as well as a graphic interface for the target application, where icons are expected to be capable of evoking available commands. To minimize user's cognitive load during interaction, a semantics-based optimization mechanism was used to find the best mapping between icons and functionalities and to expand the set of valid commands. The framework was evaluated by using it with see-through glasses for AR-based maintenance and repair operations. A set of experimental tests were designed to objectively and subjectively assess first-time user experience of the automatically generated interface in relation to that of a fully personalized interface. Moreover, intuitiveness of the automatically generated interface was studied by analyzing the results obtained through trained users on the same interface. Objective measurements (in terms of false positives, false negatives, task completion rate, and average number of attempts for activating functionalities) and subjective measurements (about system response accuracy, likeability, cognitive demand, annoyance, habitability, and speed) reveal that the results obtained by the first-time users and experienced users with the proposed framework's interface are very similar, and their performances are comparable with those of both the considered references.	augmented reality;finite-state machine;first-time user experience;general-purpose modeling;graphical user interface;mathematical optimization;natural language;optimization mechanism;performance;personalization;speech recognition;speech synthesis;vocabulary;wearable technology	Fabrizio Lamberti;Federico Manuri;Gianluca Paravati;Giovanni Piumatti;Andrea Sanna	2017	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2016.2573830	maintenance engineering;face;computer vision;speech recognition;visualization;human–computer interaction;computer science;speech;artificial intelligence;operating system;machine learning;semantics;linguistics;multimedia	Visualization	-48.58248022117504	-44.57124961092856	52538
c0600b9fc4da009f5c430c8adcb911ec046fbe99	two issues for an ambient reminding system: context-awareness and user feedback	context awareness;ambient intelligence;user feedback;interface agent;personal time management	Busy people would benefit from ambient, adaptive tools for reminding them what they have to do, depending on various contextual parameters. We are developing an adaptive and expressive agent, which learns when and how to notify users about self-assigned tasks and events. In this paper, we focus on two crucial issues for such a system: the selection of the input data set, and the design of an appropriate mechanism to get user feedback without being too intrusive. We describe in particular the inputs that encapsulate the current context of the agent: relative temporal distances, historical information about reminders and categories, and the context of both the user and the hosting device.		Nadine Richard;Seiji Yamada	2007			simulation;ambient intelligence;human–computer interaction;computer science;multimedia	Robotics	-55.76441313563764	-44.73443939870501	52543
fbd07a2c206594200bf93415998197a8ac1daa2d	responsive robot gaze to interaction partner	human robot interaction	Eyes play a central role in human-human communication, for example, in directing attention and regulating turntaking. For this reason, the eyes have been a central topic in several fields of interaction study. Although many psychological findings have encouraged previous work in both human-computer and human-robot interaction studies, there have been few explorations from the viewpoint of the timing of gaze behavior. In this study, the impression a person forms from an interaction is regarded to be strongly influenced by the feeling of being looked at which is assumed to be based on the responsiveness of the other’s gaze to the person’s one and be the basis of impression conveyance as a communicative being. In this paper, we built a robot that could move its gaze responsively to its interaction partner’s one to explore the effect of responsive gaze. In this paper, we evaluated two primitive ways of controlling a robot’s gaze responsively to its partner and confirmed that robots with such responsive gaze could give stronger feeling of being looked at than ones with non-responsive gaze.	human–robot interaction;interaction technique;responsiveness;robot	Yuichiro Yoshikawa;Kazuhiko Shinozawa;Hiroshi Ishiguro;Norihiro Hagita;Takanori Miyamoto	2006		10.15607/RSS.2006.II.037	human–robot interaction;computer science;artificial intelligence	HCI	-51.67191478609359	-50.08895954947655	52640
0421e74f5288192a45e431aad885a5b9e1d23f59	intelligent document assistant processor for pen-based computing systems	document handling;human computer interaction;intelligent user interface;roughly drawn documents;expert systems;intelligent document assistant processor;user interface;user interfaces computer interfaces power system modeling application software computational intelligence shape system software writing robustness keyboards;satisfiability;ease of use;h cos pen based computing systems idap intelligent document assistant processor intelligent user interface roughly drawn documents neat documents;pen based computing systems;neat documents;document image processing;h cos;pen based computing;idap;user interfaces;expert systems document handling user interfaces document image processing	"""In this paper, we present the framework design of IDAP (Intelligent Document Assistant Processor) with the capability of intelligent user interfme for pen-based computer systems. No conventional computer user interface am compete with pen and paper until now in terms of convenience and ease of use in generating documents. The system gets roughly d m n documents from users, ancE generates neat documents satisfiable to users.Rough document includes Mwri t ten texts, hand-dram tables, hand-drawn diagrams, handwritten mthematieul expressions. The satisfation of users is at least as important as the functionalitv and performance in pen-based system Therefore, sophisticaled user inte@ie is critical for a succes.ytb1 design Intelligent user interface methodology is employed to make the wstem more intelligent, natural, and ease of use. Human-computer interaction model &led H-COS is proposed for pen-based applimtions, and the model is applied to design IDAP. 1. PRELIMINARY Pen and paper is still used dominantly in everyday life, even though various kinds of powerful computer systems are available in reasonable prices. Pen-based computing system is an emerging technology [TappW, Chow88, Micr931 which can provide pen-and-paper-like interface to users. The input mechanism of pen-based system is natural and intuitive. It provides a natural pen-like input mechanism, i.e. users can write on the screen as if they write on the paper. Users can write/draw using electronic pens approximately as accurate as they do by pens. A text can be inserted where it is written, and a drawn shape can be placed at the drawing location. Users can select a small object in the screen rapidly and accurately. In the past computer systems were developed focusing on only functionality and performance. This research was partly supported by the grants from the Inha University and CAIR, KAIST .I _._.._""""--__--__-___ """""""".."""".,"""""""""""" Computer users were usually assumed to be familiar with applications and related system softwares. Not much efforts were spent for user interface designs. The assumption of expertized or well-trained users is no more valid these days since today's users of computer systems are expanded to ordinary people. Recently, much research has been done on more flexible and intelligent user interfaces Kohe90, Manh9l,Sas@Zl. In making a document, no conventional computer interface can compete with pen and paper until now in terms of convenience and ease of use. The pen-based system has the potential of providing pen-and-paper-like user interface as well as exploring computational power of computer system. A number of pen-based applications will grow dramatically in the next few years. In this paper, we will present a framework of IDAJ? (Intelligent Document Assistant Processor) aiming at a pen-based document generation tool. Document may include short notes, tables, sketched diagrams, mathematical expressions, etc. The primary goal of IDAP is to assist novice users in malung neat documents by only writing/drawing rough documents. Previous research for document generation tools [Tama881 has only dealt with the document synthesis in limited domains, and no user-friendly interface has been considered. The functional view of a pen-based computing system is given in Fig. 1. A user writes or draws pen data and commands an the LCD screen to make a desired document (i.e., pretty document). The pen-based computer system takes pen data of handwritt""""d-drawn document and pen commands as inputs, and produces a pretty document as output. Pretty document means a document which is satisfiable to the user as well as readable to other people. The desirable design strategies of pen-based computer system are: ease of use and enjoyable to learn; supporting for users at different level of expertise; simplicity and consistency; simplifying the beginner's task in learning the system's functions (A simplified user interface hiding the more complex function of the system.); progressively disclosing 0-8186-7128-9/95 $4.00"""	cos;centre for artificial intelligence and robotics;computation;computer;diagram;dynamic random-access memory;human-readable medium;human–computer interaction;intelligent document;intelligent user interface;pen computing;table (database);usability;user (computing)	Phill K. Rhee;T. Fujisaki	1995		10.1109/ICDAR.1995.602093	human–computer interaction;computer science;multimedia;user interface;world wide web;expert system	HCI	-48.572472504774424	-42.941266446777256	52692
fff011e3b9e94c99131a6150aaf8b6a3a8addb89	managing color in interactive systems	specification;software engineering;interactive system;user interface design;documentation	Color in the HCI community is often undervalued as to its relationship to the user and product. Aesthetics and cultural preferences are rarely considered adequately when product and interface colors are chosen. Since ninety percent of our knowledge of the world comes to us through sight, how we respond to light is intrinsic to the nature of human interaction. In this tutorial, I will explain the perceptual, physiological, and color management principles that underlie effective visual design with color. You will learn how to apply these principles to the design of graphical user interfaces, information displays, products and virtual environments. This tutorial is directed towards interface designers, human factors engineers, usability specialists, and developers of on-line information. This course is also valuable to virtual environment designers and product designers. You should have experience in developing user interfaces, in creating and manipulating digital imagery, or in designing products and virtual environments. Vision, light and color I will explain the physiology of human perception and how it relates to image representation. I will review how the concept of gamma correction, which is ubiquitous in computer graphics and video, accomplishes “perceptually-uniform” coding yet accounts for the variance of color rendering between devices. This will give you a basis of understanding for whether two different intensity levels can be distinguished. Human vision adapts over a wide range of intensities. Your viewer’s impression of your work will be determined by her viewing conditions, so you must take into account the expected viewing conditions when you create your work. Visual acuity is at a maximum only in a small portion of the visual field. As the angle from the center of the gaze increases, acuity is reduced, but sensitivity to movement and flicker increases. To make effective use of vision in an interactive system, you must be familiar with these characteristics. Contrast sensitivity is the measure of visual acuity. Familiarity with contrast sensitivity will help you to determine how much detail you can expect your viewer to perceive. I will define contrast ratio, and explain how you can maximize contrast ratio to improve subjective sharpness. Rarely in the science of color is it explained that it is the size and shape of an object and the colors generated in the surrounding visual field that influence our perception of a color. I will explain how Dithering creates the illusion of a large number of hues and tones or colors in a limited medium. I will explain how you can employ perceptual principles to use halftoning and dithering effectively. The characteristics of vision explain which combinations of colors and patterns are effective, and which are not. The phenomenon of chromostereopsis causes blue to appear at a different depth in some circumstances; I will demonstrate this effect. I will review the reasons that blue exhibits poor sharpness, and explain why you should avoid placing detail in blue. I will also outline color deficient vision color blindness and explain how this problem can be accommodated. Color psychology and cultural preferences It’s curious to understand how societies used and understood color from a historical context. Early evidence confirmed that there is no connection between language and perception. Covered briefly, I shall see the role that color played in defining cultures. Classic color psychology suggested that there were temporary physical changes resulting from exposure	acutance;color management;computer graphics;contrast ratio;display device;dither;expect;flicker (screen);gamma correction;graphical user interface;human factors and ergonomics;human–computer interaction;interactivity;online and offline;usability;user interface design;virtual reality	Mary A. Mooney	1998		10.1145/286498.286649	user interface design;interactive systems engineering;human–computer interaction;documentation;computer science;software design;functional specification;interactive media;adaptation;user interface;specification;software system	HCI	-49.883844548631224	-45.0497980846392	52841
b94a25e8fb7988fa81249d7e70954faab6d7ce77	considerations for the design of exergames	rstdpub exergaming games;bepress selected works;rstdpub;game design;exergaming;video game;games;success factor	Exergaming is the use of video games in an exercise activity. In this paper we consider game design for successful exergames. To do this, we review the history of exergaming and the current state of research in this field. We find that there exists some research aimed at evaluating the physical and health characteristics of exergames, but research on how to design exercise games is still in the early stages. From an analysis of this information, and drawing on established principles from sports science for the prescription of exercise programs, we then attempt to identify success factors to guide designers of exergaming systems.		Jeff Sinclair;Philip Hingston;Martin Masek	2007		10.1145/1321261.1321313	game design;games;simulation;human–computer interaction;computer science;multimedia	HCI	-61.97646914639961	-43.44201358615328	52952
3802a90af68ddd0053ccceb21ae3e69699c073e9	a data-driven approach to model culture-specific communication management styles for virtual agents	simulation;culture;behavior;communication management;virtual agents;virtual agent;multiagent systems	Virtual agents are a great opportunity in teaching intercultural competencies. Advantages, such as the repeatability of training sessions, emotional distance to virtual characters, the opportunity to over-exaggerate or generalize behavior or simply to save the costs for human training-partners support that idea. Especially the way communication is coordinated varies across cultures. In this paper, we present our approach of simulating differences in the management of communication for the American and Arabic cultures. Therefore, we give an overview of behavioral tendencies described in the literature, pointing out differences between the two cultures. Grounding our expectations in empirical data we analyzed a multi-modal corpora. These findings were integrated into a demonstrator using virtual agents and evaluated in a preliminary study.	intelligent agent;modal logic;repeatability;simulation;text corpus	Birgit Endrass;Elisabeth André;Lixing Huang;Jonathan Gratch	2010		10.1145/1838206.1838220	simulation;computer science;knowledge management;artificial intelligence;multi-agent system;communications management;culture;behavior	HCI	-54.499506440095296	-48.24156261685221	52995
d233ce525050aef1e8a5ea7693cae5c153798a21	evaluation of an ssvep and eye gaze hybrid bci		An evaluation of a hybrid Brain-Computer Interface that combines input modalities of Steady State Visual Evoked Potential (SSVEP) and eye gaze is provided. Thirty volunteers participated and all but one could use the BCI, eye-tracker and hybrid system. The hybrid BCI was compared with SSVEP alone for navigating to four domotic tasks issued via a graphical user interface. Mean performance metrics of Accuracy (Acc.), Efficiency (Eff.) and Information Transfer Rate (ITR) all improved (mean Acc. = 93.3% to 99.84%, mean Eff. = 89.56% to 99.74%, mean ITR = 23.78 to 24.41 bpm). While the absolute improvements are small, better performance may contribute to user acceptability, as the eye-gaze component adds minimal additional user effort to the interaction yet provides control that is more robust.	brain–computer interface	Chris P. Brennan;Paul J. McCullagh;Gaye Lightbody;Leo Galway	2017		10.3217/978-3-85125-533-1-09	brain–computer interface;information transfer;hybrid system;computer vision;eye tracking;artificial intelligence;graphical user interface;computer science	Vision	-48.343193233544476	-46.31908811006067	52997
c64329e9dae609d553843732cf41f5bead34934b	combining empirical studies of audio-lingual and visual-facial modalities for emotion recognition	empirical study;multi modal interface;emotion recognition;facial expression analysis;human subjects;affective user modeling;audio lingual affect recognition;visual facial affect recognition;multi modal interfaces;empirical studies;facial expression;user model	In this paper, we present and discuss two empirical studies that we have conducted involving human subjects and human observers concerning the recognition of emotions from audio-lingual and visual-facial modalities. Many researchers agree that these modalities are complementary to each other and that the combination of the two can improve the accuracy in affective user models. However, there is a shortage of research in empirical work concerning the strengths and weaknesses of each modality so that more accurate recognizers can be built. In our research, we have investigated the recognition of emotions from the above mentioned modalities with respect to 6 basic emotional states, namely  happiness,  sadness, surprise, anger and  disgust as well as the emotionless state which we refer to as  neutral . We have found that certain states such as neutral happiness and surprise are more clearly recognized from the visual-facial modality whereas sadness and disgust are more clearly recognized from the audio-lingual modality.	emotion recognition	Maria Virvou;George A. Tsihrintzis;Efthymios Alepis;Ioanna-Ourania Stathopoulou;Katerina Kabassi	2007		10.1007/978-3-540-74827-4_141	psychology;cognitive psychology;communication;social psychology	HCI	-50.98141041793318	-48.2731973897836	53008
76b69aa5a2f03ed3bcc3ff7a0ab80c57d97c1c84	referential communication as a collective property of a brain-body-environment-body-brain system: a minimal cognitive model		Referential communication is a complex form of social interaction whereby agents manage to coordinate behavior with respect to features that are not immediately present during the interaction. A famous example from nature is the bee waggle dance. We used an minimal cognitive approach to create a model of referential communication that is sufficiently minimal to permit a full dynamical analysis, and yet still complex enough so that the results provide a useful perspective onto the processes that could be involved in natural referential communication. The task is for two embodied agents to interact in a “hive” area such that one of the agents (the receiver) is able to move to a specific “target”, the location of which is only available to the other agent (the sender). The task implicitly requires adopting the right role (sender vs. receiver), disambiguating between translational and communicative motion, and switching from communicative to target seeking behavior. Similar to the waggle dance, the best solution involved a correlation between duration of contact and distance to be traveled. Dynamical analysis revealed that this behavior cannot be attributed to the sender in isolation.	apache hive;cognitive model;dynamical system;embodied agent	Jorge I. Campos;Tom Froese	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8280856	communication;cognitive model;task analysis;social relation;cognition;waggle dance;embodied cognition;communication source;computer science	AI	-51.479653484891244	-49.7703749140482	53079
457e2c24909fc49fa0fc637cb949b0b0e33a929f	simkeys: an efficient keypad configuration for mobile communications	keyboards;text entry;text messaging;internet keyboards mobile radio ergonomics;cognitive process;internet;wireless internet;mobile radio;wireless internet keypad configuration mobile communication input efficiency ergonomics usability text messaging;mobile communication;ergonomics;mobile communication keyboards costs telephony ergonomics mobile computing message service usability optimization methods internet;mobile user	Although text messaging services are becoming increasingly popular in today's global wireless market, fundamental design issues still linger with respect to text entry methods on mobile communication devices. Current methods may often be plagued with problems such as poor typing efficiency, stringent physical size limitations, and an unwarranted cognitive processing burden on mobile users. The proposed text entry method for mobile communication devices, called SIMKEYS, balances input efficiency, ergonomics, usability, and cost via a compact 12-button keypad. Pursuing a deterministic and linguistically optimized approach to character disambiguation, SIMKEYS achieves significant improvement in typing performance over existing methods, verified by extensive simulation results. It also consumes negligible amounts of system resources and incurs minimal development costs. Because of its simplicity and efficiency, SIMKEYS opens the door to exciting opportunities in the next stage of development of the wireless Internet.	cognition;human factors and ergonomics;list of code lyoko episodes;simulation;usability;word-sense disambiguation	Rick W. Ha;Pin-Han Ho;Xuemin Shen	2004	IEEE Communications Magazine	10.1109/MCOM.2004.1362557	mobile broadband;mobile identification number;mobile search;the internet;cognition;mobile web;mobile telephony;imt advanced;telecommunications;computer science;human factors and ergonomics;operating system;mobile technology;multimedia;mobile station;mobile computing;law;world wide web;mobile communications over ip;computer security;computer network;mobile payment	Mobile	-49.791931796472916	-42.2923504555267	53094
d0623d968983848d56a54e34c59a6806d0111268	understanding the opinion forming processes of experts and customers during evaluations of automotive sounds	pilot study;qa76 electronic computers computer science computer software;product design;ta engineering general civil engineering general	"""A challenge in automotive engineering is to understand the subjective reactions of individuals to vehicle sounds; this is necessary in order to improve decision making during product design. We can use """"structured evaluations"""" to achieve this, but we need to ensure that 1) we understand the reasons behind such evaluations i.e. the opinion forming process and 2) that such evaluations are analogous to appraisals of vehicles on the road. Hence for structured evaluations to be effective, it is important that we understand the opinion forming process in real-life situations. Since there is a lack of knowledge on how people form perceptions aboutvehicles in reality, an appraisals framework is described in this paper. Moreover, this paper discusses a pilot study that investigated how experts assess vehicle sounds on-road, as well as planned future studies to examine how customers evaluate automotive sounds."""		Louise Humphreys;Sebastiano Giudice;Paul Jennings;Rebecca Cain;Garry Dunne;Mark Allman-Ward	2009		10.1007/978-3-642-02728-4_41	simulation;engineering;operations management	ML	-61.58603753090403	-50.663659475468336	53265
0ad609178f816d2406c98288d8fdb469fbf188db	liquidtext: a flexible, multitouch environment to support active reading	user evaluation;design process;document representation;visualization;active reading;multitouch input;interaction technique	Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers' activities. Most computer-based active reading support seeks to replicate the affordances of paper, but paper has limitations, being in many ways inflexible. In this paper we introduce LiquidText, a computer-based active reading system that takes a fundamentally different approach, offering a flexible, fluid document representation built on multitouch input, with a range of interaction techniques designed to facilitate the activities of active reading. We report here on our design for LiquidText, its interactions and gesture vocabulary, and our design process, including formative user evaluations which helped shape the final system.	interaction technique;multi-touch;self-replicating machine;vocabulary	Craig S. Tashman;W. Keith Edwards	2011		10.1145/1978942.1979430	visualization;design process;human–computer interaction;computer science;multimedia;world wide web;interaction technique	HCI	-53.25026462861299	-42.11086469071821	53422
22e9639cc1edc681d8c194197952b73a7e774cbb	supporting distant familial relationships with the internet of things	closeness;internet of things;distant family relationships;in the wild study;awareness devices	In this paper we discuss the opportunities of 'off the shelf' Internet of things technologies to be used to support closeness in interpersonal relationships. We give our motivation to study IoT on technologies to support distant interpersonal relationships. We present two designs, 'SmartLamps' and 'Connected Rings', which use IoT technology to foster experiences of relatedness between distant families. We present some of the challenges faced while evaluating these devices using 'in the wild' research.	centrality;internet of things	Bhagyashree Patil;Ryan Kelly;Danaë Emma Beckford Stanton Fraser;Jeff Gavin;Clare Reddington	2016		10.1145/2968219.2968343	human–computer interaction;computer science;internet privacy;world wide web;internet of things	HCI	-58.355676113882176	-40.09662366596462	53442
0b8565378f777d4bb8e0606034bed09353c5cea2	robot humor: how self-irony and schadenfreude influence people's rating of robot likability	animals;market research;human computer interaction;legged locomotion;human robot interaction;animation	Humor in robotics is a promising, though not yet significantly researched topic. We performed a user study exploring two different kinds of laughter. In our study, participants observed a robot-robot interaction where an iCat and a NAO robot exhibited different laughing behavior. While NAO laughed at itself (self-irony), the iCat laughed at NAO (Schadenfreude1). Our participants watched four turns of the same robot-robot interaction, with either NAO or the iCat laughing, both robots laughing, or no robot laughing (baseline). After each turn we asked the participants to rate both robots' likability individually. Our results show that the participants liked a robot with a positively attributed form of humor significantly more than its gloating robotic interaction partner. However, likability ratings showed a trend to approach each other when either robot laughed or when both robots laughed together. Both, the higher likability ratings for a robot showing positively attributed humor and the decreasing difference in likability ratings when both robots laugh together, provide proof of the positive effect of humor. While participants' age did not affect likability ratings, there was a significant interaction effect between participants' gender and robot type. Female participants rated the iCat more likable, while male participants liked NAO better. In addition, more neurotic people liked the self-ironic robot more when no robot laughed and more open people like the robot showing Schadenfreude more when both robots laughed.	baseline (configuration management);human–robot interaction;irony;nao (robot);robot;usability testing	Nicole Mirnig;Susanne Stadler;Gerald Stollnberger;Manuel Giuliani;Manfred Tscheligi	2016	2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2016.7745106	market research;human–robot interaction;anime;simulation;computer science;artificial intelligence	Robotics	-51.620853312979314	-50.442878386857906	53461
e4c83b9b7525292f7211da27225dd35518d83b2e	jigsaw together: a distributed collaborative game for players with diverse skills and preferences	universal access;multiplayer games;collaborative interfaces	Presently it is very hard (or even impossible) to allow multiple players with highly diverse characteristics (including age, skills, and preferences) to collaboratively share and play a single jigsaw puzzle. Towards this end, the work presented in this paper aims to expand the capabilities of digital jigsaw puzzles in 3 directions: (a) multiplayability by a large number of players; (b) accessibility by people with handmotor and visual impairments; and (c) concurrent playability by people with highly diverse characteristics. In this context, we present an electronic puzzle game which supports single player as well as distributed multiplayer sessions by people with diverse characteristics. The paper introduces the background against which the work is based and describes the key design features of the resulting game's user interface and gameplay.	accessibility;emoticon;user interface	Dimitris Grammenos;Antonis Chatziantoniou	2014		10.1145/2593968.2610453	simulation;computer science;multimedia;world wide web	HCI	-54.111066327971336	-39.71671570787639	53809
48dfb2a6b49036b0cd4cba83fe188403cd5ef7fc	computer-supported human-human multilingual communication.	human interaction;service provider;indexing terms;multimodal integration;robust performance;multimodal interaction;perceptual user interface;human machine interaction;machine translation	Computers have become an essential part of modern life, providing services in a multiplicity of ways. Access to these services, however, comes at a price: human attention is bound and directed toward a technical artifact in a human-machine interaction setting at the expense of time and attention for other humans. This paper explores a new class of computer services that support human-human interaction and communication implicitly and transparently. Computers in the Human Interaction Loop (CHIL), require consideration of all communication modalities, multimodal integration and more robust performance. We review the technologies and several CHIL services providing human-human support. Among them, we specifically highlight advanced computer services for cross-lingual communication.	human–computer interaction;multimodal interaction	Alexander H. Waibel;Keni Bernardin;Matthias Wölfel	2006		10.1007/978-3-540-77296-5_25	service provider;interpersonal relationship;simulation;index term;computer science;artificial intelligence;multimodal interaction;multimedia;machine translation	HCI	-52.35203856080215	-38.98192947922821	53929
0bd1c15d4f123cfce0bd5afd996b877bfb6891a1	development of navigation skills through audio haptic videogaming in learners who are blind	orientation;mobility	This study presents the development of a video game with audio and haptic interfaces that allows for the stimulation of orientation and mobility skills in people who are blind through the use of virtual environments. We evaluate the usability and the impact of the use of an audio and haptic-based videogame on the development of orientation and mobility skills in school-age blind learners. The results show that the interfaces used in the videogame are usable and appropriately designed, and that the haptic interface is as effective as the audio interface for orientation and mobility purposes. © 2012 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Scientific Programme Committee of the 4th International Conference on Software Development for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2012)	accessibility;haptic technology;norm (social);software development;usability;virtual reality	Jaime Sánchez;Márcia de Borba Campos	2013	J. UCS	10.3217/jucs-019-18-2677	computer vision;simulation;computer science;multimedia	HCI	-55.77847530842884	-45.78669150636886	54041
d28314942ced289b86d7852adab0205113012305	accessible smart cities?: inspecting the accessibility of brazilian municipalities' mobile applications	accessibility evaluation;smart cities;mobile accessibility	The use of interactive technologies to aid in the implementation of smart cities has a significant potential to support disabled users in performing their activities as citizens. In this study, we present an investigation of the accessibility of a sample of 10 mobile Android™ applications of Brazilian municipalities, two from each of the five big geographical regions of the country, focusing especially on users with visual disabilities. The results showed that many of the applications were not in accordance with accessibility guidelines, with an average of 57 instances of violations and an average of 11.6 different criteria violated per application. The main problems included issues like not addressing labelling of non-textual content, headings, identifying user location, colour contrast, enabling users to interact using screen reader gestures, focus visibility and lack of adaptation of text contained in image. Although the growth in mobile applications for has boosted the possibilities aligned with the principles of smart cities, there is a strong need for including accessibility in the design of such applications in order for disabled people to benefit from the potential they can have for their lives.	android;crash reporter;interaction;mobile app;mobile device;smart city;usability;web content accessibility guidelines;web accessibility	Lucas Pedroso Carvalho;Bruno Piovesan Melchiori Peruzza;Flávia Santos;Lucas Pereira Ferreira;André Pimenta Freire	2016		10.1145/3033701.3033718	engineering;civil engineering;transport engineering;computer security	HCI	-50.341200109162195	-41.66945339200509	54250
f27746ea63ba837197813e1e9eaa2bf4b650e128	modelling noise-resilient single-switch scanning systems		Single-switch scanning systems allow nonspeaking individuals with motor disabilities to communicate by triggering a single switch (e.g., raising an eye brow). A problem with current single-switch scanning systems is that while they result in reasonable performance in noiseless conditions, for instance via simulation or tests with able-bodied users, they fail to accurately model the noise sources that are introduced when a non-speaking individual with motor disabilities is triggering the switch in a realistic use context. To help assist the development of more noise-resilient singleswitch scanning systems we have developed a mathematical model of scanning systems which incorporates extensive noise modelling. Our model includes an improvement to the standard scanning method, which we call fast-scan, which we show via simulation can be more suitable for certain users of scanning systems.		Emli-Mari Nel;Per Ola Kristensson;David J. C. MacKay	2017	CoRR		computer science;human–computer interaction;real-time computing	EDA	-49.3960664343111	-46.41855876258474	54296
b0083516adef849feefdc84e58a4e17114664f06	how to nudge in situ: designing lambent devices to deliver salient information in supermarkets	mobile device;nudging;tangible embedded interaction;recommender system;persuasive technology;in the wild study;mobile devices;social norm	There are a number of mobile shopping aids and recommender systems available, but none can be easily used for a weekly shop at a local supermarket. We present a minimal, mobile and fully functional lambent display that clips onto any shopping trolley handle, intended to nudge people when choosing what to buy. It provides salient information about the food miles for various scanned food items represented by varying lengths of lit LEDs on the handle and a changing emoticon comparing the average miles of all the products in the trolley against a social norm. When evaluated in situ, the lambent handle display nudged people to choose products with fewer food miles than the items they selected using their ordinary shopping strategies. People also felt guilty when the average mileage of the contents of their entire shopping trolley was above the social norm. The findings are discussed in terms of how to provide different kinds of product information that people care about, using simple lambent displays.	emoticon;mobile payment;norm (social);nudge (instant messaging);recommender system	Vaiva Kalnikaité;Yvonne Rogers;Jon Bird;Nicolas Villar;Khaled Bachour;Stephen J. Payne;Peter M. Todd;Johannes Schöning;Antonio Krüger;Stefan Kreitmayer	2011		10.1145/2030112.2030115	embedded system;simulation;computer science;operating system;persuasive technology;mobile device;computer security;recommender system	HCI	-52.16827648570968	-42.36351400325041	54373
5e2961b1785e552c30bc5ef304c1215f42b6c3fb	contextual affect sensing and metaphor interpretation	drama improvisation and intelligent agents;g700 artificial intelligence;contextual affect sensing;metaphor interpretation	Sensing social representations (e.g. relationships and common interests) of a conversation and recognizing affect and metaphor from context are challenging but essential for the building of an intelligent agent with emotion and social intelligence. In this paper, we report contextual affect detection based on emotion modeling of personal and social improvisational context. We also discuss cooking and sensory metaphor (including temperature, light, taste, and smell metaphors) interpretation. The overall affect sensing model has been embedded in an AI agent interacting with human users. The evaluation results indicated that the new development made the AI agent perform generally better in improvisational interaction. 2012 International Federation for Information Processing Published by Elsevier B.V. All rights reserved. 1 The bully, Mayid, is picking on a new schoolmate, Lisa. Elise and Dave (Lisa’s	algorithm;apple lisa;artificial intelligence;artificial neural network;bayesian network;embedded system;hidden markov model;intelligent agent;interaction;international federation for information processing;markov chain;nonlinear gameplay;norm (social);optimistic concurrency control;personalization;simulation;supervised learning;theory	Li Zhang;M. Alamgir Hossain	2012	Entertainment Computing	10.1016/j.entcom.2011.12.002	artificial intelligence;social psychology	AI	-52.95827603963558	-46.97468406992353	54393
0e353b43aa5e740177392d299949c6d409c0cae1	evidance: a mobile application for orchestrating multiple services ecologies	mobile;mobile service;interactive system;user experience;services;mobile application;everyday life	In this paper, we introduce some preliminary considerations on the design of interactive system in a service based-economy. The discussion is supported by an early design exploration of a mobile application aimed to support people in orchestrating multiple services ecologies in their everyday life.	ecology;interactivity;mobile app	Leonardo Giusti;Massimo Zancanaro	2010		10.1145/1864431.1864461	user experience design;simulation;service;mobile web;human–computer interaction;computer science;operating system;mobile technology;multimedia;mobile computing	HCI	-54.82809697815963	-38.95144524439444	54554
bd1a1e84d500ae0ec636a39c58c876bf4a9372ac	web-safe fonts for device-independent mobile web applications	user interface;device independent applications;web safe fonts;web applications;mobile web	The increasing diversity of mobile devices used to access web applications cause new problems to developers of device-independent mobile web applications. One of them is related to inconsistent fonts support. This paper provides font usage guidelines for the mobile Web. The guidelines are based on results of a font availability detection experiment we have carried out on a wide range of diverse mobile devices. The paper includes a detailed description of the experiment methodology and a summary of results.	mobile device;web application;web typography	Jacek Chmielewski	2013		10.1145/2536853.2536916	web service;web application security;web development;web application;web modeling;mobile search;cross-origin resource sharing;web analytics;mobile web;web mapping;web-based simulation;web design;web accessibility initiative;web standards;computer science;operating system;web navigation;web page;database;multimedia;user interface;world wide web;mashup	Web+IR	-51.13777952991899	-41.43164126287678	54730
0520da81637d7b705e47f4452849842070e98d4c	the wall: participatory design workspace in support of creativity, collaboration, and socialization	team production;collaboration;participatory design workspace;social behavior;global team;participatory design;social work;exploratory study;high performance;knowledge work;shared workspace;geographic distribution	A key challenge faced by organizations is to provide project teams with workspaces, information, and collaboration technologies that fosters creativity and high-performance team productivity. This requires understanding the relation between and impacts of (1) workspace, (2) activity and content that is created, and (3) social, behavioral, and cognitive aspects of work. This paper describes an exploratory study of everyday activities in the context of knowledge work in a shared workspace used by a high-tech global design team that explores future products. The study formalizes key elements for productive knowledge work as a function of tasks, context, and team. It identifies enablers, hindrances, and requirements for physical, virtual, and social work environments. The study identified, through semi-structured interviews, surveys, and on-site shadowing, a key workspace component that facilitates dynamic participation of all team members. This workspace component is a wall used as a large, public, physical display surface for project content (the WALL). The WALL acts as a mediator for individual reflection-in-action and team reflection-in-interaction. It serves as “social glue” both between individuals and between geographically distributed subgroups.	requirement;semiconductor industry;socialization;workspace	Renate Fruchter;Petra Bosch-Sijtsema	2010	AI & SOCIETY	10.1007/s00146-010-0307-1	social science;simulation;social work;social behavior;knowledge management;exploratory research;collaboration;engineering support	HCI	-60.934306707449316	-38.908385790965276	54885
3fd7b028e215d1fc2af5a9463ca3e2c8943a22c0	universal principles of human communication: preliminary evidence from a cross-cultural communication game	cross-cultural;dialogue;experimental semiotics;icon;interaction;language evolution;pragmatics;symbol	The present study points to several potentially universal principles of human communication. Pairs of participants, sampled from culturally and linguistically distinct societies (Western and Japanese, N = 108: 16 Western-Western, 15 Japanese-Japanese and 23 Western-Japanese dyads), played a dyadic communication game in which they tried to communicate a range of experimenter-specified items to a partner by drawing, but without speaking or using letters or numbers. This paradigm forced participants to create a novel communication system. A range of similar communication behaviors were observed among the within-culture groups (Western-Western and Japanese-Japanese) and the across-culture group (Western-Japanese): They (a) used iconic signs to bootstrap successful communication, (b) addressed breakdowns in communication using other-initiated repairs, (c) simplified their communication behavior over repeated social interactions, and (d) aligned their communication behavior over repeated social interactions. While the across-culture Western-Japanese dyads found the task more challenging, and cultural differences in communication behavior were observed, the same basic findings applied across all groups. Our findings, which rely on two distinct cultural and linguistic groups, offer preliminary evidence for several universal principles of human communication.		Nicolas Fay;Bradley Walker;Nik Swoboda;Ichiro Umata;Takugo Fukaya;Yasuhiro Katagiri;Simon Garrod	2018	Cognitive science	10.1111/cogs.12664	psychology;social psychology;cross-cultural;cross-cultural communication;human communication;pragmatics;symbol;icon	HCI	-53.19645321008825	-48.52626473337169	54984
4673a341995134f8b83c70b6c94103f6f325c23b	shyness level and sensitivity to gaze from agents - are shy people sensitive to agent's gaze?		This paper reports how shy people perceive different amount of gaze from a virtual agent and how their perception of the gaze affects comfortableness of the interaction. Our preliminary results indicate shy people are sensitive to even a very low amounts of gaze from the agent. However, contrary to our expectations, as the amounts of gaze from the agent increases, shy people had more favorable impression toward the agent, and they did not perceive the adequate amount of gaze as most comfortable.		Tomoko Koda;Masaki Ogura;Yu Matsui	2016		10.1007/978-3-319-47665-0_33	psychology;cognitive psychology;communication;social psychology	HCI	-52.19622007281813	-51.59239945458333	55030
a09f13e2d04500fa6d9402d0ed227bc0528b8f82	experience tags: enriching sensor data in an awareness display for family caregivers	awareness displays;subjective tags;interaction design	The design of awareness displays to support family care has been explored in many recent studies. Whereas user studies indicate that caregivers are interested to know seniors’ subjective experiences regarding activities, events and general attitudes, product developers tend to focus on using sensors to automatically detect the state and context of seniors in time, resulting in systems that are unable to capture the seniors’ experiences. This short paper presents experience tagging, a mechanism which enables end-users to enrich sensor data using subjective tags. A research concept of an awareness display for family caregivers is presented to illustrate how the mechanism can be integrated in the design of an awareness display. The preliminary findings from a 4-week field trial with three caregiver/senior couples are presented. As a next step, the use of experience tags could be studied in other settings where people or systems are interested to know the user perspective on sensor data.	experience;industrial and organizational psychology;nl (complexity);sensor;usability testing	Martijn H. Vastenburg;Natalia Romero Herrera	2011		10.1007/978-3-642-25167-2_38	human–computer interaction;computer science;interaction design;multimedia	HCI	-58.09464724400018	-43.125248644324195	55187
fde4a393b8675b7cbb0a8bb98977fa0ff9226a45	knowledge in co-action: social intelligence in collaborative design activity	coordinated autonomy æ graphical interaction æ knowledge in co-action æ parallel coordinated moves æ social intelligence	Skilled cooperative action means being able to understand the communicative situation and know how and when to respond appropriately  for the purpose at hand. This skill is of the performance of knowledge in co-action and is a form of social intelligence for  sustainable interaction. Social intelligence, here, denotes the ability of actors and agents to manage their relationships  with each other. Within an environment we have people, tools, artefacts and technologies that we engage with. Let us consider  all of these as dynamic representations of knowledge. When this knowledge becomes enacted, i.e., when we understand how to  use it to communicate effectively, such that it becomes invisible to us, it becomes knowledge in co-action. A challenge of  social intelligence design is to create mediating interfaces that can become invisible to us, i.e., as an extension of ourselves.  In this paper, we present a study of the way people use surfaces that afford graphical interaction, in collaborative design  tasks, in order to inform the design of intelligent user interfaces. This is a descriptive study rather than a usability study,  to explore how size, orientation and horizontal and vertical positioning, influences the functionality of the surface in a  collaborative setting.  	artificial intelligence	Satinder P. Gill;Jan O. Borchers	2008		10.1007/978-1-84628-927-9_3	simulation;parallel coordinates;human–computer interaction;computer science;knowledge management;artificial intelligence;social intelligence	HCI	-61.08246467331543	-39.41232289725845	55331
8610a91d600cdd80124b5fa000cad6726da0a4aa	evaluating a pervasive game for urban awareness		The combination of augmented reality and pervasive games in urban environments can be exploited to enable situated and informal learning through ludic and engaging activities. In this research, we explore how to use such technologies to improve citizens' awareness about their urban environment by means of an AR pervasive game to learn about a specific urban space. Since the game is pervasively played in a physical space, many usability issues need to be assessed before evaluating whether it can engage citizens whilst promoting some sense of urban awareness. In this paper, we introduce a usability study of the application and a preliminary set of factors to be analysed to assess user engagement.	augmented reality;ludic interface;pervasive informatics;situated;usability testing;while	Federico Fabiano;Mónica Sánchez-Francisco;Paloma Díaz;Ignacio Aedo	2018		10.1145/3236112.3236140	situated;multimedia;pervasive game;augmented reality;usability;informal learning;business	HCI	-55.43676777606254	-39.04529174999615	55342
0fd22b1989fa91e023288ab15b64fd593c349495	the emotional hearing aid: an assistive tool for children with asperger syndrome	real time;autism;theory of mind;spectrum;dynamic bayesian networks;facial expression analysis;dynamic bayesian network;asperger syndrome;experimental evaluation;facial expression;mind reading;hearing aid;social environment	People diagnosed along the autistic spectrum often have difficulties interacting with others in natural social environments. The emotional hearing aid is a portable assistive computer-based technology designed to help children with Asperger syndrome read and respond to the facial expressions of people they interact with. The tool implements the two principal elements that constitute one’s ability to empathize with others: the ability to identify a person’s mental state, a process known as mind-reading or theory of mind, and the ability to react appropriately to it (known as sympathizing). An automated mind-reading system attributes a mental state to a person by observing the behaviour of that person in real-time. Then the reaction advisor suggests to the user of the emotional hearing an appropriate reaction to the recognized mental state. This paper describes progress in the development and validation of the emotional hearing aid on two fronts. First, the implementation of the reaction advisor is described, showing how it takes into account the persistence, intensity and degree of confidence of a mental state inference. Second, the paper presents an experimental evaluation of the automated mind-reading system on six classes of complex mental states. In light of this progress, the paper concludes with a discussion of the challenges that still need to be addressed in developing and validating the emotional hearing aid.	assistive technology;interaction;mental state;mind;norm (social);persistence (computer science);real-time clock	Rana El Kaliouby;Peter Robinson	2005	Universal Access in the Information Society	10.1007/s10209-005-0119-0	computer science;mind-blindness;dynamic bayesian network	HCI	-56.056274562121615	-51.799112251357556	55404
2c8c1c59fb985e6bceb89548c9df2564dd143340	early steps towards understanding text legibility in handheld augmented reality	text legibility understanding follow on user based studies text label rendering text drawing approach screen aligned annotation mobile tracking capability graphic display ar handheld augmented reality;color perception handheld augmented reality user interface design text legibility;color perception;rendering computer graphics augmented reality mobile computing;user interface design;handheld augmented reality;augmented reality;text legibility;rendering computer graphics;mobile computing;augmented reality mobile communication color lighting visualization guidelines	Over the past decades, augmented reality (AR) has seen vast improvements in graphic displays and mobile tracking capabilities. To our knowledge, handheld AR researcher in text legibility has mostly focused on algorithms for overlaying screen-aligned annotations; no one has yet employed a series of user-based studies to systematically investigate text legibility in handheld AR applications. In this preliminary work, we survey current approaches to text depictions in AR applications and the literature. We have found no single consistent form of displaying text, but see some basic trends emerging. This initial work lays the foundation for examining different text styles in various environments in order to create guidelines for effective text drawing approaches. By assessing current strategies for rendering text labels in handheld AR, we can catalog drawing styles for use in follow-on user-based studies.	ascii art;algorithm;augmented reality;handheld game console	Brittany Dao;Joseph L. Gabbard	2013	2013 IEEE Virtual Reality (VR)	10.1109/VR.2013.6549411	user interface design;computer vision;augmented reality;computer-mediated reality;human–computer interaction;computer science;operating system;multimedia;color vision;mobile computing;computer graphics (images)	Visualization	-48.87899464844937	-41.90604815927983	55419
a952bae0c7be29e8a55b958afe35cd2d21394c38	designing mobile services for mardi	design process;mobile device;co creation value mobile devices web content design;handheld computer;prototypes;web accessibility;co creation value;malaysian agricultural research and development institute mobile service design mobile handheld device web access desktop environment web sites design mobile web application design web content user centred design service science approach user satisfaction co creation value;user preferences;ease of use;proof of concept;mobile communication mobile handsets handheld computers navigation web design guidelines prototypes;web design mobile computing user centred design;web application design;navigation;mobile web;mobile service;web site design;web design;guidelines;mobile communication;mobile handsets;handheld device;web content design;user centred design;information navigation;mobile computing;agricultural research;user satisfaction;mobile application;mobile devices;handheld computers	Currently, mobile handheld device are being used increasingly for web access. This leads to the issue relating to the ease of use for users, which refers to not user-friendly web design, unorganized content and difficulty of information navigation. Based on literature analysis, design of physical features and functions for mobile devices are unique, as it should emphasize mobility, personality and flexibility features, apart from providing the added values, such as accessibility at anytime and anywhere access. However as most web applications are designed specifically for desktop environments, it is discovered that most web applications design are inappropriate for mobile devices. In other words, web sites design for desktop is unsuitable to be adopted for the mobile devices. Literature had stated that designing mobile web application approach differs from development ordinary web for desktop computer. Adapting the original web content dynamically to deal with the constraints of mobile handheld devices (the screen size and limited system resources and variation of user preferences) becomes very important. Combination of User Centred Design (UCD) and Service Science (SS) approach expected to enhance quality of the mobile web that can meet user satisfaction. As such the purpose of this study is to identify the design of mobile web content that is suitable for users' in which it meet users' values and requirement. The work conducted uses a co-creation approach in which co-creation values are obtained through a series of process. Co-creation value is essential as it is the missing part that is not being incorporated during the design process. As a result a guideline on web mobile design application based on co-creation values is established. The investigations presented in this paper highlight some ways in development of mobile web applications by adopting co-creation value with customer to make it more accessible to mobile devices. A case study conducted at Malaysian Agricultural Research And Development Institute (MARDI) as its web mobile applications is still at its initial. A prototype system based on the proposed guideline is provided as a proof of concept and shows the difference required in web applications for mobile design where values are incorporated.	accessibility;anytime algorithm;desktop computer;display size;internet access;mobile app;mobile device;prototype;usability;user (computing);user-centered design;wd anywhere access;web application;web content;web design	Daud Endam;Yazrina Yahya;Muriati Mukhtar;Wan Azlin Zurita Wan Ahmad	2011	Proceedings of the 2011 International Conference on Electrical Engineering and Informatics	10.1109/ICEEI.2011.6021570	web service;web application security;web development;web modeling;mobile search;web analytics;mobile web;web mapping;web design;human–computer interaction;web accessibility initiative;web standards;computer science;engineering;operating system;mobile technology;web navigation;mobile device;multimedia;mobile business development;web engineering;mobile computing;world wide web;web design program;mashup	HCI	-51.66693388367074	-41.163240644723814	55705
4bede503aebd3c936b5ff07e9c8537a45003d30f	child-centred design supported by comprehensive child application use analysis	conference item;user experience;user centred design;human and computer interaction	Since children already use and explore applications on smartphones, we use this as the starting point for design. Our monitoring and analysis framework, BaranC, enables us to discover and analyse which applications children uses and precisely how they interact with them. The monitoring happens unobtrusively in the background so children interact normally in their own natural environment without artificial constraints. Thus, we can discover to what extent a child of a particular age engages with, and how they physically interact with, existing applications. This information in turn provides the basis for design of new child-centred applications which can then be subject to the same comprehensive child use analysis using our framework. The work focuses on the first aspect, namely, the monitoring and analysis of current child use of smartphones. Experiments show the value of this approach and interesting results have been obtained from this precise monitoring of child smartphone usage.	experiment;information;java platform, standard edition;smartphone;unobtrusive javascript	Mohammad Hashemi;John Herbert	2016		10.1145/2930674.2936013	simulation;human–computer interaction;engineering;data mining	HCI	-56.99295493076273	-44.12153758347223	55715
79d2c487f38ea5d5df09364061cf57f80124ce7d	personalized web search based on the understanding level of a user		A system for mounting a flashlight on a firearm so that the mounting of the flashlight does not interfere with the sighting system, be it telescopic, non-telescopic, or a combination of the two. Various embodiments of mounts are disclosed for these several types of sightings systems. One embodiment for a telescope sight system comprises a separable mounting of the flashlight on the firearm which does not affect the mounting of the telescope sight.	web search engine	Soojung Lee	2008			world wide web;web modeling;sight;web page;telescope;human–computer interaction;flashlight;web service;web design;web navigation;computer science	Web+IR	-49.90892937646256	-38.853534111773875	56027
6977d7929360a4e68f3e8c5561ed5df3bd017d6e	relationship between personal space and the big five with telepresence robot	the big five;telepresence robot;personal space	"""The robot called """"Telepresence Robot"""" is on business in recent years. However, the robot does not consider user's personal space when the robot approaches the user. Telepresence robot might give users fear if the robot unintentionally invades the user's personal space when the user have conversation with the robot at the first time. To better develop the system of the robot, here we study about how near the robot approaches a user in advance. We verified the relationship between personal space and the big five by using neural network. It is revealed that the most influential factor for the neural network is agreeableness. By confirming user's personal space in advance, the conversation between Telepresence Robot and human becomes natural and interactive."""	telerobotics	Yoshifumi Kokubo;Eri Sato-Shimokawara;Toru Yamaguchi	2016		10.1007/978-3-319-43518-3_25	telerobotics;mobile robot;robot learning;computer vision;simulation;computer science;engineering;artificial intelligence;social robot;personal space;multimedia;ubiquitous robot;mobile robot navigation;personal robot	Robotics	-51.16240188609653	-49.87694567794863	56094
144bf3f6e11ddc00e32f20521454b3a39f232d22	improving public transit usability for blind and deaf-blind people by connecting a braille display to a smartphone	deaf blind;blind;accessibility;public transit usability	We conducted interviews with blind and deaf-blind people to understand how they use the public transit system. In this paper, we discuss key challenges our participants faced and present a tool we developed to alleviate these challenges. We built this tool on MoBraille, a novel framework that enables a Braille display to benefit from many features in an Android phone without knowledge of proprietary, device-specific protocols. We conducted participatory design with a deaf-blind person and describe the lessons learned about designing an interface for a deaf-blind person.	refreshable braille display;smartphone;usability	Shiri Azenkot;Emily Fortuna	2010		10.1145/1878803.1878890	simulation;computer science;accessibility;multimedia;internet privacy;world wide web	HCI	-49.47219274355624	-41.5889253352887	56160
18c8e3336b835fe2c0b7034325d9d7781f3b273b	using your fingers to think: enabling subjective routing with a rubber band metaphor	elasticity;tangible;interaction;visualization;tourism;exploration;metaphor;tangible interaction;constraints	There is a class of complex problems where solutions must satisfy multiple subjective criteria, while meeting speci ̄c quanti ̄able constraints. Route planning for leisurely travel is an example of a problem in this class. Constraints including total available time, transit times, and one's budget and subjective interests determine whether a potential solution is acceptable to a prospective traveler. In this paper we present a route planning (routing) interface that metaphorically leverages various elastic properties of a rubber band to allow for playful interaction with the relevant constraints. Each of these properties attenuation, tension, and color were integrated into an experimental system and then investigated in a series of task-based evaluations. Our research shows this playful interaction enables potential travelers to explore the solution space in order to ̄nd a route that meets, not only the easily quanti ̄able constraints, but also their own subjective preferences.	color;experimental system;feasible region;human computer;nl (complexity);nl-complete;numerical aperture;prospective search;routing	Andrew Bennett;Matthew J. D'Orazio;Christopher Peter Lueg	2015	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194015400148	interaction;simulation;visualization;exploration;computer science;engineering;artificial intelligence;elasticity;tourism	HCI	-49.435327880477686	-39.492976401123364	56397
8994812b0a96b98f0c8806b0caf92f75d70a5b6d	exploration of multimodal input interaction based on goals	interaction modalities;modality combinations;multimodal interaction;usability goals	Today applications demand newer and newer ways through which humans can interact with the system for effective and natural interaction. Each interaction modality have unique features and supports different interaction goals, which makes them logically appropriate for specific types of interaction necessary for different applications. With several multimodal input technologies now being available for users, a challenge is to design optimal combinations of multiple modalities for specific tasks. Also, it is important to understand that, how these modalities may coherently be used together in a well-coordinated manner. This paper presents our initial research wherein we did exploration with the objective of designing a scheme for identification of optimal multimodal input interaction for various applications and use cases. We identified the key interaction goals of few sample applications or usage scenarios, and systematically compared those with the capabilities of the modalities, in order to identify optimal multimodal combination for those applications.	interaction design;modality (human–computer interaction);multimodal interaction	Sanjay Ghosh;Anirudha N. Joshi	2013		10.1145/2525194.2525213	usability goals;simulation;computer science;multimodal interaction;multimedia	HCI	-52.194585809532406	-38.54442295875603	56415
493d7d8662484f5d2f9f7e486fe3c604780d91b4	seeing more: visualizing audio cues	user study;audio visual	Using audio visualization, we seek to demonstrate how natural interaction is augmented with the addition of interaction history. Our Conversation Clock visualization captures and represents audio in a persistent and meaningful representation to provide social cues not available in an otherwise ephemeral conversation. In this paper we present user study evaluation of the Conversation Clock as utilized by familiar groups and demonstrate how individuals use the salient cues to evaluate their own interaction.	audio signal processing;information;music visualization;usability testing	Tony Bergstrom;Karrie Karahalios	2007		10.1007/978-3-540-74800-7_3	computer vision;computer science;multimedia	HCI	-53.305265716716605	-45.015160392994126	56595
96210c8916c90f92d52df6af6009cd6966ad8c52	unconscious transmission services of human feelings	human nature;requirements elicitation;transmission of feelings;next generation;ubiquitous services	This paper was focused on the next generation of ubiquitous services by using ubiquitous networks and devices. This paper was especially focused on the transmission services of feelings to others. In the paper, some conventional transmission services of feelings were introduced and a few of the unconscious transmission services of feelings to both specific targets and multiple targets were pointed out. The paper proposed two examples of the new services that would enable the users to transmit their feelings unconsciously to others by using ubiquitous networks and devices. These services were proposed through the PRESPE (Participatory Requirements Elicitation using Scenarios and Photo Essays) approach and called respectively the “aura transmission system” and “back scratcher system”. Further discussion about the usefulness and possible negative influences on human nature or society by the new services was done, and the future research efforts of these services were described.		Mitsuhiko Karashima;Yuko Ishibashi	2007		10.1007/978-3-540-73345-4_9	psychology;knowledge management;communication;social psychology	Mobile	-58.018800414070796	-39.62372528617732	56619
faca7633d4f8cd042d2442eafc010f63eed332b1	interactive multimedia content for older adults: the case of seniorchannel		Interactive multimodal content fruition is increasingly available on platforms accessible via smart televisions (TVs), personal computers (PCs), or tablets. Based on the case of SeniorChannel TV, this paper contributes to understanding whether this format can meet the needs of older users. The paper first describes SeniorChannel TV and the usability guidelines according to which it was designed. It then reports two user studies, one of which was carried out in the field with seven test households and focused on usability. The second study was carried out in experience labs in Italy and Spain with 20 participants and assessed users’ satisfaction and an active audience’s experience with the final prototype. The paper offers encouraging results on the potential of interactive multimodal content to support an active audience experience, and it describes the double-level at which accessibility can be ensured.	accessibility;cognition;interactive media;multimodal interaction;personal computer;population;prototype;requirement;smart tv;social capital;tv tuner card;tablet computer;television;usability testing	Valeria Orso;Anna Spagnolli;Luciano Gamberini;Francisco Ibañez;Maria Elena Fabregat	2016	Multimedia Tools and Applications	10.1007/s11042-016-3553-5	simulation;human–computer interaction;multimedia;world wide web;computer security	HCI	-55.96281527776641	-38.533781483847434	57603
a9db4d8d77719b8c9312eba03582a72121dffcf9	vocalizing dance movement for interactive sonification of laban effort factors	interactive sonification;motion sound mapping;effort factors;multimodal;vocalization;movement qualities;laban movement analysis;effort factors movement qualities;dance	We investigate the use of interactive sound feedback for dance pedagogy based on the practice of vocalizing while moving. Our goal is to allow dancers to access a greater range of expressive movement qualities through vocalization. We propose a methodology for the sonification of Effort Factors, as defined in Laban Movement Analysis, based on vocalizations performed by movement experts. Based on the experiential outcomes of an exploratory workshop, we propose a set of design guidelines that can be applied to interactive sonification systems for learning to perform Laban Effort Factors in a dance pedagogy context.	sonification	Jules Françoise;Sarah Fdili Alaoui;Thecla Schiphorst;Frédéric Bevilacqua	2014		10.1145/2598510.2598582	simulation;computer science;engineering;multimodal interaction;dance;multimedia	HCI	-55.18940039371064	-47.109797249304506	57637
2568bf35de9d3eab2655168f7de588f3c73e30a3	multimodal human attention detection for reading	conference paper;human attention level;multimodal interaction;facial features;mouse dynamics	Affective computing in human-computer interaction research enables computers to understand human affects or emotions to provide better service. In this paper, we investigate the detection of human attention useful in intelligent e-learning applications. Our principle is to use only ubiquitous hardware available in most computer systems, namely, webcam and mouse. Information from multiple modalities is fused together for effective human attention detection. We invite human subjects to carry out experiments in reading articles being subjected to different kinds of distraction to induce different attention levels. Machine-learning techniques are applied to identify useful features to recognize human attention level. Our results indicate improved performance with multimodal inputs, suggesting an interesting affective computing direction.	affective computing;computer;experiment;human–computer interaction;machine learning;multimodal interaction;webcam	Jiajia Li;Grace Ngai;Hong Va Leong;Stephen Chi-fai Chan	2016		10.1145/2851613.2851681	computer vision;computer science;multimodal interaction;multimedia	AI	-52.54187127456615	-46.06933710141139	57824
cf4ca4ea9d3c5c6761564e4c962b2a4114f6101f	the use of voice input to induce human communication with banking chatbots		The use of chatbots is more common in our everyday lives than ever before. However, few studies have been conducted comparing the differences between text- and voice-input modalities of chatbots in the banking industry. In this study, through empirical and survey-based research, users were shown to rate their relationships with the banking chatbot as more helpful and self-validating when they communicate with it by a voice-input modality than by a text-input modality.	modality (human–computer interaction);software agent	Songhyun Kim;Junseok Goh;Soojin Jun	2018		10.1145/3173386.3176970	human–computer interaction;chatbot;modalities;computer science;direct voice input;human communication;human–robot interaction	HCI	-52.071932833387145	-48.760276368061064	57838
37ef4d5899097318bc58161b604fa21052be3801	a reflexive, not impulsive agent	conversational agents;design methodologies;social agents;agent tools	The aim of our present research is to build an Agent capable of communicative and expressive behavior. The Agent should be able to express its emotions but also to refrain from expressing them: a reflexive, not an impulsive Agent. A Reflexive Agent is an agent who thinks it over before displaying one's emotions, that is, one who, when feeling an emotion, &lquo;decides” not to display it immediately. In this paper we present our enriched discourse generator and we give a general overview of the factors that we consider to determine the displaying or not displaying of an emotion.	agent	Catherine Pelachaud;Isabella Poggi;Berardina De Carolis;Fiorella de Rosis	2001		10.1145/375735.376102	embodied agent;multimedia	AI	-53.1787780599931	-48.74453791718915	57966
3f53d44d11e334dab09ac09be8c356b53c0a01cc	lazy recognition as a principle of pen interfaces	pen interface;lazy recognition	The pen is suitable for creative work since one can express almost everything and is not bothered by the method to use. Experimental pen-based systems and products have not exploited the ‘aummted’ nature of handwriting. They try to recognize handwriting immediately after each pattern is written with the result of frequent misrecognition and thus inte.nupt user’s thinking. This paper presents lazy nxognition scheme which delays the display of raognition until needed. One’s thought is better developed by working with one’s handwriting. Lazy recognition also provide easier structure to process handwritten patterns. Automatic segmentation of Chamctersand diagmms is described.	handwriting recognition;lazy evaluation	Masaki Nakagawa;Kimiyoshi Machii;Naoki Kato;Toshio Souya	1993		10.1145/259964.260121	natural language processing;speech recognition	Robotics	-48.63372122920626	-43.272875009790745	58081
51909222452d2381606b1bcbdaa9aad989c9c189	three types of viewers' favorite music videos	preference evaluation;kansei engineering;questionnaire survey;clustering;k means clustering;young people;music videos	The purpose of this study is to classify viewers' favorite music videos based on viewers' attributes evaluation and identify their characteristics. In this study, we designed a web-based questionnaire survey to collect data from forty-three young people. Participants watched fifteen music videos one-by-one and rated overall preference and twelve attributes with five-point scales. Then, we carried out the k-means clustering analysis according to the viewers' attributes evaluation ratings. As a result, we found that there were three types of viewers' favorite music videos. Viewers gave high evaluations to those music videos primarily because: (1) auditory-leading type: they liked music and singer; (2) visual-leading type: they were amazed by the imaging technique; (3) synergic type: they got favorable impressions overall.allIt is noteworthy that stories related to the lyrics and time-order structured had especially a positive impact on the viewers' evaluation.	cluster analysis;k-means clustering;synergy;web application	M. Kamata;K. Furukawa	2007		10.1145/1255047.1255087	psychology;multimedia;advertising;communication	HCI	-58.782252101551656	-46.056343993125815	58101
610d038c50f9bc151f7518c977063a86da93b1cf	a methodology for introducing competitive anxiety and pressure in vr sports training	flow;training;virtual reality;sports;social evaluative thread	*Correspondence: Ferran Argelaguet Sanz, Hybrid Team, Inria Rennes, Campus de Beaulieu, Rennes 35042, France e-mail: fernando.argelaguet_sanz@ inria.fr Athletes’ performances are influenced by internal and external factors, including their psychological state and environmental factors, especially during competition. As a consequence, current training programs include stress management. In this paper, we explore whether highly immersive systems can be used for such training programs. First, we propose methodological guidelines to design sport training scenarios both on considering the elements that a training routine must have and how external factors might influence the participant. The proposed guidelines are based on Flow and social-evaluative threat theories. Second, to illustrate and validate our methodology, we designed an experimental setup reproducing a 10 m Olympic pistol shooting. We analyzed whether changes in the environment are able to induce changes in user performance, physiological responses, and the subjective perception of the task. The simulation included stressors in order to raise a social-evaluative threat, such as aggressive public behavior or unforced errors, increasing the pressure while performing the task.The results showed significant differences in their subjective impressions, trends in the behavioral and physiological data were also observed. Taken together, our results suggest that highly immersive systems could be further used for training in sports.	email;immersion (virtual reality);mental state;performance;simulation;theory	Ferran Argelaguet;Franck Multon;Anatole Lécuyer	2015	Front. Robotics and AI	10.3389/frobt.2015.00010	simulation;flow;computer science;artificial intelligence;virtual reality;multimedia	HCI	-54.134802998802876	-50.722755947246384	58125
2645d69a83fb57b6ee5acc7e9f9ba8cbb82ff6cb	the need for new application specific interface elements	working life;design process;human computer interaction;socialvetenskap;psychology excluding applied psychology;user interface;interface element;social sciences;computer and information science;psychology;interface elements;natural sciences;samhallsvetenskap;domain specific style guide;psykologi exklusive tillampad psykologi;data och informationsvetenskap;workspace metaphor	The design of user interfaces for skilled workers in professional work settings should be based on style-guides that certify efficiency. Most of today’s style-guides and design guidelines over-emphasise general aspects or aspects relevant to novices. To increase efficiency both of the design process and of the resulting interface, more domain specific interface elements should be used. This paper explains the basic ideas of such domain specific style-guides and gives some examples from the health care domain.	user interface	Jan Gulliksen;M. Johnson;Mats Lind;Else Nygren;Bengt L. Sandblad	1993			human–computer interaction;computer science;multimedia	HCI	-61.93098925875313	-42.81286944092798	58191
00e62a8972771b83b171c6306cb0800c39c051b3	user-centered design with illiterate persons: the case of the atm user interface	automated teller machines;automated teller machine;internet protocols;user interface;speech;user centered design;context of use;computer networks;research and development;design method;self efficacy;functional illiteracy;user requirements;icons;participatory design;avatar;user interfaces;asynchronous transfer mode;mental model	One of the major challenges in current user interface research and development is the accommodation of diversity in users and contexts of use in order to improve the self-efficacy of citizens. A common banking service, which should be designed for diversity, is the Automated Teller Machine (ATM). This paper describes the various user-centered design techniques to involve the future users of an ATM for illiterate persons, and reports the results of applying the techniques to a group of six Dutch functional illiterate persons. First, it has resulted in a set of user requirements and promising redesign concepts for the current ATM, relating to hardware, functionality, order of actions, lay-out, interaction modalities, and the mental model of cash withdrawal. Second, it has provided insight into how user-centered design techniques should be applied to this specific, but heterogeneous, user group.	atm turbo;user interface;user-centered design	Anita H. M. Cremers;Jacomien G. M. de Jong;Johan S. van Balken	2008		10.1007/978-3-540-70540-6_104	simulation;human–computer interaction;computer science;multimedia	HCI	-53.03506260284972	-40.11124863262751	58209
ba09253de41a829a695af186ca69c63bdd0acd15	facial expressions as game input with different emotional feedback conditions	affective interfaces;user effectiveness;feedback;emotion;user experience;games;facial expression	"""We propose a game design approach that utilizes facial expressions as an input method under different emotional feedback configurations. A study was conducted in a shopping centre to assess our game """"EmoFlowers"""" focusing on user experience and user effectiveness. The study revealed that interaction with a game via facial expression is perceived naturally, is easy to learn, and provides a positive user experience."""	input method;user experience;video game design	Michael Lankes;Stefan Riegler;Astrid Weiss;Thomas Mirlacher;Michael Pirker;Manfred Tscheligi	2008		10.1145/1501750.1501809	psychology;simulation;multimedia;communication	HCI	-56.21482119711906	-47.62094661360155	58400
24a1cb5fbe3025180096a6c3795897c628d3b72c	engage people in pro-environmental behaviors through online prosocial interaction and pro-health intervention	pro environmental behavior;behavioral intervention;health and wellness;prosocial behavior	People are often unaware that everyday behavior and lifestyle choices involving food, exercise, and shopping all have varying levels of consequences on the environment. In fact, this makes it difficult for people to understand the mutual relationship between personal health and the environmental health. My thesis investigates a lifestyle intervention that emphasizes the mutual benefits of pro-health and pro-environmental behaviors. I further intend to investigate online prosocial interaction in this intervention and its impact on participant motivation to engage in pro-environmental behaviors.		Pei-Yi Kuo	2015		10.1145/2702613.2702615	prosocial behavior	HCI	-58.45206686771418	-51.2466501851854	58404
09b0e9a87b187d8ceb8764da0182b13e1a7f0b7c	supporting the on-site emergency management through a visualisation technique for mobile devices	mobile device;decision maker;temporal information;emergency management;handheld device;visual analytics;visual interfaces;mobile devices	In case of emergency, visual analytics applications may be a successful means for quickly organising necessary activities. They allow decision-makers to immediately visualise the status of the crisis, plan the evacuation and address people towards vacancies in emergency centres. Although the effectiveness of such applications is immediately clear, further support may be gained by allowing people to directly manage the emergency on site. In this sense, it seems to be particularly desiderable to provide interfaces which support visual analytics tasks on small and handheld devices without losing their communicative efficacy. In this article, we adopt and extend a visualisation techinque, named Framy, specifically conceived for visualising in a very intuitive way a large number of aggregates on very small devices. In particular, we show how it reveals to be suitable for the management of these kinds of emergencies by embedding and qualitatively aggregating both spatial and temporal information useful for catching status and evolution of events. An example concerning an evacuation scenario shows the Framy extended capability.		Luca Paolino;Marco Romano;Monica Sebillo;Giuliana Vitiello	2010	J. Location Based Services	10.1080/17489725.2010.537282	visual analytics;simulation;human–computer interaction;computer science;operating system;mobile device;multimedia;world wide web	HCI	-55.940647141750546	-43.34480402750826	58512
817134847476f9a3ef2a6b825beb473ac94c4a71	end-user visualizations	end user computing;end user development;handheld computer;hardware accelerator;conceptual framework;video game;low power;real time image warping;3d graphics;image warping;end user programming	Computer visualization has advanced dramatically over the last few years, partially driven by the exploding video game market. 3D hardware acceleration has reached the point where even low-power handheld computers can render and animate complex 3D graphics efficiently. Unfortunately, end-user computing does not yet provide the necessary tools and conceptual frameworks to let end-user developers access these technologies and build their own interactive 2D and 3D applications such as rich visualizations, animations and simulations. In this paper, we demonstrate the Agent Warp Engine (AWE), a formula-based shape-warping framework for end-user visualization.	3d computer graphics;end-user computing;hardware acceleration;low-power broadcasting;mobile device;simulation	Alexander Repenning;Andri Ioannidou	2008		10.1145/1385569.1385672	image warping;simulation;hardware acceleration;human–computer interaction;computer science;operating system;end-user computing;conceptual framework;multimedia;programming language;world wide web;3d computer graphics;computer graphics (images)	HCI	-48.93987812816187	-38.05922151375632	58637
4303bb85737ecae5fc27bdf598056defcb289a84	how do users make a people-centric slideshow?	emotions;slideshows;crowdsourcing	This paper presents a pilot user study that attempts to shed light on the ways users create people-centric slideshows, with the objective of scaling it up to a crowdsourcing experiment. The study focuses on two major directions, namely image selection and image sequencing. Participants were asked to select photos of a specific person from an initial set and arrange them into a slideshow. Results show that there is correlation between specific predictors and selected images, as well as their relative position in the final sequence. This indicates that a crowdsourcing experiment will indeed highlight the characteristics of the average user, which can then be incorporated into an automatic people-centric slideshow creator.	crowdsourcing;image scaling;usability testing	Vassilios Vonikakis;Subramanian Ramanathan;Stefan Winkler	2013		10.1145/2506364.2506373	engineering;data mining;multimedia;world wide web	HCI	-54.598743200080754	-42.504691696218494	58787
c638dfb1d05055b217397c090b76e5e7786324db	voice anthropomorphism, interlocutor modelling and alignment effects on syntactic choices in human-computer dialogue	human computer dialogue;interlocutor modelling;persistence;speech interaction;user behaviour;speakers;acquisition;machines;language production;psycholinguistics;syntactic alignment;coordination	The growth of speech interfaces and speech interaction with computer partners has made it increasingly important to understand the factors that determine users' language choices in human-computer dialogue. We report two controlled experiments that used a picture-naming-matching task to investigate whether users in human-computer speech-based interactions tend to use the same grammatical structures as their conversational partners, and whether such syntactic alignment can impact strong default grammatical preferences. We additionally investigate whether beliefs about system capabilities that are based on partner identity (i.e. human or computer) and speech interface design cues (here, voice anthropomorphism) affect the magnitude of syntactic alignment in such interactions. We demonstrate syntactic alignment for both dative structures (e.g., give the waitress the apple vs. give the apple to the waitress), where there is no strong default preference for one or other structure (Experiment 1), and noun phrase structures (e.g., a purple circle vs. a circle that is purple), where there is a strong default preference for one structure (Experiment 2). The tendency to align syntactically was unaffected by partner identity (human vs. computer) or voice anthropomorphism. These findings have both practical and theoretical implications for HCI by demonstrating the potential for spoken dialogue system behaviour to influence users' syntactic choices in interaction. As well as verifying natural corpora findings, this work also highlights that priming and cognitive mechanisms that are unmediated by beliefs about partner identity could be important in understanding why people align syntactically in human-computer dialogue. Paper investigates syntactic alignment in spoken human-computer dialogue.The role of partner modelling through partner type and voice is also explored.Humans align similarly with human and computer partners, irrespective of voice.Priming is an important mechanism to consider in explaining our HCD choices.Syntactic alignment can affect strong default preferences and could be used to improve spoken dialogue technology.		Benjamin R. Cowan;Holly P. Branigan;Mateo Obregón;Enas Bugis;Russell Beale	2015	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2015.05.008	natural language processing;persistence;machine;computer science;artificial intelligence;linguistics;psycholinguistics	NLP	-52.588706673222894	-52.06696088565862	58896
1abb2c3bf0dab6ceb720494516362133fba5fd7e	iattac: a system for autonomous agents and dynamic social interactions - the architecture		Realistic social interactions are an important aspect for games, especially in the domain of serious games. Some games like Façade or Prom Week have an impressive AI engine for this, but there is room for improvement. In this paper we present iATTAC, a system for autonomous agents and their social interactions. Our system is based on principles also used in other systems such as “StoryBricks”, but also incorporates other aspects to realize realistic social interactions. It is designed to be used for educational games against cyber-bullying, but it is general enough to be used for other games. We describe the theoretical basis used as well as the architecture of the system.	autonomous robot;cyberbullying;interaction;requirement	Edgar Cebolledo;Olga De Troyer	2015		10.1007/978-3-319-19126-3_12		AI	-55.25677169139933	-46.77141699191444	58919
bcd6c6226e9662153f2eb99f4c8fd6841a59ae38	bubble drum-agog-ing: polyrhythm games & other inter activities		This paper describes the bubble drum set, along with several polyrhythm games and interactive music activities that have been developed to show its potential for use as an input controller. The bubble drum set combines various sizes of colorful exercise balls, held in place or suspended with conventional drum hardware and thus creating a trap kit configuration in which the spherical surfaces can be struck and stroked from varying angles using sticks, brushes, or even by hands alone. The acoustic properties of these fitness balls are surprisingly rich, capable of producing subtle differences in timbre while being responsive over a wide dynamic range. The entire set has been purposefully designed to provide a player with the means to achieve a rigorous and healthy physical workout, in addition to the achieving beneficial cognitive and sensory stimulation that comes from playing music with a sensitive and expressive instrument.	acoustic cryptanalysis;cognition;drum memory;dynamic music;dynamic range;kinetic data structure	Jay Alan Jackson	2012			bubble;acoustics;drum;polyrhythm;physics	HCI	-48.2811604163387	-49.55435527812311	59105
8b46a8d32442c10e087ae4c9f1f947775e425980	enhancing overall object placement by understanding uncertain spatial and qualitative distance information in user commands		Humans prefer to use voice commands to guide their peer companions in daily assistive tasks. In human perspective, they expect same behavior from assistive robot companions as well. The paper presents an approach towards using such voice instructions based on uncertain and qualitative information to describe object placements. Consider a case in which a set of objects has to be arranged on a table in a particular spatial area. In such a situation, humans will prefer to use a single command regarding overall arrangement rather than repeating the same command for each and every object placement. In such scenarios, people will be comfortable with commands which are simple and with non-technical words. Most of such commands include uncertain spatial terms such as “Left”, “Middle”, “Right” and uncertain qualitative terms such as “Together”, “Little separately”, “Separately” to describe the arrangement. For example “Keep all objects together in the middle of the table” and “Keep objects separately on the right side of the table” can be considered. But in some situations, these commands will not give a direct idea about the placement location of the objects. For instance, “Keep the middle of the table free” can be cited. Therefore, the robot must be able to understand precisely such information in commands before executing them. The experiments are conducted in a simulated domestic environment. Results of the experiment are presented and discussed.	algorithm;assistive technology;experiment;fuzzy logic;humans;robot;voice command device	M. M. S. N. Edirisinghe;M. A. Viraj J. Muthugala;H. P. Chapa Sirithunge;A. G. Buddhika P. Jayasekara	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460624	voice command device;task analysis;visualization;robot;control engineering;human–computer interaction;engineering;robot kinematics;domestic environment	Robotics	-49.51032597853166	-50.61497175418211	59108
3ea0d4f220140153826c4e0e588229edbc6d4a9e	peripheral participants in mediated communication	mediated communication;overhearing;awareness;presence;participation;video mediated communication;field study;social presence;x rays	When more than two people take part in a conversation or work task their involvement may be either as ‘primary’ or ‘peripheral’ participants depending on whether or not they are actively involved in the current shared task. This distinction was operationalised in an experiment. An interested peripheral participant listened in to the conversation of two others, one of whom was in the same room and one of whom was remote. Whether one was a primary or peripheral participant had a large effect on ratings of social presence, larger than the effect of whether one was remote or copresent.	peripheral;social presence theory	Andrew F. Monk;Leon Adam Watts	1998		10.1145/286498.286765	awareness;telecommunications;multimedia;field research	HCI	-54.500748496101096	-49.544473428780535	59158
4b1e4d94f0f81bd31933cf140489145868c9fb0c	3d talking-head interface to voice-interactive services on mobile phones	cellphone;mobile phone;voice interaction;talking head;power consumption;talking assistant;rendering	This paper presents a novel framework for easy creation of interactive, platform-independent voiceservices with an animated 3D talking-head interface, on mobile phones. The Framework supports automated multi-modal interaction using speech and 3D graphics. The difficulty of synchronizing the audio stream to the animation is examined and alternatives for distributed network control of the animation and application logic is discussed. The ability of modern mobile devices to handle such applications is documented and it is shown that the power consumption trade-off of rendering on the mobile phone versus streaming from the server favors the phone. The presented tools will empower developers and researchers in future research and usability studies in the area of mobile talking-head applications (Figure 1). These may be used for example in entertainment, commerce, health care or education. DOI: 10.4018/978-1-4666-2068-1.ch008	3d computer graphics;business logic;mobile device;mobile phone;modal logic;server (computing);streaming media;usability	Jirí Danihelka;Roman Hak;Lukas Kencl;Jirí Zára	2011	IJMHCI	10.4018/jmhci.2011040104	embedded system;mobile search;simulation;mobile web;human–computer interaction;rendering;gsm services;computer science;operating system;mobile technology;multimedia;mobile station;mobile computing	HCI	-48.94714941505332	-38.20590439513002	59334
03a56bb26c7d81a4915eae2071d96a22dc99dcb5	facilitating smartphone use for blind people through a human powered approach		From a longitudinal study of smartphone adoption with blind users, we uncovered the need for frequent assistance and the opportunity for effective and efficient knowledge sharing. Smartphones are constantly evolving platforms where new applications, features, and consequently barriers, appear every day. Building on comprehensive knowledge of challenges and coping mechanisms employed by blind people, we are exploring how human-powered solutions can contribute. A human-powered approach has the potential to address efficacy, availability and coverage issues by expanding the pool of supporters. Our goal is to devise a set of human-powered tools to facilitate and promote smartphone usage. With in-context solutions we aim to investigate solutions that enable user independence and self-learning. We will augment knowledge sharing interactions and investigate its impact in promoting new smartphone usages.	code coverage;interaction;smartphone	André Rodrigues	2018	ACM SIGACCESS	10.1145/3178412.3178418	computer science;human–computer interaction;coping (psychology);knowledge sharing;longitudinal study	HCI	-59.950583354733574	-42.00238543589694	59692
93e49da5ab4d3988c071ee31d59697723b3c9d0e	let’s get personal		Agents that are able to build relationships with the people they are interacting with are envisioned to be more successful in longterm interactions. Small talk about impersonal topics has been found an adequate tool in human-agent interactions for manipulation of such relationships. We suspect that an agent and the interaction with it will be evaluated even more positively when the agent talks about personal information it remembers about its interlocutor from previous encounters. In this paper a model of person memory that provides virtual agents with information needed in social conversations is presented. An interaction study demonstrates the impact of personal information in human-agent conversations and validates the performance of our model.	central processing unit;dialog system;intelligent agent;interaction;personally identifiable information	Nikita Mattar;Ipke Wachsmuth	2014		10.1007/978-3-319-07230-2_43	human–computer interaction;computer science;suspect;personally identifiable information;small talk	AI	-52.22282298179658	-48.813507128394846	60000
0b35d86e38d2c3963eaf37dc5c1c170fd8e7215d	affective sensors, privacy, and ethical contracts	sensors;contractualism;emotion recognition;ethics;privacy;affective computing	Sensing affect raises critical privacy concerns, which are examined here using ethical theory, and with a study that illuminates the connection between ethical theory and privacy. We take the perspective that affect sensing systems encode a designer's ethical and moral decisions: which emotions will be recognized, who can access recognition results, and what use is made of recognized emotions. Previous work on privacy has argued that users want feedback and control over such ethical choices. In response, we develop ethical contracts from the theory of contractualism, which grounds moral decisions on mutual agreement. Current findings indicate that users report significantly more respect for privacy in systems with an ethical contract when compared to a control.	encode;privacy;sensor	Carson Reynolds;Rosalind W. Picard	2004		10.1145/985921.985999	ethics;computer science;knowledge management;sensor;artificial intelligence;affective computing;privacy	HCI	-60.87056739955957	-43.313731866240964	60033
389150acc7808a14765074319e2fa260216f535b	assessing effectiveness of personality style in documentation	documentation management;personality;bepress selected works;documentation personality effectiveness documentation management human factors;human factors;effectiveness;documentation	This paper extends previous work by other researchers that indicated that users of computers preferred a computer with a personality that was similar to theirs. We conducted a similar experiment, but looking beyond preference to see if the personality of documentation would make a difference in the user's performance. Our data suggest did not indicate that personality match affects performance; and if such a relationship exists it is likely to be weak. We discuss the related research, describe our methodology, present our results, and describe their implications and limitations.	computer;documentation;experiment	Kenneth Sayles;David G. Novick	2004		10.1145/1026533.1026554	documentation;computer science;knowledge management;human factors and ergonomics;multimedia;personality	HCI	-60.0320214535107	-47.561572015927624	60151
4c56b084022d74ded9a2e07e085d0e066b01a8b8	haptic communication of dimensions of emotions using air jet based tactile stimulation	tactile;air jet stimulation;emotion	Several studies showed the relevance of haptics to convey various types of emotions. This paper proposes to investigate a more suitable tactile stimulation strategy based on mobile air jet which provides a non-intrusive tactile stimulation on different and large areas on the body. Moreover, this tactile strategy allows an efficient simulation of skin mechanoreceptors which play an important role in social and affective behaviors. In order to understand the relationships between the physical features of the air jet and the perception of emotions, we conducted an experimental study with sixteen participants. The results highlight a main effect of the intensity and movement velocity of the air jet stimulation on the evaluations of valence, arousal, and dominance.	affective computing;autonomous robot;cognition;experiment;haptic technology;human–computer interaction;intelligent agent;multimodal interaction;relevance;simulation;velocity (software development)	Mohamed Yacine Tsalamlal;Nizar Ouarti;Jean-Claude Martin;Mehdi Ammi	2014	Journal on Multimodal User Interfaces	10.1007/s12193-014-0162-3	simulation;communication	HCI	-50.46887377872576	-49.56907817671304	60216
96fa2ac6df4316f63e127327bc16df6ec681286a	the usability of transparent overview layers	groupware;transparent interfaces;overviews;computer science;exploratory study	Viewports into large visual workspaces are sometimes supplemented by a separate window that displays a miniaturized overview of the entire workspace. Instead of this separate window, we have layered a transparent version of the overview atop the viewport. Because the overview fills the display, it becomes the largest size possible. An exploratory study indicates that people can use this unusual system, where they switch between layers when performing a construction task.	usability;viewport;workspace	Donald A. Cox;Jasdeep S. Chugh;Carl Gutwin;Saul Greenberg	1998		10.1145/286498.286777	simulation;human–computer interaction;computer science;multimedia;world wide web;exploratory research;collaborative software	HCI	-48.53096772927871	-39.70982729531545	60468
64defc51132f6faa5ff4afffaa26d9777c0aa010	an interactive social boarding system using home infotainment platform	hospitality;social network;tv;home infotainment platform;voip	The authors propose a customer interactive and connected boarder experience for the hospitality industry using the in-room TV set and a Home Infotainment Platform (HIP) connected to the same. This aims at building an interactive and social platform for interacting with the Hotel services and facilities. It also facilitates the replacement of the EPABX in the room with more interactive means for providing services including but not restricted to restaurant table booking, conference room booking, wake-up call service and external communications. This will lead to a more cost-effective deployment of services with a richer feature-set.		Sounak Dey;Avik Ghose	2011		10.1007/978-3-642-24704-0_42	social science;simulation;hospitality;computer science;voice over ip;world wide web;computer security;social network	HCI	-55.08795349523407	-39.96796910828489	60473
e42f92c6698c5be4ae3642a25f0e41cb6d6f0609	improving access of elderly people to real environments: a semantic based approach	settore inf 01 informatica;navigation;multimodality;3d environment;xhtml voice profile;semantic description;elderly people;guided tour;semantic 3d environments	Access to real environments is often conditioned by a number of issues, including the skills of the user (i.e. affected by aging, physical and psychological deficiencies, etc.) and the complexity of the real environment itself. This work proposes an approach for helping users with different skills, including elderly people, to navigate through complex real scenes; such approach is based on the semantic description of the objects and zones that characterize the environment itself and takes advantage of an implementation architecture based on web standards for generating navigational support. A case study related to the creation of a guided tour through the indoor and outdoor locations of the city of Venice, accessible through a multimodal web browser, is presented.	multimodal interaction;web standards	Fabio Pittarello;Alessandro De Faveri	2006		10.1145/1133265.1133341	navigation;simulation;human–computer interaction;multimedia;world wide web	AI	-50.32571962808484	-39.3986457170269	60495
baed11bc1ae7b2cf1e5d4e3a981e120a5ee292a1	user-centered design and agency in interactive data visualizations	agency;user centred design data visualisation;risk communication agency interactive visualizations user centered design;user centered design;user feedback user centered design interactive data visualization information exploration user experience visualization interface user agency visualization development audience engagement audience co creation interface design data selection risk scenario parameters;interactive visualizations;risk communication;data visualization usability visualization collaboration testing user centered design	Interactive data visualizations facilitate user exploration of information and can offer insight into patterns and relationships within the data. Nevertheless, the user's experience is constrained by the rhetorical choices of the visualization designers. Most scholarship on the relationship between user, interface, and designer focuses on how agency is shared between designer and user within the visualization interface. This paper focuses on an additional site in which user agency may occur: during visualization development. A user-centered development process involving audience engagement and co-creation can provide an additional space in which to negotiate agency. This paper envisions how this process might work, focusing on one example of user collaboration in the development of an interactive visualization for communicating about risks associated with sea-level rise. It outlines decisions made by developers regarding interface design, data selection, and risk scenario parameters, illustrates pathways by which users have participated in the design process, and describes how user feedback has helped shape the ultimate interaction space. Implications for the development of other interactive visualizations are discussed.	information visualization;interactive visualization;interactivity;risk factor (computing);user-centered design	Sonia Stephens	2015	2015 IEEE International Professional Communication Conference (IPCC)	10.1109/IPCC.2015.7235819	user interface design;user;user experience design;user-centered design;user modeling;information visualization;computer user satisfaction;interactive systems engineering;interactive visualization;human–computer interaction;user journey;computer science;agency;multimedia;interactive media;user interface;world wide web	Visualization	-61.58792784020433	-39.44151280957465	60609
0c8336c570c27cc6aad2a8fd920219021d2730dc	designing mobile interactions for the ageing populations		We are concurrently witnessing two significant shifts: mobiles are becoming the most used computing device; and older people are becoming the largest demographic group. However, despite the recent increase in related CHI publication, older adults continue to be underrepresented in HCI research as well as commercially, further widening the digital divide they face and hampering their social participation. This workshop aims to increase the momentum for such research within CHI and related fields such as gerontechnology. We plan to create a space for discussing and sharing principles and strategies to design and evaluate mobile user interfaces for the aging population. We thus welcome contributions to empirical studies, theories, design and evaluation of mobile interfaces for older adults.		Sayan Sarcar;Cosmin Munteanu;Jussi P. P. Jokinen;Antti Oulasvirta;Chaklam Silpasuwanchai;Neil Charness;Mark D. Dunlop;Xiangshi Ren	2017		10.1145/3027063.3027074	human–computer interaction;empirical research;social engagement;ageing;multimedia;population ageing;digital divide;gerontechnology;computer science;user interface	HCI	-61.78384696396627	-42.2706804453416	60762
b07c8fa9bf18aa2c494175a80ccac27dacb2debb	a taxonomy for rfid	information systems;taxonomy radiofrequency identification frequency information systems monitoring scalability hardware transponders navigation feedback;navigation;feedback;monitoring;taxonomy;scalability;transponders;frequency;radiofrequency identification;hardware	RFID systems come in a myriad of forms, each catering to a specific need. However, a systematic classification to reduce the confusion of potential adopters, researchers and enthusiasts is still lacking. This article proposes and evaluates a taxonomy of various RFID systems currently available. The taxonomy can be used for gaining an understanding of this technology, the factors for implementation of a successful RFID system, its strengths and weaknesses as well as scalability options. Both novice as well as experienced RFID researchers will benefit from this classification.	radio-frequency identification;scalability;taxonomy (general)	Taimur Hassan;Samir Chatterjee	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.32	navigation;real-time computing;scalability;simulation;computer science;frequency;transponder;feedback;world wide web;information system;taxonomy	Visualization	-62.055533690279375	-43.57439371740623	60841
4e2508ad628b5cb45e20892d5ab274d85424ecad	gaze: using mobile devices to promote discovery and data collection	data collection;community sensing;physical crowdsourcing;citizen science	Developments in citizen science, community sensing, and crowdsourcing offer the opportunity of large scale data collection of the physical world because of the ubiquity of sensor-rich, mobile devices. Despite this opportunity, large-scale data collection about physical spaces is currently not widespread because of high-effort participation. In this paper, we explore the ability for people to contribute on the go. We developed Gaze, a system that will collect information about people's responses to physical spaces through low-effort feedback. To enable low-effort contributions for large scale data collection, we have developed a design pattern called Identify-Focus-Capture that identifies opportunities for users given current situational context, helps users to focus in on the opportunity, and captures useful data through simple actions or gestures. Through our pilot, users successfully helped collect 50+ data points about their environment, showing that useful data can be collected when the opportunity is low-effort.	citizen science;crowdsourcing;data point;mobile device;software design pattern;usb on-the-go	Zachary Allen	2015		10.1145/2702613.2726960	citizen science;data mining;internet privacy;world wide web;data collection	HCI	-57.028703998945595	-42.270666009095656	60933
b92706987564679ecce48f65f1b90fcf60f968ab	case study of a multi-robot healthcare system: effects of docking and metaphor on persuasion	multi robot system;healthcare system;multi robot healthcare system;interpersonal relationship;persuasion	This paper reports the docking and metaphor effects on persuasion among multi-robot healthcare systems. The goal of our research is to make a robot friend that lives with its users and persuades them to make appropriate healthcare decisions. To realize such a robot friend, we propose a physical approach called docking as well as a contextual approach called metaphor to perform relational inheritance among multi-robot systems. We implemented a multi-robot persuasion system based on the two approaches and verified its effectiveness. The experimental results revealed that users emphasize interpersonal relationships to decide whether to follow the robot’s advice when utilizing the metaphor approach, and that users emphasize robot aggressiveness when utilizing docking approach.	docking (molecular);robot	Osamu Sugiyama;Kazuhiko Shinozawa;Takaaki Akimoto;Norihiro Hagita	2010		10.1007/978-3-642-17248-9_10	simulation;engineering;communication;social psychology	Robotics	-51.68988448392186	-50.95419581829963	60955
5ea26cdd68a191b7eaefa01c267731fcb387a7c4	talking with robots about objects: a system-level evaluation in hri	learning artificial intelligence human robot interaction;internal metrics robot talking system level evaluation hri interactive object learning system oriented evaluation paradise method spoken dialog systems external metrics;design process;atmospheric measurements;social robotics human robot interaction object learning;particle measurements;spoken dialog system;interaction style;usa councils;human robot interaction;robots atmospheric measurements particle measurements speech recognition humans usa councils;object learning;robots;social robotics;speech recognition;humans;user behavior;learning artificial intelligence;user satisfaction;social robot	We present the design process, realization and evaluation of a robot system for nteractive object learning. The system-oriented evaluation, in particular, addresses an open problem for the evaluation of systems, where overall user satisfaction depends not only on the performance of the parts, but also on their combination, and on user behavior. Based on the PARADISE method known from spoken dialog systems, we have defined and applied internal and external metrics for fine-grained and largely automatable identification of such relationships. Through evaluation with n=28 subjects, indicator functions explaining up to 55% of variation in several satisfaction metrics were found. Furthermore, we demonstrate that the system's interaction style reduces the need for instruction and successfully recovers partial failures.	dialog system;human–robot interaction;robot;spoken dialog systems;test automation	Julia Peltason;Nina Riether;Britta Wrede;Ingo Lütkebohle	2012	2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2157689.2157841	human–robot interaction;simulation;computer science;artificial intelligence;social robot	Robotics	-51.34144330122929	-47.969624324638716	61097
017cb7d821987b118072cd3292d93eb247461feb	a de-construction of wireless device usage	wireless devices;flow;wireless;phratria;media;artifact;culture	In this article, wireless technology use is addressed with a focus on the factors that underlie wireless interaction. A de-construction of the information processing theories of user/technology interaction is presented. While commercial and useful applications of wireless devices are numerous, wireless interaction is emerging as a means of social interaction—an extension of the user’s personal image—and as an object of amusement and play. The technology/user interaction theories that have driven the discussions of computer assisted communication media are information richness, communicative action, and social influence modeling. This article will extend this theoretical view of wireless devices by using flow theory to address elements of fun, control, and focus. Then, these technology/user interaction theories are used with respect to wireless devices to propose areas for future research.	human–computer interaction;information processing theory	Mary R. Lind	2007	IJTHI	10.4018/jthi.2007040103	media;flow;human–computer interaction;computer science;electrical engineering;body area network;multimedia;communication;social psychology;world wide web;computer security;wireless;culture	HCI	-58.17241129152179	-39.58032365839009	61292
ec5b49ab23b708a08d74be24ea9d068bd7b3ec83	what are you talking about while driving?: an analysis of in-car conversations aimed at conversation sharing	conversation analysis;knowledge sharing;in car conversations;location aware	In this study, we propose an in-car conversation sharing system. People frequently converse in a car. In these conversations, people often talk about points of interest that they have just passed. Because we believe that they contain useful information, the aim of our study is to share the conversations. To develop such a system, we needed to know about the characteristics of in-car conversations. Consequently we collected 120 in-car conversations with their locations over a 10-month period. Our analysis showed that many types of conversation take place in a car; but of the greatest interest is when the subject of conversation is a specific location or area. We discuss the requirements for an in-car conversation sharing system to guide our on-going research.	point of interest;requirement	Kohei Matsumura;Yasuyuki Sumi	2014		10.1145/2667317.2667417	simulation;computer science;multimedia;communication	HCI	-54.86775845346757	-41.847017996391294	61349
4501d9ddcedb4f32713ce1f95479d9223e22ee6e	wearable aura: an interactive projection on personal space to enhance communication		This study focuses on how technology can encourage and ease awkwardness-free communications between people in real-world scenarios. We propose a device, The Wearable Aura, able to project a personalized animation onto oneu0027s Personal Distance zone. This projection, as an extension of one-self is reactive to useru0027s cognitive status, aware of its environment, context and useru0027s activity. Our user study supports the idea that an interactive projection around an individual can indeed benefit the communications with other individuals.	personalization;usability testing;wearable computer	Dingding Zheng;Laura Lugaresi;George Chernyshov;Benjamin Tag;Masa Inakage;Kai Kunze	2017		10.1145/3123024.3123161	wearable technology;human–computer interaction;proxemics;social relation;personal space;wearable computer;animation;computer science;cognition;multimedia;aura	HCI	-54.23864636575885	-43.23690278642266	61549
2c9fefb999f04f25beac9a281411511b6117df36	casual schedule management and shared system using an avatar	schedule sharing;motivation;social network service;avatar	Many organizations do not use schedulers, that is schedule management and shared systems. Often, this is because users find it difficult to remain motivated to use such systems. Therefore, we have developed a casual schedule management and shared system that makes use of an avatar. The dress-up items and accessories available for each avatar increase, depending on the number of items in a schedule. This system can be used on mixi--a Japanese social networking site. From the results of our experiments, we found that our system was able to maintain a user's motivation. This is particularly true of users who are interested in acquiring dress-up items and accessories, as we found that they input their schedule more than the users who are less interested in those aspects of the system.		Takashi Yoshino;Takayuki Yamano	2011		10.1007/978-3-642-23851-2_23	simulation;engineering;multimedia;advertising	Robotics	-57.73034842778961	-48.6878197233822	62029
9b935218b54378fafda81a3d9c8008d915ceb4ac	effects of see-through interfaces on user acceptance of small-screen information systems	menu translucency;user interface;technology acceptance model;ease of use;large screen display;mobile phone;conference paper;translucent interface;system design;small screen device;small screen displays;information system;user acceptance;small screen maximization	Small-screen devices such as mobile phones are increasingly pervasive. Reduced screen areas compromise the ease-of-use of such devices, and consequently, a concern for system designers becomes the maximization of available screen space. On large-screen displays, menus can overlap and obscure others, and be displayed simultaneously to the user. This is generally not the case with small screens: where a user selects from an on-screen menu, that menu must ‘vacate’ the screen before another appears. Menu translucency, where a user can see through an on-screen menu to displayed elements beneath, is a possible solution to small-screen display maximization. Based on experimental evidence with 70 participants, and using an extended Technology Acceptance Model (TAM) this research examines the effect of on-screen translucent menus on perceptions of ease-ofuse, usefulness, and enjoyment for a third generation mobile phone prototype user interface. We offer explanations for our findings and discuss implications for practitioners and researchers.	expectation–maximization algorithm;glossary of computer graphics;ibm tivoli access manager;mobile phone;prototype;services menu;user interface	Thomas Acton;William Golden;Hans van der Heijden	2005			usability;human–computer interaction;computer science;multimedia;user interface;world wide web;information system;systems design	HCI	-49.31363922031636	-42.24387960008241	62055
0eef02ffbf3894186ef362cd0ece9609c3b271ce	the effect of representations on communication and product during collaborative modeling	modeling process;graphical representation;different external representation;different phase;shared representation;modeling representation;collaborative modeling task;model representation;different representation;collaborative computer modeling task;collaboration;computer modeling;representations;simulation	In this paper we investigate the effect of different external representations on the process and product of collaborative computer modeling tasks. Shared representations can significantly influence the processes of modeling and communication. We compare pairs working on a collaborative modeling task using a text based model representation with others using a graphical representation. Results indicate that the graphical representation leads to better modeling results. Further analysis of the communication between learners will reveal more detailed insight in the precise effects of the representation on the modeling and communication processes.	computer simulation;graphical user interface;process (computing);text-based (computing)	Simone Löhner;Wouter R. van Joolingen	2002			computer simulation;natural language processing;simulation;human–computer interaction;computer science;collaboration	HCI	-61.179263084818565	-46.85734730269131	62066
4926fd796161f03cc5cb5f0d257d2d1b02e6be53	the uncanny valley and the importance of eye contact		The Uncanny Valley hypothesis describes the negative emotional response of human observers that is evoked by artificial figures or prostheses with a human-like appearance. Many studies have pointed out the meaning of facial features, but did not further investigate the importance of eye contact and its role in decision making about artificial faces. In this study we recorded the number and duration of fixations of participants (N = 53) and recorded gaze movements and fixations on different areas of interest, as well as the response time when a participant judged a face as non-human. In a subsequent questionnaire, we grasped subjective ratings. In our analysis we found correlations between the likeability and the duration of eye fixations on the eye area. The gaze sequences show that artificial faces were visually processed similar to the real ones and mostly remained not assessed as artificial as long as the eye regions were not considered.	response time (technology);uncanny valley	Valentin Schwind;Solveigh Jäger	2015			psychology;developmental psychology;communication;social psychology	HCI	-50.131616645576656	-51.884372504854724	62115
a9e544c3936001dcd711846266af23c839ba3b97	drumming with a humanoid robot : lessons learnt from designing and analysing human-robot interaction studies	conference paper	We summarize methodological and experimental design issues related to three human-robot interaction studies investigating a drumming experience with Kaspar, a humanoid child-sized robot, and (in total 116) human participants. Our aim is not to have Kaspar just replicate the human’s drumming but to engage in a ‘social manner’ in a call and response turn-taking interaction. This requires the set up of enjoyable as well as (as much as possible) controlled experiments. Two Human-Robot Interaction (HRI) experiments with adult participants and one experiment with primary school children were carried out to investigate different aspects of such interactions. We briefly summarize issues concerning experimental methodology and design, as well as ethical, legal, safety issues in addition to many ‘practical’ challenges of setting up and conducting HRI experiments with an autonomous humanoid robot.	autonomous robot;design of experiments;experiment;futures studies;humanoid robot;human–robot interaction;self-replicating machine;usability testing	Hatice Kose-Bagci;Kerstin Dautenhahn;Chrystopher L. Nehaniv	2009			simulation;computer science	Robotics	-53.0545695634426	-50.6636014367156	62324
7b953060dd2d753cd2fe41de8b3acd9a53cd8e84	enhancing accessibility and engagement for those with disabilities		Pervasive computing technology can enhance quality of life for those with disabilities by providing access to timely information and helping them to navigate their environment independently. Three research projects focusing on different impairments demonstrate the importance of including target users in the design and implementation of an accessibility system.	accessibility	Kyle Rector	2018	IEEE Pervasive Computing	10.1109/MPRV.2018.011591056	autism;human–computer interaction;multimedia;ubiquitous computing;autism spectrum disorder;computer science	HCI	-56.59184623978907	-43.73580318689523	62429
1ab0d073bd769d89333aa47ab1a9d057e5aea4e7	friends: brain-monitoring agents for adaptive socio-technical systems	context awareness;ambient intelligence;multi agent systems;cognitive inference	Brain-monitoring is quickly becoming an important field of research, with potentially significant impacts on how people will interact with technology. As understandings of the inner-workings of the brain become more accurate technologies are becoming more advanced, smaller, cheaper, and ubiquitous. It is expected that new forms of computing that take advantage of brain states will be developed. This will enable systems to be highly aware of user mental contexts (emotions, intentions, and moods). These systems would display higher autonomic behavior and would streamline user-interaction while managing the use of brain context data for applications and services. There are few studies of how to develop and make use of agent architectures in this new domain. Current approaches target a single user and application situation. To be ubiquitous it is unrealistic for applications to have specialized overhead for individual users. Personalizable, but distributed approaches are needed. To realize a general purpose agent for brain-monitoring and management of brain context is the goal of this work. This involves the selection of a brain-monitoring paradigm, the selection of an agent architecture paradigm, an inferencing mechanism, and the combination of the three towards a unified framework. Early framework designs are discussed, as well as core motivations, and eventual proof-of-concept applications using brain context.	adobe streamline;agent architecture;autonomic computing;autonomous robot;care-providing robot friend;context-aware pervasive systems;experiment;overhead (computing);programming paradigm;sociotechnical system;unified framework	Alexis Morris;Mihaela Ulieru	2012	Multiagent and Grid Systems	10.3233/MGS-120198	simulation;ambient intelligence;computer science;knowledge management;artificial intelligence;multi-agent system	HCI	-56.5541263666742	-43.895796140193255	62583
909fd3a335d99ccd1b3b4efff8ed52345bebe9f9	evaluation of trippple: a field analysis	mobile;reality;annotation;travel;location;augmented;sharing;geonotes;social;network	This paper illustrates a field research performed with a team of experts involved in the evaluation of Trippple, a system aimed at supporting the different phases of a tourist trip, in order to provide feedback and insights, both on the functionalities already implemented (that at the time of evaluation were available only as early and very unstable prototypes), and on the functionalities still to be implemented. We show how the involvement of professionals helped to focus on challenging aspects, instead of less important, cosmetic, issues and resulted profitable in terms of early feedback, issues spotted, and improvements suggested.	control theory;feedback;field research;lexicon	Selene Uras;Emanuela De Vita;Daniele Ardu;Ivan Marcialis;Alessandro Soro;Gavino Paddeu	2012		10.1145/2428955.2428965	reality;simulation;computer science;knowledge management;operating system;mobile technology;multimedia;social;location;computer security	Visualization	-56.54755433536138	-41.207345492069194	62761
393fc57ff1f68133457f05d7a8e83925b37ed4fd	non-visual web browsing: beyond web accessibility	screen reader;web accessibility;web content semantics;web usability	People with vision impairments typically use screen readers to browse the Web. To facilitate non-visual browsing, web sites must be made accessible to screen readers, i.e., all the visible elements in the web site must be readable by the screen reader. But even if web sites are accessible, screen-reader users may not find them easy to use and/or easy to navigate. For example, they may not be able to locate the desired information without having to listen to a lot of irrelevant contents. These issues go beyond web accessibility and directly impact web usability. Several techniques have been reported in the accessibility literature for making the Web usable for screen reading. This paper is a review of these techniques. Interestingly, the review reveals that understanding the semantics of the web content is the overarching theme that drives these techniques for improving web usability.	browsing;color vision defect;human-readable medium;intrinsic drive;relevance;screen reading;web site;web accessibility;web content;web usability;world wide web;contents - htmllinktype	I. V. Ramakrishnan;Vikas Ashok;Syed Masum Billah	2017	Universal access in human-computer interaction : designing novel interactions : 11th International Conference, UAHCI 2017, held as part of HCI International 2017, Vancouver, BC, Canada, July 9-14, 2017, Proceedings. Part II. Internation...	10.1007/978-3-319-58703-5_24	web page;web standards;world wide web;web development;semantic web stack;web navigation;web 2.0;web design;web accessibility initiative;computer science	HCI	-50.98355054618672	-41.76724600400488	62829
3384324d400a9209bb184ca1bd8adef7c5a15133	enhanced situational awareness and communication for emergency response	context awareness;incidents;spills;mobile sensing;location awareness;human and computer interaction	It is important to recognize emergency responders? needs during emergency response to workplace incidents in order to propose solutions to facilitate responders? tasks and resolve incidents in a timely manner. To understand emergency response procedures involved in workplace incidents, we interviewed McGill Safety personnel. We identify potential areas of improvement in their procedures, which help us to shape research objectives. We then propose methods to address these objectives. We focus our investigation on a spill scenario and briefly describe our mobile solution to assist in this use context.		Minoo Erfani Joorabchi	2014		10.1145/2628363.2634266	problem management;simulation;computer security	HCI	-60.84435655154622	-40.876108503865474	62983
d05d4d6bbc152e878041a8007558e552b79d82a5	a novel educational game for teaching emotion identification skills to preschoolers with autism diagnosis	autism;facial emotion recognition;kinect;gesture based interaction;natural user interface	Emotion recognition is essential in human communication and social interaction. Children with autism have been reported to exhibit deficits in understanding and expressing emotions. Those deficits seem to be rather permanent so intervention tools for improving those impairments are desirable. Educational interventions for teaching emotion recognition should occur as early as possible. It is argued that Serious Games can be very effective in the areas of therapy and education for children with autism. However, those computer interventions require considerable skills for interaction. Before the age of 6, most children with autism do not have such basic motor skills in order to manipulate a mouse or a keyboard. Our approach takes account of the specific characteristics of preschoolers with autism and their physical inabilities. By creating an educational computer game, which provides physical interaction with natural user interface (NUI), we aim to support early intervention and to enhance emotion recognition skills.	emotion recognition;human–computer interaction;natural user interface;pc game	Eirini Christinaki;Nikolas Vidakis;George A. Triantafyllidis	2014	Comput. Sci. Inf. Syst.	10.2298/CSIS140215039C	computer science;natural user interface	HCI	-56.80846880814592	-51.71903437633077	62992
19d49a6a8460c1fade37771577883f58cdaec71f	morel: remotely launchable outdoor playthings	ad hoc rule improvisation;physical play;pervasive game;mobile games;pervasive games	This paper proposes Morel, a physical plaything device that facilitates the emergence of new forms of outdoor physical play. It encourages the improvising of new games and behavior by not defining game rules on its own, but by providing players the ability to know the existence of other Morels in the vicinity, and to remotely make other Morels launch up in the air. One game that can be played with Morels is Police & Bomber, a variation of Kick-the-can with wireless ranges as vital gameplay elements.	emergence;kick the can;police quest: in pursuit of the death angel	Kenji Iguchi;Masa Inakage	2006		10.1145/1178823.1178866	simulation;geography;game mechanics;communication;computer security	HCI	-54.709296314557655	-39.94150909958105	63069
f30b0c23f7957b3164f35656ccf18a13274683fe	a study on the expression of emotions using lights in apparel types	user-centered design.;index terms— user interfaces;natural language;interaction styles;user centered design;interaction design;indexing terms;facial expression;user interface	When types of communication between people are observed, one can see that communication not only consist of words but also, contextual communication consist of facial expressions and body gestures. In this study, elements that need to be considered when using light in clothes in order to express the thoughts and various emotions of the wearer and surrounding people and to design contextual interaction rather than simply for visual effects, are examined. Clothes and light are central visual elements therefore, the relationship between perception of objects through sight and emotions are examined, elements of visual language of cloths and light are examined through documentary record, elements of visual language such as shape, color, and texture of light and clothes that influence each other are classified as well as unique elements of visual elements of light such as blink speed and blink pattern, and terms that are related to the psychological effects of these elements are extracted. Based on this, using the 8 most representative human emotions which includes happiness, excitement, anger, hatred, sadness, shock, fear, and shame as standards of design, interaction design elements using clothes and light for expression of each emotion are organized in a matrix.	hatred;interaction design;sadness;visual effects;visual language	Yongsoon Choi;JuYong Kim;JaeKi Kyoun;Duk Hyun;Jihong Jeung	2007			computer vision;artificial intelligence;sadness;perception;interaction design;visual language;computer science;facial expression;shame;user-centered design;gesture	HCI	-51.89180412713478	-46.610253819679315	63252
78c31fddca41c169fdb0dd0092b6eed92e7c8c85	lessons from failure: re-conceiving blogging as personal change support	ethnography;concept design;user study;mobile computer;q science general;user studies;mobile phone;handheld devices and mobile computing;handheld device;social media;interaction design;field study;smoking cessation;qa76 computer software	This paper reports on research-driven design of social technologies. It describes an exploratory field study evaluating and re-conceiving blogging technologies - a mobile phone, a mobile blog, a Weblog and synchronization software - to support personal change, in this case quitting smoking. We briefly describe the design of the blogging technologies and summarise the outcomes of their extended use by four people trying to quit smoking in terms of technology usage, domestication and acceptance and, smoking cessation. We then document some notable features of failure, both of the technology and the quit attempts, describing how understanding the nuances and subtleties of failure highlights important design considerations. Finally, we present some methodological and design recommendations emerging from: a design workshop involving the participants in the field study; and a desktop design exercise.	blog;desktop computer;field research;mobile phone	Connor Graham;Christine Satchell;Mark Rouncefield;James Balmford;Peter Benda	2007		10.1145/1389908.1389937	simulation;social media;human–computer interaction;computer science;interaction design;mobile device;multimedia;ethnography;concept art	HCI	-58.375675669893404	-44.65159709427002	63401
30cb51dd2506eafdba63bfe807b97ede8427c8e0	"""""""it's in love with you"""": communicating status and preference with simple product movements"""	user evaluation;human computer interaction;agency;actuated interfaces;multimodal interaction;ubiquitous computing;social status	In some situations users perceive product movements as an indication of agency. This makes it relevant to gain an understanding of how and why movements communicate attributes related to agency and what impact it has on users. This paper describes an experiment in which users, alone or in pairs, interact with a TV designed to move in way that communicates the agency related attributes social status or likeability. Results show that the TV movements are perceived differently when one versus two users are present. While most single users evaluate the TV positively, most users in pairs find the differential treatment problematic.	multi-user	Ditte Hvas Mortensen;Sam Hepworth;Kirstine Berg;Marianne Graves Petersen	2012		10.1145/2212776.2212784	human–computer interaction;social status;computer science;multimodal interaction;agency;world wide web;ubiquitous computing	HCI	-51.42997070574002	-49.88564532860206	63632
96f5053ab6ad8ddbf58dff2ebc306659eec6303b	will you follow the robot's advice?: the impact of robot types and task types on people's perception of a robot	tele operated robot;human robot interaction;art appraiser;qualitative task;quantitative task;autonomous robot	Robots could be classified into an autonomous robot and a tele-operated robot according to the levels of autonomy. As a match between robot types and task types is important, we explored the impact of robot types and task types on social presence, trustworthiness, and willingness to follow the robot's advice in art appraising situation. We executed a 2(robot types: autonomous robot vs. tele-operated robot) X 2(task types: quantitative task vs. qualitative task) mixed-participants experiment (N=30). Participants perceived more social presence toward the tele-operated robot than the autonomous robot while the autonomous robot was perceived more trustworthy than the tele-operated robot. The robot types and the task types had an interaction effect on the perceived trustworthiness and the willingness to follow the advice. Implications for the appropriate design by the robot types and the task types regarding human-robot interaction are discussed.	autonomous robot;autonomy;human–robot interaction;social presence theory;television;trust (emotion)	Hyewon Lee;Jung-Ju Choi;Sonya S. Kwak	2014		10.1145/2658861.2658906	mobile robot;robot learning;computer vision;simulation;engineering;social robot;robot control;communication;mobile robot navigation;personal robot	Robotics	-51.933789602677905	-50.58606263911801	63751
1d5bfd165bad14da069e7f76b2af761c2aab8552	evaluating home devices with real and virtual simulations	user experience;perspective taking;evaluation	The work aimed to develop a method for evaluating objects in real or virtual environment. It should specify the relevant evaluation dimensions depending on the environment (REAL or VIRTUAL) and task that can be performed (I DO an action, or I WATCH an action). These conditions can have an impact on the mental representation of the object, since they may involve a different perspective taking and spatial reference. A first study highlights that participants produced larger task verbalization (describe an object or simulate its use) in virtual context that in real context, and a second study showed that an observer evaluates the usability of objects more favorably than an actor.	evaluation function;mental representation;simulation;spatial reference system;usability;virtual reality	Benjamin Chateau	2014		10.1145/2637248.2637281	user experience design;simulation;human–computer interaction;computer science;evaluation;multimedia	Visualization	-50.2395458574133	-48.873731806319114	63853
38c7234ec67dbdd1c0b091bc84936c6700b36778	survey on intelligent personalized mobile tour guides and a use case walking tour app		In this paper, we present a solution that introduces, an electronic guide application for Android smartphones and tablets that aims to assist users with guidance to predefined or user defined points of interest and routes. Instead of buying a tour guide book, visiting an online site, joining a sightseeing tour group or hiring a personal tour guide the proposed smartphone application uses the user's preferences and internet technologies to guide them to their chosen destinations while providing information about them. Our approach includes (a) study of existing navigational systems using mobile devices to find basic and modern functionality requirements (b) design and creation of software for displaying cultural sites, displaying information for such sites on demand and guiding the user through predefined or customized routes and (c) the creation of a central management system (insertion, deletion and editing) of cultural interest points.		Athanasios Kountouris;Evangelos Sakkopoulos	2018	2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2018.00105	multimedia;artificial intelligence;machine learning;point of interest;the internet;management system;android (operating system);mobile device;computer science;destinations;software;server	Mobile	-51.00238230676405	-40.88288320597612	63923
7b7137e5e19a01c4549fa244eac56e4bd09dcd15	modeling human interaction resources to support the design of wearable multimodal systems	input devices and strategies;human interaction;interaction devices;interface design;h 5 2 user interfaces;human factors;multimodal system;multimodal interaction;wearable computer;wearable computing;interaction resource model;user machine systems	Designing wearable application interfaces that integrate well into real-world processes like aircraft maintenance or medical examinations is challenging. One of themain success criteria is how well the multimodal interaction with the computer system fits an already existing real-world task. Therefore, the interface design needs to take the real-world task flow into account from the beginning.  We propose a model of interaction devices and human interaction capabilities that helps evaluate how well different interaction devices/techniques integrate with specific real-world scenarios. The model was developed based on a survey of wearable interaction research literature. Combining this model with descriptions of observed real-world tasks, possible conflicts between task performance and device requirements can be visualized helping the interface designer to find a suitable solution.	fits;multimodal interaction;requirement;scientific literature;wearable computer	Tobias Klug;Max Mühlhäuser	2007		10.1145/1322192.1322244	simulation;speech recognition;interactive systems engineering;wearable computer;human–computer interaction;computer science;human factors and ergonomics;multimedia	HCI	-50.15663216228273	-45.95055535080637	64203
94c660f725fba89ac0ca6a7ab41fcfed1357d0eb	location-based entertainment (panel): the next generation	next generation	We focus not on the business model, other than to the extent that it affects design and its effect on issues like throughput and demographics. Instead, our focus is on the process and content that goes into a creating a guest experience in an LBE venue. We’ll also discuss what works and what doesn’t! An underlying theme is that LBE attractions represent a new medium, and no one really knows how to author successful attractions yet.	location-based service;throughput;venue (sound system)	Randy F. Pausch;Trevor Bryant;Jon Snoddy;Joe Garlington;Jordan Weisman	1998		10.1145/280953.281584	computer science	HCI	-55.84926405401503	-40.32701930907056	64331
ea405ae10c607f0b61e47b7f96b994c4bdac077d	co-curator: designing for mobile ideation in groups	collocated interaction;smartphones;mood boards;handheld devices;ideation;interaction design	We introduce Co-Curator, a prototype mobile app designed to support collection and sharing of referential sources of inspiration in face-to-face design ideation meetings. The design of the app stems from both ideas of repurposing mobile devices in everyday mundane tasks and existing practice amongst designers to share and collate sources of inspiration during the early stages of collaborative design projects. The findings from a trial show that the app was positively received and that people felt that it supported creating a collection of sources, as well as the task of sharing within design ideation meetings. Furthermore, the trial suggests that the synchronised gesture required to share sources seemingly alleviates the awkwardness arising from public gesture performance. Finally, from the findings we also highlight further considerations that need to be given to better support coordination and focus within these meetings.	mobile app;mobile device;prototype	Martin Porcheron;Andrés Lucero;Joel E. Fischer	2016		10.1145/2994310.2994350	simulation;human–computer interaction;engineering;multimedia	HCI	-57.87306465834227	-41.29621807169955	64348
25eb06feb26c6785d3c50d13b0bac2f470054ddf	usage of it and electronic devices, and its structure, for community-dwelling elderly	aide handicape;handicapped aid;ayuda minusvalido;interfase usuario;equipement menager;domestic appliances;user interface;elderly;information technology;personne âgee;structure electronique;hombre;age;technologie information;anciano;user assistance;estructura electronica;assistance utilisateur;asistencia usuario;human;household;menage;elderly people;interface utilisateur;equipo domestico;tecnologia informacion;familia;electronic structure;homme;edad	Electrical household appliances and IT (information technology) are believed to increase the QOL and well-being of the people who use them. The benefits of electronic devices for elderly people would be more evident than for younger people because it is assumed that such equipment would compensate for the decline of functional ability in the elderly. However, there has been only very limited research on the actual usage and influence of such devices in relation to generation and age. The purposes of the present study were to clarify the actual situation with regard to the use of IT and electronic devices by community-dwelling elderly, and to characterize individuals according to their familiarity with such devices		Madoka Ogawa;Hiroki Inagaki;Yasuyuki Gondo	2006		10.1007/11788713_110	simulation;computer science;operating system;user interface;information technology;electronic structure	ECom	-60.577019293716646	-49.80102412401597	64397
2c06b045fbd494135c347e3ed0ee26b390c67132	introducing shared character control to existing video games	video games;cooperation;collaboration;shared control;multi player games;social	Many people enjoy the social aspects of gaming, but most video games are designed to be played by one person at a time. We introduce Legion:Gaming (LGaming), a system that increases the sociability of single-player video games by allowing joint co-located play. The LGaming mediation framework flexibly merges the inputs of multiple players into a single control stream before forwarding it to the gaming system in real-time, and supports visual overlays to give players feedback on the newly-injected social dimensions of the game. Studies with more than 50 participants explore the new space enabled by LGaming, showing social and preferential effects of several archetype mediation strategies. The LGaming approach has the potential to improve social aspects of existing single-player games, allow novices to learn from experts while playing together simultaneously, and improve players’ gaming performance.	midi controller;real-time transcription;virtual world	Anna Loparev;Walter S. Lasecki;Kyle I. Murray;Jeffrey P. Bigham	2014			video game design;simulation;4x;turns, rounds and time-keeping systems in games;computer science;emergent gameplay;game mechanics;distributed computing;multimedia;social;management;cooperation;collaboration	HCI	-56.24038225390069	-47.04059605092043	64706
f6a6b1439ead074db8a0d60916d183efc96bd035	are children with asd more prone to test the intentions of the robonova robot compared to a human?	intention testing behaviors;imitation;autism;human–robot interaction	This study proposes an innovative device specifically designed for investigating the ability of children with autism spectrum disorder (ASD) to test the intention of a partner in a dyadic interactive game. Twenty one children with ASD were exposed to both a contingent and a noncontingent interaction condition with either a human agent or the Robonova robot as partners. The statistical analysis indicates a strong tendency toward a significant higher frequency of testing behaviors in the robot noncontingent condition and no difference between the two groups (robot/human) for the contingent condition. Children with ASD showed significantly more eye gaze to the robot compared to the human agent in both contingent and noncontingent conditions, but no difference in affect was found. The high level of initiations recorded in all conditions suggests that the game has a high motivational value for ASD children. Further longitudinal studies should investigate if such synchronous interaction games lead to improved shared intentionality in children with ASD.	robot	Andreea Peca;Ramona Simut;Sebastian Pintea;Bram Vanderborght	2015	I. J. Social Robotics	10.1007/s12369-015-0317-8		Robotics	-52.981665643186425	-50.9809758468207	64713
6cf07c06dfc7d07cd1e496b5999c3c9b94b3fcf1	measuring flow experience of computer game players	flow theory;enjoyment;computer games	This research-in-progress paper reports on the development of an instrument for measuring flow experience of computer game players. Flow theory (Csikszentmihalyi, 1993) has been widely adopted in various research fields such as information systems (IS), human-computer action (HCI), and computer games. We argue that flow experience in computer game play leads to enjoyment and therefore can be measured as a dimension of enjoyment in addition to emotion. Development process of the instrument is discussed in this paper.		José Pablo Zagal;Susy S. Chan;Jingli Zhang	2010			video game design;simulation;human–computer interaction;computer science;game mechanics;multimedia	HCI	-60.26820564429868	-45.17668061355766	64756
47d279f8ac74cffbdaa111e1317f9cf089321f94	development of smart infant-parents affective telepresence system	smart sensing;virtual presence;affective presence	Crying is the language of babies. Inability of parents in understanding the needs of babies causes stress and anxiety. The aim of this study is to develop a rapid prototype of infant-parent communication system. The system was tested on real babies and parents, while they were apart. The Results pointed to the overall acceptance and effectiveness of the system in cry translation and reducing the parents' anxiety with regards to baby cries.	prototype;rapid prototyping	Elham Saadatian;Reihaneh Hosseinzade Hariri;Adrian David Cheok;Ryohei Nakatsu	2014		10.1145/2658861.2658924	psychology;simulation;communication;social psychology	HCI	-56.6896496391772	-51.74739295482544	64954
04d297b16eeaa22089b37eb25791a7dba14969e4	developing an embodied pedagogical agent with and for young people with autism spectrum disorder	autism spectrum disorder;embodied pedagogical agent;participatory design	This paper describes how we developed an embodied pedagogical agent (EPA) with and for young people with autism spectrum disorder (ASD). ASD is characterised by impairments in social communication, imagination, and perspective-taking, which can compromise design and collaboration. However, if an ASD preference for visual processing can be supported by providing images of design ideas as they develop, these difficulties may be overcome. We describe a methodology that successfully supports the visualisation and development of EPAs using our prototype visualisation tool (EPA DK), enabling ASD users to function as active design participants.	battery eliminator circuit;expectation propagation;imagination age;pedagogical agent;prototype	Beate Grawemeyer;Hilary Johnson;Mark J. Brosnan;Emma Ashwin;Laura Benton	2012		10.1007/978-3-642-30950-2_33	visual processing;participatory design;visualization;developmental psychology;imagination;autism spectrum disorder;embodied cognition;compromise;psychology	HCI	-56.611894608728385	-50.76227652026536	65088
03a207e2f1dae7e5c5cbd69bd33defe0a5e96e87	personal stories within virtual environments: a cancer patient information software case study	cancer patient;virtual environment	Virtual environments can create a relaxed mood, increasing a patient's receptivity to learning. Personal stories and an individual approach to the content, rather than abstract facts, make the CD-generated experience more vivid and real. With the user in control, selecting content and interacting constantly with the program, the virtual experience is more meaningful than the one created by simply retrieving information. This article explains how three CD-ROMs containing cancer information embody personal stories and medical information in virtual environments.		Darcy Drew Greene;Carrie Heeter	1998	Cyberpsy., Behavior, and Soc. Networking	10.1089/cpb.1998.1.201	psychology;medicine;human–computer interaction;computer science;virtual machine;instructional simulation;multimedia;world wide web	HPC	-53.93382107296529	-44.55963734519815	65165
9341876017b0ab6860097a11eedb360e8e4be979	generating dynamic narratives with real time interactions utilizing mobile technology	interactive environments;mobile game play;social connectivity dynamic narrative generation real time interactions mobile technology smart phones game developers interactive environments mobile game play;games global positioning system servers real time systems smart phones mobile communication buildings;real time interactions;social connectivity;smart phones;smart phones computer games interactive systems mobile computing real time systems;dynamic narrative generation;servers;global positioning system;games;mobile communication;game developers;computer games;mobile computing;interactive systems;mobile technology;buildings;real time systems	The popularity of smartphones and other mobile technologies provides unique and exciting opportunities for game developers to create interesting game experiences and simultaneously study how players react and interact to these new environments. By studying and enhancing these new interactive environments and utilizing these technologies, we can break free of traditional game experiences and create newer and more exciting games with the flexibility of mobile devices. This study explores how we expand our idea of what a traditional game should be and poses a newer, fresher look on mobile game play and social connectivity. We have added to the notion of playing a game without actively engaging in it from the foundation of previous research. We have done this in order to build players' unique stories that will allow players to make more meaningful choices throughout their gameplay experience. By offering the player real time choices and active engagement in a mobile game that currently offers none, we expect to increase the levels of enjoyment and usefulness, from both educational and recreational viewpoints.	interaction;mobile device;mobile game;smartphone;traditional game	Jon A. Preston;Joshua Skelton;William D. Forsyth;Jeffrey D. Greene	2014	2014 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)	10.1109/CGames.2014.6934140	game design;games;cheap talk;simulation;mobile telephony;global positioning system;human–computer interaction;computer science;operating system;game mechanics;mobile technology;game art design;game developer;multimedia;game design document;mobile computing;server	HCI	-54.47027440609325	-39.766232205549926	65193
ae3d92c64806e54d1a4b98792894b7693d12e3d8	personalized serious games for cognitive intervention with lifelog visual analytics		This paper presents a novel serious game app and a method to cre- ate and integrate personalized game content based on lifelog visual analytics. The main objective is to extract personalized content from visual lifelogs, integrate it into mobile games, and evaluate the effect of personalization on user experience. First, a suite of visual analysis methods is proposed to extract semantic informa- tion from visual lifelogs and discover the association among the lifelog entities. The outcome is dataset that contains augmented and personal lifelog images. Next, a mobile game app is developed that makes use of the dataset as game content. Finally, an experiment is conducted to evaluate user gameplay behaviors in the wild over three months, where a mixture of generic and personalized game content is deployed. It is observed that user adherence is heightened by personalized game content as compared to generic content. Also observed is a higher enjoyment level in personalized than generic game content. The result provides the first empirical evidence of the effect of personalized games on user adherence and preference for cognitive intervention. This work paves the way for effective cognitive training with user-generated content.	cluster analysis;cognition;entity;heuristic;lifelog;mobile game;personalization;pipeline (computing);user experience;user-generated content;visual analytics	Qianli Xu;Vigneshwaran Subbaraju;Vivian Shuhsien Huang;Aijing Wang;Kathleen Kang;Sonia Cristina de Souza;Yanhong Dong;Liyuan Li;Joo-Hwee Lim	2018		10.1145/3240508.3240598	lifelog;multimedia;personalization;cognitive training;cognitive intervention;visual analytics;user experience design;empirical evidence;suite;computer science	HCI	-59.176701281437495	-47.84506707209843	65349
0093018a15e8f41fc41b2be0d70784d47fd78471	quantitative results comparing three intelligent interfaces for information capture: a case study adding name information into an electronic personal organizer	intelligent interfaces;intelligent user interface;handwriting recognition;artificial intelligent;soft keyboard	Efficiently entering information into a computer is key to enjoying the benefits of computing. This paper describes three intelligent user interfaces: handwriting recognition, adaptive menus, and predictive fillin. In the context of adding a person’s name and address to an electronic organizer, tests show handwriting recognition is slower than typing on an on-screen, soft keyboard, while adaptive menus and predictive fillin can be twice as fast. This paper also presents strategies for applying these three interfaces to other information collection domains.	electronic organizer;functional dependency;handwriting recognition;image organizer;information capture;intelligent user interface;run time (program lifecycle phase)	Jeffrey C. Schlimmer;Patricia Crane Wells	1996	J. Artif. Intell. Res.	10.1613/jair.321	simulation;human–computer interaction;intelligent character recognition;computer science;artificial intelligence;multimedia;handwriting recognition	HCI	-48.52778147465987	-42.954156211256254	65384
19d03c47d90ecd97b4310348934a5282969fdba8	user's issues in crossmedia applications	scenario driven interview;user needs;user s behavior;digital media;crossmedia application;non digital medium;digital medium;think aloud protocol	Technology allows users to interact with a wide variety of information and services. However, more and more users need to integrate complementary content to previously accessed information. Crossmedia applications combine different information pieces, which are stored in different media, as a continuous story. Our study selects the particular case of combining printed material and internet resources for the purpose of delivering complementary information to users. Our investigation conducts a workshop with users composed of a scenario-driven interview and a talk-aloud protocol. This experiment reveals the behavior and difficulties of users when they are combining digital and non-digital media to gather complementary information. In addition, some recommendation is suggested focused on the improvement of the user's experience in crossmedia application that should be considered by designers.	digital media;printing;think aloud protocol	João Soares de Oliveira Neto;Nicolas Roussel;Lucia Vilela Leite Filgueiras	2009		10.1145/1621995.1622018	think aloud protocol;human–computer interaction;computer science;digital media;multimedia;law;world wide web	HCI	-56.75859118656373	-40.4647743080571	65407
ee4d31116c8dd71540a20bb7562928469b0934f9	introduction to special issue on human-computer information retrieval	special issue;human-computer information retrieval	Contemporary search engines are optimized for look-up scenarios where the information target is well-defined and human–machine interaction is limited to queries and search-result selections. In this role the search system serves as a cognitive prosthetic, temporarily enhancing people’s mental capabilities to provide access to additional information not known to the searcher or not readily accessible to them. However, this type of support is insufficient for tasks requiring more involved information interaction (e.g., where cross-query learning may be important) and situations where information behavior encompasses more than just information seeking. People may often possess more aspirational goals such as augmenting their intellect (Engelbart, 1962) and applying their knowledge to explore, learn, and make sense of the information they encounter (Marchionini, 2006a). To meet these demands search systems need to form a symbiotic relationship with their users, providing support for fluid and meaningful interaction between human and machine, and promoting critical thinking and increased interaction with information to facilitate cognitive development. Human–computer information retrieval (HCIR) is the study of methods that integrate human intelligence and algorithmic search to help people better search, explore, learn from, and leverage information (Marchionini, 2006b). It comprises a number of sub-disciplines including exploratory search (White & Roth, 2009) which combines querying and browsing strategies to foster learning and investigation; information retrieval in context (Ingwersen & Järvelin, 2005) which considers aspects of the user or environment that are typically not reflected in query statements; and interactive information retrieval (IIR), which is primarily focused on the interactive communication processes between the main actors in retrieval operations: users, systems, and optionally, intermediaries (Ingwersen, 1992). All of these sub-disciplines share a common goal: understanding and improving the way that people leverage technology to derive value from information. HCIR affords searchers self-actualization, deep involvement in the search process, and predominant roles in system design, use, and evaluation. Over the past few decades, search behavior has converged on a small number of tactics that transform the user into a passive information receiver rather than an active information seeker (Allan et al., 2012). HCIR systems empower searchers to be more proactive, critical thinkers during the information search process. To achieve this they must help users acquire better information search skills (through tutorials, tips, etc. (Bateman, Teevan, & White, 2012; Moraveji, Russell, & Mease, 2011)) and provide better system support for information interaction and understanding. Marchionini (2006b) proposed the following design goals for search systems where users have more control in determining relevant results: (i) help people making sense of information (cf. Dervin, 1998); (ii) amplify and reward good intellectual effort; (iii) have flexible architectures; (iv) situate themselves within a broader information ecology of memories and tools; (v) support the information lifecycle from creation to use; (vi) support tuning by users, and (vii) should be engaging and enjoyable to use. By realizing many of these goals, HCIR systems can help people become more effective information seekers and consumers, and more informed individuals generally. Existing capabilities of search systems already provide some support for the objectives listed above. Beyond presenting a ranked list of search results chosen with respect to the provided query, features such as spelling suggestions and suggested queries provide mechanisms to lead the user to potentially relevant content. Importantly from an HCIR perspective, control over selection and interpretation of the suggestions offered still remains with the searcher. Systems are also becoming increasingly aware of their users and their situations that extend beyond the query statements they issue. Personalization employs user models to individualize search results to a particular user’s interests (Teevan, Dumais, & Horvitz, 2005). Relevance feedback (including implicit feedback from interaction behavior and biometrics from physiological sensors) enables search systems to develop richer representations of users’ tasks and search interests by capturing relevance judgments explicitly from searchers (Rocchio, 1971) or mining them from their search interactions (Kelly & Teevan, 2003) or physiological signals (Feild, Allan, & Jones, 2010). The search behavior of other users (primarily queries and clickthrough) can also be mined in the aggregate and used to help rank results (Agichtein, Brill, & Dumais, 2006; Joachims, 2002) or suggest paths to follow through document collections (Wexelblat & Maes, 1999; White, Bilenko, & Cucerzan 2007). Recent research on mining finer-grained search interactions, such as mouse movements to estimate searcher’s gaze attention, is a promising direction for richer behavioral modeling on the Web (Guo & Agichtein, 2010; Huang, White, & Dumais, 2011).	aggregate data;behavioral modeling;biometrics;brill tagger;cognitive science;emoticon;exploratory search;human–computer information retrieval;human–computer interaction;infinite impulse response;information behavior;information ecology;information search process;information seeking;intellect;jones calculus;kelly criterion;lookup table;mined;personalization;realms of the haunting;relevance feedback;sensor;systems design;user interface;vii;viola–jones object detection framework;web search engine;world wide web	Ryen W. White;Robert G. Capra;Gene Golovchinsky;Bill Kules;Catherine L. Smith;Daniel Tunkelang	2013	Inf. Process. Manage.	10.1016/j.ipm.2013.02.002		HCI	-61.25708810152505	-41.98038244964417	65557
23b2854746f0dd7c7ddfc9e3d4b1edf42f65a6bb	audience-targeted design considerations for effective scientific storytelling	simulation;museums;data visualisation;visualization;human factors;humanities;storytelling;scientific computing;user centred design	An effective visualization must be carefully designed according to its purpose. This article describes three projects focused on scientific storytelling in a different domain area and for a different target audience. The authors describe the lessons learned working in each scientific field and the techniques used to tailor the visual narrative to a specific audience type. The three projects are a visualization of particle accelerator data designed for domain scientists, a presentation of new findings from the fusion community designed for nonexpert adults, and an interactive exhibit of phytoplankton populations tailored toward museum visitors, especially children. Special design decisions had to be made to handle the unique conditions of each scientific area as well as the given background knowledge of the target audience. By evaluating the effectiveness of each of method, the authors gain insight into which aspects become important in developing a visualization with maximum usability.	population;scientific visualization;usability	Franz Sauer;Tyson Neuroth;Jacqueline Chu;Kwan-Liu Ma	2016	Computing in Science & Engineering	10.1109/MCSE.2016.100	computational science;visual analytics;simulation;information visualization;visualization;human–computer interaction;computer science;human factors and ergonomics;data mining;multimedia;data visualization	HCI	-59.5869579155978	-46.58994480914274	65630
bd1699438e5362b60a4fc7760d74cceb582a5184	basic experimental verification of grasping information interface concept, grasping force increases in precise periods	pointing device;fitts law;adaptive interface;silent messages;man machine interface;communication channels;face to face;grasping force	In human-human communications, especially in face-to-face communication, sub-verbal and non-verbal messages have more importance than messages transported by words. On the other hand, in traditional manmachine interfaces, machines only understand pre-defined operations, and never understand operators’ sub-verbal and non-verbal messages. This causes some usability problems in machine operations. We have proposed elsewhere that Grasping Information Interface Concept (GIIC) is the key idea to alleviate the above-mentioned communication gap between man and machine, and this paper verifies GIIC experimentally. GIIC regards grasping-and-moving as a fundamental hand operation necessary for performing tasks using modern manmachine interfaces, and behavioral measures associated with grasping, such as force, posture, etc., should have much potential in developing task-adaptive and operator-adaptive interfaces because it is known that how people grasp devices is dependent on the purpose of these tasks. GIIC provides machines with a communication channel to understand operators’ intents more through the grasping information.	channel (communications);experiment;poor posture;usability	Sigeru Sato;Muneo Kitajima;Yukio Fukui	2007		10.1007/978-3-540-73345-4_22	computer vision;simulation;computer science;communication	HCI	-50.14516080357292	-49.51019730928578	65732
66340d4de701c34fc47c927ec304931589148d6d	natural language and dialogue interfaces		The design and development of natural interactive systems requires that the specific aspects of natural communication are taken into account. Besides the capability to understand and generate linguistic expressions, natural language use includes cooperation and planning of complex actions on the basis of observations of the communicative context, i.e., communicative competence. This Chapter discusses natural language dialogue interfaces and develops the view of interactive systems as communicating agents which can cooperate with the user on a shared task. Natural interaction is considered an approach to interface design which attempts to empower different users in various everyday situations to exploit the strategies they have learnt in human-human communication, with an ultimate aim of constructing intelligent and intuitive interfaces that are aware of the context and the user's individual needs. The notion of natural interaction thus refers to the spoken dialogue system's ability to support functionality that the user finds intuitive and easy, i.e., the interface should afford natural interaction. The view is supported by an evaluation study concerning a multimodal route navigation system.	command-line interface;complex systems;computer user satisfaction;dialog system;human–computer interaction;interactivity;loss function;multimodal interaction;natural language understanding;optimization problem;point of view (computer hardware company);requirement;screenshot;spoken dialog systems;usability	Kristiina Jokinen	2009		10.1201/9781420064995-c31	universal networking language;interface design;natural language processing;natural language;natural language user interface;communicative competence;exploit;navigation system;expression (mathematics);computer science;artificial intelligence	HCI	-52.117023831147975	-38.39034894255207	65905
0a0ee20a75d82172bfb930dc5f7d8e07a22ac3a6	"""learning multi-modal grounded linguistic semantics by playing """"i spy"""""""		Grounded language learning bridges words like ‘red’ and ‘square’ with robot perception. The vast majority of existing work in this space limits robot perception to vision. In this paper, we build perceptual models that use haptic, auditory, and proprioceptive data acquired through robot exploratory behaviors to go beyond vision. Our system learns to ground natural language words describing objects using supervision from an interactive humanrobot “I Spy” game. In this game, the human and robot take turns describing one object among several, then trying to guess which object the other has described. All supervision labels were gathered from human participants physically present to play this game with a robot. We demonstrate that our multi-modal system for grounding natural language outperforms a traditional, vision-only grounding framework by comparing the two on the “I Spy” task. We also provide a qualitative analysis of the groundings learned in the game, visualizing what words are understood better with multi-modal sensory information as well as identifying learned word meanings that correlate with physical object properties (e.g. ‘small’ negatively correlates with object weight).	haptic technology;modal logic;natural language;robot	Jesse Thomason;Jivko Sinapov;Maxwell Svetlik;Peter Stone;Raymond J. Mooney	2016				AI	-50.920784645634996	-50.01436410294462	66053
b06aee2c8ed666e9a25e1c0aefdee349824fc0b7	elicitation of haptic user interface needs of people with low vision		Various assistive technologies such as haptic technology are used to help people with visual impairments comprehend complex information. Yet there is likely to be a misconception that users with the same disability category share the same user interface needs; furthermore, the majority of the literature has been oriented toward total blindness rather than low vision, possibly leading to dissatisfaction with assistive technologies and discontinuation of its use by those with low vision. The aim of this article is to advance the understanding of the needs of those with low vision especially in relation to haptic-incorporated multimodal user interfaces. A scenario-based, participatory design approach was used to explore their needs. A total of 19 user needs were systematically documented under three categories: audition (n = 5), touch (n = 11), and vision (n = 3). This article focuses on qualitatively exploring their needs and theoretically interpreting the needs in the light of previous studies.	haptic technology;user interface	Hyung Nam Kim;Tonya L. Smith-Jackson;Chang Soo Nam	2013	Int. J. Hum. Comput. Interaction	10.1080/10447318.2012.722465	computer vision;human–computer interaction;computer science;multimedia	HCI	-54.497488233195284	-45.36421906601411	66367
b25f098e7c1411d99797f0e558cb1c906c0bdd59	the “y” of it matters, even for storyline visualization		Storylines are adept at communicating complex change by encoding time on the x-axis and using the proximity of lines in the y direction to represent interaction between entities. The original definition of a storyline visualization requires data defined in terms of explicit interaction groups. Relaxing this definition allows storyline visualization to be applied more generally, but this creates questions about how the y-coordinate should encode interactions when this is tied to a particular place or state. To answer this question, we conducted a design study where we considered two layout algorithm design alternatives within a geo-temporal analysis tool written to solve part of the VAST Challenge 2014. We measured the performance of users at overview and detail oriented tasks between two storyline layout algorithms. To the best of our knowledge, this paper is the first work to question the design principles for storyline visualization, and what we found surprised us. For overview tasks with the alternative layout, which has a consistent encoding for the y-coordinate, users performed moderately better (${p}\lt.05$) than the storyline layout based on existing design constraints and aesthetic criteria. Our empirical findings were also supported by first-hand accounts taken from interviews with multiple expert analysts, who suggested that the inconsistent meaning of the y-axis was misleading. These findings led us to design a new storyline layout algorithm that is a “best of both” where the y-axis has a consistent meaning but aesthetic criteria (e.g., line crossings) are considered.		Dustin Arendt;Meg Pirrung	2017	2017 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2017.8585487	visualization;data visualization;data mining;computer science;encode;human–computer interaction;design elements and principles;encoding (memory);algorithm design	Visualization	-61.13236884737756	-38.467978768952285	66385
ca8c45236327b565b986607b3b378f95371bc73d	awareness in the home: the nuances of relationships, domestic coordination and communication	interactive entertainment;group communication		awareness	Saul Greenberg;Carman Neustaedter;Kathryn Elliot	2009		10.1007/978-1-84882-477-5_3	psychology;multimedia;communication;social psychology	HCI	-58.13027196097681	-39.66659124475808	66470
284269263aef325d494ae32f6721e41f12b35241	designed by end users: meanings of technology in the case of everyday life with diabetes		This paper presents end users’ ability to work across boundaries in design. The point of departure is a research project in which 60 end users participated as co-designers of ICT to support their everyday lives with the chronic illness diabetes. In additional to a series of digital co-designs, 22 mock-ups designed by the end users emerged from the project. These mock-ups/end-user designs are analyzed, with a focus on boundaries. This design case presents end users’ ability to create continuities across boundaries through their willingness to step into the unknown territory of ICT design and through their fusion of meanings of technology, diabetes, and everyday life experience in their designs. The paper concludes with reflections on engagement in boundary relations and call for embracing end users’ contributions to design by focusing on horizontal and hybrid cooperations.		Anne Marie Kanstrup	2013		10.1007/978-3-642-38706-7_14	human–computer interaction;engineering;knowledge management;communication	HCI	-60.688355640726144	-39.31132238986239	66514
27581c799e90c3fe8c00590eb6c8535c9d962a03	evaluating a user-elicited gesture set for interactive displays	user elicitation;multi touch;gesture set;evaluation;pen;talk	Recently, many studies were conducted which focused on eliciting gestures from users in order to come up with gesture sets for surface computing. However, there are still many questions to clarify concerning the value of this method regarding to the usability of such gesture sets in real systems. In this work, we contribute a usability test of an implemented gesture set based on user suggested pen and hand gestures for node-link diagram editing on interactive displays. The results of the usability test gave valuable insight in how users interact spontaneously with such a gestural interface. In particular, we found that the methodology of eliciting gestures from users reveals what kinds of gestures users prefer but that it does not necessarily show how they are applied. Beyond that, we observed how participants differentiate between touch and pen within complex workflows.	diagram;gesture recognition;magdeburg;mental model;molecule editor;prototype;structure editor;surface computing;usability testing	Jens Heydekorn;Mathias Frisch;Raimund Dachselt	2011			computer vision;gesture recognition;multimedia;communication	HCI	-54.19131225518068	-44.050598362971336	66546
02a705f6dfccf6ae23a6911994195c8c37d717b0	puffy, a friendly inflatable social robot		The video describes Puffy, a friendly inflatable social robot companion for children that has been developed in cooperation with a team of psychologists and educators. Puffy has a combination of features which makes it unique with respect to existing robots.	openbsd;social robot	Alessandro Ubaldi;Mirko Gelsomini;Marzia Degiorgi;Giulia Leonardi;Simone Penati;Noëlie Ramuzat;Jacopo Silvestri;Franca Garzotto	2018		10.1145/3170427.3186595	robot;social robot;human–computer interaction;inflatable;computer science	Robotics	-55.295994735759024	-47.07285113078533	66655
dda4e2144e395dd5eb615e603fa79affd8234efe	encouraging better hand drying hygiene	hygienic interfaces;conference contribution;privacy issues;computer science;public restrooms;entertainment software	Electric hand driers have the potential to improve sanitation when using public toilets; if used properly, electric driers can dry hands more thoroughly than towels, and users do not come into physical contact with potentially contaminated objects. But electric driers are frequently used for just a few seconds--and so the potential advantage is lost. This paper describes the prototyping and evaluation of a system intended to encourage longer hand drying times in public toilets. The challenges are: to develop hygienic interfaces for use in toilet areas; to design simple to use software that is engaging enough to be used several times a day; and to conduct usability and system acceptance tests in an environment in which users are highly sensitive about privacy issues.	acceptance testing;privacy;usability	Sally Jo Cunningham;Andrew Will	2008		10.1145/1496976.1496982	simulation;human–computer interaction;computer science	HCI	-49.88969547104107	-45.60359853176707	66656
9607783c144ad7000356cce1f187fae0d8081095	design and evaluation of a personalized cancer treatment system using human-computer interaction techniques		This paper presents a case study where Human-Computer Interaction techniques were applied in the design and evaluation of a health system. The system consisted of a software platform that supports personalized cancer chemotherapy based on a tumor chemosensitivity assay. The essential background on personalized cancer treatment is provided. The system was designed using “contextual design,” a user-centered technique that involves contextual inquiry, interpretation, work modeling, consolidation, visioning, storyboarding and paper prototyping. The most salient products from the design phase and details of the system implementation are shown. The system was assessed using the Heuristic Evaluation method, which is a usability inspection performed by experts. Results from this evaluation indicate that only one of ten heuristics was missing from the system, while five were partially covered and four were fully covered. Contextual design; heuristic evaluation; HCI techniques; personalized cancer treatment; ATP tumor chemosensitivity assay.	human–computer interaction;interaction technique	Alexandra Martínez Porras;Rodrigo Mora;Gustavo López Herrera;Constantino Bolaños;Daniel Alvarado;Andrés Solano;Mariana López;Steve Quirós;Andrés Báez	2016		10.1007/978-3-319-31232-3_67	heuristic evaluation;systems engineering;implementation;paper prototyping;heuristics;usability inspection;contextual inquiry;contextual design;pluralistic walkthrough;computer science	HCI	-62.82873084683723	-51.618647454034104	66689
8c9751a84bf9f2cca8bb3ee0b8d17add825f0bed	designing the user interface for multimodal speech and pen-based gesture applications: state-of-the-art systems and future research directions	user interface	The growing interest in multimodal interface design is inspired in large part by the goals of supporting more transparent, flexible, efficient, and powerfully expressive means of human–computer interaction than in the past. Multimodal interfaces are expected to support a wider range of diverse applications, be usable by a broader spectrum of the average population, and function more reliably under realistic and challenging usage conditions. In this article, we summarize the emerging architectural approaches for interpreting speech and pen-based gestural input in a robust manner—including early and late fusion approaches, and the new hybrid symbolic-statistical approach. We also describe a diverse collection of state-of-the-art multimodal systems that process users’ spoken and gestural input. These applications range from map-based and virtual reality systems for engaging in simulations and training, to field medic systems for mobile use in noisy environments, to web-based transactions and standard text-editing applications that will reshape daily computing and have a significant commercial impact. To realize successful multimodal systems of the future, many key research challenges remain to be addressed. Among these challenges are the development of cognitive theories to guide multimodal system design, and the development of effective natural language processing, dialogue processing, and error-handling techniques. In addition, new multimodal systems will be needed that can function more robustly and adaptively, and with support for collaborative multiperson use. Before this new class of systems can proliferate, toolkits also will be needed to promote software development for both simulated and functioning systems.	dialog system;human–computer interaction;list of toolkits;multimodal interaction;natural language processing;population;simulation;software development;systems design;theory;user interface;virtual reality;web application	Sharon L. Oviatt;Philip R. Cohen;Lizhong Wu;Lisbeth Duncan;Bernhard Suhm;Josh Bers;Thomas G. Holzman;Terry Winograd;James A. Landay;Jim Larson;David L. Ferro	2000	Human-Computer Interaction	10.1207/S15327051HCI1504_1	simulation;human–computer interaction;computer science;artificial intelligence;multimedia;communication;user interface	HCI	-52.29571620725314	-38.77289871763373	66821
79977ab78d2695cf37b4deae8626cb148548d025	cued retrieval of personal memories of social interactions	episodic memory;topic modeling;social interactions;lifelog data	This paper aims at developing a social interactions summarizer system that firstly summarizes a person's daily social interactions, with the purpose of enhancing his episodic memory and secondly provides various methods for searching in the collected data. The first goal originates from studies that have shown that replaying video or audio recordings of an experience have proved effective in enhancing people's episodic memory. The second goal is based on the fact that with the emergence of wearable devices for lifelogging, every day huge archives of data consisting of images, audio, etc could be generated from a person's life. Over time the growth rate of such archives is so substantially high that manually searching them, even after a few months of data collection, would be cumbersome and virtually impossible. In this study, we present a method for effectively summarizing one's social interactions for enhancing her episodic memory. Our results, reporting work in progress, illustrate that our method is highly effective in augmenting one's episodic memory.	archive;computer memory;emergence;interaction;lifelog;wearable technology	Seyed Ali Bahrainian;Fabio Crestani	2016		10.1145/2983576.2983577	psychology;multimedia;communication;social psychology	AI	-55.36730626261677	-45.93007344295551	66919
a261917d852875dcabb2ba8f4c4e5f99f1862152	marquee: a tool for real-time video logging	multimedia;gestural interface;user interface;real time;user study;user studies;gestural interfaces;video indexing;video annotation;penbased computing;user interfaces	We describe Marquee, a pen-based video logging tool which enables users to correlate their personal notes and keywords with a videotape during recording. We present our observations about coordinating the task of logging in real time and describe the three phase, user-centered approach we took in designing the tool. Our early work explored the functionalities needed by users to successfully create a log. In the second phase we focused on testing our intuitions about logging by conducting user studies with paper mock-ups. In the final phase, we implemented a working prototype system and placed it in a setting to see if it supported people logging in real time.	data logger;login;marquee element;mock object;prototype;real-time transcription;usability testing;user-centered design;video logging	Karon Weber;Alex Poon	1994		10.1145/191666.191697	human–computer interaction;computer science;operating system;multimedia;user interface;world wide web	HCI	-48.51843752596581	-39.31555196666885	66947
cb1cc715485e9eaaee7c74a967ab9904372ca8cf	an optimal device selection for user satisfaction of content sharing	context awareness;content sharing;user satisfaction;device selection	With the paradigm from one-user-one-device to multi-device-one-user, people frequently switch between different devices to satisfy constant changes. The ultimate goal of researches about computing across multiple devices is to help people move hands-free across various devices. However, it is still a challenge to decide the most optimum device for a task under a certain environment. This paper proposes an optimal device selection for content sharing considering user satisfaction.	programming paradigm	Jiamei Tang;Paul Kim;Sangwook Kim	2014		10.1145/2554850.2559920	computer user satisfaction;computer science;knowledge management;internet privacy;world wide web	HCI	-54.03290197923562	-42.752839700819365	66987
3e1a7bca59d1b55b71696217cee0ae2aa3d95b44	emotions and messages in simple robot gestures	emotion recognition;human robot interaction;arm movement;social robots;gestures;emotion;social robot	Understanding how people interpret robot gestures will aid design of effective social robots. We examine the generation and interpretation of gestures in a simple social robot capable of head and arm movement using two studies. In the first study, four participants created gestures with corresponding messages and emotions based on 12 different scenarios provided to them. The resulting gestures were then shown in the second study to 12 participants who judged which emotions and messages were being conveyed. Knowledge (present or absent) of the motivating scenario (context) for each gesture was manipulated as an experimental factor. Context was found to assist message understanding while providing only modest assistance to emotion recognition. While better than chance, both emotion (22%) and message understanding (40%) accuracies were relatively low. The results obtained are discussed in terms of implied guidelines for designing gestures for social robots.	human–robot interaction;robot	Jamy Li;Mark H. Chignell;Sachi Mizobuchi;Michiaki Yasumura	2009		10.1007/978-3-642-02577-8_36	human–robot interaction;computer vision;computer science;artificial intelligence;social robot	Robotics	-51.05031673539186	-50.19227274016963	67178
327244c1131e4debc44900ea99ec0ee2e3914c19	a friendly navigation-system based on points of interest, augmented reality and context-awareness	context awareness;disorientation;monitoring;ubiquitous computing;augmented reality;mobile computing;geolocation	This paper presents a system to supply spatial orientation and support for daily-activities from a friendly and understandable perspective. We propose a model based on points of interest or well-known places, generating friendly routes to a destination based on user context instead of classical street names and quantitative distances. Moreover, the system offers augmented reality views that include contextual information. This philosophy of navigation is closer to the needs of users in their usual environments as well as in unknown places (e.g. tourism, business trips, etc.). The proposal is focused on any kind of people but it is especially useful for those who are not accustomed to use new technologies, people with disorientation problems and, in general, for people with some slight cognitive deficit. The system also includes mechanisms to know the contextual situation of the user by relatives or friends, supporting the desirable social requirements of nowadays applications.	augmented reality;context awareness;point of interest;requirement	José Ma Luna;Ramón Hervás;Jesús Fontecha;José Bravo	2012		10.1007/978-3-642-35377-2_19	augmented reality;simulation;human–computer interaction;computer science;operating system;geolocation;multimedia;mobile computing;ubiquitous computing	HCI	-50.094781511515876	-40.911732751671536	67390
59f3a34f74abe6e081fae0d729b49cb0a70e5917	the role of usability in the design and evaluation of dynamic traffic displays	lab based evaluation;development process;usability engineering methods;usability engineering;conceptual design;design and implementation;behavior change;web survey;exploratory study	Dynamic traffic displays are continuously replacing solid traffic signs [cf. e.g. 1]. Besides their obvious benefits, dynamic traffic signs may cause many potential problems, which are to be considered in the design and implementation of new signs. A project is presented by describing the basic considerations and methods applied in the development of a dynamic traffic display which was designed with the goal to optimally present information to traffic participants and support a behavioral change. The steps performed within the development process of design alternatives are presented as well as the different usability engineering methods applied in a web survey and an exploratory study in order to evaluate the design alternatives.	usability	Gerhard Leitner;Martin Hitz;Rudolf Melcher	2008		10.1007/978-3-540-89350-9_15	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;simulation;usability;human–computer interaction;systems engineering;engineering;system usability scale;usability engineering;heuristic evaluation;usability lab;usability inspection	HCI	-61.93179517271643	-51.01412352286537	67405
5de5c9b9f3dac2edabe7c62f7210bc9e68a0026c	who matters: a closer look at interpersonal relationship in mobile interruptibility		"""Interruptibility research is growing in computer-mediated communication (CMC). While much CMC research concerns """"interpersonal"""" communication, we have not seen a close examination of the impact of who in mobile interruptibility research. In this paper, we propose a study more closely investigating the interplay between interpersonal relationship characteristics with contextual factors and their impact on users' receptivity to communication."""	computer-mediated communication;information	Kuan-Yin Chen;Hao-Ping Lee;Chih-Heng Lin;Yung-Ju Chang	2017		10.1145/3123024.3124569	ubiquitous computing;human–computer interaction;embedded system;interpersonal relationship;computer science;multimedia;receptivity;interpersonal communication	HCI	-58.56200540206175	-40.04689580566411	67420
f50b4675a056bc410ed8ac573cdf0703fd08d946	the importance of gaze and gesture in interactive multimodal explanation	pragmatics;human interaction;multimodal communication;gesture multimodal communication;collaboration computer mediated human interaction;modelisation;multimodality;pragmatique;multimodalite;student teacher;interactive explanation gaze;communication non verbale;collaborative computing;human computer interface;non verbal communication	The objective of this research is twofold. Firstly, we argue that gaze and gesture play an essential part in interactive explanation and that it is thus a multimodal phenomenon. Two corpora are analyzed: (1) a group of teacher novices and experts and (2) a student teacher dyad, both of whom construct explanations of students’ reasoning after viewing videos of student dyads who are solving physics problems. We illustrate roles of gaze in explanations constructed within a group and roles of gesture in explanation constructed within a dyad. Secondly, we show how the analysis of such knowledge-rich empirical data pinpoints particular difficulties in designing human–computer interfaces that can support explanation between humans, or a fortiori, that can support explanation between a human and a computer.	catherine browman;goto;multimodal interaction;text corpus	Kristine Lund	2007	Language Resources and Evaluation	10.1007/s10579-007-9058-0	nonverbal communication;interpersonal relationship;linguistics;multimedia;social psychology;pragmatics	HCI	-53.66205797427811	-47.53145951591894	67633
08c04e6d06ed7a77f0244eec0274d14909456d28	automated data collection for evaluating collaborative systems	automated data collection;human computer interaction;data collection;metrics;collaborative system;multi user;evaluation metric;lessons learned;collaborative systems;automated logging tools;evaluation;special interest group	The purpose of this Special Interest Group (SIG) session is to share lessons learned about using automated logging techniques to collect data for evaluating collaborative (multi-user) systems. Automated logging techniques are frequently used in evaluating the human-computer interaction of single-user systems. There has been much less experience in using logging techniques for evaluating collaborative systems. We will discuss logging to collect data that are useful for evaluating collaborative systems.	collaborative software;human–computer interaction;multi-user	Jill L. Drury;Tari Lin Fanderclai;Frank Linton	1999		10.1145/632716.632938	special interest group;human–computer interaction;computer science;evaluation;data mining;database;management;metrics;data collection;collaboration	OS	-62.40198917771115	-45.299606182669805	67635
38b44710a2accdc2793d18ec2db269abb76d097f	computer support for social awareness in flexible work	design research;social awareness;new offices;field study;flexibility;ambience	How do we conceptualize social awareness, and what support is needed to develop and maintain social awareness in flexible work settings? The paper begins by arguing the relevance of designing for social awareness in flexible work. It points out how social awareness is suspended in the field of tension that exists between the ephemerality and continuity of social encounters, exploring ways to construct identity through relationships by means of social encounters – notably those that are accidental and unforced. We probe into this issue through design research: In particular, we present three exploratory prototyping processes in an open office setting (examining the concepts of a shared calendar, personal panels, and ambient awareness cues). Field studies, conducted in parallel, have contributed to a conceptual deconstruction of CSCW concepts, resulting in a focus on cues to relatedness, to belonging, and to care. Analyzing these three prototypes in their microcosmic usage setting results in specific recommendations for the three types of applications with respect to social awareness. The experiences indicate that the metaphors a ‘shared mirror’ and ‘breadcrumbs’ are promising foundations on which to base further design. We present these analyses and suggest that the metaphors work because of their ability to map experiences from the physical space into conceptual experiences. We conclude that social awareness in flexible work must be constructed indirectly, presenting itself as an option, rather than as a consequence of being able to overhear and oversee.	ambient awareness;anomalous experiences;backup;breadcrumb (navigation);cit program tumor identity cards;chat room;computer-supported cooperative work;eva conferences;error-tolerant design;experience;experiment;focal (programming language);feedback;friis formulas for noise;mobile phone;nonlinear gameplay;persistence (computer science);personalization;photocopier;physical access;r.c. pro-am;relevance;santa claus machine;scott continuity;sensemaking;social network;social structure;subtext;technical support;telecommuting;vanish (computer science);whole earth 'lectronic link	Susanne Bødker;Ellen Christiansen	2005	Computer Supported Cooperative Work (CSCW)	10.1007/s10606-005-9011-y	psychology;social science;simulation;design research;human–computer interaction;knowledge management;sociology;communication;management;social psychology;law;world wide web;social consciousness;field research	HCI	-58.963192453255516	-40.794414514175216	67724
fe154ad378ba382cf9ba375f08f09da4ffbe31ff	bringing together commercial and academic perspectives for the development of intelligent ami interfaces	voicexml;dialog systems;speech interaction;statistical methodologies;web interfaces	The users of Ambient Intelligence systems expect an intelligent behavior from their environment, receiving adapted and easily accessible services and functionality. This can only be possible if the communication between the user and the system is carried out through an interface that is simple (i.e. which does not have a steep learning curve), fluid (i.e. the communication takes place rapidly and effectively), and robust (i.e. the system understands the user correctly). Natural language interfaces such as dialog systems combine the previous three requisites, as they are based on a spoken conversation between the user and the system that resembles human communication. The current industrial development of commercial dialog systems deploys robust interfaces in strictly defined application domains. However, commercial systems have not yet adopted the new perspective proposed in the academic settings, which would allow straightforward adaptation of these interfaces to various application domains. This would be highly beneficial for their use in AmI settings as the same interface could be used in varying environments. In this paper, we propose a new approach to bridge the gap between the academic and industrial perspectives in order to develop dialog systems using an academic paradigm while employing the industrial standards, which makes it possible to obtain new generation interfaces without the need for changing the already existing commercial infrastructures. Our proposal has been evaluated with the successful development of a real dialog system that follows our proposed approach to manage dialog and generates code compliant with the industry-wide standard VoiceXML.	intelligent agent	David Griol;José M. Molina López;Zoraida Callejas Carrión	2012	JAISE	10.3233/AIS-2012-0145	human–computer interaction;computer science;artificial intelligence;operating system;dialog system;world wide web	HCI	-51.50499107302442	-38.20678730531403	67961
6782b90f9a70be7eb1af2ed50b5708f4cc4381bc	competitively versus cooperatively? an analysis of the effect of gameplay on human emotions and behaviors		This research aims to explore the impact of cooperative or competitive gaming modes on players’ emotion and behaviors. We conducted a with-in subject study with 30 participants. Participants were asked to play a fighting game with a male research confederate in two different gameplay modes. We examined (1) self-reported preference, (2) changes in the gamers’ emotional states, (3) facial expression data captured by emotion recognition software, and (4) video recordings of the gaming sessions. The statistical results showed no significant differences. However, we were able to identify unique behavioral patterns shown in the competitive gameplay mode.		Kenneth Clark;Lusene Donzo;Joon-Suk Lee	2018		10.1007/978-3-319-91250-9_33	communication;human–computer interaction;computer science;facial expression;emotion recognition;behavioral pattern	HCI	-54.08943778136349	-49.627760645581965	68071
1c6ddd5b93f38a6aefca98e0174cd9e7e51636cb	effects of communication media on intellective and negotiation task performance		Among several theories to explain how different communications media affect task performance, media richness theory is one of the most frequently cited. Media richness theory proposes that task performance will be improved when task information requirements are matched to a medium’s ability to convey information. The main objective of this research is to examine the media richness theory in a laboratory experiment. The investigation focuses on the effect of four different communication media (text, audio, video, and face-toface) on objective task performance on an intellective task and a negotiation task. For the negotiation task, a social psychological factor, consonancy, was involved to examine the interaction effect with media on performance. The results of this study did not support media richness theory in general. Audio was the most efficient medium for the intellective task, but there was no significant difference among medium groups in terms of effectiveness measure. For the negotiation task, this study failed to support the combined theory of media richness and social psychology. There was no significant media-by-consonancy interaction on the negotiation payoff.	digital media;requirement;theory	Kil-Soo Suh	1996			knowledge management;computer science;negotiation;social psychology;stochastic game;media richness theory;species richness	NLP	-54.12544521134485	-49.87274704155744	68240
7a9167a810550973a4fd5587a3d790aeec65aea3	reference model of next-generation digital personal assistant: integrating proactive behavior		Digital personal assistants such as Apple's Siri or Google Assistant emerge and penetrate our everyday lives, acting as digital helper for searching information or executing simple tasks. However, with their primarily reactive behavior through conversational input current assistants are rather limited in their support. This paper proposes a novel reference model of next-generation digital personal assistants which integrates the user's goals and a proactive behavior of support to achieve these goals. We report the findings of our focus group discussion with 11 researchers to develop and substantiate our model as well as identify common areas of human-centered assistance, namely mental, physical, activity, environment, social, and technology support. We further show and discuss important research challenges of next-generation assistants. Using our proposed reference model, researchers in the community can now design and classify their future personal assistants.	focus group;google assistant;personal digital assistant;reference model;siri	Christian Meurisch;Maria-Dorina Ionescu;Benedikt Schmidt;Max Mühlhäuser	2017		10.1145/3123024.3123145	proactivity;focus group;embedded system;reference model;human–computer interaction;computer science;knowledge management;personal information manager	HCI	-56.26367856057834	-41.13237401972172	68246
8fe249f75bc57146455bceb1149968ef349dd1a2	the personal adaptive in-car hmi: integration of external applications for personalized use	personalization;user modeling;automotive apps;adaptation;model based development;interaction modeling;user interfaces	We describe an approach for integrating non-automotive applications into in-car-entertainment systems while taking account of manifold personalization capabilities within a mobile environment. Adaptive user interfaces are generated for external applications using well-known interaction and personalization concepts. The interaction concepts are defined via state-based interaction models and utilized for the integration of various applications in order to guarantee a common look and feel. Context-aware adaptations of the user interfaces are achieved by supporting the process of gathering an augmented user model with a personalization concept in form of personalization guidelines. We present and discuss an exemplary application for a personalized, safe in-car HMI that automatically adapts to the targeted design and interaction concept as well as to the personal needs of the user.	adaptive user interface;common look and feel;human–computer interaction;personalization;prototype;requirement	Sandro Rodriguez Garzon;Mark Poguntke	2011		10.1007/978-3-642-28509-7_5	simulation;user modeling;human–computer interaction;computer science;multimedia;user interface	HCI	-52.87241909792737	-38.566958325659954	68267
151547a7c78002f0311c66d4b278a30ce47655e1	measuring expected interactivity: scale development and validation	human computer interaction;expected interactivity;perceived interactivity;scale development;communication	An implicit assumption underlying previous interactivity studies is that every time people use a communication medium (e.g., website) or device (e.g., smartphone), they perceive its interactivity through analyzing it from scratch trait-by-trait. As psychologists have long shown, however, we quite often skip such an intensive analysis, and rely on our expectations or schematic knowledge to perceive/evaluate an object. This study is designed to develop a measure of individuals’ expectation of interactivity toward a medium, called expected interactivity (EI). After specifying three conceptual dimensions underlying EI – sensory, semantic, and behavioral dimensions – scales for capturing them are developed, refined, and validated through multiple studies. Implications for future interactivity research are discussed.	binary prefix;interactivity;schematic;smartphone	Dongyoung Sohn;Sejung Marina Choi	2014	New Media & Society	10.1177/1461444813495808	simulation;computer science;multimedia;interactivity;social psychology	HCI	-60.11313343224994	-45.77873003150848	68357
fc858b26c40ddcac553ee07fec7c99a88d6f2a44	drawing in aphasia: moving towards the interactive	multimodal communication;it value;non verbal communication	"""This paper reviews the literature on the use of drawing to communicate by people whose language is restricted due to aphasia. The advantages of drawing over other forms of non-verbal communication for this population are detailed, followed by discussion of different approaches to communicative drawing with reference to descriptive reports, treatment studies and review papers. The two main approaches differ in their view of drawing either as an alternative to speech or as an augmentative tool in multimodal communication. In the former approach the focus is on drawing skill or quality. Successful transmission of messages is the goal, and this depends on the production of recognizable drawings. In contrast, in the latter approach quality of drawings is secondary to its value as an interactive medium. The focus is on interpersonal aspects of communication and drawing is used alongside other modalities as a medium of social connectedness. The main principles of interactive drawing are discussed with examples from recent therapy studies. These are: the importance of drawing """"economically"""" rather than producing """"good"""" drawings; the contribution of the communication partner in facilitating, developing and maintaining a shared interaction; and the importance of using interactive drawing within natural communication contexts, in particular conversation."""		Carol Sacchett	2002	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.2002.1018	nonverbal communication;multimedia	HCI	-59.19109642938059	-38.73532038529505	68554
22a9ffb7894cf3e0bc9905917a2673c375d4a939	jogchalking: capturing and visualizing affective experience for recreational runners	gesture;running;visualization;emotion;design	We present JogChalker, a system that allows recreational runners to capture their affective experience while running using touch gestures. Using a small set of simple gestures, a runner can record affect while running without looking at a screen or entering into a multi-step interaction. Gestures are recognized, but also recorded at high fidelity, as we believe how the gesture is made may itself be expressive and useful for runners to review. We present our initial prototype, describe the goals, structure, and outcomes of a four-week participatory design session, and discuss the consequent capture and visualization implications for JogChalker that we are currently exploring.	prototype	Nabil Bin Hannan;Felwah Alqahtani;Derek F. Reilly	2016		10.1145/2908805.2909406	design;simulation;visualization;emotion;engineering;multimedia;gesture	HCI	-54.92520538652556	-43.335678758753225	68584
c67c7b1f4978387b9b135958d687a606e90864d0	artificial folklore for simulated religions		In this paper we use grammar-directed procedural content generation (PCG) techniques to develop folklore; based on the seven basic story plots, for a simulated religion. A hierarchy of values for a simulated community was first generated. Using these values, a variety of deities were procedurally generated, each with their own reflected values and persona. A Context-Free Grammar is then traversed in order to generate fables appropriate for each deities persona. The intention of this work is to generate fables which can be used to contextualize a given simulated culture's beliefs.		Jason Andrew Hall;Benjamin Williams;Christopher J. Headleand	2017	2017 International Conference on Cyberworlds (CW)	10.1109/CW.2017.28	hierarchy of values;multimedia;cultural diversity;persona;folklore;computer science;grammar	Robotics	-57.03580511692659	-47.94347313768632	68641
a290994a88cafc926ea3eec1293855a0f295a002	towards artificial emotions to assist social coordination in hri	hri;artificial emotions;social robot;communication of emotions	Coordination of human-robot joint activity must depend on the ability of human and artificial agencies to interpret and interleave their actions. In this paper we consider the potential of artificial emotions to serve as task-relevant coordination devices in human-robot teams. We present two studies aiming to understand whether a non-humanoid robot can express artificial emotions in a manner that is meaningful to a human observer, the first based on static images and the second on the dynamic production of embodied robot expressions. We present a mixed-methods approach to the problem, combining statistical treatment of ratings data and thematic analysis of qualitative data. Our results demonstrate that even very simple movements of a non-humanoid robot can convey emotional meaning, and that when people attribute emotional states to a robot, they typically apply an event-based frame to make sense of the robotic expressions they have seen. Artificial emotions with high arousal level and negative valence are relatively easy for people to recognise compared to expressions with positive valence. We discuss the potential for using motion in different parts of a non-humanoid robot body to support the attribution of emotion in HRI, towards ethically responsible design of artificial emotions that could contribute to the efficacy of joint human-robot activities.		Jekaterina Novikova;Leon Adam Watts	2015	I. J. Social Robotics	10.1007/s12369-014-0254-y	computer science;artificial intelligence;social robot	AI	-50.65489371975216	-50.72409851257581	68765
00f84a00251e335389a544c8cd3cd593fe61e720	designing interaction with media façades: a case study	new technology;media facades;urban space;evaluation method;user centered design;interactive lighting design;user experience;interaction design;structural design;experience design	Media façades are one prominent example of how new technologies currently augment urban spaces. At the same time, they offer new, ubiquitous opportunities for novel applications. To achieve a usable and enjoyable outcome, however, designing interaction with media façades demands a structured design process. In this paper, we present our experiences designing iRiS, a system for remote interaction with media façades. We approached the development following a user-centered design approach and addressing the process at two points with additional means: (1) using a purpose-built prototyping toolkit testing and exploring both, content and hardware before deploying the system on the actual façade and (2) experimental use and adaptation of user experience (UX) evaluation methods to investigate the users actions and emotions more holistically in this context.	holism;structured analysis;user experience;user-centered design	Alexander Wiethoff;Sven Gehring	2012		10.1145/2317956.2318004	user experience design;user-centered design;simulation;human–computer interaction;experience design;computer science;engineering;interaction design;multimedia	HCI	-54.91612722217557	-38.20828403632542	69071
b2852f0f480514944a541b48379564f10665c497	nodding responses by collective proxy robots for enhancing social telepresence	telepresence;bystander robot;robot mediated communication	It is expected that the social presence of a distant person can be well conveyed in telecommunication using a robot as a proxy of that person. This paper proposes a novel form of robotic telecommunication, which consists not only of a proxy robot but also an additional bystander robot that autonomously responds to the interlocutor in front of them. The second robot is expected to complement the responses of the proxy robot so that the interlocutor feels stronger social telepresence of the distant person. A psychological experiment using two small humanoid robots as proxy and bystander reveals a positive effect on conveying a stronger feeling of social telepresence of the distant person.	humanoid robot;proxy server;social presence theory	Tsunehiro Arimoto;Yuichiro Yoshikawa;Hiroshi Ishiguro	2014		10.1145/2658861.2658888	psychology;simulation;social robot;communication;social psychology	Robotics	-51.93110359515874	-50.37766495530999	69347
54b069892327da15a6018b2f93c30f0dd0809aa6	do infants consider a robot as a social partner in collaborative activity?	social interaction;human robot interaction;agent;infants social cognition;collaborative activities;robot	Human infants can consider humans as collaborative agents, but little is known about whether they also recognize robots as collaborative agents. This study investigated that how infants understand robot agents while they watched collaborative interactions between a human and a robot. We presented a novel visual habituation paradigm in which a human and a robot performed a collaborative activity to 13-month-old infants. Our findings suggested that 13-month-olds can appreciate robots as collaborative partners. We interpreted infants' expectancy violation responses to actions of the robot as facilitating their understanding about nonhuman agents as social partner.	interaction;programming paradigm;robot	Yunhee Park;Shoji Itakura;Annette M. E. Henderson;Takayuki Kanda;Naoki Furuhata;Hiroshi Ishiguro	2015		10.1145/2814940.2814953	psychology;developmental psychology;communication;social psychology	Robotics	-52.88046969231888	-50.39281627403918	69877
153586d5dbde7768d3f29d6350749977187e62ed	hands that speak: an integrated approach to studying complex human communicative body movements	sensors;depth cameras;sign language;sign language recognition image motion analysis;data collection;assistive technology gesture recognition cameras sensors data collection data visualization three dimensional displays;kinect;chronoviz sign language gestures depth cameras kinect visualization;visualization;chronoviz;gestures;three dimensional displays;data visualization;assistive technology;complex human communicative body movements human motion signal analysis gestures sign language naturalistic data collection depth cameras;gesture recognition;cameras	Gestures, the visible body movements that are ubiquitous in human behavior, are key elements of natural communication. Understanding them is fundamental to designing computing applications with more natural forms of interaction. Both sign languages and everyday gestures reveal the rich signal capacity of this modality. However, although research is developing at fast pace, we still lack in-depth understanding of the elements that create the underlying symbolic signals. This is partly due to lack of tools for studying communicative movements in context. We introduce a novel approach to address this problem based on unobtrusive depth cameras and developed an infrastructure supporting naturalistic data collection. While we focus on sign language and gestures, the tools we developed are applicable for other types of body based research applications. We report on the quality of data collection, and we show how our approach can lead to novel insights and understanding of communicative movements.	modality (human–computer interaction)	Nadir Weibel;So-One Hwang;Steven Rick;Erfan Sayyari;Dan Lenzen;James D. Hollan	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.82	computer vision;visualization;sign language;computer science;sensor;gesture recognition;multimedia;gesture;data visualization;statistics;data collection	HCI	-50.556990114471546	-43.565877927506534	69941
2faaa5b78628cc3d0bec939910661a474a833781	position paper: quality-of-experience of cyber-physical system applications		This paper takes a view on the Quality-of-Experience (QoE) perspective of Cyber-Physical System (CpS) applications involving users. We provide an overview of characteristics of CPS applications, their relation to QoE and implications for assessing QoE of such systems. Furthermore, we incorporate eudaimonic aspects such as meaningfulness and personal growth that need to be considered in order to grasp the strongly multi-dimensional aspects of QoE in this context.	cyber-physical system	Florian Hammer;Sebastian Egger-Lampl;Sebastian Möller	2017	2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)	10.1109/QoMEX.2017.7965666	position paper;multimedia;personal development;computer science;cyber-physical system;quality of experience;pragmatics;grasp	HPC	-58.17067492316953	-47.1641933583814	70030
1222fd5834ea3f31361610031590639d22e0aced	biological sensor fusion using information request for dependable web-based cscw systems	cyberspace;groupware;reliability;sensor fusion biosensors face recognition groupware;computer supported cooperative work;cscw computer supported cooperative work;biosensors physiology face recognition reliability sensor fusion cyberspace accuracy;face recognition biological sensor fusion information request web based cscw system computer supported cooperative work face to face communication stressing cyberspace multimedia;accuracy;situation assessment sensor fusion cscw computer supported cooperative work;physiology;face recognition;sensor fusion;situation assessment;biosensors	In Web-based CSCW (Computer-Supported Cooperative Work), remote members communicate their intentions in cyberspace. However, different from face-to-face communication, partners' situations including their interest, concentration, boredom, and tiredness cannot be easily transmitted. Oversight and mishearing of remote partners is often overlooked. Besides, it is further difficult to understand their real intentions sufficiently. To overcome these problems, biological sensor fusion for dependable Web-based CSCW Systems is proposed. This assesses or estimates situations of remote users through fusing information of multiple biological sensors and the related general contexts. By transmitting and using information of estimated users' situations, the system enriches the cyberspace through stressing or providing warnings by multimedia. This paper clarifies the mechanism of sensor fusion engine. In this mechanism, by making information requests to different algorithms to improve estimation accuracy based on analysis of higher layers, namely situation synthesis and analysis layers, robust face recognition is realized.	algorithm;computer-supported cooperative work;cyberspace;facial recognition system;sensor;transmitter	Yoshitaka Sakurai;Kouhei Takada;Takashi Kawabe;Setsuo Tsuruta	2011	2011 International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2011.113	simulation;engineering;knowledge management;communication	Robotics	-54.16594575444545	-45.568590975876795	70089
179284a21a8bc303383ce32dbf82936e82a19ad4	seeking beyond with integral: a user study of sense-making enabled by anchor-based virtual integration of library systems	information use;information processing;information seeking	This article presents a user study showing the effectiveness of a linked-based, virtual integration infrastructure that gives users access to relevant online resources, empowering them to design an information-seeking path that is specifically relevant to their context. IntegraL provides a lightweight approach to improve and augment search functionality by dynamically generating context-focused “anchors” for recognized elements of interest generated by library services. This article includes a description of how IntegraL’s design supports users’ information-seeking behavior. A full user study with both objective and subjective measures of IntegraL and hypothesis testing regarding IntegraL’s effectiveness of the user’s information-seeking experience are described along with data analysis, implications arising from this kind of virtual integration, and possible future directions.	information seeking behavior;sensemaking;usability testing	Shuyuan Mary Ho;Michael Bieber;Min Song;Xiangmin Zhang	2013	JASIST	10.1002/asi.22904	human–computer interaction;information processing;computer science;knowledge management;world wide web	HCI	-57.05076408969887	-40.80597405650257	70118
3c2f7c42a135dc9b207306991e7087b6fd852f91	the flo)(ps: negotiating between habitual and explorative gestures		The perceived affordances of an everyday object guide its user toward habitual movements and experiences. Physical actions that are not immediately associated with established body techniques often remain neglected. Can sound activate those potentials for action that remain latent in the physicality of an object? How can the exploration of underused and unusual bodily movements be fostered? This paper presents the Flo)(ps project, a series of interactive sounding glasses, which aim to foster social interaction by means of habitual and explorative sonic gestures within everyday contexts. We discuss the design process and the qualitative evaluation of collaborative and individual user experience. The results show that social interaction and personal use require different ways of transitioning from habitual to explorative gestures, and point toward possible solutions to be further explored.	automatic sounding;user experience	Karmen Franinovic	2011			multimedia;human–computer interaction;user experience design;engineering design process;social relation;computer science;negotiation;gesture	HCI	-58.36743749615852	-38.04876996551317	70123
b29ea6d35e8680412ce4ff7906f460d9b062cc16	understanding and intervening communicational behavior using artificial intelligence	machine learning;user interface design;behavior analysis;affective computing	Portable and inexpensive technologies have the potential to capture a huge variety of signals about human being. Systematic analysis of these signals can provide deep understanding on the basic nature of interpersonal communication. I am interested in taking a machine learning approach for analyzing human behaviors---atleast in a formal, well-established setting (e.g. in public speaking, job interview etc.). Understanding human behavior will enable us to design systems capable to make people self-aware. In many cases they might be useful for behavior modification as well.	artificial intelligence;machine learning;self-awareness;sentience	Md. Iftekhar Tanveer	2016		10.1145/2876456.2876468	user interface design;simulation;human–computer interaction;computer science;artificial intelligence;machine learning;affective computing;world wide web	AI	-53.29153328028031	-46.016097242031954	70152
ea7e8954e8fc1f2edc30cae45fc1eee12f6f19cf	mobile air ticket booking	m commerce;internet access;mobile usability;air ticket booking;guidelines;user interface design;domain specificity;cognitive complexity	Online air ticket booking is a cognitively complex task even on fully-functional internet-access devices such as desktops, representing a repetitive multi-parametric search in the flights database and then browsing long lists of flights found, consisting of different carriers, prices, dates and times, to create an optimal combination of outbound and inbound flights. We present the results of research into prospective users of mobile air ticketing, a set of domain-specific user interface design guidelines, and a wireframe design for mobile air ticket booking application.	electronic ticket;inbound marketing;parametric search;prospective search;user interface design;wire-frame model	Ivan Burmistrov	2009			user interface design;simulation;mobile commerce;internet access;computer science;engineering;cognitive complexity;world wide web	HCI	-51.59611127932352	-39.905794518674675	70415
6ddac7f7f482c64ec5a8777da1631687107f5a73	holomol: human memory augmentation with mixed-reality technologies		HoloMoL is a platform that helps us memorize different types of information by combining the method of loci memorization technique and mixed reality contents delivered through Microsoft HoloLens. This paper presents an overview of HoloMoL's design concept and implementation. To further understand our approach, we started by carrying out an exploratory study to investigate its usability aspects. Beside various interaction insights, results mainly indicated that participants utilized multiple memorization techniques that they thought worked best for intended information. Furthermore, we present some discussions about a participatory design workshop to exploit HoloMoL use cases. The results indicated a wider range of possible HoloMoL applications beyond learning and simple memorization. Additionally, the different methods for memorizing information found in this study offer insights for developing new services based on the method of loci.	microsoft hololens;mixed reality;pervasive informatics;samegame;usability	Yuki Yamada;Keisuke Irie;Kota Gushima;Fumiko Ishizawa;Mohammed AlSada;Tatsuo Nakajima	2017		10.1145/3131085.3131097	human–computer interaction;exploratory research;usability;participatory design;mixed reality;memory augmentation;use case;method of loci;memorization;computer science	HCI	-54.35452710651634	-38.69754954941329	70447
2e070d4d23b35470407fd2dfb0ae74a32fed5c63	applying augmented reality to industrial settings	industry;augmented reality;mobile devices	State-of-the-art mobile devices containing various sensors and interaction technologies have enabled the development of novel solutions for people working in industrial settings. In particular, introducing augmented reality into the mobile device domain could help maintenance engineers while they perform work tasks in a factory. This poster presents and discusses two concepts that explore how maintenance engineers could use augmented reality to view additional information related to equipment found in a factory setting.	augmented reality;mobile device;sensor	Elina Vartiainen;Peder Boberg;Oskar Qvarnström;Jonas Brönmark	2013		10.1145/2459236.2459284	computer-mediated reality;simulation;human–computer interaction;engineering;multimedia	HCI	-54.43457810991103	-38.277659165535574	70686
acab6aa78ab5773590ae8157c684dcc27ecff74b	modeling and using salience in multimodal interaction systems	geographic information;multimodal interaction	We are interested in input to human-machine multimodal interaction systems for geographical information search. In our context of study, the system offers to the user the ability of using speech, gesture and visual modes. The system displays a map on the screen, the user ask the system about sites (hotels, campsites, ...) by specifying a place of search. Referenced places are objects in the visual context like cities, road, river, etc. The system should determine the designated object to complete the understanding process of user's request. In this context, we aim to improve the reference resolution process while taking into account ambiguous designations. In this paper, we focus on the modeling of visual context. In this modeling we take into account the notion of salience, its role in the designation and in the processing methods.		Ali Choumane;Jacques Siroux	2009		10.1007/978-3-642-02577-8_2	computer vision;computer science;multimodal interaction;multimedia	NLP	-49.9100606152275	-38.789458389226496	70691
d8453531498c11ec824b87211d604d1a2bac890b	push me, shove me and i show you how you feel: recognising mood from emotionally rich interaction	emotional state;research through design;interactive system;interaction design;tight coupling;inherent feedback	The mood or emotional state you are in colours the way you interact with people and systems. Future interactive systems need to recognise emotional aspects in order to be truly adaptive. We designed an alarm clock, which elicits rich expressive behaviour and demonstrated that it is able to read your mood from the way you set it. We validated film clips, used them to induce moods after which participants had to set the alarm clock. From the dynamic setting behaviour we inferred parameters from which we calculated equations to identify the mood. The results illustrate the importance of a tight coupling between action and appearance in interaction design, through freedom of interaction and matching inherent feedback.	color;interaction design;video clip;windows me	Stephan Wensveen;Kees C. J. Overbeeke;J. P. Djajadiningrat	2002		10.1145/778712.778759	simulation;human–computer interaction;coupling;computer science;interaction design	HCI	-53.292180595848556	-45.330157168880355	70995
edefd4f9726335fcb7e198a7bb800f7432614fe3	effects of using indirect language by a robot to change human attitudes	human robot interaction;direct and indirect language;persuading people	The use of indirect language is considered useful for persuading people in human communication. The aim of this research is to determine whether this also occurs within human-robot interaction. Thus, it is hypothesized that indirect language will have greater influence in attitude changes towards a product in comparison to direct language. A seven-point semantic differential scale was employed to measure participants attitude changes towards a product advertised by a Nao Robot using either direct or indirect speech. Results showed no significant differences between the direct and indirect language experimental conditions. This may indicate that in human-robot interaction indirect language may not function similarly as it does in human communication. A larger sample size and improvements in stimuli are suggested for future works.	human–robot interaction;nao (robot);robot	Alexander López;Bryan Ccasane;Renato Paredes;Francisco Cuellar	2017		10.1145/3029798.3038310	human–robot interaction;simulation;computer science;artificial intelligence	AI	-52.152965206437955	-51.02384161239475	71009
4960a341c74825c144daa621f45d53fc27f6f03e	preliminary evaluation of the audience-driven movie	galvanic skin response;audience driven movie;experience evaluation;physiological response	In this paper we introduce an audience-driven theater experience, DIM Movie, in which audience participates in a pre-created CG movie as its roles, and report the subjective and physiological evaluations for the audience experience offered by DIM movie. Specifically, we present three different experiences to an audience-a traditional movie, its Self-DIM (SDIM) version with the audience's participation, and its Self-Friend-DIM (SFDIM) version with co-participation of the audience and his friends. The evaluation results show that the DIM movies (SDIM and SFDIM) elicit greater subjective sense of presence, engagement, and emotional reaction, and stronger physiological response (galvanic skin response, GSR) as compared with the traditional movie form; moreover, audiences show a phasic GSR increase responding to the appearance of their own or friends' CG characters on the movie screen.	anomalous experiences;cg (programming language);galvanic isolation;projection screen	Tao Lin;Akinobu Maejima;Shigeo Morishima;Atsumi Imamiya	2008		10.1145/1358628.1358843	skin conductance;multimedia	HCI	-54.286178685370466	-48.82612870870714	71152
5a0c71d7cf802bfd6cb36b511b87aa89ece6d181	cluestr: mobile social networking for enhanced group communication	mobile device;group initialization;hci;social software;group communication;proof of concept;social network;clustering;mobile terminal;group interaction	Recent technological advances foster the spreading of social software in the mobile domain. Hence, future usage patterns of mobile devices will involve more group interaction. While collaboration using mobile devices is an active area of research, only limited attention has been paid to the efficient initiation of group communication from mobile terminals. In this paper we present a community-aware mechanism that allows to efficiently select contacts in order to address them as a group. We have integrated the proposed method into a proof-of-concept application, and present preliminary experiments that demonstrate the accuracy of the approach and show significant time savings in the group initialization process.	algorithm;cluster analysis;experiment;interaction;mobile device;mobile social network;recommender system;sparse matrix	Reto Grob;Michael Kuhn;Roger Wattenhofer;Martin Wirz	2009		10.1145/1531674.1531686	mobile identification number;mobile search;social science;simulation;human–computer interaction;communication in small groups;computer science;operating system;mobile technology;mobile device;cluster analysis;communication;mobile computing;proof of concept;world wide web;social network	HCI	-59.68714121180422	-40.936807244078125	71226
0c2b18a69b04c97391c5d7c38d94e403c848d1e4	end user computing ergonomics: facts or fads?	human computer interaction;end user computing;telecommuting;hci;end users;mobile computing	A casual perusal of the current information technology (IT) literature supports the notion that interest in computing ergonomics is relatively low. Design improvements and technological advances have helped to reduce and even eliminate many of the early computing ergonomic problems. However, any perception that computer ergonomics is yesterday’s news overlooks two important computer use trends: expanding variety of use, especially as related to mobile computing and alternative office arrangements, and extended volume of use. These trends suggest that IT managers can expect a resurgence in ergonomic related challenges in the near future. abstraCt	end-user computing;human factors and ergonomics;independence day: resurgence;mobile computing	Carol Clark	2006	JOEUC	10.4018/joeuc.2006070104	end user;human–computer interaction;computer science;operating system;end-user computing;multimedia;mobile computing;world wide web	HCI	-55.783094791489745	-41.10177909869127	71236
a5e1125c3f9478083225190ac29eb871b627912f	"""""""that's aggravating, very aggravating"""": is it possible to classify behaviors in couple interactions using automatically derived lexical features?"""	behavioral signal processing;psychology;bsp;human behavior;behavioral informatics;observational studies;lexical features;couple therapy;categorization	Psychology is often grounded in observational studies of human interaction behavior, and hence on human perception and judgment. There are many practical and theoretical challenges in observational practice. Technology holds the promise of mitigating some of these difficulties by assisting in the evaluation of higher level human behavior. In this work we attempt to address two questions: (1) Does the lexical channel contain the necessary information towards such an evaluation; and if yes (2) Can such information be captured by a noisy automated transcription process. We utilize a large corpus of couple interaction data, collected in the context of a longitudinal study of couple therapy. In the original study, each spouse was manually evaluated with several sessionlevel behavioral codes (e.g., level of acceptance toward other spouse). Our results will show that both of our research questions can be answered positively and encourage future research into such assistive observational technologies.	code;interaction;text corpus;transcription (software)	Panayiotis G. Georgiou;Matthew Black;Adam C. Lammert;Brian R W Baucom;Shrikanth (Shri) Narayanan	2011		10.1007/978-3-642-24600-5_12	psychology;binary space partitioning;developmental psychology;artificial intelligence;data mining;communication;human behavior;social psychology;observational study;categorization	HCI	-54.10707113636479	-49.58618340599174	71270
e3b66b816df003addd7d393f644bcb4749825791	how designing for people with and without disabilities shapes student design thinking	accessibility;assistive technology;design;design thinking	Despite practices addressing disability in design and advocating user-centered design (UCD) approaches, popular mainstream technologies remain largely inaccessible for people with disabilities. We conducted a design course study investigating how student designers regard disability and explored how designing for both disabled and non-disabled users encouraged students to think about accessibility throughout the design process. Students focused on a design project while learning UCD concepts and techniques, working with people with and without disabilities throughout the project. We found that designing for both disabled and non-disabled users surfaced challenges and tensions in finding solutions to satisfy both groups, influencing students' attitudes toward accessible design. In addressing these tensions, non-functional aspects of accessible design emerged as important complements to functional aspects for users with and without disabilities.	accessibility;user-centered design	Kristen Shinohara;Cynthia L. Bennett;Jacob O. Wobbrock	2016		10.1145/2982142.2982158	design;simulation;design thinking;human–computer interaction;computer science;accessibility;multimedia;world wide web	HCI	-62.29660484345219	-41.83928138191858	71415
20025b1e2703fcf0da559db3f910173274a38653	exploring the relationship between visual context and affect in diagram interpretation		Among the growing body of research on the interpretation of diagrams there appears to have been relatively little attention paid to emotional or attitudinal responses, despite the fact that they may be significant for communicators aiming to stimulate interest, influence attitudes, or motivate action. This research explores the impact on affect of visual context in biological life cycle diagrams. In two qualitative studies, participants viewed decontextualized life cycle diagrams along with diagrams that included a contextual backdrop, and discussed their interpretations, associations, and attitudes toward the diagram content. Thematic analysis of the data revealed that context was associated with an elevated sense of empathy and concern for the animal, and a stronger perception of personal relevance—clear indications that diagram design can have important emotional and attitudinal impacts.	diagram	Matthew Wood;Susan Stocklmayer	2018		10.1007/978-3-319-91376-6_46	thematic analysis;diagram;social psychology;perception;empathy;qualitative research;psychology	HCI	-58.04294765066331	-48.88477253779963	71784
22f0506c6678ca31c110071b6bc4b321bb99885e	a passive brain-computer interface for supporting gaze-based human-machine interaction	clear negativity;hands-free interaction;passive brain-computer interface;evokes eeg activity;gaze-based human-machine interaction;selection process;human-machine interaction;specific intention;implicit interaction;eye movement;item selection;human-computer interaction	"""Tracking eye movements to control technical systems is becoming increasingly popular; the use of eye movements to direct a cursor in human-computer interaction (HCI) is particularly convenient and caters for both healthy and disabled users alike. However, it is often difficult to find an appropriate substitute for the click operation, especially within the context of hands-free interaction. The most common approach is the use of dwell-times, but this can lead to the so-called """"Midas-Touch"""" problem. This problem is defined by the fact that the system incorrectly interprets fixations due to long processing times or spontaneous dwellings as a user command. The current study explores the event-related potentials (ERPs) that might indicate a user's intention to select. Therefore, Electroencephalography (EEG) data was recorded from 10 participants during an interaction with a dwell-time system within a selection process. The aim was to identify EEG potentials related to the intention to interact (i.e. the selection of targets on a screen) and to classify these against EEG potentials unrelated to interaction during random fixations on the screen. As a result, we found a clear negativity over parietal electrodes for the intention of item selection. This negativity did not occur when participant fixated an object without intention to select (no specific intention). We robustly could classify the underlying brain activity in most of our participants with an average accuracy of 81%. The presented study provides evidence that the intention to interact evokes EEG activity that can clearly be detected by passive BCI technology. This leads to a new type of implicit interaction that holds the potential to improve human-machine interaction by increasing efficiency and making it more intuitive."""	brain–computer interface	Janna Protzak;Klas Ihme;Thorsten O. Zander	2013		10.1007/978-3-642-39188-0_71	psychology;simulation;communication;social psychology	HCI	-48.53664800308049	-46.96499790704486	71868
a922bf92ff6ff94c652ea35b5644a69f00e2d2d5	attentional behavior of users on the move towards pervasive advertising media		In this chapter we analyze the attention of users on the move towards pervasive advertising media. We report the findings of two multi-sensor eye tracking studies designed to provide a better understand ing of the actual attentional behavior of users on the move in different public env ironments. In the first study 106 participants were equipped with eye tracking techno logy and asked to use public transportation vehicles equipped with information a nd dvertising screens. In a second study 16 participants were asked to stroll thr ough a shopping street for about 15 minutes, and during this time different indicato rs for their behavior and focus of attention (eye tracking, movement and pose track ing) were captured. Motion and pose data was correlated with eye tracking data to identify typical patterns of attention. We report the results of these studies, then discuss the implications of the main findings for pervasive advertising and fin ally reflect on the used research methodology.	env;eye tracking;pervasive informatics;reflow soldering	Johann Schrammel;Elke E. Mattheiss;Susen Döbelt;Lucas Paletta;Alexander Almer;Manfred Tscheligi	2011		10.1007/978-0-85729-352-7_14	psychology;multimedia;advertising;internet privacy	HCI	-55.974029682889686	-42.33013927222538	71904
563096e05d73f863f878e6afb54427f2935719de	web-based morphological charts for concept design in collaborative product development	design tool;concept design;collaborative product development;production process;conceptual design;internet;web based system;world wide web;morphological chart analysis;intranet;web technology;article;product development	Morphological Chart Analysis is one of the formal design tools enabling collaborative product development. It is widely accepted in the textbooks and by practitioners as an effective technique for conceptual design of products, processes, and systems. This paper proposes to exploit the Web technology to implement the morphological chart analysis method on the Internet/Intranet. A prototype system, consisting of a concept browser/editor, a functional analyzer, a concept generator, a concept assessor, and all linked to a central concept database, is demonstrated. Parties concerned in product development are able to contribute in different locations to the same project. In addition to project team members, even experienced customers and potential suppliers are able to contribute their ideas to the concept base using the concept browser/editor. The incorporation of various decision-making activities of concept design into one integrated Web-based system allows the designer to choose the most appropriate idea from potential alternatives in an objective and systematic way.	chart;collaborative product development;intranet;new product development;prototype;world wide web	George Q. Huang;Kai-Ling Mak	1999	J. Intelligent Manufacturing	10.1023/A:1008999908120	web development;web modeling;the internet;web design;computer science;systems engineering;engineering;knowledge management;marketing;conceptual design;scheduling;product design;world wide web;concept art;new product development	SE	-62.620691016769115	-39.071576305264564	72170
5b8e6eac28098defd9bb08189aa75d9bbfc2f160	echovis: training echolocation using binaural recordings – initial benchmark results		In this paper, we describe a recently begun project aimed at teaching of echolocation using a mobile game. The presented research concerns initial echolocation tests with real world obstacles and similar tests performed using binaural recordings. Tests that included detection and recognition of large obstacles in various environments (padded room, non-padded room, outdoors) were performed by three groups 10 persons each: blind children, blind adults and sighted adults. A mixed group of volunteers also tested binaural recordings of the same environments using a mobile application for Android and iOS devices. The presented preliminary research shows a large variance in echolocation ability of the participants. Less than 20% of the 30 volunteers could reliably (with u003e80% certainty) localize 1 m and 2 m wide walls at distances 1 to 3 m, while about as many showed no echolocation skills and answered at a random level. On average sighted adults performed better in echolocation tests than blind children, but worse than blind adults. Tests in outdoor environments showed much better results than indoors and a padded room was marginally better for echolocation than the non-padded room. Performance with recordings was generally worse than in analogous real tests, but the same trends could be clearly observed, e.g. a proportional drop-off of correctness with distance. The tests with recordings also demonstrated that a repeatable pre-recorded or synthesized clicker originating from a loudspeaker was a better solution than recordings with live clicker sounds.		Michal Bujacz;Marta Szyrman;Grzegorz Górski;Rafal Charlampowicz;Slawomir Strugarek;Adam Bancarewicz;Anna Trzmiel;Agnieszka Nelec;Piotr Witek;Aleksander Waszkielewicz	2018		10.1007/978-3-319-94274-2_15	acoustics;clicker;binaural recording;human echolocation;blindness;computer science	Vision	-53.065044131350454	-51.558647893500506	72317
1613d28655ae89ecc50470c82478694dcbde32ec	multimodal approach to affective human-robot interaction design with children	humanoid robot;story telling;young children;affective interaction;interaction style;collaboration;human robot interaction;wizard of oz;social robots;physiological response;human robot communication;social robot	Two studies examined the different features of humanoid robots and the influence on children's affective behavior. The first study looked at interaction styles and general features of robots. The second study looked at how the robot's attention influences children's behavior and engagement. Through activities familiar to young children (e.g., table setting, story telling), the first study found that cooperative interaction style elicited more oculesic behavior and social engagement. The second study found that quality of attention, type of attention, and length of interaction influences affective behavior and engagement. In the quality of attention, Wizard-of-Oz (woz) elicited the most affective behavior, but automatic attention worked as well as woz when the interaction was short. The type of attention going from nonverbal to verbal attention increased children's oculesic behavior, utterance, and physiological response. Affective interactions did not seem to depend on a single mechanism, but a well-chosen confluence of technical features.	confluence;humanoid robot;human–robot interaction;interaction design;multimodal interaction;monotone	Sandra Y. Okita;Victor Ng-Thow-Hing;Ravi Kiran Sarvadevabhatla	2011	TiiS	10.1145/2030365.2030370	human–robot interaction;computer science;artificial intelligence;social robot	HCI	-51.99633470203868	-50.17787287385534	72357
7a197316207a50ba4efbf876d27887320b412e9f	integrating audio and visual information for modelling communicative behaviours perceived as different		In human face-to-face interaction, participants can rely on a number of audio-visual information for interpreting interlocutors’ communicative intentions, such information strongly contributing to the successfulness of communication. Modelling these typical human abilities represents a main objective in human communication research, including technological applications like human-machine interaction. In this pilot study we explore the possibility of using audio-visual parameters for describing/measuring the differences perceived in interlocutor’s communicative behaviours. Preliminary results derived from the multimodal analysis of a single subject seem to indicate that measuring the distribution of some prosodic and hand gesture events which are temporally co-occurring contribute to the accounting of such perceived differences. Moreover, as far as gesture events are concerned, it has been observed that relevant information are not simply to be found in the occurences of single gestures, but mainly in some gesture modalities (for example, “single stroke” vs “multiple stroke” gestures, one-hand vs both-hands gestures, etc...). In this paper we also introduce and describe a software package, ViSuite, we developed for multimodal processing and used for the work described in this paper.	human–computer interaction;multimodal interaction;temporal logic	Michelina Savino;Laura Scivetti;Mario Refice	2008			software;artificial intelligence;natural language processing;modalities;human communication;computer science;gesture	HCI	-52.05320284951322	-47.79095028653827	72374
9fcb10da685e145d4597cff09af798bb58119a1f	customised city maps in mobile applications for senior citizens	accessibility;age;app(s) and app design;customizing maps;geographic information;high contrasts;low vision;older adult(s)	Map services should be used in mobile applications for senior citizens. Do the commonly used map services meet the needs of elderly people? - Exemplarily, the contrast ratios of common maps in comparison to an optimized custom rendered map are examined in the paper.		Frank Reins;Frank Berker;Helmut Heck	2017	Studies in health technology and informatics	10.3233/978-1-61499-798-6-622	city map;civil engineering;engineering	HCI	-50.4549737065055	-41.27371676371825	72418
de3041d38743d1df7f9dea4b50018f0fa5fcaadc	travel distance judgment: an environmental distance information cognitive processing perspective	environmental;processing;judgment;travel;perspective;cognitive;information;distance	A consumer makes travel distance judgment to determine the place to visit. Stores that gain favorable travel distance judgment could gain access to a large volume of customer base. Travel distance judgment is often made with the aid of technologies, such as the mobile location-based service (LBS). In the present researchin-progress, we build on the human's environmental distance information cognitive processing model to propose how the travel distance information and visual geospatial information jointly influence a consumer's travel distance judgment. We posit that the combination of direct-distance travel information and destination visual reachable geospatial information (2D-map) could result in favorable travel distance judgment; likewise, the combination of estimated travel time information and destination visual opaque geospatial information (3D-map) could result in good travel distance judgment. Empirical validations on the propositions are also proposed. The article ends with a discussion on potential implications for research and practice.	cognition;location-based service	Meng-Xiang Li;Chuan-Hoo Tan;Kwok Kee Wei	2013			judgment;perspective;cognition;information;computer science;knowledge management;processing;management science;distance;social psychology	HCI	-59.58902679747669	-43.17437368307898	72548
561b1ffd08b33bd8c2c771f58cbfea2082bfdeac	social reverse geocoding studies: describing city images using geotagged social tagging	3d interaction technique;natural gesture interaction;handheld augmented reality;fingertip detection	Owing to the increasing use of social networking in the mobile environment, people today share more than a million geotagged objects that include objects with social tagging on a daily basis. In this paper, we propose social reverse geocoding (SRG). Social reverse geocoding (SRG) provides highly descriptive geographical information to mobile users. GPS provides the user with latitude and longitude values; however, these values are cumbersome for determining a precise location. A traditional reverse geocoding (conversion of the abovementioned values into street addresses) provides location information based on administrative labeling, but people often do not recognize locations or their surrounding environs from street addresses alone. To address this problem with location recognition, we have created SRG, a reverse geocoding system that enhances location data with user-generated information and provides assistance through a mobile interface [Sueda, et al. 2012]. Through a user study of SRG, we found a clear correlation between the number of tags and the locality of the residents. The obtained result indicates that the residents define the area of a city through SRG as closer than that defined by its street address. Further, the result reveals the potential of developing location-based services based on the image of the city obtained using social tagging on the Internet.	folksonomy;geocoding;geographic coordinate system;geotagging;global positioning system;internet;locality of reference;location-based service;strongly regular graph;usability testing;user-generated content	Koh Sueda	2013		10.1145/2543651.2543679	computer vision;world wide web;computer security;geocoding;computer graphics (images)	HCI	-53.4738498364755	-41.014977709568065	72570
b72dcd7e99350fa456b46c19276ecf8874810bb3	reconciling paper and tablets: interaction mappings for linking physical information with digital documents	physical information;mobile device interaction;contact augmented reality;transparent devices;interaction design	Despite the increasing use of tablet computers, there is evidence that paper still plays an important role for recording ideas and knowledge. Research on tablet usage suggests that they are seen to have a complementary role to that of paper. However, current methods of transferring paper-based information onto a digital device are limited to transcribing, scanning and taking a picture. We present a design study that investigates better-integrated ways of linking paper-based information with digital documents, such as websites or files. Our solution leverages new transparent display technologies for providing a direct augmentation of paper-based information while at the same time being capable of displaying associated digital documents. Through a series of design iterations and user evaluations, we identified interaction mappings for this new type of augmented reality as well as considerations for future implementations of transparent mobile devices.	augmented reality;display device;interaction design;iteration;mobile device;oled;physical information;tablet computer	James Dumesny;Martin Tomitsch	2014		10.1145/2686612.2686641	simulation;human–computer interaction;computer science;interaction design;multimedia	HCI	-48.37443258199948	-41.462983949354964	72587
56a27a68f68aa42c0b89f5fae8603b5e16524664	effects of visual cue and spatial distance on exitability in electronic negotiation	communicacion mediatizada computador;anonymity;exitability;social interaction;interaction sociale;negociation;hombre;exit behavior;repere visuel;anonymat;continuation norm;psychological factor;interaccion social;electronic negotiation;negociacion;communication mediatisee ordinateur;visual cues;human;bargaining;computer mediated communication;distancia;visual anonymity;vision;distance;spatial distance;homme;anonimato;visual cue;role play;marca visual	We examined the effects of the visual anonymity of self and spatial distance on exitability in electronic negotiation in a role-play experiment. Exitability is the psychological factor that causes one to perceive the negotiation as unstable. We predicted that the lack of visual information and the spread of spatial distance would reduce anticipation of retaliation, make the continuation norm less salient, and prompt to exit from the current negotiation. Visual anonymity was manipulated by two conditions (visual anonymity or non-anonymity conditions). Spatial distance was manipulated by two conditions (remote or close conditions). Forty-three students were assigned in one of these four conditions, and negotiated. The results showed both the visual anonymity and remote distance inhibited the activation of continuation norm, prompted to exit from the current negotiation.		Taketoshi Hatta;Ohbuchi Ken-ichi	2008	Computers in Human Behavior	10.1016/j.chb.2007.05.008	psychology;vision;social relation;social science;anonymity;sensory cue;communication;distance;social psychology;negotiation;computer-mediated communication	HCI	-53.3874698507804	-51.605161720604144	72594
d65c9d26d4c8442455bd4ffc708cf0fca40cbbc2	hypernavigation in the physical space: adapting presentations to the user and to the situational context (technical note)	user model	Abstract This paper describes a portable system lo support a new way of visiting cultural and tourist sites. The perspective is that the visitor moves in a physical space like a museum, while seeking information and guidance through the use of a hand-held electronic guide. Techniques are presented to adapt the content of the presentations to the particular visitor, place, and moment of visit (that is, taking into account the user model, knowledge of the physical location and the physical space around it, and the history of previous interactions).		Elena Not;Daniela Petrelli;Marcello Sarini;Oliviero Stock;Carlo Strapparava;Massimo Zancanaro	1998	The New Review of Hypermedia and Multimedia	10.1080/13614569808914694	simulation;user modeling;human–computer interaction;computer science;multimedia;world wide web	HCI	-55.708871781018864	-38.79118773289442	72654
52584050a2a7f6134088fc7190b7c0c2f8cbf552	how the timing and magnitude of robot errors influence peoples' trust of robots in an emergency scenario			robot	Alessandra Rossi;Kerstin Dautenhahn;Kheng Lee Koay;Michael L. Walters	2017		10.1007/978-3-319-70022-9_5		Robotics	-52.4890944647137	-50.58632572436566	72746
5ca9e74ba3201edb1b0dfcd3a8593c811db7c223	transitions in interface objects: searching databases	c850 cognitive affective psychology;journal article	Two experiments demonstrate that a list-like database interface which benefits from the persistence of contextual information does not show the same degree of benefit of collocating objects over display changes that has been previously observed in amap-searching study. This provides some support for the claim that the nature of the task must be taken into account in choosing how to design dynamic displays. We discuss the benefit of basing design principles on theoretical models derived from film cutting methods used in cinematography, so that they can be extended to novel design situations.	database;experiment;persistence (computer science)	Tim Gamble;Jon May	2016	Adv. Human-Computer Interaction	10.1155/2016/5916843	psychology;simulation;human–computer interaction;computer science;engineering;multimedia;social psychology	HCI	-54.52194722288453	-44.709821216514754	72752
35c87ab2b46ec504963b4df3f7adafde1f62284a	towards a serious game playing empathic robotic tutorial dialogue system	serious games;dialogue management;tutoring systems;empathic robotic tutor	There are several challenges in applying conversational social robots to Technology Enhanced Learning and Serious Gaming. In this paper, we focus in particular on the dialogue management issues in building an empathic robotic tutor that plays a multi-person serious game with students to help them learn and understand the underlying educational concepts.	cognitive tutor;dialog system;dialog tree;social robot	Srinivasan Janarthanam;Helen F. Hastie;Amol A. Deshmukh;Ruth Aylett	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2563707	simulation;multimedia	Robotics	-54.94987098098551	-46.53928292219765	72829
0262c3c01854dbe48bdfd420fc503bc928b89aa1	a design pattern language for accessible web sites	rich internet application;design method;web design;accessibility;design pattern	Dynamic web sites and rich internet applications have recently got widespread. An important challenge is guaranteeing their accessibility to all potential users regardless of physical and cognitive disabilities as well as hardware and software limitations. To this aim, WCAG 2.0 guidelines have been released as the newest W3C recommendation for accessible web content, and WAI-ARIA are reference specifications for accessible rich internet applications. However, both design resources contain a huge amount of information, and, like all standards and guidelines, do not provide designers with a clear design method. This paper proposes a design pattern language for accessibility to help web designers create accessible rich internet applications compliant with the most recent standards. The language has been implemented as an accessible rich internet application itself, allowing designers with disabilities to participate in web design. The results of a preliminary evaluation are finally discussed.	design pattern;dynamic web page;pattern language;rich internet application;wai-aria;web accessibility initiative;web content accessibility guidelines;web design	Daniela Fogli;Loredana Parasiliti Provenza;Cristian Bernareggi	2010		10.1145/1842993.1843048	web development;web modeling;rich internet application;web design;design methods;human–computer interaction;web accessibility initiative;web standards;computer science;accessibility;web accessibility;multimedia;design pattern;world wide web	HCI	-51.76988677162964	-41.047676330689164	72863
48974ec7e4479825f3c3998ab8b9c5c9dd8615c6	an interdisciplinary undergraduate design course for wearable and pervasive computing products	wearable computing interdisciplinary design pervasive computing;sensors;pervasive computing;prototypes;wearable computers;diabetes;wearable computers computer science education educational courses ubiquitous computing;interdisciplinary design;computer science education;educational courses;ubiquitous computing;wearable computer;sensors prototypes wearable computers accelerometers fires diabetes;industrial design interdisciplinary undergraduate design course wearable computing products pervasive computing products computer engineering;wearable computing;fires;accelerometers;industrial design	This paper reports on a design experience for undergraduates in computer engineering, industrial design, and marketing that focuses on pervasive computing devices. Across a broad range of targeted application areas and user groups, many of the student designs have been wearable computers. Consequently, our course will be of interest to the wearable computing community, particularly in terms of our aim of bridging the gap between design and engineering. For the two most recent offerings of the course, we have utilized external observers and surveyed the students in order to validate the impact of aspects of our process and changes to it. This paper presents an overview of our process with both qualitative and quantitative results from these two most recent offerings.	bridging (networking);computation;computer engineering;nonlinear gameplay;physical computing;self-organization;ubiquitous computing;wearable computer;wearable technology	Thomas L. Martin;Kahyun Kim;Jason B. Forsyth;Lisa D. McNair;Eloise Coupey;Ed Dorsa	2011	2011 15th Annual International Symposium on Wearable Computers	10.1109/ISWC.2011.13	embedded system;simulation;wearable computer;human–computer interaction;computer science;ubiquitous computing	Arch	-60.406272375865065	-40.16599298792599	73145
38836f9374265ec68032000d3a447550288fba38	shared interaction on a wall-sized display in a data manipulation task	ucl;wall sized display;discovery;theses;conference proceedings;collaboration styles;pick and drop;digital web resources;ucl discovery;open access;classification task;shared interaction;co located collaboration;ucl library;book chapters;open access repository;ucl research	Wall-sized displays support small groups of users working together on large amounts of data. Observational studies of such settings have shown that users adopt a range of collaboration styles, from loosely to closely coupled. Shared interaction techniques, in which multiple users perform a command collaboratively, have also been introduced to support co-located collaborative work. In this paper, we operationalize five collaborative situations with increasing levels of coupling, and test the effects of providing shared interaction support for a data manipulation task in each situation. The results show the benefits of shared interaction for close collaboration: it encourages collaborative manipulation, it is more efficient and preferred by users, and it reduces physical navigation and fatigue. We also identify the time costs caused by disruption and communication in loose collaboration and analyze the trade-offs between parallelization and close collaboration. These findings inform the design of shared interaction techniques to support collaboration on wall-sized displays.	denial-of-service attack;interaction technique;multi-user;parallel computing	Can Liu;Olivier Chapuis;Michel Beaudouin-Lafon;Eric Lecolinet	2016		10.1145/2858036.2858039	simulation;human–computer interaction;computer science;operating system;world wide web	HCI	-60.03546488286066	-42.75696158845011	73320
7fea55f86153a5d5cacf4080007f69c101fae36b	understanding 3d mid-air hand gestures with interactive surfaces and displays: a systematic literature review		Copyright and moral rights to this thesis/research project are retained by the author and/or other copyright owners. The work is supplied on the understanding that any use for commercial gain is strictly forbidden. A copy may be downloaded for personal, non-commercial, research or study without prior permission and without charge. Any use of the thesis/research project for private study or research must be properly acknowledged with reference to the work’s full bibliographic details.		Celeste Groenewald;Craig Anslow;Junayed Islam;Chris Rooney;Peter J. Passmore;B. L. William Wong	2016			human–computer interaction;gesture recognition;multimedia;classification scheme;computer science;systematic review;gesture	HCI	-57.769303845896175	-41.58288310553674	73347
930e32d658288982099c562c552c1e616d19da42	co-located collaborative web search: understanding status quo practices	search engine;collaborative search;search interfaces;observational study;next generation;co located collaboration;web search;diary study	Co-located collaborative Web search is a surprisingly common activity, despite the fact that Web browsers and search engines are not designed to support collaboration. We report the findings of two studies (a diary study and an observational study) that provide insights regarding the frequency of co-located collaborative searching, the strategies participants use, and the pros and cons of these strategies. We then articulate design implications for next-generation tools that could enhance the experience of co-located collaborative search.	diary studies;web search engine	Saleema Amershi;Meredith Ringel Morris	2009		10.1145/1520340.1520547	semantic search;computer science;data science;data mining;search analytics;world wide web;observational study;search engine	HCI	-60.73917448116142	-42.638245583069676	73366
9ed9a06ad5a2bd59d22f49b8de9c4090c3fdb771	user appropriation of mobile technologies: motives, conditions and design properties	conditions;activity;mobile computer;motives;appropriation;mobile computing;mobile technology;human activity;user acceptance	The mobility of activities entails intrinsic parameters such as the mobility of tasks and technologies, as well as changing conditions underlying mobile computing. The interactions between these parameters bear directly on the appropriation of mobile technologies deployed in these activities. In this paper, I analyze the appropriation of mobile technologies as a function of motives, conditions of use, and technology design properties. The analysis explains the flexibility of mobile computing as a direct function of the appropriation process. The paper contributes to understanding mobile technology use and improving user acceptance by extending existing conceptualizations of technology use. Technology personalization and use in non-organizational contexts are the essentials of the extension, suggesting that mobile computing is a function of use for serving both organizationally-sanctioned and personal motives. Implications for researching mobile technology use and for designing mobile technologies are drawn.	camera resectioning;conceptualization (information science);interaction;mobile computing;personalization	Gamel O. Wiredu	2007	Information and Organization	10.1016/j.infoandorg.2007.03.002	mobile search;simulation;human–computer interaction;computer science;engineering;knowledge management;mobile technology;mobile business development;mobile computing	HCI	-58.41052280756605	-40.40855174970023	73471
f914e0a7832c904d4535bb8ac4cb22f09162c0f1	multimedia experience enhancement through affective computing		The aim of this work is to offer multimedia access (i.e. video queue and playlist) based on affective aspects of the interaction. In particular, the biosignals gathered from a commercial smartwatch are processed to propose an unobtrusive video classification based on users emotions. The validation performed allows to find a relation between the biosignal and the reported affective experience obtained using the Self-Assessment Manikin (SAM).	affective computing;smartwatch	Lucio Ciabattoni;Francesco Ferracuti;Sauro Longhi;Lucia Pepa;Luca Romeo;Federica Verdini	2017	2017 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2017.7889278	simulation;telecommunications;computer science;multimedia	Robotics	-52.2600305986348	-43.76081694232713	73596
d76c476c0c2919f149e67c3320994bd348e91793	jokebox: coordinating shared encounters in public spaces	in the wild;public display;audio interface;coordination	Eye contact is crucial to shared encounters in public spaces. However, most urban technologies that aim to foster social interaction tend to rely on screens, directing a significant proportion of the usersâ attention towards the device rather than to those with whom the encounter is shared. We present the design and evaluation of the Jokebox, a lightweight technology that requires two passers-by to coordinate actions to hear a joke. In three in the wild studies at different locations we found that our design supported micro-level coordination in a consistent manner: by encouraging people to make eye contact and by using audible jokes, users engaged in interactions that often led to further conversation and laughter. We describe how opportunities for macro-level coordination were key to the success of the installation, but varied by context. Finally, we present design implications for considering both the micro and macro levels of social coordination.	interaction;interactive design;interactivity;prototype;spaces;the jesus incident;ubiquitous computing;wizard (software)	Mara Balestrini;Raymundo Cornejo;Paul Marshall;Monica Tentori;Jon Bird;Yvonne Rogers	2016		10.1145/2818048.2835203	simulation;human–computer interaction;communication;social psychology;world wide web	HCI	-58.69822930558513	-40.689700789286704	73802
1982cdbab48065a7cc8a6a9337c11cc33d105705	do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy	digital fabrication;microcontrollers;diy;cellphone;prototyping;electronics;toolkits	This paper describes our do-it-yourself cellphone and our use of it to investigate the possibilities and limits of high-tech DIY practice. We describe our autobiographical approach -- making the phone and using it in our daily lives -- and our work disseminating the cellphone in workshops and online. This informs a discussion of the implications of technology for DIY practice. We suggest an understanding of DIY as an individual's ability to combine existing technologies into a desired product, enabled and limited by ecosystems of industrial actors and individuals. We distinguish different pathways into high-tech DIY practice, consider the relationship between prototyping and production, and discuss the effect of technology on DIY's relevance and tools, and on notions of transparency. We conclude by reflecting on the relationship between DIY and empowerment: the extent to which making devices gives people control over the technology in their lives.	ecosystem;institute for operations research and the management sciences;mobile phone;relevance;software prototyping	David Mellis;Leah Buechley	2014		10.1145/2556288.2557309	microcontroller;electronics;simulation;computer science;prototype;multimedia	HCI	-60.2153050644456	-38.61879468026628	73839
f6ba24550ffb66874bfd21294f1184a9e9d76e50	gamification, quantified-self or social networking? matching users’ goals with motivational technology		Systems and services we employ in our daily life have increasingly been augmented with motivational designs which fall under the classes of (1) gamification, (2) quantified-self and (3) social networking features that aim to help users reach their goals via motivational enforcement. However, users differ in terms of their orientation and focus toward goals and in terms of the attributes of their goals. Therefore, different classes of motivational design may have a differential fit for users. Being able to distinguish the goal profiles of users, motivational design could be better tailored. Therefore, in this study we investigate how different goal foci (outcome and focus), goals orientation (mastery, proving, and avoiding), and goal attributes (specificity and difficulty) are associated with perceived importance of gamification, social networking and quantified-self features. We employ survey data ($$\mathrm{N}=167$$ N=167 ) from users of HeiaHeia; a popular exercise encouragement app. Results indicate that goal-setting related factors of users and attributes of goals are connected with users’ preference over motivational design classes. In particular, the results reveal that being outcome-focused is associated with positive evaluations of gamification and quantified-self design classes. Users with higher proving-orientation perceived gamification and social networking design classes as more important, users with lower goal avoidance-orientation perceived social networking design as more important, whereas users with higher mastery-orientation perceived quantified-self design more important. Users with difficult goals were less likely to perceive gamification and social networking design important, whereas for users with high goal specificity quantified-self features were important. The findings provide insights for the automatic adaptation of motivational designs to users’ goals. However, more research is naturally needed to further investigate generalizability of the results.	gamification;quantified self;sensitivity and specificity	Juho Hamari;Lobna Hassan;Antonio Dias	2018	User Modeling and User-Adapted Interaction	10.1007/s11257-018-9200-2	knowledge management;computer science;data mining;goal orientation;survey data collection;generalizability theory;enforcement;social network;goal setting	HCI	-59.76198768278963	-45.87757158134803	74011
f7ee3d446b28199489d04ea47e9690021c401c7b	horizontal vs. vertical: how the orientation of a large interactive surface impacts collaboration in multi-surface environments		Defining the form factor and set-up of surfaces, i.e., their size, position, and orientation, is one of the first decisions made when designing multisurface environments (MSE). To support these choices, we conducted a study on how the orientation of a large display used alongside tablets impacts collaboration. Previous research involving only one interactive surface shows that display orientation changes how people interact with the display, the way they position themselves, or look at each other. Our study shows that in a MSE setting, the orientation of a large surface has a different impact: (1) it nuances previous results showing that horizontal surfaces are better for collaboration. (2) it impacts the way activities are conducted. The horizontal condition leads to more implicit coordination and balanced interaction with the large display, but to less structured work, while in the vertical condition, group coordination is more explicit and is structured around one main interactor. Compared to previous work, we also propose a more structured, comprehensive and detailed analysis grid for collaboration in MSE. Finally, based on our results, we derive recommendations for MSE design.		Lili Tong;Aurélien Tabard;Sébastien George;Audrey Serna	2017		10.1007/978-3-319-67687-6_14	grid;computer science;simulation;horizontal and vertical;interactor;form factor (quantum field theory)	HCI	-61.5358328678032	-40.25006046460181	74033
c2a696865208e9a85dfd94fb20e40fe2e4f35284	teaching a humanoid: a user study on learning by demonstration with hoap-3	manipulators;satisfaction rate hoap 3 demonstration tasks humanoid learning by demonstration task completion;intelligent robots;user study;training;learning by imitation;speech;intelligent robots humanoid robots human robot interaction;hoap 3;human robot interaction;data mining;programming by demonstration;humanoid robots;learning by demonstration;demonstration tasks;education educational robots humanoid robots machine learning human robot interaction stress collaborative work robotic assembly performance analysis feedback;humans;hoap humanoid robot;satisfaction rate;humanoid;task completion	This article reports on the results of a user study investigating the satisfaction of nave users conducting two learning by demonstration tasks with the HOAP-3 robot. The main goal of this study was to gain insights on how to ensure a successful as well as satisfactory experience for nave users. The participants performed two tasks: They taught the robot to (1) push a box, and to (2) close a box. The user study was accompanied by three pre-structured questionnaires, addressing the users' satisfaction with HOAP-3, the users' affect toward the robot caused by the interaction, and the users' attitude towards robots. Furthermore, a retrospective think aloud was conducted to gain a better understanding of what influences the users' satisfaction in learning by demonstration tasks. A high task completion and final satisfaction rate could be observed. These results stress that learning by demonstration is a promising approach for nave users to learn the interaction with a robot Moreover, the short term interaction with HOAP-3 led to a positive affect, higher than the normative average on half of the female users.	retrospective think aloud;robot;usability testing	Astrid Weiss;Judith Igelsböck;Sylvain Calinon;Aude Billard;Manfred Tscheligi	2009	RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2009.5326274	human–robot interaction;computer vision;simulation;computer science;humanoid robot;speech;artificial intelligence	Robotics	-48.66010884965904	-50.56987727220007	74308
4c10b69539f25aa892d814d9ec924b897190770b	mobile graphics game with peer-to-peer android based collaborative system	games smart phones peer to peer computing androids humanoid robots bluetooth message systems;smart phones application program interfaces computer games groupware mobile computing peer to peer computing;small group interaction mobile hci smart phones applications graphics voice recognition card game;b vi community mobile graphics game peer to peer android based collaborative system smart phones graphics interaction virtual games droid hold em application peer to peer architecture voice recognition software texas hold em api application programming interface voice recognition voice feedback blind and the visually impaired	Smart phones combine graphics interaction with mobility and provide an opportunity for collaborative social interaction in small groups. They also provide an opportunity to implement virtual games with multiple participants nearby because smart phones can be used as an input and an output device. This paper presents an Android application called Droid Hold'em. Droid Hold'em utilizes a peer-to-peer architecture combined with voice recognition software to create an interactive system. The application implements the popular version of poker known as Texas Hold'em that is a common game played at social gatherings. This android application allows participants to interact in the social environment without any additional assistance needed to participate in the group activity. The implementation consists of two phases. The first is the development of a peer-to-peer communications API (Application Programming Interface) that can be used and reused by any application that wishes to utilize peer-to-peer communication. The second is to develop the Droid Hold'em game itself, which will utilize a tablet to serve in place of a poker table, and phones as game interfaces for each individual player. Because of the voice recognition and voice feedback used in our system, smart devices may have universal appeal, and may also be useful for Blind and the Visually Impaired (B/VI) community to engage on equal footing with their sighted peers.	android;application programming interface;graphics;interactivity;output device;peer-to-peer;smart device;smartphone;speech recognition;tablet computer;user experience	Timothy W. Poley;Sudhanshu K. Semwal	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974014	simulation;human–computer interaction;computer science;multimedia	HCI	-48.38899874532824	-38.383708223372174	74368
8a388f43b366c4366d3d402f610b92c5422b3aff	combining cognition and emotion in virtual agents		PurposernrnrnrnrnThe paper aims to explain the limitations of existing cognitive architectures and affective models, and propose a new cognitive-affective architecture that can be integrated in real intelligent agents to make them more realistic and believable.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnThe paper evaluates the state of the art, and describes the design and implementation of the cognitive-affective architecture in an agent. A brief evaluation of the agent is provided.rnrnrnrnrnFindingsrnrnrnrnrnThe paper clearly states that it is possible to use cognitive architectures to help, but there is a lack of architectures that address the problem of combining cognition and emotion in agents in a unified, simplified way. A cognitive-affective architecture is useful to make believable intelligent agents in an easier way.rnrnrnrnrnResearch limitations/implicationsrnrnrnrnrnThe paper does not explore a lot of possible future work that can be done to extend the emotional expressions of the agent, as well as including direct emotional-sensing capabilities in real time.rnrnrnrnrnPractical implicationsrnrnrnrnrnThe paper argues about the need to include cognitive-affective architectures in modern intelligent agents. The architecture allows to influence and modify the behavior of the agent in real time, to achieve a more realistic and believable interaction with the user.rnrnrnrnrnSocial implicationsrnrnrnrnrnThe paper remarks the importance of a cognitive-affective architecture that makes intelligent agents able to help the users in different tasks and environments.rnrnrnrnrnOriginality/valuernrnrnrnrnThe paper describes a new cognitive-affective architecture and its utility for modern intelligent agents. This is proven by including it in a previous agent, which boosts its behavior and emotional expression possibilities and thus improves user experience.	cognition;intelligent agent;kybernetes	Joaquín Pérez Marco;Francisco J. Serón;Eva Cerezo Bagdasari	2017	Kybernetes	10.1108/K-11-2016-0340	intelligent agent;management science;architecture;computer science;affective computing;user experience design;database-centric architecture;cognitive architecture;cognition;agent architecture	AI	-55.46750132822458	-46.81899226776993	74407
9f4407a1b4a7d5fe3d188b0d26750367e9ca4d23	does observing artificial robotic systems influence human perceptual processing in the same way as observing humans?	perceptual processing;human robot interaction;attentional selection;psychological sciences	Humanoid robots are designed and shaped to have physical bodies resembling humans. The anthropomorphic shape is aiming at facilitating interactions between humans and robots with the ultimate goal of making robots acceptable social partners. This attempt is not very new to roboticists and there is an increasing body of research showing the importance of robots’ appearance in HRI; the Uncanny Valley proposed in the 70’s [1] is however still an open problem. Our aim in this contribution is to examine how human perceptual mechanisms involved in action observation are influenced by the external shape of observed robots. Our present results show that observing robotic/cartoon hands performing grasping/pointing movements elicits similar perceptual mechanisms as observing other humans. Hence, it seems that observing actions of artificial systems can induce similar perceptual effects as observing actions of humans.	coat of arms;humans;human–robot interaction;robot;uncanny valley	Agnieszka Wykowska;Ryad Chellali;Md. Mamun Al-Amin;Hermann J. Müller	2012		10.1007/978-3-642-34103-8_33	psychology;computer vision;simulation;communication	Robotics	-50.734419701853476	-50.76435094834471	74506
39dacdee412e011a49751cc0944a859bb9b9c5e3	design strategy to stimulate a diversity of motor skills for an exergame addressed to children	sedentarism;physical activity;exergame;children;exertion interface;health;mixed reality;user control	"""A rich variety of videogames promoting physical activity has followed the emergence of new full-body interfaces. Known as exergames, these active videogames are often presented in the market as a ludic substitute to traditional sport. Although they present the benefit of being engaging, to date, the content and modality of interaction of these games cannot be granted as a regular mean to do exercise. This is an issue of particular relevance when they are perceived as a valid alternative to develop children's motor skills. This paper presents the design strategies and evaluation of the """"Fish Game"""", an exergame that has been specifically designed to spur children to execute specific types of movement determined by health experts. In a controlled assessment with 150 children, we compared the diversity of movement in the Fish Game with respect to a previously designed game. Video analysis shows a richer variety of movements was executed in the Fish Game. We discuss the limitations of our current design procedure and future avenues that could be explored with health experts to enhance it."""	emergence;ludic interface;modality (human–computer interaction);relevance	Pascal Landry;Joseph Minsky;Marta Castañer i Balcells;Oleguer Camerino i Foguet;Rosa Rodriguez-Arregui;Enric Ormo;Narcís Parés	2013		10.1145/2485760.2485781	simulation;engineering;multimedia;communication	HCI	-56.66035015414841	-49.62611310277271	74664
bcbdddc51eded1b33dce2db99af7cf3253d1ba6b	is smartwatch perceived as a wristwatch or a wearable device?: the experimental study for examining the categorization and the perceived fit with manufacturer on consumer evaluations	consumer evaluation;smartwatch;perceived fit;knowledge transfer;wearable device;categorization	Recent researches demonstrated that when facing a really new product, consumers would learn about it through knowledge transfer from the base domains (existing familiar categories) to a new product category. This paper applied this theoretical background to the smartwatch category. Smartwatch can be categorized as another variant of a wristwatch or a wearable device, so we expected that consumers' responses would vary depending on the category frame and the manufacturer. We manipulated the category frame with the message on the ad and the manufacturer with the instruction. Specifically, we found that consumers' perceived fit varied depending on the category frame and the manufacturer, and consumers formed more expectation when the watch company launched a smartwatch framed as a wearable device than it framed was a wristwatch. In Experiment 2, we observed that consumers' affective response, perceived quality, and attitude were different depending upon the number of features on the ad and the category frame. Based on these findings, we presented discussions and implications about the smartwatch.	categorization;experiment;smartwatch;watch;wearable technology	Yong Wan Park;Soomin Son;Beomsoo Kim	2016		10.1145/2971603.2971624	engineering;marketing;multimedia;advertising	HCI	-51.460214852770406	-51.65167070322018	74856
460c0cd7b81a2ce8b66d6ac1399ae9b9822df046	cooperation and flexibility in multimodal communication	multimodal communication	The design of cooperative dialog systems, new human-computer interfaces (cf. Schomacher et al 1995) and avatars in various types of virtual environments can all be improved by better knowledge of features of real human-human multimodal communication. In this paper I discuss the nature of cooperation in dialog. I will also discuss what might be called features of flexibility and conflict prevention and how they are related to cooperation. I will illustrate the features of flexibility and conflict prevention by examples drawing on videorecorded and transcribed human-human dialog. The main focus will be on nonverbal gestural means, since verbal means are somewhat better known. The paper is intended to illustrate how new ideas about the design of dialog systems (cf Pandzic et al 1996, 1997) will also lead to an interest in aspects of human-human communication that have received less attention so far.	dialog system;multimodal interaction;virtual reality;word lists by frequency	Jens Allwood	1998		10.1007/3-540-45520-5_7	computer science;artificial intelligence	AI	-52.39869901110881	-47.77227160278125	74876
6cbcc5e7918f5f4f959806036c565a498083e029	development of an android robot for studying human-robot interaction	human robot interaction	Behavior or Appearance? This is fundamental problem in robot development. Namely, not only the behavior but also the appearance of a robot influences human-robot interaction. There is, however, no research approach to tackling this problem. In order to state the problem, we have developed an android robot that has similar appearance as humans and several actuators generating micro behaviors. This paper proposes a new research direction based on the android robot.	android (robot);design of experiments;experiment;human–robot interaction;robot	Takashi Minato;Michihiro Shimada;Hiroshi Ishiguro;Shoji Itakura	2004		10.1007/978-3-540-24677-0_44	simulation;computer science;artificial intelligence;social robot;robotics;user interface	Robotics	-50.93495162514491	-51.555048951806995	75082
cae3affbf71fad6578ed58fa2b2a1dd2e396e36e	user privacy attitudes regarding proximity sensing		User attitudes on privacy with respect to location data has been extensively studied. However, user attitudes of privacy in relation to proximity sensing is still lacking. We present the results from a survey conducted on users of a proximity sensing application we developed and diffused by handing out phones with the proximity sensing application pre-installed, with 31 respondents. The results compare this type of application to location sensing in general, as well as positions our respondents in relation to previous studies in terms of general privacy policies. Four results stand out in particular: One, our respondents are more aware of and care about privacy policies than in previous studies. Two, trust is reported as being based more on the specific data access asked for, than EULA or similar text based policies. Third, the respondents are willing to allowing having proximity data about them sensed, as long as they are in control of who can sense it. Finally, our results indicate that there is no perceived difference in sensitivity between location and proximity sensing.	data access;end-user license agreement;pre-installed software;privacy policy;text-based (computing)	Håkan Jonsson;Carl Magnus Olsson	2018		10.1145/3230833.3233270	privacy policy;computer security;bluetooth;data access;computer science	HCI	-57.81288686715691	-43.71978123121052	75123
897888f1a9c15d4e0958629887be838c56a473d2	web application for recommending personalised mobile tourist routes	mobile web users web application personalised mobile tourist route recommendation sightseeing itineraries user preferences web users;user interfaces human computer interaction internet mobile computing recommender systems travel industry;user preferences;personalised mobile tourist route recommendation;web application;mobile web users;web users;sightseeing itineraries	This study deals with the problem of deriving personalised recommendations for daily sightseeing itineraries for tourists visiting any destination. The authors’ approach considers selected places of interest that a traveller would potentially wish to visit and derives a near-optimal itinerary for each day of visit; the places of potential interest are selected based on stated or implied user preferences. The authors’ method enables the planning of customised daily personalised tourist itineraries considering user preferences, time available for visiting sights on a daily basis, opening days of sights and average visiting times for these sights. Herein, the authors propose a heuristic solution to this problem addressed to both web and mobile web users. Evaluation and simulation results verify the competence of the authors’ approach against an alternative method.	heuristic;simulation;user (computing);web application	Damianos Gavalas;Michael Kenteris;Charalampos Konstantopoulos;Grammati E. Pantziou	2012	IET Software	10.1049/iet-sen.2011.0156	web application;mobile search;computer science;engineering;multimedia;internet privacy;programming language;world wide web	Mobile	-50.968575736881405	-40.847404678990536	75229
cc9edee7c9bd71b3ca6948b1beb7d9d72a238fa3	assessing users' subjective quality of experience with the world wide web: an exploratory examination of temporal changes in technology acceptance	human computer interaction;information technology;experience;quality of experience;behavioral science;internet usage;technology acceptance;world wide web;usability;user acceptance;temporal change	Contemporary information technology?(IT)-related research has focused on use or user acceptance as a key dependent measure for valuing IT. By understanding the determinants of IT use, we gain descriptive information about successful IT, and prescriptive information for better deploying IT resources and improving their utility. Although there are several competing theories regarding IT use, research findings often cite their inability to account for temporal changes in usage behaviors. Furthermore, contemporary human?computer interaction perspectives often focus on the robust and growing literature surrounding usability and likeability; however, few studies have provided insight into the components of, or antecedents to, the utility dimension. This research attempts to address these gaps by introducing the construct of users'quality of experience as a potential mediator between the determinants of use and actual usage behaviors and their outcomes. A pilot survey concerning Internet usage generated potentially relevant items which were later refined into a questionnaire assessing each item's relative importance to perceptions of quality of experience. Initial indications suggest 10 of the items represent a temporally stable and unidimensional construct. Findings are also interpreted within the context of IT and cognitive/behavioral science perspectives, further providing for face validity of the quality of experience construct.	world wide web	Michael G. Morris;Jason M. Turner	2001	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.2001.0460	usability;human–computer interaction;computer science;knowledge management;multimedia;information technology	HCI	-60.17027729607154	-45.94457535143349	75306
0b93aa45de6d73fe1f67c3f90d015f291e32ce1a	real-time adaptation of augmented-reality games for optimizing player satisfaction	pediatrics;rule based system;real time;real time adaptation;test bed;adaptive learning augmented reality game real time adaptation player satisfaction optimization playware physical interactive platform cognitive user model entertainment preference rule based system;entertainment preference;artificial neural networks;adaptation model;human factors;augmented reality testing predictive models delay artificial neural networks programmable control adaptive control knowledge based systems real time systems foot;games;cognition;adaptive learning;playware physical interactive platform;learning artificial intelligence augmented reality cognition computer games entertainment human factors knowledge based systems;tiles;augmented reality game;learning artificial intelligence;augmented reality;computer games;player satisfaction optimization;entertainment;cognitive user model;knowledge based systems;physical interaction;user model;data models;real time systems	A first endeavor for optimizing player satisfaction in augmented-reality games through the dasiaPlaywarepsila physical interactive platform is presented in this paper. Constructed user models, reported in the literature, map individual playing characteristics to reported entertainment preferences of augmented-reality game players. An adaptive mechanism then adjusts controllable game parameters in real-time in order to improve the entertainment value of the game for the player. The basic approach presented here applies gradient ascent to such a model to reveal the direction toward games of higher entertainment value while a rule-based system exploits the derivative information to adjust specific game parameters to augment the entertainment value. Those adjustments take place frequently during the game in small time intervals that maintain the constructed model's accuracy. Performance of the adaptation mechanism is evaluated using a game survey experiment. Results reveal that children show a notable preference for the adaptive versus the static Bug-Smasher (dasiaPlaywarepsila test-bed) game variant even when simple adaptive approaches like the one proposed are used. The limitations and the use of the methodology as a baseline effective adaptive mechanism to entertainment augmentation are discussed.	augmented reality;baseline (configuration management);gradient descent;real-time clock;real-time transcription;rule-based system;testbed;times ascent	Georgios N. Yannakakis;John Hallam	2008	2008 IEEE Symposium On Computational Intelligence and Games	10.1109/CIG.2008.5035627	non-cooperative game;game design;bayesian game;games;data modeling;augmented reality;entertainment;simulation;user modeling;cognition;extensive-form game;simultaneous game;computer science;artificial intelligence;game mechanics;machine learning;repeated game;strategy;multimedia;screening game;normal-form game;simulations and games in economics education;sequential game;adaptive learning;artificial neural network;testbed	HCI	-48.79474169281754	-51.470430718481424	75325
aa08943bdf6da32fa8fc3fe67a4fa826a2dc4f4e	re-live the moment: visualizing run experiences to motivate future exercises	behavioral change;exercises;running;android;life logging;autobiographical memories;multi modal capture	Contemporary psychology theory emphasizes that people are more likely to achieve planned behavior if they are reminded of previous good experiences of that behavior. In this position paper we describe the results of a pilot study exploring the experimental in-the-wild validation of these findings in the context of run exercises. Based on today's technological improvements in data collection (advanced mobile and wearable sensors) and data visualization to capture and replay running exercise experiences, we created an experimental prototype that takes pictures during one's run and, based on the music one was listening to at the time, plays back slide shows of the experience. In an initial pilot study with 10 runners, we equipped 5 runners (the experimental group) with our prototype for 10 days and afterwards interviewed them on how the system influenced their exercise behavior.	data visualization;experiment;prototype;sensor;wearable computer	Agon Bexheti;Anton Fedosov;Jesper Findahl;Marc Langheinrich;Evangelos Niforatos	2015		10.1145/2786567.2794316	simulation;human–computer interaction;computer science;artificial intelligence;multimedia;android	HCI	-55.17248505968236	-43.54877075052815	75401
37b6f7aa7aecca3295e157097bf3af51e586b006	multimodal design for enactive toys	motor skills;young children;visual impairment	In this paper we will investigate how non–visual senses can be used in toys to enhance and enrich the play experience of all children, while favoring accessibility and inclusion of visually-impaired children. Previous research has shown that – especially for young children developing sensory-motor skills – exploration and play are two tightly linked activities: everything is new and needs to be “investigated” and playful behaviors emerge from active exploration. We will propose a new approach in designing and creating objects that elicit this type of behavior and encourage exploration by providing real–time dynamic, haptic, tactile, auditory, and even olfactory feedback depending on children’s gestures, movements, and emitted sounds. We believe that this design paradigm is highly innovative with respect to previous research and existing products – whose interaction is very often based on static feedback. Interactive and dynamic feedback is intrinsically more engaging and allows a variety of quality learning patterns.	accessibility;emergentism;enactivism;haptic technology;high- and low-level;interactivity;multimodal interaction;programming paradigm;toys	Amalia de Götzen;Luca Mion;Federico Avanzini;Stefania Serafin	2007		10.1007/978-3-540-85035-9_14	simulation;motor skill;multimedia	HCI	-53.28853657492618	-44.73683108172335	75415
ef9fde74c074ec8ed88569c1d3d396880d97e90b	player talk - the functions of communication in multplayer role-playing games	personality;interaction;player behavior;online community;role playing game;digital media;multiplayer game;role playing games;communication;online communication;communication pattern;characters	Communication is a vital component of multiplayer gameplay, constituting a large part of the total player interaction. This article presents a comprehensive study of the role of interplayer communication during the gaming process in digital and tabletop role-playing game formats. A series of empirical game experiments are presented and the player-based communication analyzed, with the aim of clarifying how format (media of expression) impacts on verbal communication in multiplayer games; as well as examining player communication in general. The results show distinct differences in the communication patterns between the two game formats, directly related to the limitations and requirements of the tabletop and digital media utilized, for example in the amount of “in-character” communication. Interplayer communication in both formats is highly focused on functional content, that is, oriented towards supporting practical gameplay; however, functional content has different meanings on the two platforms. These and other results are discussed in the context of format differences and in the larger context of the functions of verbal communication during the playing of multiplayer games.	digital media;experiment;requirement	Anders Drachen;Jonas Heide Smith	2008	Computers in Entertainment	10.1145/1461999.1462008	video game design;interaction;simulation;computer science;digital media;game mechanics;multimedia;personality	HCI	-58.68461633021317	-38.98180885688106	75785
c2fc51c79c70f5bdc155ed02cdcae29d3e7145c4	multimodal interfaces: challenges and perspectives	adaptability;multimodal interface;fusion;interface design;human centered computing;multimodal interfaces	The development of interfaces has been a technology-driven process. However, the newly developed multimodal interfaces are using recognition-based technologies that must interpret human-speech, gesture, gaze, movement patterns, and other behavioral cues. As a result, the interface design requires a human-centered approach. In this paper we review the major approaches to multimodal Human Computer Interaction, giving an overview the user and task modeling, and to the multimodal fusion. We highlight the challenges, open issues, and the future trends in multimodal interfaces research.	human computer;human–computer interaction;multimodal interaction;oracle fusion architecture	Nicu Sebe	2009	JAISE	10.3233/AIS-2009-0003	adaptability;human–computer interaction;fusion;computer science;human-centered computing;interface design;multimedia	HCI	-52.92779104176676	-38.674778886370504	75840
138eb38bd11ebe88a83402e5fb91d49a3a892466	exploring of the barrier-free design for visual impairment in graphical user interface design		According to the China Disabled Persons’ Federation statistics, by 2015 China’s low vision and the number of blind people had up to 31.475 million; and color blindness in China is about 5.5% to 9%. While the red-green blind population accounts for about 8.5% of the global population. Of which 6% of the population suffered from color weak, and about 2% of the population is color blindness. Visually impaired people can not compete with ordinary people in the living environment of information access. In this situation, as the rapid expansion of network information, visual barriers are more hard to access to information from the network and had some obstacles that the amount of information obtained they get is more limited than before compared with present ordinary people. The mainly way people who suffer from visual impairment cognitive world are tactile, auditory, olfactory, taste, a certain vision of the obstacles may be the color of cognitive problems. That means when those people browsing the graphical interface they may have some problems if the design not humane enough. Graphical User Interface is a main way to expression in the human-computer interaction interface, but its main form of interaction is visual. Even ordinary people in daily life in case of excessive information will encounter problems, which will lead to inconvenience when visually impaired people accepted Information in the Graphical User Interface such as machine operation interface. For example, people with color blindness, green blindness is the most common form of color blindness, green blind and red blind can not see what we call the red line and green line of color. Blue blindness do not see the colors we call blue line and yellow line because of the lack of cone cells. If designers use these kinds of colors, then in the eyes of these special people, there will be a lot of mistakes, which will badly affect the user experience. As a result, although the rapid development of the network and the popularity of intelligent devices had opened a new door for these people, because of such kind of imperfect graphical user interface design for those special people, that can not play a key role. Actually in the last century, the concept of barrier-free design has been put forward by the United Nations in order to achieve the concept of equality for all that people who have trouble visually in society can eliminate obstacles and lead to a cheerful life. After that, there are many people had made efforts in some fields, for instance, product design, architectural design, interior design and other aspects of the design has a more robust design specifications. In the design of virtual products, also has progress. However, over the years the domestic © Springer International Publishing AG 2017 C. Stephanidis (Ed.): HCII Posters 2017, Part II, CCIS 714, pp. 523–533, 2017. DOI: 10.1007/978-3-319-58753-0_74 visual impairment of people in the improvement of quality of life has not been greatly improved, the attention of interface design for the special groups is relatively small. This requires pay more attention to barrier-free design in the Graphical User Interface. At the same time, at the international level, thanks to the introduction of the United States’s Section 508, Accessibility Guidelines by W3C web-side, IOS systems and Android system, so that foreign designers in the barrier-free interface design has a more comprehensive design guidance, which are worthy of the domestic interface designers learn and assimilates. In the first stage, the author summarizes the potential problems in the use of visual barriers and explores the need for the design of barrier-free graphical interface. The second stage is to obtain the information through the disabled. The way of analysis and interface color, the interface of information acquisition ways to study the two aspects, and finally hope to visually impaired people such as color blindness, visual disabilities can make a positive help.	android;color;freedom of information laws by country;graphical user interface;human–computer interaction;information access;pokémon red;section 508 amendment to the rehabilitation act of 1973;springer (tank);user experience;user interface design;web accessibility initiative;ios	Yilin Chai;Ying Cao	2017		10.1007/978-3-319-58753-0_74	multimedia;human–computer interaction;computer science;graphical user interface testing;visual impairment;user experience design;information access;cognition;graphical user interface;user interface;population	HCI	-50.306537339814874	-40.45896210416179	76018
652cc02769a5b6a6860ba25200a66b4e7dcf4eaa	video mediated recruitment for online studies	usability testing;conference paper;youtube;online usability testing;video promotion;participant recruitment	More than ever, researchers are turning to the internet as a means to conduct HCI studies. Despite the promise of a worldwide audience, recruiting participants can still be a difficult task. In this video we discuss and illustrate that videos - through their sharable and entertaining nature - can greatly assist the recruitment process. Videos can also be a crucial part in developing an online presence, which may yield a community of followers and interested individuals. This community in turn can provide many long term benefits to the research, beyond just the recruitment phase.	human–computer interaction;presence information	Torben Sko;Henry J. Gardner	2012		10.1145/2212776.2212476	simulation;usability;human–computer interaction;computer science;multimedia;world wide web	HCI	-60.08828646262	-44.055203191795215	76085
c1b8d97729bec6156b2eb88f3c6192d4fecd5235	a robot's slip of the tongue: effect of speech error on the familiarity of a humanoid robot		This study investigated the effect of speech errors made by a robot on people's perception of the familiarity of the robot. Four types of speech errors were implemented for a communicating robot. Subjects' perception of the familiarity of the robot, along with other subjective evaluations of impressions of the robot, were measured in an experiment and compared between conditions with and without speech error. Results showed that speech error improved the familiarity score when the robot did not make any speech errors in the first contact with subjects and then made speech errors in the second contact on a separate day. On the other hand, speech errors lowered people's perception of the sincerity of the robot. These results imply that the robot should not make speech errors in the early stage of engagement with human users, while some speech errors after the users become accustomed with the robot might be effective in improving users' perception of the familiarity of the robot. Results also showed that speech error improved familiarity for people having low-scoring attitudes about the diversity and operation of robots.	humanoid robot;measurement in quantum mechanics;speech synthesis;star trek: first contact	Takayuki Gompei;Hiroyuki Umemuro	2015	2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2015.7333630	computer vision;speech recognition	Robotics	-51.90102592940357	-51.117581823279124	76185
3041f440013f672280fab37d3c6c8055efa16b4d	integrating development of task and object models	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias;object model	integration process can be contrasted to the notion of scenarios used in other design methods. They are similar to instances of use-cases [5], in that they capture a single thread of execution in a given usage context. However, they are more elaborate than usecase instances because they narrate not only the interaction events but also the experience of the user(s)—the usage goals, expectations, and reactions that convey information about the system’s usefulness and usability [3]. User interaction scenarios are also similar to the task descriptions developed and analyzed in cooperative design [7], but focus less on organizational relationships and workflow, and more on users’ cognitive activities. Our approach offers a specific technique for	thread (computing);usability	Mary Beth Rosson	1999	Commun. ACM	10.1145/291469.293168	object model;computer science;programming language	HCI	-52.97028275281845	-38.375949654991544	76189
3b53282f5e2d6d321fb0dd0cf0c2500a4553f4ca	distributed meetings: a meeting capture and broadcasting system	teleconferencing;travel time;user study;meeting capture;spatial index;microphone array;indexation;time compression;meeting indexing;360 degree video;everyday life	The common meeting is an integral part of everyday life for most workgroups. However, due to travel, time, or other constraints, people are often not able to attend all the meetings they need to. Teleconferencing and recording of meetings can address this problem. In this paper we describe a system that provides these features, as well as a user study evaluation of the system. The system uses a variety of capture devices (a novel 360° camera, a whiteboard camera, an overview camera, and a microphone array) to provide a rich experience for people who want to participate in a meeting from a distance. The system is also combined with speaker clustering, spatial indexing, and time compression to provide a rich experience for people who miss a meeting and want to watch it afterward.	cluster analysis;dos;duplex (telecommunications);echo suppression and cancellation;floor and ceiling functions;intranet;microphone;real-time transcription;requirement;speech recognition;timeline;usability testing;window function	Ross Cutler;Yong Rui;Anoop Gupta;Jonathan J. Cadiz;Ivan Tashev;Li-wei He;Alex Colburn;Zhengyou Zhang;Zicheng Liu;Steve Silverberg	2002		10.1145/641007.641112	simulation;teleconference;computer science;multimedia;world wide web;spatial database	HCI	-49.40966133173609	-38.352593887276534	76200
8dfd01dd64343b1a899e6a836cb991eeb0d41aa8	robotic assistance during ambulation by older adults		"""Some older adults require assistance with ambulation due to physical mobility limitations. Others lack the cognitive ability, either alone or in combination with physical impairment, to get where they need to go. Investigation of older adults' gait speed, social interaction, and responsiveness to a robot during ambulation is part of the Nursebot Project, a unique collaboration of health care professionals and technologists focused on developing a personal robotic assistant for frail elderly adults at home. """"Pearl,"""" the Nursebot prototype Description of the Project Self-reported walking ability may be the best indicator of functional mobility and performance of activities of daily living among older adults in the community. ' The importance of walking as a form of exercise and a means by which to connect with others warrants efforts to design a robotic device that, among other functions, encourages social interaction and safe ambulation in a vulnerable and largely sedentary population. The Nursebot Project involves clinicians and researchers from the University of Pittsburgh, Carnegie Mellon University, and the University of Michigan who are developing a personal robotic assistant to augment the in-home help and supervision provided by family members, friends, and health care providers. The ultimate goal is to produce a robot with multiple functionalities (e.g., issuing reminders to eat, drink fluids, and take medication; monitoring health status and medication adherence; enhancing communication with persons outside the home; providing physical assistance with ambulation and other activities of daily living; and promoting personal safety), which could be tailored to an individual's evolving needs. Our current prototype, """"Pearl,"""" has E.T.-like eyes, ears that spin when information is being processed (indicating that she cannot converse at the same time), and a mouth that can frown or smile. """"Pearl"""" is equipped with mapping technology that enables her to learn the layout of her environment, then navigate autonomously within it. Using laser sensors, she is able to detect changes in her surroundings, as when furniture is relocated or a person moves within her field of vision, thus enabling her to avoid collision. """"Pearl"""" is capable of limited natural language dialogue, with everything she says also displayed on her touchscreen chest. Her height is adjustable, and she has a tray on which items can be transported.2 Early field tests have demonstrated that older adults will interact with """"Pearl."""" Yet, she is not able to keep pace with the varying speeds at which older adults walk, and her speech is not easily understood, particularly while walking. Thus, we have undertaken a field investigation of older adults' gait speed and social interaction while ambulating alone, with another person, and with """"Pearl."""" The investigations include older adults from a retirement community who live either independently or in an assisted living environment and ambulate with or without an assistive device, such as a walker or cane."""	amiga walker;assistive technology;cognition;natural language;prototype;responsiveness;robot;sensor;touchscreen	Judith T. Matthews;Sandra Engberg;Michael Montemerlo;Joelle Pineau;Nicholas Roy;Joan Rogers;Sebastian Thrun	2002			during ambulation;physical mobility;gerontology;health care;gait;population;medicine	HCI	-49.30203738037901	-48.73284808218517	76205
f13277eebd0dd24d72e01bea872380f787393be0	visual dependency structure matrix for multidisciplinary design optimization tradeoff studies	design optimization;dependency structure matrix	The design of complex products, such as automobiles and aircraft, necessitates modeling of the physics within numerous participating disciplines that are inherently linked through the transference of critical data. The resulting complexity makes it essentially impossible for designers or design teams, regardless of the number of participants or expertise of the participants, to intuitively understand the interdependencies of the disciplinary analyses and tasks. Recent methods and tools being developed in the field of multidisciplinary design optimization provide a means of representing these inherent couplings, as well as a way in which tradeoffs between accuracy and efficiency may be explored. It is with this in mind that the visual dependency structure matrix has been developed in this work. The visual dependency structure matrix is a web-based framework, coupled with underlying cost and error models, that enables designers to explore the possibility of eliminating or suspending couplings interactively, before or during a complex analysis run.The paper presents the visual dependency structure matrix framework and shows how the visual dependency structure matrix can be used as a mechanism for designers to cut computational costs during the design process without sacrificing the desired accuracy of the system level process.	computation;design structure matrix;interactivity;interdependence;mathematical optimization;multidisciplinary design optimization;web application	Kenneth W. English;Christina L. Bloebaum	2008	JACIC	10.2514/1.32038	mathematical optimization;simulation;computer science;engineering drawing	HCI	-61.18620048004068	-38.443775701802124	76267
adc9682dc6105f34e700b8066e69f314021c2b9e	the effects of group size in the furniture assembly task		Does the number of additional participants affect the physical performance or the psychological evaluation of participants on carrying out a task? This paper examines the effects of group size, either individuals, two-party or five-party, using the furniture assembly task. We use three behavioral indexes, i.e. degree of completion, time-to-completion, and duration of interaction with materials, in a physical performance evaluation. Furthermore, we use three psychological indexes, i.e., degrees of contribution, satisfaction, and familiarity, in a psychological evaluation. In duration of interaction with materials, time-to-completion, and degree of contribution, the members of two-person groups take longer or feel more individually significant than do the members of five-person groups. These results suggest that social loafing effects have emerged by increasing the number of participants. We expect these findings to help in designing relationality among people as well as between people and artifacts.		Noriko Suzuki;Mayuka Imashiro;Mamiko Sakata;Michiya Yamamoto	2017		10.1007/978-3-319-58524-6_51	social psychology;social facilitation;social loafing;psychological evaluation;psychology	HCI	-52.816047226913476	-51.20326018481161	76492
205756a9ac4e7ef196c4bee0b6e980ac9f83eaf9	towards an ontology-based customization approach for supporting people with special needs.	smart home;assistive device;people with disabilities;special needs	People with disabilities encounter serious limitations in interacting with their home environment since their requirements are not met properly. Personal assisting devices interacting with the services offered by smart home environments can help to improve the quality of their lives. A major prerequisite for this is to provide an appropriate customization architecture which allows to reason about the person’s current situation in terms of personal, technical and natural context and to adapt the home environment’s services accordingly. This paper proposes a customization approach based on an ontology which comprehensively represents the situation of persons with special needs for the purpose of adapting their home environment’s services.	home automation;interaction;ontology (information science);requirement	Wieland Schwinger;Werner Retschitzegger;Franz Pühretmair;Gerhard Nussbaum	2005			simulation;human–computer interaction;engineering;multimedia	HCI	-51.361788149824804	-40.10817790538306	76743
928d168ceec486935c2353f141adb77db910efe4	automatically measuring biomechanical skills of violin performance: an exploratory study		This evaluation study explores how automated movement analysis can be used to catch the biomechanical skills needed for a physically accurate violin performance, maximizing efficiency and minimizing injuries. Starting from a previously recorded multimodal dataset, we compute movement features from motion captured data of five violinists performing three violin exercises: octave shift, string crossing, and a Romantic repertoire piece. Three violin teachers were asked to evaluate audio, video, and both audio and video stimuli of the selected exercises. We correlated their ratings with automatically extracted movement features. Whereas these features are purely visual (i.e., they are computed from motion captured data only), we asked teachers to also evaluate audio because it can be considered as the direct translation of movement skills into another modality. In this way, we can also look at possible relations between evaluation of the audio aspects of the performance and biomechanical skills of violin playing. Results show that the proposed movement features can be partially used to measure the biomechanical skills of the violin players to support learning and mitigate the risk of injuries.	modality (human–computer interaction);motion capture;multimodal interaction	Erica Volta;Maurizio Mancini;Giovanna Varni;Gualtiero Volpe	2018		10.1145/3212721.3212840	exploratory research;repertoire;octave;human–computer interaction;software;violin;motor control;computer science	HCI	-50.51727692840629	-49.04583480508907	76812
ee18e7424985f5c78e5e1417c16694e185fc8d17	using photo diaries to elicit user requirements from older adults: a case study on mobility barriers		Older adults encounter numerous barriers to mobility, many of which are in the built environment. Technological solutions may enable them to mitigate these barriers and promote physical activity. To design appropriate technological solutions, it is crucial to understand the specific barriers to mobility older adults face from their perspectives. Photo diary studies allow older adults to autonomously document their experiences to support generation of user needs and requirements. We investigate the methodological appropriateness of photo diaries for exploring experiences of older adults and eliciting their requirements for new technologies. A photo diary study was conducted with 26 older adults, who were given disposable cameras to document things that affect their mobility. As well as presenting a selection of the mobility barriers identified in this study, the paper outlines a number of methodological issues relating to the use of photo diaries for eliciting the needs and requirements of older adults.	photoblog;requirement	David Swallow;Helen Petrie;Christopher Power;Alistair D. N. Edwards	2015		10.1007/978-3-319-22701-6_11	human–computer interaction;internet privacy;world wide web	HCI	-59.34301036089228	-41.929411607077725	76815
afcb1fe5af6d6cb1c5ab638cf2bfb84347588f69	review on using physiology in quality of experience		In the area of Quality of Experience (QoE), one challenge is to design test methodologies in order to evaluate the perceived quality of multimedia content delivered through technical systems. Traditionally, this evaluation is done using subjective opinion tests. However, sometimes it is difficult for observers to communicate the experienced quality through the given scale. Furthermore, those tests do not give insights into how the user is reacting on an internal physiological level. To overcome these issues, one approach is to use physiological measures, in order to derive a direct non-verbal response of the recipient. In this paper, we review studies that have been performed in the domain of QoE using physiological measures and we look into current activities in standardization bodies. We present challenges this research faces, and give an overview on what researchers should be aware of when they want to start working in this research area.		Sebastian Arndt;Kjell Brunnström;Eva Cheng;Ulrich Engelke;Sebastian Möller;Jan-Niklas Antons	2016			data science;verbal response;standardization;quality of experience;multimedia;computer science	HCI	-57.2767030933953	-47.025217970523755	76904
4a1e85a065e8a10cb1a40945cd7604c8871ed172	creating rapport with virtual agents	positive feedback;virtual characters;nonverbal behavior;virtual human;evaluation;virtual agents;rapport;virtual agent	Recent research has established the potential for virtual characters to establish rapport with humans through simple contingent nonverbal behaviors. We hypothesized that the contingency, not just the frequency of positive feedback is crucial when it comes to creating rapport. The primary goal in this study was evaluative: can an agent generate behavior that engenders feelings of rapport in human speakers and how does this compare to human generated feedback? A secondary goal was to answer the question: Is contingency (as opposed to frequency) of agent feedback crucial when it comes to creating feelings of rapport? Results suggest that contingency matters when it comes to creating rapport and that agent generated behavior was as good as human listeners in creating rapport. A “virtual human listener” condition performed worse than other conditions.	contingency (philosophy);positive feedback;virtual actor	Jonathan Gratch;Ning Wang;Jillian Gerten;Edward Fast;Robin Duffy	2007		10.1007/978-3-540-74997-4_12	psychology;positive feedback;knowledge management;evaluation;communication;social psychology	AI	-52.77669036856379	-49.88207342098587	77502
4dfbb23118a9d260ac0a7883a5a238a2593d438d	indoor navigation map for visually impaired people	indoor navigation for visually impaired people;braille blocks;voice indoor map	Due to recent progress of geospatial and mobile technologies, it becomes available to provide geospatial information services to visually impaired people such as BlindSquare. In this demo paper, we present a prototype of voice indoor routing map service, called VIM(Voice-based Indoor Maps) for visually impaired people. This prototype service has been designed for navigation along braille blocks between two points in indoor space and developed by using TalkBack user-interface of Android OS. The voice navigation information is mainly based on an OGC standard [3], IndoorGML [2], which serves as the framework data model and XML schema to describe the network connectivity in indoor space. The data model of VIM is designed by considering several safety requirements for visually impaired people. The prototype service has been implemented and tested on a real site of subway station in Seoul.	android;crash reporter;data model;nautical chart;operating system;prototype;requirement;routing;user interface;vim;xml schema	Hyeong-Gyu Ryu;Taehoon Kim;Ki-Joune Li	2014		10.1145/2676528.2676533	computer vision;simulation;engineering;multimedia	Mobile	-49.89880734489093	-39.23640346090012	77772
7427ed0f8251ceadb7f83520a47770213a36d7f7	a method to detect lies in free communication using diverse nonverbal information: towards an attentive agent	nonverbal information;and lies;discriminant analysis;information agent;communication	We usually speculate partner's mental states by diverse nonverbal information. Agents need the ability for natural communication with people. In this paper, we focused on a lie as one of the typical behavior in which we often express our mental states unconsciously. The purpose of this study is to experimentally investigate the possibility of automatic lie detection in communication. We proposed an experimental setting in which participants could spontaneously decide whether or not to tell a lie. We then conducted an experiment to record participants' behavior in this setting. After that, we investigated, by discriminant analysis, that we could achieve 68% accuracy in classifying the utterances into lies and the rest without taking account of individual features by using the noverbal behavior data. We would detect participants' stresses when they told a lie. The suggestions in this paper are useful to an agent which pays attention to user's mental states.		Yoshimasa Ohmoto;Kazuhiro Ueda;Takehiko Ohno	2009		10.1007/978-3-642-04875-3_10	computer vision;computer science;artificial intelligence;linear discriminant analysis	AI	-51.38391406113589	-49.61363946678284	77869
15f3ca8c762f7ef8c6d2d7a0271e39918748a457	using motion sensing for learning: a serious nutrition game		A mixed reality game was created to teach middle and high school students about nutrition and the USDA My Plate icon. This mixed reality game included both digital components (projected graphics on the floor) and tangible, physical components (motion tracking wands that were handheld). The game goal was to feed the alien the healthiest food item from a pair of items. Students learned about the amount of nutrients and optimizers in the digital food items and practiced making rapid food decisions. In the final level of the game players interacted with My Plate and each food item filled the appropriate quadrant in real time. Nineteen 4th graders played through the game in one 1.5 hour session. Significant learning gains were seen on a pretest and posttest that assessed nutrition knowledge, pairedt (18) = 4.13, p u003c .001. We support the need for call for more embodied games that challenge children to practice making quick food choice decisions and we explore how motion capture games can affect engagement, health behaviors, and knowledge outcomes.		Mina Johnson-Glenberg	2013		10.1007/978-3-642-39420-1_40	computer vision;simulation;communication	HCI	-55.90850838307497	-47.92019530606642	77872
784a164b9a27d57588d4c7b174dc19f905b1af82	mobile collaboration for young children: reading and creating stories	multimedia communications;multimedia;college park allison druin fails;jerry alan;dissertation;computer science mobile collaboration for young children reading and creating stories university of maryland	Within the last decade, mobile devices have become an integral part of society, at home or work, in industrialized and developing countries. For children, these devices have primarily been geared towards communication, information consumption, or individual creative purposes. Prior research indicates social interaction and collaboration are essential to the social and cognitive development of young children. This dissertation research focuses on supporting collaboration among mobile users, specifically children ages 6 to 10—while collaboratively reading and creating stories. I developed Mobile Stories, a novel software system for the Windows Mobile platform that supports collaborative story experiences, with special attention to two collocated collaboration experiences: content splitting and space sharing. Content splitting is where interface parts (e.g. words, pictures) are split between two or more devices. Space sharing is where the same content (e.g. a document) is spread or shared across devices. These collocated collaborative configurations help address mobile devices' primary limitation: a small screen. #R##N#The three research questions addressed are: how does Mobile Stories affect children's collaboration and mobility, what are some appropriate interfaces for collocated mobile collaboration with children, and when are the developed interfaces preferred and why. Mobile Stories was designed and develop using the Cooperative Inquiry design method. Formative studies furthered the design process, and gave insight as to how these collaborative interfaces might be used. A formal, mixed method study was conducted to investigate the relative advantages for each of the collocated collaborative interfaces, as well as to explore mobility and collaboration.#R##N#The results of the formal study show children were more mobile while creating stories than when reading and sharing them. As for task effectiveness, children read more pages when they were closer, and created more pages when they were further apart and more mobile. Children were closer together when they read using the content split configuration. While creating their stories, children rarely used the collocated collaborative configurations and used verbal collaboration instead. Several indicators pointed to relative advantages of the split content configuration over the share space configuration; however, the advantages of each are discussed.		Jerry Alan Fails	2009			simulation;human–computer interaction;engineering;multimedia	HCI	-62.638906261504	-41.21319404657176	77954
7e645a374314f58ef9931fd63d8b97d9f92e60ce	personality type indicator models in serious games: a case study in a surgical navigation game	serious games;myers briggs type indicator mbti;simulation;personality types;serious games computing human factors psychology;game parameters personality type indicator models serious games surgical navigation game educational environment game personalization human centered paradigm game based simulation environment psychological types theory myers briggs type indicator mbti personality preference measure;personality types myers briggs type indicator mbti serious games simulation education;games correlation navigation surgery training accuracy	Serious games are a popular concept in both the research and commercial areas. It is agreed that the concept refers to the use of computer games without the main purpose of pure entertainment. In addition to being entertaining, they have some additional educational or training objectives as well. Serious games are used in different areas such as military, government, educational, corporate, and healthcare. However, according to their individual differences, it is not always possible to provide such an educational environment that fits expectations and preferences of all audience. Hence, personalization is becoming an essential issue in serious game environments, which focus on a human-centered paradigm aiming to provide adaptive and personalized services to the users according to the context. However, how such a personalization should be affectively implemented in the design of serious games is a challenge. This study aims to better understand the affect of personality types on game play. For this purpose, a game-based simulation environment which also records all details of the player during the performance of several tasks in the game play was used. Twenty nine students were asked to play the simulation game. Additionally, their personality types were collected based on the theory of psychological types by Carl Jung, the Myers-Briggs Type Indicator (MBTI) which measures personality preferences as defined by Four Dichotomous pairs of mental functions or attitudes. The correlation between these personality types and individual performance measures of players during the game play was analyzed. However no significant correlation between game parameters and the players' personality types has been recorded. This may be because of the limited number of participants that need to be examined in the future studies.	educational entertainment;fits;futures studies;pc game;personalization;programming paradigm;simulation;video game developer	G. G. Menekse;Nergiz Ercil Cagiltay;Erol Özçelik	2015	2015 International Conference on Information Technology Based Higher Education and Training (ITHET)	10.1109/ITHET.2015.7218020	simulation;computer science;artificial intelligence;multimedia	HCI	-58.70844701529681	-49.798278393657775	78028
b6a502fd9abc33edbc41faa1a5f2021332d6c68d	a study of the interface usability issues of mobile learning applications for smart phones from the users perspective		A conceptual framework for measuring the usability characteristics of mobile learning (m-Learning) application has been developed. Furthermore, a software prototype for smartphones to assess usability issues of m-Learning applications has also been designed and implemented. This prototype has been developed, using Java language and the Android Software Development Kit, based on the recommended guidelines of the proposed conceptual framework. The usability of the proposed model was compared to a generally available similar mobile application (based on the Blackboard) by conducting a questionnairebased survey at Western University. The two models were evaluated in terms of ease of use, user satisfaction, attractiveness, and learnability. The results of the questionnaire showed that the participants considered the user interface based on our proposed framework more user-friendly as compared to the Blackboard-based user interface.	android software development;computer user satisfaction;interactivity;java;learnability;mobile app;prototype;qualitative comparative analysis;reverse engineering;smartphone;software development kit;software engineering;software prototyping;usability;user interface	Abdalha Ali;Muasaad Alrasheedi;Abdelkader H. Ouda;Luiz Fernando Capretz	2015	CoRR	10.5121/ijite.2014.3401	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;usability;human–computer interaction;computer science;system usability scale;usability engineering;multimedia;heuristic evaluation;world wide web;usability lab;usability inspection	HCI	-62.60314357967872	-46.43770262638363	78093
50b673bec7c471900bace522b7a46ab2966fab6a	analyzing emergent users’ text messages data and exploring its benefits		While users in the developed world can choose to adopt the technology that suits their needs, the emergent users cannot afford this luxury, and hence, they adapt themselves to the technology that is readily available. When technology is designed, such as the mobile-phone technology, it is an implicit assumption that it would be adopted by the emergent users in due course. However, such user groups have different needs, and they follow different usage patterns as compared to users from the developed world. In this paper, we target an emergent user base, i.e., users from a university in Pakistan, and analyze their texting behavior on mobile phones. We see interesting results, such as the long-term linguistic adaptation of users in the absence of reasonable Urdu keyboards, the overt preference for communicating in Roman Urdu, and the social forces related to textual interaction. We also present two case studies on how a single dataset can effectively help understand emergent users, improve usability of some tasks, and also help users perform previously difficult tasks with ease.		Anas Bilal;Aimal Rextin;Ahmad Kakakhail;Mehwish Nasim	2019	IEEE Access	10.1109/ACCESS.2018.2885332	multimedia;distributed computing;computer science;usability	HCI	-56.940200700073206	-42.51249735094021	78113
1ab4b9fb318325be3c0f69efb38d4f3c028d6257	sharing everyday places i go while preserving privacy	location based reminder;design guideline;data visualization;informed consent;location privacy;local search;place set	Several new location-based information applications reveal sets of places that an individual frequently visits. This practice gives rise to related privacy questions and new interface needs. For example, while electronic system users want to be in control of private data and know how those who have it will employ it [10], there are no design guidelines for garnering informed consent for using place-based information. In addition, the set of places a person frequents may reveal information such as: 1) when they are likely to go to a place, or 2) within close proximity, where they live. If a user considers this information private, they may still inadvertently disclose it: humans have difficulty comprehending aggregate effects of their actions [1]. A system could therefore deliver benefit by identifying notable risks and informing the user. This research plan will address these key issues and will ultimately inform privacy interface design.	aggregate data;goto;information privacy	Pamela J. Ludford	2006		10.1145/1125451.1125785	informed consent;information privacy;privacy by design;computer science;local search;data mining;internet privacy;world wide web;computer security;data visualization	HCI	-57.91152618863935	-43.080286559359074	78176
1484117b7bff6a3d90dcd5b3645cab4e4167d08a	"""corrigendum to """"are there optimal levels of arousal to memory? effects of arousal, centrality, and familiarity on brand memory in video games"""" [comput. human behav. 28 (2012) 285-291]"""	brand memory;human behav;video game;optimal level		centrality	Eui Jun Jeong;Frank Biocca	2012	Computers in Human Behavior	10.1016/j.chb.2012.02.018	psychology;cognitive psychology;artificial intelligence;social psychology	AI	-54.93972773640464	-51.895095727576646	78218
5f0782270a40383494e21e3d9d8c8b38bcf98fe4	socially assistive robotics: human-robot interaction methods for creating robots that care	assistive robotics	Socially assistive robotics (SAR) is a new subfield of robotics that bridges HRI, rehabilitation robotics, social robotics, and service robotics. SAR focuses on developing machines capable of assisting users, typically in health and education contexts, through social rather than physical interaction. The robot's physical embodiment is at the heart of SAR's effectiveness, as it leverages the inherently human tendency to engage with lifelike (but not necessarily humanlike or otherwise biomimetic) social behavior. This talk will describe research into embodiment, modeling and steering social dynamics, and long-term user adaptation for SAR. The research will be grounded in projects involving analysis of multi-modal activity data, modeling personality and engagement, formalizing social use of space and non-verbal communication, and personalizing the interaction with the user over a period of months. The presented methods and algorithms will be validated on implemented SAR systems evaluated by human subject cohorts from a variety of user populations, including stroke patients, children with autism spectrum disorder, and elderly with Alzheimers and other forms of dementia.	algorithm;biomimetics;data modeling;human–computer interaction;human–robot interaction;modal logic;population;rehabilitation robotics;social dynamics;social robot	Maja J. Mataric	2014		10.1145/2559636.2560043	simulation;computer science;artificial intelligence;developmental robotics	HCI	-55.4847390995074	-49.7598165048003	78488
bb6ad707d2ad89fdd057d68af2325b9aacce3d55	intimate care: exploring etextiles for teaching female pelvic fitness	craft;wellbeing;professor patrick olivier;dr robert comber;wearable;eprints newcastle university;body literacy;open access;care;materiality;design;health;dr madeline balaam;etextiles	Intimate care is integral to the lifecourse, and it includes care tasks that are linked to personal hygiene, bodily functions and products. In this paper, we explore the potential of eTextiles as catalysts for conversations around intimate care. We designed a kit that integrates eTextiles as the core material to teach and learn about intimate parts of the self and to support body literacy. We deployed this design kit in an educational context, with a group of six female participants aged 15-16. We suggest avenues for future research within health and wellbeing, in combination with smart, wearable materials.	wearable computer	Teresa Almeida;Rob Comber;Patrick Olivier;Madeline Balaam	2014		10.1145/2598784.2602768	design;human–computer interaction;materiality;computer science;engineering;artificial intelligence;health;management;mechanical engineering	HCI	-62.60965691550255	-41.40947806654578	78688
1057ad0b3c15bb10e4d6816e72625fecdbfdf336	o' game, can you feel my frustration?: improving user's gaming experience via stresscam	stress monitoring;video games;human computer interaction;game difficulty adjustment;usability evaluation;interactive entertainment;video game;thermal imaging;blood flow;game playing;contact stress;computer game	One of the major challenges of video game design is to have appropriate difficulty levels for users in order to maximize the entertainment value of the game. Game players may lose interests if a game is either too easy or too difficult. This paper presents a novel methodology to improve user's experience in computer games by automatically adjusting the level of the game difficulty. The difficulty level is computed from measurements of the facial physiology of the players at a distance. The measurements are based on the assumption that the players' performance during the game-playing session alters blood flow in the supraorbital region, which is an indirect measurement of increased mental activities. This alters heat dissipation, which can be monitored in a contact-free manner through a thermal imaging-based stress monitoring and analysis system, known as StressCam.  In this work, we investigated on two primary objectives: (1) the feasibility of utilizing the facial physiology in automatically adjusting the difficulty level of the game and (2) the capability of the automatic difficulty level adjustment in improving game players' experience. We employed and extended a XNA video game for this study, and performed an in-depth, comparative usability evaluation on it. Our results show that the automatic difficulty adjustable system successfully maintains game players' interests and substantially outperforms traditional fixed-difficulty mode games. Although a number of issues of this preliminary study remain to be investigated further, this research opens a new direction that utilizes non-contact stress measurements for monitoring and further enhancing a variety of user-centric, interactive entertainment activities.	microsoft xna;pc game;thermal management (electronics);usability;video game design;video game developer	Chang Yun;Dvijesh Shastri;Ioannis T. Pavlidis;Zhigang Deng	2009		10.1145/1518701.1519036	non-cooperative game;video game design;game design;simulation;human–computer interaction;simultaneous game;blood flow;game mechanics;game art design;multimedia;screening game;game design document;sequential game;contact mechanics;game testing	HCI	-50.10033621640986	-46.070661216697836	78734
319ba1b541d838f4bef720b95062ad4e1bd56a6e	quick response codes to instantiate interactive medical device instructions for display on a smartphone		Usability is an increasingly important factor within the field of healthcare and medical device development. One of the main issues with the usability of medical devices is their complex nature. Therefore, it is vital that comprehensive and clear instructions are provided to aid in the operation of these devices. While paper-based instructions are commonly provided, they have many disadvantages which can be addressed by interactive digital instructions. Moreover, in an era of pervasive computing, it is important to provide these instructions at the point of need. This can be done using a Quick Response code and a smartphone which allows for interactive instructions to be instantly accessible. This paper presents a case study and a working prototype to test the utility of interactive medical device instructions accessed by a QR code attached to the medical device.		Megan Patterson;Raymond Bond;Maurice D. Mulvenna;Carol Reid;Fiona McMahon;Pauric McGowan;Jenna McGarry;Hugh Cormican	2017		10.14236/ewic/HCI2017.22	multimedia;computer science;human–computer interaction;usability;ubiquitous computing	HCI	-50.62591481143998	-40.705968909947906	78780
859b643dca11fad8689031a0756f87b9da328ed5	does identification with virtual model making shopping experience more enjoyable? the case of virtual mirror		The advancements in 3D technologies provide a new presentation format for online products, namely virtual mirror, which transforms the traditional way of presenting products online. Previous studies have been focused on the utilitarian perspective of virtual mirror and largely ignored its hedonic effects. To fill this gap, this paper proposes a research model showing that virtual mirror exhibits higher levels of interactivity and model similarity than other presentation formats such as static pictures and videos. Virtual mirror enables consumers to adjust the virtual model to match with their own physical appearance, which enhances the consumers’ identification with the model and consequently their perceived reduction of self-discrepancy. Reduced self-discrepancy is argued to be positively associated with elation and enjoyment. The overall enhanced enjoyment leads to increased purchase intention and website retention. An experiment is proposed to test the research model. Findings from this research can have significant research and practical implications.		Varun Grover;Dan Jiang;Heshan Sun	2015			psychology;simulation;human–computer interaction;multimedia	Visualization	-58.81175858399029	-47.218187839459816	79002
5bab05f87e78206745efe1a335e09d89459aa399	interpreting technology-mediated identity: perception of social intention and meaning in bluetooth names	digital identity;mobile device;multi dimensional scaling;social identity;qualitative analysis;bluetooth;hierarchical cluster analysis;mobile technology	The ubiquitous and highly personal nature of mobile devices, together with the partially embodied nature of Bluetooth, means that mobile device based Bluetooth provides unique affordances for communicating aspects of identity. We report a study of how people interpret Bluetooth names in terms of social identity, considering it as an example of mobile technology-mediated identity. We used card-sorting, hierarchical cluster analysis, multi-dimensional scaling and qualitative analysis to establish perceived types of Bluetooth name and dimensions of naming; illustrating how people conceptualise and interpret technology-mediated identity projected by others.	bluetooth;cluster analysis;hierarchical clustering;image scaling;mobile device;multidimensional scaling;sorting	Freya Palmer;Eamonn O'Neill	2010		10.1145/1952222.1952273	social identity theory;multidimensional scaling;computer science;qualitative research;operating system;mobile technology;mobile device;hierarchical clustering;bluetooth;world wide web	HCI	-58.19459550958605	-40.53278041006788	79054
0ac3605856c7862f95d5cb11eeb2933fd5e608e6	a survey of variation techniques for repetitive games music	games music;generative music	How much time will a player spend in an interactive scene? For the majority of game scenarios this is impossible to predict. Therefore, their musical accompaniment is usually disposed to continuously loop until player interaction triggers a change. This approach involves an existential danger: Sooner or later the player becomes aware of the repetitive character of the ambience design; the game scenario emerges as a mere mechanical arrangement and loses much of its integrity.  In this survey paper we systematize and discuss the common approaches to conceal musical repetition. Furthermore, we complement them by a number of approaches that incorporate arrangement techniques, aspects of expressive music performance, and generative variation methods that work actively against repetitiveness.	emergence;expressive power (computer science)	Axel Berndt;Raimund Dachselt;Rainer Groh	2012		10.1145/2371456.2371466	simulation;computer science;artificial intelligence;multimedia	HCI	-52.88910176510821	-45.15889316814986	79080
5d8c0a6422787d1e9e4c57436cfe01aaac110c76	intrusive and non-intrusive evaluation of ambient displays	human computer interaction;infovis;hci;information visualization;behavioral science;visualization;evaluation;information system;ambient display	This paper addresses two problems: “What are the appropriate methods for evaluating information systems?” and “How do we measure the impact of ambient information systems?” Inspired by concepts in the social and behavioral science, we categorize the evaluation of ambient displays into two styles: intrusive and nonintrusive. Furthermore, two case studies are used to illustrate these two evaluation styles. An intrusive evaluation of MoneyColor shows that the correct disruptive order for ambient displays is animation, color, area and shape. A non-intrusive evaluation of Fisherman proposes an effectiveness measurement, and reveals three issues to improve the effectiveness of ambient displays.	categorization;experiment;information system;regular expression	Xiaobin Shen;Peter Eades;Seok-Hee Hong;Andrew Vande Moere	2007			simulation;human–computer interaction;computer science;multimedia	HCI	-58.19917544894545	-46.420103761330914	79304
9b541f33190ccfd43df3f1e12a5831792eeb8108	intimate objects	intimate objects;intimacy;couples;participatory design;reflective design	We present a preliminary and ongoing study into intimate objects: technological devices for maintaining intimacy at a distance. We use the notion of critical technical practice to provide a theoretical framework on which to base our designs, building devices that differ from mass communication devices in three ways: they are for couples in a relationship to communicate with each other, not with everybody else, they are for a specific couple to use, not a generic couple, and they are for the transmission of specific intimate communication, not all-purpose communication.We present an overview of the study, give some examples of intimate object sketches produced by our subjects, and discuss questions posed by the study, particularly those concerning the generalizability of the results.		Joseph Kaye;Liz Goulding	2004		10.1145/1013115.1013175	human–computer interaction;engineering;generalizability theory;participatory design;critical technical practice	HCI	-59.20374576780824	-39.94357991704291	79309
a5a4b239f99a74276e05f1a55d5138b3b96a4fd5	user experience of smart phones in mobile journalism: early findings on influence of professional role	journalism;smart phone;statistical significance;work;user experience	We used an online questionnaire in the end of a case study to explore whether and how professional role - the role of a news journalist or a news photographer - affects user experience of smart phones used for mobile news making. Fifteen participants assessed the pragmatic and hedonic qualities and an overall judgment of appeal of a smart phone based mobile journalism system. We found that photographers assessed the hedonic quality identification more negatively than journalists and a similar trend was found for hedonic quality stimulation. We did not find a statistically significant difference between the user groups for the perception of pragmatic qualities or overall judgment of appeal.	smartphone;user experience	Heli Väätäjä	2010		10.1145/1952222.1952224	user experience design;human–computer interaction;journalism;computer science;statistical significance;multimedia;work	HCI	-58.89537062707819	-45.88528544966103	79317
cb73cfe0ed9f47aef44a54a9d24d2ef1e49a43c1	from a robotic vacuum cleaner to robot companion: acceptance and engagement in domestic environments	robot companion;mobile robots;human robot interaction;sustainability;situational awareness;edutainment	This paper shows preliminary results of the project DR4GHE (Domestic Robot 4 Gaming Health and Eco-sustainability). The main purpose is to develop a Robot Companion for domestic applications able to advise and suggest good practices to users. Interaction and engagement with the user are introduced providing to the Robot Vacuum Cleaner RVC an additional intelligence and leveraging the existing level of acceptance. Morphological aspects, in addition to behavioral traits, assume a key role in the perceptual transition of the RVC from object to subject. Human-robot interaction takes place on two levels: direct interaction, in particular with visual and sound signals; and mediated interaction, through a GUI for smartphone and tablets.	domestic robot;graphical user interface;human–robot interaction;robotic vacuum cleaner;smartphone	Maria Luce Lupetti;Stefano Rosa;Gabriele Ermacora	2015		10.1145/2701973.2702004	human–robot interaction;mobile robot;situation awareness;simulation;computer science;artificial intelligence;social robot;multimedia;sustainability	HCI	-51.82100304713562	-46.075510195539984	79430
e01ca8efdc2eb98d960377a91b6d442b8a50fd5a	handling conversation interruption in many-to-many hr interaction considering emotional behaviors and human relationships		In the future, communication robots are expected to join many-to-many human-robot interactions. Thus, robots must handle interruptions requesting a new task outside of the current conversation. In this paper, we propose a novel scheduler which decides switch timing of conversational tasks when a robot is interrupted. The model grasps the structure of the conversation and finds its breakpoints based on adjacency pairs. In order to decide whether to switch conversational tasks on each breakpoint or not, the model prioritizes conversational tasks considering an importance of its topic and a length as contexts of each conversational task. The model also uses human relationships and emotional behaviors to decide priority of conversational tasks. The result of an evaluation experiment shows that our proposed scheduler could impress subjects more favorably than that which always prioritizes an interrupter.	breakpoint;evaluation function;experiment;interaction;interrupt;interruption science;many-to-many;modal logic;norm (social);personalization;prototype;robot;scheduling (computing)	Takumi Horie;Kazunori Takashio	2018	2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2018.8525745	simulation;conversation;task analysis;many-to-many (data model);breakpoint;real-time computing;interpersonal relationship;adjacency pairs;computer science;context model;human–robot interaction	Robotics	-50.16436799927155	-50.91677782712271	79537
6835c4a3fa48a0fa807f4483ecdf5a83ae73d7cd	a creative prototype illustrating the ambient user experience of an intelligent future factory	user centered design ucd;science fiction prototyping sfp;process control work;industry 4 0;ambient user experience ux design	This article introduces user experience research that has been carried out by evaluating a video-illustrated science fiction prototype with process control workers. Essentially, the prototype ‘A remote operator’s day in a future control center in 2025’ was aimed at discovering opportunities for new interaction methods and ambient intelligence for the factories of the future. The theoretical objective was to carry out experience design research, which was based on explicit ambient user experience goals in the nominated industrial work context. This article describes the complete creative prototyping process, starting from the initial user research that included evaluations of current work practices, technological trend studies and co-design workshops, and concluding with user research that assessed the final design outcome, the science fiction prototype. The main contribution of the article is on the ambient user experience goals, the creation process of the video-illustrated science fiction prototype, and on the reflection of how the experience-driven prototype was evaluated in two research setups: as video sequences embedded in a Web survey, and as interviews carried out with expert process control workers. For the science fiction prototyping process, the contribution demonstrates how the method may employ video-illustration as a means for future-oriented user experience research, and how complementary user-centered methods may be used to validate the results.		Tiina Kymäläinen;Eija Kaasinen;Jaakko Hakulinen;Tomi Heimonen;Petri Mannonen;Maiju Aikala;Hannu Paunonen;Jouni Ruotsalainen;Lauri Lehtikunnas	2017	JAISE	10.3233/AIS-160417	user interface design;user experience design;simulation;human–computer interaction	HCI	-62.54732488531617	-38.22632699367903	79785
f52c12e042883d397659a79641314a48afb3a3fe	the camera as an actor design-in-use of telemedicine infrastructure in surgery	new technology;bea;telemedicine;inscriptions;design in use;translations;multimedia communication;actor network theory;configuration;video mediated communication;alignment;heterogeneous network;work practice;health care	This paper describes the evolvinginterrelationship between a pre-establishedwork practice and a new technology, with anemphasis on how the technology itselfparticipates in the process and introduceschanges, while at the same time being changeditself. The case study concerns theintroduction of multimedia communicationtechnology into a surgical operating theatre.Concepts from Actor-network theory are found toprovide a useful perspective on the descriptionand analysis of the case. The technology andthe work practice are viewed as a newheterogeneous actor-network, whoseconfiguration changed continuously. Thesechanges are conceptualised as alignmentattempts where the different actants' interestsare translated and inscribed into e.g.artefacts, rules or routines. The alignment ofthis heterogeneous network was achieved througha continuous process of design, test andredesign of different configurations of people,practices and artefacts. The relevance of thefindings is discussed, related to how we maythink about design of open and generictechnologies. Viewing design as design ofconfigurations; the creation of a well-workingmix of people, practices and artefacts, may bea helpful and relevant design metaphor.	actor model;centrality;displacement mapping;emergence;holism;indeterminacy in concurrent computation;iteration;network theory;object linking and embedding;relevance;situated	Margunn Aanestad	2003	Computer Supported Cooperative Work (CSCW)	10.1023/A:1022492210898	psychology;social science;simulation;heterogeneous network;human–computer interaction;telecommunications;computer science;knowledge management;multimedia;communication;configuration;management;social psychology;world wide web;health care	HCI	-60.620885062274574	-39.295587090910715	80048
3ef20e626a5ccbf459ceef8f52a7d8b85f136c73	99designs: an analysis of creative competition in crowdsourced design	99designs;quantitative analysis;crowdsourcing	We provide a study of crowdsourced design based on the popular service 99designs, a website where users create design contests for other users to submit their ideas for evaluation, competing for a monetary amount offered. By quantitatively analyzing a large number of contests, we report on the dynamics of the interactions between contests and designers. We show results on the effects of different financial incentives and contests’ properties on the number and quality of submissions, as well as on how rewards are distributed across designers. We find that higher financial incentives do not translate to more effort by individual designers, but nonetheless have an impact on the quality outcome of contests by attracting a larger pool of designers. We also show that a majority of contests are dominated by a disproportionate few designers, which are both more active and effective in the service.	crowdsourcing;interaction	Ricardo Matsumura de Araújo	2013			simulation;computer science;quantitative analysis;crowdsourcing	HCI	-59.50131210251934	-45.61379038727892	80111
2755183a5dceec4e3ad34893673f2c0ea8e9da13	board game prototyping to co-design a better location-based digital game	serious games;paper prototyping;cultural heritage;historical reflection;location based games;iterative design	In this case study we describe the iterative process of paper prototyping, using a board game, to co-design a location-based mobile application. The end goal of the application is to motivate reflection on historical topics about migration. The board game serves to capture the core concerns of this application by simulating movement through the city. Three play tests highlighted the users' interest and issues with the historical content, the way this content is represented, and the players' responses to the interactions and motivating mechanisms of the application. Results show that the board game helped capture important design preferences and problems, ensuring the improvement of our scenario. This feedback can help reduce development effort and implement a future technology prototype closer to the needs of our end users.	facet (geometry);feedback;futures studies;interaction;iteration;mobile app;paper prototyping;prototype;simulation	Catherine Emma Jones;Antonios Liapis;Ioanna Lykourentzou;Daniele Guido	2017		10.1145/3027063.3053348	video game design;iterative design;game design;simulation;4x;level design;human–computer interaction;computer science;cultural heritage;emergent gameplay;game mechanics;game art design;game developer;multimedia;video game development	HCI	-55.93070867272038	-38.62092794656149	80131
5038ee5396c55e02ed773c608565be1e427ee3ef	psychosocial and cultural modeling in human computation systems: a gamification approach		“Gamification”, the application of gameplay to real-world problems, enables the development of human computation systems that support decision-making through the integration of social and machine intelligence. One of gamification’s major benefits includes the creation of a problem solving environment where the influence of cognitive and cultural biases on human judgment can be curtailed through collaborative and competitive reasoning. By reducing biases on human judgment, gamification allows human computation systems to exploit human creativity relatively unhindered by human error. Operationally, gamification uses simulation to harvest human behavioral data that provide valuable insights for the solution of real-world problems.	gamification;human-based computation	Antonio Sanfilippo;Roderick M. Riensche;Jereme Haack;Scott Butner	2013		10.1007/978-1-4614-8806-4_65	psychology;simulation;knowledge management;social psychology	NLP	-57.43150252850043	-47.37835906734394	80143
4b2d27e84e14b4d8a675bc059ca0c66c9ecb7a7c	getting to know you: relationship between intergroup contact and willingness to interact		While researchers expect it will be technologically possible for robots to be widely available in society in the near future, the public shows negative attitudes toward robots that may impede their acceptance. Intergroup contact theory shows that positive contact with an outgroup reduces prejudice and increases positive emotions towards that outgroup. This was applied to an interaction between a participant and a humanoid robot to determine if those who interacted directly with, including touching, the robot would perceive all robots in a more positive manner and be more willing to interact with them. Results indicated that contact with the robot, compared with the Control condition, produced a marginally higher willingness to interact with robots.	humanoid robot;outgroup (cladistics)	Kathryn Wallisch;Marlena R. Fraune;Selma Sabanovic;Steven Sherrin;Eliot R. Smith	2018		10.1145/3173386.3177017	outgroup;humanoid robot;human–computer interaction;social robot;computer science;robot;prejudice (legal term)	Robotics	-52.111035278502065	-51.075568265534656	80630
c52a9031e05eaf7053c3146997f43e4e30a06dd1	nonspeech sound design for a hierarchical information system	auditory cue;hierarchical information system;novel user interface;information system;sighted user;structural information;user group;human-centered design methodology;visual user interface;nonspeech sound design;sound design methodology;participatory design	This research describes a human-centered design methodology for creating nonspeech sounds to enhance navigation in a visual user interface. This paper describes how the sound design methodology proposed in [10][11] was extended to sonify a novel 3D-visualized information system for sighted users navigating a hierarchical structure. The method ensures that the sounds designed are not based on personal or ad hoc choices, and instead exploits the creativity of a user group as an application of participatory design in sound. Recommendations are derived from this case study on how to design auditory cues for familiar or novel user interfaces to convey structural information in an informative and intuitive way.	information system	Rafa Absar;Catherine Guastavino	2011		10.1007/978-3-642-21753-1_52	speech recognition;engineering;multimedia;communication	EDA	-52.86087803206199	-39.300180523294465	80696
b9cc698b26fa0a832ec28c618edc82e71ecf3711	social common sense modeling of a spread-out queue in public space for a service robot	queue;social service robot;public space;common sense modeling	This paper describes method to model social common sense for an interactive robot that provides customers in a spread-out queue with a service in a public space. Interactive robots that provide services in a public space, such as handing out flyers or touting, have been developed. To provide such services, robot behavior must be appropriate, i.e., comparable to that of a human. Such appropriate behavior is based on social common sense, which is a human concept. However, modeling social common sense when a human provides a service in public space is difficult. This paper focuses on a service, e.g., handing out flyers, provided by a robot to customers waiting in a queue where the order of the queue is unclear. By modeling the unconscious order of the queue as social common sense, we develop a robot that can provide a service in an appropriate order. To model the unconscious order of the queue, the human order is defined by the geometric relationship between a human and a robot and the queue order that an individual recognizes. Through an experiment conducted in a public space, we confirm that the robot with the modeled common sense hands out flyers to customers in an appropriate order. In addition, the robot can give advice to a customer who cuts into the line.	interactivity;service robot	Kana Uotani;Masayuki Kanbara;Shogo Nishimura;Takayuki Kanbara;Satoru Satake;Norihiro Hagita	2017		10.1145/3029798.3038345	simulation;computer science;knowledge management;queue	Robotics	-50.129415243927525	-50.93030121383112	80886
49398ac8240cc77e7119e92d88a2686a9ba95392	ongoing research about the use of commercial-off-the-shelf wrist wearables in educational contexts		In this paper, we present the main achievements and analysis of our ongoing piece of research about the use of wearables in educational contexts. This work has led us to explore the use of wearables in educational environments with the aim of enriching the student profile with new information, such as sleep and stress indicators. These indicators can be estimated through the use of widely available wearable device sensors, namely Commercial-Off-The-Shelf wrist wearables. The first step has been to validate the use of these devices and their sensors as good predictors of stress and sleep. Once this has been validated, we have proposed some indicators that offer the user the opportunity to get information such as the sleepiness quality, the chronotype, the latent stress of the stress regularity. These are different features that contribute to get a better knowledge of the learner and his state. In this paper, we will present the main research lines that make up our project, the elements implemented in our system and how these indicators can be applied in educational environments.	sensor;wearable computer;wearable technology	Francisco de Arriba Pérez;Manuel Caeiro;Juan M. Santos-Gago	2017			multimedia;commercial off-the-shelf;wrist;wearable computer;engineering	HCI	-60.63569339701463	-51.939141185688285	81189
e98b238f9af8e931029cbf9feec6f987392e608c	a note of caution regarding anthropomorphism in hci agents	trust;affect as information;hci;agent;universal usability;anthropomorphism	Universal usability is an important component of HCI, particularly as companies promote their products in increasingly global markets to users with diverse cultural backgrounds. Successful anthropomorphic agents must have appropriate computer etiquette and nonverbal communication patterns. Because there are differences in etiquette, tone, formality, and colloquialisms across different user populations, it is unlikely that a generic anthropomorphic agent would be universally appealing. Additionally, because anthropomorphic characters are depicted as capable of human reasoning and possessing human motivations, users may ascribe undue trust in these agents. Trust is a complex construct that exerts an important role in a user's interactions with an interface or system. Feelings and perceptions about an anthropomorphic agent may impact the construction of a mental model about a system, which may lead to inappropriate calibrations of automation trust that is based on an emotional connection with the anthropomorphic agent rather than on actual system performance.	human–computer interaction	Kimberly E. Culley;Poornima Madhavan	2013	Computers in Human Behavior	10.1016/j.chb.2012.11.023	psychology;simulation;computer science;universal usability;communication;trustworthy computing;social psychology	HCI	-52.65160922190794	-51.823041890686284	81192
40aaed75c4158931104f93efe17db484eb0a1c68	real-time wordometer demonstration using commercial eog glasses		"""Reading is an important part of our everyday life. Most of us read every day at work, in the transportation, at home, etc. Except by counting the number of books a person read in a year or a month, it is very hard to quantify reading. We want to create a """"wordometer"""" that counts how many words a user read. Such an application could encourage people to read more, just like pedometers encourage to walk more. We propose a demonstration of such a system based on eye movements analysis extracted from EoG glasses."""	book;real-time transcription	Hitinui Robert;Koichi Kise;Olivier Augereau	2017		10.1145/3123024.3123183	computer science;electrooculography;simulation;everyday life	HCI	-51.97799793568938	-43.295014268551895	81218
6a589a768f9e56fb06e9aa9a975e6fca74644f03	crafting the initial user experience to achieve community goals	online communities;control group;selected works;user interface;user preferences;field experiment;online community;recommender system;user experience;bepress;new user problem;user behavior;entry barrier;user interfaces;tagging	"""Recommender systems try to address the """"new user problem"""" by quickly and painlessly learning user preferences so that users can begin receiving recommendations as soon as possible. We take an expanded perspective on the new user experience, seeing it as an opportunity to elicit valuable contributions to the community and shape subsequent user behavior. We conducted a field experiment in MovieLens where we imposed additional work on new users: not only did they have to rate movies, they also had to enter varying numbers of tags. While requiring more work led to fewer users completing the entry process, the benefits were significant: the remaining users produced a large volume of tags initially, and continued to enter tags at a much higher rate than a control group. Further, their rating behavior was not depressed. Our results suggest that careful design of the initial user experience can lead to significant benefits for an online community."""	movielens;online community;recommender system;user (computing);user experience	Sara Drenner;Shilad Sen;Loren G. Terveen	2008		10.1145/1454008.1454039	user;user experience design;user modeling;computer user satisfaction;human–computer interaction;user journey;computer science;user requirements document;unique user;multimedia;user interface;world wide web;recommender system	HCI	-55.76108221012201	-43.25465187884719	81246
d9501171c4888abbc44785f79de140724e44290a	user-driven applications	human computer interaction	User-driven applications are the programs, in which the full control is given to the users. Designers of such programs are responsible only for developing an instrument for solving some task, but they do not enforce users to work with this instrument according with the predefined scenario. Users’ control of the applications means that only users decide at any moment WHAT, WHEN, and HOW must appear on the screen. Such applications can be constructed only on the basis of moveable / resizable elements. Programs, based on such elements, have very interesting features and open absolutely new possibilities. This article describes the design of the user-driven applications and shows the consequences of switching to such type of programs on the samples from different areas.		Sergey Andreyev	2010	CoRR		simulation;human–computer interaction;computer science;operating system	PL	-51.66825833259969	-38.638070017056066	81405
3fbb8feba1ae094e59cf3131615d7b7c9fbd5274	giok the alien: an ar-based integrated system for the empowerment of problem-solving, pragmatic, and social skills in pre-school children	augmented reality;children;communication disorders;cooperative games;empowerment;interactive learning environments;pragmatic skills	The use of technology for educational purposes is a consolidated reality, and many new tools are constantly being devised and offered for use with both normally developing children and children with special needs. Nonetheless, a detailed analysis of the processes being stimulated and of the goals being pursued is often lacking or absent. In this work we describe the design, development and preliminary testing of an integrated system which combines the use of smart devices, a physical cube, augmented reality (AR) technology, a smart TV, and a software application especially designed to stimulate cognitive and social functions in pre-school children. The system was tested with three groups of children (25 children in total) during kindergarten activities. The results show that the system is easy to understand, elicits high levels of participation and social interaction, favors strategic behaviors, and can be used by the children with limited need of instruction and support by the adult. The implications for empowerment in typically developing children and the possibilities for use with children who have specific impairments in social communication are discussed.	alien;augmented reality;behavior;child, preschool;cognition disorders;conceptualization (information science);data curation;digital curation;frozen erythrocytes pediatric units given:num:pt:^bpu:qn;gilles de la tourette syndrome;linear algebra;problem solving;sensor;smart tv;smart device;tangible user interface	Maria Luisa Lorusso;Marisa Giorgetti;Simona Travellini;Luca Greci;Andrea Zangiacomi;Marta Mondellini;Marco Sacco;Gianluigi Reni	2018		10.3390/s18072368	engineering;pedagogy;electronic engineering;alien;augmented reality;social skills;empowerment	HCI	-57.337478034138094	-51.578691769027415	81451
46c899244b29120cd486c93423eac6c6b21ab72c	learning sign language from a social robot peer by playing an interactive game	robot sign recognition sign language learning social robot peer interactive game sign language tutoring sl tutoring communication impairments robovie r3 humanoid robot hand movements body gesture face gesture led dof wrist independent fingers colored flashcard recognition rgb d camera based system one to one play paper based test hearing impaired children;computers;humanoid robots;games;games humanoid robots assistive technology gesture recognition face computers;assistive technology;face;sign language recognition cameras computer aided instruction computer games control engineering computing dexterous manipulators handicapped aids humanoid robots interactive systems robot vision;gesture recognition	Summary form only given. This work presents a humanoid robot assisted interactive game for Sign Language (SL) tutoring. The game is specially designed for children with communication impairments. The children play the game with a modified Robovie R3 humanoid robot which is able to express a set of chosen words in SL using hand movements, body and face gestures. The robotic platform is specially modified with LEDs in face, additional DOFs in wrist and 5 independent fingers at hands for robust SL generation. The robot is able to communicate with the children by recognizing colored flashcards through a RGB-D camera based system and generating a selected subset of signs, including motivating facial gestures, in return. The presented game is composed of three stages: 1) Introduction of the selected signs to a group of children, 2) Each child's one-to-one play with the robot using flashcards 3) Paper-based test to evaluate the recognition of the signed demonstrated by the robot. Current video presents Screenshots from a preliminary study with a group of hearing-impaired children (7-14 years), where children had almost 100% score in recognizing the robot's signs from a subset of 10 words.	flexos;humanoid robot;one-to-one (data model);sl (complexity);screenshot;social robot	Pinar Uluer;Neziha Akalin;Hatice Kose-Bagci	2014	2014 IEEE-RAS International Conference on Humanoid Robots	10.1109/HUMANOIDS.2014.7041397	face;games;computer vision;simulation;computer science;humanoid robot;artificial intelligence;social robot;gesture recognition	Robotics	-49.3578348572578	-49.12354293797992	81788
680eb3128dcf4bafbac28713d5cd306c6da494d8	designing for ease is designing for all: experiences from a simplified office suite	disabled people;metaphors;user interface;reference point;design for all;assistive technology;office equipment;user interfaces	Aims to present the work done in the development of a simplified office suite for disabled and focus on the use of technology applied to the area of “designing for all”. The paper presents an overview of the state‐of‐the‐art in the design for all. It provides practical references to techniques used. The main scope of the paper is to explore the developed technology and give details for the adopted mechanisms. It provides information about designing and implementing software applications for disabled and present a case study for mentally disabled. The paper presents a system that can be used by a specific target group. For this reason, it should be used as reference point for this group, although several techniques can be used for other user categories. The paper is a very useful presentation of an actual system that has been designed and implemented to cover the needs of disabled, useful for interaction with designers and researchers in assistive technology, and it fulfils the need for demonstrative techn...		Panagiotis Destounis;John D. Garofalakis;George Mavritsakis;Maria Rigou;Spiros Sirmakessis;Giannis Tzimas	2004	IT & People	10.1108/09593840410554193	simulation;human–computer interaction;computer science;engineering;multimedia;user interface	HCI	-49.56014732674053	-40.62654093856273	82119
14c8fb54361652bfee4bec896d63bd1c76cc9fcb	extraversion affects attentive processes of personal images		Personality traits are an important part of the psychology with so many study to consider this actually a huge field. On the other hand, the relationship between personality traits and attentional process has not been deepen extended yet, above all using technological advanced measures to quantify attention. In this study we selected personal and neutral photos presenting all of them to the participants while tracking the eyes movements by using an eye-tracker. Results showed that personal images have in general higher number of fixation and more saccades. Specifically, while extroverts showed no differences in exploring personal and neutral photos, introverts participants showed an higher number of fixations and more saccades for personal images than neutral. These results if confirmed in further studies pone interesting questions about the role of personality in attentional processes linked to personal experiences.		Pietro Cipresso;Diego Soto Gómez;Giuseppe Riva;Emanuela Saita	2018		10.1007/978-3-030-01093-5_2	distributed computing;psychometrics;computer science;cognitive psychology;big five personality traits;personality;fixation (psychology);personal experience;extraversion and introversion;eye tracking	Robotics	-55.067079873032654	-49.253729496852124	82148
3d247f2a33f73e30e854bb475880e2582ff6fbe7	body-technology interfaces	craft;cultural computing;personal narratives;critical design;participatory design	Our interactions with personal electronic devices provoke a broad range of emotional states from frustration to confusion to feverish obsession. Increasingly, these devices mediate our everyday work activities, our social network development and our personal communications. In this paper, we propose a participatory installation that aims to bring critical awareness and consideration to the complex relationship between people and their technological artifacts. Based on participant interview data, we will create Body-Technology Interfaces’ in the form of hand-knitted custom wrappers for personal electronic devices. Each BTI will reflect salient interaction behaviors between the participant and their chosen device. Analyzed participant interview data, BTI designs and overall participant response to the project will be documented and shared online.	btrieve;interaction;obsession (video game);social network	Rebecca P. Stern;Aisling Kelliher	2008		10.1145/1795234.1795321	social science;simulation;human–computer interaction;computer science;engineering;management;social psychology;mechanical engineering	HCI	-60.21582252993725	-38.823583299584485	82315
9d04f46706bcc1b235ff056f859333732dda53ec	programming for usability in nonvisual user interfaces	user interface;user interface software;software engineering;evaluation;nonvisual user interfaces	2. INTRODUCTION Nonvisual user interfaces have been implemented since alternatives to the visual presentation have become available. Unlike multimedia systems are nonvisual user interfaces dedicated to be usable with or without a visual presentation. The increase in applications with a pure nonvisual user interface as for example web browsers, newspaper reading programs, document reading programs or mobility aids for visually impaired people has made it possible to generalize about the various approaches used to generate a nonvisual user interface.	usability;user interface	Gerhard Weber	1998		10.1145/274497.274507	user interface design;look and feel;user;10-foot user interface;user experience design;user modeling;human–computer interaction;computer science;evaluation;monolithic application;event-driven programming;natural user interface;user interface;heuristic evaluation;graphical user interface testing	HCI	-49.28713273192386	-40.62636761182392	82442
5f4e6135f4beded036c8cb507f4b6ffc6f008794	supporting salespersons through location based mobile applications and services	location service;work environment;information overload;mobile application	The paper aims at assessing how mobile location applications and services can support salespersons‚ for greater performance when they are operating within a mobile work environment. After briefly discussing the state of the art issues associated with mobile location technologies‚ the paper conceptualises key dimensions of location-based mobile support. The paper then suggests a categorization of salespersons tasks based on both properties of location-based mobile support and the areas of salespersons tasks that may be affected by mobile location technologies. A third section suggests potential mobile location services and applications that can support salespersons in performing effectively their everyday tasks and links such applications to the determinant of salespersons’ performance. The paper concludes with a discussion of a number of critical issues such as salespersons privacy‚ risk of information overload‚ autonomy and some core areas of further research.	angular defect;autonomy;categorization;information overload;location-based service;mobile app;requirement	Chihab BenMoussa	2004		10.1007/1-4020-8155-3_9	mobile search;human–computer interaction;operations management;location-based service;mobile computing;world wide web	HCI	-59.860213165115255	-41.636595872268416	82462
5f39263cb42390d71e812b599226486476e034be	the influence of virtual agents on player experience and performance	performance;social facilitation;social impact;player experience;virtual agent	This paper contributes a systematic research approach as well as findings of an empirical study conducted to investigate the effect of virtual agents on task performance and player experience in digital games. As virtual agents are supposed to evoke social effects similar to real humans under certain conditions, the basic social phenomenon social facilitation is examined in a testbed game that was specifically developed to enable systematical variation of single impact factors of social facilitation. Independent variables were the presence of a virtual agent (present vs. not present) and the output device (ordinary monitor vs. head-mounted display). Results indicate social inhibition effects, but only for players using a head-mounted display. Additional potential impact factors and future research directions are discussed.	entity;futures studies;game mechanics;gender hci;head-mounted display;intelligent agent;output device;testbed;virtual reality	Katharina Emmerich;Maic Masuch	2016		10.1145/2967934.2968092	simulation;engineering;multimedia;social psychology	HCI	-53.711804723647774	-50.14770545381268	82506
c5466bc7184552c2ee3fb78671e25d93a87e0b89	designing smartphone feedback based on vibration impression	vibration pattern;impression;feedback design;user defined vibration;smartphone	The existing vibration feedback patterns on touchscreen devices are simple. Similar patterns are adopted for different contexts. Designing appropriate patterns suitable for specific contexts is a meaningful issue. In order to design new patterns, this study investigated the impression of user-generated vibration patterns. We first collected various types of user-defined patterns. Then, the impressions of the collected patterns were quantified by subjective evaluations. The relationship between the impressions and vibration pattern features was analysed. The results reveal features relevant to user impression. This study presents design guidelines for vibration patterns based on these results.	impression (online media);smartphone;touchscreen;user-generated content	Shota Shiraga;Yuichiro Kinoshita;Kentaro Go	2016		10.1145/2851581.2892430	embedded system;simulation;multimedia	HCI	-56.473621441445545	-45.249925001817374	82670
406c0b9efaf97c3c3d9f4fc5f4fc71f968dc757a	building on the usability study: two explorations on how to better understand an interface	usability study;user experience	In this paper, we describe two separate studies that improved our ability to understand our users’ experience of our products at salesforce.com. The first study explored a methodology of combining expert and novice performance data to yield a measure of intuitiveness. The second study created a methodology that combines both verbal and nonverbal emotion scales to better understand the emotional effect our products have on our users. We present both these methods as expansions on the standard usability study and examples of ways to better understand your users within an industry environment.	marginal model;usability testing;user experience	Anshu Agarwal;Madhu Prabaker	2009		10.1007/978-3-642-02574-7_43	usability goals;pluralistic walkthrough;cognitive walkthrough;user experience design;human–computer interaction;computer science;knowledge management;usability engineering;multimedia;usability lab	HCI	-60.120284853047345	-46.59588397365243	82696
d348f0c9eddf6bef100e70c43d30f041778430b9	designing and equipping a usability laboratory	etude utilisation;laboratory study;etude en laboratoire;evaluation systeme;concepcion ingenieria;engineering design;exigence;laboratory equipment;recoleccion dato;data gathering;operating conditions;conception ingenierie;reaccion utilizador;relacion hombre maquina;information technology;evaluacion sistema;data capture;man machine relation;technologie information;work environment;requirement;ensayo laboratorio;user reaction;equipo laboratorio;laboratory test;system evaluation;reaction utilisateur;condition operatoire;cd93 9 dlj neologisme cree pour usability;exigencia;utilisabilite;environnement physique;user centred design;physical environment;relation homme machine;essai laboratoire;tecnologia informacion;usability;medio ambiente fisico;condicion operatoria;collecte donnee;equipement laboratoire;use study;estudio en laboratorio	The goal of usability lab design is to create a space where high quality data captureoccurs in an environment that looks and feels like the workplace of the product that is being tested. The lab must be part recording studio and part flexible work environment. Since most work environments are not recording studios, achieving a balance between simulation of the work environment and high quality data capture presents a challenge to usability lab designers. Steps can be taken with a user-centred design process to insure that a usability lab design meets this goal. This paper describes such a usercentred design process and how it. in combination with practical architectural and equipment guidelines derived from the authors' past experience, can be used in the design and redesign of future labs. The authors also discuss what changed in the present lab at NCR as a result of these guidelines.	display resolution;numeric character reference;simulation;usability lab;user-centered design	Louis Blatt;Mark Jacobson;Steve Miller	1994	Behaviour & IT	10.1080/01449299408914587	usability goals;pluralistic walkthrough;web usability;simulation;usability;computer science;engineering;requirement;usability engineering;automatic identification and data capture;information technology;usability lab;statistics;usability inspection;data collection;mechanical engineering	HCI	-62.76937329574842	-49.20615538543805	82865
7c2d49baee5f1027dca6df00d2bba3a5353faf70	modeling user satisfaction from the extraction of user experience elements in online product reviews		With the abundance of product reviews available online, online review data represent invaluable resources for understanding the user experience of various products in their real usage environments. Extant online review studies have considered UX elements mostly related to emotions. We collected 64,772 sentences from 4,380 online reviews of three electronic products, and analyzed the content of the online reviews using LIWC in order to extract various UX elements going beyond emotions. The study results show that UX elements extracted from online reviews had significant effects on user satisfaction. In addition to the emotional factors (hedonic, user burden), the results show that expectation confirmation and pragmatic factors play significant roles in determining user satisfaction.	a/ux;user experience	Jincheul Jang;Mun Yong Yi	2017		10.1145/3027063.3053097	user interface design;user experience design;user modeling;computer user satisfaction;human–computer interaction;computer science;knowledge management;multimedia	Web+IR	-58.922749580102796	-46.02853421858529	82939
fdbb48c332baa3ab5db1fb1c83615da97be3a42f	lyssna: a design fiction to reframe food waste	smart environments connected home;sustainability;behavior change;home	In this paper we propose the design fiction, Lyssna, a diegetic prototype in the form of a hearing aid for your refrigerator that aims at reintegrating lost aspects of food. Lyssna is based on home studies of food practices informed by Mediation Theory and Theories of Practice. Our aim is to explore an alternative framing from behavioral theories for designing for food waste. In the process, we hope to open up the design space for enabling reconfigurations of everyday food practices.	framing (world wide web);prototype	Doenja Oogjes;Miguel Bruns Alonso;Ron Wakkary	2016		10.1145/2908805.2909401	simulation;engineering;behavior change;sustainability	HCI	-60.171672721993446	-38.19138861586845	83027
5562effbe51ef776d90f674511ba2f80e6a4389c	how effective is it to design by voice?	crowded graphical interface;independent group;graphically crowded user-interfaces;usability problem;typical common graphical metaphor;fertile environment;experimental interface design toolkits;limited use;interface design environments;multimodal interaction metaphor;interface design;interactive visualization;multimodal interaction;graphical interface;user interface;information overload	Previous studies on usability of crowded graphical nterfaces that are full of widgets like menus, buttons, palet te-tools etc, have shown evidence that they create a fertile envi ro ment for information overload and usability problems. In thi s paper, we investigate the use of multimodal interaction metap hors (visual, vocal and aural) for improving effectiveness of lea rning functions and completing tasks in one of the most g raphically crowded user-interfaces, the user-interface of IDEs (or Interface Design Environments). This investigation was done e mpirically on two experimental interface design toolkits (TVOI D and MMID) which were built especially for the study. As sessment of the visual and multimodal interaction metaphors was carried out by two independent groups of users (A and B) of which each consisted of 15 users. Results showed that the use of speech for input and output along with limited use of the mouse was more effective than interacting visually only u sing the typical common graphical metaphors: pull-down menus , toolbar, toolbox, properties-table and status-bar.	graphical user interface;information overload;input/output;integrated development environment;list of toolkits;multimodal interaction;usability	Mohammad M. Alsuraihi;Dimitris I. Rigas	2007		10.1145/1531407.1531449		HCI	-48.595445933297775	-45.251301349858714	83126
0337bddb120d16c2a6a0793745e3dab142a1d728	psychological responses to simulated displays of mismatched emotional expressions	cognitive dissonance;repeated measures;virtual human;hci;embodied agents;emotion;virtual humans;characters;affective computing;embodied agent;emotional expression	Embodied agents are often designed with the ability to simulate human emotion. This paper investigates the psychological impact of simulated emotional expressions on computer users with a particular emphasis on how mismatched facial and audio expressions are perceived (e.g. a happy face with a concerned voice). In a within-subjects repeated measures experiment (N = 68), mismatched animations were perceived as more engaging, warm, concerned and happy when a happy or warm face was in the animation (as opposed to a neutral or concerned face) and when a happy or warm voice was in the animation (as opposed to a neutral or concerned voice). The results appear to follow cognitive dissonance theory as subjects attempted to make mismatched expressions consistent on both the visual and audio dimensions of animations, resulting in confused perceptions of the emotional expressions. Design implications for affective embodied agents are discussed and future research areas identified.	embodied agent;simulation;user (computing)	Chris Creed;Russell Beale	2008	Interacting with Computers	10.1016/j.intcom.2007.11.004	emotion;embodied agent;computer science;emotional expression;artificial intelligence;affective computing;cognitive dissonance	HCI	-52.196640030891565	-49.44921006528971	83176
29345bca26eb5013ac48333d921c34742abf6c1a	emotional sharing behavior for a social robot in a competitive setting	robot sensing systems;atmospheric measurements;particle measurements;human robot interaction;distance measurement;games	Is a robot that shares explicitly its emotions with users more believable and friendly? In a previous study addressing this question, results suggested that an emotion sharing feature in a robot may have negative effects in the perception of that robot. Here, we address the same question but also take into account the “competence” of a robot executing a task, to understand if some kind of interaction occurs.	social robot	Sofia Petisca;João Dias;Patrícia Alves-Oliveira;Ana Paiva	2016	2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2016.7745200	human–robot interaction;robot learning;games;simulation;computer science;artificial intelligence;social robot;multimedia;mobile robot navigation;personal robot	Robotics	-51.84537694491407	-50.36623654052972	83296
b03c71939ec9a87feee044a195171992078760ca	the dynamics of film-induced affect and its effect on the interaction with tablet pcs	human computer interaction;temporal dynamics;affect;user experience;mobile devices	Affective states have become a crucial part of human–computer interaction research. Many studies have analysed the impact of the technology on the users' affective states as a part of what is called user experience UX. We consider the impact of antecedent affective states on interaction with a technological artefact. We induced positive and negative affective states using film clips. Then we analysed the impact of affects on the subsequent interaction with a tablet PC. Results show that positive and negative affective states have different emotional activation patterns. Positive affect was more sensitive for changes in tasks and experimental setting. In addition, these activation patterns affected behaviour for a short time only. These findings are discussed against the background of research into UX dynamics, dynamics of affect, and user-centred design research.	tablet computer	Stefan Brandenburg;Nils Backhaus	2016	Behaviour & IT	10.1080/0144929X.2016.1151076	psychology;user experience design;simulation;human–computer interaction;computer science;mobile device;multimedia;affect	HCI	-57.57110433271138	-46.39671516548373	83458
36a991c9492157635e7129a5e9e28fefbb2df26e	realizing robust human-robot interaction under real environments with noises	human robot interaction;spoken dialogue systems	A human speaker considers her interlocutor's situation when she determines to begin speaking in human-human interaction. We assume this tendency is also applicable to human-robot interaction when a human treats a humanoid robot as a social being and behaves as a cooperative user. As a part of this social norm, we have built a model of predicting when a user is likely to begin speaking to a humanoid robot. This proposed model can be used to prevent a robot from generating erroneous reactions by ignoring input noises. In my Ph.D. thesis, we will realize robust human-robot interaction under real environments with noises. To achieve this, we began constructing a robot dialogue system using multiple modalities, such as audio and visual, and the robot's posture information. We plan to: 1) construct a robot dialogue system, 2) develop systems using social norms, such as an input sound classifier, controlling user's untimely utterances, and estimating user's degree of urgency, and 3) extend it from a one-to-one dialogue system to a multi-party one.	dialog system;dialog tree;humanoid robot;human–robot interaction;norm (social);one-to-one (data model);poor posture	Takaaki Sugiyama	2014		10.1145/2663204.2666283	human–robot interaction;computer vision;simulation;speech recognition;human–computer interaction;computer science;artificial intelligence;social robot;machine learning	Robotics	-51.08176230850247	-49.5772786146617	83471
9ce6730aedbd4b6e05f157397be05b33893bd69f	a multimodal perception framework for users emotional state assessment in social robotics		In this work, we present an unobtrusive and non-invasive perception framework based on the synergy between two main acquisition systems: the Touch-Me Pad, consisting of two electronic patches for physiological signal extraction and processing; and the Scene Analyzer, a visual-auditory perception system specifically designed for the detection of social and emotional cues. It will be explained how the information extracted by this specific kind of framework is particularly suitable for social robotics applications and how the system has been conceived in order to be used in human-robot interaction scenarios.	artificial intelligence;experiment;humanoid robot;human–robot interaction;multimodal interaction;robotics;social robot;synergy;unobtrusive javascript	Lorenzo Cominelli;Nicola Carbonaro;Daniele Mazzei;Roberto Garofalo;Alessandro Tognetti;Danilo De Rossi	2017	Future Internet	10.3390/fi9030042	computer science;social robot;simulation;perception;human–robot interaction	Robotics	-51.751779983080766	-46.13950615637787	83488
2553a04279db808128d6fb8e29f12a79be723a03	moccha: a mobile campus app for analyzing user behavior in the field	app store;ecological validity;mobile applications;user behavior;field study	In this paper, we present MoCCha, a mobile campus application used not only as a subject of research, but as a research platform for a number of scientific disciplines. Using apps that are available from mobile application stores enables studying user behavior in the field with the aim for ecological validity that human-subject studies in lab environments are potentially missing.	mobile app	Tilo Westermann;Sebastian Möller	2012		10.1145/2399016.2399154	mobile search;human–computer interaction;ecological validity;multimedia;world wide web;field research	HCI	-56.435944811511796	-42.30844017581133	83609
03286273c2a83199dfcac5032f466453be728699	learning from failure: designing for complex sociotechnical systems		As ubiquitous computing solutions are becoming part of everyday life, their design has to account for the challenges of complex sociotechnical systems. Unexpected behavior and interactions between multiple systems, users and stakeholders challenge design methods and raise the risk of failure. This workshop provides an opportunity for the UbiComp community to reflect on these failures and juxtapose them with human-centered design methods. Through short participant authored failure reports, hands-on design sessions in groups and all-group discussion, we will share challenges and reflect on lessons learned for the design of complex sociotechnical systems.	hands-on computing;interaction;sociotechnical system;ubiquitous computing;user-centered design	Lars Müller;Matthias Budde;Nadir Weibel;Eliah Aronoff Spencer;Michael Beigl;Don Norman	2017		10.1145/3123024.3124460	ubiquitous computing;human–computer interaction;sociotechnical system;design methods;computer science;everyday life	HCI	-60.536675131018136	-39.98420956085452	83678
d3f0c8153a0067354b61d9649ad86daef069876e	avatar creation and video game enjoyment	verlagswesen;video games;satisfiability;video game;enjoyment;journalismus;life satisfaction;identification;070 nachrichtenmedien;avatar;computer game	Based on the model of complex entertainment experiences (Vorderer, Klimmt, & Ritterfeld, 2004), the competitiveness of a computer game (media prerequisite) and the individual life satisfaction (user prerequisite) are hypothesized to influence game enjoyment. Avatar-player similarity was hypothesized to determine identification with the avatar, which in turn was suggested to enhance the enjoyment experience. In a quasi-experimental study, (N = 666) participants were asked to choose the personality features of an avatar for six different game scenarios. The results demonstrate that the games’ competitiveness as well as the participants’ life satisfaction influenced avatar choice and identification. In noncompetitive games, similar avatars were created, whereas in competitive games, dissimilar avatars were created. Participants who were well satisfied with their lives created avatars that resemble themselves in terms of personality factors, whereas dissatisfied users created dissimilar avatars. Player-avatar...		Sabine Trepte;Leonard Reinecke	2010	J. Media Psychology	10.1027/1864-1105/a000022	psychology;identification;game design;simulation;game mechanics;multimedia;social psychology;satisfiability	HCI	-56.60270801416267	-48.87358251928739	83774
20adbe62eaf46b8f490c50dd5713d7940fedee04	visualizing ambivalence: showing what mixed feelings look like	likert;ambivalence;small multiples;d3;public opinion;visualization;mixed feelings;storytelling	Measures of ambivalence in public opinion have grown in prominence in recent years within a variety of fields because of evidence that they may better represent how people hold opinions than traditional Likert-type scales. Rather than assume people hold only positive or negative feelings toward a person or issue, these measures assume positive and negative feelings may co-occur as mixed feelings. Using information visualization and interactive storytelling techniques, we aim to show a broad audience how ambivalence data might be interpreted and demonstrate the utility of measuring ambivalence. Our resulting visualization, MixedFeelings.us, shows data from a survey of undergraduates on 14 topics of public interest and uses design elements like small multiples and animation as well as brief narratives to illustrate core concepts.	information visualization;interactive storytelling;small multiple	Galen Panger;Bryan Rea;Steven Weber	2013		10.1145/2468356.2468540	visualization;ambivalence;public opinion;multimedia;likert scale	HCI	-57.56880124413784	-39.79786434458976	83776
c4fb2de4a5dc28710d9880aece321acf68338fde	interactive generative adversarial networks for facial expression generation in dyadic interactions		A social interaction is a social exchange between two or more individuals, where individuals modify and adjust their behaviors in response to their interaction partners. Our social interactions are one of most fundamental aspects of our lives and can profoundly affect our mood, both positively and negatively. With growing interest in virtual reality and avatar-mediated interactions, it is desirable to make these interactions natural and human like to promote positive effect in the interactions and applications such as intelligent tutoring systems, automated interview systems and e-learning. In this paper, we propose a method to generate facial behaviors for an agent. These behaviors include facial expressions and head pose and they are generated considering the users affective state. Our models learn semantically meaningful representations of the face and generate appropriate and temporally smooth facial behaviors in dyadic interactions.	avatar (computing);dyadic transformation;facial recognition system;generative adversarial networks;intelligent agent;interaction;temporal logic;usability testing;virtual reality	Behnaz Nojavanasghari;Yuchi Huang;Saad M. Khan	2018	CoRR		mood;adversarial system;generative grammar;machine learning;artificial intelligence;social relation;computer science;facial expression;affect (psychology);social exchange theory	ML	-55.424684861375624	-49.12438048173747	83800
3a15bbe58293c9fa159568aa1bed896de9328a1b	multimodal interactive e-learning : an empirical study : an experimental study that investigates the effect of multimodal metaphors on the usability of e-learning interfaces and the production of empirically derived guidelines for the use of these metaphors in the software engineering process			experiment;multimodal interaction;software development process;software engineering;usability	Marwan Alseid	2009			empirical research;multimedia;human–computer interaction;usability;software development process;computer science	SE	-62.663665610758926	-46.336612331930695	83971
76e0afad6b9e5c3a92c0c5068addbdb24cf9935b	user experience changing patterns of chinese users		This study examined the differences between pragmatic and hedonic users for their experience changing over time. Two questions were probed in this study. We first compared two user experience changing patterns (i.e., how the quality of users’ experience develops over time) between pragmatic and hedonic users in 4 weeks usage. Then, we studied how each phrase in the user experience changing patterns contributed to the overall perceived quality of products. Our results found that: (1) user experience changing patterns of Chinese users (Orientation and Identification) were different from western users (Orientation, Identification, and Incorporation); (2) user experience changing patterns were different between pragmatic (Orientation, Incorporation, and Identification) and hedonic users (Exploration and Identification); (3) changes on deciding factors to the overall products perceptions was derived by phrase transitions: utility and identification influenced long-term product perceptions by pragmatic users, while personal needs satisfaction influenced long-term product perceptions by hedonic users.	user experience	Yanan Chen;Jing Liu;Guozhen Zhao;Xianghong Sun	2016		10.1007/978-3-319-40355-7_33	user journey	HCI	-58.858867861553684	-45.960484024935944	84044
78e34b5efe93c1aa49a4d4195adb739693acde00	overlaying paper maps with digital information services for tourists	value added services;interactive paper;information service;digital mapping	Despite the increasing availability of various forms of digital maps and guides, paper still prevails as the main information medium used by tourists during city visits. The authors describe how recent technologies for digitally augmented paper maps can be used to develop interactive paper maps that provide value-added services for tourists through digital overlays. An initial investigation into the use of these maps to support visitors to the Edinburgh festivals is also presented.	cartography;digital rights management;map;personal digital assistant;point of view (computer hardware company);speech synthesis;usability testing	Moira C. Norrie;Beat Signer	2005		10.1007/3-211-27283-6_3	digital mapping;multimedia;advertising;world wide web	HCI	-55.43121412719678	-39.2621058294487	84072
1149cc5a76fe29384fa34ca55dbe324fdaf25c45	self-service systems: new methodology reveals customer real-time actions during merger	automatic teller machine;prediccion;libre service;erreur;banking industry;human computer interaction;service system;sex;new information communication technology;red www;real time;relacion hombre maquina;tacit knowledge;procedural and tacit knowledge;reseau web;hombre;man machine relation;sexe;age;autoservicio;cognitive aging;real time data;capital investment;self service;practical intelligence;human;knowledge transfer;world wide web;procedural knowledge;profitability;nouvelle technologie information communication;relation homme machine;error;point of view;software design;atm;sexo;prediction;nueva tecnologia informacion comunicacion;homme;edad	Automatic teller machines (ATMs) being developed today may astonish customers. Some of these sophisticated new ATMs deliver full banking services, dispense theater tickets, and cruise the World Wide Web. What may be more striking is the fact that, since the inception of ATMs 30 years ago, bankers, developers, and deployers have not had precise information on how clients perform in real time when using even the simplest ones. Consequently, from the point of view of cognitive research, it is not surprising that, although the banking industry has considerable capital investment tied up in ATMs, banks do not obtain the desired returns. ATMs would need to be utilized more often and for more profitable transactions, which generally means more cognitively demanding ones, in order to bring in profits. To accomplish that mission, designers and bankers need precise information about what customers really do when using the machines. This paper discusses a study conducted with a new methodology that allows the capture of relevant, detailed, and real-time data from electronic self-service systems. That same methodology can be applied to businesses as diverse as airlines, hotels, internet transactions, and many others. In our study, the data were collected during the challenging times of a merger of two large international banks that jointly have over 550,000 customers and 1000 ATMs. A sample of 15,099 users, ages 16–79 years old, participated. These customers performed 60,259 financial transactions during their 44,435 visits to 103 ATMs in 22 days. Accuracy, as measured by success and errors in obtaining the desired outcome, and time spent with input, measured on-line in milliseconds, were the dependent variables. The data were cross-referenced to identify education, gender, age, experience, and other demographic variables. The implications of the findings for the study of human– computer interaction, practical intelligence, and procedural knowledge are discussed. # 2003 Elsevier Ltd. All rights reserved.	atm turbo;cognition;dependent ml;experience;human–computer interaction;information;line level;online and offline;online banking;point of view (computer hardware company);point of sale;real-time clock;real-time computing;real-time data;real-time locating system;world wide web	Regina Colonia-Willner	2004	Computers in Human Behavior	10.1016/j.chb.2003.10.017	psychology;real-time data;social science;simulation;prediction;computer science;software design;sex;atmosphere;procedural knowledge;social psychology;operations research;world wide web;statistics;profitability index;service system	HCI	-60.88478500833046	-49.30164925399763	84189
a9e4ef4ecbfccd51d207de3af0f1ac644fdd1f4c	listening to vs overhearing robots in a hotel public space	significant difference;following type;interactive functionalities;hotel public space;human-robot interaction;direct interaction;preliminary work;smaller-sized robot;conversational ability;indirect interaction;elevators;robot kinematics;human robot interaction	This report presents preliminary work performed using robots with different socially interactive functionalities in a hotel public space in order to investigate human-robot interactions (HRI). We developed robots that enable the following types of interactions: (i) indirect interaction, where twin robots (Gemini), with body-movement and conversational ability, engage in a conversation and guests can gather information through overhearing the robots, and (ii) direct interaction, where a smaller-sized robot (Palro), that can detect the presence of guests, greets them directly. In both cases, guest-behavior is studied using four categories that define the levels of a guest's response toward the robots. Several significant differences among the levels of attention paid by the guests to the robots are observed in the experiments.	experiment;human–robot interaction;robot	Yadong Pan;Haruka Okada;Toshiaki Uchiyama;Kenji Suzuki	2013	2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)		human–robot interaction;mobile robot;tico robot;simulation;computer science;artificial intelligence;social robot;robot control;personal robot	Robotics	-51.49200372849308	-50.14089352215729	84272
d5f29567befb6a329a4a09fda22fbb16e64499d6	virtual reality as a communication process	realism;semiotics;virtual reality;communication	In this work, we consider immersive Virtual Reality (VR) as a communication process between humans, mediated by computer systems, which uses interaction, visualization, and other sensory stimuli to convey information. From this viewpoint, it is relevant to understand how VR can solve a given communication problem, what is therefore the expressive power of VR system, i.e., its ability in establishing the communication, what are the guidelines to design an effective system, and what are the more relevant models of VR applications. Firstly, we try to clarify the notion of reality in Virtual Reality systems and conclude that reality is not an intrinsic characteristic of VR, rather the result of a conventional way of coding information. The purpose of coding is to lead the observer to the conclusion that the VR set is what is called in italian as verisimile (from Latin veri similis), i.e., “similar-to-the-real-thing”. So the creation of an effective VR application is an artifice or an illusion. But in order to avoid an over-reliance on the creativity of the VR designer, we intend to identify a solid ground on which different kinds of VR solutions can be considered in terms of their ability to solve the desired communication objective. To this aim, we will rely on methods derived from rhetoric to semiotics.	coherence (physics);criticality matrix;desktop computer;haptic technology;head-mounted display;human–robot interaction;immersion (virtual reality);level of detail;semiotics;simulation;virtual reality	Daniele Marini;Raffaella Folgieri;Davide Gadia;Alessandro Rizzi	2011	Virtual Reality	10.1007/s10055-011-0200-3	computer-mediated reality;simulation;computer science;semiotics;virtual reality;multimedia;realism	Visualization	-54.08421613157189	-47.14679328784193	84382
b495e7b23e58250ff20a4511bed9e277fff6a790	two tests for synergy of player in basketball games		In the analysis of the strength or efficiency of players in a game it is usually assumed that there is no interaction between the strength or efficiency of players against the alternative that players display synergy, i.e a group of players work together better than would be predicted by just considering their individual strengths or efficiencies. This paper deals with two tests for synergy when considering the strength or efficiency of a triplet of players in a game.	display device;synergy;triplet state	Jacek Dembinski;Ilona Kopocinska;Boleslaw Kopocinski	2006	Int. J. Comp. Sci. Sport		mathematics education;basketball games;psychology	HCI	-56.114565663599016	-48.51123401117905	84548
66335855d45be5ce8a46edeeb3024fba212ba849	evaluation of intelligent camera control systems based on cognitive models of comprehension	intelligent camera control;cognitive psychology;computer model;camera control;visual discourse;automatic generation;discourse comprehension;evaluation methodology;computational models of narrative;cognitive model;question answering	We propose a novel evaluation methodology for intelligent camera control systems based on established techniques of measuring story comprehension from cognitive psychology. The proposed methodology can be used specifically for evaluating the effectiveness of the camera system in communicating the story. We introduce a psychological model of question answering called QUEST and present a preliminary evaluation design of videos automatically generated by Darshak, an intelligent cinematic camera planning system. Initial results from our analysis are encouraging and motivate further work in evaluation of intelligent camera control systems as well as cognitive models of story comprehension through the visual medium.	cognitive model;control system;question answering	Arnav Jhala;Robert Michael Young	2009		10.1145/1536513.1536569	cognitive model;computer vision;simulation;question answering;computer science;artificial intelligence;multimedia	Robotics	-52.84391230114484	-46.45806776411119	84601
0a1984b38a5329eb82ad82daec34371888fa7655	a collaborative tool for capturing, sharing and connecting user research study in design	design research database;user needs;design process;usability testing;design research;collaborative tools;collaborative design research tool;user research	The objective of our project is to build a web based tool for generating a valuable design user research resource. User research is a process of discovering desirable and undesirable users' needs and expectation from a product or service. This user research information provides crucial sources of research insights, which lead to a process of finding ideas about functionality, features, criteria, and design attributes of a product or service. Usability testing is also considered as a part of the user research process to verify the feasibility of the design. The proposed Capturing, Sharing, and Connecting User Research (CSCUR) tool can help the design researcher to record and utilize user data efficiently. CSCUR tool provides a keyword list and procedure used as a guideline for design researchers to investigate related issues that need to be considered in design process, leading to an innovative design and responding to users' needs. Searching functionality facilitates activities in exchanging ideas and encouraging teamwork among the design research community.		Chujit Treerattanaphan	2008		10.1007/978-3-540-88011-0_37	user interface design;user experience design;user-centered design;user modeling;computer user satisfaction;design process;design research;human–computer interaction;experience design;computer science;systems engineering;engineering;knowledge management;software engineering;design education;user interface;mechanical engineering	HCI	-62.45745514396324	-38.82422963893469	84684
cfe17f904f36a59711f95210e0e37e5cbafcbef8	towards smart notifications using research in the large	smart devices;smart notification;notification	Notifications are a core function of current smart devices. They inform users about a variety of events, such as new messages, comments on social networks posts or application updates. As such, notifications are the main mechanisms to proactively communicate with the user. Focusing on individual device types such as PCs and smartphones, previous work showed that notifications can be distractive and disruptive. The ongoing wave of smart devices makes it possible to reach the user through multiple devices at once -- amplifying the effects of notifications. What is missing is an understanding of notifications in a multi-device environment to enable the smart management of notifications across devices. In this paper we present a system that is able to share notifications across smartphones, tablets, PCs, and smart TVs. It can further reach users through connected devices such as smart watches and smart glasses. The system currently distributes 5.3 million notifications by almost 30,000 users every day. It is not only intended to provide a holistic notification mechanism but also serves us to conduct large scale user studies to gain a deeper understanding of notifications in a multi-device environment.	holism;personal computer;smart tv;smart device;smartglasses;smartphone;smartwatch;social network;tablet computer	Dominik Weber;Alireza Sahami Shirazi;Niels Henze	2015		10.1145/2786567.2794334	internet privacy;world wide web;computer security	HCI	-56.29342763961325	-42.146296835646005	84846
855425eb134085557b32d96abb82509f47fb56f6	understanding multimodal deixis with gaze and gesture in conversational interfaces		When humans communicate, we use deictic expressions to refer to objects in our surrounding and put them in the context of our actions. In face to face interaction, we can complement verbal expressions with gestures and, hence, we do not need to be too precise in our verbal protocols. Our interlocutors hear our speaking; see our gestures and they even read our eyes. They interpret our deictic expressions, try to identify the referents and – normally – they will understand. If only machines could do alike.#R##N##R##N#The driving vision behind the research in this thesis are multimodal conversational interfaces where humans are engaged in natural dialogues with computer systems. The embodied conversational agent Max developed in the A.I. group at Bielefeld University is an example of such an interface. Max is already able to produce multimodal deictic expressions using speech, gaze and gestures, but his capabilities to understand humans are not on par. If he was able to resolve multimodal deictic expressions, his understanding of humans would increase and interacting with him would become more natural. #R##N##R##N#Following this vision, we as scientists are confronted with several challenges. First, accurate models for human pointing have to be found. Second, precise data on multimodal interactions has to be collected, integrated and analyzed in order to create these models. This data is multimodal (transcripts, voice and video recordings, annotations) and not directly accessible for analysis (voice and video recordings). Third, technologies have to be developed to support the integration and the analysis of the multimodal data. Fourth, the created models have to be implemented, evaluated and optimized until they allow a natural interaction with the conversational interface.#R##N##R##N#To this ends, this work aims to deepen our knowledge of human non-verbal deixis, specifically of manual and gaze pointing, and to apply this knowledge in conversational interfaces. At the core of the theoretical and empirical investigations of this thesis are models for the interpretation of pointing gestures to objects. These models address the following questions: When are we pointing? Where are we pointing to? Which objects are we pointing at? With respect to these questions, this thesis makes the following three contributions: First, gaze-based interaction technology for 3D environments: Gaze plays an important role in human communication, not only in deictic reference. Yet, technology for gaze interaction is still less developed than technology for manual interaction.#R##N##R##N#In this thesis, we have developed components for real-time tracking of eye movements and of the point of regard in 3D space and integrated them in a framework for Deictic Reference In Virtual Environments (DRIVE). DRIVE provides viable information about human communicative behavior in real-time. This data can be used to investigate and to design processes on higher cognitive levels, such as turn-taking, check-backs, shared attention and resolving deictic reference. #R##N##R##N#Second, data-driven modeling: We answer the theoretical questions about timing, direction, accuracy and dereferential power of pointing by data-driven modeling.#R##N##R##N#As empirical basis for the simulations, we created a substantial corpus with highprecision data from an extensive study on multimodal pointing. Two further studies complemented this effort with substantial data on gaze pointing in 3D. Based on this data, we have developed several models of pointing and successfully created a model for the interpretation of manual pointing that achieves a human-like performance level.#R##N##R##N#Third, new methodologies for research on multimodal deixis in the fields of linguistics and computer science: The experimental-simulative approach to modeling – which we follow in this thesis – requires large collections of heterogeneous data to be recorded, integrated, analyzed and resimulated. To support the researcher in these tasks, we developed the Interactive Augmented Data Explorer (IADE). IADE is an innovative tool for research on multimodal interaction based on virtual reality technology. It allows researchers to literally immerse into multimodal data#R##N#and interactively explore them in real-time and in virtual space. With IADE we have also extended established approaches for scientific visualization of linguistic data to 3D, which previously existed only for 2D methods of analysis (e.g. video recordings or computer screen experiments). By this means, we extended Mc-Neill’s 2D depiction of the gesture space to gesture space volumes expanding in time and space. Similarly, we created attention volumes, a new way to visualize the distribution of attention in 3D environments.	multimodal interaction	Thies Pfeiffer	2011			computer vision;computer science;multimedia;communication	HCI	-50.31688729137336	-43.539519981480865	84867
b92c1786b2c656c19d54235f637f47850c7ff10f	personality perception of robot avatar teleoperators in solo and dyadic tasks	humanoid robotics;personality;human robot interaction;tele presence;empirical research	2 Humanoid robot avatars are a potential new tele-communication tool whereby a user is remotely 3 represented by a robot that replicates their arm, head and possibly face movements. They have 4 been shown to have a number of benefits over more traditional media such as phones or video 5 calls. However using a tele-operated humanoid as a communication medium inherently changes 6 the appearance of the operator, and appearance based stereotypes are used in interpersonal 7 judgements (whether consciously or unconsciously). One such judgement that plays a key role 8 in how people interact is personality. Hence, we have been motivated to investigate if and how 9 using a robot avatar alters the perceived personality of tele-operators. To do so we carried out 10 two studies where participants performed 3 communication tasks, solo in study one and dyadic in 11 study two, and were recorded on video both with and without robot mediation. Judges recruited 12 using online crowdsourcing services then made personality judgements of the participants in the 13 video clips. We observed that judges were able to make internally consistent trait judgements 14 in both communication conditions. However, judge agreement was affected by robot mediation, 15 although which traits were affected was highly task dependent. Our most important finding was 16 that in dyadic tasks personality trait perception was shifted to incorporate cues relating to the 17 robot’s appearance when it was used to communicate. Our findings have important implications 18 for tele-presence robot design and personality expression in autonomous robots. 19		Paul Bremner;Oya Çeliktutan;Hatice Gunes	2017	Front. Robotics and AI	10.3389/frobt.2017.00016	psychology;computer vision;social robot;communication;social psychology	Robotics	-51.712228972139606	-50.59937508573448	84891
f7b5f8c4edce558ba7d121cc4dbee3148641b01e	a mobile device user interface with a simple, classic design	mobile device user interface;channel guide;remote control;mobile device;user interface;cell phones;presses;channel;personal digital assistants;navigation;graphical user interfaces;human factors;monitoring;user interfaces personal digital assistants cellular phones microcomputers laboratories navigation graphical user interfaces telephony manufacturing mobile computing;mobile handsets;pda functionality;gui;mobile device gui television remote control channel human factors;gui design;television remote control;telecommunication channels;mobile computing;user interfaces;telecommunication channels graphical user interfaces mobile computing;channel guide mobile device user interface pda functionality cell phones gui design	We developed a GUI that improves the usability of cell phones, PDAs, and other mobile devices. It has a well-known, time-tested, simple design that offers many advantages over the current hierarchical menu that becomes increasingly complex and convoluted with the continual expansion of cell phone and PDA functionality. Our GUI design associates digital destinations with channels, like a television remote control. Users directly access destinations by entering a channel rather than navigating through menus. It allows browsing and direct connection to all available destinations and can be set up to access specific desired ones. It is user programmable and creates a Channel Guide that shows users which destinations are assigned to which channels according to their wants and needs.	graphical user interface;mobile device;mobile phone;personal digital assistant;remote control;usability	R. Paul Morris;Julie J. Tomlinson	2008	IEEE Transactions on Consumer Electronics	10.1109/TCE.2008.4637614	embedded system;human–computer interaction;computer science;engineering;operating system;graphical user interface;multimedia;user interface;mobile computing	HCI	-48.93246602524538	-42.76135362112055	84906
0acdfb6d1b20043790402c695b124f8840a39122	social vr platform: building 360-degree shared vr spaces		Virtual Reality (VR) and 360-degree video are set to become part of the future social environment, enriching and enhancing the way we share experiences and collaborate remotely. In this demo, we present our ongoing efforts towards social and shared VR; a modular web based VR framework that extends current video conferencing capabilities with new VR functionalities. The framework allows for two people to come together for mediated audio-visual interaction, while engaging in (interactive) content. First results show that a majority of users appreciate the quality and feel highly immersed and present. Thus, with our demo we show that current web technologies can enable a high level of engagement and interaction in VR.	360-degree video;high-level programming language;spaces;virtual reality	Simon Gunkel;Martin Prins;Hans Stokking;Omar Niamut	2017		10.1145/3084289.3089914	social environment;web application;human–computer interaction;webrtc;modular design;multimedia;virtual reality;videoconferencing;computer science	HCI	-56.56928238121037	-38.459564829612695	85027
ccbae32c57f37dcce3ac435991e92c959132084f	use case focused user-interaction diagram: a communication tool within aal projects		The modeling of user interaction in the context of Active and Assisted Living (AAL) projects requires the involvement of different stakeholder groups to achieve usable and acceptable results. Within the research project ZentrAAL a comprehensive participatory approach is deployed, to achieve the goal of a user driven conceptualization, development, and evaluation process. Within this process, the modeling of the user interface and interaction, based on defined use cases is performed by means of various methods.  The proposed concept contains an interaction schema that represents elements of the human -- system interface, e.g. navigation, dimensions of use cases, interaction and information elements as well as element labels depicted in one view per use case. The interaction schema acts as a communication tool during the user interaction conceptualization phase in AAL projects. First outcomes of the conceptualization of the use case focused interaction diagram are the improvement of interdisciplinary communication, easy derivation of interface prototypes, and additional point of view for stakeholders in a project.	atm adaptation layer;conceptualization (information science);diagram;unified modeling language;user interface	Daniela Krainer;Daniela Elisabeth Ströckl;Johannes Oberzaucher	2017		10.1145/3056540.3064944	user interface design;human–computer interaction;interactivity;computer science;interaction overview diagram;interaction design;user experience design;use case;interactive systems engineering;user interface	HCI	-60.74408032418375	-39.28845884405794	85218
077e7be56563c918081a72dfae381411f069b5ca	emerging requirements for multi-modal annotation and analysis tools.	multimodal interface;next generation;empirical evaluation;eye gaze	We review existing capabilities of multi-modal annotation and analysis tools by presenting a survey of seven representative tools, and providing a sample annotation using one system. We discuss emerging requirements including handling electronic ink, eye-gaze tracking, and other time-based considerations. We briefly review aspects of empirically evaluating tool effectiveness and suggest that multimodal interfaces in future analytical tools may be desirable. We conclude by providing a tentative list of desired features for next-generation tools.	electronic paper;eye tracking;modal logic;multimodal interaction;requirement	Tony Bigbee;Dan Loehr;Lisa C. Harper	2001			computer vision;human–computer interaction;eye tracking;computer science;linguistics;multimedia	HCI	-52.79953772947124	-38.941641660803256	85258
0afc63840d9c217f0c49c50d6ce735d76b9ff30f	the development of a haptic virtual reality environment to study body image and affect		We report the results of a preliminary study testing the effect of participants' mood rating on visual motor performance using a haptic device to manipulate a cartoonish human body. Our results suggest that moods involving high arousal (e.g. happiness) produce larger movements whereas mood involving low arousal (e.g. sadness) produce slower speed of performance. Our results are used for the development of a new haptic virtual reality application that we briefly present here. This application is intended to create a more interactive and motivational environment to treat body image issues and for emotional communication.	arousal;body dysmorphic disorders;body image;haptic device component;haptic technology;large;mood (psychological function);movement;sadness;virtual reality	Line Tremblay;Stéphane Bouchard;Brahim Chebbi;Lai Wei;Johana Monthuy-Blanc;Dominic Boulanger	2013	Studies in health technology and informatics	10.3233/978-1-61499-282-0-80	mood;low arousal theory;knowledge management;cognitive psychology;haptic technology;sadness;happiness;virtual reality;arousal;medicine	HCI	-48.27721091257259	-49.90581789536308	85481
b3344b1d673abc0e3dabd53c58750479e84eb119	metaphorical mapping between raw–cooked food and strangeness–familiarity in chinese culture		Previous research has demonstrated metaphorical mappings between physical coldness–warmth and social distance–closeness. Since the concepts of interpersonal warmth are frequently expressed in terms of food-related words in Chinese, the present study sought to explore whether the concept of raw–cooked food could be unconsciously and automatically mapped onto strangeness–familiarity. After rating the nutritive value of raw or cooked foods, participants were presented with morphing movies in which their acquaintances gradually transformed into strangers or strangers gradually morphed into acquaintances, and were asked to stop the movies when the combined images became predominantly target faces. The results demonstrated that unconscious and automatic metaphorical mappings between raw–cooked food and strangeness–familiarity exist. This study provides a foundation for testing whether Chinese people can think about interpersonal familiarity using mental representations of raw–cooked food and supports cognitive metaphor theory from a crosslinguistic perspective.	centrality;cooking (activity);desktop metaphor;face;food;morphing;the movies;unconscious personality factor	Xiaohong Deng;Yuan Qu;Huihui Zheng;Yang Lu;Xin Zhong;Anne Ward;Zijun Li	2016	Cognitive Processing	10.1007/s10339-016-0778-1	psychology;cognitive psychology;linguistics;communication;social psychology;cognitive science	HCI	-51.990192679657426	-47.49848325272394	85483
d8af8cd53c088748a4ac1e20b3d9def5b88216f2	longitudinal affective computing - virtual agents that respond to user mood	longitudinal study;affect;agents;persuasive technology;mood	We present two empirical studies which examine user mood in long-term interaction with virtual conversational agents. The first study finds evidence for mood as a longitudinal construct independent of momentary affect and demonstrates that mood can be reliably identified by human judges observing user-agent interactions. The second study demonstrates that mood is an important consideration for virtual agents designed to persuade users, by showing that favors are more persuasive than direct requests when users are in negative moods, while direct requests are more persuasive for users in positive moods.	affective computing;dialog system;futures studies;intelligent agent;interaction;sensor;user agent	Lazlo Ring;Timothy W. Bickmore;Daniel Schulman	2012		10.1007/978-3-642-33197-8_9	psychology;affect infusion model;computer science;artificial intelligence;software agent;persuasive technology;psychotherapist;social psychology;mood management theory;clinical psychology;affect	HCI	-52.42465244114612	-51.60349531331842	85518
cf2c6ff5489392672228ddfb700a744534a7de63	maximized modality or constrained consistency?		A key debate in the interface literature is whether to make each modality as human-like as possible or instead to match the level of humanness of each modality. A three-condition experiment (recorded speech with synthesized face; synthesized speech with a synthesized face; or recorded speech with no face) was conducted (N = 36). When the modalities were matched, individuals exhibited significantly greater impression management and willingness to disclose personal information and felt more comfortable using the interface.	modality (human–computer interaction);personally identifiable information;speech synthesis	Clifford Nass;Li Gong	1999				HCI	-51.37355341527604	-46.73706663595097	85572
259394b3e8a21556211e3ee93ff4e0e842ac2955	a comparison of robot interaction with tactile gaming console stimulation in clinical applications		Technological advancements in recent years have encouraged lots of research focus on robot interaction among individuals with intellectual disability, especially among kids with Autism Spectrum Disorders (ASD). However, promising advancements shown by these investigations, about use of interactive robots for rehabilitation of such individuals can be questioned on various aspects, e.g. is effectiveness of interaction therapy because of the robot itself or due to the sensory stimulations? Only few studies have shown any significant comparison in remedial therapy using interactive robots with non-robotic visual stimulations. In proposed research, authors have tried to explore this idea by comparing response of robotic interactions with stimulations caused by a tactile gaming console, among individuals with profound and multiple learning disability (PMLD). The results show that robot interactions are more effective but stimulations caused by tactile gaming consoles can significantly serve as complementary tool for therapeutic benefit of patients.	robot	Jainendra Shukla;Julián Cristiano;Laia Anguera;Jaume Vergés-Llahí;Domenec Puig	2015		10.1007/978-3-319-27149-1_34	computer vision;simulation;multimedia	Robotics	-56.50560081712857	-50.10943905056942	85697
0d5e1b530203d8653608486d1fdea8e5b145704d	wi-wave: urban furniture for browsing internet contents in public spaces	activity analysis;human computer interaction;universal access;urban furniture;gestural interface;ambient device;podcast;tangible user interface;gesture interface;ultrasonic sensors;human factors;audio;public space;ubiquitous computing;interaction design;radio;emergent behaviour;human factors theory;ultrasonic sensor	"""Motivation -- The socio-technical challenges created by Tangible User Interfaces with regards to invasiveness, privacy, visibility, control, etc. have been pointed out by several authors, but this case study focuses on two, more basic socio-technical aspects regarding the user's perspective and interaction with others. The paper presents a case study regarding the design of the interaction of interactive urban furniture, Wi-roni, for browsing information on the Web through a gesture-based interface in a public space.  Research approach -- The interaction modalities options were discussed and analyzed during the convergence phase, in which designers, technicians and users worked on the design of a prototype that could respond to the activity analysis and the shaping of physical factors.  Findings/Design -- The prototypes evaluation and assessment with users revealed many interesting aspects that mainly regard the interaction modality that changed significantly according to the shape of the artefact.  Research limitations/Implications -- Wi-roni is just a first exercise in this research direction. The design of other furniture will allows a more complete study regarding the emerging behaviour of the people involved in new and old convivial activities in public spaces.  Originality/Value -- We propose to respond to sociotechnical challenges by conceiving interaction modalities suitable for social activities complementing distant communication with in-presence communication and harmonizing """"everywhere"""" with the specific values of a given location.  Take away message -- Designing unique artefact needs a big effort that is necessary in order to design a set of devices with an aesthetic and imaginative values."""	gesture recognition;interaction design;internet;maurizio lenzerini;mock object;modality (human–computer interaction);noise shaping;prototype;sociotechnical system;status message (instant messaging);swing (java);tangible user interface;ubiquitous computing;visual artifact;washing machine;web service;world wide web	Elisa Rubegni;Jevon Brunk;Maurizio Caporali;Erik Grönvall;Andrea Alessandrini;Antonio Rizzo	2008		10.1145/1473018.1473032	simulation;human–computer interaction;computer science;engineering;electrical engineering;multimedia;ultrasonic sensor;ubiquitous computing	HCI	-55.070809870925636	-38.0569207663887	85731
1b23d460ac85e574d16f45d41379d0065bd5c16a	emotional facial expression analysis in the time domain		Emotions have been studied for a long time and results show that they play an important role in human cognitive functions. In fact, emotions play an extremely important role during the communication between people. And the human face is the most communicative part of the body for expressing emotions; it is recognized that a link exists between facial activity and emotional states. In order to make computer applications more believable and friendly, giving them the ability to recognize and/or express emotions are research fields which have been much focused on. Being able to perform these tasks, firstly, we need to have knowledge about the relationship between emotion and facial activity. Up to now, there have been proposed researches on this relationship. However, almost all these researches focused on analyzing the relationship without taking into account time factors. They analyzed the relationship but did not examined it in the time domain. In this paper, we propose a work on analyzing the relationship between emotions and facial activity in the time domain. Our goal is finding the temporal patterns of facial activity of six basic emotions (happy, sad, angry, fear, surprise, disgust). To perform this task, we analyzed a spontaneous video database in order to consider how facial activities which are related to the six basic emotions happen temporally. From there, we bring out the general temporal patterns for facial expressions of each of the six emotions.		Thi Duyen Ngo;Thi Chau Ma;The Duy Bui	2014		10.1007/978-3-319-11680-8_39	machine learning;surprise;communication;computer science;emotion classification;disgust;time domain;facial expression;artificial intelligence;cognition	Vision	-51.666302650181805	-47.12423009859864	86059
4768a73fc38252ea4f0909f6f597859f4e4ac113	a survey on interactive games over mobile networks	settore inf 01 informatica;mobility;videogame;networking;interactivity	The mobile revolution has brought us the possibility to enjoy our favorite applications anywhere and anytime. In this context, interactive games over mobile networks embody a fascinating case study both for their commercial success and for their technical challenges, thus sparking interest and development. The current state of the art of interactive games over mobile networks is captured in this article. We discuss main requirements and analyze possible combinations of existing solutions in order to provide better support for highly interactive game sessions with mobile players. Copyright c © 2011 John Wiley & Sons, Ltd.	anytime algorithm;experiment;interactivity;john d. wiley;requirement	Mario Gerla;Dario Maggiorini;Claudio E. Palazzi;Armir Bujari	2013	Wireless Communications and Mobile Computing	10.1002/wcm.2197	simulation;computer science;operating system;multimedia;interactivity;mobile computing;world wide web;computer network	HCI	-54.584485695289864	-39.22121721042466	86100
0937d8c0644f1b62b2c0f9171ffb708c876c9eea	giving interaction a hand: deep models of co-speech gesture in multimodal systems	generation;gesture;speech;recognition;multimodal systems	Humans frequently join words and gestures for multimodal communication. Such natural co-speech gesturing goes far beyond what can be currently processed by gesture-based interfaces and especially its coordination with speech still poses open challenges for basic research and multimodal interfaces alike. How can we develop computational models for processing and generating natural speech-gesture behavior, in a flexible, fast and adaptive manner similar to humans? In this talk I will review approaches and methods applied to this problem and I will argue that such models need to (and can) based on a deeper understanding of what shapes co-speech gesturing in a particular situation. I will present work that connects empirical analyses with computational modeling and evaluation to unravel the cognitive, embodied and socio-interactional mechanisms underlying the use of speech- accompanying gestural behavior, and to develop deeper models of these mechanisms for interactive systems such as virtual characters, humanoid robots, or multimodal interfaces.	computational model;humanoid robot;humans;multimodal interaction;natural language	Stefan Kopp	2013		10.1145/2522848.2532201	natural language processing;generation;speech recognition;computer science;speech;linguistics;gesture	HCI	-51.80298585720517	-47.13942271112926	86105
6c6d2c9db006770ed35e7b247e5792ac88d7779b	interaction design in a mobile food recommender system	conferenceobject	One of the most important steps in building a recommender system is the interaction design process, which defines how the recommender system interacts with a user. It also shapes the experience the user gets, from the point she registers and provides her preferences to the system, to the point she receives recommendations generated by the system. A proper interaction design may improve user experience and hence may result in higher usability of the system, as well as, in higher satisfaction. In this paper, we focus on the interaction design of a mobile food recommender system that, through a novel interaction process, elicits users’ long-term and short-term preferences for recipes. User’s long-term preferences are captured by asking the user to rate and tag familiar recipes, while for collecting the short-term preferences, the user is asked to select the ingredients she would like to include in the recipe to be prepared. Based on the combined exploitation of both types of preferences, a set of personalized recommendations is generated. We conducted a user study measuring the usability of the proposed interaction. The results of the study show that the majority of users rates the quality of the recommendations high and the system achieves usability scores above the standard benchmark.	benchmark (computing);interaction design;personalization;processor register;recommender system;usability testing;user experience	Mehdi Elahi;Mouzhi Ge;Francesco Ricci;Ignacio Fernández-Tobías;Shlomo Berkovsky;David Massimo	2015			human–computer interaction;world wide web	HCI	-58.35195742696845	-45.58947384138925	86268
2e79a3a49a71e3f06397871f13a31e1259e54c4b	technical report: a tool for measuring prosodic accommodation		Social interaction is a dynamic and joint activity where all participants are engaged and coordinate their behaviour in the co-construction of meaning. It is observed that conversational partners adapt their pitch, intensity and timing behaviour to their interlocutors. The majority of research has focused on its linear manifestation over the course of an interaction. De Looze et al hypothesised that it evolves dynamically with functional social aspects. In the work of De Looze et al, they proposed through their praat based feature extraction and matlab based visualisation that one can visualise prosodic accommodation at the positive correlation threshold values. and the capture of its dynamic manifestation. Here we seek to build a complete system for measuring prosodic accommodation with matlab. This work uses data collected in a pilot training scenario where senior pilot and co-pilot are engaged in conversation during the flight. Additionally, we use the data from a ship wreck task by two pilots. We also attempt to evaluate this measures of accommodation with ground truth labels given by a trainer of Crew (or sometimes Crisis) Resource Management (CRM).	feature extraction;ground truth;matlab;pitch (music);praat	Sucheta Ghosh	2015	CoRR		computer vision;simulation;speech recognition	NLP	-51.74384373808631	-48.53610988725333	86341
f8f557abf99b3fdf57c4ef46786f80b26c85d252	contextking: virtual kingdoms in real life	pervasive;ubiquitous computing computer games social networking online;context aware;resistance;contextking;virtual pawns;mondial;game mondial pervasive context aware virtual;social network;earth surface;games;pervasive game;it adoption;social networking online;mobile communication;social network contextking virtual kingdoms mondial pervasive games earth surface virtual pawns;game;ubiquitous computing;ontologies;virtual kingdoms;temperature sensors context aware services context humans mobile handsets earth social network services intelligent sensors working environment noise cities and towns;temperature measurement;communities;computer games;mondial pervasive games;virtual;context	Mondial pervasive games exchange the game board for earth’s surface and the users themselves wander over the earth as game pieces over the game board. ContextKing is a mondial pervasive game that uses sensory inputs from the real-world to create a new game experience that can be played within the user’s social network, whenever the user finds the time, and from any place in the world. We discuss the game set-up, the adoption and usage of the game in real-life, as well as some observations from the game play.	pervasive informatics;real life;social network	Johan Koolwaaij;Martin Wibbels;Sebastian Böhm;Marko Luther	2009	2009 Conference in Games and Virtual Worlds for Serious Applications	10.1109/VS-GAMES.2009.21	non-cooperative game;video game design;game design;simulation;simultaneous game;computer science;win-win game;game mechanics;game art design;metagaming;repeated game;game developer;multimedia;screening game;simulations and games in economics education;game design document;sequential game;video game development;world wide web;game client	HCI	-56.0877110449215	-39.73726120644915	86492
315c25f14eb25359676d38ba86a5ff8e6a99f80a	situated micro-displays for activity-aware systems	situated micro display;mobile work;conference report;activity centric system	Most activity-aware systems designed to support mobile workers in dynamic environments, such as hospitals or industrial plants, typically consider the use of mobile devices and large displays. However, we envision potential benefits of using ubiquitous micro-displays as support of mobile workers activities. Particularly, in this paper we show how the use of situated micro-displays, as a mechanism for embedding information into a physical environment, can contribute to improve the performance and experience of mobile workers in those scenarios. The article also describes the prototype of a micro-display network designed to support people performing spatially distributed activities. It also presents a user study that helps understand how the spatial distribution of situated micro-displays impacts on the mobile workers performance.	computer user satisfaction;context-aware pervasive systems;field research;mobile device;prototype;real-time clock;situated;usability testing;user experience	Esunly Medina;Fahim Kawsar;Roc Meseguer;Sergio F. Ochoa	2014		10.1007/978-3-319-07788-8_42	simulation;human–computer interaction;engineering;knowledge management;situated	HCI	-56.64131363180861	-43.63565919749252	86593
36bbf3f15870a520162e40b0ffd72675648f94e3	seascape and volcano: visualizing online discussions using timeless motion	usenet;social interaction;user study;motion;interface design;online discussion;large scale;visualization;animation	Motion is the strongest visual appeal to attention [2], yet it is rarely used in the visualization of large-scale quantitative information. Motion is complex; it can vary across numerous dimensions, each of which is potentially an information-bearing element in the visualization. Which dimensions are used and how the data is mapped onto them are the key questions in using motion effectively. In this paper we present two interfaces that use motion as the primary visual element for representing data. These interfaces, Seascape and Volcano, use periodic animation loops to represent key social interaction features in online discussions. We propose that motion may be particularly well suited for representing data about behavior and actions, creating visualizations that intuitively depict different levels and types of activity. In this paper we describe the interfaces we have built and present the results of preliminary user studies.	music visualization;scientific visualization;usability testing	Francis Lam;Judith S. Donath	2005		10.1145/1056808.1056972	anime;social relation;simulation;visualization;human–computer interaction;computer science;interface design;motion;world wide web;computer graphics (images)	HCI	-55.13222649438452	-43.41230677398303	86658
89f11c03cb34a2011249c8cd1a27b938594d1c06	investigating the utility of eye-tracking information on affect and reasoning for user modeling	negative affect;user study;pupil size;eye tracking;user model	We investigate the utility of an eye tracker for providing information on users’ affect and reasoning. To do so, we conducted a user study, results from which show that users’ pupillary responses differ significantly between positive and negative affective states. As far as reasoning is concerned, while our analysis shows that larger pupil size is associated with more constructive reasoning events, it also suggests that to disambiguate between different kinds of reasoning, additional information may be needed. Our results show that pupillary response is a promising non-invasive avenue for increasing user model bandwidth.		Kasia Muldner;Robert Christopherson;Robert K. Atkinson;Winslow S. Burleson	2009		10.1007/978-3-642-02247-0_15	psychology;simulation;communication;social psychology	AI	-54.589457050499576	-48.711319818139	86718
d8edd50683d0c29c3cd44ba063f214e436819472	card-stunt as a service: empowering a massively packed crowd for instant collective expressiveness		"""Excerpted from """"Card-stunt as a Service: Empowering a Massively Packed Crowd for Instant Collective Expressiveness"""" from MobiSys 2017, Proceedings of the 15th Annual ACM International Conference on Mobile Systems, Applications, and Services, with permission. https://dl.acm.org/ citation.cfm?id=3081357 © ACM 2017.  Imagine a densely packed crowd with a common voice, such as people in a candlelight vigil or a protest. We envision an innovation through mobile computing technologies to empower such crowds. We present Card-stunt as a Service (CaaS), a mobile service allowing them to instantly create a massive collective visualization by simply holding their phones up. The key challenge is to achieve instant, infrastructurefree, decimeter-level localization of individuals in a massively packed crowd, within a low latency. CaaS addresses the challenges by mobile visible-light sensing and scalable constrained optimization. Within less than a minute, each person is given individualized pixels so that they can do their part in the overall visualization*."""	constrained optimization;mathematical optimization;mobile computing;pixel;scalability	Chungkuk Yoo;Inseok Hwang;Seungwoo Kang;Myung-Chul Kim;Seonghoon Kim;Daeyoung Won;Yu Gu;Junehwa Song	2017	GetMobile	10.1145/3191789.3191797	visualization;mobile service;scalability;crowds;latency (engineering);permission;mobile computing;computer science;instant;distributed computing	Mobile	-49.08320262294977	-38.31885126216743	86775
0570a1d58ea2e7cc2260cf3a16e375a7cbac0b87	when are users comfortable sharing locations with advertisers?	mobile;user needs;expressiveness;location based sharing;user study;mobile computer;position location;targeting;revenue sharing;secure communications;privacy;telecommunications;advertising	As smartphones and other mobile computing devices have increased in ubiquity, advertisers have begun to realize a more effective way of targeting users and a promising area for revenue growth: location-based advertising. This trend brings to bear new questions about whether or not users will adopt products involving this potentially invasive form of advertising and what sorts of protections they should be given. Our real-world user study of 27 participants echoes earlier findings that users have significant privacy concerns regarding sharing their locations with advertisers. However, we examine these concerns in more detail and find that they are complex (e.g., relating not only to the quantity of ads, but the locations and times at which they are received). With advanced privacy settings, users stated they would feel more comfortable and share more information than with a simple opt-in/opt-out mechanism.	mobile computing;privacy;smartphone;usability testing	Patrick Gage Kelley;Michael Benisch;Lorrie Faith Cranor;Norman M. Sadeh	2011		10.1145/1978942.1979299	targeting;computer science;share of voice;operating system;mobile technology;expressivity;internet privacy;mobile computing;privacy;world wide web;computer security	HCI	-57.43048042753061	-42.63209222045915	86794
1d6fddfac37ebbc4503fef4e99aa08b951b36097	shared family calendars: promoting symmetry and accessibility	elderly;digital paper;universal usability;calendar;home;layered interface;family technology;privacy	We describe the design and use of a system facilitating the sharing of calendar information between remotely located, multi-generational family members. Most previous work in this area involves software enabling younger family members to monitor their parents. We have found, however, that older adults are equally if not more interested in the activities of younger family members. The major obstacle preventing them from participating in information sharing is the technology itself. Therefore, we developed a multi-layered interface approach that offers simple interaction to older users. In our system, users can choose to enter information into a computerized calendar or write it by hand on digital paper calendars. All of the information is automatically shared among everyone in the distributed family. By making the interface more accessible to older users, we promote symmetrical sharing of information among both older and younger family members. We present our participatory design process, describe the user interface, and report on an exploratory field study in three households of an extended family.	accessibility;digital paper;field research;user interface	Catherine Plaisant;Aaron Clamage;Hilary Hutchinson;Benjamin B. Bederson;Allison Druin	2006	ACM Trans. Comput.-Hum. Interact.	10.1145/1183456.1183458	simulation;human–computer interaction;computer science;universal usability;privacy;world wide web	HCI	-57.29503583896674	-40.76161437310148	86921
acbadf0a59c85b9f34a520db2853ce7a421bed0f	virtual reality applications in rehabilitation	virtual rehabilitation;cognitive impairment;virtual reality;conference paper;biomedical engineering	One of the most valuable applications of virtual reality (VR) is in the domain of rehabilitation. After brain injuries or diseases, many patients suffer from impaired physical and/or cognitive capabilities, such as difficulties in moving arms or remembering names. Over the past two decades, VR has been tested and examined as a technology to assist patients' recovery and rehabilitation, both physical and cognitive. The increasing prevalence of low-cost VR devices brings new opportunities, allowing VR to be used in practice. Using VR devices such as head-mounted displays (HMDs), special virtual scenes can be designed to assist patients in the process of re-training their brain and reorganizing their functions and abilities. However, such VR interfaces and applications must be comprehensively tested and examined for their effectiveness and potential side effects. This paper presents a review of related literature and discusses the new opportunities and challenges. Most of existing studies examined VR as an assessment method rather than a training/exercise method. Nevertheless, promising cases and positive preliminary results have been shown. Considering the increasing need for self-administered, home-based, and personalized rehabilitation, VR rehabilitation is potentially an important approach. This area requires more studies and research effort.	coat of arms;head-mounted display;personalization;playstation vr;side effect (computer science);virtual reality	Shi Cao	2016		10.1007/978-3-319-39510-4_1	simulation;human–computer interaction;computer science;virtual reality;multimedia	HCI	-56.48187718366071	-50.269783486865585	87031
22c35d359b49bd34aef1ecce819de1f7ad1050d1	'you're virtually there': mobile communication practices, locational information sharing and place attachment			attachments;mobile phone	Didem Ozkul	2013	First Monday			HCI	-55.36465856668129	-39.945988469864744	87044
0073588bea1fe52fd907a8d11c1e3dd2f294a6c8	evaluating a conversation-centered interactive drama	embodied conversational agents;language understanding;believable agents;interactive drama;evaluation;embodied conversational agent	There is a growing interest in developing technologies for creating interactive dramas [13, 22]. Evaluating them, however, remains an open research problem. In this paper, we present a method for evaluating the technical and design approaches employed in a conversation-centered interactive drama. This method correlates players' subjective experience during conversational breakdowns, captured using retrospective protocols, with the corresponding AI processing in the input language understanding and dialog management subsystems. The methodology is employed to analyze conversation breakdowns in the interactive drama Façade. We find that the narrative cues offered by an interactive drama, coupled with believable character performance, can allow players to interpretively bridge system limitations and avoid experiencing a conversation breakdown. Further, we find that, contrary to standard practice for task-oriented conversation systems, using shallowly understood information as part of the system output hampers the player experience in an interactive drama.	dialog manager;interactive storytelling;natural language understanding;open research	Manish Mehta;Steven Dow;Michael Mateas;Blair MacIntyre	2007		10.1145/1329125.1329135	simulation;computer science;evaluation;multimedia	HCI	-53.78638798757475	-47.60577202134247	87063
d32c3b85a853c3b315fbc31c3267f5dd6d20f067	quantifying the creativity support of digital tools through the creativity support index	psychometrics;evaluation;creativity support tools;surveys	Creativity support tools help people engage creatively with the world, but measuring how well a tool supports creativity is challenging since creativity is ill-defined. To this end, we developed the Creativity Support Index (CSI), which is a psychometric survey designed for evaluating the ability of a creativity support tool to assist a user engaged in creative work. The CSI measures six dimensions of creativity support: Exploration, Expressiveness, Immersion, Enjoyment, Results Worth Effort, and Collaboration. The CSI allows researchers to understand not just how well a tool supports creative work overall, but what aspects of creativity support may need attention. In this article, we present the CSI, along with scenarios for how it can be deployed in a variety of HCI research settings and how the CSI scores can help target design improvements. We also present the iterative, rigorous development and validation process used to create the CSI.	human–computer interaction;immersion (virtual reality);iterative method	Erin Cherry;Celine Latulipe	2014	ACM Trans. Comput.-Hum. Interact.	10.1145/2617588	simulation;creativity technique;knowledge management;evaluation;psychometrics	HCI	-61.75290588726696	-45.22898463600307	87175
01ec71ed33ccc495429dfddef12a081fc6b83831	mocking ads through mobile web services	ubiquitous creativity;web based creative service;communication	The need for creativity is ubiquitous, and mobile devices connected to Web services can help us. Linguistic creativity is widely used in advertisements to surprise us, to get our attention, and to stick concepts in our memory. However, creativity can also be used as a defense. When we walk in the street, we are overwhelmed by messages that try to get our attention with any persuasive device at hand. As messages get ever more aggressive, often our basic cognitive defenses-trying not to perceive those messages-are not sufficient. One advanced defensive technique is based on transforming the perceived message into something different for instance, making use of irony or hyperbole from what was originally meant in the message. In this article, we describe an implemented application for smartphones, which creatively modifies the linguistic expression in a virtual copy of a poster encountered on the street. The mobile system is inspired by the subvertising practice of countercultural art.		Lorenzo Gatti;Marco Guerini;Oliviero Stock;Carlo Strapparava	2015	Computational Intelligence	10.1111/coin.12042	web service;human–computer interaction;computer science;multimedia;web intelligence;world wide web	AI	-51.64510365250549	-42.11938516283514	87243
dac5424f34bf36821c08d01ecefbff17f7b4f048	interactive therapy approach through collaborative physical play between a socially assistive humanoid robot and children with autism spectrum disorder		This paper presents an exploratory study in which children with autism spectrum disorder (ASD) interact with a NAO humanoid robot in an interactive football game scenario. The study was conducted during 4 sessions with three boys diagnosed with ASD. It observed improvements in therapeutic outcomes such as social interaction, communication, eye contact, joint attention and turn taking. Qualitative and quantitative analysis were conducted using various approaches such as video documenting, surveys and assessment scales. In order to establish the efficacy of the study children interacted with their typically developing peers and parents post intervention to relate skills learned in robot-human setting to human-human setting. The quantitative results gathered and analyzed from pre and post implementation showed an increased in execution and duration of target behaviors. Manual coding and qualitative analysis of videos also verified that the proposed robot mediated play setting demonstrated improvements in social development of children with ASD in areas of communicative competence, turn taking, social interaction and proxemics and eye contact.	humanoid robot	Saima Tariq;Sara Baber Sial;Asbah Ashfaq;Yasar Ayaz;Muhammad Naveed;Saba Mohsin	2016		10.1007/978-3-319-47437-3_55	psychology;developmental psychology;psychotherapist;communication	Robotics	-54.38816599925844	-50.52176695199826	87359
04855c717e24d970bbace708c34cbd9bf6de1095	helping visually impaired people use smart phones in education: content retrieval with fingerprint identification	biometrics;blind;visually impaired;content retrieval;fingerprint identification	The paper proposes an architecture for content retrieval with smart phones, by exploiting fingerprint identification, in order to help visually impaired people to use educational material in electronic format. Use cases and design specifications are presented, and implementation details are discussed. The proposed architecture can be implemented as a standalone application fairly simply, or it can constitute the basis for further, more sophisticated frameworks.	fingerprint;smartphone;software framework	A. Kampouraki;Dimitris Vassis;Petros Belsis;Christos Skourlas	2015		10.1145/2801948.2801975	fingerprint;computer science;multimedia;internet privacy;world wide web;biometrics	HCI	-50.344420691957524	-40.263401251915006	87482
392bd0f59f12c8d0bfbab8e3a1f3a919b62383cf	strolling with street atmosphere visualization: development of a tourist support system	tourist navigation;streetscape impression;visualization;strolling tours;attracting interest	Information about the characteristics or impressions of streets is useful to tourists. This paper introduces a strolling support system that utilizes street atmosphere visualization. The system runs on a smartphone and alerts users to the existence of nearby attractive streets and areas by vibration and visualized characterization of streets. For the visualization, subjective evaluation experiments were conducted to investigate the impression of streetscapes in Kyoto. Analysis of the evaluation results revealed three factors that are relevant to street characteristics. Using the factor scores of the evaluated streetscapes, the characteristics are visualized using colours. In user studies, eight participants examined its use while walking around the city. The user studies suggest that the system attracts users' attention to surrounding environments and increases the amount of photography and conversation during their walk.	color;experiment;smartphone;usability testing	Yuichiro Kinoshita;Satoshi Tsukanaka;Kentaro Go	2013		10.1145/2468356.2468454	simulation;visualization;human–computer interaction;computer science;multimedia;world wide web	HCI	-54.133297525435864	-41.69816318030521	87498
208f0cfaa4439cb290fa4cdc0ec52d4d19710ff5	personalizing intelligent systems and robots with human motion data		According to Merhabian, more than (90,%) of human-human communication is non-verbal when expressing affects and attitudes. Further studies have shown that a large proportion of non-verbal communication can be attributed to posture and to gesture. They communicate information about action: intent, meaning, as well as information about internal states such as affects. Emotional understanding is a key for satisfying and successful interaction between two or more humans, it must also be true for human-robot interaction. In this paper we explore the importance of non verbal information and communication, typically motion data, and how it can be used to develop and to personalize intelligent systems and robots. First, we present and discuss our findings on the strong correlation between what humans feel during an unannounced interaction with a humanoid robot and their movements and attitudes. Then, we propose a framework that uses not only the kinematics information of movements but also the dynamics. We use the direct measure of the dynamics when available. If not we propose to compute the dynamics from the kinematics, and use it to understand human motions. Finally, we discuss some developments and concrete applications in the field of health care and HRI.	robot	Gentiane Venture;Ritta Baddoura;Yuta Kawashima;Noritaka Kawashima;Takumi Yabuki	2013		10.1007/978-3-319-28872-7_18	robot;human–computer interaction;humanoid robot;intelligent decision support system;zero moment point;human–robot interaction;contact force;kinematics;computer science;gesture	Robotics	-51.11623936795929	-50.269073344910964	87574
551080e8a9658ce2cff4cf6bb6afff19302403d7	joint action with a virtual robotic vs. human agent		Abstract Prior research has revealed that when performing joint action tasks with a human co-actor, we automatically form representations not only of our own action, but also of the action of the co-actor we are interacting with, creating an action discrimination problem. Studies suggest these processes are affected by the human/non-human nature of the agent the task is shared with. In two experiments (Experiments 1 and 2), we measured the Joint Simon Effect (JSE) as an index of action discrimination, using a virtual version of the joint go/no-go task in which the task was shared with a virtual robotic vs. human hand. Furthermore, both experiments tested whether the JSE was affected by sensorimotor experience during which the participant manipulated the virtual robotic hand via an exoskeleton (vs. passive observation of movements of the virtual robotic hand). Experiment 2 replicated Experiment 1, except that prior to the joint action task, participants were informed about the robotic vs. human nature of the two virtual hands (no such information was given in Experiment 1). Both experiments demonstrated a significant JSE, which did not differ between robotic and human partner. Analysis of the results further indicates that the JSE obtained in the robotic condition was not modified after manipulating the virtual robotic hand. These results suggest that the human vs. non-human appearance of the partner is not a determinant of joint action performance in virtual settings.	robot	Frederique Bunlon;Jean-Pierre Gazeau;Floren Colloud;Peter J. Marshall;Cedric Bouquet	2018	Cognitive Systems Research	10.1016/j.cogsys.2018.09.017	simon effect;machine learning;psychology;artificial intelligence	AI	-50.92982124759865	-51.01861670075663	87614
94278cedce9b9290757fce4850b6afe34544748e	enhancing driving safety and user experience through unobtrusive and function-specific feedback		Inappropriate trust in the capabilities of automated driving systems can result in misuse and insufficient monitoring behaviour that impedes safe manual driving performance following takeovers. Previous studies indicate that the communication of system uncertainty can promote appropriate use and monitoring by calibrating trust. However, existing approaches require the driver to regularly glance at the instrument cluster to perceive the changes in uncertainty. This may lead to missed uncertainty changes and user disruptions. Furthermore, the benefits of conveying the uncertainty of the different vehicle functions such as lateral and longitudinal control have yet to be explored. This research addresses these gaps by investigating the impact of unobtrusive and function-specific feedback on driving safety and user experience. Transferring knowledge from other disciplines, several different techniques will be assessed in terms of their suitability for conveying uncertainty in a driving context.		Alexander Kunze;Stephen J. Summerskill;Russell Marshall;Ashleigh J. Filtness	2017		10.1145/3131726.3131762	simulation;engineering;user experience design	SE	-61.58099954192145	-51.90408714980604	87696
4e431ec73dbba2690079235ec48fcb2134a28cb9	authority and level of automation - lessons to be learned in design of in-vehicle assistance systems	human computer interaction;manniska datorinteraktion interaktionsdesign	Authority and level of automation : Lessons to be learned in design of in-vehicle assistance systems	automation	Anders Jansson;Patrik Stensson;Ida Bodin;Anton Axelsson;Simon Tschirner	2014		10.1007/978-3-319-07227-2_39	simulation;human–computer interaction;computer science	EDA	-53.1014502493605	-40.01461312333921	88031
4911cc8997d8f64de72c364e7a9934f77cb59d9b	the best approach to a large computing capability	do it yourself;individual difference	The best approach to a large computing capability is to build your own multi-processor system, utilizing the most effective elements available from the leading hardware manufacturers. To understand this approach, it would be useful to describe the type of system which is to be built. It is evident that many of the system characteristics will be prescribed by the application, others will be purely a matter of personal choice. The essential characteristics are few in number and must not be confused with the non-essential characteristics. The remainder of this paper presents a set of do-it-yourself instructions for designing your own multi-processor system which stresses the essential characteristics. The intent being that the reader can follow through these instructions and design his own system for his own particular application. In this way, each reader can have a specific system in mind which he can evaluate critically. Although there would be individual differences in the systems under consideration by different individuals, the essential characteristics would be the same, and discussion would then tend to center about these essential features. The paper concludes with a summary in which the design approach is reviewed in an attempt to emphasize the utility of the approach.	multiprocessing	George P. West	1967		10.1145/1465482.1465557	simulation;engineering;operations management	HPC	-61.04487157054028	-38.27014487772367	88236
1f4cce2bb764e7087e87cce5701c393aa15ecc4f	towards the next generation of uist: developing for all users	developpement logiciel;interfase usuario;user interface;program design;conception programme;ingenieria logiciel;software engineering;programme utilitaire;utility program;desarrollo logicial;software development;next generation;genie logiciel;interface utilisateur;concepcion programa;programa utilitario	This paper discusses design requirements and criteria for developing interactive computerbased applications and telematic services accessible by different user groups, including disabled and elderly people, in the context of the emerging Information Society. To this effect, recent contributions towards user interfaces for all are reviewed and an HCI research and practice agenda is discussed.	acm symposium on user interface software and technology;next-generation network	Constantine Stephanidis	1997			simulation;human–computer interaction;computer science;systems engineering;engineering;software development;software engineering;program design language;user interface	NLP	-61.62406728440464	-48.708750306573656	88258
9630c8cfbb86764ceea3ee497d4d276a0a6cd3e8	reusing models and properties in the analysis of similar interactive devices	procurement;haslab haslab uminho;medical devices;modal action logic;interactive systems;ivy	The paper is concerned with the comparative analysis of interactive devices. It compares two devices by checking systematically a set of template properties that are designed to explore important interface characteristics. The two devices are designed to support similar tasks in a clinical setting. The devices differ as a result of judgements based on a range of considerations including software. Variations between designs are often relatively subtle and do not always become evident through even relatively thorough user testing. Notwithstanding their subtlety, these differences may be important to the safety or usability of the device. The illustrated approach uses formal techniques to provide the analysis. This means that similar analysis can be applied systematically.	formal methods;qualitative comparative analysis;usability;user research	Michael D. Harrison;José Francisco Creissac Freitas de Campos;Paolo Masci	2013	Innovations in Systems and Software Engineering	10.1007/s11334-013-0201-3	embedded system;simulation;procurement;computer science;engineering;multimedia;engineering drawing	SE	-60.899947974789825	-47.15966228193705	88364
26be52be720966c91e88e5e0605e73a5a5393d1f	towards context based affective computing	social sciences computing;social interactions context based affective computing context based affect recognition cbar;ubiquitous computing;context conferences affective computing educational institutions visualization context modeling tv;ubiquitous computing social sciences computing	This is an introduction to the Second International Workshop on Context Based Affect Recognition CBAR 2013 Held in conjunction with Affective Computing and Intelligent Interaction 2-5 September 2013, Geneva, Switzerland.	affective computing;switzerland	Zakia Hammal;Merlin Suarez	2013	2013 Humaine Association Conference on Affective Computing and Intelligent Interaction	10.1109/ACII.2013.149	context-aware pervasive systems;human–computer interaction;computer science;knowledge management;end-user computing;multimedia;ubiquitous computing	Robotics	-57.22269849547586	-38.02285807510315	88650
cd2e6f4b46aef8680d58618546d1717d41a9538b	understanding interaction in hybrid ubiquitous computing environments	hybrid ubiquitous computing environments;human interaction;asymmetry;reconciliation work;media space;fragmentation;ubiquitous computing environment	Different kinds of computing environment effect human interaction in different kinds of ways and understanding how different environments 'work', as it were, is important to their evaluation and ongoing design. Ethnographic studies of media spaces and CVEs, for example, showed that these kinds of environment introduce asymmetry and fragment the reciprocity of perspectives that is essential to human interaction. Users are therefore obliged to engage in 'compensation work' if interaction is to proceed. However, asymmetry and fragmentation are intentional features of the hybrid ubiquitous computing environments that have emerged over recent years, which is to say that they are deliberately 'built in' to the environment through the design of heterogeneous interaction mechanisms. Interaction in hybrid ubicomp environments therefore relies upon a different order of interactional work, namely 'reconciliation work'.	fragmentation (computing);media space;ubiquitous computing	Andy Crabtree;Tom Rodden	2009		10.1145/1658550.1658551	interpersonal relationship;simulation;human–computer interaction;computer science;operating system;fragmentation;asymmetry	HCI	-56.86961235070553	-38.799690773182654	88770
73adb479a338ad64804c3d98ce01169f6cf59060	the paradox of phone attachment: development and validation of the young adult attachment to phone scale (yaps)	technology;phone addiction;attachment theory;smartphone attachment;smartphone measure	Accurate evaluation of people's attachment to phones is crucial to understanding the impact of phone use in everyday life. The Young Adult Attachment to Phone Scale (YAPS) is a concise instrument, representing the first multi-dimensional measure of phone attachment. After item development involving focus groups with young adults and content validity analysis from attachment experts, a preliminary version of the YAPS was administered to 955 participants ages 18e29. Exploratory and confirmatory factor analyses supported a 2-dimension structure: Refuge, characterized by feeling safe with the phone and uncomfortable upon separation; and Burden, characterized by relief upon separation from the phone and the perception that it diminishes enjoyment of a given moment. Findings reflect the strong psychometric properties of the YAPS, including reliability, factorial validity and criterion validity with relevant constructs. The YAPS appears promising for future research aimed at understanding the nature of attachment to phones in human behavior. © 2016 Elsevier Ltd. All rights reserved.	attachments;card security code;experience;exploratory testing;focus group;unavailability	Leora Trub;Baptiste Barbot	2016	Computers in Human Behavior	10.1016/j.chb.2016.07.050	psychology;developmental psychology;attachment theory;communication;social psychology;technology	HCI	-59.61710392198952	-49.27639097170376	88807
556fc5cd4d01cf452ded4022dc4798ba40884576	from desktop to phonetop: a ui for web interaction on very small devices	pointing device;user interface;pda;transducing;web phone;interaction model;wireless web;web browsing;large displays;transcoding;interaction technique	While it is generally accepted that new Internet terminals should leverage the installed base of Web content and services, the differences between desktop computers and very small devices makes this challenging. Indeed, the browser interaction model has evolved on desktop computers having a unique combination of user interface (large display, keyboard, pointing device), hardware, and networking capabilities. In contrast, Internet enabled cell phones, typically with 3-10 lines of text, sacrifice usability as Web terminals in favor of portability and other functions. Based on our earlier experiences building and using a Web browser for small devices we propose a new UI that splits apart the integrated activities of link following and reading into separate modes: navigating to; and acting on web content. This interaction technique for very small devices is both simpler for navigating and allows users to do more than just read. The M-Links system incorporates modal browsing interaction and addresses a number of associated problems. We have built our system with an emphasis on simplicity and user extensibility and describe the design, implementation and evolution of the user interface.	desktop computer;extensibility;interaction technique;internet access;mobile phone;modal logic;pointing device;software portability;usability;user interface;web content	Jonathan Trevor;David M. Hilbert;Bill N. Schilit;Tzu Khiau Koh	2001		10.1145/502348.502366	web service;web development;web modeling;transcoding;framing;web mapping;web-based simulation;web design;human–computer interaction;web accessibility initiative;computer science;operating system;web navigation;web page;multimedia;client-side scripting;user interface;world wide web;interaction technique;pointing device	HCI	-50.098565532045605	-40.03058548027039	88811
b54821e35654b25a90bfff3ee6974f26981d57e4	multi-party conversation of driving agents: the effects of overhearing information on lifelikeness and distraction		Recently, the applications of conversational robots have been gaining popularity due to their potential in providing information while engaging the user in a conversation. However, when a user's attention is already focused on a task, engaging them in conversation may be difficult or even risky. The Human-Robot Interaction (HRI) field should consider interaction methods where a conversational robot can keep the user informed but without the obligation of engagement in the conversation. In this study, we discuss such an approach within a driving scenario by utilizing a multi-party social robot platform that comprises three minimalistic conversational robots, which possesses the feature of being able to decrease the number of directed utterances toward a driver through a turn-taking process among the robots. The results of this study revealed that overhearing information from the multi-party conversation of driving agents is perceived as possessing more life-like characteristics compared to a conventional, one-to-one communication-based approach that directly addresses the driver. Moreover, the proposed approach reduced the distraction level and increased the enjoyment of the drivers.		Nihan Karatas;Shintaro Tamura;Momoko Fushiki;Michio Okada	2018		10.1145/3284432.3284466	robot;computer science;social psychology;conversation;social robot;human–computer interaction;distraction;popularity;obligation	HCI	-51.54219528739632	-50.07019199878688	88838
b1eb02a7f8238936d99f8ffd04d70a60ffb8e8be	moving beyond market research: demystifying smartphone user behavior in india		Large-scale mobile data studies can reveal valuable insights into user behavior, which in turn can assist system designers to create better user experiences. After a careful review of existing mobile data literature, we found that there have been no large-scale studies to understand smartphone usage behavior in India -- the second-largest and fastest growing smartphone market in the world. With the goal of understanding various facets of smartphone usage in India, we conducted a mixed-method longitudinal data collection study through an Android app released on Google Play. Our app was installed by 215 users, and logged 11.9 million data points from them over a period of 8 months. We analyzed this rich dataset along the lines of four broad facets of smartphone behavior -- how users use different apps, interact with notihcations, react to different contexts, and charge their smartphones -- to paint a holistic picture of smartphone usage behavior of Indian users. This quantitative analysis was complemented by a survey with 55 users and semi-structured interviews with 26 users to deeply understand their smartphone usage behavior. While our first-of-its-kind study uncovered many interesting facts about Indian smartphone users, we also found striking differences in usage behavior compared to past studies in other geographical contexts. We observed that Indian users spend significant time with their smartphones after midnight, continuously check notifications without attending to them and are extremely conscious about their smartphones’ battery. Perhaps the most dramatic finding is the nature of mobile consumerism of Indian users as shown by our results. Taken together, these and the rest of our findings demonstrate the unique characteristics that are shaping the smartphone usage behavior of Indian users.	battery charger;data point;fastest;holism;noise shaping;play store;scheduling (computing);semiconductor industry;smartphone;traffic shaping;user experience	Akhil Mathur;Lakshmi Manasa Kalanadhabhatta;Rahul Majethia;Fahim Kawsar	2017	IMWUT	10.1145/3130947	data collection;market research;mobile broadband;android (operating system);internet privacy;engineering	HCI	-60.582226611080635	-51.16958047913665	88845
3c0a4da7bd34d02693a6449526748073d35e677e	driven by a social and interactional routine: responding to a mobile phone summons in a car		The article reports findings from a qualitative study that draws on the methods of conversation analysis and on audio-video recordings of ordinary, real-life, non-experimental driving situations. The article shows what happens in a car after a mobile phone summons, i.e., the initial ring or beep of a car occupantâ€™s phone. It identifies three phases (i.e., orienting to, locating and handling a phone) that follow the summons and lead to an attempt at verbally responding to the summons. It is shown that the ringing of a phone (indicating an incoming call) or the beeping of a phone (indicating an incoming text message), as a socially and interactionally significant action, is treated as requiring a more or less immediate response. It is argued that this routinization of responding to a summons explains driversâ€™, and possible passengers,â€™ use of a mobile phone while traveling in a car.	mobile phone	Mirka Rauniomaa;Pentti Haddington	2012	IJCBPL	10.4018/ijcbpl.2012070104	engineering;advertising;communication;computer security	HCI	-57.58832987643557	-49.901045548898246	89127
a21d5b5776108a3308e5a587eb08af7225798422	linking spatial haptic perception to linguistic representations: assisting utterances for tactile-map explorations	assisted map reading;representation for natural language generation;haptic human computer interaction;virtual audio tactile map;spatial knowledge acquisition	Assisting utterances are helpful for blind and visually impaired map users exploring tactile maps. Virtual tactile maps explorable by haptic human-computer interfaces form the basis for multimodal presentations including automatically generated assisting utterances. This paper presents first empirical results regarding the type of utterances suitable for assisting the acquisition of survey knowledge on the basis of virtual tactile maps. The structure of the internal knowledge base, which has to support a connection between dynamic exploration movements and natural language, is presented. An example illustrates the approach and shows its practicability.	tactile graphic	Kris Lohmann;Carola Eschenbach;Christopher Habel	2011		10.1007/978-3-642-23196-4_18	natural language processing;computer vision;computer science;communication	NLP	-48.273189758229535	-39.9182663540661	89185
190b9b52f1689febbc462c8328c76a18720600d8	principles of educational multimedia user interface design	interfase usuario;ergonomia aplicada;computer assisted teaching;ergonomie conception;articulo sintesis;user interface;article synthese;educational multimedia;hombre;ensenanza asistida por computador;human;interface utilisateur;user interface design;educacion;review;applied ergonomics;enseignement assiste ordinateur;homme	INTRODUCTION Multimedia user interfaces combine various media, such as text, graphics, sound, and video, to present information. Because of improvements in technology and decreases in costs, many human factors engineers will soon be designing user interfaces that include multimedia. Many educators, parents, and students believe that multimedia helps people to learn, so one popular application of this technology will be the field of education. Unfortunately, the existing educational multimedia user interface design guidelines are based almost entirely on the opinions of experts (e.g., Allen, 1974; Arens, Hovy, & Vossers, 1993; Feiner & McKeown, 1990, 1991; Reiser & Gagne, 1982) rather than on the results of empirical research. This provides a weak foundation on which to make design decisions and slows progress in making educational multimedia user interfaces more effective. The purpose of this paper is to describe empirically based principles that multimedia user interface designers can employ to create applications that improve the likelihood that people will learn. The principles are derived from studies conducted in a wide variety of fields, including psychology, computer science, instructional design, and graphics design. The principles focus on educational multimedia applications. Other sources (e.g., Mayhew, 1992; Smith & Mosier, 1986) provide more general user interface design principles and guidelines. In any learning situation, four basic factors should be considered when evaluating learning (Bransford, 1978; Jenkins, 1979): the characteristics of (a) the materials, (b) the learner, (c) the learning task, and (d) the test of learning. CHARACTERISTICS OF THE MATERIALS The characteristics of the learning materials can significantly affect learning. Learning material characteristics include the medium, physical structure, psychological structure, conceptual difficulty, and sequence (Bransford, 1978). The following principles suggest ways to design the learning materials to improve learning. Use the Medium That Best Communicates the Information Although opinions differ (e.g., Clark, 1983; Mayer, 1997), limited evidence suggests that some media are better than others at communicating certain kinds of information (e.g., Najjar, 1996b). For example, when a learner needs to remember a small amount of verbal information for a short period of time, information that is presented via the auditory medium is generally remembered better than information that is presented via text. In one study (Murdock, 1968), learners recalled and recognized 10 items from a list better when they were presented using sound than when using text. This result is consistent (Penney, 1975; Watkins & Watkins, 1980). Studies that found conflicting results (e.g., Marcer, 1967; Sherman & Turvey, 1969) used long retention intervals or inappropriate instructions or scoring methods. For retaining information over longer periods, text appears to be better than sound for communicating verbal information. Text was superior to sound when the verbal information was a list of words (Severin, 1967), instructions (Sewell & Moore, 1980), four-line poems (Menne & Menne, 1972), and nonsense syllables (Chan, Travers, & Van Mondfrans, 1965; Van Mondfrans & Travers, 1964). However, one study (Van Mondfrans & Travers, 1964) found no learning differences between auditory and textual words. Also, if the learner's visual channel is already occupied, then it may be more appropriate to use audio verbal information than textual information. This situation occurs, for example, when pictorial animations and auditory verbal information are presented together (e.g., Baggett & Ehrenfeucht, 1983; Mayer & Anderson, 1992). A picture, it is commonly said, can be worth a thousand words. Pictures seem to help people learn information more effectively than text. This picture superiority effect appears to be strong. …	user interface design	Lawrence J. Najjar	1998	Human Factors	10.1518/001872098779480505	user interface design;psychology;cognitive psychology;medicine;human–computer interaction;computer science;engineering;artificial intelligence;multimedia;communication;user interface;mechanical engineering	HCI	-60.304697683275336	-48.14494514228517	89239
8cc8cca0536327fbe66d1d3ae56caf8dca74d402	two decades of traffic system education using the simulation game mobility		MOBILITY is a digital simulation game about traffic system planning, which has been designed as a serious game with the purpose of education and awareness raising. Since the year 2000 it has been used more than a million times in both educational and entertainment contexts. The production of digital serious games, such as MOBILITY, requires a lot of effort. Therefore, serious games are valuable investments that are expected to be of high benefit during their technical lifetime. Much has been written about the effectiveness of the use of serious games and efficiency of game production, however later phases of serious games’ lifecycles are comparatively unknown. Based on a lifecycle description of MOBILITY, a categorization of lifetime-determining factors called game aging is developed. The categorization is intended to serve as methodological framework to guide lifecycle management of serious games, such as assessing the status of a serious game regarding the categories of game aging. Game aging distinguishes three categories: technology, domain knowledge and user experience. For each of these categories the specific characteristics of MOBILITY are described and discussed. Regarding methodology, the evaluations are based on expert interviews, questionnaires and guided interviews. In summary, after two decades of application MOBILITY is still an effective educational tool for traffic system planning, although each of the examined categories shows signs of game aging. Further research is needed to systematize the framework of game aging.	simulation	Heinrich Söbke;Shankarram Athreya;Almudena Carrión-Valencia	2018		10.1007/978-3-030-02762-9_6	management science;software development process;business;entertainment;domain knowledge;categorization;user experience design;business system planning;application lifecycle management	Mobile	-62.36063553406413	-51.34198732339548	89392
ef171d5643f7c068ffc8be365228e94f55e9c958	a role casting method based on emotions in a story generation system	online game;non player character	We first point out a problem in the role casting method of a story generation system called OPIATE and then propose a solution to this problem. The existing casting method does not take into account the emotions of a cast non-player character towards actions that it must perform in its role, leading to a miscast. In the proposed casting method, such emotions are considered, besides emotions towards other characters as done in the existing one. Evaluation results, using an online-game simulator, confirm the effectiveness of the proposed method over the existing one with respect to the number of miscasts.		Ruck Thawonmas;Masanao Kamozaki;Yousuke Ohno	2007		10.1007/978-3-540-74873-1_22	simulation;engineering;multimedia;social psychology	AI	-54.47634410786371	-47.95330088550255	89406
e904df9534c2beeeec4f88bb365c2b3f11bd661a	join the ride! user requirements and interface design guidelines for a commuter carpooling platform		Carpooling might be a solution for maintaining mobility and reducing traffic problems of cities. In order to exploit the potential of carpooling for congested cities, to enhance the awareness of carpooling platforms among commuters and citizens, and to improve the interaction with existing carpooling web solutions, user-centered research methods (focus groups and usability analysis) were applied to understand the key motivators, acceptance barriers, and design requirements associated with carpooling platforms. The diversity of potential commuter platform users regarding age, gender, carpoolingand Internet expertise was also considered.	acceptance testing;focus group;internet;requirement;usability;user-centered design	Katrin Arning;Martina Ziefle;Heike Muehlhans	2013		10.1007/978-3-642-39238-2_2	simulation;engineering;civil engineering;transport engineering	Mobile	-56.051985473846415	-39.56245162282458	89442
0980378f938e34841fc0647c3ae8f1faf3a9ceb4	"""""""i can watch what i want"""": a diary study of on-demand and cross-device viewing"""		In recent years, on-demand video services, such as Netflix and Amazon Video, have become extremely popular. To understand how people use these services, we recruited 20 people from nine households to keep a viewing diary for 14 days. To better understand these household viewing diaries, in-depth interviews were conducted. We found that people took advantage of the freedom and choice that on-demand services offer, watching on different devices and in different locations, both in the home and outside. People often watched alone so they could watch what they wanted, rather than coming together to watch something of mutual interest. Despite this flexibility, the evening prime time continued to be the most popular time for people to watch on-demand content. Sometimes they watched for extended periods, and during interviews concerns were expressed about how on-demand services make it far too easy to watch too much and that this is often undesirable.	diary studies;expectation propagation;laptop;web service	Jacob M. Rigby;Duncan P. Brumby;Sandy Gould;Anna L. Cox	2018		10.1145/3210825.3210832		HCI	-55.31874520501981	-40.36992347356695	89592
0ca279b95b63b25db594deb46d8f21d9b45bbd92	epik - virtual rehabilitation platform devised to increase self-reliance of people with limited mobility		In this paper we describe a virtual rehabilitation platform designed to improve balance of people with physical impairment using the Microsoft® Kinect® sensor. Different types of users can interact with the platform: Administrators, therapists, and final users (patients), using their own interfaces and modules. Six modules have been designed: Profile, Administrator, Evaluation, Therapist, Game and Results; but only four have been implemented so far: Administrator, Evaluation, Therapist and Game. The Administrator’s module is used to generate a database of exercises. The Therapist’s module allows therapists to configure the game training session using combinations of exercises from the database. The patients’ or game module includes a 3D immersive environment, where they perform the prescribed rehabilitation exercises, previously configured by a therapist. The platform is in its first beta version and ready to be tested.	immersion (virtual reality);kinect;software release life cycle;system administrator;user-centered design;velocity (software development)	Sonia Garrote;Azael J. Herrero;Miguel Pedraza-Hueso;Carlos González-Gutiérrez;María V. Fernández-San Román;Francisco Javier Díaz Pernas;Héctor Menéndez;Cristina M. Ferrero;Mario Martínez-Zarzuela	2015		10.5220/0005484301880193	simulation;medicine;physical medicine and rehabilitation;physical therapy	HCI	-51.136843605660204	-44.95767590949879	89692
be68da71e531d3d706c3afc1af93e8688f29be0e	buildbot: robotic monitoring of agile software development teams	agile software development;human computer interaction;monitoring programming software engineering auditory system humans software prototyping virtual prototyping robot sensing systems robot vision systems atmosphere;human robot interaction;development process;software engineering;robotic interface buildbot robotic monitoring agile software development teams continuous integration process human robot interaction human group dynamics software engineering;group dynamic;design and implementation;robots;software engineering human computer interaction robots	In this paper, we describe BuildBot, a robotic interface developed to assist with the continuous integration process utilized by co-located agile software development teams. BuildBot's physical nature allows us to engage the agile software development team members through vision, hearing and touch. In this way, BuildBot becomes an active part of the development process by bringing together human-robot interaction, human group dynamics and software engineering concepts through a number of interaction modalities. In this paper we describe the design and implementation of the BuildBot prototype, a robotic interface that can sense virtual stimuli, in this case the state of a software build, and react accordingly in a physical way via vision, sound and touch. We present an early evaluation comparing BuildBot to two other tools used by an agile team to monitor the continuous integration process. We also show preliminary results indicating that BuildBot may be more noticeable to the developers and contribute to a fun and lighthearted atmosphere. We argue that by increasing awareness of the state of the software build, BuildBot can assist in the self-supervision of agile software engineering teams and can help the team achieve its goals in a more engaging and sociable manner.	agile software development;buildbot;continuous integration;human–robot interaction;prototype;realms;robot;software build;software developer;software engineering;virtual reality;workstation	Ruth Ablett;Ehud Sharlin;Frank Maurer;Jörg Denzinger;Craig Schock	2007	RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2007.4415217	human–robot interaction;robot;personal software process;team software process;simulation;software engineering process group;human–computer interaction;agile usability engineering;computer science;artificial intelligence;software design;social software engineering;software development;software design description;software construction;agile software development;systems development life cycle;software walkthrough;empirical process;resource-oriented architecture;lean software development;software development process;group dynamics;software system	SE	-52.136375316308964	-44.822305407585354	89780
f1821200526adf4c3f78d54d2980c84cdd48e436	where to place my ambient persuasive display? insights from a six-month study	private household;requirement study;ambient persuasive display;household change;limited knowledge;persuasive display;six-month study;long-term household study;placement decision;minimal change;actual placement	How does the placement of an ambient persuasive display for modifying energy consumption in the household change over a period of six months? There is limited knowledge about where individuals place such displays in their private households. Location is essential for the sustainable usage of persuasive displays. There is a need to gain insights into the placement decisions of users. We gathered this information in two studies. First, we did a requirement study to collect data where participants would potentially place a display. Second, we conducted a long-term household study to review the actual placement. Participants sent us pictures of their positioning at the beginning and the end of the study. It revealed minimal changes in the position of the displays, but that the choice of position is a very intentional one. We point out our findings and the benefit of this knowledge for the development of ambient persuasive displays.		Patricia M. Kluckner;Astrid Weiss;Manfred Tscheligi	2013		10.1007/978-3-642-37157-8_14	simulation;communication;social psychology	HCI	-58.527742475115936	-43.549283120732184	89960
194eb3fcae9537d022de7a42957beef4b5278eba	sociable robot improves toddler vocabulary skills	robot sensing systems;time 2 week sociable robot autonomously operated robot intervention period toddler vocabulary skills early childhood education center;pediatrics;ubiquitous computering algorithms human factors robotics;games pediatrics educational institutions vocabulary robot sensing systems;vocabulary;ubiquitous computering;robotics;human factors;vocabulary educational robots human robot interaction social aspects of automation;games;algorithms;ubiquitous computing	We report results of a study in which a low cost sociable robot was immersed at an Early Childhood Education Center for a period of 2 weeks. The study was designed to investigate whether the robot, which operated fully autonomously during the intervention period, could improve target vocabulary skills of 18-24 month of age toddlers. The results showed a 27 % improvement in knowledge of the target words taught by the robot when compared to a matched set of control words. The results suggest that sociable robots may be an effective and low cost technology to enrich Early Childhood Education environments.	robot;vocabulary	Javier R. Movellan;Micah Eckhardt;Marjo Virnes;Angelica Rodriguez	2009	2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1514095.1514189	robot learning;games;simulation;computer science;multimedia;robotics;ubiquitous computing;personal robot	Robotics	-49.197865556645084	-48.97002338167495	90015
0bb4b3185ea04b2fe7c5721a5096cf913a5a26c8	integration of nomadic devices with automotive user interfaces	automotive engineering;wireless nomadic devices infotainment vehicular integration;web 2 0 information migration;telematics;automotive engineering user interfaces personal digital assistants cellular phones digital audio players calendars videos keyboards vehicles accidents;wireless;google map;user interface;cellular radio;cell phones;user interfaces cellular radio internet traffic engineering computing;ajax based applications;vehicular integration;computer architecture;internet;automotive user interfaces;infotainment;safety;traffic engineering computing;bluetooth;vehicles;google maps automotive user interfaces nomadic devices cell phones web 2 0 information migration internet ajax based applications;user interfaces;cellular phones;google maps;nomadic devices	The number of nomadic devices such as PDAs, MP3 players and especially cell phones has largely grown in the last years; Indeed, cell phones are becoming powerful, always-connected computers that store a lot of personal information (contacts, calendar, personal videos and pictures). The small size of their keyboards and screens is a major limitation of nomadic devices, hampering their utilization in vehicles. Handling them while driving may distract the user and increases the risk of accident, and it is illegal in some countries. According to the Web 2.0 vision, the Internet is a platform rather than a mere source of information. The interfaces of Ajax-based applications are user friendly, and they allow storing personal information and preferences. Google Maps is a good example of this philosophy. Nowadays, it is a familiar tool in desktop computers to locate destinations and to plan routes at home. In this paper we propose a new model of Web 2.0 information migration to nomadic devices that facilitates is access to cars.	ajax (programming);data mule;delay-tolerant networking;desktop computer;embedded system;image;information source;internet;mp3;mobile phone;personal digital assistant;personally identifiable information;prototype;usability;user interface;vhdl-ams;web 2.0;world wide web	Felipe J. Gil-Castiñeira;David Chaves-Díeguez;Francisco Javier González-Castaño	2009	IEEE Transactions on Consumer Electronics	10.1109/TCE.2009.4814411	embedded system;telecommunications;computer science;engineering;operating system;multimedia;user interface;world wide web	Mobile	-49.814413914753416	-42.07654344534949	90253
b16c0f41e4c854cce2ed474953944e4f13269eaa	a study of the cultural effects of designing a user interface for a web-based service	user interface;user interface design;chinese;cultural differences;web based service	With the globalisation of markets and the internet, customer satisfaction now depends on how seriously service providers take into account regional user needs combined with culturally-suitable user interface design. The objective of this study was to investigate the effects of two cultural dimensions, Time Orientation (TO) and Communication Style (CS), on user performance in browsing a web-based service. A comparison in Hofstedes cultural dimensions was also made between two Chinese-speaking student groups. The results showed that participants with polychronic TO performed faster and took fewer steps than those with monochronic TO. Participants with high-context CS were more disorientated than those with low-context CS. The comparison in cultural dimensions indicated that there is a variety even within Chinese-speaking cultures. To be able to meet customers expectations and increase their satisfaction, it is necessary for user interface designers to consider these cultural effects.	user interface design;web application	Pei-Luen Patrick Rau;Sheau-Farn Max Liang	2003	IJSTM	10.1504/IJSTM.2003.003627	user interface design;user;computer user satisfaction;human–computer interaction;computer science;multimedia;user interface;world wide web;chinese	HCI	-60.20645113202547	-46.583251559558526	90300
b102953a64b5eb45dbc76d47765f62eea792df3d	ihap: towards a vision substitution system for active analysis of facial expressions	real time;depth of field;layers;rendering	"""People who are blind have the inherent tendency of exploring their interaction partner's face to know them better and feel closer. This becomes a necessity when partners become engaged in a conversation and want to be aware of the different facial expressions. Current technologies can deliver coarse-grained abstract haptic cues to the visually impaired. A better solution is needed -- one that allows a blind individual interpretation of others' facial expressions while engaged in bilateral conversation. To meet this goal, the development and evaluation of a platform called 'iHap' is proposed - an interactive haptic-based """"Explore-learn-interact"""" paradigm that enables a blind individual to access his own facial expressions in a dynamic virtual environment. It is hypothesized that persistent haptic exploration of different movements of a blind individual's own facial features for different expressions in the virtual environment will help him master the haptic language of facial expressions. Hence he will be able to explore others' facial expressions/emotions while engaged in social interaction. As a blind individual makes active use of the sense of touch through feature by feature analysis, emphasis has been given to feature-based active exploration of facial expressions."""	bilateral filter;haptic technology;programming paradigm;rewriting;virtual reality	Shamima Yasmin;Sethuraman Panchanathan	2015		10.1145/2699276.2721394	computer vision;layers;rendering;computer science;depth of field;multimedia;computer graphics (images)	HCI	-52.943393861815025	-44.617731410074676	90409
a47ccb0df4e54098f9e4a58836f52f103329bf3b	a model for generating and animating groups of virtual agents	animacion por computador;multiagent system;group formation;visual representation;crowd;group membership;multitud;computer animation;sistema multiagente;foule;virtual agent;systeme multiagent;animation par ordinateur	This paper presents a model to generate and animate groups which emerge as a function of interaction among virtual agents. The agents are characterized through the following parameters: sociability, communication, comfort, perception and memory. The emergent groups are characterized through the cohesion parameter which describes the homogeneity of ideas of the group members. In this work we are mainly interested in investigating the formation of groups (membership and time for grouping), the groups characterization (cohesion parameter) and their visual representation (group formation). The overall results suggest that the interaction among agents contributes to larger groups and higher crowd cohesion values.	cohesion (computer science);emergence;intelligent agent	Marta Becker Villamil;Soraia Raupp Musse;Luiz Paulo Luna de Oliveira	2003		10.1007/978-3-540-39396-2_26	simulation;computer science;artificial intelligence;computer animation	HCI	-53.13424018567869	-48.737959798377446	90460
6ae6cac0c5bf4886fe6733d3a4e3b1c0f84d52b8	bridging the web accessibility divide	computer engineering bridging the web accessibility divide state university of new york at stony brook i v ramakrishnan;change detection;web pages;web accessibility;partitioning;semantic blocks;visual navigation;information overload;non visual;content analysis;screen reader;machine learning;steven skiena borodin yevgen;web transaction;assistive technology;visual impairment;content adaptation;process model;dynamic content;content adaption;context;hearsay	The Web has become the primary medium for accessing information and for conducting many types of online transactions, including shopping, paying bills, making travel plans, etc. The primary mode of interaction over the Web is via graphical browsers designed for visual navigation. Sighted users can visually segment web pages and quickly identify relevant information. On the contrary, screen readers the dominant assistive technology used by visually impaired individuals function by speaking out the screen’s content serially. Consequently, users with visual impairments are forced to listen to the information in web pages sequentially, thereby experiencing considerable information overload. This problem becomes even more prominent when conducting online transactions that often involve a number of steps spanning several pages. Thus, there is a large gap in Web accessibility between individuals with visual impairments and their sighted counterparts. This paper we describe our ongoing work on this problem. We have developed several techniques that synergistically couple web content analysis, user’s browsing context, process modeling and machine learning to bridge this divide. These techniques include: 1) context-directed browsing that uses link context to find relevant information as users move from page to page; 2) change detection that separates the interface from the implementation of web pages and helps users find relevant information in changing web content; and 3) process modeling that helps users find concepts relevant in web transactions. We describe these three techniques within the context of our Hearsay non-visual web browser.	algorithm;assistive technology;bridging (networking);cns;dynamic web page;e-commerce;file spanning;graphical user interface;ibm notes;information overload;internet information services;machine learning;machine vision;mobile device;natural language processing;process modeling;relevance;speech synthesis;synergy;user experience;web 2.0;web accessibility;web content;web page;world wide web	I. V. Ramakrishnan;Jalal Mahmud;Yevgen Borodin;Muhammad Asiful Islam;Faisal Ahmed	2009	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2009.03.007	web service;web development;web modeling;framing;web analytics;web mapping;web design;human–computer interaction;content analysis;web accessibility initiative;web standards;computer science;dynamic web page;information overload;web navigation;social semantic web;web accessibility;web page;process modeling;printer-friendly;multimedia;client-side scripting;web intelligence;web 2.0;world wide web;change detection;web server;mashup	Web+IR	-52.191711627467384	-41.58816386242454	90462
fc65c138844129170683872eead38ec256b6e047	usability heuristics and qualitative indicators for the usability evaluation of touch screen ventilator systems	usability evaluation;intensive care unit;touch screen;user interface;patient care;heuristic evaluation;patient safety;critically ill patient;medical error	A ventilator system provides respiratory support to critically ill patients in the Intensive Care Unit. Increasing complexity in the user interface, features and functionalities of ventilator systems can cause medical errors and cost the life of a patient. Therefore, the usability of ventilator systems is most crucial to ensure patient safety. We have evolved a specialized set of heuristics combined with objectively defined usability indicators for the usability evaluation of touch screen based ventilator systems. Our study presents the heuristic evaluation of three touch screen based ventilator systems manufactured by three different companies. The heuristic evaluation has been performed by four different usability evaluators to ensure the reliability of heuristics proposed in this paper. The specialized set of heuristics linked with user interface components and the objectively defined usability indicators are found more reliable in identifying specific usability problems of ventilator systems.	heuristic (computer science);heuristic evaluation;touchscreen;usability;user interface	Dinesh S. Katre;Ganesh Bhutkar;Shekhar Karmarkar	2009		10.1007/978-3-642-11762-6_8	usability goals;pluralistic walkthrough;web usability;embedded system;cognitive walkthrough;simulation;usability;human–computer interaction;engineering;heuristic evaluation;usability inspection	HCI	-62.79569930577882	-51.77778146743043	90513
3dc2e7b025b6857ffa91729c783a4c0aacd67385	understanding the whethers, hows, and whys of divisible interfaces	paper prototyping;personal computer;multi device interfaces;divisible interfaces	Users are increasingly shifting from interacting with a single, personal computer to interacting across multiple, heterogeneous devices. We present results from a pair of studies investigating specifically how and why users might divide an application's interface across devices in private, semi-private, and public environments. Our results suggest that users are interested in dividing interfaces in all of these environments. While the types of divisions and reasons for dividing varied across users and environments, common themes were that users divided interfaces to improve interaction, to share information, and to balance usability and privacy. Based on our results, we present implications for the design of divisible interfaces.	interaction;personal computer;semiconductor industry;usability	Heather M. Hutchings;Jeffrey S. Pierce	2006		10.1145/1133265.1133320	human–computer interaction;computer science;operating system;distributed computing;world wide web	HCI	-56.64040063578936	-39.352429380214794	90591
45c4e14a17b85448174ca3bd636f89682290ed14	hotwire: an apparatus for simulating primary tasks in wearable computing	human computer interaction;hotwire experiment;interruption study;primary task simulation;wearable computer;laboratory experiment;wearable computing	In this paper we present a novel apparatus for simulating real world primary tasks typically found in wearable computing. Additionally, we report on a preliminary interruption study using the new apparatus in a laboratory experiment and compare its results with previous work to show its applicability for research in human-computer interaction for wearable computers.	human–computer interaction;interrupt;simulation;wearable computer	Hendrik Witt;Mikael Drugge	2006		10.1145/1125451.1125732	simulation;wearable computer;human–computer interaction;computer science;multimedia	HCI	-49.86466292752118	-46.20593951208965	90649
8a72fddb8f9628ab5e9820ac232091989351d21e	exploring the effects of robot gender on child-robot interaction		Despite the increase of research and applications for child-robot interactions, little is known about children»s responses to a robot»s gender across age and gender groups. This paper presents an exploratory study intended to examine whether the perceived robot»s gender affects the interaction between a child and a robot. This paper details the preliminary results of an observational child-centered study with a gendered robot that was conducted in the hall of a residential facility with 24 children. Our findings suggest that children liked playing with the robot of the same gender as them.	interaction;robot	Korlan Zhumabekova;Altynay Ismailova;Daniyar Kushkinbayev;Anara Sandygulova	2018		10.1145/3173386.3177044	human–computer interaction;exploratory research;social robot;robot;computer science;observational study	HCI	-53.2945661255662	-51.05536828380997	90755
2f10013befc90ece385a0d2a85ce5e4c61841ce5	a location-based personal task reminder for mobile users	location based services;gps;wi fi;locationing	Personal task reminders have been indispensable for modern people, in order to remind them of their tasks at specific circumstances. Traditional paper-based reminders are still useful, but they cannot be organized efficiently. Electronic reminders based on the calendar in cell phones are more efficient and gaining popularity, but such reminders are mostly triggered by time. In many situations, tasks are only meaningful to be performed at a specific location, so it would be useful if reminders for those tasks can be triggered only when the person to be reminded is physically near or located at that location. Therefore, in this research, we develop a location-based personal task reminder for Android-based smartphones and tablets. To distinguish our work from existing ones that rely solely on the GPS technology, we take advantage of the ubiquity of IEEE 802.11 WLAN infrastructure to compliment the “blind spots” of GPS location sensing. Combining the two technologies makes it possible for the personal task reminder to be effective in both indoor and outdoor environments. We also propose two operating models for the personal task reminder to boost the usability of the application. Furthermore, as long as the WLAN infrastructure is available, our work as a foundation of location-based services can easily be extended to be used in many other scenarios, such as guiding in public transportation systems or tourist attractions, location-based learning, and even caring of the Dementia residents.	android;canonical account;global positioning system;location-based service;mobile device;mobile phone;operating model;smartphone;software versioning;usability;user experience;user interface	Chi-Yi Lin;Ming-Tze Hung	2013	Personal and Ubiquitous Computing	10.1007/s00779-013-0646-2	embedded system;simulation;global positioning system;computer science;location-based service;internet privacy	HCI	-50.146565952421916	-41.55850229567653	90771
c1a624ef06ea3118b2370752ee841cc49f69a0e7	intuito: opportunistic tangible programming by demonstration for physical components		"""As computer programming becomes more important to various fields and disciplines and as it is more commonly taught in education settings, the number of end-users with basic programming experience is increasing. The importance of being able to easily and quickly develop programs has prompted research in """"opportunistic' programming methods. This research contributes to this domain by introducing a platform called Intuito, designed for programming physical components (sensors and actuators) through direct """"programming by demonstration' techniques. Our approach is to offer users a tangible system that maps the user's actions with sensors and actuators into editable text-based code by inferring the user's intentions. We present our initial hardware and software prototype with an in-lab preliminary evaluation of this system."""	as-interface;basic programming;bluetooth;brainstorm;computer programming;database;home automation;map;programmer;programming by demonstration;prototype;software prototyping;text-based (computing);usability testing;wearable technology	Rawan Alharbi;Nabil Alshurafa;Michael Horn	2017		10.1145/3027063.3053264	inductive programming;functional reactive programming;multimedia;human–computer interaction;event-driven programming;programming paradigm;intentional programming;programming by demonstration;reactive programming;computer science;extensible programming	HCI	-50.861190757413496	-38.84667729319346	90876
e144300b6e1963ee1b0d370605f26624f84476b7	an invisible gorilla: is it a matter of focus of attention?	focus of attention;eeg sensors;video training exercises	How to evaluate users’ attention level in a video task is a challenge. One of the conventional methods is to link users’ focus of attention to their performance undertaken in a video. However, this is not always true in a video environment, as users’ poor performance may be resulted from some other reasons rather than a lack of focus of attention. In this article, we demonstrated our assumption by using an Electroencephalography (EEG) sensor, which measured the users’ attention level in a video task. Our results showed one case that some of the users with a poor performance in the video task had the same level of attention compared to those users with a good performance. In particular, an interference object in the video, aimed for distracting the users’ attention, had no impact on some of the users’ focus when they were already involved in the video task.	electroencephalography;immersion (virtual reality);interference (communication);performance;usability testing	Chen Wang;Pablo César;Erik Geelhoed	2013		10.1007/978-3-319-03731-8_30	multimedia	Vision	-49.33215603417777	-47.359096345837045	90881
10389d6f37e8d1394d3fcd19d988a8e3856bfd8e	spalendar: visualizing a group's calendar events over a geographic space on a public display	interactive visualization;location;social network;visualization;design human factors;situated interaction;calendar;public display;technical report;video;group	Portable paper calendars (i. e., day planners and organizers) have greatly influenced the design of group electronic calendars. Both use time units (hours/days/weeks/etc.) to organize visuals, with useful information (e.g., event types, locations, attendees) usually presented as - perhaps abbreviated or even hidden - text fields within those time units. The problem is that, for a group, this visual sorting of individual events into time buckets conveys only limited information about the social network of people. For example, people's whereabouts cannot be read 'at a glance' but require examining the text. Our goal is to explore an alternate visualization that can reflect and illustrate group members' calendar events. Our main idea is to display the group's calendar events as spatiotemporal activities occurring over a geographic space animated over time, all presented on a highly interactive public display. In particular, our Spalendar (Spatial Calendar) design animates people's past, present and forthcoming movements between event locations as well as their static locations. Detail of people's events, their movements and their locations is progressively revealed and controlled by the viewer's proximity to the display, their identity, and their gestural interactions with it, all of which are tracked by the public display.	calendaring software;interaction;social network;sorting	Xiang 'Anthony' Chen;Sebastian Boring;M. Sheelagh T. Carpendale;Anthony Tang;Saul Greenberg	2012		10.1145/2254556.2254686	simulation;video;visualization;interactive visualization;human–computer interaction;computer science;artificial intelligence;technical report;data mining;multimedia;group;location;world wide web;social network	HCI	-55.233599818129036	-43.087672308941386	91080
9edff11c2d08bdd3ec09faa0ea58c422dc0fa02e	the nature of the bots: how people respond to robots, virtual agents and humans as multimodal stimuli	dominance;embodiment;mirroring;human robot interaction;display;gestures;virtual agents;physical agents	This research agenda aims to understand how people treat robots along two dialectics. In the mechanical-living dialectic, fabricated entities are assessed against their organic counterparts to see if people respond differently to robots versus other people. Multiple experiments are conducted that compare human-robot relationships to human-human relationships by manipulating roles in videos of dyadic conversations shown to participants. In the physical-digital dialectic, a physically embodied robotic agent is compared to either a digitally-presented virtual agent (such as an animated character on a computer screen) or a digitally-presented robotic agent (such as a live video feed of the robot). The role of physical and digital embodiment and display medium are explored through a comprehensive survey and analysis of existing experimental works comparing physical and digital agents. Key research questions, related work, scope, research approach, current findings and remaining work are outlined.	computer monitor;dyadic transformation;entity;experiment;human–robot interaction;intelligent agent;multimodal interaction;robot;video	Jamy Li	2013		10.1145/2522848.2532193	human–robot interaction;computer vision;simulation;mirroring;embodied agent;computer science;artificial intelligence;linguistics;multimedia;dominance;gesture	HCI	-52.66813827917361	-49.63421247162516	91253
008397f7b7f1865f1b7b119f3f0d96411f7c2f5d	a multi-agent system for meting out influence in an intelligent environment	multi agent system;office building;data collection;intelligent environment;multi agent systems;agents;intelligent environments;ubiquitous computing;environmental factor	Intelligent environments are physical spaces that can sense and respond to the people and events taking place within them, providing opportunities for people to influence environmental factors that affect them, such as the lighting, temperature, décor or background music in the common areas of an office building. The designer of an environment that can be influenced by a group of collocated people rather than a single individual must decide how to accord influence among the individuals in the group. We have designed two multi-agent group preference arbitration schemes and tested them out in an intelligent environment, MUSICFX, which controls the selection of music played in a fitness center. One scheme seeks to maximize the average satisfaction of the inhabitants, the other seeks to maximize the equitable distribution of satisfaction among the inhabitants. We present the results of a series of experiments using real data collected from the deployed system, and discuss the ramifications of these two potentially conflicting goals.	experiment;intelligent environment;multi-agent system	M. V. Nagendra Prasad;Joseph F. McCarthy	1999			simulation;computer science;knowledge management;artificial intelligence;software agent;multi-agent system;data collection	AI	-57.688361353229396	-48.7551618552203	91272
291e52a27afb84c8ae7f7fe7c2982fab75b94a8e	a cultural re-mediation model for storytelling in pre-school education		The use of the emotional language of stories and the amplification of the empathic driver thanks to the identification with story characters, makes the storytelling a valuable educational approach, especially for children. In accordance with embodied and situated cognition theories, manipulative storytelling proposes interactive environments where it is also possible for learners to manipulate the story through objects and tangible interfaces. In line with this vision, we propose in this paper a new model enabling the design and the execution of educational stories for children aged from 3 to 6. Stories are seen as sequences of missions: game experiences where children can interact to reach the educational objective. A re-mediation strategy, able to adapt the story on three different axis (immediacy-hypermediation, similarity-dissimilarity and aggregation-disaggregation) on the basis of assessment results, is also presented. A proof of concept based on the popular Brother Grimm’s Hansel and Gretel tale is then discussed to demonstrate the capabilities of the model in the construction and deconstruction of the building blocks of a story.		Nicola Capuano;Angelo Gaeta;Matteo Gaeta;Giuseppina Rita Mangione;Anna Pierri	2015	iJET		cognition;artificial intelligence;multimedia	NLP	-54.37678630513448	-46.8148513016427	91436
dfb86d89a9aa5e543685e311cd8043d72bb82888	investigating intrusiveness of workload adaptation	brain computer interface;user study;workload adaptive assistance;intrusiveness	In this paper, we investigate how an automatic task assistant which can detect and react to a user's workload level is able to support the user in a complex, dynamic task. In a user study, we design a dispatcher scenario with low and high workload conditions and compare the effect of four support strategies with different levels of intrusiveness using objective and subjective metrics. We see that a more intrusive strategy results in higher efficiency and effectiveness, but is also less accepted by the participants. We also show that the benefit of supportive behavior depends on the user's workload level, i.e. adaptation to its changes are necessary. We describe and evaluate a Brain Computer Interface that is able to provide the necessary user state detection.	brain–computer interface;usability testing	Felix Putze;Tanja Schultz	2014		10.1145/2663204.2663279	brain–computer interface;real-time computing;simulation;human–computer interaction;computer science	Web+IR	-48.43394214719073	-47.15041775238959	91596
4b621bc8460f83c429ccbbfbb1496700070c160a	ar petite theater: augmented reality storybook for supporting children's empathy behavior	atmospheric measurements;role playing augmented reality empathy early school age children human computer interaction;particle measurements;social aspects of automation augmented reality behavioural sciences multimedia computing;abstracts magnetic resonance imaging atmospheric measurements particle measurements sun;egocentric perspective augmented reality storybook children empathy behavior support children role playing augmented reality technology interactive reading experience school age children;abstracts;magnetic resonance imaging;sun	In this paper, we present an AR Petite Theater, a story book that enables role-play using augmented reality (AR) technology. It provides an opportunity for children to learn the ability of empathy through interactive reading experience by thinking and speaking in accordance with the character's role of the story. In general, empathy is one of most important elements for children to make friends at school and to expand their social relations. In particular, it is crucial for early school-age children who have difficulties in getting along with friends due to their egocentric perspective. Through the experiment with 24 six-year-old children, we measured children's role-playing participation and perspective taking state. As a result, more empathic behaviors were revealed in the AR group. Children in the AR condition were more actively involved in role-playing and showed less unrelated perspectives than children in the non-AR condition. Therefore, we verified that AR Petite Theater had the potential of expanding children's ability to empathize with others.	augmented reality;screenwriting	Kyungwon Gil;Jimin Rhim;Taejin Ha;Young Yim Doh;Woontack Woo	2014	2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)	10.1109/ISMAR-AMH.2014.6935433	sun microsystems;simulation;computer science;magnetic resonance imaging;multimedia	HCI	-57.4452812407241	-39.60131515214742	91742
2fd0bd3add31407ad2e3a159e8b202f76f659d0d	augmenting online conversation through automated discourse tagging	communication systems;user study;collaboration;runtime;text messaging;tagging sparks facial animation context avatars rendering computer graphics collaboration buildings communication systems runtime;automatic annotation;facial animation;sparks;computer mediated communication;avatars;rendering computer graphics;face to face;context;buildings;route planning;tagging	In face-to-face communication, the communicative function of the spoken text is clarified through supporting verbal and nonverbal discourse devices. In computer-mediated communication, the mediating channel may not be able to carry all those devices. To ensure the original intent gets communicated effectively, discourse tags can be embedded in a message to encode the communicative function of text given the context in which it was produced. The receiving client can then generate its own supporting discourse devices from the received tags, taking into account the receiver's context. Spark is a synchronous CMC architecture based on this concept of a message transformation, where an outgoing text message gets automatically annotated with discourse function markup that is then rendered as nonverbal discourse cues by a graphical avatar agent on the receiver side. A user study performed on a derived application for collaborative route planning demonstrates the strength of the approach.	computer-mediated communication;encode;embedded system;graphical user interface;markup language;usability testing	Hannes Högni Vilhjálmsson	2005	Proceedings of the 38th Annual Hawaii International Conference on System Sciences	10.1109/HICSS.2005.109	computer facial animation;computer science;operating system;database;multimedia;programming language;management;world wide web;communications system;computer-mediated communication;collaboration	HCI	-52.245113845809364	-44.73611250580564	91785
44f692e8abb8f61cabb494ed0470de7b68b144da	making the link - providing mobile media for novice communities in the developing world	m4d;south african;low income;situated media;developing world;ict4d;mobile user	In this paper we investigate the media needs of low-income mobile users in a South African township. We develop and deploy a system that allows users to download media at no costs to themselves, in order to probe future media requirements for similar user groups. We discover that not only are the community interested in developmental information, but are also just as interested in sharing local music or videos. Furthermore, the community consume the media in ways that we did not expect, which had direct impacts on their lives. Finally, we conclude with some reflections on the value of media and the most appropriate ways to deliver it in developing		Andrew J. Maunder;Gary Marsden;Richard Harper	2011	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2010.12.009	simulation;developing country;multimedia	HCI	-56.02854767380848	-40.62739200395663	91878
b22a081a2227ba230563afaa10f20bb536b76bd7	evaluating and informing the design of chatbots		Text messaging-based conversational agents (CAs), popularly called chatbots, received significant attention in the last two years. However, chatbots are still in their nascent stage: They have a low penetration rate as 84% of the Internet users have not used a chatbot yet. Hence, understanding the usage patterns of first-time users can potentially inform and guide the design of future chatbots. In this paper, we report the findings of a study with 16 first-time chatbot users interacting with eight chatbots over multiple sessions on the Facebook Messenger platform. Analysis of chat logs and user interviews revealed that users preferred chatbots that provided either a 'human-like' natural language conversation ability, or an engaging experience that exploited the benefits of the familiar turn-based messaging interface. We conclude with implications to evolve the design of chatbots, such as: clarify chatbot capabilities, sustain conversation context, handle dialog failures, and end conversations gracefully.	chat log;dialog system;embedded system;facebook messenger;file spanning;interaction;natural language;software agent;text-based (computing)	Mohit Jain;Pratyush Kumar;Ramachandra Kota;Shwetak N. Patel	2018		10.1145/3196709.3196735	human–computer interaction;chatbot;engineering;multimedia;conversation;the internet;natural language;dialog box;dialog system	HCI	-55.59571963511929	-43.361238268409984	92025
f5dd773e89e8ab624db01245f2f729661b30eb68	self-reflection on personal values to support value-sensitive design	long period;value elicitation;experience sampling;tool support;affect;development tool;human values;personal informatics;exploratory study;social media;value sensitive design	The impact of ubiquitous technology and social media on our lives is rapidly increasing. We explicitly need to consider personal values affected or violated by these systems. Value-sensitive design can guide a designer in building systems that account for human values. However, the framework lacks clear steps to guide elicitation of stakeholders’ values. We argue that developing tools for value elicitation that designers can use or give to stakeholders is a feasible solution to this challenge. Crucial in eliciting values is that a stakeholder has to have an understanding about her own values and how they relate in importance. This requires self-reflection. Self-reflection, in turn, requires thinking or analysing one’s behaviour in meaningful moments over a long period of time. In this paper, we investigate how current methods from various disciplines can be combined and applied in a tool supporting reflection on personal values. We present an exploratory study investigating photo elicitation and a value questionnaire as methods for expressing and eliciting values with a tool. Based on the results we present an envisioned mobile personal informatics application that triggers people to reflect about their values in real-life contexts.	attribute–value pair;informatics;quantified self;real life;self-reflection;social media;value (ethics);value sensitive design	Alina Pommeranz;Christian Detweiler;Pascal Wiggers;Catholijn M. Jonker	2011			engineering;knowledge management;management science;social psychology	HCI	-59.08978135137171	-43.41097317692855	92176
9a3e3e3aa5629210ca7a52f035813e6d67f1c5cc	transition of aesthetic emotions in interactive environments		With the rapid expansion in interactive environments, the need for more sophisticated cognitive models of aesthetic emotion transition is even more pressing for both academic and industrial applications. As part of our research to develop a model of aesthetic emotions and their patterns of transition, we have conducted two free report experiments concerning an interactive environment (a driving simulation), and have extracted and analyzed emotion words from collected verbal protocol data. In this research, we considered aesthetic emotions to be an overall configuration of cognitive components, and this configuration is a subjective experience of emotions, and thus of a state of mind. The results offer some insights into the mechanisms and structure of aesthetic emotions.	cognitive model;driving simulator;experiment;interactivity;mind;simulation	Ana Constantinescu;Naoko Matsumoto;Daisuke Moriyasu;Hajime Murai;Akifumi Tokosumi	2004			cognitive psychology;aesthetic emotions;computer science;cognition	AI	-52.878455388366014	-46.22720777685089	92285
3af534a952b0dd8b177c2be772f52f2b73f76668	teleoperated android as a tool for cognitive studies, communication and art		Following the successful workshops in 2005 and 2006 on Android Science, the aim of this full-day workshop is to introduce and discuss on current insights and future usage of teleoperated androids. Teleoperated androids, robots owning humanlike appearance equipped with semi-autonomous teleoperation facility, was first introduce to the world in 2007 with the public release of Geminoid HI-1. Geminoid is a teleoperated android robot that resembles existing human being. While androids were designed for studying human nature in general, geminoids was made to study individual aspects as presence or personality traits, tracing their origins and implementation into robots. Both its appearance that resembles the source person and its teleoperation functionality serves in making Geminoid as a research tool. After the release of Geminoid HI-1, several types of teleoperated androids has been produced: Geminoid F, Geminoid DK, Telenoid R1/R2 and Elfoid P1. While the Geminoids are after real existing persons, Telenoid and Elfoid are attempts to represent human beings in their minimalistic forms; a challenge to see to what extent elements that forms us can be omitted but still able to transfer presence of the teleoperating person. Since their birth, Geminoids and Telenoids have been used in a variety of domains throughout the world, from studies in various fields such as in cognitive psychology / neuroscience, social psychiatry, developmental psychology, robotics, and human-machine interface to philosophy and art. One example is the android drama which showed new possibilities on not only on usage for teleoperated android robots but for artistic representations as well as seeking purity in the natures of human beings. The past workshops that concentrated on autonomous humanlike robots and androids laid a foundation for android science research, a field that integrates the synthetic approach from robotics with the empirical methodologies of the social sciences. Participants, coming from engineering and the social, cognitive, and biological sciences sought fundamental principles underlying cognition and communication between individuals. In this workshop, we will focus on the further enhanced and broadened usage of teleoperated androids that can provide new means for cognitive science studies, and can bridge the gap between cognitive neuroscience and the behavioral sciences, as well as philosophy, social science and arts, leading to a new way of understanding human beings.	android (robot);android science;autonomous robot;cognition;cognitive science;pure function;robotics;semiconductor industry;synthetic data;telenoid r1;user interface	Shuichi Nishio;Hiroshi Ishiguro	2012			human–computer interaction;psychology;multimedia;android (operating system);teleoperation	HCI	-54.03965211458179	-47.45678314585706	92470
8b7e7c31d1349ec32fd7d85d99de28d4fcd13997	identifying and representing elements of local contexts in namibia	context aware;user centered design;graphical user interface;re contextualization;graphical representation;human centered design;participatory design;interaction design;context;indigenous knowledge	In an attempt to represent local context in a 3D visualisationfor rural elders in Namibia we have foundmajor differences in theconceptualizationof this context between external and local partners in the co-creation process. Through the evaluation of a mobile context capture tool we found a clear disconnection of community members with both abstract and absolute representations of points, paths and areas. From this we discuss how the local concepts of space and time as frames of reference can not be represented adequately with our current selection of contextual data, and how we are engaging in participatory activities to derive a common understanding of contextual representations.	application domain;distortion	Kasper Rodil;Kasper Løvborg Jensen;Matthias Rehm;Heike Winschiers-Theophilus	2013		10.1007/978-3-642-39265-8_37	user-centered design;human–computer interaction;computer science;knowledge management	HCI	-60.71754679331109	-39.32134871455717	93182
a609fff000ed4a3cceac5af510b1faa93b07601a	exploration of new-generation human computer interface based on participatory design strategy		This study researched the next-generation human computer interactions. In particular, brainwave computer interaction (BCI) is emphasized. To investigate BCI, two stages are included: interface development to develop a BCI game, and interface evaluation with a series of user experiments to test user experience. For both stages, participatory design is adopted as the essential principle to involve potential users to provide their expectations and insights on possible application scenarios of BCI in daily life, help define the requirements, assist in concept screening and user experience investigation. In particular, a prototype with hardware (including brainwave computer chipsets and Bluetooth module) and software (i.e., a PC Tetris game developed by Labview) was developed. The physical part is to collect users’ neural signals, and such signals will be used to control the game. A group of participants were involved to play the game, and interviews based on game experience questionnaire was constructed to identify participants’ experience on BCI and also other traditional interfaces. Through results analysis, it can be concluded that BCI shows obvious strength which is more immersive, attractive and enjoyable. Therefore, BCI could be promising to enhance user experience and bring more fun to task completion.	human computer;human–computer interaction	Danni Chang;C. K. M. Lee;Lo Kwok Leung	2018		10.1007/978-3-319-91797-9_1	chipset;human–computer interaction;user experience design;immersion (virtual reality);participatory design;software;bluetooth;computer science	HCI	-50.73430555123506	-45.65087100648349	93221
ae8a41024bb0762d5266198eb304be2afc82c08c	avatar realism and social interaction quality in virtual reality	avatar realism behavioral cues social cues verbal task presence physical performance vr virtual reality rw real world verbal based social interactions physical based social interactions full body avatar embodiment immersive virtual environments behavioral channels reduced social information social interaction quality;electronic mail;atmospheric measurements;social sciences computing avatars behavioural sciences computing;collaboration;virtual environments;avatars virtual environments electronic mail collaboration games atmospheric measurements;games;h 5 1 information systems artificial augmented and virtual realities;avatars	In this paper, we describe an experimental method to investigate the effects of reduced social information and behavioral channels in immersive virtual environments with full-body avatar embodiment. We compared physical-based and verbal-based social interactions in real world (RW) and virtual reality (VR). Participants were represented by abstract avatars that did not display gaze, facial expressions or social cues from appearance. Our results show significant differences in terms of presence and physical performance. However, differences in effectiveness in the verbal task were not present. Participants appear to efficiently compensate for missing social and behavioral cues by shifting their attentions to other behavioral channels.	experiment;interaction;read-write memory;virtual reality	Daniel Roth;Jean-Luc Lugrin;Dmitri Galakhov;Arvid Hofmann;Gary Bente;Marc Erich Latoschik;Arnulph Fuhrmann	2016	2016 IEEE Virtual Reality (VR)	10.1109/VR.2016.7504761	games;human–computer interaction;computer science;multimedia;collaboration	Visualization	-52.86162885757904	-49.88318219644048	93483
a649fd60ee1d7234f6da525ee3d7941196cdd534	how touch glove and expertise influence the basic touch gestures performances for people with systemic sclerosis		The technology has become a common part of our daily lives, and the integration of touchscreen technology into devices is quickly becoming equally common. In recent years, much research has been conducted on how people interact with handheld devices and on different types and uses of touchscreen technology, but there are few studies regarding people with severe problems of dexterity. For this reason, the present study aims to understand the effect of expertize with touchscreen on the performance of basic touch-gestures (i.e., tapping, dragging, pinching and spreading) in the case of people with Systemic Sclerosis. The performances of a total of twelve patients with SSc, six with and six without previous experience with touchscreen technology, were compared in the study. Recommendations based on the results of this study are proposed to improve the accessibility of touch-screen interfaces for these patients.	accessibility;drag and drop;mobile device;performance;recommender system;touchscreen	Francesca Gullà;Silvia Ceccacci;Roberto Menghi;Michele Germani	2018		10.1145/3197768.3197773	human–computer interaction;computer science;usability;mobile device;touchscreen;gesture	HCI	-48.466922570923884	-45.43358619869616	93493
bd318e959236b0d33a7567b6d3afc8d5e92b8ea3	building ethically bounded ai		The more AI agents are deployed in scenarios with possibly unexpected situations, the more they need to be flexible, adaptive, and creative in achieving the goal we have given them. Thus, a certain level of freedom to choose the best path to the goal is inherent in making AI robust and flexible enough. At the same time, however, the pervasive deployment of AI in our life, whether AI is autonomous or collaborating with humans, raises several ethical challenges. AI agents should be aware and follow appropriate ethical principles and should thus exhibit properties such as fairness or other virtues. These ethical principles should define the boundaries of AI’s freedom and creativity. However, it is still a challenge to understand how to specify and reason with ethical boundaries in AI agents and how to combine them appropriately with subjective preferences and goal specifications. Some initial attempts employ either a data-driven examplebased approach for both, or a symbolic rule-based approach for both. We envision a modular approach where any AI technique can be used for any of these essential ingredients in decision making or decision support systems, paired with a contextual approach to define their combination and relative weight. In a world where neither humans nor AI systems work in isolation, but are tightly interconnected, e.g., the Internet of Things, we also envision a compositional approach to building ethically bounded AI, where the ethical properties of each component can be fruitfully exploited to derive those of the overall system. In this paper we define and motivate the notion of ethically-bounded AI, we describe two concrete examples, and we outline some outstanding challenges. Motivation and Overall Vision Whatever we do in our everyday life, be it at work or in our personal activities, we need to make decisions: what to eat, where to go on vacation, what car to buy, which route to take to go to work, what job to choose, and many more. To make these decisions, we usually rely on our subjective preferences over the possible options. If we need to buy a car, we may have preferences over its color, its maker, its engine, and many other features. If we need to decide which restaurant to go for dinner, we may have preferences over location, facilities, food, drinks, and many other features. However, subjective preferences are not the only source of guidance when making our decisions. In many domains preferences are combined with moral values, ethical principles, or behavioral constraints that are applicable to the decision scenario and are prioritized over the preferences (Rossi 2016; Greene 2014). We have have our own preferences over food, but maybe the doctor recommended that we follow a diet to avoid some health issues, so we need to combine the doctor’s guidelines with our taste preferences (Balakrishnan et al. 2018; Balakrishnan et al. 2019). This is especially true in decision that may have an impact on others. In this context, social norms, regulations and laws could provide guidelines to follow when making a decision (Sen 1974; Thomson 1985). While driving our car, we may want to drive as fast as possible to get home sooner, but social norms and laws provide limits to speed and dangerous deriving behavior. AI systems are increasingly supporting human decision making, or they make decisions autonomously. So it is natural to ask ourselves how to code both subjective preferences and ethical principles in these systems. This is especially necessary when AI systems tackle ill-defined problems whose solution procedure cannot be accurately defined by a rule-based approach but require data-driven and/or learning approaches, which are increasingly used in AI. Data-driven AI systems are indeed very successful in terms of accuracy and flexibility, and they can be very “creative” in achieving a goal, finding paths to the goal that could positively surprise humans and teach them innovative ways to solve a problem, such as the move that the AlphaGo system used against Lee Sedol in the 2017 match (Silver et al. 2017) and a similar system that used uncommon methods to set records in Atari games (Mnih et al. 2013). However, creativity and freedom without boundaries can sometimes lead to undesired actions: the system could achieve its goal in ways that are not considered acceptable according to values and norms of the impacted community. Recently researchers at DeepMind collected a list of examples of “specification gaming” behaviors and released AI Safety Block Worlds to examine these behaviors (Leike et al. 2017). Examples of specification gaming includes: • a reinforcement learning agent in a boat racing game going in circles and repeatedly hitting the same reward targets in order to increase the score, instead of actually playMore examples are available at: https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/		Francesca Rossi;Nicholas Mattei	2018	CoRR			AI	-53.087669791222055	-43.67857028526568	93621
33f30b4560ad13d7a41e793468bd156d453cd1ea	mobile attachment: separation from the mobile phone induces physiological and behavioural stress and attentional bias to separation-related stimuli	cell phone;mobile phone;separation;attachment;attentional bias;human mobile interaction	Humans have a biological predisposition to form attachment to social partners. This attachment, however, is not restricted to humans: non-human and inanimate targets are often involved. People are increasingly engaged with their mobiles but whether their behaviour toward these devices can be regarded as an attachment behaviour has not yet been experimentally tested. Here we hypothesized the existence of mobile attachment. We expected people to seek the proximity of the mobile and give stress response upon separation from it, which manifests both at behavioural and physiological level. We also predicted that separation from the mobile should induce specific separation-related emotions, which leads to increased attention to separation-related stimuli. We applied a version of the Strange Situation Test using a mobile phone, with behavioural, physiological, cognitive and self-report measures, and the emotional Stroop test. Additionally, we constructed a questionnaire to self-assess mobile attachment. Separation from the mobile induced behavioural and physiological stress, proximity seeking behaviour, and an attentional bias to separation-related stimuli for participants with higher mobile attachment. These effects were only observable when no other mobile was present. According to the questionnaire, secure base and safe haven are also relevant aspects of attachment to a mobile. These results support that humans form attachment toward their mobile which is similar to social attachment. This could emerge by cultural recycling of the attachment system’s evolutionary structures. keywords: mobile phone, cell phone, human-mobile interaction, attachment, separation, attentional bias	attachments;cognition;computer recycling;experiment;haven (graph theory);humans;human–robot interaction;mobile interaction;mobile phone;observable;predispositioning theory;responsiveness;smart device;wheatley (portal)	Veronika Konok;Ákos Pogány;Adám Miklósi	2017	Computers in Human Behavior	10.1016/j.chb.2017.02.002	psychology;cognitive psychology;developmental psychology;attachment theory;communication;social psychology;attentional bias	HCI	-53.45448726713516	-50.6337783583528	93920
b1c5077200ebe0424a67e6a8c6620fca5b4bd347	more to meetings: challenges in using speech-based technology to support meetings	collaborative workplace technology;speech interaction;automatic speech recognition;meeting agents	Personal assistants using a command-dialogue model of speech recognition, such as Siri and Cortana, have become increasingly powerful and popular for individual use. In this paper we explore whether similar techniques could be used to create a speech-based agent system which, in a group meeting setting, would similarly monitor spoken dialogue, pro-actively detect useful actions, and carry out those actions without specific commands being spoken. Using a low-fi technical probe, we investigated how such a system might perform in the collaborative work setting and how users might respond to it. We recorded and transcribed a varied set of nine meetings from which we generated simulated lists of automated 'action items', which we then asked the meeting participants to review retrospectively. The low rankings given on these discovered items are suggestive of the difficulty in applying personal assistant technology to the group setting, and we document the issues emerging from the study. Through observations, we explored the nature of meetings and the challenges they present for speech agents.	cortana (halo);personal digital assistant;siri;speech recognition	Moira McGregor;John C. Tang	2017		10.1145/2998181.2998335	speech recognition;human–computer interaction;computer science;multimedia;communication;world wide web	HCI	-51.448390519147196	-45.601850889855946	94082
a37560b8401f52c9bd138d9254767327011393fd	energylife: pervasive energy awareness for households	serious games;energy awareness;wireless sensor;user interface;domestic systems;smart phone;interaction design;serious game;mobile interaction	We present Energy Life a system utilizing wireless sensors, mobile and ambient interfaces that turn energy consumers into active players. Energy Life participants play through different levels collecting scores in savings and through advice tip reading and quizzes. We describe principles, logic of the game, implementation and user interfaces providing rationale for design choices. Key principles embodied in Energy Life are: situated and combined feedback including knowledge and consumption information, intuitiveness and non-intrusiveness by utilizing an always at hand solution on a touch enabled smart phone and lighting as an ambient interface, sustained interaction and engagement by using a applied game that connects players within and between households.	design rationale;pervasive informatics;sensor;situated;smartphone;speedrun;user interface	Christoffer Björkskog;Giulio Jacucci;Luciano Gamberini;Tatu Nieminen;Topi Mikkola;Carin Torstensson;Massimo Bertoncini	2010		10.1145/1864431.1864436	embedded system;simulation;mobile interaction;human–computer interaction;computer science;interaction design;multimedia;user interface;computer security	HCI	-53.792513251029895	-38.88571823472032	94143
2c1de8173997f9f6bb856e73f9173a8cba51050e	feel as agent: immersive digital dollhouse enhances sociality of children with developmental disorders	developmental disorders;immersive play therapy;digital play therapy;children;design;play therapy device	Children suffering with learning and developmental disorders require daily training to develop their social skills. However, such daily training is sometimes not provided because it requires interactive help from therapists, and lots of special programs required for the training. We proposed an immersive digital dollhouse that enhances traditional psychological play therapy with sensors installed, while provides feedback from the sensors to the computer graphics (CG). The immersive digital dollhouse provides an immersive space for children, which develops their communication skills through their imaginary play with the complement of CG for enhancing the understanding of their situation, and it is easy to use in their home as daily training. We conducted an experiment with a 6-year old child with a similar level as the older children with developmental disorders. We found that the number of reactions was twice as many as with a normal dollhouse, and the number of miscommunications was less than one-tenth.	computer graphics;experiment;eye tracking;imaginary time;neural oscillation;sensor	Midori Sugaya;Hirotaka Osawa;Yoshiko Okada;Irini Giannopulu	2015		10.1145/2814940.2814963	psychology;simulation;multimedia;communication	HCI	-56.88547272076429	-51.29132527494443	94170
2ab8713b0fd54e880569689b78bb0b7dd08b625b	agency effects in human-computer interaction		The studies presented in this article explore a human-centered conceptualization of agents and agency based on the observation that people attribute agency to sufficiently complex interactive systems. Although agency attribution appears to be an unconscious human response, findings from social psychology, affective computing, and perceptual-motor studies suggest agency attribution influences human–computer interaction (HCI). Three studies are presented that examine whether recent findings on agency attribution in physical environments also apply in the virtual environments characteristic of HCI. Results of the studies indicate that agency effects operate in desktop computing environments. Agency effects, however, appear to be influenced by learning effects that preserve a previously observed relationship between perception and action but alter how this effect is expressed. Results suggest that there are both bottom-up and top-down contributions to agency effects in HCI.	human–computer interaction	John E. McEneaney	2013	Int. J. Hum. Comput. Interaction	10.1080/10447318.2013.777826	human–computer interaction	HCI	-53.49061311707587	-49.26268668921765	94266
e7f158f6fe527fd449425dfba6ca0caa2ff92b0c	text-based on-line conferencing: a conceptual and empirical analysis using a minimal prototype	teleconferencing	This article is concerned with an analysis of the requirements for text-based on-line conferencing. From a system perspective, text-based on-line conferencing can be viewed as either message passing or data sharing. These complementary views give rise to different design dimensions. For example, the message-passing view is concerned with granularity, channels, message labels, and so on. The data-sharing view is concerned with the access different individuals have to the text: read only, appending, editing, pointing, and so on. A deliberately sparse prototype was built and placed in this design space. This minimal prototype has limited functionality so that the real problems experienced by users can show through. Relevant literature from disciplines such as social psychology, conversational analysis, and linguistics is briefly reviewed in terms of three generic communication tasks: synchronizing communication, maintaining structural coherence, and maintaining referents. An empirical analysis of subjectsu0027 use of the sparse prototype was analyzed to establish the relevance of the generic communication tasks to text-based on-line conferencing. Possible forms that support for these tasks might take are discussed.	prototype;text-based (computing)	John C. McCarthy;Victoria C. Miles;Andrew F. Monk;Michael D. Harrison;Alan J. Dix;Peter C. Wright	1993	Human-Computer Interaction	10.1207/s15327051hci0802_3	human–computer interaction;computer science;artificial intelligence;operating system;multimedia;communication;world wide web	AI	-58.8052895065975	-39.317987274753435	94379
eb68c3e9385959f818a9f7de168a0d7528b8cb9d	the ergonomics lab: a practical approach	etude utilisation;laboratory study;stumbling blocks;etude en laboratoire;evaluation systeme;design process;usability testing;performance test;ergonomia;criterio resultado;concepcion sistema;user participation;relacion hombre maquina;information technology;evaluacion sistema;heuristic method;experience;usuario;man machine relation;performance requirement;metodo heuristico;besoin utilisateur;necesidad usuario;utilisateur;critere performance;technologie information;ergonomie;ensayo laboratorio;technical handbook;performance tests;laboratory test;standard testing methodology and corresponding equipment;system evaluation;cd93 9 dlj neologisme cree pour usability;guia tecnica;user need;system design;utilisabilite;participacion;multiple trade offs;user;relation homme machine;methode heuristique;experiencia;essai laboratoire;tecnologia informacion;usability;participation;ergonomics;conception systeme;guide technique;use study;user participation in design process;estudio en laboratorio;heuristic investigation test	This article is concerned with methods and experiences in usability testing of standard application business software. In order to achieve the multiple trade-off between scientific objectivity, practical applicability, and the costbenefit ratio, a set of standard methods and the resulting testing environment in the ergonomics lab are described and demonstrated by examples. Stumbling blocks are discussed. Necessary additional prerequisites for a successful practical approach are stressed. 1. The multiple trade-off User participation in the on-going process of software development is generally recognized as a proven tool for designing usable software (see Ulich 1988, Williges et al. 1987, Rauterberg 1991). Building an ergonomics laboratory is one possible means of providing this user participation. The successful operation of an ergonomics laboratory as part of the software design process demands the simultaneous optimization of: scientific objectivity; practical applicability; and the cost-benefit ratio. 1.1. Scientific objectioity For empirical usability testing methods and procedures (see Kirakowski el al. 1990, Lim and Long 1992, Hampte-Neteler and Rodiger 1992, Rauterberg 1991, Oppermann 1988) the theoretical basis for measurement, which was developed in the social sciences, is the yardstick to be compared against. The theoretical requirements, and the derived criteria objectivity, reliability, and, to some extent, validity (Cook and Campbell 1979), tend t o be more readily fulfilled the closer the process of the acquisition of empirical, software ergonomic data resembles the process of classical experimentation. 1.2. Practical application When actually applied in practice, the constructive aspects of the data produced by a method takes on primary importance. Definitive statements regarding the usability of a software application (in the sense of 'time on task' for a standard task, for example) are only of limited value, if no arguments for a decision between design alternatives can be arrived at , o r no new design implications can be derived from the empirical data. 1.3. Cosrs atld benefits An additional distinguishing feature of evaluation methodologies is the cost-benefit ratio inherent to any given method (see for example Mantei et al. 1988, Nielsen 1992, Karat 1990). This feature has been discussed widely. In practice its significance should not be underestimated. A software ergonomic evaluation methodology must be applicable within the bounds of justifiable expense in terms of time and personnel resources. A standard method pool and the corresponding testing environment are the prerequisites in exerting a constructive influence upon the software development process based on solid empirical datawhile simultaneously maintaining a reasonable costbenefit ratio. 1.4. Standard strategy as framework To minimize costs every test procedure should be as standardized as possible. To be flexible enough, the procedures should be modular combinable. A standard framework for usability studies has been developed at SAP A G , with methods varying in objectivity and their cost-benefit ratio. This standard set of 0144-929W94 I1O.M @ 1994 Taylor L Francis LtJ. D ow nl oa de d by [ C ol um bi a U ni ve rs ity ] at 1 6: 00 0 5 Fe br ua ry 2 01 5 46 c. Neugebauer and N. Spielmann methods for usability in testing consists of four fundamental building blocks: (1) Background information questionnaire: questionnaire concerning professional experience and software knowledge; (2) Working on standard tasks: measurement of performance on standard tasks (see Rauterberg 1991, Rengger 1991); video-based behavioural observation using the 'think aloud' method (see Duncker 1935, Ericcson and Simon 1980, Vainio-Larsson 1990, Crellin et al. 1990); (3) Subjective evaluation: questionnaires using screen mock-ups; usability questionnaire based on the ISO 9241-10 (ISO 1991)/DIN 66234 part 8 (DIN 1988) standards; (4) Structured discussion: video confrontation (see section 3.1); semi-standardized interview or discussion methods. In every study an introduction is provided concerning the SAP GVI (graphical user interface) and the application or task area under test. This is meant to guarantee a common baseline for all test participants. Not all of the methods assigned to a particular method block will necessarily be applied in every study. However, every study contains at least one method from every block. Planning a study starts off with specifying the ISO 9241-10 (ISO 1991) criterion that is to be measured and with ISO 9241-11 (ISO 1991) defining the context of use. Potential experimental factors (for example, user groups and the degree of task complexity), and factors that should ideally be maintained constant, are defined. Rather than building a lab and seeing what might be possible, the design of an ergonomics laboratory and its equipment has to reflect the methodological concept of the investigators. Figure 1 illustrates a schematic representation of the SAP ergonomics laboratory. The main features are: discussed below. 2. Testing room, observation room and video The lab is divided into the actual testing room and an observation room, separated by a one-way screen. Systematic ('experimenter' biases) and unsystematic biases (e.g., noise, disturbing phone calls, etc.) are thus minimized. This helps to establish more constant conditions-at least in regard to physical environment variables-which are a prerequisite for objective data acquisition. In many cases it is necessary to separate the Figure 1. Layout of the ergonomics laboratory. test person from the developer/human factors specialist to allow the test person to make her or his own experiences. The work stations in the testing room can be monitored via video camera, because the use of video material is central to many evaluation methods mentioned before. The observation room, as illustrated in figure 1, is equipped with recording and logging equipment. This enables both the software supported 'real-time' logging of user behaviour and the subsequent analysis of video tapes. 2.1. Discussion area In the testing room the discussion area has space for up to 10 people. Here system walk-throughs or example-based discussions via a barco beamer can be done. An additional video recorder is installed as well for video confrontation (see below). Test workplaces and the discussion area are combined to avoid long walks and ever changing (disruptive) environments. It also helps to reduce the scientific/cold look of the lab. 3. The laboratory in operational use The following section describes two different methodological subsets. The first variant is of a constructive design and puts an emphasis upon qualitative methodology. The second applies quantitative measurement to provide quantitative statements concerning the variable under examination. 3.1. Heuristic investigation test HITs are designed to uncover serious usability problems caused by the software design at a minimum of expense. Heuristic investigation tests embody the following central characteristics: D ow nl oa de d by [ C ol um bi a U ni ve rs ity ] at 1 6: 00 0 5 Fe br ua ry 2 01 5 The ergonomics lab 47 -extensive application of qualitative methodology; -a reduction in the sample size (max. N = 5) with one test person per session; -every HIT takes about 7-8 h per day and test person; -the test participants are exclusively experts in the respective work area in which the software application will be used. This is of vital importance for the variable 'Suitability for task'. This selection is thought to counter-balance the potentially negative effects of the restricted sample size. These characteristics clearly differentiate a HIT from 'heuristic evaluation' as proposed by Nielsen (1992). HITS are performed as illustrated in figure 2. The section 'Working on standard tasks' is used for the video observation of the test participants while they are working on the tasks. In order to optimize the analysis of the video log, the test participants are requested to 'think aloud'. Usability problems are logged according to a standardized log schedule in real time. This section normally takes about 2.5 h. This video log provides the basis for the third section (see below). The test participants are then required to fill out a questionnaire regarding their previous experience and to complete another one containing screen mock-ups (duration: 0.5 h). The broad category 'Structured discussion' includes video confrontation. In this procedure the test participants are confronted with video sequences that were recorded in the first section showing potential usability problems. The sequences are analysed interactively, then ranked according to their importance. This video confrontation is most useful because test persons tend to be unable to remember dialogue situations, especially when they appear at the beginning of the .................................. ............................................................................ ........................... Component Objective Method applied	barco creator;baseline (configuration management);business software;dfa minimization;data acquisition;digital video recorder;erp;environment variable;expanded memory;experience;francis;field electron emission;graphical user interface;heuristic evaluation;hit (internet);human factors and ergonomics;image noise;interactive media;mathematical optimization;mock object;objectivity/db;one-way function;real-time computing;real-time locating system;requirement;schematic;semiconductor industry;software design;software development process;stumbleupon;unified model;usability testing;video blog;videocassette recorder;webcam	Claus Neugebauer;Nicola Spielmann	1994	Behaviour & IT	10.1080/01449299408914583	simulation;usability;human–computer interaction;computer science;engineering;operations research;information technology	HCI	-62.78831670295139	-49.24169562670326	94423
56fb5df4d5187b131ecc201648afc5e5170ab99c	"""""""beyond the desktop, out of the office..."""" designing interactive graphics applications for mobile devices"""	mobile device;interactive graphics	The recent availability of increasingly powerful PDAs and mobile phones is making it possible to develop new applications based on interactive (2D as well as 3D) graphics. However, limitations of mobile devices and the peculiar needs of users on-the-go require a careful design of applications that are specifically thought for mobile devices and users [8]. Mobile graphics applications become even more innovative and provide functionalities that were unavailable on desktop systems when they are integrated with various sensors (e.g., GPS, accelerometers, heart rate monitors, pulseoximeters, ...) that allow one to adapt the behavior of the application according to position in space (locationawareness) and other parameters (contextawareness). In this way, the mobile device becomes able to choose what to draw and how to draw it on the display based on what is happening to the user as well as the physical world that surrounds her. Moreover, the data recorded by mobile sensors about the behavior of users on the move lends itself to the design of visualizations that can be important in domains such as health care, urban planning, geomarketing, emergency management, and others. This invited talk will first discuss why and how mobile graphics applications require to be approached differently from traditional ones. Then, it will demonstrate some new mobile applications that have been developed in domains as diverse as tourism, health and fitness, navigation, and architectural visualization. Finally, it will deal with the visualization of mobile users’ behaviors by showing two different tools we have recently	3d computer graphics;architectural rendering;desktop computer;geomarketing;global positioning system;mobile app;mobile device;mobile operating system;mobile phone;personal digital assistant;sensor;usb on-the-go	Luca Chittaro	2007		10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2007/151-153	human–computer interaction;computer graphics lighting;multimedia;graphics software;computer graphics (images)	HCI	-49.3628189717004	-40.731115392745224	94532
d529dd9139610cace7a58061d53bb52a4f9c575b	towards community browsing for shared experiences: the webrowse system	conference proceeding	We introduce the new concept of community browsing: a group of people browsing the web together and simultaneously. Community browsing is part of the broader notion of shared experience, where individuals share the experience of an event. We have developed a prototype of a mobile application that enables community browsing, and involves new technologies such as a peer-topeer Electronic Institution and bipolar preference aggregation.	browsing;mobile app;prototype;social network aggregation	Matthew Yee-King;Roberto Confalonieri;Dave De Jonge;Nardine Osman;Katina Hazelden;Leila Amgoud;Henri Prade;Carles Sierra;Mark d'Inverno	2012			engineering;knowledge management;multimedia;world wide web	HCI	-57.27029687898813	-39.52681128005854	94669
a78dad794d8d0fecfefd617ed4ef50c5a4a02997	challenges to assessing usability in the wild: a case study		This article describes one part of a human factors study conducted over 3 months in a petro-chemical manufacturing plant in Australia. The project had two purposes, namely, to identify issues to be included in a training course for plant operators and to identify low-level usability-related software issues that might be rectifiable prior to system implementation. After interviewing 28 operators and eight managers, the operators were observed on the job while interacting with the old system. Finally, the 3-part usability assessment comprising 2 expert inspections and a user-based quasi-walkthrough was conducted. As the study took place shortly before a new, off-the-shelf automated manufacturing system was implemented, it was not possible to test an interactive version, relying instead exclusively on static screens. This made it impossible to provide user performance data, which could have helped to convince management of the seriousness of certain problems. One of these proved so severe that an engineer ha...	usability	Gitte Lindgaard	2015	Int. J. Hum. Comput. Interaction	10.1080/10447318.2015.1065697	simulation;human–computer interaction;artificial intelligence;world wide web	HCI	-62.161421499862634	-50.896902050125604	94806
41e3981eef43f7057c0035ba8c3cc9839b485593	natural-language interactive narratives in imaginal exposure therapy for obsessive-compulsive disorder		Obsessive-compulsive disorder (OCD) is an anxiety-based disorder that affects around 2.5% of the population. A common treatment for OCD is exposure therapy, where the patient repeatedly confronts a feared experience, which has the long-term effect of decreasing their anxiety. Some exposures consist of reading and writing stories about an imagined anxiety-provoking scenario. In this paper, we present a technology that enables patients to interactively contribute to exposure stories by supplying natural language input (typed or spoken) that advances a scenario. This interactivity could potentially increase the patient’s sense of immersion in an exposure and contribute to its success. We introduce the NLP task behind processing inputs to predict new events in the scenario, and describe our initial approach. We then illustrate the future possibility of this work with an example of an exposure scenario authored with our application.	auditory processing disorder;immersion (virtual reality);information seeking;interaction;interactivity;natural language processing;personalization	Melissa Roemmele;Paola Mardo;Andrew Gordon	2017			cognitive psychology;exposure therapy;artificial intelligence;natural language processing;computer science;natural language;narrative	HCI	-56.63261442078871	-50.80479142734339	94808
f1cd12182e3febdb838e48d57116f6f393e88b20	game scenes evaluation and player's dominant emotion prediction		In this paper, we present a solution for computer assisted emotional analysis of game session. The proposed approach combines eye movements and facial expressions to annotate the perceived game objects with the expressed dominate emotions. Moreover, our system EMOGRAPH (Emotional Graph) gives easy access to information about user experience and predicts player’s emotions. The prediction mainly uses both subjective measures through questionnaire and objective measures through brain wave activity (electroencephalography - EEG) combined with eye tracking data. EMOGRAPH’s method was experimented on 21 participants playing horror game “Outlast”. Our results show the effectiveness of our method in the identification of the emotions and their triggers. We also present our emotion prediction approach using game scene’s design goal (defined by OCC variables from the model of emotions’ cognitive evaluation of Ortony, Clore and Collins [1]) to annotate the player’s situation in a scene and machine learning algorithms. The prediction results are promising and would widen possibilities in game design.		René Doumbouya;Mohamed S. Benlamine;Aude Dufresne;Claude Frasson	2018		10.1007/978-3-319-91464-0_6	artificial intelligence;machine learning;computer science;affective computing;cognitive evaluation theory;user experience design;facial expression;eye tracking;graph;game design	NLP	-55.75177457469443	-48.26981242419224	94861
a422c5a6878aee0fb75bde43ca238990c468cf26	playtesting for indie studios	case studies;game development;games user research;user experience;playtesting;indie developers	Creating video games is a lengthy and demanding process. Financial success for games studios often depends on making games that deliver a fun and engaging experience for a diverse audience of players. Therefore, understanding how players interact and behave during gameplay is of vital importance. Playtesting aims to assist developers to achieve their design intent and help to identify and resolve potential problem areas during development. However, playtests are not always feasible or affordable for smaller, independent game developers (indie studios) because they require specialized equipment and expertise. In addition to this, there is a lack of research on the value of playtesting for indie studios, which means most indie developers are not convinced of the value of user research and playtesting. This paper reports on our collaboration with six commercial indie developers conducting eleven rounds of playtesting session. Through these collaborations, our paper contributes to this growing domain by highlighting the value of playtesting for indie developers and discussing the user research process and approaches based on indie developers' needs and budget.	playtest;user research;video game developer	Pejman Mirza-Babaei;Naeem Moosajee;Brandon Drenikow	2016		10.1145/2994310.2994364	simulation;human–computer interaction;engineering;multimedia	HCI	-60.109870828976845	-45.10867551035548	94893
e9f2650de8082c2cd4e7b57d3abe4c602306f1e0	understanding customers' interests in the wild		Today, retailers spend considerable efforts to provide a personalized shopping experience to their customers. As data-driven marketing helps to meet customer requirements, it is important to understand individual needs. However, offline stores---unlike their online counterparts---have great difficulty knowing their customers' needs due to a lack of proper context information. In this paper, we proposed a framework for estimating customer interests by using various sensor devices. The participants in our pilot study expected that recommendation services that adopt their interests would help to reduce their shopping time. As a result, shop assistants will have a stronger ability to understand, analyze, and even predict customer interests in the near future.	online and offline;personal digital assistant;personalization;requirement	Soowon Kang;Auk Kim;Jemin Lee;Ikhee Shin;Uichin Lee	2018		10.1145/3267305.3267625	human–computer interaction;marketing;computer science	Mobile	-54.753053299380596	-41.96392215883333	94950
ff5e8a1d0f2df8ddd969663d96d49b63154ef061	web widgets barriers for visually impaired users	web accessibility;blind and partially sighted;dynamic applications;evaluation;partially sighted and blind;rich internet application (ria)	Currently, websites are mainly composed of web widgets, dynamic elements and updatable sections - like autosuggest list, carousel, slideshow etc. In order to contribute with the development of accessible rich internet applications, this work aims to better understand the interaction of severely visually impaired users with these pages, gathering their main barriers and difficulties.		Letícia Seixas Pereira;Dominique Archambault	2017	Studies in health technology and informatics	10.3233/978-1-61499-798-6-836	knowledge management;world wide web;medicine	HCI	-56.10003447997791	-43.242199100209405	95004
9270891d9bac529ed4719b9dce466748fe9e386d	exploring user gains in participatory design processes with vulnerable children		This paper contributes to the debate on benefits that children can gain through their involvement in Participatory Design (PD) and highlights the importance of user gains in relation to vulnerable children. As vulnerable children are prone to marginalisation, this paper explores the user gains they may acquire when participating in PD processes. We report on the results of `Making Things!': a long-term PD project to (co-)design FabLab workshops for the future together with local, vulnerable children (6-12 y/o). The analysis points to three benefits that these children gain through their participation: developing self-esteem, learning-by-doing, and broadening their horizons. Based on our findings, we pinpoint the importance of an approach to PD that is sensitive to the complexities of participants (cf. `Design for vulnerability') and discuss the need for suitable methods to assess children's user gains.1	fab lab	Selina Schepers;Katrien Dreessen;Bieke Zaman	2018		10.1145/3210604.3210617	knowledge management;engineering;participatory design;vulnerability	HCI	-62.63676715934983	-42.884300389526736	95092
c84f7a50a8e25b884f433821c0a5daf0f6b6da0b	sandboxes: supporting social play through collaborative multimedia composition on mobile phones	social computing;mobile device;multimedia composition;mobile phone;media spaces;media space;media sharing;mobile devices	Media sharing over mobile devices is quickly becoming a common practice, used to support a variety of social processes. Most existing systems employ a model of sharing that treats each shared item as a distinct message. We argue that there are compelling reasons to utilize a more flexible, cohesive approach to media sharing. To test this idea, we developed Sandboxes, a prototype application for mobile phones that goes beyond basic media sharing to offer a form of collaborative multimedia composition. The design of Sandboxes is based upon three primary themes: interactivity, flexibility and cohesiveness.	group cohesiveness;interactivity;mobile device;mobile phone;prototype;sandbox (computer security);speedrun	David Fono;Scott Counts	2006		10.1145/1180875.1180900	mobile search;human–computer interaction;computer science;operating system;mobile device;multimedia;internet privacy;world wide web;social computing	HCI	-57.19541912715337	-39.52647701765642	95205
f70c5a2c4a3debe0c14ee404c13d29851b0ffe86	user modelling in a dialog system	recommendation;multi-modal dialog;user model	In people’s home the amount of on-line available digital content such as video, music, or pictures is rapidly increasing. First home server products are available. Efficient selection of content will be a problem for users. We developed a flexible multimodal dialog system to overcome this. A keycomponent is the user model, which learns very fast from user behaviour. All information like key-words are determined automatically and scored according to their relevance. No manual setting is required.	dialog system;digital recording;home server;image;multimodal interaction;online and offline;relevance;server (computing);user modeling;video	Ralf Kompe;Martin C. Emele;Silke Goronzy;Robert Mencl;Sunna Torge	2003			human–computer interaction;dialog box;computer science;dialog system	ML	-48.401467986594504	-38.45061288332378	95353
01d49a6943848574b751dc8805839f0cd39fbc18	i can already guess your answer: predicting respondent reactions during dyadic negotiation	speech acoustics history visualization context proposals time factors;prediction human behavior analysis negotiation nonverbal behavior;history;nonverbal behavior;behavioural sciences computing;acoustics;speech;audio visual behavioral cues dyadic negotiation acoustic behavioral cues face to face negotiation dataset nonverbal behavior behavioral symmetry;visualization;time factors;human behavior analysis;proposals;prediction;context;negotiation	Negotiation is a component deeply ingrained in our daily lives, and it can be challenging for a person to predict the respondent's reaction (acceptance or rejection) to a negotiation offer. In this work, we focus on finding acoustic and visual behavioral cues that are predictive of the respondent's immediate reactions using a face-to-face negotiation dataset, which consists of 42 dyadic interactions in a simulated negotiation setting. We show our results of exploring four different sources of information, namely nonverbal behavior of the proposer, that of the respondent, mutual behavior between the interactants related to behavioral symmetry and asymmetry, and past negotiation history between the interactants. Firstly, we show that considering other sources of information (other than the nonverbal behavior of the respondent) can also have comparable performance in predicting respondent reactions. Secondly, we show that automatically extracted mutual behavioral cues of symmetry and asymmetry are predictive partially due to their capturing information of the nature of the interaction itself, whether it is cooperative or competitive. Lastly, we identify audio-visual behavioral cues that are most predictive of the respondent's immediate reactions.	acoustic cryptanalysis;dyadic transformation;interaction;rejection sampling	Sunghyun Park;Stefan Scherer;Jonathan Gratch;Peter J. Carnevale;Louis-Philippe Morency	2015	IEEE Transactions on Affective Computing	10.1109/TAFFC.2015.2396079	psychology;developmental psychology;visualization;prediction;speech;linguistics;communication;social psychology;negotiation;statistics	Vision	-52.92307385035363	-49.38100191912016	95414
5c7346c71e3fb925193382ea6d6a4981449a044d	multimodal hci: exploratory studies on effects of first impression and single modality ratings in retrospective evaluation	multimodal dialog system;user factors;user experience;evaluation;quality aspects	This paper deals with the relevance of the first impression of interactive systems, based on short passive visual/auditory stimuli of system output. Individual consistency between such impressions and retrospective user ratings, obtained directly after real interaction, is studied in four exploratory experiments. All systems allow for voice user input. Two systems are considered to be multimodal as they support additional input other than speech (e.g., gesture); whereas the other two systems, offering speech as the sole input modality, are multimedia systems. The first impression of the four systems is based on screen-shots of typical display views and selected prompts of the systems’ speech output. Measures used here were pragmatic quality (i.e., the functional aspects of a system such as efficiency and effectiveness that are closely related to the concept of usability) and hedonic qualities (i.e., the systems non-instrumental aspects such as its ability to provide stimulation and identification—to evoke the psychological well-being of the user. It was tested, whether consistency found for web-sites can also be found for speech-based systems. In our case, this consistency was assessed not between systems, but within systems. Results indicate that users’ first impression of system output does correlate with ratings collected after the interaction for each of the four systems. For the two truly multimodal systems, ratings after single input (e.g., only voice, only touch screen) also correlates with ratings of a multimodal interaction with the same system. This result confirms data from literature. However, our assumption of lower correlations for the first impression of pragmatic quality, expected due to its experience-based character, is not supported. Instead, pragmatic quality seems to represent a construct with low consistency in general. Reasons for this might be found in the benefit of pragmatic quality experienced during multimodal interaction that is neither covered by unimodal interaction, nor predictable from a first impression. Additional multiple regression analysis for the two systems with multiple input modalities show that the first impression of the visual system output can complement predictors from the single modality interactions to model post-usage multimodal ratings. However, which of the output channels has a relevant impact was found to be highly system dependent.	experiment;human–computer interaction;modality (human–computer interaction);multimodal interaction;relevance;touchscreen;usability	Benjamin Weiss;Ina Wechsung;Stefan Hillmann;Sebastian Möller	2016	Journal on Multimodal User Interfaces	10.1007/s12193-016-0233-8	multimedia;communication	HCI	-48.96983616896618	-47.10010300229027	95462
d10d7f2a165fdac9a3be5dd23b1deaf9c31f67e5	sphero as an interactive tool in computer games for people with id	ipad air;smart toy;interactive systems computer games handicapped aids;color;handicapped aids;ipad air sphero interactive tool computer games intellectual disabilities;interactive tool;intellectual disabilities;games;sphero;intellectual disability;computer games;interactive systems;cameras;color games cameras;sphero smart toy intellectual disability	This paper presents an experiment in which people with intellectual disabilities played 3 apps with different levels and purposes on an iPad Air. As part of the game they were required to interact with Sphero and the activities they tried to perform required motor skills, attention and memory. We have selected two groups of participants according to their level of support needs. The results show the highest level of satisfaction in both groups in the game involving Sphero. In terms of effectiveness of activities for this profile of participant as interventions the results reveal that driving and care activities do show an adequate response, though with worse results related to memory.	color;pc game;ipad	Amaia Méndez Zorrilla;Begoña García Zapirain;J. Eskubi-Astobiza;L. Fernandez-Cordero	2015	2015 Computer Games: AI, Animation, Mobile, Multimedia, Educational and Serious Games (CGAMES)	10.1109/CGames.2015.7272953	games;simulation;human–computer interaction;computer science;multimedia;intellectual disability	HCI	-55.73257041646071	-48.116467297089216	95495
7507a2b28d7f603387b883a97ae1f2f0d6498f2c	a study on the acceptance of website interaction aids by older adults	human computer interaction;accessibility;older adults;usability	The goal of the present work is to investigate the potential acceptance of a set of web interaction aids by older adults, in order to help them overcome difficulties associated with ageing and help them continue using the web as a source of information, communication and services. This paper presents a survey with older adults concerning their perceptions about a set of web interaction aids defined after a field observation study, a study with questionnaires and user tests of web applications. The survey involved 313 participants, of which about 44 % were older adults and elderly users. The results showed that the use of aids to support the interaction of older adults with the web promotes improvements in the interaction of older adults and younger users alike, which supports the argument for enhanced universal usability. Finally, it was possible to diagnose barriers that still remain and which aids had best acceptance by older adults.	accessibility;assistive technology;information source;universal usability;web application;web design;web page	Silvana Maria Affonso de Lara;Renata Pontin de Mattos Fortes;Cibele Maria Russo;André Pimenta Freire	2015	Universal Access in the Information Society	10.1007/s10209-015-0419-y	usability;human–computer interaction;computer science;accessibility;multimedia;world wide web	HCI	-58.26418484809638	-44.95342123289576	95513
55ca6160d8b6c8a251de698f5c239ddaeaf99783	creating audio-augmented environments	context awareness;audio systems;context aware;intelligent user interface;user modeling;context model;adaptive systems;user experience;adaptive system;user testing;audio interface;user model;acoustic applications	The paper deals with the design and creation of an intelligent user interface augmenting the user experience in everyday environments, by providing an immersive audio environment. We highlight the potential of augmenting the visual real environment in a personalized way, thanks to context modeling techniques. The LISTEN project, a system for an immersive audio augmented environment applied in the art exhibition domain, provides an example of modeling and personalization methods affecting the audio interface in terms of content and organization. In addition, the different evolution steps of the system and the outcomes of the accompanying user tests are here reported.	augmented reality;embedded system;immersion (virtual reality);intelligent user interface;personalization;user experience;user modeling	Andreas Zimmermann;Andreas Lorenz	2005	Int. J. Pervasive Computing and Communications	10.1108/17427370580000111	user interface design;user;user experience design;user modeling;human–computer interaction;computer science;adaptive system;multimedia;natural user interface;user interface;world wide web	HCI	-53.24823238397067	-38.27363403161406	95642
e451e7f7fed326e2f17f3e0f3258071413383107	just-in-time technology to encourage incremental, dietary behavior change	software;computers handheld;diet;humans;health behavior;user computer interface;point of care systems;feeding behavior	"""Our multi-disciplinary team is developing mobile computing software that uses """"just-in-time"""" presentation of information to motivate behavior change. Using a participatory design process, preliminary interviews have helped us to establish 10 design goals. We have employed some to create a prototype of a tool that encourages better dietary decision making through incremental, just-in-time motivation at the point of purchase."""	decision making;increment;just-in-time compilation;mobile computing;numerous;point of sale;prototype	Stephen S. Intille;Charles Kukla;Ramesh Farzanfar;Waseem S Bakr	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		simulation;human–computer interaction;engineering;multimedia	Embedded	-62.640987297098235	-43.364713341676655	95733
07494d46196f30607615bee5e2fbb0d769082e58	game design and neuroscience cooperation in the challenge-based immersion in mobile devices as tablets and smartphones		The significant number of digital game applications for mobile devices, such as smartphones and tablets, motivates the concern of designers regarding the impact that the application of design elements may have in the construction of the gameplay experience. This concern is intensified when involving children on the stage of brain and cognitive development. This scenario is favorable to the cooperation between Game Design and Neuroscience, which are discussed in this article from the proximity between the elements of Challenge-based Immersion and attention mechanisms, decision-making, emotional and cognitive processing, and voluntary motor action. Among the main results obtained in the evaluation of two focus groups aged between 7–8 years-old and 9–12 years-old, there is the directly proportional association between cognitive involvement of the player with the game; the player control of the charts and navigation through the digital game objects; and the player motivation to overcome the challenges in this context.	immersion (virtual reality);mobile operating system;smartphone;tablet computer	Rachel Zuanon	2016		10.1007/978-3-319-39862-4_14	simulation;engineering;multimedia;communication	HCI	-56.810692196160545	-46.26777507369047	95866
087d714d526ce022fd5dad2922cec5a6409567d9	smartphone habit and behavior in brunei: personalization, gender, and generation gap	habit;generation gap;personality;gender;brunei;behavior;smartphone	A smartphone is a device which offers advanced technologies, functions similarly to a computer, supports multitasking and makes it easy to remain connected with others. The following survey design research examined the usage patterns of smartphone users across different demographics. The results of this study provide insights into the prevalence of respondents’ usage of smartphones and their habits and behavior related to smartphone use itself especially among the younger generation of social disorders such as nomophobia and phubbing. In addition to documenting the experience of smartphone users, the research also examines personality patterns related to smartphone usage, the trends of different age groups, and the effects of gender preferences.	personalization;smartphone	Muhammad Anshari;Yabit Alas;Glenn Hardaker;J. H. Jaidin;Mark Smith;Annie D. Ahad	2016	Computers in Human Behavior	10.1016/j.chb.2016.07.063	psychology;simulation;habit;multimedia;personality;social psychology;behavior	AI	-58.43250888196189	-44.932613286249435	95892
5a4254a9fa135a9a708861336051d1c0773b65f9	using ambient intelligence to improve public transport accessibility		This paper described how ubiquitous computing and ambient intelligence can be applied in order to make more accessible the public road transport for people with special needs. The main goal of the proposed system is to assist to this kind of people during the trips. This system is autonomous and does not affect the common operations carried out in the public transport infrastructure; it provides useful data obtained transparently, using different sensors installed in the infrastructure.	accessibility;ambient intelligence	Carmelo R. García;Alexis Quesada-Arencibia;Teresa Cristóbal;Gabino Padrón;Ricardo Pérez;Francisco Alayón Hernández	2014		10.1007/978-3-319-13102-3_4	trips architecture;ubiquitous computing;human–computer interaction;public transport;ambient intelligence;computer science;intelligent transportation system	HCI	-50.15643254563174	-41.510864992394204	95925
0dc6db36cd8f2e666eca49b44083a4cd423cc055	beyond time and error: a cognitive approach to the evaluation of graph drawings	graph drawing;visualization efficiency;user study;visual design;cognitive process;visualization;evaluation;cognitive load;questionnaire;eye tracking	Time and error are commonly used to measure the effectiveness of graph drawings. However, such measures are limited in providing more fundamental knowledge that is useful for general visualization design. We therefore apply a cognitive approach in evaluations. This approach evaluates graph drawings from a cognitive perspective, measuring more than just time and error. Three user studies are conducted to demonstrate the usefulness of this approach.	graph drawing;usability testing	Weidong Huang;Peter Eades;Seok-Hee Hong	2008		10.1145/1377966.1377970	questionnaire;computer vision;simulation;cognition;visualization;eye tracking;computer science;evaluation;multimedia;cognitive load;graph drawing	HCI	-59.374895117015555	-46.78959511427704	96052
4a143bef612ccca4a22dca16b3c4bb8045dbbe04	towards universal search design	inclusive design;search engines;intellectual disability	For people with cognitive disabilities, technology is more often thought of as a support mechanism, rather than a source of division that may require intervention to equalize access across the cognitive spectrum. This paper presents a first attempt at formalizing the digital gap created by the generalization of search engines. This was achieved through the development of a mapping of cognitive abilities required by users to execute low-level tasks during a standard Web search task. The mapping demonstrates how critical these abilities are to successfully use search engines with an adequate level of independence. It will lead to a set of design guidelines for search engine interfaces that will allow for the engagement of users of all abilities, and also, more importantly, in search algorithms such as query suggestion and measure of relevance (i.e. ranking).	cognition;high- and low-level;relevance;search algorithm;web search engine	Laurianne Sitbon;Lauren Fell;David Poxon;Jinglan Zhang;Shlomo Geva	2014		10.1145/2682862.2682882	simulation;universal design;computer science;knowledge management;artificial intelligence;world wide web;intellectual disability;information retrieval;search engine	HCI	-61.86510039722966	-42.72083781994876	96120
d0e7e8ef3eaeacae6a3be04d6c2262e2dbdac220	aspects of user profiles that can improve mobile augmented reality usage		Augmented Reality (AR) applications running on mobile devices have become more popular in recent years. As with digital games, many developers have begun to direct their applications to mobile platforms, although the processing power of these devices is usually smaller when compared to the computing power of laptops and desktops. Applications developed for computing devices, including mobile devices, typically have a well-defined target audience, and some of them use AR technology. The use of AR can actually add value to the application, but despite the additional motivation, interaction in this type of environment may be more complex compared to traditional applications. Considering this context, the main objective of the present work is to identify which key aspects in the user profile impact the design of mobile AR applications.	affinity analysis;augmented reality;desktop computer;download;experiment;laptop;mobile device;user profile	Silvio Ricardo Rodrigues Sanches;Marcio Oizumi;Claiton Oliveira;Eduardo Filgueiras Damasceno;Antonio Carlos Sementille	2017	2017 19th Symposium on Virtual and Augmented Reality (SVR)	10.1109/SVR.2017.38	human–computer interaction;augmented reality;multimedia;mobile device;target audience;computer science;user profile	HCI	-54.039942601808505	-39.82120833367013	96284
c8f400525492cf5c3c8fce42f82981a6fac6ae07	computational awareness in a tactile-responsive humanoid robot comedian	engineering;humanoid robotics;robot responsiveness computational awareness tactile responsive humanoid robot comedian robot friends social awareness intuitive human robot interactions tactile feedback;robot entertainment;robotics;human robot interaction;humanoid robots;artificial intelligence robotics humanoid robotics human robot interaction computational awareness robot entertainment engineering programming;human robot interaction haptic interfaces humanoid robots;artificial intelligence;conferences cybernetics;haptic interfaces;programming;computational awareness	In the future, humans will have robot friends that will need to have social and computational awareness for intuitive human-robot interactions. In this paper, we demonstrate a method for incorporating computational awareness in a humanoid robot comedian scenario that uses tactile feedback to respond to the audience. Our findings indicate that incorporating computational awareness in a humanoid robot must also take into account the users' ability to detect responsiveness in a robot.	computation;humanoid robot;humans;interaction;responsiveness	Paul Kaefer;Kevin Germino;Dustin Venske;Andrew B. Williams	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.485	mobile robot;robot learning;computer vision;cog;simulation;computer science;humanoid robot;artificial intelligence;social robot;robot control;robotics;ubiquitous robot;personal robot	Robotics	-52.039357527929255	-49.784933375296404	96339
427f25a699667919671c678123232066c9e3c146	emotion mirror: a novel intervention for autism based on real-time expression recognition	emotion mirror;real-time expression recognition;social deficit;novel intervention system;novel intersection;computer vision;facial expression perception;social functioning;facial expression;real-time facial expression processing;dynamic facial expression;cartoon character	"""Facial expression perception and production are crucial for social functioning. Children with autism spectrum disorders (ASD) are impaired in their ability to produce and perceive dynamic facial expressions, which may contribute to social deficits. Here we present a novel intervention system for improving facial expression perception and production in children with ASD based on computer vision. We present a live demo of the Emotion Mirror, a game where the children make facial expressions of basic emotions (anger, disgust, fear, happiness, sadness, and surprise) that are """"mirrored"""" by a cartoon character on the screen who responds dynamically in real-time. In the reverse mirror condition, the character makes an expression and children are rewarded when they successfully copy the expression of the character. This application demonstrates a novel intersection of computer vision and medicine enabled by real-time facial expression processing."""	computer vision;expression (computer science);real-time clock;real-time transcription;sadness	David M. Deriso;Joshua Susskind;Lauren Krieger;Marian Stewart Bartlett	2012		10.1007/978-3-642-33885-4_79	surprise;cognitive psychology;artificial intelligence;disgust;autism;emotion classification;sadness;anger;pattern recognition;facial expression;perception;computer science	Graphics	-50.68315766612836	-51.96798663545844	96581
cf9af1b7ce28a37c82b9815d031b958c088ef8b0	the impact of chinese traditional cultural on the gesture and user experience in mobile interaction design		Many designer using traditional cultural elements in mobile application interaction design, this design concept enhance user’s cognitive and emotion. Users will be inspired by an inner cultural identity when using App, and they will feel delighted about the operation. So integrate the traditional cultural elements into the interactive system is necessary, however, how to design the cultural element can conform to the user’s mental model, and have a positive impact on the user experience, that is the direction of the paper.	interaction design;mobile interaction;user experience	Ren Long;Xu Liu;Tian Lei;Xue Chen;Ziliang Jin	2017		10.1007/978-3-319-57931-3_5	interaction design;multimedia;human–computer interaction;cultural identity;user experience design;gesture;mobile interaction;cognition;computer science	HCI	-54.48401824571064	-38.50397366420494	96713
518f3e356501fb0aa2edc5b82b166082fa0b9f97	persistence matters: making the most of chat in tightly-coupled work	task performance;empirical study;persistence;mediated communication;community computing;text chat;computer mediated communication;information design;empirical studies;language;shared visual space;communication	How much history of the dialogue should a chat client include? Some chat clients have minimized the dialogue history to deploy the space for other purposes. A theory of conversational coordination suggests that stripping away history raises the cost of conversational grounding, creating problems for both writers and readers. To test this proposition and inform design, we conducted an experiment in which one person instructed another on how to solve a simple puzzle. Participants had chat clients that showed either a single conversational turn or six of them. Having the dialogue history helped collaborators communicate efficiently and led to faster and better task performance. The dialogue history was most useful when the puzzles were more linguistically complex and when instructors could not see the work area. We present evidence of participants adapting their discourse to partially compensate for deficits in the communication media.	instant messaging;online chat;persistence (computer science)	Darren Gergle;David R. Millen;Robert E. Kraut;Susan R. Fussell	2004		10.1145/985692.985747	human–computer interaction;computer science;multimedia;empirical research;world wide web;computer-mediated communication	HCI	-55.03384085375875	-44.57831709933253	96757
c143945daf4b3e7e46c436b7b405b7e02ec31c9c	permulin: personal in- and output on interactive surfaces	multi view display;personalized multitouch;tabletops	"""Interactive tables are well suited for co-located collaboration. Most prior research assumed users to share the same overall display output; a key challenge was the appropriate partitioning of screen real estate, assembling the right information """"at the users' finger-tips"""" through simultaneous input. A different approach is followed in recent multi-view display environments: they offer personal output for each team member, yet risk to dissolve the team due to the lack of a common visual focus. Our approach combines both lines of thought, guided by the question: """"What if the visible output and simultaneous input was partly shared and partly private?"""" We present Permulin as a concrete corresponding implementation, based on a set of novel interaction concepts that support fluid transitions between individual, group activities and coordination of group activities."""		Roman Lissermann;Jochen Huber;Jürgen Steimle;Max Mühlhäuser	2013		10.1145/2468356.2479616	simulation;human–computer interaction;multimedia;world wide web	HCI	-61.60696051464446	-39.39643812075174	96807
32da93d797e114f69ff2a5bbe868d0c6b7c45f81	exploring iphone usage: the influence of socioeconomic differences on smartphone adoption, usage and usability	diversity;mobile;user study;smartphones;iphone;ses;applications;socioeconomic status	Previous studies have found that smartphone users differ by orders of magnitude. We explore this variability to understand how users install and use native applications in ecologically-valid environments. A quasi-experimental approach is applied to compare how users in different socio-economic status (SES) groups adopt new smartphone technology along with how applications are installed and used. We present a longitudinal study of 34 iPhone 3GS users. 24 of these participants were chosen from two carefully selected SES groups who were otherwise similar and balanced. Usage data collected through an in-device programmable logger, as well as several structured interviews, identify similarities, differences, and trends, and highlight systematic differences in smartphone usage. A group of 10 lower SES participants were later recruited and confirm the influence of SES diversity on device usage. Among our findings are that a large number of applications were uninstalled, lower SES groups spent more money on applications and installed more applications overall, and the lowest SES group perceived the usability of their iPhones poorly in comparison to the other groups. We further discuss the primary reasons behind this low score, and suggest design implications to better support users across SES brackets.	accessible surface area;data logger;ecology;human–computer interaction;ibm notes;machine code;scsi enclosure services;smartphone;snapshot (computer storage);spatial variability;usability;usage data	Ahmad Rahmati;Chad Tossell;Clayton Shepard;Philip T. Kortum;Lin Zhong	2012		10.1145/2371574.2371577	computer science;socioeconomic status;operating system;mobile technology;multimedia;information technology;world wide web;computer security	HCI	-61.36364623764182	-43.98327979143698	96976
7c5ad588838bc65fc9cc424c453087f8314cab35	mms (multimedia messaging service) enabled web map dispatching solution for location enhanced fieldwork management	web mapping	Field workers, such as service men, perform every day many different tasks at different locations. Work-orders can be in well-known locations, e.g. weekly checks. But most service companies get work orders also as an alert in places where service men have not visited frequently or ever. In such cases navigation information is needed. The paper presents a web map dispatching pilot solution using MMS phones with attention to Enterprise Resource Planning.	enterprise resource planning;field research	Jari Reini	2003			world wide web;multimedia messaging service;web mapping;database;enterprise resource planning;computer science	HCI	-50.84210729214648	-39.94482148055317	97087
d9dee1fd04651d77c3bb612d0f4f2431fb921b72	discovering user interface requirements of search results for mobile clients by contextual inquiry	user interface;hierarchical access;interface design;contextual inquiry;mobile search;mobile interfaces;user requirements	This paper reports our  in situ  study using contextual inquiry (CI). It solicits user requirements of hierarchically organized search results for mobile access. In our experiment, search activities of our subjects are recorded in the video, and the interviewer solicits the interface requirements, during and after the experiment. An affinity diagram is built as a summary of our findings in the experiment, and the major issues are discussed in this paper. The search behavior of our subjects is summarized into a flow chart. In this study, we report mobile interface features that are desired by our users in addition to those found in an earlier survey.	contextual inquiry;user interface	David L. Chan;Robert Wing Pong Luk;Hong Va Leong;Edward Kei Shiu Ho	2009		10.1007/978-3-642-02559-4_40	user interface design;mobile search;human–computer interaction;computer science;contextual inquiry;multimedia;world wide web	Mobile	-55.549997483597	-43.19087557503861	97090
8dde027a56c09d0dc0fd257f5ef6d9d1b10c37be	nudge & influence through mobile devices	mobile device;social norms;emerging technology;mobile phone;influence;qa75 electronic computers computer science;interactive application;nudge;behavioral wedge;persuasive technology;focal point;cost effectiveness;scientific communication;social groups;mobile phones;social networking sites;interaction design;mobile devices;everyday life;social norm	The aim of this workshop is to provide a focal point for research and technology dedicated to persuasion and influence on mobile platforms. We aspire to establish a scientific network and community dedicated to emerging technologies for persuasion using mobile devices. This workshop would be a unique opportunity for interaction designers and researchers in this area to share their latest research and technologies on 'nudge' methods with the scientific communities. Patterns of consumption such as drinking and smoking are shaped by the taken-for-granted practices of everyday life. However, these practices are not fixed and 'immensely malleable'. Consequently, it is important to understand how the habits of everyday life change and evolve. Our decisions are inevitably influenced by how the choices are presented. Therefore, it is legitimate to deliberately 'nudge' people's behaviour in order to improve their lives. Mobile devices can play a significant role in shaping normal practices in three distinct ways: (1) they facilitate the capture of information at the right time and place; (2) they provide non-invasive and cost effective methods for communicating personalised data that compare individual performance with relevant social group performance; and (3) social network sites running on the device facilitate communication of personalised data that relate to the participant's self-defined community. Among the issues the workshop will take on are:(a) What opportunities do mobile interventions provide? (b) How far the intervention should go? (c) Is persuasion ethical? and (d) How can we extend the scale of intervention in a society using mobile devices? Participants will contribute to the workshop with examples of nudge and persuasive technologies, and we will work together to create novel ideas, interactive applications on the phone, and discuss future opportunities.	apevia;emoticon;focal (programming language);interaction design;mobile device;noise shaping;non-malleable codes;nudge (instant messaging);social network	Parisa Eslambolchilar;Max L. Wilson;Andreas Komninos	2010		10.1145/1851600.1851735	simulation;human–computer interaction;computer science;operating system;persuasive technology;mobile device;norm	HCI	-58.27573848492913	-41.652997143707864	97145
ae630dc5e18d97a2d94c5bd7fad5fe36237b103a	user attributes in processing 3d vr-enabled showroom: gender, visual cognitive styles, and the sense of presence	3d;cognitive style;virtual reality;gender;presence;virtual environment	Virtual environments (VEs) offer unique opportunities enabling users to experience real-time interactive objects and environments. Due to its dynamic three-dimensional (3D) presentation capability on two-dimensional screens, research has addressed the VE in relation to users’ spatial cognitive factors. However, little is known about users’ preferred cognitive modes for processing visual information and factors that affect visual cognitive processing in experiencing VEs. Research on gender differences in human–computer interaction has developed as a subfield approached from an interdisciplinary perspective that encompasses fields such as information science, marketing, neuroscience, and education. This study aims to investigate whether different visual cognitive styles influence the sense of presence (i.e., simulated experience in VEs) and how visual cognitions and presence affect user satisfaction of the 3D integrated system, as well as to uncover empirical evidence of gender influence on those relationships.#R##N##R##N#A total of 181 college students (90 men, 91 women) in diverse disciplines participated in an experiment using a VE stimulus and were given a questionnaire. The questionnaire was adapted to measure participants’ tendencies to use object versus spatial visualization, their sense of presence, and user satisfaction in the VE. Using multigroup structural equation modeling, we examined 3D visual information processing and gender effects. The results identify the relationship among visual cognitions, presence, and user satisfaction in VEs. We find it interesting that the results demonstrated significant gender differences in satisfaction as well as in processing visual information that influences user experience of the 3D VR embedded interface. Whereas women’s object visualization style was found to affect their sense of presence in VEs; for men, it was spatial visualization. This result supports and further explains findings of previous studies suggesting that gender effects account for differences in processing visual information.	anomalous experiences	So-Yeon Yoon;Yunsung Choi;Hyunjoo Oh	2015	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2015.04.002	human–computer interaction;cognitive style;computer science;virtual machine;artificial intelligence;operating system;virtual reality;multimedia	HCI	-58.4721816907746	-47.70926499519196	97217
3c4f01d85a4718dc30bc543e6596a0ecd08cdd5e	character actor: design and evaluation of expressive robot car seat motion		How might an actuated car seat become an expressive robot? To explore the possibilities of this novel interaction, we conducted a full design exploration from prototyping to validation, drawing on methods for embodied physical interaction design. First, we applied physical and digital puppeteering techniques to explore how a car seat can display emotional affect through movement with limited degrees of freedom in a semi-structured design workshop. Second, prototyped emotions were formalized with the Laban Effort framework and translated into computer animations. Third, we tested if lay users understood the expressions communicated by the animations in an online validation study on Amazon Mechanical Turk.  Participants generally agreed with our interpretation of six prototyped expressive states for the robot car seat (Neutral, Aggressive, Confident, Cool, Excited, and Quirky), and reported quantitative and qualitative reactions to each including perceived safety, which varied across conditions. Participants reported more implied cognition for higher valence expressions, and also were more likely to agree with our design intent. This specific case of physical interaction design and evaluation serves as a vignette for how to design and validate novel physical expressions in non-anthropomorphic robot interfaces.	amazon mechanical turk;autonomous car;cognition;human–computer interaction;interaction design;regular expression;robot;semiconductor industry;structured analysis;the turk	Hamish Tennent;Dylan Moore;Wendy Ju	2017	IMWUT	10.1145/3161407	simulation;car seat;interaction design;expression (mathematics);cognition;vignette;affect (psychology);embodied cognition;robotics;artificial intelligence;computer science	HCI	-51.173775147993375	-50.175692036268245	97483
166cb019eec3800c4bc042f55cda00fa0bb324d6	privacy concerns in sharing personal consumption data through online applications	social network services;electronic mail;privacy social network services data privacy electronic mail home appliances buildings computer science;home appliances;data privacy;social aspects of automation data privacy internet power aware computing power consumption;tolerance levels online eco feedback social applications energy awareness privacy concerns personal electricity consumption data sharing online contacts social electricity online application personal energy management social environment collaborative environment cyprus singapore student semester exercise acceptance levels;computer science;eco feedback privacy users perceptions energy awareness social electricity online social applications;buildings;privacy	As online eco-feedback social applications are being increasingly used around the world for motivating citizens to become more energy-aware, privacy concerns in terms of sharing personal electricity consumption data among online contacts are rising. Through Social Electricity, an online application offering personal energy management through a social and collaborative environment, we study the privacy concerns of the users in two case studies, in Cyprus and Singapore. For the Cyprus case, we present an analysis of results gathered through a large questionnaire-based survey combined with mini focus group studies. For the Singapore case, we analyze the findings collected through a students' semester exercise. This paper provides interesting insights about the overall acceptance and tolerance levels of users of eco-feedback social applications.	focus group;information sensitivity;privacy;privacy policy;web application	Andreas Kamilaris;Andreas Pitsillides;Sekhar Kondepudi;Nikos Komninos	2016	2016 International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2016.7577124	privacy software;privacy policy;information privacy;privacy by design;computer science;internet privacy;privacy;computer security	HCI	-60.16599010499222	-51.33223684708133	97820
7a3a6baecab310756313ff47c2f148a689be6265	emotional sea: showing valence and arousal through the sharpness and movement of digital cartoonish sea waves	behavioural sciences computing;valence arousal digital emotions movement sharpness;flocking algorithm emotional sea digital cartoonish sea waves nonanthropomorphic approach arousal dimensions bèzier curves arousal value;vectors shape heuristic algorithms cybernetics humans face visualization	This paper proposes and explores a nonanthropomorphic approach to express emotions. Emotions are represented in terms of valence and arousal dimensions, and they are visually expressed through the shape and movement of a series of digital cartoonish sea waves which are modeled as simple Bèzier curves. In particular, the valence value is expressed through the sharpness of the curves (the more negative the valence, the sharper the curves), while the arousal value is expressed through their movement (controlled by a flocking algorithm). Furthermore, this paper describes a user study which investigated whether the valence and arousal expressed by our model are appropriately perceived by the users or not. The results suggest that combinations of sharpness and movement are perceived correctly as particular emotions and that sharpness and movement are perceived as valence and arousal, respectively. We also found that valence in our model has a slight side effect in the perception of arousal. The more negative the valence, the higher the arousal is perceived.	algorithm;norm (social);usability testing	Jesús Ibáñez	2013	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMCA.2012.2220542	flocking (behavior);cognitive psychology;control theory;valence (chemistry);perception;arousal;mathematics	HCI	-49.529054310793555	-50.58622398459385	97907
eec62ca266afa1be07505cdb640160d9e25c8cbf	preconceptions and individual differences in understanding visual metaphors	information visualization;information interfaces and presentation hci h 5 m miscellaneous;thinking style;spatial ability;individual difference;information interfaces and presentation	Understanding information visualization is more than a matter of reading a series of data values; it is also a matter of incorporating a visual structure into one’s own thinking about a problem. We have proposed visual metaphors as a framework for understanding high-level visual structure and its effect on visualization use. Although there is some evidence that visual metaphors can affect visualization use, the nature of this effect is still ambiguous. We propose that a user’s preconceived metaphors for data and other individual differences play an important role in her ability to think in a variety of visual metaphors, and subsequently in her ability to use a visualization. We test this hypothesis by conducting a study in which a participant’s preconceptions and thinking style were compared with the degree to which she is affected by conflicting metaphors in a visualization and its task questions. The results show that metaphor compatibility has a significant effect on accuracy, but that factors such as spatial ability and personality can lessen this effect. We also find a complex influence of self-reported metaphor preference on performance. These findings shed light on how people use visual metaphors to understand a visualization.	cognition;cognitive science;high- and low-level;information visualization;interface metaphor;noise shaping;time series;unbalanced circuit	Caroline Ziemkiewicz;Robert Kosara	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01442.x	computer vision;information visualization;computer science;multimedia	HCI	-49.232032981512404	-50.084658635138034	98063
ba3313a8e135949aa0c293d7efc85583b5727e3d	h-slate: a hybrid braille slate soft keyboard for touchscreen devices	text entry;accessibility;visually impaired;slate and stylus;braille;touchscreens;soft keyboard	Touchscreens and touch input enabled interfaces are becoming more prevalent across electronic devices. They have already become the dominant input interface among mobile phones and tablets. Nowadays, even personal computers and laptops with touch enabled displays are being introduced more frequently to the market. The use of these devices becomes a demanding interaction challenge for the visually impaired because of the lack of tactile cues in their input surface. This is especially challenging to visually impaired elders who find it difficult to adapt to the accessibility technologies currently available for mobile devices. In this work we present H-Slate, our working prototype of a Braille slate soft keyboard that leverages the user's previous Braille writing experience and extends the Braille text input to all the applications and features in the device.	accessibility;haptic technology;input device;input method;laptop;mobile device;mobile phone;personal computer;prototype;removable media;stylus (computing);tablet computer;touchscreen	Luis Cavazos Quero;Garam Lee;Jing Yang;Jun-Dong Cho	2017		10.1145/3022198.3026340	computer hardware;computer science;accessibility;multimedia;communication;world wide web	HCI	-48.72917986522938	-41.878244308798195	98135
21003052d23434cdd587b861bb783712fa753bfe	formative work analysis to design caregiver robots	caregiver robot;caregiver;caregiving;eldercare;elder;work analysis;formative analysis;context conditioned variability	This paper describes recent developments in a research project that seeks to explore and describe how caregiving robots should function by analyzing caregiving in elders' homes, creating a detailed account of current elder care practices, and translating this account into design recommendations for caregiving robots.	robot	Keith S. Jones;Barbara Cherry;Mohan Sridharan	2015		10.1145/2701973.2702025	job analysis	HCI	-60.29226900590807	-50.62635571087394	98260
bef68a5e53be1b2fb8d3c88a969c1cf3c250c86c	"""the status of using """"big eye"""" chinese screen reader on """"wretch"""" blog in taiwan"""	web navigation;web pages;information technology;web accessibility;visually impaired users;accessibility blind and visually impaired;natural language interaction;construct validity;web design;visual impairment;statistical graphs	"""The """"Wretch"""" Blog (http://www.wretch.cc/) is one of the most popular blogs in Taiwan. Through the Chinese screen reader """"Big Eye"""", visual impaired users are able to interact with ordinary people on the """"Wretch"""" Blog. They can share their experience and feeling via their personal space and forum. In general, most functionality of the """"Wretch"""" Blog works well for visual impaired people except some perception transferred by pictures only. However, originally blog systems are developed for ordinary people, and do not concern the usability for visual impaired users. Lack of the concept of accessibility design brings some obstacle to visual impaired people.  When a blog system is designated, the principles of designing web accessibility should be included. Therefore, visual impaired users are able to surf blogs easily. Many suggestions from visual disability are illustrated below to provide the critical issues for designing blogs by referencing """"Wretch"""" Blog. It is hoped that the suggestions are useful for developing new blogs and/or revising existing blogs.  1. Providing valid maps  No matter a real map for space or a virtual sitemap for web navigation. It is important for visual impaired users to reconstruct a temporary psychological """"map"""" for unknown space in short time. They are able to """"walk"""" through a particular space only dependent on this """"map"""". For blind people, not like ordinary people can see obstacle by eyes, they only know obstacle exist while they hit it. In a new environment, how to construct valid guiding functionality is one of the most important issues.  Seeing through the service platform of """"Wretch"""" Blog, there is no valid navigation mechanism. It makes the first visits visual impaired users very difficult to use it. They have to explore and experiment by no targets, and spend much more time than ordinary people. It might be good to leverage thought of navigation mechanism, i.e. sitemap, to assist blind people to reconstruct a whole map for better understanding the website. It is not necessary to be too complex. It is good enough only to describe the blocks of the major templates, as well as to explain the hierarchy and the paths of the website.  2. Positioning himself/herself  For unknown web context, visual impaired users usually loose themselves very often. """"Searching cue and direction"""" is a lesson to train blind people who are able to walk independently. In case that they loose direction, they must have some ways to go certain """"positions"""" in their psychological """"map"""". Therefore, they may establish a new direction for future navigation. The idea of using accelerated keys is just the same thought.  3. Locating the major blocks  The major block of web content is usually located at the center of a webpage for most websites. Visual impaired users may use accelerated key to reach this block directly. Using the """"Blinding Scroll Bar"""" and """"Simulating Mouse"""" functions of """"Big Eye"""" screen reader, they may read the information of Web easily. If the location of the major block of web content is not precise, visual impaired users have to use """"TAB"""" or """"SHIFT+TAB"""" keys to sequentially surf the web content. The navigating process is become very inefficiently. Many screen readers made in Taiwan provide excellent features to read the major block of web content directly. However, not all of web designers leverage standard HTML syntaxes to design their Web. There are no <P> and </P> tags between the major block. Therefore, """"Big Eye"""" with these excellent features is useless. Moreover, though other screen readers with similar features may ignore the hyperlinks to reach the text part directly, however, much irrelative information may be accompanied with those texts.  4. Establishing voice reading mechanism for checking registration  Voice reading mechanism to assist blind people to validate their registered accounts and preserve security issues is established on some Portals in Taiwan. It overcomes the problem that visual impaired users can not see the validate text auto created by image. They have opportunity to accomplish the registration independently, such as on google or MSN Webs. However, though the """"Wretch"""" Blog does provide similar mechanism, its function seems not work very well. How to fix the problem may make it more accessible.  5. Adding alternative text  While surfing the web pages of the """"Wretch"""" Blog, many hyperlinks do not have alternative texts to explain the purpose of the links. Therefore, visual impaired users are difficult to understand the complete functionality provided by webpage. It might be good to add the alternative texts for all non-text objects.  Actually, blind people ask not much. If blog designers follow these principles to develop blogs, such as the """"Wretch"""" Blog does, most of the functionality fulfills the requirements of accessibility Web. It is hoped that more and more websites in Taiwan can be built by this phenomena. Letting more visual impaired users navigate these websites freely. They may enjoy the convenience just like ordinary people by information technology."""	blinding (cryptography);blog;global positioning system;html;hyperlink;image;portals;principle of good enough;requirement;scroll wheel;site map;speeded up robust features;usability;web accessibility;web content;web design;web navigation;web page	Yui-Liang Chen;Yung-Yu Ho	2007		10.1145/1243441.1243447	engineering;multimedia;internet privacy;world wide web	HCI	-51.346827625293294	-41.973566950470186	98368
1369ab2ee03df56ee419bb0d12de26885b802249	objsampler: a ubiquitous logging tool for recording encounters with real world objects	graphical user interface ubiquitous logging tool encounter recording rf id reader rf id tag real world object objsampler;hardware usability ubiquitous computing batteries web pages graphical user interfaces rfid tags sampling methods spine;user study;graphical user interface;ubiquitous logging tool;graphical user interfaces;real world object;design and implementation;ubiquitous computing graphical user interfaces radiofrequency identification;objsampler;sensor nodes;ubiquitous computing;rf id tag;radiofrequency identification;rf id reader;encounter recording;ubiquitous computing environment	"""We propose a novel tool, called objSampler, with which users can record and recall """"encounters"""" with objects in ubiquitous computing environments. We encounter various things, individuals, and places in the real world either consciously, meaning encounters that we are aware of, or unconsciously, meaning those we are unaware of but physically close to them. While some of those encounters are particularly important or treasurable to us, the physical memory in our brain is often too volatile to remember them. In objSampler, we address this issue by providing a state-of-art hardware called objPipette that embeds a sensor node, an RF-ID reader, and a battery cell. Users can record conscious encounters with it by scanning RF-ID tags pasted on real world objects. In addition, the objPipette detects and records the places where the user is. Users can recall the recorded encounters by using a software support in objSampler, called objScope. This paper describes the design and implementation of objSampler. User study, which is also provided in this paper, shows that objSampler provides a unique and intuitive means to achieve the above goal"""	computer data storage;consciousness;graphical user interface;internet backbone;rf modulator;radio frequency;sensor node;ubiquitous computing;usability testing	Jun'ichi Yura;Hideaki Ogawa;Taizo Zushi;Jin Nakazawa;Hideyuki Tokuda	2006	12th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA'06)	10.1109/RTCSA.2006.46	embedded system;real-time computing;human–computer interaction;computer science;operating system;graphical user interface;multimedia;world wide web;ubiquitous computing	HCI	-48.79839386812315	-40.604263492146195	98421
c837f695900fe8236f78d1b7f1a3f35cb62c9f5e	storybank: mobile digital storytelling in a development context	mobile;development;digital library;digital storytelling;information sharing;multimedia communication;cross section;india	Mobile imaging and digital storytelling currently support a growing practice of multimedia communication in the West. In this paper we describe a project which explores their benefit in the East, to support non-textual information sharing in an Indian village. Local audiovisual story creation and sharing activities were carried out in a one month trial, using 10 customized cameraphones and a digital library of stories represented on a village display. The findings show that the system was usable by a cross-section of the community and valued for its ability to express a mixture of development and community information in an accessible form. Lessons for the role of HCI in this context are also discussed.	digital library;human–computer interaction	David M. Frohlich;Dorothy Rachovides;Kiriaki Riga;Ramnath Bhat;Maxine Frank;Eran A. Edirisinghe;Dhammike Wickramanayaka;Matt Jones;Will Harwood	2009		10.1145/1518701.1518972	digital library;simulation;human–computer interaction;computer science;mobile technology;cross section;multimedia;world wide web	HCI	-56.20239702531017	-38.58524343605041	98666
cab8b0d3ef3bf043ac2a295c340445f54594d869	locative media and situated learning	mobile;heritage;pedagogy;collaborative learning;museums;gps;situated learning;locative;augmented reality	This article covers the conception and development of Empedia, a new locative software environment for mobile phones specifically designed for expanded archives, documentary and heritage/historical interpretation, using situated and collaborative learning, at resonant and related sites. It will examine our developmental methods employed through a number of workshops for pilot projects, employed specifically to test the reception of rich media assets and augmented reality features in a simple open source user interface and authoring environment for iPhone and browser consumption. The research projects at the Institute of Creative Technologies (IOCT) examined here include: a D. H. Lawrence Heritage Blue Line trail in Eastwood, Nottinghamshire (2009); Riverains, a dramatised history trail in Shoreditch, London (2010); and the use of collaborative documentary in Codes of Disobedience and Dysfunctionality in Athens (2011).	situated	Martin Rieser;Sean Clark	2013	Digital Creativity	10.1080/14626268.2013.813381	situated learning;visual arts;augmented reality;collaborative learning;simulation;locative case;global positioning system;human–computer interaction;computer science;artificial intelligence;mobile technology;multimedia;world wide web	HCI	-56.09955702607478	-38.35606349702718	98702
c9353a66593c5979b519f3ebcd2d7924fa2b4ba7	the autonomy levels and the human intervention levels of robots: the impact of robot types in human-robot interaction	service robots ontologies human robot interaction interviews receivers educational institutions;telerobotics control engineering computing control system synthesis human robot interaction;service robots;human robot interaction;receivers;autonomy levels social robots social presence tele operated robot autonomous robot emotional engagement human robot interaction human intervention levels;interviews;ontologies	The objective of this study is to examine the effect of the robot types on emotional engagement with robots. Robots are classified into an autonomous robot and a tele-operated robot according to the levels of autonomy. On the contrary, robots could be distinguished depending on the levels of human intervention required for controlling a robot. An autonomous robot performs task by itself while a tele-operated robot requires an operator's help in task-oriented activity. In emotional communication, an autonomous robot expresses robotic emotions by itself whereas a tele-operated robot delivers an operator's emotions to a receiver. In this study, we compared the impact of the two robot types on perceived intelligence and social presence of robots. We executed a 2 (robot types: an autonomous robot vs. a tele-operated robot) within-participants experiment (N=36). Participants had an interview with either autonomous robot interviewers or tele-operated robot interviewers. They evaluated autonomous robots as more intelligent than tele-operated robots while they felt more social presence toward tele-operated robots than autonomous robots. Implications for design of social robots to increase humans' emotional engagement with robots are discussed.	autonomous robot;autonomy;humans;human–robot interaction;social presence theory;social robot;television	Jung-Ju Choi;Yunkyung Kim;Sonya S. Kwak	2014	The 23rd IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2014.6926394	human–robot interaction;mobile robot;robot learning;computer vision;tico robot;simulation;interview;computer science;ontology;artificial intelligence;social robot;robot control;mobile robot navigation;personal robot	Robotics	-51.75650616532215	-50.68629091830889	98848
50827ac9a8de9201f6351065def21e63b2f6c6fd	visualizing the process - a graph-based approach to enhancing system-user knowledge sharing	dynamical processes;design guideline;collaborative problem solving;enterprise resource planning;knowledge sharing;user interface design;information system;community involvement	Our research is concerned with developing design guidelines aimed at improving the usability of enterprisewide information systems by employing collaborative problem solving as a model for user-system interaction. In this paper, we present our approach to addressing a critical design issue that we identified through our field research: namely, system-to-user communication involving components of a complex process flow. This approach uses a dynamic process graph and a set of related task links that are displayed alongside the traditional ERP task interfaces. We outline the collaborative framework and position our solution within it. This solution can benefit other application areas, especially those that involve protracted processes that are not familiar to	erp;field research;information system;problem solving;usability	Tamara Babaian;Wendy T. Lucas;Heikki Topi	2007			user interface design;computer science;knowledge management;management science;information system	HCI	-61.84746533711995	-38.87259151657743	98916
ab0a9e34640ef1905cec9499341a5e082501056c	keeping in touch by technology: maintaining friendships after a residential move	mediated communication;mobility;social relationship;cmc;social relationships;social support;communication technology;communication;natural experiment;friendship	Many observers have praised new communication technologies for providing convenient and affordable tools for maintaining relationships at a distance. Yet the precise role of mediated communication in relationship maintenance has been difficult to isolate. In this paper, we treat residential moves as natural experiments that threaten existing social relationships and often force people to rely on mediated communication to maintain their old relationships. Results from a 3-wave survey of 900 residential movers describing 1892 relationships shows that email and the telephone play different roles in social relationships. Email helps maintain social relationships, in the sense that relationships decline when email drops after the move. However increases in email are not associated with increases in the depth of the relationship or exchanges of support. In contrast, phone calls help movers grow relationships and exchange social support.	email;experiment;social support	Irina Shklovski;Robert E. Kraut;Jonathon N. Cummings	2008		10.1145/1357054.1357182	information and communications technology;computer science;natural experiment;mobile computing;world wide web	HCI	-58.088228877099674	-50.035729799840276	98929
d84534ef718996db9c7ebe218b74c76bdbcf26e3	seensearch: a context directed search facilitator for home entertainment devices	internet;home computing;information retrieval;internet;seensearch;context directed search facilitator;home entertainment device;context-directed search;internet search on tv;keyboard-less search;query extraction and composition;query refinement;seamless information retrieval	The Internet has become an extremely popular source of entertainment and information. But, despite the growing amount of media content, most Web sites today are designed for access via web browsers on the PC, making it difficult for home consumers to access Internet content on their TVs or other devices that lack keyboards. As a result, the Internet is generally restricted to access on the PC or via cumbersome interfaces on non-PC devices. In this paper, we present unobtrusive and assistive technologies enabling home users to easily find and access Internet content related to the TV program they are watching. Using these technologies, the user is now able to access relevant information and video content on the Internet while watching TV.		Alan Messer;Anugeetha Kunjithapatham;Phuong Nguyen;Priyang Rathod;Mithun Sheshagiri;Doreen Cheng;Simon Gibbs	2008		10.1109/PERCOM.2008.107	embedded system;the internet;computer science;operating system;multimedia;internet privacy;user interface;world wide web	HCI	-50.196268259758845	-40.049437885471306	98959
9f58eaf4e40703f72c616cc759379e1553d736bc	on visual granularity: collocated sales meeting interactions in the machine industry		Visual representations are being used in typical sales meetings of the machine industry to exchange information and support social interactions. In these meetings, sales representatives design for granularity by taking into account verbal and visual details of communication. Our article builds on increasingly occurring collocated interactions in sales meetings investigating the social relevance of mobile devices in face-to-face settings. The article aims to understand the supporting and disturbing role of visual granularity in sales meetings and develops design implications for interaction designers. We conducted an ethnographic study of sales meetings in material handling and paper machine industries, including Conversation Analysis (CA) of video recordings, and involving groups of professional analysts that are seldom used in HCI. Our findings draw evidence from sales meetings and design processes on successful and unsuccessful use of granularity in visual representations. Finally, we propose seven design guidelines for visual granularity striving to understand buyers' perceptions and visual qualities.	complex systems;database;human–computer interaction;information flow (information theory);interaction design;material handling;mobile device;relevance;usability;user experience	Mikko Illi;Maria Karyda;Andrés Lucero	2018		10.1145/3173574.3173721	human–computer interaction;multimedia;granularity;conversation analysis;mobile device;machine industry;computer science	HCI	-61.00613793552987	-38.36797827030863	99053
35117915568105de0e56513fa247eb25b30d539a	behavioral and emotional spoken cues related to mental states in human-robot social interaction	affective interaction;human robot interaction;real time emotion detection;social robots;humor	Understanding human behavioral and emotional cues occurring in interaction has become a major research interest due to the emergence of numerous applications such as in social robotics. While there is agreement across different theories that some behavioral signals are involved in communicating information, there is a lack of consensus regarding their specificity, their universality, and whether they convey emotions, affective, cognitive, mental states or all of those. Our goal in this study is to explore the relationship between behavioral and emotional cues extracted from speech (e.g., laughter, speech duration, negative emotions) with different communicative information about the human participant. This study is based on a corpus of audio/video data of humorous interactions between the nao{} robot and 37 human participants. Participants filled three questionnaires about their personality, sense of humor and mental states regarding the interaction. This work reveals the existence of many links between behavioral and emotional cues and the mental states reported by human participants through self-report questionnaires. However, we have not found a clear connection between reported mental states and participants profiles.	cognition;emergence;http 404;interaction;mental state;nao (robot);robotics;sensitivity and specificity;social robot;text corpus;theory;universality probability	Lucile Bechade;Guillaume Dubuisson Duplessis;Mohamed El Amine Sehili;Laurence Devillers	2015		10.1145/2818346.2820777	human–robot interaction;computer science;artificial intelligence;social robot;comedy	HCI	-52.63691480007891	-49.6219861891276	99110
8bdc2ba4353cc48509938f33f71c6629ad1046b4	what interactivity means to the user essential insights into and a scale for perceived interactivity		The selection and use of media depend largely on how users perceive such media. A central aspect of the “new media” is their interactivity, but how users perceive this phenomenon has rarely been researched. This study provides an in-depth investigation into the perception component of interactivity and develops a compact scale for its measurement. According to psychological approaches, practical uses (affordances) – not physical or technical characteristics – guide perception. While existing scales mostly measure whether the “interactive” technical features of devices or websites are noticed, our instrument is based on the affordances that interactivity provides. Consequently, a new research design, the use-identified meaning, was implemented. This is the first study on interactivity that empirically examines a wide range of Internet-based services, thus meeting the broad ambit of interactivity. Our results generally validate the existing constructs, which are largely based on technical characteristics, yet provide additional insights into the relevant contexts and the subjective significance of different aspects of interactivity.	ambit;interactivity;new media	Dominik J. Leiner;Oliver Quiring	2008	J. Computer-Mediated Communication	10.1111/j.1083-6101.2008.01434.x	human–computer interaction;computer science;multimedia;interactivity;social psychology;world wide web	HCI	-60.10427934088523	-45.797250188416996	99130
f5874cccf870fe0586306ab105d678b551e020bc	physiovr: a novel mobile virtual reality framework for physiological computing	wearables;physiological computing;virtual reality;emg;heart rate;eeg;smartphone;framework;open source	Virtual Reality (VR) is morphing into a ubiquitous technology by leveraging of smartphones and screenless cases in order to provide highly immersive experiences at a low price point. The result of this shift in paradigm is now known as mobile VR (mVR). Although mVR offers numerous advantages over conventional immersive VR methods, one of the biggest limitations is related with the interaction pathways available for the mVR experiences. Using physiological computing principles, we created the PhysioVR framework, an Open-Source software tool developed to facilitate the integration of physiological signals measured through wearable devices in mVR applications. PhysioVR includes heart rate (HR) signals from Android wearables, electroencephalography (EEG) signals from a low-cost brain computer interface and electromyography (EMG) signals from a wireless armband. The physiological sensors are connected with a smartphone via Bluetooth and the PhysioVR facilitates the streaming of the data using UDP communication protocol, thus allowing a multicast transmission for a third party application such as the Unity3D game engine. Furthermore, the framework provides a bidirectional communication with the VR content allowing an external event triggering using a real-time control as well as data recording options. We developed a demo game project called EmoCat Rescue which encourage players to modulate HR levels in order to successfully complete the in-game mission. EmoCat Rescue is included in the PhysioVR project which can be freely downloaded. This framework simplifies the acquisition, streaming and recording of multiple physiological signals and parameters from wearable consumer devices providing a single and efficient interface to create novel physiologically-responsive mVR applications.	android;application programming interface;bluetooth;brain–computer interface;communications protocol;electroencephalography;electromyography;experience;game demo;game engine;interactivity;matlab;morphing;multicast;multimodal interaction;open-source software;price point;programming language;programming paradigm;programming tool;python;real-time locating system;screenless;sensor;smartphone;unity;virtual reality;virtual world;wearable computer;wearable technology	John Edison Muñoz Cardona;Teresa Paulino;Harry Vasanth;Karolina Baras	2016	2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)	10.1109/HealthCom.2016.7749512	embedded system;simulation;engineering;multimedia	Visualization	-52.87062547418525	-43.21874349242651	99201
0333746cbe16d657505549930019774cd064f406	powering interactive intelligent systems with the crowd	intelligent systems;human computation;crowdsourcing	Creating intelligent systems that are able to recognize a user's behavior, understand unrestricted spoken natural language, complete complex tasks, and respond fluently could change the way computers are used in daily life. But fully-automated intelligent systems are a far-off goal -- currently, machines struggle in many real-world settings because problems can be almost entirely unconstrained and can vary greatly between instances. Human computation has been shown to be effective in many of these settings, but is traditionally applied in an offline, batch-processing fashion. My work focuses on a new model of continuous, real-time crowdsourcing that enables interactive crowd-powered systems.	artificial intelligence;batch processing;computer;crowdsourcing;human-based computation;natural language;online and offline;real-time locating system	Walter S. Lasecki	2014		10.1145/2658779.2661168	simulation;intelligent decision support system;human–computer interaction;computer science;artificial intelligence;operating system;multimedia;crowdsourcing	AI	-51.39597285660094	-44.405566832761664	99230
bffb6f418f2a32f249af62f4c773d73dae3501ad	task-oriented information value measurement based on space-time prisms	space time prism;information value;time geography	Recent years have witnessed a large increase in the amount of information available from the Web and many other sources. Such an information deluge presents a challenge for individuals who have to identify useful information items to complete particular tasks in hand. Information value theory (IVT) from economics and artificial intelligence has provided some guidance on this issue. However, existing IVT studies often focus on monetary values, while ignoring the spatiotemporal properties which can play important roles in everyday tasks. In this paper, we propose a theoretical framework for task-oriented information value measurement. This framework integrates information value theory with the space-time prism from time geography and measures the value of information based on its impact on an individual’s space-time prisms and its capability of improving task planning. We develop and formalize this framework by extending the utility function from space-time accessibility studies and elaborate it using a simplified example from time geography. We conduct a simulation on a real-world transportation network using the proposed framework. Our research could be applied to improving information display on small-screen mobile devices (e.g., smartwatches) by assigning priorities to different information items.	accessibility;artificial intelligence;display device;mobile device;simulation;smartwatch;time geography;utility;world wide web	Yingjie Hu;Krzysztof Janowicz;Yuqi Chen	2016	International Journal of Geographical Information Science	10.1080/13658816.2015.1124434	simulation;time geography;geography;computer science;machine learning;value of information;management science;cartography	AI	-59.65862152403624	-43.4065894216652	99341
804b0d7796026259c869f29c6d7d308925d9dda8	the effect of virtual agents' emotion displays and appraisals on people's decision making in negotiation	appraisal theories;reverse appraisal;emotion displays;negotiation	There is growing evidence that emotion displays can impact people’s decision making in negotiation. However, despite increasing interest in AI and HCI on negotiation as a means to resolve differences between humans and agents, emotion has been largely ignored. We explore how emotion displays in virtual agents impact people’s decision making in human-agent negotiation. This paper presents an experiment (N=204) that studies the effects of virtual agents’ displays of joy, sadness, anger and guilt on people’s decision to counteroffer, accept or drop out from the negotiation, as well as on people’s expectations about the agents’ decisions. The paper also presents evidence for a mechanism underlying such effects based on appraisal theories of emotion whereby people retrieve, from emotion displays, information about how the agent is appraising the ongoing interaction and, from this information, infer about the agent’s intentions and reach decisions themselves. We discuss implications for the design of intelligent virtual agents that can negotiate effectively.	human–computer interaction;intelligent agent;sadness;theory	Celso de Melo;Peter J. Carnevale;Jonathan Gratch	2012		10.1007/978-3-642-33197-8_6	psychology;knowledge management;communication;social psychology;negotiation	HCI	-52.506144511584104	-51.92174704655188	99345
f292cbe46555525af17b6995d1e5969d011df28f	visualization of heart activity in virtual reality: a biofeedback application using wearable sensors		Stress or anxiety disorders are a growing problem in industrialized countries. Those can be effectively countered by several relaxation techniques which are more effective using biofeedback. Modern virtual reality hardware provides a high level of immersion to its users. This directly affects the feeling of presence. An increased feeling of presence may allow biofeedback mechanisms to work more effectively. We build on this idea and explore how different visualizations of a user's cardiac activity in a virtual environment can be used in biofeedback scenarios — and how effective they are. Using a state-of-the-art virtual reality headset, 14 participants were subjected to four different visualizations of their own heart rate (one control visualization and three experimental visualizations). In different experiments, we examined whether they were able to estimate their heart rate based on the visualization and whether we could influence it subconsciously. Furthermore, we used the AttrakDiff questionnaire to assess the usability and attractiveness of each of the four visualizations. For the three non-reference ones, we observed significant positively correlating changes in the heart rate between the real-time true representation of the heart rate and a simulated increased heart rate visualization with a mean magnitude of 1.96 ± 0.39 beats per minute. The results from the source and number estimation experiments and the questionnaire led to the conclusion that the most appealing and best working visualization for biofeedback is a synchronized modulation/modification of the virtual environment itself.	experiment;headset (audio);high-level programming language;immersion (virtual reality);linear programming relaxation;modulation;real-time clock;scientific visualization;sensor;usability;virtual reality headset;wearable computer;wearable technology	Stefan Gradl;Markus Wirth;Tobias Zillig;Bjoern M. Eskofier	2018	2018 IEEE 15th International Conference on Wearable and Implantable Body Sensor Networks (BSN)	10.1109/BSN.2018.8329681	wearable computer;visualization;artificial intelligence;computer vision;human–computer interaction;usability;immersion (virtual reality);computer science;biofeedback;virtual machine;headset;virtual reality	Visualization	-54.843173029140594	-49.7502612354214	99468
55c7c55237512b1ab4e9d71f8644b86d5d9c0d60	mobile and context-aware grocery shopping to promote active aging	active aging;price sensitivity;social shopping;grocery shopping	"""Active aging aims at promoting physical activity, socialization and participation in society as a mechanism to improve physical and mental health. We explore the use of a mobile, context-aware application to help elders transform their grocery shopping experience into an activity that promotes active aging. We describe the design and formative evaluation of WaSSAA, a mobile application to persuade elders to exercise and socialize while sharing grocery prices and promoting """"smart"""" grocery shopping. WaSSAA uses location information to promote social encounters and to ask shoppers to gather price information for fellow users, and the accelerometer to estimate physical activity and reward its user. Results of a formative evaluation of the usefulness of WaSSAA with 16 elders shows that older adults are aware and sensitive to grocery prices and find the application useful to guide them when comparing prices during grocery shopping. They also perceive grocery shopping as a social activity and welcome WaSSAA's services to encourage in-person encounters."""		Netzahualcóyotl Hernández;Carlos Refugio;Monica Tentori;Jesús Favela;Sergio F. Ochoa	2013		10.1007/978-3-319-03092-0_11	social shopping;formative assessment;marketing;mental health;computer science;multimedia;socialization;ask price	Robotics	-58.16412831682674	-45.23861819758917	99504
5fd539b435162a761001f01ff1c57d9961e8c188	a study of effective social cues within ubiquitous robotics	human-robot interaction;ubiquitous computing;hri results;effective social cues;non-verbal social;sensorial resources;social interfaces;ubiquitous computational;ubiquitous computing;ubiquitous robotic system;human-robot interaction;non-verbal communication;social robotics;ubiquitous robotics	Ubiquitous computing is the execution of computational tasks through everyday objects. Ubiquitous robotics augments the capabilities of one or more robots by leveraging ubiquitous computational and/or sensorial resources. Augmentation complements and/or enhances the capabilities of one or more robots while such robots can simultaneously serve as intermediaries or social interfaces to ubiquitous services. This paper posits the importance of conducting user studies to validate related HRI results within ubiquitous robotics. Specifically, the paper presents a pilot study designed to test the effectiveness of acknowledging human presence via non-verbal social cues and its impact on the user's acceptance and engagement with a ubiquitous robotic system.	human–robot interaction;robotics;ubiquitous computing;ubiquitous robot	Anara Sandygulova;David Swords;Sameh Abdel-Naby;Gregory M. P. O'Hare;Mauro Dragone	2013	2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)		human–robot interaction;nonverbal communication;context-aware pervasive systems;simulation;human–computer interaction;computer science;artificial intelligence;social robot;ubiquitous robot;ubiquitous computing	Robotics	-52.178236903782526	-50.047385161209625	99517
21a93665646aa6d104b68e5803b9604a56972dec	unveiling the multimedia unconscious: implicit cognitive processes and multimedia content analysis	flickr;image representation;feature extraction;personality traits;cognitive processes	"""One of the main findings of cognitive sciences is that automatic processes of which we are unaware shape, to a significant extent, our perception of the environment. The phenomenon applies not only to the real world, but also to multimedia data we consume every day. Whenever we look at pictures, watch a video or listen to audio recordings, our conscious attention efforts focus on the observable content, but our cognition spontaneously perceives intentions, beliefs, values, attitudes and other constructs that, while being outside of our conscious awareness, still shape our reactions and behavior. So far, multimedia technologies have neglected such a phenomenon to a large extent. This paper argues that taking into account cognitive effects is possible and it can also improve multimedia approaches. As a supporting proof-of-concept, the paper shows not only that there are visual patterns correlated with the personality traits of 300 Flickr users to a statistically significant extent, but also that the personality traits (both self-assessed and attributed by others) of those users can be inferred from the images these latter post as """"favourite""""."""	cognition;cognitive science;flickr;image;observable	Marco Cristani;Alessandro Vinciarelli;Cristina Segalin;Alessandro Perina	2013		10.1145/2502081.2502280	computer vision;cognition;feature extraction;computer science;machine learning;multimedia;big five personality traits;world wide web	Web+IR	-54.37092417457513	-48.81445050736489	99521
814342d0f66eea0daaad2c738281310a5301f914	analyzing crowdsourcing to teach mobile crowdsensing a few lessons	crowdsourcing;crowdsensing;human–computer interaction;data mining	In recent years, mobile computing has shown so much potential that one can see a boundary-blurring expansion between the physical and the digital world. In this context, one of the most sought after research areas is mobile crowdsensing. To realize the vision of crowdsensing, there is a plethora of work in the literature that focuses on the technical capabilities of a mobile device. However, an important and a critical problem that eludes literature is the issue of human participation. We base this argument on a very simple, yet powerful fact that a mobile device is still a person’s private property. Therefore, considering human mentality, can we expect a person to contribute all the time? In this respect, it is not feasible for a human dependent computational system to ignore the inevitable human factor and focus only on the mechanical properties. In this paper, we look into the often ignored human aspects and will study the problem from a psychological perspective. We take inspiration from the mature paradigm of crowdsourcing and discuss the importance of a few human factors that could teach us how to encourage user participation in mobile crowdsensing. Further, we also explore a person’s habitual characteristics that could help answer the decade’s old question: How to get quality responses from the crowd? We use a psycho-technological approach to observe, understand, and find a few details regarding human behavior in online systems. Lastly, we take inspiration from the analysis to present a roadmap that aids in engineering a better and effective crowdsensing platform.	computation;crowdsensing;crowdsourcing;expect;human factors and ergonomics;intellect;locality of reference;mobile computing;mobile device;norm (social);numerical analysis;presence information;programming paradigm;stack overflow;theory	Tanveer Ahmed;Abhishek Srivastava	2018	Cognition, Technology & Work	10.1007/s10111-018-0474-2	crowdsensing;knowledge management;engineering;mobile device;mobile computing;private property;crowdsourcing	HCI	-58.64174181175974	-41.72550317820416	99776
9cbf8e98eca4941f8836790f3daea33bb4228470	improving song guessing games through music track composition		In this work we propose a different scheme for music guessing games, based on a constructive approach. By analyzing current available mobile games, we show the barriers that must be surpassed to make such games viable and how novel this work is. We have implemented a game prototype called “What’s the Song” and performed user tests with both usual and constructive approaches. A Likert questionnaire was answered by all users and it points out that the constructive approach improves game engagement and overall user experience.		João Marcelo X. N. Teixeira;Dicksson Almeida;Edvar Vilar Neto;Veronica Teichrieb	2015		10.1007/978-3-319-20889-3_29	speech recognition;computer science;multimedia;communication	HCI	-56.66758785448551	-47.64736225686036	99783
cf68f68f79782554b61787d8c38df7145f75344d	brickroad: a light-weight tool for spontaneous design of location-enhanced applications	tool support;user feedback;design space;prototyping;wizard of oz;on the fly;ubiquitous computing;location enhanced computing	It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications.	feedback;prototype;spontaneous order;wizard of oz experiment	Alan King Lun Liu;Yang Li	2007		10.1145/1240624.1240673	simulation;human–computer interaction;computer science;operating system;prototype;world wide web;ubiquitous computing	HCI	-51.24104627641805	-38.24528386115961	100183
10adb3df6e1a9410a2c4ae81a98b6bdd66c0d3e3	tastybeats: making mocktails with heartbeats	biofeedback;physical activity;fluid interaction	The heart not only represents love and emotions. Its measurement is also essential to evaluate fitness. However, visualizing heart rate so far has been limited to virtual screens with restrictive interaction, thus providing us an opportunity to develop a new interactive visualization scheme. With the PumpSpark Fountain Development Kit, we see an opportunity to create a personalized drink using the measured heartbeat data of an individual during physical activity. We describe a prototype system called TastyBeats where one or two participants engage themselves in a fluidic spectacle of creating a mocktail that matches their heartbeats. Our work expands the view of visualizing physical activity beyond virtual screen by providing a real-time and interactive visualization of heart beat data. The TastyBeats induces an active engagement of the player with representation of personal heartbeat in the form of a mocktail created by mixing different flavors together.	interactive visualization;personalization;prototype;real-time transcription;virtual desktop	Rohit Ashok Khot;Jeewon Lee;Helmut Munz;Deepti Aggarwal;Florian Mueller	2014		10.1145/2559206.2574830	simulation;multimedia;physical fitness	HCI	-53.28539429453375	-43.765559706527135	100304
44fcd31c7782496923ec78b020cf476117c1ab39	how does the robot feel? perception of valence and arousal in emotional body language			robot	Mina Marmpena;Angelica Lim;Torbjørn S. Dahl	2018	Paladyn	10.1515/pjbr-2018-0012	machine learning;body language;robot;artificial intelligence;perception;computer science;valence (chemistry);cognitive psychology;arousal	HCI	-53.08049189141314	-49.87931201752666	100335
97824a47b4befb6705f12a1dc772b6ef70c95e19	attention estimation for child-robot interaction	child robot interaction;attention estimation;multimodal information	In this paper, we present a method of estimating a child's attention, one of the more important human mental states, in a free-play scenario of child-robot interaction. First, we developed a system that could sense a child's verbal and non- verbal multimodal signals such as gaze, facial expression, proximity, and so on. Then, the observed information was used to train a Support Vector Machine (SVM) to estimate a human's attention level. We investigated the accuracy of the proposed method by comparing with a human judge's estimation, and obtained some promising results which we discuss here.	human–robot interaction;mental state;multimodal interaction;observed information;robot;support vector machine	Muhammad Attamimi;Masahiro Miyata;Tetsuji Yamada;Takashi Omori;Ryoma Hida	2016		10.1145/2974804.2980510	psychology;computer vision;communication;social psychology	HCI	-50.38634796487284	-49.04719561010488	100394
a6baeec3d65821235095c36b82e4021f11e14a2a	defining sociability and social presence in social tv	user interface;sociability;user experience;social presence;social tv	Social TV, a new interactive television service, has been rapidly developing. With the conceptual model of sociability, this study empirically investigates the effects of perceived sociability on the motivations and attitudes toward Social TV. A model is created to validate the relationship of perceived sociality to social presence, usability, and intention. Empirical findings show the key influence of sociability on users' acceptance and intent to continue using Social TV. Implications of the findings are discussed in terms of building a theory of sociability and providing practical insights into developing a meaningful sociable TV interface.	social presence theory;social television	Dong-Hee Shin	2013	Computers in Human Behavior	10.1016/j.chb.2012.07.006	psychology;user experience design;human–computer interaction;computer science;multimedia;user interface;social psychology	HCI	-59.77430489262322	-45.379341266507296	100460
5312fe48dbf6ebb3f0c1a247cab50758ebcc050d	on the implications of sense of control over bicycling: design of a physical stamina-aware bike	vdp teknologi 500 informasjons og kommunikasjonsteknologi 550;sense of control;stamina aware;system evaluation;machine intelligence and smart services;smart services;machine intelligence;indexation;mobile sensing system;bicycling;feedback system;stamina cost;stamina awareness;environmental awareness	Bicycling has become a mainstream activity among the environmental aware generation. Bicycling communities have gradually shown interests in quantitative data of the bicycling experiences such as road roughness, inclination, pollution, etc. Bikers utilize these data to infer the possible stamina cost and quality of surroundings. This supports them to make a better decision. This study assumes that fitness level indexed by stamina cost could enhance a biker's sense of control. The prototype in this paper was developed to provide stamina cost information, which is inferred from the terrain patterns of a biking route. In the system evaluation, participants took a positive attitude toward this prototype and approved the importance of stamina cost feedback. This paper also concluded several key issues about designing the stamina cost feedback system for bikers.	experience;prototype	Chao-Lung Lee;David A Lee;Yun-Maw Cheng;Li-Chieh Chen;Wei-Chia Chen;Frode Eika Sandnes	2010		10.1145/1952222.1952227	simulation;human–computer interaction;computer science;feedback;cycling;computer security	HCI	-58.43847291125245	-42.44461447314228	100581
b7e06646c9b5c5b8025fcd74b5349b339069680e	cross-platform service user experience: a field study and an initial framework	mobile device;web service;conceptual framework;crossmedial interactions;cross platform web services;user experience;user experience ux;field study;mobile terminal;web based service	Many web-based services utilize both desktop and mobile terminals in delivering content and functionality to their users. In terms of user experience (UX), the overall chain of interactions, including mobile and non-mobile settings, becomes a central design target. The aim of this study was to investigate, what are the key elements of user experience associated with these, cross-platform interactions. This paper presents the findings from a four week long field study with three web-based cross-platform services. During the study, participants used the services on both their PCs and mobile devices. Diaries and interviews were used for gathering users' experiences with the services. Based on our findings and reflection with related work, we argue that central elements of cross-platform service UX include fit for cross-contextual activities, flow of interactions and content, and perceived service coherence. We propose an initial conceptual framework of cross-platform user experience. The framework can be used to guide the design of cross-platform web services, as it draws attention to elements of user experience that are essentially influenced by the characteristics of cross-platform settings.	a/ux;desktop computer;field research;interaction;mobile device;personal computer;user experience;web application;web service	Minna Wäljas;Katarina Segerståhl;Kaisa Väänänen;Harri Oinas-Kukkonen	2010		10.1145/1851600.1851637	user interface design;web service;user experience design;mobile search;mobile web;web design;human–computer interaction;user journey;computer science;service delivery framework;ws-policy;mobile device;conceptual framework;multimedia;world wide web;field research	HCI	-57.02755315175931	-40.86621682632132	100654
45ce2cb7ca3d32a14621469ac78d17a488e9f6a0	actions speak louder than words: an exploration of game play behavior and results from traditional assessments of individual differences		In this paper, we describe the results of an exploratory pilot study examining the use of a video game as an assessment tool. This is part of a larger project aimed at identifying the components and mechanics of accurate and engaging assessment games. A critical step towards this goal is to understand what player behaviors might naturally be associated with traditionally measured human variables (e.g. cognitive and non-cognitive individual differences). We use the custom game, Food for Thought, and its in-game logging capabilities to examine relationships between different play behaviors, like planning and level retrying, with results from traditionally measured psychosocial, multitasking, and personality variables. In a sample of 30 undergraduate students, we found 10 statistically significant correlations between in-game player behavior and measures from traditional assessments (ACT Engage, SynWin, and the BFI-44). These preliminary results suggest promise in understanding human individual differences through the exploration of player behaviors.	cognition;computer multitasking;game mechanics;observable;polystation;virtual world	Laura M. Levy;Rob Solomon;Joann Moore;Jason Way;Ruitao Liu;Maribeth Gandy Coleman	2015			multimedia;computer science	HCI	-54.91426899894566	-50.12311273368902	100793
4713403bbd636f81cc73df458646ab0465129494	examining the frankenstein syndrome - an open-ended cross-cultural survey	humanoid robots;attitudes;survey;article	This paper reports findings from an open-ended survey on attitudes towards humanoid robots collected from samples in the United Kingdom and Japan. 335 participants were asked how they felt about humanoid robots becoming widespread in society and what tasks they wanted humanoid robots to perform. While the UK sample was overall less negative towards humanoid robots than their Japanese counterparts, the UK sample did not want robots to perform tasks that required capabilities deemed as human qualities, such as empathy, caring, or independent decision making.	frankenstein complex;humanoid robot;nonlinear gameplay	Dag Sverre Syrdal;Tatsuya Nomura;Hiroto Hirai;Kerstin Dautenhahn	2011		10.1007/978-3-642-25504-5_13	psychology;simulation;communication;social psychology	Robotics	-52.663955482682326	-51.288795477866394	100843
a1343f6f512dd0bbc4c5a61e7b63821628265a6a	trust, privacy and relationships in 'pervasive education': families' views on homework and technologies	mobile device;technology management;capture and access;information transfer;information and communication technology;ubiquitous computing;education research	Extensive educational research discusses the potential for information and communication technologies in supporting homework, but most has focused on providing content. The research in this paper focuses instead on the issues around managing homework and balancing home and school through the capabilities of ubiquitous technologies. As part of our requirements capture we presented three families with demonstrators of ubiquitous computing systems. Our technologies provoked reactions to situated and embedded information capture and access, and locational information capture through mobile devices. The subtlety and complexity of roles and relationships of different family members raised issues around trust and privacy in relation to children's homework practices. We consider how these drove acceptance of the technologies, and how the contrasts between family and educational relationships produced different requirements for technologies managing information transfer inside and outside the home. Overall, we highlight how respect for these concerns can inform the design of pervasive technologies, particularly within the domestic and educational contexts bridged.	pervasive informatics;privacy	Katie Fraser;Tom Rodden;Claire O'Malley	2007		10.1007/978-3-540-72037-9_11	information and communications technology;simulation;information transfer;human–computer interaction;telecommunications;computer science;knowledge management;technology management;operating system;mobile device;multimedia;computer security;ubiquitous computing	HCI	-58.76796211873713	-40.74441128632446	100926
33af18ee44e92e911f09e1c2bbb8da1c71380490	an experimental eye-tracking study for the design of a context-dependent social robot blinking model		Human gaze and blinking behaviours have been recently considered, to empower humanlike robots to convey a realistic behaviour in a social human-robot interaction. This paper reports the findings of our investigation on human eye-blinking behaviour in relation to human gaze behaviour, in a human-human interaction. These findings then can be used to design a humanlike eye-blinking model for a social humanlike robot. In an experimental eye-tracking study, we showed to 11 participants, a 7-minute video of social interactions of two people, and collected their eye-blinking and gaze behaviours with an eye-tracker. Analysing the collected data, we measured information such as participants’ blinking rate, maximum and minimum blinking duration, number of frequent (multiple) blinking, as well as the participants’ gaze directions on environment. The results revealed that participants’ blinking rate in a social interaction are qualitatively correlated to the gaze behaviour, as higher number of gaze shift increased the blinking rate. Based on the findings of this study, we can propose a context-dependent blinking model as an important component of the robot’s gaze control system that can empower our robot to mimic human blinking behaviour in a multiparty social interaction.	eye tracking;social robot	Abolfazl Zaraki;Maryam Banitalebi Dehkordi;Daniele Mazzei;Danilo De Rossi	2014		10.1007/978-3-319-09435-9_31	gaze;social robot;robot;social relation;human–computer interaction;eye tracking;psychology;gaze directions	Robotics	-51.723424238221796	-49.69837533376423	100980
d8dfd9f0ffb6771efe29cd67f6899359d648d2cf	mobile interaction with the real world: an evaluation and comparison of physical mobile interaction techniques	mobile device;object interaction;design and development;pointing;user preferences;comparison;physical mobile interaction;user mediated object interaction;evaluation;scanning;touching;smart environment;interaction technique;mobile interaction;qa76 computer software	Mobile devices are more and more used for mobile interactions with things, places and people in the real world. However, so far no studies have discussed which interaction techniques are preferred by users in different contexts. This paper presents an experimental comparison of four different physical mobile interaction techniques: touching, pointing, scanning and usermediated object interaction. To evaluate these techniques across different scenarios and to collect real usage data, four prototypes were implemented: a system for mobile interaction in smart environments, a mobile tourist guide, a mobile museum guide and a prototype for mobile interaction with advertisement posters. In each setting an experimental comparison was performed. Based on the results of these studies, which involved over 60 participants in total, advantages and disadvantages of these interaction techniques are described. Context-specific user preferences are presented for the interaction techniques, to help application designers and developers decide which interaction technique(s) to integrate into their application and which consequences this decision has.	interaction technique;mobile interaction;prototype;smart environment;usage data;user (computing)	Enrico Rukzio;Gregor Broll;Karin Bee;Albrecht Schmidt	2007		10.1007/978-3-540-76652-0_1	mobile search;simulation;interactive systems engineering;mobile interaction;human–computer interaction;computer science;evaluation;mobile device;multimedia;smart environment;mobile computing;interaction technique	HCI	-49.56043481468606	-40.84288628951337	101024
d5d8461065ece4c25f4f7bd97ff43f1a370ef94d	the automaticity of social behavior towards robots: the influence of cognitive load on interpersonal distance to approachable versus less approachable robots	human robot interaction;interpersonal distance;media equation;persuasive robotics;persuasive technology;social robotics	Social robots are designed to promote social responses by human users. Based on the Media Equation theory, we argue that the way in which people interact with technology resembles the way in which humans interact with other humans, and, crucially, that these social responses are mainly of an automatic nature. To investigate the automaticity of social behavior towards robots, the current study assessed a well-studied (in human-human interaction) social behavior: interpersonal distance people keep, though not from other humans but from a robot. Earlier research suggested that the social behavior of distance keeping depends (amongst others) on the bodily posture of the interaction partner. Based on these earlier studies, we expected that participants would keep an interpersonal distance dependent on the posture of their robotic interaction partner especially if a participant was responding in more automatic ways. We manipulated robot posture (approachable versus less approachable) and the cognitive load of the participant (high versus low), and measured user-robot approach distance in ten short interaction tasks. In line with expectations, results suggested that especially participants under high cognitive load approached the robot closer when its posture communicated approachableness than when it communicated less approachableness. Thereby, the current results suggested that especially when people are cognitively distracted, their behavior towards robots is of a social nature and comparable to their behavior when responding to other humans. Implications for theory, research and design of social robots are discussed.	robot	Jaap Ham;Mirjam van Esch;Yvonne Limpens;Jente de Pee;John-John Cabibihan;Shuzhi Sam Ge	2012		10.1007/978-3-642-34103-8_2	psychology;simulation;media lab europe's social robots;communication;social psychology	Robotics	-52.1202577443042	-50.700170472256175	101125
304915f5d70d897e7222da6d5ef95bd2f9bd6d1a	a personal perspective on photowork: implicit human–computer interaction for photo collection management	personal information management;photo collection organization;photowork;implicit human computer interaction	In the age of digital photography, the amount of photos we have in our personal collections has increased substantially along with the effort needed to manage these new, larger collections. This issue has already been addressed in various ways: from organization by meta-data analysis to image recognition and social network analysis. We introduce a new, more personal perspective on photowork that aims at understanding the user and his/her subjective relationship to the photos. It does so by means of implicit human–computer interaction, that is, by observing the user’s interaction with the photos. In order to study this interaction, we designed an experiment to see how people behave when manipulating photos on a tablet and how this implicitly conveyed information can be used to aid photo collection management.	computer vision;digital photography;human–computer interaction;social network analysis;tablet computer	Bojan Blazica;Daniel Vladusic;Dunja Mladenic	2013	Personal and Ubiquitous Computing	10.1007/s00779-013-0650-6	computer vision;human–computer interaction;computer science;personal information management;multimedia	HCI	-57.314255811196524	-40.45061033702672	101160
019b247f6dd8fa5d6288cf4a37bac19c61cf368a	how to manage affective state in child-robot tutoring interactions?		Social robots represent a fruitful enhancement of intelligent tutoring systems that can be used for one-to-one tutoring. The role of affective states during learning has so far only scarcely been considered in such systems, because it is unclear which cues should be tracked, how they should be interpreted, and how the system should react to them. Therefore, we conducted expert interviews with preschool teachers, and based on these results suggest a conceptual model for tracing and managing the affective state of preschool children during robot-child tutoring.	computation;computational model;influence diagram;information;interaction;one-to-one (data model);social robot	Thorsten Schodde;Laura Hoffmann;Stefan Kopp	2017	2017 International Conference on Companion Technology (ICCT)	10.1109/COMPANION.2017.8287073	conceptual model;social robot;human–computer interaction;affect (psychology);robot;psychology;tracing	Robotics	-55.68533315991762	-50.44630555224342	101253
51b4c28e7882493dea19a7747584992181650127	wearable systems for e-health and wellbeing		Wearable devices, such as smartwatches and fitness bands, are becoming a key element of our lives. They are used in an always increasing number of activities, for example during sport sessions for keeping track of energy expenditure, or when walking as unobtrusive pedestrian navigation systems. In general, these devices are worn continuously throughout the day and thus provide the opportunity to gather information about their users with unprecedented levels. In addition, many wearable devices are directly worn over the skin and they may include sensors not available on common smartphones (e.g., for monitoring the user’s heart rate). As a consequence, they are particularly suitable for those medical applications where continuous monitoring is fundamental. At the same time, the massive amount of information collected through these devices is enabling novel applications in the context of ehealth and wellbeing. Finally, it is known that abundance of information promotes an effective management of patients’ condition, and a well-informed patient is more likely to conduct a healthy lifestyle. This issue of Personal and Ubiquitous Computing collects recent, original research in the area of wearable systems for ehealth and wellbeing. Fourteen papers were initially submitted to this issue. After two rounds of review, four of them were finally accepted for publication. The first paper, BSleep behavior assessment via smartwatch and stigmergic receptive fields^, presents a method for automatic assessment of sleep quality using a smartwatch. Heartbeat rate and wrist motion samples are processed using computational stigmergy, a bio-inspired technique that relies on digital pheromone marks. The second paper, BSocial Recommendations for Personalized Fitness Assistance^, presents a novel framework—PRO-Fit—aimed at engaging users in fitness activities. The proposed framework minimizes the need for user input and proactively generates personalized fitness schedules. Collaborative filtering and social network information are exploited to automatically provide activities and fitness buddy recommendations. The third paper, BRobust Orientation Estimate via Inertial Guided Visual Sample Consensus^, presents a method for estimating the orientation of body joints using a wearable camera paired with an Inertial Measurement Unit (IMU). Visual information is used to correct the drift of the IMU, whereas information produced by the IMU enables more accurate and efficient image-based estimation. The last paper, BSVM-based classification method to identify alcohol consumption using ECG and PPG monitoring^, presents a method for detecting alcohol intoxication that is compatible with the requirements of wearable devices. Cardiac activity, observed through simple sensor configurations, is given as input to a classification system in charge of estimating the status of the user. Finally, as co-guest editors of this issue, we would like to thank all the authors for their contributions. * Alessio Vecchio alessio.vecchio@unipi.it	british informatics olympiad;collaborative filtering;personal and ubiquitous computing;personalization;recommender system;requirement;sensor;smartphone;smartwatch;social network;stigmergy;unobtrusive javascript;wearable computer;wearable technology	Guglielmo Cola;Alessio Vecchio	2017	Personal and Ubiquitous Computing	10.1007/s00779-017-1041-1	multimedia;human–computer interaction;computer science;wearable computer	HCI	-53.64738561073475	-42.527983009892075	101508
e6569b26604ca0cd96a4847abf381788c447e7b7	conversational interaction with multiple agents initiated via proxemics and gaze		This paper explores the use of proxemics and gaze in multimodal multiparty interaction in virtual reality (VR). While many applications with sophisticated implementations have been developed, we sought to create, using more lightweight tools, a multimodal multiparty application in which users had a strong sense of both autonomy and immersion. In conversations with virtual agents, true mixed-initiative interaction is difficult to achieve because initiative can include choice of topic. Our work suggests that using proxemics and gaze can enable multiparty conversations with virtual agents that more closely resemble mixed-initiative interaction.		David Novick;Laura J. Hinojos;A. Eduardo Rodriguez;Adriana Camacho;Mahdokht Afravi	2018		10.1145/3284432.3287185	implementation;social psychology;proxemics;computer science;gaze;immersion (virtual reality);human–computer interaction;virtual reality;autonomy	HCI	-52.562188243453015	-48.87753445335557	101808
88e3f74d6fec2ba89553abc0f6a844d06f91309b	public ubiquitous computing systems: lessons from the e-campus display deployments	e campus display;large scale networked display public ubiquitous computing system e campus display deployment lancaster university e campus project;project management;ubiquitous computing displays pervasive computing videos art probes large scale systems conferences mobile computing computer applications;pervasive computing;qa75 electronic computers computer science;large scale;educational administrative data processing;e campus display real world deployment;lessons learned;real world deployment;ubiquitous computing educational administrative data processing project management;public display;public space;ubiquitous computing	Lessons learned from building and deploying three experimental public display systems have general app to many types of public ubicomp deployments. Lancaster University's e-Campus project is exploring the creation of large-scale networked displays as part of a public, interactive pervasive computing environment. For the project, we built and deployed three experimental display systems that vary in technology, location, scale, and user community, and they've given us a rich set of experiences. We've summarized 13 lessons learned from this experience. The lessons certainly apply to researchers planning similar deployments. We also believe they will generalize to other public ubicomp installations. The e-Campus project is embarking on a major new set of deployments. We're using these lessons to help guide our work and we believe the lessons learned will be valuable to all researchers deploying ubicomp systems in public spaces	experience;ubiquitous computing;virtual community	Oliver Storz;Adrian Friday;Nigel Davies;Joe Finney;Corina Sas;Jennifer G. Sheridan	2006	IEEE Pervasive Computing	10.1109/MPRV.2006.56	context-aware pervasive systems;simulation;human–computer interaction;computer science;operating system;world wide web;ubiquitous computing	HCI	-60.23121710443402	-40.887848028115684	101891
4b1c6e55ae86502993866a6684470f7d6af8f70e	grumpy & pinocchio: answering human-agent negotiation questions through realistic agent design		We present the Interactive Arbitration Guide Online (IAGO) platform, a tool for designing human-aware agents for use in negotiation. Current state-of-the-art research platforms are ideally suited for agent-agent interaction. While helpful, these often fail to address the reality of human negotiation, which involves irrational actors, natural language, and deception. To illustrate the strengths of the IAGO platform, the authors describe four agents which are designed to showcase the key design features of the system. We go on to show how these agents might be used to answer core questions in human-centered computing, by reproducing classical human-human negotiation results in a 2x2 human-agent study. The study presents results largely in line with expectations of human-human negotiation outcomes, and helps to demonstrate the validity and usefulness of the IAGO platform.	aggregate data;computation;human-centered computing;humans;intelligent agent;interactivity;natural language	Johnathan Mell;Jonathan Gratch	2017			computer science;deception;natural language;negotiation;iago;knowledge management;arbitration	AI	-54.711172770162435	-47.42923911276952	101893
60fa787888270060465b6df638770eff40f5d34f	integration of multimodal interaction as assistance in virtual environments	language learning;speech input;multimodal interaction;information access;experiential study;far user;integration mechanism;virtual environment	This paper discusses the significance of the multimodal interaction in virtual environments (VE) and the criticalities involved in integration and coordination between modes during interaction. Also, we present an architecture and design of the integration mechanism with respect to information access in second language learning. In this connection, we have conducted an experiential study on speech inputs to understand how far users’ experience of information can be considered to be supportive to this architecture.	information access;multimodal interaction;virtual reality	Kiran Pala;Ram Naresh;Sachin Joshi;Suryakanth V. Gangashetty	2012			human–computer interaction;engineering;multimedia;communication	HCI	-53.00232505595392	-39.93081611995491	101902
815fbb8947bfa2b4af8cfac15403b4432f6dea65	ontology-based user modeling in an augmented audio reality system for museums	audio augmented reality;user evaluation;context aware;human computer interaction;user evaluations;semantic technologies;mobile computer;testing;tangible user interface;user modeling;recommender system;adaptive system;user testing;ubiquitous computing;ontologies;augmented reality;museum guide;user model;support function;experience design;knowledge base	Ubiquitous computing is a challenging area that allows us to further our understanding and techniques of context-aware and adaptive systems. Among the challenges is the general problem of capturing the larger context in interaction from the perspective of user modeling and human–computer interaction (HCI). The imperative to address this issue is great considering the emergence of ubiquitous and mobile computing environments. This paper provides an account of our addressing the specific problem of supporting functionality as well as the experience design issues related to museum visits through user modeling in combination with an audio augmented reality and tangible user interface system. This paper details our deployment and evaluation of ec(h)o – an augmented audio reality system for museums. We explore the possibility of supporting a context-aware adaptive system by linking environment, interaction objects and users at an abstract semantic level instead of at the content level. From the user modeling perspective ec(h)o is a knowledge-based recommender system. In this paper we present our findings from user testing and how our approach works well with an audio and tangible user interface within a ubiquitous computing system. We conclude by showing where further research is needed.	adaptive system;augmented reality;emergence;experience design;human–computer interaction;imperative programming;knowledge-based recommender system;mobile computing;modeling perspective;software deployment;tangible user interface;ubiquitous computing;usability testing;user modeling	Marek Hatala;Ron Wakkary	2005	User Modeling and User-Adapted Interaction	10.1007/s11257-005-2304-5	user;augmented reality;knowledge base;user modeling;human–computer interaction;computer science;artificial intelligence;adaptive system;multimedia;world wide web;ubiquitous computing;recommender system	HCI	-53.485135666165256	-38.35604015175408	101943
282c7e58f5ba2a98d7eda2b29eacf23ad6450d85	mobile cloud storage: a contextual experience	mobile;context aware;social sciences;quality;quality of experience qoe;cloud storage services	"""In an increasingly connected world, users access personal or shared data, stored """"in the cloud"""" (e.g., Dropbox, Skydrive, iCloud) with multiple devices. Despite the popularity of cloud storage services, little work has focused on investigating cloud storage users' Quality of Experience (QoE), in particular on mobile devices. Moreover, it is not clear how users' context might affect QoE. We conducted an online survey with 349 cloud service users to gain insight into their usage and affordances. In a 2-week follow-up study, we monitored mobile cloud service usage on tablets and smartphones, in real-time using a mobile-based Experience Sampling Method (ESM) questionnaire. We collected 156 responses on in-situ context of use for Dropbox on mobile devices. We provide insights for future QoE-aware cloud services by highlighting the most important mobile contextual factors (e.g., connectivity, location, social, device), and how they affect users' experiences while using such services on their mobile devices."""	academy;dropbox;experience;gibbs sampling;mobile cloud computing;mobile cloud storage;mobile device;multi-user;onedrive.com;real-time clock;smartphone;tablet computer;icloud	Karel Vandenbroucke;Denzil Ferreira;Jorge Gonçalves;Vassilis Kostakos;Katrien De Moor	2014		10.1145/2628363.2628386	mobile search;computer science;operating system;mobile technology;multimedia;internet privacy;mobile computing;world wide web	HCI	-57.939528199798744	-44.14493905972179	102056
1c952dcb556f0917aaa26fad8084a87a19296dae	encountering sensecam: personal recording technologies in everyday life	experience sampling;north american;sensecam;primary user;paratyping;privacy;everyday life	In this paper, we present a study of responses to the idea of being recorded by a ubicomp recording technology called SenseCam. This study focused on real-life situations in two North American and two European locations. We present the findings of this study and their implications, specifically how those who might be recorded perceive and react to SenseCam. We describe what system parameters, social processes, and policies are required to meet the needs of both the primary users and these secondary stakeholders and how being situated within a particular locale can influence responses. Our results indicate that people would tolerate potential incursions from SenseCam for particular purposes. Furthermore, they would typically prefer to be informed about and to consent to recording as well as to grant permission before any data is shared. These preferences, however, are unlikely to instigate a request for deletion or other action on their part. These results inform future design of recording technologies like SenseCam and provide a broader understanding of how ubicomp technologies might be taken up across different cultural and political regions.	microsoft sensecam;real life;situated;ubiquitous computing	David H. Nguyen;Gabriela Marcu;Gillian R. Hayes;Khai N. Truong;James M Scott;Marc Langheinrich;Christof Roduner	2009		10.1145/1620545.1620571	simulation;human–computer interaction;computer science;experience sampling method;privacy;computer security	HCI	-57.733365814891	-41.99328991515125	102077
8fd4d09d8a5a31aeba33bd562306a6ea6700f432	from personal memories to sharable memories	interpersonal communication;shared memory;workshop	The exchange of personal experiences is a way of supporting decision making and interpersonal communication. In this article, we discuss how augmented personal memories could be exploited in order to support such a sharing. We start with a brief summary of a system implementing an augmented memory for a single user. Then, we exploit results from interviews to define an example scenario involving sharable memories. This scenario serves as background for a discussion of various questions related to sharing memoriesand potential approaches to their solution. We especially focus on the selection of relevant experiences and sharing partners, sharing methods, and the configuration of those sharing methods by means of reflection.	context-sensitive help;field research;iteration;usability testing	Nathalie Basselin;Alexander Kröner	2006			human–computer interaction;computer science;distributed computing;communication	HCI	-57.498999536413784	-40.41951511168045	102261
644abb16520725383946202f0ed44e3a50fbe203	designing on-site: facilitating participatory contextual architecture with mobile phones	architecture;context;mobile devices;field study	Some movements within modern architecture particularly emphasise the importance of matching buildings to their surroundings. However, practicing such ‘‘contextual architecture’’ is highly challenging and typically not something the future inhabitants of a building are well equipped for participating in. This paper explores the potentials of using mobile phone technology for facilitating such client participation in the parts of an architecture process that take place on the building site. For this we introduce ArchiLens, a mobile system for interactive on-site 3D visualisation of houses, and findings from a field study with 40 participants in the process of building or modifying their home. The study showed that using the system helped evoke people’s imagination of the look and feel of their future house, and envision it in context. This enabled them to participatemore closely in the design process on-site by iteratively reviewing design alternatives and exploring, for example, other placements and materials. © 2012 Elsevier B.V. All rights reserved.	ar (unix);emergence;field research;graphics;interaction;interactive visualization;interactivity;look and feel;mobile phone;noise shaping;orientation (graph theory);tablet computer;topography;user experience;visualization (graphics)	Mikael B. Skov;Jesper Kjeldskov;Jeni Paay;Niels Husted;Jacob Nørskov;Kenneth Pedersen	2013	Pervasive and Mobile Computing	10.1016/j.pmcj.2012.05.004	embedded system;simulation;human–computer interaction;computer science;architecture;operating system;multimedia;computer security;field research	HCI	-56.0148605979669	-38.85411617933491	102289
c280b36816b779a58ec75b4be906f71601152690	thinking, feeling, and worrying: how uncertainty and anticipatory anxiety affect technology use				Chun-Lung Huang;Mark Srite;Peter Haried	2017			anticipatory anxiety;computer science;feeling;social psychology	HCI	-55.537518395754425	-51.95416335097095	102334
73c61df8c4ce4110721ef1aae2c4c10d554ed8aa	an accessible media player as a user agent for the web	user agent;web pages;mobility;web accessibility;visual interaction;non visual interaction;usability;web development	This paper presents  webLection ,a tool that aims at increasing the uptake of the Web by a variety of potential users. With  WebLection Web content is locally rendered into standard audio formats, and, ultimately, manipulated just like music employing the  playing list behaviour as an intuitive interaction metaphor. Although  webLection originates from research for blind Web users, significant benefits emerge for other types users too, including Web developers, since it can be used, on the one hand, to easily transform and make Web content available through its audio equivalent, and on the other hand to inspect the accessibility and usability of Web pages for users of screen readers.	user agent;world wide web	Alexandros Mourouzis;Nikolaos Partarakis;Constantina Doulgeraki;C. Galanakis;Constantine Stephanidis	2008		10.1007/978-3-540-70540-6_68	web service;web application security;static web page;web development;web modeling;framing;web analytics;web mapping;web design;human–computer interaction;web accessibility initiative;web standards;computer science;web navigation;social semantic web;web page;semantic web stack;multimedia;web 2.0;world wide web;web server;mashup	AI	-50.11435818321055	-39.981972577024436	102339
70094c4695387212addad1f8baa5139f8556ca3c	advances in meeting recognition	high-quality recording;speech recognition;recognition event;meeting recognition;recognition application;c	Speech recognition has advanced considerably, but has been limited almost entirely either to situations in which close speaking microphones are natural and acceptable (telephone, dictation, command&control, etc.) or in which high-quality recordings are ensured. Furthermore, most recognition applications involve controlled recording environments, in which the user turns the recognition event on and off and speaks cooperatively for the purpose of being recognized. Unfortunately, the majority of situations in which humans speak with each other fall outside of these limitations. When we meet with others, we speak without turning on or off equipment, or we don’t require precise positioning vis a vis the listener. Recognition of speech during human encounters, or “meeting recognition”, therefore represents the ultimate frontier for speech recognition, as it forces robustness, knowledge of context, and integration in an environment and/or human experience.	humans;microphone;precise point positioning;speech recognition;visual instruction set	Alexander H. Waibel;Hua Yu;Tanja Schultz;Yue Pan;Michael Bett;Martin Westphal;Hagen Soltau;Thomas Schaaf;Florian Metze	2001			speaker recognition;speech recognition;engineering;multimedia;communication	HCI	-50.6754368458197	-44.01662314238353	102376
8357b178c5b385f148c9b0e955d0f8d8ad0a5e0e	the design of a mobile portion size estimation interface for a low literacy population	shape;biomedical research;interface design;mobile computing;cognition;solids;estimation;bioinformatics	Being aware of one's portion sizes is a key component of maintaining a healthy diet, however, it is difficult for individuals especially low literacy populations to estimate their consumption. Nutritional monitoring applications can help but most of them are designed for people with high literacy and numeracy skills. In this paper, we designed and evaluated six portion size estimation interfaces through a Wizard of Oz based experiment using low-fidelity prototypes with ten varying literacy individuals. The interfaces were designed based on the cognitive strategies adults use for reporting portion sizes in diet recall studies. Participants made correct estimates with interfaces designed for liquid and amorphous foods, but had difficulties with those designed for solid foods. Based on these findings, we provide recommendations for designing accurate and low literacy-accessible portion size estimating mobile interfaces.	estimated;food;healthy diet;interface device component;population;portion size;precision and recall;wizard (software)	Beenish Chaudry;Kay Connelly;Katie A. Siek;Janet L. Welch	2011	2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops		embedded system;estimation;simulation;cognition;human–computer interaction;telecommunications;shape;computer science;artificial intelligence;interface design;operating system;solid;multimedia;mobile computing;statistics	HCI	-57.33555026906552	-45.14162908557647	102429
7322b3280a23ad83f2add8c3aa032481783f1191	a paper-digital interface for information capture and display in time-critical medical work	healthcare;situation awareness;pediatrics;paediatrics;fluids;health care	We conducted a study in a pediatric trauma center to elicit design requirements for the TraumaPen system-a mixed paper-digital interface using a digital pen and a wall display-to support situation awareness during trauma resuscitation. In this paper, we describe the field research that informed the initial system prototype and then present findings from two studies in which the prototype was used to further explore the application area. Our results showed the potential for digital pen technology in supporting teamwork in the dynamic and safety-critical setting of the trauma bay, but also revealed several limitations of this technology. We conclude by discussing challenges and requirements for the use of paper-digital interfaces in assisting fast-paced, collaborative work processes.	digital pen;field research;information capture;prototype;requirement;window of opportunity	Aleksandra Sarcevic;Nadir Weibel;James D. Hollan;Randall S. Burd	2012	2012 6th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops		embedded system;situation awareness;simulation;human–computer interaction;computer security;health care	HCI	-61.640385261050206	-51.311617041344746	102454
ebc68ed309896a92c29f688a6de3735a2586d588	survey-based discussions on morally contentious applications of interactive robotics	roboethics;survey;military robots;eldercare robots;social robotics	Introduction: As applications of robotics extend to areas that directly impact human life, such as the military and eldercare, the deployment of autonomous and semi-autonomous robots increasingly requires the input of stakeholder opinions. Up to now, technological deployment has been relying on the guidance of government/military policy and the healthcare system without specific incorporation of professional and lay opinion. Methods: This paper presents results from a roboethics study that uses the unique “N-Reasons” scenario-based survey instrument. The instrument collected “Yes, No, Neutral” responses from more than 250 responders via the Internet along with their ethics-content reasons for the answers, allowing the respondents to agree to previously-provided reasons or to write their own. Data from three questions relating to military and eldercare robots are analyzed qualitatively and quantitatively. Results: The survey reveals that respondents weigh the appropriateness of robotics technology deployment in concert with the level of auThis work is supported by the Natural Sciences and Engineering Research Council of Canada. The Roboethics Survey was funded by Genome Canada through the offices of Genome British Columbia. A. Moon · H.F.M. Van der Loos CARIS Lab, Institute for Computing, Information and Cognitive Systems (ICICS), Department of Mechanical Engineering, University of British Columbia, 6250 Applied Science Lane, Vancouver, B.C., V6T 1Z4, Canada Tel.: +1-604-822-3147, Fax: +1-604-822-2403 E-mail: ajung@amoon.ca, vdl@mech.ubc.ca P. Danielson The W. Maurice Young Centre for Applied Ethics, University of British Columbia, 227-6356 Agricultural Road, Vancouver, B.C., V6T 1Z2, Canada Tel.: +1-604-822-8625, Fax: +1-604-822-8627 E-mail: pad@ethics.ubc.ca tonomy conferred upon it. The accepted level of robot autonomy does not appear to be solely dependent on the perceived efficiency and effectiveness of the technology, but is subject to the robot’s relationship with the public’s principle-based reasons and the application field in focus. Conclusion: the N-Reasons instrument was effective in eliciting ethical commentary in a simple, on-line survey format and provides insights into the interactions between the issues that respondents consider across application and technology boundaries.	autonomous robot;autonomy;columbia (supercomputer);display resolution;fax;futures studies;humans;human–robot interaction;interactivity;internet;like button;military robot;norm (social);online and offline;rejection sampling;remote control;robotics;screenshot;semiconductor industry;software deployment	AJung Moon;Peter Danielson;H. F. Machiel Van der Loos	2012	I. J. Social Robotics	10.1007/s12369-011-0120-0	simulation;artificial intelligence;management science	HCI	-53.17556822055949	-51.978684576547224	102459
2e5e596511c1089316b50c911dd9051195c1e430	enhancing input device evaluation: longitudinal approaches	pointing device;input device;longitudinal study;evaluation method;laser pointer;evaluation;inproceedings;retention task;longitudinal data;transfer task	In this paper we present our experiences with longitudinal study designs for input device evaluation. In this domain, analyzing learning is currently the main reason for applying longitudinal designs. We will shortly discuss related research questions and outline two case studies in which we used different approaches to address this issue. Finally, we will point out future research tasks in the context of longitudinal evaluation methods.	input device	Jens Gerken;Hans-Joachim Bieg;Stefan Dierdorf;Harald Reiterer	2009		10.1145/1520340.1520665	real-time computing;simulation;human–computer interaction;computer science;evaluation;operating system;cross-sequential study;input device;pointing device	HCI	-62.04807415625137	-47.09568457133618	102606
1522f7812b2c7c183abcabe8e7f6710e048b3d8e	a social robot as a card game player		This paper describes a social robotic game player that is able to successfully play a team card game called Sueca. The question we will address in this paper is: how can we build a social robot player that is able to balance its ability to play the card game with natural and social behaviours towards its partner and its opponents. The first challenge we faced concerned the development of a competent artificial player for a hidden information game, whose time constraint is the average human decision time. To accomplish this requirement, the Perfect Information Monte-Carlo (PIMC) algorithm was used. Further, we have performed an analysis of this algorithm’s possible parametrizations for games trees that cannot be fully explored in a reasonable amount of time with a MinMax search. Additionally, given the nature of the Sueca game, such robotic player must master the social interactions both as a partner and as an opponent. To do that, an emotional agent framework (FAtiMA) was used to build the emotional and social behaviours of the robot. At each moment, the robot not only plays competitively but also appraises the situation and responds emotionally in a natural manner. To test the approach, we conducted a user study and compared the levels of trust participants attributed to the robots and to human partners. Results have shown that the robot team exhibited a winning rate of 60%. Concerning the social aspects, the results also showed that human players increased their trust in the robot as their game partners (similar to the way to the trust levels change towards human partners). As interactive entertainment expands, computer games are progressively moving from the virtual world back to the physical world. Augmented reality games, haptic interfaces in gaming, touch tables, etc, are some of the types of interactivity placing human players in physically situated entertainment experiences. In parallel with this move into the physical world, artificial partners and opponents can also be created to exist in such physical world. To do that, the area of entertainment robots offers challenging opportunities as it explores the role of a robot as a game player. In general, social robots can contribute with new and broad ways of creating socially engaging interactions with humans in entertainment contexts. The challenges of these human-robot interactions may vary from game to game. Some games, when played in the physical world not only hold complex social Copyright c ⃝ 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. behaviours, but they also hinder performance aspects related with the competitive nature of the game itself. Furthermore, in many types of games, current advances in Artificial Intelligence (AI) over the past few years has shown that strong and powerful algorithms combined with significant amounts of data, are able to defeat human world champions of these games (see for example, the game of Go). These results raise our expectations and people are starting to consider such artificial agents as fierce competitors. Yet, when we consider multi-player games, where the social environment becomes more relevant, and when the games are played in the physical world, how will people perceive a social robotic player compared to human standards? Will people be willing to trust a social robot to be his partner in a team game? To address these questions we created a social autonomous robotic partner for the Sueca card game, with a twofold goal of both playing competitively and interacting socially with the other players. The development of such robotic game player introduces some challenging aspects, in particular finding the best balance between social responses and computations related with the game, in order for the socially intelligent agent to produce natural and human-like behaviours. Another important challenge of creating an intelligent agent in this social context is the time constraint on the computation of a hidden information card game. State-of-the-art approaches, for instance PIMC, promise good results on the Sueca domain according to the game properties. However, the full computation of multiple perfect information games is not time-efficient and will hinder natural interaction in a game with human players. Therefore, this paper also explores how the algorithm’s parametrizations affect the game results in order to choose the best performance-time configuration. Finally, by using an expressive robot that is able to express emotions, provide spoken feedback, and respond socially, the game experience can be created balancing these social and game competencies. In this case, we built the social competencies by using an emotional agent framework (FatiMA) which allows for emotional appraisal to occur and fire social and emotional behaviours. At each moment, the robot not only plays competitively, but also appraises the situation and responds emotionally to the game situations. Proceedings, The Thirteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE-17)	algorithm;artificial intelligence;augmented reality;autonomous robot;experience;human–robot interaction;information card;intelligent agent;interactivity;international symposium on fundamentals of computation theory;minimax;multi-touch;pc game;polystation;requirement;run time (program lifecycle phase);situated;social robot;usability testing;video game developer;virtual world	Filipa Correia;Patrícia Alves-Oliveira;Tiago Ribeiro;Francisco S. Melo;Ana Paiva	2017			social robot;multimedia;simulation;non-cooperative game;video game design;computer science;simultaneous game;strategy;game design	AI	-54.856934693025984	-47.456746569823196	102630
c04c16c8d3cf6dcbb15432794fe8af83356b594a	towards an analysis framework of technology habituation by older users	rituals;positive ageing;smart;acceptance;appropriation;kettle;routines;analysis;adoption;habituation;older users;messaging;framework;things	Smart everyday objects could support the wellbeing, independent living and social connectedness of ageing people, but their successful adoption depends upon them fitting with their skills, values and goals. Many technologies fail in this respect. Our work is aimed at designs that engage older people by building on their individual affective attachment to habituated objects and leveraging, from a participatory design perspective, the creative process through which people continuously adapt their homes and tools to their own lifestyle. We contribute a novel analytic framework based on an analysis of related research on appropriation and habituated objects. It identifies steps in appropriation from inspection to performance and habituation. We test this framework with the preliminary testing of an augmented habituated object, a messaging kettle. While only used in one home so far, its daily use has provoked many thoughts, scenarios and projections about use by friends, both practical, utopian and dystopian.	attachments	Alessandro Soro;Margot Brereton;Paul Roe	2016		10.1145/2901790.2901806	message;computer science;software framework;kettle;analysis;smart criteria;management;habituation	HCI	-58.64385819410689	-42.92120416779174	102733
7be45755f9d6705ee23da2f7df52e590fae0ba35	txteagle: mobile crowdsourcing	service provider;user study;appropriate technology;mobile phone;high school student;mobile phones;reputation systems;crowdsourcing	We present txteagle, a system that enables people to earn small amounts of money by completing simple tasks on their mobile phone for corporations who pay them in either airtime or MPESA (mobile money). The system is currently being launched in Kenya and Rwanda in collaboration with the mobile phone service providers Safaricom and MTN Rwanda. Tasks include translation, transcription, and surveys. User studies in Nairobi involving high school students, taxi drivers, and local security guards have been completed and the service has recently launched in Kenya nationwide.	airtime;crowdsourcing;mobile payment;mobile phone;peer-to-peer;real-time web;software deployment;transcription (software);usability testing	Nathan Eagle	2009		10.1007/978-3-642-02767-3_50	mobile web;gsm services;engineering;advertising;internet privacy;computer security;mobile payment	HCI	-55.08284235997996	-40.4332670612896	102737
a81ed951e5c0e2e10857234842a368cab671cf97	implementation of a 3-dimensional game for developing balanced brainwave	biology computing;right cerebral hemisphere analysis;human computer interaction;brain computer interfaces human computer interaction scalp communication system control pervasive computing computer interfaces pattern recognition electroencephalography software engineering conference management;real time;brain wave data 3d game balanced brain wave computer interaction human computer interaction pattern recognition brain wave research left cerebral hemisphere analysis right cerebral hemisphere analysis;user interfaces biology computing brain models computer games human computer interaction;brain models;null;satisfiability;left cerebral hemisphere analysis;balanced brain wave computer interaction;pattern recognition;3d game;3 dimensional;computer games;brain wave research;brain wave data;user interfaces;human computer interface	In a ubiquitous condition, HCI (human computer interaction) is popularly used to meet users' needs for high quality service. In a condition with HCI, there are a lot of interfaces that are used to satisfy the needs of the users. As a result of these changes, various types of effective human computer interface methods have been developed. In many studies, researchers have focused on using brain-wave interface, BCI (brain-wave computer interaction). BCI is one of the research areas in HCI. Nowadays, studies which are related to BCI are under way to find effective methods of controlling and collecting brain-wave. Most researches related to BCI are not centralized and not systematic. BCI research uses brain wave which is gathered from the subjects' scalp. The brain wave is affected easily in an experimental condition. Moreover, subjects do not control their brain well when they attend the research. These problems bring about ineffective results research. In most research to related in HCI and BCI, that is to say - pattern recognition, the most important foundation of the research is to set a standard about subjects' mindset and attitude in research. For this factor, in this paper, we propose the implementation of a 3-dimensional game for developing balanced brain wave. Apart from other kinds of pattern recognition, in BCI, it is difficult to gather the specific brain wave researchers want. Researchers do not know effective methods for gathering the brain wave they want. Subjects also do not know how to release the brain wave researchers expect. To solve these kinds of problems, we propose a novel game for developing balanced brain wave. The game works by balancing the power of the brain-wave values from the left cerebral hemisphere and right cerebral hemisphere. Subjects look at a computer screen. On the screen, there is a game which is made by our proposed algorithm. In real time, subjects are able to observe gathered brain wave data and therefore teach themselves to produce the appropriate brain wave. To verify the effectiveness of our proposed system, we analyzed the difference of brain wave gathered form the left and right cerebral hemisphere. On the basis of the balanced left and right cerebral hemisphere analysis, we propose the Implementation of a 3-dimensional game for stably developing balanced brain-wave.	algorithm;brain–computer interface;centralized computing;computer monitor;display resolution;human computer;human–computer interaction;neural oscillation;pattern recognition;quality of service;real-time computing	Beom-Soo Shim;Sung-Wook Lee;Jeong-Hoon Shin	2007	5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007)	10.1109/SERA.2007.94	three-dimensional space;simulation;human–computer interaction;computer science;artificial intelligence;user interface;satisfiability	HCI	-50.74654597810096	-45.71843215408173	102957
5173421306b8702149834522774e42cbec892753	visualization of complex health data on mobile devices	visualization;health data;mobile devices	"""As we track and collect more and more personal health data using multimedia devices and systems, it is getting more and more complex to visualize our health data. This is further challenged as the mobile phone, in spite of its limited screen size and interaction possibilities, is for many persons the main tool for accessing and reviewing their data. We therefore examined how complex and heterogeneous health data can be visualized on mobile phones. We found two different visualization needs: """"My health, now"""" gives objective feedback about my current health status, at a glance covering the last 72 hours, and in details on demand for the last 7 days. The visualization of """"my health, in the past"""" is needed for reflection and analysis and covers the last up to 6 months. Our findings complement existing analyses of user interaction with self-tracking systems and provide suggestions for future research on visualization of health data."""	display size;mobile phone;tracking system	Jochen Meyer;Anastasia Kazakova;Merlin Büsing;Susanne Boll	2016		10.1145/2985766.2985774	simulation;human–computer interaction;engineering;multimedia	HCI	-55.384630206017384	-42.418567775944545	103184
0c321c3c7a7f8e96f2b14498147eb907bb3cec54	toinggg: how changes in children's activity level influence creativity in open-ended play	creativity;design research;physical play;open ended play	This paper describes an explorative study with an open-ended play environment called Toinggg that consists of three interactive trampolines and was developed for children aged 6-8 years old. Toinggg was used to evaluate the change of children’s activity level on creativity in open-ended play. With this exploration, we aim to gain a better understanding of the balance between physical activity and creativity in play. In a user evaluation twenty-one children played in groups of three with Toinggg. Results show an increase in development of new game play and creativity after a moment of rest concerning the activity level of the interaction behavior.	nonlinear gameplay	Bas van Hoeve;Linda De Valk;Mathilde M. Bekker	2013		10.1007/978-3-319-03161-3_72	psychology;simulation;communication;social psychology	HCI	-55.98372284767904	-48.56597888478959	103279
d0a14f014d938ec1225c306003135eaad0047c84	assessing the communicability of human- data interaction mechanisms in transparency enhancing tools		The growing practice of accumulating personal data to generate predictions about users, leverages the need for mechanisms that allow people a more effective control of their data. An emerging field of studies called Human-Data Interaction (HDI), proposes the inclusion of human at the center of the data flow, providing mechanisms for citizens to interact explicitly with the collected data. Researches in HDI have discussed ways to offer Transparency Enhancing Tools (TETs), i.e., tools that support people on HDI issues related to privacy and personal data protection. Many works conducted about TETs focuses on usability issues, exploring aspects such as efficiency, user satisfaction and ease of learning. In this work, on the other hand, we aim to assess the communicability of HDI mechanisms in TETs. Hence, we applied the Semiotic Inspection Method (SIM) to investigate if and how HDI concepts are applied in two different TETs used for personal data management. We triangulated results from the study with findings from another investigation about communicability issues carried out in the same domain, but by observing and interviewing users.	adobe creative suite;algorithm;dataflow;human–computer interaction;information privacy;partial application;personal information management;personally identifiable information;semiotic engineering;semiotics;usability;vii	Patrick Santos;Luciana Salgado;José Viterbo Filho	2018	2018 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2018F174	data mining;management science;data management;usability;transparency (graphic);computer science;data protection act 1998;interview;data flow diagram	HCI	-61.56553295182951	-44.725185273990554	103307
2e4749d32579df46cf168e5245c28b21d3e3fc85	multisense—context-aware nonverbal behavior analysis framework: a psychological distress use case	real time systems synchronization computer architecture pipelines psychology affective computing context;psychology;computer architecture;synchronization;pipelines;framework for multimodal behavioral understanding multisense system for affective computing behavior quantification automatic distress assessment;context;affective computing;real time systems	During face-to-face interactions, people naturally integrate nonverbal behaviors such as facial expressions and body postures as part of the conversation to infer the communicative intent or emotional state of their interlocutor. The interpretation of these nonverbal behaviors will often be contextualized by interactional cues such as the previous spoken question, the general discussion topic or the physical environment. A critical step in creating computers able to understand or participate in this type of social face-to-face interactions is to develop a computational platform to synchronously recognize nonverbal behaviors as part of the interactional context. In this platform, information for the acoustic and visual modalities should be carefully synchronized and rapidly processed. At the same time, contextual and interactional cues should be remembered and integrated to better interpret nonverbal (and verbal) behaviors. In this article, we introduce a real-time computational framework, MultiSense, which offers flexible and efficient synchronization approaches for context-based nonverbal behavior analysis. MultiSense is designed to utilize interactional cues from both interlocutors (e.g., from the computer and the human participant) and integrate this contextual information when interpreting nonverbal behaviors. MultiSense can also assimilate behaviors over a full interaction and summarize the observed affective states of the user. We demonstrate the capabilities of the new framework with a concrete use case from the mental health domain where MultiSense is used as part of a decision support tool to assess indicators of psychological distress such as depression and post-traumatic stress disorder (PTSD). In this scenario, MultiSense not only infers psychological distress indicators from nonverbal behaviors but also broadcasts the user state in real-time to a virtual agent (i.e., a digital interviewer) designed to conduct semi-structured interviews with human participants. Our experiments show the added value of our multimodal synchronization approaches and also demonstrate the importance of MultiSense contextual interpretation when inferring distress indicators.	acoustic cryptanalysis;affective computing;computer;decision support system;depth perception;distress (novel);experiment;interactional linguistics;inventory;multimodal interaction;real-time clock;real-time transcription;semiconductor industry	Giota Stratou;Louis-Philippe Morency	2017	IEEE Transactions on Affective Computing	10.1109/TAFFC.2016.2614300	psychology;synchronization;computer vision;developmental psychology;computer science;artificial intelligence;affective computing;pipeline transport;communication;social psychology	HCI	-52.233559142342074	-47.53852132777951	103309
466c1eb2a241e9690a83d68989dad3c090a5c060	mobile search: the future	mobile;phone;handheld;mobile phone;search;user experience;usability	This panel covers mobile search: what does the future have in store for us? What about marketing and advertising---how will that impact the user experience? What about voice search? Do we have to all get QWERTY (or Asian language equivalent) keypads, or will the 12-digit keypad be enough?	user experience	Scott Weiss	2007		10.1145/1377999.1378044	user experience design;mobile search;mobile web;usability;human–computer interaction;gsm services;computer science;operating system;mobile technology;mobile device;multimedia;internet privacy;world wide web	OS	-51.988560012801805	-39.95160396274951	103332
00d8b7a03d5e0c6c56e1ff730b223fd220c9b256	modeling empathy for a virtual human: how, when and to what extent? (extended abstract)		Going along the questions of how, when and to what extent does empathy arise in humans, we propose an approach to model empathy for EMMA – an Empathic MultiModal Agent – based on three processing steps: First, the Empathy Mechanism by which an empathic emotion is produced. Second, the Empathy Modulation by which the empathic emotion is modulated. Third, the Expression of Empathy by which EMMA’s modulated empathic emotion is expressed through her multiple modalities. The proposed model is integrated in a conversational agent scenario involving the virtual humans MAX and EMMA.	dialog system;emma;max;modulation;virtual actor	Hana Boukricha;Ipke Wachsmuth	2011			simulation theory of empathy	NLP	-53.28670930147856	-48.750978662355685	103575
8bd9872e6e5f5193cb73f7e8fd15ffe654dc12c2	every user his visualization? user performance and preferences of different hierarchical layouts	users;information visualization;usability;hierarchical technique	Lately, more studies have started to look into adapting information visualization to individual users. This paper adds to those studies by analysing whether gender, field of study, and experience influenced user performance and preference in four different hierarchical layouts. The results show that, generally, the three factors did not show significant differences between layouts, but also revealed some interesting indications for further studies.		Tanja Mercun;Maja Zumer	2013		10.1007/978-3-319-03599-4_26	information visualization;usability;human–computer interaction;computer science;multimedia;world wide web	HCI	-59.26683524141093	-46.84179678709964	103767
6c1c864d2ec7c2061b422963c0a6fd59dc57de80	model of augmented reality and pedestrian navigation about the territorial heritage: design, implementation and evaluation	mobile pedestrian navigation;mobile learning;territorial heritage;augmented reality	This research aims to establish the generation and educational effectiveness of a digital learning module, linked to the implementation of Pedestrian Navigation System characteristics and Augmented Reality (AR-PNS), developing training processes linked to spatial information about the historical heritage and cultural, corresponding to the cities of Salamanca (Spain) and Santiago (Chile). The research focuses on two main areas: the first is the design and development of a PNS-AR platform, defining the architecture, functionality, interface and implementation; in a second stage of empirical testing modes, understanding and effectiveness of PNS-AR model created in a context of territorial Situated Learning will develop cultural heritage. Finally, the expected results are building flexible software in a mobile environment that allows the presentation of content on the historical heritage and the determination of its effectiveness in the context of situated learning and mobile.	ar (unix);augmented reality;autoregressive model;situated	Jorge Joo Nagata;José Rafael García-Bermejo Giner	2014		10.1145/2669711.2669966	simulation;human–computer interaction;geography;multimedia	HCI	-50.50904580903204	-39.29671974463553	103838
2871f700442df4382b311fbcd48f5c5ba9136082	mobile re-finding of web information using a voice interface	conversation analysis;human computer interaction;web pages;user interface;information retrieval;access to information;information management;speech recognition;voice user interface	Mobile access to information is a considerable problem for many users, especially to information found on the Web. In this paper, we explore how a voice-controlled service, accessible by telephone, could support mobile users' needs for re-finding specific information previously found on the Web. We outline challenges in creating such a service and describe architectural and user interfaces issues discovered in an exploratory prototype we built called WebContext. We also present the results of a study – motivated by our experience with WebContext – to explore what people remember about information that they are trying to re-find and how they express information re-finding requests in a collaborative conversation. As part of the study, we examine how end-usercreated Web page annotations can be used to help support mobile information re-finding. We observed the use of URLs, page titles, and descriptions of page contents to help identify waypoints in the search process. Furthermore, we observed that the annotations were utilized extensively, indicating that explicitly added context by the user can play an important role in re-finding.	freedom of information laws by country;prototype;user interface;waypoint;web page;world wide web	Robert G. Capra;Manuel A. Pérez-Quiñones	2004	CoRR		web service;human–computer interaction;computer science;web navigation;web page;multimedia;information management;user interface;world wide web	HCI	-52.36588878057567	-41.147919787204074	104055
8d5d2b63222638ca84314a14479a4bc885cffe68	using diaries for evaluating interactive products: the relevance of form and context	mobile;web;wearable;diaries;response rate;evaluation studies	In this paper we discuss two studies, in which we used incident diaries to evaluate different aspects of a web-based tool and a wearable display. For the web-based tool we used a diary in form of a table distributed in digital form, which resulted in a very low number of responses. Results from follow-up interviews revealed that one of the reasons for this low response rate was a mismatch between diary form and study context. For the wearable display we designed booklets, which featured predefined sections and questions as well as space for open comments. Although previous research has identified disadvantages of paper-based diaries, this method proved to be valuable for collecting feedback in a mobile context. Based on our experiences and the results from the studies, we provide a qualitative discussion of design issues for diaries used in mobile and desktop-based contexts.	add-ons for firefox;browser extension;desktop computer;diary studies;embedded system;head-mounted display;online diary;relevance;usability;wearable computer;web application	Martin Tomitsch;Nikash Singh;Ghazaleh Javadian	2010		10.1145/1952222.1952266	wearable computer;human–computer interaction;computer science;operating system;mobile technology;response rate;multimedia;world wide web	HCI	-56.25612426288199	-43.691506435655405	104144
222a30f3ea3fd004ec11bd2264596bc0eeb4436d	optimizing display energy consumption for hybrid android apps (invited talk)	web applications;display energy;energy optimization;mobile systems	Energy has emerged as an important quality metric for apps that run on mobile platforms. This talk describes our approach for reducing display energy by automatically changing the color schemes used by a web app so that the pages consume less energy when displayed on an OLED based smartphone.	android;mobile device;oled;optimizing compiler;smartphone;web application	Ding Li;Angelica Huyen Tran;William G. J. Halfond	2015		10.1145/2804345.2804356	simulation;engineering;multimedia;world wide web	Mobile	-48.89871916253086	-39.30037757388108	104292
5b009931edb60c8eee8d2322ea7074fa8001cc98	groupenergytable: an interactive tabletop for energy conservation	energy conservation;travel habit groupenergytable interactive tabletop energy conservation shared electricity transportation data energy tip electricity use;energy tip;shared electricity;travel habit;interactive tabletop;transportation data;pervasive computing interactive surfaces ubiquitous computing sustainability;pervasive computing;interactive surfaces;power distribution;sustainability;groupenergytable;power engineering computing;interactive system;sustainable development green design interactive systems power distribution transportation;transportation;ubiquitous computing;electricity;power engineering computing electricity energy conservation interactive systems;green design;interactive systems;sustainable development;electricity use	The GroupEnergyTable is an interactive tabletop that lets users explore shared electricity and transportation data, view energy tips, and set goals. A two-month study shows how the GroupEnergyTable can help decrease electricity use and change travel habits.		Katherine Everitt;Peter F. Oven;Shwetak N. Patel;James A. Landay	2012	IEEE Pervasive Computing	10.1109/MPRV.2012.43	simulation;energy conservation;human–computer interaction;computer science;electricity;multimedia;ubiquitous computing;sustainability;sustainable development	HCI	-58.331969268980885	-42.2634996993469	104579
0044119524c08164650250163120bcb89adf6345	a context-aware virtual secretary in a smart office environment	context awareness;context aware;availability;contextual information;interruptibility;field experiment;workplace;virtual secretary;computer mediated communication;face to face;social norm;smart space	A lot of the communication at the workplace - via the phone as well as face-to-face - occurs in inappropriate contexts, disturbing meetings and conversations, invading personal and corporate privacy, and more broadly breaking social norms. This is because both, callers and visitors in front of closed office doors, face the same problem: they can only guess the other person's current availability for a conversation.  We present a context-aware Virtual Secretary designed to facilitate more socially appropriate communication at the workplace. This service aims towards understanding a person's activity in smart offices, and passes on important contextual information to callers and visitors in order to facilitate more informed human decisions about how and when to initiate contact.  We have deployed this Virtual Secretary in the office of a senior researcher, mediating all his actual phone calls and in-person meetings for several weeks. With the Virtual Secretary active, the number of inappropriate workplace interruptions could be significantly reduced.	norm (social);privacy	Maria Danninger;Rainer Stiefelhagen	2008		10.1145/1459359.1459430	availability;simulation;field experiment;world wide web;computer-mediated communication;norm	HCI	-58.725554026452386	-42.16803031731518	104588
213580b9125f506cb171ef6036b5e78858d15aaa	non-verbal communication with a social robot peer: towards robot assisted interactive sign language tutoring	assistive technology gesture recognition games humanoid robots educational institutions;sign language humanoid robots interaction games non verbal communication;humanoid robots;hearing impaired children nonverbal communication social robot peer robot assisted interactive sign language tutoring humanoid robot assisted imitation based interactive game children with communication impairments robovie r3 humanoid robot hand movements body gestures face gestures nonmanual facial gestures colored flashcard recognition rgb d camera based system turn taking skills;games;assistive technology;sign language recognition handicapped aids humanoid robots human robot interaction interactive systems natural language interfaces robot vision;gesture recognition	This paper presents a humanoid robot assisted imitation based interactive game for Sign Language (SL) tutoring. The game is specially designed for children with communication impairments. The work presented is a part of Robot Sign Language Tutor* project. In this study, a Robovie R3 humanoid robot is used to express a set of chosen words in SL using hand movements, body and face gestures. The robot platform is specially modified with LEDs in face (for non-manual facial gestures), additional DoFs in wrist and 5 independent fingers at hands for robust SL generation. The robot is able to communicate with the participant by recognizing signs and colored flashcards through a RGB-D camera based system and generating a selected subset of signs, including motivating facial gestures, in return. The game also aims to improve children's imitation and turn-taking skills and to teach the words semantically. Current paper presents results from the preliminary study with a group of hearing impaired children, where children had almost 100% score in recognizing the robot's signs from a subset of 12 words.	design of experiments;humanoid robot;sl (complexity);social robot;vocabulary	Neziha Akalin;Pinar Uluer;Hatice Kose-Bagci	2014	2014 IEEE-RAS International Conference on Humanoid Robots	10.1109/HUMANOIDS.2014.7041509	games;computer vision;simulation;computer science;humanoid robot;artificial intelligence;social robot;gesture recognition;personal robot	Robotics	-49.43667044358463	-49.13043964381574	104628
acc17fee7d9ae1736f768151f149cef440a2ffb6	designing a multi-slate reading environment to support active reading activities	tablet computer;horizontal display;distributed user interface;electronic books;active reading	Despite predictions of the paperless office, most knowledge workers and students still rely heavily on paper in most of their document practices. Research has shown that paper's dominance can be attributed to the fact that it supports a broad range of these users' diverse reading requirements. Our analysis of the literature suggests that a new class of reading device consisting of an interconnected environment of thin and lightweight electronic slates could potentially unify the distinct advantages of e-books, PCs, and tabletop computers to offer an electronic reading solution providing functionality comparable to, or even exceeding, that of paper. This article presents the design and construction of such a system. In it, we explain how data can be mapped to slates, detail interactions for linking the slates, and describe tools that leverage the connectivity between slates. A preliminary study of the system indicates that such a system has the potential of being an electronic alternative to paper.	book;e-book;interaction;iteration;paperless office;prototype;requirement;surface computer;table computer;tablet computer	Nicholas Chen;François Guimbretière;Abigail Sellen	2012	ACM Trans. Comput.-Hum. Interact.	10.1145/2362364.2362366	human–computer interaction;computer science;multimedia;world wide web	HCI	-48.781145574295415	-39.83701786832829	104685
7ca0e36eacb938eea11630f02d3c4f2f3abc219d	artificial pleasure and pain antagonism mechanism in a social robot		The goal of the work is to build some Python modules that allow the Nao robot to emulate a somatosensorial system similar to the human one. Assuming it can perceive some feelings similar to the ones recognized by the human system, it will be possible to make it react appropriately to the external stimuli. The idea is to have a group of software sensors working simultaneously, providing some feedback to show how the robot is feeling at a particular time. It will be able to feel articular pain and stress, to perceive people in his surroundings (and in a future work to react according to the knowledge of them with face recognition), feel pleasure by recognizing caresses on his head and respond to the surrounding noise level.		Antonello Galipó;Ignazio Infantino;Umberto Maniscalco;Salvatore Gaglio	2017		10.1007/978-3-319-59480-4_19	psychology;psychotherapist;communication;social psychology	Robotics	-51.08752663661401	-49.61204417635979	104720
d01611ed71e0b3adbbdeeb66f392243064afd8be	protocols for evaluation of site accessibility with the participation of blind users	usability;accessibility	User interfaces, through which users interact with the systems, should be designed according to the accessibility guidelines, with focus on usability. To this end, the designers of these interfaces should analyze whether their requirements meet the to meet the needs of users with different characteristics is not a trivial task. It is paramount to involve the users and analyze quality, since they allow the identification of many usability problems where the focus in on their accessibility. The present work aims to analyze two methods of observation involving people with totally impaired vision in order to develop a protocol with recommendations that can assist professionals in the identification of characteristics and problems, which can with totally impaired vision. © 2012 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Scientific Programme Committee of the 4th International Conference on Software Development for Enhancing Accessibility and Fighting Info-exclusion (DSAI 2012)	accessibility;requirement;software development;usability;user interface	Simone Bacellar Leal Ferreira;Denis Silva da Silveira;Eliane Pinheiro Capra;Ariane Oliveira Ferreira	2012		10.1016/j.procs.2012.10.006	impaired vision;visual impairment;human–computer interaction;multimedia;usability goals;usability;computer science;usability inspection;user interface	HCI	-55.998421511169994	-45.67308089707714	104784
71e127764b69c11abfc17842e71620561e06493c	models for ownership: implications for long-term relationships to objects		Recent HCI research has shown that there are important differences in the ways that people interact with physical and digital objects, and that these differences have negative implications for how people value digital objects. This work in progress explores one finding from a study comparing uses of paper and e-books that suggests that not only are there important differences in the ways people perceive their ownership of physical and digital objects, but that the context of digital ownership (e.g. through an account vs. files stored on a personal computer) also introduces variations in how people value their digital possessions.	book;e-book;human–computer interaction;personal computer	Jane Gruning	2017		10.1145/3027063.3053232	human–computer interaction;multimedia;work in process;computer science	HCI	-56.965147066565486	-40.363819456281085	104815
69dea8772a54da577b8432ce9af1117bb56ca0d5	evaluating new interactions in healthcare: challenges and approaches	new technology;healthcare;qa75 electronic computers computer science;ra public aspects of medicine;evaluation	New technologies for supporting the provision of healthcare are increasingly pervasive. While healthcare computing previously referred to a desktop computer within the consulting room, we are now seeing an ever broader range of software, hardware and settings. This workshop is concerned with how to conduct evaluations which allow assessment of the overall impact of technology. The workshop will explore challenges and approaches for evaluating new interactions in healthcare. In this paper we outline the goals for this workshop and summarize the issues and questions it intends to explore.	desktop computer;interaction;pervasive informatics	Rebecca Randell;Geraldine Fitzpatrick;Stephanie M. Wilson;Lena Mamykina;Charlotte Tang	2009		10.1145/1520340.1520737	human–computer interaction;knowledge management;evaluation;management science;management	HCI	-62.09809238076037	-42.88511939932148	104993
d96ae4121fe59c387b9fdf16ec902056463b2fba	direct and mediated interactions in the maintenance of social relationships	social relationships;mediated interactions	This paper is an analysis of how mediated interaction has changed the ways in which we establish and develop interpersonal relationships. The paper examines the dimensions of friendship and also the attempts to separate out the role of interaction via various media such as mobile telephony, MUDs, MOOs, and IRC. The paper finds that interaction via the Internet may aid the establishment of relationships. The relationships are, however, slower to develop and necessarily migrate over to other forms of communication including face to face interaction. After the establishment of a relationship there is a preference for more simultaneous, direct interaction with which one can coordinate every day activities.	adobe streamline;emergence;interaction;internet relay chat;mud;mobile phone;putnam model;spontaneous order	Rich Ling	2000			communication;face-to-face interaction;friendship;interpersonal relationship;the internet;mobile telephony;business	HCI	-58.90841283203912	-38.65168682921448	105021
5f6ba466a970e130af468b79f8eaf193eeccb092	the informatics needs of amateur endurance athletic coaches	physical activity;sports;personal informatics;athletes	Personal informatics applications are increasingly available for amateur endurance athletes to record and monitor their performance and training. This information can be valuable for coaches who tailor training programs based on this data. Despite this, it is not clear if the information provided by such tools map to the real needs of the amateur athletic community. To address this, we conducted interviews with eight amateur athletic coaches of endurance athletes. Our results show that athlete-specific contextual factors can be important to track and monitor in relation to performance-based metrics. This information can be difficult to capture, analyze, and share. This suggests design opportunities for personal informatics applications for amateur athletes and coaches.	informatics;quantified self	Brett Wakefield;Carman Neustaedter;Serena Hillman	2014		10.1145/2559206.2581174	simulation;multimedia;physical fitness	HCI	-58.420520450410244	-44.603321056755654	105075
45b3ab2db9298e022bdf7a8dcfbb44f5ce54f097	interacting with robots: can we encourage social interaction skills in children with autism?	social interaction;virtual environment	Robots, virtual environments and other computer based technologies are increasingly applied in therapy and education. The work reported in this article, being part of the Aurora project [1], investigates the potential use of robots as therapeutic or educational 'toys' specifically for use by children with autism. Children with autism show difficulties in social interaction, communication and imagination (referred to by many authors as the triad of impairment, e.g. [15]). Our research focuses on ways that robotic systems can engage autistic children in simple interactive activities (e.g. imitation and turn--taking games) with the aim of encouraging basic communication and social interaction skills.	aurora;robot;toys;virtual reality	Ben Robins;Kerstin Dautenhahn	2004	ACM SIGACCESS	10.1145/1055680.1055682	simulation;computer science;virtual machine;operating system	HCI	-55.43962721665723	-47.34782989388114	105405
cbd8528da32ae8089362427d46a718b7f7064e48	towards seamless support of natural collaborative interactions	computer supported collaborative learning;computer supported cooperative work cscw;computer supported cooperative work	In order to effectively support collaboration it is important that computer technology seamlessly support users’ natural interactions instead of inhibiting or constraining the collaborative process. The research presented in this paper examines the human-human component of computer supported cooperative work and how the design of technology can impact how people work together. In particular, this study examined children’s natural interactions when working in a physical medium compared to two computer-based environments (a traditional desktop computer and a system augmented to provide each user with a mouse and a cursor). Results of this research demonstrate that given the opportunity, children will take advantage of the ability to interact concurrently. In addition, users’ verbal interactions and performance can be constrained when they are forced to interact sequentially, as in the traditional computer setup. Supporting concurrent interactions with multiple input devices is a first step towards developing effective collaborative environments that support users’ natural collaborative interactions.	computer-supported cooperative work;concurrency (computer science);cursor (databases);desktop computer;input device;interaction;seamless3d	Stacey D. Scott;Garth B. D. Shoemaker;Kori Inkpen Quinn	2000			human–computer interaction;computer-supported collaborative learning;computer-supported cooperative work;computer science;knowledge management	HCI	-54.01473992412422	-43.98490988245303	105584
9395ca1c36c89348f7cd779bce325ca96fc4ee50	a mobile shopping assistant to support product domesticity in consumer decisions	human computer interaction;web based services;mobile recommendation systems;mobile commerce;persuasive technologies;human centered computing;electronic computers computer science	In this paper we propose and develop a mobile persuasive application to raise user's interest in specific products, by providing information about each product, focusing on the production country and the origin of the company that produces it. During shopping, the user receives information about each product by optically scanning product barcodes with a mobile device. Recommendations for similar products based on product origin are also provided. In an exploratory evaluation, users indicated that the application was found to be easy to use and was rated useful. Moreover, our experimental results show that the proposed system can significantly affect the decision making process of the users.	barcode;mobile device;recommender system	Sotirios-Foivos Stamopoulos;Andreas Komninos;Ioannis Garofalakis	2014		10.1145/2645791.2645830	mobile search;mobile commerce;human–computer interaction;computer science;human-centered computing;data mining;database;multimedia;mobile computing;world wide web;computer security	HCI	-52.39757978177055	-42.14823860169026	105685
6c888555ae8cd02b360ebe0b2a59c0b9f16dff8c	improving interactions with spatial context-aware services	location based services;scenic routes;geohci;context aware applications;geospatial information;proceedings paper;space usage rules	We have seen a recent rise of context- as well as location-based-mobile services. Finally, those services entering applications and adding features to mobile operating system to make everyday user interactions handier. Nevertheless, those services still have certain limitations, such as lack of certain data types that limit them to exploit their full potentials. My research is situated in the area of human-computer interaction with strong links to the field of intelligent user interfaces and aims to improve interactions with spatial context-aware services by combining methods from computer vision and artificial intelligence.	artificial intelligence;computer vision;context-aware network;human–computer interaction;intelligent user interface;location-based service;mobile operating system;situated	Pavel Andreevich Samsonov	2016		10.1145/2876456.2876459	human–computer interaction;computer science;geospatial analysis;location-based service;data mining;services computing;world wide web	AI	-50.056931782020754	-40.90264014842659	105698
e3043ac91f63c393feb34b65ab83bbce6d5546d3	accessibility in digital cinema: a proposal for generation and distribution of audio description	deficiencia visual;aplicacaes multimidia;cinema digital;acessibilidade	Technological advances in digital cinema have allowed people to encounter experiences that awaken their imagination and expose them to other realities. Experiencing these realties can be more difficult for the blind or visually impaired, however. In our cinema rooms, visual impairments create barriers that can restrict a person's access to critical information. Therefore, we propose a solution that attempts to eliminate these barriers by using a computational system that is able to automatically generate and distribute accessible audio tracks that describe the digital cinema experience. Using mobile devices to provide the content, visually impaired participants were given the opportunity to partake in an experiment to confirm or reject the viability of the solution presented in this article. The results of the experiment demonstrated that our computational system may be a feasible solution.	accessibility;audio description;cinema 4d;experience;mobile device;model of computation	Leonardo Araújo Domingues;Virgínia P. Campos;Tiago Maritan Ugulino de Araújo;Guido Lemos de Souza Filho	2016		10.1145/2976796.2976867	computer vision;simulation;telecommunications;artificial intelligence;multimedia;world wide web	HCI	-50.823383996213224	-40.24153479223292	105936
ebd29b97de44aaedcfcf1bcc9a99179654e71f6b	vision based user interface for cellular phones			mobile phone;user interface	E. Nakamura;K. Murayama;M. Ichimura;Kazuaki Sawada	2001			shell (computing);user interface design;10-foot user interface;natural user interface;human–computer interaction;computer science;user interface	HCI	-49.30647426386831	-38.4391665299174	106090
4bf915daaa414f324a2f0160f868b07aaff5f127	scaling mobile applications using interactive-device user training		"""As smartphones become cheaper and more ubiquitous, they are increasingly used in global development projects for data collection, processing, and computation-intensive tasks. To sustainably implement such solutions, the costs of deployment, overall training, and long-term usage must be considered. In this paper, we examine the training process and sustainability of mobile application for Integrated Management of Childhood Illnesses (IMCI). We first report a comparison of application Mobile-IMCI with the incumbent paper-based module on accuracy, time, and performance in both qualitative and quantitative analyses. We then report an initial exploration of techniques to minimize training time and costs by enabling users to learn applications via a method called """"Interactive-Device Training"""" or IDT. We show that IDT can yield significant improvement in training and learning outcomes with reduced error rates. We conclude that such device-enabled training can reduce the need for explicit training and thus create a more sustainable development approach."""	android;computation;e-government;field research;interrupt descriptor table;mobile app;smartphone;software deployment;usability	Hamid Mehmood;Sameea Ashraf;Ali Imran;Samia Ibtasam	2018		10.1145/3209811.3209821	management science;data collection;software deployment;scaling;sustainability;sustainable development;international development;computer science	HCI	-62.57390025321347	-44.223321168965036	106159
7abc0039332de6b81b05271d5b42aa0e9eb8831d	naturalness, adaptation and cooperativeness in spoken dialogue systems	contextual information;spoken dialogue system;adaptive dialogue strategies;cognitive technical systems;dynamic adaptation;context modeling;dialogue manager	"""In this paper, we consider three distinct but interacting """"cognitive"""" features of spoken dialogue systems that may contribute to better acceptance by users: naturalness of the interaction, adaptation and cooperativeness. In order to achieve them, we particularly concentrate on the dialogue management functionalities of modeling contextual information and of dynamical adapting both analytical and generative aspects of the system's behavior according to the current state of the interaction. Finally, we illustrate the introduced design concepts for the spoken dialogue system Contact."""	dialog system	Milan Gnjatovic;Darko Pekar;Vlado Delic	2010		10.1007/978-3-642-18184-9_24	psychology;natural language processing;speech recognition;communication	NLP	-52.37083522767589	-47.477178153153965	106162
c858cd9d58c8cbb05efe81ec9e6ce196e394482e	telluswho: guided social network data collection	social network data;social network services;telluswho;social networking online internet;electronic mail;data collection;real world social network structures;guided social network data collection;social software;data mining;social ties;social software design;social network;internet;data visualization;social networking online;web based social network survey tool;interviews;egocentric ties;organizations;social network services data mining organizations electronic mail interviews data visualization;egocentric ties guided social network data collection real world social network structures social software design telluswho web based social network survey tool social network data	Significant gaps exist in our knowledge of real world social network structures, which in turn limit our understanding of how to design social software. One important reason for this has been that researchers have not been able to systematically probe individuals in sufficient detail about 'who' and 'how' they interact with in the social networks they wish to study. To address this shortcoming we designed TellUsWho, a web-based social network survey tool. We explored the tool's utility by studying the social ties of 141 students. TellUsWho supported the collection of rich social network data in a relatively short time period. Within an average of 34 minutes, respondents were able to describe their egocentric ties with people they regularly keep in contact. On average, respondents listed 42 alters, for each of which they answered 27 questions, resulting in 1134 responses. This compares favorably to traditional methods, which could require up to 15 hours per subject.	social network;utility;web application	Stephen T. Ricken;Richard P. Schuler;Sukeshini A. Grandhi;Quentin Jones	2010	2010 43rd Hawaii International Conference on System Sciences	10.1109/HICSS.2010.365	public relations;interpersonal ties;the internet;interview;computer science;organization;data mining;database;world wide web;data visualization;statistics;social network;data collection	HCI	-60.66453461698722	-43.746189223564144	106170
d647cfbd4ceb8eb1f6f5eebb0aa3dad1e32d4466	cloudbits: supporting conversations through augmented zero-query search visualization		The retrieval of additional information from public (e.g., map data) or private (e.g., e-mail) information sources using personal smart devices is a common habit in today's co-located conversations. This behavior of users imposes challenges in two main areas: 1) cognitive focus switching and 2) information sharing.  In this paper, we explore a novel approach for conversation support through augmented information bits, allowing users to see and access information right in front of their eyes. To that end, we investigate the requirements for the design of a user interface to support conversations through proactive information retrieval in an exploratory study. Based on the results, we 2) present CloudBits: A set of visualization and interaction techniques to provide mutual awareness and enhance coupling in conversations through augmented zero-query search visualization along with its prototype implementation. Finally, we 3) report the findings of a qualitative evaluation and conclude with guidelines for the design of user interfaces for conversation support.	email;information retrieval;interaction technique;prototype;requirement;smart device;user interface	Florian Müller;Sebastian Günther;Azita Hosseini Nejad;Niloofar Dezfuli;Mohammadreza Khalilbeigi;Max Mühlhäuser	2017		10.1145/3131277.3132173	computer science;information sharing;conversation;human–computer interaction;visualization;exploratory research;multimedia;user interface;cognition	HCI	-53.16564330891679	-41.40068112720386	106215
a85f88ef367fe8bf3e56b0db6b2d1e1a7c42c20b	understanding the effect of existing positive relationships on a social motion-based game for health		In this paper, we present the iterative design of StepQuest, a Fitbit-based social motion-based game for health (MGH) to sustain physical activity (PA) and support extended play. We conducted two 6-week user studies (n=24) to evaluate the effectiveness of the game to promote PA for an extended period of time as well as the role of existing social relationship. Our findings indicate that a pre-existing positive relationship (e.g., friendship) has a positive impact on players' PA levels when they play a social MGH, compared to strangers, and that this effect was amplified when more gameplay actions were available. However, our results also show that overall PA levels declined for both groups in week 4, and that pre-existing social relationship and a variety of gameplay actions are not enough to sustain long-term motivation for PA. Based on these results and drawing from game design literature, we present a list of design implications including less-discussed key topics such as game balancing.	iterative design;iterative method;monumenta germaniae historica;pa degree;usability testing;virtual world	Karina Caro;Yuanyuan Feng;Timothy Day;Evan Freed;Boyd Fox;Jichen Zhu	2018		10.1145/3240925.3240942	iterative design;friendship;knowledge management;distributed computing;computer science;game design	HCI	-60.20737447571677	-44.23199414384061	106231
258d0be005c18e1003bf6dabc99e4492ca6911b5	mapping music in the palm of your hand, explore and discover your collection	graph drawing;user interface;contextual information;graphic user interface	The trends of miniaturization and increasing storage capabilities for portable music players made it possible to carry increasingly more music on small portable devices, but it also introduced negative consequences for the user interface and navigation. Finding music in large collections can be hard if one does not know exactly what to look for. In this paper a novel user interface to browse and navigate through music on small devices is proposed, together with the enabling algorithms. The goal of this interface is to enable the users to explore and discover their entire collection and to support nonspecific searches. To this end, a new way to visualize and navigate through music is introduced: the artist map. The artist map is designed to provide an overview of an entire music collection, or a subset thereof, by clearly visualizing the similarity between artists, computed from the music itself. Contextual information (e.g. mood, genre) is added by coloring and by attribute magnets. The artist map is implemented by a graph-drawing algorithm, which uses an improved energy model. The proposed algorithm and interface have been implemented in a prototype and will be tested with ‘real’ users.	algorithm;browsing;graph coloring;graph drawing;mobile device;prototype;user interface	Fabio Vignoli;Rob van Gulik;Huub van de Wetering	2004			human–computer interaction;computer science;graphical user interface;multimedia;natural user interface;graph drawing;user interface;world wide web	HCI	-48.71254464616759	-40.08405626695385	106301
2d3017a021bb1e7b21a41f316b155f7434215c52	"""""""whatsapp is for family; messenger is for friends"""": communication places in app ecosystems"""		Today's users communicate via multiple apps, even when they offer almost identical functionality. We studied how and why users distribute their contacts within their app ecosystem. We found that the contacts in an app affect a user's conversations with other contacts, their communication patterns in the app, and the quality of their social relationships. Users appropriate the features and technical constraints of their apps to create idiosyncratic communication places, each with its own recursively defined membership rules, perceived purposes, and emotional connotations. Users also shift the boundaries of their communication places to accommodate changes in their contacts' behaviour, the dynamics of their relationships, and the restrictions of the technology. We argue that communication apps should support creating multiple communication places within the same app, relocating conversations across apps, and accessing functionality from other apps.	blueprint;ecosystem;mobile app;recursion;recursive definition;relocation (computing);whatsapp messenger	Midas Nouwens;Carla F. Griggio;Wendy E. Mackay	2017		10.1145/3025453.3025484	internet privacy;world wide web	HCI	-57.66863226785905	-39.55741897415006	106431
85994079f055661128b6bcf8293d7e7384c09f77	mobile phone preferences and values: the u.k. vs. korea	factor analysis;user interface;satisfiability;qualitative study	Two studies were designed to identify cross-cultural patterns of mobile phones usage and preferences for User Interfaces among Korean and British users.. The first study was a quantitative study (Questionnaires analysed by factor analysis), whose results demonstrated the two groups have different frustrations with and are satisfied by different aspects of mobile phone. The second study was a qualitative study (User Evaluation), which showed different values and focuses on different aspects of the User Interface.	factor analysis;mobile phone;user interface	Hyunjin Cha;Lidia Oshlyansky;Paul A. Cairns	2005			mobile phone;human–computer interaction;gsm services;internet privacy;computer science;user interface	HCI	-58.83190389146353	-45.74851985311304	106532
0fbb3fee4aed144ac52cc80042d6cf5fb00207ca	the role of language skills in interactive social book search sessions	casual leisure behaviour;social book searching;interface design;qa75 electronic computers computer science;multilingual information access	When searching for books, people frequently have to deal with content that is in a language different from their own. However, research on multilingual systems has generally focused on the user interface's language rather than the content language. In this paper, we describe and compare early results from the multilingual aspects in the Interactive Social Book Search (iSBS) task at CLEF 2014 and 2015. A preliminary analysis of usage patterns for native English and non-native English speakers indicates an influence of language skills on search behaviour during goal-oriented and casual leisure tasks. Based on previous experiences and results, strengths and challenges of IIR studies are discussed.	book;infinite impulse response;interactivity;user interface	Maria Gäde;Mark M. Hall	2016		10.1145/2854946.2854990	natural language processing;computer science;multimedia;communication	HCI	-51.22328404951541	-43.8972767604549	106542
8236182aa4b26e1d2109e4d1ab392d1972d16b63	affective computing with primary and secondary emotions in a virtual human	affective gaming;emotion expression;bdi based architecture;virtual reality;virtual human;pad emotion space;affect simulation architecture;primary and secondary emotions;aware emotions;emotion dynamics;emotion modeling;affective computing;embodied agent	We introduce the WASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity) Affect Simulation Architecture, in which a virtual human’s cognitive reasoning capabilities are combined with simulated embodiment to achieve the simulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PAD space), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the ability to reason about current events in the light of experiences and expectations. By technically representing aspects of each secondary emotion’s connotative meaning in PAD space, we not only assure their mood-congruent elicitation, but also combine them with facial expressions, that are concurrently driven by primary emotions. Results of an empirical study suggest that human players in a card game scenario judge our virtual human MAX significantly older when secondary emotions are simulated in addition to primary ones.	affective computing;categorization;cognitive computing;color gradient;experience;humans;max;simulation;virtual actor	Christian Werner Becker-Asano;Ipke Wachsmuth	2009	Autonomous Agents and Multi-Agent Systems	10.1007/s10458-009-9094-9	embodied agent;computer science;artificial intelligence;emotion classification;affective computing;virtual reality;multimedia	AI	-50.93336600926898	-51.50398181656303	106590
23696295304583f7a8a791f9e0e26a28728f074f	the five most important research issues in effective game for health design (from a behavioral scientist's perspective)	story;feedback;behavior change;videogames;mediating variables;fun;long term change;generalization	"""Games for Health are a relatively new genre of games and an innovative intervention method for changing behavior to promote health or prevent disease. At the current time, most children and many adults wish to be entertained, not educated or """"talked at"""". Video games which can be entertaining, thereby, provide an ideal modality for influencing health related behaviors. Given the recency of the genre, however, it is not clear how best to design video games to change behavior.  The mediating variable model has been proposed as a conceptual model for understanding how behavior changes occur. Understanding how video games may influence behavior and health introduces a new variable, game play, into the mediating variable model.  Adults and children generally play games in general, and video games in particular, because they are """"fun"""". Approximately equivalent terms are """"enjoyable"""" or """"engaging"""". The concept of """"fun"""" (or its related constructs) has not been precisely defined, nor operationalized. Psychosocial, physiological, and embodiment approaches to studying fun have been attempted, but not thoroughly researched. Better understanding is needed of what in the experience of video game play constitutes fun, and the relationships among the psychosocial, physiological, and related constructs and methods. This should enhance the design of video games for health, by enhancing the players' desire to continue game play, and thereby increasing the game players' exposure to the change inducing elements.  Stories, or narratives, have been incorporated into many video games for health. Stories have been hypothesized to """"transport"""" the player out of their attention to their immediate surroundings, or """"immerse"""" the player in the story line, thereby enhancing the player's attention to messages or other intervention procedures embedded in the story, e.g. character modeling of desired behaviors. Cutscenes within games can be used to advance the storyline or stories can be used separate from the games (e.g. in parallel books). Better understanding of a) how stories immerse players should lead to stories which are more effective at influencing behavior; b) how to use stories in, or in parallel to, game play should enhance immersion; and c) which behavior change procedures, and how, to insert them in stories, should enhance resulting mediating variable and behavior change."""	book;cutscene;embedded system;emoticon;immersion (virtual reality);inductive reasoning;modality (human–computer interaction)	Thomas Baranowski	2014		10.1145/2656719.2656720	psychology;simulation;game mechanics;metagaming;multimedia;social psychology	HCI	-56.665561790450525	-50.903692517166064	106676
fdbc681c85d5d32d724edfc374f7031f8e3a7100	the influence of human factors on olfaction based mulsemedia quality of experience	media olfactory multimedia communication synchronization human factors quality of service testing;multiple sensorial media olfaction based mulsemedia quality of experience human factor influence user perception user qoe;testing;media;quality of experience chemioception human factors multimedia systems;human factors;synchronization;multimedia communication;quality of service;olfactory;sensory experience mulsemedia olfaction enhanced multimedia olfaction based mulsemedia quality of experience	With the aim to enrich users' perceived multimedia experience, the authors present the results of an empirical study which looked at user perception of olfaction based mulsemedia. The goal is to evaluate the influence of users' age and gender on user quality of experience (QoE) considering various scent types and categories (pleasant or not). The results present a complex relationship between these variables and how they influence user QoE. They indicate that different user groups report different perception of content level factors for olfaction based mulsemedia.	haptic technology;human factors and ergonomics;lero (software engineering);recommender system;software engineering;vii	Niall Murray;Brian Lee;Yuansong Qiao;Gabriel-Miro Muntean	2016	2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX)	10.1109/QoMEX.2016.7498975	synchronization;media;quality of service;telecommunications;computer science;human factors and ergonomics;olfaction;multimedia;software testing	SE	-57.42985569152653	-46.92412992165128	106792
3bdf4e06d922db85074c4d2db91ae1363cc90587	towards developing assistive haptic feedback for visually impaired internet users	web pages;web accessibility;blind;use of force;visual impairment;haptic feedback;participatory design;haptic;scenarios;design methodology	Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions.	html element;haptic technology;internet;vocabulary;web page;world wide web	Ravi Kuber;Wai Yu;Graham McAllister	2007		10.1145/1240624.1240854	simulation;human–computer interaction;computer science;multimedia;haptic technology;world wide web	HCI	-51.627731392688666	-41.10564014222774	106826
f935f984266b0e322132e5a720ca48e920fe81f2	canihelp: a platform for inclusive collaboration		Technology plays a key role in daily life of people with special needs, being a mean of integration or even communication with society. By built up experience, we find that support tools play a crucial part in empowerment of persons with special needs and small advances may represent shifts and opportunities. The diversity of solutions and the need for dedicated hardware to each feature represents a barrier to its use, compromising the success of the solutions against, among others, problems of usability and scale. This paper aims to explore the concept of inclusive collaboration to enhance the mutual interaction and assistance. The proposed approach combines and generalizes the usage of human computation in a collaborative environment with assistive technologies creating redundancy and complementarity in the solutions provided, contributing to enhance the quality of life of people with special needs and the elderly. The CanIHelp platform is an embodiment of the concept as a result from an orchestrated model using mechanisms of collective intelligence through social inclusion initiatives. The platform features up for integrating assistive technologies, collaborative tools and multiple multimedia communication channels, accessible through multimodal interfaces for universal access. A discussion of the impacts of fostering collaboration and broadening from the research concepts to the societal impacts is presented. As final remarks a set of future research challenges and guidelines are identified.	assistive technology;collaborative software;collective intelligence;complementarity theory;human-based computation;multimodal interaction;s60 (software platform);the quality of life;usability	Hugo Paredes;Hugo Fernandes;André Sousa;Renata Fortes;Fernando Luiz Koch;Vítor Filipe;João Barroso	2015		10.1007/978-3-319-20681-3_45	simulation;human–computer interaction;engineering;knowledge management	HCI	-62.31816120605705	-41.126951907397554	106830
f5c33f3ea625ff36ad653030000d6e814904a8ea	evaluating facial displays of emotion for the android robot geminoid f	dynamic facial expression facial emotion display evaluation android robot geminoid f robot nonverbal expressiveness;humanoid robot;online survey;facial expressions;androids;android science;emotion recognition;online survey android science affective computing facial expressions;humanoid robots androids humans face europe pressing;pressing;face recognition;humanoid robots;face;humans;humanoid robots emotion recognition face recognition;facial expression;europe;affective computing	With android robots becoming increasingly sophisticated in their technical as well as artistic design, their non-verbal expressiveness is getting closer to that of real humans. Accordingly, this paper presents results of two online surveys designed to evaluate a female android's facial display of five basic emotions. We prepared both surveys in English, German, and Japanese language allowing us to analyze for inter-cultural differences. Accordingly, we not only found that our design of the emotional expressions “fearful” and “surprised” were often confused, but also that many Japanese participants seemed to confuse “angry” with “sad” in contrast to the German and English participants. Although similar facial displays portrayed by the model person of Geminoid F achieved higher recognition rates overall, portraying fearful has been similarly difficult for the model person. We conclude that improving the android's expressiveness especially around the eyes would be a useful next step in android design. In general, these results could be complemented by an evaluation of dynamic facial expressions of Geminoid F in future research.	android (robot);robot;telenoid r1	Christian Werner Becker-Asano;Hiroshi Ishiguro	2011	2011 IEEE Workshop on Affective Computational Intelligence (WACI)	10.1109/WACI.2011.5953147	psychology;computer vision;communication;social psychology	HCI	-52.28891895875408	-50.62576680803744	106917
939a15f278c0151c7875a43e1a434311a5ef81ca	user interface design practice for the web in new zealand	interfase usuario;oceanie;human computer interaction;user interface;man machine dialogue;information technology;hci;result;interface design;it education;nueva zelandia;enquete;internet;web design guidelines;nouvelle zelande;resultado;dialogo hombre maquina;interface utilisateur;user interface design;resultat;encuesta;new zealand;survey;user interfaces;oceania;dialogue homme machine	In a survey of 62 enterprises in New Zealand, including the six major universities, we were interested in finding out the state of industrial and educational practice with respect to the field of user interface design for the web. Our research revealed that usability issues seem to have taken a backseat to other kinds of development concerns. There is general lack of formal education, knowledge and skills in usability methods, processes and techniques amongst designers and developers. We also found that most universities in New Zealand offer one or two Human-Computer Interaction (HCI) courses within their information technology undergraduate degree programmes as electives. Conversely, our research shows that elsewhere internationally, HCI has become a major area of study especially where usability is a major industrial concern. We discuss the problem, its implications and possible remedies.	user interface design	Ramesh Lal;Scott P. Overmyer	2008	Int. J. Web Eng. Technol.	10.1504/IJWET.2008.019535	pluralistic walkthrough;web usability;simulation;usability;human–computer interaction;computer science;artificial intelligence;software engineering;usability engineering;database;multimedia;user interface;management;information technology;heuristic evaluation;world wide web	Web+IR	-61.99422108528429	-48.55754839345941	106992
5772e2e9eb2b5e430db055fc98b5d485905acfa4	using self-reported experiences to explore the issues of women in crisis situations	self reporting experiences;probes;women;crisis situations	Within Australia women are more likely to experience poverty than their male counterparts, where certain negative life events could potentially place women in a crisis situation. This paper describes the use of a self-reported probe kit in a marginalised community of women who are living in crisis situations. The kit contains a video camera, disposable camera and a set of task cards to prompt them to capture certain experiences. We applied this method with 13 participants from a community care centre and found the self-reported experiences to reveal both useful and insightful perspectives around the lives of women in crisis situations. Through this methodology the women shared different aspects of their lives, challenged stereotypes, and were empowered to share their stories and experiences. This methodology is useful in sensitive settings as it includes participants in the design process, and supports their privacy by enabling agency. It also allows for digital inclusion in terms of interacting with and using the camera technology.	camera phone;disposable camera;experience;interaction;miranda;privacy;robot kit	Tara Capel;Jennyfer Lawrence Taylor;Dhaval Vyas	2016		10.1145/3010915.3010962	simulation;computer security	HCI	-58.66976654453094	-51.20229725731822	107038
8a4679924c162c0f006f6daade740075269706a1	modeling linguistic and personality adaptation for natural language generation		Previous work has shown that conversants adapt to many aspects of their partners’ language. Other work has shown that while every person is unique, they often share general patterns of behavior. Theories of personality aim to explain these shared patterns, and studies have shown that many linguistic cues are correlated with personality traits. We propose an adaptation measure for adaptive natural language generation for dialogs that integrates the predictions of both personality theories and adaptation theories, that can be applied as a dialog unfolds, on a turn by turn basis. We show that our measure meets criteria for validity, and that adaptation varies according to corpora and task, speaker, and the set of features used to model it. We also produce fine-grained models according to the dialog segmentation or the speaker, and demonstrate the decaying trend of adaptation.	natural language generation;text corpus;theory;turn-by-turn navigation;dialog	Zhichao Hu;Jean E. Fox Tree;Marilyn A. Walker	2018			artificial intelligence;natural language processing;computer science;natural language generation;personality	NLP	-52.57215824931174	-48.129982652628	107082
75bd18b26ef39fa80e114e36409d193c56863a34	user study on affectim, an avatar-based instant messaging system employing rule-based affect sensing from text	affect sensing from text;instant messaging;social interaction;emotional intelligence;user study;rule based;emotion recognition;gold standard;text messaging;online community;affective user interface;intelligent system;computer mediated communication;is success;virtual environment;avatar based instant messaging	Social interaction among people is an essential part of every society, and a strong foundation for the development and selfactualization of a person. Even in virtual environments we tend to interact in a social way. Our research addresses the tasks of recognition, interpretation, and visualization of affect communicated through text messaging. In order to facilitate sensitive and expressive interaction in computer-mediated communication, we previously introduced a novel syntactical rule-based approach to affect recognition from text. The evaluation of the developed Affect Analysis Model showed promising results regarding its capability to accurately recognize affective information in text from an existing corpus of informal online conversations. To enrich the user’s experience in online communication, to make it enjoyable, exciting, and fun, we implemented a web-based Instant Messaging (IM) application, AffectIM, and endowed it with emotional intelligence by integrating the developed Affect Analysis Model. This paper describes the findings of a twenty-person study conducted with our AffectIM system. The results of the study indicate that our IM system with automatic emotion recognition function can achieve a level of affective intelligence (system is successful at conveying the user’s feelings, avatar expression is appropriate) that is comparable to ‘‘gold standard’’, where users select the label of the conveyed emotion manually. & 2010 Elsevier Ltd. All rights reserved.	computer-mediated communication;emotion recognition;instant messaging;interpretation (logic);logic programming;online chat;virtual reality;web application	Alena Neviarouskaya;Helmut Prendinger;Mitsuru Ishizuka	2010	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2010.02.003	rule-based system;social relation;emotional intelligence;human–computer interaction;gold standard;computer science;virtual machine;artificial intelligence;operating system;multimedia;world wide web;computer-mediated communication	HCI	-53.187249836964654	-46.920119873751496	107114
a5bcd231140a867e2de3649294c5bfa348556a9b	life review in end of life care: a practitioner's perspective	reflective remembering;life review;end of life;significant memories;physical and digital aids	This paper presents an exploratory study of life review as a therapeutic technique performed in the end of life care. We describe interviews with four therapists practicing life review and discuss initial findings showing the benefits of closure and empowerment for patients' emotional wellbeing. Findings also highlight the importance of reflective remembering in life review, together with the challenge of recalling details of significant life events, and of their emotional processing. Another finding relates to the current limited use of technology for end of life review, with an emphasis of printed photos, music and significant objects for supporting recall of key events. Our findings led to design implications for supporting the construction of life review and the recording of life review process. We conclude with a discussion of the challenges of life review in end of life care and of the need to explore such digital tools to support it.	printing;social media;timeline	Corina Sas;Shuang Ren;Alina Coman;Sarah Clinch;Nigel Davies	2016		10.1145/2851581.2892491	life review	HCI	-58.37067625942412	-44.65697580924921	107226
7a220ea59e838c29658f68777356d4dbf777f915	exploring correlational information in aggregated quantified self data dashboards	mashups;data dashboards;quantified self;data aggregation;self tracking;correlation analysis	Data aggregation platforms are often depicted as a panacea for users wanting to examine correlations within the multi-faceted data that they collect. In this paper we describe inherent challenges with the provision of multi-faceted, correlational information in data aggregation tools, and present a set of hypotheses related to these challenges. We point to design considerations for improving such tools and describe an on-going study of one such tool, Exist.io, in which we aim to explore the issues discussed.	data aggregation;faceted classification;quantified self	Simon L. Jones	2015		10.1145/2800835.2800963	data aggregator;computer science;data science;data mining;quantified self;world wide web;mashup	HCI	-62.023551699614195	-40.831771499032676	107250
0648623950e3069e8b66ea65addf49e9e20677b6	what can doodles on the arm teach us about on-body interaction?	on body interaction;skin interaction	The use of the skin as interaction surface is gaining popularity in the HCI community. To offer an alternative perspective on how we might design on-body interactions, we conducted a questionnaire asking if, how, and why people mark their skin. We found that visibility and ease of access were important factors for choosing to mark the body. We also found that while some participants consider marking the body as a private activity, most participants perceive such markings as a public display. This tension between the personal nature of on-body interaction and the skin as a public display, as well as hedonic uses of body markings, present interesting design challenges.	biological system;human–computer interaction;item unique identification;skin (computing)	Paul Strohmeier;Juan Pablo Carrascal;Kasper Hornbæk	2016		10.1145/2851581.2892544	simulation;computer science	HCI	-56.829376702148636	-45.83751413717766	107464
7c68c31031eeff1cc507e68c5b8c1b42b83f0982	co-designing for new city-citizen interaction possibilities: weaving prototypes and interventions in the design and development of urban mediator	design and development;citizen driven innovations;social practices;co design;e goverment;user innovation	This paper explores issues of participation in urban life, particularly new partnerships between city and citizens to co-design new services for their cities. We will share experiences from working on the design and development of a software infrastructure, Urban Mediator, and its related social practices. We conclude by pointing out the necessity of considering the software artifacts designed as being part of a toolkit for co-design that can enhance conversations between cities and citizens, and enable the envisioning of new practices related to city-citizen interactions.		Andrea Botero;Joanna Saad-Sulonen	2008		10.1145/1795234.1795296	co-design;simulation;e-government;human–computer interaction;computer science;systems engineering;engineering;knowledge management	HCI	-60.51590656900875	-39.290947151998736	107676
54e01a80216da44feba155025371cc0374618627	occasional users' experiences of visiting a virtual environment	learning process;design tool;virtual reality cad human factors user centred design user interfaces;computational steering;virtual environment visit;cad;virtual reality;user tests;cave like environment;user interviews;occasional user experiences;human factors;phenomenographical study;user testing;user centred design occasional user experiences virtual environment visit phenomenographical study user tests user interviews vr technology cave like environment;parallel visualization;user centred design;virtual environment;vr technology;data redistribution;virtual space;user interfaces;virtual environment testing navigation legged locomotion usability humans process planning organizing guidelines mechanical engineering;numerical simulation	The aim of the study is to analyze occasional users' experiences of visiting a virtual environment. The phenomenographical study consists of user tests and user interviews. The user test includes 6 users, 3 men and 3 women of different ages with no previous knowledge of VR-technology. The test process for each person consists of three visits to a Cave-like environment using four different applications. All the test users found VE impressive and enjoyed visiting it. However, they found moving in a virtual space problematic. They felt uncomfortable, even sick and they got lost. The findings indicate that there are both technical and human issues in using VE as a design tool for occasional users. Moving in VE can be improved by technical development, as well as by better planning of occasional users' visits to VE, considering users' learning process during the visit.	assistive technology;design tool;experience;virtual reality	Tarja Tiainen;Tarja Katajamäki;Asko Ellman;Taina Kaapu	2006	2006 Tenth IEEE International Symposium on Distributed Simulation and Real-Time Applications	10.1109/DS-RT.2006.26	simulation;human–computer interaction;engineering;multimedia	Visualization	-53.12920857443107	-40.111976513883235	107723
9d42f5d0582ae27f423a0f39b809505cd262527b	conceptualizing, designing, and investigating locative media use in urban space	human computer interaction;theoretical framework;urban space;locative media;computer human interaction;conceptual design;design and implementation;computer mediated communication;location awareness;user interaction	  This chapter investigates the social implications of locative media (LM) use and attempts to outline a theoretical framework  that may support the design and implementation of location-based applications. Furthermore, it stresses the significance of  physical space and location awareness as important factors that influence both human–computer interaction and computer-mediated  communication. The chapter documents part of the theoretical aspect of the research undertaken as part of LOcation-based Communication  Urban NETwork (LOCUNET), a project that aims to investigate the way users interact with one another (human–computer–human  interaction aspect) and with the location-based system itself (human–computer interaction aspect). A number of relevant theoretical  approaches are discussed in an attempt to provide a holistic theoretical background for LM use. Additionally, the actual implementation  of the LOCUNET system is described and some of the findings are discussed.    		Katerina Diamantaki;Charalampos Rizopoulos;Dimitris Charitos;Nikos Kaimakamis	2010		10.1007/978-1-84882-727-1_4	human–computer interaction;computer science;multimedia;communication	HCI	-58.936590106186806	-38.99295082212569	108116
9d311ab130e7c847e05f935db8aea02f119f0360	the roles of sensory modalities in collaborative virtual environments (cves)	perception intermodale;task performance;modalite stimulus;condition dependence;copresence collaboration;realite virtuelle;realidad virtual;cooperation;collaboration;virtual reality;user perception;hombre;modalidad estimulo;sensory feedback;copresence;percepcion;stimulus modality;cooperacion;retroaccion;retroaction;sensibilidad tactil;human;feedback regulation;haptic feedback;presence;user behavior;intermodal perception;perception;percepcion intermodal;collaborative virtual environments cves;user interaction;vision;collaborative virtual environment;human perception;sensibilite tactile;tactile sensitivity;homme	This study was conducted to assess the effects of sensorial modalities on user performance, perception, and behavior in collaborative virtual environments (CVEs). Participants played a CVE game, air hockey, together with a remote partner under different sensory modality conditions, depending on the type of sensory feedback provided: visual-only (V), visual-haptic (V+H), and visual-haptic-audio feedback (V+H+A). Three types of measurements were used as dependent variables: (1) task performance measured as playing time, (2) user perception including the sense of presence, the sense of togetherness, and perceived collaboration, and (3) behavior measurement including the amount of force applied and the mallet deviation. Results of the study indicated that the task performance, perception, and user behavior in CVEs can be affected due to supported sensory modalities. Therefore, the multiple sensory information types that are required to perform the task at hand should be provided to effectively support collaboration between people in CVEs. The outcomes of this research should have a broad impact on multimodal user interaction, including research on physiological, psychophysical, and psychological mechanisms underlying human perception on multisensory feedback in CVEs.	collaborative virtual environment;virtual reality	Chang Soo Nam;Joseph Shu;Donghun Chung	2008	Computers in Human Behavior	10.1016/j.chb.2007.07.014	psychology;cognitive psychology;simulation;virtual reality;multimedia;communication;perception;social psychology	HCI	-52.69392779878781	-50.45009598984024	108148
0ce3e4430163b8a401993128662fa6a6d540c851	modelling the affective power of locutions in a persuasive dialogue game		One of the most important contemporary directions of development in the field of artificial intelligence is to equip AI systems with emotional intelligence. This work is part of this trend. The paper presents a mathematical model that allows us to describe changes in players’ emotional states as a response to dialogue actions. To this end, we use the paradigm of dialogue games and propose a method of rating locutions. The method is inspired by the affective rating system SAM which uses Mehrabian’s PAD space which distinguishes emotions because of three attributes: Pleasantness (valence) (P), Arousal (A), and Dominance (D). Emotions that are analyzed are taken from Ekman’s model with five universally accepted labels: fear, disgust, anger, sadness, and joy. In addition, we describe the emerging tool for the realization of dialogue games with emotional reasoning. This tool is the basis for designing a system for verifying the properties of dialog protocols.		Magdalena Kacprzak;Anna Sawicka;Andrzej Zbrzezny	2018		10.1007/978-3-319-91262-2_49	computer science;artificial intelligence;machine learning;emotional reasoning;social psychology;disgust;affect (psychology);dialog box;anger;emotional intelligence;sadness;arousal	NLP	-52.952756462146766	-48.75664813064083	108185
d7e9c5d95478f33ac85be7dcefa3c552d08d2a29	the influence of a gesture-based learning approach on preschoolers’ learning performance, motor skills, and motion behaviors		ABSTRACTThis study developed a gesture-based learning approach to build a virtual interactive learning environment for preschoolers by combining a gesture-based computing device and a game-based learning model. Using sequential analysis, this study investigated how this approach influenced children’s learning performance, motor skills, and motion behaviors. A quasi-experiment was conducted with 142 kindergarten-level-3 preschoolers. The results showed that the gesture-based learning approach improved the students’ learning performance and motor skills compared with the traditional activity-based learning approach. The main learning pattern showed that the preschoolers controlled their body motion behaviors and movements to learning cognitive knowledge, which achieving a flow state that improved preschoolers’ learning performance and motor skills. In addition, the main motion pattern showed that the preschoolers interacted with the game by coordinating their body movement with the projected human skeleton’...		Hsien-Sheng Hsiao;Jyun-Chen Chen;Chien-Yu Lin;Wen-Nong Chen	2018	Interactive Learning Environments	10.1080/10494820.2017.1419498	multimedia;machine learning;computer science;motor skill;cognition;flow (psychology);artificial intelligence;interactive learning;gesture	ML	-55.122972289962334	-49.976471508047865	108274
7e9ef4c1e62849b58034180a6e5b31938f439b78	an empathic robotic tutor for school classrooms: considering expectation and satisfaction of children as end-users		Before interacting with a futuristic technology such as a robot, there is a lot of space for the creation of a whole set of expectations towards that interaction. Once that interaction happens, users can be left with a hand full of satisfaction, dissatisfaction, or even a mix of both. To study the possible role of experience as a mediator between expectation and satisfaction, we developed a scale for HRI that measures expectations and satisfaction of the users. Afterwards, we conducted a study with end-users interacting with a social robot. The robot is being developed to be an empathic robotic tutor to be used in real schools, with input from primary end-users (children). Children’s expectations and subsequent satisfaction after the interaction with the robotic tutor were analysed. The results can be fed back to the system developers on how well it is being designed for such a target population, and what factors regarding their expectation and satisfaction have shifted after the experience of interaction. By delivering on the children’s expectations, we aim to design a robotic tutor that provides enough satisfaction to sustain an enjoyable and natural interaction in the real educational	cognitive tutor;human–robot interaction;social robot	Patrícia Alves-Oliveira;Tiago Ribeiro;Sofia Petisca;Eugenio Di Tullio;Francisco S. Melo;Ana Paiva	2015		10.1007/978-3-319-25554-5_3	multimedia;social psychology;pedagogy	HCI	-53.829586054608434	-50.45831910595955	108411
bfda45aed614b026bcd37969d156ea78a9c67173	investigating intention to use an interactive television game	interaction;technology acceptance model;digital television;interactive television game	Besides the excellent quality of picture and sound, and the plethora of available channels, digital interactive television provides access to applications and services with the touch of a button. Interactive television games are becoming popular since television viewers are able to virtually participate in the game. The aim of the work presented in this paper is to investigate factors affecting users’ intention to use an interactive television game that is built upon a popular television game. Towards this aim, we formed a model based on the Technology Acceptance Model (TAM) as well as additional factors derived from previous research in the domains of online games and fun information systems.		George Koniaris;George Lekakos	2009			game design;simulation;multimedia;advertising;interactive television;video game development	HCI	-59.42087142954726	-45.15292801796643	108525
5b89719effd137b5b1748120e00ebe6e3e4f8292	a model to develop videogames for orientation and mobility	design and development;levels of abstraction;serious videogames;audiogames;orientation and mobility;software engineering model	There is a real need to have systems for people with visual disabilities to be able to improve their orientation and mobility skills, and especially for children to be able to improve their autonomy into the future. However, these systems must be designed according to available objectives, methodologies and resources, as well as by taking the interests and ways of interacting of the end users into account. This work presents a model for the development of videogame-based applications, which includes differing levels of abstraction and different stages in the design and development of systems that allow for the improvement of orientation and mobility skills for people with visual disability. The feasibility of the model was studied by modeling two videogames for children with visual disabilities.	autonomy;interaction;principle of abstraction	Jaime Sánchez;Luis Guerrero;Mauricio Sáenz;Héctor Flores	2010		10.1007/978-3-642-14100-3_44	simulation;human–computer interaction;engineering;multimedia	HCI	-61.197296820007395	-46.5487666749424	108641
1cc262da1bacc2549107b577ef7ec185b9c858c0	on improving visual-facial emotion recognition with audio-lingual and keyboard stroke pattern information	databases;computers;emotion recognition keyboards face recognition face detection intelligent agent human computer interaction psychology speech informatics instruments;face recognition emotion recognition;keyboards;empirical study;human computer interaction;multi modal interface;visual facial modality visual facial emotion recognition audio lingual information keyboard stroke pattern information emotion recognition keyboard stroke information;emotion recognition;facial expression analysis;human subjects;accuracy;face recognition;affective user modeling;visual facial affect recognition;multi modal interfaces;humans;empirical studies;human computer interaction facial expression analysis visual facial affect recognition empirical studies affective user modeling multi modal interfaces;user model	In this paper, we investigate the possibility of improving the accuracy of visual-facial emotion recognition through use of additional (complementary)information. The investigation is based on three empirical studies that we have conducted involving human subjects and human observers. The studies were concerned with the recognition of emotions from a visual-facial modality, audio-lingual and keyboard-stroke information, respectively. They were inspired by the relative shortage of such previous research in empirical work concerning the strengths and weaknesses of each modality so that the extent can be determined to which the keyboard-stroke and audio-lingual information complements and improves the emotion recognition accuracy of the visual-facial modality. Specifically, our research focused on the recognition of six basic emotion states, namely happiness, sadness, surprise, anger and disgust as well as the emotionless state which we refer to as neutral. We have found that the visual-facial modality may allow the recognition of certain states, such as neutral and surprise, with sufficient accuracy. However, its accuracy in recognizing anger and disgust can be improved significantly if assisted by keyboard-stroke information.	emotion recognition;modality (human–computer interaction);sadness	George A. Tsihrintzis;Maria Virvou;Ioanna-Ourania Stathopoulou;Efthymios Alepis	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.282	facial recognition system;computer vision;computer science;empirical research	AI	-50.94436071013403	-48.240085027201346	108706
8ba590f8851efcbdfd66815e5b39dc3f802c1c93	evaluating the use of a very large-scale presentation and collaboration framework	interactive surface;collaboration;evaluation	"""In this paper we describe the use and evaluation of CubIT, a multi-user, very large-scale presentation and collaboration framework. CubIT is installed at the Queensland University of Technology's (QUT) Cube facility. The """"Cube"""" is an interactive visualisation facility made up of five very large-scale interactive multi-panel wall displays, each consisting of up to twelve 55-inch multi-touch screens (48 screens in total) and massive projected display screens situated above the display panels. The paper outlines the unique design challenges, features, use and evaluation of CubIT. The system was built to make the Cube facility accessible to QUT's academic and student population. CubIT enables users to easily upload and share their own media content, and allows multiple users to simultaneously interact with the Cube's wall displays. The features of CubIT are implemented via three user interfaces, a multi-touch interface working on the wall displays, a mobile phone and tablet application and a web-based content management system. The evaluation reveals issues around the public use and functional scope of the system."""	cubit;content management system;cube;interactive visualization;mobile phone;multi-touch;multi-user;situated;tablet computer;touch user interface;touchscreen;upload;web content	Markus Rittenbruch	2014		10.1145/2611009.2611023	human–computer interaction;engineering;multimedia;world wide web	HCI	-56.329162328812245	-38.3261672650097	108834
1ee17607615bd79978c6c3ee5e1aa0734d2742c9	crouch, hold and engage: spatial aspects of augmented reality browsing	augmented reality browsers;proceedings paper;augmented reality;ergonomics;mobile devices	Displays that use an AR browser to augment a printed poster are nowadays commonplace in many cities. Whilst much research exists on the technical issues and interaction techniques related to such AR displays, currently there has been little research on how these applications are actually used. In this paper, we present the first study reporting on usage comfort and spatial aspects when using an AR browsing app on to browse augmented content on a physical poster. Key findings are that the mean distance users preferred to stand from the poster content was 129 cm (SD = 34 cm) and that standing further from the poster enabled a browsing task to be completed more quickly. Based on our findings we make recommendations on the content and spatial location of AR poster installations.	ar (unix);augmented reality;browsing;interaction technique;printing;while	Ashley Colley;Tuomas Lappalainen;Elisa Määttänen;Johannes Schöning;Jonna Häkkilä	2016		10.1145/2971485.2971527	augmented reality;human–computer interaction;computer science;operating system;mobile device;multimedia;computer graphics (images)	HCI	-48.83534176530371	-40.29226020545611	108913
beef729536b899e06c87ba951f7fbdee74cd571e	the effect of logo location in navigation bar on web brand recognition based on event-related potential		In order to study the cognitive process of brand recognition in different positions (left, middle and right) of the web navigation bar, this paper adopts the Oddball experimental paradigm in event-related potentials combined with behavioral data for experimental investigation. An analytical comparison of the P300 amplitude of the LOGO located in three certain positions in the navigation bar is conducted. The LOGO placed on the left/right can generate larger amplitude than the LOGO placed on the middle. The experimental result shows that LOGO location in navigation bar have a great significance on brand recognition. From neural mechanism of visual cognition processing, ERP can objectively and effectively obtain the implicit feedback of web brand recognition from users, which provides a quantitative index for establishing an accurate evaluation model of web brand recognition.	navigation bar	Yingying Dong;Chengqi Xue;Ningyue Peng;Yafeng Niu	2018		10.1007/978-3-319-91716-0_20	brand awareness;logo;navigation bar;human–computer interaction;event-related potential;cognition;computer science	Robotics	-48.315603026995454	-47.92320664502162	108927
55cb3dbcbe684310a62634408dc44ae5e3836806	supporting gardeners to plan domestic watering: a case study of designing an 'everyday simulation'	engagement;simulation;water supply;sustainability;simulation technique;cognitive engineering;interaction design;water;water demand	We describe a project to design an internet-based application to support gardeners reasoning about the water demands and water supply for their gardens. This application is identified here as an instance of 'everyday simulation'; implying the use of simulation techniques for non-specialist users. Design strategies for everyday simulations are discussed including: the characteristic of simulations of inverting inputs and outputs; simulation by refinement; the embodiment of material constraints; and the educational aspect of simulation for non-specialists.	domestic robot;internet;refinement (computing);simulation	Jon M. Pearce;John Murphy;Wally Smith	2008		10.1145/1517744.1517748	water;simulation;human–computer interaction;computer science;interaction design;management science;water supply;sustainability;cognitive ergonomics	Mobile	-60.06632870561015	-38.4159306816199	108990
8d0650996bc53693ae93653879fafac8ac77f554	navigating, discovering and exploring the web: strategies used by people with print disabilities on interactive websites		The majority of research into web accessibility has focused on identifying and eliminating the problems that people with disabilities encounter when interacting with the Web. In this paper we argue that we need to move away from studying user problems to studying how people with disabilities apply interaction strategies while browsing the Web. In this paper we present a study of 19 print disabled users, including blind, partially sighted and dyslexic people, interacting with a variety of interactive Web 2.0 web applications. The participants undertook tasks using concurrent and retrospective protocols to elicit information about how they interact with web content. The result of this study was a collection of 586 strategic action sequences that were classified into seven different types of strategy. Differences in the application of strategies between the user groups are presented, as well as the most frequent strategies used by each user group. We close the paper by discussing some implications for the design of websites and assistive technologies as well as the future directions for empirical research in accessibility.	assistive technology;interaction;web 2.0;web accessibility;web application;web content;world wide web	Christopher Power;Helen Petrie;David Swallow;Emma Murphy;Blaithin Gallagher;Carlos A. Velasco	2013		10.1007/978-3-642-40483-2_47	human–computer interaction;multimedia	HCI	-55.70853255507169	-43.6374052663246	109135
defc3ae6f9767189ab907e0934c89a1db8906b1e	the relationship between visual interface aesthetics, task performance, and preference	qa75 electronic computers computer science	The purpose of this  thesis  was to develop a conceptual framework that shows the relationship between aesthetics, performance, and preference  in computer interface #R##N#design. To investigate this relationship,  the thesis  focused on investigating the effect of layout aesthetics on visual search performance and preference. #R##N##R##N#This thesis begins with a literature review of related work followed by the rationale for conducting this research, in particular, defining what it meant by visual aesthetics in the context of interface design. #R##N##R##N#Chapter 4  focused on investigating the effect of layout aesthetics on performance and preference. The results  show that  response time  performance and preference  increased #R##N#with increasing  aesthetic level. Preference and performance  were  found to be highly correlated.#R##N##R##N#Chapter 5  focused on investigating users’ layout  preference  when they were not involved with a performance-based task. The results showed, surprisingly,  that preference  was  highest with a  “moderate”  level of  layout aesthetics and lowest with “high” and “low” levels of aesthetics.#R##N##R##N#Chapter 6  focused on investigating visual effort  by measuring eye movement pattern during task performance. The results showed that visual effort increased with a #R##N#decreasing level of aesthetics. #R##N##R##N#Chapter 7  extended the experiment  in Chapter 4  using more “ecologically valid” stimuli. The results essentially replicated the results produced in Chapter 4. #R##N##R##N#Chapter 8  focused on investigating the relationship between  so-called “classical” aesthetics and  background  “expressive”  aesthetics. The results showed  that task #R##N#performance using classical aesthetics was highest with high and low levels of aesthetics and worst  with medium levels  of aesthetics. Performance  with  expressive #R##N#aesthetics increased with decreasing aesthetic levels. #R##N##R##N#This thesis concludes with a conceptual framework for aesthetic design to help interface designers design interfaces that look aesthetically pleasing while at the same time supporting good task performance.		Carolyn Salimun	2013			psychology;aesthetics;multimedia;social psychology	Robotics	-59.20449395293242	-46.98961524485517	109269
867b8ee45773cddca435239e5955909ce60bf337	identifying relevant cs contexts using the miracle question	informatics in context;miracle question;cs in context;mobile phone;content analysis;qualitative study;mobile phones;everyday life	"""The context-oriented approach for teaching CS wants to provide a framework to design teaching units that paint a more interesting picture of CS and show the relevance of CS in the students' everyday life. Our approach for identifying and preparing interesting contexts for children is divided into three steps: First, we start from the IT systems children and youths use every day to get hints for a suitable context. Second, we use a variation of the so-called miracle question to narrow and sharpen the focus onto that context. For the analysis, we use qualitative content analysis following Mayring. Finally, the categories we found are analyzed regarding the use for preparing material to ease the design of teaching units for CS in context. We report from our study with 130 children and the analysis of their questions along the context """"mobile phone""""."""	mobile phone;relevance	Ira Diethelm;Christian Borowski;Thomas Weber	2010		10.1145/1930464.1930477	humanities;computer science;multimedia;communication	HCI	-58.81695899171261	-38.03475081890011	109354
a1202860193e2b7804e6fb28d93eab04299c3c99	who turned the clock? effects of manipulated zeitgebers, cognitive load and immersion on time estimation	clocks;circadian rhythm;virtual environments;sensitivity;virtual reality helmet mounted displays;estimation;sun estimation clocks virtual environments games circadian rhythm sensitivity;games;sun;virtual environments time perception cognitive load;cognitive load;near natural computer generated virtual worlds manipulated zeitgebers cognitive load time estimation virtual reality technologies computer generated immersive virtual environments ive near natural audiovisual stimuli physical world vr research distance underestimation perceptual discrepancies temporal durations immersive head mounted display environment hmd dual task paradigm verbal cognitive load;time perception	Current virtual reality (VR) technologies have enormous potential to allow humans to experience computer-generated immersive virtual environments (IVEs). Many of these IVEs support near-natural audiovisual stimuli similar to the stimuli generated in our physical world. However, decades of VR research have been devoted to exploring and understand differences between perception and action in such IVEs compared to real-world perception and action. Although, significant differences have been revealed for spatiotemporal perception between IVEs and the physical world such as distance underestimation, there is still a scarcity of knowledge about the reasons for such perceptual discrepancies, in particular regarding the perception of temporal durations in IVEs. In this article, we explore the effects of manipulated zeitgebers, cognitive load and immersion on time estimation as yet unexplored factors of spatiotemporal perception in IVEs. We present an experiment in which we analyze human sensitivity to temporal durations while experiencing an immersive head-mounted display (HMO) environment. We found that manipulations of external zeitgebers caused by a natural or unnatural movement of the virtual sun had a significant effect on time judgments. Moreover, using the dual-task paradigm the results show that increased spatial and verbal cognitive load resulted in a significant shortening of judged time as well as an interaction with the external zeitgebers. Finally, we discuss the implications for the design of near-natural computer-generated virtual worlds.	acclimatization;audio media;chronic progressive external ophthalmoplegia;computer-generated holography;depth perception;dual;head-mounted display;health maintenance organizations;immersion (virtual reality);judgment;multimodal interaction;programming paradigm;vr - veterans rand health survey;virtual reality;virtual world;troxacitabine	Christian Schatzschneider;Gerd Bruder;Frank Steinicke	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2518137	games;computer vision;estimation;simulation;sensitivity;computer science;multimedia;cognitive load;time perception;circadian rhythm;statistics	Visualization	-48.39955958682682	-50.60451089270361	109494
7b6630ffd9614d4e039c552b12e2dd03e7e09b23	individuals' process of metaphor interpretations and interestingness cognition		In this paper, we investigated the process of interestingness cognition in metaphor comprehension. We did this from the point of view that the interestingness of a metaphor (e.g., “life is like a gamble”) is related to its interpretative diversity. Two studies were conducted to assess this phenomenon: Study 1 (interpretation-production) and Study 2 (interpretationpresentation study). In Study 1, we observed that a greater number of interpretations were produced from a metaphor that was interesting and easy to understand as compared to one that was less interesting and difficult to understand. In Study 2, we observed that a metaphor was more interesting when more information on simile interpretation was presented. On the basis of these results, we discuss the relationship between the process of metaphor comprehension and metaphor evaluation.	cognition;desktop metaphor;flickr;simile	Tomohiro Taira;Takashi Kusumi;Akira Utsumi	2012				HCI	-58.90979826277458	-47.34750307617835	109580
bfe963a2d6619a7156ea2bfb188473b46ee21369	using the wizard of oz method to train persuasive agents	goal orientation;digital camera;wizard of oz;learning methods;conversational agent	Persuasive conversational agents persuade users to change their attitudes or behaviors through conversation and are expected to be applied as virtual sales-clerks in e-shopping sites. Developing such an agent requires a conversation model that identifies the most appropriate responses to the user's inputs. To create such a model, we propose the approach of combining a learning agent with the Wizard of Oz method; in this approach, a person (called the Wizard) talks to the user pretending to be the agent. The agent learns from the conversations between the Wizard and the user and constructs its own conversation model. In this approach, the Wizard has to reply to most of the user's inputs at the beginning, but the burden gradually falls because the agent learns how to reply as the conversation model grows.#R##N##R##N#Every persuasive conversation has the goal of persuading the user and ends with success or failure. We introduce a goal-oriented conversation model that can represent the success probability of persuasion and a learning method to update the model depending on the success/failure of the persuasive conversation. We introduce a learning persuasive agent that implements the conversation model and the learning method and evaluate it in the situation wherein the agent persuades users to choose one type of digital camera over another. The agent could succeed in reducing the Wizard's inputs by 48%, and, more interestingly, succeeded in persuading 2 users without any help from the Wizard.		Maiko Kawasoe;Tatsuya Narita;Yasuhiko Kitamura	2008		10.1007/978-3-540-85834-8_15	simulation;computer science;artificial intelligence;goal orientation;dialog system;multimedia;world wide web	AI	-52.45714709399706	-48.70173645137093	109767
87010ee5c144ac8fda3c21fb158a4833c42fa010	analysing privacy in visual lifelogging		The visual lifelogging activity enables a user, the lifelogger, to passively capture images from a first-person perspective and ultimately create a visual diary encoding every possible aspect of her life with unprecedented details. In recent years, it has gained popularities among different groups of users. However, the possibility of ubiquitous presence of lifelogging devices specifically in private spheres has raised serious concerns with respect to personal privacy. In this article, we have presented a thorough discussion of privacy with respect to visual lifelogging. We have readjusted the existing definition of lifelogging to reflect different aspects of privacy and introduced a first-ever privacy threat model identifying several threats with respect to visual lifelogging. We have also shown how the existing privacy guidelines and approaches are inadequate to mitigate the identified threats. Finally, we have outlined a set of requirements and guidelines that can be used to mitigate the identified threats while designing and developing a privacy-preserving framework for visual lifelogging.	encode;first-person (video games);holism;lifelog;privacy;privacy policy;ramification problem;requirement;software developer;threat model;traction teampage	Md. Sadek Ferdous;Soumyadeb Chowdhury;Joemon M. Jose	2017	Pervasive and Mobile Computing	10.1016/j.pmcj.2017.03.003	lifelog;privacy by design;internet privacy;computer science;computer security;threat model	HCI	-57.61924067178717	-43.91554348278629	110114
ca32b565a6992fffedc6ac72d96063e87c44416f	designing, engineering, and evaluating gesture user interfaces		This course will introduce participants to the three main stages of the development life cycle of gesture-based interactions: (ul) how to design a gesture user interface (UI) by carefully considering key aspects, such as gesture recognition techniques, variability in gesture articulation, properties of invariance (sampling, direction, position, scale, rotation), and good practices for gesture set design, (ii) how to implement a gesture UI with existing recognizers, software architecture, and libraries, and (iii) how to evaluate a gesture user interface with the help of various metrics of user performance. The course will also cover a discussion about the wide range of gestures, such as touch, finger, wrist, hand, arm, and whole-body gestures. Participants will be  engaged to try out various tools on their own laptops and will leave the course with a set of useful resources for prototyping and evaluating gesture-based interactions in their own projects.	biconnected component;finite-state machine;gesture recognition;interaction;laptop;library (computing);safety engineering;sampling (signal processing);software architecture;software development process;spatial variability;user interface	Jean Vanderdonckt;Radu-Daniel Vatavu	2018		10.1145/3170427.3170648	user interface design;software development process;gesture recognition;human–computer interaction;gesture;software architecture;computer science;user interface	HCI	-51.77323061428211	-44.42446258097738	110265
49dd13f27e51649134a2a5fdd83101d345ef566b	explorations in the speakers' interaction experience and self-assessments		The paper focuses on the interlocutors' self-evaluation in Finnish and Estonian first encounter dialogues. It studies affective and emotive impressions of the participants after they have met the partner for the first time, and presents comparison of the evaluation along the gender, age and education parameters. The results bring forward some statistically significant differences between the two groups, and point to different, culturally determined evaluation scales. The paper discusses the impact of the findings on the complex issues related to the evaluation of automatic interactive systems, and carries over to such applications as intelligent training and tutoring systems, and interactions with robots, encouraging further studies on the interlocutors' engagement in interaction and their evaluation of the success of the interaction.	impression (online media);interaction;robot	Kristiina Jokinen	2012			simulation	HCI	-54.5892129599201	-48.2548070737586	110310
bf854a7f07e09ab5389f9311e8f281cebc38b737	development of culture-specific gaze behaviours of virtual agents		Gaze plays an important role in human-human communication. Adequate gaze control of a virtual agent is also essential for successful and believable human-agent interaction. Researchers in intelligent virtual agents have developed gaze control models by taking account of gaze duration, frequency and timing of gaze aversion. However, none of them have considered cultural differences in gaze behaviours. We aim to investigate cultural differences in gaze behaviours and their perception, by developing virtual agents with Japanese gaze behaviours, western gaze behaviours, their hybrid gaze behaviours, and full gaze behaviours, and compare their effects on the impressions of the agents and interactions. This position paper proposes our research agenda, describes the implemented gaze models, and our experimental design.	design of experiments;intelligent agent;interaction;javaserver pages;risk aversion	Tomoko Koda;Taku Hirano;Takuto Ishioh	2017		10.5220/0006229402910295	gaze;computer science;artificial intelligence;machine learning;human–computer interaction	HCI	-53.116440468862066	-49.97439008182361	110407
8585c8e558dcbc2a92bb08e78b8dd3009e7954ef	a framework for the multimodal joint work of turn construction in face-to-face interaction	conversation analysis;nonverbal communication;gesture;multimodality;gesture studies	We propose a framework for understanding the multimodal joint work of turn construction in face-to-face interaction. Using concepts from conversation analysis, nonverbal communication, and gesture studies, in a qualitative analysis of face-to-face interaction, we observe that, collaboratively and in a joint work, participants produce moves, within the current-speaker’s turn, that allow them to deal with possible moves that could compromise the projectable trajectory of the interaction in progress. Working at the micro level of interaction, we propose a framework that will allows a better understanding of how a turn can be collaboratively produced and how other levels of sequence organization can be produced in order to achieve the desired social-agreement outcome. 2016 Elsevier B.V. All rights reserved.	ampersand;artificial intelligence;feedback;flowchart;gesture recognition;holism;multimodal interaction;norm (social);parallel computing;unity	Cacilda V. Lima;João Ranhel	2017	Cognitive Systems Research	10.1016/j.cogsys.2016.07.005	psychology;nonverbal communication;simulation;artificial intelligence;linguistics;communication;gesture	AI	-54.63536873189215	-46.94529924903663	110542
23da57fcb4727065d5a0edb4e44533aefeca3d53	rhythm modeling, visualizations and applications	context aware computing;instant messaging;cmc;user perception;user preferences;user modeling;visualization;rhythms;awareness;temporal pattern;computer mediated communication;cscw;user model	"""People use their awareness of others' temporal patterns to plan work activities and communication. This paper presents algorithms for programatically detecting and modeling temporal patterns from a record of online presence data. We describe analytic and end-user visualizations of rhythmic patterns and the tradeoffs between them. We conducted a design study that explored the accuracy of the derived rhythm models compared to user perceptions, user preference among the visualization alternatives, and users' privacy preferences. We also present a prototype application based on the rhythm model that detects when a person is """"away"""" for an extended period and predicts their return. We discuss the implications of this technology on the design of computer-mediated communication."""	algorithm;computer-mediated communication;prototype;sensor	James Begole;John C. Tang;Rosco Hill	2003		10.1145/964696.964698	user modeling;human–computer interaction;computer science;multimedia;world wide web;computer-mediated communication	HCI	-55.92393168657573	-44.495855899241825	110612
20e3e9456001e1a131b23dba1cd58a1e402da3a7	uma: a system for universal mathematics accessibility	universal mathematics accessibility;notation-independent tool;multi-institution collaboration;uma system;unsighted individual;aural navigation;sighted individual;inter-convert mathematical document;universal access	We describe the UMA system, a system developed under a multi-institution collaboration for making mathematics universally accessible. The UMA system includes translators that freely inter-convert mathematical documents transcribed in formats used by unsighted individual (Nemeth, Marburg) to those used by sighted individuals (LaTeX, Math-ML, OpenMath) and vice versa. The UMA system also includes notation-independent tools for aural navigation of mathematics. In this paper, we give an overview of the UMA system and the techniques used for realizing it.	accessibility;uniform memory access	Arthur I. Karshmer;Gopal Gupta;Enrico Pontelli;Klaus Miesenberger;N. Ammalai;Deepa Gopal;Mario Batusic;Bernhard Stöger;B. Palmer;Hai-Feng Guo	2004	ACM SIGACCESS	10.1145/1029014.1028642	simulation;universal design;computer science;multimedia;world wide web	Theory	-48.92301196217504	-39.30974013687368	110729
b49fd45a3fa9555b806324c3bf07f9cd1ad7a864	reminder objects in the connected home of the future and beyond		This paper presents best practices of how to design reminder objects. Reminder objects are digitally augmented everyday objects which break down and communicate complex information via sensory input and output.  In the first section of this paper, we introduce reminder objects --what they are and how they work.  We describe our understanding of computing and the interaction between humans and technology in detail in the second section. In section three, we present our vision how reminder objects can enrich the user's experience by combining different objects.  We show corresponding examples of our work in this field in the two following sections. Two scenarios -- checking the weather and navigating the city -- will illustrate our understanding of reminder objects.  The paper concludes with a discussion of the presented work and an outlook about the future of reminder objects.	best practice;input/output;microsoft outlook for mac	Martina Uhlig;Henrik Rieß;Peter Klein	2017		10.1145/3056540.3064949	contextual design;human–computer interaction;simulation;usability;computer science;multimedia;best practice;user experience design;input/output;home automation;user-centered design	HCI	-54.50586517382684	-38.25891911984879	110928
368aed5119514186cd40c8a1cb340b2b3f9871ca	users' participation to creative design of new solutions for mobility: an exploratory study	creative design;transportation;user involvement	As transportation is one of the main environmental concerns, design of new solutions in this area constitutes a priority for the European Union. This study aims to compare different factors of user involvement in design in terms of obtained contributions of users, whether positive or negative. Based on the Critical Incidents Technique, we interviewed 23 experts (especially in transportation), asking them to describe their positive and negative experiences when they collaborated with users in design projects. This resulted in the collection of 71 Critical Incidents (40 positive and 31 negative) that were then characterized along 6 coding categories. We conducted a Multiple Correspondence Analysis (MCA) on the corresponding contingency table and found two main axes that structured the incidents. The interpretation of the axes indicated that individual user involvement allows obtaining rich information about users' needs whereas collective user involvement allows enhancing user acceptance. Moreover, users involved at later stages of development suggest mainly ideas for service improvement, whereas users involved at earlier stages of innovation suggest creative ideas provided that they are supplied tools to develop their projection skills.	contingency table;experience;multiple correspondence analysis	Peter Richard;Jean-Marie Burkhardt;Todd Lubart	2014		10.1145/2637248.2637258	transport;simulation;human–computer interaction;engineering;multimedia	HCI	-61.318057503447015	-40.804617326305795	110929
5d81112167061326b37435e0b582c6c567bf30fd	"""""""this has to be the cats"""" - personal data legibility in networked sensing systems"""	ethnography;networked sensing systems;articulation work;personal data;accountability;privacy	Notions like 'Big Data' and the 'Internet of Things' turn upon anticipated harvesting of personal data through ubiquitous computing and networked sensing systems. It is largely presumed that understandings of peopleâs everyday interactions will be relatively easy to âread offâ of such data and that this, in turn, poses a privacy threat. An ethnographic study of how people account for sensed data to third parties uncovers serious challenges to such ideas. The study reveals that the legibility of sensor data turns upon various orders of situated reasoning involved in articulating the data and making it accountable. Articulation work is indispensable to personal data sharing and raises real requirements for networked sensing systems premised on the harvesting of personal data.	biconnected component;big data;interaction;internet of things;personally identifiable information;requirement;situated;ubiquitous computing	Peter Tolmie;Andy Crabtree;Tom Rodden;James A. Colley;Ewa Luger	2016		10.1145/2818048.2819992	human–computer interaction;telecommunications;computer science;ethnography;internet privacy;communication;management;privacy;social psychology;world wide web;computer security;anthropology	HCI	-58.66033029983964	-39.51503879520718	111110
c83bf3c174a5348af7e27769364c6031ae251f57	exploring the design of game enjoyment through the perspectives of novice game developers	flow theory;game enjoyment;game design education;global game jam;gameflow	In this collaborative research, the authors explored the ways in which novice game designers utilize strategies and methods to promote player enjoyment. Adopting the GameFlow model and an exploratory survey, this study examined the perceptions of the 2011 Global Game Jammers at three different sites in regards to designing games that result in player enjoyment. The results of the study were consistent with the findings of the current literature on game enjoyment, and insinuated the notion of interconnected relationships between each GameFlow element. The study also suggested the existence of five latent groups of novice game designers who differed in their preference or perceived importance of game enjoyment elements. Lastly, there appeared to be an association between individual characteristics and perceptions of game flow design elements among novice game designers.		Fengfeng Ke;Nilay Yildirim;Jacob Enfield	2012	IJGCMS	10.4018/jgcms.2012100104	non-cooperative game;video game design;game design;simulation;game mechanics;game developer;multimedia;game design document;social psychology	HCI	-58.725536786910254	-47.54354829469955	111151
400aa8e53894efa64b9ac59c83ee9a2033e3598a	does locality make a difference? assessing the effectiveness of location-aware narratives	locative media;location aware narratives;narrative transportation;presence	Please cite this article in press as: Karapanos, E. Comput. (2012), http://dx.doi.org/10.1016/j.intc With the increasing sophistication of mobile computing, a growing interest has been paid to locative media that aim at providing immersive experiences. Location aware narratives are a particular kind of locative media that aim at ‘‘telling stories that unfold in real space’’. This paper presents a study that aimed at assessing an underlying hypothesis of location-aware narratives: that the coupling between the physical space and the narrative will result in increased levels of immersion in the narrative. Forty-five individuals experienced a location-aware video narrative in three locations: (a) the original location that contains physical cues from the narrative world, (b) a different location that yet portrays a similar atmosphere, and (c) a location that contains neither physical cues nor a similar atmosphere. Significant differences were found in users’ experiences with the narrative in terms of immersion in the story and mental imagery, but not with regard to feelings of presence, emotional involvement or the memorability of story elements. We reflect on these findings and the implications for the design of location-aware narratives and highlight questions for further research. 2012 British Informatics Society Limited. All rights reserved.	cognitive science;emoticon;experience;haptic technology;immersion (virtual reality);informatics;linkage (software);locality of reference;location awareness;location-based game;maxima and minima;mobile computing;recommender system;virtual reality;virtual world	Evangelos Karapanos;Mary Barreto;Valentina Nisi;Evangelos Niforatos	2012	Interacting with Computers	10.1016/j.intcom.2012.03.005	narrative inquiry;narrative criticism;multimedia	HCI	-56.87669984420561	-39.8472643668686	111187
e31b62725d9d2a7cf961df4f750eef908ca393cf	applying insights from film theory and cinematic technique to create a sense of community and participation in a distributed video environment	sense of community	Abstract#R##N##R##N#New tools for mediating interaction require fresh theoretical perspectives that can assist in creating constructive climates for communication and learning. In the past decade distributed video systems have proliferated as tools for instruction and communication. These systems promise increased personal interaction by approximating natural communication through visual contact and verbal exchange. However, research on the use of these tools has consistently pointed out the dissatisfaction of users and the limitations placed on meaningful, engaged communication (Debough, 1999; Simonson et al., 2000). The problem centers on fostering co-presence and engagement among those who use interactive, video-based systems for distance education or work-related activities. The purpose of this paper is to enrich the conversation regarding how to address these issues of communication and engagement. I argue that because most distance education or electronic meeting systems employ variations of two-way compressed or digital video, they are essentially filmic media, and as such users of these distributed visual environments can capitalize on insights from the rich theoretic base of film theory and cinematic technique to engage meaningful interaction and support responsive communication. An illustrative case study in which these techniques are used is presented.		Joan M. Mazur	2000	J. Computer-Mediated Communication	10.1111/j.1083-6101.2000.tb00351.x	psychology;social science;simulation;computer science;multimedia;sociology;communication;social psychology;world wide web	HCI	-59.181956352154096	-39.04235368566983	111460
59ed363a046dee0061c8349a4d68f67ed96651ed	usability analysis for redesign of a caribbean academic library web site: a case study	information architecture;sample size;dk atira pure researchoutput researchoutputtypes contributiontojournal article;usability evaluation;usability testing;communications;auditing;user study;focus group;west indies;user studies;interface design;web design;worldwide web;user behaviour;design;organisational change;academic libraries;user satisfaction;design methodology	Purpose – This paper seeks to present a usability evaluation of the web site of the Main Library of the St Augustine Campus of the University of the West Indies (UWI) to get users and site visitors to identify the major strengths and weaknesses of the site and to incorporate the results and participant feedback into a redesign that reflects users’ intuitions rather than those of the site developers and librarians. Design/methodology/approach – A combination of experimental and respondent research strategies was used to evaluate usability. These included survey questionnaires, focus groups, formal usability testing and card sort. In addition, both usability heuristics and ISO guidelines were used to assess effectiveness, learnability, usefulness and user satisfaction. Respondent strategies used a sample size of 529 participants for the self-completion questionnaires and 16 participants in the focus group sessions. Experimental strategies combined observation of 21 individual participants and three groups of participants in the usability tests. In the card sort protocol nine individual participants and three groups of participants were observed. Findings – The findings identified challenges in the site’s information architecture (labelling and organisation) and in the interface design. Research limitations/implications – More ethnographic approaches are needed to elicit distinctive Caribbean user behaviours. Practical implications – The study concludes that similar usability evaluations should be undertaken at the other UWI campus library web sites and that usability training should be incorporated into the culture of the library organisation. Critical next steps for the web designer are also suggested. Originality/value – The paper presents issues of organisational change and the impact of technology on the relationship between systems and user services librarians.	focus group;heuristic (computer science);information architecture;learnability;librarian;organizational behavior;usability testing;web design	Richard Rogers;Hugh Preston	2009	OCLC Systems & Services	10.1108/10650750910982584	pluralistic walkthrough;web usability;design;usability;web design;human–computer interaction;computer science;system usability scale;interface design;focus group;multimedia;world wide web;usability lab;information architecture	HCI	-62.286278623065435	-47.96319977762973	111524
bc34cda2d699e32f16c2686de6c0c6cfb0fb7cce	exploring social awareness: a design case study in minimal communication		Computer-mediated communication technology is ubiquitous in today»s society. However, the design of these technologies often takes a screen-based approach and requires users to adopt new usage conventions. While these methods have been widely successful in helping individuals communicate, we take a step back in this paper and explore the design implications of a simpler tangible system for keeping in touch. This system consists of a pair of artificial electronic flowers, which connect and transmit information to each other. Our contribution is not in the actual implementation, but rather in the design implications that follow. In our modest evaluation we found participants using our system in informal, relaxed and sometimes novel ways.	code;computer-mediated communication;field research;futures studies;information system;mobile app;peripheral;smartphone	Torben Wallbaum;Maria Rauschenberger;Janko Timmermann;Wilko Heuten;Susanne C. J. Boll	2018		10.1145/3170427.3174365	human–computer interaction;social consciousness;computer science;information and communications technology	HCI	-57.94044601408179	-40.925131865278345	111712
4eb0bea81762491fbdda84ac85f9b9714520ea24	supporting privacy by preventing misclosure	focus group;disclosure;older adult;aging;technology acceptance;ubiquitous computing;error;diary study;privacy;misclosure	Despite extensive concerns about privacy and multiple potential consequences of revealing personal information, many users still experience invasions of privacy when interacting with technology. For this reason, privacy is an important and complex issue in HCI. This thesis focuses on specific psychological issues of privacy in HCI, primarily the accidental disclosure of information or misclosure. Using multiple methods including focus groups, a diary study, and an experimental manipulation, this thesis seeks to catalog the incidence of such errors, identify the interface issues associated with each type of error, and provide design recommendations for preventing each type of disclosure error.	diary studies;error-tolerant design;focus group;human–computer interaction;incidence matrix;personally identifiable information;privacy	Kelly E. Caine	2009		10.1145/1520340.1520448	disclosure;privacy software;human–computer interaction;privacy by design;computer science;focus group;internet privacy;privacy;world wide web;computer security;ubiquitous computing	HCI	-58.21531971351269	-43.314721978380454	111903
429125fe550fdb2963c9718b10e3aff2cd14a632	the information discovery framework	divergent thinking;berrypicking;evaluation method;information foraging;information discovery;mental models;working memory;information seeking;mental model	This paper continues the movement from technology centered to human centered approaches in the study of tasks that involve finding, understanding, and using information, and tools that support these tasks. The iterative role of information as a stimulus to cognition is considered. The information discovery framework consists of a flowchart of connected human cognitive and digital computer states and processes. The purpose of the framework is to inform the design of tools for finding and using information. Divergent thinking laboratory tasks serve as an evaluation method.	cognition;computer;flowchart;information discovery;iteration	Andruid Kerne;Steven M. Smith	2004		10.1145/1013115.1013179	divergent thinking;computer science;knowledge management;artificial intelligence;personal information management;working memory	HCI	-62.17558068980228	-39.17196884932519	112034
cd9732bdf2dca696c1a75540ab19350856f2a87c	questionnaires for evaluation in information visualization	computer and information science;information visualization;evaluation;data och informationsvetenskap;subjective usability measurement	The position taken in this paper is that the availability of standardized questionnaires specifically developed for measuring users' perception of usability in evaluation studies in information visualization would provide the community with an excellent additional instrument. The need for such an instrument is evident for several important reasons. Pursuing the development, validation and use of questionnaires will add significantly to the evidence base necessary for the community to guide the production of high-quality visualization techniques, facilitate adoption by users, promote successful commercialization and guide future research tasks.	information visualization;usability	Camilla Forsell;Matthew D. Cooper	2012		10.1145/2442576.2442592	human–computer interaction;engineering;knowledge management;multimedia	HCI	-61.76138961003801	-45.46033146075038	112067
a725e6dfd6a09778ea4dff7b8d3f47348e8c41dd	unipass: design and evaluation of a smart device-based password manager for visually impaired users	smart device;password manager;authentication;accessibility;visual impairments	Visually impaired users face various challenges in web authentication. We designed UniPass, an accessible password manager for visually impaired users based on a smart device. To evaluate UniPass, we tested and compared UniPass with two commercial password managers: LastPass, a popular password manager and StrongPass, a smart device-based password manager. Our study results of ten users, six blind and four with low vision, suggest that password managers are a promising authentication approach for visually impaired users. Participants using UniPass had the highest task completion rate and took the shortest time to complete an authentication related task. Furthermore, the majority (seven out of ten) of our participants preferred UniPass over LastPass and StrongPass.	authentication;lastpass;password manager;smart device	Natã M. Barbosa;Jordan Hayes;Yang Wang	2016		10.1145/2971648.2971722	cognitive password;password policy;computer science;accessibility;authentication;internet privacy;one-time password;world wide web;computer security	HCI	-48.732163710621776	-44.45191123107041	112295
21347ca44f40621aefd438e2c82f9a99d87de986	my2cents: enabling research on consumer-product interaction	business model;consumers;other research area;barcode scanning;products;retail;shopping	Barcode scanners for smartphones enable mobile product-centric services for consumers. We have developed a mobile app that enables consumers to share their use of and opinions about products with their friends and others. Our goal is to establish a product-centric information stream generated by users to benefit other consumers and retail businesses and to enable large-scale research on consumer-product interaction. This paper describes our approach to create a sustainable service. We report first experiences and an initial evaluation after releasing the app to the public, give an overview over possible business models, and discuss some of the challenges we experienced during implementation.	barcode;collaborative filtering;experiment;interaction;microsoft outlook for mac;mobile app;mobile phone;smartphone;the quality of life;usability	Stephan Karpischek;Florian Michahelles;Elgar Fleisch	2011	Personal and Ubiquitous Computing	10.1007/s00779-011-0426-9	business model;product;consumer;retail	HCI	-54.73784903664176	-40.575419937768345	112310
fbebcdd2b23225cded29fee028957165218574f6	bibliometric mapping of science in a policy context	bibliometrie;representacion conocimientos;graphical interface;validacion;sciences;information mapping;bibliometria;politica cientifica;scientific policy;methode;science policy;ciencia;interfase;internet;information representation;interface;bibliometrics;cartographie information;validation;representation information;knowledge representation;representation connaissances;metodo;politique scientifique;method	Despite the promising introduction of bibliometric maps of science in a science policy context in the nineteen seventies, they have not been very successful yet. It seems, however, that only now they are becoming acknowledged as a useful tool. This is mainly due to the developments and integration of hypertext and graphical interfaces. Because of this, the strength of such navigation tools becomes obvious. The communication through the Internet enables the field expert (as a kind of peer review) as well as the user (from a science policy context) to contribute to the quality of the map and the interface. Moreover, the interface can provide suggestions to answer policy-related question, which is the initial purpose of such maps.	bibliometrics;graphical user interface;hypertext;internet;map	Ed C. M. Noyons	2001	Scientometrics	10.1023/A:1005694202977	knowledge representation and reasoning;method;the internet;social science;bibliometrics;computer science;information mapping;artificial intelligence;interface;data mining;graphical user interface	HCI	-61.82448397485322	-49.00550295160693	112425
56bc64a56b4648943ee86f651712eaa072cd1a4a	timing control of utterance and gesture in interaction between human and humanoid robot	humanoid robot;human interaction;grasping;social interaction;socially interactive robots;social sciences;mobile robots;natural human robot communication;human robot interaction;social sciences humanoid robots mobile robots;nonverbal robot functions;socially interactive robots human humanoid robot interaction nonverbal robot functions natural human robot communication interpersonal interaction scenario robot timing control;humanoid robots;socially interactive robot human robot interaction timing control elderly persons social robot;elderly person;human humanoid robot interaction;interpersonal interaction scenario;mathematical model;timing control;humans;robot timing control;correlation;elderly persons;timing humanoid robots robot kinematics human robot interaction communication system control robot control computational intelligence psychology speech senior citizens;socially interactive robot;social robot;robot kinematics;timing	Towards establishing future-oriented relations between humans and robots, not only verbal, but also nonverbal robot functions have been studied. However, it is not clear how these different functions should be combined and implemented in robots in order to achieve ‘natural’ human-robot communication or interaction. In this paper, we focus on the timing for the coordination between utterance as a verbal function and body motion as a nonverbal function. To begin with, we investigated the temporal order and correlation between utterance and gesture in an interpersonal (human-human) interaction scenario as a preliminary experiment (Experiment 1). Then, we controlled the robot's response timing based on findings of the first experiment and evaluated the effectiveness of the robot's timing control in human-robot interaction (Experiment 2). It was shown that elderly participants significantly preferred the controlled robot's response. In addition, the timing of utterance and gestures affected the impression of the robot and interpretation of the verbal message. These results are important findings for designing socially interactive robots for the aging society.	humanoid robot;humans;human–robot interaction	Yumiko Muto;Shoji Takasugi;Tomohito Yamamoto;Yoshihiro Miyake	2009	RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2009.5326319	human–robot interaction;social relation;computer vision;simulation;computer science;humanoid robot;artificial intelligence	Robotics	-50.972854132099705	-50.508572384295356	112525
0caa7194761752d88d35b69601de1da9349a0a02	smart: the smart meeting room task at isl	human interaction;communication system;human computer interaction;business data processing;humans switches laboratories computer interfaces interactive systems information filtering information filters costs monitoring merging;business data processing interactive systems user interfaces;audio analysis;interactive systems;user interfaces;monitoring smart smart meeting room task isl integrated meeting support rooms interactive meeting support rooms	As computational and communications systems become increasingly smaller, faster, more powerful, and more integrated, the goal of interactive, integrated meeting support rooms is slowly becoming reality. It is already possible, for instance, to rapidly locate task-related information during a meeting, filter it, and share it with remote users. Unfortunately, the technologies that provide such capabilities are as obstructive as they are useful – they force humans to focus on the tool rather than the task. Thus the veneer of utility often hides the true costs of use, which are longer, less focused human interactions. To address this issue, we present our current research efforts towards SMaRT: the Smart Meeting Room Task. The goal of SMaRT is to provide meeting support services that do not require explicit human-computer interaction. Instead, by monitoring the activities in the meeting room using both video and audio analysis, the room wil l be able to react appropriately to users’ needs and allow the users to focus on their own goals.	human–computer interaction;norm (social);isl	Alexander H. Waibel;Tanja Schultz;Michael Bett;Matthias Denecke;Robert G. Malkin;Ivica Rogina;Rainer Stiefelhagen;Jie Yang	2003		10.1109/ICASSP.2003.1202752	interpersonal relationship;simulation;human–computer interaction;telecommunications;computer science;multimedia;user interface;audio analyzer;communications system	HCI	-49.41109370765773	-38.48959934531211	112576
e2f46d5156af314be254224b231b22f185ca7211	calls for interaction: the more the better? user experience of 3d carousel and additional interaction techniques	user engagement;interaction techniques;user experience;3d carousel	We perform a user study to investigate the psychological consequences of adding interaction techniques to the interface. In a betweensubjects experiment (N = 143), we explore how (i) variations in sheer number of interaction techniques and (ii) addition of a novel technique, i.e., 3D carousel, influence the volume of users’ actions, their memory, perceptions of interactivity, as well as their attitudes and behaviors toward a website. Power usage is examined as a potential moderator. First-cut findings from self-reports and log data indicate that the 3D carousel feature has a strong impact on user experience, both positive and negative. It also moderates the curvilinear effect of adding traditional interaction techniques to the interface.	google moderator;interaction technique;interactivity;usability testing;user experience	S. Shyam Sundar;Saraswathi Bellur;Jeeyun Oh;Haiyan Jia	2011		10.1007/978-3-642-23768-3_64	user experience design;simulation;human–computer interaction;computer science;multimedia	HCI	-56.86790020943226	-45.128414080919306	112605
4ba482978ca9012a77ad411423b88b5b0a6f7d24	software-evaluation based upon iso 9241 part 10	visual display terminal;graphic user interface;system development;software evaluation	In this article the software evaluation instrument ISONORM 9241/10 is presented. This instrument was developed from ISO 9241: Ergonomic requirements for office work with visual display terminals (VDTs), Part 10: Dialogue Principles. The capabilities of this instrument are shown through two methods. First, two different kinds of computer-systems (with and without graphical user interface) are evaluated for their conformity to ISO 9241/10. Second, a procedure is shown in which ISONORM 9241/10 is used as a basis for moderation with user-groups, when in the beginning of a designprocess, through the forum of a participative system-development, first demands are formulated. It is shown that the user-friendliness of systems with GUI is judged to be significantly superior in all seven principles of ISO 9241/10, to those systems without GUI. In the user-group meeting, through ISONORM 9241/10, many concrete recommendations for a new software to be developed could be generated.		Jochen Prümper	1993		10.1007/3-540-57312-7_74	user interface design;embedded system;human–computer interaction;computer science;computer graphics (images)	Vision	-62.08105382339026	-47.67009120703993	112962
20f0fb1fbcec009b67a1eb75b43621850bf7d1d9	exploring emotional preference for smartphone applications	gyroscopes;pilot study;preference matrix emotional preference smartphone application human behaviour touch interface embedded sensor accelerometer gyroscope human emotion recognition user touch behaviour off line analysis;decision tree;touch sensitive screens;sensors;behavioural sciences computing;human behaviour;smart phones;mobile computer;speech;emotion recognition;psychology;matrix algebra;touch sensitive screens accelerometers behavioural sciences computing emotion recognition gyroscopes haptic interfaces matrix algebra smart phones;emotion recognition humans mobile communication psychology sensors decision trees speech;machine intelligence;mobile communication;humans;machine intelligence affective computing emotion recognition mobile computing;haptic interfaces;mobile computing;decision trees;accelerometers;affective computing	Emotion is an essential element of human behaviours. In this research, we investigated human behaviours related with the touch interface on a smartphone as a way to understand users' emotional states. As modern smartphones have various embedded sensors such as accelerometer and gyroscope, we aim to utilize data from these embedded sensors for recognizing human emotion and further finding emotional preferences for smartphone applications. We collected 12 attributes from 3 sensors during users' touch behaviours, and recognized seven basic emotions with off-line analysis. Finally, we generated a preference matrix of applications by calculating the difference between prior and posterior emotional states to the application usage. The pilot study showed 0.57 of an average f1-measure score (and 0.82 with decision tree based methods) with 455 cases of touch behaviour. We discovered that a simple touching behaviour has a potential for recognizing users' emotional states.	authentication;decision tree;embedded system;emotion recognition;f1 score;gyroscope;mobile app;online and offline;preference learning;sensor;smartphone;touch user interface;window function	Hyun-Jun Kim;Young Sang Choi	2012	2012 IEEE Consumer Communications and Networking Conference (CCNC)	10.1109/CCNC.2012.6181095	computer vision;computer science;operating system;decision tree;multimedia;mobile computing	Mobile	-49.56202475687529	-48.12909473302854	113007
4a372fa5ed3955985665c645561e1d56019d0bb1	multi-channel coverage for a dangerous australians museum exhibit		Dangerous animals fascinate people; and Australia has more than its fair share of them. This paper outlines our work in the design of two different museum applications that are able to reuse a single-source of content to cater for the specific needs of their target audience. The underlying goal of this work is to show how museum content can be made more accessible, more interactive, and personalised to different users and their situational context. This is achieved through the use of modern computing platforms like mobile phones and interactive wall displays that support ubiquitous, context-sensitive, and personalised information delivery.	context-sensitive help;mobile phone;personalization	Rainer Wasinger;Matthew Wardrop;Anthony Collins;Michael Fry;Judy Kay;Bob Kummerfeld	2012				HCI	-54.41132044972624	-40.50411217822367	113135
e73d53ed870cdc440be8666c4a1bb53f11996d5a	canefitter: investigation on appropriate cane selection and proper cane use for the elderly	the elderly;non invasive gait analysis;cane fitting;adaptive teaching;intelligent cane recommendation;shared view	With the aging population, the demand of canes to support independent living of the elderly has greatly emerged. However, most elders with canes have never been instructed on the proper use and often have inappropriate devices. This work presents CaneFitter, a cane fitting system that consists of two major components: 1) recommendation module, which generates adaptive recommendations on better fitting canes based on the efficient gait analysis technique; 2) teaching module, where the image of an elderly user segmented from the live video is merged with the training video, allowing the user to learn the cane use in an immersive augmented virtual environment. Also, the user is adaptively instructed to correct their postures by using automatic posture matching techniques. We deploy CaneFitter in an elderly community and collect constructive feedback for further system improvement.	gait analysis;poor posture;virtual reality	Meiyu Huang;Yiqiang Chen;Wen Ji;Xiaojuan Ma;Jing Zhang;Yuguang Fan;Lianjun Dai	2015		10.1145/2800835.2800927	embedded system;simulation;artificial intelligence	HCI	-51.99399198503857	-44.16169663576143	113347
225e437758468aeba88d720ca268ec16e175bc62	empowering educators with google's android app inventor: an online workshop in mobile app design	selected works;bepress	"""Introduction Mobile devices such as smartphones are vastly gaining popularity (Johnson, Levine, Smith, & Stone, 2010) due to their relatively strong computing capability built into small sizes, their Internet connectivity, and the availability of various types and easy-to-use mobile software applications ("""" mobile apps """"). It is estimated that by 2015, 80% of people accessing the Internet will do it through cell phones (Johnson, Smith, Willis, Levine, & Haywood, 2011). Mobile technologies are now gaining increased attention and popularity across education sectors, which has led to innovation in mobile app design (Johnson et al., 2010)."""	app inventor for android;earl levine;mobile app;mobile computing;mobile operating system;mobile phone;play store;smartphone;visual programming language	Yu-Chang Hsu;Kerry Rice;Lisa Dawley	2012	BJET	10.1111/j.1467-8535.2011.01241.x	psychology;human–computer interaction;multimedia;world wide web;android	HCI	-55.9668618890648	-40.50818526175952	113352
401a328e833294f25e967fe8b2e8c4b402dbb7e7	ethically-guided emotional responses for social robots: should i be angry?		Emotions play a critical role in human-robot interaction. Human-robot interaction in social contexts will be more effective if robots can understand human emotions and express (display) emotions accordingly as a means to communicate their own internal state. In this paper we present a novel computational model of robot emotion generation based on appraisal theory and guided by ethical judgement. There have been recent advances in developing emotion for robots. However, despite the extensive research on robot emotion, it is difficult to say if a particular robot is exhibiting appropriate emotions or even showing that it can empathize with humans by exhibiting similar emotions to humans in the same situation. A key question is - to what extent should a robot direct anger toward a young child or an elderly person for an act that it should show anger towards an ordinary adult to signal danger or stupidity? Realizing the need for an ethically guided approach to emotion expressions in social robots as they interact with people, we present a novel Ethical Emotion Generation System (EEGS) for the expression of the most acceptable emotions in social robots.	social robot	Suman Ojha;Mary-Anne Williams	2016		10.1007/978-3-319-47437-3_23	cognitive psychology;psychotherapist;social psychology	Robotics	-52.503108980199904	-50.79686728328553	113387
e9be3bf12fff721131d5ff1a1ce3d2da0ff62701	improving intelligibility and control in ubicomp	feedforward;user interface;ubicomp;explanations;feedback;end user configuration;control;intelligibility;interaction technique	Users often become frustrated when they are unable to understand and control a ubicomp environment. Previous work has suggested that ubicomp systems should be intelligible to allow users to understand how the system works and controllable to let users intervene when the system makes a mistake. In my thesis, I focus on novel user interfaces and interaction techniques to support intelligibility and control.	intelligibility (philosophy);interaction technique;ubiquitous computing;user interface	Jo Vermeulen	2010		10.1145/1864431.1864493	simulation;human–computer interaction;computer science;feedback;user interface;ubiquitous computing;intelligibility;interaction technique;feed forward;scientific control	HCI	-50.7013836196486	-45.26684702363384	113419
bc6d3c901655f44fe97742e641d7b40a52f4a6c1	online privacy-safe engagement tracking system		Tracking learnersu0027 engagement is useful for monitoring their learning quality. With an increasing number of online video courses, a system that can automatically track learnersu0027 engagement is expected to significantly help in improving the outcomes of learnersu0027 study. In this demo, we show such a system to predict a useru0027s engagement changes in real time. Our system utilizes webcams ubiquitously existing in nowadays computers, the face tracking function that runs inside the Web browsers to avoid sending learnersu0027 videos to the cloud, and a Python Flask web service. Our demo provides a solution of using mature technologies to provide real-time engagement monitoring with privacy protection.	computer;flask;privacy;python;real-time computing;real-time transcription;tracking system;video clip;web service;webcam;world wide web	Cheng Zhang;Cheng Chang;Lei Chen;Yang Liu	2018		10.1145/3242969.3266295	human–computer interaction;web service;facial motion capture;python (programming language);tracking system;cloud computing;computer science	HCI	-53.200344262365185	-42.879521543969915	113430
3551e25f1816a32898f4e89c346df9356e5ff435	wizard of oz vs autonomous: children's perception changes according to robot's operation condition		The presence of robots in human lifestyle is no longer a distant reality, as robots are being employed in several fields, including educational purposes. However, most of the research in educational robotics does not use autonomous social behavior, but rather techniques like Wizard of Oz (WoZ). This paper presents the very first test in a school environment of a robotic architecture to control an autonomous system for educational interactions, evaluated from useru0027s perspective when compared to a teleoperated situation. The architecture aims to manage three main communication robot resources — speech, vision and gesture — in an autonomous way and provide an interaction as acceptable as when someone controls the robot. The experiment was performed randomly assigning 82 students aged between 7 and 11 to interact with a NAO robot in two conditions of robot operation: autonomous and teleoperated. The results suggest that there is no significant difference between the conditions in useru0027s enjoyment and system time response, but they decreased their perception regarding robotu0027s intelligence after knowing about the teleoperation.	autonomous robot;autonomous system (internet);cognitive robotics;computer vision;educational robotics;gesture recognition;interaction;nao (robot);randomness;system time;wizard of oz experiment	Daniel Tozadore;Adam M. H. Pinto;Roseli Romero;Gabriele Trovato	2017	2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2017.8172374	architecture;simulation;educational robotics;computer science;teleoperation;robot;autonomous system (internet);autonomous system (mathematics);wizard;gesture	Robotics	-51.973760311056	-50.43840264096161	113536
4abe9f765f8edc5bd0e99de95061c258d7dcceaa	exploring child-robot proxemics		This paper presents an exploratory research on the proxemics behavior occurring during child-robot interaction. Due to the increase in usage of NAO robots in child environments and applications, it is increasingly important to design an appropriate model for proximate interaction for children of different age groups. For this purpose we conducted an exploratory study »in the wild» inviting 26 children. Our main findings indicate that proximity depends on age. Future work is needed to understand the factors that influence child-robot proxemics.	autonomous robot;nao (robot)	Dana Tokmurzina;Nurbolat Sagitzhan;Abzal Nurgaliyev;Anara Sandygulova	2018		10.1145/3173386.3177083	human–computer interaction;exploratory research;social robot;proxemics;computer science;robot;human–robot interaction	HCI	-53.47663264571772	-50.4565675307952	113720
22545126c51ed21d435073516929a47fbc7b4793	emotional self-regulation of individuals with autism spectrum disorders: smartwatches for monitoring and interaction	affective computing;assistive technologies;behavioral monitoring;cognitive disabilities;mobile assistance;ubiquitous computing;wearable computing	In this paper, we analyze the needs of individuals with Autism Spectrum Disorders (ASD) to have a pervasive, feasible and non-stigmatizing form of assistance in their emotional self-regulation, in order to ease certain behavioral issues that undermine their mental health throughout their life. We argue the potential of recent widespread wearables, and more specifically smartwatches, to achieve this goal. Then, a smartwatch system that implements a wide range of self-regulation strategies and infers outburst patterns from physiological signals and movement is presented, along with an authoring tool for smartphones that is to be used by caregivers or family members to create and edit these strategies, in an adaptive way. We conducted an intensive experiment with two individuals with ASD who showed varied, representative behavioral responses to their emotional dysregulation. Both users were able to employ effective, customized emotional self-regulation strategies by means of the system, recovering from the majority of mild stress episodes and temper tantrums experienced in the nine days of experiment in their classroom.	autism spectrum disorders;autistic disorder;customize;pervasive informatics;self-control as a personality trait;smartphone;smartwatch;tantrums;wearable computer;mental health	Juan Carlos Torrado;Javier Gómez;Germán Montoro	2017		10.3390/s17061359	wearable computer;engineering;cognitive psychology;electronic engineering;mental health;autism;asd;affective computing;simulation;ubiquitous computing;emotional dysregulation;emotional self-regulation	HCI	-57.06964476480868	-52.00542840527142	113746
70f7c301d287ed2f6b445b199eb69ca2b73c806d	permutation: a corpus-based approach for modeling personality and multimodal expression of affects in virtual characters	virtual characters;personality;multimodality;emotion;virtual agents;virtual agent	In order to improve the consistency of their affective multimodal behaviors, interactive virtual agents might benefit from a model of personality inspired from psychology. In this paper, we revisit the different approaches considered in personality psychology. We show that previous efforts to endow virtual agents with personality made only a limited use of these approaches. Finally, we introduce our PERMUTATION corpus-based framework.	multimodal interaction	Céline Clavel;Jean-Claude Martin	2009		10.1007/978-3-642-02809-0_23	psychology;psychotherapist;communication;social psychology	NLP	-53.42377801688153	-48.67257561456198	113829
135e931e6a80d48153c4632f7b82e0c7f842bceb	designing universally accessible networking services for a mobile personal assistant	design process;universal access;web content accessibility guidelines;web accessibility;best practice;web service;device independence;qa75 electronic computers computer science;mobile accessibility;prototyping;mobile web;user testing;user interface design;network services	At present, a tendency towards smaller computer sizes and at the same time increasingly inaccessible web content can be noted. Despite the worldwide recognized importance of Web accessibility, the lack of accessibility of web services has an increasingly negative impact on all users. In order to address this issue, W3C has released a recommendation on Mobile Web Best Practices, supplementary to the Web Content Accessibility Guidelines. This paper presents the design and prototype development of universally accessible networking services that fully comply with those standards. Validation and expert accessibility evaluation on the XHTML Basic prototypes present 100% compliance. The followed design process is presented in details, outlining general as well as specific issues and related solutions that may be of interest to other designers. The results will be further verified through user tests on implemented services.	prototype;web content accessibility guidelines;web accessibility;web service;world wide web;xhtml	Ioannis Basdekis;Panagiotis Karampelas;Voula Doulgeraki;Constantine Stephanidis	2009		10.1007/978-3-642-02710-9_31	web service;web application security;web development;web modeling;web analytics;mobile web;web mapping;web-based simulation;web design;human–computer interaction;web accessibility initiative;web standards;computer science;ws-policy;web navigation;web accessibility;multimedia;web engineering;web 2.0;world wide web	Networks	-51.87021972736834	-41.02065197835139	113857
f048f5471041c1ccac6e87314eb3daaf59ecb4e6	embodied simulations of physical phenomena		At the crossroads between computational physics, human-computer interaction and mediated performance, the present proposal aims at presenting the vast complexity of physical phenomena in an intuitive, embodied manner. Specifically, we created an interactive system capable of accurately simulating the rules of physical phenomena in game form. Through the game, participants perform a dance-like, analogue computing of the Ising model, a model frequently used for phase transitions. A smartphone-based system guides the participants in a playful manner by means of visual and aural cues. The system mediates the multiple interactions happening among actants in a way consistent with the physical model, therefore enabling an embodied simulation of the phenomenon.	analog computer;computational physics;computer simulation;human–computer interaction;interactivity;ising model;smartphone	Carina Karner;Chiara Cardelli;Adrián Artacho	2018		10.1145/3212721.3212894	phase transition;human–computer interaction;embodied cognition;ising model;phenomenon;computer science	HCI	-53.08701865339447	-45.459188322908695	114018
80c1561ea178251dcab1cb7fbc8820870fd19a88	qualitative analysis of visualization: a building design field study	long term study;qualitative analysis;visualization;visual representation;evaluation;building design;field study;ethnographic field study;work practice	We conducted an ethnographic field study examining the ways in which building design teams used visual representations of data to coordinate their work. Here we describe our experience with this field study approach, including both quantitative and qualitative analysis of field study data. Conducting a field study enabled us to effectively examine real work practice of a diverse team of experts, which would have been nearly impossible in a laboratory study. We also found that structured qualitative analysis methods provided deeper insight into our results than our initial quantitative approach. Our experience suggests that field studies and qualitative analysis could have substantial benefit in visualization and could nicely complement existing quantitative laboratory studies.	field research	Melanie Tory;Sheryl Staub-French	2008		10.1145/1377966.1377975	simulation;visualization;human–computer interaction;qualitative research;evaluation;building design;management science;field research	HCI	-61.705098028981325	-45.13846914362933	114029
de612b4588b17d281b7ae61d51b642408120f915	narrative engagement in games - a continuation desire perspective		User/player experiences may be evaluated in many ways, however, most concepts describing engagement with interactive artifacts tend to be complex and limited. This paper focuses on an aspect of engagement, which we believe, may be used to quantify any Interactive Storytelling (IS) experience. The willingness to continue an experience or Continuation Desire is a driver for meaningful and engaging experience, which is often overlooked. We believe that Continuation Desire is a useful tool for assessing narrative quality when combined with factors related to narrative engagement. We discuss possible aspects related to evaluating narrative engagement and Continuation Desire. The resulting framework represents a basis for evaluating IS artifacts (e.g games and IS applications) in future studies.	continuation;experience;futures studies;interactive storytelling;interactivity	Henrik Schoenau-Fog;Sandy Louchart;Theodore Lim;María T. Soto-Sanfiel	2013				HCI	-59.911740442077374	-45.528778669263545	114059
cc706c341dbaf8ff65fe6b228047c93dc370df7c	development of a handshake robot system for embodied interaction with humans	geriatrics;sensory evaluation handshake robot system embodied interaction social welfare older citizens emotional aspect embodied rhythms handshake approaching motion secondary delay elements;social sciences computing emotion recognition geriatrics human computer interaction motion control position control robots;social welfare;human computer interaction;motion control;emotion recognition;handshake robot system;secondary delay elements;sensory evaluation;position control;social sciences computing;robots;emotional aspect;handshake approaching motion;human robot interaction rhythm robot sensing systems displays intelligent robots computer science motion analysis biological system modeling delay medical services;older citizens;embodied rhythms;embodied interaction	It is expected that robots will play an important role in social welfare and service for the older citizens. These robots should display an emotional aspect to make them more acceptable to humans. Humans shake hands in order to greet each other and display a feeling of closeness. A handshake is the embodied interaction with contact by which humans can directly share embodied rhythms. In this paper, we develop a handshake robot system for embodied interaction. The robot can generate the handshake approaching motion that is acceptable to human emotion by using secondary delay elements from the trajectory of a human hand. The effectiveness of this handshake robot is demonstrated by sensory evaluation	centrality;embodied cognition;humans;robot	Mitsuru Jindai;Tomio Watanabe;Satoru Shibata;Tomonori Yamamoto	2006	ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2006.314484	robot;motion control;simulation;computer science;artificial intelligence;social welfare;geriatrics	Robotics	-50.64598624561883	-50.341592977927824	114116
c21cad764c3fded17919d8a1ed40b3a7e02ac26b	where is my team: supporting situation awareness with tactile displays	spatial information encoding;user interface;tactile user interface;cognitive process;tactile display;multiplayer game;situation awareness;spatial information	A group of friends visiting a crowded and noisy music festival is an example of a situation where knowing the location of other people is important, but where external factors, such as darkness or noise, can limit the ability to keep track of the others. By combining theories about situation awareness and cognitive processing we inferred that communicating information via the sense of touch is a promising approach in such situations. We therefore investigated how to present the location of several people using a tactile torso display. In particular we focused on encoding spatial distances in the tactile signals. We experimentally compared encoding spatial distances in the rhythm, duration, and intensity of a tactile signal. Our findings show that all parameters are suited to encode distances. None of it was clearly outperformed. We then embedded our tactile location encoding into a fast-paced 3D multiplayer game. In this game, team play and the awareness of the team members' locations are crucial for the success in the game. The results provides evidence that the locations of the team members could be processed effectively despite the game's high cognitive demands. In addition, the team equipped with the tactile display showed a better team play and a higher situation awareness.	cognition;encode;embedded system;experiment;head-mounted display;image noise;tactile imaging;theory	Martin Pielot;Oliver Krull;Susanne Boll	2010		10.1145/1753326.1753581	situation awareness;simulation;cognition;computer science;operating system;spatial analysis;user interface	HCI	-50.75247652159773	-48.22089979179933	114160
ec3b76887c6099020133b4b18b20d0a471735f78	adapting a virtual agent to users' vocabulary and needs	virtual agent	Duarte Digital is an agent that engages in inquiry-oriented conversations about an art artifact. Since it was build for a Museum, interactions are supposed to be directed to different types of audience: an interaction with an art expert should be carried out in a different way than an interaction with a child; likewise, interactions with users interested in learning should be distinct from interactions with users having only entertainment goals. As so, an agent needs to undergo two tasks: it must understand the user’s knowledge about the topic, and his/her learning goals; it should adapt its vocabulary and dialogue strategy to cope with the user’s characteristics and expectations. This paper presents a simple and straighforward model of interaction that allows a virtual agent to understand its interlocutors based on their vocabulary and to adapt to their expertise and needs.	interaction;vocabulary	Ana Cristina Mendes;Rui Prada;Luísa Coheur	2009		10.1007/978-3-642-04380-2_76	human–computer interaction;computer science;multimedia;communication	HCI	-53.679784840465906	-47.655343910807694	114364
db1a53ab83745a0f201784a63a8cbe727bb6f76d	configuring attention in the multiscreen living room		We have conducted a video study of households in Scotland with cohabiting students and young professionals. In this paper we unpack five examples of how mobile devices are used by people watching television. In the examples we explore how screens are used together a) in a physical ecology, b) in an embodied way, c) in an orderly way, and d) with respect to others. We point out that mobile devices are routinely used to access media that is unconnected and unrelated to media on television, for example for sending and receiving messages, browsing social media, and browsing websites. We suggest that mobile devices are not used to directly enhance television programmes, but to enhance leisure time. We suggest that it is important, when considering mobile devices as second screens, not just to treat these as a design topic, but to pay attention to how they are interactionally integrated into the living room.	ecology;emoticon;mobile device;multi-screen video;social media;television	John Rooksby;Timothy E. Smith;Alistair Morrison;Mattias Rost;Matthew Chalmers	2015		10.1007/978-3-319-20499-4_13	simulation;human–computer interaction;multimedia;communication;world wide web	HCI	-55.74948407256069	-40.729470418208784	114466
db79230ca0f292fcc8125a6bdc1778945b3df5ed	designing cloud computing into taipei city: a pilot study of the service design from taipei cloud		For offering holistic service quality, in 2013, the Taipei City Hall promote “Taipei Cloud” service for citizen to enhance web services based on convenient, free, and public Wi-Fi hotspots all over the city. This pilot experiment explores on user experience and perception of “Taipei Cloud” service from subjects’ usage by participant-observation to know whether “Taipei Cloud” service can match subjects’ demand in their daily life. Six subjects use “Taipei Cloud” service randomly to obtain their cloud computing data record by their smart mobile phone APP during their own trips. Then, time-geography theory is applied to be evaluated subjects’ usage. The finding are shown that: (1). there is no direct correlation between time and spatial facts through subjects’ usage on citizen cloud service; (2).Until now, in subjects’ opinion, to share or contact others should be a function added in citizen cloud; (3).To compare subjects’ usage of citizen cloud, “command” is more popular than other online actions.; (4).In holistic user experiences, subjects usually prefer higher interaction with cloud computing service.	cloud computing	Jui-Ping Ma;Stanely Wei;Rungtai Lin	2014		10.1007/978-3-319-07308-8_66	simulation	HCI	-57.880438395261535	-44.15533696478938	114470
2d3f225b17b1610b4590a1b36fdd853ac3e7a301	evaluating the effects of culture and etiquette on human-computer interaction and human performance		We claim that ideas of etiquette can be expanded and utilized to facilitate, inform, and predict human-computer interaction and perceptions. By expanding on the qualitative model of etiquette proposed by Brown and Levinson we created a quantitative, computational model of etiquette that allows a machine to interpret and display politeness. This model was then embedded into a testbed and a series of experiments involving human task performance were completed to test various hypotheses related to the model. Relevant compliance data (e.g., accuracy, response time, attitudes, etc.) were obtained as dependent variables. The results show that the variables included in our model have important effects on subjects’ decision making and performance in our experimental tasks. The results also demonstrate that variations in etiquette can result in objective, measurable consequences in human+machine performance.	computational model;dependent ml;embedded system;experiment;human-based computation;human–computer interaction;levinson recursion;response time (technology);testbed	Peggy Wu;Tammy Ott;C. A. Miller	2009			computer science;artificial intelligence;machine learning;variables;politeness;etiquette;testbed	AI	-53.31657214560305	-50.42284671026089	114495
c98594701b415f238be6826501479aef455176ef	happiness recognition from mobile phone data	recognition systems;social computing;reality mining;happiness recognition;behavioural sciences computing;pervasive computing;machine learning;emotional state recognition;pattern classification;mobile handsets;3 class daily happiness recognition problem mobile phone data mobile phone usage data background noise indicators weather factor personality traits machine learning model random forest classifier;learning artificial intelligence;human behavior analysis;pattern classification behavioural sciences computing learning artificial intelligence mobile computing mobile handsets;mobile phone usage patterns;mobile computing;affective computing;subjective well being;educational robots mechatronics service robots educational institutions project management;social computing happiness recognition emotional state recognition mobile phone usage patterns human behavior analysis subjective well being machine learning recognition systems reality mining affective computing pervasive computing	In this paper we provide the first evidence that daily happiness of individuals can be automatically recognized using an extensive set of indicators obtained from the mobile phone usage data (call log, sms and Bluetooth proximity data) and ``background noise'' indicators coming from the weather factor and personality traits. Our final machine learning model, based on the Random Forest classifier, obtains an accuracy score of 80.81% for a 3-class daily happiness recognition problem. Moreover, we identify and discuss the indicators, which have strong predictive power in the source and the feature spaces, discuss different approaches, machine learning models and provide an insight for future research.	bluetooth;emoticon;machine learning;mobile phone;pc bruno;random forest;smartphone;usage data	Andrey Bogomolov;Bruno Lepri;Fabio Pianesi	2013	2013 International Conference on Social Computing	10.1109/SocialCom.2013.118	simulation;computer science;artificial intelligence;machine learning;affective computing;subjective well-being;mobile computing;social computing	Robotics	-59.809450215329825	-51.06727871630193	114500
113a368ad1a6397866f0343e33fd60aa734334d6	evaluation and design of auditory feedback for a mobile outdoor training assistant	requirement analysis;interaction design	This paper presents a study about the design and evaluation of auditory feedback for a mobile outdoor training assistant. The requirement analysis and evaluation has been conducted with sportsmen from different disciplines. This led to a new auditory and interaction design of the mobile client. In this paper we report the findings of the auditory component and we provide recommendations for the use of signal or voice feedback for different training situations.	interaction design;positive feedback;prototype;requirement;requirements analysis;usability;user (computing);user interface;user requirements document	Ekaterina Kurdyukova;Jochen Hahnen;Wolfgang Prinz;Wido Wirsam	2008			simulation;engineering;multimedia;communication	HCI	-54.67837666538835	-46.017654978365535	114614
85dd6d02ad0810305750879dc43af49541786f5b	applying usability patterns in e-commerce applications	e commerce;usability patterns;user interfaces	The exigencies and the particular characteristics of website development are a great challenge for designers and developers. There are many differences between typical software application development and website development. In website development, the presentation component; visual and graphical, plays an important role, which is not that important for not web applications. This component can be documented by using patterns, and particularly usability patterns. Traditionally, guidelines have been used to deal with it. These patterns should be written so that they can be used by users, designers and developers. Thus, users will be able to make proposals, user interface designers will be able to imagine and developers will be able to build the application.	e-commerce;usability	Francisco Montero Simarro;Víctor López-Jaquero;José Pascual Molina	2008			usability goals;pluralistic walkthrough;web usability;human–computer interaction;computer science;multimedia;world wide web;usability inspection	DB	-51.54854891710335	-39.332410098681464	114754
66b70c4e046e4688b24afe3adb001b8ed5efa3ab	flickr and public image-sharing: distant closeness and photo exhibition	empirical study;social interaction;social networking;digital photos;photography;flickr com;social network;distant closeness;digital media;photo sharing	This paper presents an empirical study in progress of the use of Flickr.com, part of an on-going research program on personal digital media, including images. Two new kinds of image-sharing with Flickr are.distant closeness. and.photo exhibition.. We are seeing changing uses of images in social interaction and increased multi-modal communication.	centrality;digital media;flickr;modal logic	Nancy A. Van House	2007		10.1145/1240866.1241068	social relation;multimedia;internet privacy;world wide web;social network	HCI	-56.01476804846176	-40.08342900417992	114901
00eefd43f5b9e2441b4e8774e3eb171ee0ae0424	br'eye: an android mobile application to teach arabic and french braille alphabets to blind children in tunisia		This paper presents an Android mobile application consisting in an educational content for visually handicapped children in Tunisia. The application involves simple and various interfaces that aim to teach Braille alphabet in both Arabic and French. It uses multimodal interaction methods as well as a novel approach to help young users locate areas of interest on the screen.	mobile app	Amina Bouraoui;Mejdi Soufi	2018		10.1007/978-3-319-94277-3_56	multimedia;arabic;braille;android (operating system);multimodal interaction;alphabet;computer science	HCI	-49.88760594314714	-43.48923337178079	115008
14d02985043e56f52324da1d3418f0392c47608b	a study on the introduction of open source software in the public administration	life cycle;user participation;data collection;office automation;open source software;public administration	This paper reports about a study on the introduction of Open Source Software (OSS) in a Public Administration located in Europe. In the specific, we introduced the office automation software OpenOffice.org. The Public Administration examined introduced OSS as a means to save on the license costs and to have a larger space for customisation purposes. The adoption of the new software can have an impact on the employees’ productivity that need to be evaluated during the migration process. In this article, we compare the usage of OpenOffice.org and Microsoft Office. Data about the usual office activities performed by the users participating to the experimentation have been collected by means of an automated non-invasive data collection tool. The result of this study reports a similar usage pattern of both suites in terms of workload, but a different approach in using functionalities provided by each software. A further analysis on the life cycles of documents elaborated with the office suites seem to validate the similarities among the software solutions examined.	open sound system;open-source software;personalization	Bruno Rossi;Barbara Russo;Giancarlo Succi	2006		10.1007/0-387-34226-5_16	biological life cycle;human–computer interaction;engineering;software engineering;world wide web;statistics;data collection	SE	-61.187573873111674	-41.11388183782044	115151
91e028f9dbd906480559234e0d6bb8fa5c29b182	guest editorial: multimedia in social mobile computing (msmc)		The special issue on Multimedia in Social Mobile Computing (MSMC) was organised aiming to stimulate cross-disciplinary debate on researches involving multimedia technologies and social mobile computing. The amount of multimedia data accessible from mobile devices is increasing more and more over the years, and new challenges on data management, situation-awareness, personalization, privacy, and security are emerging. The variety of multimedia data enables new applications across different research domains comprising mobile media analysis, mobile social networks, mobile human-computer interaction and multimodal issues [2, 3]. The community of researchers is increasingly investigating issues related to the pervasive use of mobile devices (e.g. Smartphone, PDA, GPS navigation and laptops) and wireless technology; mobile computing is experiencing a phase of strong innovation and, multimedia data and content are spreading over the network of mobile technologies. All these different aspects are studied in the perspective of mobile technologies and the collaborative multimedia systems that use devices interconnected through an ad-hoc network. In this direction, social networks and content-sharing web systems are increasingly emerging as platforms that facilitate the creation and sharing of multimedia content and supporting new types of interaction. The growth of multimedia social systems stimulates researches on social computing that investigate emerging issues and challenges in modelling, analyzing and effectively interacting with social media. That is why the topic of social multimedia computing is attracting researchers in multimedia computing and social sciences, as well as entrepreneurs producing software and mobile devices and applications. Multimed Tools Appl DOI 10.1007/s11042-017-4441-3	display resolution;gps navigation device;global positioning system;hoc (programming language);human–computer interaction;laptop;mobile computing;mobile device;mobile media;mobile social network;multimodal interaction;personal digital assistant;personalization;pervasive informatics;privacy;smartphone;social computing;social media;social system;software peer review	Fernando Ferri;Patrizia Grifoni;Arianna D'Ulizia;Maria Chiara Caschera	2017	Multimedia Tools and Applications	10.1007/s11042-017-4441-3	computer science;mobile computing;multimedia	HCI	-57.21713618580304	-38.24517923249563	115263
4fe9bbe8dc67d115cb326339077eb49da0f94804	spontaneous gesture production patterns on multi-touch interactive surfaces		Expressivity of hand movements is much greater than what current interaction techniques enable in touch-screen input. Especially for collaboration, hands are used to interact but also to express intentions, point to the physical space in which collaboration takes place, and communicate meaningful actions to collaborators. Various types of interaction are enabled by multi-touch surfaces (singe and both hands, single and multiple fingers, etc.), and standard approaches to tactile interactive systems usually fail in handling such complexity of expresion. The diversity of multi-touch input also makes designing multi-touch gestures a difficult task. We believe that one cause for this design challenge is our limited understanding of variability in multi-touch gesture articulation, which affects users’ opportunities to use gestures effectively in current multi-touch interfaces. A better understanding of multi-touch gesture variability can also lead to more robust design to support different users’ gesture preferences. In this chapter we present our results on multi-touch gesture variability. We are mainly concerned with understanding variability in multi-touch gestures articulation from a pure user-centric perspective. We present a comprehensive investigation on how users vary their gestures in multi-touch gestures even under unconstrained articulation conditions. We conducted two experiments from which we collected 6669 multi-touch gestures from 46 participants. We performed a qualitative analysis of user gesture variability to derive a taxonomy for users’ multi-touch gestures that complements other existing taxonomies. We also provide a comprehensive analysis on the strategies employed by users to create different gesture articulation variations for the same gesture type.	multi-touch;spontaneous order	Yosra Rekik;Radu-Daniel Vatavu;Laurent Grisoni	2016		10.1007/978-3-319-45853-3_3	computer vision;multimedia;communication	HCI	-51.48457772529512	-46.21612453118673	115496
8e3eb7ae68eaee3cc2c301333582ae5b05d5c28c	an audio browser for increasing access to world wide web sites for blind and visually impaired computer users	serveur institutionnel;archive institutionnelle;open access;visual impairment;world wide web;archive ouverte unige;cybertheses;institutional repository	The development of electronic aids for visually impaired persons has been ongoing for decades, such as for reading, facilitating mobility and for educational and occupational activities (Brabyn J.A. 1985). More recently, a pressing need to offer blind and visually impaired computer users access to Internet-based digital information has been identified (D. Burger Ed. 1996) (Paciello M.G. 1996). The generalized use of graphical user interfaces (GUIs), coupled with the recent popularization of the World Wide Web and graphical HTML pages, however limits access to the Internet for persons with visual disabilities. In this context, blind and visually impaired computer users are less and less able to take advantage of the enormous wealth of information which is offered over the World Wide Web.	digital data;graphical user interface;html;internet;j. a. scott kelso;user (computing);world wide web	Lori Petrucci;Patrick Roth;André Assimacopoulos;Thierry Pun	1999			computer science;web navigation;web page;multimedia;internet privacy;world wide web	Web+IR	-50.47808301567532	-39.8917991457734	115606
f2b524d61e9eccaee07d2c960809a3758686fb7c	exploratory study on users' behavior: smartphone usage	qualitative research;exploratory study;quantitative research		exploratory testing;smartphone	Leigh A. Mutchler;Jung P. Shim;Dustin Ormond	2011				HCI	-58.941833557125136	-44.69669615289155	115762
8e2eb4470ca9441f097f41a5551a12b8102bc0d1	ballons, boats and ponies: interface manipulation style and learning in a constraint-based planning task	interface manipulation style;constraint-based planning task	The role of the interface in structuring student learning and in directing the learner’s cognitive effort toward relevant material has become increasingly centralised in recent years. Specifically, interface designers have been called on to design interfaces which keep the learner focused on or “engaged” in the domain material, with the view that such engagement will have learning benefits. In this paper we operationalise the notion of cognitive engagement in terms of familiar cognitive psychological principles: planning and learning. Following laboratory studies, we have taken the view that cognitive planning can be induced by increasing the “cost” of selecting and executing actions by designing less direct interfaces. A study is reported which contrasts direct and indirect manipulation interfaces for a constraint-based planning task. Results from the study suggest that manipulation style can indeed affect users’ information search and task solution strategies.	motion planning	Shirley J. Holst;Elizabeth F. Churchill;David J. Gilmore	1997			simulation;human–computer interaction;cognitive style;knowledge management;artificial intelligence	Robotics	-54.903219296673264	-45.05873395573685	115875
d37283615c854c52e37af3de0ea39ef15d9e8317	multimodal teaching analytics: automated extraction of orchestration graphs from wearable sensor data	teaching analytics;activity detection;eye-tracking;multimodal learning analytics;sensors	The pedagogical modelling of everyday classroom practice is an interesting kind of evidence, both for educational research and teachers' own professional development. This paper explores the usage of wearable sensors and machine learning techniques to automatically extract orchestration graphs (teaching activities and their social plane over time), on a dataset of 12 classroom sessions enacted by two different teachers in different classroom settings. The dataset included mobile eye-tracking as well as audiovisual and accelerometry data from sensors worn by the teacher. We evaluated both time-independent and time-aware models, achieving median F1 scores of about 0.7-0.8 on leave-one-session-out k-fold cross-validation. Although these results show the feasibility of this approach, they also highlight the need for larger datasets, recorded in a wider variety of classroom settings, to provide automated tagging of classroom practice that can be used in everyday practice across multiple teachers.		Luis Pablo Prieto;Kshitij Sharma;Lukasz Kidzinski;María Jesús Rodríguez-Triana;Pierre Dillenbourg	2018	Journal of computer assisted learning	10.1111/jcal.12232	orchestration (computing);automation;data collection;knowledge management;human–computer interaction;wearable computer;computer science;eye tracking;analytics;graph	HCI	-60.718550437820014	-51.91644297760623	115928
29cddc5850f6e9018a6c03a89b708adb1663f782	the role of physical affordances in multifunctional mobile device design	human computer interaction;mobile device;affordances;cognitive models;media;interaction design;mobile devices;multifunctionality	"""As designers of mobile/media-rich devices continue to incorporate more features/functionality, the evolution of interfaces will become more complex. Meanwhile, users cognitive models must be aligned with new device capabilities and corresponding physical affordances. In this paper, the authors argue that based on HCI design theory, users approach objects by building mental models starting with physical appearance. Findings suggest that users who embrace a device’s multifunctionality are prevented from taking full advantage of an array of features due to an apparent cognitive constraint caused by a lack of physical controls. The authors submit that this problem stems from established mental models and past associated behaviors of both mobile and non-mobile interactive devices. In conclusion, users expressed a preference for immediate access and use of certain physical device controls within a multi-tasking environment, suggesting that as mobile computing becomes more prevalent, physical affordances in multifunctional devices may remain or increase in importance. devices with multifunctional capabilities (Heo, Ham, Park, Song, & Yoon, 2009; Monk, Fellas, & Ley, 2004). The functionality of these devices is further enhanced by the possibility of transferring media content to a fixed interface display, such as a personal computer (PC), TV, or stereo system. The emergence of such multimedia-enabled mobile devices creates a number of physical and conceptual design challenges that revolve around two issues. DOI: 10.4018/jitwe.2010100103 International Journal of Information Technology and Web Engineering, 5(4), 40-57, October-December 2010 41 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. The first issue is related to the fact that commercial devices are relatively shrinking –even the iPad is smaller than a typical laptop, yet they continue to incorporate more features and functionality. Consequently, controls and interfaces have either become more crowded or have been buried in complex hierarchically structured graphical user interfaces (GUIs) (Vivrou & Kabbasi, 2002). The second issue is that the ever-increasing functionality offered by these novel technologies is limited by the socio-cultural maps and cognitive models that users and designers carry in their minds about mobile and non-mobile device capabilities and their corresponding physical affordances (Faiola, & MacDorman, 2008; Gibson 1977, Hartson, 2003, Norman, 2002). The concept of affordance designates the capacity of a device to suggest a particular kind of use by virtue of some physical attribute. For example, a cell phone’s most significant affordance is related to voice calling, as an object made to be grasped with one hand and positioned between the ear and mouth. This affordance is reinforced both by the physical design of the device and its controls (softkeys, menu options, hardwired buttons, etc.), as well as the way in which people approach it cognitively. Physical affordances are extremely effective when they are incorporated into simple/ unifunctional devices with limited functions (Norman, 1998). However, problems often emerge when these multimedia devices additionally serve as gateways and transfer devices for video, photos, text, and various other types of information and media content between different types of platforms. For example, how should the device make its non-talking affordances visible and immediately understandable to the user who associates the device with a more basic cell phone or home phone that only makes calls? The process of “unveiling” the functional potential of the multimedia device relies heavily on creating features and interface and interaction design solutions that suggest the idea that the device is not just a cell phone, but also a vehicle for content capture, storage, and transfer between various platforms. The study described here suggests that users approach such multifunctional devices with cognitive models derived from their prior experiences of using phones, cameras, camcorders, PDAs, and PCs. A directive principle should be that industrial and interaction designers must consider the users’ prior experience with media devices, in order to avoid conflicts with existing cognitive or mental models associated with the use of these single appliance interactive devices. Forlizzi (2007) specifically recommends thorough examination of prior subjective experiences with mobile products, which can lead to generalizable knowledge for design activities. At the same time, the design process should not be dogmatic. Ecological, participatory design is preferable. Prototypes that reflect a combination of existing and novel features and practices need to be continuously tested and “winning” features sorted out in the process of actual usage. Patterns of use need to be monitored and the conclusions of such monitoring fed back into participatory design activities (Forlizzi, 2007). This paper, which is theoretically informed by affordance theory (Norman, 2002), addresses the role that particular affordances and cognitive models play in facilitating or hindering the use of the cell phone as a gateway for multimedia content generation, transfer, and visualization. More specifically, we reconsider the role of the touch screen interface and the physical device affordances in such multifunctional mobile devices. MULTIFUNCTIONAL DEVICES AND AFFORDANCES Discussions about how new audio and video technologies and information management should be embedded in the mobile communication environment and assimilated by users go back to the 1980s and to Xerox’s Palo Alto Research Center (Abowd & Mynatt, 2000; Dourish, 2001). Nevertheless, the practical integration of multimedia functionality within a mobile device is an evolving concept (Gold16 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/role-physical-affordancesmultifunctional-mobile/49199?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Select, InfoSci-Select, InfoSci-Select, InfoSci-Select, InfoSci-Digital Marketing, E-Business, and EServices eJournal Collection, InfoSci-Networking, Mobile Applications, and Web Technologies eJournal Collection, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science, InfoSci-Select. Recommend this product to"""	2.5d;align (company);bridging (networking);cognitive model;computer multitasking;desktop computer;desktop metaphor;directive (programming);ecology;embedded system;emergence;experience;graphical user interface;human–computer interaction;information appliance;information management;interaction design;international journal of information technology;jenkins;kaisa nyberg;mp3;map;mental model;mobile computing;mobile device;mobile phone;multi-function printer;norm (social);palo;peripheral;personal computer;personal digital assistant;physical computing;physical design (electronics);programming paradigm;social affordance;stationary process;touchscreen;ubiquitous computing;usability;web engineering;ipad	Sorin Adam Matei;Anthony Faiola;David J. Wheatley;Tim Altom	2010	IJITWE	10.4018/jitwe.2010100103	simulation;human–computer interaction;computer science;mobile device;multimedia	HCI	-49.64993291205361	-40.91316004389647	116109
dfd7a0b2c7fc964427986a5318f9fba2e57dc011	increasing psychological well-being through human-robot interaction		Intelligent tutoring systems, electronic fitness bands, and assistive robots all contribute toward increasing the wellness of humans by providing different forms of support. As a class of machines focused on increasing the physical and psychological well-being of users emerges, new design considerations and questions arise. We are exploring the potential of prosocial machines via social robotic systems focused on enhancing a user's psychological well-being through positive interventions. This article briefly summarizes our initial approach to understanding prosocial machines via a positive psychology based intervention focused on comparing the ability of different systems to induce measurable increases in a human's level of hopefulness.	emergence;humans;human–robot interaction;robot	Zachary Henkel;Cindy L. Bethel	2016	2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)		human–robot interaction;positive psychology;simulation;usability;computer science;artificial intelligence;social robot	Robotics	-53.48761836453515	-50.46951122102938	116179
841eafc526a84e124fcfd8c6a1085ee8cd9ac324	professor piano: a music application for people with intellectual disabilities	usability evaluation;user tests;piano;android devices;intellectual disability	"""In this paper it is presented a music application for people with intellectual disabilities, called """"Professor Piano"""". We created this application to be a solution for music education for this group of people. For that we present the development and implementation of the app. We choose the virtual piano and the mobile devices as the basis for our solution. It was conducted an assessment of the current status and features of mobile applications also using this paradigm, from which we concluded that, currently, there is not a virtual piano application oriented to people with intellectual disabilities so we design, develop and tested a new application, the """"Professor Piano"""".  To validate the """"Professor Piano"""" application approach, we evaluated the application usage by a group of people with intellectual disabilities, without having too much user experience with mobile technologies, with the aim to measure the effectiveness, efficiency and satisfaction. We registered the following variables: success in a conclusion of a level (effectiveness); the percentage of correct notes played versus all notes of that level (efficiency); and the motivation at the end of the experience (satisfaction).  The results obtained shows the interest and motivation of the users in playing with the application. In the four tests, three persons completed and wanted to continue the testing experience. This results also shows the importance of using an intuitive design and also of displaying the score at the end of each level, giving an extra boost to the user to replay or advance to the next level."""	mobile app;mobile device;programming paradigm;user experience	Dennis Paulino;Duarte Amaral;Mariana Amaral;Arsénio Reis;João Barroso;Tânia Rocha	2016		10.1145/3019943.3019982	psychology;simulation;human–computer interaction;multimedia	HCI	-57.91003101278673	-45.73952743219487	116189
cf1019565eb0e9a94c6ff8cba254ebd6a9faf564	techniques of dialogue simulation	elbot;interactive customer assistants;dialogue simulation;social psychology;artificial solutions	We claim that it is more effective to simulate intelligence than it is to recreate it. To this end several of the classic social psychological theories suggest strategies to transform the dialogue into an encounter with a consistent and cohesive personality. The secret is to use the mind-set of the user to the advantage of the conversation, and to provoke the user into showing typical behavior. This is presented in an online system: Elbot.com.	simulation;theory;on-line system	Fred Roberts;Björn Gülsdorff	2007		10.1007/978-3-540-74997-4_68	psychology;computer science;knowledge management;artificial intelligence;multimedia;social psychology	AI	-54.02584998687084	-47.51886894443844	116313
4d035e082bd0c12c6bbddb6f8ef17e2e40ee7336	effect of robot performance on human–robot trust in time-critical situations	trust;human robot interaction;social robots;rescue robots;human robot trust cooperative systems emergency guidance robot human robot interaction;technical report;atmospheric measurements particle measurements navigation educational robots time factors reliability;robot	Robots have the potential to save lives in high-risk situations, such as emergency evacuations. To realize this potential, we must understand how factors such as the robotu0027s performance, the riskiness of the situation, and the evacueeu0027s motivation influence his or her decision to follow a robot. In this paper, we developed a set of experiments that tasked individuals with navigating a virtual maze using different methods to simulate an evacuation. Participants chose whether or not to use the robot for guidance in each of two separate navigation rounds. The robot performed poorly in two of the three conditions. The participantu0027s decision to use the robot and self-reported trust in the robot served as dependent measures. A 53% drop in self-reported trust was found when the robot performs poorly. Self-reports of trust were strongly correlated with the decision to use the robot for guidance ( $phi ({90}) = + 0.745$ ). We conclude that a mistake made by a robot will cause a person to have a significantly lower level of trust in it in later interactions.	experiment;human–robot interaction;report;robot;simulation;virtual reality	Paul Robinette;Ayanna M. Howard;Alan R. Wagner	2017	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2017.2648849	social robot;robot learning;computer science;machine learning;artificial intelligence;simulation;personal robot;mobile robot navigation;robot control;mobile robot;rescue robot;technical report	Robotics	-51.315249358153984	-51.44827995070675	116351
0a0605b340c8e2ea355f43ab6d9e7c30cf960546	noisespy: a real-time mobile phone platform for urban noise monitoring and mapping	pollution monitoring;real time;noise mapping;pervasive sensing;contextual information;mobile phone;user experience;online mapping;ubiquitous computing;mobile computing;institutional repository research archive oaister;data logger	In this paper we present the design, implementation, evaluation, and user experiences of the NoiseSpy application, our sound sensing system that turns the mobile phone into a low-cost data logger for monitoring environmental noise. It allows users to explore a city area while collaboratively visualizing noise levels in real-time. The software combines the sound levels with GPS data in order to generate a map of sound levels that were encountered during a journey. We report early findings from the trials which have been carried out by cycling couriers who were given Nokia mobile phones equipped with the NoiseSpy software to collect noise data around Cambridge city. Indications are that, not only is the functionality of this personal environmental sensing tool engaging for users, but aspects such as personalization of data, contextual information, and reflection upon both the data and its collection, are important factors in obtaining and retaining their interest.	data logger;global positioning system;mobile phone;personalization;real-time transcription	Eiman Kanjo	2010	MONET	10.1007/s11036-009-0217-y	human–computer interaction;computer science;operating system;data logger;multimedia;mobile station;mobile computing;world wide web;computer security;ubiquitous computing	HCI	-54.26345763306316	-40.79710098188482	116442
86e2a76cdda9661766a98e534a95c7e880afa8a1	comfortable approach distance with small unmanned aerial vehicles	social aspects of automation autonomous aerial vehicles human robot interaction;human robot interaction;social aspects of automation;robots heart rate variability atmospheric measurements particle measurements psychology interviews safety;autonomous aerial vehicles;human aerial robot interactions comfortable approach distance suav small unmanned aerial vehicle law enforcement crowd control entertainment flying personal assistants unmanned ground vehicles human proxemics studies psychophysiological sensing	This paper presents the first known human-subject study of comfortable approach distance and height for human interaction with a small unmanned aerial vehicle (sUAV), finding no conclusive difference in comfort with a sUAV approaching a human at above head height or below head height. Understanding the amount, if any, of discomfort introduced by a sUAV flying in close proximity to a human is critical for law enforcement, crowd control, entertainment, or flying personal assistants. Previous work has focused on how humans interact with each other or with unmanned ground vehicles, and the experimental methods typically rely on the human participant to consciously express distress. The approach taken was to duplicate the experimental set up in human proxemics studies, while adding psychophysiological sensing, under the hypothesis that human-robot interaction will mirror human-human interaction. The 16 participant, within-subjects experiment did not confirm this hypothesis. Instead a sUAV above height of a “tall” person in human experiments (2.13 m) did not produce statistically different heart rate variability nor cause the participant to stop the robot further away than for a sUAV at a “short” height (1.52 m). The lack of effect may be due to two possible confounds: i) duplicating prior human proxemics experiments did not capture how a sUAV would likely move or interact and ii) telling the participants that the robot could not hurt them. Despite possible confounding, the results raise the question of whether human-human psychological and physical distancing behavior transfers to human-aerial robot interactions.	asea irb;aerial photography;aerobot;computational auditory scene analysis;consciousness;experiment;heart rate variability;human–robot interaction;inventory;robot;unmanned aerial vehicle;unmanned spacecraft	Brittany A. Duncan;Robin R. Murphy	2013	2013 IEEE RO-MAN	10.1109/ROMAN.2013.6628409	human–robot interaction;computer vision;simulation;computer science;artificial intelligence	Robotics	-51.94282277373828	-51.094504957390164	116457
f5bdd5c80a90a98fc2c132bc7a163bc00f375c6d	a framework for itinerary personalization in cultural tourism of smart cities		Smart tourism in cities of art is a personalized user experience that exploits smart city infrastructures to offer increased opportunities of visit and services and time optimization. Traditionally, this capability requires the availability of personal mobile systems and geolocalization, augmented with some smart computing that provides the due information and functions at the right time and location of the visit. However effective smart tourism should also account for the fact that they exist different user requirements at different stages of the visit and that interests and requirements not only differ from one user to the other but also may change through time for each individual user. According to this, an effective framework for smart tourism should offer the possibility of an easy definition of individual user visits and offer to each user the capability of making changes or updates to his/her visit plan during the visit. It should also consider the possibility that different devices are offered and used at the different stages of the visit. In this paper we present the prototype of a framework where different devices are used for the definition and modification of a personalized visit. In particular it exploits a wall mounted touchscreen in a visitor center which permits the early definition of a visit plan and a mobile device which allows online updates and changes of the planes well as display of geolocalized information during the time of the visit. An application server platform and a network infrastructure allow to record user activities as well as search and retrieve personalized data.	application server;geographic coordinate system;geolocation;mathematical optimization;mobile app;mobile device;nicola salmoria;personalization;prototype;requirement;server (computing);smart city;touchscreen;user experience;user requirements document;web application	Gianpaolo D'Amico;Simone Ercoli;Alberto Del Bimbo	2013			cultural tourism;personalization;smart city;tourism geography;user requirements document;internet privacy;application server;mobile device;user experience design;business	Web+IR	-51.09445375274831	-40.87357957981949	116469
e4d3551eb7381b8fd40edcf0c85a129ef84512b8	mobile augmented reality guides in cultural heritage		Mobile augmented reality (MAR) technology creates unprecedented possibilities for delivering engaging, immersive experiences to the visitors of cultural heritage sites. Despite the proliferation of available prototypes, the relevant literature still lacks studies investigating the way that users interact with MAR interfaces as well as identifying major usability problems and technology acceptance factors. Herein, we present KnossosAR, a MAR guide implemented for the archaeological site of Knossos (in Crete, Greece) which serves as a testbed for pursuing the abovementioned research objectives while also comparing the (dis)advantages of MAR vs. map-based mobile interfaces in outdoor cultural heritage sites. Among other technical contributions, KnossosAR addresses the occlusion problem, which is commonly encountered in location-based AR applications; that is, it employs an efficient method for estimating the field of view (FoV) of the user in order to handle situations wherein a point of interest is occluded by a physical obstacle (e.g. building). We have conducted field trials which provide preliminary evidence of the efficiency, effectiveness and utility of KnossosAR (including the incorporated FoV estimation approach). CCS Concepts • Software and its engineering➝Software creation and management • Information systems➝Information systems applications • Human-centered computing➝Human computer interaction (HCI) • Human-centered computing➝Ubiquitous and mobile computing.	augmented reality;experience;field of view in video games;human computer;human-centered computing;human–computer interaction;management information system;mobile computing;point of interest;testbed;usability	Panagiotis Galatis;Damianos Gavalas;Vlasios Kasapakis;Grammati E. Pantziou;Christos D. Zaroliagis	2016		10.4108/eai.30-11-2016.2266954	human–computer interaction;multimedia;computer graphics (images)	HCI	-59.55036184510981	-40.93832896236929	116540
b68cfa7272d0c22fd23a1e31b4d7c49c19aeea9f	interface tailoring by exploiting temporality of attributes for small screens	context based approach;personal digital assistant;personal computer;user interface;pervasive computing;data collection;mobile phone;mobile environment;mobile interfaces;mobile interface forms;user interface design;interface tailoring;user interfaces	In the pervasive computing era, mobile phones and personal digital assistants are widely used for data collection. The traditional user interfaces which are employed for data collection in personal computer environments are to be modified appropriately for the mobile environment. Because, it is difficult to display full interface on a single mobile screen due to the limitation of the mobile phone screen size. Interface tailoring methods are investigated in the literature for designing user interface for mobile screens. In the literature, temporality-based approach is proposed for designing efficient user interface for personal computer environment. In this paper, we extend the notion of attribute temporality to interface tailoring methods and propose an improved user interface design approach for small screens. The analysis on the real-world datasets shows that the proposed approach can be used for better user interface design for small screens.	display size;mobile device;mobile phone;norm (social);personal computer;personal digital assistant;television;ubiquitous computing;user interface design	Mittapally Kumara Swamy;P. Krishna Reddy;R. Uday Kiran;M. Venugopal Reddy	2010		10.1007/978-3-642-12038-1_19	user interface design;user;10-foot user interface;mobile search;interface metaphor;shell;human–computer interaction;natural language user interface;computer science;multimedia;natural user interface;user interface;world wide web;ubiquitous computing;multiple document interface	HCI	-49.40354615209155	-41.51739902281795	116543
0f1164ac5749dce5d8feee181f11d0f0d1f7af98	unpacking the television: user practices around a changing technology	television;ethnography;domestic technology;domestic technologies;video recording;downloading;file sharing	This article investigates the changing television watching practices amongst early adopters of personal hard-disk video recorders (such as Tivo) and Internet downloading of video. Through in-depth interviews with 21 video enthusiasts, we describe how the rhythms of television watching change when decoupled from broadcast TV schedules. Devices such as Tivo do not simply replace videotapes; TV watching becomes more active as programs are gathered from the schedules, played from a stored collection and fast forwarded and paused during playback. Downloads users exploit the Internet to view shows and movies not broadcast, yet this watching is not fundamentally different from recording shows using a PVR, since both involve selection of shows from a limited range and a wait before the shows can be watched.	broadcast television systems;digital video recorder;download;hard disk drive;internet;tivo	Louise Barkhuus;Barry A. T. Brown	2009	ACM Trans. Comput.-Hum. Interact.	10.1145/1592440.1592444	internet television;upload;computer science;multimedia;ethnography;internet privacy;television;file sharing	HCI	-55.43114651953144	-40.89828246249442	116624
e7bebf9e60575b3d5fc89d0937e9dfdce38be057	how much control is enough? influence of unreliable input on user experience	human computer interaction;human computer interaction brain computer interfaces;games accuracy noise keyboards brain visualization electroencephalography;brain computer interfaces;simple game user experience brain computer interfaces bci human computer interaction systems body based inputs gesture based systems gaze based systems perceived control;human computer interaction brain computer interfaces computer interfaces	Brain-computer interfaces (BCI) provide a valuable new input modality within human-computer interaction systems. However, like other body-based inputs such as gesture or gaze based systems, the system recognition of input commands is still far from perfect. This raises important questions, such as what level of control should such an interface be able to provide. What is the relationship between actual and perceived control? And in the case of applications for entertainment in which fun is an important part of user experience, should we even aim for the highest level of control, or is the optimum elsewhere? In this paper, we evaluate whether we can modulate the amount of control and if a game can be fun with less than perfect control. In the experiment users (n=158) played a simple game in which a hamster has to be guided to the exit of a maze. The amount of control the user has over the hamster is varied. The variation of control through confusion matrices makes it possible to simulate the experience of using a BCI, while using the traditional keyboard for input. After each session the user completed a short questionnaire on user experience and perceived control. Analysis of the data showed that the perceived control of the user could largely be explained by the amount of control in the respective session. As expected, user frustration decreases with increasing control. Moreover, the results indicate that the relation between fun and control is not linear. Although at lower levels of control fun does increase with improved control, the level of fun drops just before perfect control is reached (with an optimum around 96%). This poses new insights for developers of games who want to incorporate some form of BCI or other modality with unreliable input in their game: for creating a fun game, unreliable input can be used to create a challenge for the user.	brain neoplasms;brain–computer interface;cdisc adas-cog - commands summary score;confusion matrix;human–computer interaction;modality (human–computer interaction);simulation;user experience;keyboard;recurrent childhood brain stem glioma	Bram van de Laar;Danny Plass-Oude Bos;Boris Reuderink;Mannes Poel;Anton Nijholt	2013	IEEE Transactions on Cybernetics	10.1109/TCYB.2013.2282279	brain–computer interface;simulation;human–computer interaction;computer science;artificial intelligence;multimedia;user interface	HCI	-48.595925938161514	-46.28061800435513	116642
2e5cc813c6f9ddddff6bdb921fbc570a4c4e9138	majic videoconferencing system: experiments, evaluation and improvement	video image;verbal information;important factor;life-size video image;eye contact;majic videoconferencing system;facial expression;new majic prototype;verbal language;majic environment;non-verbal information	We need to know the real intentions of participants that are not expressed by verbal languages This means that not only verbal information but also non-verbal information (i e , gestures, facial expression, eyes of participant, etc.) is a very important factor We proposed and implemented MAJIC, a multi-party videoconferencing system that enables eye contact among people in remote places, with life-sized images of participants In order to evaluate users' perceptions of MAJIC, we have experimented with the size, background and boundary of the video images. These experiments verify the sense of presence in MAJIC environments where life-size video images without boundaries are supported We developed a new MAJIC prototype based on these experiments	anomalous experiences;experiment;need to know;prototype	Yusuke Ichikawa;Ken-ichi Okada;Giseok Jeong;Shunsuke Tanaka;Yutaka Matsushita	1995			computer vision;simulation;computer science;multimedia;communication	HCI	-50.488621162905964	-48.74880555724077	116696
1ad473d67aec7e379809bb6fd8d247d215b683a0	generating queries and replies during information-seeking interactions	satisfiability;hierarchical representation;information transfer;information seeking	Analysis of naturally occurring information-seeking dialogues indicates that they usually consist of a number of distinct discourse segments, such as a greeting segment, a request issued by a user, an optional clariication segment, a transfer of information segment, and a nal closing segment. The clariication interaction is often initiated by the information provider, and it may be due to one of the following reasons: (1) there is confusion regarding the user's intentions, (2) there is insuucient information to formulate a plan to satisfy a recognized intention, or (3) there is diiculty in formulating a plan that satisses a recognized intention. Once the information provider determines the user's intention and formulates a plan to achieve this intention, the information transfer phase is initiated to inform the user about the proposed plan. In this paper, we present a mechanism for generating queries during the clariication stage and answers during the information transfer stage. Given a hierarchical representation of the alternatives possibly intended by a user, and the probabilities of these alternatives, our mechanism determines the hierarchy level at which a query must be directed, and the query to be posed in order to determine the alternative intended by the user. Once the user's intentions are ascertained, the mechanism determines whether additional information is required and the manner in which queries may be posed to acquire this information. When a user's intentions cannot be satissed by means of a single plan, our mechanism enters into a negotiation process to alter the user's speciications until a valid plan is formulated. In the nal stages of the interaction, the mechanism determines the information to be transferred and generates an answer to eeect the transfer. The mechanisms for negotiation and for the generation of queries and answers described in this paper have been implemented in a system called radar, a computerized information providing system that functions as a travel agent.	closing (morphology);interaction;radar	Bhavani Raskutti;Ingrid Zukerman	1997	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1997.0150	information transfer;computer science;knowledge management;artificial intelligence;data mining;satisfiability	AI	-54.67656772494017	-45.2240122906693	116707
2dc99860a8c9c110c915565dd5477abd4f62571b	collecticiels: neuf degrés de couplage	coupling;groupware;multimodal interface;interaction modalities;experimentations	This paper is about the coupling of collaborative activities and the goal of this work is to refine the existing definition of coupling, based on an experimental and exploratory approach. Indeed, we suppose that the coupling may be characterized with nine degrees in a two dimension space. To do this, we have considered multimodal interfaces applied to groupware interfaces. Then, we have developed two applications, which one is detailed in this paper, in order to experimentally highlight the existence of these nine degrees. This first step seems to confirm our hypothesis.	collaborative software;coupling (computer programming);experiment;multimodal interaction	Frédéric Jourde;Yann Laurillau;Laurence Nigay	2009		10.1145/1629826.1629870	simulation;engineering;communication;engineering drawing	Robotics	-62.068718908854486	-40.03064479746897	116807
9c9b00b96d72bd28b1deb56b8e62b6d54611ae6c	effect of emotional synchronization using facial expression recognition in human-robot communication	facial expression recognition;communication system;human robot interaction emotion recognition;emotion recognition;doubling time;human robot interaction;humans robots synchronization emotion recognition face recognition vectors face;communication time emotional synchronization facial expression recognition human robot communication kansei communication system human emotional state;face recognition;vectors;synchronization;robots;face;humans;facial expression;synchronous communication;vector field	In this paper, we developed a KANSEI communication system between human and robot based on emotional synchronization to human emotional state using facial expression recognition. And we conducted experiments to evaluate the effectiveness of the proposed system. The robot recognizes human emotion through their facial expressions, and synchronizes its own emotion with the recognized emotion dynamically by using a vector field of dynamics. Then the robot expresses its own emotions by facial expressions. In the communication experiment, we found that the subjects' feeling became much comfortable after communicating with the robot in the case of emotional synchronization, while that the subjects felt a little uncomfortable after communicating with the robot in the case of non-synchronization. Meanwhile, subjects in the case of emotional synchronization communicated much more with the robot, and the communication time was as double times as the time when communicated in the case of non-synchronization. Furthermore, subjects communicated in the case of emotional synchronization had good impressions on the robot, and also were much better than the impressions in the case of non-synchronization. So it was confirmed in this study that the emotional synchronization in human-robot communication could be effective to make human keeping a comfortable state and would make the robot much more favorable and acceptable to human.	emoticon;experiment;robot;synchronization (computer science)	Yi Li;Minoru Hashimoto	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181741	facial recognition system;human–robot interaction;robot;face;synchronization;computer vision;vector field;computer science;doubling time;artificial intelligence;asynchronous communication;facial expression;communications system	Robotics	-50.7297914743727	-50.39113926674437	117106
32925a4d19f7fd589af2ad2617f3a590bd344849	deducing human emotions by robots: computing basic non-verbal expressions of performed actions during a work task	production planning human emotions nonverbal expressions human robot work task industrial setting emotional valence reinforcement learning agent actor critic algorithm;production planning control engineering computing human robot interaction industrial robots learning artificial intelligence;computational modeling robots sensitivity learning artificial intelligence ergonomics physiology standards	We have established an emotional model to enhance a virtual worker simulation, which could be also used to support robots in a joined human-robot work-task inside an industrial setting. The robot is able to understand people's individual and specific knowledge as well as capabilities, which are ultimately linked to an emotional consequence. As a result, the emotional model outputs the emotional valence calculated as positive or negative values, respective to reward and punishment. This output is applied as value function for a reinforcement learning agent. There we use an actor critic algorithm extended by eligibility traces and task specific conditions to learn the optimal action sequences. We show the influence of emotional reward leads to differences in the learned action sequences in comparison to a simple task performance evaluation reward. Therefore the robot is able to calculate emotional feelings of a human during a given working task, is able to decide if there is a better, more emotional stable path to doing this working task and moreover the robot is able to decide when the human is needed help or even not.	actor model;algorithm;bellman equation;performance evaluation;reinforcement learning;robot;simulation;tracing (software)	Martina Truschzinski;Helge U. Dinkelbach;Nicholas H. Müller;Peter Ohler;Fred Hamke;Peter Pretzel	2014	2014 IEEE International Symposium on Intelligent Control (ISIC)	10.1109/ISIC.2014.6967618	simulation;computer science;artificial intelligence;communication	Robotics	-50.22733345392157	-50.90753927517362	117266
4e257f617c3de4fd9a80c9ad2081d468e17c54de	frustrating the user on purpose: using biosignals in a pilot study to detect the user's emotional state	pilot study;human computer interaction;emotion physiology;user interface;affect;interface design;social science;biosensing;context dependent;affective computing	Our goal was to develop a computer system trained to sense a user’s emotional state via the recognition of physiological signals. In the course of developing an exploratory pilot study toward this end, we encountered and addressed unique and context-dependent interface design and synchronization challenges. We used social science methods to induce a state of frustration in users, collected the physiological data, and developed an effective strategy for coupling these data with real-world events.	computer;context-sensitive language;pilot ace	Jocelyn Riseberg;Jonathan Klein;Raul Fernandez;Rosalind W. Picard	1998		10.1145/286498.286715	user experience design;simulation;human–computer interaction;computer science;interface design;context-dependent memory;affective computing;user interface;biosensor;affect	HCI	-54.01925411792918	-46.234739894504216	117321
88d6f1b6bc290d702aac82983cb5dff34645d057	accessible design through shared user modelling	user modelling;mobile device;touch screen;mathematics manipulation;accessibility;visual impairments;adaptive user interface;user interaction;domain specificity;user model	In the proposed thesis, research examines possible exploitations of shared user modelling in order to improve the accuracy and scope of models used for personalisation within touch screen mobile devices to improve the accessibility and usability of software applications. Previous work in adaptive user interfaces has relied on local and domain specific user models, which lack in scope and detail. Shared user models can increase the accuracy and depth of data used to adapt the interfaces and user interactions.	accessibility;adaptive user interface;interaction;mobile device;personalization;touchscreen;usability	Kyle Montague	2011	ACM SIGACCESS	10.1145/1948954.1948960	user interface design;user;10-foot user interface;user experience design;user modeling;computer user satisfaction;human–computer interaction;computer science;user requirements document;accessibility;mobile device;multimedia;natural user interface;user interface;world wide web	HCI	-49.45673514431531	-40.99889155633476	117347
562e9a8cc39068c0f6684a486e68a1f351d624bf	scenario-based requirements capture for human factors integration	pedestrian safety;life cycle;poison control;injury prevention;safety literature;trace;traffic safety;injury control;software engineering;cognitive;requirements;home safety;usability engineering;support system;injury research;safety abstracts;human factors;system;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;scenarios;falls;cognitive function;use case;functions;ergonomics;suicide prevention;hfi	Scenarios have been used by many engineering disciplines to assist the quality of their professional application to systems throughout a system life-cycle. At early phases of the system life-cycle, Systems and Software Engineers have adopted the Use Case as a means of representing system requirements through the address of user functions. Furthermore, usability engineers also use scenarios as a means of promoting better usability of systems throughout the system life-cycle. Moreover, all practitioners of the mentioned disciplines use some form of requirements capture and trace throughout the system life-cycle. However, in general Human Factors (HF) and Human Factors Integration (HFI) practitioners do not. This paper examines the efficacy of the multi disciplinary use of scenarios to assist the capture of HFI and system requirements. Such an approach benefits the early establishment of requirements and thus supports system life-cycle trace and matching of both physical and cognitive functions.	cognition;human factors and ergonomics;human factors integration;requirement;software engineer;system lifecycle;system requirements;usability engineering	Iain S. MacLeod	2007	Cognition, Technology & Work	10.1007/s10111-007-0099-3	psychology;reliability engineering;cognition;medicine;human–computer interaction;systems engineering;engineering;human factors and ergonomics;computer security;mechanical engineering	SE	-61.500466757084574	-46.794219758507204	117514
53f4135aa5a32e130a3a55990be6f011c2e192e5	accessibility evaluation of rich internet applications interface components for mobile screen readers	aria;visually impaired users;mobile web accessibility;rich internet applications;screen reader users	The growth in the use of mobile devices to use Websites has made it important to carefully consider how accessible they are to disabled users. In particular, the accessibility of Rich Internet Applications (RIA) poses serious challenges for visually impaired users employing screen readers. In this study, we performed an accessibility evaluation of a sample of 25 interface components from the Bootstrap front-end framework. The evaluation involved conformance analyses of the components with the Accessible Rich Internet Applications (ARIA) 1.0 and expert manual evaluations of interfaces using Android's TalkBack and Apple iOS's VoiceOver screen readers. The results showed that the sampled interface components were in conformance with ARIA's techniques. However, in the empirical tests, 10 of 25 components in TalkBack and 4 of 25 components in VoiceOver, showed accessibility problems that can cause serious issues to visually impaired users on mobile devices. This shows that developers need to be aware of mobile devices' screen readers limitations even when implementing compliant interface components, and that more work needs to be done to provide more satisfactory interaction for RIA to be used by visually impaired users on mobile devices.	accessibility;android;bootstrapping (statistics);conformance testing;crash reporter;mobile device;mobile phone;rich internet application;wai-aria;ios	Lucas Pedroso Carvalho;Lucas Pereira Ferreira;André Pimenta Freire	2016		10.1145/2851613.2851680	rich internet application;computer science;multimedia;internet privacy;world wide web	HCI	-50.80342371150688	-42.145983705592805	117712
33234f6fbcb36bcdb307ee0d7a4a8fd2a8ff10dc	a context-aware framework for collaborative activities in pervasive communities		Pervasive environments involve the interaction of users with the objects that surround them and also other participants. In this way, pervasive communities can lead the user to participate beyond traditional pervasive spaces, enabling the cooperation among groups taking into account not only individual interests, but also the collective and social context. In this study, the authors explore the potential of using context-aware information in CSCW application in order to support collaboration in pervasive environments. In particular this paper describes the approach used in the design and development of a context-aware framework utilizing users’ context information interpretation for behaviour adaptation of collaborative applications in pervasive communities. A Context-Aware Framework for Collaborative Activities in Pervasive Communities	collaborative software;computer-supported cooperative work;pervasive informatics;prototype;session (computer science);usability	Christopher Lima;Mário Antunes;Diogo Gomes;Rui L. Aguiar;Telma Mota	2014	IJDST	10.4018/ijdst.2014040103	context-aware pervasive systems;human–computer interaction;knowledge management	HCI	-57.21091864815532	-38.44570425597156	117897
0f17e8eca1f29aa96233bedb7f3cf22022bd6355	analysis of older users' perceived requests and opportunities with technologies: a scenario-based assessment	scenario assessment;focus groups;cognitive games;elderly people;user s needs	"""The HERMES Cognitive Care and Guidance for Active Aging project proposes an integrated approach to cognitive assistance, promoting the autonomy of elderly users through pervasive technology. This work aims to describe elderly people’s opinions when they are presented scenarios developed in this project. Two focus groups were organized in Austria and Spain with a view to collecting their impressions about the way in which the technological device can cover their needs; complementarily, a second session was conducted including a quantitative questionnaire. Although some participants were reluctant to use the technology, they welcomed some functionalities of the HERMES system and they considered that using them can help them to become familiar with them. Usefulness, usability, and use of real-life information for functionalities such as cognitive games are considered to be key areas of the project. This evaluation has provided the developers of the system with meaningful information to improve it and it guarantees that the system addresses elderly people’s needs. development of a series of new opportunities for leisure and social activities for older people. There are a number of studies attempting to find these applications and the relevance of these opportunities in the everyday life of elderly people (for a review, see Burdick & Kwon, 2004). DOI: 10.4018/jaci.2011010105 International Journal of Ambient Computing and Intelligence, 3(1), 42-52, January-March 2011 43 Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. Technology can be used directly by elderly people to enhance mental well-being and expand social engagement. However, older people are often reluctant to accept any technology that aims to reduce their autonomy or minimize their cognitive or functional efforts because it would mean dependency (Buiza, Gonzalez, Etxaniz, Urdaneta, Yanguas, et al., 2008). It has been shown that the assessment of needs in elderly people can improve the functionality of technology (Walters, Iliffe, See Tai, & Orrell, 2000). In this respect, analysis and understanding of the older users’ feelings when interacting with technology devices in different scenarios is a key requirement that adds value to assistive technology which could have a substantial impact on the users’ daily life. The HERMES (Cognitive Care and Guidance for Active Aging) project is cofunded by the European Commission within the 7th Framework Programme (http://www. fp7-hermes.eu/). Its objective is to reduce agerelated cognitive decline and facilitate episodic memory, advanced activities reminding and cognitive training. It provides assistance but also promotes the autonomy of users in their daily lives, using pervasive non obtrusive technology at home and outside the home. Aging is often accompanied by different types of age-related memory changes, especially episodic memory declines (Craik, 2000). This decline implies difficulties with the memory of autobiographical events that can be explicitly stated, such as times or places. Age-related deficits are also present in attention processes, partly because of the increased difficulty of older adults to filter out irrelevant information, to establish clear goals and to inhibit irrelevant information (Mayhorn, Rogers, & Fisk, 2004), and in executive capabilities related to abstraction capabilities, reasoning about unfamiliar problems and self-monitoring (von Hippel, 2007). To sum up, these changes result in a loss of detail of memories, a reduced ability to plan one’s own life and a subsequent reduced quality of life. It is explicitly not the goal of the project to make people dependent on the HERMES system, but rather to provide support, increase the feeling of security and avoid the fear of forgetting. The first step in this project was to carry out a requirement analysis by means of a questionnaire, focus groups, diaries, cultural probes, interviews and memory assessment (Urdaneta, Buiza, Gonzalez, Facal, Geven et al., 2009). This analysis provided us with relevant information to formulate real scenarios where the HERMES system can be used. According to Carroll (1995), scenarios contain and describe a setting, the agents or actors, their goals and purposes and the things they do. From scenarios we get a context in which the actors act with the product. The use of scenarios not only serves to aid technical development, but they are also useful in communication with the potential end-users to come up with requirements for the tools and applications that are developed within the HERMES project. The scenarios provide an instantaneous vision of a specific setting and its context and they offer a way to imagine design concepts in use (Saffer, 2007). They give us a way of describing an application and, more important, an interaction with an application in words. Because of this they can be used to communicate and transform the findings from the requirements analysis into a prototype. Five scenarios linked to the HERMES objectives have been developed. The scenarios were composed using the results from the requirements analysis. Based on an overview of the results of the requirements analysis, five scenarios for each of the HERMES objectives have been developed: (a) Facilitation of episodic memory, through the capture of content in audio (Petsatodis & Boukis, 2009) and video (Katsarakis & Pnevmatikakis, 2009) including when, where, who, what and why. Advanced intelligent speech and image processing techniques are being developed to index, annotate, and summarize the information captured, based on semantics extraction, events identification and inferences. The 9 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/analysis-older-users-perceivedrequests/52040?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	assistive technology;autonomy;carroll morgan (computer scientist);computer science;focus group;image processing;interaction;librarian;pervasive informatics;prototype;real life;relevance;requests;requirement;requirements analysis;usability;web page	Mari Feli González;David Facal;Ana Belén Navarro;Arjan Geven;Manfred Tscheligi;Elena Urdaneta;José Javier Yanguas	2011	IJACI	10.4018/jaci.2011010105	simulation;human–computer interaction;knowledge management;focus group;multimedia	HCI	-62.059343007623575	-41.145349681724475	118186
e3b23ae0c264b70ffdfc9d43f72c37d9c328e224	mobile attachment: emotional attachment towards mobile devices and services	theoretical framework;mobile device;user experience;ages;user behavior;experience sampling method;mobile attachment	In my thesis I address the topic of mobile attachment. I provide a theoretical framework for mobile attachment together with influencing factors that indicate user's emotional attachment (EA) to mobile devices and services. I investigate how the concept of user experience (UX) and EA are linked together and I outline how user behavior driven experience sampling can be exploited to measure mobile attachment. My research will result in design suggestions how the creation of EA to mobile devices and services can be facilitated.	a/ux;attachments;mobile device;sampling (signal processing);user experience	Alexander Meschtscherjakov	2009		10.1145/1613858.1613975	user experience design;simulation;human–computer interaction;computer science;operating system;mobile device;multimedia;experience sampling method	HCI	-57.17731996787112	-41.40628366152243	118525
05cef3118817c0a43049d048cfab7f19ff98ceff	physiological data gathering in mobile environments	data gathering;mobile environment;user experience;assessment methods;mobile environments;physiological interaction;interaction technique	Mobile environments and applications have been the target of extensive research with a focus on usability assessment methods and combating user experience issues. These methods rely mostly on observable data, discarding a significant amount of data which can be captured from the users. Physiological measures capture is a growing research theme in which biological signals are used as means to interact with an application. This type of interaction allows researchers to access data which would otherwise be concealed using traditional assessment techniques. This paper describes the use of such interaction techniques in mobile environments through the use of a comprehensive platform which integrates means to assess users' heartbeat rate.	interaction technique;observable;usability;user experience	Luís Duarte;Marco de Sá;Luís Carriço	2010		10.1145/1864431.1864459	user experience design;simulation;human–computer interaction;computer science;data mining;interaction technique;data collection	HCI	-57.106896895045324	-44.229284646333205	118602
b4e85fe6adec448a0a74129a934b36023bd66cb2	qoe assessment for broadcasting multi sensorial media in smart home scenario		One of the goals of future TV broadcast services is to provide realistic media contents to the users. The user's sense of reality can be reinforced by adding to conventional media multiple sensorial effects, through five-sense stimulus (i.e., taste, sight, touch, smell, and hearing). In a smart home environment, to deliver the additional effects, customary devices (e.g., air conditioning, lights, etc.), provided of opportune smart features, have to be preferred to ad-hoc devices, often deployed in other applications as for example in gaming systems. In this context, a key issue is the interconnection among the TV and the customary devices that deliver the additional sensorial effects to the user. In such a framework, home customary devices play a role to implement additional effects to the conventional broadcast TV service. In this study, a prototype is implemented for broadcasting multi sensorial media in a real smart home scenario. Real customary devices are deployed. A subjective test measurement campaign based on mean opinion score was performed to assess the Quality of Experience of the users and the feasibility of the proposed multi sensorial media TV service.	hoc (programming language);home automation;interconnection;prototype;smart pascal	Lana Jalal;Matteo Anedda;Vlad Popescu;Maurizio Murroni	2018	2018 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)	10.1109/BMSB.2018.8436875	mean opinion score;computer science;air conditioning;computer network;sight;multimedia;home automation;broadcast television systems;quality of experience;test measurement;broadcasting	Mobile	-53.70879530541813	-42.332360881649436	118779
3871912682d3aa30409a74ebcc1e8e57088e2457	towards to ubiquitous affective learning	cognitive science;ubiquitous learning;electroencephalography;facial expression	With the development of computer science, cognitive science and psychology, a new paradigm, affective learning, has emerged into e-learning/ubiquitous learning domain. Although scientists and researchers have achieved fruitful outcomes in exploring the ways of detecting and understanding learners affect, e.g. eyes motion, facial expression etc. in ubiquitous environment, it sounds still necessary to deepen the recognition of learners affect in learning procedure with innovative methodologies. Our research focused on using bio-signals based methodology to explore learner’s affect and the study was primarily made on Electroencephalography (EEG). For the purpose of evaluating our findings, we also developed an ubiquitous affective learning prototype. The result of experiment was encouraging and more theoretical and practical work should be investigated in this subject. R.-S. Chang et al. (Eds.): GPC 2010, LNCS 6104, p. 4, 2010. c © Springer-Verlag Berlin Heidelberg 2010	british informatics olympiad;cognitive science;electroencephalography;lecture notes in computer science;programming paradigm;prototype;sensor;springer (tank)	Bin Hu	2010		10.1007/978-3-642-13067-0_4	human–computer interaction;electroencephalography;learning sciences;facial expression	AI	-56.86511698677931	-49.541214960665656	118783
13fdd46db93a8f204187f19dc99c19d251b24ef5	i smell creativity: exploring the effects of olfactory and auditory cues to support creative writing tasks		Humans perceive different objects, scenes or places using all their senses. Our sensory richness also plays an important role for creative activities. Humans also recall those sensory experiences in order to spark creativity, e.g. while writing a text. This paper presents a study with 100 students, divided in groups, that explores the effect of auditory and olfactory cues and their combination during a creative writing exercise. Our results provide useful insights suggesting that olfactory cues have an important role in the creative process of users and even when this type of cues are combined with auditory cues. We believe, that this type of modalities should gain more relevance on the development of creativity support tools and environments for supporting the creative writing process.	experience;humans;relevance;sensory neuroscience	Frederica Gonçalves;Diogo Cabral;Pedro F. Campos;Johannes Schöning	2017		10.1007/978-3-319-67684-5_11	creative writing;multimedia;modalities;olfaction;cognitive psychology;odor;computer science;sensory system;recall;creativity	HCI	-54.28744887691772	-48.77912741753839	118863
577c663aabf7d84bacdd60f7edc25efd58c64b84	ecological interfaces: extending the pointing paradigm by visual context	language comprehension;interfaz multimodal;comprension verbal;linguistica matematica;multimodal interface;man machine dialogue;information visuelle;comprehension verbale;simulation experiment;verbal comprehension;informacion visual;computer science computation and language;visual information;multimodal system;dialogo hombre maquina;linguistique mathematique;visual perception;software architecture design;comprension lenguaje;comprehension langage;computational linguistics;analyse contextuelle;interface multimodale;dialogue homme machine	Following the ecological approach to visual perception, this paper presents an innovative framework for the design of multimodal systems. The proposal emphasises the role of the visual context on gestural communication. It is aimed at extending the concept of affordances to explain referring gesture variability. The validity of the approach is confirmed by results of a simulation experiment. A discussion of practical implications of our findings for software architecture design is presented.	heart rate variability;multimodal interaction;programming paradigm;simulation;software architecture;spatial variability;spontaneous order;systems design	Antonella De Angeli;Laurent Romary;Frederic Wolff	1999		10.1007/3-540-48315-2_8	natural language processing;software architecture;visual perception;computer science;computational linguistics;linguistics	HCI	-52.3580533813887	-46.95859189150022	118929
3751c241c14e73843c45b57d6a82301c5ba61515	social welfare and inequality in a networked resource game with human players	games erbium network topology robots educational institutions avatars analytical models;robots social welfare networked resource game graphical online game human player experiments;behavioural sciences computing;computer games behavioural sciences computing;computer games	This paper introduces the networked resource game with human players, implemented by a graphical online game where players can play their cards and accumulate rewards. We analyze social welfare and inequality through human players experiments, and show how these relate to the results of simulations using algorithms and robots.	algorithm;experiment;graphical user interface;robot;simulation;social inequality	Bowen Ni;Yu-Han Chang;Rajiv T. Maheswaran	2013	2013 International Conference on Social Computing	10.1109/SocialCom.2013.153	non-cooperative game;video game design;combinatorial game theory;game design;simulation;computer science;game mechanics;distributed computing;game developer;multimedia;screening game;simulations and games in economics education;sequential game	Robotics	-56.1683583019967	-47.09207651248915	119228
b420a6f8d1cca93d0673ca50f32df6a18261c8e7	human factors of journal usage and design of electronic texts	human factors	The present paper reports on a study of journal usage amongst human factors researchers. The aim of the study was to shed light on how journals are used with a view to making recommendations about the development of a full-text, searchable database that would support such usage. The results indicate that levels of usage vary over time, the range of journals covered is small and readers overlook a large proportion of the contents of articles. Furthermore, three reading strategies are observed which indicate that the presentation of journal articles is not ideally suited to their uses. The implications of these findings for developing suitable computer-based applications are discussed.	human factors and ergonomics	Andrew Dillon;John Richardson;Cliff McKnight	1989	Interacting with Computers	10.1016/0953-5438(89)90025-8	human–computer interaction;computer science;human factors and ergonomics;multimedia;world wide web	HCI	-60.530819064939024	-47.9441713035246	119286
1096c4cb0944d5e8f59649bc82f0034f1c7fe328	feature - understanding convergence	understanding convergence	interviews about how people communicate , view TV, play games, use the Internet, listen to music, and inform themselves. We spend time with all the members of the household and often ask them to keep diaries of their activities. In 2005 we also started a longitudinal study with 60 households that we will follow until the end of 2008, looking at every aspect of their ICT usage at home. Ethnographic user studies have become a staple of many companies that want to be at the edge of innovation. What makes our experience unique is our focus on all the ICT technology in the home, from PC to TV, from hi-fi to mobile phone, from land line to digital camera. We systematically put this in the context of people's daily schedules and lifestyles. When we look at the evolution of communication patterns, we compare the use of all channels and devices and can therefore consider the full palette of tools our participants have at their disposal. The Divergence of Communi­ cation Channels. One of the recurring questions in the debate about converged services concerns the interrelation of different communication channels, such as email, mobile voice, instant mes-saging, and SMS. Should all channels be on every device? Should we be able to seamlessly move from one channel to another? Should content and communication be linked more closely? And most significantly, what benefits will users find in the convergence of all the channels? In the past three years, we have asked more than 500 people, from all age groups, life stages, professional, linguistic, and regional backgrounds, to keep a record of all their communications , with the exclusion of professional exchanges and face-to-face conversations. Participants have been asked to keep a diary for four days, jotting down every mediated interaction. This includes dialogues that occurred via SMS, email, voice calls on the landline and mobile phone, and IM sessions or calls from the PC. For each exchange we asked participants to indicate whom they've communicated with, which channel they used, what topic they discussed, and other critical information about the call. We have then gone back to discuss the diary with the participants individually, in order to understand, line by line, why they chose one channel of communication over another. When discussing, for instance, the rationale behind selecting SMS instead of a phone call, it becomes obvious that the reasoning is highly sophisticated …	design rationale;digital camera;e-services;email;instant messaging;internet;landline;mobile phone;palette (computing);schedule (computer science)	Stefana Broadbent;Valerie Bauwens	2008	Interactions	10.1145/1330526.1330536		HCI	-58.81168463296485	-38.52106625196556	119362
75949f01b4fbd01db5031f6cf7dcb89b63820831	fashion victims	skin blush;hertzian space;wearables;fashion victims;social consequences of mobile communication;critical design;mobile communication;bleed;emf;clothing;phone calls	Making the invisible visible in the world of mobile communication. The ubiquitous presence of mobile communication devices - and the fashion in which they are adopted by different cultures - is not only redefining the way people communicate but also the way they more generally behave. Mobile communication devices, particularly mobile phones, introduce a digital space overlapping the physical space of the body: the birth of this hybrid space brings along a number of social consequences, most of which still invisible, hard to map and to explain. Adopting a critical approach in creating wearable probes apt to explore and illustrate this space is here proposed as a valuable strategy in order to make the invisible visible in the world of mobile communication. In Fashion Victims we chose clothing as the medium for making this invisible world visible; we have designed a collection of garments that react (respond and change) according to the surrounding mobile phone calls. We want to see what would happen if our clothes - everyday objects that we carry on our person - were able to display this presence. The metaphor we have decided to use for visualizing mobile communication comes directly from nature: clothes, as a second skin, react to the environment and change in color. Here, as more and more phone calls are conducted in their surroundings, the clothes progressively and permanently change color. Fashion Victims subverts the expected behavior of an everyday object to create and raise awareness about the subject of mobile communication. By producing a physical result with every call, the mobile phone is revealed in all of its pervasiveness and intrusiveness: its tendency to violate the private space we potentially have within the public context. http://www.fashionvictims.org.	color;definition;mobile phone;wearable computer	Davide Agnelli;Dario Buzzini;Tal Drori	2004		10.1145/1013115.1013162	simulation;mobile telephony;wearable computer;computer science;engineering;artificial intelligence;electromotive force;clothing	HCI	-48.857041381068534	-40.54675491021963	119680
fd12d6298f36b4e159392c489e0258f37790edc4	assistive technology solution for blind users based on friendsourcing		In this paper, IT-based solution was proposed an assistance tool for blind users to enable them to deal with their daily activities while supporting their privacy. This solution is based on the friend-sourcing concept through the integration between the capabilities of both the smartphone and the social networking website (Twitter). The proposed solution not only supports the English but also the both Arabic language which is highly needed for the Arabic world. The first stage of this solution (capturing and saving the video by the blind user) was implemented and evaluated through a field study consisting of a number of blind users who were happy with the idea and found the current stage of the prototype easy of use.	assistive technology	Dina A. Abdrabo;Tarek Gaber;M. Wahied	2015		10.1007/978-3-319-26690-9_37	multimedia;arabic;activities of daily living;social network;computer science;crowdsourcing	HCI	-54.734824210755264	-40.62285461538857	119950
509d8621511aced6e9b18a74bfedf4ed1f0406f2	effects of image-based rendering and reconstruction on game developers efficiency, game performance, and gaming experience		Image-based rendering and reconstruction (IBR) approaches minimize time and costs to develop video-game assets, aiming to assist small game studios and indie game developers survive in the competitive video-game industry. To further investigate the interplay of IBR on developers’ efficiency, game performance, and players’ gaming experience we conducted two evaluation studies: a comparative, ecologically valid study with professional game developers who created games with and without an IBR-based game development pipeline, and a user study, based on eye-tracking and A/B testing, with gamers who played the developed games. The analysis of the results indicates that IBR tools provide a credible solution for creating low cost video game assets in short time, sacrificing game performance though. From a player’s perspective, we note that the IBR approach influenced players’ preference and gaming experience within contexts of varying levels of player’s visual intersections related to the IBR-created game assets.	a/b testing;ecology;eye tracking;image-based modeling and rendering;scalability;usability testing;video game developer;video game development	George E. Raptis;Christina P. Katsini;Christos Fidas;Nikolaos M. Avouris	2017		10.1007/978-3-319-67684-5_6	simulation;game testing;multimedia;computer science;game art design;game design;video game development;game design document;game developer;level design;game development tool	HCI	-59.78816138634309	-45.42445202044754	119977
20ba352e53451444c91bcb2a92bc6efc661057b6	icf based usability scale: evaluating usability according to the evaluators' perspective about the users' performance	usability assessment scale;disability and health;international classification of functioning;scale validation	The ICF based Usability Scale (ICF-US) is a generic usability evaluation scale based on the conceptual model of the International Classification of Functioning, Disability and Health (ICF) and consists of two subscales. This usability evaluation instrument is part of a comprehensive framework for the design, development and evaluation of Ambient Assisted Living (AAL) products and services for older adults.  The ICF-US has been previously validated for self-perceived usability. The aims of the study reported in this paper were to verify if ICF-US is also suitable for usability evaluation of AAL products or services considering the opinion of the evaluators about the users.  The results indicate that the ICF-US can be useful tool for usability evaluation of AAL products or services based on the evaluators' perspective about the users' performance.	atm adaptation layer;usability;windows firewall	Ana Isabel Martins;Alexandra Queirós;Anabela G. Silva;Nelson Pacheco da Rocha	2016		10.1145/3019943.3019997	usability goals;pluralistic walkthrough;web usability;cognitive walkthrough;usability;human–computer interaction;systems engineering;engineering;system usability scale;usability engineering;multimedia;heuristic evaluation;usability lab;usability inspection	HCI	-62.440481083321565	-46.7787384982143	120038
125d1b6db3e3186bf94b70a84b21b5160b8f1141	an initial model for designing socially translucent systems for behavior change	social translucence;conceptual model;behavior change	Applications aiming at behavior change are gaining momentum within HCI. Much of that work has been built upon the idea of psychological empowerment. We report on a qualitative study that aimed at inquiring at an alternative path to behavior change through strengthening individuals' feelings of personal accountability. Two behavior-change-related scenarios were construed to evaluate how people perceive socially translucent systems aiding the process of behavior adaptation. We found that motivation to change is shaped by the access to information concerning one's behavior, by the type of provided feedback and the strength of the social ties accessing that information. Based on these results we propose an initial model defining possible approaches that can be considered when designing socially translucent systems supporting behavior change.	freedom of information laws by country;human–computer interaction	Mary Barreto;Agnieszka Matysiak Szóstek;Evangelos Karapanos	2013		10.1145/2499149.2499162	psychology;behavior change methods;knowledge management;communication;social psychology;behavior management	HCI	-58.91682789682229	-41.1854867160965	120070
924db1bc0f3a9da9484344ce34814a00d21dee5e	users' interaction with world wide web resources: an exploratory study using a holistic approach	cognitive style;interfase usuario;red www;user interface;information retrieval;interaction;donnee factuelle;holistic approach;conceptual framework;affectif;dato factografico;analyse registre transaction;affective state;transaction log analysis;state trait anxiety inventory;internet;recherche information;transaction log;comportement utilisateur;cognition;registre transaction;cognicion;world wide web;angustia ansiedad;interface utilisateur;reseau www;angoisse anxiete;affective;user behavior;recuperacion informacion;questionnaires;modeling methodology;affective measures;anxiety;exploratory study;man machine systems;models;factual data;comportamiento usuario;graduate student	This paper presents the first part of the research on user–Web interaction: a multidimensional model, methodology, and general findings. The objectives of this study are three-fold: (1) to explore factors of user–Web interaction in finding factual information and what happens during this interaction; (2) to develop a conceptual framework for studying user–Web interaction; and (3) to apply a process-tracing method for conducting holistic user–Web studies. The proposed model consists of three components:  user, interface , and the  World Wide Web . User–Web interaction is viewed as a communication process facilitated through an interface. A process-tracing technique has been designed to capture the processes of user-Web interactions. Twenty-four graduate students participated in this study. Prior to the interaction, each participant was given a questionnaire to report his/her computer and Web experience, the State Trait Anxiety Inventory (form Y1 and form Y2) to measure affective states, and an individually administered Embedded Figure Test to measure cognitive style. Each participant used the Web to find answers to two factual questions. Both the processes (continuous screen shots) and the concurrent verbalizations of thoughts were recorded in synchronized video–audio data. The findings provided rich information on users’ cognitive, affective and physical behaviors. The proposed model is used to present the findings of user behavior in connections with interfaces and the Web.	holism;web resource;world wide web	Peiling Wang;William B. Hawk;Carol Tenopir	2000	Inf. Process. Manage.	10.1016/S0306-4573(99)00059-X	questionnaire;interaction;the internet;simulation;cognition;human–computer interaction;cognitive style;computer science;transaction log;conceptual framework;user interface;world wide web;information retrieval;exploratory research;statistics;affect;anxiety	DB	-58.32194116987177	-48.10282176976139	120353
2d5dc0fb58089b26c2069a24f4351834ba59819f	making pretense visible and graspable: an augmented reality approach to promote pretend play	cotton;mirrors;autism;bridges;pretend play;ar technology augmented reality pretend play behavior autism linguistic competency social competency creativity competency;handicapped aids;airplanes;autistic children augmented reality pretend play;handicapped aids augmented reality;augmented reality;autism augmented reality airplanes mirrors bridges educational institutions cotton;autistic children	Children with autism are often found to lack facility for pretend play. It is believed that this deficit is linked to linguistic, social and creativity competencies in autism. We observe that both Augmented Reality (AR) and pretend play involve processing of information that is coupled with real scenes while not necessarily being directly perceived. This research therefore examines the potential of using AR technologies to promote pretend play behaviors in children with autism. As an initial outcome, we present the design and implementation of an AR system that aims to enhance the comprehension and flexibility of object substitution during pretend play.	augmented reality;bmc remedy action request system;play store	Zhen Bai;Alan F. Blackwell;George Coulouris	2012	2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)	10.1109/ISMAR.2012.6402567	augmented reality;simulation;autism;computer science;cotton	Visualization	-55.95010827673694	-47.855130968360534	120370
2764da7758aa053ea4a5cd95a59b5a9cac8833c8	sensitive braille displays with atc technology (active tactile control) as a tool for learning braille	learning process;blind users;interactive learning	The Idea of a Sensitive Braille DisplayAccess to computers for blind users can be provided with speech and/or Braille output. A Braille display providing Braille output can interact with the computer. In order to be able to use a Braille display as an effective control unit for the computer is was the goal to create a sensitive Braille display which can detect the tactile reading position of the blind user. The research of how to detect the tactile reading position on a Braille display has lead to the invention of ATC (Active Tactile Control). New tools based on ATC for can be created for interactive learning, monitoring the learning process as well as assistance functions. State of the Art Braille Displays Braille presented as tactile raised dots for each character are a common tool for accessing information for blind users. Compared to speech output systems, Braille presented on a Braille display offers a lot of advantages. 1. Braille offers the possibility to show structured information enabling blind users to grasp the structure of a document and the positioning of elements like in a table. 2. Braille is the only possibility for blind users for a self determined reading. Like a sighted reading a book, the blind user can determine the reading speed and pattern, he can choose to read sections several times or move on to other sections where in comparison speech output simply announce the information whether the user want to hear them or not. 3. Braille is an excellent literacy tool. Compared to speech output, with Braille, users can actually experience the exact spelling of words which opens up a complete different approach to access information compared to speech. Since only 40 or 80 characters of the whole screen are shown on the Braille display it is necessary to shift the section by using navigation keys. Until now, there was no technology available to detect the tactile reading position on a Braille display. The detection of the reading position will make it possible to improve the efficiency of a blind user to interact with a computer. For example, a text displayed on a Braille display could automatically be scrolled when the last character shown on the Braille display has been read. The speech output can be synchronized with the reading position, too.	advanced tactical center;advanced transportation controller;computer;control unit;refreshable braille display;tactile imaging	Siegfried Kipke	2008		10.1007/978-3-540-70540-6_125	speech recognition;engineering;multimedia;communication	HCI	-48.9893534246805	-43.22256677508294	120459
246b0547da7c49a66f2ae5a27f09d3de5890346d	growing food in the city: design ideations for urban residential gardeners	urban agriculture;urban informatics;food;gardening;sustainable hci;interaction design	Urban agriculture refers to the production of food in urban and peri-urban spaces. It can contribute positively to health and food security of a city, while also reducing 'food miles.' It takes on many forms, from the large and organised community garden, to the small and discrete backyard or balcony. This study focuses on small-scale food production in the form of residential gardening for home or personal use. We explore opportunities to support people's engagement in urban agriculture via human-computer interaction design. This research presents the findings and HCI design insights from our study of residential gardeners in Brisbane, Australia. By exploring their understanding of gardening practice with a human-centred design approach, we present six key themes, highlighting opportunities and challenges relating to available time and space; the process of learning and experimentation; and the role of existing online platforms to support gardening practice. Finally we discuss the overarching theme of shared knowledge, and how HCI could improve community engagement and gardening practice.	gardening (cryptanalysis);human–computer interaction;interaction design;residential gateway	Peter Lyle;Jaz Hee-jeong Choi;Marcus Foth	2015		10.1145/2768545.2768549	environmental planning;environmental engineering;engineering;civil engineering	HCI	-58.13803482095661	-38.61049650750316	120670
4bc13277b053ce5e5542a0b9f277df13f97aabef	exploring archaeological parks by playing games on mobile devices		Explore! is an m-learning system that combining e-learning and mobile computing allows middle school students to interact with learning materials in different ways while playing a game in an archaeological park. Design is based on user-centred and participatory approaches. The evaluation of Explore! through systematic field studies has shown that it is able to transform the visit to archaeological parks into a more complete and culturally rich experience. Thanks to the generality of the software infrastructure, games to be played in different parks can be easily created; to this aim, an Authoring Tool to be used by history experts and/or teachers has been developed.	mobile computing	Carmelo Ardito;Paolo Buono;Maria Francesca Costabile;Rosa Lanzilotti;Antonio Piccinno;Adalberto Lafcadio Simeone	2009	IxD&A		simulation;human–computer interaction;engineering;multimedia	HCI	-56.06195847816737	-38.5301815347242	120733
83d3742d19e996578eeef6435ee437a0386b037b	understanding online produce cue effects on consumer behavior: evidence from eeg data			electroencephalography	Ya-Ling Wu;Chun-Yu Hsiung	2018			consumer behaviour;computer science;knowledge management;cognitive psychology;electroencephalography	HCI	-55.531249182867164	-51.05314643857916	121297
1cc9cbe01f5855dcda78aa3257df705a6b01b78b	design of a virtual reality driving environment to assess performance of teenagers with asd		Autism Spectrum Disorder (ASD) is an extremely common and costly neurodevelopmental disorder. While significant research has been devoted to addressing social communication skill deficits of people with ASD, relatively less attention has been paid to improving their deficits in daily activities such as driving. Only two empirical studies have investigated driving performance in individuals with ASD—both employing proprietary driving simulation software. We designed a novel Virtual Reality (VR) driving simulator so that we could integrate various sensory modules directly into our system as well as to define task-oriented protocols that would not be otherwise possible using commercial software. We conducted a small user study with a group of individuals with ASD and a group of typically developing community controls. We found that our system was capable of distinguishing behavioral patterns between both groups indicating that it is suitable for use in designing a protocol aimed at improving driving performance.	auditory processing disorder;behavioral pattern;commercial software;driving simulator;electroencephalography;finite-state machine;hobbs meter;programming paradigm;simulation software;uml state machine;usability testing;virtual reality	Joshua W. Wade;Dayi Bian;Lian Zhang;Amy Swanson;Medha Shukla Sarkar;Zachary Warren;Nilanjan Sarkar	2014		10.1007/978-3-319-07440-5_43	simulation;developmental psychology;engineering;communication	HCI	-56.300145176363394	-52.01344852590442	121400
b96349695386a21b4644a947b78ba4f822da2d83	the important features of mobile phones: how context affects user evaluation?	large interactive display surfaces;user evaluation;mobile phone;computer supported collaborative work	The aim of this study was to find out what kind of features (functional or design aspects) real users evaluate. A secondary interest was to study how the context picture affects user evaluation of the requested features of a mobile phone. The purpose of the pictures was to create an impression of a certain context, in which the phones could be used. Two pictures were shown and the subjects were asked to mark the five features they considered important and five that they considered non-important. 36 subjects representing many different professions participated, and clear preferences were found. It seems that the idea of context was at some levels understood because the results of the two pictures were different.	functional programming;mobile phone	Laura Vesala;Toni Koskinen;Lauri Repokari;Teemu Seppälä;Sakari Tamminen	2001		10.1145/2331812.2331826	human–computer interaction;computer science;multimedia;world wide web	HCI	-56.92826062836455	-40.78378764698852	121536
460a918bf468aa54c3994397deb37caa8476346e	emotive non-anthropomorphic robots perceived as more calming, friendly, and attentive for victim management	emotion urban search and rescue;robotics;human robot interaction	This paper describes results from a large-scale, complex human study using non-facial and non-verbal affect for victim management in robot-assisted Urban Search and Rescue Applications. Statistically significant results are presented that indicate participants felt emotive robots were more calming, friendlier, and attentive.	robot	Cindy L. Bethel;Robin R. Murphy	2010			simulation;computer science;artificial intelligence;robotics	HCI	-52.549936037923295	-50.421405441291796	121741
191f0706f8134e607080af3f36db5205e6816b6f	the cross-domain re-interpretation of artistic ideas		The goal of this study was to investigate the translate-ability of creative works into other domains. We tested whether people were able to recognize which works of art were inspired by which pieces of music. Three expert painters created four paintings, each of which was the artist’s interpretation of one of four different pieces of instrumental music. Participants were able to identify which paintings were inspired by which pieces of music at statistically significant above-chance levels. The findings support the hypothesis that creative ideas can exist in an at least somewhat domainindependent state of potentiality and become more welldefined as they are actualized in accordance with the constraints of a particular domain.		Apara Ranjan;Liane Gabora;Brian O'Connor	2013			aesthetics	HCI	-54.000896769150174	-47.55244294396012	121812
306ec7e085fb4dc5d7c25c2c2350a76f0c1b05f9	smell-based memory recollection and communication support	olfactory modality;recollection;fond memories;communication	Many victims of The Great East Japan Earthquake lost many precious mementos. Such loses can result in more time being required to recover emotionally and mentally. This paper proposes an effective reminder management system using smell. The system focuses on fond memory recollection. Preliminary experiments using a device that produces smell showed that it was effective to help recall fond memories by smell. This system encourages us to remember fond memories using smell, record the smells into a system and communicates with people who have similar experience.	code smell;experiment	Yusuke Kita;Yoshio Nakatani	2011		10.1007/978-3-642-22950-3_14	psychology;artificial intelligence;communication;social psychology	OS	-54.82811376454512	-49.73783574753513	122034
38a9f63f23f33084ddeb08006fb118fe751480fe	alma: a layered model of affect	virtual characters;personality;real time;virtual human;modeling language;simulation of affect;cognitive process;emotion;embodied conversational characters;mood	In this paper we introduce ALMA - A Layered Model of Affect. It integrates three major affective characteristics: emotions, moods and personality that cover short, medium, and long term affect. The use of this model consists of two phases: In the preparation phase appraisal rules and personality profiles for characters must be specified with the help of AffectML - our XML based affect modeling language. In the runtime phase, the specified appraisal rules are used to compute real-time emotions and moods as results of a subjective appraisal of relevant input. The computed affective characteristics are represented in AffectML and can be processed by sub-sequent modules that control the cognitive processes and physical behavior of embodied conversational characters. ALMA is part of the VirtualHuman project which develops interactive virtual characters that serve as dialog partners with human-like conversational skills. ALMA provides our virtual humans with a personality profile and with real-time emotions and moods. These are used by the multimodal behavior generation module to enrich the lifelike and believable qualities.	modeling language;multimodal interaction;real-time clock;real-time locating system;xml;dialog	Patrick Gebhard	2005		10.1145/1082473.1082478	emotion;artificial intelligence;personality;modeling language	HCI	-52.91800328623559	-47.335309579427815	122254
d6a418139d18aadf1fa6f16bf0bebc18348adcf9	mobile refinding of web information using a voice interface: an exploratory study	conversation analysis;voice user interfaces;information sources;web pages;information refinding;user interface;information management;speech recognition;information need;exploratory study;voice user interface	Refinding information found on the web is a considerable problem for many users, especially when in mobile situations. In this paper, we explore how a voice-controlled service, accessible by telephone, could help to support mobile users' needs for refinding specific information previously found on the web. We outline challenges in creating such a service and describe architectural and user interfaces issues involved in an exploratory prototype system called WebContext.We also present the results of a study - motivated by our experience with WebContext - to explore what people remember about information that they are trying to refind and how they express information refinding requests in a collaborative conversation. The results and observations from our study: 1) add support and extend prior research on the importance of waypoints in the refinding process, 2) provide evidence that refinding may be accomplished using an iterative, two-stage model in which users first search for the information source, and then browse for the particular information being sought, revealing details of their information need as they make progress, and 3) give insights into the use of annotations added to web pages by the user to help in a collaborative refinding process. We also note the importance of context and artifacts in the refinding process and comment on the possible implications of our findings for the design of tools and interfaces for information refinding with a special emphasis on implications for voice interfaces for mobile refinding.	browsing;information needs;information source;iterative method;prototype;refind;user interface;waypoint;web page	Robert G. Capra;Manuel A. Pérez-Quiñones	2005		10.1145/1111360.1111369	human–computer interaction;computer science;multimedia;world wide web	HCI	-52.70363813014489	-41.05634545665601	122300
5f0157e8a852fc2b1b548342102405aa53c39eb9	usability engineering for augmented reality: employing user-based studies to inform design	artificial;multimedia information systems;design process;human computer interaction;design engineering;application software;user interface;virtual reality;user based studies;user centered design;indexing terms;style guides;multimedia information system;augmented;emerging technology;process design;user based studies usability engineering augmented reality human computer interaction user interface design ue approach;usability engineering;h 5 2 user interfaces;virtual realities;graphical user interfaces;human factors;guidelines;evaluation methodology;design guideline;algorithms biomedical engineering computer graphics computer aided design data display equipment design equipment failure analysis human engineering image enhancement image interpretation computer assisted imaging three dimensional man machine systems numerical analysis computer assisted signal processing computer assisted user computer interface;lessons learned;ue approach;screen design;and virtual realities;user interfaces augmented reality human computer interaction human factors;graphic user interface;user interface design;user centered design user interfaces evaluation methodology graphical user interfaces artificial augmented and virtual realities;information design;augmented reality;usability;user interfaces;ergonomics;usability design engineering augmented reality user interfaces guidelines human computer interaction process design virtual reality application software ergonomics	"""A major challenge, and thus opportunity, in the field of human-computer interaction and specifically usability engineering (UE) is designing effective user interfaces for emerging technologies that have no established design guidelines or interaction metaphors or introduce completely new ways for users to perceive and interact with technology and the world around them. Clearly, augmented reality (AR) is one such emerging technology. We propose a UE approach that employs user-based studies to inform design by iteratively inserting a series of user-based studies into a traditional usability-engineering life cycle to better inform initial user interface designs. We present an exemplar user-based study conducted to gain insight into how users perceive text in outdoor AR settings and to derive implications for design in outdoor AR. We also describe """"lessons learned"""" from our experiences, conducting user-based studies as part of the design process."""	ascii art;algorithm;augmented reality;behavior;color;contrast ratio;experience;human–computer interaction;usability engineering;user interface device component;user interface design	Joseph L. Gabbard;J. Edward Swan	2008	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2008.24	user interface design;user experience design;simulation;interactive systems engineering;human–computer interaction;computer science;human factors and ergonomics;graphical user interface;multimedia;user interface	Visualization	-49.12935866293933	-42.10871774782524	122580
8b7c3c6e79f054e8350977b23489e937792d4f4d	felt emotions		What does it mean “feeling” something? How body activation and its perception is crucial in emotional experience? How it impact on the cognitive components of human emotions and their “appraisal” function, or is affected by them? Which are the different mental paths of emotional experiences?	experience	Cristiano Castelfranchi	2015				HCI	-54.898462489679	-51.651117195399	122784
2f5560277ae3c0498cbdc881a9346515aaa1cd6a	a diary study of rendezvousing: implications for position-aware computing and communications for the general public	mobile;university student;personal computing and communications;personal computer;performance;position awareness;rendezvousing;computer science and informatics;diary study	This paper presents a diary study of rendezvousing as performed by university students. The study suggests that endezvousing frequently does not occur exactly as planned, but this is not necessarily problematic. It also reveals that 'problem' rendezvous were attributed more frequently to modes of travel, over-running of previous activities and lack of information about other rendezvousers, than to lack of information about travel, or local geography. These, and other, findings have implications for the design of position-aware computing and communications for the general public.	diary studies	Martin Colbert	2001		10.1145/500286.500292	simulation;human–computer interaction;performance;computer science;operating system;mobile technology;multimedia;world wide web	HCI	-58.285309494295454	-41.692730964835874	123105
b835b4d8f6e96b759e8f3d8af804651c66784de5	mobile and physical user interfaces for nfc-based mobile interaction with multiple tags	mobile device;user interface;user study;emerging technology;near field communication;multi tag interaction;evaluation;usability;single tag interaction;mobile interaction;nfc;physical user interface	Near Field Communication (NFC) is an emerging technology for mobile interaction with everyday objects and associated digital resources. Apart from simple interactions with single tags, NFC has the potential for more elaborate interactions with physical objects that comprise multiple tags and serve as physical user interfaces (UI). This paper investigates the design of mobile and physical UIs for the interaction with multiple NFC-tags. It focuses on three basic interactions that qualify for multi-tag interaction - the navigation between parts of an application, the selection of items and the combination of items. Two user studies compare different configurations of mobile and physical UIs for these interactions in order to evaluate the allocation of application features and UI elements to mobile devices and tagged objects. The results advocate the continuous interaction on the latter, instead of splitting interactions between mobile and physical UIs.	categorization;hyperlink;mobile app;mobile device;mobile interaction;moving target indication;near field communication;usability testing;user interface	Gregor Broll;Doris Hausen	2010		10.1145/1851600.1851624	mobile search;mobile interaction;human–computer interaction;computer science;operating system;multimedia;near field communication;mobile computing;world wide web	HCI	-49.40758493791363	-40.43002831896817	123113
b8d064544af84f70f25cec645bd18e8755e84437	factors affecting webpage's visual interface design and style	user evaluation;design criteria;visual communication;web interface;interface style;website;web design;principal component analysis;proceedings paper;literature review;visual interfaces;visual interface design;web visualization	In the past, many researches of web interface were focused on usability and technical aspects. Instead, this research takes the visual communication-oriented approach to see how much the visual interface style adds to its rating. The main purpose of this study is to understand the design criteria and major factors that influenced different web visual interface styles. First of all, Researchers made use of literature review and interviews with 31 users to collect important information about key design criteria and guidelines of web interface design, from which a total of 11 major design criteria were identified. After that, a Likert-type 7point scale was applied to rate 90 website based on 11 design criteria, and 32 subjects were invited to participate in an experiment. The result showed that ‘title or logo, promotion of image, ease of information display, willingness to read, colors, structure, attraction, layout, usability, hyperlink, and readability of texts’ were the important design criteria that users cared about. Subsequently, these 11 design criteria were further analyzed using principal component analysis to identify two critical factors, ‘emotion factor’ and ‘function factor,’ affecting users’ evaluation. Finally, how the two factors and design criteria that influence six types of website interface style are discussed in the latter part of this paper. It is hoped that this research could provide valuable insight for web designers or developers to select a proper style based on users’ evaluation.	color;display device;hyperlink;logo;principal component analysis;usability;user interface;web application;web design;web page	Chun-Cheng Hsu	2011		10.1016/j.procs.2011.01.009	web modeling;web design;human–computer interaction;computer science;machine learning;data mining;multimedia;design education;user interface;world wide web;visual communication;principal component analysis	HCI	-59.64343823198321	-47.31897900918804	123195
5e9e19f411d87a3c6da7cd3e55d42dd9cb090398	assessing the impact of virtual human's appearance on users' trust levels		Virtual humans are used to facilitate interactions in sensitive contexts such as healthcare. In such contexts, trust in the information source plays an important role in reception of the information. Prior work has shown that physical appearance affects trustworthiness in human-human interactions; therefore, we examined the effect of virtual humanu0027s appearance on usersu0027 trust. We ran a between-users study with 12 adult participants, who watched a video of a virtual human with professional attire (e.g., lab coat) or with general attire (e.g., button-down shirt). We examined the duration of eye fixation on the virtual humanu0027s face along with participantsu0027 self-reported trust levels. We found that there was no statistical difference in eye contact or trust between the two test conditions.	eye tracking;information source;interaction;trust (emotion);virtual actor	Mohan Zalake;Julia Woodward;Amanpreet Kapoor;Benjamin Lok	2018		10.1145/3267851.3267863	trustworthiness;fixation (visual);virtual actor;human physical appearance;social psychology;applied psychology;eye tracking;computer science;health care;eye contact	HCI	-53.947792451692585	-51.736852422953625	123332
2e2711831097bcb7bcd4a969913841bce9cfe3c0	design, development, and usability evaluation of a system for adding and editing social media banners in the immersive street-level 3d virtual city		In this paper, we present design and implementation of a system for adding and visualizing social media content in an immersive street-level 3D virtual city environment. The system enables its users to add banners anywhere in the virtual 3D environment, typically on building façades, walls, or on the ground. The banner's owner is then able to edit the banner and select the social media platform to load the content from, thereby creating a social media content banner with a specific ID. The system supports four social media platforms: Facebook, Twitter, Pinterest, and Flickr. Users can also customize banners' position, rotation, and the visual elements such as text, images and colors. To evaluate our system's usability, we conducted an iterative usability evaluation with 12 participants. Each evaluation round with three participants indicated improvements to the system, which were implemented before next evaluation round. Finally, after the last modifications, system was found to be easy to use by average users and only a little help was needed for non-experienced users. We believe this system could provide added value for the business owners and users by enabling social media content to be add on the 3D virtual city and use it as a marketing platform.	academy;color;flickr;handy board;image;information source;iterative method;multimedia framework;open innovation;relevance;social media;usability testing;virtual reality;virtual world	Mahmoud Badri;Minna Pakanen;Paula Alavesa;Hannu Kukka;Timo Ojala	2017	2017 9th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)	10.1109/VS-GAMES.2017.8056577	immersion (virtual reality);world wide web;banner;usability;multimedia;city environment;social media;engineering;added value	HCI	-50.2149615926838	-38.09044515387368	123341
2c84ccad67032b03c8a460346cdf36266082151f	"""""""only if you use english you will get to more things"""": using smartphones to navigate multilingualism"""		We contribute to the intersection of multilingualism and human-computer interaction (HCI) with our investigation of language preferences in the context of the interface design of interactive systems. Through interview data collected from avid smartphone users located across distinct user groups in India, none of whom were native English speakers, we examine the factors that shape language choice and use on their mobile devices. Our findings indicate that these users frequently engage in English communication proactively and enthusiastically, despite their lack of English fluency, and we detail their motivations for doing so. We then discuss how language in technology use can be a way of putting forth mobility as an aspect of one's identity, making the case for an intersectional approach to studying language in HCI.	forth;human–computer interaction;mobile device;smartphone	Naveena Karusala;Aditya Vishwanath;Aditya Vashistha;Sunita Kumar;Neha Kumar	2018		10.1145/3173574.3174147	multimedia;human–computer interaction;multilingualism;interface design;fluency;mobile device;computer science;if and only if	HCI	-57.55409881324338	-41.46779623615193	123403
0af0bcb0f977887c3211e1018d6649f934168d4e	bus stops as interactive touchpoints: improving engagement and use of public transport		Bus stops are key touchpoints to improve the quality and engagement of citizens with public transports. Despite their ubiquity in modern urban landscapes they are seldom considered a key design/technology element in improving the public transport experience. This paper describes a design case study where different teams attempted to improve bus stops using interactive technologies. The resulting concept prototypes were designed to provide citizens and tourists with (i) safe, attractive and accessible public spaces, (ii) attractive, accessible and efficient public transport; and, (iii) smart traveller information tools and services for sustainable mobility. Our case was set in Madeira, a medium sized European island, where tourism widely contribute to the local economy and buses represent the only available public mean of transport. We present the research insights and the design concepts leading to improve engagement and use of public transport.	accessibility;emoticon;human–computer interaction;personalization;pervasive informatics;quality of service;storyboard;user experience	Catia Prandi;Valentina Nisi;Nuno Jardim Nunes	2017		10.1145/3125571.3125593	public transport;tourism;transport engineering;engineering	HCI	-59.65904041270342	-39.19565932835445	123581
64a029d2b402d03bca8c80c82702a269d2bc5bbd	rfid implant developments: where are we headed and why? [commentary]	headed;social implications of technology;philosophical considerations;why;developments;social implications of technology rfid human factors implants philosophical considerations;implantable device radio frequency identification rfid implant;implant;human factors;rfid;implants;radiofrequency identification prosthetics;where	Examines the impact of technologies in society, initially exploring the technology and use of radio frequency identification (RFID) as an implantable device. Are such devices being designed and engineered to replace former infrastructures that have been in place to help monitor, control, and assist the activities of the general populace? Suggests that implantable devices are inanimate objects, void of spirit, and have no motive or underlying teleology residing within the technology itself. Discusses how such technologies are impacted by societies that deploy them.		Sharon Bradley-Munn	2016	IEEE Technol. Soc. Mag.	10.1109/MTS.2016.2554420	radio-frequency identification;computer science;engineering;electrical engineering;human factors and ergonomics;biological engineering	Vision	-60.25119586692372	-38.791461846164694	123617
f8787888c1b525b792f011a5f05c6a111279c5b9	desu 100: about the temptation to destroy a robot	hci;destruction;cruelty;human;pleasure;robot	"""Whilst previous research examined the behaviour of humans instructed to destroy robots, this paper is concerned with the question """"Are humans tempted to destroy robots?"""" For this purpose, an interactive installation was created, consisting of the robot DESU 100 and a button on a pedestal. The visitors of this installation were faced with the opportunity to push the button, and herewith forcing the robot to hit itself. Despite feeling sympathy for DESU 100, most of the visitors yielded to the temptation and pressed the button at least once, experiencing satisfaction."""	humans;robot;while	Julia Ringler;Holger Reckter	2012		10.1145/2148131.2148164	psychology;simulation;communication;social psychology	Robotics	-52.618322393258566	-51.17588402952918	123635
32f751f077cf1f33554d804a32cdb3df266c64e3	the long-term evaluation of fisherman in a partial-attention environment	long period;human computer interaction;evaluation method;intrusive evaluation;information visualization;face tracking;behavioral science;user involvement;ambient display;ambient displays	"""Ambient display is a specific subfield of information visualization that only uses partial visual and cognitive attention of its users. Conducting an evaluation while drawing partial user attention is a challenging problem. Many normal information visualization evaluation methods (full attention) may not suit the evaluation of ambient displays.  Inspired by concepts in the social and behavioral science, we categorize the evaluation of ambient displays into two methodologies: intrusive and non-intrusive. The major difference between these two approaches is the level of user involvement, as an intrusive evaluation requires a higher user involvement than a non-intrusive evaluation.  Based on our long-term (5 months) non-intrusive evaluation of Fisherman presented in [16], this paper provides a detailed discussion of the actual technical and experimental setup of unobtrusively measurement of user gaze over a long period by using a face-tracking camera and IR sensors. In addition, this paper also demonstrates a solution to the ethical problem of using video cameras to collect data in a semi-public place. Finally, a quantitative term of """"interest"""" measurement with three remarks is also addressed."""	categorization;information visualization;semiconductor industry;sensor	Xiaobin Shen;Andrew Vande Moere;Peter Eades;Seok-Hee Hong	2008		10.1145/1377966.1377979	facial motion capture;simulation;information visualization;human–computer interaction;computer science;multimedia;world wide web	HCI	-57.955887260667836	-46.1784412633841	123657
1022d0e7bb8ca1952d209fc5c47cc8e0a647c800	astute: increased situational awareness through proactive decision support and adaptive map-centric user interfaces	context usability engines security mobile communication geospatial analysis prototypes;human computer interaction;notebook computers decision support systems emergency services graphical user interfaces human computer interaction mobile computing;graphical user interfaces;decision support systems;notebook computers;mobile computing;border control situational awareness proactive decision support adaptive map centric user interfaces astute project european artemis project embedded systems mobile systems human machine interfaces sensed environment user state emergency workers field operations on sleeve mobile devices tablet sized mobile devices geospatial map centric user interface ui context reasoning user state reasoning hmi emergency domain;emergency services	The Astute project is an ongoing European Artemis project that researches methods to improve the effectiveness of embedded and mobile systems. It does so by providing human-machine interfaces (HMIs) that automatically and proactively adapt, based on the sensed environment and user state. One of the implemented demonstrators supports emergency workers during field operations using on-sleeve and tablet-sized mobile devices. Extensive field and usability studies have proved that a geospatial, map-centric user interface (UI)is essential to provide a low-barrier interface that is easy to learn. The integration of context and user-state reasoning enables proactive decision support that makes HMIs smarter and more effective in stressful and critical situations. We argue that the promising results obtained for the emergency domain have great potential to improve the current practice in border control use cases as well.	decision support system;embedded system;geopackage;interoperability;mobile device;requirement;tablet computer;usability;user interface	Bart Adams;Frank Suykens	2013	2013 European Intelligence and Security Informatics Conference	10.1109/EISIC.2013.74	user interface design;simulation;human–computer interaction;computer science;knowledge management;data mining;graphical user interface;user interface;mobile computing;computer security	HCI	-51.1070477868311	-38.99788285399084	123679
b1995c0649c9fae0c83448c03a613487e1bc047b	informedia experience-on-demand: capturing, integrating and communicating experiences across people, time and space	multimedia information systems;multimedia information system;content analysis;video and location content analysis;demand systems;audio;natural language processing	The Informedia Experience-on-Demand system uses speech, image, and natural language processing combined with GPS information to capture, integrate, and communicate personal multimedia experiences. This paper discusses in initial prototype of the EOD system.	global positioning system;natural language processing;prototype	Howard D. Wactlar;Michael G. Christel;Alexander G. Hauptmann;Yihong Gong	1999	ACM Comput. Surv.	10.1145/323216.323356	content analysis;computer science;multimedia;world wide web	HCI	-49.59955105680236	-38.54036667671139	123783
62da48be9595b75f01a5bf92001babad6e13aa8f	twenty-five years of hci: growth without progress?	case history;ucl;relacion hombre maquina;discipline;disciplina;discovery;man machine relation;theses;conference proceedings;discipline scientifique;man machine system;digital web resources;historique;ucl discovery;open access;sistema hombre maquina;ucl library;relation homme machine;book chapters;open access repository;historica;recherche scientifique;scientific research;investigacion cientifica;systeme homme machine;ucl research	Human-Computer Interaction (HCI) has been developing over the last twenty-five years. The aim of this paper is to review that development. It concludes that, as a field, there has been growth, for example in computing technology, design of interactions and research. However, the paper also concludes that, as a discipline, HCI has only made limited progress. There has been little validation if its research knowledge to support the design of effective work. The limited progress is shown by the continuing need for more effective: human-computer interactions; design of such interactions; and research to support such design. The paper proposes that the specification of relations between research, design, and human-computer interactions for effective work would better support validation, and so progress in HCI, as a discipline.	human–computer interaction	John Long	1997			discipline;scientific method;computer science;engineering;artificial intelligence;operations research	HCI	-61.86569139974118	-48.883578649574396	123836
468af6f4a1797b4ece3e2515558c99a63e3ba7c5	paper prototypes for the detection of stereotype violations in (medical) device operation - are they good enough?	controls;3 d prototype;fidelity;stereotypes;paper prototype	"""Controls for most technologies, including medical devices, are becoming increasingly complex, difficult to intuitively understand and don't necessarily follow population stereotypes. The resulting delays and errors are unacceptable when seconds can mean the difference between life and death. In this study participants were asked to """"control"""" a system using a paper prototype (color photographs of controls) and then with a higher fidelity prototype of the same physical controls to determine performance differences among ethnicities and genders. No ethnic nor gender differences were found, and the comparison of paper versus higher fidelity prototypes also showed no significant differences. Thus, paper prototypes can be employed as an early device design usability tool to illustrate stereotype violations long before the first physical prototype. This will not only save money in the development and design processes, but also makes sure that even the most complex devices are intuitively understandable and operable for their basic functions."""		M. Susan Hallbeck;Sonja Koneczny;Justine Smith	2009	Studies in health technology and informatics	10.3233/978-1-58603-964-6-109	simulation;engineering;communication;social psychology	HCI	-49.91427260603843	-45.11786183266231	123856
c88f9892edb1bcf71b133558db1f3f8640ed252d	investigating human identity using the idmirror interactive installation	interactivity;physical reality;identity;virtual world;mobile technologies	idMirror is an artistic project that investigates how social networks and emerging mobile technologies have forever changed the perception of human identity. Social responsibility should be taken into account when dealing with visual practice. People today live in a time of constant changes to their daily life. Technological progress brings about transformation in every aspect of human existence, including the perception of one's self. New ways of communication and cultural forms are a means of transfiguration of present day identities, forms of community and interpersonal relationships; our perception of time and space is being re-established. People talk about digital life as the place of hope, the place where something new will come to them. Has the identity of contemporary citizen shifted to the level of a code; captured in our mobile devices such as tablets and smartphones, and exposed in a form of information on the WWW? The essential question nowadays is: Where are we?	digital life;mobile device;smartphone;social network;tablet computer;www	Masa Jazbec;Floris Erich	2016		10.1145/2851581.2891091	human–computer interaction;computer science;operating system;mobile technology;multimedia;interactivity;management;world wide web	HCI	-57.504012232543765	-39.26524519126079	123863
b7d617e182d6968dda51fba6f09bbe82a699ead2	from human communication to intelligent user interfaces: corpora of spoken estonian	human interaction;user interface	We argue for the necessity of studying human-human sp oken conversations of various kinds in order to create us er interfaces to databases. An efficient user interface benefits from a well-organized corpus that can be used for investigat in the strategies people use in conversations in order to be efficient and to handle the spoken communication problems. For modeling the natural behaviour and testing the model we need a dialogue corpus where the roles of participants are close to the roles of the dial ogue system and its user. For that reason, we collect and investigate the Corpus of the Spoken Estonian and the Estonian Dialogue Corpu s as the sources for human-human interaction investigation. The transcriptio n c nventions and annotation typology of spoken hum an-human dialogues in Estonian are introduced. For creating a user interface t he corpus of one institutional conversation type is in sufficient, since we need to know what phenomena are inherent for the spoken langu age in general, what means are used only in certain ty pes of the conversations and what are the differences.	biological anthropology;database;intelligent user interface;need to know;text corpus	Tiit Hennoste;Olga Gerassimenko;Riina Kasterpalu;Mare Koit;Andriela Rääbis;Krista Strandson	2008			artificial intelligence;user modeling;natural language processing;conversation;user interface design;intelligent user interface;user experience design;spoken language;natural language user interface;computer science;user interface	NLP	-52.46072886088166	-48.04946328245018	124086
668a1e0a1750faf59b8773fe9e2df8a2713f03e4	designing intergenerational play via enactive interaction, competition and acceleration	enactive interaction;physical gaming;user evaluation;design process;competition;social interaction;game design;ease of use;youngsters;design rationale;intergenerational play;seniors	We report on the design process and the design rationales of a physical mini-game, to be played by seniors and youngsters. First, we explain that we seek enactive interaction, rather than physical action. Next, we elaborate on how competition correlates with social interaction, relying on FIRO theory. Then, we analyze how the sensor technology within the WiiMote affords acceleration. Via an evaluation of existing physical mini-games, seniors and youngsters empirically verify these three design rationales on enactive interaction, competition and acceleration. We conclude that these rationales result in ease-of-use, equality-in-ease-of-use and visibility-of-player-action, which in turn stimulate competition and consequently intergenerational play. Finally, we present the design and user evaluation of our physical mini-game, designed in accordance with these rationales.	design rationale;enactivism;wii remote plus	Vero Vanden Abeele;Bob De Schutter	2009	Personal and Ubiquitous Computing	10.1007/s00779-009-0262-3	game design;social relation;simulation;competition;design process;usability;human–computer interaction;computer science;design rationale	HCI	-61.14819258702187	-42.85752322670972	124550
444fe22a821a91a9e6f73c3e60f7d27e98352387	imhotep: an approach to user and device conscious mobile applications	new technology;mobile device;user aware;adaptable interfaces;fuzzy logic;accessibility;people with disabilities;knowledge elicitation;source code;user interfaces;mobile application	As the dependence on mobile devices increases, the need for supporting a wider range of users and devices becomes crucial. Elders and people with disabilities adopt new technologies reluctantly, a tendency caused by the lack of adaptation of these technologies to their needs. To address this challenge, this paper describes a framework, Imhotep, whose aim is to aid developers in the accessible application creation process, making the creation of user-centered applications easier and faster. Our framework allows to easily adapt the applications to the constraints imposed by the user capabilities (sensorial, cognitive, and physical capabilities) and device capabilities by providing a repository that will manage the compilation and deployment of applications that include a set of preprocessor directives in the source code. These directives are enhanced with concepts that are automatically adjusted to the current trends of mobile devices by using a Fuzzy Knowledge-Eliciting Reasoner. Our final goal is to increase the number of applications targeted to elders and people with disabilities providing tools that facilitate their development. The paper also describes the evaluation of both the accuracy of the fuzzy terms generated for mobile devices and the usability of the proposed platform.	compiler;fuzzy concept;fuzzy logic;mobile app;mobile device;preprocessor;semantic reasoner;software deployment;usability;user-centered design	Aitor Almeida;Pablo Orduña;Eduardo Castillejo;Diego López-de-Ipiña;Marcos Sacristán	2010	Personal and Ubiquitous Computing	10.1007/s00779-010-0359-8	fuzzy logic;simulation;human–computer interaction;computer science;accessibility;operating system;mobile device;multimedia;user interface;source code	HCI	-50.012300013668856	-41.16029749034795	124744
a888b08cc87de450d93a7b5778027ada35f8ce87	granular interface design: decomposing learning tasks and enhancing tutoring interaction	interface design;user interface;grain size	 This paper considers granularity from an interface design viewpoint. Thelearning tasks are decomposed into smaller components at varying levels ofgranularity with the perspective shift enabled through the user interface. Theyremove the need for the system to engage in complex inferencing about the userknowledge as the system can provide a status feedback (e.g. correct/incorrect) at acoarser grain size and require the student to use a fine grained interface for moredetailed interaction.... 		Ashok Patel;Kinshuk	1997				HCI	-54.67640875938536	-44.581768069115824	124911
f2781c1766a7dc6ba99d6241debf5671239f57b0	embodied companion technologies for autistic children	embodiment;case studies;prototypes;autism;children;co design	With few exceptions, technology for autistic children tends to be focused on the regulation of perceived deficits. With OutsideTheBox we focus on the strengths of the children as design partners and created in our first year four technological objects together with them. They all have common that they are embedded in the children's lives and share some degree of embodied interaction. We present a case study along with four objects, two of them with wearable components, two of them focused at sharing experiences in an embodied mode. This opens up the argument not only for more design actually led by autistic children, but also for companion technologies that embody situatedness. Such technologies are then not driven by an outsider's perspective of what an autistic child needs, but rather are intrinsically valuable to them as a user.	embedded system;situated;wearable computer	Katharina Spiel;Julia Makhaeva;Christopher Frauenberger	2016		10.1145/2839462.2839495	psychology;simulation;developmental psychology;communication	HCI	-60.274437821051364	-38.79415112865522	124928
8ac421a1ec2db5af36ea7efc06172f581fa76fe5	a study of speech versus braille and large print of mathematical expressions		Several systems have been developed that allow mathematical expressions to be spoken and navigated. This paper describes studies involving the latest revision of the most widely used system: MathPlayer 4. This version includes features to allow navigation of mathematical expressions. Students with blindness or low vision used NVDA + MathPlayer to read Microsoft Word documents with math problems in them. The results were compared with the same students reading similar documents using their favorite modality (braille or large print). The results showed that speech augmented with navigation resulted in similar comprehension rates compared to when students used their preferred modality. This is an important finding because electronic documents are often available in situations where braille or large print documents are not.		Neil Soiffer	2016		10.1007/978-3-319-41264-1_8	natural language processing;speech recognition;communication	NLP	-49.272143347916774	-44.21020376368433	125043
5c0844b10da88f70fb625fdca3acab0f0210b0bf	insider threat: language-action cues in group dynamics	online deception;insider threat detection;trusted human computer interaction;language action cues	Language as a symbolic medium plays an important role in virtual communications. Words communicated online as action cues can provide indications of an actor's behavioral intent. This paper describes an ongoing investigation into the impact of a deceptive insider on group dynamics in virtual team collaboration. An experiment using an online game environment was conducted in 2014. Our findings support the hypothesis that language-action cues of group interactions will change significantly after an insider has been compromised and makes efforts to deceive. Furthermore, the language used in group dynamic interaction will tend to employ more cognition, inclusivity and exclusivity words when interacting with each other and with the focal insider. Future work will employ finely tuned complex Linguistic Inquiry and Word Count dictionaries to identify additional language-action cues for deception.	cognition;dictionary;focal (programming language);insider threat;interaction	Shuyuan Mary Ho;Hengyi Fu;Shashanka Surya Timmarajus;Cheryl Booth;Jung Hoon Baeg;Muye Liu	2015		10.1145/2751957.2751978	psychology;communication;social psychology;computer security	HCI	-53.743640939468804	-49.09983826400532	125124
5f3af55498a607d2a68b68b03b2ab38fccf508f7	media enjoyment as a function of control over characters	agency;technology;character;enjoyment;identification	This paper argues that the enjoyment of interactive media, especially interactive narratives, can be explained via perceptions of control. Specifically, control over a character’s choices, lead to higher perceptions of control which increased user enjoyment. Three different experiments using varying narratives, grammatical perspectives and story outcomes support these arguments consistently. This series of studies demonstrates that perceptions of control over media characters facilitate positive attitudes toward media content, corroborating and expanding upon earlier entertainment research. This research demonstrates a low-tech application of content-based user control in new media environments.		Ryan Rogers;Francesca R. Dillman Carpentier;Lisa Barnard	2016	Entertainment Computing	10.1016/j.entcom.2015.11.002	identification;simulation;computer science;agency;multimedia;social psychology;character;technology	HCI	-58.34524839256552	-47.30826649600829	125132
2bbea09ea91d8743b59711f32b0a08cce5816ea9	designing transparent interaction for ubiquitous computing: theory and application	cognitive skills;ubiquitous computing;interaction design	Designing transparent interaction is important for ubiquitous computing (ubicomp). A psychology framework that characterizes user's cognitive behavior in ubicomp environments would be invaluable for guiding the interaction design to be optimally compatible with human capabilities and limitations. By analyzing the cognitive skill and attention selectivity, such a framework is proposed in this paper. Correspondingly, a context-sensitive multimodal architecture is presented on the level of technology. A case study, where the theory was implemented in a handheld hypermedia guide and deployed into the context of authentic use, is then discussed.	ubiquitous computing	Weining Yue;Heng Wang;Guoping Wang	2007		10.1007/978-3-540-73105-4_37	cognitive skill;simulation;human–computer interaction;computer science;interaction design;multimedia;ubiquitous computing	HCI	-53.66138231150869	-38.62228522749028	125498
873a4a7c3ae06aeae5819e3786b2a5ad15339cda	predictors of psychological anthropomorphization, mind perception, and the fulfillment of social needs: a case study with a zoomorphic robot	robots psychology games anthropomorphism computers atmospheric measurements particle measurements	We conducted a human-robot interaction (HRI) experiment in which we tested the effect of inclusionary status (social inclusion vs. social exclusion) and a dispositional correlate of anthropomorphism on social needs fulfillment and the evaluation of a social robot, respectively. The experiment was initiated by an interaction phase including free play between the user and the zoomorphic robot Pleo. This was followed by the experimental manipulation according to which participants were exposed to an experience of social inclusion or social exclusion during a computer game. Subsequently, participants evaluated the robot regarding psychological anthropomorphism, mind perception, and reported the experienced fulfillment of social needs as well as their individual disposition to anthropomorphize. The present research aimed at demonstrating that situationally induced inclusionary status should predominantly influence experienced social needs fulfillment, but not anthropomorphic inferences about a robot. Analogously, we presumed that evaluations of the robot should mainly be driven by the individual disposition to anthropomorphize nonhuman entities, whereas inclusionary status should not affect these judgments. As predicted, inclusionary status only affected experienced social needs fulfillment, whereas the experimental manipulation did not affect robot-related evaluations. In a similar vein, participants low (vs. high) in anthropomorphism differed in their assessment of humanity and mind perception of the robot prototype, whereas inclusionary status did not affect these anthropomorphic inferences. Results are discussed in light of the existing literature on social exclusion, social needs fulfillment, and anthropomorphization of robots.	entity;human–robot interaction;mind;pc game;pleo;prototype;social robot	Friederike Eyssel;Michaela Pfundmair	2015	2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2015.7333647	computer science;artificial intelligence	HCI	-52.50914795682582	-51.147293454488945	125553
8bba1845a85370618cd5c400ec8be42208554549	towards more robust speech interactions for deaf and hard of hearing users		Mobile, wearable, and other ubiquitous computing devices are increasingly creating a context in which conventional keyboard and screen-based inputs are being replaced in favor of more natural speech-based interactions. Digital personal assistants use speech to control a wide range of functionality, from environmental controls to information access. However, many deaf and hard-of-hearing users have speech patterns that vary from those of hearing users due to incomplete acoustic feedback from their own voices. Because automatic speech recognition (ASR) systems are largely trained using speech from hearing individuals, speech-controlled technologies are typically inaccessible to deaf users. Prior work has focused on providing deaf users access to aural output via real-time captioning or signing, but little has been done to improve users' ability to provide input to these systems' speech-based interfaces. Further, the vocalization patterns of deaf speech often make accurate recognition intractable for both automated systems and human listeners, making traditional approaches to mitigate ASR limitations, such as human captionists, less effective. To bridge this accessibility gap, we investigate the limitations of common speech recognition approaches and techniques---both automatic and human-powered---when applied to deaf speech. We then explore the effectiveness of an iterative crowdsourcing workflow, and characterize the potential for groups to collectively exceed the performance of individuals. This paper contributes a better understanding of the challenges of deaf speech recognition and provides insights for future system development in this space.	accessibility;audio feedback;automated system recovery;crowdsourcing;information access;interaction;iterative method;natural language;real-time transcription;speech recognition;ubiquitous computing;wearable computer	Raymond Fok;Harmanpreet Kaur;Luwen Feng;Martez E. Mott;Walter S. Lasecki	2018		10.1145/3234695.3236343	human–computer interaction;multimedia;ubiquitous computing;wearable computer;human computation;audio feedback;computer science;information access;closed captioning;crowdsourcing;workflow	HCI	-50.734444746433226	-44.117210050261356	125585
2634b9119fcb4eec611acbd5366513a24f95f244	relational agents improve engagement and learning in science museum visitors	pedagogical agent;relational agents;intelligent tutoring system;social interfaces;embodied conversational agent;intelligent virtual agent;interactive installation	A virtual museum guide agent that uses human relationship-building behaviors to engage museum visitors is described. The agent, named “Tinker”, appears in the form of a human-sized anthropomorphic robot, and uses nonverbal conversational behavior, empathy, social dialogue, reciprocal selfdisclosure and other relational behavior to establish social bonds with users. Tinker can describe exhibits in the museum, give directions, and discuss technical aspects of her own implementation. Results from an experiment involving 1,607 visitors indicate that the use of relational behavior leads to significantly greater engagement by museum visitors, measured by session length, number of sessions, and self-reported attitude, as well as learning gains, as measured by a knowledge test, compared to the same agent that did not use relational behavior. Implications for museum exhibits and intelligent tutoring systems are discussed.	computer vision;mobile device;robot;tinker	Timothy W. Bickmore;Laura M. Pfeifer;Daniel Schulman	2011		10.1007/978-3-642-23974-8_7	psychology;knowledge management;artificial intelligence;multimedia;communication	AI	-52.70373985868736	-50.14288283702795	125680
97abe130c1bd09eb2947f5e1555a0924140449c7	designing and testing credibility: the case of a serious game on nightlife risks		This paper describes a game directed to young adults and aimed at sensitizing them about potential risks of psychoactive substance abuse during nightlife events. Of interest here is that this game targets a domain in which the credibility of a persuasive intervention is particularly fragile. The design decisions and the recommendations inspiring them are described first, characterized by an effort to fit the context in which the game was going to be used. In addition, a field study with real users during nightlife events is reported (N = 136), in which several dimensions of the game credibility are evaluated and compared with the credibility of a serious information tool (leaflets) in a between-participant design. By describing this case, the opportunity is taken to emphasize the importance of serious games credibility, and to enumerate some of the occasions to improve its strength that can be found during its design to evaluation.		Luciano Gamberini;Massimo Nucci;Luca Zamboni;Giovanni DeGiuli;Sabrina Cipolletta;Claudia Villa;Valeria Monarca;Mafalda Candigliota;Giuseppe Pirotto;Stephane Leclerq;Anna Spagnolli	2018		10.1007/978-3-319-78978-1_18	computer science;social psychology;nightlife;psychoactive substance abuse;applied psychology;credibility	ECom	-61.71586503336783	-43.36341962926256	125746
64c3c997481c07b6a6f6fdb7e3dab25fe50512df	lessons learned from evaluating the usability of mobile spreadsheet applications	mobile applications;usability guidelines	It is estimated that 90% of all the analysts in business perform calculations on spreadsheets. Due to advances in technology, spreadsheet applications can now be used on mobile devices and several such applications are available for platforms such as Android and iOS. Research on spreadsheets revolves around several themes, but little work has been done in evaluating the usability of such applications (desktop or mobile). This paper presents lessons learned and usability guidelines derived from laboratory usability testing of mobile spreadsheet applications. Twelve participants were given a task to be solved using a mobile spreadsheet application and based on the video recordings of their interactions with the application patterns of recurring actions and sequences of actions were derived. Navigation, selection, feedback, and transparency of features were some of the main themes in the results of the testing, pointing to a set of guidelines which are also generalizable across other types of mobile applications.	android;desktop computer;interaction;mobile app;mobile device;spreadsheet;usability testing;ios	Derek Flood;Rachel Harrison;Claudia Iacob	2012		10.1007/978-3-642-34347-6_23	usability goals;web usability;simulation;usability;human–computer interaction;computer science;usability engineering;world wide web;usability lab;usability inspection	HCI	-62.41843541074714	-45.480572666505225	125878
48cbba5c421b8f9b49c36206a7be28d47ca1627b	crystalchat: visualizing personal chat history	social network services;instant messaging;electronic mail;history;social interaction;data visualization;online social network;computer science;history social network services data visualization computer science electronic mail	As more people take part in online conversations, awareness of the varying conversational styles and social mores afforded by different software is growing. However, this awareness is largely built on personal impressions as varying styles of social interactions are hard to discover in text-based presentations. Through visualization we explore social and temporal interactions in instant messaging. CrystalChat visualizes personal chat history. Rather than showing online social networks that indicate merely who talks to who, CrystalChat reveals the patterns in an individual’s communications with those people who are part of their personal chat history. The patterns revealed come from instant messaging data that includes information about temporal clustering, conversation initiation, conversation termination, length of conversations, length of postings, patterns of repetitive or alternating postings, and emotional tone as represented by emoticons.	cluster analysis;emoticon;instant messaging;interaction;mores;online chat;social network;text-based (computing)	Annie Tat;M. Sheelagh T. Carpendale	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.107	human–computer interaction;computer science;multimedia;world wide web;data visualization;social computing;computer-mediated communication	HCI	-53.52468586580262	-44.52026432441293	125905
fe0c36a811c39b97fcb9068babeb9a8ee025a6de	designing and evaluating a vibrotactile language for sensory substitution systems.		The sense of touch can be used for sensory substitution, i.e., to represent visual or auditory cues to impaired users. Sensory substitution often requires the extensive training of subjects, leading to exhaustion and frustration over time. The goal of this paper is to investigate the ability of the subjects to recognize alphanumeric letters on 3 × 3 vibration array, where the subjects can fully personalize the variables including spatial location, vibratory rhythm, burst duration and intensity. We present a vibrotactile device for delivering the spatiotemporal letter patterns while maintaining the high level of expressiveness. The results prove that this system is an effective solution with a low cognitive load for visually/auditory impaired people and for any context that would benefit from leaving the eyes/ears free for other tasks.		Majid Janidarmian;Atena Roshan Fekr;Katarzyna Radecka;Zeljko Zilic	2017		10.1007/978-3-319-98551-0_7	communication;somatosensory system;alphanumeric;haptic technology;expressivity;sensory substitution;frustration;computer science;cognitive load	NLP	-48.75600461994674	-47.803188642873415	126128
c738319e7235c1fc9b73bb26eb116ab50b8a4471	initiating interactions and negotiating approach: a robotic trash can in the field	initiating interaction;human robot interaction;negotiation;distance	In this study, we address how people respond to a robotic trashcan initiating interactions and offering its service. We show that considerable coordination and negotiation work takes place both between human and robot and between humans who are involved in a joint activity when the robot approaches. While in this scenario attention getting was no problem, the interactions posed significant problems to people who did not want the robot’s service. The unwillingness to interact with the robot was mostly communicated by withholding social signals, which means that human-robot interaction designers not only need to build in ways to respond to human social signals in a timely and appropriate manner, but also a representation of what kinds of signals could be expected in order to interpret the ostensive lack of such signals adequately.	fold (higher-order function);human–robot interaction;interaction design;interrupt;modality (human–computer interaction);ostensive definition;rejection sampling;robot;social proof;trash (computing)	Kerstin Fischer;Stephen Yang;Brian K. Mok;Rohan Maheshwari;David Sirkin;Wendy Ju	2015			human–robot interaction;simulation;computer science;artificial intelligence;distance;negotiation	Robotics	-50.65143588568576	-47.91086026590048	126156
3997407f2344f5593e3e0d4a1f1b7b1a5e2d04e8	effects of pre-game stories on feelings of presence and evaluation of computer games	self perception;game theory;physical presence;videojuego;teoria juego;theorie jeu;video game;jeu video;autoperception;senal video;signal video;game evaluation;video signal;juegos de computadora;self presence;jeu ordinateur;computer games;pre game stories;autopercepcion;computer game;computer game design	Two experiments examined the effects of exposure to a pre-game story prior to playing a computer game. In Experiment 1, participants played a computer game after watching a 5 min pre-game story video about the main character of the game. Prior exposure to the pre-game story positively influenced participants’ feelings of presence and their game evaluation. The effect of pre-game story exposure on game evaluation was mediated by participants’ feelings of presence. When a comparison between participants who watched the pre-game story and those who watched a non-story video was conducted, no mediating role of feelings of presence was found. In Experiment 2, participants read a movie script before playing the game. Its results partially replicated those of Experiment 1 with no significant mediating role of feelings of presence. The implications of the current study were discussed with respect to (1) studies on stories in computer games, (2) presence research, and (3) the design of computer games. & 2010 Elsevier Ltd. All rights reserved.	experiment;maxima and minima;pc game;video game developer	Namkee Park;Kwan Min Lee;Seung-A. Annie Jin;Sukhee Kang	2010	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2010.07.002	game theory;simulation;computer science;multimedia;self-perception theory	HCI	-53.64123308032534	-51.9086105010956	126541
7fbefd19c22ef3853a0ee37f59305402fce08eff	the design of a smart tray with its canteen users: a formative study		The ability of taking responsible decisions concerning eating depends on the eating context. This paper considers users of university canteen environments. It outlines the GAPH project and system for informing canteen users about their eating choices, and the effects of choices on their diet. The main component of the system is a tangible solution: the smart GAPH tray. The paper presents the design approach for rapidly deploying tray prototypes, and for assessing them in their natural context. It focuses on the most recent study concerning end users’ interaction with the GAPH tray, and reflects over its results also in terms of the chosen design approach for tangibles for novel contexts.		Vincenzo Del Fatto;Rosella Gennari;Alessandra Melonio;Guerriero Raimato	2017		10.1007/978-3-319-60819-8_5	embedded system;simulation;engineering;multimedia	HCI	-58.82134909373337	-42.46540308117862	126646
a614a2ef21ee112e440cd2c5b97c6940e4725417	"""""""designing for the web"""" revisited: a survey of informal and experienced web developers"""	developpement logiciel;site web;base donnee;online survey;red www;accesibilidad;authentication;reseau web;database;base dato;ease of use;qualite service;authentification;control proceso;autenticacion;internet;accessibility;desarrollo logicial;software development;process control;controle qualite;utilisabilite;world wide web;sitio web;usabilidad;quality control;usability;commande processus;service quality;accessibilite;web site;web development;control calidad;calidad servicio	We report a subset of findings from a survey of over 300 web developers – a mixture of professional and more casual developers – targeted at understanding the needs, problems and the processes that developers follow and the tools they use. The prototypical web developer from our sample is meticulous about the quality of the web sites she produces, considers usability issues but neglects accessibility concerns. Web developers have many similar interests regarding web applications or features such as authentication, databases, online surveys or forms. They value ease of use as the most important property of a web development tool but mention many other needs such as integration with other tools, strong code editing features, or WYSIWYG facilities. This report details findings regarding process, tools, quality control, and learning.	web developer;world wide web	Mary Beth Rosson;Julie F. Ballin;Jochen Rode;Brooke Toward	2005		10.1007/11531371_66	web application security;web development;web modeling;web analytics;usability;web design;web accessibility initiative;web standards;computer science;web navigation;process control;social semantic web;data mining;authentication;database;web intelligence;web engineering;web 2.0;world wide web;web design program;computer security;mashup	Web+IR	-62.10395407832374	-48.65343950865846	126927
3f01cc5ca277881aa7bda481204adfb06f906104	an observation of behavioral changes of indoor dogs in response to caring behavior by humanoid robots - can dogs and robots be companions?		The aim of our research is to build good relationships between pets and robots at home. We aim to promote of positive interaction between pets and robots. Recently, robots have been become popular with the general populace. There is a lot of research in human-robot interaction. We pay attention to pets that live in houses with humans. It is required for pets to like robots for positive interactions between pets and robots to exist. In this paper, we examine that 1) a robot can take care of dog, and 2) dogs and robots can be companion by caring behavior of robots toward dogs. In our experiment, we used two robots. One of the robots takes care of a dog, while the other does not. We observed which robot the dog chooses to interact with and had seventeen dogs participate in this study. We performed this statistical test to judge whether the dogs treated the robots with any significant differences.	care-of address;humans;human–robot interaction;robot	Motoko Suzuki;Yuichi Sei;Yasuyuki Tahara;Akihiko Ohsuga	2017		10.5220/0006188604810488	computer vision;simulation	Robotics	-52.321608109604334	-51.21501403594174	126955
b1322db60cfb4b92f3068e5ad881455ddf1dd2b8	fieldguide: smartwatches in a multi-display museum environment		Deciding on what to see in a large museum can be overwhelming. We present FieldGuide, a smartwatch based system designed to facilitate museum gallery exploration. We discuss our design and implementation, followed by an evaluation conducted with twelve visitors in a natural history museum. Our findings describe how smartwatches can fit into a multi-display museum environment and strike a balance between personal and public interactions.	interaction;smartwatch	Amartya Banerjee;Rovik Robert;Michael S. Horn	2018		10.1145/3170427.3188694	human–computer interaction;multimedia;smartwatch;computer science;natural history	HCI	-56.01427852177692	-42.411910054207176	126970
06803e34f1b8265c036f155f7ce6b6d5052ff1cd	anthropomorphism, agency, and ethopoeia: computers as social actors	agent based;social psychology	Attempts to generate anthropomorphic responses to computers have been based on complex, agent-based interfaces. This study provides experimental evidence that minimal social cues can induce computer-literate individuals to use social rules-praise of others is more valid than praise of self, praise of others is friendlier than pmise of self, and criticism of others is less friendly than criticism of self—to evaluate the performance of computers. We also demonstrate that different voices are treated as distinct agents.	agent-based model;computer	Clifford Nass;Jonathan Steuer;Ellen R. Tauber;Heidi Reeder	1993		10.1145/259964.260137	computer science	Web+IR	-52.70848690952154	-50.39708653804521	127455
daac9da01ac8948f4c348d4bc821b333cbafb4e9	using the crowd to understand and adapt user interfaces	formal method;engineering community;initial work;human expert;user interface flexibility;engineering user interface;user interface;highlight project;human computation method;engineering method;social media	Engineering user interfaces has long implied careful design carried out using formal methods applied by human experts and automated systems. While these methods have advantages, especially for creating interfaces that have the flexibility to adapt to users and situations, they can also be time consuming, expensive, and there are relatively few experts able to apply them effectively. In particular, many engineering methods require the construction of one or more models, each of which can only be created through many hours of work by an expert. In this keynote, I will explore how social and human computation methods can be applied to reduce the barriers to achieving user interface flexibility and ultimately to using engineering methods. In a first example, I will illustrate how groups of users can work together to modify and improve user interfaces through end-user programming examples from the CoScripter and Highlight projects. I will then discuss some initial work on using a crowd of novice workers to create models of existing user interfaces. I hope this keynote will inspire the engineering community to consider alternate approaches that creatively combine formal methods with the power of crowds.	user interface	Jeffrey Nichols	2013		10.1145/2480296.2480344	simulation;human–computer interaction;engineering;multimedia;user interface	HCI	-51.57347480124017	-38.0314352750889	127658
55c557476deca491c92f54304c720be06af1cf4e	designing for diverse stakeholder engagement in resource-intensive practices.		"""Despite many contributions to Sustainable HCI stressing the importance of """"moving beyond the individual"""", a majority of HCI work is still targeted mainly at consumers or resource users. However, many stakeholders influence resource use and including such stakeholders in design work can open up new design opportunities for supporting sustainable practices. In this paper, we present results from a longitudinal study of practices related to energy improvement work in housing cooperatives. During the study, we discovered new opportunities for interactive technologies to support this work when we involved various stakeholders other than housing cooperatives. In addition, we discuss more general implications for design aiming to support diverse stakeholder engagement in practices related to resource use: which stakeholders and practices to include, temporal aspects of engagement, and opportunities for supporting shared responsibility for resource use."""	human–computer interaction	Hanna Hasselqvist;Elina Eriksson	2018		10.1145/3240167.3240193	human–computer interaction;knowledge management;stakeholder engagement;computer science	HCI	-60.9903287097362	-40.8399022693347	127688
109c27b7692af4bee4fa0412eaec742895c41d2e	musicfx: an arbiter of group preferences for computer aupported collaborative workouts	empirical study;human computer interaction;social interaction;warrooms;office building;intelligent environment;metrics;rapid software development;intelligent environments;social behavior;audio;audiospaces;shared spaces;collocation;ubiquitous computing;evaluation;shared space;social interactions;empirical studies;productivity;team rooms;quantitative evaluation;environmental factor;afit	Environmental factors affecting shared spaces are typically designed to appeal to the broadest audiences they are expected to serve, ignoring the preferences of the people actually inhabiting the environment at any given time. Examples of such factors include the lighting, temperature, decor or music in the common areas of an office building. We have designed and deployed MUSICFX, a group preference arbitration system that allows the members of a fitness center to influence, but not directly control, the selection of music in a fitness center. We present a number of empirical results from our work with this intelligent environment: the results of a poll of fitness center members, a quantitative evaluation of the performance of a group preference arbitrator in a shared environment, and some interesting anecdotes about members’ experiences with the system.	arbiter (electronics)	Joseph F. McCarthy;Theodore D. Anagnost	1998		10.1145/289444.289511	social science;simulation;human–computer interaction;computer science;operating system;sociology;communication;empirical research;management;social psychology;world wide web;ubiquitous computing	HCI	-57.73855186456788	-48.66367836791438	127704
38e25872a67a7d6603b1bdfac715d9c8ac943330	they are looking at me!: understanding how audience presence impacts on public display users		It is well known from prior work, that people interacting as well as attending to a public display attract further people to interact. This behavior is commonly referred to as the honeypot effect. At the same time, there are often situations where an audience is present in the vicinity of a public display that does not actively engage or pay attention to the display or an approaching user. However, it is largely unknown how such a passive audience impacts on users or people who intend to interact. In this paper, we investigate the influence of a passive audience on the engagement of people with a public display. In more detail, we report on the deployment of a display in a public space. We collected and analyzed video logs to understand how people react to passive audience in the vicinity of public displays. We found an influence on where interacting users position themselves relative to both display and passive audience as well as on their behavior. Our findings are valuable for display providers and space owners who want to maximize the display's benefits.	dbpedia;honeypot (computing);interaction;modality (human–computer interaction);software deployment	Vito Gentile;Mohamed Khamis;Salvatore Sorce;Florian Alt	2017		10.1145/3078810.3078822	software deployment;honeypot;human–computer interaction;multimedia;business	HCI	-57.33612798649555	-42.48735272096696	127946
6b79251d429957a0fb6b06685beb92c4c6451dc2	flower-pop: facilitating casual group conversations with multiple mobile devices		We explore the potential use of mobile devices as a collaborative sensing system that can proactively mediate casual group conversations. In this study, we aim to investigate (i) the impacts of a mobile system's passive and active conversation facilitation and (ii) the ways in which sociocultural aspects that affect casual group conversation should be considered in the design of proactive mobile systems. Toward this goal, we developed Flower-Pop, a mobile system that monitors group conversations and visualizes interaction patterns using metaphorical expressions based on blossoms. This system provides passive facilitation as well as active facilitation modes such as proactive conversation visualization and photo sharing. The active modes can encourage inactive participants to share photos and select random people to speak. Focusing on Korea, our field study showed that Flower-Pop's mediation created smooth topic/speaker transitions and encouraged less-active speakers to better engage in group conversation. We also found that the sociocultural aspects of casual group conversation, such as the location's characteristics, social relations, and the group's interests, affected participants' use of the Flower-Pop system. Based on our findings, we discuss methods for designing mobile systems for conversation facilitation and outline how opportune sociocultural factors could be identified based on mobile devices.	field research;mobile device;powered speakers	Moon-Hwan Lee;Yea-Kyung Row;Oosung Son;Uichin Lee;Jaejeung Kim;Jungi Jeong;Seung Ryoul Maeng;Tek-Jin Nam	2017	IMWUT	10.1145/3161170	conversation;communication;visualization;social relation;business;facilitation;mobile device;casual	HCI	-58.78590894770033	-40.583735938506734	128134
08436c56d6f789bfb34b1933db377090bc375340	visibility and characteristics of the mobile phones for elderly people	technologie communication;visibilite;visibilidad;telecommunication sans fil;elderly;usuario desfavorecido;telephone;personne âgee;hombre;utilisateur defavorise;sensory handicap;handicap sensoriel;anciano;mobile phone;low vision;malviendo;visibility;malvoyance;telecomunicacion sin hilo;human;desventaja sensoria;disadvantaged user;elderly people;communication technology;telefono;tecnologia comunicacion;homme;wireless telecommunication	Although mobile phones (MPs) have become important IT devices, there are few studies on the visibility of MPs for elderly people. Using six types of MPs, we analysed the reading performance among elderly people who read 11 numerics on each MP. The subjects were 130 people aged 18 to 86 years, including 60 people over 60 years of age. The subjects' visual functions of cataract cloudiness (CC) and near vision for a 50 cm distant target (NV) were measured. In a twoway ANOVA, two kinds of dependant variables, reading speed (RS) and the number of errors in reading (Error) were used for the subjects' reading performance. Two independent variables were taken from five variables. Each time one variable was fixed as the type of MPs. The other was taken as either age, CC, NV, individual history on MP operation or room illuminance (RI). Eventually, 10 ANOVAs were calculated. Significant differences were found in all ANOVAs except that for RI. We undertook a multiple logistic regression analysis. Independent variable...		Masako Omori;Tomoyuki Watanabe;Jo Takai;Hiroki Takada;Masaru Miyao	2002	Behaviour & IT	10.1080/0144929021000048466	information and communications technology;simulation;telecommunications;visibility	HCI	-60.53982204257022	-49.902686910839236	128444
85b4ef20e1c752423da363eefb236fd4bd9f1d27	witchcraft: a workbench for intelligent exploration of human computer conversations.		We present Witchcraft, an open-source framework for the evaluation of prediction models for spoken dialogue systems based on interaction logs and audio recordings. The use of Witchcraft is two fold: first, it provides an adaptable user interface to easily manage and browse thousands of logged dialogues (e.g. calls). Second, with help of the underlying models and the connected machine learning framework RapidMiner the workbench is able to display at each dialogue turn the probability of the task being completed based on the dialogue history. It estimates the emotional state, gender and age of the user. While browsing through a logged conversation, the user can directly observe the prediction result of the models at each dialogue step. By that, Witchcraft allows for spotting problematic dialogue situations and demonstrates where the current system and the prediction models have design flaws. Witchcraft will be made publically available to the community and will be deployed as open-source project.	browsing;dialog system;machine learning;open-source software;rapidminer;user interface;workbench	Alexander Schmitt;Gregor Bertrand;Tobias Heinroth;Wolfgang Minker;Jackson Liscombe	2010			human–computer interaction	NLP	-51.59405655842581	-45.42068194278377	128512
810ddab5c54e55c0b418d84030f18361c603005f	enabling future consumer radios to interact directly with things		Many Things in the Internet of Things will likely interact directly with consumers, via the consumerâs personal handheld device. That observation suggests that the radio(s) or other communications devices in the handheld need to be consistent with those communications devices in Things. This essay looks quickly at the likely evolution of radios in handhelds and asks us to consider whether that evolution is consistent with the Internet of Things and if not, what we might do to encourage interoperability in the future.		Craig Partridge	2016			engineering;multimedia;internet privacy;world wide web	HCI	-55.779970175715	-40.32820236313563	128533
bf057bae75c609548df3c3d2bfaff16503464fc8	seek out katipunan: a mobile augmented reality for museum visualization		"""""""Seek Out Katipunan"""" is a mobile application integrated with augmented reality. With the help of AR (Augmented Reality), this project can make the learning experience of a student, tourist and educators more interesting and educational for Museo Ng Katipunan. The aforementioned it aids and entertains the visitors as they pass through the museum while browsing the application without any other people's assistance. Through the mobile application it will view the 3D animation of the displayed artifacts and the direct view of the environment of the museum. The QR Code (Quick Responsive Code) Scanner will direct the user to the web artifact link that provides all the details regarding the scanned artifact with the 3D animation and voice overview. The project also provides a promotional website that contains more information about the museum such as the events, photo gallery, testimonials of the museum's officials and the location of the museum. The project will be able to reach more people and convince them to visit the museum and to make the Filipino history more interesting."""	3d computer graphics;augmented reality;computer animation;mobile app;qr code	Honeylou Claire R. Colcol;Joel V. Padilla;Yves Dexel V. Buella;Irvin E. Barrientos;Van Tristan V. Calimlim;Ma. Corazon G. Fernando	2017		10.1145/3162957.3162980	computer animation;multimedia;visualization;augmented reality;computer science	HCI	-50.096872443155235	-38.0412916799006	128626
4cae61a6b7bc0405778eb9669d5397561f1dd837	towards inclusive digital television		Over the last decade, the shift from analogue to digital technology has brought about significant changes to the television landscape. The subsequent emergence of mobile, IPTV and other carriers affords the opportunity to creatively reassess how people interact and engage within this diverging medium. Accessibility services to audio-visual content through sign language, subtitles and audio description have become vital forms of interaction for deaf and hard of hearing, those with low literacy or learning disabilities, and blind and partially sighted people. Improved accessibility affords both humane and economic benefits to the wider society, as access to suitable interactive media implies better quality of life, independence and social inclusion. The payback for technology providers is also considerable, as greater inclusion implies broader market potential for commercial products. Digital television (DTV) potentially affords enhancements in communication, quality of life, safety and support of independent living. Related examples include community television applications in the UK, where the medium has been used to support communication between older citizens in public housing and local authority services [5], as well as social television solutions aimed at improving social connectedness for older people living alone [11]. Despite this, the dangers of a widening digital divide remain. Ease of use of DTV continues to be a formidable problem—in the purchasing, self-installation of equipment and access of content. Consequentially, there are still a significant number of people who will struggle to adapt to using this technology. Freeman and Lessiter [4] classify these vulnerable groups as those on low incomes and/or with a reduction in one or more ability. In particular, there is strong evidence to suggest that reductions in cognition, sensory and manual dexterity can create significant barriers to the access of related interactive services. This includes the poor design of remote controls, both in terms of their design consistency, tactile feedback and appropriate labelling of buttons. These issues can be further exacerbated by age-related changes to working memory, creating additional ‘cognitive load’ in the mapping and switching of attention between remote control and TV interfaces [2]. Colour contrast, font type, screen size and distance to screen can all invariably affect text legibility; however, in many instances, DTV lacks support features to readily personalize graphical content. As such, there is an increasing consensus that the self-adaptation of the user interface will help improve interaction barriers for a wider spectrum of users. One notable example is the GUIDE project, which aims to develop design solutions sensitive to the accessibility needs of users who suffer from combinations of progressive perceptual, motor and cognitive problems. Some progress has been made in exploring accessible interaction modes and metaphors. For example, Cesar et al. [3] investigated the use of a secondary screen for television interaction. Whilst not explicitly in support of inclusive design, this and other alternative input/output configurations clearly have potential accessibility benefits. Springett M. Springett (&) Interaction Design Centre, Middlesex University, London NW4 4BT, UK e-mail: m.springett@mdx.ac.uk	accessibility;audio description;cognition;digital electronics;display size;email;emergence;graphical user interface;iptv;input/output;interaction design;interactive media;personalization;purchasing;remote control;social television;usability;while	Mark V. Springett;Mark D. Rice;Richard N. Griffiths	2011	Universal Access in the Information Society	10.1007/s10209-011-0261-9	simulation;human–computer interaction;multimedia;world wide web	HCI	-62.0183309482902	-41.84313727953361	128681
1bf221d8484279d12b9ddd51e18696a11975e244	usability engineering methods for the web: results from a usability study	heuristics;heuristic evaluation;evaluation;usability engineering;indexation	"""The paper presents the results of a study on usability methods for evaluating Web sites. lt summarizes the """"Heuristics for Web Communications, and reports the practical experiences with these heuristics, contrasting them with the """"Keevil Index and combining them with user testing with thinking aloud. It concludes that working with the """"Heuristics for Web Communications takes more time and effort than working with the """"Kevil Index,"""" but produces more consistent results. The heuristics proved to be applicable both in heuristic evaluation and in combination with user testing."""	heuristic (computer science);heuristic evaluation;usability engineering;usability testing;user research;web usability;world wide web	Ilse Maria Harms;Werner Schweibenz	2000				Web+IR	-62.02515367741276	-48.06130864877526	128688
bc7bcfbb1cf916a96a18ec3e0ac42e38b0876950	a multimodal guide for the augmented campus	user needs;mobile device;personal digital assistant;information retrieval;common sense reasoning;human environment interfaces;multimodal guides;context aware service;pervasive services;user experience;speech recognition;audio visual;mobile devices;service provision	"""The use of Personal Digital Assistants (PDAs) with ad-hoc built-in information retrieval and auto-localization functionalities can help people navigating an environment in a more natural manner compared to traditional audio/visual pre-recorded guides. In this work we propose and discuss a user-friendly, multi-modal guide system for pervasive context-aware service provision within augmented environments. The proposed system is adaptable to the user needs of mobility within a given environment; it is usable on different mobile devices and in particular on PDAs, which are used as advanced adaptive HEI (human-environment interaction) interfaces. An information retrieval service is provided that is easily accessible through spoken language interaction in cooperation with an auto-localization service. The interaction is enabled by speech recognition and synthesis technologies, and by a ChatBot system, endowed with common sense reasoning capabilities to properly interpret user speech and provide him with the requested information. This interaction mode turns to be more natural, and users are required to have only basic skills on the use of PDAs. The auto-localization service relies on a RFID-based framework, which resides partly in the mobile side of the entire system (PDAs), and partly in the environment side. In particular, RFID technology allows the system to provide users with context-related information. An implemented case study is showed that illustrates service provision in an augmented environment within university campus settings (termed """"Augmented Campus""""). Lastly, a discussion about user experiences while using trial services within the Augmented Campus is given."""	canonical account;commonsense reasoning;experience;hoc (programming language);information retrieval;mobile device;modal logic;multimodal interaction;personal digital assistant;pervasive informatics;speech recognition;usability	Salvatore Sorce;Agnese Augello;Antonella Santangelo;Giovanni Pilato;Antonio Gentile;Alessandro Genco;Salvatore Gaglio	2007		10.1145/1294046.1294123	human–computer interaction;engineering;multimedia;world wide web	HCI	-50.10940917484016	-39.65242741218137	128884
bfff351898ddceefb48e175ac094070f47aa1f42	context aware addressee estimation for human robot interaction	addressee estimation;human robot interaction;visual focus of attention;context	The paper investigates the problem of addressee recognition -to whom a speaker's utterance is intended- in a setting involving a humanoid robot interacting with multiple persons. More specifically, as it is well known that addressee can primarily be derived from the speaker's visual focus of attention (VFOA) defined as whom or what a person is looking at, we address the following questions: how much does the performance degrade when using automatically extracted VFOA from head pose instead of the VFOA ground-truth? Can the conversational context improve addressee recognition by using it either directly as a side cue in the addressee classifier, or indirectly by improving the VFOA recognition, or in both ways? Finally, from a computational perspective, which VFOA features and normalizations are better and does it matter whether the VFOA recognition module only monitors whether a person looks at potential addressee targets (the robot, people) or if it also considers objects of interest in the environment (paintings in our case) as additional VFOA targets? Experiments on the public Vernissage database where the humanoid Nao robots make a quiz to two participants shows that reducing VFOA confusion (either through context, or by ignoring VFOA targets) improves addressee recognition.	computation;ground truth;humanoid robot;human–robot interaction	Samira Sheikhi;Dinesh Babu Jayagopi;Vasil Khalidov;Jean-Marc Odobez	2013		10.1145/2535948.2535958	psychology;computer vision;speech recognition;communication	Robotics	-50.55288723438166	-49.16467942573497	129038
98a8e9096d213b69a0e0e85ef01356f4ed99f62f	cell phone system for tour & information guide	voice guide system;cellular phones databases information science information retrieval xml legged locomotion history internet cities and towns costs;history;speech synthesis;data compression;cellular radio;audio database;speech coding;voice data synthesis;voice data compression;tour information guide system;audio database cell phone system tour information guide system voice guide system historic sites voice data synthesis voice data compression;cell phone system;system development;user interfaces audio databases cellular radio data compression history speech coding speech synthesis;audio databases;user interfaces;historic sites	We created a voice guide system for historic sites on trial, in which cell phones are applied as the interface to interpret for the history of the site. The system developed here, converts the data with a text into the synthesized voice data, and compresses it. The system stores the compressed voice data in the database. And, the data can be accessible to the database from the cellular phone. Also, we picked out the technical and management problems of the trial system from a questionnaire and studied the effectiveness of the system. In this paper, we describe this system would be useful if the economic problem of downloading data is solved.	download;mobile phone;speech synthesis	Nariaki Kato;Naohiro Ishii	2007	6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)	10.1109/ICIS.2007.73	speech recognition;computer science;multimedia;world wide web	DB	-48.849242351049455	-39.01588583234879	129145
a964d68a27ef01837c44e1707ec9b7a1a64e14a8	enhancing digital libraries with social navigation: the case of ensemble	social navigation;portal;digital library;information access;user experience;navigation support	A traditional library is a social place, however the social nature of the library is typically lost when the library goes digital. This paper argues social navigation, an important group of social information access techniques, could be used to replicate some social features of traditional libraries and to enhance the user experience. Using the case of Ensemble, a major educational digital library, the paper describes how social navigation could be used to extend digital library portals, how social wisdom can be collected, and how it can be used to guide portal users to valuable resources.	digital library;information access;interaction;library (computing);portals;self-replicating machine;server (computing);user experience	Peter Brusilovsky;Lillian N. Cassel;Lois M. L. Delcambre;Edward A. Fox;Richard Furuta;Daniel D. Garcia;Frank M. Shipman;Paul Logasa Bogen;Michael Yudelson	2010		10.1007/978-3-642-15464-5_13	turn-by-turn navigation;digital library;computer science;multimedia;jet bridge;world wide web	HCI	-59.427165409814	-38.443088898544595	129567
595730dc04b779ece0891a12b05579b0e0f04d64	video data and video links in mediated communication: what do users value?	mediated communication;computer supported cooperative work;video conference;multimedia application;financial services;customer service;multimedia systems;multimedia data;service delivery	Abstract   Most studies of video-mediated, computer-supported cooperative work have investigated the impact of video conference communication links between users. Fewer studies have explored the use of multimedia systems which provide video data. In our study, the perceived benefits of these two sorts of video provision have been directly compared. We explored how users rate the value and usefulness of video links and video data in the same collaborative task, where the video links and data were delivered at different frame rates. Our comparisons of the perceived relative values of teledata and telepresence are based on the responses of 117 users each of whom took part in a session lasting around 45 min in one of the two simulations. Both studies manipulated the quality of multimedia delivery for telepresence and teledata in the same way. The simulations were: (i) the Travel Service Simulation where participants plan a holiday itinerary and (ii) the Financial Service Simulation where participants choose a property and arrange an appropriate mortgage. Participants produced very similar ratings for the perceived quality of the telepresence and the teledata. Subjects across both studies were also in broad agreement on the relative usefulness of the various kinds of multimedia data, teledata being regarded as generally more useful than telepresence. Subjects in both studies tended to rank teledata high in terms of (a) what was most useful, (b) what was the most important feature to preserve and (c) what was the most important to improve. For these multimedia customer services, teledata is more highly valued by users than telepresence. Within such complex multimedia applications, the indication for service delivery then is that, if bandwidth is limited, it would be better assigned to teledata services than to telepresence.		Anne H. Anderson;Lucy Smallwood;Rory Macdonald;Jim Mullin;Annemarie Fleming;Claire O'Malley	2000	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1999.0335	simulation;human–computer interaction;financial services;computer science;service delivery framework;computer-supported cooperative work;multimedia;videoconferencing;world wide web	HCI	-60.24154710097722	-46.69782596044224	129570
8d858721bc9de5b0a7f06a5c96ace03572b65fa1	look who's visiting: supporting visitor awareness in the web	human computer interaction;work environment;qa75 electronic computers computer science;world wide web;augmented reality;ambient media	Individuals, groups and organizations host places in the World Wide Web to attract visitors, but once they have established a web presence they usually maintain little or no awareness of visiting activity. However, the standard web infrastructure supports the capture of detailed activity-related information. In the first part of this paper, we contribute a preliminary study conducted with expert web hosts in different domains, investigating the use of information on visiting activity as feedback for web operation. From this study, we infer general requirements for web awareness support, based on which we have designed two systems aimed to promote more awareness of web activity and visitors. The first is a system supporting ambient notification of web events, enduser configurability, and ambient display for overview and comparison of activity in a web place. The second system moves beyond awareness of web activity to provide glances into the visitors’ sites, introducing reciprocity to the host–visitor relationship. Both systems have been prototyped and deployed in work environments for an evaluation in everyday use. # 2002 Academic Press	ambient network;display device;event (computing);feedback;list of code lyoko episodes;open platform;peripheral;prototype;requirement;situated;speeded up robust features;telecooperation office;web hosting service;web presence;world wide web	Hans-Werner Gellersen;Albrecht Schmidt	2002	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.2001.0514	augmented reality;web development;simulation;web analytics;web design;human–computer interaction;web accessibility initiative;computer science;web navigation;multimedia;web intelligence;web engineering;world wide web	Web+IR	-55.38287075368925	-39.23138149238136	129639
24e1316c9e7cf125415caa830a2c6876ebfdead9	"""web accessibility: is it just a """"merry-go-round""""?"""	universal access;mobile device;web accessibility;mobile web;universal usability;accessibility;usability	While many of the issues that are being raised in relation to mobile web accessibility are similar or the same to those that have been promoted over the past few years in relation to mainstream web accessibility, that doesn't necessarily mean that we're simply going over old material. Rather, it provides a jumping off point for mobile web accessibility. In turn, the differences in emphasis which result from the specific constraints of mobile devices could be crucial in highlighting some aspects of accessibility which, until now, have been neglected.	mobile device;web accessibility	Donna Smillie	2006		10.1145/1133219.1133236	mobile search;web accessibility initiative;web standards;computer science;multimedia;internet privacy;web engineering;world wide web	Web+IR	-51.98279489317134	-40.84354177990117	129674
6262e69d286cebc5d88112dc37a8cf493edfe891	usemonitor: suivre l'évolution de l'utilisabilité des sites web à partir de l'analyse des fichiers de journalisation	log file analysis;web sites usability;efficiency measurement;efficiency measures	This paper introduces UseMonitor, a tool intended to implement the task oriented analysis of the log date. It allows quantifying the average task efficiency that web sites have been offering to theirs users during the accomplishment of transactional tasks. Brief, it makes possible to implement an important usability factor monitoring program in contexts where pages supporting tasks change frequently.	bibliothèque de l'école des chartes;usability	Walter de Abreu Cybis	2006		10.1145/1132736.1132790	human–computer interaction;computer science;data mining;world wide web	Security	-62.310295009579015	-48.84762168281778	129734
0175113d7bf1ae176a59278e5aa6f03eb96baa1e	design and evaluation of the effectiveness of a sonification technique for real time heart-rate data	heart rate;sonification;biofeedback;athletes	This article is motivated by the question “Can a sonification system that provides continuous auditory heart rate feedback help stabilize an athlete’s heart rate at a given target heart rate while exercising?” The sonification system uses a Polar H7 heart rate sensor to measure the heart rate of the athlete and an iOS device for its processing and display. We implemented several sonification approaches, of which two were tested in both a unimodal and an audiovisual context in comparison to a purely visual feedback and to not having any feedback. The system’s objective performance and multiple subjective usability aspects were evaluated in an experiment with 16 subjects. The experiment has to be considered a pilot study because the exercising conditions were artificial. The subjects were exercising on an indoor cycle and could focus their visual sense on the visual display all the time. It was found that all of the feedback methods could convey information to the athlete and were therefore clearly superior to not having any feedback. The failure of showing a supremacy of the multimodal methods over the purely visual one can be reasoned by the fact that the testing conditions were artificial and could therefore not show the advantages of auditory/audiovisual feedback due to limited bandwidth of the visual channel. The conclusions we make about the design and evaluation of such sonification systems can be considered a useful starting point for further work in this field.	multimodal interaction;sonification;supremacy: your will be done;usability;ios	Benjamin Stahl;Balaji Thoshkahna	2016	Journal on Multimodal User Interfaces	10.1007/s12193-016-0218-7	computer vision;real-time computing;simulation;human–computer interaction;artificial intelligence;multimedia;communication	HCI	-49.49325283869083	-47.00648229462073	129905
b56365d47f32cb1ad02689e8f7ad288e2fc03cdc	"""jogging over a distance: supporting a """"jogging together"""" experience although being apart"""	mobile phones;motivational reason;healthy activity;physical;jogging;spatialized audio;sports;pace cue;local jogger;social interaction;jogging partner;running;geographically distant jogger;exhausting;prospective jogger;exertion interface;active;social support	"""Jogging is a healthy activity and many people enjoy jogging with others for social and motivational reasons. However, jogging partners might not always live in the same location, and it may be difficult to find a local jogger who runs at the same pace, we found through a survey """"Jogging over a Distance"""" allows geographically distant joggers to socialize and motivate one another by using spatialized audio to convey presence and pace cues, similar to the experience of running side by side. We hope our approach encourages active and prospective joggers to jog longer and more often, while simultaneously supporting friendships."""	jog dial;prospective search;socialization	Florian Mueller;Shannon O'Brien;Alex Thorogood	2007		10.1145/1240866.1241045	sportscenter;social relation;simulation;multimedia;active set method	HCI	-57.67072759288489	-41.45664076964443	130047
882f996240a841190f8c48f144a19fe8699368e4	chicaro: tele-presence robot for interacting with babies and toddlers		This paper reports a tele-presence robot named ChiCaRo, which is designed for interaction with babies and toddlers. ChiCaRo can physically interact with babies and toddlers by moving around and using its small hand. We conducted a field trial at a playroom where babies and toddlers can freely play to investigate ChiCaRou0027s effectiveness. In the experiment adult participants interacted with their babies and toddlers by ChiCaRo and another robot. The adult participants evaluated ChiCaRo highly in the context of remote interaction with their babies and toddlers.	interaction;robot;television	Kasumi Abe;Masahiro Shiomi;Yachao Pei;Tingyi Zhang;Narumitsu Ikeda;Takayuki Nagai	2016		10.1080/01691864.2018.1434014	developmental psychology;pediatrics;communication	Robotics	-49.67477033595165	-48.7050493841739	130298
86f515e60859bb638554ac3797679a2be7974baf	a videophone prototype system evaluated by elderly users in the living lab schwechat	aal;usability evaluation;touch screen;elderly;field test;ambient assisted living;large scale;system evaluation;information and communication technology;e inclusion;elderly people;ict;ubiquitous computing;voip	Elderly people often experience difficulties in using modern Information and Communication Technologies. This paper presents findings of an evaluation and a field test of a touch screen based internet videophone system mounted in a wooden frame in order to provide a non technical appearance. During a 14-day lasting field test in real-life environment the goal was to evaluate if and to what extent the elderly participants would benefit from using such a modern multimodal way of communication. Four prototype systems were installed in four private homes and were tested successfully by six persons. It was found that the elderly users actually benefited from the touchscreen control, the proportionally large-scale GUI and the VoIP-and video-telephone functions. Despite the small scale of the evaluation the gathered data demonstrates the potential this technology might have in daily life in particular for the emerging ambient assisted living (AAL) area.	living lab;prototype	Johannes Oberzaucher;Katharina Werner;Harald P. Mairböck;Christian Beck;Paul Panek;Walter Hlauschek;Wolfgang L. Zagler	2009		10.1007/978-3-642-10308-7_24	embedded system;simulation;engineering;multimedia	HCI	-55.14148129299138	-41.90563155272353	130363
ca8cfc393688c4d88df0788d21424882698bcd69	mining a multimodal corpus of doctor's training for virtual patient's feedbacks		Doctors should be trained not only to perform medical or surgical acts but also to develop competences in communication for their interaction with patients. For instance, the way doctors deliver bad news has a significant impact on the therapeutic process. In order to facilitate the doctors’ training to break bad news, we aim at developing a virtual patient ables to interact in a multimodal way with doctors announcing an undesirable event. One of the key elements to create an engaging interaction is the feedbacks’ behavior of the virtual character. In order to model the virtual patient’s feedbacks in the context of breaking bad news, we have analyzed a corpus of real doctor’s training. The verbal and nonverbal signals of both the doctors and the patients have been annotated. In order to identify the types of feedbacks and the elements that may elicit a feedback, we have explored the corpus based on sequences mining methods. Rules, that have been extracted from the corpus, enable us to determine when a virtual patient should express which feedbacks when a doctor announces a bad new	feedback;multimodal interaction	Chris Porhet;Magalie Ochs;Jorane Saubesty;Grégoire de Montcheuil;Roxane Bertrand	2017		10.1145/3136755.3136816	human–computer interaction;nonverbal communication;multimedia;computer science;virtual reality;competence (human resources);virtual patient;virtual training	NLP	-53.21781859427178	-47.42264648968543	130395
6bfc7bc0c707dba5063fa680d0d93cce62b0eb02	poster: understanding mobile user interactions with the iot	energy;simulation;internet of things;physical analytics	"""The increasing reach of the Internet of Things (IoT) is leading to a world rich in sensors [3] that can be used to support physical analytics -- analogous to web analytics but targeted at user interactions with physical devices in the real-world (e.g. [2]). In contrast to web analytics, physical analytics systems typically only provide data relating to sensors and objects without consideration of individual users. This is mainly a consequence of an inability to track individual mobile user interactions across multiple physical objects (or across sessions of interaction with a single object) using, for example, an analogue of a web cookie. Indeed, such a """"physical analytics cookie"""" could raise significant privacy concerns.  However, in many cases a more """"human-centric"""" approach to analytics would enable us to provide new and interesting insights into interactions between mobile users and the physical world [1]. In our work we endeavour to leverage synthetic user traces of human mobility, and data from real IoT systems, to provide such insights."""	endeavour (supercomputer);http cookie;interaction;internet of things;sensor;synthetic intelligence;tracing (software);web analytics	Mateusz Mikusz;Oliver Bates;Sarah Clinch;Nigel Davies;Adrian Friday;Anastasios Noulas	2016		10.1145/2938559.2938607	analytics;energy;web analytics;computer science;multimedia;internet privacy;world wide web;internet of things	HCI	-56.681161709983975	-41.97657372622724	130413
3cd6ba025dc88de399f1ad2f28d0e081c0d14408	may smartphones help to maintain audience attention during presentations?		In this paper we describe a new tool for interactive presentations: the speaker shows a common slideshow on the screen, and the users can see the same slide in their smartphone or tablet, independently from its model and brand. The system can be used for both on-line and on-site presentations and encourages the user to perform social activities, e. g., comment or like a slide. The author can also submit a questionnaire or a poll to the audience and see in real-time the answers. Our tool has been used during 37 different events, followed by 3753 users. We recorded the actions of the users and, depending on the different kind of events, the average of actions ranges from 1 to 8 per user per presentation. This data shows that our tool helps to increase users engagement and to maintain user attention.	authentication;comment (computer programming);email;google moderator;html5;online and offline;privacy;projection screen;real-time transcription;smartphone;tablet computer;video projector;web page	Matteo Ciman;Yari Formaggio;Ombretta Gaggi;Marco Regazzo	2015		10.5220/0005441100550063	multimedia;internet privacy	HCI	-53.05970509036524	-42.790437822504316	130434
a1244bef6933af373656e5434cca535e25c3ec64	meet your users in situ data collection from within apps in large-scale deployments	user questionnaires;data collection;tempest;tooling;large scale deployments	Increasingly, 'app-store' releases of software are used as a vehicle for large-scale user trials 'in the wild'. Several opportunities and methodological challenges arise from having little or no access to users, other than through the application itself. So far, researchers have needed to hardcode survey items into the software application studied, which is laborious and error prone. This paper discusses how these problems are addressed using TEMPEST, a platform for longitudinal in situ data collection. The authors illustrate the use of TEMPEST to study the deployment and real-world use of a tablet application called idAnimate; this application has been designed to support the creation of simple animations as design representations during the creative design process. The authors discuss how the tool has supported the gathering of data in over 4000 installations, both from a development and research perspective, and relate their experiences to current research perspectives on large-scale app trials.		Nikolaos Batalas;Javier Quevedo-Fernández;Jean-Bernard Martens;Panos Markopoulos	2015	IJHCR	10.4018/IJHCR.2015070102	simulation;human–computer interaction;computer science;data mining;world wide web;computer security;data collection	HCI	-62.265118389654255	-44.955583827185244	130442
4baca7e6f380f86ababc7f81127e84b706d82e8d	a cognitively based approach to affect sensing from text	emotions;human computer interaction;formal model;affective chat;cognitive theory;occ model;affective ui;natural language;cognitive structure;computational humor;affective computing	"""Studying the relationship between natural language and affective information as well as assessing the underpinned affective qualities of natural language are becoming crucial for improving human computer interaction. Different approaches have already been employed to """"sense"""" affective information from text but none of those considered the cognitive structure of individual emotions and appraisal structure of those emotions adopted by emotion sensing programs. It has also been observed that previous attempts for textual affect sensing have categorized texts into a number of emotion groups, e.g. six so-called """"basic"""" emotion proposed by Paul Ekman which we believe insufficient to classify textual emotions. Hence we propose a different approach to sense affective information from texts by applying the cognitive theory of emotions known as OCC model [1] which distinguishes several emotion types that can be identified by assessing valenced reactions to events, agents or objects described in the texts. In particular we want to create a formal model that can not only """"understand"""" what emotions people wrap with their textual messages, but also can make automatic empathic response with respect to the emotional state detected in the text (e.g. in a chat system). We first briefly describe relevant works and then we explain our proposal with examples. Finally we conclude with future work plans."""	categorization;cognitive science;formal language;human computer;human–computer interaction;natural language;optimistic concurrency control	Shaikh Mostafa Al Masum;Helmut Prendinger;Mitsuru Ishizuka	2006		10.1145/1111449.1111518	emotion;computer science;artificial intelligence;affective computing;affective science;natural language;computational humor	AI	-52.95238046052251	-46.84766861179148	130453
a218f6d3bb615dd8c7c7cd3916f287b634d9d47e	acceptance of ubiquitous computing	etude utilisateur;etude utilisation;new technology;information communication technology;travail;advantage;user study;estudio utilizacion;estudio usuario;laptop computer;acceptance;aceptacion;inconveniente;tablet pc;inconvenient;disadvantage;acceptation;ordinateur portable;work;ubiquitous computing;trabajo;ventaja;avantage;ordenador portatil;user acceptance;use study;nueva tecnologia informacion comunicacion;technologie information communication	N THE LAST DECADE, UBIQUITOUS computing has moved from a futuristic vision to a reality. As computing power continues to increase and hardware becomes more compact, computers have become part of our work and social life, anywhere and anytime. Benefiting from the combination of wireless connectivity and portability similar to that of a traditional spiral notebook, the tablet PC is allowing people to rethink how they do their work. The tablet PC offers such features as lightweight portability, wireless connectivity, and, as the most important factor differentiating it from notebook and desktop computers, stylus input in addition to the traditional keyboard. Obviously, the purpose of these features is to allow users to perform their jobs more effectively and efficiently. However, relatively little prior empirical research exists on whether users perceive that the technological benefits of the tablet PC meet their business needs. Thus we are lifting the lid and looking inside the black box of tablet PC use to attempt to better understand what affects the acceptance and use of the tablet PC in the corporate world. To gain rich insights into how these computing devices are used in the corporate environment, we collected qualitative data at several corporate sites in a range of industries, including medical, education, publishing, and retail. Each organization selected a group of individuals to use the tablet PC as their primary personal computing device for three months or longer. Each study participant was trained on how to use the device, and technical support was provided to the users throughout the study. Participants shared their experiences with us during semistructured interviews. The interviews not only gave us the opportunity to explore variables associated with technology acceptance in previous research, but also enabled new findings to emerge. This article reports the results of this research effort.	anytime algorithm;black box;business requirements;desktop computer;experience;job stream;lambda lifting;personal computer;stylus (computing);tablet computer;technical support;ubiquitous computing	Monica J. Garfield	2005	IS Management	10.1201/1078.10580530/45520.22.4.20050901/90027.3	simulation;advantage;human–computer interaction;computer science;work;ubiquitous computing	HCI	-55.28200574912621	-41.799912163059595	130505
f3f522d0f7942e2af3720d906475972930e05b99	user interface transfer for driver information systems: a survey and an improved approach	user interface description;automotive user interface framework;connected car;automotive application platform;in vehicle infotainment system	At present, devices are establishing themselves on the mobile device market which permit personalization and expansion by means of applications. These applications are increasingly also expected in the vehicle. In contrast to mobile devices, an expandable system in the vehicle is subject to special requirements. These are discussed in this publication and existing approaches are evaluated with regard to the requirements. In this case, outplacing subsequent applications to a smartphone or web server is identified as the best solution. For user interface (UI) integration to the driver information system, final user interface descriptions are identified as a good compromise between complexity and reusability. An improved approach for UI transfer with final UI descriptions using HTML is presented. Compared to existing concepts, this achieves an improvement in the form of graphical quality, response behaviour, reusability and complexity. A prototype implementation makes it clear that a series production system can be subsequently expanded with applications that cannot be distinguished from the basic functions of the driver information system in terms of graphical quality and response behaviour.	graphical user interface;html;information system;mobile device;personalization;production system (computer science);prototype;requirement;server (computing);smartphone;web server	Fabian Hüger	2011		10.1145/2381416.2381435	user interface design;embedded system;user;simulation;engineering;user interface;world wide web	HCI	-51.46037961088038	-39.475909819193895	130685
61373d86cda216cf69571ff134b5250952ca4cf3	tabletalk: integrating personal devices and content for commensal experiences at the family dinner table	food;family mealtime;dr robert comber;commensality;eprints newcastle university;open access;smartphone;dr geremy farr wharton	This paper joins the ubiquitous computing scholarship that investigates the use of technologies in collocated shared settings like family mealtime. Family mealtimes are an important site for fostering togetherness, sharing everyday experiences, and nurturing familial ties. While technologies, especially television and personal devices are often criticized for disrupting the social aspects of mealtimes, they are widely available and commonly used nevertheless. In this paper, we explore this tension and present a novel system TableTalk, which transforms personal devices into a communal shared display on the table to enrich mealtime interactions and experience. Our field study shows that TableTalk does not undermine togetherness, but supports familial expectations and experiences by stimulating conversation, reminiscing, bonding, education, and socializing. We discuss how technology that is sensitive to the needs of family interactions can augment the commensal experience and reflect on design choices and opportunities that contribute, rather than disrupt, family mealtimes.	experience;field research;interaction;socialization;television;ubiquitous computing	Hasan Shahid Ferdous;Bernd Ploderer;Hilary Davis;Frank Vetere;Kenton O'Hara;Geremy Farr-Wharton;Rob Comber	2016		10.1145/2971648.2971715	human–computer interaction;computer security	HCI	-59.59160435686968	-39.8430016441173	131239
4bbe961aa3ffcb8705cd614464b93e2f8a71ed3d	using shared representations to improve coordination and intent inference	plan recognition;groupware;adaptive user interfaces;user adaptation;coordinating representations;knowledge acquisition;adaptive system;common knowledge;communication channels	In groupware, users must communicate about their intentions and aintain common knowledge via communication channels that are explicitly designed into the system. Depending upon the task, generic communication tools like chat or a shared whiteboard may not be sufficient to support effective coordination. We have previously reported on a methodology that helps the designer develop task specific communication tools, called coordinating representations, for groupware systems. Coordinating representations lend structure and persistence to coordinating information. We have shown that coordinating representations are readily adopted by a user population, reduce coordination errors, and improve performance in a domain task. As we show in this article, coordinating representations present a unique opportunity to acquire user information in collaborative, user-adapted systems. Because coordinating representations support the exchange of coordinating information, they offer a window onto task and coordination-specific knowledge that is shared by users. Because they add structure to communication, the information that passes through them can be easily exploited by adaptive technology. This approach provides a simple technique for acquiring user knowledge in collaborative, user-adapted systems. We document our application of this approach to an existing groupware system. Several empirical results are provided. First, we show how information that is made available by a coordinating representation can be used to infer user intentions. We also show how this information can be used to mine free text chat for intent information, and show that this information further enhances intent inference. Empirical data shows that an automatic plan generation component, which is driven by information from a coordinating representation, reduces coordination errors and cognitive effort for its users. Finally, our methodology is summarized, and we present a framework for comparing our approach to other strategies for user knowledge acquisition in adaptive systems.	adaptive system;assistive technology;collaborative software;knowledge acquisition;online chat;persistence (computer science);population	Joshua Introne;Richard Alterman	2006	User Modeling and User-Adapted Interaction	10.1007/s11257-006-9009-2	simulation;human–computer interaction;computer science;knowledge management;artificial intelligence;adaptive system;world wide web;common knowledge;channel	HCI	-61.573484688264536	-39.5615146104352	131341
84360dca08c8d229bdd4fa9816c065091a5307f5	using ontologies in an e-commerce environment: help or hype?	ontology based search;e commerce;low fidelity prototyping;consumer decision process;ontology engineering	Even though online shopping is becoming increasingly popular, many consumers are still reluctant to buy online, especially when it comes to apparel. One approach to improve adaption is to base e-commerce search engines on ontologies to allow a more intuitive search process. This paper presents the results of an analysis how a sample of online shoppers perceived various ontology-based features in an online shop. The data was gathered in two focus groups with panelists coming from different socio-demographic backgrounds (middle-aged women, students in their twenties). Most of the middle-aged women panelists actively shopped for apparel by means of catalogues. However, across the focus groups, most panelists are very reluctant buying apparel online. Our study suggests that age has a higher influence on the information search behaviour of consumers in online shops than gender. The study concludes with suggestions for adapting ontology-based systems to these findings.	digital camera;e-commerce;focus group;futures studies;online shopping;ontology (information science);ontology engineering;requirement;systems engineering;web search engine	Franziska Brecht;Kerstin Schäfer	2010		10.1007/978-3-642-15141-5_10	engineering;knowledge management;marketing;multimedia	AI	-60.67120119242917	-44.77105058991976	131463
06f74f79867655919245e38a85ae506a04c00f85	stb: human-dependent sociable trash box	human-dependent sociable trash box;social coupling;refuse disposal;child-dependent robot;manifold affiliation behavior;interactive behavior;social aspects of automation;children-assisted robot;human-robot interaction;mobile robots;trash collection;sociable trash box;interactive vocalization;intentional stance;stb behavior;social interaction;social rapport;conveying intention;pediatrics;pyroelectricity;human robot interaction;servomotors	We developed a Sociable Trash Box (STB) as a children-assisted robot able to collect the trash in order to convey its intentional stance to children. The STB is capable of engaging manifold affiliation behaviors to build a social rapport with children by collecting the trash around their environment. In particular, the STB is a child-dependent robot that walks alone in a public space for tracing humans and trash for the purpose of collecting the trash. The robot is incapable of collecting the trash by itself, and it engages by using interactive behaviors and vocalizations to make a social coupling with children based on the robot's anticipation to accomplish its goal. The present experiment investigates how STB behaviors are effective in conveying intentions to evoke children's social interactions and to assist in collecting the trash in their environment.	interaction;robot;set-top box	Yuto Yamaji;Taisuke Miyake;Yuta Yoshiike;P. Ravindra De Silva;Michio Okada	2010	2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1734454.1734541	human–robot interaction;mobile robot;social relation;simulation;computer science;artificial intelligence	Robotics	-51.448333455330456	-49.942136832483946	131546
0b2dcc8c38f61a3862db590d6dea367baf651b53	enhancing video games in real time with biofeedback data	volume matting;auto rotoscoping;real time;video game;heart rate;object tracking;user interaction	All video games have the ability to affect a player and the result can be seen in changes of his or her heart rate, perspiration, focus or concentration. This change is a large part of what draws a person to play a game in the first place but overtime players body starts to adjust to the stimuli in the game thus decreasing the interest. What if the game could continuously adjust to players biofeedback and keep the engagement and excitement levels high longer?		Tatyana Koutepova;Yantong Liu;Xiao Lan;Jihyun Jeong	2010		10.1145/1900354.1900417	real-time computing;simulation;computer science;video tracking;multimedia	AI	-53.31556527969997	-44.22868639532308	131699
713a59adab39245fcee72a11767ac68053a5eec1	are discrete emotions useful in human-robot interaction? feedback from motion capture analysis	image motion analysis;joints measurement three dimensional displays indexes motion segmentation legged locomotion;emotion recognition;human robot interaction;conference paper;motion capture;motion capture human robot interaction discrete emotions;image motion analysis emotion recognition human robot interaction;emotional expression modeling human robot interaction motion capture analysis discrete emotions social expressive robot;discrete emotions	We have conducted a study analyzing motion capture data of bodily expressions of human emotions towards the goal of building a social expressive robot that interacts with and supports hospitalized children. Although modeling emotional expression (and recognition) in (by) robots in terms of discrete categories presents advantages such as ease and clarity of interpretation, our results show that this approach also poses a number of problems. The main issues relate to the loss of subtle expressions and feelings, individual features, context, and social interaction elements that are present in real life.	human–robot interaction;motion capture;real life;robot;social robot	Matthew Lewis;Lola Cañamero	2013	2013 Humaine Association Conference on Affective Computing and Intelligent Interaction	10.1109/ACII.2013.23	psychology;human–robot interaction;computer vision;motion capture;simulation;computer science;artificial intelligence;communication	AI	-50.776582068497945	-50.48353316499786	131777
6d1184c77bcee87e3ae074ed317c840e330d0ec0	the analysis and assessment of adjustment of selected web sites and web browsers to the needs of people with disabilities	disabled people;internet standards;graphical interface;user interface;web browsers;people with disabilities;web sites;internet application	In the 21st century internet is becoming an indispensable element of every person's life. Frequently internet is the basic source of information. Moreover it enables communication, making financial transactions, shopping, etc. Unfortunately in many cases internet applications and sites are not adjusted to psychomotor and perception abilities of the disabled, the number of which is continuously increasing in Poland and all over the world. Very often the sites and applications are illegible and not user-friendly.#R##N##R##N#The article presents results of the analysis on adjustment of selected Web site and Web browser graphic interfaces to the needs of disabled people.	google sites	Aleksandra Polak-Sopinska;Zbigniew Wisniewski	2009		10.1007/978-3-642-02713-0_82	web service;web application security;web development;the internet;web of things;web design;human–computer interaction;web accessibility initiative;web standards;engineering;web navigation;web page;multimedia;internet presence management;world wide web;mashup	HCI	-51.445563277493704	-40.36412567229132	131780
2922e48e7084b2d3dd1321d782227e65192c68a3	head motion synchronization in the process of consensus building	image motion analysis;synchronisation behavioural sciences computing image motion analysis;behavioural sciences computing;synchronization accelerometers acceleration materials correlation buildings head;synchronisation;consensus degree head motion synchronization consensus building human communication body motion synchronization questionnaire evaluation synchronization time	Human communication contains not only explicit factors like the meaning of utterance but also implicit factors like body motion. We presume that the synchronization of body motions has a long time with an increased consensus degree during consensus building, and conducted a conversation task to verify this presumption. The present study focuses on the positive correlation of head motions as an indicator of body motion synchronization and questionnaire evaluation as an indicator of consensus building to analyze the relationship between head motion synchronization and consensus degree. Our experimental results showed that two participants' head motions synchronized with each other and the synchronization time of the head motions has a long time during the period of high consensus evaluation. The results suggest that the synchronization period has a long time as consensus degree increases in the process of consensus building.		Yuki Inoue;Eisuke Ono;Jinhwan Kwon;Masanari Motohashi;Daisuke Ikari;Ken-ichiro Ogawa;Yoshihiro Miyake	2013	Proceedings of the 2013 IEEE/SICE International Symposium on System Integration	10.1109/SII.2013.6776680	real-time computing;simulation;computer science;control theory	Robotics	-50.29808164760229	-50.958649334131664	131818
d1a19f9ad11421960e374708fd154d05c0d0a78f	predictive and highly ambiguous typing for a severely speech and motion impaired user	asynchronous communication	Typing commands is the access of choice for many experienced computer users because of the speed and flexibili ty frequent interactions can take place and the ease of defining and using macros. One specific group of persons who can be counted as frequent computer users are speech impaired people relying on electronic devices for augmentative and alternative communication (AAC). But many speech impaired users are severely motor impaired, too. Therefore, the usage of a physical or on-screen keyboard is prohibitively costly for them with a standard keyboard layout. This paper presents a communication aid based on a highly ambiguous keyboard with word completion for communication, interaction and navigation. 1. Electronic communication for severely speech impaired users One outstanding feature of the information society nowadays is the importance of text as communication media in emails, SMS, newsgroups, and webpages. Even in synchronous situations like chatting electronic devices (computers, mobile phones, hand-helds) are used to transmit textual information . The success of ubiquituous communication has partly its reasons in the advantages of written messages via SMS: 1. they may be used for a synchronous or asynchronous dialogue as wanted; 2. they can be absorbed very fast and 3. they can be displayed in private (an important point for the use in classrooms). Likewise, chats, e-mails and newsgroups have become attractive alternative channels of synchronous or asynchronous communication for a varity of virtual communities (groups of interests). For the fraction of population affected by analphabetism, this development establishes a new barrier for participating in society. On the other hand, electronic communication could become an equally accessible communication channel for speech impared members of tomorrow’s information society. However, many strongly speech impaired people have severe motion impairments, too, because of the same causation: by birth (e.g. cerebral palsy), by accident or by disease (e.g. stroke, Lou Gehrig's or multiple sclerosis). For them, typing text with a standard keyboard or the usage of a graphical input device might be impossible. Often only the operation of a single or very few switch signals via buttons, joystick, eye tracking, EEG or other sensors is possible. There are several solutions available for substituting the physical keyboard of a computer by a virtual, on-screen keyboard with different layouts that can be operated with one or two physical switches by scanning: In the simple case of linear scanning, the user presses a switch A repeatedly to step from one key of the virtual keyboard to the next key of the scanning cycle until he reaches the desired key that is then activated by pressing a switch B. For rowcolumn scanning, the user first steps through rows of keys with switch A, selects the wanted row by switch B and then steps through the columns of keys in this row, finally activating the desired key again with switch B. In case only one physical switch is operated, one of the switches can be substituted by self-activation after a certain delay. Thus, the operation of a keyboard is simulated with one or two physical switches, but typing text letter by letter this way is cumbersome: in general, the typing of a word of six letters on a 32 keys keyboard by row-column scanning wil l take dozens of scanning steps. The achieved written communication rate ranges from less than 1 to 5 wpm (words per minute) — a typist's rate in comparison ranges from 10 to 20 wpm depending on her level of expertise (Darragh and Witten, 1992). 2. Ambiguous keyboards and word prediction Instead of reducing the number of required keystrokes for a word by using an enlarged keyboard with e.g. iconic codings, Kushler (1998) proposes the use of an ambiguous keyboard with multiple letter key assignments in the way phone keys are used for the so called vanity phone numbers: every phone digit key from 2 to 9 is additionally labeled with at least three letters. Instead of memorizing digit sequences for the phone number of telephone services, it suffices to dial the phone keys labeled with the letters of e.g. the name of the provider. If arbitrary words are coded this way many encodings will be the same for different words, i.e. the decoding function is not injective. Therefore, the user has to select the intended word in a list of word suggestions (ordererd e.g. by word frequencies) whenever the mapping between the encoding and the intended word is not one-to-one. Nevertheless, as Witten (1982) already pointed out, with nine letter keys only eight percent of 24,500 words actually are encoded ambiguously and thus need adisambiguation step. Following studies (Foulds et al., 1987) concentrated on ambiguous typing where only the next character is predicted based on n-grams and corrected if necessary, as the size of an electronic full word or even syllable dictionary would have been too limited (Arnott & Javed, 1992). The drawback of this character-based disambiguation is that the user has to pay attention to the predicted word prefix after each keystroke. Today, the storage of large vocabulary in main memory of a standard computer is not a serious problem anymore. The advantages of an ambiguous keyboard with eight keys and word disambiguation are enumerated by Kushler (1998) for users of alternative and augmentative communication devices as follows: 1. The efficiency of an ambiguous keyboard is near to one keystroke per letter. 2. Apart from literacy, no memorization of special encodings is required. 3. Attention to the display is required only after the word has been typed. 4. A keyboard with fewer keys can have larger keys for direct selection. 5. The average time to select a key by scanning is reduced considerably. 6. Simple, linear scanning can be used efficiently to select a key. 7. Fewer keys may allow direct selection with various input devices. Surely, the main arguments for a character-based text input with an ambiguous keyboard are that the keystroke per letter efficiency is very high and that there is no need for the user to learn any special encodings besides standard orthography. Further, if the user did a typing mistake, this error is corrected more easily as if the typing mistake is done via scanning on a 100+ keys keyboard. Finally, a character-based vocabulary can be extended very easily with new words, whereas an iconic language system has to depend on the user to memorize the icon word associations and reaches its limits, if we do not restrict ourselves to a base vocabulary of a few thousand words. The use of an ambiguous keyboard is compatible with another technique to accelerate typing input: the prediction and completion of user input. Actually, the completing prediction of commands and other user input (e.g. Darragh and Witten, 1992) to accelerate keyboard input for motion impaired users is a well-known and much used feature of standard software like word processors or command shells nowadays. The key idea is to present the user at every step of user input a ranked list of predictions what the user is going to type next based on a statistical model of the recent input. On top of reducing the typing costs there is another advantage of this input enhancing feature for users who do not always memorize exactly the set of admitted inputs in a certain context: The user can type the prefix of the intended input and request a list to be displayed for possible completion alternatives, thus reducing the cognitive load of memorization for orthography (Newell et al., 1995). 3. The UKO pilot study UKO is the abbreviation for German “Unbekanntes Kommunikationsobjekt” (i.e. “unidentified communication object” ) – the name given to our communication aid by its pilot user, a fifteen-year old girl with cerebral palsy who visits a regular school. This communication aid consists of an ambiguous keyboard with four letter keys plus an “enter” and a “delete” key. The keys are scanned cyclically. A second physical switch is used to activate the word completion with the word suggestions depicted on the right side (as in Figure 1). Figure 1. The UKO virtual keyboard (after selecting the first key four times) In his diploma thesis, Garbe (2000) followed an evolutionary optimisation approach to find an ambiguous letter key assignment for a keyboard with six keys that is to be used by cyclic scanning (cf. Levine and GoodenoughTrepagnier, 1990). The UKO system includes keyboard layouts for German and English and the corresponding lexica from the CELEX lexicon database with 360,000 resp. 160,000 word form entries (Baayen et al., 1995). Using the 360,000 German word form lexicon including word frequencies information, the ambiguous word form lists do not grow longer than 34 entries. This motivated us to look further for even smaller keyboards, and, actually, a keyboard with only three letter keys is used now, with a fourth key functioning as a quasimodal command key (Raskin, 2000) that is used in connection with one of the letter keys to invoke the “enter”, “delete” and “complete” function of the UKO system. These three plus one keys wil l be selected directly by our pilot user who formerly has used two-switch-scanning until now. Therefore, another considerable typing speed-up is expected. But even with linear scanning the six keys of the UKO keyboard as depicted in Figure 1, experimental results compared with an iconic communication system are encouraging: an time improvement of 18% could be achieved on a small test set of ten sentences with ten words in average, mainly since there were on average two unknown words per sentence using the iconic vocabulary, which then had to be spelled rather costly. Using the larger CELEX lexicon for the UKO system, only two of the 101 words in total were unknown for the ten sentences. The sentences with no unknown words have been entered in approximately the same time of 8.56 seconds	advanced audio coding;ambiguous grammar;causality;central processing unit;channel (communications);column (database);computer data storage;computer keyboard;dictionary;diploma;eur-lex;electroencephalography;email;event (computing);eye tracking;grams;graphical user interface;input device;interaction;joystick;lexicon;mathematical optimization;microsoft word for mac;mobile phone;n-gram;network switch;one-to-one (data model);plover;protologism;sensor;simulation;statistical model;syllable;telephone number;test set;text-based (computing);typing;user (computing);virtual community;virtual keyboard;vocabulary;word lists by frequency;word-sense disambiguation;words per minute	Michael Kühn;Jorn Garbe	2001			human–computer interaction;typing;multimedia;asynchronous communication;augmentative and alternative communication;mobile phone;virtual community;computer science	HCI	-48.94570257553578	-43.90948422539383	131877
9dbae81866dbca3912bf446942370be108bb9efc	designs on dignity: perceptions of technology among the homeless	at risk populations;urban environment;social context;social computing;homeless;social network;qualitative study;information need;urban computing;diary study;social environment;value sensitive design	Technology, it is argued, has the potential to improve everyone's life: from the workplace, to entertainment, to easing chores around the home. But what of people who have neither job nor home? We undertook a qualitative study of the homeless population in a metropolitan U.S. city to better understand what it means to be homeless and how technology--from cell phones to bus passes--affects their daily lives. The themes we identify provide an array of opportunities for technological interventions that can empower the homeless population. Our investigation also reveals the need to reexamine some of the assumptions made in HCI about the relationship people have with technology. We suggest a broader awareness of the social context of technology use as a critical component when considering design innovation for the homeless.	human–computer interaction;mobile phone	Christopher A. Le Dantec;W. Keith Edwards	2008		10.1145/1357054.1357155	social environment;human–computer interaction;computer science;social computing	HCI	-58.51992048620092	-41.36855689314501	132006
efd7a1546f26020d104ec4d92c624d3c0761950d	exploring the uncanny valley effect in social robotics	robot design;affective human robot interaction;emotion recognition;uncanny valley effect	To ensure natural communication in Human-Robot Interaction (HRI), robots' design and appearance features, e.g., like the degree of anthropomorphism and especially the expression of emotions, must be considered. In this study, we investigated how different types of robots are perceived in complex affective settings. While varying the robots' degree of anthropomorphism and expressed emotions, participants' emotion recognition ability and the influence on the perceived uncanniness of the robots were observed. We used 16 different scenes from movies, in which robots were presented that systematically differed in their anthropomorphic appearance and behavior. N = 98 participants rated the human-likeness and their perceived uncanniness of four types of robots in four different emotional states each (happiness, sadness, anger, and neutral). Considering the results it was possible to recreate the Uncanny Valley Effect [1] with complex stimuli and to show the influence of expressed emotions by robots on the perceived human-likeness and uncanniness.	emotion recognition;human–robot interaction;mcgurk effect;robot;robotics;sadness;uncanny valley	Nico Tschöpe;Julian Elias Reiser;Michael Oehl	2017		10.1145/3029798.3038319	computer science;artificial intelligence;uncanny valley	Robotics	-51.16327401003715	-50.569297076073944	132245
2ee0945c7b0dc674e03d44431e6183dff11dfc1b	airhockey over a distance	social interaction;videoconference;air hockey;tangible interface;distributed environment;computer mediated communication;social experiment;physical interface;exertion interface;connectedness	In modern society, people increasingly lack social interaction, although beneficial to work and personal life. Airhockey Over a Distance addresses this issue by recreating the social experience facilitated by physical game play in a distributed environment. We networked two airhockey tables and augmented them with a videoconference. Concealed mechanics on each table allow for a physical puck to be shot back and forth between the two locations. Supporting the hitting of a fast-moving, tangible puck between the two players creates a compelling social game experience which was confirmed by about 30 players. Our preliminary findings suggest that our casual physical game supports social interactions and contributes to an increased connectedness between people who are geographically apart.	dos;interaction	Florian Mueller;Luke Cole;Shannon O'Brien;Wouter Walmink	2006		10.1145/1125451.1125665	social relation;simulation;social experiment;human–computer interaction;social connectedness;computer science;multimedia;videoconferencing;world wide web;distributed computing environment;computer-mediated communication	HCI	-56.80381696365229	-38.70813683085629	132353
3f0f4ca53bc245504ebae7ffb8ba7ff2ca03ddba	the use of abstraction and motion in the design of social interfaces	social interaction;design methods;public installations;social interfaces;design method;visual cues;social awareness;iterative design;social cues;socially aware systems;interaction design;qualitative evaluation	In this paper, we explore how dynamic visual cues can be used to create accessible and meaningful social interfaces without raising expectations beyond what is achievable with current technology. Our approach is inspired by research in perceptual causality, which suggests that simple displays in motion can evoke high-level social and emotional content. For our exploration, we iteratively designed and implemented a public social interface using abstraction and motion as design elements. Our interface communicated simple social and emotional content such as displaying happiness when there is high social interaction in the environment. Our qualitative evaluations showed that people frequently and repeatedly interacted with the interface while they tried to make sense of the underlying social content. They also shared their models with others, which led to more social interaction in the environment.	causality;high- and low-level;social interface;social media	Bilge Mutlu;Jodi Forlizzi;Illah R. Nourbakhsh;Jessica K. Hodgins	2006		10.1145/1142405.1142444	social relation;social learning;design methods;human–computer interaction;social competence;computer science;social heuristics;multimedia	HCI	-53.47514651488605	-44.8709165286531	132369
32c062d882f9c04a3832cc3598acc9eb2e8d2725	hospital user research using new media arts	new media arts;intensive care;user research;mobile devices;new media art	This paper presents a comparative analysis of group interaction around two display types, shared and individual, using a ‘new media’ arts application as a way to explore the physical technology setup for an intensive care unit in a hospital. We propose this method for laboratory settings when the research questions derive from socially complex environments, but realworld interventions are not possible. While users solve an ‘interaction problem’ that is posed through the ‘new media’ arts application for their own expressive purposes, researchers can analyse and collate the results to understand the solution space. We present a study with the bodyPaint application to address a design issue that we discovered when assessing the merits of an electronic patient record system.	feasible region;new media;qualitative comparative analysis;user research	Cecily Morrison;Alan F. Blackwell	2009		10.1145/1671011.1671055	simulation;medicine;human–computer interaction;multimedia	HCI	-61.094258630141965	-42.478758774644234	132688
8fcf2683e22cec2ae5008417e27c48b831e33d20	evaluating web accessibility for specific mobile devices	user agent;mobile device;device tailored evaluations;web accessibility;false negative;automatic generation;mobile web;false positive	This paper presents a tool for evaluating web accessibility for mobile devices regardless their software, hardware or user agent characteristics. Taking the mobileOK Basic tests by the W3C as a basis, these tests are extended so that device characteristics can be considered in the evaluation process. A sound tool that takes into account these extended tests has been developed. Device features of a given device are retrieved from heterogeneous device description repositories and CC/PP based profiles are automatically generated. Based on these profiles, evaluation queries are dynamically created obtaining device-tailored evaluation reports. Finally, in order to demonstrate the feasibility of the tool, a case study has been conducted concluding that the tool reduces the number of false positives and false negatives.	evaluation function;mobile device;user agent;web accessibility	Markel Vigo;Amaia Aizpurua;Myriam Arrue;Julio Abascal	2008		10.1145/1368044.1368059	computer science;multimedia;internet privacy;world wide web	HCI	-51.21171473546657	-41.49327537715017	132698
8223a3b2711d2aa293e626a8a9501ced2b111919	understanding system implementation and user behavior in a collaborative information seeking environment.	user study;evaluation;user behavior;collaborative information seeking	It is well said that two minds are better than one. When it comes to accessing or processing some information, it seems natural to expect that when people work together in collaboration they (1) can accomplish more, (2) benefit from other people’s experience and expertise on the given topic, and (3) influence each other and develop a more profound understanding of the subject than when they are isolated. While it seems that doing collaboration with others will make sense in many situations, the value of collaboration is often overlooked. Based on their extensive study with patent office workers, Hansen and Jarvelin [2] concluded that the assumption that information retrieval performance is purely individual needs to be reconsidered. Twidale and Nichols [4] argued that a truly user-centered system must acknowledge and support collaborative interactions between users and showed that users often desire to collaborate on search tasks. As the need to collaborate continues, the behavior of users in a collaborative environments remains under-studied, and the tools to facilitate collaborative information seeking have left much to be desired, my proposed research for studying Collaborative Information Seeking (CIS) is not only timely, but also very important. So far my research has primarily been focused on the system side. For instance, my work with others has shown the effectiveness of combing queries from different users for the same topic [1], as well as of algorithmically mediating the results for a collaborative search environment [3]. I would now like to focus my attention on more user-centric IR systems that facilitate intentional, interactive, and immediate collaboration among users. As a first step in this direction, I have developed a system called Coagmento, which allows a pair of users to search TREC collections and col-	algorithm;collaborative information seeking;information retrieval;interaction;mind;nichols plot;text retrieval conference;user-centered design	Chirag Shah	2008	TCDL Bulletin	10.1145/1390334.1390571	user modeling;computer user satisfaction;human–computer interaction;knowledge management;evaluation;world wide web	Web+IR	-60.28543657461269	-42.34663915398091	132747
ce1145c42cec36f3185ec5d9c6eacdda0dde3281	collection and annotation of a corpus of human-human multimodal interactions: emotion and others anthropomorphic characteristics	human interaction;corpus collection;affective interaction;human human interaction;annotation;multimodal interaction;it evaluation;multimodal behaviours	In order to design affective interactive systems, experimental grounding is required for studying expressions of emotion during interaction. In this paper, we present the EmoTaboo protocol for the collection of multimodal emotional behaviours occurring during human-human interactions in a game context. First annotations revealed that the collected data contains various multimodal expressions of emotions and other mental states. In order to reduce the influence of language via a predetermined set of labels and to take into account differences between coders in their capacity to verbalize their perception, we introduce a new annotation methodology based on 1) a hierarchical taxonomy of emotion-related words, and 2) the design of the annotation interface. Future directions include the implementation of such an annotation tool and its evaluation for the annotation of multimodal interactive and emotional behaviours. We will also extend our first annotation scheme to several other characteristics interdependent of emotions.	cognition;consciousness;dyadic transformation;experiment;human–computer interaction;interdependence;mental state;multimodal interaction;openness;text corpus;theory;wordnet	Aurélie Zara;Valérie Maffiolo;Jean-Claude Martin;Laurence Devillers	2007		10.1007/978-3-540-74889-2_41	natural language processing;interpersonal relationship;speech recognition;computer science;multimodal interaction;multimedia;communication	NLP	-52.588436770571086	-47.556347885680815	132826
d073854cc33c9c08e679c7a3805ef9bea324ba42	slll at the ntcir-12 lifelog task: sleepflower and the lit subtask		SLLL (Waseda University SakaiLaboratoryLifeLog team) is working on a prototype smartphone application called Sleepflower, which is designed to improve the sleep cycles of a group of users through a collaborative effort. A flower metaphor is displayed on the smartphone screen to represent the current sleepiness of a particular user, along with similar metaphors for the other group members, in the hope of improving the lifestyles of the group as a whole. One significant limitation of the current prototype is that sleep hours and sleepiness grades need to be entered manually; we are hoping to build a new prototype that semi-automaticallly collects lifelog data such as those provided by the NTCIR Lifelog task. As an initial step towards this goal, we manually analyse the NTCIR Lifelog image data from the viewpoint of individual sleeping habits and discuss possible approaches to leveraging such data for the next version of Sleepflower.	lifelog;mobile app;prototype;semiconductor industry;smartphone	Satomi Iijima;Tetsuya Sakai	2016			lifelog;information retrieval;computer science	HCI	-55.37194983554658	-43.085709385229364	132937
62867745cb82bca5314002eb91574b4b921624d7	acquisition and use of mobility habits for personal assistants	consumer preferences;habits;mobility;personalized traveler information;hidden markov models global positioning system feature extraction public transportation smart phones predictive models;data quality mobility habit use mobility habit acquisition personal assistants human mobility behavior ecological awareness intermodal mobility behavior mobility options cars bike sharing smart phones information overload digital mobility assistants user habits user preferences intelligent assistance personalized mobility models habitual trips habitual destinations sparse sensor data mobile devices battery life;smartphones;konferenzveroffentlichung;websearch;personal digital assistants;traffic information systems smart phones;travel behavior;publications database;rwth publications	With large parts of human population increasingly living in big cities, the mobility behavior of humans is about to change faster than ever before. Not only convenience and increasing ecological awareness lead to more intermodal mobility behavior, also the rise of new mobility options like car-or bike sharing are becoming more and more common. Wide distribution of smartphones and the on-trip availability of high-speed Internet let users inform themselves about a vast variety of mobility options. This information overload can overburden users who often have the simple wish to conveniently travel from A to B. Digital Mobility Assistants ease the burden of selecting the best mobility option for a particular user by incorporating the users' habits and preferences and providing relevant information at just the right time. To enable such intelligent assistance, we propose to create personalized mobility models that include not only information about habitual trips and destinations, but also allow for the detection of preferred travel modes. Our system is specifically designed to use sparse sensor data from mobile devices, such as smartphones, to offer an adequate balance between battery-life and data quality.	cluster analysis;data quality;humans;information overload;internet access;mobile device;personalization;smartphone;sparse matrix	Lukas Nack;Roman Roor;Michael Karg;Alexandra Kirsch;Olga Birth;Sebastian Leibe;Markus Strassberger	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.245	simulation;engineering;multimedia;advertising;mobility model	Robotics	-50.07311688140309	-40.99038428572964	132978
9245c5f9355888fd6a0c32a641e7e00b0d9c0cf6	people with specific learning difficulties: easy to read and hci	learning difficulties	Off the beaten tracks of technically focused accessibility and usability regulations lies a field of research - almost undiscovered by mainstream accessibility and usability discussions that has the potential to serve people with Specific Learning Difficulties as well as other possible target groups best: How to provide information, tools, services and structures that is readable, understandable and usable for the biggest possible user group.	human–computer interaction	Andrea Petz;Bror Tronbacke	2008		10.1007/978-3-540-70540-6_100	human–computer interaction;computer science;multimedia;world wide web	HCI	-51.706021335612334	-39.94101494947239	133071
8eb75bb38d7d3362be1d169154201dc803efcc6e	a lightweight algorithm for procedural generation of emotionally affected behavior and appearance		Displaying believable emotional reactions in virtual characters is required in applications ranging from virtual-reality trainers to video games. Manual scripting is the most frequently used method and enables an arbitrarily high fidelity of the emotions displayed. However, scripting is labour intense and greatly reduces the scope of emotions displayed and emotionally affected behavior in virtual characters. As a result, only a few virtual characters can display believable emotions and only in pre-scripted encounters. In this paper we implement and evaluate a lightweight algorithm for procedurally controlling both emotionally affected behavior and emotional appearance of a virtual character. The algorithm is based on two psychological models of emotions: conservation of resources and appraisal. The former component controls emotionally affected behavior of a virtual character whereas the latter generates explicit numeric descriptors of the character’s emotions which can be used to drive the character’s appearance. We implement the algorithm in a simple testbed and compare it to two baseline approaches via a user study. Human participants judged the emotions displayed by the algorithm to be more believable than those of the baselines.	algorithm;baseline (configuration management);chain-of-responsibility pattern;computational model;procedural generation;testbed;usability testing;virtual reality	Yathirajan Brammadesam Manavalan;Vadim Bulitko;Marcia Spetch	2015			multimedia;simulation;computer science;psychological models;high fidelity;scripting language;testbed;algorithm	HCI	-54.877944620554445	-48.13324165696003	133093
9fb0fe95ad54c0cb20355fed800c2db9233d5348	sparcs: exploring sharing suggestions to enhance family connectedness	families;sharing;home;connectedness;field study	Staying in touch with extended family members can be a challenge in part because of the time and effort required, even with the help of current technologies. To explore the value of sharing suggestions in sparking communication and facilitating sharing between extended families, we iteratively built SPARCS, a prototype that encourages frequent sharing of photos and calendar information between extended families. Results from a five-week field study with 7 pairs of families highlight a number of important features for an ideal sharing system to help families stay connected, including asynchronous chat and easily configurable sharing suggestions.	field research;prototype	A. J. Bernheim Brush;Kori Inkpen Quinn;Kimberly Tee	2008		10.1145/1460563.1460661	simulation;social connectedness;computer science;sociology;communication;world wide web;anthropology;field research	HCI	-58.16369080412457	-40.33730709894333	133460
2a31a4bfe695ddb563973f8183abf8eb8e35fcf8	evaluating exploratory visualization systems: a user study on how clustering-based visualization systems support information seeking from large document collections	human computer interaction;information visualization;clustering;cognition;information seeking	Iterative, opportunistic and evolving visual sensemaking has been an important research topic as it assists users in overcoming ever-increasing information overload. Exploratory visualization systems (EVSs) maximize users’ information gain through learning and have been widely used in scientific discovery and decision making contexts. Although many EVSs have been developed recently, there is a lack of general guidance on how to evaluate such systems. Researchers face challenges such as understanding the cognitive learning process supported by these systems. In this paper, we present a formal user study on Newdle, a clusteringbased EVS for large news collections, shedding light on a general methodology for EVS evaluation. Our approach is built upon cognitive load theory that takes the users as well as the system as the foci of evaluation. The carefully designed procedures allow us to thoroughly examine the users’ cognitive process as well as control the variability among human subjects. Through this study, we analyze how and why clustering-based EVSs benefit (or not) users in a variety of information seeking tasks. We also summarize leverage points for designing clustering-based EVSs.	cluster analysis;cognition;exploratory testing;heart rate variability;information gain in decision trees;information overload;information seeking;kullback–leibler divergence;sensemaking;twelve leverage points;usability testing	Yujie Liu;Scott Barlowe;Yaqin Feng;Jing Yang;Min Jiang	2013	Information Visualization	10.1177/1473871612459995	information visualization;cognition;computer science;artificial intelligence;machine learning;data mining;multimedia;cluster analysis;world wide web	HCI	-61.41704839136955	-45.167895174810845	133499
ab7e08e94314b596ba3f48cdb7984d06ba565960	linking physical activities and video games	sports monitoring;player questionnaire;video games;application federation;physical activity tracking;exercise motivation	This study presents a concept for linking individual physical activities and video games together to build an ecosystem to motivate players to exercise. We used a systematic mapping study to establish current state of art and a user questionnaire to understand how players feel about digital rewards from physical exercises. In addition we implemented a prototype to demonstrate the applicability. The results suggest that combining games and physical activity trackers together is technologically feasible, and there is an audience who would be willing to exercise in order to receive rewards in games.	activity tracker;ecosystem;prototype	Jouni Ikonen;Petri Ryhänen;Janne Parkkila;Antti Knutas	2015		10.1145/2812428.2812457	simulation;turns, rounds and time-keeping systems in games;multimedia	HCI	-56.34728587118378	-42.251701226867475	133505
763e5f3f411a5c8d946882cbcc794e62188a8d4b	designing configurable automotive dashboards on liquid crystal displays	road user tests;pedestrian safety;liquid crystal display;poison control;injury prevention;safety literature;liquid crystal displays;digital automotive dashboards;traffic safety;injury control;multimedia systems;graphics design;home safety;injury research;safety abstracts;human factors;adaptive cruise control;car;occupational safety;safety;user testing;safety research;accident prevention;violence prevention;bicycle safety;information system;communication channels;poisoning prevention;falls;runtime configurability;ergonomics;suicide prevention;human machine interaction;graphic design	The instrument cluster is an important element of the automotive passive safety system, since it shows to the driver the status of the car’s signals. This role becomes even more important as the number of advanced driving assistance systems (e.g., frontal collision warning, night vision support, parking aids, adaptive cruise control) increases. However, the larger number of warnings and signals conflicts with the limited display area available in vehicle. The ACTIVE project has developed software programmable dashboards on liquid crystal displays (LCDs), studying an efficient exploitation of the visual space of the instrument cluster. Such displays are flexible in terms of customization and of runtime configurability, allowing changes to number, layout, and appearance of visible instruments according to the actual driving conditions. Moreover, configurable dashboards can become an open communication channel able to integrate and harmonize, according primarily to safety considerations, any kind of visual information coming from present and future information systems (e.g., concerning safety and infotainment). This paper contributes to the study of this emerging research field through the description of the flow of design we followed in developing a real in-car system, and through the analysis of the potential impact on users of such a new flexible interface. In particular, we discuss results of lab and road tests conducted at Robert Bosch GmbH in Germany.	augmented reality;channel (communications);computer monitor;desktop computer;device driver;function overloading;human–computer interaction;information system;intelligent agent;liquid-crystal display;mobile phone;paging;personal digital assistant;real-time transcription;thin-film-transistor liquid-crystal display	Francesco Bellotti;Alessandro De Gloria;Andrea Poggi;Luisa Andreone;S. Damiani;P. Knoll	2004	Cognition, Technology & Work	10.1007/s10111-004-0163-1	embedded system;simulation;medicine;environmental health;human–computer interaction;computer science;engineering;human factors and ergonomics;liquid-crystal display;computer security;mechanical engineering	HCI	-49.35151917931758	-42.32525217759573	133689
78c03269dbe2a3a38fde23656cbca9463bd65aed	the role of verbal and nonverbal communication in a two-person, cooperative manipulation task		Motivated by the differences between human and robot teams, we investigated the role of verbal communication between human teammates as they work together to move a large object to a series of target locations. Only one member of the group was told the target sequence by the experimenters, while the second teammate had no target knowledge. The two experimental conditions we compared were haptic-verbal (teammates are allowed to talk) and haptic only (no talking allowed). The team’s trajectory was recorded and evaluated. In addition, participants completed a NASA TLX-style postexperimental survey which gauges workload along 6 different dimensions. In our initial experiment we found no significant difference in performance when verbal communication was added. In a follow-up experiment, using a different manipulation task, we did find that the addition of verbal communication significantly improved performance and reduced the perceived workload. In both experiments, for the haptic-only condition, we found that a remarkable number of groups independently improvised common haptic communication protocols (CHIPs). We speculate that such protocols can be substituted for verbal communication and that the performance difference between verbal and nonverbal communication may be related to how easy it is to distinguish the CHIPs from motions required for task completion.	experiment;haptic technology;robot	Sarangi P. Parikh;Joel M. Esposito;Jeremy Searock	2014	Adv. Human-Computer Interaction	10.1155/2014/375105	psychology;simulation;communication;social psychology	HCI	-51.1543141295311	-50.62896520948165	133723
a98842f58b8627b7eb149fb5448a31a3e3d30ece	"""""""context"""" from the human perspective: dispositions and practice"""		As the notion of ubiquitous computing moves from abstract ideal to collective reality, a number of opportunities emerge that have the potential to dramatically change the devices that populate our daily lives and the patterns of interaction that those devices engender. To ensure that ubiquitous technologies enable useful interactions, we need to incorporate a more expressive notion of context, including how it is enacted, how it is identified, and how it is understood and utilized. This paper presents such an approach, highlighting the ways in which context can be defined in practice through the identification of the human dispositions that shape our everyday activities. These dispositions provide a shared vocabulary for technologies and its users to more effectively mediate meaningful interactions.	interaction;population;ubiquitous computing;vocabulary	Michael Gilbert;Julia Katherine Haines;Elizabeth F. Churchill;Monica Caraway;Kelly Graham;Gabriela Madrid Valero;Alexandra Olarnyk;Swetha Ramaswamy;Padma Ravikumar;Jihoon Suh;Manuel Zetino;Mark Zachry	2017		10.1145/3123024.3123100	ubiquitous computing;human–computer interaction;design methods;computer science;knowledge management;vocabulary	HCI	-58.56365366379832	-39.55143069331788	133880
dbf2b2dbbe361ec5d00d0075d6de3b4e4dd98aad	anisam & aniavatar: animated visualizations of affective states	emotions;visualization;feedback;mood;affective states	Tools that provide visual feedback about emotions to the user in the form of an avatar or an emoticon have become increasingly important. While a great deal of effort has already been put into the reliable and accurate automatic detection of emotions, only very little is known about how this information about affective states should be displayed in a comprehensible way to the user. In the present study, three newly developed feedback tools were evaluated. The tools were developed on the basis of an existing non-verbal questionnaire to represent two dimensions of emotion (i.e. valence and arousal) based on the circumplex model of affect. A total number of 826 participants were tested, using different vignettes that describe situations with specific affective content. Employing three newly developed affective feedback tools (AniSAM, AniAvatar and MergedSAM), the ratings obtained were compared to ratings using the original SAM instrument, a well-established questionnaire to measure affect. Results indicated that the animated feedback increased the accuracy of the arousal representation. Furthermore, valence feedback was more accurate when provided with an animated manikin-based tool rather than an avatar-based tool. This provided first evidence for the usefulness of animated tools offering visual feedback on user emotion. All instruments need to undergo further development. AniSAM and AniAvatar can be downloaded for purposes of practical applications and further research.	emoticon;human–computer interaction	Andreas Sonderegger;Klaus Heyden;Alain Chavaillaz;Jürgen S. Sauer	2016		10.1145/2858036.2858365	simulation;visualization;emotion;human–computer interaction;computer science;feedback;multimedia	HCI	-58.73081414647853	-46.97133711084859	133938
734b78cf052a2cfad9a3d3b467f200a1f91c9048	beyond the gamepad: hci and game controller design and evaluation		A game controller, and how that controller is supported in a game, can have a significant impact on a player's gaming experience. In recent years there has been an increasing amount of computer game focused HCI research, but the impact of controller-related issues on user experience remains relatively unexplored. In this chapter we highlight the limitations of current practices with respect to designing support for both standard and innovative controllers in games. We proceed to explore the use of the McNamara and Kirakowski's (2006) theoretical framework of interaction in order to better design and evaluate controller usage in games. Finally, we will present the findings of a case study applying this model to the evaluation and comparison of three different game control techniques: gamepad, keyboard and force feedback steering wheel. This study highlights not only the need for greater understanding of user experience with game controllers, but also the need for parallel research of both functionality and usability in order to understand the interaction as a whole.	benchmark (computing);biometrics;game controller;gamepad;haptic technology;human–computer interaction;pc game;steering wheel;usability;usability testing;user experience;virtual world	Michael A. Brown;Aidan Kehoe;Jurek Kirakowski;Ian J. Pitt	2010		10.1007/978-1-84882-963-3_12	simulation;human–computer interaction;engineering;multimedia	HCI	-48.65584402903235	-45.129324360961746	134078
cf02f1e30798d6f792c3056aefda4910a918b309	using a telepresence robot to improve self-efficacy of people with developmental disabilities		People with Developmental Disabilities (DD) often rely on other people to perform basic activities such as leaving the house and accessing public spaces. This problem, exaggerated by a decrease in community engagement, has been documented to decrease their sense of self-efficacy. Telepresence robots provide a unique opportunity for people with DD to access public spaces, particularly for those who are homebound or dependent on others for using transportation or buying exhibit tickets. This research evaluates the use of telepresence robots operated by people with DD in exploring a public exhibit. This study was in partnership with Hope Services, an organization that provides skill-improving activities for people with DD. Our analysis consisted of quantitative and qualitative methods using data from semi-structured pre- and post-interviews focusing on participants' sense of physical and social self- efficacy, and well-being. Our study revealed positive trends toward showing that using telepresence can contribute to wellbeing and physical and social self-efficacy. Therefore, we believe that there is some promise for using telepresence robots to tour an exploratory space for people with DD and that it can be a viable option for those who face accessibility limitations.	accessibility;developmental robotics;robot;semiconductor industry;telerobotics	Natalie Friedman;Rawan Mohammad Al Saudi	2018		10.1145/3234695.3240985	social connectedness;human–computer interaction;applied psychology;robot;telerobotics;general partnership;computer science;community engagement;qualitative research;self-efficacy	HCI	-54.52785275204821	-50.84792336219821	134211
b320834b973b6e26d0b7744e1cf01850eb1db5c7	the role of modular robotics in mediating nonverbal social exchanges	fonction green;social isolation;social interactive modular robotic device;patient therapeutic intervention;social exchanges;rolling pin;technologie communication;inelasticite;pins;nonverbal communication;funcion green;social interaction;nonverbal social exchange;rotation measurement;design and development;systeme modulaire;inelasticidad;vibracion;sistema modular;robotics;orientation;imitation;patient care;social dynamic;plastics;medical robotics;radio communication technology modular robot nonverbal social exchange nonverbal communication dementia care rolling pin social interactive modular robotic device patient therapeutic intervention semitransparent plastic tube;red green and blue;social exchange;inelasticity;feedback;robot kinematics dementia vibration measurement feedback pins plastics rotation measurement velocity measurement radio communication communications technology;retroaccion;tangible media dementia gesture based interaction imitation modular robotics social exchanges;gesture based interaction;retroaction;social skill;vibration;interaction pattern;modular system;vibration measurement;feedback regulation;patient care medical robotics;radio communication technology;material plastico;robotica;dementia;radio communication;orientacion;communications technology;semitransparent plastic tube;tangible media;radiocommunication;robotique;communication technology;velocity measurement;dementia care;modular robot;patient participation;green function;tecnologia comunicacion;radiocomunicacion;matiere plastique;robot kinematics;modular robotics	This paper outlines the use of modular robotics to encourage and facilitate nonverbal communication during therapeutic intervention in dementia care. A set of new socially interactive modular robotic devices called rolling pins (RPs) has been designed and developed to assist the therapist in interacting with dementia-affected patients. The RPs are semitransparent plastic tubes that are capable of measuring their orientation and the speed of their rotation; at a local level, they have three types of feedback: red, green, and blue light, sound, and vibration. The peculiarity of the RPs is that they are able to communicate with each other or with other devices equipped with the same radio communication technology. The RPs are usually used in pairs, as the local feedback of an RP can be set depending not only on its own speed and orientation but also on the speed and the orientation of the peer RP. The system is not used as a therapeutic tool per se but as a facilitator and a mediator of social dynamics during normal therapy to counteract social isolation that can result in dementia through the loss of social skills. An experiment is reported that shows that by using the RPs, the patients participated in the activity by coordinating their behavior with the therapist and imitating the same interaction patterns generated by the therapist.	authorization;embedded system;feedback;ieee xplore;interaction design;modality (human–computer interaction);rp (complexity);robot;robotics;rolling hash;social dynamics;social reality;spontaneous order;dialog	Patrizia Marti;Leonardo Giusti;Henrik Hautop Lund	2009	IEEE Transactions on Robotics	10.1109/TRO.2009.2020346	information and communications technology;simulation;computer science;engineering;artificial intelligence;robotics	Robotics	-50.37087587928734	-47.000430196841506	134227
492b218717f6daa2721f0068d686f5a3428c5ce6	""""""" e-ti """", prototype d'assistance à la planification d'itinéraires multimodaux: spécifications ergonomiques pour une application web sur la base d'une démarche expérimentale"""	support tool;experimental design method;ergonomic specification;route planning	This paper presents an experimental study and a prototype support tool on the Web for planning multimodal routes. The ergonomic specifications underlying the support tool were formulated on the basis of data collected in the study, conducted with future users of the tool. People with different knowledge levels on the relevant transportation means and with different abilities in route planning, had to design routes using two different assistance systems. The first one only presents information, leaving design up to the user; the second system designs the route on the basis of constraints specified by the user. Results show that preference for a system is correlated with the user's knowledge level and competence in route planning. The prototype is being validated via its intended users.	experiment;human factors and ergonomics;knowledge level;linear algebra;multimodal interaction;prototype	Emmanuel Duplàa;Willemien Visser	2002		10.1145/777005.777015	simulation;systems engineering;engineering;transport engineering	HCI	-61.963548759213	-39.09809699791501	134302
ae9eed0f080d0d94969293b38d89ec62c773d65d	rhythmic walking interactions with auditory feedback: an exploratory study	agency;footsteps;sonic interaction design;rhythmic interaction;audio input	Walking is a natural rhythmic activity that has become of interest as a means of interacting with software systems such as computer games. Therefore, designing multimodal walking interactions calls for further examination. This exploratory study presents a system capable of different kinds of interactions based on varying the temporal characteristics of the output, using the sound of human walking as the input. The system either provides a direct synthesis of a walking sound based on the detected amplitude envelope of the user's footstep sounds, or provides a continuous synthetic walking sound as a stimulus for the walking human, either with a fixed tempo or a tempo adapting to the human gait. In a pilot experiment, the different interaction modes are studied with respect to their effect on the walking tempo and the experience of the subjects. The results tentatively outline different user profiles in interacting with such a system.	multimodal interaction;pc game;software system;synthetic intelligence;user profile	Antti Jylhä;Stefania Serafin;Cumhur Erkut	2012		10.1145/2371456.2371467	simulation;human–computer interaction;sonic interaction design;computer science;agency	HCI	-50.62539484719079	-47.11740303426582	134382
5184b422c09406cab08e996123e2a6e8be0e1efc	a multi-word password proposal (gridword) and exploring questions about science in security research and usable security evaluation	passwords;graphical password;remote access;internet access;mobile device;touch screen;virtual keyboard;text input;evaluation;scientific knowledge;usable security;knowledge base	Our agenda is two-fold. First, we introduce and give a technical description of gridWord, a novel knowledge-based authentication mechanism involving elements of both text and graphical passwords. It is intended to address a new research challenge arising from the evolution of Internet access devices, and which may arguably be viewed as motivating a new paradigm: remote access password schemes which accommodate users who alternately login from devices with, and without, full physical keyboards (e.g., users alternating between desktops with easy text input, and mobile devices with tiny or touch-screen virtual keyboards). While the core ideas behind gridWord are well-formed, and may be viewed as a new variation of old (text-based) ideas of building passwords from multiple words, many aspects including recommended parameterization and configuration details, preferred platforms, and primary targets of application remain to be explored in detail. We nonetheless solicit early feedback from the community for several reasons, related to our second agenda item: we use gridWord as a concrete target to focus exploration of a number of questions involving (a) the evaluation of usable security proposals, (b) the often conflicting objectives of various parties involved in the publication of academic research, and (c) the relationship between the design and publication of new security mechanisms and the pursuit of scientific knowledge through experimentation. We believe the second agenda item is important to pursue, given our observation that experts in usability and security have widely varying expectations, and lack consensus on what is important for the evaluation, comparison, and publication of usable security proposals.	emoticon;graphical user interface;human–computer interaction (security);internet access;knowledge-based authentication;login;mobile device;password;programming paradigm;text-based (computing);touchscreen;usability;virtual keyboard;well-formed element;well-formed formula	Kemal Bicakci;Paul C. van Oorschot	2011		10.1145/2073276.2073280	password policy;knowledge base;internet access;computer science;evaluation;mobile device;internet privacy;world wide web;password;computer security;sociology of scientific knowledge	Security	-49.451646899558064	-39.95658139067975	134438
90362e0742bf4f1b6faa1d3542b8cbea4bf16a1d	participatory design workshops with children with cancer: lessons learned	human computer interaction;systemvetenskap informationssystem och informatik;healthcare;information systems;manniska datorinteraktion interaktionsdesign;children;comics;participatory design	The design and development of information technology for use in health services presents a complex and sensitive situation. It includes not only managing differing interests and situations, but does so in a context that might give rise to negative emotions among the participating users. When the future users are children, this design process becomes even more complex. Participatory design is considered suitable for design with children. The premise for the participation of the children in this study was that they were, or had been treated for cancer. Therefore, their participation could awaken negative emotions, and make the situation difficult for them to handle. How participatory design with children can be conducted in such a sensitive context is therefore explored, grounded in the experience from six design workshops. The workshops evolved around the concept of comics as a way to allow the children to express themselves with familiar means. Three main lessons were learned from the workshops: working in pairs promotes an efficient work situation and the possibility to keep an eye on the children's wellbeing; proxies need to be distanced from the participating children; and the scenarios in the comics set the level of realism of the result.	negative feedback	Susanne Lindberg	2013		10.1145/2485760.2485840	simulation;engineering;knowledge management;multimedia	HCI	-61.0086128890662	-42.3681132434029	134893
c0a08f1606da5ce9d5382991ae28fd1e477a618a	field trial of a dual device user experience for itv	auxiliary information;field trial;interactive tv;second screen application;user experience;itv;semantic relations;user interaction;dual device user experience	With the rise in highly capable, mobile and networked secondary devices, the two-screen Enhanced TV is a more plausible proposition today than ever before. This paper presents a field trial of a prototype that aimed to understand a conceptual merger of TV and second screen user experiences. Our prototype concept can be described as a companion device experience that enhances TV viewing by providing auxiliary information and media on a second screen. The additional media is semantically related and synchronized, in terms of timeline, to the TV content. We ran a three-week field trial in 11 households. Participants used our prototype as a companion to their TV shows. We provided a total of 43 episodes from 10 popular TV shows throughout the study period. Overall feedback to our concept was quite positive. 10 out of our 11 participants said they enjoyed the experience. Our prototype allowed participants to better connect with their TV shows and have an enriched social life around TV. We also report some of the discovered user desires regarding user interaction design such as kinds of customization controls needed and the pacing of posts of additional information to the second screen.	feedback;interaction design;prototype;second screen;timeline;user experience	Santosh Basapur;Gunnar Harboe;Hiren M. Mandalia;Ashley Novak;Van Vuong;Crysta J. Metcalf	2011		10.1145/2000119.2000145	user experience design;simulation;human–computer interaction;telecommunications;computer science;multimedia;interactive television;world wide web	HCI	-54.07892519920669	-41.30621555834022	134907
12c9cdf7b4c52b9933da3e8e8f0c9a1da805bda2	exploratory search and hci: designing and evaluating interfaces to support exploratory search interaction	information exploration;human computer interaction;exploratory search;information retrieval;user interface evaluation;evaluation;user interfaces	"""The model of search as a turn-taking dialogue between the user and an intermediary has remained unchanged for decades. However, there is growing interest within the search community in evolving this model to support search-driven information exploration activities. So-called """"exploratory search"""" describes a class of search activities that move beyond fact retrieval toward fostering learning, investigation, and information use. Exploratory search interaction focuses on the user-system communication essential during exploratory search processes. Given this user-centered focus, the CHI conference is an ideal venue to discuss mechanisms to support exploratory search behaviors. Specifically, this workshop aims to gather researchers, academics, and practitioners working in human-computer interaction, information retrieval, and other related disciplines, for a discussion of the issues relating to the design and evaluation of interfaces to help users explore, learn, and use information. These are important issues with far-reaching implications for how many computer users accomplish their tasks."""	chi;exploratory search;exploratory testing;human–computer interaction;information retrieval;user (computing);user-centered design;venue (sound system)	Ryen W. White;Steven M. Drucker;Gary Marchionini;Marti A. Hearst;Monica M. C. Schraefel	2007		10.1145/1240866.1241100	cognitive models of information retrieval;human–computer interaction;computer science;evaluation;multimedia;search analytics;user interface;world wide web;human–computer information retrieval	HCI	-60.68433898178675	-42.038703280646445	135030
49dfc60622486c52887a327df4d2a5749f56ac7d	ourplace: the convergence of locative media and online participatory culture	geo technologies;mobile;online video editing;locative media;sense of place;online community;video editing;digital story telling;participatory media;interactive media;file sharing;interaction design	The trans-locative potential of the Internet has driven the design of many online applications. Online communities largely cluster around topics of interest, which take precedence over participants' geographical locations. The site of production is often disregarded when creative content appears online. However, for some, a sense of place is a defining aspect of creativity. Yet environments that focus on the display and sharing of regionally situated content have, so far, been largely overlooked.  Recent developments in geo-technologies have precipitated the emergence of a new field of interactive media. Entitled locative media, it emphasizes the geographical context of media. This paper argues that we might combine practices of locative media (experiential mapping and geo-spatial annotation) with aspects of online participatory culture (uploading, file-sharing and search categorization) to produce online applications that support geographically 'located' communities. It discusses the design considerations and possibilities of this convergence, making reference to an example, OurPlace 3G to 3D, which has to date been developed as a prototype. It goes on to discuss the benefits and potential uses of such convergent applications, including the co-production of spatial-temporal narratives of place.	categorization;emergence;file sharing;interactive media;internet;location-based game;participatory culture;prototype;situated;source-to-source compiler;upload	Jillian Hamilton	2009		10.1145/1738826.1738906	sense of place;human–computer interaction;computer science;mobile technology;interaction design;multimedia;interactive media;world wide web;file sharing	HCI	-58.23360964765818	-38.40175205230851	135242
7ca1447303e8f1d8863aabe66cc8c404ef8f0636	towards increased utility of and satisfaction with group recommender systems		Research on group recommender systems (GRS) has yielded innovative concepts for suggesting services or products to groups of users as well as for bringing users with similar tastes together. We have developed such concepts for group recommender systems and a platform in the domain of movie recommendations for groups. In this workshop we argue that putting a stronger focus on the evolution of the group negotiation process as well as social psychological concepts in the respective decision phase can increase the usability of GRS.	recommender system;usability	Christoph Beckmann;Tom Gross	2013			simulation;engineering;knowledge management;world wide web	Web+IR	-59.926997723612665	-44.37988828513029	135540
d032079adb8dede06b48af51abad16b15af62f9f	the social psychology of dialogue simulation as applied in elbot		Because of the high expectations users have on virtual assistants to interact with said systems on a human level, the rules of social interaction potentially apply and less the influence of emotion cues associated with the system responses. To this end the social psychological theories of control, reactance, schemata, and social comparison suggest strategies to transform the dialogue with a virtual assistant into an encounter with a consistent and cohesive personality, in effect using the mind-set of the user to the advantage of the conversation, provoking the user into reacting predictably while at the same time preserving the user's illusion of control. These methods are presented in an online system: Elbot.com.	simulation	Fred Roberts	2014	IJSE	10.4018/ijse.2014070103	psychology;computer science;artificial intelligence;multimedia;communication;social psychology	NLP	-52.708932208433104	-49.4853192487841	135610
629bf1f076f8d5bc203c573d4ba1dad5bb6743cf	a meta-analysis of factors influencing the development of trust in automation: implications for understanding autonomy in future systems	trust;human robot interaction;meta analysis;human automation interaction	OBJECTIVE We used meta-analysis to assess research concerning human trust in automation to understand the foundation upon which future autonomous systems can be built.   BACKGROUND Trust is increasingly important in the growing need for synergistic human-machine teaming. Thus, we expand on our previous meta-analytic foundation in the field of human-robot interaction to include all of automation interaction.   METHOD We used meta-analysis to assess trust in automation. Thirty studies provided 164 pairwise effect sizes, and 16 studies provided 63 correlational effect sizes.   RESULTS The overall effect size of all factors on trust development was ḡ = +0.48, and the correlational effect was [Formula: see text]  = +0.34, each of which represented medium effects. Moderator effects were observed for the human-related (ḡ  = +0.49; [Formula: see text] = +0.16) and automation-related (ḡ = +0.53; [Formula: see text] = +0.41) factors. Moderator effects specific to environmental factors proved insufficient in number to calculate at this time.   CONCLUSION Findings provide a quantitative representation of factors influencing the development of trust in automation as well as identify additional areas of needed empirical research.   APPLICATION This work has important implications to the enhancement of current and future human-automation interaction, especially in high-risk or extreme performance environments.	automation;autonomous system (internet);google moderator;human–robot interaction;objective-c;synergy	Kristin E. Schaefer;Jessie Y. C. Chen;James Leo Szalma;Peter A. Hancock	2016	Human factors	10.1177/0018720816634228	human–robot interaction;meta-analysis;simulation;human–computer interaction;computer science;engineering;knowledge management;trustworthy computing;social psychology	HCI	-59.07940103223776	-49.36281548236096	135631
3fae3ceca3db5ded46483e97bc0248bfd7abf263	the influence of cognitive ability on the susceptibility to persuasive strategies		The realization that individuals may differ in their susceptibility to various persuasive strategies has motivated a shift of Persuasive Technology (PT) design from the traditional one-size-fits-all approach to a personalized approach that adapts to individuals’ preferences. In Persuasive Educational Technologies (PETs) design, learners’ cognitive level is an important dimension for personalization given that it can affect learners’ response to and processing of various instructional contents. However, the relationship between students’ cognitive level and their level of susceptibility to persuasive strategies has not been explored quantitatively in the extant literature. As a result, we conducted an empirical study among 117 participants to investigate whether learners’ cognitive ability is an important trait to be considered in learner’s PETs design. Specifically, we assessed participants’ levels of Intelligent Quotient (IQ) and their responsiveness to three commonly used persuasive strategies in PT design: Social Comparison, Reward and Trustworthiness. Our results show that: (1) people with high cognitive level are more susceptible to Social Learning than people with low cognitive level; (2) people with low cognitive level are more susceptible to Trustworthiness than people with high cognitive level. Our results also show that there is no significant difference between people with high cognitive level and those with low cognitive level in their susceptibility to Reward strategy. Our findings provide insight into possible effective persuasive strategies which designers can employ to personalize PTs to individual users based on their cognitive level.	cognition;fits;personalization;persuasive technology;pro tools;responsiveness;trust (emotion)	Aisha Muhammad Abdullahi;Kiemute Oyibo;Rita Orji	2018			cognitive psychology;cognition;psychology	HCI	-59.75781903562115	-46.162304936021954	135855
5dba6b209c0f35ef2c62b248936f0a46f64fab3a	videobasierte handlungserkennung für die natürliche mensch-maschine-interaktion		The question addressed in this thesis is how to make use of gestures in a multimodal human-machine-interaction. To interact with current computer systems the human still has to adopt himself to the interfaces of the system. The underlying vision of this work is to enable computer system to interpret the typical human forms of interaction. Based on this question and vision the goal of this work was developed: Build a robust recognition of human gestures for a multimodal system. Thus the interactive competences of the system can be broadend and improved. Focussing this goal this work examines the theoretic basis of the human-machine-interaction as well as the practical implementation and evaluation of an automatic recognition of gestures. The gideline for the implementation is a flexible and modular architecture. This work presents novel approaches in taking the symbolic and situational context of gesture into account (see Fritsch u. a. [2004] and Hofemann u. a. [2004]). Continuative work in deriving humans intent of gestures is depicted (see Li u. a. [2005b]). This work concentrates on the interactional behaviour and gestures of humans thus mostly deictic and manipulative gestures are considered. Their context is the main aspect of these gesture, it allows reasoning about their meaning and intention. As mentioned above the gesture recognition system is intended to be part of a multimodal system. This integration is shown by the successful use of the developed system within a mobile, social, and multimodal robot (see Haasch u. a. [2005] and Wrede u. a. [2004a]) and within an wearable assistant system (see Hanheide u. a. [2006]). Human-human-communication and the field of gestures are in the focus of research for many years. Hence this work gives an overview on communication theory and psychological research relevant for the human-machine interaction. A young and challenging aspect is the research on the topic: ”How do children learn the manipulation of objects from their parents.“ The theory developed by Brand u. a. [2002] is the basis for an automatic analysis of parents behaviour presented in this work (see Fritsch u. a. [2005a]). This work is a contribution to the vision of a natural human-machine-interaction. The emphasis lies on the videobased recognition of human actions and gestures. Part of this work is published in English. Please see appendix ‘E’ on page 140 for references.	gesture recognition;human–computer interaction;maschine;multimodal interaction;theory;wearable computer	Nils Hofemann	2006			psychology;simulation;artificial intelligence;gesture recognition;communication	HCI	-52.48494793899681	-46.15530771180047	136018
4a1aba32dd0cb1f1eebd0a1e917b2753d7da8526	the routines and needs of grandparents and parents for grandparent-grandchild conversations over distance	grandparent and grandchild communication;design;family communication	A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet there are few studies of the actual conversational routines of these groups as well as the social challenges that might arise as a result of technology usage. To address this gap, we conducted an interview and diary study that explores the conversational practices of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe the focus of grandparent-grandchild conversations and show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildren's lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.	diary studies;self-consciousness	Azadeh Forghani;Carman Neustaedter	2014		10.1145/2556288.2557255	design	HCI	-58.60717988978646	-41.30724321711083	136106
e0d0f98829e7dd812f5d157010f06b3854b2c932	understanding the everyday use of head-worn computers	computers;google;wearable computers helmet mounted displays human computer interaction;performance evaluation;user centric;smart phones;glass;interaction techniques head worn computers smart glasses everyday use social acceptability;user experience;interviews computers context glass performance evaluation google smart phones;interviews;smart glasses;context;interaction paradigm head worn computers hwc everyday usage use context social acceptance interaction techniques microinteractions	Early research on head-worn computers (HWCs) has focused on hardware and specific applications. However, there is little research about the everyday usage of head-worn computers in particular aspects such as: context of use, social acceptance across different activities, audiences and interaction techniques. This paper provides insights into the use of head-worn computers by capturing the opinions of novice and expert users through a survey, a three-week diary study, and interviews. The overarching finding is that the context of use is critical, either due to the need to support micro-interactions, or because the interaction paradigm itself should depend on the context of use.		Anita Vogl;Nicolas Louveton;Rod McCall;Mark Billinghurst;Michael J Haller	2015	2015 8th International Conference on Human System Interaction (HSI)	10.1109/HSI.2015.7170668	simulation;human–computer interaction;engineering;multimedia	HCI	-56.083115097666145	-41.657673675300636	136152
4d3e5ee9c9d51e50407277c00aac2415fb069be9	practical findings from applying the psd model for evaluating software design specifications	model specification;design principle;specifications;research design;attitude change;guide;social support;system design;practice;analysis;elaboration likelihood model;model fitting;software design;mobile internet;persuasive systems design model	This paper presents practical findings from applying the PSD model to evaluating the support for persuasive features in software design specifications for a mobile Internet device. On the one hand, our experiences suggest that the PSD model fits relatively well for evaluating design specifications. On the other hand, the model would benefit from more specific heuristics for evaluating each technique to avoid unnecessary subjectivity. Better distinction between the design principles in the social support category would also make the model easier to use. Practitioners who have no theoretical background can apply the PSD model to increase the persuasiveness of the systems they design. The greatest benefit of the PSD model for researchers designing new systems may be achieved when it is applied together with a sound theory, such as the Elaboration Likelihood Model. Using the ELM together with the PSD model, one may increase the chances for attitude change.	adobe photoshop;software design	Teppo Räisänen;Tuomas Lehto;Harri Oinas-Kukkonen	2010		10.1007/978-3-642-13226-1_19	psychology;simulation;human–computer interaction;computer science;artificial intelligence;software design;analysis;management science;social psychology;attitude change;specification;systems design	SE	-62.13415509859594	-44.45917140742108	136307
6f995c5d1538a16433f81c84629f08c10710abdf	ambient timer - unobtrusively reminding users of upcoming tasks with ambient light		"""Daily office work is often a mix of concentrated desktop work and scheduled meetings and appointments. However, constantly checking the clock and alarming popups interrupt the flow of creative work as they require the user's focused attention. We present Ambient Timer, an ambient light display designed to unobtrusively remind users of upcoming events. The light display mounted around the monitor is designed to slowly catch the user's attention and raise awareness for an upcoming event while not distracting her from the primary creative task such as writing a paper. Our experiment compared established reminder techniques such as checking the clock or using popups against Ambient Timer in two different designs. One of these designs produced a reminder in which the participants felt well informed on the progress of time and experienced a better """"flow"""" of work than with traditional reminders."""	555 timer ic;desktop computer;interrupt	Heiko Müller;Anastasia Kazakova;Martin Pielot;Wilko Heuten;Susanne Boll	2013		10.1007/978-3-642-40483-2_15	embedded system;real-time computing;computer hardware	HCI	-52.32129743784319	-43.61231748149221	136343
903a8db7bac7a2826cd98ae5425d839852274f7d	like at first sight: understanding user engagement with the world of microvideos		Several content-driven platforms have adopted the ‘micro video’ format, a new form of short video that is constrained in duration, typically at most 5–10 s long. Micro videos are typically viewed through mobile apps, and are presented to viewers as a long list of videos that can be scrolled through. How should micro video creators capture viewers’ attention in the short attention span? Does quality of content matter? Or do social effects predominate, giving content from users with large numbers of followers a greater chance of becoming popular? To the extent that quality matters, what aspect of the video – aesthetics or affect – is critical to ensuring user engagement? We examine these questions using a snapshot of nearly all (>120, 000) videos uploaded to globally accessible channels on the micro video platform Vine over an 8 week period. We find that although social factors do affect engagement, content quality becomes equally important at the top end of the engagement scale. Furthermore, using the temporal aspects of video, we verify that decisions are made quickly, and that first impressions matter more, with the first seconds of the video typically being of higher quality and having a large effect on overall user engagement. We verify these data-driven insights with a user study from 115 respondents, confirming that users tend to engage with micro videos based on “first sight”, and that users see this format as a more immediate and less professional medium than traditional user-generated video (e.g., YouTube) or user-generated images (e.g., Flickr).	bbc micro;flickr;mobile app;snapshot (computer storage);usability testing;user-generated content;video clip	Sagar Joglekar;Nishanth R. Sastry;Miriam Redi	2017		10.1007/978-3-319-67217-5_15	sight;computer science;internet privacy;attention span	HCI	-55.214789550691464	-41.68922278946374	136417
5174ea6010d75dd97b79bdccbd91749b3e27436f	"""playing """"air instruments"""": mimicry of sound-producing gestures by novices and experts"""	interfase usuario;user interface;gesture;musica;journal article;man machine system;musique;sistema hombre maquina;interface utilisateur;music;geste;gesto;systeme homme machine	Both musicians and non-musicians can often be seen making sound-producing gestures in the air without touching any real instruments. Such ”air playing” can be regarded as an expression of how people perceive and imagine music, and studying the relationships between these gestures and sound might contribute to our knowledge of how gestures help structure our experience of music.	approximation algorithm;graph of a function;multimodal interaction;shallow parsing;vagueness	Rolf Inge Godøy;Egil Haga;Alexander Refsum Jensenius	2005		10.1007/11678816_29	speech recognition;computer science;artificial intelligence;music;multimedia;user interface;gesture	HCI	-50.88224439216098	-46.92174721276078	136462
7a4bfa3344fac7d921a807df464b1efb1b25f739	letspic: supporting in-situ collaborative photography over a large physical space		Recent advances in mobile computing technology have made it increasingly common for collocated users to perform collaborative photography over a large physical space in various group activity scenarios such as field trips, site surveys, and group tours. Unlike traditional collocated interactions in a shared physical space, we find that mobility and group dynamics make awareness of group activities over a large physical space very challenging. In this work, we design LetsPic, a group photoware that supports group awareness for in-situ collaborative photography over the large physical space. We have iteratively built the app and performed user studies in site survey and group tour scenarios (n = 31, n = 24). Our results confirmed that LetsPic effectively promotes group awareness, facilitates group coordination, and encourages collaboration in both scenarios. We discuss practical design implications based on our findings.	interaction;mobile computing;usability testing	Auk Kim;Sungjoon Kang;Uichin Lee	2017		10.1145/3025453.3025693	computer graphics (images)	HCI	-59.56423670872457	-40.910115654512474	136718
72f01ccbf5d7fe6881d79034db9054236dc5ef08	wise:: a wizard interface supporting enhanced usability	cognitive deficit;user interface;close coupling;user centered design;older adult;interactive method;application program interface;linear interaction;operating system;accessibility;cognitive strategies;effective cognitive strategy prompting;rest of the world;age related challenges;interaction effect;gerontology;interaction design;scripting language	"""The current state of software which targets older adults' ability to use computers focuses on physical issues while largely ignoring the cognitive issues. As a larger percentage of Americans are considered """"old"""" (60+), the lack of a system tailored to the needs of this age demographic has resulted in a part of the population that is disconnected from the rest of the world. This paper describes WISE, an alternative OS and application UI that specifically targets the cognitive deficits of older adults."""	computer;operating system;usability;user interface;wizard (software)	Joshua M. Hailpern	2006		10.1145/1168987.1169061	user-centered design;interaction;simulation;human–computer interaction;application programming interface;computer science;accessibility;operating system;interaction design;scripting language;multimedia;user interface;world wide web	HCI	-57.403482464748855	-44.762040926956395	136862
6fc9d0d50b89a70d3579680d407eb17b56e3fbde	context-aware gesture recognition in classical music conducting	gesture;music information retrieval;conducting;classical music	Body movement has received increasing attention in music technology research during the last years. Some new musical interfaces make use of gestures to control music in a meaningful and intuitive way. A typical approach is to use the orchestra conducting paradigm, in which the computer that generates the music would be a \textit{virtual orchestra} conducted by the user. However, although conductors' gestures are complex and their meaning can vary depending on the musical context, this context-dependency is still to explore. We propose a method to study context-dependency of body and facial gestures of conductors in orchestral classical music based on temporal clustering of gestures into actions, followed by an analysis of the evolution of audio features after action occurrences. For this, multi-modal data (audio, video, motion capture) will be recorded in real live concerts and rehearsals situations using unobtrusive techniques.	cluster analysis;computer;gesture recognition;modal logic;motion capture;music technology;programming paradigm	Álvaro Sarasúa	2013		10.1145/2502081.2502216	speech recognition;conductor;multimedia;classical music;gesture;musicality	HCI	-51.71453213847436	-46.99106678102369	136947
8bb054c4e8b83947ac428698b0eadf85615e004b	an exploration on brain computer interface and its recent trends	electroencephalography;brain computer interface	Detailed exploration on Brain Computer Interface (BCI) and its recent trends has been done in this paper. Work is being done to identify objects, images, videos and their color compositions. Efforts are on the way in understanding speech, words, emotions, feelings and moods. When humans watch the surrounding environment, visual data is processed by the brain, and it is possible to reconstruct the same on the screen with some appreciable accuracy by analyzing the physiological data. This data is acquired by using one of the non-invasive techniques like electroencephalography (EEG) in BCI. The acquired signal is to be translated to produce the image on to the screen. This paper also lays suitable directions for future work. KeywordsBCI; EEG; brain image reconstruction.	brain–computer interface;electroencephalography;iterative reconstruction;operating system;privacy;signal processing	T. Kameswara Rao;M. Rajya Lakshmi;T. V. Prasad	2012	CoRR		brain–computer interface;computer vision;electroencephalography;computer science;artificial intelligence	Vision	-52.5234102284115	-45.07052614245534	137153
b7e25c310f5ec79593ca327e35b322d426f88723	baby faces: user-interface design for small displays	personal digital assistant;user interface;mobile phone;personal digital assistants;information appliance;graphic user interface;handheld device;user interface design;mobile phones;information appliances;high spatial resolution;spatial resolution	User in&face conferences and literature usually dwell upon projects in which large color palettes, high spatial resolution, and large-size displays are presumed to be available. Many consumer information appliances and handheld devices are often more limited in their characteristics, yet m increasingly important to bring the power of the Web, productivity tools, databases, transactions, and entertainment to more and more people on the go, or at least not in front of higher-performance PCs, NCs, or workstations. Professionals with insight into the challenges and achievements of designing graphical user interfaces for small displays will debate the best way to design fa products in which many characteristics are significantly limited, e.g., fonts, color resolution, spatial resolution, and graphics. These user interfaces, which might be called “baby faces” seem simpler in some ways, but also are actually quite complex as a design challenge when one designs to account for their limited characteristics.	database;face (geometry);glossary of computer graphics;graphical user interface;information appliance;mobile device;palette (computing);usb on-the-go;user interface design;workstation;world wide web	Aaron Marcus;Joseph V. Ferrante;Timo Kinnunen;Kari Kuutti;Erik Sparre	1998		10.1145/286498.286547	user interface design;embedded system;10-foot user interface;image resolution;human–computer interaction;computer science;operating system;mobile device;graphical user interface;multimedia;natural user interface;information appliance;user interface	HCI	-48.98986435829049	-38.85813282229499	137156
42169b92a9f6dd77f28fa11b30d5041667923374	predicting human decision-making: from prediction to action		Automated agents that interact proficiently with people can be useful in supporting, training or replacing people in complex tasks. The inclusion of people presents novel problems for the design of automated agents' strategies. People do not necessarily adhere to the optimal, monolithic strategies that can be derived analytically. Their behavior is affected by a multitude of social and psychological factors. In this talk I will show how combining machine learning techniques for human modeling, human behavioral models, formal decision-making and game theory approaches enables agents to interact well with people. Applications include intelligent agents that help drivers reduce energy consumption, agents that support rehabilitation, employer-employee negotiation and agents that support a human operator in managing a team of low-cost mobile robots in search and rescue tasks.		Sarit Kraus	2018		10.1145/3284432.3287194	game theory;autonomous agent;intelligent agent;social psychology;computer science;search and rescue;decision theory;energy consumption;human–computer interaction;negotiation;mobile robot	HCI	-51.17939678752118	-49.840079839872494	137168
ecc2e7752ca4ab5da2bd9078055cf0f02b355f14	eye tracking and its application in usability and media research	media research;eye tracking;usability;research article	Over the last ten years the Internet has become an incredibly important media in everyday life of ordinary people. By now the World Wide Web is not a foreign concept anymore; millions of people make use of the internet in terms of e-mail, online banking, online shops, etc. Companies have realised the necessity of user friendly interfaces and software which even an inexperienced user is able to handle. Since the interaction with the Internet becomes ubiquitous, assessing usability of interfaces is a fundamental and necessary part of HCI development. Observing the overt behaviour of users, (which button does a user click on, how is the mouse used), retrospective self report, questionnaires and thinking aloud methods are just examples of traditional and quite successful strategies in order to investigate usability problems. So, why should there be a need for a new method when conventional methods seem sufficient in optimising usability and what is it’s contribution in the evaluation of how usable a particular design is? We will give a short introduction of the eye tracking method in applied marketing research and its benefits. Reporting two of our studies we will discuss the limits of traditional usability testing and will show how tracking the eye gaze can fill this gap.	email;experience;eye tracking;human–computer interaction;internet;newbie;online banking;online shopping;usability testing;world wide web	Michael Schiessl;Sabrina Duda;Andreas Thölke;Rico Fischer	2003	MMI Interaktiv		computer vision;human–computer interaction;computer science;multimedia	HCI	-51.41085179079826	-40.31798014371622	137190
28395c43267d45a64df11c9f2644591171fe2814	i'll knock you when i'm ready...: reflecting on media richness beyond bandwidth and imitation	cues;mediated communication;media richness;meaning and language;emotion;computer mediated communication;device;channels;communication	Following the research field of Computer Mediated Communication (CMC), we explore and expand upon the notion of media richness. We consider the term outside its ordinary domain of conventional communication mediums, such as email, phone or video calls. We focus on minimal communication, and the qualities of suggestive interactions that mediate communication. We introduce Knock-Knock as a novel, shape-changing communication medium, and use it as a rhetorical tool to reflect upon the notion of media richness. In doing so, we highlight the value of meaning and language creation that suggestive communication mediums make possible. Finally, we propose three directions for the future evaluation of the richness experienced in communication, mediated by suggestive communication artefacts.	bandwidth (signal processing);computer-mediated communication;email;interaction	Majken Kirkegaard Rasmussen;Natalie Lehoux;Ioana Ocnarescu;Peter Gall Krogh	2012		10.1145/2317956.2317974	communication noise;emotion;multimedia;computer-mediated communication	PL	-58.1901625809001	-38.92212027195537	137210
a2e170eeb8372fa748735e0e242735a7da80cfce	frustrating the user on purpose: a step toward building an affective computer	human computer interaction;emotion physiology;user interface;hidden markov model;affect;social science;biosensing;pattern recognition;affective computing	Using social science methods to induce a state of frustration in users we collected physiologi cal video and behavioral data and developed a strategy for coupling these data with real world events The e ectiveness of the proposed strat egy was tested in a study with thirty six sub jects where the system was shown to reliably synchronize and gather data for a ect analysis Hidden Markov Models were applied to each sub ject s physiological signals of skin conductivity and blood volume pressure in an e ort to see if regimes of likely frustration could be automat ically discriminated from regimes when all was proceeding smoothly This pattern recognition approach correctly classi ed these two regimes of the time Mouse clicking behavior was also synchronized to frustration eliciting events and analyzed revealing NN distinct patterns of clicking responses	hidden markov model;markov chain;open road tolling;pattern recognition;smoothing	Jocelyn Scheirer;Raul Fernandez;Jonathan Klein;Rosalind W. Picard	2001	Interacting with Computers	10.1016/S0953-5438(01)00059-5	simulation;human–computer interaction;computer science;artificial intelligence;affective computing;user interface;world wide web;hidden markov model;biosensor;affect	ML	-53.879583243625355	-45.95271887719375	137402
97feff7923a62d7cd63602fd5aa2bfe2ec6f95f3	"""home2home: a """"lightweight"""" gift-giving portal between homes"""	user centered design;learning technology;through handwriting;family;technical gift giving;dispersed;across countries;community capacity;communication;emotive;ambient display	"""As families become more dispersed within countries and around the world, the ability to maintain frequent and personalized communication becomes more challenging. Home2Home is a lightweight, smartboard device with ambient display that supports family communication practices with particular attention to the novice technology user. By leveraging the ease of a whiteboard and instant sharing, the familiarity of notepads and """"care packages,"""" and the emotive qualities of handwriting and voice, Home2Home is an easy-to-learn technology that affords the major communication capacities of other software and devices, together in one place. In this paper, we describe the system and the user-centered design process employed to create it."""	interaction technique;personalization;prototype;smart board;user-centered design	Alexandra Boughton;Arjun Gopalakrishna;Bhavya Udayashankar;Alexandra Morgan	2012		10.1145/2212776.2212434	educational technology;user-centered design;simulation;human–computer interaction;computer science;multimedia;world wide web	HCI	-55.55733704937185	-41.46567842858432	137469
bb031d65211c8e5ecc52b283e786373601c74d7c	does aesthetics of web page interface matters to mandarin learning	human computer interaction;web pages;computers and society	Aesthetics of web page refers to how attractive a web page is in which it catches the attention of the user to read through the information. In addition, the visual appearance is important in getting attentions of the users. Moreover, it was found that those screens, which were perceived as aesthetically pleasing, were having a better usability. Usability might be a strong basic in relating to the applicability for learning, and in this study pertaining to Mandarin learning. It was also found that aesthetically pleasing layouts of web page would motivate students in Mandarin learning The Mandarin Learning web pages were manipulated according to the desired aesthetic measurements. GUI aesthetic measuring method was used for this purpose. The Aesthetics-Measurement Application (AMA) accomplished with six aesthetic measures was developed and used. On top of it, questionnaires were distributed to the users to gather information on the students’ perceptions on the aesthetic aspects and learning aspects. Respondents for this study were students taking Mandarin course level I at UiTM Terengganu. A significant correlation of the aesthetic aspect was found with its relevance to Mandarin learning. In summary, aesthetics should not be ignored or overlooked in designing effective learning interfaces for educational purposes.	graphical user interface;relevance;super robot monkey team hyperforce go!;usability;web page	Jasni Mohamad Zain;Mengkar Tey;Yingsoon Goh	2011	CoRR		human–computer interaction;computer science;web page;multimedia;world wide web	HCI	-60.144504967964224	-47.69191756857927	137476
589beea7341fc374c092e92cee19097933ac57c2	social empowerment of intellectually impaired through a cloud mobile system	serious games;intellectual impairments;technology enhanced learning;mobility;empowerment;intellectual disabilities;cloud computing	There is not a unique definition of “empowerment”, nevertheless the idea that it involves, on the one hand, people having control over their own lives and, on the other, some social aspects seems to be a common characteristic. Most authors recognize three levels of empowerment: individual, group, and community level, which are interconnected and changes at one level influence the others. Enhancing individual competence and self-esteem has a direct effect on the control of one’s own life and, in turn, on the social components of empowerment. In this paper we present Smart Angel, a project that aims at creating a network involving families, caregivers, experts, and tutors, as well as the final users and their friends, based on a mobile cloud system in support of both everyday living and urban mobility for people with medium-mild intellectual disabilities, with particular attention to the Down syndrome. The system can be seen as a tool to empower its users to be more independent and therefore increasing their possibility to have an active role in their life and an active participation to the community.	assistive technology;autonomy;immersion (virtual reality);intellect;interaction;mobile cloud computing;mobile operating system;virtual reality	Laura Freina;Rosa Maria Bottino;Michela Ott;Filippo Costa	2015	Future Internet	10.3390/fi7040429	empowerment;simulation;cloud computing;computer science;knowledge management;operating system;mobile computing	HCI	-62.294665697109075	-41.81431365717871	137526
5e3a88db17cc268cbd22d9aa550e51afc3d4df50	modelling perception using image processing algorithms	comparative analysis;human computer interaction;image processing;visually impaired users;perception model;people with disabilities;visual search;eye movement;visual impairment;image processing techniques;able bodied;user model;human visual perception	User modeling is widely used in HCI but there are very few systematic HCI modelling tools for people with disabilities. We are developing user models to help with the design and evaluation of interfaces for people with a wide range of abilities. We present a perception model that can work for some kinds of visually-impaired users as well as for able-bodied people. The model takes a list of mouse events, a sequence of bitmap images of an interface and locations of different objects in the interface as input, and produces a sequence of eyemovements as output. Our model can predict the visual search time for two different visual search tasks with significant accuracy for both able-bodied and visuallyimpaired people.	alan f. blackwell;algorithm;bitmap;blackwell (series);color vision;experiment;human–computer interaction;image processing;simulation;software engineer;user interface;user modeling	Pradipta Biswas;Peter Robinson	2009		10.1145/1671011.1671075	computer vision;computer science;multimedia;human visual system model;communication	HCI	-48.5756155826389	-45.79645264313542	137577
c2dad380e6c9fb11d73fd611666461ce34be5cbd	human-robot interaction-based intention sharing of assistant robot for elderly people		Intention reading is considered as an important issue in the field of human-robot interaction (HRI). Specifically, for cooperation between a human and a robotic system, a robot should be aware of a given situation and human intention, which necessarily requires high-level knowledge and balanced interaction. For the disabled and elderly, who may not be familiar with manipulating robotic systems, intention sharing between two different agents is preferable for accurate intention reading. In this paper, we focus on the effect of intention sharing of a human user and a robot assistant to improve cooperation.	human–robot interaction;robot	Jeong-Yean Yang;Oh-Hun Kwon;Chan-Soon Lim;Dong-Soo Kwon	2013		10.1007/978-3-642-35485-4_35	simulation;human–computer interaction;multimedia	Robotics	-50.883023635810694	-50.19831720537244	137599
5dff6ba7c25b7e5fddc5a39998f88ed41aac8d52	airtransnote: augmented classrooms with digital pen devices and rfid tags	radio networks;mobile computing light pens radiofrequency identification computer aided instruction user interfaces interactive systems telecontrol equipment educational aids mobile handsets radio networks;computer aided instruction;telecontrol equipment;rfid tag;wireless communication;light pens;educational aids;mobile handsets;interactive lectures airtransnote augmented classrooms digital pen devices rfid tag reader student notes wireless communications note taking portable remote controller selection interface;mobile computing;interactive systems;user interfaces;radiofrequency identification;rfid tags personal communication networks personal digital assistants communication system control collaboration optical recording optical transmitters radiofrequency identification displays management training	"""AirTransNote augments activities in classrooms by sharing student notes written on regular paper using wireless communications. AirTransNote uses digital pens to free students from the need to use PCs for note taking. To improve the effectiveness of the system, we used a portable remote controller with an RFID tag reader. Teachers can select notes for students by using the controller as """"magic wand."""" The selection interface is intuitive for both teachers and students. Also, the system can save time for setting up devices before lectures. The system promotes an augmented classroom, enabling interactive lectures in regular classrooms using natural styles."""	digital pen;radio-frequency identification;remote control;usability	Motoki Miura;Susumu Kunifuji;Buntarou Shizuki;Jiro Tanaka	2005	IEEE International Workshop on Wireless and Mobile Technologies in Education (WMTE'05)	10.1109/WMTE.2005.9	embedded system;human–computer interaction;computer science;multimedia	HCI	-49.214290862675675	-42.83555689472119	137657
0266ea7a500a0d27232caa9cb9b8c807684572b4	the evaluation of interface aesthetics	objective methods;aesthetics evaluation;working paper;subjective methods	There are many factors that contribute towards good user experience (Roto, Law, Vermeeren and Hoonhout, 2011). These factors include the content and its organization, the functionality and features, the information and interaction design, as well as the visual design (Garett, 2002; Morville's, 2004; and Hassenzahl, 2005).  This paper builds on the contribution of visual design into user experience as grounds to tackle the assessment of visual aesthetics evaluation methods. The intention of the study is to test objective and subjective evaluation methods with the same objects for comparison. Finding out the correlations between the objective and subjective evaluation results enables the usage of computerized image analysis for the purposes of evaluating aesthetics. The work reported in this paper thus contributes towards identifying a suitable objective method for a mathematical description of beauty.	image analysis;interaction design;usability;user experience	Mati Mõttus;David R. Lamas;Maarja Pajusalu;Rui Torres	2013		10.1145/2500342.2500345	engineering;multimedia;social psychology	HCI	-59.580544103357035	-47.06188931680447	137736
cedd0bf6b3724a70fe4c1468e509aaa41d757973	"""mobile data services usage: an in depth investigation of the influence of the """"personal layer"""" of place"""	place	The new mobile networked environments ask for more investigation in order to explain users’ behaviour and users’ low demand for mobile data services. A field study, conducted in the territory of Greece, researched the use of a specific mobile data services platform, called here as Service A trying to identify how users experience place before deciding to use mobile data services. The findings of the research tend to suggest that participants did experience the different places in a similar way before deciding to use mobile data services. The study adopted the humanistic geographical perspective as represented by the four “layers of place” introduced by Yi-Fu Tuan’s theory. The findings presented in this specific paper highlight the strongest patterns coming from the analysis of the “Personal layer” of place as represented by Tuan that are important influential elements in the decision of the users to start using mobile data services . The contribution of this paper is that it argues that the users’ decision to start using mobile data services is influenced and triggered by their interaction with their surrounding environment and thus there is need to consider the role of this environment in the study of adoption and use of mobile data services.	execution unit;field research	Homer Papadopoulos;Gamila Shoib	2009				HCI	-57.002694269158724	-40.680659958725066	138189
19db2731688ad1379bd29c12b12ffe96f3cd3793	interaction techniques for ambiguity resolution in recognition-based interfaces	panoramic;cartographic projection;user interface;error correction techniques;natural interaction;recognition;error correction;imaging;ambiguity resolution;cartography;photofinish and strip photography;technical report;scanning;peripheral;interaction technique	Because of its promise of natural interaction, recognition is coming into its own as a mainstream technology for use with computers. Both commercial and research applications are beginning to use it extensively. However the errors made by recognizers can be quite costly, and this is increasingly becoming a focus for researchers. We present a survey of existing error correction techniques in the user interface. These mediation techniques most commonly fall into one of two strategies, repetition and choice. Based on the needs uncovered by this survey, we have developed OOPS, a toolkit that supports resolution of input ambiguity through mediation. This paper describes four new interaction techniques built using OOPS, and the toolkit mechanisms required to build them. These interaction techniques each address problems not directly handled by standard approaches to mediation, and can all be re-used in a variety of settings.	computer;error detection and correction;finite-state machine;interaction technique;linux kernel oops;user interface	Jennifer Mankoff;Scott E. Hudson;Gregory D. Abowd	2000		10.1145/1185657.1185767	medical imaging;computer vision;simulation;error detection and correction;computer science;artificial intelligence;technical report;operating system;user interface;interaction technique;peripheral;computer graphics (images)	HCI	-48.464622253465066	-42.00422501055283	138240
9b9e325dba63c71b8bb7b1e04bd3a0877744aed7	control mechanisms of perceived phase error on synchronized tapping toward communication support systems based on psychological timing control	control systems;communication system;information technology;error correction mechanism;time varying systems;human like communication system synchronized tapping communication support system psychological timing control psychological interaction mechanism synchronization tapping task phase error correction perceived timing physical timing attentional resource;support system;error correction;timing control systems time varying systems;physical interaction;communication system control control systems error correction psychology timing intersymbol interference information technology computational intelligence human robot interaction computer errors;timing	In recent years, information technology rapidly increases the opportunity of human communication. However, communication supporting systems, such as tele-presence and CSCW, were mainly developed based on physical interaction and not on psychological one. In this article, we analyzed the psychological interaction mechanism of human timing control using synchronization tapping task. Particularly, we focused on the phase error correction, and the following 2 facts were found: 1) perceived timing is not coincident with physical timing; and 2) the perceived timing is controlled by two types of phase error correction mechanisms. One requires attentional resources and the other does not. These results suggest that timing control for human communication support system should be based on his/her perceived timing, and such psychological timing control mechanism is useful for realizing the human-like communication systems	computer-supported cooperative work;error detection and correction;human–computer interaction;television	Kouji Takano;Yoshihiro Miyake	2006	ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2006.314471	real-time computing;simulation;error detection and correction;computer science;information technology;communications system	Embedded	-49.98726802905058	-49.78924044342002	138534
0eb53cb8fb49f61341a6adb0485a0d4ac7416647	‘what i see is not what you get’: why culture-specific behaviours for virtual characters should be user-tested across cultures		Integrating culture into the behavioural models of virtual characters requires knowledge from very different disciplines such as cross-cultural psychology and computer science. If culture-related behavioural differences are simulated with a virtual character system, users might not necessarily understand the intent of the designer. This is, in part, due to the influence of culture on not only users, but also designers. To gain a greater understanding of the instantiation of culture in the behaviour of virtual characters, and on this potential mismatch between designer and user, we have conducted two experiments. In these experiments, we tried to simulate one dimension of culture (Masculinity vs. Femininity) in the behaviour of virtual characters. We created four scenarios in the first experiment and six in the second. In each of these scenarios, the same two characters interact with each other. The verbal and non-verbal behaviour of these characters differs depending on their cultural scripts. In two user perception studies, we investigated how these differences are judged by human participants with different cultural backgrounds. Besides expected differences between participants from Masculine and Feminine countries, we found significant differences in perception between participants from Individualistic and Collectivistic countries. We also found that the user’s interpretation of the character’s motivation had a significant influence on the perception of the scenarios. Based on our findings, we give recommendations for researchers that aim to design culture-specific behaviours for virtual characters.	computer science;experiment;mind;nonlinear gameplay;simulation;tatsunoko vs. capcom:;universal instantiation	Nick Degens;Birgit Endrass;Gert Jan Hofstede;Adrie J. M. Beulens;Elisabeth André	2014	AI & SOCIETY	10.1007/s00146-014-0567-2	multimedia;social psychology	HCI	-57.091119910689066	-47.960739801758784	138549
576db9467cf60cdd8b0383f05edd69c98c9c29ef	a social metaphor-based 3d virtual environment	3d virtual environment;group communications;social learning;virtual community;virtual learning;virtual environments;group communication;client server;design and implementation;avatars;virtual environment;synchronous communication;virtual space	"""Our design goal for OnLive Traveler was to develop a virtual community system that emulates natural social paradigms, allowing the participants to sense a tele-presence, the subjective sensation that remote users are actually co-located within a virtual space. Once this level of immersive """"sense of presence"""" and engagement is achieved, we believe an enhanced level of socialization, learning, and communication are achievable.OnLive Traveler is a client-server application allowing realtime synchronous communication between individuals over the Internet. The Traveler client interface presents the user with a shared virtual 3D world, in which participants are represented by avatars. The primary mode of communication is through multi-point, full duplex voice, managed by the server.We examine a number of very specific design and implementation decisions that were made to achieve this goal within platform constraints. We also will detail some observed results gleaned from the virtual community and virtual learning user-base, which has been using Traveler for several years."""	anomalous experiences;avatar (computing);client–server model;duplex (telecommunications);emulator;hologram time traveler;internet;server (computing);socialization;television;virtual community;virtual reality	Steve DiPaola;David Collins	2003		10.1145/965106.965134	social learning;simulation;human–computer interaction;communication in small groups;computer science;virtual machine;instructional simulation;asynchronous communication;metaverse;multimedia;client–server model;virtual learning environment	Visualization	-54.11617017169768	-43.42244944107045	138593
31bcc6c59de94ec7049fb51c2ab8e6d28e9aa73d	gaze-based infotainment agents	real time;multi modal presentation;preference detection;eye movement;interest recognition;eye tracking;eye gaze	We propose an infotainment presentation system that relies on eyegaze as an intuitive and unobtrusive input modality. The system analyzes eye movements in real-time to infer users' attention, visual interest, and preference regarding interface objects. The application consists of a virtual showroom where a team of two highly realistic 3D agents presents product items in an entertaining and attractive way. The presentation flow adapts to the user's attentiveness and interest, or lack thereof, and thus provides a more personalized and user-attentive experience of the presentation.	modality (human–computer interaction);personalization;real-time computing;real-time transcription	Helmut Prendinger;Tobias Eichner;Elisabeth André;Mitsuru Ishizuka	2007		10.1145/1255047.1255064	psychology;computer vision;eye tracking;multimedia;communication	HCI	-49.29466654884018	-43.01253788693544	138596
1b3d720e1219568907d95f08bf9c8be5133ecb36	are you exposed?: conveying information exposure	design space;location sharing;access to information;exposure;privacy	We explore the design space of interfaces for conveying and managing 'exposure' - the actual access to information by parties authorized to access it. Our goal is to convey the resulting disclosure in a quickly interpretable form and to enable lightweight interactions to manage exposure, if needed. Toward this end, we propose mapping levels of exposure to levels of concepts familiar in everyday practice, e.g., the appearance and physiology of an avatar. We hope that our ideas will spur further expansion and exploration of the design space around these issues.	authorization;avatar (computing);freedom of information laws by country;interaction	Sameer Patil;Apu Kapadia	2012		10.1145/2141512.2141575	simulation;human–computer interaction;computer science;knowledge management;exposure;communication;privacy;social psychology;world wide web	HCI	-58.8059284026213	-40.45327003560745	138631
c388fc91ee4bce323e007dc8ad7671a881261c83	time perception, immersion and music in videogames	gaming experience;immersion;videogames;music;time perception	People who play videogames often report the sense of immersion in the game with a particular feature of immersion being a loss of the sense of time passing. In this paper, we investigate if altering the degree of immersion in a videogame really does influence people’s psychological perception of time passing. We use music to make a maze game more immersive and we measure time perception using two paradigms that are well-established in psychology. We find that the addition of music does alter time perception but only in one paradigm. Additionally, music was able to influence immersion by both increasing it or decreasing it depending on the choice of music. The overall picture is therefore complex but suggests that music could be an important factor in the perception of time whilst playing videogames.	immersion (virtual reality);programming paradigm;while	Timothy Sanders;Paul A. Cairns	2010			simulation;art;multimedia;communication	HCI	-48.823975942604754	-49.56524541732394	138643
554f6f383d119cc81e30e911040c190fec4648e5	exploring issues of user model transparency and proactive behaviour in an office environment control system	context history;confidence level;intelligent environment;inference rule;qa75 electronic computers computer science;proactive behaviour;control system;machine learning;prototype deployment;scrutability;fuzzy decision tree;inference;user model	It is important that systems that exhibit proactive behaviour do so in a way that does not surprise or frustrate the user. Consequently, it is desirable for such systems to be both personalised and designed in such a way as to enable the user to scrutinise her user model (part of which should hold the rules describing the behaviour of the system). This article describes on-going work to investigate the design of a prototype system that can learn a given user’s behaviour in an office environment in order to use the inferred rules to populate a user model and support appropriate proactive behaviour (e.g. turning on the user’s fan under appropriate conditions). We explore the tension between user control and proactive services and consider issues related to the design of appropriate transparency with a view to supporting user comprehensibility of system behaviour. To this end, our system enables the user to scrutinise and possibly over-ride the ‘IF-THEN’ rules held in her user model. The system infers these rules from the context history (effectively a data set generated using a variety of sensors) associated with the user by using a fuzzy-decision-tree-based algorithm that can provide a confidence level for each rule in the user model. The evolution of the system has been guided by feedback from a number of real-life users in a university department. A questionnaire study has yielded supplementary results concerning the extent to which the approach taken meets users’ expectations and requirements.	adaptive system;algorithm;computer science;computer-supported cooperative work;control system;decision tree;diploma;display device;embedded system;fan-in;feedback;german research centre for artificial intelligence;human computer;human factors and ergonomics;human–computer interaction;industrial and organizational psychology;interaction technique;interrupt;level of detail;machine learning;message-oriented middleware;mobile app;population;proactive parallel suite;prototype;real life;requirement;sas;sensor;situated;software deployment;spatial–temporal reasoning;ubiquitous computing;usability;user interface;user modeling;user-centered design;wizard (software);ios	Keith Cheverst;Hee Byun;Dan Fitton;Corina Sas;Christian Kray;Nicolas Villar	2005	User Modeling and User-Adapted Interaction	10.1007/s11257-005-1269-8	user interface design;user;user experience design;simulation;user modeling;computer user satisfaction;confidence interval;human–computer interaction;user journey;computer science;knowledge management;control system;artificial intelligence;user requirements document;machine learning;data mining;user interface;world wide web;user story;rule of inference	HCI	-53.18426960486193	-39.56038245670533	139010
ea49c86391213c67d3deb58f996f82f44d350ee8	digilog book for temple bell tolling experience based on interactive augmented reality	culture technology;digilog book;multisensory experience;augmented reality;user interaction;article	We first present the concept of the Digilog Book, an augmented paper book that provides additional multimedia content stimulating readers’ five senses using augmented reality (AR) technologies. We also develop a prototype to show the usefulness and effectiveness of the book. The Digilog book has the following characteristics: AR content descriptions for updatable multisensory AR contents; enhanced experience with multisensory feedback; and interactive experience with computerized vision-based manual input methods. As an example of an entertaining and interactive Digilog Book, this paper presents a “temple bell experience” book and its implementation details. Informal user observation and interviews were conducted to verify the feasibility of the prototype book. As a result, this case study of the Digilog book can be useful in guiding the design and implementation of other Digilog applications, including posters, pictures, newspapers, and sign boards.	ampersand;augmented reality;image;input method;prototype;the code book	Taejin Ha;Youngho Lee;Woontack Woo	2010	Virtual Reality	10.1007/s10055-010-0164-8	augmented reality;human–computer interaction;computer science;artificial intelligence;multimedia;computer graphics (images)	HCI	-48.958358240109874	-39.42452765595239	139029
46b64adca5ef3009c1cb817196ef471c7988c3ed	life on the edge: supporting collaboration in location-based experiences	g400 computer science;ubiquitous;mobile;group formation;educational game;study;games;video recording;location based;spatial locality;shared context;g440 human computer interaction;collaborative	We study a collaborative location-based game in which groups of 'lions' hunt together on a virtual savannah that is overlaid on an open playing field. The game implements a straight-forward approach to location-based triggering in which players must be in the same spatial locale in order to share information and act together. Comparison of video recordings of physical play with system recordings of game events reveals subtle and complex interactions between highly dynamic player behavior and the underlying technology. While players exhibit a fluid approach to group formation, the system embodies a more rigid view, leading to difficulties with sharing context and coordinating actions, most notably when groups of players span virtual locale boundaries or initiate actions while on the move. We propose techniques for extending locales to support more flexible grouping and also discuss the broader implications of our findings for location-based applications in general.	interaction;location-based game;location-based service	Steve Benford;Duncan Rowland;Martin Flintham;Adam Drozd;Richard Hull;Josephine Reid;Jo Morrison;Keri Facer	2005		10.1145/1054972.1055072	games;simulation;human–computer interaction;computer science;operating system;mobile technology;multimedia;world wide web;ubiquitous computing	HCI	-57.779227365294794	-39.9751112950708	139234
05b54ac342c41176ef14f65b44b7efec38c32849	living with listening services: privacy and control in iot	manniska maskin interaktion mmi;systemvetenskap informationssystem och informatik;information systems;man machine interaction mmi	In this paper we discuss the impact to home, work, and civil life from the deployment of continuous listening services. An example service we call the Continuous Speech Stream (CSS), would provide a real time list of keywords generated from the user’s spoken interactions with others. We report the concerns expressed by our participants and offer an initial set of design recommendations for IoT based services built on such rich, personal data.		Donald McMillan;Antoine Loriette	2015		10.1007/978-3-319-18609-2_8	speech recognition;engineering;communication;world wide web	Mobile	-54.52542227512903	-40.64523404372654	139241
2ab1b89147698d38a2285ab1dd13f91ee94bc71d	she's electric - the influence of body proportions on perceived gender of robots across cultures		The assignment of gender to robots is a debatable topic. Subtle aspects related to gender, in a robot’s appearance, may create biased expectations of the robot’s abilities and influence user acceptance. The present research is a cross-cultural study involving more than 150 participants to investigate the perception of gender in robot design by manipulating body proportions. We are focusing specifically on the contrast between two extremely different cultures: Peruvian and Japanese. From the survey based on stimuli varying in the proportion between chest, waist, and hips, the results indicate the importance of chest-to-hip ratio and waist-to-hip ratio in the attribution of gender to robots.	robot;waist–hip ratio	Gabriele Trovato;Cesar Lucho;Renato Paredes	2018	Robotics	10.3390/robotics7030050		HCI	-52.52953801597089	-51.381737868718744	139593
5362fd85b10b0e1f87cd4c978c163110ea48d90c	a first step toward the automatic understanding of social touch for naturalistic human–robot interaction	touch recognition;robot pet companion;human robot interaction;affective context;multimodal interaction;behavior analysis;social touch	Social robots should be able to automatically understand and respond to human touch. The meaning of touch does not only depend on the form of touch but also on the context in which the touch takes place. To gain more insight into the factors that are relevant to interpret the meaning of touch within a social context we elicited touch behaviors by letting participants interact with a robot pet companion in the context of different affective scenarios. In a contextualized lab setting, participants (n = 31) acted as if they were coming home in different emotional states (i.e., stressed, depressed, relaxed, and excited) without being given specific instructions on the kinds of behaviors that they should display. Based on video footage of the interactions and interviews we explored the use of touch behaviors, the expressed social messages, and the expected robot pet responses. Results show that emotional state influenced the social messages that were communicated to the robot pet as well as the expected responses. Furthermore, it was found that multimodal cues were used to communicate with the robot pet, that is, participants often talked to the robot pet while touching it and making eye contact. Additionally, the findings of this study indicate that the categorization of touch behaviors into discrete touch gesture categories based on dictionary definitions is not a suitable approach to capture the complex nature of touch behaviors in less controlled settings. These findings can inform the design of a behavioral model for robot pet companions and future directions to interpret touch behaviors in less controlled settings are discussed.	behavioral modeling;categorization;dictionary;human–robot interaction;multimodal interaction;social robot	Merel M. Jung;Mannes Poel;Dennis Reidsma;Dirk Heylen	2017	Front. ICT	10.3389/fict.2017.00003	psychology;human–robot interaction;computer vision;computer science;artificial intelligence;multimodal interaction;communication;social psychology	HCI	-52.08430812190121	-49.49428654876323	139595
3a845dd73e92fab1b8a2725ee00782b696086f39	special issue introduction		This special issues highlights research advances that were presented at the Thirteenth International Conference on Pervasive Computing and Communications (PerCom 2015). The PerCom 2015 conferencewas held in St. Louis March 23–27, 2015, and provided an opportunity for researchers to present their original ideas and results, to relate practical development experiences, and to spark ideas for new research directions and collaborations. Selection of papers for this special issue was very competitive. A total of 243 papers were submitted to the PerCom conference and were reviewed by our 99 technical committee members. The acceptance rate for the conference was 12%. The papers presented state-of-the-art ideas in activity sensing, sensor data mining, energy analytics, mobile assistance, pervasive health, pervasive transportation, sensing applications, and security. In the case of the eleven full-length papers that were accepted for the conference, we invited the authors to submit an extended version of their more recent work for possible publication in this special issue. We received nine submissions and selected six of these papers for inclusion in this special issue. The first paper of this special issue introduces a pervasive computing-based approach to enhancing exercising through video games. In the paper ‘‘User-optimized activity recognition for exergaming’’, BobakMortazavi, Mohammad Pourhomayoun, Sunghoon Lee, Suneil Nyamathi, Brandon Wu, and Majid Sarrafzadeh use wearable sensors to monitor movements in their augmented reality soccer exergame called SoccAR. The authors found that not only can multiple classifiers be combined to improve motion recognition performance based on leave-one-subject-out analysis, but user-specific optimization can be integrated to further improve recognition by adapting to the characteristics of each user. Such activity recognition can heighten the success of a mobile game and thus serve as a mechanism for improving fitness through virtual gaming. The next four papers focus on pervasive computing in the context of smart phones. The second paper in this special issue, ‘‘Towards attention-aware adaptive notification in smart phones’’ by Tadashi Okoshi, Hiroki Nozaki, Jin Nakazawa, and Hideyuki Tokuda, analyzes the timing of smart phone notifications. These authors recognize that interrupting users who are in the middle of a task is likely to reduce the effectiveness of the notification as well as introduce task errors and increase the user’s cognitive load. To ameliorate the impact of smart phone interruptions, the authors introduce a middleware called Attelia that detects breakpoints in a user’s interactions. Attelia relies on supervised learning of breakpoint situations based on data that is collected by the phone itself. Evaluation of Attelia for 30 users indicates that not only can the middleware detect breakpoints but information delivery that occurs during these breakpoints reduces frustration over random timings. In the third paper titled ‘‘Robust and ubiquitous smartphone-based lane detection’’, Heba Aly, Anas Basalamah, Moustafa Youssef utilize smart phones to provide intelligent transportation assistance. These authors introduce the LaneQuest system that detects the position of a vehicle with respect to the lanes on a road. This technology can provide valuable assistance to manual and automated drivers. LaneQuest utilizesmultiple sources of information inside and outside the vehicle to enhance the robustness of its position estimation. The authors report that not only does LaneQuest detect the correct car lane in 92% of the evaluation cases but it does so with a very small energy footprint, making it easily usable for Android devices. Energy usage of mobile devices was a common theme for this year’s PerCom conference. While the previous paper designed a system to be energy efficient, the fourth paper in this special issue analyzes existing interaction modalities to explicitly determine their impact on energy consumption. Fangzhou Jiang, Eisa Zarepour, Mahbub Hassan, Aruna Seneviratne, and Prasant Mohapatra consider the text input modalities of soft keyboard input, speech to text, and swyping in their paper ‘‘Type, talk, or swype: Characterizing and comparing energy consumption of mobile input modalities.’’ The authors find that not only do these modalities consume different amounts of battery energy but their consumption is dependent upon factors such as the length of the user input. In addition, they estimate the percentage of battery usage that can be expected for typical scenarios when one of these modalities is used constantly. The fifth paper in this special issue builds a more general model of smart phone battery consumption. In the paper ‘‘Constella: Crowdsourced system setting recommendations for mobile devices’’, Ella Peltonen, Eemil Lagerspetz, Petteri	activity recognition;android;augmented reality;breakpoint;crowdsourcing;data mining;device driver;ella (programming language);extended industry standard architecture;interaction;interrupt;mathematical optimization;middleware;mobile device;mobile game;pervasive informatics;plover;sensor;smartphone;speech recognition;supervised learning;ubiquitous computing;virtual reality;wearable computer	Diane J. Cook;Christian Becker;Andreas Bulling;Zhiwen Yu	2016	Pervasive and Mobile Computing	10.1016/j.pmcj.2015.12.006		HCI	-57.59004102416813	-45.448811300980964	139682
3b6629caec170142f45712c83f382e499e1c2153	web design guidelines for text presentation for older people : empirical evidence from thailand and the uk		Numerous sets of web design guidelines for making websites more accessible for older people have been suggested, but there is little empirical evidence from studies with older people upon which to base their recommendations. In addition, the different web design guidelines often provide different recommendations. Finally, most of the web design guidelines are in English and relate to the use of the Latin alphabet. Currently, there are no web design guidelines for the Thai language or for Thai older people. The objective of this research is to investigate the recommendations from web design guidelines for Thai and UK older people, especially the recommendations related to the presentation of text for reading web pages. These are the variables investigated: line spacing, text justification, font type, font size, text colour and background colour. The recommendations were investigated with a series of empirical studies that asked both younger and older people to read web pages presented in different ways. The first study investigated the effect of line spacing and text justification. The results of this experiment found that 1.5 or double line spacing were preferred by both younger and older people in the UK and Thailand. For the UK web readers, both left justification and left right justification were preferred. For Thai web readers, left right justification was preferred. As interesting issues about the task emerged in the first experiment, the second study explored the range and appropriateness of a variety of tasks for research about reading web pages. The results of the experiment indicated the use of skimming reading as an appropriate task in the further experiments. The third study investigated the effect of font type and size on skim reading web pages. The experiment found that UK web users preferred Arial font type in comparison to Times New Roman, however Thai web users preferred a Thai conservative font type, which is closely related to serif. On font size, 14 point or larger was preferred by both the UK and Thai younger adults. For both the UK and Thai older adults, 16 point was preferred. The fourth study investigated the effect of text and background colour on skim reading web pages. Black text on white background and sepia text on off-white were preferred by all participants. Based on results of the experiment in this programme of research, an evidence-based set of web design guidelines for the presentation of text for older people in both Thailand and the UK was developed.	credit card fraud;experiment;norm (social);web accessibility;web design;web page;web typography	Sorachai Kamollimsakul	2016			engineering;multimedia;advertising;world wide web	HCI	-60.63753649684363	-48.13939608516271	139774
54b8d87b30eea3e93bbd114ddcb60502f2f7a481	the bass-station: a community based information space	mobile device;3d sound;information space;dj;local community;community building;augmented reality	The Bass-Station is a novel mobile device that allows people to easily share their artistic digital belongings with their immediate physical community. Building on currently available technology, incorporated into an everyday object, we create an information space that affords people of an artistic and collaborative community the ability to share and exchange their personal media. The Bass-Station facilitates communication and sharing between people in a local community, making use of technology as a medium for developing relationships and new artistic forms.	beneath a steel sky;mobile device	Ahmi Wolf;Mark Argo	2003		10.1145/965400.965555	augmented reality;simulation;computer science;operating system;mobile device;community building;multimedia	HCI	-56.58521064636681	-38.376791399358666	139897
73bb977d2d56e6aea7373ca9aee16052a87f9bf0	p300 harmonies: a brain-computer musical interface		We present P300 harmonies: a P300-based Brain-Computer Musical Interface. Using a commercial low-cost EEG device, the user can voluntarily change the harmony of an arpeggio by focusing and mentally counting the occurrences of each note. The arpeggio consists of 6 notes separated by an interval of 175ms. The notes of the arpeggio are controlled through 6 switches, where each switch has two possible states: up and down. When a switch is in the up-state the note produced by this switch is one tone or semitone -depending on the switchhigher than when in the downstate. By focusing on each of the notes of the arpeggio, the user may change -after 12 repetitionsthe state of the corresponding switch. The notes of the arpeggio appear in a random order. The state of each switch is shown on a screen. Each switch flashes when the corresponding note is heard. The user can either focus exclusively on the auditory presentation or make use of the visual presentation as well. The interface was presented in a live performance, where the user was able to successfully change the state of all switches with 100% accuracy. An additional preliminary evaluation was performed with 3 more users, in which the selection accuracy was 83.33%.	electroencephalography;network switch	Zacharias Vamvakousis;Rafael Antonio Márquez Ramírez	2014			psychology;simulation;communication;social psychology	HCI	-48.69340804711212	-46.66518162292249	139957
0893e12b8f1ca51e54149bfd54b179ed02b1381c	the hedonic value of sonnengarten: touching plants to trigger light		Sonnengarten is an interactive light installation, controlled by touching plants. It was developed for an urban festival, with the aim of increasing attractiveness of a courtyard and passageway. Light patterns were varied over the course of the festival. Requiring prolonged touch for a more complex light reaction increased interaction duration compared to the initial 1-step process and resulted in the installation being rated higher in hedonic quality in AttrakDiff questionnaires.	light gun	Till Fastnacht;Patrick Tobias Fischer;Eva Hornecker;Sabine Zierold;Abraham Ornelas Aispuro;Johannes Marschall	2017		10.1145/3152832.3157809	human–computer interaction;multimedia;attractiveness;computer science	HCI	-54.39101275328497	-42.22588582912487	140073
041589bb599b475fdffd5a87086856efba86b19c	turn-taking phenomena in incremental dialogue systems		In this paper, a turn-taking phenomenon taxonomy is introduced, organised according to the level of information conveyed. It is aimed to provide a better grasp of the behaviours used by humans while talking to each other, so that they can be methodically replicated in spoken dialogue systems. Five interesting phenomena have been implemented in a simulated environment: the system barge-in with three variants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable.	andrew barto;classification tree method;coherence (physics);computer performance;dialog system;experiment;reinforcement learning;taxonomy (general);trusted third party;virtual reality	Hatim Khouzaimi;Romain Laroche;Fabrice Lefèvre	2015			simulation;artificial intelligence;machine learning	NLP	-52.366390052026006	-48.32625586141401	140113
74adf7ed6a3ce2fd964180d77918d023707c4656	developing digital library design guidelines to support blind users		ABSTRACT This study investigates the types of help-seeking situations affecting 32 blind users in interacting with five digital libraries (DLs). Multiple methods were applied to collect data: pre-questionnaires, think aloud, transaction logs, and post-questionnaires. The paper identifies 43 types of situations under three categories of physical situations and five categories of cognitive situations. Most important, DL design guidelines are created to support blind users overcoming these situations.	digital library;interaction;library (computing)	Iris Xie;Rakesh Babu;Melissa Davey Castillo;Tae Hee Lee;Rongyue Jing	2018		10.1145/3234695.3241024	multimedia;human–computer interaction;digital library;usability;think aloud protocol;computer science;cognition;transaction log	HCI	-56.11823766112239	-43.74508592803533	140232
9554d63d3663188b667b85ecbd00318b0f873d76	associative personal information management	mobile;personal information management;design principle;associative network;network mobility;associations	Personal information management (PIM) is an important and hard research problem. Previous systems suffer inflexibility because of strict hierarchies and immobility. I present an alternative approach, based on associations and moving beyond today's desktop metaphor, to provide ways of managing information while mobile. To illustrate the concepts, I introduce the Associative PDA, a prototype we have designed and evaluated. Finally, I discuss some design principles, which will guide my future work.	desktop computer;desktop metaphor;personal digital assistant;personal information management;prototype	Jonathan Diehl	2009		10.1145/1520340.1520437	simulation;human–computer interaction;computer science;knowledge management;artificial intelligence;mobile technology;personal information management;group information management;management;world wide web;personal information manager	HCI	-53.610425688805634	-38.8202808280418	140279
e1b2b969cd3bb84c0353852e51f0c9531545ee7b	bridging gaps: affective communication in long distance relationships	intimate computing;mediated communication;evocative experience;affect;long distance;presence in absence;computer mediated communication;user research;romantic relationship;affective computing	This study examines communication methods and needs of people in long distance romantic relationships to understand how intimate computing can help create or augment already existing artifacts to promote feeling of connectivity within non-collocated couples. We report our research in progress and provide a collection of initial design concepts based on the user research.	bridging (networking);user research	Shruti Bhandari;Shaowen Bardzell	2008		10.1145/1358628.1358758	human–computer interaction;artificial intelligence;affective computing;affect	HCI	-58.878029279920426	-40.27062019963109	140286
4779c5e590fcc39319d2e1e435daf7b045c93bf6	time to retire old methodologies? reflecting on conducting usability evaluations with older adults	evaluation methodologies;older adults;usability	"""The global population is becoming older, and the trend for this shift is only accelerating. At the same time, older adults are using the Internet and mobile technologies in increasingly large numbers. As evidenced by the proceedings of many conferences such as the ACM MobileHCI or the ACM CHI, the usability of interactive technologies designed for older adults is of significant concern. Yet, the methodologies we employ for designing and evaluating such interfaces are largely the same as those used for any other user group. In this position paper, we argue that one methodological size does not fit all especially when it comes to usability evaluations with older adults. We do so by reflecting on our own experiences with designing and evaluating interactive technologies for older adults (particularly for those over 80 years -- the """"oldest old""""). We then propose for discussion senior-centred approaches and adaptations of established usability evaluation methodologies."""	chi;internet;mobilehci;usability	Rachel L. Franz;Cosmin Munteanu;Bárbara Barbosa Neves;Ronald Baecker	2015		10.1145/2786567.2794303	simulation;usability;human–computer interaction;computer science;multimedia	HCI	-61.95708148378997	-42.565686061259555	140404
b2a3c08ff0518e7ca7193496b2835a1b42d7cd33	development of web-based platform for privacy protective avatar mediated distance-care	privacy protection;distant care;avatar mediated communication;health care	We propose a web-based platform for privacy-protected avatar mediated distant-care. The system can avateer an elderly person based on their articular angles acquired by a motion capture system, and render the whole body animation of the avatar on a web-browser. The avatar-mediated architecture design allow caregivers to observe the elderly persons’ behavior all day long, without violating their privacy. In addition, we will show an example implementation integrating multiple sensors in the platform. By integrating multiple sensors into the platform, caregivers can observe the avatar with the elderly person’s health-related status. The implemented system showed the low communication bandwidth dependency, and sufficient frame-rate for the animation to be smoothly seen.		Yu Kobayashi;Dai Hasegawa;Shinichi Shirakawa;Hiroshi Sakuta;Eijun Nakayama	2015		10.1007/978-3-319-32270-4_13	internet privacy;world wide web;computer security;health care	Crypto	-48.51659144284099	-48.70409613130376	140453
10e951872f9801beeef0c22728751a6554b495f0	persuasive robotics: the influence of robot gender on human behavior	computers;humanoid robot;human interaction;social interaction;mobile robots humanoid robots human robot interaction;mobile robots;psychology;human robot interaction;data mining;human behavior;persuasive robotics;humanoid robots;museum of science;human robot interaction intelligent robots humanoid robots psychology educational robots usa councils laboratories hospitals;robots;mobile communication;humans;robot gender;boston;bars;humanoid robot persuasive robotics robot gender human behavior human robot interaction social interaction museum of science boston	Persuasive Robotics is the study of persuasion as it applies to human-robot interaction (HRI). Persuasion can be generally defined as an attempt to change another's beliefs or behavior. The act of influencing others is fundamental to nearly every type of social interaction. Any agent desiring to seamlessly operate in a social manner will need to incorporate this type of core human behavior. As in human interaction, myriad aspects of a humanoid robot's appearance and behavior can significantly alter its persuasiveness - this work will focus on one particular factor: gender. In the current study, run at the Museum of Science in Boston, subjects interacted with a humanoid robot whose gender was varied. After a short interaction and persuasive appeal, subjects responded to a donation request made by the robot, and subsequently completed a post-study questionnaire. Findings showed that men were more likely to donate money to the female robot, while women showed little preference. Subjects also tended to rate the robot of the opposite sex as more credible, trustworthy, and engaging. In the case of trust and engagement the effect was much stronger between male subjects and the female robot. These results demonstrate the importance of considering robot and human gender in the design of HRI.	cognitive robotics;fembot;humanoid robot;human–robot interaction;trust (emotion)	Mikey Siegel;Cynthia Breazeal;Michael I. Norton	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354116	simulation;computer science;engineering;humanoid robot;artificial intelligence;human behavior	Robotics	-52.2302141868282	-51.09842513234431	140479
7e155ca060061ada4f827f9339bfa7cf566757d4	the gender perspective in cultural probes	gender and design;mobile communication;cultural probes;participatory design	This paper is an experience report about the appliance of participatory design methods for a gender sensitive approach. Investigating their appropriateness to gather gender specific insights, we are particularly interested in their potential of avoiding the recreation of gender stereotypes. In this context, we reflect the design of our research environments, methods and tools according to their unconscious gender assumptions which might cause stereotype answers. Our empirical study, called Women’s Phone, aimed both at involving female prospective users to avoid gender clichés and to critically investigate conventional and stereotypical design solutions of mobile phones. We judge the suitability of the methods used in two respects: • Their value in keeping researchers away from reproducing conventional gender images, • Their meaning as an incorporation of the researchers’ attitudes and its impact on the research results. We consider our set of ‘cultural probes’ used in the project as the strongest evidence of the researchers’ inherent gender assumptions. Therefore, we will explore the visibility of the ‘gender point of view’ in the probes and draw implications from it for future gender-sensitive design inquiries.	mobile phone;norm (social);prospective search;windows phone	Katharina Bredies;Sandra Buchmüller;Gesche Joost	2008		10.1145/1795234.1795256	social science;mobile telephony;computer science;gender studies;social psychology	HCI	-58.40665134733678	-41.652722888740314	140560
3e42af3bbb5cc24fa426ff7328e7f50c82ac75fb	assistive embedded technologies	quality of life;assistive technologies;assistive technologies tinetra embedded computing;technologie informatique embarque;blind user;utilisateur aveugle;blind users;user assistance;embedded systems;handicapped aids;assistance utilisateur;tinetra;asistencia usuario;assistive technology;safety critical application;blind user assistive embedded technolog safety critical application trinetra system;cost effectiveness;handicapped aids embedded systems;cellular phones costs embedded computing investments bluetooth manufacturing speech synthesis computer vision navigation testing;assistive embedded technolog;embedded computing;embedded device;trinetra system	Embedded computing technologies are not only an integral part of traditional safety- critical applications such as jet engine and automotive brake control, they are also being used to improve people's quality of life. Trinetra integrates embedded devices to let blind users enjoy cost-effective, independent shopping. The day-to-day needs of a typical blind user greatly influenced our design and evaluation of the Trinetra system. From the beginning, the user of our system also proved instrumental in helping design and tests the system	embedded system;floor and ceiling functions	Priya Narasimhan	2006	Computer	10.1109/MC.2006.221	embedded system;simulation;cost-effectiveness analysis;quality of life;computer science;multimedia	EDA	-51.46467119187074	-42.78189928863027	140590
895cb3731b3de6bf4770b5ff3ada6906d1476826	archi: engaging with museum objects spatially through whole body movement	engagement;whole body movement;performative interactions;body as interface;emergent experience	We explore body movement as a medium. We investigate how body movement may help define the quality of human experience in particular, when mediated through pervasive digital technologies.  In this paper, we present an interactive installation developed and implemented in a museum context. We outline the iterative design methodology and compare data from the deployment. We highlight in particular the importance of taking into account full body and performative interactions as an important factor of human experience.  We integrate approaches that explore the embodied, and the performative nature of human interactions and describe an attempt to develop new ways when designing for emergent experience and interactivity enabled through depth sensing (with Kinect) that go beyond traditionally applied methods within Human Computer Interaction (HCI).  While the users study was successful in identifying emergent issues related to embodied interactions and social behavior patterns in the museum, our analysis highlights influences on usage and behavior patterns including the social dimension, the physical setting, and the type of body movement it affords.  The paper concludes that we should rethink the relationship between the body and space through mediated interactions. The implementation outcome demonstrates the need to develop a better understanding of performative interactions generated through full body movement and its subjective spatial relationships. We suggest that these attempts will help inform further experiments with depth sensing and will have a critical impact on current research in HCI, and on future attempts to developing digitally mediated interactions when designing responsive environments in a social public setting.	emergence;experiment;human computer;human–computer interaction;interactivity;iterative design;iterative method;kinect;pervasive informatics;software deployment	Ava Fatah gen. Schieck;Ana Maria Moutinho	2012		10.1145/2393132.2393141	simulation;human–computer interaction;engineering;communication	HCI	-59.10634848664185	-38.48949514267652	140633
df2be4d7f103c1dd4464c77d98e9f7f3eb830bef	work in progress: using mobile phones to accomplish an audience response system with igoogle home page	electronic learning;object recognition;opensocial;search engines;smart phones;gadget audience response system igoogle opensocial;opensocial gadgets audience response system igoogle home page mobile phones;smart phones educational computing mobile computing search engines;gadget;receivers;audience response system;portable computers;igoogle;web services;educational computing;mobile computing;web services smart phones receivers electronic learning portable computers object recognition	Audience Response Systems can benefit the normal course of the classes. Dedicated Audience Response Systems can be quite expensive to purchase and maintain. Additionally, the question types supported are somewhat limited, usually only choice questions are available. In our previous works we have developed a set of OpenSocial gadgets that can be included in a personal iGoogle page. Our future work is centred in providing a electronic voting system based on gadgets with iGoogle using mobile devices as smartphones and laptops for voting.	home page;laptop;mobile device;mobile phone;opensocial;smartphone	Martín Llamas Nistal;Manuel Caeiro;Juan González-Tato;Javier Álvarez-Osuna	2012	2012 Frontiers in Education Conference Proceedings	10.1109/FIE.2012.6462391	computer science;multimedia;internet privacy;world wide web	HCI	-50.56684772378567	-42.709680229039265	140671
2e695a01fe858f481978b9650036a9b0f012f6f6	simulating virtual humans crowds in facilities		The area of crowd simulation has been widely explored in several contexts from entertainment to safety purposes. In this paper we present an approach to simulate the evacuation of crowds in facilities such as hospitals, geriatric clinics, orphanages and etc. We use Snook tables to parametrize the effort of people to push patients impacting the people speed when evacuating a specific environment. In addition, we compare our method with another simulation in a hospital.	crowd simulation;graeme snooks;humans;table (database)	Diogo Schaffer;Conrado Boeira;Gabriel Rockenbach;Guilherme Maurer;André Antonitsch;Soraia Raupp Musse	2018		10.1145/3267851.3267888	multimedia;entertainment;crowds;computer science;crowd simulation	HCI	-50.25962387615629	-44.894232388458995	140695
24399306d81f427c4afaddae1d37e9fb357a43f7	owens luis - a context-aware multi-modal smart office chair in an ambient environment	sleepiness recognition context awareness multi modal displays;quality of life;context awareness;context aware;hypersonic directional speaker context aware multimodal smart office chair ambient environment owens luis quality of life qol physiological states mental states multimodal displays color temperature led light;work environment;furniture;ubiquitous computing computer displays furniture office automation;multi modal displays;computer displays;ubiquitous computing;sleepiness recognition;office automation	This paper introduces a smart office chair, Owens Luis, whose pronunciation has a meaning of “an encouraging chair ( )” in Japanese. For most of the people, office environments are the place where they spend the longest time while awake. To improve the quality of life (QoL) in the office, Owens Luis monitors an office worker’s mental and physiological states such as sleepiness and concentration, and controls the working environment by multi-modal displays including a motion chair, a variable color-temperature LED light and a hypersonic directional speaker. Keywords-Context awareness; Multi-modal displays; Sleepiness recognition;	context awareness;modal logic;office chair;the quality of life	Kiyoshi Kiyokawa;Masahide Hatanaka;Kazufumi Hosoda;Masashi Okada;Hironori Shigeta;Yasunori Ishihara;Fukuhito Ooshita;Hirotsugu Kakugawa;Satoshi Kurihara;Koichi Moriyama	2012		10.1109/VR.2012.6180951	simulation;quality of life;human–computer interaction;computer science;multimedia;ubiquitous computing	HCI	-49.13461471709152	-47.80221796365486	140753
6aa79d7f480732575ebefb2d13aad6220f6ebcbc	landscape or portrait? the impact of page orientation on the understandability of scientific posters		The recent developments in the eye tracking technology lead to new insights in how humans read, yet little is known about how the layout affects the comprehension. In this study, the differences in the understandability and the reading behaviour of two different page orientations (portrait and landscape) of a scientific poster are investigated. An eye tracking experiment was designed to find out whether the participants focus more on different areas in different orientations and whether the orientation has any effect on the reading behaviour or the overall comprehension of the poster. The participants' gazes were recorded and mapped onto the document using homographies. The saccade and transitional analysis over 30 participants concludes that the portrait orientation is better for remembering specific details while the landscape orientation supplements a high level understanding.	eye tracking;high-level programming language;list comprehension	Marc Beck;Seyyed Saleh Mozaffari Chanijani;Syed Saqib Bukhari;Andreas Dengel	2017	2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2017.376	saccade;artificial intelligence;computer vision;computer science;eye tracking;portrait;comprehension;page orientation	HCI	-59.25478788456727	-48.43029344091459	140826
3b1fd1004c39f583b74e3ecf4c653eaa3d76aad7	wear.x: developing wearables that embody felt experience		Physical discomfort can be highly personal, difficult to discern from the outside, challenging to effectively communicate. Yet communicating discomfort can be of great value. We present a method for developing wearables that transfer one person's discomfort to another: a modified fashion ideation process that enables a person to bring their hidden embodied experiences into wearable form. Using five complementary foci, the method seeks to simulate rather than replicate; to support people to find abstracted expressions for their lived experiences of discomfort, with which to negotiate shared understanding. The resulting wearables support empathic engagement with how another person might feel. Physical discomfort can be highly personal, difficult to discern from the outside, challenging to effectively communicate. Yet communicating discomfort can be of great value. We present a method for developing wearables that transfer one person's discomfort to another: a modified fashion ideation process that enables a person to bring their hidden embodied experiences into wearable form. Using five complementary foci, the method seeks to simulate rather than replicate; to support people to find abstracted expressions for their lived experiences of discomfort, with which to negotiate shared understanding. The resulting wearables support empathic engagement with how another person might feel.	experience;self-replicating machine;simulation;wearable computer	Janne Mascha Beuthel;Danielle Wilde	2017		10.1145/3064663.3064799	multimedia;engineering;wearable computer;empathy;ideation;embodied cognition;negotiation	HCI	-51.52380702086429	-49.22150797861922	140938
13904b1a8d2446470c936d0d5ad87a1843aa0911	turn taking in e-mail discussions		This chapter investigates turn taking in naturally occurring e-mail discussions. In e-mail discussions, participants can self select to contribute at any time, turns cannot be interrupted, and adjacency cannot be guaranteed. However, participants engage in recognisable discussions and “speaker” change occurs. Patterns of turn taking can be observed in the data, and there are many parallels with spoken conversation. In e-mail discussions, the current participant may select a new participant, and those selected usually respond; participants may self select (the most common method of turn taking); and the current participant may choose to continue, either by writing an extended turn or by sending separate consecutive messages. Response is not obligatory unless a respondent has been specified. There is no priority system through which a change of participant takes priority. Because there is less pressure toward current speaker selects last, the system encourages multiple participants to engage in the discussion.	email;interrupt;parallels desktop for mac	Sandra M. Harrison	2008			human–computer interaction;computer science;communication;world wide web	HCI	-52.560383797964136	-43.951616461771316	140964
eb9e4179b93ea480f70e9cf84a2a496e37a11e4a	regulative or constitutive behaviors: culture and identity in human interaction	human interaction;multimodal interface;nonverbal behavior;virtual human;social signal;constitutive behavior;human agent interaction;multimodal interfaces	"""The term 'social signal' implies that one person emits a signal that another picks up, and that the signal regulates some sort of socially appropriate behavior. Taking examples from my recent research on culture and identity both in human-human and human-agent interaction, I will try to problematize the notion of a """"social signal"""" by demonstrating the many cases where there is no signal independently or prior to the people who use it, and where the exchange of signals constitutes rule-making, as opposed to following it."""		Justine Cassell	2010		10.1145/1878116.1878136	psychology;developmental psychology;communication;social psychology	ECom	-51.87723420428778	-49.62999045467076	140986
466b989a49a284bd99872e5db048d04fe232044b	thermo-message: exploring the potential of heat as a modality of peripheral expression	interpersonal communication;peripheral expression;focus group;modality;experience prototyping;thermal expression	"""Peripheral expressions using various modalities are considered as possible alternative ways of delivering information in our communication. In this research, we aimed to explore how the thermal expression can be used in the interpersonal communication. Based on the result of the focus group interview, we developed a pair of devices with which the users can exchange a """"thermal message"""" each other. Experience prototyping was conducted with the devices in the real daily life context of the users. We identifed the charateristics of thermal expression, and confirmed the potential of the thermal expression in interpersonal communication."""	focus group;peripheral	Wonjun Lee;Youn-Kyung Lim	2010		10.1145/1753846.1754131	focus group;multimedia;interpersonal communication	HCI	-54.65154129048561	-43.118680902979975	141028
692caf7ee5f3f2d2557c55f888046cc2c463ce6e	using individual and collaborative challenges in behavior change support systems: findings from a two-month field trial of a trip planner application		Besides other popular strategies, such as feedback and (social) comparisons, challenges have been proposed and used to influence people’s behavior towards a targeted goal. However, only very limited data on the effectiveness of such approaches and how to best design them is available yet. In this work we report the findings of a two months field study analyzing the effectiveness and perception of challenges in the context of influencing personal mobility. Individual and collaborative approaches towards challenges were studied, and specific focus was laid on what aspect makes users willing to participate in these challenges. Our findings suggest that both individual and collaborative challenges have the potential to sustain the interest of users in using behavior change support systems, that collaborative and individual challenges seem to not attract different types of users, that individual challenges in general are preferred, and that challenges are only a useful means for a subset of users. Also, ICT-competence seems to be an important aspect of being willing to participate in electronically organized challenges.	feedback;field research;interaction;persuasive technology	Johann Schrammel;Sebastian Prost;Elke E. Mattheiss;Efthimios Bothos;Manfred Tscheligi	2015		10.1007/978-3-319-20306-5_15	simulation;knowledge management;management science	HCI	-60.5498478924709	-41.326134554916315	141073
e697dc33747384760b7193f772a3d2cd39a2c1f9	sensing the news: user experiences when reading locative news	location based services;journalism;locative media;hyperlocal news;locative journalism;mobile media	This article focuses on user experiences on reading location-aware news on the mobile platform and aims to explore what experiences this kind of locative journalism generates and how such experiences change the users‟ social interaction with news. We produced a specially designed mobile application and tailored news stories specific to this project called LocaNews in order to explore participants‟ relation to the content in this journalistic format. The result is generated through a field study and a questionnaire of 32 people to find out how they experience the news presented in this format. The user participants‟ responses are analyzed based on their news experiences, contextualizing places and their social interaction with the news within this form of journalism. Results showed that the local, semi-local and non-local user approaches the locative news in a different manner, but that the average user found this kind of news more interesting and more informative than ordinary news. The participants also have a problem identifying this as journalism, rather than an information service.	digital journalism;experience;field research;information;location awareness;location-based game;mobile app;mobile operating system;semiconductor industry	Kjetil Vaage Øie	2012	Future Internet	10.3390/fi4010161	journalism;computer science;news media;location-based service;multimedia;internet privacy;law;world wide web	HCI	-54.895666750090236	-40.52166930579088	141084
41b92891e81b27579e5bd0b47a09b232fb4bc05b	"""""""collaborative mobile user interface design"""": how should companies design the mobile user interface together?"""	design webs;mobile user interfaces;user interface;personal experience design;mobile service;mobile user interface;collaborative design;china;experience design	The special session will discuss challenges, real-world examples and future directions in the collaborative design of the user interfaces of mobile services, devices and application in and between Asia and the West.	user interface design	David M. L. Williams	2006		10.1145/1292331.1292413	user interface design;user;user experience design;mobile search;user modeling;mobile web;human–computer interaction;user journey;experience design;computer science;operating system;multimedia;design education;natural user interface;user interface;mobile computing;world wide web;china	HCI	-52.21486273545309	-39.22996273135024	141099
5a5f2c87b54f91f85c2284a82470c81923520894	engaging children with autism in a shape perception task using a haptic force feedback interface	social interaction;shape perception task;hci;autism spectrum disorders;motors skills	Atypical sensori-motor reactions and social interaction difficulties are commonly reported in Autism Spectrum Disorders (ASD). In our work, we consider the possible relationship between using our sense of touch to discover our environment and the development of interaction competencies, in the particular case of ASD. For this purpose we will use a task of shape perception, and a haptic feedback device. The design of the haptic device will be based on the State of the Art and advices from experts in ASD. We plan to work on the needs and skills of children on the spectrum in the lower range of intelligence scores. This article details the development of our PhD project, which aims at designing efficient and reliable haptic force feedback interfaces and interactions for ASD user. Preliminary results on the development of our interface and the design of the interaction tasks are presented as well as our specific contributions.	haptic technology;interaction	Alix Pérusseau-Lambert	2016		10.1145/2993148.2997614	social relation;simulation;human–computer interaction;computer science;multimedia	HCI	-56.210941541515226	-50.25255791898967	141190
48aa1e18860ef25e2cb0f53a047e3ac3489644e8	feelings elicited by auditory feedback from a computationally augmented artifact: the flops	emotions;human computer interaction;elicited feelings;computationally augmented interface;behavioural sciences computing;acoustics;computationally augmented artifact;auditory displays;glass;appraisal;appraisal glass noise computational modeling psychoacoustic models context acoustics;active artifact manipulation;human computer interaction auditory displays augmented reality behavioural sciences computing;computational modeling;acoustically augmented artifact;active artifact manipulation elicited feelings auditory feedback computationally augmented artifact emotions acoustically augmented artifact acoustic features;emotion;acoustical features;manipulation;acoustic features;auditory feedback;augmented reality;psychoacoustic models;context;noise;manipulation computationally augmented interface emotion auditory displays acoustical features	This paper reports on emotions felt by users manipulating a computationally and acoustically augmented artifact. Prior studies have highlighted systematic relationships between acoustic features and emotions felt when individuals are passively listening to sounds. However, during interaction with real or computationally augmented artifacts, acoustic feedback results from users' active manipulation of the artifact. In such a setting, both sound and manipulation can contribute to the emotions that are elicited. We report on a set of experimental studies that examined the respective roles of sound and manipulation in eliciting emotions from users. The results show that, while the difficulty of the manipulation task predominated, the acoustical qualities of the sounds also influenced the feelings reported by participants. When the sounds were embedded in an interface, their pleasantness primarily influenced the valence of the users' feelings. However, the results also suggested that pleasant sounds made the task slightly easier, and left the users feeling more in control. The results of these studies provide guidelines for the measurement and design of affective aspects of sound in computationally augmented artifacts and interfaces.	acoustic cryptanalysis;audio feedback;augmented reality;embedded system;flops	Guillaume Lemaître;Olivier Houix;Patrick Susini;Yon Visell;Karmen Franinovic	2012	IEEE Transactions on Affective Computing	10.1109/T-AFFC.2012.1	computer vision;augmented reality;speech recognition;emotion;computer science;communication	HCI	-51.29860630642345	-46.73242595583127	141330
ac23b8d5d2f27fdf741ec74e4aeb75a9e8ceaa28	ad hoc participation in situation assessment: supporting mobile collaboration in emergencies	ethnography;collaboration;emergency management;awareness;design case study;situation assessment;participation;mobile devices	Emergencies are characterized by high complexity and unpredictability. In order to assess and manage them successfully, improvisation work and informal communication, even beyond local and organizational boundaries, is needed. Such informal practices can facilitate ad hoc participation of units in situation assessment, but this may lack overall situation awareness. This article presents a study on how emergent “collaboration needs” in current work of response teams located on-site and in the control center could be supported by mobile geo-collaboration systems. First, we present the results of an empirical study about informal work and mobile collaboration practices of emergency services. Then we describe the concept of a mobile geo-collaboration system that addresses the aspects detected in the empirical study and that was implemented as an Android application using web sockets, a technology enabling full-duplex ad hoc communication. Finally, we outline the findings of its evaluation in practice and its implications.	android;duplex (telecommunications);emergence;hoc (programming language);situation calculus;websocket	Christian Reuter;Thomas Ludwig;Volkmar Pipek	2014	ACM Trans. Comput.-Hum. Interact.	10.1145/2651365	simulation;awareness;computer science;knowledge management;mobile device;ethnography;situation analysis;management;emergency management;collaboration	HCI	-60.199006203998394	-40.50682706745807	141367
e5339c4b3974096ba2b31876a272ab1d5fe99145	developmental changes in children understanding robotic actions: the case of lifting	motion pictures;lifting humanoid robots human robot interaction;collaboration;trajectory robot kinematics robot motion motion pictures humanoid robots collaboration;human robot interaction human development action understanding humanoid robotics;trajectory;humanoid robots;human robot interaction children developmental changes robot to human communication lifting execution humanoid robot;robot motion;robot kinematics	Humans develop already from the first years of life the ability to understand the actions and intentions of others and naturally use this skill to help others [1]. It would be important for the future of human-robot collaboration if children could easily generalize this understanding to robotic agents. In this paper we have investigated whether this is possible, at least in the context of inferring object weight from the observation of a humanoid action. Our results show that children of different ages need a different degree of human-likeness in robot motion to be able to infer which weight is being lifted. Indeed, from 10 years of age on, even non-humanlike trajectories can communicate the lifted load, if the lifting speed is appropriately varied as a function of weight. Conversely, younger children are significantly better at judging weight only in presence of a human-like trajectory. Hence, robots should adapt even the basic properties of their motion to their users, taking into account that children perception progressively changes with age.	humans;lambda lifting;norm (social);robot	Alessandra Sciutti;Laura Patanè;Oskar Palinko;Francesco Nori;Giulio Sandini	2014	4th International Conference on Development and Learning and on Epigenetic Robotics	10.1109/DEVLRN.2014.6983002	mobile robot;computer vision;simulation;articulated robot;engineering;humanoid robot;social robot;robot control;communication;personal robot	Robotics	-50.822106457296904	-50.63564740630667	141527
6499d17538c295682326de8908f3cce7f831edb7	presentation technique of scents using mobile olfactory display for digital signage	olfactory information;pulse ejection;olfactory display;olfactory characteristics;scented digital signage	Understanding and attention value of the advertisement will be advanced by adding scents to the digital signage. However, it was difficult to have corresponding one-to-many relationships, movements of users, and precise chronological control of scents. In this study, using mobile olfactory display, we propose the digital signage with scent which takes account of users’ movements. The concept of this study is constructing the system having scents, movements, and communication. This system was built by enabling to receive the scent ejection signal from the advertisement, achieve the distance by the image of web-camera, and eject the scents with the strength in accordance with distance, to have the control of scents which accedes to substance of advertisement and positional relationship. As a result of evaluations, the olfactory information was carried down to users with great accuracy. The scents production of the advertisements will be possible with the use of this system.	ar (unix);digital signage;experiment;information foraging;multi-user;one-to-many (data model);picture-in-picture;transmitter;webcam	Sayumi Sugimoto;Ryo Segawa;Daisuke Noguchi;Yuichi Bannai;Ken-ichi Okada	2011		10.1007/978-3-642-23765-2_23	multimedia	HCI	-48.499204214129094	-47.738054056072244	141587
ff657c2e3cf5a16df0b54fbb482a4ff99826d70a	usability evaluation of software as service from individuals			software as a service;usability	Chaudhry Muhammad Nadeem Faisal	2011	e-Minds		usability lab;component-based usability testing;cognitive walkthrough;usability;human–computer interaction;usability engineering;usability inspection;pluralistic walkthrough;usability goals;computer science	HCI	-62.81394574761139	-46.20584447323316	141710
6037a90ee9539abdd45cf5b3259a51e85c1fee23	adaptive interfaces: a little learning is a dangerous thing	adaptive interfaces;physical disability;low vision;mobile computing	In this paper we present a possible approach to improve accessibility and usability of software applications through shared user models. Previous work in adaptive user interfaces has relied on local and domain specific user models, which lack in scope and detail. Shared user models can increase the accuracy and depth of data used to adapt the interfaces and user interactions. This research focuses on the accessibility of touch screen mobile devices for users with low vision and mobility impairments.		Kyle Montague;Vicki L. Hanson;Andy Cobley	2011		10.1007/978-3-642-21672-5_43	user interface design;simulation;user modeling;human–computer interaction;computer science;multimedia;post-wimp;user interface	HCI	-49.31569403900469	-41.45075623853251	141735
c3ad0466ea9f70eca834657792354216cf45de70	disembodied performance	theater;performance;visualization;physiological sensors	Early in Tod Machover's opera Death and the Powers, the main character, Simon Powers, is subsumed into a technological environment of his own creation. The theatrical set comes alive in the form of robotic, visual, and sonic elements that allow the actor to extend his range and influence across the stage in unique and dynamic ways. This environment must compellingly assume the behavior and expression of the absent Simon. In order to distill the essence of this character, we recover performance parameters in real time from physiological sensors, voice, and vision systems. These gesture and performance parameters are then mapped to a visual language that incorporates cognitive and semantic models informed by modal relationships. This language allows the off-stage actor to express emotion and interact with others on stage. Our Disembodied Performance system takes a new direction in augmented performance by employing a non-representational abstraction of a human presence that fully translates a character into an environment.	modal logic;robot;sensor;visual language	Peter Alexander Torpey;Elena Naomi Jessop	2009		10.1145/1520340.1520555	simulation;visualization;human–computer interaction;performance;computer science;artificial intelligence;management	AI	-51.263238158151424	-48.21325298510853	141773
e80c0e1167639e75585a88dc44a5fcdc2a651ec5	"""evaluation of virtual reality products and applications from individual, organizational and societal perspectives - the """"view"""" case study"""	modelizacion;concepcion asistida;multicriteria analysis;interfase usuario;computer aided design;usability testing;realite virtuelle;ergonomia;visualizacion;realidad virtual;user interface;data collection;virtual reality;multi criteria analysis;ergonomie;development process;modelisation;assessment tool;visualization;visualisation;evaluation methodology;conception assistee;interface utilisateur;analisis multicriterio;analyse multicritere;modeling;ergonomics;hierarchical model	Virtual reality (VR) has evolved in technology and applications within the last decade. Technical advances have led to the development of novel interaction devices, interaction concepts, more reliable and robust VR set-ups, advanced visualization and modeling software. However, decisions regarding which VR set-ups and devices are suitable for particular applications are becoming more difficult due to the rapid stream of technical development. In the ‘‘VIEW of the Future’’ project (IST-2000-26089), the development process was coupled with an extensive and multivariable evaluation procedure. The latter has taken advantage of direct neurophysiological and psychophysiological measurements and a variety of self-report tools administered in a set of different but closely linked experiments. Furthermore, the implementation of VR solutions in different applications was examined with a socio-economic perspective, by applying a multi-criteria analysis (MCA) using an analytical hierarchical model. The data collected during the experimental trials enabled us to reach general conclusions regarding the systems used, and to derive applicability guidelines to facilitate the implementation of VR products. This paper presents all aspects of the evaluation methodology: Usability Test Battery for neuroand psycho-physiological measurements, VIEW-IT heuristic assessment tool, questionnaires, MCA methodology). A summary of the results includes usability and ergonomic findings for different VR set-ups, and the impact of VR implementation on a variety of applications. r 2005 Elsevier Ltd. All rights reserved.	experiment;heuristic;hierarchical database model;human factors and ergonomics;interaction technique;usability testing;virtual reality	Ioannis Karaseitanidis;Angelos Amditis;Harshada Patel;Sarah Sharples;Evangelos Bekiaris;Alexander H. Bullinger;Jolanda G. Tromp	2006	International Journal of Man-Machine Studies	10.1016/j.ijhcs.2005.08.013	simulation;visualization;human–computer interaction;computer science;operating system;virtual reality	Visualization	-61.97749166463184	-47.20680424926465	142061
ba656903ec37f0ad4544c1d03c97fb6b335691f5	an exploration of social grouping in robots: effects of behavioral mimicry, appearance, and eye gaze		People naturally and easily establish social groupings based on appearance, behavior, and other nonverbal signals. However, psychologists have yet to understand how these varied signals interact. For example, which factor has the strongest effect on establishing social groups? What happens when two of the factors conflict? Part of the difficulty of answering these questions is that people are unique and stochastic stimuli. To address this problem, we use robots as a visually simple and precisely controllable platform for examining the relative influence of social grouping features. We examine how behavioral mimicry, similarity of appearance, and direction of gaze influence peoples’ perception of which group a robot belongs to. Experimental data shows that behavioral mimicry has the most dominant influence on social grouping, though this influence is modulated by appearance. Non-mutual gaze was found to be a weak modulator of the perception of grouping. These results provide insight into the phenomenon of social grouping, and suggest areas for future exploration.	modulation;rf modulator;robot;weak value;xslt/muenchian grouping	Ahsan Nawroj;Mariya Toneva;Henny Admoni;Brian Scassellati	2014			psychology;cognitive psychology;social psychology;human physical appearance;experimental data;social relation;social group;perception;eye tracking;gesture;phenomenon	HCI	-51.90506958711558	-49.68965800363498	142155
66f735307cafb39b3fd511d86b2626b182f3edf2	how do people talk with a robot?: an analysis of human-robot dialogues in the real world	common ground;human robot interaction;human robot dialogue;interaction pattern;information interfaces and presentation;social norm;social robot;speech based interaction	This paper reports the preliminary results of a human-robot dialogue analysis in the real world with the goal of understanding users' interaction patterns. We analyzed the dialogue log data of Roboceptionist, a robotic receptionist located in a high-traffic area in an academic building [2][3]. The results show that (i) the occupation and background (persona) of the robot help people establish common ground with the robot, and (ii) there is great variability in the extent that users follow social norms of human-human dialogues in human-robot dialogues. Based on these results, we describe implications for designing the dialogue of a social robot.	norm (social);social robot;spatial variability	Min Kyung Lee;Maxim Makatchev	2009		10.1145/1520340.1520569	human–robot interaction;simulation;human–computer interaction;computer science;artificial intelligence;social robot;norm	Robotics	-52.56916497161939	-48.732879479631	142172
63125486fcd52c987268dd837c348572847d65a0	lacasa: location and context-aware safety assistant	prototypes;mobile computing;mobile devices;human computer interaction;accelerometers;risk management;decision support systems;decision theory	Wandering is a common behavior among people with dementia (PwD). It is also one of the main concerns of caregivers since it can cause the person to get lost and injured. The frequency and manner in which a person wanders is highly influenced by the person's background and contextual factors specific to the situation. In this paper we investigate some of the properties of wandering behaviours, particularly related to our ability to sense them with mobile devices. We then propose a novel decision-theoretic model that estimates the risk faced by the PwD and decides on the appropriate action to take, such as prompting the PwD or calling the caregiver. The model can be tailored to the user needs (e.g. known locations, level of cognitive decline) and takes into account uncertainty, and contextual information gathered from sensors, such as current location, noise, and proximity to the caregiver. A preliminary version of the system has been instantiated in a wandering assistance application for mobile devices running on an Android platform.	android;decision theory;interactivity;markov chain;mobile device;partially observable markov decision process;partially observable system;prototype;sensor;wandering set	Jesse Hoey;Xiao Yang;Eduardo Quintana;Jesús Favela	2012	2012 6th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops		embedded system;simulation;decision theory;human–computer interaction;risk management;computer science;artificial intelligence;operating system;mobile computing;computer security;statistics	Robotics	-57.896574630131404	-51.94886578394706	142255
99e1f9a41d152a3f26a1365269dfccffa208784f	designing an adaptive web navigation interface for users with variable pointing performance		Many online services and products require users to point and interact with user interface elements. For individuals who experience variable pointing ability due to physical impairments, environmental issues or age, using an input device (e.g., a computer mouse) to select elements on a website can be difficult. Adaptive user interfaces dynamically change their functionality in response to user behavior. They can support individuals with variable pointing abilities by 1) adapting dynamically to make element selection easier when a user is experiencing pointing difficulties, and 2) informing users about these pointing errors. While adaptive interfaces are increasingly prevalent on the Web, little is known about the preferences and expectations of users with variable pointing abilities and how to design systems that dynamically support them given these preferences.  We conducted an investigation with 27 individuals who intermittently experience pointing problems to inform the design of an adaptive interface for web navigation. We used a functional high-fidelity prototype as a probe to gather information about user preferences and expectations. Our participants expected the system to recognize and integrate their preferences for how pointing tasks were carried out, preferred to receive information about system functionality and wanted to be in control of the interaction. We used findings from the study to inform the design of an adaptive Web navigation interface, PINATA that tracks user pointing performance over time and provides dynamic notifications and assistance tailored to their specifications. Our work contributes to a better understanding of users' preferences and expectations of the design of an adaptive pointing system.	adaptive user interface;complex adaptive system;computer mouse;e-services;input device;prototype;user (computing);web navigation;world wide web	Aqueasha Martin-Hammond;Foad Hamidi;Tejas Bhalerao;Christian Ortega;Abdullah Ali;Catherine Hornback;Casey Means;Amy Hurst	2018		10.1145/3192714.3192818	input device;human–computer interaction;web navigation;user interface;computer science	HCI	-57.19773282199093	-44.721183665714264	142311
888b0c9c3e0c1cc4a0cfd26ef97b9eeab5b2c9ce	safe-in-place awareness gps system with distance-based and duration-based notification control	participatory design;safe in place gps system	This paper describes the design of SIPGPS (Safe-in-Place GPS System) which is a GPS assistance environment helping track the elderly people outdoors. This environment is intended to facilitate the use of the GPS cell phones in assisting elderly people with walking safely in daily life. SIPGPS facilitates safe-in-place by assisting elderly people with emergency assistance via distance-based and duration-based notification control. The SIPGPS which provides the dedicated family easier way to locate their elderly family may expand the role of care in remote location.		Chi Nung Chu;Gene Chu	2011		10.1007/978-3-642-21616-9_32	embedded system;simulation;computer science;computer security	Robotics	-50.25764686608956	-41.75618802917118	142604
7b1f33ad1cd7d5b9fdd4d4f0ac58bc0aff722d65	speech-driven embodied entrainment character system with hand motion input in mobile environment	human interaction;human communication;mobile environment;sensory evaluation;cellular phone;embodied communication;embodied interaction	InterActor is a speech-input-driven CG-embodied interaction character that can generate communicative movements and actions for entrained interactions. InterPuppet, on the other hand, is an embodied interaction character that is driven by both speech input-similar to InterActor-and hand motion input, like a puppet. Therefore, humans can use InterPuppet to effectively communicate by using deliberate body movements and natural communicative movements and actions. In this paper, an advanced InterPuppet system that uses a cellular-phone-type device is developed, which can be used in a mobile environment. The effectiveness of the system is demonstrated by performing a sensory evaluation experiment in an actual remote communication scenario.	brainwave entrainment;embodied cognition;interaction;mobile phone	Kouzi Osaki;Tomio Watanabe;Michiya Yamamoto	2007		10.1145/1322192.1322242	computer vision;interpersonal relationship;simulation;embodied agent;human communication	HCI	-50.23475882252208	-49.307252296132425	142787
135209f507e998acbd57812bc22f7e2338c3bafb	partially disembodied robot: social interactions with a robot's virtual body	disembodiment;embodiment;human robot interaction;social presence	We propose a novel social robot called partially disembodied robot. This system has the advantages of real-world robots and virtual agents, guaranteeing a high social presence without sacrificing space efficiency. The robot consists of body parts that mimic human hands and eyes in order to give the user visual feedback, and is able to react to human contact through 3D detection, thus allowing the possibility for the user to interact through touching the robot. We evaluated how our system regulates users' behaviors during the solving process of the Tower of Hanoi problem. First, the users solve a Tower of Hanoi problem while being helped by the robot, but without having defined its body. In the second phase, the users were asked to define the robot's body and to play with it using the different interactions implemented. Finally, they were asked to solve the Tower of Hanoi problem once again, this time with the robot's body they defined. We could observe that the presence of the robot was perceived much more clearly by the user after they defined the robot's body, and when they were able to physically interact with it. Users' social response to the robot also seemed to be mediated by their feelings about its social presence. Finally, we found that the shyness of the users can impact the size of the robot's body that they define.	interaction;robot;virtual body	Hirotaka Osawa;Thibault Voisin;Michita Imai	2012		10.1007/978-3-642-34103-8_44	simulation;engineering;artificial intelligence;social robot;communication;personal robot	Robotics	-50.60970121076493	-49.994911278617934	142930
14e868c255218c2f97417307605928c080c60a40	peripheral display of digital handwritten notes	peripheral display;field trial;handwritten notes;tablet pc;reminders;information interfaces and presentation;idea generation;ambient display;digital ink	We present a system for the peripheral display of digital handwritten notes, motivated by the joint observation that people seldom refer back to their notes and that these notes often contain useful information. We describe the user-led design of the system, incorporating interviews, paper prototypes, and interactive prototypes. A preliminary field trial of the system indicates that users derive value from the system both for low-distraction reminding and for serendipitous idea generation. These promising initial results suggest significant scope for future work.	paper prototyping;peripheral;recommender system	Gary Hsieh;Kenneth R. Wood;Abigail Sellen	2006		10.1145/1124772.1124815	human–computer interaction;ideation;multimedia;management;world wide web;computer graphics (images)	HCI	-53.25476779969081	-41.01907953117767	143202
03ac874720c694093aade1b8ef6bcfb2538af8c2	modality specific assessment of video game player's experience using the emotiv	video games;emotiv epoc;electroencephalographic;cognitive	A growing body of literature has emerged that focuses upon cognitive assessment of video game player experience. Given the growing popularity of video gaming and the increasing literature on cognitive aspects of video gamers, there is a growing need for novel approaches to assessment of the cognitive processes that occur while persons are immersed in video games. In this study, we assessed various stimulus modalities and gaming events using an off-the-shelf EEG devise. A significant difference was found among different stimulus modalities with increasingly difficult cognitive demands. Specifically, beta and gamma power were significantly increased during high intensity events when compared to low intensity gaming events. Our findings suggest that the Emotiv EEG can be used to differentiate between varying stimulus modalities and accompanying cognitive processes. 2015 Elsevier B.V. All rights reserved.	epoc (operating system);electroencephalography;emotiv systems;frequency band;futures studies;headset (audio);polystation;power supply	Timothy McMahan;Ian Parberry;Thomas D. Parsons	2015	Entertainment Computing	10.1016/j.entcom.2015.03.001	simulation;cognition;multimedia	HCI	-55.32166714486905	-49.18555746448609	143268
2d23c7539cd530014d9ea11c52c26df3bfd8f728	locality and privacy in people-nearby applications	people nearby applications;qualitative study;mobile computing;privacy;location based social networks	People-Nearby applications are becoming a popular way for individuals to search for new social relations in their physical vicinity. This paper presents the results of a qualitative study, based on 25 interviews, examining how privacy and locality are managed in these applications. We describe how location is used as a grounding mechanism, providing a platform for honest and truthful signals in the challenging process of forming new social relations. We discuss our findings by suggesting theoretical frameworks that can be used to analyze the social space induced by the applications, as well as to inform the design of new technologies that foster the creation of new social ties.	locality of reference;privacy	Eran Toch;Inbal Levi	2013		10.1145/2493432.2493485	computer science;qualitative research;operating system;internet privacy;mobile computing;privacy;world wide web;computer security;computer network	HCI	-58.731246157785044	-40.62163812552761	143397
42f23deda606acfa9e0ec2cae3d6ab1f60e74563	it's not all written on the robot's face	emotions;facial expressions;robot;context	Past work on creating robots that can make convincing emotional expressions has concentrated on the quality of those expressions, and on assessing people’s ability to recognize them in neutral contexts, without any strong emotional valence. It would be interesting to find out whether observers’ judgments of the facial cues of a robot would be affected by a surrounding emotional context. This paper takes its inspiration from the contextual effects found on our interpretation of the expressions on human faces and computer avatars, and looks at the extent to which they also apply to the interpretation of the facial expressions of a mechanical robot head. The kinds of contexts that affect the recognition of robot emotional expressions, the circumstances under which such contextual effects occur, and the relationship between emotions and the surrounding situation, are observed and analyzed. Design implications for believable emotional robots are drawn.	robot	Jiaming Zhang;Amanda J. C. Sharkey	2012	Robotics and Autonomous Systems	10.1016/j.robot.2012.05.017	robot;computer vision;emotion;computer science;emotional expression;artificial intelligence;facial expression	Robotics	-51.34599208668885	-50.79580772635235	143501
54953e2c58794df76687072abc4bcd6c3371e23b	measuring navigation efficiency in the ide	software;cognitive science;protocols;empirical study;mice;efficiency;interaction data;navigation efficiency measurement ui user interface source code software system ide integrated development environment;browsers;navigation;ide;navigation browsers user interfaces mice protocols software cognitive science;navigation effort;empirical study interaction data ide navigation effort efficiency productivity;productivity;user interfaces;user interfaces software engineering source code software	While coding, developers construct and maintain mental models of software systems to support the task at hand. Although source code is the main product of software development, the process involves navigating and inspecting entities beyond the ones that are edited by the end of a task. Developers use various user interfaces (UI) offered by the Integrated Development Environment (IDE) to navigate the complex, and often hidden, relationships between program entities. These UIs impose fixed navigation costs, in terms of the number of interactions that a developer is required to perform to reach an entity of interest. It is unclear to what extent the actual navigation effort differs from an ideal setting, and if there is any room for actual improvement. We present a preliminary empirical study, where we analyzed a corpus of IDE interaction data coming from 6 developers totaling more than 20 days of development activity. To measure the navigation efficiency, we compute a combination of different ideal settings and compare them against the observed navigation events. Our findings reveal that, on average, developers perform 1.5 to 19 times more navigation events than the ideal case. While different factors make the ideal setting unfeasible, we believe that this calls for novel approaches to support the navigation in integrated development environments.	entity;high availability;integrated development environment;interaction;mental model;pharo;programmer;recommender system;software development;software system;text corpus;user interface	Roberto Minelli;Andrea Mocci;Michele Lanza	2016	2016 7th International Workshop on Empirical Software Engineering in Practice (IWESEP)	10.1109/IWESEP.2016.11	turn-by-turn navigation;simulation;human–computer interaction;computer science;world wide web	SE	-51.66766831558423	-45.34364304306485	143691
ae92d4b21eaba91e77374cda5f5b1d7804999d6a	household indicators for developing innovative feedback technologies	energy efficiency;energy conservation;demand response;sweden;electronic mail;domestic appliances;energy efficient;wireless application protocol;home appliances;energy consumption domestic appliances energy conservation;energy efficiency electricity questionnaire sweden consumer s behavior;engineering and technology;teknik och teknologier;energy consumption;electricity;demand response measures household indicators innovative feedback technologies energy consumption;questionnaire;response rate;electricity home appliances energy consumption electronic mail educational institutions wireless application protocol knowledge engineering;consumer s behavior;knowledge engineering	Numerous studies have shown that households' consumption is an important part of the total energy consumed in different countries. However, there is very little work done on finding appropriate strategies of giving households' effective feedback on their energy consumption. This study analyzes several indicators that could be considered before analyzing residential overall energy consumption and providing information, feedback, or developing demand-response measures. A questionnaire sent out to 2000 households having 33% response rate shows that the total households' income and characteristics, occupants' age and users' energy attitudes and interest are the key components designing relevant energy information strategies.	feedback	Iana Vassileva;Fredrik Wallin;Yong Ding;Michael Beigl;Erik Dahlquist	2011	2011 2nd IEEE PES International Conference and Exhibition on Innovative Smart Grid Technologies	10.1109/ISGTEurope.2011.6162715	marketing;economy;business;commerce	Robotics	-60.18952730453343	-51.43534427926779	143900
588a298fbc5dda19829d98df0a96af2db38e75e4	let's talk topically with artificial agents! - providing agents with humanlike topic awareness in everyday dialog situations		Spoken interactions between humans are characterized by coherent sequences of utterances assigning a thematical structure to the whole conversation. Such coherence and the success of a meaningful and flexible dialog are based on the cognitive ability to be aware of the ongoing conversational topic. This paper presents how to enable such topically coherent conversations between humans and interactive systems by emulating humanlike topic awareness in artificial agents. Therefore, we firstly automated human topic awareness on the basis of preprocessed Wikipedia knowledge and secondly transferred such computer-based awareness to a virtual agent. As a result, we contribute to improve human-agent dialogs by enabling topical talk between human and artificial conversation partners.	automatic identification and data capture;cognition;cognitive science;coherence (physics);dialog system;emulator;german research centre for artificial intelligence;intelligent agent;interaction;requirement;sensor;systems architecture;wikipedia;dialog	Alexa Breuing;Ipke Wachsmuth	2012				AI	-53.014729434530224	-47.76539432128222	144072
22ed2d30b82b64522d84989b9a4291440bbb434a	supporting air traffic control collaboration with a tabletop system	air traffic control;interactive system design;collaboration;tabletop;multi user;multi touch;cscw;task allocation	Collaboration is key to safety and efficiency in Air Traffic Control. Legacy paper-based systems enable seamless and non-verbal collaboration, but trends in new software and hardware for ATC tend to separate controllers more and more, which hinders collaboration. This paper presents a new interactive system designed to support collaboration in ATC. We ran a series of interviews and workshops to identify collaborative situations in ATC. From this analysis, we derived a set of requirements to support collaboration: support mutual awareness, communication and coordination, dynamic task allocation and simultaneous use with more than two people. We designed a set of new interactive tools to fulfill the requirements, by using a multi-user tabletop surface, appropriate feedthrough, and reified and partially-accomplishable actions. Preliminary evaluation shows that feedthrough is important, users benefit from a number of tools to communicate and coordinate their actions, and the tabletop is actually usable by three people both in tightly coupled tasks and parallel, individual activities. At a higher level, we also found that co-location is not enough to generate mutual awareness if users are not engaged in meaningful collaboration.	advanced transportation controller;interactivity;multi-user;reification (computer science);requirement;seamless3d	Stéphane Conversy;Hélène Gaspard-Boulinc;Stéphane Chatty;Stéphane Valès;Carole Dupré;Claire Ollagnon	2011		10.1145/1958824.1958891	real-time computing;simulation;human–computer interaction;computer science;operating system;air traffic control;computer-supported cooperative work;management;world wide web;collaboration	HCI	-61.42987511048409	-40.08877904737987	144392
881dcea72165688e62973a3f25f223f9a5237f03	from context-aware to context-based: mobile just-in-time retrieval of cultural heritage objects		Cultural content providers face the challenge of disseminating their content to the general public. Meanwhile, access to Web resources shifts from desktop to mobile devices and the wide range of contextual sensors of those devices can be used to proactively retrieve and present resources in an unobtrusive manner. This proactive process, also known as just-in-time retrieval, increases the amount of information viewed and hence is a viable way to increase the visibility of cultural content. We provide a contextual model for mobile just-in-time retrieval, discuss the role of sensor information for its contextual dimensions and show the model’s applicability with a prototypical implementation. Our proposed approach enriches a user’s web experience with cultural content and the developed model can provide guidance for other domains.	desktop computer;just-in-time compilation;mobile device;sensor;unobtrusive javascript;web resource	Jörg Schlötterer;Christin Seifert;Wolfgang Lutz;Michael Granitzer	2015		10.1007/978-3-319-16354-3_90	multimedia	Web+IR	-53.861437423965754	-40.40737768186913	144552
31523ee33b3208de1493a85406e0caa63e84351e	will people keep the secret of a humanoid robot?— psychological intimacy in hri	trust;sociality;interaction patterns;human robot interaction;psychological intimacy;robot having secret	"""Will people keep the secret of a socially compelling robot who shares, in confidence, a """"personal"""" (robot) failing? Toward answering this question, 81 adults participated in a 20-minute interaction with (a) a humanoid robot (Robovie) interacting in a highly social way as a lab tour guide, and (b) with a human being interacting in the same highly social way. As a baseline comparison, participants also interacted with (c) a humanoid robot (Robovie) interacting in a more rudimentary social way. In each condition, the tour guide asks for the secret keeping behavior. Results showed that the majority of the participants (59%) kept the secret of the highly social robot, and did not tell the experimenter when asked directly, with the robot present. This percentage did not differ statistically from the percentage who kept the human's secret (67%). It did differ statistically when the robot engaged in the more rudimentary social interaction (11%). These results suggest that as humanoid robots become increasingly social in their interaction, that people will form increasingly intimate and trusting psychological relationships with them. Discussion focuses on design principles (how to engender psychological intimacy in human-robot interaction) and norms (whether it is even desirable to do so, and if so in what contexts)."""	baseline (configuration management);confidentiality;emoticon;failure;humanoid robot;human–robot interaction;personal robot;social robot;trust (emotion)	Peter H. Kahn;Takayuki Kanda;Hiroshi Ishiguro;Brian T. Gill;Solace Shen;Heather E. Gary;Jolina H. Ruckert	2015	2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2696454.2696486	human–robot interaction;simulation;computer science;artificial intelligence;trustworthy computing;sociality	Robotics	-52.257131512263356	-51.18411642381858	144566
1e34ca6dd63c1554e1132f33225b9e17d5e573b9	using a process graph to improve system-user knowledge sharing	user interface design methodologies;dynamical processes;erp system;business process model;enterprise wide systems;enterprise resource planning;knowledge sharing;user interface design;usability;community involvement	We present our approach to addressing a critical design issue affecting users of ERP systems: the lack of transparency of the underlying business process model. To enhance system-to-user communication involving complex process flows, we have implemented a dynamic process graph and a set of related task links that are displayed alongside the traditional ERP task interface. This solution can also benefit other applications involving prolonged processes that are unfamiliar to the user.	business process;erp;enterprise resource planning;process modeling	Tamara Babaian;Wendy T. Lucas;Heikki Topi	2007		10.1145/1234772.1234797	user interface design;usability;human–computer interaction;computer science;knowledge management;business process modeling	HCI	-61.75552503189591	-38.95535030758809	144715
f3076d055f557084c71e70ba3c95da915e935f50	cognitive load and usability analysis of r-map for the people who are blind or visual impaired	virtual sound;task performance;sonification;usability study;working memory load;cognitive load theory;assistive technology;ocr;working memory;visual impairment;cognitive load;android phone;usability	"""The ultimate goal of this work is to understand the confluence of cognitive load and usability studies in evaluating the performance of fully integrated assistive technology solutions. The platform used for this study is called, Reconfigured Mobile Android Phone (R-MAP). The focus of this study is to measure the cognitive load and perform usability analysis and use them as a guide to refine the design and improve the usability of the R-MAP. A """"secondary task performance"""" based procedure for measuring the cognitive load was used to study the R-MAP. The score of the secondary task performance was found to have strong relationship with the cognitive load, usability of the R-MAP and also the differences in performances among various categories of users."""	assistive technology;confluence;performance;usability	Gahangir Hossain;Akbar S. Shaik;Mohammed Yeasin	2011		10.1145/2038476.2038503	pluralistic walkthrough;component-based usability testing;cognitive walkthrough;simulation;usability;human–computer interaction;computer science;multimedia;cognitive load;heuristic evaluation;usability lab;usability inspection	HCI	-49.188258714601474	-45.58407870838403	144723
925a0a1f43dc3d0f99c2ebe697c1e4d3b098c45c	activating people with dementia using natural user interface interaction on a surface computer		Reminiscence Therapy can act as an effective and conducive method for increasing the Quality of Life (QoL) of people with dementia (PwD) when implemented properly. In addition to non-digital approaches, digitally enhanced systems can be built to elicit positive memories as well as emotions using multimodal interaction and digital content. In the same line, interactive multimedia systems can also be used to provide meaningful, engaging and joyful activities for PwD in order to further increase well-being and QoL.  The aim of this study was to investigate whether using natural user interfaces (NUI) provides benefits to interactive multimedia systems for PwD. Elaborated interaction possibilities should further facilitate the physical and mental activation of PwD as well as stimulate positive feelings, empowerment and joy. Since there are no applications available that satisfy the particular requirements of our user group, we developed an interactive aquarium application as our study object. The application supports touch gestures as well as tangible object interaction.  The application can be used to playfully activate and engage PwD. It can help to establish and to improve communication with PwD, promote positive feelings and, last but not least, be fun. The study demonstrated that interactive multimedia systems using NUI and object interaction are a promising approach to improve the QoL of PwD.	digital recording;multimodal interaction;natural user interface;requirement;surface computer;the quality of life	Ramazan Gündogdu;Alexander Bejan;Christophe Kunze;Matthias Wölfel	2017		10.1145/3154862.3154929	interactive media;distributed computing;natural user interface;computer science;human–computer interaction;surface computing;reminiscence therapy;gesture;digital content;multimodal interaction;user interface	HCI	-56.31156353340514	-43.86108252899701	144831
b366c7fdc0e5b3fa32cf53fa92ffacb56623bca8	maintaining the presence of remote speakers on telepresence robots by visual morphing to reduce loneliness		Telepresence robots can provide the sense that a remote person is physically present. However, this sense disappears suddenly once a call ends. Therefore, the speaker may feel loneliness. This study explores “tele-vestige” in which speakers can perceive the weak social presence of a remote speaker after a call ended. To provide this tele-vestige, the remote speaker's face is morphed into a telepresence robot's face after the call ends. We conducted an experiment to investigate the effect of this morphing technique on loneliness.	javaserver pages;morphing;robot;social presence theory;tele-artist;telerobotics;television	Hirokazu Yoshida;Fumihide Tanaka	2018	2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2018.8525537	loneliness;simulation;robot;morphing;telerobotics;computer science;robot kinematics	Robotics	-51.624546361070706	-50.44319904245789	144867
9b1a2ed1b7107dc848d24f4389e3489a56a9f89b	recommendation effects of a social robot for advertisement-use context in a shopping mall	social robot;advertisement;field trial	We developed a coupon-giving robot system for a shopping mall to explore possible applications using social robots in daily environments, particularly for advertising. The system provided information through conversations with people. The robot was semi-autonomous, which means that it was partly controlled by a human operator, to cope with the difficulty of speech recognition in real environments. We conducted two field trials to investigate two kinds of effectiveness related to recommendations: the presence of a robot and different conversation schemas. Although a robot can strongly attract people with its presence and interaction, it remains unknown whether it can increase the effects of advertisements in real environments. Our field trial results show that a small robot increased the number of people who printed coupons more than a normal-sized robot. The number of people who printed coupons also increased when the robot asked visitors to freely select from all coupon candidates or to listen to its recommendation.	autonomous robot;online advertising;printing;robotics;semiconductor industry;social robot;speech recognition	Masahiro Shiomi;Kazuhiko Shinozawa;Yoshifumi Nakagawa;Takahiro Miyashita;Toshio Sakamoto;Toshimitsu Terakubo;Hiroshi Ishiguro;Norihiro Hagita	2013	I. J. Social Robotics	10.1007/s12369-013-0180-4	simulation;multimedia;personal robot	Robotics	-49.815488173510495	-48.34657267091995	144883
b146dae1422bcc95147a1c09d9d0afad25f2b62a	an intelligent mobile commerce system with dynamic contents builder and mobile products browser	commerce electronique;tratamiento transaccion;electronic commerce;systeme intelligent;navegacion informacion;comercio electronico;mobile device;concepcion sistema;e commerce;navigation information;relacion orden;sistema inteligente;information browsing;ordering;commerce mobile;dynamical system;systeme dynamique;relation ordre;mobile commerce;system design;intelligent system;next generation;dynamic content;sistema dinamico;transaction processing;conception systeme;electronic trade;traitement transaction	Mobile commerce (MC) is expected to occupy an important part in electronic commerce in spite of a number of problems such as restriction of device, limited contents and expensive charge system. But the functions that can automatically extend the limited contents, which are provided for the MC and efficiently support commercial transaction on the expensive charge system, are essential for the activation of the MC. In this paper we propose a next generation intelligence mobile commerce system, which enables a series of e-commerce activities like searching, ordering and settlement on the mobile device including the functions mentioned above. The proposed system has been actually designed, implemented and confirmed its effectiveness through experiments.	mobile commerce	Sera Jang;Eunseok Lee	2002		10.1007/3-540-45675-9_30	e-commerce;embedded system;mobile search;simulation;mobile commerce;transaction processing;order theory;computer science;operating system;dynamical system;dynamic web page;mobile device;database;computer security;systems design	Mobile	-52.56788624023519	-41.58221265779137	144911
1082db9065ea5b3f9a3c111a7ac46cd1a295ff08	twistersearch: supporting social search with tabletop and mobile displays	post wimp;tabletop and tangible interaction;sysdemo;inproceedings;social search	This demo presents TwisterSearch, a system for co-located and collaborative Web search that was designed in accordance with the canonical model of social search by Evans and Chi (2009). In a first phase before search, participants frame the context of the intended search and thereafter gather initial information requirements on a tabletop. These requirements are then refined through discussion and yield the foundation for the search task itself, which is performed in parallel on multiple mobile displays. These private devices are used to search the Web for evidence files and to populate the visual workspace of the tabletop with them. Moreover, the personal device allows both a highly parallel search as well as a tightly-coupled collaborative search, to enable seamless switching between collective and solitary search activities. In our TwisterSearch demo, participants can have a firsthand experience of these different individual phases of social search.	chi;canonical model;population;requirement;seamless3d;social search;web search engine;workspace;world wide web	Roman Rädle;Hans-Christian Jetter;Harald Reiterer	2012			human–computer interaction;multimedia;world wide web	HCI	-53.27455122056713	-41.619454582618246	144951
9c1c7611ba2110fe9fe5da81a6f59d1d65d92b95	putting locative technology in its sense of place	mobility management mobile radio;decision support systems societies;mobility management mobile radio mobile computing;geotargetted information sense ofplace location based services place theory locative media;mobile computing;locative technology social elements personal experience information behaviour diverse information sources sense of place role location based services exploratory survey study mobile devices ubiquitous technology	Our relationship to the places we inhabit and encounter is considered a foundational human experience. As we interact and learn about places, we bestow meaning on such places, forming the mental concept of a sense of place. Although our relationships to place have been considered since antiquity, new ubiquitous technologies, specifically mobile devices and location-based services, may be altering people's everyday relationships to place. This paper reports on an exploratory survey study conducted to provide groundwork for understanding the elements that comprise sense of place and the role location-based services may play. It was found that sense of place arises from diverse information sources, is multimodal, and is individualistic. The survey confirmed the importance of personal experience as a valuable and primary means to form a sense of place. Yet, respondents engaged in a diverse range of information behaviour, which was integral in forming their sense of place. The functionality and information provided by location-based services worked with personal experience and social elements that foster a sense of place.	location-based game;location-based service;mobile device;multimodal interaction	Glen Farrelly	2013	2013 IEEE International Symposium on Technology and Society (ISTAS): Social Implications of Wearable Computing and Augmediated Reality in Everyday Life	10.1109/ISTAS.2013.6613125	geography;knowledge management;communication;social psychology	HCI	-58.41699023360813	-40.836200835730345	145057
5fb739fc0aa0d1f681e28fbfbaae8284a42332c8	towards touch screen live instruments with less risk: a gestural approach		Although touch screen interfaces such as smartphones and tablet PCs have become an important part of our life and are being used in almost every situation, these interfaces are facing some difficulties in being used in live musical performances, despite the numerous benefits they can musically offer. Among those difficulties, we identify and focus on the visual dedication requirement of interaction and nevertheless high risk of making mistakes, and design a simple musical interface aiming to alleviate these problems. In order to reduce visual dedication, we employ larger on-screen controls. To reduce risk of mistakes, we choose a gestural approach and incorporate plucking gestures, which require users to pull and release a touch after initiated. The interface is qualitatively tested, focusing on playability, visual dedication, and risk of making mistakes. While playability and risk received positive feedbacks, reducing visual dedication received partial agreement and seems to require further investigation. Although the interface is yet immature and too simple to be used on stage, we believe that identifying and solving the problems that touch screens have while being used in live situations is meaningful and valuable to discuss.	performance;smartphone;tablet computer;touchscreen	Edward Jangwon Lee;Woon Seung Yeo	2014			simulation;engineering;multimedia;communication	HCI	-49.91451890315254	-45.70932242593758	145090
6475c4d1c307b4d9e825116c1ca9b0bb72907dd9	tests of cognitive training as archetypes in elderly people - identifying design categories for cognitive and communicative interaction				R. Isabel Rojas ClaudiaIsabelRojas;M. Alberto Castillo JuanAlbertoCastillo	2016		10.1007/978-3-319-39943-0_36	psychology;psychiatry;physical medicine and rehabilitation;clinical psychology	HCI	-55.95073784500144	-51.544280712263124	145225
d94773e2f7f6bd703dd80416130b5f647233616f	advanced user assistance for setting up a home theater		In many situations of daily life, such as in educational, work-related, or social contexts, one can observe an increasing demand for intelligent assistance systems. In this chapter, we show how such assistance can be provided in a wide range of application scenarios – based on the integration of user-centered planning with advanced dialog and interaction management capabilities. Our approach is demonstrated by a system that assists a user in the task of setting up a complex home theater. The theater consists of several hi-fi devices that need to be connected with each other using the available cables and adapters. In particular for technically inexperienced users the task is quite challenging due to the high number of different ports of the devices and because the used cables might not be known to the user. Support is provided by presenting a detailed sequence of instructions that solves the task.	automated planning and scheduling;bertrand (programming language);blue (queue management algorithm);experience;home theater in a box;user-centered design;dialog	Pascal Bercher;Felix Richter;Thilo Hoernle;Thomas Geier;Daniel Höller;Gregor Behnke;Florian Nielsen;Frank Honold;Felix Schüssel;Stephan Reuter;Wolfgang Minker;Michael Weber;Klaus C. J. Dietmayer;Susanne Biundo-Stephan	2017		10.1007/978-3-319-43665-4_24	simulation;port (computer networking);dialog box;user assistance;computer science	HCI	-52.097933031659096	-39.96502949305524	145297
8df4b26e041f406dda2fb5cd04f41f07c19dbf15	use of large sample sizes and multiple evaluation methods in human-robot interaction experimentation		This paper presents details on planning and designing human studies for Human-Robot Interaction. There is a discussion of the importance of using large sample sizes to better represent the populations being investigated in order to have a better chance of obtaining statistically significant results for small to medium effects. Coverage of the four primary methods of evaluation are presented: (1) self-assessments, (2) behavioral observations, (3) psychophysiological measures, and (4) task performance metrics. The paper discusses the importance of using multiple methods of evaluation in order to have reliable and accurate results and to obtain convergent validity. Recommendations for planning and designing a large-scale, complex human study are detailed as well as lessons learned from a recent study that was conducted using 128 participants, four methods of evaluation, and a high fidelity, simulated disaster site.	human–robot interaction;population;recommender system	Cindy L. Bethel;Robin R. Murphy	2009			artificial intelligence;machine learning;computer science;sample size determination;convergent validity;human study;human–robot interaction;high fidelity	HCI	-58.98922793562712	-49.20268113750547	145302
e35ce51091a24fb63a9dabd2cc9cb85cecab79fe	route communication in dialogue: a matter of principles	route instruction;dialogue paradigm;present study;route communication;communicative action;visual co-presence;real-time interaction;conversation pattern	The present study uses the dialogue paradigm to explore route communication. It revolves around the analysis of a corpus of route instructions produced in real-time interaction with the follower. It explores the variation in forming route instructions and the factors that contribute in it. The results show that visual co-presence influences the performance, conversation patterns and configuration of instructions. Most importantly, the results suggest an analogy between the choices of instructiongivers and the communicative actions of their partners. 1.1 Spatial language in dialogue The main question this paper attempts to address is how people produce route instructions in dialogue. The current zeitgeist in language research and dialogue system development seems to be the unified investigation of spatial language and dialogue (Coventry et al., 2009). Indicative of the growing prioritisation of dialogue in the study of spatial language are the on-going research efforts within the MapTask 1 project and the GIVE challenge 2 . 1.2 A framework for the analysis of route	dialog system;programming paradigm;real-time transcription;text corpus;zeitgeist	Theodora Koulouri;Stanislao Lauria	2010			computer science;artificial intelligence;communication;social psychology	NLP	-52.90166713343182	-47.684959614657174	145317
0cc301c038a83679a596b7de4ddf8b729b814612	framework for ubiquitous social networks		This paper presents a novel framework for ubiquitous social networks (USNs). Instead of making virtual connections, on the basis of human social networks, an effort has been made to facilitate interactions among human social networks with the help of virtual social networks. The imperative domains that support ubiquitous social networks are highlighted and different scenarios are provided to project real world applications of proposed framework. Our proposed framework can provide preliminary foundations for creating “ubiquitous social networks” in true essence. Keywords– Ubiquitous computing, ubiquitous social network, ubiquitous wearable computers, social networks, wearable computers, mobile ubiquitous computing.	imperative programming;interaction;prototype;real life;social network	Atta ur Rehman Khan;Mazliza Othman;Abdul Nasir Khan;Imran Ali Khan	2012	CoRR		evolving networks;knowledge management;socioeconomics;sociology;social psychology	HCI	-58.35799523304036	-40.0265763310712	145321
efe7f65c55448d14e0638661ef680759ddade132	an evaluation framework for the design concepts of tangible interface on new collaborative work support system	user needs;collaborative work;hta;trend analysis;tangible interface;satisfiability;scenario;support system;conceptual design;support group;technology trends analysis;concept evaluation;user requirements;cpv;hierarchical task analysis;functional requirement;evaluation framework;new products	This study aims to suggest a systematic evaluation framework to evaluate design concepts of a new product at the conceptual design phase based on users' requirements and tasks, development trends of relevant technologies, and the CPV. The proposed framework to evaluate design concepts of a new product consists of three phases. In phase 1, we identify and analyze users' needs, functional requirements and their expected tasks by utilizing user scenario-based analysis and hierarchical task analysis. In phase 2, by deploying a relevant technology roadmap, we investigate technology alternatives for satisfying the user needs or functional requirements. In phase 3, we evaluate the design concepts using evaluation checklist, which is based on functional requirements derived from relationships analysis, utilizing CPV attribute for a quantifiable measure. A case study was demonstrated to evaluate the design concepts of a new CSCW-based tangible interface that was recently designed to support group decision making activities.	tangible user interface	Youngbo Suh;Cheol Lee;Joobong Song;Minjoo Jung;Myung Hwan Yun	2007		10.1007/978-3-540-73107-8_133	concentrated photovoltaics;html application;human–computer interaction;trend analysis;computer science;knowledge management;scenario;user requirements document;data mining;task analysis;conceptual design;functional requirement;satisfiability	HCI	-62.196602674660674	-46.15359490201826	145385
675f265c425e3dcb7b3822454ac3a082e73a489f	intelligent and interactive companion combined with wearable technology and re-creatable environment to avoid anxiety.				Hashini Senaratne	2017		10.14236/ewic/HCI2017.19	wearable technology;human–computer interaction;anxiety;computer science	HCI	-53.55347829192337	-43.00281883547098	145416
7cc09e19632a4430a2ff50a10fe8413eeee10fa3	ubiquitous accessibility for people with visual impairments: are we there yet?	k.4.2 computers and society: social issues;ubiquitous accessibility;mobile computing;multiple screen readers;remote access;visually impaired users	Ubiquitous access is an increasingly common vision of computing, wherein users can interact with any computing device or service from anywhere, at any time. In the era of personal computing, users with visual impairments required special-purpose, assistive technologies, such as screen readers, to interact with computers. This paper investigates whether technologies like screen readers have kept pace with, or have created a barrier to, the trend toward ubiquitous access, with a specific focus on desktop computing as this is still the primary way computers are used in education and employment. Towards that, the paper presents a user study with 21 visually-impaired participants, specifically involving the switching of screen readers within and across different computing platforms, and the use of screen readers in remote access scenarios. Among the findings, the study shows that, even for remote desktop access - an early forerunner of true ubiquitous access - screen readers are too limited, if not unusable. The study also identifies several accessibility needs, such as uniformity of navigational experience across devices, and recommends potential solutions. In summary, assistive technologies have not made the jump into the era of ubiquitous access, and multiple, inconsistent screen readers create new practical problems for users with visual impairments.	accessibility;area striata structure;assistive technology;circuit complexity;computation (action);computers;desktop computer;desktop virtualization;interface device component;operating system;personal computer;remote desktop software;screen reading;self-help devices;smartphone;solutions;usability testing;virtual desktop	Syed Masum Billah;Vikas Ashok;Donald E. Porter;I. V. Ramakrishnan	2017	Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference	10.1145/3025453.3025731	human–computer interaction;multimedia;computer science;mobile computing	HCI	-49.07978597404773	-41.7346853063706	145457
2c49262a67745d385805b28404e0181511f5117b	why is this happening to me?: how player attribution can broaden our understanding of player experience		Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.	conceptualization (information science);theory;user research	Ansgar E. Depping;Regan Lee Mandryk	2017		10.1145/3025453.3025648	simulation;multimedia	HCI	-57.24208824144541	-47.97380605429881	145462
5508e79cce8547935ebdb1e6b5c345ac7acf62fc	employing affection in elderly healthcare serious games interventions	serious games;cognitive exercise;physical training;guidelines;affective computing	Serious games for elderly healthcare provide a promising and novel way to promote the well-being of senior citizens. The gaming environment, originally designed for a younger target population, benefits from the increasing power of personal computers, mobiles devices (phones, tablets) and SmartTVs, as well as the recent emergence of motion capture technology developed for videogame consoles via worn physical sensors and controller free sensors. Measuring self-efficacy by elderly individuals on such gaming environments has characterized them in terms of their effectiveness to motivate an audience reluctant to undertake more conventional forms of activities. However, the relationship between the features making the game challenging and the senior user's behaviour in becoming motivated so as to interact with the system independently and effectively is still elusive. For instance, failure in understanding the game's instructions or adapting to the speed and complexity may be thought of as barriers that affect the seniors' satisfactory interaction within the gaming environment. A step towards this direction would require using emotions in the midst of the gaming environment so as to allow for the embodiment of real-time mental (cognitive and emotional), and physical data. The main goal is to focus on assessing the features that encourage the elderly individuals to interact with the gaming environment on a daily basis. We propose to further enhance the gaming environment through the use of personal biosensors (i.e. wireless EEG) and cameras (i.e. fisheye camera) so as to collect the user's mental and physical changes over time and fuse them in a decision support system. This information will eventually provide feedback on the gaming experience so as to modify it according to the user's affective state.	decision support system;electroencephalography;emergence;fisheye;motion capture;personal computer;real-time transcription;sensor;tablet computer;whole earth 'lectronic link;windows mobile	Charis Styliadis;Evdokimos I. Konstantinidis;Antonis Billis;Panagiotis D. Bamidis	2014		10.1145/2674396.2674456	embedded system;simulation;human–computer interaction;computer science;artificial intelligence;affective computing;multimedia;physical fitness;computer security	HCI	-56.968987080060444	-51.199089251771824	145469
256e0d53abf8b8191086e70946b66a3092d4418e	canine-centered interface design: supporting the work of diabetes alert dogs	user centered design;diabetes alert dog;human animal interaction;multispecies ethnography;animal computer interaction	Many people with Diabetes live with the continuous threat of hypoglycemic attacks and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset of an attack before the condition of the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alarm system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on the requirements for a physical canine user interface, involving dogs, their handlers and specialist dog trainers in the design process. We discuss tensions between the requirements for canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics, and reflect on how we can move from designing for dogs to designing with dogs.	onset (audio);requirement;user interface	Charlotte L. Robinson;Clara Mancini;Janet van der Linden;Claire Guest;Robert Harris	2014		10.1145/2556288.2557396	user-centered design;simulation;human–computer interaction;computer science	HCI	-50.8085861594591	-45.89779584643264	145680
02cb5ec1db975e5c20137dd9fa78a9195fad0441	moodscope: building a mood sensor from smartphone usage patterns	mood-enabled application;daily mood average;usage history;initial accuracy;formative statistical study;smartphone usage pattern;physical property;measure acceleration;first-of-its-kind smartphone software system;important input;formative statistical mood study;mood-sharing social application;mental state;mood sensor;moodscope api;smartphone-logged data;communication history;application usage pattern;machine learning;affective computing;computer engineering	"""We present MoodScope, a software system which infers the mood of its user based on how the smartphone is used. Similar to smartphone sensors that measure acceleration, light, and other physical properties, MoodScope is a """"sensor"""" that measures the mental state of the user and provides mood as an important input to context-aware computing. We run a formative statistical study with smartphone-logged data collected from 32 participants over two months. Through the study, we find that by analyzing communication history and application usage patterns, we can statistically infer a user's daily mood average with an accuracy of 93% after a two-month training period. Motivated by these results, we build a service, MoodScope, which analyzes usage history to act as a sensor of the user's mood."""	context awareness;mental state;sensor;smartphone;software system	Robert LiKamWa;Yunxin Liu;Nicholas D. Lane;Lin Zhong	2013		10.1145/2462456.2483967	simulation;computer science;operating system;affective computing;multimedia;mobile computing;world wide web	Mobile	-59.89260651957549	-50.864083420846455	145760
5aea0d72e8282350600c02172169f61c556626f9	supporting negotiation behavior with haptics-enabled human-computer interfaces	computers;human computer interaction;haptic i o;game theory;haptic user interfaces;performance;tit for tat negotiation strategy haptics enabled human computer interfaces human computer interaction real life interaction scenarios computer systems behavioral patterns human human negotiation scenarios two party negotiation game haptic cues audio visual cues negotiation related behavior conveyance real time continuous two party negotiation scenario game theory negotiation literature computer opponent concession behavior competition behavior negotiation behavior human recognition accuracy machine displayed behavior;journal article;force;haptic negotiation;computational modeling;human factors;games;robots;haptic negotiation human factors experimentation haptic i o haptic user interfaces haptic guidance dynamic systems and control multimodal systems virtual environment modeling performance;human computer interaction game theory haptic interfaces;virtual environment modeling;multimodal systems;humans;haptic interfaces;experimentation;haptic interfaces computers humans games computational modeling robots force;haptic guidance;dynamic systems and control	An active research goal for human-computer interaction is to allow humans to communicate with computers in an intuitive and natural fashion, especially in real-life interaction scenarios. One approach that has been advocated to achieve this has been to build computer systems with human-like qualities and capabilities. In this paper, we present insight on how human-computer interaction can be enriched by employing the computers with behavioral patterns that naturally appear in human-human negotiation scenarios. For this purpose, we introduce a two-party negotiation game specifically built for studying the effectiveness of haptic and audio-visual cues in conveying negotiation related behaviors. The game is centered around a real-time continuous two-party negotiation scenario based on the existing game-theory and negotiation literature. During the game, humans are confronted with a computer opponent, which can display different behaviors, such as concession, competition, and negotiation. Through a user study, we show that the behaviors that are associated with human negotiation can be incorporated into human-computer interaction, and the addition of haptic cues provides a statistically significant increase in the human-recognition accuracy of machine-displayed behaviors. In addition to aspects of conveying these negotiation-related behaviors, we also focus on and report game-theoretical aspects of the overall interaction experience. In particular, we show that, as reported in the game-theory literature, certain negotiation strategies such as tit-for-tat may generate maximum combined utility for the negotiating parties, providing an excellent balance between the energy spent by the user and the combined utility of the negotiating parties.	acclimatization;adaptive behavior;audio media;behavior, adaptive;behavioral pattern;computer systems;conflict (psychology);expectation–maximization algorithm;experiment;game theory;hallucinations, tactile;haptic device component;haptic technology;human–computer interaction;human–robot interaction;nist hash function competition;optic nerve glioma, childhood;real life;real-time locating system;robot;usability testing	Salih Ozgur Oguz;Ayse Küçükyilmaz;T. Metin Sezgin;Cagatay Basdogan	2012	IEEE Transactions on Haptics	10.1109/TOH.2012.37	robot;games;game theory;simulation;human–computer interaction;performance;computer science;artificial intelligence;human factors and ergonomics;multimedia;computational model;force	HCI	-50.83061332116621	-49.40427781844771	145869
792155e714305da79a2bc664a7b8782dcd0719dc	verbal design: a participatory design approach with illiterate patient user groups		This paper presents a Participatory Design approach focused on applying primarily Verbal Design techniques working alongside illiterate People with Diabetes (PWD) from low socio-economic groups in Pakistan. After gathering a set of initial findings through classic Participatory Design and encountering several challenges, we discuss the development of our Verbal Design Approach in response which uses Narrative Scoping and Persona along with Invisible Design videos to structure and drive discussion and document design. Preliminary work showed that the approach resonated with our illiterate participants.	scope (computer science)	Kehkashan Zeb;Stephen Lindsay;Suleman Shahid;Matt Jones	2018		10.1145/3197391.3205448	engineering;persona;multimedia;participatory design;narrative;information design	HCI	-59.929223767205116	-38.109574329531114	145964
96409575ec40f92fc1ca2a2880e7b676cf34f001	the wot as an awareness booster in agile development workspaces		Continuous feedback is one of the most important concepts in agile development. We argue for the need to increase the awareness that the team maintains of various facets of the development activity. We then introduce iFLUX, an event-driven middleware designed for the Web of Things. We explain how it provides a platform that facilitates the creation of augmented workplaces that connect various information sources with physical displays, also known as information radiators.	agile software development;booster (electric power);workspace	Olivier Liechti;Jacques Pasquier-Rocha;Laurent Prévost;Pascal Gremaud	2016		10.1007/978-3-319-38791-8_56	simulation	Robotics	-60.57588905398882	-39.75258820133878	146171
b704f37bca6060e017aa6cb51a655cad6bdd970a	the gamification user types hexad scale	user types;gameful design;hexad;gamification	Several studies have indicated the need for personalizing gamified systems to users' personalities. However, mapping user personality onto design elements is difficult. Hexad is a gamification user types model that attempts this mapping but lacks a standard procedure to assess user preferences. Therefore, we created a 24-items survey response scale to score users' preferences towards the six different motivations in the Hexad framework. We used internal and test-retest reliability analysis, as well as factor analysis, to validate this new scale. Further analysis revealed significant associations of the Hexad user types with the Big Five personality traits. In addition, a correlation analysis confirmed the framework's validity as a measure of user preference towards different game design elements. This scale instrument contributes to games user research because it enables accurate measures of user preference in gamification.	factor analysis;gamification;repeatability;user (computing);user research;video game design	Gustavo Fortes Tondello;Rina R. Wehbe;Lisa Diamond;Marc Busch;Andrzej Marczewski;Lennart E. Nacke	2016		10.1145/2967934.2968082	engineering;knowledge management;multimedia;world wide web	HCI	-60.535376396259295	-46.52736369622187	146534
b5f85bb150e847439ed49766fd2fb88ec3ebc881	tools for dynamics simulation of robots: a survey based on user feedback		The number of tools for dynamics simulation has grown in the last years. It is necessary for the robotics community to have elements to ponder which of the available tools is the best for their research. As a complement to an objective and quantitative comparison, difficult to obtain since not all the tools are open-source, an element of evaluation is user feedback. With this goal in mind, we created an online survey about the use of dynamical simulation in robotics. This paper reports the analysis of the participants’ answers and a descriptive information fiche for the most relevant tools. We believe this report will be helpful for roboticists to choose the best simulation tool for their researches.	dynamical simulation;open-source software;robot;robotics	Serena Ivaldi;Vincent Padois;Francesco Nori	2014	CoRR		simulation;human–computer interaction;computer science;artificial intelligence;multimedia	Robotics	-59.22671740234661	-48.94217386981075	146566
7eecbe409ed230a4c70203cd0e4e3f9f0d62fd88	eliciting gestural feedback in chinese and swedish informal interactions	swedish;eliciting;gestural;feedback;emotion;chinese;attitude	In this paper, how people use gestural feedback to elicit further interaction is studied in Chinese and Swedish intercultural and mono-cultural interactions. The results can be used to make the intelligent virtual agents in Chinese and Swedish communication contexts behave more human-like.	interaction	Jia Lu	2012		10.1007/978-3-642-33197-8_52	attitude;psychology;emotion;feedback;multimedia;communication;social psychology;chinese	HCI	-52.77955373192681	-48.74387859792051	146572
3294a0e19a185e5821efd8aa258b1142e8d6cfbd	space is part of the product: using attrakdiff to identify spatial impact on user experience with media façades		In HCI research, the user experience (UX) in response to interactive public installations, media façades and displays is frequently evaluated using the AttrakDiff questionnaire. The latent assumption is that its result is invariant to changes over time, environment and context. While previous research analyzed the impact of time as single variable, studies have not yet investigated environment or context. At the same time, researchers and practitioners appear to have the intuitive assumption that interaction with any media façade is best experienced from the middle at a distance which is 'convenient' to watch. We investigated the temporal, spatial and contextual impact on AttrakDiff's user rated pragmatic and hedonic qualities and attractiveness. Analysis revealed that interacting from different positions in close vicinity (<15m) parallel to the media façade did not significantly influence UX. Ratings were mostly invariant when conducting the study at two different lived environments; and short-timed repeated measures using AttrakDiff did not cause a decline in participants' ratings.	a/ux;human–computer interaction;relevance;user experience	Patrick Tobias Fischer;Saskia F. Kuliga;Mark Eisenberg;Ibni Amin	2018		10.1145/3205873.3205875	multimedia;user experience design;attractiveness;invariant (mathematics);computer science;facade	HCI	-58.41993050338084	-45.81936378110946	146578
6d11f568bfcf4b85a0dabcc004757585d6d33a1d	social recipe recommendation to reduce food waste	persuasive technology;food waste;mobile computing;recommendation systems	Little attention has been given to food waste prevention in households by changing consumers' behaviors. In this paper, we present a social recipe recommender which is a mobile application being developed to reduce food waste in households by recommending recipes to a group of connected people. The application will allow the logging of food and waste related daily practices and will persuade a group of users to share their food by recommending recipes based on available ingredients within this group. The method of data collection, persuasion and the experiments are described through this paper.	experiment;mobile app;recommender system	Fulya Yalvaç;Veranika Lim;Jun Hu;Mathias Funk;Matthias Rauterberg	2014		10.1145/2559206.2581226	computer science;operating system;persuasive technology;mobile computing	AI	-59.35500510051376	-51.32211039798072	146918
6a927b0ce529c8bff4507cd24f0498581a353054	desafios da computação ubíqua por uma visão de ihc	human computer interaction;user experience;ubiquitous computing	Ubiquitous computing is characterized by the technology embedded in everyday devices, changing the way users interact with applications. This paper presents an impact analysis of scale, context, transparency and privacy and its implications for the field of Human-Computer Interaction, presenting also examples of commercial applications and suggestions for the Brazilian market.	design of the fat file system;power-on reset	Leticia Ramos;Roberto Cesar Betini	2014			user experience design;simulation;human–computer interaction;computer science;multimedia;ubiquitous computing	Crypto	-55.63288421614634	-41.00690112709275	147050
d651e7718d3954debdf5d7c1993c285b49e6fcfc	designing for movement: the case of sports	manniska maskin interaktion mmi;accelerometer data;systemvetenskap informationssystem och informatik;information systems;sensors;interaction;man machine interaction mmi;sports;interviews;design;movement;feeling	We have identified six themes we identified as interesting for future work in movement based interaction design for sports: the central position of the subjective feeling, the core of sports is enough, feeling did not prevent injury, non-interpretive representations, the shortcomings of logging biodata, and temporality of feedback. The themes are grounded in technical explorations for golf and running and a set of interviews with athletes. Here, we outline findings from our work to illustrate these themes.	interaction design	Stina Nylander;Jakob Tholander	2014		10.1145/2617995.2618018	simulation;engineering;artificial intelligence;communication	HCI	-55.95787078589944	-42.491948208401716	147098
bdb0fbb94f9bb54660ffce1e62bcc9d44b7dfcac	a dynamic multimodal approach for assessing learners' interaction experience	flow;interaction experience;stuck;dynamic bayesian networks;emotional responses;biofeedback sensing;off task	In this paper we seek to model the users' experience within an interactive learning environment. More precisely, we are interested in assessing three extreme trends in the interaction experience, namely flow (a perfect immersion within the task), stuck (a difficulty to maintain focused attention) and off-task (a drop out from the task). We propose a hierarchical probabilistic framework using a dynamic Bayesian network to simultaneously assess the probability of experiencing each trend, as well as the emotional responses occurring subsequently. The framework combines three-modality diagnostic variables that sense the learner's experience including physiology, behavior and performance, predictive variables that represent the current context and the learner's profile, and a dynamic structure that tracks the temporal evolution of the learner's experience. We describe the experimental study conducted to validate our approach. A protocol was established to elicit the three target trends as 44 participants interacted with three learning environments involving different cognitive tasks. Physiological activities (electroencephalography, skin conductance and blood volume pulse), patterns of the interaction, and performance during the task were recorded. We demonstrate that the proposed framework outperforms conventional non-dynamic modeling approaches such as static Bayesian networks, as well as three non-hierarchical formalisms including naive Bayes classifiers, decision trees and support vector machines.	conductance (graph);decision tree;dynamic bayesian network;electroencephalography;experiment;immersion (virtual reality);modality (human–computer interaction);multimodal interaction;naive bayes classifier;pulse;support vector machine	Imene Jraidi;Maher Chaouachi;Claude Frasson	2013		10.1145/2522848.2522896	computer vision;simulation;speech recognition;flow;emotion;computer science;artificial intelligence;machine learning;dynamic bayesian network	HCI	-55.53160268625715	-48.823023345608675	147138
dfa9c7612b73ff936fda85f59f53850aeb0d7499	introducing ambient assisted living technology at the home of the elderly: challenges and lessons learned	elderly;appropriation;ambient assisted living;design implications;technology acceptance	The promise of pervasive computing applications is to surround people with affordable, transparent and unobtrusive technology. However, several barriers including usability concerns, a lack of perceived usefulness, and low technology self-efficacy may jeopardize the successful adoption of ambient assisted living AAL systems, particularly by the elderly. Following the development of the SocialConnector system, which mediates and coordinates the communication effort of family members with their elders, this paper describes the iterative design process conducted to help improve the acceptance of the system by end-users. This process considered the implicit and explicit concerns and expectations of the intended target users, and it involved three improvement cycles along an action research approach. Through this process, we obtained a set of lessons learned that aim to describe how to unobtrusively introduce sensing and monitoring technology at the home of the elderly. Keeping simple yet meaningful interaction metaphors helps increase the learnability and perceived usefulness of AAL technology by the elderly.If older adults perceive the value of having such kinds of tools installed in their homes, then they are prone to assume them as part of their lives. Likewise, situational and activity awareness mechanisms, such as visual notification badges and audio-enhanced user interfaces, can be used to persuade the elderly to approach the system and eventually use it. Finally, the design of AAL solutions also requires active consideration of the needs and attitudes of other family members, particularly those who assume an active role in the caring process of their elders.		Diego Muñoz;Francisco J. Gutierrez;Sergio F. Ochoa	2015		10.1007/978-3-319-26410-3_12	simulation;human–computer interaction	HCI	-58.906104239054336	-42.37531119692802	147191
78c78da84244db46acb43d21344514695ab08684	on the use of visualization to support awareness of human activities in software development: a survey and a framework	assessment tool;visualization;computer supported collaborative work;awareness;software development;human activity;formative evaluation	This paper proposes a framework for describing, comparing and understanding visualization tools that provide awareness of human activities in software development. The framework has several purposes -- it can act as a formative evaluation mechanism for tool designers; as an assessment tool for potential tool users; and as a comparison tool so that tool researchers can compare and understand the differences between various tools and identify potential new research areas. We use this framework to structure a survey of visualization tools for activity awareness in software development. Based on this survey we suggest directions for future research.	software development	Margaret-Anne D. Storey;Davor Cubranic;Daniel M. Germán	2005		10.1145/1056018.1056045	awareness;visualization;human–computer interaction;computer science;knowledge management;software development;formative assessment	HCI	-61.61023672966435	-44.88637047123586	147325
0e21d5a6ba5a7ad2a97e58a86daa5f5e3a87950d	intentions to use information technologies: an integrative model	integrative model;user development;integrable model;information technology;user expectations;user characteristics;user attitudes	An integrative model explaining intentions to use an information technology is proposed. The primary objective is to obtain a clearer picture of how intentions are formed, and draws on previous research such as the Technology Acceptance Model (Davis, Bagozzi, & Warshaw, 1989) and the Decomposed Theory of Planned Behavior (Taylor & Todd, 1995a). The conceptual model was tested using questionnaire responses from 189 subjects, measured at two time periods approximately two months apart. The results generally supported the hypothesized relationships, and revealed strong influences of both personal innovativeness and computer self-efficacy.		Ronald L. Thompson;Deborah Compeau;Christopher A. Higgins	2006	JOEUC	10.4018/joeuc.2006070102	user;user experience design;user modeling;computer user satisfaction;human–computer interaction;computer science;knowledge management;user requirements document;multimedia;law;information technology	AI	-60.41294676248173	-46.708998178741645	147347
3a6c8850b19cd17a0e99552077490b6e8e47e0cb	push-and-pull switching: window switching based on window overlapping	overlapping;user study;window manager;window switching;group membership;window management	We propose Push-and-Pull Switching, a window switching technique using window overlapping to implicitly define groups. Push-and-Pull Switching enables switching between groups and restacking the focused window to any position to change its group membership. The technique was evaluated in an experiment which found that Push-and-Pull Switching improves switching performance by more than 50% compared to other switching techniques in different scenarios. A longitudinal user study indicates that participants invoked this switching technique 15% of the time on single monitor displays and that they found it easy to understand and use.	experiment;microsoft windows;switching time;usability testing;window function	Quan Xu;Géry Casiez	2010		10.1145/1753326.1753526	embedded system;real-time computing;computer hardware;computer science	HCI	-49.64243973327629	-44.627653872150226	147515
f0adeac68273a557f912b3b3611010a20cb0384f	discovering different kinds of smartphone users through their application usage behaviors	user groups;clustering	Understanding smartphone users is fundamental for creating better smartphones, and improving the smartphone usage experience and generating generalizable and reproducible research. However, smartphone manufacturers and most of the mobile computing research community make a simplifying assumption that all smartphone users are similar or, at best, constitute a small number of user types, based on their behaviors. Manufacturers design phones for the broadest audience and hope they work for all users. Researchers mostly analyze data from smartphone-based user studies and report results without accounting for the many different groups of people that make up the user base of smartphones. In this work, we challenge these elementary characterizations of smartphone users and show evidence of the existence of a much more diverse set of users. We analyzed one month of application usage from 106,762 Android users and discovered 382 distinct types of users based on their application usage behaviors, using our own two-step clustering and feature ranking selection approach. Our results have profound implications on the reproducibility and reliability of mobile computing studies, design and development of applications, determination of which apps should be pre-installed on a smartphone and, in general, on the smartphone usage experience for different types of users.	android;cluster analysis;mobile computing;pre-installed software;smartphone	Sha Zhao;Julian Ramos;Jianrong Tao;Ziwen Jiang;Shijian Li;Zhaohui Wu;Gang Pan;Anind K. Dey	2016		10.1145/2971648.2971696	computer science;multimedia;internet privacy;cluster analysis;world wide web	HCI	-57.187463112980794	-43.01896911864246	147626
d91b00d6bb768352bf05447cbf6e36ff73365c5f	proposal for a novel computerized menu-presentation interface for restaurants	food;menu presentation;user interface;menu;restaurant	Food is a necessity of life for all, and is a source of entertainment to many. Due to poor design of menu-presentation system in restaurants, be it online or manual, often people are forced to select dishes, without properly being informed about whether it would cater their likes and dislikes or their health requirements. It is a fact that the choices and requirements are varied and designing a menu-interface to satisfy everybody is a challenging task. In this paper, we propose a general framework for a low-cost customizable computerized menu-system that any restaurant or food-chain can adopt for better user-friendliness and usefulness for themselves as well as for their customers.	food chain;requirement;usability	Goutam Paul;Soumi Paul	2013		10.1145/2525194.2525281	computer science;operating system;multimedia;user interface	HCI	-51.30083759751771	-40.14430890995695	147863
fec8d0aa20d293bfd21181eea1c8f8f2daff63ed	exploring networked message signs as a new medium for urban communication		In this work, we reflect on the use of LED message sign displays as an enabling technology for multipurpose, dynamic and open display networks for urban environments. We argue that the specific affordances of message signs may provide the ground for the emergence of a new type of digital and locative outdoor media with the capability to serve relevant and unserved purposes of urban communication. Our main goal is to provide an analytical perspective into the opportunities and challenges of this approach, and characterize the distinctive features that may define the uniqueness of this medium within the broader ecology of urban displays. To address this set of challenges, we explore different perspectives and research approaches, including photo and market surveys, interviews and prototyping. The results provide new insights about this medium, which are organised around 5 different themes: technical architecture, urban integration, direction, media and interaction.	ecology;emergence;information technology architecture;pervasive informatics;software prototyping;theme (computing)	Rui José;André Pinheiro;Helena Rodrigues	2018		10.1145/3205873.3205884	multimedia;locative case;locative media;uniqueness;architecture;affordance;computer science;digital signage	HCI	-58.04927374014432	-38.58136105641128	147864
db3efe280f906dc72ace4bb579147edade6cb308	the madeira touch: encouraging visual-spatial exploration using a tactile interactive display		The current information marketplace for tourists is dominated by for-profit purveyors of information. Potential visitors must rely on experts-for-hire or search engine results in order to learn about a desired destination. In this paper, we introduce The Madeira Touch, a multimodal display installation rooted in the unique characteristics of Madeira, which allows users to explore the island by selecting a type of scenery and showing the user-generated photos of that type of scenery in a map-based interface. To make this pervasive display more engaging, we designed an exploratory tactile-input mode of interaction: users will be able to touch a physical object, representing a type of scenery (a rock for mountains, a seashell for the sea, etc.), which will then bring up suitable photos of that type of scenery overlaid on a map of the island. The display will help users to form their mental image of the island and to plan trips that best suit their interests.	multimodal interaction;pervasive informatics;social media;user-generated content;web search engine	Catia Prandi;Catherine Chiodo;Ricjeareu Villaflor;Nicolas Autzen;Johannes Schöning	2017			computer science	HCI	-49.67680229028367	-39.50378677234653	147985
14b03c69858e730681e36eb770e94d12a70a37a8	conversation trees and threaded chats	instant messaging;usability study;program design;persistent conversation;computer human interaction;interface design;human computer human interaction;turn taking;computer mediated communication;conversation;synchronous communication;data structure;chat programs	Chat programs and instant messaging services are increasingly popular among Internet users. However, basic issues with the interfaces and data structures of most forms of chat limit their utility for use in formal interactions (like group meetings) and decision-making tasks. In this paper, we discuss Threaded Text Chat, a program designed to address some of the deficiencies of current chat programs. Standard forms of chat introduce ambiguity into interaction in a number of ways, most profoundly by rupturing connections between turns and replies. Threaded Chat presents a solution to this problem by supporting the basic turn-taking structure of human conversation. While the solution introduces interface design challenges of its own, usability studies show that users' patterns of interaction in Threaded Chat are equally effective, but different (and possibly more efficient) than standard chat programs.	data structure;instant messaging;interaction;usability	Marc Smith;Jonathan J. Cadiz;Byron Burkhalter	2000		10.1145/358916.358980	data structure;human–computer interaction;computer science;interface design;asynchronous communication;program design language;multimedia;communication;world wide web;computer-mediated communication	Web+IR	-55.105907325609536	-44.027698891189445	148100
bd1be0fe81091c3ad3091ef0417b939d14e013e5	inclusive side-scrolling action game securing accessibility for visually impaired people		Though many computer games have recently become accessible for gamers with visual impairments, these players still face difficulty in manipulating game characters and acquiring visual information. It is true that although an increasing number of games for visually impaired people called audio games are being developed, many of these games cannot satisfy their basic needs because of the shortage of contents and are difficult for sighted people because of no visual information. Based on this situation, we have been developing accessible games for visually impaired people that feature enriched materials and multimodal information presentation. However, the needs of real-time action on accessible games remain unsolved. In this article, our objective is to develop an inclusive side scroller game with high real-time performance and accessibility functions for visually impaired people, and be available to play with more than one person including sighted persons.	accessibility;scrolling	Masaki Matsuo;Takahiro Miura;Masatsugu Sakajiri;Junji Onishi;Tsukasa Ono	2017		10.1007/978-3-319-68059-0_41	economic shortage;human–computer interaction;multimedia;scrolling;auditory display;computer science;basic needs	HCI	-50.52439379478245	-40.30980755277871	148353
49e8367bb667f8f6f06e2492d870592ee97945ed	video browsing on handheld devices&#x2014;interface designs for the next generation of mobile video players	mobile multimedia;interfaces;navigation handheld computers watches weather forecasting switches portable media players personal digital assistants tv temperature mobile handsets;video signal processing;user study;interface design;media;video signal processing mobile handsets user interfaces;navigation;streaming media;mobile communication;handheld devices;next generation;mobile handsets;handheld device;user interface design;user interface designs;portable media players;video browsing;video;mobile video players video browsing handheld devices user interface designs;user interfaces;mobile video players;interaction technique;mobile video;wheels	This paper gives an overview of a group's recent and ongoing work on creating a flexible, intuitive, and powerful interface to improve video browsing on handheld devices in a similar way to how the iPhone's interaction techniques revolutionized navigation in mobile static media. This paper presented several developed and evaluated concepts and related user-interface designs. The paper limit the discussion to the presentation of the designs and refer to the related publications for detailed descriptions of evaluations and user studies.	browsing;interaction technique;mobile device;next-generation network;usability testing;user interface	Qibin Sun;Wolfgang Hürst	2008	IEEE MultiMedia	10.1109/MMUL.2008.66	embedded system;human–computer interaction;computer science;operating system;mobile device;multimedia	HCI	-48.38223024749887	-40.854951319543055	148520
a922aa22f52a8713869ca39ff68eae119b0e1e41	a design science framework for designing and assessing user experience	user experience;design science	User Experience is a well recognized factor in design and evaluation of artifacts in Human-Computer Interaction. There are many user experience models reported in the literature to reflect this status. Techniques and instruments for managing user experience are still not sufficient. In this paper, we discuss design science research and important user experience models reported in the literature and propose an integrated design science framework for designing and assessing user experience. We also present the results of an experimental study to validate our proposed framework and the instrument employed.		Sisira Adikari;Craig McDonald;John Campbell	2011		10.1007/978-3-642-21602-2_3	user interface design;user;user experience design;user modeling;computer user satisfaction;interactive systems engineering;human–computer interaction;experience design;computer science;knowledge management;user requirements document;user interface	Robotics	-62.34942692813383	-46.38671438745806	148550
0db0bcf80f3d5f384d52de2dd931d028a996abd0	brain activity patterns induced by interrupting the cognitive processes with online advertising	brain activity patterns;cognitive processes;eeg;interruptions;online advertising	As a result of the increasing role of online advertising and strong competition among advertisers, intrusive techniques are commonly used to attract web users’ attention. Moreover, since marketing content is usually delivered to the target audience when they are performing typical online tasks, like searching for information or reading online content, its delivery interrupts the web user’s current cognitive process. The question posed by many researchers in the field of online advertising is: how should we measure the influence of interruption of cognitive processes on human behavior and emotional state? Much research has been conducted in this field; however, most of this research has focused on monitoring activity in the simulated environment, or processing declarative responses given by users in prepared questionnaires. In this paper, a more direct real-time approach is taken, and the effect of the interruption on a web user is analyzed directly by studying the activity of his brain. This paper presents the results of an experiment that was conducted to find the brain activity patterns associated with interruptions of the cognitive process by showing internet advertisements during a text-reading task. Three specific aspects were addressed in the experiment: individual patterns, the consistency of these patterns across trials, and the intra-subject correlation of the individual patterns. Two main effects were observed for most subjects: a drop in activity in the frontal and prefrontal cortical areas across all frequency bands, and significant changes in the frontal/prefrontal asymmetry index.	advertisements;amendment;asymmetry index;attention deficit hyperactivity disorder;bands;consent forms;declaration (computer programming);declarative programming;electroencephalography;emotional states;experiment;frequency band;helsinki declaration;interrupt;license;mental processes;online advertising;predispositioning theory;real-time clock;real-time computing;virtual reality;web content;cognitive processes;standards characteristics	Izabela Rejer;Jaroslaw Jankowski	2017		10.1007/s10339-017-0815-8	psychology;the internet;brain activity and meditation;online advertising;cognitive psychology;electroencephalography;target audience;cognition;correlation	HCI	-54.65718959079493	-49.05999203760814	148624
b761eae2d5458c980ad4c923ac86c1fc23d68dca	multimodal dialogue in mobile local search	dialog;search;multimodal	"""Speak4itSM is a multimodal, mobile search application that provides information about local businesses. Users can combine speech and touch input simultaneously to make search queries or commands to the application. For example, a user might say, """"gas stations"""", while simultaneously tracing a route on a touchscreen. In this demonstration, we describe the extension of our multimodal semantic processing architecture and application from a one-shot query system to a multimodal dialogue system that tracks dialogue state over multiple turns. We illustrate the capabilities and limitations of an information-state-based approach to multimodal interpretation. We provide interactive demonstrations of Speak4it on a tablet and a smartphone, and explain the challenges of supporting true multimodal interaction in a deployed mobile service."""	dialog system;list of google products;local search (optimization);multimodal interaction;smartphone;tablet computer;touchscreen;web search query	Patrick Ehlen;Michael Johnston	2012		10.1145/2388676.2388741	computer vision;speech recognition;computer science;multimodal interaction;multimedia	HCI	-50.49567134728372	-39.733205357109064	148779
25cfa8552c67472166429250c29651e18b449acf	towards the simulation of social interactions through embodied conversational agents	embodied conversational agents;social interaction;speech acts;expressed emotion;emotional and social interaction;situated cognition;embodied conversational agent;virtual therapy	In this paper, we present a pluridisciplinary approach in order to model the behavior of an embodied conversational agent that expresses emotional and social interactions. We present our methodology to reproduce credible social interactions. Particularly, we discuss the role of the context, the culture, and the emotions in the model of the management of speech acts. This model has been implemented in the context of virtual therapy to simulate the interaction between a therapist and a post-CVA patient.	dialog system;embodied agent;human–computer interaction;immersion (virtual reality);simulation;situated;virtual reality therapy	María Lucila Morales-Rodríguez;Bernard Pavard;Juan Javier González Barbosa;José Antonio Martínez Flores	2008		10.1007/978-3-540-87656-4_68	social relation;embodied agent;computer science;situated cognition	HCI	-53.4431958332444	-48.41993867787937	148820
bd8d2911d4fce55e915310c38de12adeab22e98e	exploring the four social bonds evolvement for an accompanying minimally designed robot		In this paper, we investigate the effect of combining inarticu- late utterances (IU) with iconic gestures (IG) in addition to the response mode (proactive or reactive) and its impact on the bonds formation as well as the establishment of a positive relationship between the human and the accompanying robot. Specifically, we employ different scenarios while measuring in each instance the different social bonds that occur and we evaluate the human-robot relationship (HRR) in order to pick the behaviors that yield a positive HRR. Experimental results show that combining proactivity with the full mode (IU+IG) leads to social bonds evolvement and then to a better positive HRR.	robot	Youssef Khaoula;P. Ravindra De Silva;Michio Okada	2015		10.1007/978-3-319-25554-5_34	simulation;engineering;artificial intelligence;communication	Robotics	-50.20019184217554	-51.01965365056334	148989
687282bfcd2b6a38c162826c849b1a01685077f5	natural language processing for industry		Recently, natural language processing applications have become very popular in the industry. Examples of such applications include “semantic” enterprise search engines, document categorizers, speech recognizers and – last but not least – conversational agents, also known as virtual assistants or “chatbots”. The latter in particular are very sought-after in the customer care domain, where the aim is to complement the live agent experience with an artificial intelligence able to help users fulfil a task. In this paper, we discuss the challenges and limitations of industrial chatbot applications, with a particular focus on the “human-in-the-loop” aspect, whereby a cooperation between human and machine takes place in mutual interest. Furthermore, we analyse how the same aspect intervenes in other industrial natural language processing applications.	artificial intelligence;categorization;dialog system;finite-state machine;natural language processing;web search engine	Silvia Quarteroni	2018	Informatik-Spektrum	10.1007/s00287-018-1094-1	chatbot;computer science;search engine;natural language processing;artificial intelligence	AI	-52.121484926360026	-48.25234061770026	149271
635470eaf9e7b38c75c1059d2b8a8256a18e2124	exploring current practices for battery use and management of smartwatches	battery usage;smartwatch;recharging;wearable device	As an emerging wearable device, a number of commercial smartwatches have been released and widely used. While many people have concerns about the battery life of a smartwatch, there is no systematic study for the main usage of a smartwatch, its battery life, or battery discharging and recharging patterns of real smartwatch users. Accordingly, we know little about the current practices for battery use and management of smartwatches. To address this, we conduct an online survey to examine usage behaviors of 59 smartwatch users and an in-depth analysis on the battery usage data from 17 Android Wear smartwatch users. We investigate the unique characteristics of smartwatches' battery usage, users' satisfaction and concerns, and recharging patterns through an online survey and data analysis on battery usage.	android wear;smartwatch;usage data;wearable technology	Chulhong Min;Seungwoo Kang;Chungkuk Yoo;Jeehoon Cha;Sangwon Choi;Younghan Oh;Junehwa Song	2015		10.1145/2802083.2802085	embedded system;simulation;engineering;computer security	HCI	-60.46263542979582	-51.52164638012133	149314
63f567ee34e92c506b04b0d86cdc180ef44b577e	exploring skin conductance synchronisation in everyday interactions	empathy;skin conductance;mixed methods;gsr;biosensors;physiological synchrony	Detecting interpersonal and emotional aspects of behaviour is a growing area of research within HCI. However, this work primarily processes data from individuals, rather than drawing on the dynamics of an interaction between people. Literature in social psychology and neuroscience suggests that the synchronisation of peoples' biosignals, in particular skin conductance (EDA), can be indicative of complex interpersonal aspects such as empathy. This paper reports on an exploratory, mixed methods study to test the potential of EDA synchronisation to indicate qualities of interpersonal interaction in real-world relationships and contexts. We show that EDA synchrony can be indicate meaningful social aspects in everyday settings, linking it to the mutual emotional engagement of those interacting. This connects to earlier work on empathy in psychotherapy, and suggests new interpretations of EDA sychronisation in other social contexts. We then outline how these findings open opportunities for novel HCI and ubicomp applications, supporting training of social skills such as empathy for doctors, and more generally to explore shared experiences such as multiplayer games.	conductance (graph);electronic design automation;experience;human–computer interaction;ubiquitous computing;virtual synchrony	Petr Slovák;Paul Tennent;Stuart Reeves;Geraldine Fitzpatrick	2014		10.1145/2639189.2639206	skin conductance;multimethodology;biosensor	HCI	-55.56848025913001	-49.33059770262633	149321
892613706525fbb07d39805c82bc968e6fbbe555	conversational agent in argumentation - a model and evaluation on a dialogue corpus		Communication between two participants, A and B, is considered, where A has a communicative goal that his/her partner, B, will make a decision to perform an action D. A computational model of argumentation is developed which includes reasoning. Communicative strategies and tactics used by participants for achieving their communicative goals are considered. A simple dialogue system (conversational agent) is implemented which can optionally play the role of A or B using classified sets of pre-defined Estonian sentences. For further evaluation of the model and with the aim to develop the dialogue system, the analysis of the Estonian Dialogue Corpus is carried out. Calls of sales clerks who persuade clients to take training courses of an educational company are analysed. The calls end mostly with the postponement of the decision therefore the sales clerks do not achieve their communicative goal.	computational model;dialog system;dialog tree	Mare Koit	2011			natural language processing	NLP	-53.471003004675566	-47.990706933978345	149371
c1c11c44aa682a86514bcd89a25c99f67318598c	chord character evaluation model based on harmoniousness: application to music mood visualization interface		The chord, along with melody and rhythm, is one of the important elements in constituting music, but the cause of music's psychological effects are, for the most part, yet to be clarified. There are previous studies that define chord characters on the basis of the levels of dissonance, tension and modality, but there is not enough research to discuss psychological indexes which is called chord's “brightness.” Therefore, in this study, in order to define a chord character evaluation based on harmoniousness, we propose a method for estimating the impression of brightness in chords. Evaluation experiments were performed in order to validate the proposed method. As a result, a strong correlation was found between the proposed degree of harmoniousness (H) and the results of psychological experiments. Furthermore, through the application of these results, an interface for representing musical mood through color was developed.	color;experiment;information visualization;modality (human–computer interaction)	Eriko Aiba;Kensuke Tobitani;Takayuki Shimotomai;Mitsuaki Tani;Noriko Nagata;Takashi X. Fujisawa	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505187	multimedia	Robotics	-49.14435278724793	-49.96159069919567	149473
d01a58d73fad6399d3c5653654b90bb75213f308	lifeview: a lifelog visualization tool for supporting sentimental recall and sharing	lifelog;user study;sharing;cartoons;sentimental recall;contextual hyperlinks	The majority of past HCI research on Lifelogging has focused on using specialized capture devices such as the Microsoft SenseCam for recording our life experiences visually. However, we also record many of our daily life events in a textual form on popular platforms like Facebook or using our smartphones. Such primarily textual lifelogs can also potentially help us in reliving our past memories and sharing them with friends. In this paper, we present the design and implementation of LifeView, a tool for visualizing such primarily textual lifelogs for the purposes of Sentimental Recall and Sharing. We propose to depict life events using cartoons, and claim that it will result in a better recall experience. We also propose that linking the various life interactions based on appropriate context will be useful when people browse their lifelogs. Two within-subject user experiments are presented to validate our design -- results show that a) users prefer cartoon abstractions over the actual lifelog data, and b) contextual linking of life events is useful for goal-oriented navigation and sharing.	browsing;emoticon;experiment;human–computer interaction;lifelog;microsoft sensecam;smartphone	Akhil Mathur;Anirban Majumder;Samik Datta;Sreedal Menon;Shipra Malhotra;Ankur Dahiya	2012		10.1145/2414536.2414596	human–computer interaction;computer science;multimedia;internet privacy;world wide web;lifelog	HCI	-55.87251924458702	-43.50792938105966	149576
a901caa1096bef26e297196c7c1e355ecbe6ba4e	a context aware architecture to support people with partial visual impairments	ambient intelligence;decision support system;speculative computation	Nowadays there are several systems that help people with disabilities on their quotidian tasks. The visual impairment is a problem that affects several people in their tasks and movements. In this work we propose an architecture capable of processing information from the environment and suggesting actions to the user with visual impairments, to avoid a possible obstacle. This architecture intends to improve the support given to the user in their daily movements. The idea is to use speculative computation to predict the users’ intentions and even to justify the reactive or proactive users’ behaviors.	computation;speculative execution	João P. Fernandes;João Laranjeira;Paulo Novais;Goreti Marreiros;José Neves	2013		10.1007/978-3-319-00551-5_41	simulation;decision support system;ambient intelligence;computer science;multimedia	HCI	-57.81970572117604	-51.7814037099581	149593
c35888767455fe2fae7284c72922d51e92010ef4	stop procrastinating: tilt, time is life time, a persuasive application	addiction;self monitoring;adaptation;persuasion;smartphone	As smartphone is spreading all over the world, deep in our daily life, new problems emerge like smartphone addiction and procrastination. We propose TILT (Time Is Life Time), a persuasive application that fights procrastination and helps people to decrease phone usage. TILT is based on self-monitoring, a design principle for persuasive technology. Persuasive messages are adapted to the user context to bring diversity and relevance to persuasion. A six-weeks trial is reported showing that persuasion adaptation strengthens persuasive power of self-monitoring and limits its attrition.	attrition (website);interactivity;persuasive technology;relevance;smartphone	Anthony Foulonneau;Gaëlle Calvary;Eric Villain	2016		10.1145/3010915.3010947	simulation;addiction;persuasive technology;self-monitoring;adaptation	HCI	-58.22165208709204	-50.91509985653093	149601
64a620a5cd067bfeee315b04cfacedd660e7fd2c	readability formulas have even more limitations than klare discusses	text comprehension;reliability;usability testing;literature review	A literature review reveals many technical weaknesses of readability formulas (when compared to direct usability testing with typical readers): they were developed for children s school books, not adult technical documentation;they ignore between-reader differences and the effects of content, layout, and retrieval aids on text usefulness; they emphasizecountable features at the expense of more subtle contributors to text comprehension.	book;list comprehension;usability testing	Janice Redish	2000	ACM Journal of Computer Documentation	10.1145/344599.344637	computer science;reliability;multimedia;world wide web;information retrieval	HCI	-60.522326685779106	-48.02137466913652	149781
