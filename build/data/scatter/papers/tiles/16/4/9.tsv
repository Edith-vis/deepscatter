id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
a6b78c8d28d73af7019fe10dc6cd5153d0acda93	experiences of using sdl collected in iskratel sdl methodology	iskratel sdl methodology	This paper summarises the experiences of introducing SDL in the company IskraTEL. The main methodological rules collected in IskraTEL SDL Methodology (ISDLM) are presented. An overview of extended and added features during the simulation and implementation phase is described in detail. Final results of prototype and final product are discussed. Finally, the experience of using SDL­88 and the GEODE tool is mentioned, as are our future plans and expectations.		Aana Robnik	1995			theoretical computer science;final product;computer science;executable;computer architecture;message sequence chart	Robotics	-52.97582977005374	22.802105203672447	43347
7cce446abdcee7c2efbbb300bd9af2624867c29a	realization of systematic reliability analysis of decomposable systems	pipes and filters architecture systematic reliability analysis decomposable systems software complexity software system certification mathematical inference expressions exception handling;software metrics;software system certification;software reliability exception handling object oriented programming software metrics software quality;systematic reliability analysis;software complexity;software systems;object oriented programming;mathematical inference expressions;exception handling;reliability analysis;software reliability;pipes and filters architecture;software quality;decomposable systems;software systems reliability runtime java software testing computer science neodymium hardware computer architecture sorting	"""In addition to the ever increasing software complexity, there has been a significant increase in the demand for more flexible and dependable software systems. Therefore, it is necessary to be able not only to achieve high quality but also to rigorously demonstrate that high quality has been achieved. While relatively mature techniques exist for certifying hardware systems, methods of certifying software systems are still being actively researched. More importantly, even though substantial research has been carried out to reduce the complexity of the software system through decomposition, one major hurdle is the need to certify the overall system on the basis of the component properties. Our early research introduced a novel approach that enhances the """"accessibility"""" of each component, so that the properties of a system can be mathematically inferred from those of its components. In this paper, we show the validity of these mathematical inference expressions through different classes of components and system using Java's exception handling, an implementation of pipes-and-filters architecture, and a simple sorting selector"""	accessibility;display resolution;exception handling;java;pipeline (software);programming complexity;reliability engineering;software system;sorting	Joon Hyung Kim;Garrett Hoff	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.154	reliability engineering;real-time computing;computer science;operating system;software engineering;database;programming language;software quality	SE	-55.38396854609095	31.203018703006176	43403
1b5bd6e8cde7f2a2abfc0992e49c229af03395c0	identifying technical risks in third-party software for embedded products	consumer electronics;embedded software software prototyping software standards prototypes manufacturing laboratories consumer electronics hardware software maintenance information processing;embedded systems;commercial off the shelf software technical risk third party software embedded software cots software in house software component software integration;software packages embedded systems;software component;software packages;embedded software	Market and technology changes are forcing consumer electronics manufacturers to integrate third-party software in their embedded products. However, this integration is more challenging than for the mainstream COTS market, given fewer standards, less opportunity for prototyping and fewer independent sources of information. Therefore, while satisfactory processes have been proposed for evaluating COTS software, they can only be exploited for embedded software if an approach is available to identify potential technical risks. Such an approach has been developed, embodied in a checklist, which aims to guide an assessor as they build their understanding of the interactions between components, given the documentation typically supplied. The checklist contents are informed by a series of studies of the root causes of failures during the integration of both in-house and third-party software components. The paper focuses on how the checklist is structured so that incompatible design decisions in different components can be identified. The checklist has been validated on two development projects in the early phases of evaluating third-party components.	component-based software engineering;documentation;embedded software;embedded system;interaction;software prototyping;third-party software component	Tim Trew;Gerben Soepenberg	2006	Fifth International Conference on Commercial-off-the-Shelf (COTS)-Based Software Systems (ICCBSS'05)	10.1109/ICCBSS.2006.18	embedded system;personal software process;medical software;long-term support;verification and validation;software sizing;systems engineering;engineering;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software measurement;software deployment;software system;avionics software;software peer review	SE	-61.144602900489126	27.34174700208804	43564
8280056dd0d5077044dc5871f98feb17c252449b	complexity metrics for spreadsheet models	complexity metrics;software engineering;error rate;structured data	Several complexity metrics are described which are related to logic structure, data structure and size of spreadsheet models. They primarily concentrate on the dispersion of cell references and cell paths. Most metrics are newly defined, while some are adapted from traditional software engineering. Their purpose is the identification of cells which are liable to errors. In addition, they can be used to estimate the values of dependent process metrics, such as the development duration and effort, and especially to adjust the cell error rate in accordance with the contents of each individual cell, in order to accurately asses the reliability of a model. Finally, two conceptual constructs – the reference branching condition cell and the condition block – are discussed, aiming at improving the reliability, modifiability, auditability and comprehensibility of logical tests.	data structure;software engineering;spreadsheet	Andrej Bregar	2004	CoRR		reliability engineering;data model;word error rate;computer science;systems engineering;theoretical computer science;software engineering	SE	-60.09482662820098	30.14128502606746	43651
05bfdb82abee60fa73c3930b30f77e46f7ea9026	engineering privacy requirements valuable lessons from another realm	privacy initiatives privacy requirements privacy by design approach systems engineering nonfunctional requirements design guidance software engineers web accessibility;privacy guidelines law data privacy proposals context;systems analysis data privacy internet software engineering;privacy by design privacy requirements requirement decomposition privacy principles privacy patterns	The Privacy by Design approach to systems engineering introduces privacy requirements in the early stages of development, instead of patching up a built system afterwards. However, `vague', `disconnected from technology', or `aspirational' are some terms employed nowadays to refer to the privacy principles which must lead the development process. Although privacy has become a first-class citizen in the realm of non-functional requirements and some methodological frameworks help developers by providing design guidance, software engineers often miss a solid reference detailing which specific, technical requirements they must abide by, and a systematic methodology to follow. In this position paper, we look into a domain that has already successfully tackled these problems - web accessibility -, and propose translating their findings into the realm of privacy requirements engineering, analyzing as well the gaps not yet covered by current privacy initiatives.	first-class citizen;functional requirement;non-functional requirement;privacy by design;requirements engineering;software engineer;systems engineering;vagueness;web accessibility	Yod Samuel Martín;José M. del Álamo;Juan C. Yelmo	2014	2014 IEEE 1st International Workshop on Evolving Security and Privacy Requirements Engineering (ESPRE)	10.1109/ESPRE.2014.6890523	privacy software;information privacy;privacy by design;engineering;internet privacy;world wide web;computer security	SE	-57.930968341725915	21.743926374062717	43696
14d3e766a58dd15f1f12069b4aebb6dba551b6e5	software reuse and reusability based on requirements: product lines, cases and feature-similarity models		Several socioeconomic trends are increasing per sonalised customer demands. Suppliers are responding with mass customisation but the management of large-scale cost-effective software reuse remains a difficult challenge. Software reuse and reusability range from operational, ad-hoc and short-term to strategic, planned and long-term. Often the focus of attention is just on code or low-level design. This tutorial presents and compares two different requirements-led approaches. The first approach deals with requirements reuse and reusability in the context of product line engineering. The second approach deals with requirements reuse and reusability in the context of case-based reasoning. Both approaches have different key properties and trade-offs between the costs of making software artefacts reusable and the benefits of reusing them. To aid large-scale development we have proposed a Feature-Similarity Model, which draws on both approaches to facilitate discovering requirements relationships using similarity metrics. A Feature-Similarity Model also helps with the evolution of a product line, since new requirements can be introduced first into a case base and then gradually included into a product line representation.	code reuse;requirement	Hermann Kaindl;Mike Mannion	2018		10.1109/RE.2018.00010	systems engineering;requirements engineering;domain engineering;software;reuse;reusability;computer science;cognition	SE	-60.62784825313141	20.990603807557545	43713
829325728c3ca32e2c11b2126a6def81e59d3881	twenty-five years of formal methods and railways: what next?		Since more than 25ayears, railway signalling is the subject of successful industrial application of formal methods in the development and verification of its computerized equipment.#R##N##R##N#However the evolution of the technology of railways signalling systems in this long term has had a strong influence on the way formal methods can be applied in their design and implementation. At the same time important advances had been also achieved in the formal methods area. The scope of the formal methods discipline has enlarged from the methodological provably correct software construction of the beginnings to the analysis and modelling of increasingly complex systems, always on the edge of the ever improving capacity of the analysis tools, thanks to the technological advances in formal verification of both qualitative and quantitative properties of such complex systems.#R##N##R##N#The thesis we will put forward in this paper is that the complexity of future railway systems of systems can be addressed with advantage only by a higher degree of distribution of functions on local interoperable computers - communicating by means of standard protocols - and by adopting a multi-level formal modelling suitable to support the verification at different abstraction levels, and at different life-cycle times, of the safe interaction among the distributed functions.	formal methods	Alessandro Fantechi	2013		10.1007/978-3-319-05032-4_13	formal methods;computer science;software engineering;formal specification;algorithm	Logic	-57.47046453829066	25.57276855626639	43752
9f82d9086e30cf613aa5c958bc58b20c7c28f284	determining component reliability using a testing index	component testing;component based software engineering;software reliability;software engineering	Component-Based Software Engineering has the potential to provide reliable systems based on tested components quickly and economically, but these systems will only be as reliable as the components from which they are constructed. We propose a 6-point scale which can be used to rate the degree to which a component has been tested. This scale can be used by developers to assess the risk of using a third party component. Since a variety of test strategies are used, it is necessary to correlate testing strategies with our scale. In this paper, we examine the testing strategies specified in British Standard 7925-2 and show how they relate to the reliability levels that we propose. Since well-behaved use of resources is also a key factor in overall system reliability, we propose that an 'R' tag be added to the rated level when resource usage has been verified to be within reasonable bounds.		John Morris;Chiou Peng Lam;Gareth A. Lee;Kris Parker;Gary A. Bundell	2002			reliability engineering;component-based usability testing;software performance testing;system integration testing;systems engineering;engineering;software reliability testing;software construction;data mining;software testing	SE	-62.03414673196286	31.00332030680169	43757
81626e79213783aec748afbbfc5a81343e689914	towards a systems engineering essence		SEMAT/OMG Essence provides a powerful Language and a Kernel for describing software development processes. How can it be tweaked to apply it to systems engineering methods description? We must harmonize Essence and various systems engineering standards in order to provide a more formal system approach to obtaining a Systems Engineering Essence. In this paper, an approach of using Essence for systems engineering is presented. In this approach we partly modified a Kernel only within engineering solution area of concerns and completely preserved Language as an excellent situational method engineering foundation.	formal system;kernel (operating system);method engineering;semat;software development;systems engineering	Anatoly Levenchuk	2015	CoRR		system of systems engineering;computer science;systems engineering;algorithm	SE	-54.37858722332514	23.051599690533305	43778
5a1d3871de116d6a18cc9bd6486a3bf235130719	using knowledge-based transformations to reverse-engineer cobol programs	system re engineering knowledge based transformations reverse engineering cobol programs program restructuring tool software tool tampr program transformation system commercial product;software tool;computer languages;cobol;programming profession computer science laboratories robustness reverse engineering costs computer languages engines humans;commercial product;program transformation;program restructuring tool;knowledge based transformations;engines;cobol programs;system re engineering;programming profession;robustness;software tools;tampr program transformation system;humans;computer science;program development;knowledge based systems;reverse engineering;knowledge base;systems re engineering	We describe a program restructuring tool under development. The tool is constructed using program transformations executed by the TAMPR program transformation system. We discuss the knowledge embodied in the transformations and how they restructure an example COBOL program developed in the mid-1970s. While the tool needs to be extended further to produce a robust commercial product, early use for restructuring COBOL programs demonstrates the power and flexibility of this transformational approach.	cobol;reverse engineering	Terence J. Harmer;Patrick J. McParland;James M. Boyle	1996		10.1109/KBSE.1996.552829	knowledge base;computer science;systems engineering;software engineering;knowledge-based systems;cobol;programming language;reverse engineering;robustness;computer engineering	AI	-49.647606442219455	31.6058893051231	43803
8aec92e111a317d7d685565475171d21e9188911	design patterns in scientific software	object oriented design;conference paper;design pattern	This paper proposes that object-oriented design patterns can greatly help with the design and construction of scientific software. It describes a method of teaching design patterns which introduces patterns as they are used in refactoring, extending and reusing a computational science case study. The method has been taught into a graduate level eScience curriculum for three years.	code refactoring;computational science;design pattern;e-science	Henry J. Gardner	2004		10.1007/978-3-540-24767-8_82	software design pattern;architectural pattern;computer science;software design;object-oriented design;continuous design;interaction design pattern;pattern language;database;design pattern;distributed design patterns;design education;programming language;structural pattern;creational pattern	SE	-51.161994283202944	28.344600952348973	43824
4d7a97b2042c748f9323f1be1e912af7c1a36d22	visual modeling of business problems: workflow and patterns	data visualisation;diagrams;probability;workflow management software;schlumberger software;business problems;calculation diagrams;calculation logic;computer-based business analysis;high level conceptual modeling;multilayer visual representation;probabilistic analysis;visual modeling workflow	Computer-based business analysis relies on models, or algorithmic representations of the business process. Real-life business problems can become very complex, which creates difficulties in generation, analysis, testing, and the actual use of the models. The paper discusses a proposed solution: the visual modeling workflow. A diagram or a group of diagrams represent each step within this workflow. The visual modeling process can be simplified by applying patterns or problem-solution formulas. Such modeling patterns include decoupling, encapsulation, visualization of user workflow, multi-layer visual representation of the calculation logic, and early identification and visualization of uncertainties. The patterns are applied to the visual modeling workflow, which include high level conceptual modeling, using Domain Models and Calculation Diagrams to visualize the calculation logic, visualization of testing and consolidations, and visualization of results of probabilistic analysis and simulation. The described methodology is used in a number of Schlumberger's software application.	algorithm;business analysis;business process;coupling (computer programming);diagram;encapsulation (networking);high-level programming language;institute for operations research and the management sciences;layer (electronics);probabilistic analysis of algorithms;simulation;visual modeling	Lev Virine;Jason McVean	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.		probabilistic analysis of algorithms;computer science;conceptual model;diagram;theoretical computer science;domain model;probability;data mining;database;mathematics;business process;story-driven modeling;business process modeling;data visualization;statistics;workflow technology	Visualization	-49.91086716422715	25.3818558114433	43907
a0c697230b34678cfc050aa8e4b080239ab48138	knowledge-based support for the development of database-centered applications	application development;application generation systems database centered applications application development toolkit artificial intelligence productivity tools expert developers end user oriented approach application oriented interface;application software productivity data models user interfaces artificial intelligence database systems database languages software packages packaging functional programming;application software;database management systems;application oriented interface;expert developers;application generators;packaging;functional programming;artificial intelligent;software tools application generators database management systems knowledge based systems;database systems;end user oriented approach;artificial intelligence;application generation systems;software tools;productivity;application development toolkit;database centered applications;productivity tools;user interfaces;database languages;knowledge based systems;software packages;data models;knowledge base	Database application productivity tools have not generally lived up to their claims for t rue end users. Higher productivity has been enjoyed by well-trained developers only. Several factors contribute to the skeptical attitude by end users toward productivity tools that claim to support the development of database-centered application software. The conceptual gap between what end users conceive their applications to be and what the tools require these users to do is the most important reason why end users have not strongly embraced these tools. To the end users, the application-development process is foreign and the structure used to organize the data (i.e., the details of the data model) is intimidating and arcane. Using the Application Development Toolkit as an example, this paper illustrates that by borrowing some techniques from the artificial intelligence field, database-centered application-development productivity tools can be made more acceptable to end users and more useful to expert developers.	artificial intelligence;data model;database	Hany M. Atchan;Rob Bell;Bhavani M. Thuraisingham	1989		10.1109/ICDE.1989.47240	data modeling;packaging and labeling;knowledge base;productivity;application software;computer science;data mining;database;functional programming;user interface;rapid application development;query language	DB	-53.27359009402374	27.30029185668742	43932
1632ae859da2af5fa09c2e24999ad415057a80c0	capturing autonomy features for unmanned spacecraft with are, the autonomy requirements engineering approach	selfadaptive systems;software engineering;info eu repo semantics article;requirements engineering;autonomous and self adaptive systems;autonomy requirements;autonomic systems;are	Along with the traditional requirements, requirements engineering for autonomous and self-adaptive systems needs to address requirements related to adaptation issues, in particular: (1) what adaptations are possible; (2) under what constrains; and (3) how those adaptations are realized. Note that adaptations arise when a system needs to cope with changes to ensure realization of the system’s objectives. The autonomy requirements engineering approach converts adaptation issues into autonomy features where goal-oriented requirements engineering is used along with a model for generic autonomy requirements. The approach is intended to help engineers develop missions for unmanned exploration, often with limited or no human control.	adaptive system;autonomous robot;autonomy;esa;requirement;requirements engineering;unmanned aerial vehicle;unmanned spacecraft	Emil Vassev;Michael G. Hinchey	2015	Innovations in Systems and Software Engineering	10.1007/s11334-015-0257-3	requirements analysis;requirements management;simulation;business requirements;systems engineering;engineering;knowledge management;requirement;needs analysis;system requirements specification;requirements engineering;non-functional requirement	SE	-57.297896971812136	21.885379785335203	44148
16b458bba3fa4da6629332e3326446416fa5859c	articulation: an integrated approach to the diagnosis, replanning, and rescheduling of software process failures	plan execution;integrated approach;dynamic scheduling programming knowledge based systems problem solving software prototyping contracts prototypes electric breakdown resource management;software performance evaluation software quality system recovery software fault tolerance scheduling knowledge based systems;software process plans;knowledge based system;software prototyping;articulation;adaptive process based software development;prototypes;software process failures;resource management;software performance evaluation;software fault tolerance;contracts;prototype knowledge based system;electric breakdown;system recovery;scheduling;diagnosed failure;software development;prototype knowledge based system software process failures integrated approach software process plans diagnosed failure adaptive process based software development articulation plan execution;programming;software quality;knowledge based systems;software process;problem solving;dynamic scheduling	The papers presents an integrated approach to articulate software process plans that fail. The approach, called articulation, repairs a plan when a diagnosed failure occurs and reschedules changes that ensure the plan's continuation. In implementing articulation, we combine diagnosis, replanning, and rescheduling into a powerful mechanism supporting process-based software development. Use of articulation in plan execution supports recovery and repair of unanticipated failures, as well as revising and improving the plans to become more eeective. In this paper, we also describe how a prototype knowledge-based system we developed implements the articulation approach.	biconnected component;continuation;knowledge-based systems;prototype;software development process	Peiwei Mi;Walt Scacchi	1993		10.1109/KBSE.1993.341195	reliability engineering;programming;real-time computing;dynamic priority scheduling;computer science;systems engineering;engineering;software development;operating system;software engineering;knowledge-based systems;prototype;scheduling;software development process;software quality;software fault tolerance	SE	-56.286922719521904	29.541144626409597	44259
b4c4b47a334f1997cb3a0562d3e1cad4626f7db1	tasks and methods for software maintenance: a process oriented framework	software life cycle.;software maintenance;software development;framework	The paper proposes a framework of various tasks involved in the software maintenance process. The work reported in this paper disassembles the complex process of software maintenance into tasks as to aid in the allocation of resources, acquisition of appropriate tools, and distributing responsibilities of the software maintenance process. The associated toolsets, methods, input-output sources, and communication protocols between tasks are addressed in this paper. This work is intended to conveying a high-level understanding of the software maintenance process and its dimensions. Software maintenance can be viewed in various ways depending on its purposes, nature and characteristics. We also show that software maintenance and development are two separate processes, but they are highly interrelated and interdependent. We attempt to find the intersection of activities between the software development and maintenance processes in the final part of this paper, and the software maintenance process is integrated with the development process into a high level software life cycle model.	software maintenance	Khaled M. Khan;Bruce W. N. Lo;Torbjørn Skramstad	2001	Australasian J. of Inf. Systems			SE	-56.29251259060231	22.791618909270493	44365
0fcc2248015ec0de6c50582450ebf9b1c51d2208	a computer-aided process from problems to laws in requirements engineering		In today’s world many products and services are highly dependent on software and information systems. With the growing importance of IT systems, legislators worldwide decided to regulate and enforce laws for IT systems. With respect to this situation, the impact of compliance on the development of IT systems becomes more and more severe. Hence, software engineers have a need for techniques to deal with compliance. But identifying relevant compliance regulations for IT systems is a challenging task. We proposed patterns and a structured method to tackle these problems [1]. A crucial step is the transformation of requirements into a structure, which allows for the identification of laws. The transformation step was described in general in [2]. This work describes a method to structure the requirements, elicit the needed domain knowledge and transform requirements into law identification pattern instances. The manual execution of this method was reported by us to be time consuming and tedious. Hence, in this work we identify the points for (semi-)automation, and we outline a first implementation for the automation. We present our results using a voting system as an example, which was obtained from the ModIWa DFG (Juristisch-informatische Modellierung von Internetwahlen (II). A Deutsche Forschungsgemeinschaft project: http://cms.uni-kassel.de/unicms/index.php?id=38536) project and the common criteria profile for voting systems.	requirements engineering	Stephan Faßbender;Maritta Heisel	2013		10.1007/978-3-662-44920-2_14	systems engineering;requirement;process engineering;requirements engineering;non-functional requirement;mechanical engineering	SE	-57.04097029373207	21.172839216679964	44381
54c73e7083c5487c93b42c54648dcd95f4e133db	transaction-oriented work-flow concepts in inter-organizational environments	legacy system;business process	Workflow techniques have gained a lot of attention as a means to support business process r~engineering but also as a means to integrate legacy systems. Most workflow models view the applications as a fixed set of tasks. In this paper we analyse inter-organisational application domains and analyse properties for transactional workflows and systems supporting them. We study a workflow model for the applications where job step instances cannot be fixed in advance. We analyse requirements arising horn this kind of environments through a particular application, and introduce special modelling components to support these requirements. We also develop the concept of C-unit to cope with concurrency anomalies and recovery.	application domain;business process;concurrency (computer science);data integrity;distributed computing;goto;legacy system;multiprocessing;requirement	Jian Tang;Jari Veijalainen	1995		10.1145/221270.221583	computer science;knowledge management;artifact-centric business process model;process management;business process;business process discovery;business process modeling;legacy system	DB	-56.18156281240261	18.856228792614107	44651
27bf9c46999c0577ddca9d645072ae621592a424	mde in support of visualization systems design: a multi-staged approach tailored for multiple roles		Visualization systems such as dashboards are commonly used to analyze data and support users in their decision making, in communities as different as medical care, transport and software engineering. The increasing amount of data produced and continuous development of new visualizations exacerbate the difficulty of designing such dashboards, while the visualization need is broaden to specialist and non-specialist final users. In this context, we offer a multi-user approach, based on Model Driven Engineering (MDE). The idea is for the designer to express the visualization need by characterization, according to a given taxonomy. We provide a Domain Specific Language (DSL) to design the system and a Software Product Line (SPL) to capture the technological variability of visualization widgets. We performed a user study, using a software project management use case, to validate if dashboard users and designers are able to use a taxonomy to express their visualization need.	abstraction layer;code generation (compiler);digital subscriber line;domain-specific language;executable;feature model;graphical user interface;heart rate variability;information visualization;model-driven engineering;multi-user;parse tree;point of view (computer hardware company);sirius systems technology;software engineering;software product line;software project management;spatial variability;systems design;taxonomy (general);usability testing	Ivan Logre;Anne-Marie Pinna-Dery	2018	PACMHCI	10.1145/3229096	metamodeling;systems engineering;visualization;systems design;domain-specific language;model-driven architecture;software project management;software product line;computer science;digital subscriber line	Visualization	-49.797586496584	22.881060698722568	44956
cdf7f0aa309bc99ce00627690126f238e0739878	modelbyvoice - towards a general purpose model editor for blind people		Context: Current modelling technologies, with the support of modelling frameworks, are in the base of the current adoption of Model-Driven Software development MDD and supporting Software Engineering phases. Problem: The focus of these tools are solely on graphical support and visual models. In fact, the chosen modelling language’s concrete syntax is either graphical or textual or both. This approach is discarding the use of other senses for modelling purposes, and, for instance, the possibility of blind software engineers to take advantage of modelling and deal with the abstractions captured by those. It is necessary to improve the productivity of people with limitations or disabilities while modelling.They should not be excluded from the modelling activity. This situation of accessibility barriers starts already at education of Modelling. Method: In this paper we present a prototype of a tool that aims to take advantage of current voice recognition and speech synthesis to edit models in diverse modelling languages. The elegance of this work is the fact that, not only it is meant to make MDD accessible to a broader spectrum of practitioners, but also it is developed with an MDD approach. Results: A prototype was built, named ModelByVoice. This tool is not bound to a particular modelling language, as long as it is meta-modelled. ModelByVoice is the base for a new tool that will enable MDD highlighting the relevant human factor of accessibility via voice and audio to models. Ultimately, it aims at bringing accessibility for blind people to deal with MDD and Domain Specific (Modelling) Languages DS(M)Ls the same way it is already done with diagrammatic languages with the current Modelling workbenches.	accessibility;diagram;domain-specific language;graphical user interface;human factors and ergonomics;model-driven engineering;modeling language;parse tree;prototype;software development;software engineer;software engineering;speech recognition;speech synthesis;viavoice	João Lopes;João Cambeiro;Vasco Amaral	2018				SE	-49.25432273881435	23.72854881189444	44986
86b1a98328349bac477f9c323c8e716b5e4d56cd	refactoring of automotive models to handle the variant problem		Models and model-based languages are more and more used in the automotive domain [1] to define artifacts for software (requirements, software and hardware architectures, code structure and behavior) to run in a car. Models and code reflect a remarkable complexity, due to safety critical properties and the huge amount of possible variants [2]. The big number of variants comes from simple or elaborated functionality, different realizations of functionality, combination of functionality, integration of proprietary solutions, country-specific legality constraints, and alike. This presentation concentrates on Simulink models [3], which are an essential part of the model structure describing automotive software. Especially, we show how to use refactoring [4] in order to express commonalities and differences of models and, therefore, facilitate reuse and extensibility as essential quality measures. Even more, refactoring is also the means to handle the variant problem. The presentation is based on a chapter of [5]. It remains on an informal example by example basis.	automotive software;code refactoring;extensibility;requirement;simulink	Cem Mengi;Manfred Nagl	2012	Softwaretechnik-Trends		operating system;database;code refactoring	SE	-54.646827845299306	26.295544519825782	45016
f507d948245fba47765a597e39038a90ab34c1e7	fama-ovm: a tool for the automated analysis of ovms	ovms;articulo;modelling language;software products lines;tools;fama ovm a tool for the automated analysis of ovms;software product line	Orthogonal Variability Model (OVM) is a modelling language for representing variability in Software Product Line Engineering. The automated analysis of OVMs is defined as the computer-aided extraction of information from such models. In this paper, we present FaMa-OVM, which is a pioneer tool for the automated analysis of OVMs. FaMa-OVM is easy to extend or integrate in other tools. It has been developed as part of the FaMa ecosystem enabling the benefits coming from other tools of that ecosystem as FaMaFW and BeTTy.	ecosystem;fama im;fama–french three-factor model;heart rate variability;modeling language;open verification methodology;software product line;spatial variability	Fabricia Roos-Frantz;José A. Galindo;David Benavides;Antonio Ruiz Cortés	2012		10.1145/2364412.2364456	computer science;systems engineering;software engineering	SE	-53.804206166029	25.629869728826943	45025
6ecc959922fa377914bdc60748bd4caf97fcd48e	how to drill down to rest apis: resource harvesting with a pattern tool	web services application program interfaces;software;servers;image color analysis;application program interfaces;unified modeling language;web services;adaptation models;context;unified modeling language context adaptation models servers software educational institutions image color analysis;resource oriented mindset rest api resource harvesting pattern tool service providers web services http put post get questionnaire based method speech act theory	REST has become a popular architectural style among service providers. It is considered as an easy way to design and consume Web services. REST can be realized as using HTTP PUT, POST, and GET operations. However, the focus on the implementation technique often leads to ignoring the original REST constraints and definitions proposed by R. Fielding. Thus, this way of thinking might result in misuse of REST. In addition, less emphasis is put on designing good REST APIs, which indeed is not a trivial task. In this paper, we propose a questionnaire-based method, motivated by speech-act theory, to harvest the essential API concepts and their relationships from the functional service requirements. We present our pattern-based implementation of the method. We define a reusable REST API pattern, which can be applied in different contexts to produce an API model according to the REST design principles. The main benefit of the questionaire-based method is on shifting the focus from an operation-based to a resource-oriented mindset. The paper includes an empirical evaluation.	application programming interface;functional requirement;information model;representational state transfer;sequence diagram;unified modeling language;web service	Mikko Hartikainen;Markku Laitkorpi;Anna Ruokonen;Tarja Systä	2011	2011 13th IEEE International Symposium on Web Systems Evolution (WSE)	10.1109/WSE.2011.6081831	web service;unified modeling language;simulation;computer science;operating system;software engineering;database;multimedia;programming language;law;world wide web;server	SE	-48.71383535861401	18.628703866257915	45049
ba41362645dd1770500cf5ce75fd0aebbfa9f53c	conformance testing for quality assurance of clustering architectures	load balancing based architectures;conformance testing;timed automata;online model based testing	Given the scalability of load balancing based architectures, it is increasingly necessary to develop appropriate quality assurance methodologies and techniques, of which Testing is widely adopted and used one. This paper describes a distributed platform for checking the conformance between real functioning of a given load balancer and its specified requirements. Our solution is based on Timed Automata as model for testing supported load balancing algorithms. This paper also shows a novel prototype tool support, LBACT, implemented for quality assurance of load balancing based architectures. Finally, we illustrate our contribution in the context of BPEL clustering mechanisms.	algorithm;business process execution language;cluster analysis;conformance testing;institute for operations research and the management sciences;load balancing (computing);model-based testing;prototype;requirement;scalability;timed automaton	Afef Jmal Maâlej;Zeineb Ben Makhlouf;Moez Krichen;Mohamed Jmaiel	2013		10.1145/2489300.2489338	embedded system;real-time computing;computer science;conformance testing;distributed computing	SE	-51.891961356098335	18.345486135191454	45064
6262889c050a84d364bef6a776e29b11ed8eb522	ethnographic data for product development: a collaborative process	product development	As user-interface specialists, the authors have developed a process for using ethnographic data to drive design in a product development environment. This process involves three main steps: collecting observational data, analyzing the data to produce a model useful for design, and successfully communicating the results of this analysis to all project teamment. For each of these three steps, we detail our approach and experiences with the process, discuss the artifacts and models that we produced, and present the tools used.	artifact (software development);new product development;systems design;user interface	Scott Lewis;Michael Mateas;Susan Palmiter;Gene Lynch	1996	Interactions	10.1145/242485.242505	computer science;systems engineering;new product development	HCI	-62.35533617305676	18.91605552365951	45204
13fc2d55745ef8961680d880eb81ea1d20353e99	early validation of control software for automation plants on the example of a seawater desalination plant		In automation plants, the software that controls the behavior of a plant must adhere to strict process requirements arising from the technical processes and from the physical plant design. In current practice, the validation of the control software starts late in the engineering process – in many cases not before the plant is almost completely constructed, leading to increased efforts for correcting revealed defects. Based on an industrial example, we propose an approach that allows early validation of automation software against the plant processes and assumptions about the physical plant design through simulation.	automation;business process;content-control software;executable;information system;list of version control software;physical plant;requirement;simulation;software system	Veronika Brandstetter;Andreas Froese;Bastian Tenbergen;Andreas Vogelsang;Jan Christoph Wehrstedt;Thorsten Weyer	2015			automation;systems engineering;engineering design process;desalination;software;process engineering;physical plant;engineering	EDA	-61.801096021073334	20.521135109785778	45321
bcec8da1018ff7efebbbaceab4bc6603f28698ac	component-oriented version management for hardware software co-design	large applications;software testing;hardware software co design;code coverage;system design;software development;version management	Nowadays, the development of modern computing devices involves a substantial and growing part of software development. A great challenge for engineers is to manage the evolution of a system with several components in the face of mounting complexity due to concurrent hardware and software development. This paper presents our preliminary research results on a novel component-oriented version management mechanism that is capable of versioning the underlying logical contents of components in system design models and associated software artifacts in a cohesive manner. We have applied this approach to create a prototype of a versioning system for hardware software co-design.	graph (discrete mathematics);prototype;software development;systems design;version control	Tien N. Nguyen;Zhao Zhang	2006		10.1145/1188966.1189009	personal software process;verification and validation;software sizing;computer science;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;software engineering;software construction;hardware architecture;database;distributed computing;software testing;code coverage;programming language;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software system;systems design;software peer review	SE	-52.0491985293958	29.612765851969996	45537
ee4d0f17bb3a033b4c2b4db4d07017207b0eb04c	using tranformation rules to align requirements and archictectural models	software;model quality improvement stream strategy structural architectural model goal oriented requirements model alignment requirements model preparation architectural solution generation architectural solution selection architecture refinement horizontal transformation rule vertical transformation rule refactored i models istar models transformation language qvto process productivity improvement;formal specification;automation requirements engineering software architecture transformation rules;software maintenance;requirements engineering;connectors;computer architecture;software architecture;transforms;video recording;transformation rules;connectors video recording software reactive power computer architecture automation transforms;software quality formal specification software architecture software maintenance;software quality;reactive power;automation	In previous works we have defined the STREAM strategy to align requirements and architectural models. It includes four activities and several transformations rules that could be used to support the systematic generation of a structural architectural model from goal oriented requirements models. The activities include the Preparation of Requirements Models, Generation of Architectural Solutions, Selection of Architectural Solution and Refinement of the Architecture. The first two activities are time consuming and rely on four horizontal and four vertical transformation rules which are current performed manually, requiring much attention from the analyst. For example, the first activity consists of the refactoring of the goal models, while the second one derives architectural models from the refactored i* (iStar) models. In this paper we automate seven out of the eight transformation rules of the two first activities of STREAM approach. The transformation language used to implement the rules was QVTO. We rely on a running example to illustrate the use of the automated rules. Hence, our approach has the potential to improve the process productivity and the quality of the models produced.	acme;align (company);code refactoring;eclipse;hoc (programming language);input/output;refinement (computing);requirement;transformation language;xml metadata interchange	Monique Soares;Carla Schuenemann;Gabriela Guedes;Jaelson Brelaz de Castro;Cleice Talitha Nascimento Souza;Tarcísio Pereira	2013	2013 27th Brazilian Symposium on Software Engineering	10.1109/SBES.2013.8	reliability engineering;computer science;systems engineering;software engineering	SE	-53.00397273842173	24.893019002148606	45827
643281cf689fdb88b43eaf3226d1b309041b72e8	information modelling of edif	design automation;information model;design automation data models permission computer science very large scale integration documentation reverse engineering computer aided engineering proposals formal specifications;very large scale integration;formal specifications;modelling framework;permission;modelling language;levels of abstraction;computer aided engineering;information modelling;computer science;proposals;documentation;reverse engineering;data models	This paper introduces a modelling framework for capturing the semantics of VLSI CAD design objects. It summarizes the EXPRESS modelling language which has been used to model the EDIF Information Model. The model presented here, which supports existence-dependency, multiple levels of abstraction, hierarchical decomposition and connectivity, provides a platform for the integration of EDIF with different standards.	information model;modeling language;principle of abstraction	Rachel Y. W. Lau;Hilary J. Kahn	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.164892	electronic design automation;documentation;information model;computer science;systems engineering;operating system;software engineering;programming language;reverse engineering	EDA	-49.92683460349129	27.220845774405692	46148
c95a64ee7f942f42acbce8ad6b5c712c91664624	dsm'14: the 14th workshop on domain-specific modeling	modeling languages;code generation;metamodeling;domain specific languages	Domain-Specific Modeling (DSM) has proven to be a viable solution to the challenges related to abstraction mismatches between the problem and solution spaces. In many cases, DSM assists in the generation of final products from high-level models that are specific to a domain in terms of abstractions and representation. This automation is possible because both the language and generators are tailored for one domain. This paper introduces DSM and describes the related workshop at SPLASH 2014 (21 October 2014, Portland, Oregon).	domain-specific modeling;high- and low-level	Jonathan Sprinkle;Matti Rossi;Jeffrey G. Gray;Juha-Pekka Tolvanen	2014		10.1145/2660252.2662135	metamodeling;computer science;domain-specific language;modeling language;programming language;algorithm;code generation	AI	-50.97213182424502	25.04297802749141	46329
704add040ea3ca65b8bd5d728eed5a82fa5e71fe	the general problem solver as a paradigm for software design	software design		general problem solver;software design	Ranan B. Banerji	1992			computational science;computer architecture;verification and validation;software sizing;computer science;package development process;backporting;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;software design description;object-oriented design;software construction;resource-oriented architecture;goal-driven software development process;software requirements;software system	SE	-51.22476348820542	28.465871695500656	46406
4179c9cf3af116b999fe3b214741bf700c10888d	a uml profile for real time industrial control systems		A model is a simplified representation of the reality. Software models are built to represent the problems in an abstract way. Unified modeling language is a popular modeling language among software engineering community. However, due to the limitations of unified modeling language it does not provide complete modeling solution for different domains, especially for real time and industrial control system domains. The object-oriented modeling of real time industrial control systems is in its growing stage. In this research we have evaluated the existing profiles for modeling real time industrial control systems. We have identified limitations of the existing modeling notations and proposed a new profile which overcomes the existing limitations. Our profile is based on unified modeling language’s standard extension mechanism and the notations/symbols used are according to international electrotechnical committee standard.	control system;profile (uml)	Kamran Latif;Aamer Nadeem;Gang-soo Lee	2011		10.1007/978-3-642-27207-3_11	uml tool;applications of uml	Robotics	-52.076582896392274	24.526434299982533	46472
0ad7d8632cdfcc4b8e31e3128c79e5e05d425588	software reliability growth models incorporating fault dependency with various debugging time lags	software reliability program debugging;developpement logiciel;software reliability modeling;modelizacion;debugging;puesta a punto programa;poisson process;time dependent;software reliability debugging fault detection delay effects computer science programming reliability engineering application software software systems computer applications;software reliability growth models;time dependent delay function software reliability growth models fault dependency debugging time lags failure free software operation probability fault detection fault correction software reliability modeling;time dependent delay function;probabilistic approach;probability of failure;delai;debogage;modelisation;plazo;detection defaut;dependance du temps;time dependence;fault correction;desarrollo logicial;enfoque probabilista;approche probabiliste;fault detection;software development;time lag;fault dependency;proceso poisson;software debugging;temps retard;failure free software operation probability;program debugging;delay time;fiabilite logiciel;fiabilidad logicial;software reliability growth model;modeling;software reliability;tiempo retardo;deteccion imperfeccion;dependencia del tiempo;processus poisson;defect detection;debugging time lags;free software	Software reliability is defined as the probability of failure-free software operation for a specified period of time in a specified environment. Over the past 30 years, many software reliability growth models (SRGMs) have been proposed and most SRGMs assume that detected faults are immediately corrected. Actually, this assumption may not be realistic in practice. In this paper we first give a review of fault detection and correction processes in software reliability modeling. Furthermore, we show how several existing SRGMs based on NHPP models can be derived by applying the time-dependent delay function. On the other hand, it is generally observed that mutually independent software faults are on different program paths. Sometimes mutually dependent faults can be removed if and only if the leading faults were removed. Therefore, here we incorporate the ideas of fault dependency and time-dependent delay function into software reliability growth modeling. Some new SRGMs are proposed and several numerical examples are included to illustrate the results. Experimental results show that the proposed framework to incorporate both fault dependency and time-dependent delay function for SRGMs has a fairly accurate prediction capability	average-case complexity;categorization;debugging;fault detection and isolation;numerical analysis;reliability engineering;software development;software quality;software reliability testing	Chin-Yu Huang;Chu-Ti Lin;Sy-Yen Kuo;Michael R. Lyu;Chuan-Ching Sue	2004	Proceedings of the 28th Annual International Computer Software and Applications Conference, 2004. COMPSAC 2004.	10.1109/CMPSAC.2004.1342826	reliability engineering;embedded system;real-time computing;systems modeling;poisson process;computer science;software development;operating system;software engineering;programming language;debugging;fault detection and isolation;software quality;statistics	SE	-62.15737314370084	32.13985092975658	46530
8bf64fa7a09d58e1cb03d9f4e052b38f6253bcc7	an ameliorated methodology for the abstraction of object oriented features from software requirements specification		The Business Process (BP) requirements is specified in the form of software requirements specification (SRS). This SRS serves as a base for software development. The software needs to be developed in a syllogized software development life cycle (SDLC) stages. The SRS which denote the requirements of BP is used as input to the analysis stage from which the paradigm dependent components are to be abstracted. Hither to the components are abstracted manually with the exception of hiatuses of semi-automated methods for few of the components. The SRS is construed with reference to the specific paradigm through which the design is to be developed. Unfortunately, no complete automated methodology exists for the abstraction of all paradigm dependent components. The automated methodology eliminates the possible human errors which would have ripple effect to damage the entire software. This paper develops an innovative, unique methodology to resurrect the SRS statements as modular statements. Further develops an automated methodology for abstraction of control and data flow graphs. Further it develops an automated methodology for abstraction of useful components required for the class diagram. The class diagram emphasizes both structural and behavioral aspects. This facility is effectively used to abstract object class attributes, object methods, visibility, signature, return type etc.#R##N##R##N#Information systems are developed through software projects which use the specific software requirements specification (SRS) provided for them as the base. The SRS contains details of the information system through which appropriate software can be developed. The information systems are also viewed perceptively with different pragmatics like work, work process or usecase. The usecase is one of the prime perspective views whose sum forms the information system. In this paper, an attempt is made to abstract object class, object class attributes, object methods, interrelationships between object classes and starting with/ending with actor from unformatted, unstructured SRS text. This is achieved through our own developed classing and slicing techniques to identify respectively the class structure & object methods. Then usecase is developed through the interrelationships between object methods of different classes and start with or end with the actor. The stages involve moulding the SRS, designing control flow graph for the SRS & data flow table for the SRS statements, developing appropriate classing and slicing criteria, creating actor & actors’ interface attributes table, create slicing criteria for each usecase and then slice relevant statements for each usecase. Here, we have attempted to use Weiser modified algorithm1 to abstract exact usecase. The slicing criterion is obtained through the intersection of actor's interface attributes and the referenced/defined attributes present between two consecutive actors. Attempts have been made to resolve synonyms & heteronyms present in the SRS. The correctness & completeness of the proposed methodology depends on the realization of actor & actors’ interface attributes.	software requirements specification	M. A. ShivaramA.;Shivanand M. Handigund	2015		10.1016/j.procs.2015.08.450	simulation;computer science;artificial intelligence;operating system;data mining;database;programming language;algorithm	SE	-53.970780134959234	29.682545757983046	46593
bb17551253ae255d7ca494c9aec8c5c7ba17af71	microservices: how to make your application scale		The microservice architecture is a style inspired by serviceoriented computing that has recently started gaining popularity and that promises to change the way in which software is perceived, conceived and designed. In this paper, we describe the main features of microservices and highlight how these features improve scalability.	microservices;scalability	Nicola Dragoni;Ivan Lanese;Stephan Thordal Larsen;Manuel Mazzara;Ruslan Mustafin;Larisa Safina	2017		10.1007/978-3-319-74313-4_8	systems engineering;architecture;computer science;microservices;scalability;software;popularity	SE	-60.009180500321115	21.488914098700004	46606
0b626ab836c7f23616cc394080126d1ce8509e21	improving tests infrastructure through a model-based approach	mdarte;activity diagram;software testing;mda;flow;model based approach;test;software development;unified modeling language;andromda;junit;model driven architecture	Software tests have a high impact on the cost of software development. In practice, they are generally created at random and without any methodology, and do not have sufficient documentation. Commonly used approaches also perform the tests outside the application environment (e.g. web servers and containers). Besides, the test cases are usually restricted to target business components behavior, leaving a huge gap by not evaluating the presentation layer. Most of these practices can be explained by the overhead required to maintain manually the whole test artifacts. Applying a Model-based Approach (MBA), the creation and maintenance of test artifacts can be automated. This paper proposes a method that applies the Model-driven Architecture (MDA), a strategy of MBA, to determine the flow of test cases. The proposed method was based on the use of Unified Modeling Language (UML) activity diagrams. These diagrams allow determining the test flows and the objective of each activity, such as testing of business and presentation layers. Moreover, the generated test artifacts allow for performing the tests inside the application environment.	activity diagram;documentation;model-driven architecture;model-driven integration;overhead (computing);randomness;software development;test case;unified modeling language;web server	Roque Elias Assumpção Pinel;Filipe Braida do Carmo;Rodrigo Salvador Monteiro;Geraldo Zimbrão	2011	ACM SIGSOFT Software Engineering Notes	10.1145/1921532.1921544	reliability engineering;simulation;computer science;systems engineering;engineering;software engineering;test suite;dynamic testing;software testing;test case;test management approach;test harness	SE	-57.4673805522882	29.630787238495607	46940
a43070120215c0e4fb6d77b810e08f8513bddd08	system for automotive machine vision		The consumer automotive market is going through rapid changes. To preserve the competitiveness each new generation of advanced driver assistance systems (ADAS) heavily adds to a complexity of the hardware platform. Analysis of the latest ADAS systems, their existing and missing requirements, is a foundation for the development of the Alpha board, the hardware platform for ADAS applications. In this paper we describe the automotive vision upgrade for ADAS.	architecture design and assessment system;machine vision;requirement	Natasa Perkovic;Milos Pranjkic;Igor Kolak;Gordana Velikic	2017	2017 IEEE 7th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)	10.1109/ICCE-Berlin.2017.8210638	computer engineering;advanced driver assistance systems;automation;upgrade;machine vision;automotive industry;engineering	Robotics	-61.99970594123192	24.020046909835877	47087
cff15ea8f87d63cae96b8aeaecf2ccea4989da35	descots-ev: a tool for the evaluation of cots components	taxonomy quality management iso standards iec standards project management;formal specification;factor requirement negotiation descots ev cots component selection user requirement quality requirement;object oriented programming;quality requirement;user requirements;software tools object oriented programming software selection formal specification;software tools;quality model;software selection	In the last years, some methods have been proposed for dealing with COTS component selection. In all of them, a key point is the comparison of the user requirements, which drive the selection process, with the capabilities of the evaluated COTS. Quality models are a means to obtain structured descriptions of COTS domains. Once built, COTS in a domain may be evaluated with respect to the quality entities included therein, quality requirements may be stated with respect to the quality model, and the classical factor-requirement negotiation process may be used for the selection of the most appropriate COTS. Our goal is to have completely implemented in a near future a new version of the system DesCOTS (Grau et al., 2004) that supports all the above processes. This system is constituted by 4 subsystems: QM, that helps in the construction and management of quality models (Carvallo et al., 2004); EV, that helps in the evaluation of COTS components and that is the one presented in this paper; SL, that helps in the definition of requirements in a project and in the selection of COTS components that hold these requirements; and AD, that allows the administration of the whole system.	entity;extended validation certificate;requirement;sl (complexity);user requirements document	Carme Quer;Xavier Franch;Xavier Lopez-Pelegrin	2005	13th IEEE International Conference on Requirements Engineering (RE'05)	10.1109/RE.2005.22	reliability engineering;computer science;systems engineering;engineering;user requirements document;software engineering;formal specification;programming language;object-oriented programming	Embedded	-56.25895914865045	26.908017165260933	47167
6b69ff4fdc6f66b500e5071cd1c2638582edc7e6	an evaluation method for aspectual modeling of distributed software architectures	distributed system;program diagnostics;high level languages;comparative analysis;formal specification;architecture description language;distributed processing;evaluation method;software performance evaluation;object oriented programming;program verification;aspect oriented architectural description languages;non functional requirement;software requirements;distributed software architectures;software architecture;quality requirement;software architecture analysis;quality requirement verification;object oriented;distributed software architecture;software development;software architecture computer architecture risk analysis application software packaging software quality distributed computing programming encapsulation software testing;aspectual modeling evaluation;aspect oriented;software quality distributed processing formal specification high level languages object oriented programming program diagnostics program verification software architecture software performance evaluation;nonfunctional requirements;software architecture analysis method;object oriented implementation;distributed systems;archc language;software quality;object oriented implementation aspectual modeling evaluation distributed software architectures software requirements software development aspect oriented architectural description languages software architecture analysis quality requirement verification archc language nonfunctional requirements distributed systems	Dealing with crosscutting requirements in software development usually makes the process more complex. Modeling and analyzing of these requirements in the software architecture facilitate detecting architectural risks early. Distributed systems have more complexity and so these facilities are much useful in development of such systems. Aspect oriented Architectural Description Languages (ADD) have emerged to represent solutions for discussed problems; nevertheless, imposing radical changes to existing architectural modeling methods is not easily acceptable by architects. Software architecture analysis methods, furthermore, intend to verify that the quality requirements have been addressed properly. In this paper, we enhance ArchC# through utilization of aspect features with an especial focus on Non-Functional Requirements (NFR). ArchC# is mainly focused on describing architecture of distributed systems; in addition, it unifies software architecture with an object- oriented implementation to make executable architectures. Moreover, in this paper, a comparative analysis method is presented for evaluation of the result. All of these materials are illustrated along with a case study.	aspect-oriented programming;distributed computing;executable architecture;non-functional requirement;qualitative comparative analysis;sensor;software architecture;software development	Hamid Bagheri;Vajih Montaghami;Gholamreza Safi;Seyed-Hassan Mirian-Hosseinabadi	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493639	reference architecture;software architecture;database-centric architecture;architectural pattern;computer science;service-oriented modeling;software engineering;software architecture description;programming language;object-oriented programming;non-functional requirement	SE	-52.00583101849711	28.587651936028966	47292
79427f8e216c783a03b1049bb9241fae89e0aa24	integrating software process reuse and automation	specification languages software reusability;product line;specification languages;software reusability;automation software process product line;software automation unified modeling language context metamodeling manuals engines;software process;process variability software process reuse software process automation software process line spl development cost tool supported approach project requirement process execution modeling language;automation	Reusing software processes from a Software Process Line (SPL, i.e., a set of software processes that captures their commonalities and variabilities) and automating their execution is a way to reduce development costs. However, to our best knowledge no approach integrates both aspects. The difficulty is to automate the execution of a process whose variability is only partially resolved (i.e., a value is not set to each variable part of the process). Indeed, according to projects' constraints, it is possible to start the execution of a part of a process whose variability is resolved, while postponing the resolution of the variability of other parts of this process. In this paper, we propose a tool-supported approach that integrates both aspects. It consists of reusing processes from an SPL according to projects' requirements. The processes are bound to components that automate their execution. When the variability of a process to execute is not fully resolved, our approach consists of resolving this variability during the execution of this process. We illustrate this work on a family of processes for designing and implementing modeling languages. Our approach enables both the reuse of software processes and the automation of their execution, while enabling to resolve process variability during the execution.	automation;heart rate variability;metamodeling;modeling language;process modeling;requirement;software development process;spatial variability	Emmanuelle Rouillé;Benoît Combemale;Olivier Barais;David Touzet;Jean-Marc Jézéquel	2013	2013 20th Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2013.58	reusability;personal software process;verification and validation;team software process;real-time computing;design process;software engineering process group;computer science;systems engineering;process automation system;package development process;backporting;software design;component-based software engineering;software development;automation;software engineering;domain engineering;software construction;empirical process;software measurement;software deployment;goal-driven software development process;software development process;avionics software	SE	-55.60750940678745	26.635421684687877	47424
046d7d6b94dac46bb986926627c491c74557cbea	a language for high-level description of adaptive web systems	domain specific programming language;product line;development process;software engineering;new brunswick;adaptive web system;design and implementation;aspect oriented programming;adaptive system;domain specific language;software quality	This paper focuses on the proposal, design, and implementation of AWL, the Adaptive Web Language. Also, an example application named PENS is explained and implemented in AWL. AWL development was inspired by several issues and shortcomings in the development of adaptive Web systems using the framework for adaptive Web systems, developed in the Intelligent and Adaptive Systems Research Group, at the University of New Brunswick, Fredericton, Canada. Lack of verification mechanisms and difficulty in development are two of the existing issues in the framework. Not only does AWL address those issues in the framework, but it also offers mechanisms to increase software quality attributes, especially, reusability. AWL has been designed based on the analysis of adaptive Web systems, having taken into account the principles of reuse-based software engineering (product-lines), domain-specific languages, and aspect-oriented programming, all of which are ongoing research fields in software engineering research. A compiler, named AWL Compiler has been developed, as the implementation of AWL for our adaptive Web framework. AWL Compiler automates the development process through hiding the framework internals from the application designer, and provides verification services so that applications can be verified to be consistent and meaningful. PENS, a personalized e-News system, is explained and its various aspects are developed using AWL.	adaptive system;aspect-oriented programming;compiler;digital journalism;domain-specific language;high- and low-level;list of system quality attributes;personalization;software engineering;software quality;web language;web framework	S. Hossein Sadat-Mohtasham;Ali A. Ghorbani	2008	Journal of Systems and Software	10.1016/j.jss.2007.08.033	web modeling;simulation;aspect-oriented programming;computer science;systems engineering;domain-specific language;adaptive system;operating system;software engineering;programming language;software development process;software quality	SE	-53.22695610107625	29.506474839190503	47478
51cf85c6689d7b39dd60b1c88e2e8a9d66052282	sate--service boundary and abstraction threshold estimation for efficient services design	software;design principle;interaction point;complexity theory;service abstraction threshold estimator;service provider;measurement;reusability;service oriented architecture business maintenance engineering software engines complexity theory measurement;sate;external representation;maintenance engineering;threshold estimation engine;soa;software engineering;development environment;engines;service boundary;levels of abstraction;granularity;software engineering service oriented architecture;service providing environment;business;service consumer;service design;software architects;service abstraction threshold estimation;service oriented architecture;software architects sate service boundary service abstraction threshold estimation service design soa reusability service providing environment service consumer granularity service abstraction threshold estimator threshold estimation engine	The key to successful adoption of SOA is not only reusability but also the ease with which services can be developed, deployed and maintained in a service providing environment. One key guiding principles of SOA is implementation abstraction, that fosters complete encapsulation of implementations, exposing only the primitives as interaction points with the service. Granularity of service abstractions defines the different level of primitives exposed to prospective service consumers. The primitives being the only external representation for a service, their design is extremely important as the granularity not only determines the ease with which the services are identified, but also the ease with which services realization can be achieved. So far there has been no systematic approach to apply design principles such that right level of abstractions can be defined. We present a tool called Service Abstraction Threshold Estimator (SATE). Given the available implementation artifacts, SATE allows varying levels of primitives to be defined, elicits the complexity associated with different levels of primitives and provides a threshold estimation engine that displays the optimal level of abstraction that can be achieved in a given service development environment. We demonstrate SATE on a real-world example, and also evaluate SATE against design decisions taken by software architects. The results of our evaluation show that SATE can provide more accurate threshold estimations, and also helps in reducing the time and effort taken to maintain already developed services.	encapsulation (networking);language primitive;prospective search;service abstraction;software architect	Kalapriya Kannan;Gandhi Sivakumar;Nanjangud C. Narendra	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.9	real-time computing;simulation;computer science;systems engineering	Mobile	-56.79663375703792	21.570187234480336	47543
9befc4bc690bcb000404e56ade6377272f79abcd	"""""""design by contract"""" + """"componentware"""" = """"design by signed contract"""""""	signed;component based systems;software systems;satisfiability;componentware;formal verification;contract;software development;design;design by contract	"""The main goal of """"Design by Contract"""" is to improve correctness and robustness of software systems. For this purpose, the interfaces of classes or modules are augmented with precise specifications containing assertions. By means of these assertions, a supplier of a service imposes contractual obligations that his clients have to fulfill. ”Componentware” introduces a new software development paradigm. Systems are no longer implemented from scratch, but glued together from existing components. In this paper, we show why and how the concepts of pure design by contract fail in the context of component-based system development. In order to leverage the vision of design by contract to its full extent for component-based system development, we introduce the new concept of “Design by Signed Contract”. Signed contracts enable us to specify not only what a supplier provides to its environment, but also what a client needs from its environment. Signed contracts guarantee that client needs are satisfied by corresponding properties provided by suppliers. We show how signed contracts can be used for a more precise specification of the composition of component-based systems and a more formal verification of the correctness of these systems. Thereby, software system defects can already be detected and prevented at the specification level. 1 This work originates from the research project ZEN – Center for Technology, Methodology and Management of Software & Systems Development – a part of Bayerischer Forschungsverbund SoftwareEngineering (FORSOFT), supported by the Bayerische Forschungsstiftung. “DESIGN BY CONTRACT” + “COMPONENT WARE” = “DESIGN BY SIGNED CONTRACT” 20 JOURNAL OF OBJECT TECHNOLOGY VOL. 1, NO. 3"""	client (computing);component-based software engineering;correctness (computer science);design by contract;formal verification;programming paradigm;robustness (computer science);software development;software system;the journal of object technology;type system	Andreas Rausch	2002	Journal of Object Technology	10.5381/jot.2002.1.3.a2	contract;reliability engineering;contract management;design;formal verification;computer science;systems engineering;design by contract;software development;programming language;engineering drawing;satisfiability	SE	-58.18460108440006	27.535729141879507	47611
3a54788cd723954f1cf265cd5f612a9deb498076	software engineering for parallel systems	software engineering;parallel systems	Current approaches to software engineering practice for parallel systems are reviewed. The parallel software designer has not only to address the issues involved in the characterization of the application domain and the underlying hardware platform, but, in many instances, the production of portable, scalable software is desirable. In order to accommodate these requiremerits, a number of specific techniques and tools have been proposed, and these are discussed in this review in the framework of the parallel software life-cycle. The paper outlines the role of formal methods in the practical production of parallel software, but Rs main focus is the emergence of development methodologies and environments. These include CASE tools and run-time support systems, as well as the use of methods taken from experience of conventional software development. Because of the particular emphasis on performance of parallel systems, work on performance evaluation and monitoring systems is considered.	application domain;computer-aided software engineering;emergence;formal methods;performance evaluation;scalability;software design;software development;software release life cycle	Innes Ritchie;Ian Gorton	1994	Information & Software Technology	10.1016/0950-5849(94)90060-4	domain analysis;verification and validation;software engineering process group;software sizing;computer science;systems engineering;package development process;social software engineering;software framework;software development;software design description;software engineering;domain engineering;software construction;systems development life cycle;software walkthrough;software analytics;software deployment;computer-aided software engineering;software development process;software requirements;software system;computer engineering;software peer review	SE	-52.022218374936266	28.9020386131521	47784
c6bee3a7f690035a628d3d71ddbf58d8dd1a02a1	bridging abstraction layers in process mining: event to activity mapping		While the maturity of process mining algorithms emerges and more process mining tools enter the market, process mining projects still face the problem of different levels of abstraction when comparing events recorded by supporting IT systems with defined business activities. Current approaches for event log abstraction most often try to abstract from the events in an automated way which does not capture the required domain knowledge to fit business activities. This can lead to misinterpretation of discovered process models and wrong conformance results. We developed an approach which aims to abstract an event log to the same abstraction level which is needed by the business. Therefore, we capture domain knowledge about event to activity mappings in a formalized way and propose an algorithm to correctly cluster events to activity instances. We evaluated our approach in a case study with a German IT outsourcing company.	bridging (networking)	Thomas Baier;Jan Mendling	2013		10.1007/978-3-642-38484-4_9	real-time computing;data mining;database	HCI	-54.529180355190704	18.488819302538868	47870
6a8b4093f3c74f64f2b9fe15034392b0ae1152ec	building dynamic application networks with web services	xml schema;rate of change;software platform;similarity enhancement;application server;semantic integration of heterogeneous data;web service;development tool;operating system;specific activity;next generation;ontologies;xml databases;large classes	"""Looking at the state of the industry today, it is clear that we are in the early stages of Web Services development. Companies are still evaluating what the technology and considering how to apply it to their business. But over the past year, we seem to have reached an inflection point of companies building real systems based on Web Services. Partly this reflects an acceptance that the basic Web Services technologies - XML Schema [1][2], SOAP [3], WSDL [4] - have matured to the point where they can be used for mission critical applications. But it also reflects a growing understanding that Web Services enable a large class of systems that were previously very difficult to build. These systems are characterized by several critical properties:1. Rapid rates of change. The time is long past when companies could afford a year-long-effort to build out a new application. Businesses move at a faster pace today then ever before, and they are increasingly under pressure to do more work with fewer resources. This places a premium on the ability to build applications by quickly composing pre-existing services. The result is that systems are being connected in ways that were never imagined during development. This is reuse in the large - not just small services, but entire applications being linked together to solve a complex business function.2. Significant availability and scalability requirements. Many of these systems are """"bet-your-business"""" types of applications. They have heavy scalability and availability requirements. Often then need to connect multiple partners and service hundreds of thousands of updates in a day, without ever suffering an interruption in service.3. Heterogeneous development tools and software platforms. Each of these applications typically involves components built using a wildly diverse set of tools, operating systems, and software platforms. Partly this is a result of building systems out of existing components - many of these components are locked into certain environments, and there are no resources to rewrite or migrate to a single homogenous platform. But it is also recognition that different problems are best solved by different toolsets. Some problems are best solved by writing code on an application server, others are best suited for scripting, and still others are solved by customizing an existing enterprise application. Heterogeneity is not going away. It is only increasing.4. Multiple domains of administrative control. An aspect of heterogeneity that is often overlooked is distributed ownership. As businesses merge, acquire, and partner with other companies, there is an increasing need to build applications that span organizational boundaries.These characteristics present a unique set of challenges to the way we think about developing, describing, connecting, and configuring applications. The challenges require us to develop new ways of looking at what it takes to build an application, and what makes up a network.In this session, we examine the nature of this next generation of application, and discuss the way in which Web Services are evolving to meet their needs. The session focuses on the development techniques that allow services to be easily and dynamically composed into rich applications, and considers the capabilities required of the underlying network fabric. The session concludes with an in-depth look at some of the critical Web Services specifications actively under development by industry leaders."""	application server;enterprise software;interrupt;mission critical;next-generation network;operating system;programming tool;requirement;rewrite (programming);soap;scalability;server (computing);web services description language;web service;xml schema	Matthew Mihic	2004		10.1145/1007568.1007674	web service;web development;computer science;ontology;ws-policy;specific activity;data mining;xml database;xml schema;database;services computing;web engineering;programming language;world wide web;application server	OS	-58.69693250146154	20.174792120474727	47998
3208bd2b4c66f312e82048c0795a09f7a2dcabe5	refactoring to aspects: an interactive approach	project management;small teams;software systems;software engineering education;aspect oriented programming;software quality;software process	Current refactorings for restructuring existing software systems preserve the behavior of the software. Aspect-oriented programming constructs make existing refactorings more complex, and introduce the potential for new kinds of refactorings that target entire concerns. In many cases, behaviour preservation may be neither possible nor desirable. In this position paper, we propose an approach to refactoring aspects into a system that actively involves a developer in a dialogue with the refactoring tool. We are exploring this approach by developing two Eclipse plug-ins: one which bases the refactoring on descriptions of a concern in the code; the other which bases the refactoring on a target aspect structure.	aspect-oriented programming;case preservation;code refactoring;eclipse;plug-in (computing);software system	Jan Hannemann;Thomas Fritz;Gail C. Murphy	2003		10.1145/965660.965676	project management;aspect-oriented programming;computer science;systems engineering;engineering;software development;software engineering;software construction;programming language;software maintenance;software development process;code refactoring;software quality;software system	SE	-54.91740847078903	29.414643958841815	48128
4794457e80c2e252086876eaf5e56709ad794040	proportional intensity-based software reliability modeling with time-dependent metrics	software metrics;goodness of fit;black box approach;time dependent;proportional intensity based software reliability modeling;time dependent metrics;software fault;statistical framework;proportional hazard model;information criteria;non homogeneous poisson process;development process;nonhomogeneous poisson process model proportional intensity based software reliability modeling time dependent metrics black box approach software fault fault detection process statistical framework time dependent covariate metrics based software reliability model;reliability assessment;fault tolerant computing;stochastic processes fault tolerant computing software metrics software reliability statistical analysis;statistical analysis;stochastic processes;metrics based software reliability model;fault detection;software metric;nonhomogeneous poisson process model;fault detection process;time dependent covariate;software reliability prognostics and health management stochastic processes hazards software metrics software testing predictive models software quality software measurement fault detection;software reliability;covariance structure	The black-box approach based on stochastic software reliability models is a simple methodology with only software fault data in order to describe the temporal behavior of fault-detection processes, but fails to incorporate some significant development metrics data observed in the development process. In this paper we develop proportional intensity-based software reliability models with time-dependent metrics, and propose a statistical framework to assess the software reliability with the time-dependent covariate as well as the software fault data. The resulting models are similar to the usual proportional hazard model, but possess somewhat different covariate structure from the existing one. We compare these metrics-based software reliability models with some typical non-homogeneous Poisson process models, which are the special cases of our models, and evaluate quantitatively the goodness-of-fit from the viewpoint of information criteria. As an important result, the accuracy on reliability assessment strongly depends on the kind of software metrics used for analysis and can be improved by incorporating the time-dependent metrics data in modeling	black box;list of software reliability models;software metric;software quality;software reliability testing	Koichiro Rinsaka;Kazuya Shibata;Tadashi Dohi	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.68	reliability engineering;stochastic process;real-time computing;software sizing;computer science;software reliability testing;software metric;statistics	SE	-62.39877025305592	32.049336674415	48157
5e14bef2f7df55795054c28823c6953a72deccaf	pattern-based security requirements specification using ontologies and boilerplates	requirements specification security requirements ontology boilerplates pattern based reuse;formal specification;expert systems;software prototyping;security ontologies semantics cognition missiles software computers;ontologies artificial intelligence;software prototyping expert systems formal specification ontologies artificial intelligence security of data;security of data;security threat scenarios pattern based security requirements specification requirements engineering teams security experts ontology based approach pattern based templates requirements boilerplates prototype tool textual misuse case descriptions tmuc descriptions	The task of specifying and managing security requirements (SR) is a challenging one. Usually SR are often neglected or considered too late - leading to poor design, and cost overruns. Also, there is scarce expertise in managing SR, because most requirements engineering teams do not include security experts, which leads to prevalence of too vague or overly specific SR. In this work, we present an ontology-based approach that uses predefined pattern-based templates - requirements boilerplates - to aid requirements engineers in the formulation of SR. We realized the approach via a prototype tool that enables the formulation of SR from textual misuse case (TMUC) descriptions of security threat scenarios. The results from a preliminary evaluation suggest the viability of the proposed approach, in that the tool was judged as easy to use, supports reuse, and facilitates the formulation of good quality SR.	artificial intelligence;misuse case;ontology (information science);prototype;requirement;requirements engineering;software requirements specification;vagueness	Olawande Daramola;Guttorm Sindre;Tor Stålhane	2012	2012 Second IEEE International Workshop on Requirements Patterns (RePa)	10.1109/RePa.2012.6359973	requirements analysis;software requirements specification;computer science;systems engineering;system requirements specification;data mining;database	SE	-58.10386048389422	23.833018639659734	48392
d330540a4c88aa8dfe28d525e00e375fedcaf194	towards the extraction of variability information to assist variability modelling of complex product lines		Software product line engineering gathers a set of methods that rely on systematic reuse and mass customisation to reduce the development time and cost of a set of similar software systems. Boolean feature models are the de facto standard used to represent product line variability in terms of features, a feature being a distinguishable characteristic of one or several softwares. The extractive adoption of a product line from a set of individually developed softwares requires to extract variability information from a collection of software descriptions to model their variability. With the appearance of more and more complex software systems, software product line engineering faces new challenges including variability extraction and modelling. Extensions of boolean feature models, as multi-valued attributes or UML-like cardinalities have since been proposed to support variability modelling in complex product lines. In this paper, we propose research directions to address the issue of extracting more complex variability information, as a part of extended feature models synthesis from software descriptions. We consider the capabilities of Formal Concept Analysis, a mathematical framework for knowledge discovery, along with two of its extensions called Pattern Structures and Relational Concept Analysis, to answer this problematic. These frameworks bring theoretical foundations to complex variability extraction algorithms.		Jessie Carbonnel;Marianne Huchard;Clémentine Nebut	2018		10.1145/3168365.3168378	software system;data mining;knowledge extraction;reuse;software product line;computer science;reverse engineering;software;de facto standard;formal concept analysis	SE	-54.82304497778321	25.264038323810894	48629
3d51e0ca386620028977b50f9656005cdc54596c	a common basis for modelling service-oriented and event-driven architecture	service orientation;model based approach;higher order;modelling language;model driven engineering;service oriented architecture;enterprise architecture;event driven architecture	Component based approaches to Enterprise Architecture (EA) include Service Oriented Architecture (SOA) and Event Driven Architecture (EDA). Model-based approaches to EA support SOA in terms of components and services expressed as interfaces and messages. However, there are few modelbased approaches that support EDA even though SOA and EDA are both based on components. UML has components, however there is no support for events and no support for component patterns (or templates). This paper describes a simple extension to UML that supports both SOA and EDA. Components have both operation and event interfaces. The modelling language is implemented using a higher-order simulation language where templates are defined as functions over component definitions. The languages are described using a case study that has been implemented in Java.	enterprise architecture;event-driven architecture;event-driven programming;java;serialization;server (computing);service-orientation;service-oriented architecture;service-oriented software engineering;simulation language;systems design;unified modeling language;wrapper library	Tony Clark;Balbir S. Barn	2012		10.1145/2134254.2134258	enterprise architecture framework;reference architecture;model-driven architecture;real-time computing;higher-order logic;common component architecture;computer science;systems engineering;architecture domain;applications architecture;theoretical computer science;software engineering;service-oriented architecture;solution architecture;enterprise architecture;programming language	SE	-49.94911812988782	26.553110073983333	49027
fa3fd017e367b9cd3030ff008e645c5c6170c3e9	knowledge-based software design using design schemas	intelligent design;domain knowledge;polymorphism;software development;software design;reusable component;software specification;knowledge base	Design schemas provide a means for abstracting software designs into broadly reusable components that can be assembled and refined into new software designs. This paper describes a knowledge-based software development paradigm that is based on the design schema representation. It combines design schemas, domain knowledge, and various types of rules to assist in the quick generation of software designs from user specifications. A prototypical environment, IDeA (Intelligent Design Aid), is described that supports the knowledge-based paradigm. The schema-based techniques used in IDeA are presented along with some examples of their use.	database schema;knowledge-based systems;programming paradigm;software design;software development	Mitchell D. Lubars;Mehdi T. Harandi	1987			domain analysis;schema migration;polymorphism;knowledge base;software requirements specification;verification and validation;software mining;computer science;systems engineering;knowledge management;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;database;intelligent design;software walkthrough;programming language;resource-oriented architecture;software deployment;computer-aided software engineering;domain knowledge;software system	SE	-50.91262645929843	27.411114348471965	49107
66393d597676f9d0ce73dbc9ab3955fe5646cbdc	scalability of variability management: an example of industrial practice and some improvements	generative technique;software product line;variability management	Having set up reusable core assets for a Software Product Line (SPL), it is a common practice to apply Variation Techniques (VTs) to manage variant features. As each VT can handle only certain types of variability, multiple VTs are often employed, such as conditional compilation, configuration parameters or build tools. Our earlier study of an SPL at Fudan Wingsoft Ltd revealed potential scalability problems of multiple VTs. As a remedy to the above problems, in the follow-up study we replaced multiple VTs originally used in the Fudan Wingsoft product line, with a single, uniform VT of XML-based Variant Configuration Language (XVCL). This paper provides a proofof-concept that commonly used variation techniques can indeed be superseded by a subset of XVCL, in a simple and natural way. We describe the essence of the XVCL solution, and evaluate the benefits and trade-offs involved in multiple VTs solution and single VT XVCL solution. KeywordsGenerative technique; Software Product Line; Variability management	compiler;conditional compilation;experiment;heart rate variability;interdependence;knowledge-based configuration;scalability;software product line;spatial variability;spl (unix);xml	Yinxing Xue;Stan Jarzabek;Pengfei Ye;Xin Peng;Wenyun Zhao	2011			systems engineering;scalability;computer science	SE	-54.05771940842665	26.33790381633619	49210
f9e45a2f466a1b4ecd1912c67871e51a5fa15ed2	testing techniques for the cross-platform migration of very large interactive applications	software testing;application software;software maintenance;software maintenance program testing;software systems;inspection;large scale;interactive application;program testing;large scale legacy application;very large interactive application;database systems;test methods;xml;system testing;humans;application software inspection large scale systems system testing software systems software testing humans database systems xml service oriented architecture;service oriented architecture;socio technical context software testing very large interactive application large scale legacy application;large scale systems;socio technical context	This case recounts specific application testing techniques that have been used in the real-life cross-platform migration of a large-scale legacy application. In it we review the methodology itself alongside the socio-technical context of the migration, placing an emphasis on the way that the system's users and software were impacted through the choice of testing method	legacy system;real life;sociotechnical system;software modernization;software testing	Louis Heymans;Tony Van der Beken;Ben Wilson	2007	11th European Conference on Software Maintenance and Reengineering (CSMR'07)	10.1109/CSMR.2007.46	application software;xml;inspection;computer science;systems engineering;engineering;software engineering;service-oriented architecture;database;software testing;test method;software maintenance;system testing;software system	SE	-52.67575863724723	31.822724281958756	49213
5245a4d4a30667fe58ef99c18701d493e3e6b18b	making architectural decisions based on requirements: analysis and combination of risk-based and quality attribute-based methods	quality attribute based methods;software;architectural design;resource limitation;quality attributes;systematic analysis;software quality decision making decision support systems inference mechanisms software architecture;decision making architectural decisions quality attribute based methods software architecture software systems architectural design system requirements risk based reasoning linkage quality requirement systematic analysis;system requirements;software systems;inference mechanisms;requirements;requirement analysis;computer architecture;quality attribute based method requirements software architecture decision making risk based reasoning;quality attribute based method;software architecture;quality requirement;cognition;decision support systems;architectural decisions;computer architecture software architecture software cognition decision making couplings concrete;linkage;couplings;software quality;risk based reasoning;concrete	Software architecture is critical to the success of large software systems. It has long been recognized that architectural design has profound impact on the achievement of system requirements. Two typical methods have been proposed to help users to make architectural decisions based on requirements. One method uses risk-based reasoning to help choosing good architectural design that can meet both system requirements and resource limitations, the other one, using quality attribute model as the linkage, enables deriving a fragment of architectural design that is focused on achieving certain quality requirement. However, there is little effort on comparing the two methods to discover similarities and differences. In this paper, we conduct a systematic analysis of the two methods, and compare them from the aspects of system requirements, architectural decisions, and mapping approach. We then propose a procedure to combine the two methods that provides better support to architectural design decision making.	architectural decision;display resolution;level of detail;linkage (software);requirement;requirements analysis;software architecture;software engineer;software system;system requirements	Bingfeng Xu;Zhiqiu Huang;Ou Wei	2010	2010 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing	10.1109/UIC-ATC.2010.74	requirements analysis;decision support system;architectural pattern;computer science;data mining	SE	-59.63347461315729	27.062097950621794	49303
96dc055ee5a7ca5e7f47a3eb0e56ed56bffe5af8	measuring the evolution of meta-models - a case study of modelica and uml meta-models		The evolution of both general purpose and domain-specific meta-models and its impact on the existing models and modeling tools has been discussed extensively in the modeling research community. To assess the impact of domain-specific meta-model evolution on the modeling tools, a number of measures have been proposed by Durisic et al.,NoC(Number of Changes) being the most prominent one. The proposed measures are evaluated on a case of AUTOSAR meta-model that specifies the language for designing automotive system architectures. In this paper, we assess the applicability of these measure and the underlying data-model for their calculation in a case study of Modelica and UML meta-models. Our preliminary results show that the proposed data-model and the measures can be applied to both analyzed meta-models as we were able to capture 68/77 changes on average per Modelica/UML release. However, only a subset of the data-model elements is applicable for analyzing the evolution of Modelica and also certain transformation of the data-model is required in case of UML. Despite these encouraging results, further studies are needed to assess the usefulness of the actual measures, e.g., NoC, in assessing the impact of Modelica/UML meta-model evolution on the modeling tools.	autosar;continuation;data model;evolution;general-purpose markup language;metamodeling;network on a chip;unified modeling language	Maxime Jimenez;Darko Durisic;Miroslaw Staron	2017		10.5220/0006218204960502	uml tool;systems engineering;applications of uml;modelica;programming language	SE	-53.773654768314564	25.45209963620574	49385
056d173d631ae8fec547fa0666a6e35c09f81386	the pdp-11 virtual machine architecture: a case study	virtual machine;virtual machine monitor;ucla;software structure;pdp 11 45;hardware architecture;computer security;computer architecture;virtual machines;software development	At UCLA, a virtual machine system prototype has been constructed for the Digital Equipment Corporation PDP-11/45. In order to successfully implement that system, a number of hardware changes have been necessary. Some overcome basic inadequacies in the original hardware for this purpose, and others enhance the performance of the virtual machine software. Steps in the development of the modified hardware architecture, as well as relevant aspects of the software structure, are discussed. In addition, a case study of interactions between hardware and software developments is presented, together with conclusions motivated by that experience.	interaction;pdp-11;prototype;virtual machine	Gerald J. Popek;Charles S. Kline	1975		10.1145/800213.806527	reference architecture;hardware compatibility list;computer architecture;full virtualization;storage hypervisor;computer science;virtual machine;operating system;hardware architecture;software architecture description;abstract machine;resource-oriented architecture;virtual finite-state machine;systems architecture	Arch	-49.890918432382776	31.645961470854655	49419
9fa209963de31e17fdcb0074bb9f1b445845150b	css code quality: a metric for abstractness; or why humans beat machines in css coding	code quality;quality metric;document handling;complexity theory;measurement;human authored code;quality metrics;cascading style sheets;abstractness factor;semantics;css code quality;presentation authoring;html;humans;cascading style sheets css code quality abstractness metric css coding abstractness factor quality metric human authored code;css coding;encoding;encoding document handling;quality metrics cascading style sheets code quality presentation authoring;graphics;abstractness metric;graphic design;html encoding measurement semantics humans complexity theory graphics	Authoring CSS is a complex, time consuming task requiring not only skilled human graphic designers but also skilled human coders. Practice shows that today human authored code is still superior to machine generated CSS, but the code characteristics which make the difference have not been researched or even quantified yet. In this paper we introduce the abstractness factor, a quality metric which reveals the advantages of human authored code and can serve as an optimization criterion and benchmark for automated CSS coding. We argue that a high abstractness factor represents a high maintainability and reusability of the presentation document as well as the content document. By an evaluation of 100,000 HTML pages randomly gathered from the Web we show that today’s typical style sheet document has a significantly higher abstractness factor compared to code fully machine generated by state-of-the-art applications.	algorithm;benchmark (computing);css code;cascading style sheets;complexity;display resolution;html;humans;mathematical optimization;prototype;randomness;software quality;style sheet (web development);wysiwyg;world wide web	Matthias Keller;Martin Nussbaumer	2010	2010 Seventh International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2010.25	graphic design;html;computer science;graphics;software engineering;database;semantics;multimedia;cascading style sheets;programming language;world wide web;software quality;encoding;measurement	HCI	-59.263159601333065	30.92059734684885	49432
64cf4929369e8c608645f0f485670f329cb17bc0	implementation of the requirements driven quality control method in a small it company	quality control	The paper describes an actual software improvement process that was carried out in a small company specialized in providing software and hardware design services in the field of real-time systems. The implemented RDQC method addresses a software project by controlling its quality on the basis of the project requirements. This is done by specifying the requirements, mapping them to quality characteristics and controlling the development process towards the demanded quality. A short presentation of the company and the pilot projects is followed by the description of the method implementation process and its results. Encouraging remarks on the usefulness and profitability of the method conclude the paper.	requirement	Stanislaw Szejko;Maciej Brochocki;Hubert Lyskawa;Wojciech E. Kozlowski	2005			software requirements specification;verification and validation;software quality management;software project management;systems engineering;engineering;operations management;software engineering;software quality control;software quality;software quality analyst	Robotics	-62.152981975209656	26.970747073987496	49547
ea5abe54dee3ae47a206efeb48c1ab9b09d1ebb7	do #ifdef-based variation points realize feature model constraints?	variantion points;software product lines engineering;software engineering;feature models;producao bibliografica artigos completos publicadosem periodicos;consistency checking;conditional compilation;spl	Two mechanisms widely used in the Software Product Lines (SPL) Engineering are the feature model and the conditional compilation. The former models the variability in the problem space and the latter realizes it in the solution space. Even though the research community know that the feature model imposes a number of constraints to the product line implementation, there is a lack of support to co-evolve problem space and solution space. In this paper, we present an exploratory study whether problem space constraints are considered at source code level of #ifdef-based SPL implementations. In order to accomplish our goal, we developed a preliminary approach to check problem and solution spaces in a prototype tool (fclcheck). The results show a lack of realization of feature model constraints while implementing variation points with that mechanism. We also evaluated the scalability of the approach and the recoverability of the tool.	compiler;conditional compilation;feasible region;feature model;problem domain;prototype;scalability;serializability;software product line;spatial variability	Alcemir Rodrigues Santos;Eduardo Santana de Almeida	2015	ACM SIGSOFT Software Engineering Notes	10.1145/2830719.2830728	real-time computing;computer science;engineering;theoretical computer science;software engineering;algorithm;feature model	SE	-55.293567316349815	30.262711327469738	49609
9f7a36d761cf0892bf7334874b8ac5d29a66ddba	the role of design information in software evolution	design model;settore inf 01 informatica;design process;non functional requirement;software evolution;functional requirement	Software modeling has received a lot a of attention in the last decade and now is an important support for the design process. Actually, the design process is very important to the usability and understandability of the system, for example functional requirements present a complete description of how the system will function from the user’s perspective, while non-functional requirements dictate properties and impose constraints on the project or system. The design models and implementation code must be strictly connected, i.e. we must have correlation and consistency between the two views, and this correlation must exist during all the software cycle. Often, the early stages of development, the specifications and the design of the system, are ignored once the code has been developed. This practice cause a lot of problems, in particular when the system must evolve. Nowadays, to maintain a software is a difficult task, since there is a high coupling degree between the software itself and its environment. Often, changes in the environment cause changes in the software, in other words, the system must evolve itself to follow the evolution of its environment. Typically, a design is created initially, but as the code gets written and modified, the design is not updated to reflect such changes. This paper describes and discusses how the design information can be used to drive the software evolution and consequently to maintain consistence among design and code.	diagram;functional requirement;modeling language;non-functional requirement;programming language;software evolution;usability	Walter Cazzola;Sonia Pini;Massimo Ancona	2005			design process;software evolution;software design;functional requirement;non-functional requirement	SE	-54.050281152000046	29.238068434236475	49637
eda014e24f753702fcb4d04a03a207e89a97047f	empirically evaluating ocl and java for specifying constraints on uml models	empirical study;controlled experiment;ocl;constraints;java	The Object Constraint Language (OCL) has been applied, along with UML models, for various purposes such as supporting model-based testing, code generation, and automated consistency checking of UML models. However, a lot of challenges have been raised in the literature regarding its applicability in industry such as extensive training, slow learning curve, and significant effort to use OCL due to lack of familiarity of practitioners. To confirm these challenges, empirical evidence is needed, which is severely lacking in the literature. To build such preliminary evidence, we report a controlled experiment that was designed to evaluate OCL by comparing it with Java; a programming language that has also been used to specify constraints on UML models. Results show that the participants using OCL perform as good as the participants working with Java in terms of three objective quality metrics (i.e., completeness, conformance and redundancy) and two subjective metrics (i.e., applicability and confidence level). In addition, the participants using OCL performed consistently well for all the constraints of varying complexity, while fluctuating results were obtained for the participants using Java for the same constraints. Based on the empirical evidence, we can conclude that it does not make much difference to use OCL or Java for specifying constraints on UML models. However, the participants working with OCL performed consistently well on specifying constraints of varying complexity suggesting that OCL can be used to model complicated constraints (commonly observed in industrial applications) with the same quality as for simpler constraints. Moreover, additional analyses on the constraints when using Java and OCL tools revealed that tools are needed to specify fully correct constraints that can be used to support automation.	apl;code generation (compiler);conformance testing;customer support;java;model-based testing;programming language;unified modeling language	Tao Yue;Shaukat Ali	2014	Software & Systems Modeling	10.1007/s10270-014-0438-9	real-time computing;computer science;database;programming language;empirical research;java;object constraint language	SE	-59.39845505305444	30.04998751872017	49702
0813d56dc33bda24ee967337ad274738427a9c09	dependent and conflicting change operations of process models	class diagram;behavior modeling;version management;process model	Version management of models is common for structural diagrams such as class diagrams but still challenging for behavioral models such as process models. For process models, conflicts of change operations are difficult to resolve because often dependencies to other change operations exist. As a consequence, conflicts and dependencies between change operations must be computed and shown to the user who can then take them into account while creating a consolidated version. In this paper, we introduce the concepts of dependencies and conflicts of change operations for process models and provide a method how to compute them. We then discuss different possibilities for resolving conflicts. Using our approach it is possible to enable version management of process models with minimal manual intervention of the user.	class diagram;version control	Jochen Malte Küster;Christian Gerth;Gregor Engels	2009		10.1007/978-3-642-02674-4_12	computer science;systems engineering;operations management;management science	SE	-55.054241921651595	19.685173342635668	50121
fdcf1aaf5e42b2de6938ca2ad1761a8804a67a88	polylith: an environment to support management of tool interfaces	timed systems;requirement analysis;development tool;data transformation;mathematical problem solving	Polylith  is the name of a set of enhanced execution time system services along with development tools and an interfacing methodology. 1  As a system, Polylith supports the reliable union of many component tools, addressing the problems of data interchange and synchronization between these tools. It facilitates reuse of code, and promotes the notion that construction of large programs should be viewed instead as orchestration of services. The Polylith is visible as a grammar in which instances of environments 2  are precisely and rapidly specified; it is, through compilation and execution of assertions in that language, a medium through which many programs and tools can be united with impunity.   This paper presents an overview of the Polylith architecture, along with some brief remarks on the requirements analysis leading to Project Polylith at the University of Illinois. Section 2 presents this architecture, summarizing language and data transformation issues. Simple examples are included. Section 3 introduces one particular instance of an environment specified within Polylith called Minion. It is presented as an extended example, showing how the Polylith is utilized to construct an enthusiastic assistant for mathematical problem solving. The closing section contains some evaluation of how Polylith affects the task of environment development.		James M. Purtilo	1985	SIGPLAN Notices	10.1145/17919.806822	requirements analysis;simulation;computer science;theoretical computer science;programming language;data transformation	SE	-48.55431086921476	29.07394507748876	50148
afe9d5e5ef901b78706c147ef71c41a1f761a923	from object-oriented to goal-oriented requirements analysis	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;requirement analysis;object oriented;ciencias basicas y experimentales;tecnologias	were proposed more than 10 years ago. The Object-Oriented Systems Analysis (OOSA) technique [12] adopts the Entity-Relationship (ER) model to capture the declarative aspects of a software system. This was soon followed by two new proposals, Object-Oriented Analysis [3] and the Object-Oriented Modeling Technique (OMT) [11], which support the modeling of declarative, behavioral as well as interactive aspects of a software system. Today, there are dozens of like-minded techniques and commercial tools founded on the OO way of thinking that support development from requirements analysis to implementation. Indeed, the great promise of OOA is that the whole software development process can be streamlined and simplified by having the same building blocks (objects, classes, methods, messages, inheritance and the like) used in all phases of development, from requirements to implementation. A recent proposal, the Unified Modeling Language (UML)—see www.rational. com/uml—attempts to integrate features of the more preeminent models in OOA, thereby enhancing reusability and consolidating the growing OOA market. Why is OOA popular? In a nutshell, because it significantly advances the state of practice in requirements modeling. The pracThe growing influence of object-oriented programming on programming practice	''the legend of zelda:;entity–relationship model;requirement;requirements analysis;shlaer–mellor method;software design pattern;software development process;software system;unified modeling language	John Mylopoulos;Lawrence Chung;Eric Kai-Hsiang Yu	1999	Commun. ACM	10.1145/291469.293165	requirements analysis;computer science;programming language;object-oriented programming	SE	-52.227350299541584	24.273437913053115	50166
51c54701d66c598426adec2f689914efc8b87f96	validation of an elevator maintenance engineer scheduling ai system and its knowledge refinement	expert system	A considerably complex expert system called elevator maintenance engineer scheduling AI system was developed and has been practically used for more than seven years. However, its knowledge r finement and resultant system validation has been constantly required for its survival as a practically usable system. Their cost is quite expensive compared with the validation/refinement cost needed for ordinary sotlware systems or simple expert systems. In this paper, the history of above refinement and validation is described and the problems of the AI system validation and its knowledge r finement are analyzed. Based on this experience, some ideas to overcome these problems are proposed for efficiently building the right or practically usable AI system.	expert system;maintenance engineering;refinement (computing);resultant;scheduling (computing)	Setsuo Tsuruta;Hideaki Ishida;Masaki Honma;Akio Nakaon	1999			simulation;computer science;artificial intelligence;expert system	AI	-58.411749227695424	29.117506175343394	50296
41d19725590ef772723c5262f2edb2c121263203	an agent-oriented approach to support change propagation in software evolution	software;oriented;life cycle;agent based;software maintenance;software systems;change;agent;software evolution;support;approach;change propagation;propagation;evolution	Software maintenance and evolution is arguably a lengthy and expensive phase in the life cycle of a software system. A critical issue at this phase is change propagation: given a set of primary changes that have been made to software, what additional secondary changes are needed? Although many approaches have been proposed, automated change propagation is still a significant technical challenge in software maintenance and evolution. This paper presents a Ph.D. research in the final stages of developing and evaluating a novel, agent-based, framework to support semi-automated change propagation in evolving software systems.	agent-based model;change control;semiconductor industry;software evolution;software maintenance;software propagation;software system	Khanh Hoa Dam	2008		10.1145/1402782.1402789	change management;support;software sizing;software evolution;social software engineering;software framework;software development;software design description;software construction;evolution;software maintenance;software deployment;software metric	SE	-59.44446338294987	24.15523400736132	50351
56ded466138ed61a511410da250856551ef03c2a	ea management patterns for future state design.		Developing a future state design for any enterprise component is a crucial step in the enterprise management lifecycle. Traditional approaches rely heavily on business stakeholder participation and input. Several problems are identified with this approach which may contribute to poor design decisions. This paper introduces two EA Management patterns which aim to incorporate both stakeholder requirements and design principles to promote elegant future state designs. The paper includes a means for both documenting and assessing the application of design patterns, a description of the patterns of good design, and a method for applying these to a future state.	design pattern;enterprise architecture;loose coupling;refinement (computing);requirement;software architecture;software design pattern;software documentation;user requirements document	Chris Aitken	2010			computer science	SE	-58.44940583773402	18.55977768052381	50474
22da62af8b24bff99f66a50f37ef1d52259f7d62	relating software requirements and architectures using problem frames	formal specification;software requirements;software architecture formal specification systems analysis;software architecture;systems analysis;computer architecture programming software architecture counting circuits delay shape;software development;problem frame;software development software requirements software architectures problem frames architectural structures case study	Problem frames provide a means of analyzing and decomposing problems. They emphasise the world outside of the computer, helping the developer to focus on the problem domain, instead of drifting into inventing solutions. However, even modestly complex problems can force us into detailed consideration of the architecture of the solution. This is counter to the intention of the problem frames approach, which is to delay consideration of the solution space until a good understanding of the problem is gained. We therefore extend problem frames, allowing architectural structures, services and artifacts to be considered as part of the problem domain. Through a case study, we show how this extension enhances the applicability of problem frames in permitting an architecture-based approach to software development. We conclude that, through our extension, the applicability of problem frames is extended to include domains with existing architectural support.	feasible region;problem domain;problem frames approach;requirement;software development;software requirements	Jon G. Hall;Michael Jackson;Robin C. Laney;Bashar Nuseibeh;Lucia Rapanotti	2002		10.1109/ICRE.2002.1048516	domain analysis;multilayered architecture;functional software architecture;reference architecture;software architecture;systems analysis;software requirements specification;real-time computing;database-centric architecture;architectural pattern;computer science;systems engineering;engineering;software design;theoretical computer science;software framework;component-based software engineering;software development;software design description;software engineering;software construction;formal specification;software architecture description;programming language;resource-oriented architecture;goal-driven software development process;software requirements;software system	SE	-54.72826687617823	27.39293649886494	50526
a4665fb0be36921729b95416cfd75420aa88df40	linked data reactor: a framework for building reactive linked data applications		This paper presents Linked Data Reactor (LD-Reactor or LD-R) as a framework for developing flexible and reusable User Interface components for Linked Data applications. LD-Reactor utilizes Facebook’s ReactJS components, Flux architecture and Yahoo’s Fluxible framework for isomorphic Web applications. It also exploits SemanticUI framework for flexible UI themes. LD-R aims to apply the idea of component-based application development into RDF data model hence enhancing current user interfaces to view, browse and edit Linked Data. Documentation: http://ld-r.org Demo: http://demo.ld-r.org Code Repository: https://github.com/ali1k/ld-r	a/ux;aac-ld;bridging (networking);browsing;component-based software engineering;data model;documentation;encapsulation (networking);interoperability;linked data;react;reactor (software);semantic web;theme (computing);user interface;web components;web developer;world wide web	Ali Khalili	2016			architecture;rdf;web application;database;data model;linked data;data mining;exploit;computer science;user interface	SE	-48.37452174262613	22.08139743472198	50537
553b486bcae7efa721b6a6fd9d31945b0516f7f1	a process to increase the model quality in the context of model-based testing	maintainability model based testing domain specific languages requirements engineering scrum;unified modeling language software quality testing concrete visualization domain specific languages;scrum;software quality automata theory program testing;requirements engineering;model based testing;scrum project model based testing model quality test automation software quality mbt technique;maintainability;domain specific languages	In the past years model-based testing (MBT) has become a widely-used approach to the test automation in the industrial context. Until now the application of MBT has been limited to the software quality engineers with very good modelling skills. In order to guarantee the completeness of a model and to increase its precision there is a need to allow the usage of the approach by other project stakeholders such as requirements engineers as well as software quality engineers with a limited modelling experience. In this contribution we share the challenges discovered during the several years of the application of a certain MBT technique in a SCRUM project with particular regard to the definition of precise and complete models. A process which involves the entire software project team into the model definition starting at the very early stages of product development is presented along with its concrete implementation. First experiences with the application of the process in a particular project are presented1.	model-based testing;new product development;requirement;scrum (software development);software project management;software quality;test automation	Vladimir Entin;Mathias Winder;Bo Zhang;Andreas Claus	2015	2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)	10.1109/ICSTW.2015.7107471	test strategy;reliability engineering;verification and validation;model-based testing;software performance testing;software project management;computer science;systems engineering;domain-specific language;engineering;software reliability testing;software engineering;scrum;software construction;software testing;requirements engineering;empirical process;test management approach;software quality;maintainability;software quality analyst	SE	-60.82536528718963	26.88805040843357	50709
d0aac665b53b115ece04f053817bab3d6e06b1c6	improving modularity in genetic programming using graph-based data mining	data mining	We propose to improve the efficiency of genetic programming, a method to automatically evolve computer programs. We use graph-based data mining to identify common aspects of highly fit individuals and modularizing them by creating functions out of the subprograms identified. Empirical evaluation on the lawnmower problem shows that our approach is successful in reducing the number of generations needed to find target programs. Even though the graph-based data mining system requires additional processing time, the number of individuals required in a generation can also be greatly reduced, resulting in an overall speed-up.	computer program;data mining;genetic programming;subroutine	Istvan Jonyer;Akiko Himes	2006			genetic program;artificial intelligence;machine learning;genetic programming;data mining;computer program;computer science;modularity;graph	ML	-56.12802194445776	30.710734885950398	50725
edea131c53a8d76e98be4fa9745a86629bb4ba4a	why we need a different view of software architecture	software architecture computer architecture software engineering large scale systems systems engineering and theory history terminology computer science australia software systems;history of ideas;history;large scale representations software architecture view software architecture understanding software engineering community traditionally engineered artefacts history;dp industry;software engineering;software architecture;dp industry software architecture history	The definition and understanding of software architectures and architecture views still shows considerable disagreement in the software engineering community. This paper argues that the problems we face exist because our understanding is based on specious analogies with traditionally engineered artefacts. A review of the history of ideas shows the evolution of this understanding. A detailed examination is then presented of the differences that exist between the nature of the systems, the content of their large-scale representations, and how they are used in practice in the respective disciplines. These differences seriously undermine the analogies used to develop our understanding and this is discussed in terms of software engineering as a whole.	software architecture;software engineering;virtual artifact	Jason Baragry;Karl Reed	2001		10.1109/WICSA.2001.948419	reference architecture;software architecture;personal software process;software engineering process group;history of ideas;computer science;systems engineering;engineering;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;software walkthrough;resource-oriented architecture;software deployment;software requirements;systems architecture;software system;software peer review	SE	-62.4214359720746	21.40773449426754	50811
45d50609cfa61be09a0a3a06d8b4b53f5448e2c0	ongoing requirements discovery in high-integrity systems	distribution;formal specification;maintenance;integrable system;and enhancement;requirements discovery patterns software requirements discovery high integrity embedded systems system quality anomaly reports spacecraft projects;embedded systems formal specification formal verification systems analysis;embedded system;software and system safety;software requirements;embedded systems;formal verification;product metrics;systems analysis;error processing;requirements specifications management;mars space vehicles space technology propulsion laboratories system testing embedded system databases aerospace engineering knowledge engineering;jet propulsion laboratory	Discovering new requirements and requirements knowledge continues throughout the lifetime of many high-integrity embedded systems. Understanding the mechanisms for how we discover and resolve requirements identifies guidelines to help prevent anomalies found during testing from recurring during operations. We can improve our systems' quality by means of a better understanding of the mechanisms by which we discover requirements and manage them in testing and operations. We analyzed anomaly reports from testing and operations for eight spacecraft projects at the California Institute of Technology's Jet Propulsion Laboratory, showing that many of the anomalies during these phases involve software requirements discovery. As a result, several patterns of requirements discovery emerged. In turn, identifying these patterns leads to six guidelines for managing the ongoing requirements discovery.	anomaly detection;embedded system;requirement;software requirements	Robyn R. Lutz;Ines Carmen Mikulski	2004	IEEE Software	10.1109/MS.2004.1270757	distribution;reliability engineering;integrable system;systems analysis;requirements management;real-time computing;product metric;formal verification;computer science;systems engineering;engineering;software engineering;formal specification;programming language;software requirements	SE	-62.13598943062086	29.92586969461657	50961
449df6b6509b2f43f9e05e022e9236a7d119e797	specifying and applying commitment-based business patterns	method engineering;protocols;software engineering	Recent work in communications and business modeling emphasizes a commitment-based view of interaction. By abstracting away from implementation-level details, commitments can potentially enhance perspicuity during modeling and flexibility during enactment. We address the problem of creating commitment-based specifications that directly capture business requirements, yet apply in distributed settings. We encode important business patterns in terms of commitments and group them into methods to better capture business requirements. Our approach yields significant advantages over existing approaches: our patterns (1) respect agent autonomy; (2) capture business intuitions faithfully; and (3) can be enacted in real-life, distributed settings. We evaluate our contributions using the Extended Contract Net Protocol.	autonomy;business process;business requirements;contract net protocol;encode;real life;requirement	Amit K. Chopra;Munindar P. Singh	2011			communications protocol;method engineering;business requirements;computer science;knowledge management;artifact-centric business process model;management science;business process model and notation;business rule;new business development;business process modeling	AI	-54.64449082590634	18.280893321571583	50993
2ad6be2f5d94974d4f5cb827d18428292f38257d	model-driven dependability assessment of software systems	previous uml profile;basic dependability concept;dependability requirement;dependability specification;uml specification;uml profile proposal;uml profile;dependability analysis model;uml profiling;model-driven dependability assessment;software systems;dependability analysis technique	This introductory chapter describes the need, importance, and benefits of assessing dependability of software systems. It also establishes the approach followed in the book for dependability assessment.	dependability;model-driven integration;software system	Simona Bernardi;José Merseguer;Dorina C. Petriu	2013		10.1007/978-3-642-39512-3	reliability engineering;uml tool;computer science;systems engineering;software engineering;applications of uml;dependability	SE	-58.03741497233607	26.795287668327042	51064
40e376f91780315524a14530c0b6ae3f745cde7f	a pattern language for reverse engineering	object oriented design;software systems;development process;object oriented;pattern language;reverse engineering	Since object-oriented programming is usually associated with iterative development, reverse engineering must be considered an essential facet of the object-oriented paradigm. The reverse engineering pattern language presented here summarises the reverse engineering experience gathered as part of the FAMOOS project, a project with the explicit goal of investigating reverse and reengineering techniques in an object-oriented context. Due to limitations on EuroPLOP submissions, only part of the full pattern language is presented, namely the patterns describing how to gain an initial understanding of a software system. This work has been funded by the Swiss Government under Project no. NFS-2000-46947.96 and BBW-96.0015 as well as by the European Union under the ESPRIT program Project no. 21975 (FAMOOS). Copyright© 2000 by Serge Demeyer, Stéphane Ducasse, Oscar Nierstrasz	code refactoring;iterative and incremental development;iterative method;oscar;plop;pattern language;programming paradigm;reverse engineering;software system	Serge Demeyer;Stéphane Ducasse;Sander Tichelaar	1999			module pattern;interpreter pattern;state pattern;computer science;systems engineering;software engineering;pattern language;programming language	PL	-51.508119460568956	27.645613607126403	51187
214fcf126290fc0b57f5ffcfce0cbe074d3eb438	case-based knowledge management tools for software development	organizational learning;programming language;case base reasoning;knowledge management;organizational memory;development tool;software development;case tool;knowledge based software engineering;domain analysis;case based reasoning;domain specificity	Modern software development is a knowledge-intensive activity. The proliferation of development tools, rapidly changing technology, and increasing complexity and diversity of application domains all increase the cognitive burden placed on software developers. General purpose programming languages and CASE tools offer little relief from these problems. Knowledge management tools are needed that can effectively capture and disseminate software development knowledge that applies to the domain-specific needs of an organization. This knowledge is not static, but evolves with technology and the changing needs of the organization‘s development practices, customer base, and business milieu. This paper presents an infrastructure that supports evolving knowledge through case-based techniques and domain analysis methods that capture emerging knowledge and synthesize it into generally applicable forms. The approach is less concerned with the veracity of knowledge in its repository than evolving the knowledge toward answers to problems that fit the organization‘s technical and business context. Implications of this approach go beyond supporting software development to other knowledge-intensive professions where knowledge management tools can be used to support an organizational memory.	application domain;computer-aided software engineering;domain analysis;knowledge management;milieu intérieur;programming language;programming tool;software developer;software development;veracity	Scott Henninger	1997	Automated Software Engineering	10.1023/A:1008679010073	domain analysis;case-based reasoning;knowledge base;organizational learning;software engineering process group;software mining;computer science;systems engineering;engineering;knowledge management;package development process;software development;body of knowledge;software engineering;domain engineering;knowledge-based systems;knowledge engineering;open knowledge base connectivity;management science;procedural knowledge;knowledge extraction;personal knowledge management;knowledge value chain;computer-aided software engineering;software development process;domain knowledge	SE	-59.98802156546104	23.467087672337783	51212
c1b374b5ebed8ecaa4741b3dfdc59c6618851928	end-user software engineering and professional end-user developers	004;end user development;professional end user developers scientific computing;end user software engineering	By the term ‘professional end-user developers’ is meant professionals working in a highly technical, knowledge-rich domain who develop their own software in order to further their professional work. I have conducted empirical studies of such developers working in the domains of financial mathematics ([1], [2]), earth and space sciences ([2], [3]), and, currently, structural biology. These developers are distinguished from other end-user developers in two ways. The first is that, consistent with their being familiar with formal notations and logical scientific reasoning, they tend to have few problems with coding per se. The second is that, as a class, they have a history of developing their own software which long predates the advent of the PC.	personal computer;software engineering	Judith Segal	2007			human–computer interaction;systems engineering;engineering;software engineering	SE	-61.072490653634325	23.924130018586965	51257
7e7400cf481e5c11e462e0087ba56e0f37cdc7d1	human factors in software engineering: a review of the literature	computadora;software;logiciel;availability;ordinateur;technology;computer;software engineering;aspect humain;human factors;human aspect;technologie;genie logiciel;disponibilite;tecnologia	Abstract   A critical factor in the increased utilization of computer technology is the availability of software. Techniques must be developed to reduce the effort required to develop and maintain software and the availability of software developers must be increased. Both of these approaches could benefit from significant input from the human factors engineering community. Where should our efforts be focused? This paper will:   1.   (1) provide a framework for studying human factors in software engineering;   2.   (2) summarize the literature on human factors in software engineering; and   3.   (3) identify some research areas that should be addressed.	human factors and ergonomics;software engineering	K. Ronald Laughery;Kenneth R. Laughery	1985	Journal of Systems and Software	10.1016/0164-1212(85)90003-2	availability;personal software process;software engineering process group;systems engineering;engineering;human factors and ergonomics;package development process;social software engineering;software development;software engineering;software construction;software analytics;software deployment;technology	SE	-62.44618535063336	28.323583120688937	51264
ba47bfe3929b85d5717c69204725b340fdbe6b0d	on the development of reliable large software	developpement logiciel;outil logiciel;software tool;specialization;algorithme;algorithm;algorritmo;specialisation;herramienta controlada por logicial;desarrollo logicial;tribulle;software development;bubblesort;fiabilite logiciel;fiabilidad logicial;software reliability	Abstract At a high level of abstraction, program development can be divided into two phases: specialization and integration. In this paper, two algorithm development strategies suitable for carrying out the specialization phase are compared. Both such strategies are based on the following underlying idea: to increase software reliability the same level of attention must be devoted to the code and the specification synthesis.		Paolino Di Felice	1987	Journal of Systems and Software	10.1016/0164-1212(87)90014-8	embedded system;verification and validation;computer science;software development;bubble sort;operating system;software engineering;software deployment;algorithm;software quality;software metric;avionics software	SE	-51.03723560874609	31.048505264299127	51273
cee15146399716146037755334da7b483704dcb5	composite-based conflict resolution in merging versions of uml models	software;unified modeling language merging maintenance engineering computational modeling software software engineering data models;maintenance engineering;software engineering;computational modeling;unified modeling language;merging;unified modeling language configuration management;data models;conflict resolution stage composite based conflict resolution uml models model driven engineering software development model versioning systems team based development operation based system user interaction unified modeling language temporary merged model	Model-driven engineering is now playing an essential role in software development. Adequate model versioning systems are critical to enable efficient team-based development of models. The state-of-art model versioning systems are able to detect and help resolving basic conflicts which arise during the merging of different model versions. However, conflict resolution is typically conducted at the primitive operation level in operation-based system and user interaction is required to choose from the conflicting operations. In this study, we present an approach to resolve conflicts automatically at composite level in model versioning systems for Unified Modeling Language (UML). This approach has two main stages. During the merging stage, a temporary merged model is generated, which represent the central intention of model developers. And during the conflict resolution stage, our approach automatically finds and presents to the model developers all solutions for resolving all inconsistencies in the merged model. The approach was empirically evaluated on a range of test models and proved to be scalable to models of large size.	model-driven architecture;model-driven engineering;scalability;software development;unified modeling language;version control	Hao Chong;Renwei Zhang;Zheng Qin	2016	2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2016.7515890	maintenance engineering;unified modeling language;data modeling;model-driven architecture;simulation;systems modeling language;uml tool;computer science;software engineering;applications of uml;domain model;database;computational model;node	SE	-54.70579152570919	24.795849826539197	51311
60736098010df9a5fd7356af104ad0fc17c2a207	reliability of systems of independently developable end-user assessable logical (ideal) programs	system reliability;software fault tolerance;satisfiability;software quality critical services quality software faults system reliability end user assessable reliability software development methods;manufacturing systems application software fault detection reliability instruments artificial satellites control systems software quality computer science computer aided manufacturing;software fault tolerance software reliability;software reliability;manufacturing system;requirement specification	Computers are being used to automate critical services, including manufacturing systems, transportation, etc. For these critical applications, it is necessary to be able not only to achieve high quality but also to rigorously demonstrate that high quality has in fact been achieved. One approach that is used to facilitate prevention as well as detection of software faults is to decompose the requirements specification into more manageable portions. However, this does not necessarily enable the demonstration of high quality. This paper discusses a method of decomposing software into aspects that allows the system reliability to be inferred from the aspect reliabilities. Each aspect is independently developable, i.e., it can be designed and implemented independently of the other aspects in the system. In addition, each aspect is end-user assessable, i.e., it can be tested or verified by the end-user independently of any other aspect. We identify five classes of IDEAL (Independently Developable End-user Assessable Logical) aspects and, for each class, we present the conditions that must be satisfied in order to compute the system reliability from the aspect reliabilities.		Farokh B. Bastani;I-Ling Yen;Joon Hyung Kim;John Linn;Kashi Rao	2001		10.1109/ISSRE.2001.989485	reliability engineering;long-term support;software requirements specification;verification and validation;software sizing;computer science;systems engineering;engineering;package development process;software reliability testing;software development;operating system;software engineering;software construction;programming language;software deployment;software quality control;software quality;software fault tolerance;software metric;software quality analyst;software system;computer engineering;satisfiability;avionics software	Logic	-57.270431593220366	28.993393872657794	51616
07053db9d4ae62e62b8237d6a03a5217da07b8e9	guidelines for formalizing fusion object-oriented analysis methods	separation of concern;object oriented analysis and design;object oriented analysis;structure analysis	 . The growing interest in object-oriented analysis and design methods (OOMs) in the softwaredevelopment industry can be attributed to the support they give to some of the more significantsoftware engineering principles, for example, separation of concerns and generality. On the otherhand, most OOMs, like their structured analysis and design predecessors, produce models that are notamenable to rigorous semantic analyses. This problem can be attributed to the lack of firm semanticbases for... 		B. W. Bates;Jean-Michel Bruel;Robert B. France;María M. Larrondo-Petrie	1996		10.1007/3-540-61292-0_13	object-oriented analysis and design;computer science;systems engineering;knowledge management;software engineering;data mining	PL	-52.61297510952787	23.93538087274121	51823
25b520117b3edea34bf4338147dd7a76a036920a	fingerprinting design patterns	developpement logiciel;software metrics;patron conception;jhotdraw framework fingerprinting design patterns program design program architecture search space software metrics machine learning composite design motif;learning algorithm;object oriented methods;search space;program design;juego de funciones;patron concepcion;algorithme apprentissage;object oriented programming;jeu role;software engineering;software architecture;empreinte digitale;metamodel;machine learning;metamodele;learning artificial intelligence object oriented methods software architecture software metrics;metamodelo;desarrollo logicial;software reusability;design pattern;software development;reutilisation logiciel;fingerprint;huella digital;fingerprint recognition computer architecture software design algorithm design and analysis design engineering electronic mail machine learning algorithms software prototyping councils microarchitecture;learning artificial intelligence;role playing;programmation orientee objet;algoritmo aprendizaje	Design patterns describe good solutions to common and recurring problems in program design. The solutions are design motifs which software engineers imitate and introduce in the architecture of their program. It is important to identify the design motifs used in a program architecture to understand solved design problems and to make informed changes to the program. The identification of micro-architectures similar to design motifs is difficult because of the large search space, i.e., the many possible combinations of classes. We propose an experimental study of classes playing roles in design motifs using metrics and a machine learning algorithm to fingerprint design motifs roles. Fingerprints are sets of metric values characterising classes playing a given role. We devise fingerprints experimentally using a repository of micro-architectures similar to design motifs. We show that fingerprints help in reducing the search space of micro-architectures similar to design motifs efficiently using the Composite design motif and the JHotDraw framework.	algorithm;experiment;fingerprint;machine learning;sequence motif;software architecture;software design pattern;software engineer	Yann-Gaël Guéhéneuc;Houari A. Sahraoui;Farouk Zaidi	2004	11th Working Conference on Reverse Engineering	10.1109/WCRE.2004.21	metamodeling;software architecture;fingerprint;simulation;computer science;engineering;artificial intelligence;theoretical computer science;software development;operating system;software engineering;program design language;design pattern;programming language;object-oriented programming;software metric	SE	-53.46169630909963	32.183393298404226	52200
73512cf9644fbedc71cd9c045f82f39289e99e9c	towards an ontology of collaboration patterns	software engineering;pattern language;human computer interaction	The concept of patterns and pattern languages has been applied in different application domains like software engineering, human computer interaction, and pedagogy. In the area of Collaborative Working Environments (CWE) there are different understandings on what collaboration patterns are and how they can be described and defined. Collaboration patterns are specified at different levels of granularity and in relation to different application contexts. In this article, after introducing the general idea of patterns and its application in the CWE domain, we present an approach for creating a layered ontology in order to integrate collaboration patterns of different granularities and at different levels of abstraction.	common weakness enumeration;human computer;human–computer interaction;pattern language;principle of abstraction;software design pattern;software engineering	Jonas Pattberg;Matthias Flügge	2007			mathematical optimization;minutiae;natural language processing;ontology (information science);fingerprint;ontology;pixel;artificial intelligence;population;computer science;pattern recognition	AI	-52.03852744255541	23.109866547373148	52336
5670503d2d4d87c656b14688514eb5ab0e5eb6a4	recognizing design decisions in programs	encapsulation;representation;interleaving;design decisions;decomposition;programming language;composition;maintenance;software maintenance;specialization;representation design decisions programming constructs design information maintenance reuse activities composition decomposition encapsulation interleaving generalization specialization;software engineering;programming profession process design reverse engineering character recognition software design software engineering;programming constructs;reuse activities;programming;software reuse;generalization;software engineering programming;design information;reverse engineering	The authors present a characterization of design decisions that is based on the analysis of programming constructs. The characterization underlies a framework for documenting and manipulating design information to facilitate maintenance and reuse activities. They identify and describe the following categories of design decisions: composition and decomposition; encapsulation and interleaving; generalization and specialization; representation; data and procedures; and function and relation. The authors discuss how to recognize and represent design decisions.<<ETX>>	forward error correction;partial template specialization;software documentation	Spencer Rugaber;Stephen B. Ornburn;Richard J. LeBlanc	1990	IEEE Software	10.1109/52.43049	composition;generalization;interleaving;programming;encapsulation;computer science;systems engineering;engineering;theoretical computer science;software engineering;decomposition;programming language;software maintenance;representation;reverse engineering	SE	-51.15275544739874	29.139067833036368	52432
735297d1ede52b0d8b9a86941263b696bd04428e	model-driven approach and implementation of partial model-to-model transformations in a case tool		One of the main features of Model Driven Architecture is a model-to-model (M2M) transformations, which improve the overall model-driven systems development process by speeding up the development process itself and also enabling the reusability of the existing models within a single or even multiple projects. However, CASE tool-supported M2M transformations quite often lack so needed flexibility and customization options. The main goal of this paper is to present a practical model-driven approach to improve the usability of partial model-to-model transformations in a CASE tool environment. The approach is currently implemented in the CASE tool MagicDraw; however, it can be adopted by any other CASE tool that meets certain capability requirements.		Tomas Skersys;Saulius Pavalkis;Ingrida Lagzdinyte-Budnike	2014		10.1007/978-3-319-11958-8_21	systems engineering;personalization;usability;architecture;computer-aided software engineering;computer science;reusability	Logic	-55.30560022675811	25.702820348854303	52490
d0de723fed9033147808477a9006893ae20b4dd6	a framework for reliability estimation	software testing automatic testing software reliability sampling methods software tools acoustic testing mathematics physics computer science predictive models;formal specification;program testing software reliability software tools formal specification;random testing;program testing;software tools;test case generation reliability estimation software reliability software tools operational profiles random test cases hypothesis testing;software reliability;hypothesis test	We present a framework for reliability estimation for software modules. The framework comprises methods and tools relating not only to calculating the reliability estimates, but also for specifying and creating the operational prooles and random test cases upon which the estimations are based.	test case	Denise M. Woit	1994		10.1109/ISSRE.1994.341343	non-regression testing;random testing;reliability engineering;development testing;statistical hypothesis testing;verification and validation;regression testing;software performance testing;manual testing;system integration testing;computer science;systems engineering;acceptance testing;package development process;software reliability testing;software development;software engineering;software construction;formal specification;risk-based testing;software testing;programming language;software measurement;test management approach;software quality;software metric;statistics	EDA	-61.737658110710534	32.24124072194758	52503
b98c1147069d77cca86411f9ae6d5d3e6a4a6a58	a dsl for enterprise application integration	gestion integrada;gestion integree;dsl;empresa numerica;enterprise integration patterns;abstraction;integrated management;abstraccion;software engineering;eip;langage dedie;digital enterprise;ligne abonne numerique;digital subscriber line;building blocks;domain specific language;genie logiciel;eai;entreprise numerique;enterprise application integration;ingenieria informatica;linea abonado digital;lenguaje dedicado	Enterprise Application Integration is one of the big challenges for Software Engineering. According to a recent report published by IBM, for each US dollar spent on developing an application, companies usually spend from 5 up to 20 times more to integrate it. In this paper we propose a Domain Specific Language (DSL) for designing application integration solutions. Contrarily to Apache Camel, our DSL proposal allows to design an integration solution visually, by working with building blocks at a higher level of abstraction, to create a reusable, well documented and independent of technology/platform solutions.	apache camel;digital subscriber line;domain-specific language;enterprise application integration;enterprise software;executable;reference work;software development process;software engineering;software framework	Rafael Z. Frantz	2008	IJCAT	10.1504/IJCAT.2008.022420	digital subscriber line;computer science;systems engineering;engineering;operating system;engineering drawing;system integration	SE	-53.54178599237543	28.349098284727347	52536
109f3c82facf2b00e204ec2b4330f7c3e3031fbb	detection and prediction of errors in epc business process models	business process model	Business process modeling plays an important role in the management of business processes. As valuable design artifacts, business process models are subject to quality considerations. In this context, the absence of formal errors, such as deadlocks, is of paramount importance for the subsequent implementation of the process. This talk presents the results of my doctoral thesis that provides a fourfold contribution to the understanding of such errors in business process models with a particular focus on Event-driven Process Chains (EPCs), a business process modeling language that is frequently used in practice. Firstly, I formalize the operational semantics of EPCs in a novel way so that matching OR-splits and OR-joins never deadlock. Secondly, and based on these semantics, we introduce a soundness criterion for EPCs that offers a precise identification of those models which have errors. For the verification of this soundness notion in practice, I present two analysis tools, a ProM plug-in for a verification based on the reachability graph, and a batch program called xoEPC for a verification based on reduction rules. Thirdly, I define a set of business process model metrics that are supposed to serve as predictors for error probability of an individual EPC. Fourthly, I use statistical methods and a sample of about 2000 EPCs from practice to derive a regression function for the prediction of error probability. This function is validated against a holdout set of 113 EPCs from textbooks showing that 90% of the EPCs could be classified correctly as having errors or not. These results emphasize the importance of quality issues in business process modeling, and provides the foundations for innovations in tool support.	batch processing;business process modeling language;business requirements;deadlock;electronic product code;event-driven process chain;operational semantics;plug-in (computing);programmable read-only memory;reachability	Jan Mendling	2007			deadlock;probability of error;business process;data mining;semantics;reliability engineering;operational semantics;business process modeling;soundness;computer science;graph	SE	-57.04323876697042	22.63004868223513	52554
0db55723425f1271e3fd02abf924073e2311c690	from data capture to code generation: tools for entity modeling		The entity-relationship approach to conceptual modelling has long been at the heart of information systems design. Most automated tools and CASE environments created to support database design tend to start at the conceptual modelling stage. This assumes that somehow the analyst has been able to deduce, from the initial requirements specification, what entities are to form part of the system and how they are interrelated. We bring together in this paper two strands of our research to present a set of prototype tools to support the major stages of database design, starting with the tasks of document analysis and data capture, and progressing through to code generation. We conclude with a proposal for an integrated environment for database design.	code generation (compiler);comparison of command shells;computer-aided software engineering;database design;entity;entity–relationship model;information system;prototype;software requirements specification;systems design	Heather Fulford;D. Bowers	2000			information system;code generation;software requirements specification;data mining;entity–relationship model;database;database design;automatic identification and data capture;computer science	SE	-51.21386802252427	23.01089437094299	52563
d7978722b736d69ad159faff6f11094ead2fd9c2	non-functional properties in software product lines: a taxonomy for classification		In the recent years, the software product lines paradigm has gained interest in both industry and academia. As in traditional software development, the concept of quality is crucial for the success of software product line practices and both functional and nonfunctional characteristics must be involved in the development process in order to achieve a high quality software product line. Therefore, many efforts have been made towards the development of quality-based approaches in order to address non-functional properties in software product line development. In this paper, we propose a taxonomy that characterizes and classifies various approaches for employing non-functional properties in software product lines development. The taxonomy not only highlights the major concerns that need to be addressed in the area of quality-based software product lines, but also helps to identify various research gaps that need to be filled in future work in this area.	display resolution;programming paradigm;software development;software product line;taxonomy (general)	Mahdi Noorian;Ebrahim Bagheri;Weichang Du	2012			systems engineering;software;computer science;software development;software product line	SE	-60.13790959331698	25.59069825242739	52660
375bc7a5fc976307cf67337317861e5138453f9d	integrated requirements baseline management for complex software systems.		This paper reports on experiences from managing the requirements baseline in regards to Complex Software System. The requirements management of these starts from the architectural structure of the whole system by defining the high-level functionalities. The complex systems are architecturally organized in separate modules and each of them gives support to the development of one or more functionalities of the whole systems. The flow down of the whole system requirements towards the requirements of each module and the monitoring of the related traceability are the core activities within the baseline management. Moreover, the development plan of a complex system foreseen more than one deliveries each one characterized by new features and functionalities compared to the previous one. Each system version is defined by the set of the corresponding modules. This scenario requires a project development environment where Project Management (PM) and System Engineering (SM) activities are strictly connected and integrated. The presented approach takes into account the system development life cycle identified by quality standard adopted for the software development and documentation. Adopted methods, tools and artifacts are presented in order to describe the proposed processes taking into account PM and SE activities integration mechanisms episodic and pervasive. Keywords—Requirements Management Processes, Scope Management, Project Management and System Engineering Integration	artifact (software development);baseline (configuration management);complex system;complex systems;documentation;high- and low-level;pervasive informatics;requirement;requirements management;software development process;software project management;software system;system requirements;systems development life cycle;traceability	Sergio Funtò	2017			software system;systems engineering;computer science	SE	-54.73944600054585	23.578118692906525	52678
d054dd1749ecdcee48bb1876ebef0f7b55427972	safety concerns regarding the use of visual programming in civilian avionics software	safety critical code;automatic generated code;regulation;do 178;visual program languages	The paper examines the regulatory oversight of flight critical avionic software using Visual Programming Languages (VPLs) as a specific example and points out shortcomings with the Federal Aviation Administration's (FAA's) process of verifying software. VPLs and environments are being applied in conjunction with Automatic Generated Code (AGC) to create software for safety critical avionics systems which will control the fate of commercial vehicles and their passengers. There are no empirical, statistically significant studies which demonstrate that using VPLs to generate source code has any real advantage over text based programming languages. The paper describes the need for empirical software development studies.	automatic gain control;avionics software;software development;text-based (computing);verification and validation;visual programming language	Marc Ronell	2013		10.1145/2465470.2465477	simulation;do-178b;engineering;software development;software engineering;software construction;computer programming;computer security;avionics software	SE	-59.80895834962612	32.142495393215626	52724
5765fb016726f21c14c348699d8135d7d5f701b8	architecture viewpoint for modeling business collaboration concerns using workflow patterns		Businesses today rarely operate in isolation but must collaborate with others in a coordinated fashion. To address collaboration concerns, business analysts need to design business processes. Business process designs have a direct impact on the required software systems and the corresponding architectural design. Conversely, the architectural design imposes constraints on the business process designs. Unfortunately, business processes and software architectures are often designed separately leading to a misalignment between the two. To bridge this gap we propose the architecture collaboration viewpoint to be used by teams of business analysts and software architects when addressing business collaboration concerns. The collaboration viewpoint uses elements from business process and architecture viewpoints to provide new modeling artifacts for alignment. The design artefacts are mapping tables and workflow pattern diagrams that are used to identify misalignments and redesign the business processes. The viewpoint facilitates the communication between business analysts and architects. We illustrate the collaboration viewpoint for a food supply chain transparency system from a real industrial case study.	business process;diagram;iso/iec 42010;software architect;software architecture;software system;viewpoint;workflow pattern	Ayalew Kassahun;Bedir Tekinerdogan	2016		10.5220/0005973600270038	systems engineering;knowledge management;service-oriented modeling;process modeling;management science;workflow management system;workflow engine;business architecture;workflow technology	SE	-56.81262149145083	18.67403856363463	53015
266b97d5687f1c4a2d4e6e2f0e08fd679980afff	a survey of approaches for verifying model transformations	verification;model transformations;survey	As with other software development artifacts, model transformations are not bug-free and so must be systematically verified. Their nature, however, means that transformations require specialist verification techniques. This paper brings together current research on model transformation verification by classifying existing approaches along two dimensions. Firstly, we present a coarse-grained classification based on the technical details of the approach (e.g., testing, theorem proving, model checking). Secondly, we present a finer-grained classification which categorizes approaches according to criteria such as level of formality, transformation language, properties verified. The purpose of the survey is to bring together research in model transformation verification to act as a resource for the community. Furthermore, based on the survey, we identify a number of trends in current and past research on model transformation verification.	automated theorem proving;capability maturity model;code reuse;declarative programming;design pattern;display resolution;end-to-end principle;formal specification;formal verification;graph theory;higher-order function;imperative programming;library (computing);list of system quality attributes;microsoft outlook for mac;model checking;model transformation language;need to know;open-source software;program transformation;run time (program lifecycle phase);semantics (computer science);software development;software engineering;software testing;specification language;state space;systems engineering;test automation;test case;tree structure;verification and validation	Lukman Ab. Rahim;Jon Whittle	2013	Software & Systems Modeling	10.1007/s10270-013-0358-0	verification;computer science;data mining;runtime verification;algorithm;functional verification	SE	-54.97150136478865	29.173205883946537	53027
6e9c8aa8280a075594a0a8c02b9e1f39c32973d7	an ontology of problem frames for guiding problem frame specification	requirement engineering;software development;case tool;problem frames approach;problem frame;problem frame specification;ontology	Problem Frames approach is a new and prospective tool for classifying, analyzing and structuring software development problems. However, it has not yet been widely used mainly because lacking of CASE tools for guiding the problem frame specification development. This paper proposes an ontology based solution for this kind of CASE tools. An ontology of Problem Frames approach has been developed for this purpose. It specifies the basic terms elicited from Problem Frames approach and gives a concept model of this approach. This ontology can serve as the guidance of specifying the application problems. A case study has been given for illustration.	computer-aided software engineering;frame language;problem frames approach;prospective search;requirement;software development	Xiaohong Chen;Zhi Jin;Lijun Yi	2007		10.1007/978-3-540-76719-0_38	computer science;theoretical computer science;software development;ontology;process ontology	SE	-51.83411160183424	24.5929825027427	53058
d1c345191a949f4de52508eb0373956528eec3bd	a method-based tool for the specification of multiple views of system requirements	formal specification;multiple views;system example method based tool metamodel multiple views system requirements specification requirements representations complete documentations;requirement specification;documentation	as Abstract This article presents a tool that has been developed for creation of multiple views of system requireme specification. The key component for developing the is a metamodel that enables to represent the diffe views, each one based on a particular method a technique. The primary benefits of the tool include: us two or more techniques in a system’s specificati translating requirements representations created in one more techniques into another set of techniques; prepa complete documentations; etc. The article presents metamodel utilized, the main aspects of the tool, an short system example demonstrating the use of metamodel and of the tool.	documentation;metamodeling;requirement;system requirements	Tereza G. Kirner;Rogeria C. Gratão	1998		10.1109/HICSS.1998.654770	software requirements specification;documentation;computer science;system requirements specification;formal specification;programming language	SE	-51.69812639953829	24.85046795019296	53334
0af56a9ce758e87bf1adae98f15b69326390098d	reliability analysis of large software systems: defect data modeling	developpement logiciel;modelizacion;distributed system;large distributed systems;software testing;reliability;test programa;systeme reparti;systeme grande taille;exponential model;porcentaje falla;availability;sistema informatico;distributed processing;distributed computing;software systems;software development process;telecommunication computing;computer system;field failure report data;large scale system;ingenieria logiciel;field experiment;software engineering;analyse;data model;modelisation;communication industry;software systems military computing telecommunication computing programming mathematical model software testing distributed computing availability communication industry reliability;software reliability distributed processing large scale systems program testing;sistema repartido;defect removal;program testing;quality;desarrollo logicial;test coverage;software development;mathematical model;genie logiciel;defect data modeling;birth death mathematical model;cost effectiveness;failure rate;reliability analysis;systeme informatique;analysis;fiabilite logiciel;fiabilidad logicial;test programme;modeling;program test;software reliability;programming;bottleneck;quality reliability analysis defect data modeling software development large distributed systems bottleneck defect removal birth death mathematical model field failure report data;sistema gran escala;military computing;large scale systems;defect detection;taux panne;analisis	System reliability is inversely proportional to the number of unrepaired defects in the system. Improving reliability is a key objective during system development and field deployment, and defect removal is the bottleneck in achieving system readiness. Defect removal is ruled by the “laws of the physics” of defect behavior that control the defect removal process. The time to defect detection, the defect repair time and the factor of introduction of new defecls due to imperfect defect repair are some of the “constants” in the l a w s governing defect removal. Test coverage is a measure of defect removal effectiveness. A birth-death mathematical model based upon these constants is developed and used to model field failure report data. Ttie birth-death model is contrasted with a more classic decreasing expoiiential model. Both models indicate that defect removal is not a cost c4Tective way to achieve quality. In l a Terms-Failure rate, software reliability, software test, test cover age.	data modeling;failure rate;mathematical model;reliability engineering;software bug;software deployment;software reliability testing;software system;software testing	Ytzhak H. Levendel	1990	IEEE Trans. Software Eng.	10.1109/32.44378	reliability engineering;simulation;computer science;systems engineering;engineering;operating system;software engineering;analysis	SE	-62.219881927421476	31.63008039811928	53483
4e03beea095f9a61e44547f436dacb6fae6b7eec	estimating the cpu utilization of a rule-based system	software testing;workflow management;workload characterization;performance test;rule based system;rule based;software systems;software performance;monitoring and control;telecommunication networks;software performance testing;modeling and analysis	Rule-based software systems have become very common in telecommunications settings, particularly to monitor and control workflow management of large networks. At the same time, shorter deployment cycles are frequently necessary which has led to modifications being made to the rule base, without a full assessment of the impact of these new rules through extensive performance testing.An approach is presented that helps assess the performance of rule-based systems, in terms of its CPU utilization, by using modeling and analysis. A case study is presented applying this approach to a large rule-based system that is used to monitor a very large industrial telecommunications network.	central processing unit;rule-based system;software deployment;software performance testing;software system;telecommunications network	Alberto Avritzer;Johannes P. Ros;Elaine J. Weyuker	2004		10.1145/974044.974046	rule-based system;business rule management system;reliability engineering;verification and validation;real-time computing;software performance testing;telecommunications control software;computer science;systems engineering;software reliability testing;software engineering;software construction;software deployment;software system	SE	-61.3007429678654	30.289264689271008	53532
2cfee6ce97fedfa876d5ac145b4e051e9cb82ccf	benefits of interactive display environments in the software development process	uml;interaction techniques;software development process;diagrams;interactive display;semantic zooming;visualization;multi touch;zoomable user interface;models;interaction technique;modeling tool	Models become increasingly important for software development processes. Though there is a multitude of software modeling tools available, the handling of diagrams is still difficult. To overcome these problems we propose the usage of novel visualization and interaction techniques for the software development process, including multi-touch displays, the integration of diagrams drawn by hand and the interaction through zoomable user interfaces.	diagram;interaction technique;modeling language;multi-touch;software development process;user interface	Mathias Frisch;Raimund Dachselt	2008		10.1145/1370114.1370128	unified modeling language;software visualization;visualization;human–computer interaction;computer science;diagram;software development;multimedia;zoom;world wide web;software development process;interaction technique	HCI	-48.499603421242526	23.15221523059834	53583
23b56bf7ec5d8f74d82b4e6ce2d9eec8cd06dbfb	testability of software in service-oriented architecture	soa software;formal specification;service provider;soa software software testability service oriented architecture system architecture message exchanging protocols software development testability evaluation criteria;software maintenance;testability evaluation criteria;software performance evaluation;message exchanging protocols;emerging technology;software architecture;formal verification;program testing;evaluation criteria;software testing service oriented architecture collaborative work collaboration runtime access protocols application software computer architecture communication standards programming;software development;software testability;system architecture;service oriented architecture;open systems;software performance evaluation formal specification formal verification open systems program testing software architecture software maintenance	Service-oriented architecture (SOA) is a system architecture in which a collection of loosely coupled services communicate with each other using standard interfaces and message-exchanging protocols. As an emerging technology in software development, the SOA presents a new paradigm, and it affects the entire software development cycle including analysis, specification, design, implementation, verification, validation, maintenance and evaluation. This paper proposes several testability evaluation criteria for SOA software, which serves as a reference for both service providers and application builders to evaluate the test support to SOA software. The proposed evaluation criteria are illustrated in a stock-trading case study	loose coupling;programming paradigm;service discovery;service-oriented architecture;service-oriented device architecture;simulation;software development process;systems architecture	Wei-Tek Tsai;Jerry Zeyu Gao;Xiao Wei;Yinong Chen	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.167	service provider;reliability engineering;reference architecture;software architecture;architecture tradeoff analysis method;verification and validation;formal verification;software verification;computer science;systems engineering;package development process;software development;software design description;software engineering;service-oriented architecture;software construction;formal specification;software architecture description;open system;emerging technologies;resource-oriented architecture;software maintenance;systems architecture;oasis soa reference model;software peer review	SE	-52.484768429960475	28.361947427327625	53668
1215ff3e18e4ec49d9eedc4682976f9866e4bc59	value-based requirements traceability: lessons learned	iso standards degradation costs usa councils programming software standards standards development software systems automation maintenance engineering;degradation;formal specification;numerical software;life cycle;iso standards;costs and benefits;defense industry;software systems;maintenance engineering;defence industry;usa councils;standards development;systems analysis;lessons learned;requirement engineering;system wide requirements process;commercial engineering organization;process development;software standards;value based software engineering;teradyne deployment;requirements traceability;programming;military computing;automation	Software development standards demand requirements traceability without being explicit about the appropriate level of quality of trace links. Unfortunately, long-term trace utilizations are typically unknown at the time of trace acquisition which represents a dilemma for many companies. This paper suggests ways to balance the cost and benefits of requirements traceability. We present data from 3 case studies. Lessons learned suggest a traceability strategy that (1) provides trace links more quickly, (2) refines trace links according to user-definable value considerations, and (3) supports the later refinement of trace links in case the initial value considerations change.	agile software development;correctness (computer science);hoc (programming language);hyperlink;knowledge acquisition;refinement (computing);requirement;requirements traceability;software development process;tracing (software)	Alexander Egyed;Paul Grünbacher;Matthias Heindl;Stefan Biffl	2007	15th IEEE International Requirements Engineering Conference (RE 2007)	10.1109/RE.2007.16	maintenance engineering;reliability engineering;biological life cycle;systems analysis;programming;degradation;process development execution system;computer science;systems engineering;engineering;cost–benefit analysis;automation;software engineering;formal specification;requirements engineering;management;traceability matrix;requirements traceability;software system	SE	-60.86292479357484	27.433660688237165	53747
11086ac5d503d0e7c3c33efaa9ec152c3d904901	emergo: a tool for improving maintainability of preprocessor-based product lines	feature modeling;separation of concern;product line;dataflow analysis;software modularity;software product line;software product lines	When maintaining a feature in preprocessor-based Software Product Lines (SPLs), developers are susceptible to introduce problems into other features. This is possible because features eventually share elements (like variables and methods) with the maintained one. This scenario might be even worse when hiding features by using techniques like Virtual Separation of Concerns (VSoC), since developers cannot see the feature dependencies and, consequently, they become unaware of them. Emergent Interfaces was proposed to minimize this problem by capturing feature dependencies and then providing information about other features that can be impacted during a maintenance task. In this paper, we present Emergo, a tool capable of computing emergent interfaces between the feature we are maintaining and the others. Emergo relies on feature-sensitive dataflow analyses in the sense it takes features and the SPL feature model into consideration when computing the interfaces.	dataflow;emergent;feature model;preprocessor;separation of concerns;software product line;variable (computer science)	Márcio Ribeiro;Társis Tolêdo;Johnni Winther;Claus Brabrand;Paulo Borba	2012		10.1145/2162110.2162128	real-time computing;separation of concerns;computer science;programming language;feature model	SE	-53.42369956263394	30.01326081527188	53790
8afb73691ac59e7e6af337df29fc1847ba739d00	knowledge base management systems-tools for creating verified intelligent systems	verification;application development;software tool;knowledge base management system;life cycle;computer aided software development;rapid application development;software development;intelligent system;business rules;business process;knowledge base;expert system	As automation of business processes becomes more complex and encompasses less-structured domains, it becomes even more essential that the knowledge used by these processes is verified and accurate. Most application development is facilitated with software tools, but most business rules and expert systems are developed in environments that provide inadequate verification testing. This paper describes an emerging class of applications we refer to as Knowledge Base Management Systems (KBMS). The KMBS provides a full life-cycle environment for the development and verification of business rule and expert systems. We will present an overview of knowledge base verification, the KBMS life-cycle, and the architecture for a KBMS. We then describe building a small expert system in the KBMS, with emphasis on the verification testing at each stage. We conclude with a summary of the benefits of a KBMS. q 2003 Elsevier Science B.V. All rights reserved.	business process;expert system;knowledge base;knowledge management	Richard C. Hicks	2003	Knowl.-Based Syst.	10.1016/S0950-7051(02)00082-5	legal expert system;knowledge base;computer science;knowledge management;rapid application development;expert system	AI	-56.35365258609312	22.06763764929557	53807
4159dec26e0373244bcb5f2bf560ac76f2b0e665	from uml/ocl to sbvr specifications: a challenging transformation	information model;computacion informatica;uml;model transformation;modeling language;conceptual schema;ciencias basicas y experimentales;natural language;ocl;sbvr;unified modeling language;information system;information system design;grupo a;business rules;object constraint language	UML is currently the most widely used modeling language for the specification of the conceptual schema (CS) of an information system (IS). However, UML falls short when it comes to allow business people to define in their own language (e.g. using their own terms in natural language) the policies and rules by which they run their business. To this purpose, the Semantics of Business Vocabulary and Business Rules (SBVR) metamodel specification was proposed. SBVR is conceptualized optimally for business people and it is designed to be used for business purposes, independently of information systems designs. Clearly, SBVR and UML cannot be considered as isolated languages. Many of the business rules specified by business people must be automatically executed by the underlying information system, and thus, they must also appear in its UML CS. In this sense, the main goal of this paper is to bridge the gap between UML and SBVR by providing an automatic transformation from UML to SBVR specifications. Thanks to our transformation, designers will be able to interact with the business people (in their own language) to refine and validate the information modeled in the CS before the generation of the final IS implementation. Our transformation also takes into account all possible textual OCL (Object Constraint Language) expressions that complement the UML graphical elements.	conceptual schema;information system;metamodeling;natural language;object constraint language;semantics of business vocabulary and business rules;unified modeling language	Jordi Cabot;Raquel Pau;Ruth Raventós	2010	Inf. Syst.	10.1016/j.is.2008.12.002	unified modeling language;semantics of business vocabulary and business rules;uml tool;computer science;applications of uml;database;programming language;business rule;node;object constraint language	DB	-53.27374915241253	20.175328612702252	53877
014f9aeec32aad7f503e12b980c82a32d47ae3ab	an approach to ontology-aided performance engineering through nfr framework	performance;sig;formal semantics;software engineering;non functional requirement;software performance engineering;body of knowledge;ontology	In this article we intend to make an attempt to formalize the Software Performance Engineering Body of Knowledge (SPEBoK) by means of the formal semantics of an ontology written in OWL. We do not claim that our SPEBoK is complete nor the information contained correct. Rather we propose the structure of an ontological database to contain it. This structure allows the Performance Engineering issues to be related among themselves and even to other non-functional requirements with which they may interact. Our work uses the NFR Framework.	functional requirement;non-functional requirement;performance engineering;resource description framework;semantics (computer science);web ontology language	Pere P. Sancho;Carlos Juiz;Ramón Puigjaner;Lawrence Chung;Nary Subramanian	2007		10.1145/1216993.1217014	performance;computer science;systems engineering;body of knowledge;software engineering;ontology;formal semantics;data mining;database;non-functional requirement	SE	-54.93933583287795	22.400971730212195	53897
a4f5684baf66e450dc7bcd8910c306c6a7a4bca0	a composite design-pattern identification technique	design pattern	This paper introduces a new technique for identifying composite design patterns from existing patternbased designs. We propose two pattern metrics: pattern coverage and overlapping that can help detect a composite pattern. The effective composite patterns reflect quality properties that are considered desirable in the solution for a given problem domain and selected programming paradigm. To identify appropriate candidates, we propose an assessment with a set of design metrics in addition to pattern metrics. The calibration of value intervals for metric scores is proposed with the intention of offering the designer the possibility of adjusting the technique for each individual type of software. In this paper, we present the steps required for detecting and identifying the suitable composite pattern candidates through pattern and design metric assessment.	anti-pattern;composite pattern;model-driven architecture;model–view–controller;pattern language;problem domain;programming paradigm;sensor;software design pattern;software metric	Marjan Hericko;Simon Beloglavec	2005	Informatica (Slovenia)		computer science;design pattern	SE	-57.99022895728131	29.77973895995876	53931
d920dae4b764c7fcf39cd1e962fc276554690207	change sets revisited and configuration management of complex documents	configuration management	2.1 SCM models Feiler’s models of configuration management (check-out/check-in, composition, long transaction and change set) [Feil91] no longer adequately represent the current generation of commercial configuration management tools or the emerging tools and research systems. Are there better or expanded models to represent workspace concepts? Do we need new models for concurrent development in a widely distributed environment, or can we adapt the existing ones? Are there graphic representations and visualization methods better than the overworked version graphs? Is modelling just an irrelevant academic exercise?	configuration management;patch (computing);relevance;workspace	Stephen A. MacKay	1996		10.1007/BFb0023099	configuration management database;systems engineering;knowledge management;management science;configuration item	DB	-60.91808848489362	20.811048597984644	54020
73f8ed4dc033b78b656477a76db370d6032a638a	meta-modeling and meta-case tools - a silver bullet for model-driven hmi development?	software tool;tool support;user interface;development process;case tool;domain specific language;system development;domain specificity;meta model	Due to the increasing complexity of automotive human-machine interfaces (HMI) the development of appropriate user interfaces requires powerful development processes as well as easy-to-use software tools. However, in comparison to domains like embedded system development suitable software tool kits are missing in the field of HMI development. Actually meta-modeling and domain-specific languages represent many promising beginnings to create non-generic tool support for individual modeling tasks. Therefore, this paper presents a model-driven HMI development process and describes the utilization of visual domain-specific languages in this process. Thereby experiences with using current meta-CASE tools as well as standard office applications for creating electronic specifications are presented. Based on these experiences requirements for future meta-CASE tools are derived. The suggested enhancements could pave the way to increased acceptance of model-driven approaches among HMI developers and could consequently allow for overcoming today’s urging challenges in complex networked development processes.	computer-aided software engineering;digital subscriber line;domain-specific language;embedded system;high-level programming language;human–computer interaction;look and feel;metacase tool;metamodeling;model-driven architecture;model-driven integration;no silver bullet;problem domain;programming tool;requirement;software developer;usability;user interface	Carsten Bock	2006			simulation;systems engineering;engineering;engineering drawing	SE	-49.14319286356853	23.696662124194567	54192
423b775fbc08bf3ad6cc8beec9cbdc7c60ab1a46	service-oriented domain and business process modelling		We present Precise Service-Oriented Modelling (Precise SOM) - a novel lightweight method for integrated domain and business process modelling, which follows the service-oriented paradigm, and uses a UML profile as notation - and a detailed workflow to guide the production of the models. In our method the produced UML models are precisely defined by means of a metamodel, a set of constraints, and a limited set of UML constructs to help modellers to avoid common mistakes and to guarantee, by construction, a good quality. Precise SOM has been successfully used in an industry-academic project concerning the modelling of a big harbour.	business process;metamodeling;process modeling;profile (uml);programming paradigm;service-oriented architecture;service-oriented device architecture;service-oriented modeling;unified modeling language	Gianna Reggio;Maurizio Leotta;Diego Clerissi;Filippo Ricca	2017		10.1145/3019612.3019621	harbour;applications of uml;data mining;business process modeling;metamodeling;notation;unified modeling language;uml tool;workflow;computer science	SE	-52.90752128398758	24.629365619830917	54224
c9ce1b579b5db4b50beab87cdf73b81e00a95f0e	a uniform model for coordinating software development activities kari alho, casper lassenius and reijo sulonen	computerized agents;human agents;performance evaluation;software prototyping;application software;prototypes;distributed computing;software systems;callbacks;software development activity coordination model;process support systems;computer industry;prototype system;software engineering;programming humans automata distributed computing software prototyping prototypes software systems software engineering application software marine vehicles;software performance;automata;software houses;finite state machines;computer aided software engineering;pilot project;marine vehicles;software houses software development management computer aided software engineering finite state machines;distributed software process enactment;software development;tool invocation servers;parameterized finite state machines;software tools;humans;process support system;coordination model;programming;software tools software development activity coordination model distributed software process enactment human agents computerized agents process support system coordination model tool invocation servers callbacks parameterized finite state machines prototype system industrial pilot projects software houses;finite state machine;software development management;software process;industrial pilot projects	As the number of software engineering improvement methodologies and their adoption rate in industry increase, the validation of improvement methodologies becomes more and more important. Past validation studies show the effectiveness of improvement methodologies. However, they also reveal many technical difficulties for scientifically sound and detailed validation studies. This paper surveys the state of the art in improvement methodology validation and derives recommendations for systematic validation studies, which are substantiated by experiences from the European PROFES project. PROFES has developed a product-focused software process improvement methodology and started its empirical validation already early in the project. In brief, the main results of our validation work are: (1) Explicit product quality goals increase the effectiveness of process improvement and allow for causal analysis of observed improvements. (2) Validation should be based on explicit, a-priori set hypotheses involving multi-facetted validation criteria. (3) Improvement methodologies of different types, such as process assessment and goal-oriented measurement, are rather complementary than competing approaches.	causal filter;facet (geometry);sherlock holmes: hakushaku reijō yūkai jiken;software development process;software engineering	Kari Alho;Casper Lassenius;Reijo Sulonen	1997		10.1109/HICSS.1997.667286	callback;programming;application software;real-time computing;software performance testing;computer science;software development;operating system;software engineering;database;automaton;prototype;finite-state machine;programming language;computer-aided software engineering;software development process;software system	SE	-56.40827519731195	28.891770624764117	54397
20de5b3122c0260f01ef26a90e482e1f116f1c10	streamlining pattern support assessment for service composition languages.		Various process modeling formalisms have been leveraged to specify service compositions. For assessing the expressiveness of similar languages and for providing best practice knowledge, patterns have frequently been proposed. However, the pattern catalogs proposed do not all share and document the criteria that were used for assessing pattern support. Furthermore, the scaling of the support measure frequently is very coarse, only providing a basic level of selectivity. This paper proposes an approach that allows for measuring the pattern support for different catalogs in a uniform manner. The selectivity of the support measure is improved by using the edit distance for calculating its degree. The feasibility of the approach is shown by preliminary results of the analysis of selected patterns and orchestration languages.	best practice;edit distance;high-level programming language;image scaling;process modeling;selectivity (electronic);tracing (software)	Jörg Lenhard;Andreas Schönberger;Guido Wirtz	2011			computer science;systems engineering;data mining;database	HPC	-52.6997681357803	18.450960433313615	54504
91b59de7408c21fd6b90aa17af2289c979f0d3f1	co-evolution and reuse of automation control and simulation software: identification and definition of modification actions and strategies	analytical models;software;atomic modification action automation control software simulation software software coevolution software reuse modification action modification strategy industrial plants engineering documentation evolution category description logics;industrial plants;software engineering;software reusability control engineering computing description logic industrial plants production engineering computing;software automation context modeling context analytical models industrial plants software engineering;context modeling;context;automation	Industrial plants are multi-disciplinary systems that are operated for multiple decades. Changes in these systems are consequently indispensable, making appropriate mechanisms for managing co-evolution of engineering documentation necessary. In this paper, a co-evolution model for control and simulation software is introduced. Typical evolution categories and modification strategies for enabling co-evolution of automation control and simulation software are derived and formally defined. Using description logics, the identification of these complex modification strategies based on atomic modification actions is made possible.	automation;description logic;documentation;evolution;industrial pc;microsoft outlook for mac;physical plant;simulation software	Christoph Legat;Frank Steden;Stefan Feldmann;Michael Weyrich;Birgit Vogel-Heuser	2014	IECON 2014 - 40th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2014.7048861	domain analysis;verification and validation;software engineering process group;software sizing;software verification;search-based software engineering;systems engineering;engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software maintenance;software deployment;software requirements;software system;computer engineering	Robotics	-53.22710475758128	27.17664801160923	54834
1b7b7cec1530567e38e84687f5d8a916c74d764f	from desktop operations to lessons learned	desktop computers;groupware;project management;collaborative work;multi agent system;case base reasoning;finishing;feeds;knowledge management;research and development management;research and development documentation multiagent systems knowledge management writing feeds engines collaborative work organizing finishing;multi agent systems;research and development;engines;organizing;lessons learned;team members;case based reasoning engine;research and development projects;writing;cooperative project multi agent system knowledge management research and development projects project management lessons learned team members desktop computers case based reasoning engine;case based reasoning;cooperative project;groupware multi agent systems knowledge management research and development management project management case based reasoning;documentation;multiagent systems	This paper concerns a multi-agent system for knowledge management (KM) for research and development (R&D) projects. R&D teams have no time to organize project information nor to articulate the rationale behind the actions that generate the information. Our aim is to provide a system for helping the team members to make knowledge explicit and to allow them to share their experiences, i.e., lessons learned (LL), without asking them too much extra-work. The article focuses on how we intend to help the team members to feed the system with LL, using the operations they perform on desktop computers, and how we intend to exploit the LL by using a case-based reasoning engine. We have been developing a prototype of such a KM system for a cooperative project. Early results will be presented.	case-based reasoning;design rationale;desktop computer;desktop metaphor;experience;knowledge management;ll parser;multi-agent system;prototype;semantic reasoner	Cesar Augusto Tacla;Jean-Paul A. Barthès	2002		10.1109/CSCWD.2002.1047699	case-based reasoning;simulation;documentation;computer science;knowledge management;artificial intelligence;software engineering;multi-agent system;database;writing	AI	-49.426767448613944	19.040035265860425	55058
71a1b656a9b776723664a918a84730080ad805b4	plse-based generic simulation training platform for typical weapon equipments	military computing;simulation technologies;weapons;simulation technology;design simulation training characteristic;virtual training;domain engineering method;product line software engineering;platform-based developing models;plse-based generic simulation training;combining system;software engineering theory;general architecture;digital simulation;plse-based generic simulation training platform;domain framework;conceptual simulation platform;domain-oriented system architecture;software engineering;object-oriented development platform;typical weapon equipments;object-oriented methods;system architecture;object oriented;domain engineering	With the development of simulation technologies, virtual training for the military has become more and more important. Combining system and software engineering theory, based on the PLSE (Product Line Software Engineering) idea and method, we analyze and design simulation training characteristics for typical field equipment. We set up the domain-oriented system architecture and implement the domain framework. The research involves: putting forward the conceptual simulation platform based on PLSE, applying the domain engineering method, analyzing commonalities in the training for typical equipment, and implementing a general architecture. Using relevant technologies, we develop reusable core assets systematically and strategically, and build the object-oriented development platform and the platform-based developing models.	domain engineering;simulation;software engineering;systems architecture	Ying Liu	2006	Proceedings of the 2006 Winter Simulation Conference		domain analysis;model-driven architecture;simulation;computer science;systems engineering;engineering;social software engineering;feature-oriented domain analysis;domain engineering;object-oriented programming;systems architecture;computer engineering	SE	-57.357218122347724	27.19010049021946	55161
6460f090b45999fe81aba2b35525bd9af0b01adb	model-as-you-go: an approach for an advanced infrastructure for scientific workflows	workflow monitoring;scientific and business workflows;soa;workflow flexibility and adaptation;bpel	Most of the existing scientific workflow systems rely on proprietary concepts and workflow languages. We are convinced that the conventional workflow technology that is established in business scenarios for years is also beneficial for scientists and scientific applications. We are therefore working on a scientific workflow system based on business workflow concepts and technologies. The system offers advanced flexibility features to scientists in order to support them in creating workflows in an explorative manner and to increase robustness of scientific applications. We named the approach Model-as-you-go because it enables users to model and execute workflows in an iterative process that eventually results in a complete scientific workflow. In this paper, we present main ingredients of Model-as-you-go, show how existing workflow concepts have to be extended in order to cover the requirements of scientists, discuss the application of the concepts to BPEL, and introduce the current prototype of the system.	activity recognition;alpha compositing;blocking (computing);breakpoint;business process execution language;debugging;exception handling;experiment;hoc (programming language);iteration;open-source software;prototype;requirement;simulation;stepwise regression	Mirko Sonntag;Dimka Karastoyanova	2013	Journal of Grid Computing	10.1007/s10723-013-9268-1	workflow;xpdl;business process execution language;computer science;knowledge management;workflow management coalition;service-oriented architecture;database;windows workflow foundation;event-driven process chain;workflow management system;workflow engine;workflow technology	HPC	-51.2326080646597	22.26602379913682	55212
456a0ef7d1ebc9b2ecc4cdb70908896578949317	designing and utilising business indicator systems within enterprise models-outline of a method		The design of effective indicators and indicator systems requires a profound understanding of the relevant business context. Numerous relations and dependencies within an indicator system exist, which need to be analysed thoroughly: Many relations are based on implicit assumptions or sometimes not known by the management at all. This is of particular relevance for business success, since improperly used indicator systems may lead to ‘dysfunctional effects’ like opportunistic behaviour. This paper outlines a method for designing and utilising indicator systems. It fosters a convenient and consistent definition and interpretation of indicator systems. Furthermore, it serves as a conceptual foundation for related performance management systems, such as dashboard systems. 1. Motivation and Scope In recent years, there has been an increasing demand for indicators to guide and justify management decisions. These business indicators – often referred to as Key Performance Indicators (KPI) – promise to reduce complexity and to promote a focus on relevant goals. Therefore, they are regarded by some as a key instrument of professional management, especially with regard to supporting, measuring, and monitoring decisions ([Si90], p. 12). For instance, in the field of Performance Measurement (PM) indicators are supposed to reflect aspects that are pivotal for certain decisions; therefore, strategies and goals are repeatedly refined and put in more concrete terms until they become measureable by KPIs. As a result, managers receive a set of various indicators that aim at the measurement of an enterprise’s performance (called ‘indicator system’). Well-known examples of indicator systems are ZVEI [ZE89] and the RL indicator system [Re06] for the financial domain as well as the Performance Pyramid [LC91] or the Balanced Scorecard [KN92] for the PM domain. Indicators are generally understood as quantitative measures that are specified using several mathematical constructs (e.g., ordinal or cardinal scale) for different types of reference objects and on various levels of abstractions in the enterprise (e.g., resources, processes, or business units; [Gr02] pp. 98ff.). By using indicator systems managers can define expected target values – e.g., by referring to benchmarks –, continuously monitor them and, in case of discrepancies, intervene into the enterprise’s process execution. However, the design of indicator systems is not a trivial task. Already the specification of an indicator does not only require a profound understanding of the corresponding decision scenario but also requires considering its relations to other indicators. Furthermore, it recommends taking into account how an indicator affects managerial decision making. If managers, for instance, regard an indicator as an end in itself, it will result in opportunistic actions that are likely to not be compliant with the objectives of a firm. This is even more important since indicator systems often have a strong influence on the enterprise [KN92], because managers and other stakeholders are incited to predominantly align their behaviour with specific (maybe mandatory) indicators and associated target values only. If indicator systems do not adequately address these challenges, they are likely to fail their purpose. Against this background, we assume that indicators should not be specified separately, but with particular attention to the relations that exist between them and to the business context they are utilised in. Both, complexity and criticality of the task to design systems of interrelated indicators recommend making use of a dedicated method that explicitly addresses those challenges. In this paper, we present a proposal of a method for designing and utilising indicator systems, which is based on a domain specific modelling language and aims at fostering transparency, validity, and reliability of indicator systems. It is intended to become part of the multi-perspective enterprise modelling method MEMO [Fr02] in order to facilitate semantically rich linking and integration of models of indicator systems with models of the corresponding business context – and vice versa. The remainder of the paper is structured as follows: In section 2 important domain specific requirements for dealing with indicator systems are discussed. Based on these requirements, the elements of a method for the design and utilisation of indicator systems are presented in section 3, accompanied by first suggestions for a possible solution. The paper closes with related work (section 4) and an evaluation, concluding remarks, and an outlook to future work (section 5). 2. Business Indicator Systems: Requirements for a method Based on assumptions about the quality of indicator systems used in business practise and resulting challenges, we develop requirements of the domain for the intended method. The specification of an indicator system is a complex task that requires accounting for many aspects. Indicator systems that lack important aspects or are partially inconsistent jeopardize their very purpose. Requirement 1: The method should support – and if possible: enforce – the design of comprehensive and consistent indicator systems. For instance, there should be no contradictions or conflicts between indicators – if conflicts cannot be avoided, they should be made explicit (cf. [Ge86] pp. 114ff.). The adequate use of an indicator system implies a knowledgeable and differentiated interpretation. For many decision scenarios a plethora of indicators is available (cf. [LO06] p. 1). This hampers the selection of indicators that are significantly expressive regarding the underlying scenario, business strategies, and goals. Unsuitable indicators hold the dangers of promoting misleading conclusions and unfortunate decisions that – in the worst case – impede the achievement of the enterprise’s goals (cf. [Ec05] pp. 197f.). Requirement 2: To support the user with an appropriate interpretation, the documentation of an indicator system should be enriched with relevant context information. This requires not only to offer concepts that represent indicators, but also to account for concepts modelling the business context (e.g., strategies, goals, business processes). The adequacy of indicators as well as their relations (e.g., between themselves and to the goals) might be of question. Both are often based on subjective judgement and, thus, presumptive, whilst others are based on empirical evidence and ‘notedly’ objective (cf. [Gr02] p. 128; [LO06] p. 15; [Wa01] pp. 66f.; [So05] p. 226). Requirement 3: The method should provide concepts that allow for a differentiation of the rationale underlying an indicator and its relations. Indicator systems are relevant for and used by various groups of stakeholders. The specific preferences as well as the level of expertise vary within these groups. For instance, a process manager will have different demands on indicators than an IT manager or a business manager regarding the types of indicators as well as the levels of detail and abstraction (cf. [Gl01] p. 8). Requirement 4: The method should support a meaningful representation of indicator systems on various levels of abstraction to satisfy the needs of multiple groups of prospective users. Further, the method should support the integration of an indicator system designed for a certain perspective with indicator systems of other perspectives. For effective decision support, instances of indicator systems, i.e., concrete indicators should be provided and visualized by special tools such as dashboard systems. Requirement 5: The method should foster the construction of corresponding software systems by providing a conceptual foundation as well as guidelines for visualising indicators. 3. Elements of the method The approach we chose to develop such a method is to enhance an existing method for enterprise modelling (EM) by concepts and further components for designing and utilising indicator systems. An enterprise modelling method in particular provides some prominent advantages: A (graphical) modelling language promises – similar to the use of conceptual models in software engineering – to support a rich and intuitive documentation, which fosters the communication between stakeholders with different professional backgrounds (cf. Req. 4). Further, it can depict manifold relations in a more comprehensible way than, e.g., a sequential textual description. A modelling language is based on a formal syntax and precise (if not formal) semantics, which allows for automated analyses, for transformations into models used for software development such as, e.g., object models for IT management software, as well as for interchanging indicator systems and their data between different information systems or enterprises (cf. Req. 5). By embedding it into an existing EM method, the proposed method additionally benefits from taking into account the relevant business context (cf. Req. 2). Furthermore, we decided to use a domain specific modelling language, since general purpose modelling languages (GPML) like the ‘Unified Modelling Language’ (UML, [OM07]) or the ‘Entity-Relationship-Models’ (ERM, [Ch76]) show serious deficiencies with regard to our purpose (cf. [EJ01], [Lu04]). First, a GPML would not effectively support the construction of consistent models, since its syntax and semantics allows for expressing almost anything (lack of integrity). Second, it would be rather inconvenient to describe indicators using only generic concepts such as ‘Class’, ‘Attribute’, or ‘Association’ (lack of convenience) – the main concepts of the application domain are to be reconstructed by means of conceptual modelling in order to facilitate comfortable, intuitive, and secure modelling (cf. Req. 1). Third, the rather generic graphical notation (concrete syntax) of a GPML does not contribute to an illustrative visualisation (poor comprehensibility of models). 	align (company);application domain;benchmark (computing);best, worst and average case;business process;complexity;criticality matrix;dashboard (business);decision support system;design rationale;documentation;domain-specific modeling;emoticon;enigma machine;enterprise modelling;entity–relationship model;formal grammar;graphical user interface;information system;interpretation (logic);level of measurement;memorandum;microsoft outlook for mac;ordinal data;parse tree;principle of abstraction;process management (computing);prospective search;relevance;requirement;software development;software engineering;software system;strategic management;unified modeling language;while	Ulrich Frank;David Heise;Heiko Kattenstroth;Hanno Schauer	2008			functional software architecture;service-oriented modeling;integrated enterprise modeling;performance indicator;enterprise information system;enterprise modelling;process management;business;enterprise systems engineering;digital firm	SE	-56.22376496736169	22.589837870846242	55382
b3afd5d962b848768005edfb17f4d36bda438502	configuration and control of systemc models using tlm middleware	inspection;greencontrol;mechanical engineering;middleware;control;analysis;osci cci;greenconfig;configuration;use case;systemc;design methodology	With the emergance of ESL design methodologies, frameworks are being developed to enable engineers to easily configure and control models-under-simulation. Each of these frameworks has proven good for its specific use case, but they are incompatible.  ESL engineers must be able to leverage models and tools from different sources in order to be successful. But with today's diversity of configuration mechanisms, engineers spend too much time writing adapters between models that have been developed using different tools. We see a need for making the various existing configuration mechanisms cooperate.  We present a solution based on a SystemC middleware. The middleware uses a generic transaction passing mechanism based on TLM-2 concepts and provides inter-operability between the different configuration interfaces in a heterogeneous design. The paper analyses configuration in general and explains the technical consideration for our middleware and shows how it makes the state-of-the-art configuration frameworks inter-operable.	interoperability;middleware;operability;simulation;systemc	Christian Schröder;Wolfgang Klingauf;Robert Günzel;Mark Burton;Eric Roesler	2009		10.1145/1629435.1629447	embedded system;real-time computing;computer science;systems engineering	SE	-50.74684231312682	23.37551091519255	55485
a4e2376f60f8568f6f82099c1948ff106fbb7d0b	on inter-method and intra-method object-oriented class cohesion	software metrics;systems;object oriented design;object oriented;systems evaluation;software quality	Cohesion has been a topic of interest since structured design [20, 23] in the 1970’s. Today, there are numerous researchers continuing this work into object-oriented designs [1, 3, 5, 7, 9, 10, 12, 13, 16, 18, 19, 22]. Most of the current research has focused on the interaction of methods within a class, the inter-method cohesion. In this paper we consider both the inter-method cohesion and the intra-method cohesion of a class. We have utilized the concept of program slice [21] and extended Functional Cohesion [2] to devise a new intra-method cohesion metric, ITRA-C, for measuring cohesion of each method within the class. This intra-method cohesion is based on the notion of effects and chaining in an effect-slice. We further combine the (inter-method, intramethod)-tuple into one combined Class Cohesion, which provides a quick view of bands of cohesion for classes. A sample of a commercial bank account class is then provided to illustrate these concepts and metrics.	cohesion (computer science);program slicing;structured analysis	Frank Tsui;Orlando Karam;Sheryl Duggins;Challa Bonja	2009	IJITSA	10.4018/jitsa.2009010102	connascence;reliability engineering;software visualization;verification and validation;software sizing;computer science;systems engineering;engineering;social software engineering;component-based software engineering;software development;object-oriented design;software engineering;software construction;system;systems development life cycle;programming language;object-oriented programming;software quality;software metric;software system	SE	-59.77710929309814	31.56182027840961	55489
18c8ec05078d9b04a3723ec2e267bf0914f9ce8d	it is what it is because it was what it was	problem solving architecture architectural pattern software engineering;software systems;object oriented programming;software engineering;software architecture;software architecture object oriented programming;architectural pattern;computer architecture displays printers gravity books telephony humans engineering drawings;architecture;problem solving;problem solving software systems architectural pattern software engineering	Software systems usually have the same basic architectural pattern as their earlier incarnations, manifesting in decreasingly refined forms as we move back in time. Similarly, when a new problem confronts us, we try many different approaches, but over time, for the same kind of problem, solutions tend to converge to the same, more constrained, solution space	architectural pattern;converge;feasible region;software system	Grady Booch	2007	IEEE Software	10.1109/MS.2007.19	multilayered architecture;functional software architecture;reference architecture;software architecture;computer architecture;software design pattern;computing;software sizing;architectural pattern;computer science;engineering;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;architecture;software design description;software engineering;software construction;software architecture description;programming language;resource-oriented architecture;systems architecture;software system	Theory	-53.20615224258132	28.547899299412247	55537
6627ec6c16da149bd073bddc1f08e04f13912381	cots selection best practices in literature and in industry	data collection;best practice;embedded system;engineering and technology;teknik och teknologier;literature survey;meta model	This paper presents an extensive literature survey of the software COTS component selection methods published to date, followed by a metamodel consolidating the activities and practices of these methods. Together with data collected from practitioners and researchers in the embedded systems domain, we provide concrete recommendations which will enable organizations to identify suitable practices when designing a customized selection processes.	architectural pattern;best practice;component-based software engineering;criticality matrix;embedded system;iteration;lazy evaluation;metamodeling;requirement;requirements engineering;shortest seek first;software architect;surround sound	Rikard Land;Laurens Blankers;Michel R. V. Chaudron;Ivica Crnkovic	2008		10.1007/978-3-540-68073-4_9	systems engineering;engineering;data mining;management science	HCI	-60.55874784942636	24.744205292776467	55541
062c9f803edc5a86d1b2b70dd510ca17de9aa707	test front loading in early stages of automotive software development based on autosar	automotive engineering;software testing;automotive open system architecture;new technology;sensor systems;automotive software engineering;software testing automotive engineering programming system testing embedded software vehicles software engineering hardware sensor systems actuators;automobiles;requirement specification artifact quality;software integration;system software;software defects;validation and test;software development process;virtual software integration;actuators;automotive software development;program verification;software engineering;embedded software development;embedded systems;software architecture;program testing;test front loading;systems analysis;requirement engineering;software development;mathematical model;model based development;requirement specification artifact quality test front loading automotive software development autosar embedded software development vehicle system complexity model based design automotive software engineering software defects software architecture virtual software integration requirement engineering next mercedes benz m class generation automotive open system architecture;front loading;system testing;virtual integration;traffic engineering computing;front loading model based design validation and test autosar virtual integration;autosar;vehicles;vehicle system complexity;model based design;open systems;requirement specification;programming;next mercedes benz m class generation;traffic engineering computing automobiles embedded systems open systems program testing program verification software architecture systems analysis;embedded software;hardware	"""Embedded software development has become one of the greatest challenges in the automotive domain, due to the rising complexity of vehicle systems. A method to handle the complexity of automotive software is Model Based Design (MBD). As MBD offers great advantages in early simulation and testing, it has become today's mainstream method for automotive software engineering. However, some aspects can be initially tested after the integration of software on real hardware components (usually by the supplier) and when all parts of a system (e.g. bus systems, sensors, actuators) are present. The consequence is that the requirement specification of the according system possibly contains gaps that can lead to software defects. New technologies like the AUTOSAR standard enable additional potentials for the validation of model based developed software. Due to the AUTOSAR software architecture it is possible for an OEM to realize an early """"virtual"""" software integration with an acceptable effort and perform at next step a front loading of system tests. In this paper we present an approach that improves the quality of the requirement specification artifacts by using test front loading. In detail, we analyze the requirement engineering part of the software development process to identify aspects that can not be tested without having all system components. Afterwards, we classify these aspects and define an abstract test pattern that can be globally used for testing. Additionally, we illustrate our approach in a case study on an interior light system for the next MercedesBenz M-Class generation."""	autosar;automotive software;embedded software;model-based definition;requirements engineering;sensor;simulation;software architecture;software bug;software development process;software engineering;system integration;test card	Alexander Michailidis;Uwe Spieth;Thomas Ringler;Bernd Hedenetz;Stefan Kowalewski	2010	2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)	10.1109/DATE.2010.5457166	embedded system;software architecture;systems analysis;programming;verification and validation;software sizing;embedded software;system integration testing;software verification;systems engineering;engineering;package development process;backporting;software reliability testing;software framework;software development;software design description;operating system;software engineering;software construction;mathematical model;software testing;open system;resource-oriented architecture;system testing;software deployment;model-based design;goal-driven software development process;software development process;software metric;software system;system integration;actuator;avionics software	SE	-56.23266575662935	27.399148497056302	55602
a2044dcad699e8348b5b3fb228d03981ca7575ee	model patterns for model transformations in model driven development	computer languages;formal specification;java programming;application software;model patterns;pervasive computing;model transformation;object oriented programming;formal semantics;formal syntax;systems engineering and theory;technology management;model driven development;object oriented programming formal specification java;model transformations;formal semantics model patterns model transformations model driven development computer based systems transformation implementation language mopa java programming language formal syntax;computer based systems;java programming language;java computer languages systems engineering and theory conferences computer science technology management proposals application software embedded computing pervasive computing;computer science;software requirements and specifications;proposals;embedded computing;conferences;transformation implementation language mopa;java	Model driven development is a popular approach to master the complexity of computer based systems, but it is still missing well-established technologies for model transformations. A lot of research has been done to address this subject, most of it tends towards highly expressive and highly specialized transformation languages. This paper takes a contra point to this trend, proposing the transformation implementation language Mopa (model pattern), which is less expressive but provides more flexibility. Mopa is independent of the chosen modelling techniques, it allows the realization of different transformation approaches, and it is integrated into the Java programming language, hence easy to integrate into existing environments. Mopa is described with formal syntax and semantics, and this paper shows how to use Mopa to implement different existing transformation approaches	abstract syntax tree;code generation (compiler);eclipse modeling framework;formal grammar;java;java metadata interface;library (computing);meta-object facility;model transformation;model-driven engineering;object language;partial template specialization;programming language;scheduling (computing);simulation;software framework;transformation language;unbalanced circuit;xml metadata interchange	Markus Scheidgen	2006	Fourth Workshop on Model-Based Development of Computer-Based Systems and Third International Workshop on Model-Based Methodologies for Pervasive and Embedded Software (MBD-MOMPES'06)	10.1109/MBD-MOMPES.2006.17	application software;computer science;technology management;theoretical computer science;software engineering;formal semantics;formal specification;formal grammar;programming language;object-oriented programming;java;ubiquitous computing	SE	-48.73604958746897	26.236434921269133	55641
fb6067b91bce0612177ec0ceafc6990588b52926	hcdm/gsds - a design environment for real-time software with automatic program generation	distributed system;real time;automatic programming;program generation;software engineering environment;design method;design environment;process control;software design;finite state machine	This paper presents a report on the research project HCDM/GSDS. HCDM/GSDS represents one of the first real-time software design environments used in industrial development projects which allow completely automatic program generation from design. The design method HCDM for real-time software and the prototype tools for its support — GSDS — are described in detail. Requirements for future Software Engineering Environments are derived from the experience of the application of HCDM/GSDS.	real-time transcription	Michael Fastenbauer;Heinz Saria	1989		10.1007/3-540-51635-2_47	computer architecture;verification and validation;computer science;software design;component-based software engineering;software development;software design description;object-oriented design;software engineering;software construction;distributed design patterns;resource-oriented architecture;software system;computer engineering	SE	-49.32365622666082	29.717440250681978	55712
f4cc7d8bf56988ad5078cbcf32f90abc2b4991ac	modelling patterns for systems of systems architectures	cascading style sheets;contracts;computer architecture;cascading style sheets computer architecture service oriented architecture contracts publish subscribe object oriented modeling;publish subscribe;systems engineering service oriented architecture;service oriented architecture;object oriented modeling;sos design pattern modelling system of systems architectures sos architecture constituent systems cs fundamental architectural principles	This paper presents an initial report on modelling patterns and architectures for system of systems (SoSs) and their constituent systems (CSs). Fundamental architectural principles for systems and SoSs and relevant work published so far are discussed and summarised. We introduce an initial set of five architectural patterns suitable for SoS design, illustrating each pattern with an SoS example and identifying how it meet some basic SoS aims. Finally, we summarise our plans for developing these ideas in the future.		Claire Ingram;Richard John Payne;Simon Perry;Jon Holt;Finn Overgaard Hansen;Luís Diogo Couto	2014	2014 IEEE International Systems Conference Proceedings	10.1109/SysCon.2014.6819249	real-time computing;computer science;systems engineering;software engineering;systems design	EDA	-52.149111591248136	26.98287092115356	55856
8541ddb017eb1d0bb223dd319093c685980dd786	modeling the system-user dialog using interaction traces	learning algorithm;reverse engineering graphical user interfaces artificial intelligence wrapping prototypes testing forward contracts user interfaces application software clustering methods;system monitoring;system monitoring user interface management systems reverse engineering systems re engineering artificial intelligence graphs interactive systems;user interface reverse engineering;graphs;system user interaction;user interface reengineering;artificial intelligence;user interface management systems;state transition graph;legacy system;user interaction;interactive systems;forward engineering system user dialog modeling interaction traces user interface reverse engineering reengineering code analysis wrapping system user interaction cellest project lendi legacy navigation domain identifier legacy screen snapshot traces user action traces feature extraction artificial intelligence state transition graph clustering methods system screen graph node legacy screen behavior modeling;reverse engineering;systems re engineering	It is generally the case that some UI reverse engineering will be needed for every non-trivial reengineering project. Typically, this is done thro ugh code analysis, which can be very difficult and/or expensive. When code modification is not a must, system-user interaction can be the alternative, suc h as for wrapping purposes. In the CelLEST project, we have developed a prototype, called LeNDI, to tes t this idea. While the user interacts with the legacy system, LeNDI records traces of legacy screen snapshots and user actions. Then, it extracts a var iety of features for every snapshot and employs artifici al intelligence techniques to build a model of the leg acy UI, called a state-transition graph. LeNDI has two clustering techniques for grouping similar snapshot together as one system screen represented by one node on the graph. Using the user actions recorded in traces, LeNDI models the behavior of legacy screens as the arcs of the graph. Experiments to evaluate this process and compare it with standard learning algorithms, e.g. C4.5, gave encouraging results. When completed, the UI model can be used t o classify each individual snapshot forwarded by the legacy system to the user during his interaction through an emulator. Also, this UI model is a required input for the forward engineering phase of the CelLEST project.	c4.5 algorithm;cluster analysis;code refactoring;command language;digital footprint;emulator;graphical user interface;high- and low-level;legacy code;legacy system;machine learning;model-driven architecture;prototype;reverse engineering;snapshot (computer storage);state diagram;static program analysis;system analysis;tracing (software);wrapping (graphics);dialog	Mohammad El-Ramly;Paul Iglinski;Eleni Stroulia;Paul G. Sorenson;Bruce Matichuk	2001		10.1109/WCRE.2001.957825	system monitoring;human–computer interaction;computer science;systems engineering;operating system;software engineering;graph;programming language;world wide web;legacy system;reverse engineering	SE	-49.753133407969685	29.29135492260126	56289
d063fc0cade4a5a1334503913d0639cdfd3a3694	towards completeness and lawfulness of business process models		We address the existing gaps between business process models, enterprise architecture (EA) models and, external regulations that hinder completeness and lawfulness of business process models. As a solution we propose a high-level architecture for business process knowledge management that bridges the identified gaps. We use de-facto industry standards for modelling business processes and EA - BPMN and ArchiMate. We propose to use Bunge-Wand-Weber (BWW) model as a theoretical foundation for storing business process knowledge represented in BPMN and ArchiMate models and storing elements that address lawfulness of the models. BWW model provides a framework for systematically storing internally maintained process knowledge (models) and externally maintained knowledge (regulations), and supporting completeness and lawfulness of the models. Thus, the main contributions of our approach is supporting completeness and lawfulness of business process models and supporting the creation of information services to increase efficiency in the business process modelling context.	business process	Ludmila Penicina;Marite Kirikova	2013		10.1007/978-3-642-40823-6_6	completeness (statistics);process management;business process;business process model and notation;information system;enterprise architecture;business process modeling;architecture;archimate;computer science	Vision	-56.08582189130364	18.359790859324164	56490
ec0bab366de2d571f87ed065061348fd828c9188	analysis of workflow dynamic changes based on petri net	dynamic change;computacion informatica;migration;grupo de excelencia;structural change;large scale;change region;complex system;ciencias basicas y experimentales;workflow;workflow management system;petri net;dynamic adaptation	Dynamic adaptability has become one of the major research topics in the area of workflow management system. When adjusting a workflow process to some structural changes, there is a potential problem: the new workflow may contain errors, such as deadlock, inconsistency and even loss of instance. This paper primary addresses the issues related to workflow structural changes. It firstly defines a class of structural change called compatible change. This kind of change can be applied to the workflow process, without causing any structural errors or behavioral inconsistencies. Secondly, an algorithm is put forward to calculate the minimal region affected by the changes. Furthermore, it proves that the change regions can be used to check the compatibility of workflow changes. This approach is applicable and efficient in terms of time and space for large-scale and complex systems. Lastly, this paper discusses the problem to decide whether an active workflow instance can be smoothly evolved to the new workflow, and provides a sufficient condition for valid migration. In the end, an example is given to illustrate the effectiveness of the proposed concepts and method. 2008 Elsevier B.V. All rights reserved.	algorithm;change control board;complex systems;correctness (computer science);deadlock;petri net;smoothing	Ping Sun;Changjun Jiang	2009	Information & Software Technology	10.1016/j.infsof.2008.02.004	workflow;complex systems;computer science;human migration;knowledge management;structural change;data mining;database;petri net;workflow management system;workflow technology	AI	-55.703452966120366	28.84618280350564	56509
3de287ab47b0580196c179af9fd96ca3850c1e6a	a taxonomy to compare spi frameworks	mejoramiento procedimiento;gestion integrada;developpement logiciel;gestion integree;software process improvement;estudio comparativo;qualite;processus metier;integrated management;systematique;etude comparative;amelioration procede;sistematica;quality;desarrollo logicial;software development;taxonomy;comparative study;process improvement;product quality;business process;calidad;software process	The principle behind software process improvement (SPI) is that product quality is strongly influenced by the quality of the associated software process for development and maintenance. A number of SPI frameworks have evolved from this principle. However, these frameworks are comprehensive and differ in a variety of aspects, making them difficult to compare objectively and to select between for a company. This paper discusses four comparison methods that can be used on SPI frameworks. We have explored one of them further and propose a new SPI framework taxonomy. Our taxonomy consists of 25 relevant characteristics, which can be used to point out framework similarities and differences on a high level. An example of how the taxonomy can be applied to six common SPI frameworks is provided.	high-level programming language;software development process;taxonomy (general)	Christian Printzell Halvorsen;Reidar Conradi	2001		10.1007/3-540-45752-6_17	software development;comparative research;business process;software development process;taxonomy	SE	-61.686188981262546	28.482804301169363	56584
623f94d25f8f3a72b60d81054a4fb7ff8dc67d00	extending old compiler tools with meta-tools	software development	There are many tradeoffs involved in choosing between a new, more powerful software tool and an older, more established one. The best way to handle this problem may be to make the old tool more powerful through the use of meta-tools. Compiler tools suffer from this exact problem – we present YETI, a meta-tool that provides a framework for transforming and enhancing Yacc specifications. YETI can generate new Yacc specifications which automate common tasks, enhancing programmer productivity.	compiler;programmer;programming productivity;programming tool;yacc	John Aycock	2004			resource-oriented architecture;computer architecture;software peer review;compiler;software design description;backporting;computer-aided software engineering;package development process;programming language;social software engineering;computer science	PL	-51.9616230871063	31.379225783775837	56609
1599cbfb2eb5b7aaf6d4a57f3d7de4d73aba92d8	web applications design evolution with uwa	analytical models;web system;hypermedia markup languages;front end;pattern clustering;web design computer graphics human computer interaction hypermedia markup languages pattern clustering reverse engineering ubiquitous computing;context aware;human computer interaction;graphical modeling framework;uwa;computer graphics;two step redesign process;user centered design;gef;web application design;html;navigation;ubiquitous web application;adaptation model;eclipse graphical modeling framework web application design evolution uwa ubiquitous web application user centered design context aware web application two step redesign process semiautomatic reverse modeling phase html page forward design phase clustering technique clone detection eclipse ide environment eclipse graphical editing framework;web design;web application design evolution;context aware web application;clustering;design framework;unified modeling language;eclipse;ubiquitous web applications;ubiquitous computing;forward design phase;web application redesign;clone detection;eclipse graphical modeling framework;eclipse graphical editing framework;context modeling;clustering technique;web systems evolution;semiautomatic reverse modeling phase;gmf web application redesign web systems evolution uwa clustering clone detection eclipse gef;html page;modeling tool;reverse engineering;eclipse ide environment;gmf;analytical models navigation html unified modeling language reverse engineering adaptation model context modeling	This paper presents a semi-automatic approach to Web applications design evolution which leverages the Ubiquitous Web Applications (UWA) design framework, a methodology and a set of models and tools for the user-centered design of multi-channels and context-aware Web applications. The approach is based on a two-step redesign process: first a semi-automatic reverse modeling phase analyzes the html pages of the application front-end to abstract a model of the “as-is” design, according to the UWA formalism; second, a forward design phase starts from the recovered models and the (new) requirements available for the application to identify lacks and opportunities of improvements in the “as-is” design and produce the “to-be” version of it. The reverse modeling phase applies clustering and clone detection techniques and is supported by an Eclipse IDE environment. The forward design phase is supported by a set of UWA modeling tools which are built on top of the Eclipse Graphical Editing Framework (GEF) and of the Eclipse Graphical Modeling Framework (GMF) and that allow developers to evolve the recovered models. The results from a concrete case study to assess the validity of the redesign approach are also presented and discussed.	business process;client-side;cluster analysis;diagram;documentation;duplicate code;eclipse;evolution;front and back ends;graphical editing framework;graphical modeling framework;graphical user interface;html;requirement;reverse engineering;semantics (computer science);semiconductor industry;user-centered design;web application	Mario Luca Bernardi;Marta Cimitile;Damiano Distante;Francesco Mazzone	2010	2010 12th IEEE International Symposium on Web Systems Evolution (WSE)	10.1109/WSE.2010.5623570	eclipse;unified modeling language;navigation;user-centered design;web modeling;guanine nucleotide exchange factor;html;web design;human–computer interaction;computer science;front and back ends;operating system;software engineering;database;context model;cluster analysis;programming language;computer graphics;world wide web;ubiquitous computing;reverse engineering	SE	-48.30977673477354	22.926757243593936	56632
3576c333ff1bd618a1986b70eeefc0614e4f4974	definition and modeling of process using object orientation	requirements and architecture modeling;conceptual modeling;process oriented modeling;abstractions;specification;software development process;software engineering;reuse;software architecture;methodologies;object oriented;evolvable systems;complex systems;design;design patterns;process model;open systems;modeling;method;framework;architectural style;requirements analysis	Software development processes can be represented as objects because they and the elements that compose them have attributes and operations, can be linked by relationships and have behavior and states. Therefore, this paper proposes a way to represent processes and their elements as objects. This proposal can be used to represent process models benefiting from the object orientation properties and to define tools to automate processes.	software development	Beatriz Terezinha Borsoi;Jorge Luis Risco Becerra	2008	ACM SIGSOFT Software Engineering Notes	10.1145/1360602.1360609	software architecture;design;requirements analysis;complex systems;method;real-time computing;computer science;systems engineering;engineering;software engineering;reuse;programming language;specification;software development process	SE	-50.60024577110059	26.85873776380308	56641
d421ac9cd8da37ebcfb910eb7e185ddef838ddda	an integrated environment for requirements engineering	groupware;programming environments;computer supported cooperative work;software engineering;requirements engineering;complex system;software tools groupware programming environments software engineering;integrated environment;requirement engineering;project management costs error correction testing application software design engineering collaborative work environmental management quality management software quality;computer supported cooperative work environment;software tools;computer supported cooperative work environment programming environments software engineering integrated environment requirements engineering group participation;group participation	An integrated environment for requirements engineering that supports participatory development activities is described. The environment helps ensure quality by supporting and encouraging group participation and interaction. The computer-supported cooperative-work environment supports the development and analysis of system-and-software-level requirements for large, complex applications. It encompasses and coordinates all aspects of requirements development, from conceptual inspiration, through planning, to specific project details. Case studies of groups using this environment show it can support requirements engineering for groups of users determining system-level requirements for large, complex systems.<<ETX>>	automated planning and scheduling;comparison of command shells;computer-supported cooperative work;geographic coordinate system;requirement;requirements engineering	James D. Palmer;N. Ann Fields	1992	IEEE Software	10.1109/52.136184	requirements analysis;software requirements specification;computing;software engineering process group;performance engineering;human–computer interaction;software project management;search-based software engineering;computer science;systems engineering;engineering;software design;social software engineering;software development;requirement;software engineering;computer-supported cooperative work;software construction;requirements engineering;management;functional requirement;software development process;software requirements;collaborative software;software system;computer engineering	SE	-62.59826995408845	20.699797290331084	56962
0f3e88eacff570e2f9066b6b75f03c876db73545	experience report on the effect of market reposition on product line evolution	product repositioning product line evolution telecommunications equipment top management decision product line growth;product line;object oriented programming;experience report;software reusability;switches telecommunication switching telecommunication computing systems engineering and theory drives engineering management marketing and sales testing environmental economics product development;object oriented programming software reusability	This paper presents the result of a study on the changes that occurred in the product line of a supplier of telecommunications equipments as a result of the top management decision to change the product line's target market. The study examines six years of data and identifies potential relationships between changes in the product line and changes in the company's customer, inner context, and product layers. Some of the key findings include - that sales are negatively related to product line growth and positively related to design turnover and the number of designers assigned to the product line. In addition, the results show that there is no relationship between the size of the code added to the product line and the number of designers required to develop and test it. Furthermore, product repositioning includes moving assets from individual products to the product line.		Razvan T. Dumitrescu;Antonio J. Bailetti;Samuel Ajila	2004	Proceedings of the 2004 IEEE International Conference on Information Reuse and Integration, 2004. IRI 2004.	10.1109/IRI.2004.1431452	product cost management;market requirements document;service product management;innovation management;computer science;product lifecycle;product design specification;software engineering;core product;product management;product design;programming language;object-oriented programming;management;new product development;product engineering	EDA	-62.59851337138829	22.82171370154394	57104
0781d3edcff9e896a81d3c7d93dbbad3549ecbaa	towards tool support for situational engineering of agile methodologies	agile software development;situational engineering;software;sme approaches;method engineering;epfc;project management;agile software development methodology;tool support;software prototyping;epfc tool support situational engineering agile software development methodology sme approaches software methodology software engineering methods computer aided method engineering came tools assembly based situational method engineering bespoke agile methodology software process engineering metamodel spem 2 0 eclipse process framework composer;satisfiability;software engineering;methodology requirement agile software development methodology situational method engineering tool support;came tools;crystals;spem 2 0;assembly based situational method engineering;agile methodologies;situational method engineering;planning;software tools;software process engineering metamodel;eclipse process framework composer;software methodology;software tools software prototyping;communities;context crystals software programming communities project management planning;bespoke agile methodology;programming;context;methodology requirement;software engineering methods;computer aided method engineering	Various agile software development methodologies, practices, and techniques have been proposed in the last decade, some present novel ideas, while many are simply made up of tasks and techniques borrowed from prominent agile methodologies. Each of these methodologies prescribes a set of practices and techniques which are deemed appropriate for application in a specific context. However, there exists no single method which fits all project situations. This has resulted in the advent of Situational Method Engineering (SME) approaches, which are used for developing software methodologies that are tailored to fit the specific circumstances of the project situation at hand. Since tool support has become an essential prerequisite for widespread adoption of software engineering methods, provision of Computer-Aided Method Engineering (CAME) tools has become a priority. We provide a basis for the application of assembly-based situational method engineering to the development of bespoke agile methodologies. To this aim, a comprehensive set of relevant methodology features has first been identified, spanning the range of possible requirements that a method engineer may define for the agile methodology under development. Based on this set of requirements, a method base has been proposed that contains the method chunks necessary for satisfying these requirements. The proposed method base conforms to the Software Process Engineering Metamodel (SPEM 2.0), and can be immediately plugged into CAME tools which implement this metamodel, including the Eclipse Process Framework Composer (EPFC).	agile software development;bespoke;coherence (physics);composer;eclipse process framework;fits;file spanning;meta-process modeling;metamodeling;method engineering;requirement;software development process;software engineering;usability	Zahra Shakeri Hossein Abad;Mahsa Hasani Sadi;Raman Ramsin	2010	2010 Asia Pacific Software Engineering Conference	10.1109/APSEC.2010.45	project management;requirements analysis;agile unified process;agile usability engineering;systems engineering;engineering;requirement;software engineering;agile software development;management;computer engineering	SE	-58.1513119953574	21.282490506287775	57190
3dec40a12bed9a32150d5bdb6eed9e6bbdbecc44	a comparison of software product family process frameworks	developpement logiciel;architecture logicielle;domain engineering;software product family;ingenieria logiciel;product line;software engineering;software architecture;desarrollo logicial;product family architecture;software development;product family;genie logiciel	A number of product family process frameworks has been published recently. These frameworks focus on different aspects of product family based development. We have investigated a variety of publicly available product family frameworks and chosen four of the variants for maximum coverage of different viewpoints. We first propose a reference product line process framework. With the help of the reference framework, the chosen source frameworks are correlated and compared at the level of individual activities. Both in the reference framework and in the comparison, we stress domain engineering as one of the most essential activities.	domain engineering	Tuomo Vehkomäki;Kari Känsälä	2000		10.1007/978-3-540-44542-5_16	reference architecture;software architecture;software development;domain engineering	Web+IR	-57.6503987752671	27.99957555260323	57270
acfd829804388460cef15e7314d0c0276094679f	enriching usixml language to support awareness requirements	model driven user interface development;requirements specification;awareness	Awareness support in model-driven architecture approaches is almost nonexistent. Although it is a required feature for the development of collaborative applications, the consideration of awareness in development methodologies and tools has been hindered by the lack of model-driven oriented conceptual models. This work presents an extension to the user interface description language UsiXML for describing generic awareness support in software development, with special focus on requirements level, and keeping a traceable path throughout the development stages. UsiXML describes multimodal and multicontextual user interfaces by following a model-driven approach to software development, and one of its purposes is to enable the development of highly interactive user interfaces, where awareness plays an important role. Furthermore, a template to gather awareness information requirements is provided to help designers explore and describe them in the early design stages.	add-ons for firefox;awareness;computer-supported cooperative work;feedback;graphical user interface;hamiltonian path;information overload;interface description language;modal logic;model-driven architecture;model-driven engineering;multimodal interaction;requirement;software development;software development process;traceability	Jose Figueroa Martinez;Víctor López-Jaquero;Francisco Luis Gutiérrez Vela;Pascual González	2013	Sci. Comput. Program.	10.1016/j.scico.2012.09.020	software requirements specification;awareness;human–computer interaction;computer science;knowledge management	SE	-49.65742594620401	22.440180891055086	57309
76f83abc727fe5e53c004221851a860ad2a839dc	asset: a life cycle verification and visibility system	life cycle	This paper describes the Automated Systems and Software Engineering Technology (ASSET) System, a system of techniques and tools aiding in the management and control of product development and maintenance. Improved verification techniques are applied throughout the entire life cycle and management visibility is greatly enhanced. The paper discusses the critical need for improving upon past and present management methodology, and describes the ASSET verification methodology, the ASSET system architecture, and the current ASSET development status.	new product development;software engineering;systems architecture	Leon J. Osterweil;John R. Brown;Leon G. Stucki	1979	Journal of Systems and Software	10.1016/0164-1212(79)90007-4	reliability engineering;biological life cycle;computer science;systems engineering;engineering;it asset management	SE	-62.099353404879274	24.440755227753108	57385
a0390b09d83c0271f35060b08b08b4d3ecb48497	quality aspects for component-based systems: a metrics based approach	components;reusability;metrics;complexity;dependency;quality;maintainability	In component-based development, software systems are built by assembling components already developed and prepared for integration. To estimate the quality of components, complexity, reusability, dependability, and maintainability are the key aspects. The quality of an individual component influences the quality of the overall system. Therefore, there is a strong need to select the best quality component, both from functional and nonfunctional aspects. The present paper produces a critical analysis of metrics for various quality aspects for components and component-based systems. These aspects include four main quality factors: complexity, dependency, reusability, and maintainability. A systematic study is applied to find as much literature as possible. A total of 49 papers were found suitable after a defined search criteria. The analysis provided in this paper has a different objective as we focused on efficiency and practical ability of the proposed approach in the selected papers. The various key attributes from these two are defined. Each paper is evaluated based on the various key parameters viz. metrics definition, implementation technique, validation, usability, data source, comparative analysis, practicability, and extendibility. The paper critically examines various quality aspects and their metrics for component-based systems. In some papers, authors have also compared the results with other techniques. For characteristics like complexity and dependency, most of the proposed metrics are analytical. Soft computing and evolutionary approaches are either not being used or much less explored so far for these aspects, which may be the future concern for the researchers. In addition, hybrid approaches like neuro-fuzzy, neuro-genetic, etc., may also be examined for evaluation of these aspects. However, to conclude that one particular technique is better than others may not be appropriate. It may be true for one characteristic by considering different set of inputs and dataset but may not be true for the same with different inputs. The intension in the proposed work is to give a score for each metric proposed by the researchers based on the selected parameters, but certainly not to criticize any research contribution by authors. Copyright © 2012 John Wiley & Sons, Ltd.	component-based software engineering	Vijay Kumar;Arun Sharma;Rajesh Kumar;P. S. Grover	2012	Softw., Pract. Exper.	10.1002/spe.1153	dependency;reliability engineering;reusability;complexity;computer science;systems engineering;engineering;data mining;metrics;maintainability	SE	-60.111474695403125	25.789097950888895	57578
27bf807b41bf92fefb8aa0274c4ea8a42445f9cb	towards automated context-aware software quality management	software metrics;software;goal question metric;quality attributes;multiagent system;context aware;software quality management;complexity theory;automated context aware software quality management;multi agent system;software measurement;reactive measures;software quality multi agent systems quality management software metrics;multi agent systems;agents;software engineering environment;software engineering environments software quality management agents goal question metric technique automated software engineering;current measurement;capability maturity model;cooperative voting;software current measurement concrete capability maturity model complexity theory software measurement;reactive measures automated context aware software quality management software engineering environment goal question metric technique multiagent system competitive bidding agent behavior cooperative voting;software engineering environments;software quality;automated software engineering;quality management;competitive bidding agent behavior;concrete;goal question metric technique	To consistently improve software quality management, greater automation and tighter integration of quality tools and measurements in the software engineering environment is essential. However, automation of software quality management faces numerous challenges such as project uniqueness, project dynamics, efficiency, and limited time and quality expenditures. In this paper, an approach is proposed that extends the Goal-Question-Metric technique and automates the monitoring of quality goals via a multi-agent system by using competitive bidding agent behavior for proactive vs. cooperative voting for reactive measures. The preliminary results show promise for systematically harmonizing (conflicting) quality attributes, goals, metrics, and countermeasures and for automating aspects of software quality management.	automated planning and scheduling;causal filter;consciousness;cost estimation in software engineering;gqm;list of system quality attributes;multi-agent system;procurement;software engineering;software quality management;user profile	Gregor Grambow;Roy Oberhauser	2010	2010 Fifth International Conference on Software Engineering Advances	10.1109/ICSEA.2010.59	reliability engineering;verification and validation;quality policy;software quality management;concrete;software sizing;software project management;computer science;systems engineering;engineering;knowledge management;software development;software agent;software engineering;multi-agent system;software construction;gqm;application lifecycle management;software measurement;software quality control;capability maturity model;quality of analytical results;software quality;software metric;software quality analyst;software peer review	SE	-61.33376071084106	27.245652651755925	57579
aef8711e4ecd9de90186acf5df736d8bd0effd78	an experimental evaluation of sec+, an enhanced search engine for component-based software development	enhanced search engine;low precision;current approach;exact querying;experimental evaluation;incomplete answer;non-functional feature;semantic distance;service discovery;subsumption mechanism;component-based software development	Current approaches for service discovery are inherently restricted to the exact querying. This may provide incomplete answers since queries are often overspecified and may lead to low precision and recall. To alleviate these problems, we achieved an experimental evaluation that uses of the enhanced search engine, SEC+. This engine is based on the subsumption mechanism and a function that calculates the semantic distance. Both the used rate and the non-functional features are considered to filter the selection. We show that such a solution can improve the quality of the search and can enhance both the recall and the precision.	component-based software engineering;precision and recall;service discovery;software development;subsumption architecture;web search engine	Sofien Khemakhem;Khalil Drira;Emna Khemakhem;Mohamed Jmaiel	2008	ACM SIGSOFT Software Engineering Notes	10.1145/1384139.1384143	reliability engineering;software architecture;design;requirements analysis;complex systems;method;computer science;systems engineering;software engineering;reuse;database;service discovery;programming language;specification;metrics;software quality;search engine	SE	-57.78935132753665	32.01423697233033	57790
c69b0aad72311d708b02758eaef1d9ec3c141723	leveraging model driven engineering in software product line architectures		The process of Developing Software Product Line Architectures can be a complex task. However, the use of Model Driven Engineering (MDE) techniques can facilitate the development of SPLAs by introducing Domain Specific Languages, Graphical Editors, and Generators. Together these are considered the sacred triad of MDE. Key to understanding MDE and how it fits into SPLAs is to know exactly what each part of the trinity means, how it relates to the other parts, and what the various implementations are for each. This tutorial will demonstrate the use of the Eclipse Modeling Framework (EMF) and the Sirius Graphical Framework to create an actual MDE solution as applied to a sample SPLA. These tools collectively form what is called a Language Workbench. During this tutorial we will also illustrate how to model the visual artifacts of our Domain Model and generate a Domain Specific Graphical Editor from a Domain Specific Language. This tutorial has its foundations in years of industrial experience with large and complex SPLAs in various industries. This tutorial continues to be updated each year to include recent and critical innovations in MDE and SPL. This year will include information on key Model Transformation, Constraints and Textual Modeling Languages targeted at Software Product Lines. Additionally, it will cover advances in Software Product Line migration technologies which include techniques as to how to effectively migrate legacy systems toward and MDE/SPLA architecture and implementation. This yearu0027s tutorial includes extensive industrial experience on the testing of large and complex SPLAs. The goal of this tutorial is to educate attendees on what MDE technologies are, how exactly they relate synergistically to Software Product Line Architectures, and how to actually apply them using an existing Eclipse implementation. The benefits of the technology are so far reaching that we feel the intended audience spans technical managers, developers and CTOs. In general the target audience includes researchers and practitioners who are working on problems related to the design and implementation of SPLAs and would like to understand the benefits of applying MDE techniques towards SPLAs and leverage Eclipse as a framework to develop MDE solutions. The first half will be less technical than the second half where we cover the details of SPLA and MDE in action in complete detail showing patterns and code.	model-driven engineering;software product line	Bruce Trask;Angel Roman	2015		10.1145/2791060.2791081		SE	-53.91520900625574	24.4183948426995	57796
408d635eedd0ff38b36f9110eb1c10096ccdfcb0	a review of approaches to developing service management systems	distributed system;management system;service management;open distributed systems;field experiment;software engineering;object oriented;component reuse;object oriented development methodology;system development;development methodology;development time;services marketing;open distributed system	As service management systems are deployed in an open service market environment, the pressures on their developers to shorten development times and improve the flexibility of systems will increase. Component reuse may help in alleviating some of these pressures; however, while object-oriented reuse is used in the definition of interfaces for management systems, the systematic application of reuse to the systems' internal design is not well established. This paper examines some of the approaches applicable to service management system development from the Telecommunications, Distributed Systems, Internet and Software Engineering fields. Experience in applying some of these approaches is presented, and based on this, refined approaches to service management system development are discussed.	internet;management system;operating system service management;software engineering;third-party software component	David Lewis	2000	Journal of Network and Systems Management	10.1023/A:1009443007126	element management system;systems management;field experiment;service product management;service management;computer science;knowledge management;service design;management system;systems development life cycle;object-oriented programming;management;systems design	SE	-51.207738456377726	19.83583786677488	57837
06314a427a3b8386537f16e8e57997fb34790fac	wisdom: a website design method based on reusing design and software solutions	conceptual reuse;design process;computacion informatica;process pattern;grupo de excelencia;website design;satisfiability;mde;ciencias basicas y experimentales;cots;software reuse	Context: Websites are increasingly important for advertising and announcing information and they have become virtual business operations support tools. Thus, website designers have to take an increasing number of criteria (cost, delay, quality, security, maintenance) into account during design process to satisfy the needs. Objective: The objective of this paper was to present our WISDOM method that: guides the designer through the website design process, proposes design solutions based on already existing solutions for online website design, facilitates the choice of software components to implement specific services, and speeds up website construction. Method: The originality of our method is that it links the design process to formalized experience and a software component characterization that allows both functional and non-functional aspects to be considered. Results: This method relies on the state-of-the-art strengths in the website design process, modeling dimensions, Model-Driven Engineering and the patterns approach. We propose an implementation of our method as a dedicated website which helps website design and provides a website analysis catalog and a software component analysis catalog. Conclusion: Our analysis of the method's use highlights that formalizing the steps of the design process helps designers, especially novice designers, to design a website; our analysis of the tool's use highlights its efficiency for rapid website development and its use of the ''website family'' concept. The results are so very encouraging for both method and tool; both facilitate website design by reusing existing solutions and components.	web design	Etienne Cocquebert;Damien Trentesaux;Christian Tahon	2010	Information & Software Technology	10.1016/j.infsof.2010.07.002	feature-driven development;website architecture;design process;computer science;systems engineering;engineering;software engineering;data mining;database;world wide web;satisfiability	SE	-59.672070345667	25.529871424401037	57846
300cd5824caf4f66fe26dad43b75d751b4d73e9b	a tool to support the definition and enactment of model-driven migration processes		One of the main challenges to achieve the industrial adoption of Model-Driven Engineering (MDE) paradigm is building tools able to support model-driven software processes. We present a tool for the definition and enactment of model-driven migration processes. We have created a SPEM-based language for defining Abstract Migration models that represent an MDE migration solution for a particular pair of source and target technologies. For each legacy application to be migrated, the Abstract Migration model is transformed into a Concrete Migration model which contains all the information needed for the enactment. Then, these models are enacted by means of a process interpreter which generates Trac tickets for executing automated tasks by means of Ant scripts and managing manual tasks with the Mylyn tool.#R##N##R##N#Our work has therefore two main contributions: i) it proposes a novel solution for the enactment that integrates the execution of the automated tasks with the generation of tickets to support the manual tasks, and ii) it describes how MDE techniques can be used to implement process engineering tools, in particular migration processes. The article presents the approach and describes in detail the essential aspects of our tool.		Fco. Javier Bermúdez Ruiz;Óscar Sánchez Ramón;Jesús García Molina	2017	Journal of Systems and Software	10.1016/j.jss.2017.03.009	simulation;computer science;artificial intelligence;operating system;data mining;programming language	SE	-52.91910945947013	24.971565712593556	57919
5209d4df5dc73f21239fd79c56d4371c08e25370	a methodological framework for sysml: a problem frames-based approach	system engineering;systems engineering;software development process;software engineering;uml profile;modelling language;unified modeling language;object management group;unified modeling language software engineering systems engineering;model based development;problem frame;uml sysml problem frames object management group systems engineering software development;unified modeling language systems engineering and theory programming software engineering conference management engineering management context modeling guidelines application software computer industry	Recently, SysML has been adopted by the object management group as a modelling language for systems engineering. SysML is a UML profile that represents a subset of UML 2 with extensions. A wide adoption of the language could be hindered by the lack of a methodology that drives the modelling activities. Problem frames (PFs) are a rigorous approach to requirements modelling that has the potential to improve the software development process. Unfortunately, PFs are not supported by an intuitive notation and easy to use tools. As a consequence, their adoption in industry is limited. This paper explores the possibility of exploiting the PFs ideas in the context of SysML models. The goal is to provide model-based development processes using SysML with a set of concepts and guidelines that are sound and have already been used and validated.	entity;formal language;jackson;model-driven engineering;problem domain;problem frames approach;profile (uml);requirement;requirements analysis;smoothing;software development process;state diagram;systems modeling language;systems engineering;unified modeling language	Pietro Colombo;Vieri Del Bianco;Luigi Lavazza;Alberto Coen-Porisini	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.9	use case;metamodeling;reliability engineering;unified modeling language;model-driven architecture;software engineering process group;systems modeling language;uml tool;computer science;systems engineering;social software engineering;software development;software engineering;applications of uml;class diagram;requirements engineering;systems development life cycle;programming language;computer-aided software engineering;model-based design;software development process;object constraint language	SE	-53.452978016184716	26.19746295356373	57965
50cd48a93ca3cfcc6c5429f010791e6dda49fcf7	joint reference modeling: collaboration support through version management	project management;system architecture joint reference model collaboration support version management evolutionary development data structure;database management systems;reference model;prototypes international collaboration conference management management information systems artificial intelligence data structures information analysis information systems information technology context modeling;data structures;version management;system architecture;data structure;configuration management;project management configuration management data structures database management systems	The derivation of specific models from reference models corresponds with the creation of reference model variants. Research on the design of such variant constructions generally assumes an unchangeable stock of reference models. The potential inherent in the management of these variant constructions which reflect the changes in jointly designed reference models through time and, in doing so, their evolutionary development, has not yet been tapped into. The article at hand analyzes this problem and presents a concept for the version management of jointly designed reference models as a solution. The task to be mastered with the proposed approach can be concretized using data structures and system architecture and then prototypically implemented	data structure;reference model;systems architecture;version control	Oliver Thomas	2007	2007 40th Annual Hawaii International Conference on System Sciences (HICSS'07)	10.1109/HICSS.2007.309	reference model;data structure;data management;computer science;knowledge management;software engineering;data mining;database;configuration management;structure of management information;information management;programming language;management	SE	-50.77317629695432	18.943517821450705	58181
8f5d34da3d85b8dcf24bd74ed7a3fb2626d908be	change-based foda diagrams: bridging the gap between feature-oriented design and implementation	bottom up;implementation;separation of concern;design and implementation;feature oriented programming;design;source code;separation of concerns;coarse grained;documentation	Feature Oriented Design Analysis (FODA) diagrams present the design of feature-oriented software applications. In some cases, however, the actual implementation of such an application does not correspond to the design that was set forward by the FODA diagram. Such discrepancies are referred to as the gap between design and implementation.  We present a bottom-up approach for generating FODA diagrams from the changes to the source code. Unlike ordinary FODA diagrams, those diagrams are based on the implementation. Thanks to that, they do not only contain coarse-grained design information, but also incorporate finegrained implementation details, which can be used to bridge between feature-oriented design and implementation.	bottom-up parsing;bridging (networking);feature-oriented domain analysis;top-down and bottom-up design;voronoi diagram	Peter Ebraert;Quinten David Soetens;Dirk Janssens	2011		10.1145/1982185.1982478	real-time computing;separation of concerns;computer science;theoretical computer science;programming language	HCI	-49.42139419796673	27.250727818102103	58223
ddd42955062f20fc9b350cf9e73f6c6264c0c067	the tool generation challenge for executable domain-specific modeling languages		Executable domain-specific modeling languages (xDSMLs) have the potential of bringing major benefits to the development of complex software-intensive systems as they provide abstractions of complex system behaviors and allow for early analyses of that behavior. However, in order to be useful, xDSMLs have to be equipped with model analysis tools supporting domain engineers in comprehending, exploring, and analyzing modeled behaviors. Hand-crafting such tools in an ad hoc manner imposes significant efforts and costs on the development process and is, hence, mostly done for broadly adopted xDSML only. Executable metamodeling approaches seek to overcome this limitation by providing formalisms to define the execution semantics of xDSMLs in a systematic way building the basis for automatically generating model analysis tools. While significant advances towards achieving this vision have been achieved in recent years, there are still many challenges to be solved for generating out-of-the-box analysis support for xDSMLs. In this paper we revisit the tool generation challenge introduced by Bryant et al. [3] seven years ago reflecting on recent achievements and identifying open challenges.	domain-specific modeling;executable;modeling language	Tanja Mayerhofer;Benoît Combemale	2017		10.1007/978-3-319-74730-9_18	systems engineering;domain-specific modeling;complex system;modeling language;metamodeling;semantics;executable;abstraction;computer science	PL	-54.66754716489697	25.624519466815148	58246
65137c4b62cfd401bb29f66ce72f037fed7dc4c8	towards process lines for agent-oriented requirements engineering	software quality formal specification object oriented programming software agents;formal specification;aore process lines agent oriented software products software quality software process line engineering re agent oriented software development agent oriented requirements engineering process line aorepl core base variation points variant method step by step process line engineering method;object oriented programming;software agents;software feature extraction unified modeling language analytical models context predictive models algorithm design and analysis;requirements engineering software development process agent oriented development process line engineering;software quality	Agent-oriented software products are becoming increasingly complicated, and the competitive market is forcing the producers to reduce time-to-market and increase the quality of the software produced. Therefore, developers have come to realize the need for more reliable and efficient agent-oriented software development processes (methodologies) which address the specific needs of each and every project. Software Process Lines provide a solution to this problem by using Process Line Engineering concepts for instantiating bespoke software processes. This research focuses on developing a software process line for Requirements Engineering (RE) in the context of agent-oriented software development. Our proposed Agent-Oriented Requirements Engineering Process Line (AOREPL) incorporates a core base which can be directly used for instantiating an Agent-Oriented Requirements Engineering (AORE) process; it also defines variation points and variant method chunks to be added to the core base in order to create variant AORE processes. We also propose a step-by-step process line engineering method which enables process engineers to define and instantiate diverse AORE process lines.	algorithm;bespoke;interdependence;need to know;requirement;requirements engineering;software development process;strand (programming language);universal instantiation	Fatemeh Golpayegani;Keyvan Azadbakht;Raman Ramsin	2013	Eurocon 2013	10.1109/EUROCON.2013.6625035	reliability engineering;personal software process;software requirements specification;verification and validation;team software process;software engineering process group;software sizing;software verification;search-based software engineering;computer science;systems engineering;engineering;package development process;software design;social software engineering;component-based software engineering;software development;software agent;software engineering;domain engineering;software construction;formal specification;object-oriented programming;empirical process;software measurement;goal-driven software development process;software development process;software requirements;software quality	SE	-57.00184036186737	27.45455611507817	58261
17e39550fe8429fe670259d38187e6f7d4c31e70	dependency related parameters in the reconstruction of a layered software architecture	dependency analysis;architecture compliance;software architecture;architecture reconstruction;layers	Software architecture reconstruction techniques may be used to understand and maintain software systems, especially in these cases where architectural documentation is outdated or missing. Reconstruction of layers is interesting, since the Layers pattern is commonly used in practice. Layers reconstruction algorithms are based on dependency analysis. In this paper, we define two dependency related parameters and explore their impact on the results of a layer reconstruction algorithm. The first parameter concerns the types of dependencies between software units included in the algorithm. The second parameter concerns the maximum ratio of allowed back-call dependencies between two software units in different layers. By means of experiments on a case system, and by means of conformance checking results, we explain and illustrate the impact of differences in parameter settings. We show that these parameters have a big impact. Consequently, exact specification of used parameter values is relevant in publications. Furthermore, parameter configuration options may be considered to improve tool support.	algorithm;conformance testing;dependence analysis;documentation;experiment;software architecture;software system	Leo Pruijt;Wiebe Wiersema	2016		10.1145/2993412.3003394	reliability engineering;reference architecture;software architecture;layers;computer science;engineering;software engineering;data mining;engineering drawing;dependence analysis	SE	-55.60337465891263	23.942595338040082	58370
ca060f66c6aa2cf0900f2417702c65f327fba794	case histories on knowledge-based design systems for lsi and software	intelligent control shell;production system;knowledge based design systems;frame;software synthesis;lsi circuit synthesis;term rewriting system			Masanobu Watanabe;Toru Yamanouchi;Masahiko Iwamoto;Satoru Fujita	1995	IEICE Transactions		frame;embedded system;real-time computing;computer science;artificial intelligence;production system;software system	SE	-48.89977644639276	29.757359294520192	58405
9c410b9774a016fb8ccabaaa770a2d80fae2af1e	rapid prototyping for domain-specific languages - from stakeholder analyses to modelling tools		Today, modelling is a widely acisecepted technique in Software Engineering (SE). Many problems can be expressed using general-purpose modelling languages such as the UML. For more specific problems, the definition of a specialised domain-specific language (DSL) may be required. The definition of a domainspecific language is a time-consuming task that requires knowledge in (modelling) language design, deep understanding of the domain and, to be useful and usable, user assistance and tool support. In this paper, we present an approach to derive a domain-specific language from the description of instances of the domain under consideration: Stakeholders describe model instances from which the metamodel (the DSL) and a suitable modelling tool are derived automatically. We describe a tool that we used to experiment with this approach, its current state and the future work.	add-ons for firefox;code refactoring;digital subscriber line;domain-specific language;general-purpose modeling;mathematical optimization;metamodeling;microsoft visio;model transformation;money;prototype;rapid prototyping;requirement;software engineering;unified modeling language;usability;user interface;user-centered design	Marco Kuhrmann;Georg Kalus;Alexander Knapp	2013	Enterprise Modelling and Information Systems Architectures		natural language processing;computer science;systems engineering;programming language	SE	-48.8686535870482	24.85343059762136	58713
fd7eaca1d287a646b8ea20af6a692e5390198f88	exploring component-based approaches in forest landscape modeling	spatial context;landscape model;programming language;component based modeling;landscape component;spatial interaction;forest landscape model;spatially explicit;com;object oriented;spatial model;forest management	Forest management issues are increasingly required to be addressed in a spatial context, which has led to the development of spatially explicit forest landscape models. The numerous processes, complex spatial interactions, and diverse applications in spatial modeling make the development of forest landscape models difficult for any single research group. New developments in componentbased modeling approaches provide a viable solution. Component-based modeling breaks a monolithic model into small, interchangeable, and binary components. They have these advantages compared to the traditional modeling work: 1) developing a component is a much smaller task than developing a whole model, 2) a component can be developed using most programming languages, since the interface format is binary, and 3) new components can replace the existing ones under the same model framework; this reduces the duplication and allows the modeling community to focus resources on the common products, and to compare results. In this paper, we explore the design of a spatially explicit forest landscape model in a component-based modeling framework, based on our work on object-oriented forest landscape modeling. We examine the representation of the major components and the interactions between them. Our goal is to facilitate the use of the component-based modeling approach at the early stage of spatially explicit landscape modeling.  2002 Elsevier Science Ltd. All rights reserved.	component-based software engineering;interaction;programming language	Hong S. He;D. R. Larsen;David J. Mladenoff	2002	Environmental Modelling and Software	10.1016/S1364-8152(02)00014-2	simulation;forest management;computer science;spatial contextual awareness;object-oriented programming;ecology	AI	-52.34515794318437	29.868647012069648	58724
7c7c0baae35b422ac54b1898d6ddde4350dde14a	an xml-based meta-model for process and agent-based integrated software evolution environment (praise)	software evolution;meta model		integrated software;metamodeling;software evolution;xml	William C. Chu;Ching-Huey Wang	2005			systems engineering;xml;integrated software;computer science;software development;praise;metamodeling;software evolution;software design	SE	-51.316330079076096	26.563038711350597	59032
d60588628ddc0088a5b17cc7abb9b621e4101057	towards an agent-driven software architecture aligned with user stories	agile development;agent architecture;user story	Agile principles have taken an increasing importance in the last decades. Software Architecture (SA) definition is perceived as a non-agile practice as it is executed in a top-down manner, reminding waterfall development, and sometimes imposes heavy documentation. This paper proposes to systematically build an agent-oriented SA from a set of User Stories (US), the core artifact to document requirements in agile methodologies. Previous research has allowed to define a unified US meta-model for the generation of templates relating WHO, WHAT and WHY elements. This meta-model’s elements define a syntax issued from practitioners templates associated with semantics from Goal Oriented Requirements Engineering frameworks, more precisely i*. With a set of US following the templates of this previous model, the link between the US and SA concepts is systematically studied and a transformation process is proposed. The SA can decline agent behaviors aligned with requirements and organizational behaviors. Moreover, requirements (thus US) are subject to evolution through agile iterations; the SA can evolve with these changes in a semi-automatic manner. We thus argue that the Agent-SA produced with our transformation process contributes to the overall project agility.	agent-based model;agile software development;computer-aided software engineering;documentation;high- and low-level;iteration;metamodeling;organizational behavior;plug-in (computing);requirement;requirements engineering;scrum (software development);semiconductor industry;software architecture;software system;top-down and bottom-up design;user requirements document;user story;waterfall model	Yves Wautelet;Samedi Heng;Manuel Kolp;Christelle Scharff	2016		10.5220/0005706103370345	enterprise architecture framework;agent architecture;reference architecture;website architecture;computer science;artificial intelligence;agile software development;solution architecture;software architecture description;resource-oriented architecture;world wide web;user story;data architecture	SE	-56.973926794024074	20.177093051840817	59046
81ef4960b78acb2133405c3ce7e07e6fbaaf3cb4	managing an object-oriented project using an iterative approach	object oriented		iterative method	Perry Rotella	1994	OOPS Messenger	10.1145/260060.260093	computer science;knowledge management;programming language;object-oriented programming	PL	-50.763126948282654	27.994208370621042	59049
807669a44b1c1af458beda3352925e3699810c61	a performance model management repository based on the palladio component model		Applying performance models to evaluate component-based enterprise applications in practice is becoming more and more difficult with an increasing organizational complexity. Components can be governed by different organizational units, are subject to a continuous shift between life cycle phases, and exhibit diverging release levels. Creating and maintaining performance models based on the composition of these components can, therefore, represent an elaborate task. A Performance Model Management Repository (PMMR) supports managing performance models in complex enterprise environments. This paper presents the implementation of a PMMR based on the Palladio Component Model (PCM). The PCM meta-model is extended to enable managing and maintaining multiple versions of components and their interfaces. Furthermore, resource demand specifications derived from different hardware environments are integrated into the meta-model. The Palladio-Bench is extended for persisting PMMR elements to EMFStore.	complexity theory and organizations;component-based software engineering;enterprise software;metamodeling;test bench	Alexandru Danciu;Andreas Brunnert;Helmut Krcmar	2015	Softwaretechnik-Trends		computer science;software engineering;systems engineering	SE	-56.475916609423344	21.211992547738372	59092
e06b27ac7caee601f26c0b6e97c74ac44bcb258c	software architecture reconstruction research support as provided by husacct		Software architecture reconstruction techniques may be used to understand and maintain software systems, especially in these cases where architectural documentation is outdated or missing. This paper presents the architecture reconstruction functionality of HUSACCT and describes how this functionality may be used and extended with algorithms in support of reconstruction research focusing on modular architectures. The tool provides a graphical user interface to select an algorithm, edit its parameters and to execute or reverse the algorithm. To study the results, browsers and diagrams are available. Furthermore, a user interface is provided to enhance the determination of the effectiveness of algorithms by means of the MoJoFM metric.	algorithm;diagram;documentation;graphical user interface;software architecture;software system	Leo Pruijt;Wiebe Wiersema;Jan Martijn E. M. van der Werf	2017		10.1145/3129790.3129819	service-oriented modeling;systems engineering;computer science;resource-oriented architecture;software system;software architecture;reference architecture;software architecture description;database-centric architecture;space-based architecture	SE	-50.15752294515419	28.862777542623483	59137
6ef80bd76cea94d3b5032782194ebc70f6cdac22	merging model driven architecture and semantic web for business rules generation	management system;automatic generation;development environment;ontology definition metamodel;semantic web;artificial intelligence;reasoning;knowledge representation;ontology;business rules;model driven architecture;knowledge based systems	Business rules are statements that express (certain parts of) a business policy, defining terms and defining or constraining the operation of an entreprise, in a declarative manner. The business rule approach is more and more used due to the fact that in such systems, business experts can maintain the complex behavior of their application in a “zero development” environment. There exist more and more business rule management systems (BRMS) and rule engines, adding new needs in the business rules community. Currently the main requirement in this domain is having a standard language for representing business rules, facilitating their integration and share. Works for solving this lack are in progress at e.g OMG and W3C. The aim of this paper is to propose a way to automatically generate a part of the business rules by combining concepts coming from Model Driven Architecture and Semantic Web using the Ontology Definition Metamodel.	business rule management system;business rules engine;computation;computer science;computer-integrated manufacturing;metamodeling;model-driven architecture;natural language;ontology definition metamodel;platform-independent model;sms language;semantic web;semantics of business vocabulary and business rules;xml metadata interchange	Mouhamed Diouf;Sofian Maabout;Kaninda Musumbu	2007		10.1007/978-3-540-72982-2_9	business rule management system;business logic;semantics of business vocabulary and business rules;business domain;computer science;knowledge management;artifact-centric business process model;business process management;artificial intelligence;semantic web;ontology;business case;process modeling;data mining;production rule representation;management system;database;development environment;business process model and notation;business system planning;business process;business process discovery;business rule;business process modeling;reason;business architecture	AI	-53.65156598403471	19.386734510457416	59147
6cc6b3a2a0ac7dfd1d43dacccb19092d84fbbed3	quality attributes of systems-of-systems: a systematic literature review		System-of-Systems (SoS) have been considered the new trend of software systems for several reasons, such as the advancement of computer technology and the increasing complexity and size of the systems. The concept of SoS has the central idea of a set of operationally independent software systems that collaborate together to compose a larger and more complex system. For SoS, several quality attributes are critical due to its characteristics and domain constraints. However, the existent quality models were not conceived to address SoS. Therefore, the identification of quality models that can address the quality attributes for SoS needs to be investigated. So, the purpose of this work is to identify the most common quality attributes in SoS context and analyze their coverage by the well established ISO/IEC 25010 quality model. As a result, we have identified that the current quality models cannot address the complex interdependencies between SoS quality attributes due its dynamic nature.	apple sos;complex system;computer;iso/iec 42010;iso/iec 9126;interdependence;list of system quality attributes;non-functional requirement;software system;system of systems;systematic review;whole earth 'lectronic link	Thiago Bianchi;Daniel Soares Santos;Katia Romero Felizardo	2015	2015 IEEE/ACM 3rd International Workshop on Software Engineering for Systems-of-Systems		reliability engineering;verification and validation;computer science;systems engineering;data mining;software quality control;software quality;software quality analyst;software system	SE	-60.03895057355937	24.898045040925975	59248
ff05c6969867379349322e266e44ab156d9ab494	from application domains to executable domains: achieving reuse with a domain network	developpement logiciel;architecture logicielle;program transformation;computer software maintenance;computer software reusability;ingenieria logiciel;specification programme;transformation programme;software engineering;maintenance logiciel;software architecture;transformacion programa;desarrollo logicial;software development;reutilisation logiciel;genie logiciel;program specification;especificacion programa	Software generators are among the most effective methods for achieving software reuse. Describing an application using a domain specific language and then performing a single refinement step to an executable language is the approach used by most generators. This paper shows how to use the Domain Network (DN) concept, a set of interconnected domains, as a way to improve reuse in the context of software generation.	executable	Ulf Bergmann;Julio Cesar Sampaio do Prado Leite	2000		10.1007/978-3-540-44995-9_3	domain analysis;software architecture;computer science;software development;feature-oriented domain analysis;domain engineering;programming language	AI	-50.461852301887035	28.32943407897829	59287
924eb58f783a3ccca647dc2b26056856accbb441	service integration patterns for invoking services from business processes		In a process-driven and service-oriented architecture, services and business processes are typically integrated by invoking services from the activities of the business processes. The software architect and developer must decide how a service is invoked from a business process. In this decision the requirements that result from the business processdriven service orchestration concept must be considered, as well as the functional architecture requirements of the business processes. We present a pattern language that addresses these design issues and represents proven design knowledge for invoking services from business processes.	business process;business requirements;orchestration (computing);pattern language;requirement;service-oriented architecture;service-oriented infrastructure;software architect;word lists by frequency	Carsten Hentrich;Uwe Zdun	2007			architecture;business process;systems engineering;orchestration (computing);services computing;process management;software architecture;business service provider;computer science;industrialization of services business model;artifact-centric business process model	SE	-55.62571068680891	18.25967675208994	59436
633df21e7d72d86780493178308042920d980e52	organithms: the dynamics of software evolution	software systems;software engineering;software evolution;software systems software prototyping prototypes;portability organithms local prototyping software evolution software system specification global prototyping rapid reconfiguring function access diffusion lisp based implementation language machine architecture;design for change	No software system is static. A useful one evolves rapidly: The greater the number of users, the more rapid the change. How does one design for change? How does one treat specification dynamically? The issues that must be treated are local and global prototyping, rapid reconfiguring, and the control of function access and diffusion. What are the properties of an implementation language that are crucial? Why is a Lisp-based implementation language preferable to Ada? Does machine architecture play an important part? Can one separate portability from evolution?	ada;lisp;object language;software evolution;software portability;software system	Alan J. Perlis	1989		10.1109/CMPCON.1989.301955	software requirements specification;computer architecture;verification and validation;software sizing;computer science;package development process;backporting;software evolution;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;portability testing;software deployment;software development process;software system;computer engineering	PL	-52.269559235409865	29.626915283098338	59526
07ccb9db866bc2f7bfa324a7f727d6514ec68637	an empirical study on the usefulness of conallen's stereotypes inweb application comprehension	design model;empirical study;design notations empirical studies web applications;navigation structure;separation of concern;business logic;statistical significance;uml diagrams conallen stereotypes web application comprehension business logic navigation structure persistent data storage design diagrams;web applications;experience report;conallen stereotypes;uml diagrams;data storage;internet;empirical validation;unified modeling language;unified modeling language internet;design notations;source code;web application comprehension;empirical studies;design diagrams;reverse engineering;unified modeling language object oriented modeling reverse engineering logic navigation memory code standards context modeling costs user interfaces;persistent data storage	Comprehension of Web applications is a complex task, since several concerns co-exist in their implementation, among which the business logic, the navigation structure (as supported by hyperlinks and form submission), and persistent data storage. Design notations tailored for Web applications promise increased understandability and maintainability, thanks to the explicit representation of Web specific elements (such as hyperlinks and forms). In this paper, we report the results obtained from the execution of an empirical study involving comprehension tasks on two Web applications. Assuming the availability of the source code, two forms of design diagrams have been recovered from the code: standard UML diagrams and UML diagrams extended with Conallen's stereotypes. The research question addressed by this study is whether enriching standard UML diagrams with Web specific stereotypes gives any significant contribution to the under standability of the Web applications	business logic;computer data storage;diagram;expert system;hyperlink;list comprehension;population;programmer;reverse engineering;software system;unified modeling language;web application;world wide web	Filippo Ricca;Massimiliano Di Penta;Marco Torchiano;Paolo Tonella;Mariano Ceccato	2006	2006 Eighth IEEE International Symposium on Web Site Evolution (WSE'06)	10.1109/WSE.2006.3	unified modeling language;web modeling;computer science;operating system;software engineering;applications of uml;database;programming language;empirical research;world wide web	SE	-49.22933545632503	24.685786076038806	59574
aa60afef99ab9fc52baa5ec84a95636cc5229df7	adapting service interfaces when business processes evolve	evolution web services modeling;business rules service interface adaptation business process modeling software analysis conceptual level software design web services bpel script xml documents xml schema language optimal communication xml schemas data exchange conceptual schema platform independent model;unified modeling language xml business data models adaptation models measurement redundancy;xml electronic data interchange user interfaces web services business process execution language	Nowadays, there are many popular different notations of business process modeling, such as, e.g. BPMN [1], for a software analysis. Modeling of business processes at the conceptual level allows domain experts to cooperate in the analysis and to design the software. The whole business process model can be later translated to web services and executable BPEL [2] scripts which orchestrate all related parts together. Besides this automatization, it is necessary to define the structure of each data object in the business model. Web services usually communicate by exchanging XML documents [3]. Therefore, a software architect has to define also an XML schema of XML documents by an XML schema language, e.g. XML Schema [4]. In this paper, we present a method which derives and adapts optimal communication XML schemas for a given conceptual schema of a business process, complemented with a conceptual schema of exchanged data. We use a view on a part of a Platform Independent Model of a whole system as conceptual schema of exchanged data. We derive several XML schema documents from given inputs and choose the one which has minimal values for three metrics. The result of these three metrics is a measure of a quality of an XML schema document with respect to conceptual model of exchanged data and business rules applied on this document.	algorithm;business process execution language;business process model and notation;conceptual schema;correctness (computer science);directed acyclic graph;emoticon;executable;graph coloring;platform-independent model;problem domain;process modeling;real life;semiconductor industry;software architect;subject-matter expert;time complexity;usability;web service;xml namespace;xml schema	Vladimir Kudelas;Marek Polák;Martin Necaský;Irena Holubová	2014	2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2014.6861062	xml validation;xml encryption;xml;business process execution language;xml schema;streaming xml;computer science;xs3p;document structure description;service-oriented architecture;xml framework;soap;xml schema;database;business process model and notation;xml signature;programming language;ebxml;world wide web;xml schema editor;cxml;efficient xml interchange	DB	-53.180526039458485	19.79844152194698	59603
bedd238659c556d3269f5d0369876fc674a29962	specification matching of state-based modular components	k;data refinement specification matching state based modular component software component retrieval library component interface;280301 programming techniques;formal specification;tool support;software libraries;retrieval;component based development;specification matching;object oriented programming;software reusability;software component;user requirements;software reusability formal specification object oriented programming software libraries;700199 computer software and services not elsewhere classified;software engineering information retrieval software libraries formal specifications information technology software reusability buildings computer industry;matching method	Retrieval of software components from a library relies on techniques for matching user requirements against library component interfaces. In this paper we introduce a number of techniques for matching formally specified, statebased modules. These techniques will form the basis for retrieval tool support. The techniques described in this paper build on existing specification matching methods, based on individual functions, specified using preand post-conditions. We begin by defining a basic module matching technique, based on matching the individual units within a module. We consider variations of this technique that take into account two important features of modules: the visibility of module entities; and the use of state invariants. An advanced technique, based on data refinement and the use of coupling invariants, is also described.	component-based software engineering;entity;loose coupling;refinement (computing);requirement;specification language;user requirements document;z notation	David Hemer	2003		10.1109/APSEC.2003.1254400	computer science;theoretical computer science;component-based software engineering;database;programming language	SE	-49.35703270223271	27.89567862449744	59681
030cbf21b5eca74cf65ca899a29d271895ace603	towards a framework for building saas applications operating in diverse and dynamic environments		Enterprises have increasingly adopted the Software-as-a-service (SaaS) model to facilitate on-demand delivery of software applications. A SaaS customer - tenant - may operate in diverse environments and may demand a different level of qualities from the application. A tenant may also operate in a dynamic environment where expectations from the application may change at run-time. To be able to operate in such environments, SaaS application requires support at both the architecture and implementation levels. This paper highlights the issues in building a SaaS that can accommodate such diverse and dynamic environments. We propose a methodological framework called Chameleonic-SaaS that abstracts out the responsibilities involved and provides guidelines to realize it. Our framework introduces variability in the architecture to manipulate the architecture-level decisions, especially tactics. Feasibility of the framework is demonstrated by an example of a MOOC application.	software as a service	Ashish Agrawal;T. V. Prabhakar	2016		10.1007/978-3-319-48992-6_22	architecture;systems engineering;software;software as a service;computer science	HPC	-60.23458837830973	19.346854912278367	59739
f69a8d8e8de36212c339619fdc5709b4ded5eefd	foundations for features.	software engineering;feature interaction	The feature interaction problem arose in the field of telecommunications but is now recognized as a general problem of software engineering. Capturing the idea of feature interaction in a simple and precise way has proven difficult. This paper briefly surveys existing notions of feature and feature interaction.	feature interaction problem;software engineering	Glenn Bruns	2005			computer science;systems engineering;data science;feature-oriented domain analysis;data mining	SE	-59.39730325787794	24.95683852614542	59853
65d2e32c01cee91b3f8f81b375de9cf2e822cc8e	a software process model based on unit workload network	project management;information science;research and development management;testing;computer networks;network topology;software process model;production facilities;project management production facilities productivity network topology information science testing humans research and development management quality management computer networks;humans;productivity;quality management	We are developing a software engineering and management database called KyotoDB based on an objectbased data model. It has two types of objects. The first represents engineering data such as specifications, programs, etc., and encapsulates operations on these data. The second represents management data and encapsulates operations on the management data. Each instance of the second type object, representing each individual Unit Workload, includes process programs and operations on management data (schedule, cost, quality, etc.) for that Unit Workload. The process program in UnitWorkload class invokes tools (editors, compilers, debuggers, etc.), and pass engineering data (files) or management data to those tools. The process programs also specify procedures to maintain semantic consistency between many engineering data, as well as between many human interactions. Figure 1 shows an example hierarchial structure in KyotoDB. Figure 2 is an example of process program in class Unit Workload. Project	compiler;consistency model;data model;debugger;interaction;process modeling;software development process;software engineering	Yoshihiro Matsumoto;Kiyoshi Agusa;Tsuneo Ajisaka	1989		10.1109/ISPW.1989.690433	project management;element management system;extreme project management;systems management;program management;information technology management;software project management;data management;systems engineering;engineering;knowledge management;resource management;management science;network management application;structure of management information;information management;application lifecycle management;project management triangle;project planning	DB	-52.40792665359277	21.699034246013966	59959
b374c09f4aae61d4aa1bb27f664be8211f52bb73	'engineering' the software in systems	case tools software engineering systems engineering embedded systems reactive systems structured life cycle functional requirements nonfunctional requirements software reuse software maintenance object oriented solution implementation goal user functionality product quality skills experience project team team responsibilities;software engineering	The paper describes a method and notation for designing the software in embedded and other reactive systems. The design method is described in the context of a structured life-cycle, which recognises both functional and non-functional requirements, and it is illustrated by application to a substantial example. Mainly, for reasons of reuse and maintenance, an object-oriented solution is an implementation goal. The method focuses on producing software fit for its intended purpose in terms of user functionality, while being concerned with other aspects of product quality. It also seeks to efficiently utilise the varied skills and experience in a project team, and assist the team in distributing and meeting responsibilities. Commercially vailable CASE tools are adapted to support the method.		Derrik Morris;Peter Green;Richard Barker	1995	Software Engineering Journal	10.1049/sej.1995.0030	reliability engineering;requirements analysis;personal software process;software requirements specification;verification and validation;team software process;software engineering process group;software project management;computer science;systems engineering;engineering;software design;social software engineering;component-based software engineering;software development;software design description;requirement;software engineering;domain engineering;software construction;systems development life cycle;software walkthrough;software development process;software requirements;software system	SE	-58.99926594229078	26.34691457455323	60034
61a5ed641ca96bc850ae6f0f5aedab822bcd62c8	principles for systematic development of an assurance case template from iso 26262		A failure in a critical system can cause death, injury, financial loss, and environmental damage. To develop safe and trustworthy systems, we need to plan the development and assessment of system functionality in advance. Assurance Cases are a generalization of Safety Cases, and are gaining momentum as a preferred way of demonstrating assurance of critical properties in complex software-intensive systems. To cope with the lack of standardized assurance structures, and to encourage safety assessment prior to development, we previously proposed the use of an assurance case template. The principles presented here can be used to build an assurance case template that complies with the functional safety standard, ISO 26262 in a cost-effective way. In the future, such principles may lead to semi-automated development of these templates.	critical system;requirement;semiconductor industry;trustworthy computing	Thomas Chowdhury;Chung-Wei Lin;BaekGyu Kim;Mark Lawford;Shinichi Shiraishi;Alan Wassyng	2017	2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2017.14	computer science;trustworthiness;reliability engineering;controllability;software;functional safety;critical system	Embedded	-62.619864106930095	28.5304925432112	60160
3b37f9b623d0ae002e6ffa80654fbabc6f49b631	towards a process modeling language for method engineering support	software;method engineering;software process improvement;method engineering support;satisfiability;data mining;software development methodology;requirements engineering;computational modeling;meta modeling technique;requirements engineering method engineering support pml process modeling language software development methodology came computer aided method engineering meta modeling technique process model enacting;systems analysis;process model enacting;process support;process modeling language;software development;unified modeling language;process control;pml;programming metamodeling computer science software maintenance project management assembly software systems computer errors usability;process modeling languages;process model;came;communities;systems analysis software process improvement;programming;computer aided method engineering method engineering process modeling languages;meta model;evaluation framework;computer aided method engineering	The increasing need for flexible software development methodologies has led to a new approach called method engineering. Method engineering aims at constructing new methodologies, more flexible and better adaptable to the situation of every software development project. Computer-Aided Method Engineering (CAME) strives to support a wide range of activities involved in the engineering of a methodology that is well suited for an individual project situation. CAME environments take advantage of meta-modeling techniques that are rich in modeling the product aspect of methodologies but are severely weak in presenting, modeling and enacting process models. In this article, we have focused on the process support deficiency of CAME technology and therefore investigating the possibility of adopting suitable Process Modeling Languages (PMLs). To this aim, we have introduced a set of criteria in the form of an evaluation framework to identify the main constituents of the PML technology satisfying the requirements of method engineering.	angular defect;metamodeling;method engineering;modeling language;process modeling;requirement;software development process	Ali Niknafs;Mohsen Asadi	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.956	metamodeling;unified modeling language;method engineering;systems analysis;programming;computer science;systems engineering;software development;process control;process modeling;requirements engineering;programming language;computational model;satisfiability	SE	-57.607717003083316	26.435004179728757	60215
aa20ddd7ea73f0a68be96ff4a2b4e70b9827434f	mock object models for test driven development	program diagnostics;test driven development;unit testing;object oriented programming;system design mock object tool model test driven development unit testing;systems analysis formal verification object oriented programming program diagnostics program testing;formal verification;program testing;systems analysis;system design;mock object tool model;system testing software testing software engineering laboratories writing conference management research and development management software development management engineering management application software;object model	Test driven development uses unit tests for driving the design of the code. Mock object is an object that imitates the behavior of an object with which class under test has an association to assist the unit testing. Although many tools for mock object are used in practice, there has been few research on defining the mock object model. For the comparisons of the testing capability of the tools, it is important to define the models. In this paper we represent the models of the existing mock object tools and indicate the limitations of them. In addition we propose a new model to overcome the limitations of the existing tools. With this model, more general behavior of the class under test related to the mock object can be expressed and tested	mock object;test-driven development;unit testing	Taeksu Kim;Chanjin Park;Chisu Wu	2006	Fourth International Conference on Software Engineering Research, Management and Applications (SERA'06)	10.1109/SERA.2006.49	test-driven development;systems analysis;model-based testing;simulation;object model;white-box testing;formal verification;computer science;systems engineering;mock object;object-oriented design;software testing;unit testing;programming language;object-oriented programming;test management approach;systems design	SE	-54.86005627426524	32.08113625896703	60238
1c67019bf480db43e30c34914971ee057717e0a4	actor-led object modeling for requirements and systems analysis	system analysis;object model		requirement	Ying Liang	2001			method;computer vision;object-oriented design;systems analysis;object (computer science);object model;object-modeling technique;artificial intelligence;computer science	Robotics	-50.57304844049623	27.733786086196062	60303
d3039b87655be47f0595d4f23b96182095bc5c27	achieving seamless component composition through scenario-based deep adaptation and generation	component definition language;component generation;scenario based adaptation;hd28 management industrial management;component composition;component reuse;xml;qa76 computer software	Mismatches between pre-qualified existing components and the particular reuse context in applications have been a major factor hindering component reusability and successful composition. Although component adaptation has acted as a key solution of eliminating these mismatches, deep adaptation is often either impossible or incurring heavy overheads in the components. This paper proposes an approach, namely Scenario-based dynamic component Adaptation and GenerAtion (SAGA), to achieve deep adaptation with little code overhead through XML–based component specification, interrelated adaptation scenarios and corresponding component adaptation and generation. Keywords—Component Reuse, Scenario-Based Adaptation, Component Generation, Component Composition, Component Definition Language, XML.	component-based software engineering;overhead (computing);seamless3d;third-party software component;xml	Xiaodong Liu;Beihu Wang;Jon M. Kerridge	2005	Sci. Comput. Program.	10.1016/j.scico.2004.11.010	real-time computing;xml;common component architecture;computer science;component;programming language	SE	-55.155285840998395	26.370406290634467	60306
0285d89e288056d67b384a2b04c533735651fc38	business process variability and public values		A business process is a structure of inter-related activities that are executed in order to achieve a specific business objective. Organizations often maintain multiple variants of a given business process because of changing conditions, different regulations in different countries, or other contextual factors. We aim at specifying the relationship between a generic business process and its different variants, taking the perspective of public values, such as privacy, accountability, and transparency. The business process variants in turn may be a basis for software specifications – in this, business processes would be bridging between societal demands (possibly concerning public values) and the corresponding technical (software) functionalities. Our contribution is featuring a meta-model that describes business processes on a value-independent level; they can be extended towards value-specific business process variants that can be related in turn to software architectures. We reflect this in proposed value operationalization guidelines, using concepts from business process design as a basis; those guidelines assume coming firstly through technology-independent artefacts and secondly – through technology-specific artefacts, to arrive at software specifications that are adequate with regard to public-values-related demands.	business process;heart rate variability	Boris Shishkov;Jan Mendling	2018		10.1007/978-3-319-94214-8_31	process management;business process;accountability;business process modeling;software;transparency (graphic);software design;operationalization;bridging (networking);engineering	HCI	-57.28413782070684	19.60512207231791	60402
a636ce1e959dce2307d1c981326f8795c8034002	analyzing the effects of formal methods on the development of industrial control software	testing;formal verification;medical services;variable speed drives;industrial control;mathematical model;explosions;software design;biomedical equipment;variable speed drives mathematical model testing explosions medical services software design;x ray machines formal methods industrial control software development philips healthcare analytical software design method asd method formal technology defect free control software sophisticated x ray equipments control software units;x rays;x rays biomedical equipment formal verification health care industrial control;health care	Formal methods are being applied to the development of software of various applications at Philips Healthcare. In particular, the Analytical Software Design (ASD) method is being used as a formal technology for developing defect-free control software of highly sophisticated X-ray equipments. In this paper we analyze the effects of applying ASD to the development of various control software units developed for the X-ray machines. We compare the quality of these units with other units developed in traditional development methods. The results indicate that applying ASD as a formal technology for developing control software could result in fewer defects.	formal methods;list of version control software;software bug;software design	Jan Friso Groote;Ammar Osaiweran;Jacco H. Wesselius	2011	2011 27th IEEE International Conference on Software Maintenance (ICSM)	10.1109/ICSM.2011.6081983	personal software process;medical software;verification and validation;formal methods;software sizing;formal verification;software verification;computer science;systems engineering;engineering;package development process;software design;social software engineering;software reliability testing;software development;software design description;software engineering;software construction;mathematical model;software testing;software deployment;software development process;health care;software system;computer engineering	SE	-62.007011157780056	29.466436351384043	60427
bc738621c2bf5787dfe9dda9034c5c2f0e5f61e7	reuse facts and myths	investment;object-oriented programming;software reusability;oo technology;awareness;incentives;mid-term investment;object-oriented programming;product family;product releases;product strategy;software development process;software reuse	Non-technical, i.e., management circles are increasingly frustrated by the slow progress of reuse in terms of realized Return of Investment. Object-oriented technologies are often viewed as having reuse ‘built-in’, thereby enabling the introduction of two technologies at once with reduced effort. This view is supported by attributes of 00 technology, namely inheritance and polymorphism, which provide adaptability of available objects to diverse environments. Reuse is a software engineering discipline rather than a technology. It can be applied to any type of software assets, be it class libraries or 3rd generation software. 00T is in no way a replacement for reuse, 00T does not automatically yield high reuse rates, but 00T is an enabling platform for high degrees of reuse if explicitly pbmedjor and appropriate actions taken. Ignoring this experience leads to generation of software which is object-oriented, but not msable beyond a very limited scope.	library (computing);software engineering	Michael Wasmund	1994			reliability engineering;investment;systems engineering;engineering;software engineering;management;software development process	SE	-61.92675211868507	23.37537373421651	60442
380da64335f3d0bea16020a4deb510d35107b201	smart - scenario management and requirements tool	project management data engineering software systems software tools performance analysis;project management;formal specification;project manager;formal specification project management software tools systems analysis project support environments;requirements engineering community scenario management requirements tool web based interface project management function similarity measures;systems analysis;requirement engineering;project support environments;software tools;similarity measure	Requirements elicitation, derivation, refinement, and specification are all very time and effort intensive activities. With effective tool support, the time and effort required for these activities can be significantly reduced. The right tool will also reduce the learning curve for individuals new to Requirements Engineering by simplifying the requirements phase in its entirety. To this end, we will demonstrate the Scenario Management and Requirements Tool (SMaRT). It provides an intuitive web-based interface that supports analysts as they input, manage, view, analyze, and work with scenarios and their associated episodes, requirements, goals, obstacles, and preand postconditions. The tool also supports project management functions, and over the course of the next few years it will grow to encompass greater functionality through the implementation of: similarity measures to aid in the automatic identification of probable duplication, syntactic indicators of scenario dependencies, notifiers of probable coverage gaps, procedural guidance for analysts, as well as revision and evolution tracking mechanisms.	automatic identification and data capture;postcondition;refinement (computing);requirement;requirements elicitation;requirements engineering;web application	William H. Stufflebeam;Annie I. Antón;Thomas A. Alspaugh	2003		10.1109/ICRE.2003.1232782	project management;reliability engineering;systems analysis;requirements analysis;software requirements specification;requirements management;extreme project management;market requirements document;work breakdown structure;software project management;computer science;systems engineering;engineering;knowledge management;requirement;software engineering;formal specification;requirements engineering;application lifecycle management;project management 2.0;project management triangle;management;project planning;project portfolio management	SE	-57.809211462214904	24.49241782906838	60493
43ef1109dbd03c2a9386e689ef887bb34cf4f8ca	automatic generation of software components for financial modelling			component-based software engineering;financial modeling	Francis Oliver Bunnin	2001				SE	-51.32354763510545	26.386396541913843	60540
22a0665b2005a789f0500ff210afcebb33c2a5f5	involving non-technicians in product derivation and requirements engineering: a tool suite for product line engineering	formal specification;tool support;product derivation;product line;requirements engineering;software tools formal specification product development software quality software reusability;requirement engineering;software reusability;product line engineering;dopler tool suite;software tools;tool supported product line engineering approach;software quality;marketing and sales engineering management product customization project management laboratories software engineering software quality productivity software systems application software;software quality tool supported product line engineering approach dopler tool suite product derivation requirements engineering software reusability;product development	Deriving a product from a product line requires the involvement and cooperation of heterogeneous stakeholders such as customers, sales people, or engineers. Taking their different roles and needs into account is essential to exploit the possible benefits of product lines. In this paper we present the tool-supported product line engineering approach DOPLER. We demonstrate how the approach supports both non- technicians and engineers in product derivation and requirements engineering through a set of integrated tools.	new product development;requirements engineering	Rick Rabiser;Deepak Dhungana;Paul Grünbacher;Klaus Lehner;Christian Federspiel	2007	15th IEEE International Requirements Engineering Conference (RE 2007)	10.1109/RE.2007.26	reliability engineering;market requirements document;service product management;computer science;systems engineering;engineering;product lifecycle;product design specification;requirement;software engineering;design review;formal specification;requirements engineering;product management;product design;software quality;new product development;vision document;product engineering	SE	-57.357009691541776	27.38255353027686	60814
3f39445d303c0caf1ee2cfaf68fab4138f1ac669	on the evaluation and improvement of feature-based configuration techniques in software product lines	software;formal specification;feature based configuration technique;dp industry;open source development;software performance evaluation;open source development project;usa councils;computational modeling;scalability product development computer science open source software application software software engineering law legal factors probability distribution runtime;software product line engineering process;societies;software performance evaluation dp industry formal specification;formal analysis;software product line;feature diagrams;modeling;context;open source development project feature based configuration technique software product line engineering process formal analysis feature diagrams;conferences	Our work builds upon previous research on software product lines and formal analysis of feature diagrams carried out since several years at the University of Namur. This PhD thesis aims at evaluating and improving existing feature-based configuration techniques to ease their uptake by practitioners and their integration into the software product line engineering process. The affordability and scalability of the delivered languages, methods and tools are major concerns. Evaluation will take place in the context of an open source development project.	diagram;feature vector;open-source software;scalability;software product line	Arnaud Hubaux;Patrick Heymans	2009	2009 31st International Conference on Software Engineering - Companion Volume	10.1109/ICSE-COMPANION.2009.5071023	reliability engineering;systems modeling;computer science;systems engineering;software engineering;formal specification;programming language;computational model	SE	-57.8513860548528	25.433288798134726	60856
46b3db3cbdac9fe445cb82fbb31f27bb7e355463	a regression testing approach for software product lines architectures	software;regression testing;software reliability product development regression analysis software architecture;maintenance engineering;testing;regression testing approach;computer architecture;software architecture;software product lines architectures;feature extraction;architecture specification regression testing approach software product lines architectures;planning;regression analysis;testing software computer architecture maintenance engineering context planning feature extraction;software product line;software reliability;reference architecture;context;software product lines;product architecture;reference architecture software product lines regression testing;architecture specification;product development	In the Software Product Lines (SPL) context, where products are derived from a common platform, the reference architecture can be considered the main asset. In order to maintain its correctness and reliability after modifications, a regression testing approach based on architecture specification and code was developed. It aims to reduce the testing effort, by reusing test cases, execution results, as well as, selecting and prioritizing an effective set of test cases. Taking advantage of SPL architectures similarities, this approach can be applied among product architectures and between the reference and product architecture. This study also presents an evaluation performed in order to calibrate and improve the proposed approach.	common platform;correctness (computer science);experiment;fault detection and isolation;reference architecture;regression testing;software product line;test case	Paulo Anselmo da Mota Silveira Neto;Ivan do Carmo Machado;Yguaratã Cerqueira Cavalcanti;Eduardo Santana de Almeida;Vinicius Cardoso Garcia;Silvio Romero de Lemos Meira	2010	2010 Fourth Brazilian Symposium on Software Components, Architectures and Reuse	10.1109/SBCARS.2010.14	reliability engineering;reference architecture;computer science;systems engineering;software engineering	SE	-57.82707670064672	30.499452764900717	60873
cf16c6170cfbc2cbb1b4afdfa1a518d610ab1e19	a pattern based model evolution approach	design model;model transformation;context modeling software design information technology australia asia software engineering;object oriented programming;modeling language;software architecture;700100 computer software and services;software architecture object oriented programming;280302 software engineering;software design pattern;eclipse modeling environment pattern based model evolution mda context model driven approaches pattern modeling language software design patterns mof based role metamodel existing modeling framework	In this paper, we present a framework for pattern-based model evolution approaches in the MDA context. In the framework, users define patterns using a pattern modeling language that is designed to describe software design patterns, and they can use the patterns as rules to evolve their model. In the framework, design model evolution takes place via two steps. The first step is a binding process of selecting a pattern and defining where and how to apply the pattern in the model. The second step is an automatic model transformation that actually evolves the model according to the binding information and the pattern rule. The pattern modeling language is defined in terms of a MOF-based role metamodel, and implemented using an existing modeling framework, EMF, and incorporated as a plugin to the Eclipse modeling environment. The model evolution process is also implemented as an Eclipse plugin. With these two plugins, we provide an integrated framework where defining and validating patterns, and model evolution based on patterns can take place in a single modeling environment.	eclipse modeling framework;evolution;graphical user interface;meta-object facility;metamodeling;model transformation;modeling language;name binding;plug-in (computing);scalability;software design pattern	Soon-Kyeong Kim;David A. Carrington	2006	2006 13th Asia Pacific Software Engineering Conference (APSEC'06)	10.1109/APSEC.2006.8	module pattern;software architecture;model-driven architecture;software design pattern;simulation;state pattern;architectural pattern;computer science;systems engineering;software design;strategy pattern;software framework;component-based software engineering;software development;software analysis pattern;software engineering;interaction design pattern;domain model;data mining;adapter pattern;distributed design patterns;modeling language;programming language;object-oriented programming;structural pattern;specification pattern;proxy pattern	SE	-50.216316093635584	26.362959324754055	61090
1b0b518925d9cfee54321d9bda1f292cd4eb3a78	unifying model- and screen sharing		The complexity of engineered systems is ever increasing, resulting in a plethora of larger and more diverse models. This increase in complexity can be addressed by collaborative model development, also known as Concurrent Engineering. We distinguish two distinct types of collaboration, based on the different collaboration needs between modellers: screenshare and modelshare. Screenshare allows users to collaborate-often at the same time-using exactly the same visualization. This implies that even the most trivial model modifications, even semantics-preserving ones, are replicated for all users. Modelshare allows users to share the same model, albeit with different visualizations, offering different views on the model, as standardized in ISO/IEC/IEEE 42010:2011. Both types of collaboration are currently in use. We present a unifying framework integrating both approaches. This unifying framework is similar to our existing framework for concrete syntax, reusing existing modelling tool infrastructure. This allows for different types of collaboration to be intertwined: screensharing with some users, while modelsharing with other users.	debugging;iso/iec 42010;lock (computer science);mit engineering systems division;parse tree;replication (computing);simulation;unification (computer science)	Yentl Van Tendeloo;Hans Vangheluwe	2018	2018 IEEE 27th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)	10.1109/WETICE.2018.00031	visualization;distributed computing;reuse;computer science;collaborative model;syntax;concurrent engineering	Visualization	-48.31278702539848	25.42862842343007	61174
ceac4121ac3bbd74d598eb8eabb3cca306b45500	improvement of software quality attributes in object oriented analysis and design phase using goal-question-metric paradigm	gqm;object;class;association;mfc;ooad;software reliability	In a competitive business landscape, large organizations such as insurance companies and banks are under high pressure to innovate, improvise and distinguish their products and services while continuing to reduce the time-to market for new product introductions. Traditional approaches to software reliability modeling for such software are black box-based. Bad structure or model again can lead us to lower down these non functional properties. The basic constructs of the model are objects. We will not deal about the identification of the objects, as may be referred in many books, but how to model those objects. The objective of this paper is to provide an philosophical approach, using Goal-Question-Metric paradigm, to structure or model the identified objects of software system, in better way to improve the quality of the software.	black box;book;gqm;list of system quality attributes;non-functional requirement;programming paradigm;reliability engineering;software quality;software system	Hitesh Rajput;Lalit Kumar Singh	2011	JSEA	10.4236/jsea.2011.46039	object-oriented analysis and design;reliability engineering;association;verification and validation;software quality management;software sizing;computer science;systems engineering;engineering;artificial intelligence;package development process;social software engineering;object;component-based software engineering;software development;software design description;object-oriented design;software engineering;machine learning;software construction;gqm;class;software walkthrough;programming language;resource-oriented architecture;object-orientation;management;software deployment;software quality control;software quality;software metric;software quality analyst	SE	-62.10524693707552	26.19270229935702	61281
8c2ccd9c3143a9d3b13c6468ead68d7175bda33a	test case generation by simulating requirements analysis model	unified modeling language analytical models skeleton data models computational modeling java contracts;analytical models;software testing;formal specification;test driven development;test driven development requirements analysis unified modeling language software testing;unified modeling language formal specification;contracts;skeleton;computational modeling;unified modeling language;uml based requirements analysis model test case generation quality software development requirements specification;data models;java;requirements analysis	A key to success of high quality software development is to define valid and feasible requirements specification. This paper proposes an efficient test case generation method from the validatable UML-based requirements analysis model to improve feasibility of the requirements specification.	display resolution;requirement;requirements analysis;software development;software requirements specification;test case;unified modeling language	Ryo Shikimi;Shinpei Ogata;Saeko Matsuura	2012	2012 IEEE 36th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2012.53	reliability engineering;unified modeling language;data modeling;test-driven development;requirements analysis;software requirements specification;specification language;systems modeling language;uml tool;computer science;systems engineering;software design;requirement;software engineering;process driven development;system requirements specification;formal specification;functional specification;software testing;non-functional testing;programming language;java;computational model;node;skeleton;use case points;language of temporal ordering specification	SE	-56.20989039382859	27.845294482249095	61449
6de29b450f20135ecb3bd3e3f23b546dc288b716	correlating business objectives with services: an ontology-driven approach	software;requirements engineering ontology driven approach business objectives business functions strategic service alignment servalign management orthodoxy domain ontology;formal specification;service orientation;ontologies artificial intelligence business data processing formal specification;semantics;servalign;ontologies artificial intelligence;requirements engineering;goal modeling business objectives business services ontology service orientation;business data processing;unified modeling language;management orthodoxy;ontologies;ontology driven approach;organizations;business functions;goal modeling;era2015;business services;domain ontology;ontology;strategic service alignment;business objectives;australia;unified modeling language ontologies organizations semantics australia software	Ensuring that the IT/business functions of an organization realize its business objectives has long been recognized as a critically important question. This paper reports on a project that seeks to overturn established management orthodoxy by establishing that business objectives can be adequately modeled by leveraging a domain ontology and that methodological and tool support can be provided for the task of correlating the objectives of an organization and its service offerings. This paper presents an interim report from this project that describes how to leverage a domain ontology in i) building business objective/goal models in a top-down manner (required to be able to refine these to a level where there could be an ontological match between the languages used to describe objectives and services); ii) assessing the degree of ontological match between low-level objectives and business services as a step towards an automated framework for establishing strategic service alignment. We provide a brief illustration of our in-progress implementation within a toolkit called ServAlign.	algorithm;correctness (computer science);documentation;high- and low-level;inference engine;is-a;logic programming;natural language processing;ontology (information science);quality of service;real life;refinement (computing);sensor;strategic management;top-down and bottom-up design	Lam-Son Lê;Aditya K. Ghose;Muralee Krishnan;Krishnajith M. Krishnankunju;Konstantin Hoesch-Klohe	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.13	management by objectives;business domain;systems engineering;knowledge management;artifact-centric business process model;management science;business;business rule	Robotics	-54.58358917360242	19.24095399192669	61542
5ebfeea1c94cd00e5dceb10e0fc14a46ed837e24	experimental evaluation of a tool for change impact prediction in requirements models: design, results, and lessons learned	microsoft excel change impact prediction requirement models ibm rational requisitepro doors semiautomatic change impact analysis requirements engineer semantic information syntactic information formal semantics tric tool tool for requirements inferencing and consistency checking software requirement specification;requirements management tools;systems analysis formal specification formal verification software tools;semantics standards reliability software tools spreadsheet programs analysis of variance;change impact analysis;requirements models requirements management tools change impact analysis;requirements models	There are commercial tools like IBM Rational RequisitePro and DOORS that support semi-automatic change impact analysis for requirements. These tools capture the requirements relations and allow tracing the paths they form. In most of these tools, relation types do not say anything about the meaning of the relations except the direction. When a change is introduced to a requirement, the requirements engineer analyzes the impact of the change in related requirements. In case semantic information is missing to determine precisely how requirements are related to each other, the requirements engineer generally has to assume the worst case dependencies based on the available syntactic information only. We developed a tool that uses formal semantics of requirements relations to support change impact analysis and prediction in requirements models. The tool TRIC (Tool for Requirements Inferencing and Consistency checking) works on models that explicitly represent requirements and the relations among them with their formal semantics. In this paper we report on the evaluation of how TRIC improves the quality of change impact predictions. A quasi-experiment is systematically designed and executed to empirically validate the impact of TRIC. We conduct the quasi-experiment with 21 master's degree students predicting change impact for five change scenarios in a real software requirements specification. The participants are assigned with Microsoft Excel, IBM RequisitePro or TRIC to perform change impact prediction for the change scenarios. It is hypothesized that using TRIC would positively impact the quality of change impact predictions. Two formal hypotheses are developed. As a result of the experiment, we are not able to reject the null hypotheses, and thus we are not able to show experimentally the effectiveness of our tool. In the paper we discuss reasons for the failure to reject the null hypotheses in the experiment.	best, worst and average case;experiment;rational doors;requirement;requirements engineering;semantics (computer science);semiconductor industry;software requirements specification;xojo	Arda Goknil;Roderick van Domburg;Ivan Kurtev;Klaas van den Berg;Fons Wijnhoven	2014	2014 IEEE 4th International Model-Driven Requirements Engineering Workshop (MoDRE)	10.1109/MoDRE.2014.6890826	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;computer science;systems engineering;requirement;system requirements specification;data mining;non-functional requirement;requirements traceability	SE	-58.11240580323082	29.43472880152038	61563
d86fa56deb9f64863517442c57741345b73b6049	object-oriented development of the embedded system based on petri-nets	design process;embedded system;generalized label correcting algorithm;paradigm shift;embedded system design;object oriented;reachability tree;petri net	Embedded systems are an emerging field that has commanded attention and support from the industrial community. They have been a part of daily life today. However, complex behaviors and a lack of reusability and modularization have been obstacles to the development of successful embedded systems. A typical issue or challenge of embedded system design lies on the synthesis of software and hardware. Currently, a paradigm shift towards object-oriented (OO) techniques has been advocated in hope of increasing the reusability and modularization. In this paper, an object-oriented development method of the embedded system based on Petri-nets is proposed. The concurrent ability of Petri-nets assists the concurrent co-design of embedded systems synchronously. In addition, the paper applies the reachability tree and the generalized label-correcting (GLC) algorithm to analyze and to validate the designed processes in object-oriented Petri-net models. This solution approach is novel in a sense that by combining various operators and comparators, different types of developing problems in embedded systems can be solved with one algorithm for different values of the initial node. Author	algorithm;comparator;embedded system;petri net;programming paradigm;reachability;systems design	Chun-Che Huang;Wen-Yau Liang	2004	Computer Standards & Interfaces	10.1016/j.csi.2003.08.001	paradigm shift;real-time computing;design process;computer science;theoretical computer science;operating system;software engineering;database;distributed computing;programming language;object-oriented programming;petri net	Embedded	-48.70411078974142	30.616790442794436	61574
642de629dc7f622ac06d79d22d3ae7840c43f37e	the state of the art and future perspectives in systems of systems software architectures	architectural design;architectural representation;system of systems;architectural evaluation;architectural evolution	Currently, software systems have become increasingly large and complex, often resulted by the integration of several operationally independent systems, resulting in a new class of systems: the Systems of Systems (SoS). In another perspective, software architectures play a major role in determining system quality, since they form the backbone of any successful software-intensive system. Attention given to the software architectures of SoS is also certainly fundamental to the success of such systems. However, it is observed that there is a lack of works that present a wide and, at the same time, a detailed panorama about how SoS architectures have been treated. In this scenario, the main contribution of this paper is to present the state of the art on software architectures of SoS, mainly regarding their development, representation, evaluation, and evolution. This work also contributes with future research topics on SoS architectures that should be still investigated. Besides that, we intend this paper opens new perspectives of research in the software architecture area, intending to contribute to the success of SoS.	apple sos;internet backbone;software architecture;software system;system of systems	Elisa Yumi Nakagawa;Marcelo Benites Gonçalves;Milena Guessi;Lucas Bueno Ruas de Oliveira;Flávio Oquendo	2013		10.1145/2489850.2489853	architectural pattern;systems engineering;engineering;computer engineering	SE	-61.519282978200835	20.912630064793294	61624
21ba9e5b02ce1e0e116329e8d38e5bdf5b1a1f28	automating change evolution in model-driven engineering	mde tools;modelizacion;productivite;programming language;system modeling;orientado aspecto;program transformation;model transformation;software engineering;productividad;modelisation;model transformation model driven engineering programming languages mde tools software development system design;model driven engineering productivity aerospace electronics computer errors design automation manufacturing automation production facilities programming java refining;system design;software development;model driven engineering;software quality change evolution automation model driven engineering software complexity model transformation aspect oriented techniques legacy systems program transformation;management of change;architecture basee modele;aspect oriented;source code;information system;productivity;management of change software engineering;legacy system;modeling;model driven architecture;systeme information;oriente aspect;programming languages;modeling tool;generic programming;arquitectura basada modelo;sistema informacion	The escalating complexity of software and system models is making it difficult to rapidly explore the effects of a design decision. Automating such exploration with model transformation and aspect-oriented techniques can improve both productivity and model quality. The combination of model transformation and aspect weaving provides a powerful technology for rapidly transforming legacy systems from the high-level properties that models describe. Further, by applying aspect-oriented techniques and program transformation, small changes at the modeling level can trigger very large transformations at the source code level. Thus, model engineers can explore alternative configurations using an aspect weaver targeted for modeling tools and then use the models to generate program transformation rules for adapting legacy source code on a wide scale.	aspect weaver;aspect-oriented programming;aspect-oriented software development;high- and low-level;legacy system;model transformation;model-driven engineering;program transformation	Jeffrey G. Gray;Yuehua Lin;Jing Zhang	2006	Computer	10.1109/MC.2006.45	simulation;systems modeling;computer science;software engineering;change management;programming language	SE	-52.85583238446628	29.19879635330955	61923
992cec1881a992b77d314c9cc0a1e8c770c59a5f	reverse engineering of complex legacy telecommunication systems: problem domain, concepts, solutions, and tool support			problem domain;reverse engineering	André Marburger	2005				SE	-50.939119081792846	27.424788234600932	61983
3ac3893aefc2f5430354c2da2fe4b833bbe84722	research on workflow modeling based on coloured petri net	petri net;workflow;workflow modeling	Petri as an effective tool for modelling and analyzing processes, which is widely used in the field of workflow management. This paper introduces the correlation theory of the high-level Petri net with colour extension and brings forward a workflow modeling method based on coloured Petri net. With the thought, a workflow model of training institution management is made at last.	coloured petri net;high- and low-level	Liang Zhang;Jiayi Yao;Yingrui Zhang	2011			computer science;data mining;coloured petri net;workflow	EDA	-49.8245823787567	25.706983470821186	62297
99f7b357f20749a608a2332f1fa71e0d49284747	optimizing component-based embedded software	economical constraint;optimising compilers;code generation component based embedded software development framework embedded system development abstraction level physical constraint economical constraint memory usage energy consumption size constraint software optimization technique reusability approach flexibility oriented property software architecture use cases;software optimization technique;size constraint;random access memory;constraint optimization;application software;optimization technique;component;component based development;separation of concern;code generation;use cases;object oriented programming;data mining;runtime;software engineering;embedded system;optimization component software engineering embedded systems;computer applications;systems analysis embedded systems object oriented programming optimising compilers software architecture software reusability;embedded systems;software architecture;servers;systems analysis;energy consumption;component based embedded software development framework;levels of abstraction;software reusability;environmental economics;abstraction level;embedded system development;flexibility oriented property;optimization;time to market;functional requirement;physical constraint;use case;context;reusability approach;power generation economics;embedded computing;memory usage;embedded software;embedded software embedded system time to market runtime constraint optimization computer applications embedded computing application software power generation economics environmental economics	As functionalities required by embedded systems increase, higher levels of abstraction become necessary to fulfill development exigencies. At the same time, traditional physical and economical constraints such as size, memory usage and energy consumption subsist, making embedded systems development even more complex as it must face two contradictory requirements. In this paper, we expose how a component-based development framework is able to support these two conflicting demands. We follow a component-based approach to benefit from reusability and separation of concerns at design-time, producing flexible systems. We propose a set of flexibility-oriented properties allowing architects to generate, for a same architecture, a set of systems with different flexibility capabilities; these optimization techniques allow developers to pay for flexibility only where it is actually desired. Experiments conducted on several use-cases confirm the effectiveness of our approach.	component-based software engineering;embedded software;embedded system;experiment;mathematical optimization;optimizing compiler;principle of abstraction;requirement;separation of concerns;software development process	Olivier Lobry;Juan F. Navas;Jean-Philippe Babau	2009	2009 33rd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2009.181	use case;constrained optimization;real-time computing;computer science;systems engineering;operating system;software engineering;programming language;computer engineering	Embedded	-52.60558232479778	30.621833762534006	62337
47cb350ba8de99e3319eddcc9a62219b7c171bfb	patterns for heterogeneous tbox mappings to bridge different modelling decisions		Correspondence patterns have been proposed as templates of commonly used alignments between heterogeneous elements in ontologies, although design tools are currently not equipped with handling these definition alignments nor pattern alignments. We aim to address this by, first, formalising the notion of design pattern; secondly, defining typical modelling choice patterns and their alignments; and finally, proposing algorithms for integrating automatic pattern detection into existing ontology design tools. This gave rise to six formalised pattern alignments and two efficient local search and pattern matching algorithms to propose possible pattern alignments to the modeller.	algorithm;code refactoring;local search (optimization);modeller;ontology (information science);pattern matching;pattern recognition;software design pattern;tbox;test-driven development	Pablo R. Fillottrani;C. Maria Keet	2017		10.1007/978-3-319-58068-5_23	modeller;data mining;machine learning;ontology (information science);local search (optimization);pattern matching;computer science;pattern detection;artificial intelligence;design pattern	AI	-50.53780502185207	22.384708178698105	62383
3afc4cd120d7d4a3ef3d6a14c1e9b934a1769e27	pfast: an eclipse-based integrated tool workbench for facilities design	software tool;plugin architecture;integration;lessons learned;eclipse;rich client platform;tool integration;production flow analysis;facility design;interdisciplinary engineering;flow analysis	In this paper, we examine PFAST, an Eclipse-based integrated tool workbench targeted at rapidly integrating software tools for planning and optimizing manufacturing facilities. We describe the integrated-tool architecture, built on top of the Eclipse Rich Client Platform, which alleviates many of the problems faced by an earlier version of the system. We also describe our experiences in analyzing the requirements of the disparate tools that compose the system, the problems we faced in implementing the system, and the lessons learned. This paper highlights the successful introduction of Eclipse-based tool integration into the manufacturing facilities planning domain.	eclipse;requirement;rich client platform;workbench	Thomas Mampilly;Rajiv Ramnath;Shahrukh A. Irani	2005		10.1145/1117696.1117713	petroleum engineering;eclipse;simulation;computer science;systems engineering;engineering;data-flow analysis;database;programming language	Robotics	-50.52169053838767	24.783687820690098	62528
b20365298865b5e08790e60313251710e5151cdf	extensible graphical editors for palladio		Palladio is an approach to design and performance prediction of software architectures. An important part of the Palladio’s tooling—the Palladio Bench— are its graphical GMF-based editors. In contrast to rudimentary tree-based editors, they enable a more intuitive creation of models even for less experienced developers. However, the maintenance of the GMFbased editors has become cumbersome because the requirement arose to support an increasing amount of new language features. In this paper, we present the new generation of graphical editors for Palladio, which are based on the Sirius editor framework. Further, we present a concept of how to develop external extensions to the graphical language, which can be plugged into the new editors without the need to intrusively modify them.	business process;capability maturity model;computer graphics;extensibility;graphical modeling framework;graphical user interface;performance prediction;sirius;software architecture;software propagation;tree (data structure);usability;visual programming language	Misha Strittmatter;Michael Junker;Kiana Rostami;Sebastian Lehrig;Amine Kechaou;Bo Liu;Robert Heinrich	2016	Softwaretechnik-Trends		computer science;software engineering;extensibility	HCI	-48.681939134599816	25.367435377500126	62535
f515d6b071896d32d182ba64d7e63286bc3ab314	business processes contextualisation via context analysis	context awareness;context aware;context analysis;business process model;correctness of business process models;business process contextualisation;business process;business process modelling	Context-awareness has emerged as a new perspective for business process modelling. Even though some works have stud ied it, many challenges have not been addressed yet. There is a clear need for approaches that (i) facilitate the identification of the context proper ti s that influence a business process and (ii) provide guidance for correct model ling of contextualised business processes. This paper addresses this need by defining an approach for business process contextualisation via context anal ysis, a technique that supports reasoning about context and discovery of i ts relevant properties. The approach facilitates adequate specification of cont ext variants and of business process execution for them. As a result, we obtain business processes that fit their context and are correct.	business process;comstock–needham system;context awareness;ext js javascript framework;process modeling	Jose Luis de la Vara;Raian Ali;Fabiano Dalpiaz;Juan Sánchez;Paolo Giorgini	2010		10.1007/978-3-642-16373-9_37	business analysis;business transformation;context analysis;business domain;business requirements;knowledge management;artifact-centric business process model;business process management;business case;process modeling;management science;business process model and notation;process management;business process;process mining;business process discovery;management;business rule;new business development;business process modeling;business activity monitoring;business architecture	SE	-56.70976899043012	19.82486429107696	62634
523899d8e2c666f61ff0a822f5a8cd3c1fabb9f8	qvtr2: a rational and performance-aware extension to the relations language	rational information;alternatives selection process;performance engineering technique;performance-aware extension;relations language;different solution;qvtr2 prototype engine;mde process;qvt-relations rational;model transformations glue;design rationale;development process different solution	Model transformations glue together models in an MDE process and represent the rationale behind it. It is however likely that in a design/development process different solutions (or alternatives) for the same problem are available. When alternatives are encountered, engineers need to make a choice by relying on past experience and on quality metrics. Several languages exist to specify transformations, but all of them bury deep inside source code rational information about performance and alternatives, and none of them is capable of providing feedback to select between the different solutions. In this paper we present QVT-Relations Rational (QVTR), an extension to the Relations language to help engineers in keeping information about the design rationale in declarative transformations, and to guide them in the alternatives selection process by using performance engineering techniques to evaluate candidate solutions. We demonstrate the effectiveness of our approach by using our QVTR prototype engine on a modified version of the common UML-to-RDBMS example transformation, and by guiding the engineer in the selection of the most reasonable and performing solution.	design rationale;feedback;global optimization;model-driven engineering;performance engineering;prototype;qvt;relational database management system;run time (program lifecycle phase);unified modeling language	Mauro Luigi Drago;Carlo Ghezzi;Raffaela Mirandola	2010		10.1007/978-3-642-21210-9_31	computer science;systems engineering;engineering;software engineering;management;algorithm	PL	-54.19363327099313	30.147085279970344	62714
35fcc8d99b8f8f68c5f78bb3c99ca11522adc2e7	toward conceptual representation of patterns	software;frequency modulation;software engineering object oriented methods problem solving;conceptual model;abstraction;software engineering;software engineering patterns software development design process abstraction conceptual model;software system development conceptual representation problem solving model driven development software engineering object oriented design ground fabric;games;software development;unified modeling language;pattern recognition;fabrics;design;patterns;process;unified modeling language frequency modulation games software pattern recognition object oriented modeling fabrics;object oriented modeling	Patterns present broad solutions rather than specific results for problem solving. Such generality is required in the complex world of software development, where the notion of model-driven development is integrated with that of patterns to provide a method of communicating shared experience and knowledge. In software engineering, the introduction of patterns was driven by recognition of the need for a higher level of abstraction in object-oriented design. Nevertheless, the concept of pattern is very broad, and almost anything can potentially be a pattern. According to some researchers, the search for a clear and complete definition of a pattern may very well be an elusive endeavor. The present paper proposes a conceptual representation that aims at capturing real-world structures and processes while serving as a ground fabric for analysis and discovery of recurrent constructs such as patterns. The representation is based essentially on the notion of flow, guaranteeing continuity of visualized descriptions given in typical narratives at the origin of requirements specification in any software system development. Through examples, it is shown that approaching the notion of pattern from this direction is viable.	fm broadcasting;model-driven architecture;model-driven engineering;problem solving;requirement;scott continuity;software development;software engineering;software requirements specification;software system;unified modeling language	Sabah S. Al-Fedaghi;Mohamad Almutairy	2015	2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2015.7176247	frequency modulation;unified modeling language;games;design;software design pattern;architectural pattern;computer science;artificial intelligence;conceptual model;theoretical computer science;software development;software analysis pattern;software engineering;machine learning;database;abstraction;programming language;structural pattern;algorithm;process	SE	-53.41356236846721	24.366478473695647	62724
68226dcdbdbaf95bd5db1156b0139fbbddc6baf9	reducing complexity of large epcs	080600 information systems	Abstract: Business processes are an important instrument for understanding and improving how companies provide goods and services to customers. Therefore, many companies have documented their business processes well, often in the Event-driven Process Chains (EPC). Unfortunately, in many cases the resulting EPCs are rather complex, so that the overall process logic is hidden in low level process details. This paper proposes abstraction mechanisms for process models that aim to reduce their complexity, while keeping the overall process structure. We assume that functions are marked with efforts and splits are marked with probabilities. This information is used to separate important process parts from less important ones. Real world process models are used to validate the approach.	abstraction layer;business process;elementary;electronic product code;event-driven process chain;process modeling;prototype	Artem Polyvyanyy;Sergey Smirnov;Mathias Weske	2008			systems engineering;engineering;operations management;data mining;business process discovery	AI	-54.936615749498806	18.893902245538527	62826
85851ed0d2bd1e54d375408d74d7b9cdf75ed5f4	the three-layer architectural pattern applied to plug-in-based architectures: the eclipse case	architectural knowledge;software architecture;plug in based development;three layer architectural pattern;eclipse;article	The process of designing a software architecture using different kinds of components is often challenging. Different designs support some quality attributes whilst damaging others, therefore trade-off analysis is needed to make informed decisions. Moreover, analysis made in theory need to be complemented with observations in practice, especially when using a particular set of technologies to implement the system. In this paper we present a particular instance of this problem. We study how the Three-Layer architectural pattern may be developed using plug-ins. We compare two extreme alternatives according to several representative scenarios and their impact in some quality attributes. Then, we apply this theoretical knowledge to a case study, the implementation of a plug-in-based tool for managing architectural knowledge using Eclipse. We report some unexpected difficulties found that forced us to adapt the theoretical solution into an operative architecture. Copyright c © 2010 John Wiley & Sons, Ltd.	.net framework;architectural pattern;data transfer object;domain model;eclipse;interoperability;john d. wiley;knowledge base;knowledge management;list of system quality attributes;microsoft windows;multitier architecture;plug-in (computing);point of view (computer hardware company);software architecture;software design pattern;software developer;usability;while	David Ameller;Oriol Collell;Xavier Franch	2013	Softw., Pract. Exper.	10.1002/spe.2142	eclipse;software architecture;real-time computing;simulation;architectural geometry;architectural pattern;computer science;systems engineering;engineering;operating system	SE	-59.33255855317285	20.572753504329754	62980
614aa2ba25bb37741b7b116298448dd7b3317340	a multi-core architectural pattern selection method for the transition from single-core to multi-core architecture	multicore processing multicore architectural pattern selection method single core architecture architectural decision supporter ads domain applications contextual knowledge individual architectural pattern technical knowledge;software maintenance multiprocessing systems software architecture;concurrent computing software decoding educational institutions hardware multicore processing	Along with rapid advancements of convergent devices, increased software complexity paired with contrastingly shortened software product lifecycle have introduced new challenges from which the need to transform legacy single-core based systems to multi-core systems have emerged. Unfortunately, existing software development processes are late in providing adequate support for multi-core parallelization, failing to keep up with the speed of advancements in multi-core based hardware systems. To address this gap, in our previous work we have proposed a software development process to support the transition of an existing single-core based software to a multi-core equivalent. We have also introduced a tool, the Architectural Decision Supporter (ADS), to assist in the selection of appropriate multi-core architectural patterns and in the search for proper construction components. In this paper, we introduce a selection method for choosing the most desirable candidate among various multi-core architectural patterns implemented using ADS. The proposed method provides the means to combine the contextual knowledge of domain applications and the technical knowledge of individual architectural pattern for multi-core processing.	architectural decision;architectural pattern;concurrency (computer science);concurrency pattern;failure;functional requirement;h.264/mpeg-4 avc;intel core (microarchitecture);multi-core processor;multiprocessing;numerical analysis;parallel computing;programming complexity;selection (genetic algorithm);single-core;smart device;software development process;software quality;systems architecture;video decoder	Soojin Park;Young B. Park	2014	2014 International Conference on IT Convergence and Security (ICITCS)	10.1109/ICITCS.2014.7021712	multilayered architecture;software architecture;computer architecture;real-time computing;architectural pattern;computer science;systems engineering;presentation–abstraction–control	SE	-56.45211281248554	27.022005891901774	62994
05189cb09415de7566dbafbbfbfb3a2194e566d7	an user-driven slight ontology framework based on meta-ontology for change management	corporate modelling;change management;ontologies electronic government web services semantic web software development management engineering management environmental economics software engineering metamodeling technology management;slight ontology framework;ontologies artificial intelligence;business process model;general solution;human factors;metamodeling theory;management of change;user driven slight ontology framework;e government services;metamodeling theory user driven slight ontology framework metaontology change management e government services slight ontology framework business process modeling theory;metaontology;ontologies artificial intelligence corporate modelling government data processing human factors management of change;system management;government data processing;meta model;business process modeling theory	With the rapid development of e-government services, change management has become a main focus. Today, the most system management tasks are still performed manually. This can be easier error-made, high time-consuming and more human-needed. So we present a slight ontology framework (SOF) to solve it. It combines itself with business process modeling theory to make the process part of SOF and introduces the meta-modeling theory to analysis of the features of changes based on ontologies used to describe services for semi-automatic change management. Although we use e-government domain as the example, the approach is a general solution in other domains.	business process;change management (engineering);e-government;metamodeling;ontology (information science);process modeling;semiconductor industry;systems management	Lina Fang;Shengqun Tang;Yan Yang;Ruliang Xiao;Xinguo Deng;Youwei Xu	2007	21st International Conference on Advanced Information Networking and Applications Workshops (AINAW'07)	10.1109/AINAW.2007.93	metamodeling;systems management;computer science;knowledge management;change management;data mining;database;business process modeling	Robotics	-55.32636238859211	18.998784178396807	63004
627b673e67586d16c392b0fa4a7147f6643dee1d	evolving task oriented systems	bottom up methods;bottom up;graphical interface;top down;evolutionary design;design methods;development tool;prototyping;design method;task analysis;user involvement;graphical interfaces;new products	This paper describes an approach to developing systems which can be summarised as ‘analyse top-down, design middle-out, and build bottom-up’. A case study is described in which this approach is used to develop a system to support staff who select new products for a major UK company. The novelty of the approach lies in its use of task analysis to define an appropriate domain for the system and then the use of a working prototype to grow a system from the bottom up. The project involved using simple development tools which allowed the users to start getting business benefit from the system right from the start. Their use could therefore develop as the system evolved.	programming tool;prototype;task analysis;top-down and bottom-up design	Paul Seaton;Tom Stewart	1992		10.1145/142750.142900	simulation;design methods;human–computer interaction;computer science;operating system;top-down and bottom-up design;world wide web	Robotics	-49.69263646257727	22.367432110237417	63123
9d53e9ae9abc1dd8ee147607e6eb0ee3998309b3	agents for case-based software reuse	program understanding;java programming;cooperative agents;intelligent agent;object oriented software development;software reuse;program development	The effective reuse of previously engineered components has become a core activity in any object-oriented software development project. The task is, however, often problematic when it comes to actual retrieval and understanding of the class library in, e.g., Java. Newcomers, especially, in a software company or novices in Java programming will need time to obtain a good overview of available components. This article explores the use of intelligent agents in a case-based tool for software reuse. By introducing agent support to the retrieval mechanism of the tool we show how retrieval efficiency may be improved. The cooperating agents assist the user in retrieval of code for potential reuse in an automated way and in the background. This makes it possible for the developer to concentrate fully on her task. The tool aids in program understanding and adaptation. Thus, it allows an exploratory approach to program development and increases reuse efficiency.	code reuse	Stein Inge Morisbak;Bjørnar Tessem	2001	Applied Artificial Intelligence	10.1080/08839510151063271	real-time computing;computer science;artificial intelligence;package development process;software framework;software development;software construction;intelligent agent	AI	-55.44336039077743	30.939963594402982	63194
0fe7941e6f2bf022e0d7d61f971666ef32405946	software engineering for ensembles	software engineering;single machine;software development;weed control	Software development is difficult, even if we control most of the operational parameters and if the software is designed to run on a single machine. But in the future we will face an even more challenging task: engineering ensembles consisting of thousands, or even millions, of nodes, all operating in parallel, with open boundaries, possibly unreliable components and network links, and governed by multiple entities. To develop reliable and trustworthy software for these kinds of systems we need to go far beyond the current state of the art and address fundamental problems in software development. We present some challenges and promising avenues for research about software-engineering for ensembles.	entity;software development;software engineering;trustworthy computing	Matthias M. Hölzl;Axel Rauschmayer;Martin Wirsing	2008		10.1007/978-3-540-89437-7_2	simulation;software engineering process group;software sizing;engineering;package development process;software framework;component-based software engineering;software development;software design description;software construction;data mining;resource-oriented architecture;software deployment;software development process;software metric;software system;computer engineering;avionics software	SE	-61.7042890628768	24.24532356244276	63405
33393c10bcfc327acfba8f98ac88fd46e1270e45	map-driven modular method re-engineering: improving the rescue requirements process.		Configuring and applying complex requirements processes in organisations remains a challenging problem. This paper reports the application of the Map-driven Modular Method Re-engineering approach (MMMR) to a research-based requirements process called RESCUE in order to identify omissions and weaknesses, and to reason about improvements to RESCUE that are currently being implemented. Results have implications for both the scalability and effectiveness of the MMMR approach and for innovative requirements processes such as RESCUE.	cobham's thesis;requirement;scalability;while	Jolita Ralyté;Neil A. M. Maiden;Colette Rolland;Rébecca Deneckère	2005			reliability engineering;systems engineering;engineering	SE	-57.78126439963684	23.549888982131748	63619
dc40a2b330f9d1a19a7765327a9b47c0cfe36bec	automatic business process model assembly on the basis of subject-oriented semantic process mark-up		Business processes of large companies often lack the flexibility of their smaller competitors. This fact results in slower reaction to the changes in business environment which usually require to launch complicated IT projects. Nevertheless many tasks faced in these situations by IT departments have standard solutions which could be expressed in form of semi-formalized best practices and recommendations. Authors propose a business process model enriched by the semantic mark-up that enables to represent these recommendations in form of fully formalized high-level process descriptions. Using the proposed technical approaches concrete business process models can be generated from these descriptions. Authors discuss formal methods of searching the relevant high-level descriptions as well as rating and evaluation of the generated concrete models based on different criteria.	best practice;business architecture;business process;formal methods;high- and low-level;postcondition;process modeling;process specification;real-time clock;semantic web;semiconductor industry	Alexander Gromoff;Nikolay Kazantsev;Pavel Shapkin;Leonid Shumsky	2014	2014 11th International Conference on e-Business (ICE-B)		concrete;business domain;computer science;knowledge management;artifact-centric business process model;business process management;ontology;marketing;process modeling;data mining;database;semantics;management science;business process model and notation;process management;business process;business process discovery;management;business rule;world wide web;business process modeling;business activity monitoring;business architecture	SE	-55.21485119879147	19.412040930002476	63823
abdc56f3ae0021eead8584ff07aec9b0834680c3	on designing intelligent hypertext systems for information management in software engineering	software engineering tools;software engineering;large scale;information management;software process	Information management in large scale software engineering is a challenging problem. Hypertext systems are best suited for this purpose because of the diversity in information types that is permitted in the nodes of a hypertext. The integration of a hypertext system with software engineering tools results in a software hypertext system. We describe the design of such a system called DIF. Based on our experiences in using DIF, we recognized the need and the potential for developing a hypertext system that could utilize knowledge about its users and their software tasks and products. Such a system might then be able to act as an active participant in the software process, rather than being just a passive, albeit useful storage facility. As such, we define an Intelligent Software Hypertext System (I-SHYS1) as a software hypertext system which is knowledgeable about its environment and can use such knowledge to assist in the software process. This knowledge is partly embedded in the design of an I-SHYS (in terms of the 'agents' that I-SHYS supports) and partly defined during the use of I-SHYS (in terms of tasks that agents perform). We present a framework GOT defining and organizing this knowledge, describe potential uses of such knowledge, identify limits of our approach, and suggest methods for circumventing them.	data integrity field;embedded system;hypertext;information management;organizing (structure);software development process;software engineering	Pankaj Kumar Garg;Walt Scacchi	1987		10.1145/317426.317455	personal software process;medical software;verification and validation;computing;software engineering process group;software sizing;computer science;knowledge management;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software construction;information management;software walkthrough;software analytics;resource-oriented architecture;software deployment;world wide web;software development process;software requirements;software system	SE	-58.74239696718108	22.9778247498766	63850
9b79bba9d5595c693ac7de0fcbadbe42241ced89	computing event dependencies in system designs and programs	system design	This paper presents a method to compute metrics that predict maintainability of a system with respect to its event processing. The metrics reflect the complexity of event dependencies in an object-oriented system. They can be computed from a UML design or from a program code. The maintainability factor is obtained by comparing the calculated metrics with the metrics for a design conforming to a predefined architectural framework. The framework is claimed to minimize event dependencies.	complex event processing;enterprise architecture framework;unified modeling language	Bruc Lee Liong;Leszek A. Maciaszek	2003			software engineering;maintainability;systems engineering;computer science;systems design;unified modeling language;architecture framework;complex event processing	EDA	-53.80607831750022	26.306794842130518	63981
8aa7fb968ae9f2b2e1a3e6f8a59b31d4dfd0b44a	engineering processes - on an approach to realize a dynamic process control	heterogeneous software system;different specialized software system;process-centered engineering environment;necessary aspect;dynamic process control;design process;specific development environment;last part;engineering processes;central component;product development process;design document	The application of modern concepts and methods from information technology gains impor-tance for the execution of product development processes. Presently, the execution of such processes is supported by different specialized software systems. A flexible company-wide use of such tools is achieved by their provision within specific development environments. A result is the demand for an integration concept for heterogeneous software systems which also considers design documents and especially design processes. In the first part of this arti-cle we will present our approach for a Process-Centered Engineering Environment. A central component within the environment is responsible for the management of the design processes, i.e. modeling, enactment, etc. One necessary aspect that has to be realized by this component is the tracing of process states. Statecharts provide a suitable basis for the specification of these states even for complex processes. The second part of the article describes an adopted version of statecharts focusing on processes. Design processes are characterized by a certain unpredictability. Therefore, the environment has to provide means for changing processes at runtime. The last part of the article discusses this aspect based on an INSERT-operation.		Martin Endig;Dirk Jesko	2001	Transactions of the SDPS		simulation;computer science;systems engineering;operations management	SE	-56.12653739837773	21.768475359937828	64087
974b19ef6792f5f2f01c851cdd29042741c24f45	location-based software modeling and analysis: tropos-based approach	design and development;software systems;conceptual framework;software requirements;mobile application;modeling and analysis	The continuous growth of interest in mobile applications makes the concept of location essential to design and develop software systems. Location-based software is supposed to be able to monitor the surrounding location and choose accordingly the most appropriate behavior. In this paper, we propose a novel conceptual framework to model and analyze location-based software. We mainly focus on the social facets of locations adopting concepts such as actor, resource, and location-based behavior. Our approach is based on Tropos methodology and allows the analyst to elicit and model software requirements according to the different locations where the software will operate. We propose an extension of Tropos modeling and adapt its process to suit well with the development of location-based software. The proposed framework also includes automated analysis techniques to reason about the relation between location and location-based software.	conceptualization (information science);formal language;heart rate variability;location-based service;mobile app;requirement;software development;software requirements;software system	Raian Ali;Fabiano Dalpiaz;Paolo Giorgini	2008		10.1007/978-3-540-87877-3_14	software requirements specification;verification and validation;software sizing;computer science;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;data mining;conceptual framework;software walkthrough;software analytics;software deployment;goal-driven software development process;software requirements;software system	SE	-59.75836114213522	23.30241229924057	64120
77bbaa9551e565f804367aa08c706804d9689da0	towards the integration of formal specification in the áncora methodology		There are some non-formal methodologies such as RUP, OpenUP, agile methodologies such as SCRUP, XP and techniques like those proposed by UML, which allow the development of software. The software industry has struggled to generate quality software, as importance has not been given to the engineering requirements, resulting in a poor specification of requirements and software of poor quality. In order to generate a contribution to the specification of requirements, this article describes a methodological proposal, implementing formal methods to the results of the process of requirements analysis of the methodology Áncora.	agile software development;formal methods;formal specification;openup;requirement;requirements analysis;software industry;unified modeling language	Carlos Alberto Fernández y Fernández;Martín José José	2011	CoRR		systems engineering;functional specification;computer science;package development process;software requirements specification;software requirements;requirement;social software engineering;requirements analysis;system requirements specification	SE	-58.92028512902862	25.756743396178678	64138
160ac0a13934524264810c3aa058a07a07fce100	ai-based classification and retrieval of reusable software components	classification;information retrieval;knowledge based systems;software reusability;a* algorithm;ai-based classification;artificial intelligence based classification;classification-based reuse;closeness;domain analysis;knowledge based systems;programmers;reusable software components;reusable software retrieval;searching;shortest path algorithm;software packages;subsumption	The concept of software reusability is examined from the perspective of classifying and accessing reusable software. To improve the practicality of software reuse, one has to have a knowledge of its location, an understanding of the reusable components, and its adaptability to a particular need. The current state-of-the-art methods are assessed, and a new system for performing classification-based reuse is proposed. The concepts of subsumption and closeness introduced previously (R. Prieto-Diaz and P. Freeman, 1987) are used by the proposed reuse system to facilitate searching for reusable components and to provide capabilities for helping programmers to assess the worth of reusing particular packages. A description of the major algorithms required to compute these metrics is given. Also, domain analysis which helps in deciding whether a particular application is oriented towards software reuse is given	component-based software engineering	Aarthi Prasad;E. K. Park	1993			domain analysis;computer science;theoretical computer science;software framework;feature-oriented domain analysis;domain engineering;software construction;data mining;database	SE	-56.11892790141445	30.650218774801704	64152
d01bffd794a1feaf1d6f114a03967c53e7c8fb4f	systematic software product line test case derivation for test data reuse	software;systematics;test case derivation;semantics;testing;domain test engineering systematic software product line test case derivation test data reuse test data determination;software product lines program testing;variability software product line software product line testing test case derivation;software product line testing;testing software product lines systematics semantics data models software java;variability;software product line;software product lines;data models;java	This paper proposes a systematic software product line test case derivation method that reuses test data. With the method, significant test cases reduction can be achieved over the conventional software product line testing. The key to achieving reuse lies in performing test data determination during domain test engineering so that application test engineers share test data rather than creating different test data for different products. A case study shows the effect of significantly reducing the number of derived test cases without sacrificing error detection capability.	error detection and correction;software product line;test case;test data;test engineer	Sungwon Kang;Haeun Baek;Jungmin Kim;Jihyun Lee	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.174	reliability engineering;data modeling;verification and validation;regression testing;system integration testing;classification tree method;software verification;computer science;systems engineering;software reliability testing;software engineering;build verification test;software construction;test suite;semantics;systematics;software testing;test method;programming language;test script;java;software measurement;test case;test management approach;test harness	SE	-57.41764458514067	30.842759544916092	64214
d4deace2448788ddc1f21398281283f8dc56ed06	design of knowledge-based integrated software process improvement tools	quest a;software process generation;knowledge based software process model;quest r;software process improvement;design engineering;software libraries;application software;software process assessment;frame based representation software process improvement software quality software tools project support environments computer aided software engineering inference mechanisms knowledge based systems software reusability software libraries integrated software;knowledge management;frames;inference mechanisms;software engineering;systems engineering and theory;meta process support tool;computer architecture;environmental changes;computer aided software engineering;software quality evaluation system;software process model;control knowledge rules;process asset library;software process object reuse;knowledge inference;meta process object relationships;process support;automatic generation control;software reusability;integrated software;project support environments;project process model customization;software process metrics;quest tools design;meta process knowledge accumulation;dependence structure;software tools;frame based representation;process model;process improvement;quest i;improvement item interdependence;automatic knowledge updating mechanism;environmental change;automatic knowledge updating mechanism knowledge based integrated software process improvement tools quest tools design software quality evaluation system quest r software process assessment quest a quest i software process information repository process asset library meta process support tool meta process knowledge accumulation software process metrics knowledge inference knowledge based software process model meta process object relationships environmental changes frames project process model customization software process object reuse control knowledge rules software process generation dependency structure improvement item interdependence;dependency structure;software process information repository	The design of QUEST (software QUality Evaluation System and Technology) tools, and especially of its repository, is discussed. QUEST tools are composed of a software process assessment tool (QUEST-A), a software process improvement tool (QUEST-I) and a repository for software process information (QUEST-R). We place the emphasis of this paper on the design of QUEST-R, which acts as a process asset library (PAL) and a meta-process support tool. The meta-process knowledge can be accumulated from several cases of process improvement, which can be initiated by software process assessment and process metrics. The results or outputs of QUEST-A, QUEST-I or the other tools act as a driver of knowledge inference. To build QUEST-R, a knowledge-based software process model (KB-SPM), which incorporates meta-process objects and their relationships, is proposed. Several factors, including environmental changes and various process improvement strategies, are explicitly modeled as frames. QUEST-R (1) makes it possible to generate and customize project process models in various application domains; (2) makes it possible to reuse the software process objects; and (3) makes it easy to accumulate and enhance meta-process knowledge. Besides supporting the meta-process phase, to increase the effectiveness of the meta-process, the following facilities are proposed: (1) rules for control knowledge; (2) more affecting factors for the generation of software processes; (3) a dependency structure, for describing improvement items and their interdependence; and (4) a mechanism to automatically update the knowledge.	integrated software;software development process	Yu-Whoan Ahn;Gil-Jo Kim;Ja-Kyong Koo;Hyun-Min Park;In-Geol Chun	1998		10.1109/ICSMC.1998.724969	knowledge base;personal software process;verification and validation;team software process;design process;software engineering process group;software sizing;environmental change;software mining;computer science;knowledge management;artificial intelligence;package development process;backporting;software design;software framework;software development;software design description;software construction;software walkthrough;empirical process;computer-aided software engineering;goal-driven software development process;software development process;software metric	HPC	-52.4099024234226	21.77497950063043	64271
391fea3c937c3f45d4d237e8d2dd72fa6cdca798	multimedia conferencing systems as building blocks for complex cooperative applications	databases;groupware;teleconferencing;collaborative work;videoconference;application software;building block;work scenario graphs;data flow graphs;business communication;multimedia systems;scenario flows;conference setup;highly coordinated workflow;multimedia computing;multimedia systems application software power system modeling databases collaborative work usability videoconference cooperative systems embedded software user interfaces;cooperative systems;video conferencing systems;video conferencing;conference cooperation multimedia conferencing systems complex cooperative applications cooperative systems user centred tools software design work scenario graphs scenario flows modelling coordination policies cscw highly coordinated workflow video conferencing systems conference setup conference coordination;levels of abstraction;business data processing;coordination policies;complex cooperative applications;multimedia communication;cscw;multimedia conferencing systems;conference cooperation;power system modeling;software design;usability;user interfaces;user centred tools;embedded software;cooperative work;conference coordination	Cooperative and multimedia systems together give way for powerful user-centred tools. Current software design approaches do not reflect the complexity of such applications, a new level of abstraction is required. We present Work Scenario Graphs (WSG) and Scenario Flows (SCF) for the modelling of cooperative applications. Both modelling elements cope with different types of cooperative work and can, by combining them, express a wide variety of coordination policies-ranging from implicitly coordinated CSCW style cooperation to highly coordinated workflow style. We demonstrate the usability of WSG and SCF by modelling selected multimedia conferencing systems in an abstract, easy reusable way. We therefore introduce an abstraction for video conferencing systems based on the three basic aspects: conference setup, coordination and cooperation.		Oliver Frick	1996		10.1109/MMSD.1996.557746	simulation;human–computer interaction;computer science;multimedia	HPC	-49.9182851105242	20.472265454975343	64308
07757be8ea3d0370ed0f8fba3f43c976ec1b144a	hilpr: pretty pictures for pretty complicated (parallel) patterns	visual representations;parallel design patterns;design patterns	Users of parallel patterns need to carefully consider many subtle aspects of software design. In particular, implicit relationships with hardware realities coupled with aggressive strategies for optimization are daunting in this domain. This paper proposes a new way to leverage visual cues in HiLPR, a proposed uniform representation for parallel patterns. We show the application of this approach to three design patterns: Sparse Linear Algebra, Pipeline, and Shared Queue. An evaluation of the combination of a pattern's Forces with its Solution within this representation indicates that this approach holds promise in terms of assisting developers in making better-informed decisions about pattern implementation.	design pattern;linear algebra;mathematical optimization;software design;sparse	Donna Kaminskyj Long;Celina Berg;R. Nigel Horspool;Yvonne Coady	2011		10.1145/2578903.2579142	software design pattern;behavioral pattern;computer science;theoretical computer science;pattern language;structural pattern;engineering drawing	HCI	-51.42812338543775	31.855411939320362	64393
b26f9bda7e6ef0db255e00d246be4e08343e3c0d	towards mutation analysis for use cases	mutation analysis;requirements inspection;restricted use case modeling rucm	Requirements inspection is a well-known method for detecting defects. Various defect detection techniques for requirements inspection have been widely applied in practice such as checklist and defect-based techniques. Use case modelling is a widely accepted requirements specification method in practice; therefore, inspecting defects in use case models in a cost-effective manner is an important challenge. However, it does not exist a systematic mutation analysis approach for evaluating inspection techniques for use case models. In this paper we present the methodology we followed to systematically derive mutation operators for use case models. More specifically, we first proposed a defect taxonomy defining 94 defect types, based on the IEEE Std. 830-1998 standard. Second, we systematically applied the basic guide words of the standardized Hazard and Operability Study (HAZOP) methodology to define 191 mutation operators. Last, we defined a set of guidelines for devising defect seeding strategies. The proposed methodology was evaluated by a real world case study and six case studies from the literature. Results show that all the derived mutation operators for Restricted Use Case Modelling (RUCM) models are feasible to apply and the defect taxonomy is the most comprehensive one to compare with the literature.	mutation testing;operability;requirement;sensor;software bug;software requirements specification	Huihui Zhang;Tao Yue;Shaukat Ali;Chao Liu	2016		10.1145/2976767.2976784	use-case analysis;reliability engineering;computer science;systems engineering;engineering;mutation testing;algorithm	SE	-60.37817109178099	26.031922857750637	64611
43c8da8ace9f725fa1ef8ce38431771c995ff9b0	experiences with see architectural support for the automation	life cycle;software prototyping;prototypes;software engineering;automation object oriented modeling prototypes software prototyping user interfaces software engineering buildings navigation database systems environmental management;navigation;database systems;environmental management;user interfaces;object oriented modeling;buildings;automation	A large part of our current environment work at TRW focuses on process models in support of the full life-cycle, and Software Engineering Environment (SEE) architectural support for the implementation of such models. The process modeling aspects have centered around the definition of the PMDB+ model [l, 2,3] , and the implementation and architectural support aspects have been investigated in conjunction with the building of various prototypes, including the PMDB Viewer and the Entity-Relationship editor. This paper briefly describes the prototypes, ithe areas under investigation and some of the results. More details on the lessons learned can be presented at the workshop.	entity–relationship model;process modeling;software engineering	Manuel H. Penedo	1990		10.1109/ISPW.1990.659597	verification and validation;systems engineering;engineering;process automation system;social software engineering;component-based software engineering;software development;software engineering;software construction;systems development life cycle;software development process;software system;computer engineering	SE	-50.72560470620857	27.413145907898404	64705
b433af8898877b70d86d25f03b92268c153b91bf	modelling cad models: method for the model driven design of cad models for deep drawing tools		Designing a fully parametric CAD model of a sheet forming tool in a 3D CAD system expends temporal and financial effort and thus engineers shy away from it. The Institute of Forming Technology and Machines (IFUM) and the Society for the Advancement of Applied Computer Science (GFaI) are currently developing a new method for the model driven design of deep drawing tools. The core of this method is a graphical modelling language for the domain of deep drawing tools. Meta models of these tools allow the generation of models which in turn can be transformed to parametric CAD models and completed by geometric modelling. The new method makes the modelling of parametric relations and dependencies easier and less error-prone.	3d modeling;applied computer science;caddie;cognitive dimensions of notations;computer-aided design;digital subscriber line;geometric modeling;graphical user interface;holism;iteration;metamodeling;model-driven engineering;model-driven integration;modeling language;prototype;software prototyping;state diagram;systems modeling language;usability	Robert Scheffler;Sergej Koch;Gregor Wrobel;Matthias Pleßow;Christian Buse;Bernd-Arno Behrens	2016	2016 4th International Conference on Model-Driven Engineering and Software Development (MODELSWARD)		theoretical computer science;computer science;systems engineering;unified modeling language;deep drawing;parametric statistics;geometric design;solid modeling	EDA	-49.52363378466205	25.61048236741006	64774
eb079b6a782f492cff77d6d020fdc4654264bdeb	lessons learned from model-based safety assessment with sysml and component fault trees		Mastering the complexity of safety assurance for modern, software-intensive systems is challenging in several domains, such as automotive, robotics, and avionics. Model-based safety analysis techniques show promising results to handle this challenge by automating the generation of required artifacts for an assurance case. In this work, we adapt prominent approaches and propose facilitation of SysML models with component fault trees (CFTs) to support the fault tree analysis (FTA). While most existing approaches based on CFTs are only targeting the system topology, e. g., UML Class Diagrams, we propose an integration of CFTs with SysML Internal Block Diagrams as well as SysML Activity Diagrams. We conclude with best practices and lessons learned that emerged from applying our approach to automotive use-cases.	activity diagram;autonomous car;avionics;best practice;bus mastering;fault tree analysis;robotics;systems modeling language;unified modeling language	Arne Nordmann;Peter Munk	2018		10.1145/3239372.3239373	systems engineering;fault tree analysis;unified modeling language;model transformation;safety assurance;computer science;activity diagram;model-driven architecture;class diagram;systems modeling language	SE	-56.69528941298	23.40334766676619	64810
8821e29a24b0dc888c27f36add153bdc14c16477	architecture recovery and evaluation aiming at program understanding and reuse	program understanding;domain engineering;product line;data mining;architecture evaluation;architecture recovery;functional requirement;software inspection;software reuse;dynamic analysis	Organizations use to have implemented systems that represent a large effort and budget invested in the past. These systems are evolved and adapted over time in order to accommodate technological and business changes. Moreover, big companies often develop similar systems within the same domain. This has been motivating them to migrate to reuse approaches, such as domain engineering and product line. However, existing systems in general don't have up-to-date architectural documentation that can help in their maintenance and reuse. Considering this scenario, this paper presents an approach to architecture recovery and evaluation that aims at extracting knowledge from existing systems to help in their understanding and reuse. This extracted knowledge is represented through a recovered application architectural model composed by architectural elements that represent domain concepts traced to implemented functional requirements, which may help in generating reusable artifacts. In order to evaluate the approach feasibility, an experimental study was performed.		Aline Vasconcelos;Cláudia Maria Lima Werner	2007		10.1007/978-3-540-77619-2_5	domain analysis;simulation;computer science;systems engineering;engineering;operating system;feature-oriented domain analysis;software engineering;domain engineering;software inspection;dynamic program analysis;functional requirement;computer engineering	SE	-59.93860909098703	23.97993990770418	64855
c2432d8702e18858c6df0f75c913094ea96815ee	product certification of component performance specifications		In software engineering, performance analyses and predictions play an important role in the selection of components and the evolution of complex componentbased systems. These analyses and predictions are based on parameterized performance specifications. However, the quality of the specifications and their trustworthiness usually remain unspecified. In existing approaches, it remains unclear if a specification can be reused in another context and which effect its use may have on the quality of the analysis or prediction. In this paper, we propose a test-based approach to validate parameterized performance specifications against deployed component implementations. The validation is used to certify the quality and valid parameter ranges of the specifications.	parameterized complexity;software engineering;trust (emotion)	Henning Groenda	2010			reliability engineering;product certification;business	SE	-57.88020613667776	28.715115716162646	65331
0766bd747b577070b0e8933acf72a58cdb873ea2	comparing safety analysis based on sequence diagrams and textual use cases	sequence diagrams;misuse cases;embedded system;safety analysis;experiment;information system;experience base;use case;sequence diagram	Safety is of growing importance for information systems due to increased integration with embedded systems. Discovering potential hazards as early as possible in the development is key to avoid costly redesign later. This implies that hazards should be identified based on the requirements, and it is then useful to compare various specification techniques to find out the strengths and weaknesses of each with respect to finding and documenting hazards. This paper reports on two experiments in hazards identification – one experiment based on textual use cases and one based on systems sequence diagrams. The comparison of the experimental results reveal that use cases are better for identifying hazards related to the operation of the system while system sequence diagrams are better for the identification of hazards related to the system itself. The combination of these two techniques is therefore likely to uncover more hazards than one technique alone.	embedded system;experiment;failure cause;hazard (computer architecture);hazard analysis;information system;requirement;sequence diagram;software development process;software documentation;solid-state drive	Tor Stålhane;Guttorm Sindre;Lydie du Bousquet	2010		10.1007/978-3-642-13094-6_14	sequence diagram;reliability engineering;systems engineering;engineering;software engineering;data mining	SE	-58.992782800931614	31.02666431037991	65402
01131e1de86d779d0be8677351904f2c51d389e9	dissection of a visualization on-demand server	information visualization;interactive environment;user behavior;service oriented architecture	In this paper, we detail specifications of a Visualization On-Demand (VizOD) server. We show that packaging information visualization processes into services reachable over a network benefits both users and programmers, by reducing development cycles. We implemented a prototype based on our architecture, resulting in an innovative way to visually explore large movie database. We discuss early results and our main perspective is to federate a community of users and practitioners to better design interactive environments and understand users behaviors.	best practice;business process;discoverability;federated identity;holism;information visualization;interaction;internet movie database (imdb);library (computing);natural language;personalization;programmer;prototype;server (computing);tracing (software)	Romain Vuillemot;Béatrice Rumpler;Jean-Marie Pinon	2008		10.1007/978-3-642-00670-8_26	information visualization;interactive visualization;human–computer interaction;computer science;operating system;service-oriented architecture;data mining;database;multimedia;world wide web	HCI	-48.53672003716228	22.213607316928524	65560
74fbe642d198310f99f744475c77fb1162df021c	towards process patterns for a component retrieval system integrating the user profile	component retrieval system;software;user profile representation;process pattern;information retrieval;component;pattern;information technology;best practice;biological system modeling;catalogs;natural languages;object oriented programming;component catalog component retrieval system user profile representation search process pattern;reuse;process design;component catalog;navigation;user profile;adaptation model;component retrieval;indexing;system integration;best practices;software reusability;ontologies;object oriented programming information retrieval;user profile reuse component pattern component retrieval;proposals;search process pattern;information analysis;context;natural languages best practices indexing process design catalogs software reusability proposals information analysis information technology educational institutions	The current components' retrieval tools offer few services to facilitate a relevant search of these components. They are intended for experts having already a good knowledge of the components' catalogs. However, they are still limited for inexperienced users. In this context, the present contribution aims at analysing and comparing some existing retrieval approaches and studying the user profile representation. This study enabled us to incorporate the best practices of this field, to define our user profile and to carry out a process patterns' system guiding the integration of user profile in the search process.	application domain;best practice;digital signature;experience;ontology (information science);process patterns;type system;user profile	Hassania Ouchetto;Ounsa Roudiès;Mounia Fredj	2009	2009 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2009.5069419	user modeling;computer science;data mining;database;information technology;information retrieval;best practice	Visualization	-49.23957321844573	19.614063759288815	65622
6f31e66776f27b3cd3e424dfec2da712b780a44d	interactive visualization of design patterns can help in framework understanding	incrementality;composition;specialization;interactive visualization;aggregation;software architecture;design pattern;object oriented software engineering;metaobject protocol;source code;methodology;software reuse;reflection	Framework programming is regarded as one the main advantages of object-oriented software engineering, and is expected to increase software reuse. In exploiting frameworks, however, programmers often face difficulties caused by the complexity of the hidden architecture and the multiplicity of the design decisions that are embedded in a framework. Interactive visualization of design patterns occurring in a framework shows how the framework is operating, in a flexible yet structured way that contributes to the programmer's understanding of the underlying software architecture. In this way, programmers can explore and use frameworks efficiently even when they are distributed without vast amounts of documentation and source code.	code reuse;design pattern;documentation;embedded system;interactive visualization;interactivity;programmer;software architecture;software engineering	Danny B. Lange;Yuichi Nakamura	1995		10.1145/217838.217874	reference architecture;composition;software visualization;software architecture;model-driven architecture;software design pattern;reflection;interactive visualization;architectural pattern;computer science;package development process;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;software design description;software construction;methodology;software architecture description;design pattern;software walkthrough;programming language;resource-oriented architecture;structural pattern;software quality;software system;source code	SE	-51.6411187584647	29.41289620716979	65686
1bbc7d777a565a2bca1bae5a881ada06cfabb93c	function recovery based on program slicing	reverse engineering program debugging software maintenance;software maintenance;transform slice program slicing environment dependent operations domain dependent functionalities reference information model function recovery problem direct slice;functional recovery;program debugging;program slicing;reference information model;reverse engineering information systems data mining databases application software writing production systems concurrent computing councils data models;reverse engineering	1 To make an existing program easier to understand and modify, we propose an expectation-driven model for reverse engineering which identifies and extracts two main kinds of components: environment-dependent operations and domain-dependent functionalities. A reference information model gives expectations of components and their interface data. We apply program slicing, firstly proposed by Weiser, to this function recovery problem by modifying the notion of program slice to a direct slice and transform slice. The former, direct slice, is an executable subset of the original program containing all the statements which directly contribute either to the writing on an external sink or to the reading from an external source. The latter, transform slice, is also an executable subset including all the instructions which directly or indirectly contribute to transform an external input into an external output.	executable;health level 7;information model;program slicing;reverse engineering	Filippo Lanubile;Giuseppe Visaggio	1993		10.1109/ICSM.1993.366923	program slicing;real-time computing;computer science;engineering;operating system;software engineering;database;programming language;software maintenance;reverse engineering	PL	-50.62973370893585	31.074191573462485	65724
eef9e76fa7c4a9b6e715d71a3dbd6b95909e8f03	panacea towards a self-healing development framework	software testing;innovative programming model panacea self healing development framework software testing runtime monitoring;innovative programming model;software systems;self healing development framework;software engineering;programming model;paradigm shift;program testing;runtime monitoring;panacea;web server humans monitoring automatic testing system testing network servers databases application software software systems computer architecture;design methodology;software engineering program testing	Self-healing capabilities allow software systems to overcome problems occurring during testing and run time, and thus improve overall system behavior. The PANACEA framework introduced in this paper provides a design methodology as well as ready-to-use healing elements aimed at enhancing software systems with self-healing capabilities both at design time and at run time. The PANACEA approach is based on inserting self- healing elements into the system at design and coding time, to be used later for healing at testing and run time. Specifically, the Panacea framework is based on inserting annotations into the system code at design and coding time, to later on serve as an interface for runtime monitoring, managing, configuring and healing of the annotated system components. The current embodiment of PANACEA includes several generic components that provide self-healing capabilities suited for a variety of application types. The PANACEA runtime environment automatically activates and invokes these components in order to optimize and heal the application. The PANACEA framework provides an innovative programming model that enables development of advanced self-healing applications. PANACEA introduces a paradigm shift in which software is made self-healing by design. This paradigm shift, however, is graceful since developers are not required to master neither new programming skills, nor languages. As our initial experiments demonstrate, PANACEA introduces a very small performance overhead, and scales well.	autonomic computing;database server;experiment;feedback;horizontal pitch;ieee systems, man, and cybernetics society;international federation for information processing;linux;mimo;microsoft windows;overhead (computing);programming model;relational database;run time (program lifecycle phase);runtime system;self-management (computer science);server (computing);software system;unix;web server	David Breitgand;Maayan Goldstein;Ealan A. Henis;Onn Shehory;Yaron Weinsberg	2007	2007 10th IFIP/IEEE International Symposium on Integrated Network Management	10.1109/INM.2007.374781	paradigm shift;real-time computing;design methods;computer science;software reliability testing;software framework;software development;operating system;software construction;software testing;programming paradigm;panacea;software system	SE	-54.71487557710534	30.665822273015326	65769
0780ab734120e345669ddb215afbc81ea77d4466	explicit exception handling variability in component-based product line architectures	exceptional behaviour;separation of concern;software systems;component based software architecture;software architecture;object oriented;product line architecture;software component;exception handling;component based software development;software product line;mobile application	Separation of concerns is one of the overarching goals of exception handling in order to keep separate normal and exceptional behaviour of a software system. In the context of a software product line (SPL), this separation of concerns is also important for designing software variabilities related to different exception handling strategies, such as the choice of different handlers depending on the set of selected features. This paper presents a method for refactoring object-oriented product line architecture in order to separate explicitly their normal and exceptional behaviour into different software components. The new component-based software architecture includes variation points related to different choices of exception handlers that can be selected during product instantiations, thus facilitating the evolution of the exceptional behaviour. The feasibility of the proposed approach is assessed through a SPL of mobile applications.	code refactoring;component-based software engineering;exception handling;heart rate variability;mobile app;separation of concerns;software architecture;software product line;software system	Ivo Augusto Bertoncello;Marcelo Oliveira Dias;Patrick Henrique da S. Brito;Cecília M. F. Rubira	2008		10.1145/1454268.1454275	multilayered architecture;reliability engineering;reference architecture;software architecture;verification and validation;real-time computing;software sizing;computer science;systems engineering;package development process;backporting;software design;software framework;component-based software engineering;software development;software design description;software construction;software architecture description;resource-oriented architecture;software measurement;software deployment;software system	SE	-53.983285410277624	29.403423895936246	65804
84006e7f28fb4e854c5e71d59e03cad2d0c4383d	design patterns for integration between enterprise application with any business process management systems	databases;bridges production facilities couplings concrete databases organizations;bridges;business process management systems bpm vendor software reusability factory pattern decorator pattern bridge pattern object oriented design principle enterprise application bpm api gui graphical user interfaces;production facilities;organizations;couplings;software reusability application program interfaces business data processing graphical user interfaces organisational aspects;concrete	Most of existing Business process management (BPM) technologies have their own graphical user interfaces (GUIs), whereas users in different organizations who involved in business processes are more likely to work with a different set of GUIs. Consequently, developers have to build the specific set of GUIs in enterprise application which is appropriate for each business process, and they use BPM API to create communication between the enterprise application and BPM. However, different BPM vendors have different APIs integrated into the system. When developers need to change BPM vendor for corresponding to existing resources and devices of a new customer, the developers have to rewrite codes to interact with such new API every time. Thus a framework that is easy to plug into further enterprise application for connecting to any BPM systems and reusable is necessary. Design patterns idea is applied in object oriented design principle in order to provide an efficient way in creating more reusable software. In this paper, a new framework for enterprise application is created by applying three types of design pattern which are Bridge pattern, Decorator pattern and Factory pattern. This framework aims to be reusability, flexibility and maintainability in order to easily support BPM vendor changing.	application programming interface;beam propagation method;bridge pattern;business process;code;decorator pattern;enterprise software;factory method pattern;graphical user interface;rewrite (programming);software design pattern	Wittakarn Keeratichayakorn;Saranya Maneeroj	2014	2014 Fourth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)	10.1109/DICTAP.2014.6821647	enterprise software;concrete;organization;business process management;operating system;database;coupling	SE	-56.04254955431351	19.574717656364108	66161
ed227796c9c5fbb82ca7436bd4d3692083a1eb2a	enhancing the esim (embedded systems improving method) by combining information flow diagram with analysis matrix for efficient analysis of unexpected obstacles in embedded software	formal specification;systems analysis data flow analysis embedded systems formal specification software quality;conceptual model;embedded system;requirement analysis;embedded systems;information flow;systems analysis;conceptual model embedded systems improving method information flow diagram analysis matrix unexpected obstacle analysis embedded software quality software specification requirements analysis;data flow analysis;efficiency analysis;information analysis embedded system embedded software software engineering software quality computer industry costs reliability engineering knowledge engineering productivity;software specification;software quality;embedded software	In order to improve the quality of embedded software, this paper proposes an enhancement to the ESIM (embedded systems improving method) by combining an IFD (information flow diagram) with an Analysis Matrix to analyze unexpected obstacles in the software. These obstacles are difficult to predict in the software specification. Recently, embedded systems have become larger and more complicated. Theoretically therefore, the development cycle of these systems should be longer. On the contrary, in practice the cycle has been shortened. This trend in industry has resulted in the oversight of unexpected obstacles, and consequently affected the quality of embedded software. In order to prevent the oversight of unexpected obstacles, we have already proposed two methods for requirements analysis: the ESIM using an Analysis Matrix and a method that uses an IFD. In order to improve the efficiency of unexpected obstacle analysis at reasonable cost, we now enhance the ESIM by combining an IFD with an Analysis Matrix. The enhancement is studied from the following three viewpoints. First, a conceptual model comprising both the Analysis Matrix and IFD is defined. Then, a requirements analysis procedure is proposed, that uses both the Analysis Matrix and IFD, and assigns each specific role to either an expert or non-expert engineer. Finally, to confirm the effectiveness of this enhancement, we carry out a description experiment using an IFD.	embedded software;embedded system;experiment;formal specification;information flow diagram;requirement;requirements analysis;subscriber identity module	Yasufumi Shinyashiki;Toshiro Mise;Masaaki Hashimoto;Keiichi Katamine;Naoyasu Ubayashi;Takako Nakatani	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.49	reliability engineering;systems analysis;requirements analysis;software requirements specification;verification and validation;information flow;embedded software;computer science;systems engineering;conceptual model;software development;software engineering;data-flow analysis;software construction;formal specification;software quality;software system;avionics software	Embedded	-58.69125085131554	30.758676192595217	66256
5078fa849728222b31c8201675622dc7521d22f0	non-functional requirements framework: a mathematical programming approach			mathematical optimization;non-functional requirement;non-functional requirements framework	Amy Affleck;Aneesh Krishna;N. R. Achuthan	2015	Comput. J.	10.1093/comjnl/bxu027	programming domain;reactive programming;functional reactive programming;procedural programming;inductive programming	Embedded	-48.768506648209836	28.173995956468882	66523
b40b80eafe1856c1ef727054a67191e1d7a1b416	disambiguation and comparison of soa, microservices and self-contained systems		There is an industrial shift from Service-Oriented Architectures (SOA) into Microservices; however, a quick review of online resources on these topics reveals a range of different understandings of these two architectures. Individuals often mix terms, grant false advantages or expect different quality attributes and properties. The purpose of this paper is to provide readers a solid understanding of the differences between these two architectures and their features. We provide both research and industry perspectives to point out strengths and weaknesses of both architectural directions, and we point out many shortcomings in both approaches that are not addressed by the architecture. Finally, based on this we propose challenges for future research.	list of system quality attributes;microservices;service-oriented architecture;service-oriented device architecture;word-sense disambiguation	Tomás Cerný;Michael J. Donahoo;Jiri Pechanec	2017		10.1145/3129676.3129682	microservices;real-time computing;systems engineering;architecture;computer science;strengths and weaknesses;knowledge management	SE	-59.93170939938669	21.38776066022259	66819
2373277466b18a9c7d07f5e92873ae513d1f3b0a	an approach to developing core assets in product line	computer architecture testing moon programming software systems control systems design engineering costs production software quality;software development software product line engineering core assets;formal specification;product line;object oriented programming;software architecture;levels of abstraction;software reusability;software development;product line engineering;object oriented programming software architecture software quality software reusability formal specification;software product line;software quality	The methodologies of product-line engineering emphasize proactive reuse to construct high-quality, less costly products. To refer software product line engineering, it is important to analyze the commonality and variability of a domain and to develop core assets based on them. But, core assets are in the different levels of abstract because they are produced at different steps of software development. The variability of core assets has been exposed as a different type at different level. We must consider the variability in requirement and architecture level that are higher than code level to develop core assets successfully in product line engineering. If we consider the variability at higher level, we can reduce the amount of work that handles the variability as the development step is proceeded.	heart rate variability;requirement;software development;software product line;spatial variability	Mikyeong Moon;Keunhyuk Yeom	2004	11th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2004.21	reliability engineering;software architecture;reusability;verification and validation;software quality management;software sizing;computer science;systems engineering;engineering;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;formal specification;software walkthrough;object-oriented programming;resource-oriented architecture;software measurement;software deployment;software development process;software quality;software system	SE	-57.12539532644509	27.48515089926005	66824
c37a859722d28c5c36517ca289aa4a679c64876f	data-oriented declarative language for optimizing business processes		There is a significant number of declarative languages to describe business processes. They tend to be used when business processes need to be flexible and adaptable, being not possible to use an imperative description. Declarative languages in business process have been traditionally used to describe the order of activities, specifically the order allowed or prohibited. Unfortunately, none of them is worried about a declarative description of exchanged data between the activities and how they can influence the model. In this paper, we analyse the data description capacity of a variety of declarative languages in business processes. Using this analysis, we have detected the necessity to include data exchanged aspects in the declarative descriptions. In order to solve the gap, we propose a Data-Oriented Optimization Declarative LanguagE, called DOODLE, which includes the process requirements referred to data description, and the possibility to include an optimization function about the process output data.	declarative programming;optimizing compiler	Luisa Parody;María Teresa Gómez López;Rafael M. Gasca	2013		10.1007/978-3-319-07215-9_5	natural language processing;business process model and notation;process management;business rule	DB	-53.577137878495414	19.287569781541418	67066
bf7bcdf72663d0fbc050aeef15865aec2e61b8ae	experiences using tedeso: an extensible and interoperable model-based testing platform	model-based testing automation;workflow-driven service-oriented architectures;tedeso	The integration of novel software quality assurance tools into existing development environments must be performed in ways that leverage the benefits of the tools while minimizing their impact on existing software processes. This supports the adoption of new methodologies with minimal interference into core business practices. This paper discusses the design of Tedeso, an extensible and interoperable model-based testing platform developed to facilitate the automatic generation of tests, while supporting the needs of different stakeholders in a diverse and broad organization. We discuss Tedeso key design characteristics, in particular its extensibility and interoperability, provided through the use of a workflow-driven service-oriented architecture, and show how it has enabled and facilitated the adoption of model-based testing techniques in different business units in different sectors within SIEMENS. We also discuss some issues that come from the adoption of service-oriented architectures, showing how they have been managed in our platform.	extensibility;interference (communication);interoperability;model-based testing;service-oriented architecture;service-oriented device architecture;software quality assurance	Roberto Silveira Silva Filho;William M. Hasling;Christof J. Budnik;Monica McKenna	2012	Automated Software Engineering	10.1007/s10515-012-0118-3	simulation;systems engineering;engineering;software engineering;world wide web	SE	-59.38435800161675	21.135956287891844	67069
2cbd4339d949403a712513f00d6ae85b52de2eae	cscw systems in virtual environments: a general development framework	design methodology virtual environments groupware framework;groupware;virtual reality groupware interactive systems;collaborative work;design and development;computer supported cooperative work;virtual reality;virtual environments;three dimensional displays collaboration unified modeling language solid modeling software collaborative work avatars;software requirements;3d environment;design guideline;interactive systems cscw systems collaborative virtual environments cve computer supported cooperative work virtual reality world 3d systems;virtual environment;interactive systems;collaborative virtual environment;framework;virtual worlds;design methodology	Collaborative Virtual Environments (CVEs), defined as systems that allow performing some collaborative tasks in a virtual world, were proposed since 1990. From the beginning, these systems were developed as particular applications of Computer-Supported Cooperative Work (CSCW) in a virtual reality world, with specific restrictions on both collaborative work and technological (hardware and software) requirements. Therefore, design guidelines which could be applied to new developments have not been proposed. This paper presents a general framework for designing and developing CSCW systems in virtual 3D environments, which integrates new methodologies that provide clear and formal techniques to develop CSCW, interactive and 3D systems.	collaborative virtual environment;computation;computer-supported cooperative work;formal methods;iteration;requirement;software design;software development;software requirements specification;systems modeling;virtual reality;virtual world	Wilson J. Sarmiento;César A. Collazos	2012	2012 10th International Conference on Creating, Connecting and Collaborating through Computing	10.1109/C5.2012.17	design methods;human–computer interaction;computer science;knowledge management;virtual machine;software framework;operating system;computer-supported cooperative work;virtual reality;programming language;management;software requirements	Visualization	-49.92708420796025	20.606247768964973	67096
70b703f4920dbb1ac86b136a65f210129467886f	automatically generating and adapting model constraints to support co-evolution of design models	design model;software maintenance;co evolution;metamodeling co evolution consistency checking;automatic generation;constraint templates model constraints design model coevolution software modelers error feedback constraint adaptation mechanisms;consistency checking;metamodeling	Design models must abide by constraints that can come from diverse sources, like their metamodels, requirements, or the problem domain. Software modelers expect these constraints to be enforced on their models and receive instant error feedback if they fail. This works well when constraints are stable. However, constraints may evolve much like their models do. This evolution demands efficient constraint adaptation mechanisms to ensure that models are always validated against the correct constraints. In this paper, we present an idea based on constraint templates that tackles this evolution scenario by automatically generating and updating constraints.	evolution;metamodeling;problem domain;requirement	Andreas Demuth;Roberto Erick Lopez-Herrejon;Alexander Egyed	2012	2012 Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering	10.1145/2351676.2351730	metamodeling;real-time computing;simulation;coevolution;computer science;systems engineering;software engineering;software maintenance	SE	-55.37034710133917	29.232258897496926	67292
97ae92da64698918c3e63c19291c23338a670035	mutual satellites: round-trip modeling for complete applications	entity relationship model;round trip;uml;sql;model driven development;xaml;source code;c;entity relationship;modeling tool	During the presentation we will demonstrate a new modeling tool, implemented as an Add-In for Microsoft Visual Studio. Our tool provides complete round-trip capabilities enabling application manipulation using either the model or the source code. The tool manipulates all three application layers of conventional enterprise applications, currently with support for SQL, C# and XAML.	enterprise software;extensible application markup language;microsoft visual studio;sql	Lars Thorup;Sune Gynthersen;Kristian Dupont	2006		10.1145/1176617.1176683	real-time computing;entity–relationship model;computer science;data mining;database	HCI	-48.82140111809889	25.559610361162697	67317
4ef67ae982812488168215f5be2c98dce6e3e340	human interaction issues for user-configurable collaborative editing components	groupware;human interaction;collaborative editing;collaboration component implementations human interaction issues user configurable collaborative editing components work artefacts editing tools user configurable collaborative editing facilities component based design environments component based approach;human factors;design environment;interactive systems text editing groupware user interfaces human factors;humans collaboration collaborative work collaborative tools collaborative software computer aided software engineering design automation erbium proposals computer science;interactive systems;user interfaces;text editing	"""The ability to synchronously and asynchronously edit work artefacts has become very important in many editing tools. However, most tools usually only provide one kind of collaborative editing """"level"""", or provide incompatible levels of collaborative editing. We describe our recent work in adding flexible, user-configurable collaborative editing facilities to component-based design environments, and focuses on the human interaction issues in such systems. We also briefly describe the engineering of such tools using a component-based approach, which allows userconfigurable collaborative editing capabilities to be added to component-based tools without modifying the tool or collaboration component implementations."""	asynchronous i/o;component-based software engineering;design tool;seamless3d;semiconductor industry;synchronization (computer science)	John C. Grundy	1998		10.1109/APCHI.1998.704182	interpersonal relationship;human–computer interaction;computer science;human factors and ergonomics;operating system;multimedia;user interface;world wide web;collaborative software	HCI	-49.613993555002224	20.23109145549176	67468
4c528f54ab5b6757944f3554ce53cfe4dd15b6e4	an evaluation framework to drive future evolution of a research prototype	g400 computer science;groupware;project management;management system;prototypes discrete event simulation open source software usability project management collaboration risk management software prototyping distributed computing maintenance engineering;software maintenance;software engineering;public domain software;industrial partner evaluations open source component artefact repository distributed software engineers stand alone system artefact management systems;project support environments;software maintenance public domain software workflow management software groupware project management project support environments;workflow management software;evaluation framework;open source;time constraint	The open source component artefact repository (OSCAR) requires evaluation to confirm its suitability as a development environment for distributed software engineers. The evaluation takes note of several factors including usability of OSCAR as a stand-alone system, scalability and maintainability of the system and novel features not provided by existing artefact management systems. Additionally, the evaluation design attempts to address some of the omissions (due to time constraints) from the industrial partner evaluations. This evaluation is intended to be a prelude to the evaluation of the awareness support being added to OSCAR; thus establishing a baseline to which the effects of awareness support may be compared.	baseline (configuration management);distributed computing;open-source software;prototype;scalability;software engineer;usability	David Nutter;Stephen Rank;Cornelia Boldyreff	2004	13th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises	10.1109/ENABL.2004.13	project management;personal software process;long-term support;verification and validation;software sizing;software project management;knowledge management;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;operating system;software engineering;software construction;software as a service;management system;database;distributed computing;software walkthrough;application lifecycle management;software analytics;software maintenance;management;software deployment;public domain software;world wide web;software development process;software system;software peer review	SE	-62.84860998422951	26.28327529426799	67487
b3007632998ba3e12dc0a9d1d663b7cfe6d0593e	measuring software failure risk: methodology and an example	fiabilidad;reliability;erreur;metodologia;metric;risque;ingenieria logiciel;software engineering;methodologie;riesgo;risk;risque echec;fiabilite;genie logiciel;metrico;ejemplo;evaluation;error;evaluacion;methodology;example;metrique;exemple	Abstract   The economic significance of failure is incorporated with software reliability theory to assess  software failure risk —the expected loss resulting from software failure. The methodology draws upon probabilistic risk assessment and safety techniques to assess the potential consequence of failures in the environment in which the software will operate. The potential loss due to failures caused by faults in different modules is estimated by relating the module's function and expected use to these consequences. Loss estimates are combined with failure likelihood estimates from a time-dependent software reliability model. A case study illustrates application of the methodology to a payables processing system.		Susan A. Sherer	1994	Journal of Systems and Software	10.1016/0164-1212(94)90034-5	reliability engineering;simulation;metric;engineering;software reliability testing;evaluation;software engineering;methodology;reliability;risk;life-critical system;forensic engineering;management	OS	-61.88113533363837	31.337707090598972	67510
3b1538072b82be8812e2942520fc7950bc993631	issues in modeling process variants with provop	configural processing;model adaptation;process design;levels of abstraction;business process management;process model;business process	For a particular business process, typically, different variants exist. Each of them constitutes an adjustment of a basic process (e.g. a reference process) to specific requirements building the process context. Contemporary business process management (BPM) tools, however, do not adequately support the modeling and management of process variants. Either the variants have to be specified by separate process models or they are expressed in terms of conditional branches within the same process model. Both methods can lead to high model redundancies, which make model adaptations a time consuming and error-prone task. In this paper we discuss advanced modeling concepts of our Provop approach, which provides a flexible and powerful solution for modeling and managing process variants. With Provop, a particular process variant can be configured at a high level of abstraction by applying a set of well-defined change operations to a basic process model.	business process;cognitive dimensions of notations;high-level programming language;mathematical model;microsoft outlook for mac;network switch;process modeling;prototype;requirement	Alena Hallerbach;Thomas Bauer;Manfred Reichert	2008		10.1007/978-3-642-00328-8_6	process design;design process;computer science;systems engineering;engineering;knowledge management;artifact-centric business process model;business process management;operations management;process modeling;database;business process model and notation;business process;event-driven process chain;business process discovery;management;business process modeling	SE	-55.194748018382484	18.833658847372284	67785
2f1188f4728986b3d8777c48b90976d543b736ec	structured document framework for design patterns based on sgml	page description languages;object oriented methods;software engineering page description languages object oriented methods object oriented programming;object oriented programming;software engineering;structure and function;design pattern;software component;structured documents;sgml information science software systems visualization html joining processes databases access control object oriented programming books;markup language;object oriented design structured document framework design patterns sgml abstract software components system structures system functions object oriented analysis text configuration charts pseudo codes class source codes automatic html conversion automatic chart generation interactive code generation	Design patterns are abstract software components for system structures and functions used in OOA/OOD. They are described currently as texts (with figures), and difJicult to catalog, maintain and handle. This paper presents a framework to describe pattems as structured documents based on SGML (Structured Generalized Markup Language). A design pattern, in general, has three elements: texts, conjiguration charts and pseudo-codes, therefore SGML schemes are proposed for them respectively so that they are integrated into a single structured document. The document also includes links to related pattern documents and corresponding class source codes. This SGML-based pattern document is visualized by automatic HTML conversion and automatic chart generation. And the document is used for interactive code generation.	chart;code generation (compiler);component-based software engineering;html;software design pattern;standard generalized markup language	Mika Ohtsuki;Jun'ichi Segawa;Norihiko Yoshida;Akifumi Makinouchi	1997		10.1109/CMPSAC.1997.624848	connascence;computer science;document type definition;theoretical computer science;component-based software engineering;document type declaration;database;markup language;design pattern;programming language;object-oriented programming;design document listing	Web+IR	-48.3541211457864	27.67034575816722	68011
fc3f199d060cbd234d09e74e05a11f36903302a5	persistent meta-modeling systems as heterogeneous model repositories	database;meta modeling;model management	Model persistence has always been one of the major interests of the model-driven development community. In this context, Persistent Meta-Modeling Systems (PMMS) have been proposed as database environments dedicated to meta-modeling and model management. Yet, if existing PMMS store meta-models, models and instances, they provide mechanisms that are sometimes insufficient to accomplish some advanced model management tasks like model transformation or model analysis. In this paper we validate the work achieved in [5] by exploiting the support of user-defined operations in PMMS in order to perform model transformations and model analysis.	metamodeling;model transformation;model-driven architecture;model-driven engineering;object constraint language;persistence (computer science);programming language	Youness Bazhar;Yassine Ouhammou;Yamine Aït Ameur;Emmanuel Grolleau;Stéphane Jean	2013		10.1007/978-3-642-41366-7_3	simulation;computer science;knowledge management;data mining	DB	-53.21666208525039	24.74500267976233	68145
906e250967f51a3ea03e525830c5c9af908689fd	design patterns for open tool integration	architectural design;design tool;software systems;development process;software engineering;software architecture;design pattern;tool integration;generic programming	Design tool integration is a highly relevant area of software engineering that can greatly improve the efficiency of development processes. Design patterns have been widely recognized as important contributors to the success of software systems. This paper describes and compares two large-grain, architectural design patterns that solve specific design tool integration problems. Both patterns have been implemented and used in real-life engineering processes.	architectural pattern;authorization;design pattern;design tool;embedded software;embedded system;ibm notes;inter-process communication;internet backbone;metamodeling;real life;scalability;software design;software engineering;software propagation;software system;web application	Gabor Karsai;Andras Lang;Sandeep Neema	2004	Software & Systems Modeling	10.1007/s10270-004-0073-y	software architecture;computer architecture;software design pattern;architectural pattern;computer science;systems engineering;engineering;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;interaction design pattern;software construction;design pattern;systems development life cycle;distributed design patterns;generic programming;resource-oriented architecture;structural pattern;computer-aided software engineering;goal-driven software development process;software development process;software requirements;software system;computer engineering;systems design	SE	-51.856923980203376	28.23331281406452	68230
3f9b998f410a878aac6591554410e0bcbd5da2ce	model-integrated mechatronics - toward a new paradigm in the development of manufacturing systems	model evolution model integrated mechatronics manufacturing systems development model integration domain specific modeling languages concurrent engineering mechanical components electronic components software components mechatronic systems integrated development process archimedes agile mechatronic manufacturing systems mechatronic component model driven development;agile manufacturing;analysis and design;indexing terms;development process;domain specific modeling language;manufacturing systems mechatronics object oriented modeling computer architecture heart concurrent engineering automatic control independent component analysis agile manufacturing real time systems;model driven development;model integration design methodology mechatronic component mechatronic systems model driven development model evolution modeling;model integration;software component;component model;simulation languages;integrated manufacturing systems;control engineering computing;mechatronics;manufacturing system;mechatronic systems;control engineering computing agile manufacturing mechatronics integrated manufacturing systems simulation languages;concurrent engineering;design methodology	"""The traditional approach for the development of manufacturing systems considers the constituent parts of the system, i.e., mechanical, electronic, and software, to be developed independently and then integrated to form the final system. This approach is being criticized as inappropriate for the complexity and the dynamics of today's systems. This paper proposes an architecture that promotes model integration not only for implementation space artifacts but also in artifacts of the early analysis and design phases of the development process. The proposed architecture, which promotes reuse and significantly decreases development and validation time, is at the heart of a new paradigm called model-integrated mechatronics (MIM). MIM applies domain-specific modeling languages for the concurrent engineering of mechanical, electronic and software components of mechatronic systems. It simplifies the integrated development process of manufacturing systems by using as basic construct the mechatronic component. The MIM paradigm was utilized to define """"Archimedes,"""" a system platform that supports the engineer through a methodology, a framework, and a set of tools to automate the development process of agile mechatronic manufacturing systems."""	acorn archimedes;agile software development;automation;complexity;component-based software engineering;domain-specific language;domain-specific modeling;integrated development environment;interactivity;mechatronics;model-driven architecture;model-driven engineering;modeling language;programming paradigm;prototype	Kleanthis Thramboulidis	2005	IEEE Transactions on Industrial Informatics	10.1109/TII.2005.844427	index term;mechatronics;design methods;computer science;systems engineering;engineering;component-based software engineering;component object model;software development process;concurrent engineering;manufacturing engineering;computer engineering;systems design	Robotics	-50.06675944840744	26.83271068023939	68337
9d1658dd431080ef481ef9f2df427795f6f7e680	supporting cooperative requirements engineering with an automated tool	requirements engineering;cscw computer-supported cooperative work;cooperative requirements engineering;software engineering.;groupware;software engineering;requirement engineering;team work;computer supported cooperative work;quality assurance;software process	Requirements Engineering – one of the macro-activities of Sofware Engineering – is a systematic process of capturing, modelling and documenting requirements through an iteractive and cooperative approach of problem analysis, documentation of the resulting observations in a variety of formats of representations and verification of the accuracy of the acquired understanding [13]. It is an activity which requires team work. Groups of people formulate requirements, design and implement a system and execute quality assurance activities during the software process [28]. The cooperative work becomes necessary since solutions require different knowledge, professionals become more and more specialized and Requirements Engineering involves heterogeneous groups belonging to the same organization or not [3]. Viewing these aspects, it is worthwhile to use computational resources to support the cooperative Requirements Engineering activities. The area of Computer-Supported Cooperative Work (CSCW) is interested in how groups of people working on a cooperative basis can be assisted by computational support [28]. This work investigates how solutions from the CSCW area can support Requirements Engineering activities and introduces CRETA – a Cooperative Requirements Engineering support tool, which intends to integrate groupware applications into applications supporting Requirements Engineering. This tool was developed for the Web, using the object-orientation paradigm.	asynchronous i/o;collaborative software;computation;computational resource;computer-aided software engineering;computer-supported cooperative work;directory (computing);directory service;email;interaction;problem solving;programming paradigm;requirement;requirements engineering;scheduling (computing);software development process;software documentation;software quality;world wide web	Denise F. Togneri;Ricardo de Almeida Falbo;Crediné Silva de Menezes	2002			quality assurance;collaborative software;software engineering process group;requirements engineering;software requirements;software development process;computer-supported cooperative work;social software engineering;engineering;systems engineering	SE	-51.17046905879644	21.453536431924597	68408
232732a0c4bfae30256a6c272f0390eebd71ec14	a combined analysis method of fmea and fta for improving the safety analysis quality of safety-critical software	program diagnostics;safety critical software fault trees program diagnostics;safety critical software;fault tree analysis fmea fta software safety analysis semiauto analyzing tool safety analysis quality safety critical software failure modes and effect analysis;software safety hazards fault trees context aerospace safety;fault trees	Software safety analysis methods are used broadly in safety-critical systems to secure software safety and to recognize potential errors during software development, particularly at the early stage. FMEA and FTA are two traditional safety analysis methods, both of which provide a complementary way of identifying errors and tracking their possible influences. They have already been widely adopted in safety-critical industries. However, the effectiveness of FMEA and FTA depends on a complete understanding of the software being analyzed. Unlike hardware safety analysis, software safety analysis is usually a process of iteration. It is more difficult to get a comprehensive understanding of the software being analyzed at the early stage of software life cycle. A combined analysis method of FMEA and FTA was presented in this paper, which could detect more potential errors of software at the early stage. An analysis process which can convert and verify between FMEA and FTA was created. A semi-auto analyzing tool was developed to carry the process. Comparison experiments were carried out to testify the effectiveness of this method, which showed that the combined method proposed by this paper achieved better results.	code coverage;experiment;failure cause;failure mode and effects analysis;fault tree analysis;formal concept analysis;iteration;semiconductor industry;software development;software development process;software release life cycle;tree accumulation	Xiangyu Han;Jun Zhang	2013	2013 IEEE International Conference on Granular Computing (GrC)	10.1109/GrC.2013.6740435	verification and validation;fault tree analysis;software construction;computer security;software quality analyst	SE	-58.76708576180232	31.01592575291164	68462
0198894f167fb3ff0125bcfb25f457229d4e6d57	measurement processes are software, too	software process improvement;object oriented;object oriented approach;process model;process improvement;software process	Software process improvement and measurement are closely linked: measures are the only way to prove improvements in a process. Despite this link, and the interest in process improvement, measurement is not widely applied in industrial software production. This paper describes a method designed to guide the definition, implementation and operation of measurement processes. The method, which builds upon Fenton’s measurement framework and GQM, starts from the point that measuring a software process is in its turn a process in the software process. The three basic ideas of the method derive from this assumption: -the measurement process should reuse and suitably adapt the same phases of the software process: requirements definition, design, implementation, etc.., -a descriptive process model should be the essential starting point of a measurement process, -many concepts and tools which derive from the object oriented approach should be effectively used in the measurement process. An experimental application in an industrial process has shown that building the process model was the hardest part of the measurement process, and that it has improved the quality of measurement by reducing misunderstandings. Object oriented concepts and tools make it possible to automate certain tasks (for instance the definition of the schema of the measurement database) and to improve robustness against changes in the measurement process. This work was partially supported by the European Commission, DGIII/A, under contracts Esprit/ESSI AEFTA n. 10070, MOODS n. 23819 and PSP-NC n. 24060. This paper is published on the Journal of Systems and Software, vol. 49(1), December 1999.	database schema;estimation of signal parameters via rotational invariance techniques;gqm;journal of systems and software;process modeling;requirement;semantic web service;software development process;turned a	Maurizio Morisio	1999	Journal of Systems and Software	10.1016/S0164-1212(99)00063-1	reliability engineering;design process;software engineering process group;process capability index;computer science;systems engineering;business process management;package development process;software development;software engineering;process modeling;cosmic software sizing;object-oriented programming;empirical process;software measurement;rational unified process;engineering drawing;business process modeling;goal-driven software development process;software development process	Embedded	-58.52822615446987	24.373032353009954	68545
60d9efd19e2fe9a9c7d0139e12ed0b49af4ae6f8	introduction to the attribute driven design method	quality attributes;software architecture;software design methods;design method;software architecture design;information system;software design	This tutorial will introduce the Attribute Driven Design (ADD) method. ADD is a method for designing the software architecture of a system or collection of systems based on an explicit articulation of the quality attribute goals for the system(s). The method is appropriate for any quality attributes but has been particularly elaborated for the attributes of performance, modifiability, security, reliability/availability and usability. The method has been used for designing the software architecture of products ranging from embedded to information systems.	biconnected component;computer performance;computer security;embedded system;information system;list of system quality attributes;software architecture;usability	Felix Bachmann;Leonard J. Bass	2001			software security assurance;reliability engineering;reference architecture;software architecture;architecture tradeoff analysis method;verification and validation;computer science;systems engineering;engineering;software design;component-based software engineering;software development;software design description;software engineering;software construction;hardware architecture;database;software architecture description;resource-oriented architecture;software measurement;software deployment;software quality control;software quality;systems architecture;software system;systems design	EDA	-59.60864180264894	25.86322779056027	68587
b220c0b30b43950702f21db94500c70b8bb65e79	involving business users in formal modeling using natural language pattern sentences	knowledge authoring;formal model;user interface;user participation;business model;lessons learned;knowledge acquisition;natural language;knowledge representation;user interfaces	With knowledge representation based technologies reaching the enterprise, involving business users in modeling is more important than ever. When primary processes and business decisions are driven by models, business knowledge needs to be captured and only business users can establish whether the models created are correct. A natural language based representation of models can help business users get involved in the modeling process. We have used a representation based on natural language pattern sentences to improve business user participation in our business modeling projects. Based on the lessons learned, user interfaces have been developed that use this representation for both communicating and editing formal models.	knowledge representation and reasoning;natural language;user interface	Jeroen van Grondelle;Ronald Heller;Emiel van Haandel;Tim Verburg	2010		10.1007/978-3-642-16438-5_3	natural language processing;knowledge representation and reasoning;business logic;user modeling;semantics of business vocabulary and business rules;business domain;business requirements;computer science;knowledge management;artifact-centric business process model;artificial intelligence;process modeling;business process model and notation;multimedia;business process;business software;user interface;business process discovery;business rule;business process modeling;business activity monitoring;business architecture	Web+IR	-53.474165707396786	19.627349369079713	68820
5c6cda7440198bdafb750e6332c1adcb815fbdbc	improving the lifecycle of robotics components using domain-specific languages		There is currently a large amount of robotics software using the component-oriented programming paradigm. However, the rapid growth in number and complexity of components may compromise the scalability and the whole lifecycle of robotics software systems. Model-Driven Engineering can be used to mitigate these problems. This paper describes how using Domain-Specific Languages to generate and describe critical parts of robotic systems helps developers to perform component managerial tasks such as component creation, modification, monitoring and deployment. Four different DSLs are proposed in this paper: i) CDSL for specifying the structure of the components, ii) IDSL for the description of their interfaces, iii) DDSL for describing the deployment process of component networks and iv) PDSL to define and configure component parameters. Their benefits have been demonstrated after their implementation in RoboComp, a general-purpose and component-based robotics framework. Examples of the usage of these DSLs are shown along with experiments that demonstrate the benefits they bring to the lifecycle of the components.	algorithmic trading;cognitive dimensions of notations;component manager;component-based software engineering;data distribution service;distributed computing;domain-specific language;download;embedded system;emoticon;event (computing);experiment;general-purpose modeling;m2m (eclipse);middleware;model-driven architecture;model-driven engineering;programming language;programming paradigm;proxy server;quality of service;real-time clock;real-time operating system;real-time transcription;reference implementation;requirement;robot;robotics;sms language;scalability;software deployment;software system	Adrián Romero-Garcés;Luis Manso;Marco Antonio Gutierrez;Ramón Cintas;Pablo Bustos	2013	CoRR		simulation;computer science;systems engineering;engineering;artificial intelligence	Robotics	-51.0848277041994	23.955716926999983	68836
85a000466825476f6a6570aefb579cf448e90bfe	extracting and representing cross-language dependencies in diverse software systems	application development;program diagnostics;new technology;language use;program diagnostics software engineering reverse engineering java c language scheme;programming language;software systems;java native interface;graph exchange language cross language dependency diverse software system multilanguage software system reverse engineering tool programming language heterogeneous software system source navigator extractor jni dependency java native interface c c code unified schema gxl format;software engineering;c language;software systems reverse engineering navigation computer languages java application software displays software libraries tin scalability;scheme;reverse engineering;java	This paper presents an approach for dealing with multi-language software systems. Much of the focus of reverse engineering tools is in analyzing software systems written in one programming language. Nowadays, the abundance of new technologies and languages used to ease application development raises new challenges for reverse engineers. Therefore, this paper focuses on finding cross-language dependencies in such diverse, heterogeneous software systems. Our approach uses source navigator extractors to produce the facts inside each language. Then, we show an example for finding Java Native Interface (JNI) dependencies between facts from Java and C/C++ code. The integrated facts are produced in GXL form, and conform to a unified schema introduced in the paper. This approach is useful from several perspectives. It illustrates how to retrieve the dependencies from software systems written in more than one programming language. Also, the generated facts conform to the GXL format, which is accepted by many reverse engineering tools. The usefulness and scalability of the approach are tested in a case study.	c++;correctness (computer science);finite-state machine;gxl;java;javascript;markup language;object language;perl;programming language;reverse engineering;scalability;scripting language;sensor;software system;tcl	Daniel L. Moise;Kenny Wong	2005	12th Working Conference on Reverse Engineering (WCRE'05)	10.1109/WCRE.2005.19	software distribution;software visualization;interface description language;verification and validation;computing;scheme;application programming interface;computer science;package development process;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;operating system;software engineering;software construction;computer programming;database;real time java;programming language;resource-oriented architecture;java;rapid application development;computer-aided software engineering;software development process;reverse engineering;software system	SE	-52.25673126666178	31.508806528601145	68959
39a23c9478029190306cecfa7ff65a0df1360527	constructing evolvable enterprise implementations		Contemporary organizations are operating in increasingly volatile environments. Hence, organizations must be agile in order to be able to quickly adapt to changes in its environment. This may be a complex process, since a change to one organizational unit may affect other units. Given the increasing complexity of organizations, it has been argued that organizations should be purposefully designed. Enterprise architecture frameworks provide guidance for the design of organizational structures. Unfortunately, current enterprise architecture frameworks have a descriptive, rather than a prescriptive nature and do not seem to have a strong theoretical foundation. In software engineering literature, the Normalized Systems approach has recently been proposed to provide such deterministic design principles for the modular structure of software. The Normalized Systems approach is based on the systems theoretic concept of stability to ensure the evolvability of information systems. In our PhD research, we explore the feasibility of extending the Normalized Systems design principles to the field of enterprise architecture. Our results show that such approach is feasible and illustrate how the systems theoretic concept of stability can be used on the organizational level.	agile software development;enterprise architecture framework;information system;organizational unit (computing);software engineering;systems design;theory	Philip Huysmans	2010			computer science;implementation;computer engineering	SE	-61.58188002613758	19.24180149580368	69019
71d04492be3c2abf9e1a88b9b263193a5c51eff1	towards a framework for program understanding	program understanding;cognitive systems;attribute hierarchy program understanding framework reverse engineering tools canonical activities descriptive model support mechanism features;conceptual framework;computer aided software engineering;reverse engineering software engineering software maintenance programming profession cognition relational databases;classification framework;tools and techniques;cognitive systems reverse engineering computer aided software engineering;reverse engineering	This paper describes an initial conceptual framework for the classi cation of reverse engineering tools and techniques that aid program understanding. It is based on a description of the canonical activities that are characteristic of the reverse engineering process. A descriptive model is presented that categorizes important support mechanism features based on a hierarchy	categorization;code refactoring;experiment;legacy system;mit engineering systems division;population;program comprehension;reverse engineering;software engineering;software evolution;software system;theme (computing)	Scott R. Tilley;Dennis B. Smith;Santanu Paul	1996		10.1109/WPC.1996.501117	computing;software engineering process group;system of systems engineering;computer science;systems engineering;engineering;knowledge management;social software engineering;operating system;software engineering;conceptual framework;requirements engineering;computer-aided software engineering;reverse engineering	SE	-51.34876547483694	28.62127509442876	69032
c79ee5065e33b6bc67d94a9de63d860d8d7bc55b	visualisation for informed decision making; from code to components	web engineering;web information systems;web applications;system integration;software component;source code	The problem of trying to view and comprehend large amounts of data is a well-known one. A specialised variant of this problem is the visualisation of software code and components for the purposes of understanding, decision-making, reuse and even integration. In particular the visualisation of software components, at a much higher level than source code, has received very little research. Visualisation is a powerful tool in situations such as this. This paper presents the application of real world metaphor based visualisations that address this problem. The application of visualisation to selecting software components is especially novel. It seeks to decrease the effort required by system integrators when locating suitable components in what is an increasingly crowded marketplace. Accurate information and understanding are vital if correct and informed decisions and judgements are to be made.	component-based software engineering;scientific visualization	Stuart M. Charters;Claire Knight;Nigel Thomas;Malcolm Munro	2002		10.1145/568760.568891	web application;computer science;systems engineering;component-based software engineering;software construction;data mining;web engineering;programming language;world wide web;system integration;source code	SE	-60.42034302545501	24.155586174266244	69392
397126ac26933ae80982d5c5b153d3afea23773e	reflection and reification in process system evolution: experience and opportunity	gestion integrada;developpement logiciel;gestion integree;long period;processus metier;integrated management;reflexion;hypercode;conference item;system evolution;desarrollo logicial;software development;hyperprogrammation;process model;reflection;business process;qa76 computer software	Process systems aim to support many people involved in many processes over a long period of time. They provide facilities for storing and manipulating processes in both the representation and enactment domains. This paper argues that process systems should support ongoing transformations between these domains, at any level of granularity. The notion of creating a enactment model instance from a representation is merely one restricted transformation. Especially when process evolution is considered the case for thinking in terms of model instances is weak. This argument is supported by our experience of the ProcessWeb process system facilities for developing and evolving process models. The idea of hypercode, which supports very general transformations between representation and enactment domains, is described. This offers the prospect of further improvements in this area.	process architecture	R. Mark Greenwood;Dharini Balasubramaniam;Graham N. C. Kirby;Kenneth R. Mayes;Ronald Morrison;Wykeen Seet;Brian Warboys;Evangelos Zirintsis	2001		10.1007/3-540-45752-6_3	reflection;artificial intelligence;software development;process modeling;business process	AI	-56.4903171532634	19.229853885029655	69465
21de84705552832f297e1d431b1240b84d3cf9e9	five considerations for software architecture, part 1	software architecture;symmetry;emergence;software architecture;software design;symmetry;architecture;emergence;software;software engineering;symmetry	Many software architectures suffer from unnecessary, accidental complexity: arbitrary flexibility for its own sake, unnecessary features, design choices whose complexity is out of proportion for the problems and requirements at hand, or a focus on reusability rather than usability.The XDD family of approaches- in particular, test-driven, responsibility driven, and domain-driven design and development set the architect's focus on what to design, identifying usable architecture concepts more naturally.	domain-driven design;error-tolerant design;no silver bullet;requirement;software architecture;usability	Frank Buschmann;Kevlin Henney	2010	IEEE Software	10.1109/MS.2010.98	software architecture;programming;computer architecture;computer science;systems engineering;software design;software development;architecture;software engineering;symmetry;programming language;management;emergence;pragmatics	SE	-53.90764365098525	28.062498962810547	69492
da0cff142631d7601d9fac7f7fbe990762be6bda	s-theory: a unified theory of multi-paradigm software development	m-theory;multi-paradigm programming;s-theory	Many problems facing software engineers demand 'optimal' performance in multiple dimensions, such as computational overhead and development overhead. For these complex problems, designing an optimal solution based upon a single programming paradigm is not feasible. A more appropriate solution is to create a solution framework that embraces multiple programming paradigms, each of which is optimal for a well-defined region of the problem space. This paper proposes a theory for creating multi-paradigm software solutions that is inspired by two contributions from theoretical physics: model dependent realism and M-Theory. The proposed theoretical framework, which we call 'S-Theory', promotes the creation of actor-optimal solution frameworks, encourages technology reuse and identifies promising research directions. We use the field of sensor networks as a running example. © 2013 Springer-Verlag.	programming paradigm;software development	Danny Hughes;Nelly Bencomo;Brice Morin;Christophe Huygens;Zhun Shen;Ka Lok Man	2013		10.1007/978-3-642-38027-3_78	object-oriented analysis and design;essential unified process;design process;openup;unified process;software design;social software engineering;software development;software design description;iterative and incremental development;software construction;rational unified process;goal-driven software development process;software development process;use case points	SE	-53.92806662487148	28.16454329609522	69516
cfabb2926cfac4a22ed66e99f2d7434e41b0cbba	airplane system design for reliability and quality		Two important subjects in the airplane & system development lifecycle are addressed. The first subject is the allocation of reliability and maintainability (R&M) requirements to components from airplane and system effectiveness metrics. The second is the determination of requirements for the quality sampling plan for components, a key process in the quality system. Systematic methodology for deriving R&M requirements for components given multiple airplane effectiveness metrics are presented. Given component reliability requirements a method is presented to derive the quality level needed for component manufacturing to ensure the reliability requirements are realized in the field. Together the methodologies presented here enable an integrated and rigorous airplane and system development process following best system engineering practice.	allocation;fits;muscle rigidity;requirement;sampling (signal processing);seizures;systems design;systems engineering;trusted platform module;topiramate	Anapathur V. Ramesh;S. Mahender Reddy;Dan K. Fitzsimmons	2018	2018 IEEE International Reliability Physics Symposium (IRPS)	10.1109/IRPS.2018.8353564	electronic engineering;maintainability;reliability engineering;systems design;airplane;engineering;quality management system;systems development life cycle	Embedded	-61.148314312813994	24.914102271532723	69628
4075ea5d585adc8f9e570eb39875da086ba0f1dc	tool support for collaborative software prototyping	reconfiguration;groupware;formal specification;tool support;software prototyping;collaborative software prototyping;reconfiguration based prototyping;user feedback;groupware software prototyping software tools formal specification;tool support collaborative software prototyping firm specifications reconfiguration development environment reconfiguration based prototyping software behavior user feedback subject matter specialists;software behavior;development environment;collaborative software software prototyping prototypes testing computer science educational institutions refining computer errors feedback gerontology;software component;subject matter specialists;software tools;firm specifications;technical report	Prototyping is a means by which requirements for software projects can be deened and reened before they are committed to rm speciications for the nished software product. By this process, costly and time-consuming errors in speciication can be avoided or minimized. Reconnguration is the concept of altering the program code, bindings between program modules , or logical or physical distribution of software components while allowing the continuing execution of the software being changed. Combining these two notions suggests the potential for a development environment where requirements can be quickly and dynamically evolved. This paper discusses reconnguration-based prototyping (RBP), that is, the simultaneous consideration of requirements, software behavior and user feedback within a running system in order to derive a clear speciication of an intended product. Tools enabling RBP can coordinate the eeorts of designers, prototypers, users and subject matter specialists as they work towards concensus on an application's speciication by means of a prototype. The authors describe the scope of the modiications that can be eeected by an integration of prototyping and reconnguration protocols , and they then demonstrate that the technology exists to create such an environment. They conclude by describing a software development environment based on RBP.	algorithm;collaborative software;component-based software engineering;integrated development environment;language binding;naruto shippuden: clash of ninja revolution 3;prototype;requirement;software developer;software development;software prototyping;steady state;subject matter expert turing test;taxonomy (general)	Elliot A. Shefrin;James M. Purtilo	1995		10.1109/ENABL.1995.484545	requirements analysis;software requirements specification;verification and validation;software quality management;computer science;technical report;package development process;software design;control reconfiguration;software framework;component-based software engineering;software development;software design description;requirement;operating system;software engineering;software construction;formal specification;database;distributed computing;development environment;software walkthrough;programming language;software requirements	SE	-53.54722383744025	27.999388631746072	69633
4a2e83db5fa270aaae377ef87b23fb143e97b7c7	model-based approaches for validating business critical systems	distributed system;model based approach;program verification;development process;software engineering;production process;formal method;modelling framework;critical system;model checking;program testing;agile methodologies;safety critical software;model based testing;model test;synchronous communication;work in progress;program testing program verification safety critical software;conferences;software development model based approaches business critical system validation model coevolution coevolution prototypes promela spin b prob atellerb model based testing trace driven model checking;product development	Developing a business critical system can involve considerable difficulties. This paper describes part of a new methodology that tackles this problem using co-evolution of models and prototypes to strengthen the relationship between modelling and testing. We illustrate how different modelling frameworks, Promela/SPIN and B/ProB/AtellerB, can be used to implement this idea. As a way to reinforce integration between modelling and testing we use model-based tests and trace-driven model checking. As a result we were able to anticipate problems and guide the development of our software in a safer way, increasing our understanding of the system and its reliability.	critical system;model checking;promela;spin	Juan Carlos Augusto;Yvonne Howard;Andrew M. Gravell;Carla Ferreira;Stefan Gruner;Michael Leuschel	2003	Eleventh Annual International Workshop on Software Technology and Engineering Practice	10.1109/STEP.2003.19	reliability engineering;simulation;computer science;systems engineering	SE	-58.64287768518241	26.331855932175557	69709
18c0b96bb5c2e4801fb2097a0945f69c254f5d01	considerations for a requirements engineering process model for the development of systems of systems	systems of systems requirements engineering process process model;analytical models;systems engineering interconnected systems systems analysis;object oriented model;complexity theory;interconnected systems;systems engineering;system of systems;systems of systems;context model;systems analysis;rapid evolution;requirements engineering process;requirement engineering;distributed systems requirement engineering process model system of system development interconnected systems networked systems;analytical models adaptation models object oriented modeling complexity theory context modeling conferences;system development;process model;networked systems;adaptation models;context modeling;object oriented modeling;analytical model;conferences	The complexities associated with managing requirements for building systems within systems, interconnected and networked systems, and systems communicating with each other across many distributed types of environments has long since been recognized. However, dealing with the process of requirements engineering for these types of systems is still a serious concern for most complex projects, given the various types of system development paradigms that are carried out today, and the rapid evolution of requirements at various phases of the project. In order to obtain optimal requirements that reflect the characteristics of and constraints imposed by systems of systems, there needs to be an appropriate requirements engineering process in place. In this paper, the authors present several considerations for an ideal, generic requirements engineering process model that would be helpful in guiding the requirements engineering process for the development of systems of systems.	process modeling;requirement;requirements engineering;system of systems	Deepti Savio;P. C. Anitha;Parameshwar P. Iyer	2011	2011 Workshop on Requirements Engineering for Systems, Services and Systems-of-Systems	10.1109/RESS.2011.6043922	control engineering;reliability engineering;requirements analysis;requirements management;performance engineering;business requirements;system of systems;system of systems engineering;systems engineering;engineering;requirement;needs analysis;system requirements specification;functional specification;requirements engineering;non-functional testing;systems development life cycle;non-functional requirement;requirements traceability;systems design	SE	-60.818509224471086	19.403402561310628	69854
bbcf536b01c0ce934dda5c4bb9ec57fec60328db	focused inspections to support defect detection in automation systems engineering environments	tool support;automation systems engineering environments;inspection;feasibility study;defect detection	[Context] In Automation Systems Engineering (ASE) Environments, engineers coming from different disciplines, have to collaborate. Individual engineers, e.g., from electrical, mechanical, or software domains, apply domain-specific tools and related data models that hinder efficient collaboration due to limited capabilities for interaction and data exchange on technical and semantic level. Manual activities are required to synchronize planning data from different disciplines and can raise additional risks caused by defects and/or changes that cannot be identified efficiently. [Objective] Main objective is to improve (a) engineering processes by providing efficient data exchange mechanism and to support (b) defect detection performance in ASE environments. [Method] Software inspection (SI) and software reviews (SR) are commonly used by engineers in Software Engineering by applying welldefined approaches to systematically identify defects early in the development process. In this paper we adapt the traditional SI process for application in ASE environments and provide a software tool to support frequent synchronization and focused reviews. We evaluate and discuss the adapted process in an industry context at a large-scale system integration provider in the hydro power plant domain. [Results] Main results were that the adapted process and the software tool can be useful in the application context, i.e., the ASE domain, in order to identify defects early, increase overall product quality, and improve engineering processes in the ASE domain. [Conclusion] The proposed adapted inspection approach aligned with the software tool showed promising results to improve engineering projects in the ASE domain.	adaptive server enterprise;automation;context (computing);data model;domain-specific language;emoticon;programming tool;software bug;software engineering;software inspection;software review;system integration;systems engineering	Dietmar Winkler;Stefan Biffl	2015		10.1007/978-3-319-26844-6_27	reliability engineering;feasibility study;inspection;economics;systems engineering;engineering;software engineering;management;engineering drawing	SE	-61.11153080148428	24.51448224404131	69910
0114962a02c206ca497743c29bf4a80de46e552f	supporting service design decisions	soaml service design design decision support;surveillance;service orientation;surveillance system;service design decision;development process;design decision;soaml;software architecture;personnel;web services software architecture;support;unified modeling language;web services;service design;service oriented surveillance system;couplings;service oriented architecture;context;service oriented surveillance system service design decision service oriented architecture;surveillance couplings service oriented architecture unified modeling language context personnel	In the context of service-oriented architectures, services are expected to fulfill certain service characteristics, such as loose coupling or high autonomy. When designing new services, several decisions have to be made, such as how to group capabilities into services, that influence these characteristics. Existing development processes focus on the description of necessary steps to create services and do not explicitly describe detailed design decisions and their impact on the service characteristics. In this paper, an approach is introduced to determine this impact in order to support the design decisions. The approach is applied to design services of a service-oriented surveillance system with comprehensible service characteristics.	loose coupling;service-oriented architecture;service-oriented device architecture	Michael Gebhart;Marc Baumgartner;Sebastian Abeck	2010	2010 Fifth International Conference on Software Engineering Advances	10.1109/ICSEA.2010.19	web service;unified modeling language;software architecture;simulation;support;differentiated service;computer science;systems engineering;engineering;knowledge management;service delivery framework;software engineering;service-oriented architecture;service design;services computing;coupling;software development process	SE	-57.49426981313418	19.16305748235769	69916
9c3fad4663f224bf78e08d00f09e32b49bec9c70	rapid prototyping of web applications combining domain specific languages and model driven design	hypermedia authoring;rapid prototyping;model based designs;domain specific language;model based design	There have been several authoring methods proposed in the literature that are model based, essentially following the Model Driven Design philosophy. While useful, such methods need an effective way to allow the application designer to somehow synthesize the actual running application from the specification. In this paper, we describe HyperDE, an environment that combines Model Driven Design and Domain Specific Languages to enable rapid prototyping of Web applications.	domain-specific language;model-driven engineering;rapid prototyping;web application	Demetrius Arraes Nunes;Daniel Schwabe	2006		10.1145/1135777.1135929	simulation;human–computer interaction;computer science;domain-specific language;programming language;model-based design	SE	-48.62416650093818	23.978424145883178	69969
0ce31d8d9e09f2e40235e414782c89b15bfe2ac8	a retrospective on user interface development technology	user interface development;object oriented methods;mobile user interfaces;user interface management systems object oriented methods;model driven approach user interface development technology ui development technology form oriented framework template based framework object oriented framework declarative framework;web user interfaces;user interfaces software development xml java mobile communication;software development;ui development;mobile communication;xml;mobile user interfaces user interface development ui development web user interfaces;user interface management systems;user interfaces;java	The authors present a brief survey on the evolution of user interface (UI) development technology, especially over the past two decades, shaped by the desktop, Web, and mobile eras. From the technology mainstream, the authors describe form-oriented, template-based, object-oriented, hybrid, and declarative frameworks and address model-driven and generic approaches. The focus of this article is on a framework of UI development concerns and how these have been addressed in each analyzed technology or group of technologies. At the end, the authors summarize current issues and future directions of UI development in general.	desktop computer;model-driven integration;user interface	Zarko Mijailovic;Dragan Milicev	2013	IEEE Software	10.1109/MS.2013.45	user interface design;user;xml;user modeling;mobile telephony;interface metaphor;shell;human–computer interaction;natural language user interface;computer science;software development;composite ui application block;database;natural user interface;programming language;interactivity;model–view–controller;user interface;java;world wide web	SE	-48.36083329309204	21.229637386649067	70023
a54fa5b2911c64b6b1b247bdc25b4a8bb7d06dac	resolving linkage anomalies in extracted software system models	database system;linking heuristics;system modeling;database management systems;couplings software systems joining processes database systems computer science computer architecture conferences;software systems;software engineering;programming model;linkage anomalies;computer architecture;levels of abstraction;program extraction linkage anomalies software system models program model linking linkage resolution linking heuristics software build processing postgresql database system;database systems;postgresql database system;joining processes;software system models;database management systems software engineering;program extraction;software build processing;computer science;program model linking;couplings;linkage resolution;conferences	Program model linking has been largely overlooked and not constrained properly in the extraction of software system models. This often results in inaccurate system models at different levels of abstraction even if programs can be extracted correctly. This paper describes two constrained approaches toward accurate linkage resolution. The first approach is purely based on a set of linking heuristics. The second approach leverages the software build process and also utilizes linking heuristics. We compare these two approaches and discuss their benefits and limitations. The empirical results from a case study of the PostgreSQL database system are also presented. Our study shows that inappropriate linkage resolution leads to a relatively large number of dependency anomalies at higher levels of abstraction. These anomalies can be effectively removed using our proposed approaches.	database;heuristic (computer science);linkage (software);postgresql;principle of abstraction;simulation;software build;software system	Jingwei Wu;Richard C. Holt	2004	Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004.	10.1109/WPC.2004.1311067	systems modeling;computer science;systems engineering;software engineering;data mining;database;programming paradigm;coupling;software system	SE	-55.68930995766327	30.476694608962895	70302
f09c281729ca6c96465b45b0d5aa6b8fbcc0fc2c	a comparative study of conceptual data modeling techniques	conceptual data model	This paper compares conceptual data models including extended entity relationship (EER), semantic object model (SOM), object role modeling (ORM), and object modeling technique (OMT) in terms of model correctness, modeling time, and perceived ease-of-use. For an empirical study, 28 graduates and 72 undergraduates were selected and then divided into four equally sized groups. Each group was trained with one data modeling technique. Two cases were used; one was prepared in natural language and the other in enterprise form. The study results show some differences among the four conceptual data modeling techniques. These positive findings may help modelers better understand modeling techniques.	data modeling	Heeseok Lee;Byounggu Choi	1998	J. Database Manag.	10.4018/jdm.1998040103	idef1x;data modeling;conceptual model;simulation;data model;computer science;conceptual schema;artificial intelligence;conceptual model;data mining;database	DB	-60.24269394811935	29.544610936832697	70422
3357b4e17b4d703a5e8f7a04c1606510c405f45d	evolving and composing frameworks with aspects: the mobigrid case	large scale reuse;computer architecture large scale systems application software java software systems pattern analysis stability analysis encapsulation software architecture;quantitative stability mobigrid software frameworks large scale reuse recurring concerns core architecture implementation aspect oriented programming software evolvability oo code mobility framework feature extensions;object oriented programming;software frameworks;large scale;code mobility framework;oo;aspect oriented programming;software reusability;quantitative stability;software framework;code mobility;core architecture implementation;software evolvability;recurring concerns;mobigrid;software reusability object oriented programming;feature extensions	Software frameworks enable modular, large-scale reuse by both providing a core architecture addressing recurring concerns in a certain domain and a set of variability options. However, the high volatility of requirements nowadays often imposes a number of framework changes with an architecture-wide impact. In order to avoid the framework design erosion, the modularity and stability of its core architecture implementation must be preserved. With aspect-oriented programming (AOP) promising superior software evolvability, there is a need for verifying its efficacy to enhance or not framework architecture stability. This paper presents a systematic case study where we have compared the evolution of 00 and aspectual versions of a code mobility framework, called MobiGrid. Our analysis was driven by the application of heterogeneous evolutionary changes to MobiGrid, such as feature extensions and compositions with a second framework. Our analysis is also rooted at a comprehensive suite of conventional quantitative stability and modularity indicators.	aspect-oriented programming;code mobility;heart rate variability;intel core (microarchitecture);requirement;software framework;verification and validation;volatility	Cidiane Lobato;Alessandro F. Garcia;Uirá Kulesza;Arndt von Staa;Carlos José Pereira de Lucena	2008	Seventh International Conference on Composition-Based Software Systems (ICCBSS 2008)	10.1109/ICCBSS.2008.27	reliability engineering;real-time computing;computer science;systems engineering	SE	-57.42644090443327	28.171829376098348	70430
dc0c0240c33ebfe88eca6c00ea0994c3b4f59d9d	integrating tools in the eti platform	eti online service { tool integration { integration platform;key words: eti online service – tool integration – integration platform	The ETI Online Service complements the STTT journal by providing an opportunity to experiment interactively via the World Wide Web with tools presented in STTT papers. A precondition to an advanced, cooperative usability of those tools is the integration of their functionalities into the ETI platform, which forms the basis for the ETI coordination environment. This paper gives an overview of the tool integration tasks, explains what has to be done for a tool’s integration, and examines some of the possible alternatives. Furthermore, a layered integration model is defined, on which a first integration scheme based on design patterns is proposed. Some criteria for tool integrability are also proposed, in the hope that, together with an improved automation of the integration process, large portions of the tool integration will be taken over by the tool providers themselves, or by integration teams, instead of the ETI Service management team itself as at present.	design pattern;interactivity;precondition;usability;world wide web	Volker Braun;Tiziana Margaria;Carsten Weise	1997	International Journal on Software Tools for Technology Transfer	10.1007/s100090050004	precondition;automation;real-time computing;computer science;software design pattern;usability;service management	DB	-49.446853117943725	21.844873810267543	70431
550879723c19ffff871274fe80f4ebd228f38293	a novel approach toward object-oriented knowledge-based software integration within a case framework	object oriented;software integration		system integration	Donovan Hsieh;Fred M. Gilham	1994	JOOP		software design description;database;component-based software engineering;software framework;artificial intelligence systems integration;systems engineering;object-oriented design;software construction;resource-oriented architecture;computer science;social software engineering	PL	-51.20735197617761	27.588216889062434	70452
886b5d0c38b3dc378a0c39f3cfcde5947104cee9	requirements and evaluation procedures for evoting	evoting systems;formal specification;certification;design engineering;procurement;software performance evaluation;system evaluation;formal verification;program testing;systems analysis;nominations and elections certification system testing electronic voting security artificial intelligence computer science design engineering procurement concrete;nominations and elections;systems analysis formal specification formal verification government data processing program testing software performance evaluation;system testing;artificial intelligence;computer science;security;electronic voting;government data processing;system evaluation electronic voting evoting systems certification;concrete	Only the most trivial computer system can be expected to meet its requirements if those requirements are not specified. Despite the widespread use of electronic voting (evoting), no requirements catalogue exists that expresses the requirements for evoting systems with enough precision to be checkable. Nor do existing catalogues take evaluation techniques and certification procedures into account. This paper takes the first step towards the development of a new catalogue with corresponding assessment procedures, concentrating on a strict subset of evoting systems	computer;requirement	Melanie Volkamer;Margaret McGaley	2007	The Second International Conference on Availability, Reliability and Security (ARES'07)	10.1109/ARES.2007.124	systems engineering;engineering;software engineering;computer security	SE	-57.20866570102808	29.025632299041597	70728
19b4dc40776c9c9a10e9c0ace13d130d4bbd5096	decoupling change from design	information hiding;static verification;software architecture;graph rewriting;coordination	"""Parnas' seminal 1972 paper, """"On the Criteria To Be Used in Decomposing Systems into Modules,"""" identified simplifying change as a critical criterion for modularizing software. Successful designs are those in which a change can be accommodated by modifying a single module. There is a tacit assumption in most of the literature that once a change has been limited to a single module, the cost of making the change is essentially inconsequential. But modules have complexity of their own and are frequently large. Thus, making a change can be expensive, even if limited to a single module.We present a method of decomposing modules into smaller components for the purpose of supporting change. Although similar to the approach of modularizing programs described by Parnas, our approach is specific to decomposing modules. It is not intended to replace traditional high level modularization but rather to augment it with a second level of modularization where the standard of information hiding can be relaxed. The goal of the method is to make modules easier to change by decomposing them around smaller design decisions---ideally encoding only one design choice per submodule component.In this paper we show how submodule components can be used to address the issue of change. We also demonstrate how the ability to address change with submodule components is, to a large extent, independent of the design level modularization. Moreover, we show that, at least in some cases, by using submodule components the choice of high level modularization can itself be changed without having to rewrite large amounts of code.A method of implementation is presented using inheritance, parameterization, and static binding in a way that minimizes implementation dependencies between components. The method supports fine grained decomposition with flexible composability and almost no runtime overhead."""	composability;coupling (computer programming);high-level programming language;level design;name binding;overhead (computing);rewrite (programming)	Michael VanHilst;David Notkin	1996		10.1145/239098.239109	software architecture;real-time computing;computer science;engineering;software engineering;distributed computing;programming language;information hiding;engineering drawing;graph rewriting	SE	-52.72540395704676	30.307494165466377	70794
8847d35889236ade94ee2c92f9bd79617b25d429	ai planner assisted test generation	system under test;test generation;high level test objectives;system test;ai planning	This paper describes an AI planner assisted approach to generate test cases for system testing based on high level test objectives. We use four levels of test generation: the metaprocessor, the preprocessor, the AI planner, and the postprocessor levels. Test generation is based on an extended UML model of the system under test and a mapping of high-level test objectives into initial and goal conditions of the planner. Test objectives are derived from a series of interviews with professional testers. We suggest various options for test criteria related to test objectives. The AI planner was used to generate hundreds of test cases for a robot controlled tape silo. The planner generated tests within a reasonable time. It was successful for each test objective given.	artificial intelligence;automated planning and scheduling;domain model;domain theory;expect;graphical user interface;grid mp;high- and low-level;high-level programming language;oracle (software testing);pollack's rule;precondition;preprocessor;recovery testing;silo;system testing;system under test;tape library;test automation;test case;test suite;turing test;unified modeling language	Anneliese Amschler Andrews;Chunhui Zhu;Michael Scheetz;Eric Dahlman;Adele E. Howe	2002	Software Quality Journal	10.1023/A:1021686406575	automated planning and scheduling;simulation;computer science;systems engineering;engineering;operations management;test suite;system under test;test script;system testing;test management approach	AI	-58.259744362960106	29.42815411889022	70847
12f73ad9332124c00cc11f9b73b5f38cd446be13	delta modeling in practice: a fredhopper case study	product line;structural typing;modeling language;software product line engineering;delta oriented programming;modeling methodology;variability;software product line;programming languages	Delta modeling is a method for modeling software product lines (SPL), which supports the automated derivation of products. ABS is a recent modeling language and accompanying toolset that implements delta modeling as its core paradigm for developing variable systems. Due to its novelty, delta modeling has so far seen little practical application. However, only practical evaluation can indicate to what extent the delta modeling methodology is suited for the efficient and accurate modeling and implementation of SPLs. This paper reports on the development of an industrial scale product line in ABS following a workflow that guides the application of delta modeling in practice. By following the delta modeling workflow (DMW), we show how conflicting feature functionality can be systematically reconciled, and how DMW guides the implementation towards a globally unambiguous and complete product line. We further explain how this experience has been used to refine the workflow and its support by the ABS language.	line level;modeling language;programming paradigm;software product line	Michiel Helvensteijn;Radu Muschevici;Peter Y. H. Wong	2012		10.1145/2110147.2110163	real-time computing;simulation;computer science;systems engineering;engineering;modeling language;programming language	SE	-54.41966712326142	25.73712727518859	70925
c6376f9808c982ce0e14b19aec71ac4f4e3fa623	e-cares project: understanding complex legacy telecommunication systems	e-cares project;complex legacy telecommunication systems;complex legacy telecommunication system;reengineering legacy system;business applications embedded system;business application;additional requirement;different characteristic;e-cares research project;legacy system;embedded system;telecommunication system;embedded systems;data visualisation;real time systems;reverse engineering;response time;software fault tolerance;reliability;structural complexity;reengineering;application software;fault tolerance;concurrent computing;telecommunications;legacy systems;availability;fault tolerant	"""There are many reasons for reverse engineering or reengineering legacy systems. To date, many approaches concerning re-engineering of legacy systems have been made. The majority of these approaches are dealing with systems in the field of business applications. This paper describes the work performed for the E-CARES project so far. This project is concerned with understanding and restructuring complex legacy telecommunication systems. In contrast to business applications embedded systems, e.g. telecommunication systems, have additional requirements regarding fault tolerance, reliability, availability, and response time. We found that these requirements have a significant impact on the software part of an embedded system. It has different characteristics concerning structuring, inter-program communication, etc. Therefore, an approach is presented that includes usage of """"dynamic"""" information, multilevel abstraction/visualization, and user interaction to improve the understanding of telecommunication systems."""		André Marburger;Dominikus Herzberg	2001		10.1109/.2001.914978	systems engineering;engineering	SE	-52.540412579168205	31.71713723579045	71118
3d4598910896e9c2994e440fc1eeb31aff72c496	e-cares - telecommunication re- and reverse engineering tools	user interface;software systems;graph rewriting;reverse engineering;dynamic behavior	The E-CARES project addresses the reengineering of large and complex telecommunication systems. Within this project, graph- based reengineering tools are being developed which support not only the understanding of the static structure of the software system under study. In addition, they support the analysis and visualization of its dynamic behavior. The E-CARES prototype is based on a programmed graph rewriting system from which the underlying application logic is generated. Furthermore, it makes use of a configurable framework for building the user interface. In this demo, we show by example how the different tools within the prototype work and how the analysis results are represented to the user.	reverse engineering	André Marburger;Bernhard Westfechtel	2003		10.1007/978-3-540-25959-6_34	computer science;systems engineering;theoretical computer science;computer engineering	DB	-50.17675451102541	29.129069427423858	71192
e47eaadf22a308224c2c4e4e4d1beb479542d853	towards a theory of collaborative multimedia	groupware;theoretical model;multiple nodes collaborative multimedia media objects optimal algorithms collaborative media object synthesis software quality image size;software quality groupware multimedia computing;multimedia systems;multimedia computing;collaboration multimedia systems page description languages computer science educational institutions data structures contracts displays costs;optimal algorithm;software quality	We develop a theory of media objects, and present optimal algorithms for collaborative object synthesis for constructing multimedia documents by composing together a given set of media objects. We then extend the algorithms to incorporate quality constraints (such as image size) as well as distribution across multiple nodes. The theoretical model is validated by an experimental implementation that supports the theoretical results.	algorithm;image resolution;media object server;theory	K. Selçuk Candan;V. S. Subrahmanian;P. Venkat Rangan	1996		10.1109/MMCS.1996.534987	computer science;theoretical computer science;distributed computing;multimedia;world wide web;software quality	DB	-49.907052798617464	18.896328279048383	71204
1575e4ae33aefaccd8c8b5958f6c3ccfe707cc42	into the moana1 — hypergraph-based network layer indirection	internet;graph theory;moana network infrastructure;hypergraph-based network layer indirection;incremental architectural evolution;information-sharing service;network layer abstraction	In this paper, we introduce the Moana network infrastructure. It draws on well-adopted practices from the database and software engineering communities to provide a robust and expressive information-sharing service using hypergraph-based network indirection. Our proposal is twofold. First, we argue for the need for additional layers of indirection used in modern information systems to bring the network layer abstraction closer to the developer's world, allowing for expressiveness and flexibility in the creation of future services. Second, we present a modular and extensible design of the network fabric to support incremental architectural evolution and innovation, as well as its initial evaluation.	database;indirection;information system;software engineering	Yan Shvartzshnaider;Maximilian Ott;Olivier Mehani;Deborah Levy	2013	2013 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2013.6562894		DB	-48.345448162945715	19.635445557008225	71262
32bcfebdf74ec1f666b68ae86840e9ff07f67e5e	uml 2.0 - overview and perspectives in soc design	hardware software codesign;hardware software codesign unified modeling language system on chip;uml 2 0;application software;unified modeling language design methodology object oriented modeling hardware productivity software systems packaging software standards application software systems engineering and theory;software systems;packaging;software engineering;modeling language;hardware software codesign uml 2 0 soc design general purpose modeling language;systems engineering and theory;soc design;design method;system on chip;unified modeling language;general purpose modeling language;software standards;productivity;object oriented modeling;hardware;design methodology	The design productivity gap requires more efficient design methods. Software systems have faced the same challenge and seem to have mastered it with the introduction of more abstract design methods. The UML has become the standard for software systems modeling and thus the foundation of new design methods. Although the UML is defined as a general purpose modeling language, its application to hardware and hardware/software codesign is very limited. In order to successfully apply the UML at these fields, it is essential to understand its capabilities and to map it to a new domain.	general-purpose modeling;software system;system on a chip;systems modeling;unified modeling language	Tim Schattkowsky	2005	Design, Automation and Test in Europe	10.1109/DATE.2005.320	computer architecture;design methods;systems modeling language;uml tool;computer science;engineering;software engineering;applications of uml;shlaer–mellor method;programming language;node;computer engineering	EDA	-48.909714547834746	31.604797831745348	71425
050a74188128ee51cac77c10eeb9f5ba48789015	a document-process association model for workflow management	workflow management;formal model;software systems;form document;xml;workflow;workflow management system;document processing;business process	A WorkFlow Management System (WFMS) is a software system to support an automatic, efficient execution of business processes. A business process often involves document processing. Although, many traditional WFMSs can support the document processing to some extent, they are concerned mainly with document delivery. We propose an XML-based approach to WFMS for form document processing on the Web. Taking advantage of XML, we can partition a document into several meaningful segments, each of which in this approach becomes a unit of work that can be performed by some activities in a workflow process. Based on this document partition, we develop a formal model, called document-process association model, which can associate the units of work with process activities. The model not only provides a tight control over document-related processes, but it also enables various useful services, such as customization of document monitoring and contents-based interaction between WFMS and other application programs. A prototype system has been implemented to demonstrate the usefulness of the proposed model.		Hyerim Bae;Yeongho Kim	2002	Computers in Industry	10.1016/S0166-3615(01)00150-6	well-formed document;document engineering;workflow;xpdl;computer science;knowledge management;business process management;document management system;database;management;world wide web;workflow management system;workflow engine;vision document;design document listing;workflow technology	DB	-52.845663263615535	19.309810455201212	71612
a86a22cd8920bcfbf8747a91a8f906ef484f95e9	object oriented design and programming: a case study	object oriented design			Craig Malone	1992			object-oriented design;method;object definition language;programming language;object (computer science);computer science	HCI	-50.35915206786533	27.724761100463088	71641
3dce0635756637f5ad8afe3894b6aafd9afe2d8c	model-driven development	method engineering;human computer interaction;task model;software systems;model transformation;software development process;model driven development;software development;model management;model driven architecture	The model-driven architecture (MDA) paradigm is well-known and widely used in the field of model-based software development. However, there are still some issues that are problematic and that need to be dealt with carefully. In this paper we present a metaphor that explains how MDA grows in complexity as problems faced become more difficult or “wicked”, and how a method designed to be powerful, flexible and MDA-compliant can eventually become, in effect, a “jigsaw puzzle”. This jigsaw puzzle is not merely the result of having a collection of methodological “pieces” with routes across them, but also arises as a result of the criteria underlying the MDA abstraction layers. We compare MDA to other research fields such as human-computer interaction, model management and method engineering, and we use as an example the OO-Method, a software development method based on MDA-compliant model transformations. We focus on a methodological piece that is conceived to allow the specification of interaction requirements by means of interface sketches. These sketches are supported by a task model that serves as a sound basis for formalisation and allows the application of model transformation in order to obtain subsequent models. A case study illustrates the requirements capture method together with the software development process defined by the OO-Method. The whole process presented in the case study represents one of the possible routes that can be followed when developing a software system with the OO-Method.	formal system;horner's method;human–computer interaction;method engineering;model transformation;model-driven architecture;model-driven engineering;programming paradigm;requirement;software development process;software system;wicked	Oscar Pastor;Sergio España;José Ignacio Panach;Nathalie Aquino	2008	Informatik-Spektrum	10.1007/s00287-008-0275-8	method engineering;simulation;computer science;systems engineering;engineering;artificial intelligence;software development;software design description;v-model;software engineering;software construction;database;programming language;resource-oriented architecture;world wide web;goal-driven software development process;software development process;software metric;software system	SE	-51.01001761366702	25.726562739420444	72230
98abfb1f429d5f6dc629728b9caf8f74363538d0	supporting requirements in a traceability approach between business process and user interfaces	institutional repositories;fedora;user interface;user centered design;business process modeling;vital;requirements engineering;model driven engineering;vtls;business process;ils	This paper presents the impact of the traceability from Business Process (BP) to User Interfaces (UI) in software requirements. The application of changes made on BP or on system UIs may have an impact on software requirements, which then requires updating related models in order to coherently enable changes. The goal of mapping software requirements with task models, as an extension to an existing traceability approach, is to guarantee that UIs are aligned with requirements. This paper proposes a traceability framework on how to map requirements with UI models and analyzes the impact of changes on models of business-driven enterprise applications. Author	business process;business requirements;enterprise software;model-driven architecture;openness;requirement;requirements engineering;software requirements;traceability;user experience;user interface	Kênia Soares Sousa;Hildeberto Mendonça Filho;Jean Vanderdonckt;Marcelo Soares Pimenta	2008		10.1145/1497470.1497505	requirements analysis;model-driven architecture;software requirements specification;user-centered design;requirements management;business requirements;computer science;requirement;requirements engineering;business process;user interface;management;world wide web;business process modeling;traceability matrix;requirements traceability	SE	-56.85894362200658	20.228358117702047	72273
b0785d97ed970afb5a555de76103d7247c6de33d	collaborative networked organizations as system of systems: a model-based engineering approach		It is admitted that there is parallel between a System of Systems (SoS) and Collaborative Networked Organizations (CNOs). SoS Engineering (SoSE) carefully focuses on choosing, assembling and interfacing existing systems to build the so-called SoS. In this context, and as demonstrated by the literature and the System Engineering domain, interoperability takes on its full meaning and has to be fully considered as a decisive factor when organizations set up a CNO. This paper proposes to 1) model the SoS through a meta- model that includes concepts which 2) enable interoperability modeling and the analysis of its impact on the SoS’ characteristics, stability, integrity, performance and behavior. The proposed analysis is based on a verification approach mixing simulation and formal proof techniques.	system of systems	Mustapha Bilal;Nicolas Daclin;Vincent Chapurlat	2014		10.1007/978-3-662-44745-1_22	system of systems engineering;systems engineering;knowledge management;distributed computing	SE	-54.8542403081867	22.304139410199134	72276
6ba1f4faab984163cbf163fe3ab2aa5b376d51a7	designing for software's social complexity	developpement logiciel;complexite;manuals;automobile manufacture;application software;formal methods software engineering;complejidad;systems analysis software engineering;formal methods;complexity;manufacturing industries;software engineering;journal article;formal method;conducta social;assembly;engines;systems analysis;social behavior;desarrollo logicial;software development;production;comportement social;information system;software design;software engineering software design social complexity;systeme information;vehicle dynamics;vehicle dynamics manuals assembly regulators design methodology application software manufacturing industries automobile manufacture production engines;regulators;social complexity;design methodology;sistema informacion	"""As the """"software crisis"""" persists, we must rethink our strategy for handling complexity. A decade ago, complexity was physiological. It is now intrinsically social. Designers need methods and techniques that address the difference"""	social complexity;software crisis	José Luiz Fiadeiro	2007	Computer	10.1109/MC.2007.16	social complexity;systems analysis;application software;complexity;vehicle dynamics;simulation;formal methods;design methods;social behavior;computer science;artificial intelligence;software design;software development;operating system;software engineering;assembly;manufacturing;management;computer security;information system	DB	-61.54640213637366	19.16315640948119	72444
23104afe488c045167652c48221e468c77e189eb	a model-based awareness approach for synchronous collaborative sessions on the web	distributed system;information oriented coordination model;session management;groupware;layered architecture;collaborative system design;xml adaptive systems groupware internet java;web;java 3d;data structuring;collaborative system;coordination in collaborative activities;model based awareness;internet;awareness tool development;coordination diagrams model based awareness synchronous collaborative sessions web awareness tool development information oriented coordination model adaptive layered architecture java language java 3d xml data structuring session management;synchronous collaboration;adaptive systems;coordination diagrams;xml;session awareness coordination in collaborative activities session management collaborative system design coordination diagrams;coordination model;distributed collaboration;adaptive layered architecture;data structure;session awareness;java language;synchronous collaborative sessions;java;collaboration collaborative work collaborative tools design engineering systems engineering and theory prototypes java xml computer networks informatics	Awareness describes the knowledge acquired by a member of a collaborative session about the activities of the other members of this session. This paper presents the main aspects of the development of an awareness tool based on an information-oriented coordination model for synchronous collaboration sessions. This tool is supported by an adaptive layered architecture which is based on collaborative extensions of Java language, Java 3D and XML possibilities in terms of data structuring. The application field is related to the execution of a project review for the distributed collaborative design, which is applied to a spatial-domain scenario from the European project DSE (distributed system engineering)	awareness;data structure;distributed computing;java 3d;systems engineering;world wide web;xml	Laura Margarita Rodríguez Peralta;A. M. Gonçalves Silva	2006	2006 Fourth Latin American Web Congress	10.1109/LA-WEB.2006.2	the internet;xml;data structure;computer science;knowledge management;multitier architecture;database;programming language;java;world wide web	SE	-49.59231604824464	19.452372116878394	72455
ebe34e617948527341398d27d1c6ed8d1160cc20	model-based product line engineering in an industrial automotive context: an exploratory case study		Product Line Engineering is an approach to reuse assets of complex systems by taking advantage of commonalities between product families. Reuse within complex systems usually means reuse of artifacts from different engineering domains such as mechanical, electronics and software engineering. Model-based systems engineering is becoming a standard for systems engineering and collaboration within different domains. This paper presents an exploratory case study on initial efforts of adopting Product Line Engineering practices within the model-based systems engineering process at Volvo Construction Equipment (Volvo CE), Sweden. We have used SysML to create overloaded models of the engine systems at Volvo CE. The variability within the engine systems was captured by using the Orthogonal Variability Modeling language. The case study has shown us that overloaded SysML models tend to become complex even on small scale systems, which in turn makes scalability of the approach a major challenge. For successful reuse and to, possibly, tackle scalability, it is necessary to have a database of reusable assets from which product variants can be derived.	complex systems;heart rate variability;model-based systems engineering;scalability;software engineering;spatial variability;systems modeling language	Damir Bilic;Daniel Sundmark;Wasif Afzal;Peter Wallin;Adnan Causevic;Kelsey MacDougall	2018		10.1145/3236405.3237200	computer science;control engineering;modeling language;domain engineering;complex system;scalability;reuse;systems modeling language;systems engineering;model-based systems engineering;automotive industry	SE	-56.16113985299963	25.74138589614743	72506
6773694f65aaf4d9285ebcd90f028a57d29e839f	an approach to manage and customize variability in software processes	software;manuals;formal specification;software processes;electric breakdown;reuse;software adaptation model xml java computer architecture manuals electric breakdown;software product line reuse software process;computer architecture;eclipse process framework;adaptation model;xml;automatic handling;process specifications software processes automatic handling automatic derivation eclipse process framework;software product line;process specifications;software process;automatic derivation;java	This paper presents an approach to the management and customization of variabilities in software processes. It supports the automatic handling of variations occurring in process specifications, and promotes the automatic derivation of specific customizations of these processes. In order to validate and demonstrate the approach benefits and feasibility, the paper presents an implementation that allows the customization of processes specified in the Eclipse Process Framework (EPF).	automatic control;eclipse process framework;heart rate variability	Fellipe Araújo Aleixo;Marília Aranha Freire;Wanderson Câmara dos Santos;Uirá Kulesza	2010	2010 Brazilian Symposium on Software Engineering	10.1109/SBES.2010.18	computer science;systems engineering;software engineering;programming language	SE	-52.61446338886173	25.16030911683737	72515
54af524f267251d54dfd2eed2164af473e7ad8cd	advanced grid programming with components: a biometric identification case study	libraries;distributed application;school of no longer in use;electronics and computer science;fractals;software tool;biometrics access control;grid applications;java fractals programming libraries computational modeling engines skeleton;component based development;grid component model advanced grid programming biometric identification component oriented software development;grid component model;object oriented programming;skeleton;integrated development environment;computational modeling;engines;component oriented software development;component framework;software development;object oriented programming biometrics access control grid computing;distributed biometric identification grid component model grid integrated development environment gide;distributed biometric identification;advanced grid programming;biometric identification;grid computing;programming;business process;grid integrated development environment gide;java	Component-oriented software development has been attracting increasing attention for building complex distributed applications. A new infrastructure supporting this advanced concept is our prototype component framework based on the Grid component model. This paper provides an overview of the component framework and presents a case study where we utilise the component-oriented approach to develop a business process application for a biometric identification system. We then introduce the tools being developed as part of an integrated development environment to enable graphical component-based development of Grid applications. Finally, we report our initial findings and experiences of efficiently using the component framework and set of software tools.	biometrics;business process;code generation (compiler);component-based software engineering;debugging;distributed computing;google cloud messaging;graphical user interface;grid computing;integrated development environment;prototype;software development;software system	Thomas Weigold;Peter Buhler;Jeyarajan Thiyagalingam;Artie Basukoski;Vladimir Getov	2008	2008 32nd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2008.97	programming;real-time computing;simulation;fractal;computer science;theoretical computer science;component-based software engineering;software development;business process;programming language;object-oriented programming;java;computational model;skeleton;biometrics;grid computing	SE	-51.58150120159993	30.067889253660127	72581
10e601b1dfe29b6bdf530489ed411216e1016175	on formal specification of a proof tool	formal specification	Tools and methods for the specification and design of computer systems are increasing in sophistication. Much current research and development is attempting to exploit this sophistication to improve the effectiveness of systems development practices. It is becoming feasible to offer much higher assurance than hitherto that systems meet critical requirements, e.g. concerning safety or security. Standards such as [7] are evolving to demand the use of formal specification and verification of designs (and, one day, perhaps implementations). Thus, tools giving cost-effective means for providing formal proofs of critical requirements are of increasing importance. ICL Secure Systems, as part of its role as lead partner in the DTI-sponsored FST project, is attempting to improve the technology base for formal verification.	computer security;formal specification;formal verification;icl;requirement;software development process	Rob Arthan	1991		10.1007/3-540-54834-3_22	b-method;correctness;formal methods;object language;specification language;formal verification;computer science;z notation;formal specification;refinement;programming language;programming language specification;program derivation;language of temporal ordering specification	SE	-58.26018963371745	27.010722076380137	72771
e8907968ebcaffbf63df26a9568ab60772dae450	a top-down approach to construct execution views of a large software-intensive system	execution views;top down;software architecture;architecture reconstruction;execution architecture;architecture analysis;design;architecture;dynamic analysis	This paper presents an approach to construct execution views, which are views that describe what the software of a software-intensive system does at runtime and how it does it. The approach represents an architecture reconstruction solution based on a metamodel, a set of viewpoints, and a dynamic analysis technique. The metamodel and viewpoints capture the conventions that can be used to describe the runtime of a system developed by a particular organization. The dynamic analysis technique is used to extract and abstract runtime information from a combination of system logging and runtime measurements in a top-down fashion. The approach was developed and validated constructing execution views for a magnetic resonance imaging scanner developed by Philips Healthcare. Therefore, the approach represents a solution that can be applied at similar large and complex software-intensive systems. Copyright © 2011 John Wiley & Sons, Ltd.	john d. wiley;metamodeling;requirement;resonance;run time (program lifecycle phase);scalability;software architect;software system;top-down and bottom-up design	Trosky Boris Callo Arias;Pierre America;Paris Avgeriou	2013	Journal of Software: Evolution and Process	10.1002/smr.577	enterprise architecture framework;reference architecture;software architecture;design;real-time computing;simulation;system model;computer science;engineering;applications architecture;architecture;software engineering;solution architecture;runtime verification;systems architecture	SE	-53.100911708521906	25.54949307800625	72775
24a032c264052f97905407a4fd835bfe675ecd0d	architectural design patterns for flight software	space flight;space flight software software architectural design patterns distributed real time embedded software uml;architectural design;fsw architectural design patterns flight software software design patterns software architectures;distributed real time embedded;uml;flight software;best practice;architectural design patterns;computer architecture;software architecture;fsw;space flight software;aerospace computing;design pattern;unified modeling language;computer architecture space vehicles unified modeling language software architecture software design real time systems;software architecture design;software design pattern;software design;distributed real time;software architectures;software architecture aerospace computing;software architectural design patterns;space vehicles;embedded software;real time systems;software design patterns	Software design patterns are best practice solutions to common software design problems. When they are properly applied, software design patterns can greatly improve the quality of software architectures. However, applying design patterns in practice can be difficult since design pattern descriptions are domain and platform independent. Leveraging the benefits of design patterns is particularly important in the space flight software (FSW) domain because better designs are needed to help reduce the number of in flight software related anomalies. In order to address the aforementioned problems, this paper presents software architectural design patterns for space flight software. This paper describes how architectural design pattern templates can be used to build common features of FSW architectures. The FSW architectures produced can be validated for functional and performance correctness.	architectural pattern;best practice;correctness (computer science);embedded software;software architecture;software design pattern	Julie S. Fant;Hassan Gomaa;IV G. Pettit RobertG.Pettit	2011	2011 14th IEEE International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing Workshops	10.1109/ISORCW.2011.39	domain analysis;unified modeling language;software architecture;computer architecture;verification and validation;software design pattern;real-time computing;software sizing;behavioral pattern;architectural pattern;computer science;package development process;software design;social software engineering;software reliability testing;software framework;component-based software engineering;software development;software design description;software engineering;software construction;distributed design patterns;software walkthrough;resource-oriented architecture;structural pattern;software deployment	SE	-54.473144113175415	28.246025606110315	72844
5447e2d6de054b48a8199b686eb99fb6c6f42ec4	defining and transforming models of parkinson patients in the development of assisted-living multi-agent systems with ingenias		Some people suffer from the Parkinson disease and need as- sistance for living. Multi-agent Systems (MASs) can provide a suitable solution for their assistance. However, each patient has different circum- stances, symptoms and skills that need assistance. This paper presents a model-driven approach for developing MASs customized for each patient. The current approach presents a metamodel for modeling Parkinson pa- tients as models. In addition, this paper introduces a suite of model transformations that can transform a Parkinson patient model into an initial MAS model. This MAS model can be refined by designers and the programming code can be generated from this model. This approach ap- plies the INGENIAS methodology for generating the MAS from a design model. Finally, a case study is presented as a proof of concept.	ingenias	Iván García-Magariño	2013		10.1007/978-3-642-38061-7_43	simulation;engineering;artificial intelligence	AI	-51.297026005113516	23.18286160305956	72920
983a625886758921dfdb8f0bf21ec2c7ca1eb2ae	process-based derivation of requirements for medical devices	learning algorithms;learning algorithm;requirement specifications;medical processes;medical devices;satisfiability;model checking;medical device;process model;requirement specification	One goal of medical device certification is to show that a given medical device satisfies its requirements. The requirements that should be met by a device, however, depend on the medical processes in which the device is to be used. Such processes may be complex and, thus, critical requirements may be specified inaccurately or incompletely, or even missed altogether. We are investigating a requirement derivation approach that takes as input a model of the way the device is used in a particular medical process and a requirement that should be satisfied by that process. This approach tries to produce a derived requirement for the medical device that is sufficient to prevent any violations of the process requirement. Our approach combines a method for generating assumptions for assume-guarantee reasoning with one for interface synthesis to automate the derivation of the medical device requirements. The proposed approach performs the requirement derivation iteratively by employing a model checker and a learning algorithm. We implemented this approach and evaluated it by applying it to two small case studies. Our experiences showed that the proposed approach could be successfully applied to abstract models of portions of real-world medical processes and that the derived requirements of the medical devices appeared useful and understandable.	algorithm;model checking;requirement	Heather M. Conboy;George S. Avrunin;Lori A. Clarke	2010		10.1145/1882992.1883095	reliability engineering;computer science;systems engineering;theoretical computer science;non-functional requirement	SE	-54.94693657933793	21.4811442995113	72930
8e6c32e349659438b17525b8dc28c6eb6d2a8ccf	a tool to aid in the installation of complex software systems	software installation;software systems;portability;programming languages;file systems	Abstract#R##N##R##N#This paper describes a programming language, SIDL, in which various aspects of software installation can be modeled. SIDL supports hierarchical file systems, computers, and processes for executing programs to produce new programs and data. An example, illustrating the installation of Ratfor, and experience with the use of SIDL for describing the installation of a large software system are included.	software system	Ralph E. Griswold	1982	Softw., Pract. Exper.	10.1002/spe.4380120307	computer architecture;installation;computer science;software development;operating system;software engineering;programming language;software system	SE	-50.6698604384346	31.210344995887766	73033
8431a5cfaf2c07543bf112c3b26f191c7109b5c7	a tool chain for quality-driven software architecting	software;reliability engineering;unified modeling language formal specification object oriented programming ontologies artificial intelligence program testing software architecture software quality software reliability software tools;software testing;qpe;reliability;formal specification;articulo;a tool chain for quality driven software architecting;protege;object oriented programming;software engineering;stylebase;ontologies artificial intelligence;rap;computer architecture;software architecture;software reliability prediction;program testing;topcased uml tool;unified modeling language;software component;formal specification quality driven software architecture design software engineering stylebase protege qpe topcased uml tool rap software testing software component eclipse platform software reliability prediction software availability prediction componentbee ontology quality profile editor;componentbee;ontologies;software tools;reliability computer architecture software reliability software ontologies unified modeling language reliability engineering;software reliability;ontology;software availability prediction;software quality;eclipse platform;quality driven software architecture design;quality profile editor	The quality-driven architecture design and quality analysis (QADA) methodology uses quality requirements as a driving force when selecting software structures. In QADA, the family architecture contains qualitative quality requirements as architectural style(s) and patterns and the quantitative quality requirements as the properties of individual architectural elements. Our tool chain covers all the phases of QADA and contributes to software family engineering by providing methods to select an appropriate approach for family architecture (Stylebase), to capture and map requirements to the architecture (Protege, QPE, TOPCASED), to evaluate the maturity and quality of the architecture (Stylebase, RAP), a technique to represent variation points in the family architecture (QPE, TOPCASED), and a testing approach that can test final software components, ensure the achieved quality level, and produce feedback for the architect (ComponentBee). These tools work under the Eclipse platform and utilise free open source components.	capability maturity model;component-based software engineering;eclipse;open-source software;protégé;requirement;toolchain	Antti Evesti;Eila Niemelä;Katja Henttonen;Marko Palviainen	2008	2008 12th International Software Product Line Conference	10.1109/SPLC.2008.46	reliability engineering;reference architecture;software architecture;computer science;systems engineering;software engineering;ontology;software quality	SE	-56.4692429345175	28.428063406961755	73071
192f6314448ff270e0172a7e6ac7cd00256e3929	synthesizing data-centric models from business process models	uml;model transformation;68u31;68u01;case management;data centric bpm	Data-centric business process models couple data and control flow to specify flexible business processes. However, it can be difficult to predict the actual behavior of a data-centric model, since the global process is typically distributed over several data elements and possibly specified in a declarative way. We therefore envision a data-centric process modeling approach in which the default behavior of the process is first specified in a classical, imperative process notation, which is then transformed to a declarative, data-centric process model that can be further refined into a complete model. To support this vision, we define a semi-automated approach to synthesize an object-centric design from a business process model that specifies the flow of multiple stateful objects between activities. The object-centric design specifies in an imperative way the life cycles of the objects and the object interactions. Next, we define a mapping from an object-centric design to a declarative Guard-Stage-Milestone schema, which can be refined into a complete specification of a data-centric BPM system. The synthesis approach has been implemented and tested using a graph transformation tool.	business process;control flow;declarative programming;graph rewriting;imperative programming;interaction;process modeling;semiconductor industry;stateful firewall	Rik Eshuis;Pieter Van Gorp	2015	Computing	10.1007/s00607-015-0442-0	unified modeling language;real-time computing;computer science;artifact-centric business process model;business process management;process modeling;database;business process model and notation;business process discovery;business process modeling	SE	-55.025264944105075	18.84783230567694	73258
566fd2b0f46347c565ebe7c2a6e529bc56a38743	calculating with concepts: a technique for the development of business process support	business process support;software development process;uml class diagram;business process	This paper introduces the Calculating with Concepts (CC) technique, which has been developed to improve the precision of UML class diagrams and allows the formal reasoning based on these diagrams. This paper aims at showing the industrial benefits of using such a formal and rigorous approach to reason about business processes and software applications in the early phases of the software development process. The paper discusses how the CC technique can be used in the specification of business processes and in the development of their supporting software applications or tools. This paper also illustrates the use of the technique with a realistic case study on tool integration.	business process;class diagram;unified modeling language	Remco M. Dijkman;Luís Ferreira Pires;Stef Joosten	2001			computer science;systems engineering;operations management;process driven development;management science	SE	-56.133466919501814	22.99058459620324	73409
24371cc5fab4c607894f208928f7ffe76326faec	deriving usage model variants for model-based testing: an industrial case study	testing unified modeling language software atmospheric modeling computational modeling markov processes aerospace industry;software;usage model;aerospace domain usage model variants model based testing cost pressure aerospace industry life cycle processes industrial safety standards rtca do 178c product testing product lines pl automatic test case generation capabilities mbt tool matelo;testing;product line;aerospace industry;requirements;computational modeling;orthogonal variability model;unified modeling language;model based testing;production engineering computing aerospace computing aerospace industry aerospace testing product life cycle management;markov processes;atmospheric modeling;requirements product line model based testing usage model orthogonal variability model	The strong cost pressure of the market and safety issues faced by aerospace industry affect the development. Suppliers are forced to continuously optimize their life-cycle processes to facilitate the development of variants for different customers and shorten time to market. Additionally, industrial safety standards like RTCA/DO-178C require high efforts for testing single products. A suitably organized test process for Product Lines (PL) can meet standards. In this paper, we propose an approach that adopts Model-based Testing (MBT) for PL. Usage models, a widely used MBT formalism that provides automatic test case generation capabilities, are equipped with variability information such that usage model variants can be derived for a given set of features. The approach is integrated in the professional MBT tool MaTeLo. We report on our experience gained from an industrial case study in the aerospace domain.	do-178c;formal system;model-based testing;radio technical commission for aeronautics;spatial variability;test case	Hamza Samih;Hélène Le Guen;Ralf Bogusch;Mathieu Acher;Benoit Baudry	2014	2014 19th International Conference on Engineering of Complex Computer Systems	10.1109/ICECCS.2014.19	unified modeling language;atmospheric model;requirements analysis;model-based testing;systems engineering;engineering;software engineering;software testing;aerospace;markov process;computational model;manufacturing engineering	SE	-57.167495659456094	26.611093001559983	73421
5154b2a25a28a955aeb85cbf64d5e21e54dede32	the aspecs process		This chapter introduces an agent-oriented software process for engineering complex systems called ASPECS. ASPECS is based on a holonic organizational metamodel and provides a step-by-step guide from requirements to code allowing the modeling of a system with different levels of details using a set of refinement methods. This chapter introduces the ASPECS process using the documentation template provided by the IEEE FIPA DPDF Working Group. One of the founding principles of ASPECS is to combine both holonic structures and organizational approaches to ease the modeling and development of complex software applications. The target scope for the proposed approach can be found in complex systems and especially hierarchical complex systems. ASPECS is mainly suitable for open large-scale MAS. The main vocation of ASPECS is towards the development of holonic (as well as not-holonic) societies of software agents.	complex systems;documentation;holon (philosophy);metamodeling;refinement (computing);requirement;software agent;software development process	Massimo Cossentino;Vincent Hilaire;Nicolas Gaud;Stéphane Galland;Abder Koukam	2014		10.1007/978-3-642-39975-6_4	documentation;complex system;metamodeling;software;software development process;software agent;systems engineering;computer science	SE	-54.18327169649247	22.375056425163802	73518
3eccc6be97ced61c39959e315e9a7d815f229620	a note on bpmn analysis. towards a taxonomy of selected potential anomalies	thermostats;system recovery;logic gates;business;unified modeling language;taxonomy;joining processes	Modeling based on a graphical notation understandable for different specialists has become very popular. Within the area of business processes, the most common one is the Business Process Modeling and Notation (BPMN). BPMN is aimed at all business users who design, analyze, manage and monitor business processes. Most papers in this area focus on making use of the possibilities that BPMN makes available, but there is lack of papers analyzing possible errors and ways of detecting and eliminating them. Specification of a BPMN diagram is relatively precise, but it is only a descriptive form presented at some abstract, graphical level. Hence, the main focus of this article is an attempt to analyze the topic of the anomalies which are likely to occur when modeling with use of BPMN.	anomaly detection;business process model and notation;business process modeling language;diagram;graphical user interface;sensor	Anna Mroczek;Antoni Ligeza	2014	2014 Federated Conference on Computer Science and Information Systems	10.15439/2014F185	unified modeling language;xpdl;logic gate;computer science;artificial intelligence;data mining;database;management science;business process model and notation;thermostat;algorithm;taxonomy	ML	-54.111451635392946	20.805682999922315	73539
ce84d00f8f0de0bf56357a7153246839b7743510	a framework for synchronization between feature configurations and use cases based on bidirectional programming	stakeholders;requirements engineering;synchronization;software reusability;credit cards;conferences	Model-Driven Development (MDD) is a widely adopted approach to Requirement Engineering (RE). One basic research issue in Model-Driven Requirement Engineering (MoDRE) is requirements validation, which focuses on how to validate whether the requirements models meet stakeholders' needs or not. % Several lines of work have been performed on the transformation between feature configurations, which are responsible for specifying a software in feature-oriented approach, and use cases, which are easy to understand and often used to describe system behaviors to stakeholders. % However, most of the existing automated derivation methods about feature configurations and use cases are either in one direction or the other. Therefore, after validating the use cases, the adjustment made by stakeholders cannot be traced back to feature configurations automatically. % In this paper, we focus on synchronization between these two vital software artifacts. And we propose a framework that uses putback-based bidirectional programming to guarantee the correctness of this synchronization.	bidirectional transformation;class diagram;correctness (computer science);domain model;feature model;model-driven architecture;model-driven engineering;model-driven integration;requirement;requirements engineering;software architecture	Weize Zhao;Haiyan Zhao;Zhenjiang Hu	2016	2016 IEEE 24th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2016.040	requirements analysis;real-time computing;simulation;computer science;systems engineering	SE	-53.27473943670923	25.10119531878311	73618
95be68e410c135c053490606e309a789bb79ae4c	modeling multiple views of common features in software reengineering for reuse	domain model;multiple views;object oriented;domain analysis;reverse engineering	Common objectives of software reengineering are to improve program maintainability, to port programs into new platforms or to support new functions. To meet reengineering objectives, sometimes it is necessary to substantially re-deign programs; then, reengineering becomes an opportune moment to address reusability. In the reengineering for reuse scenario, a reusability framework is built prior to reengineering efforts. Within the framework, potentially reusable features are modeled and representation structures for capturing reusable features are built. The core of the framework is a family of domain models. Domain models are built in the course of both reverse engineering of existing programs and independent domain analysis. Domain models consist of documentation templates, organized in Object-Oriented way, that describe common (therefore reusable) features and their implementation. Often we find that, apart from similarities, there are also some variations in feature specifications and implementation from one system to another. Modeling reusable features and capturing variations in feature specification is the topic of this paper.	code refactoring	Stan Jarzabek;Chew Lim Tan	1994		10.1007/3-540-58113-8_176	domain analysis;real-time computing;domain;computer science;systems engineering;feature-oriented domain analysis;software engineering;domain engineering;domain model;process management;object-oriented programming;reverse engineering	SE	-53.84827886518362	26.441432677739666	73714
388aeb58cb0b02ece56522043987ce90f8409488	production planning in a software product line organization	design tools and techniques;software product line;design;technical management;project and people management;production planning	Business and market goals drive an organization's creation and operation of a software product line. Effective product production is critical to the success of that product line and must also be driven by those business and market goals.  This tutorial describes a method of production planning in the context of a running example software product line. It explains how to utilize production scenarios and Porter's Five Forces to transform business and market goals into a  •Production strategy, the overall approach for realizing both the core assets and products in a software product line  •Production method, the overall implementation approach that specifies the models, processes, and tools to be utilized by the core asset and product developers, and  •Production plan, the guide to how products in the software product line will be constructed from the product line's core assets.	software product line	Gary J. Chastek;John D. McGregor	2007	2011 15th International Software Product Line Conference	10.1145/2491627.2493903	product engineering;software quality control;software deployment;service product management;software development;product management;process management;software project management;software product line;engineering	SE	-62.71545707802551	22.06376263255981	73763
76eae3023dbbd03fe169a16b4a64259396a28e5b	structured handling of online interface upgrades in integrating dependable systems of systems	fault tolerant;system of systems;dependable systems;complex system;of research and development;exception handling	The integration of complex systems out of existing systems is an active area of research and development. There are many practical situations in which the interfaces of the component systems, for example belonging to separate organisations, are changed dynamically and without notification. Usually systems of system (SoS) developers deal with such situations off-line causing considerable downtime and undermining the quality of the service that SoSs are delivering [Romanovsky & Smith 2002]. In this paper we propose an approach to on-line handling such upgrades in a structured and disciplined fashion. All interface changes are viewed as abnormal events and general fault tolerance mechanisms (exception handling, in particular) are applied to dealing with them. The paper outlines general ways of detecting such interface upgrades and recovering after them. An Internet Travel Agency is used as a case study throughout the paper. An implementation demonstrating how the general approach proposed can be applied for dealing with some of the possible interface upgrades within this case study is discussed.	apple sos;complex systems;dependability;downtime;exception handling;fault tolerance;general protection fault;online and offline;sensor;smith–volterra–cantor set;system of systems	Cliff B. Jones;Panayiotis Periorellis;Alexander Romanovsky;Ian Welch	2002		10.1007/3-540-36520-6_7	real-time computing;systems engineering;engineering;computer security	SE	-56.01071112226899	21.789411891761116	73871
cac38ca7b6f276a74a9e662d3986ce06de3ebb3c	towards collaborative development based on software architecture	software architecture	Software projects often require many software engineers to coordinate their efforts to build large software systems. How to support collaborative development among the stakeholders in a project, even if separated by time or space, to produce software artifacts efficiently becomes a very important problem. Software architectures are considered important because they are the blueprints for target software products and determine system-wide qualities, and they can be used to organize various software artifacts in software development process from a high level perspective. Based on such an important role of software architectures, this paper puts forward an approach to collaborative software development based on software architecture, to support the collaboration spanning the whole software lifecycle. Moreover, the paper provides the detail on how this method works efficiently by a case study.	software architecture	Yanchun Sun;Hui Song;Xinghua Wang;Wenpin Jiao	2008			software peer review;systems engineering;software system;software deployment;resource-oriented architecture;software design description;software development;computer science;software construction;social software engineering	SE	-60.01141608027228	23.188114067492496	74083
af7543d84c5efef902e80b8fff52683ca06498de	experiences of applying model-based analysis to support the development of automotive software product lines	simulink;model transformation;product line;embedded system;embedded systems;product line engineering;eclipse modeling framework;software product line;matlab;embedded software	In embedded systems in general and in automotive systems in particular the systematic reuse of existing assets is crucial. Moreover, companies in these domains often offer whole families of similar products. Hence, the application of product line engineering seems to be an obvious option.  However, current products have reached a complexity level where management of products within a product line cannot be handled with current techniques and tools (e.g. Matlab/Simulink) alone. To sustain an efficient engineering process and to reach the required quality levels of the products, additional techniques are required.  In this paper we report on a prototypical framework for the analysis of embedded systems product lines. The techniques and tools offered by the framework were developed to support engineers in typical tasks, which occur during design, implementation, and maintenance of embedded software product lines. The techniques allow to analyse product line artefacts by transforming them into models, which are then used in an analysis process based on model transformation languages.	automotive software;embedded software;embedded system;matlab;model transformation language;simulink;software product line	Daniel Merschen;Andreas Polzer;Goetz Botterweck;Stefan Kowalewski	2011		10.1145/1944892.1944910	real-time computing;embedded software;computer science;systems engineering;engineering;product design specification;software engineering;feature model;product engineering	EDA	-56.32835377142741	25.99426013978646	74561
edcb2b240e4a51bfd7f2f4e02ed10c59c50d2a55	flexible data acquisition in object-aware process management		Data-centric approaches to business process management, in general, no longer require specific activities to be executed in a certain order, but instead data values must be present in business objects for a successful completion. While this holds the promise of more flexible processes, the addition of the data perspective results in increased complexity. Therefore, data-centric approaches must be able to cope with the increased complexity, while still fulfilling the promise of more flexible processes. Object-aware process management specifies business processes in terms of objects as well as their lifecycle processes. Lifecycle processes determine how an object acquires all necessary data values. As data values are not always available in the order the lifecycle process of an object requires, the lifecycle process must be able to flexibly handle these deviations. Object-aware process management provides operational semantics with flexible data acquisition built into it, instead of tasking the process modeler with pre-specifying a flexible process. At the technical level, the flexible data acquisition is accomplished with process rules.	business object;business process;complexity;data acquisition;hyperscale;imperative programming;microsoft outlook for mac;operational semantics;process modeling	Sebastian Steinau;Kevin Andrews;Manfred Reichert	2017			business process;process management;business process management;business object;data acquisition;operational semantics;computer science	DB	-55.594978051197124	18.976339620668988	74611
824776ec73df3dcb1d701afe7e8fbf55f1ec22db	consistency management with repair actions	databases;programming language semantics;software repair;dependence analysis;data integrity;ucl;application software;software maintenance;uml;distributed document management;logic;discovery;theses;conference proceedings;data engineering;programming language semantics data integrity software maintenance specification languages formal verification software tools;formal verification consistency management distributed document management first order logic formulae uml software repair programming language semantics;formal verification;digital web resources;specification languages;ucl discovery;engineering management;consistency management;software development environment;open access;unified modeling language;xml;first order logic formulae;ucl library;software tools;computer science;book chapters;open access repository;program slicing;programming;first order logic;domain specificity;logic unified modeling language application software xml computer science educational institutions databases programming data engineering engineering management;ucl research	Comprehensive consistency management requires a strong mechanism for repair once inconsistencies have been detected. In this paper we present a repair framework for inconsistent distributed documents. The core piece of the framework is a new method for generating interactive repairs from full first order logic formulae that constrain these documents. We present a full implementation of the components in our repair framework, as well as their application to the UML and related heterogeneous documents such as EJB deployment descriptors. We describe how our approach can be used as an infrastructure for building higher-level, domain specific frameworks and provide an overview of related work in the database and software development environment community.	enterprise javabeans;first-order logic;integrated development environment;software deployment;software development;unified modeling language	Christian Nentwich;Wolfgang Emmerich;Anthony Finkelstein	2003		10.1109/ICSE.2003.1201223	unified modeling language;information engineering;computer science;operating system;software engineering;database;programming language	SE	-49.210367062949274	28.06162660388984	74658
1e1f6b0036e67f4f8d5307c384ce51585f82d377	using sysml to describe a new methodology for semiautomatic software generation from inferred behavioral and data models	software;xsd schema inference;mdsd;application software;behaviour model;behaviour model generative programming mdsd software methogology sysml data model;code generation;formal languages;inference mechanisms;object oriented programming;automatic programming;data mining;omg consortium;computer applications;data model;computational modeling;business data processing;business;data models programming application software computer science design methodology software standards unified modeling language computer applications automation formal languages;unified modeling language;xml automatic programming business data processing data mining data models inference mechanisms object oriented programming program compilers unified modeling language;xml;data model inference;behavioral model inference;semiautomatic software component generation methodology;software standards;code generation sysml semiautomatic software component generation methodology behavioral model inference data model inference omg consortium xsd schema inference business process mining inference uml tool;computer science;generative programming;business process mining inference;program compilers;uml tool;programming;business process;software methogology;sysml;data models;generic programming;design methodology;automation	This article describes a new methodology designed for semiautomatic generation of software applications using the new standard of OMG consortium: SYSML. The methodology has behavior and data model inference steps. Both data and behavior are inferred, the first by XSD-Schema inference and the latter by Business Process Mining inferences. The paper describes how by using SYSML a better description of the methodology is given, a description that allows making a better design than using UML standard tools.	behavior model;business process;component-based software engineering;conjugate gradient method;data model;newton's method;semiconductor industry;systems modeling language;unified modeling language	Ignacio González Alonso;M. P. Almudena García Fuente;José Antonio López Brugos	2009	2009 Fourth International Conference on Systems	10.1109/ICONS.2009.50	unified modeling language;data modeling;programming;formal language;application software;xml;design methods;data model;systems modeling language;uml tool;computer science;automation;data mining;database;business process;computer applications;programming language;object-oriented programming;generic programming;computational model;code generation	Robotics	-49.19128920488289	26.94812393332169	74680
906dd3a46884124c0c929f351a7b5476ad56d132	safer language subsets: an overview and a case history, misra c	rule signal to noise;case history;computacion informatica;embedded control system;grupo de excelencia;rule categories;ciencias basicas y experimentales;safer language subsets;computer science and informatics;embedded control systems	This paper gives an overview of safer language subsets in general and considers one widely-used one, MISRA C, in particular.#R##N##R##N#The rationale, specification, implementation and enforcement of a safer language subset each introduce particular problems which has led to their inconsistent take-up over the years even in applications which may be safety-related and definitely need subset restrictions. Each of these areas will be discussed illustrating practical problems which may be encountered with standards in general before focussing on the widely used MISRA C standard [MISRA C guidelines (1998)]. The approach taken is necessarily empirical and where it is able quotes measurements.#R##N##R##N#The real objective of this paper is to produce an empirically based taxonomy of programming language subset rules to bring all these issues together and promote the concept that a safer subset must be based on measurement principles however crudely they are practised currently in software development.#R##N##R##N#The concept of signal to noise ratio of a programming standard is also introduced.	misra c	Les Hatton	2004	Information & Software Technology	10.1016/j.infsof.2003.09.016	computer science;engineering;artificial intelligence;medical history;software engineering;database;programming language;management;algorithm	NLP	-60.282932147578386	30.430088351093303	74789
0d69ca0a02dd95ce9e5817936fcf1c287f69520f	towards the dynamic reconfiguration of quality attributes	reconfiguration;quality attributes;software architecture;variability;spl	There are some Quality Attributes (QAs) whose variability is addressed through functional variability in the software architecture. Separately modelling the variability of these QAs from the variability of the base functionality of the application has many advantages (e.g., a better reusability), and facilitates the reconfiguration of the QA variants at runtime. Many factors may vary the QA functionality: variations in the user preferences and usage needs; variations in the non-functional QAs; variations in resources, hardware, or even in the functionality of the base application, that directly affect the product's QAs. In this paper, we aim to elicit the relationships and dependencies between the functionalities required to satisfy the QAs and all those factors that can provoke a reconfiguration of the software architecture at runtime. We follow an approach in which the variability of the QAs is modelled separately from the base application functionality, and propose a dynamic approach to reconfigure the software architecture based on those reconfiguration criteria.	algorithm;applications architecture;heart rate variability;list of system quality attributes;mathematical optimization;non-functional requirement;run time (program lifecycle phase);software architecture;software quality assurance;spatial variability;user (computing)	Jose Miguel Horcas;Mónica Pinto;Lidia Fuentes	2016		10.1145/2892664.2892686	reliability engineering;embedded system;real-time computing;computer science	SE	-54.706923077986474	27.421361735387453	74862
fe99f0124e3622a29816f25ff3eb21bcc7ee3e69	a systematic regression testing method and tool for software components	in house built component;component api test model;software component testing;reusable test case;regression testing;comptest systematic regression testing software component testing component based software engineering software system reusable component in house built component system component quality component based application system component based system reusable test case component test suite systematic retest component api test model application program interface;component based software engineering;software system;component based systems;software maintenance;systematic regression testing;software systems;component based system;application program interface;object oriented programming;component based software;comptest;impact analysis;program testing;component test suite;application program interfaces;software reusability;software testing system testing software tools automatic testing application software software reusability software engineering performance evaluation software maintenance helium;test methods;software component;system component quality;component based application system;systematic retest;reusable component;software reusability application program interfaces object oriented programming program testing	In component-based software engineering, software systems are mainly constructed based on reusable components, such as third-party components and in-house built components. Hence, system quality depends on the quality of the involved components. Any change of a component, it must be re-tested at the unit level, and re-integrated to form component-based application systems. Although a number of recently published papers address regression testing and maintenance of component-based systems, very few papers discuss how to identify component changes and impacts at the unit level, and find out the reusable test cases in a component's test suite to support its evolution. This paper focuses on component API-based changes and impacts, and proposes a systematic re-test method for software components based on a component API-based test model. The proposed method has been implemented in a component test tool, known as COMPTest. It can be used to automatically identify component-based API changes and impacts, as well as reusable test cases in a component test suite. The paper also reports this tool and its application results	application programming interface;automatic identification and data capture;black box;black-box testing;component-based software engineering;regression testing;software system;test automation;test case;test suite;unit testing	Jerry Zeyu Gao;Deepa Gopinathan;Quan Mai;Jingsha He	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.17	reliability engineering;component-based usability testing;common component architecture;computer science;systems engineering;component-based software engineering;operating system;software engineering;programming language;software system	SE	-55.79379714114314	31.81960116257708	74924
6804b5539b48011594575f23e7c0b84fc7e82b91	software configuration management issues in the maintenance of existing systems	software maintenance;method for software maintenance;software configuration management;model for software maintenance	The application of the Software Con6guration Management (SCM) discipline during the maintenance process of an existing poorly documented software system is vital to bring it under control. Incremental documentation, the activity of building up the software documentation whilst it is examined during the maintenance process, has a key role in such a process. The COMF’ORM (COnfiguration Management FORmalization for Maintenance) system provides a framework for aiding the maintenance process through the application of the SCM discipline. In this way reliable documentation of an existing software system is obtained incrementally whilst maintaining it. Our goal in the design of the COMFORM system is to define a method for the maintenance process through the use of forms representing each phase of a software maintenance model. This approach allows traceability among the software representations throughout the software maintenance process. In this paper we describe the foregoing steps of the COMFORM system’s method towards its formalization.	software configuration management;software documentation;software maintenance;software system;traceability;while	Miriam A. M. Capretz;Malcolm Munro	1994	Journal of Software Maintenance	10.1002/smr.4360060102	reliability engineering;reusability;personal software process;long-term support;verification and validation;software engineering process group;software sizing;software configuration management;software project management;systems engineering;engineering;package development process;backporting;software design;software development;computerized maintenance management system;software engineering;software construction;software maintenance;software deployment;goal-driven software development process;software system	SE	-58.58908390935225	24.376273568516346	75471
17ff5bc6619ad9909902dd3c3ecde1dbb7f02cd7	model-driven automated error recovery in cloud computing		With the increasing complexity of software and systems, domain analysis and modeling are becoming more important for software development and system applications. Applying domain-specific modeling languages and transformation engines is an effective approach to address platform complexity and the inability of third-generation languages to express domain concepts clearly (Schmidt, 2006). Building correct models for a specific domain can often simplify many complex tasks, particularly for distributed applications ABstrAct		Yu Sun;Jules White;Jeffrey G. Gray;Aniruddha S. Gokhale	2011		10.4018/978-1-61692-874-2.ch007	personalization;modeling language;software;domain analysis;cloud computing;theoretical computer science;software development;computer science	SE	-51.18576513353401	25.61930192412878	75596
50e7fa498411ff37c5531fbf29746df210c57817	one approach to the use of the practices of cmmidev v1.3 level 2 in a process of development of embedded systems	embedded systems hardware process control monitoring capability maturity model;document templates cmmidev v1 3 level 2 software engineering embedded computing systems software classification computational resource aircraft medical equipment automobiles space systems technological developments software component brazilian software international reference software development process;specific practices embedded system hardware software software quality cmmi maturity critical software process generic practices;software quality embedded systems	Currently the major concern of software engineering is the quality of Embedded Computing Systems, as they are a classification of software that are strongly present in our daily lives so that often we do not realize. Are composed of hardware and software encapsulated and generally dedicated to a single activity a major characteristic of such systems is the ability to perform very important tasks with little computational resource which represents a high degree of constraints to it is development and operation. It is importance is intensified when they are embedded in aircraft, medical equipment, automobiles, space systems among others that are considered critical, since if it fails, can cause major disasters. The dependence of society, different applications and technological developments are delegating all flexibility of these systems for their part formed by software, which makes it even more critical thus requiring appropriate and specific procedures in their production. The difficulty of software Engineering in meeting this demand is the specificity of each software component to be developed. The use of CMMI-DEV/V1.3 (Process Improvement of Brazilian Software) a model of international reference that directs the execution of practices necessary for the maturity of a software development process may represent a breakthrough in developing such systems one since it is development, we need to use processes with defined procedures to identify and assist in the development of products with these features and thus allow errors can be eliminated or minimized through the activities that must be performed in all stages of development This paper presents part of a study being carried out to develop a process framework that addresses all phases of a development process of embedded systems, organized into phases, activities and document templates that induce developers carrying out the good practices suggested by the level of quality CMMI-DEV/V1.3 model.	cpu cache;capability maturity model integration;component-based software engineering;computation;computational resource;embedded system;sensitivity and specificity;software development process	Magda Aparecida Silverio Miyashiro;Maurício G. V. Ferreira	2014	IISA 2014, The 5th International Conference on Information, Intelligence, Systems and Applications	10.1109/IISA.2014.6878772	personal software process;medical software;verification and validation;software engineering process group;software sizing;systems engineering;engineering;package development process;backporting;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;software measurement;software deployment;goal-driven software development process;software development process;software quality;software system;computer engineering;avionics software;software peer review	SE	-62.5973819112152	28.289176487691787	75597
26c821290eb6072c37ccaefc7a6a55d0a2d4aabd	it ecosystems: evolved complexity and unintelligent design	application development;ethnography;case studies;system administration;complexity;organizational culture;user modeling;system design;special functions;management tool;system architecture;legacy system;user model	Modern enterprise IT systems consist of many specialized functional components, often designed by multiple vendors, interconnected in a plethora of permutations to accomplish different goals. An increasingly large number of technical specialists support these systems. Designers of system administration and management tools for these environments must address complexity issues arising from variations in system architectures and topologies, integration between new and legacy systems as well as internal processes and organizational culture. This paper describes aspects of variability within and between IT environments and discusses approaches for managing complexity.	complex systems;complexity;ecosystem;heart rate variability;interaction;legacy system;middleware;network topology;process (computing);service-oriented architecture;software design;system administrator;text simplification;user interface	James L. Lentz;Terry M. Bleizeffer	2007		10.1145/1234772.1234780	organizational culture;simulation;user modeling;human–computer interaction;computer science;knowledge management;ethnography;management;computer security	SE	-61.705034981104745	19.115667659176154	75739
df3f7278562d247b39b274f35fe5a941e337ca93	issues in process architecture	processing element;product safety;software measurement;prototypes;social structures;process elements;automated structures process architecture perry wolf model software architecture process elements informal documents formal machine manipulatable objects organizational structures social structures;software systems;process architecture;organizational structures;computer architecture;computer architecture programming context modeling joining processes humans software systems software measurement product safety prototypes spirals;software architecture;informal documents;computer aided software engineering;spirals;automated structures;project support environments;joining processes;computer aided software engineering project support environments;perry wolf model;humans;formal machine manipulatable objects;context modeling;programming;organizational structure	I consider the problems of process system architecture in the context of the Perry-Wolf model of software architecture: process elements are executed in process systems by both machines and people; data elements tend to be informal documents in process systems rather than formal, machine manipulatable objects; and connecting elements are much more complex in process systems, involving both automated, social and organizational structures.	document;process architecture;software architecture;systems architecture	Dewayne E. Perry	1994		10.1109/ISPW.1994.512786	reference architecture;simulation;computer science;systems engineering;applications architecture;software engineering;process modeling;data architecture;systems architecture;systems design	SE	-50.31369867619291	30.377619424498846	75968
25e77b05aa7f80386cb80d6aac1bb9389bea8370	a model based engineering tool for ros component compositioning, configuration and generation of deployment information	software;owl;service robots;iec standards;unified modeling language;robot kinematics	Programming industrial robots requires experts -not only to create the robot applications, but also for changing them later due to different product requirements. Part of the reason for this is that all robot vendors provide their own robot programming language. Due to the language differences, robot applications cannot be reused for different robot types. Often, additional experts are required since one expert is trained only for a special robot type. This makes the use of robots uneconomical for small and medium sized enterprises. The ReApp project addresses this problem by providing a workbench based on ROS (Robot Operating System). A central part of this workbench is the skill and solution modeling tool, which allows the model-based design of robot applications composed of reusable components, and is described in this paper.	graphical user interface;industrial robot;programming language;requirement;robot operating system;software deployment;soldering;workbench	Monika Wenger;Waldemar Eisenmenger;Georg Neugschwandtner;Ben Schneider;Alois Zoitl	2016	2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2016.7733559	unified modeling language;robot learning;embedded system;simulation;computer science;systems engineering;engineering;artificial intelligence;operating system;machine learning;ubiquitous robot;programming language;mobile robot navigation;personal robot;robot kinematics	Robotics	-50.44879521763114	24.08056724280153	76121
3690a97dbd17a357ea79c6ff85358b69e93bd0d7	software reliability analysis using queuing-based model with testing effort	fault correction process;fault detection process;queuing model;software reliability;testing effort function	In this paper, we investigate software fault detection and fault correction processes based on infinite server queuing model which incorporate testing effort functions. Some researches proposed in the literature to study fault detection and fault correction processes. However, most of them do not consider the amount of resources consumed during fault detection and fault correction processes. The consumption amount of resources is usually depicted by testing effort functions which can largely influence fault detection speed and the time to correct a fault detected. Therefore, we will show that new models incorporate testing effort functions into the fault detection and fault correction processes. In additional, we study how to use queuing models to explain the fault detection and fault correction processes during software development. Parameters are estimated and experiments on actual fault data sets are illustrated. The results show that the proposed models in this paper can estimated the number of initial faults better than the model without testing effort functions.	debugging;experiment;fault detection and isolation;list of software reliability models;queueing theory;server (computing);software development;software quality;software reliability testing;xojo	Nan Zhang;Gang Cui;Hongwei Liu	2013	JSW		embedded system;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;fault model;software quality;software fault tolerance	SE	-62.76987355675662	31.928912800267483	76146
d2b12f1f8f18fd6337422e57e7838a7d0bc37334	a software development kit to implement integration solutions	business modelling;software engineering;software development kit;domain specific language;integration framework;enterprise application integration;business process;domain specific languages	Typical companies rely on their software ecosystems to support and optimise their business processes. There are a few proposals to help software engineers devise enterprise application integration solutions. Some companies need to adapt these proposals to particular contexts. Unfortunately, our analysis reveals that they are not so easy to maintain as expected. This motivated us to work on a new proposal that has been carefully designed in order to reduce maintainability efforts.	business process;enterprise application integration;enterprise software;software development kit;software ecosystem;software engineer	Rafael Z. Frantz;Rafael Corchuelo	2012		10.1145/2245276.2232042	domain analysis;functional software architecture;personal software process;enterprise system;enterprise application integration;enterprise software;software engineering process group;computer science;domain-specific language;knowledge management;package development process;social software engineering;software framework;software development;software engineering;domain engineering;software construction;software walkthrough;enterprise integration;programming language;resource-oriented architecture;software deployment;software development process;system integration	Security	-59.340986458512255	22.00198538796337	76178
4e0d7917d78ece3e5120ac2fab49537d19294ade	an approach for model composition and verification	verification;model verification;analytical models;metals;weaving model driven engineering unified modeling language prototypes merging programming packaging analytical models computer science sun;prototypes;model weaving model composition verification alloy;biological system modeling;object oriented programming;software engineering;alloy;model weaving;computational modeling;software engineering object oriented programming;weaving based model composition framework;software development;unified modeling language;model driven engineering;alloy codes;weaving;alloy language;language model;alloy analyzer;alloy analyzer model composition model verification software development model driven engineering weaving based model composition framework alloy language alloy codes;model composition	Model composition is frequently used during large software development in MDE (Model Driven Engineering). The consistency of the composed model is quite essential to model composition. This paper presents a weaving-based model composition framework (WMCF) and then gives a prototype implementation of the framework using Alloy language. Models are converted into Alloy codes and model composition is verified by the Alloy Analyzer.	alloy (specification language);alloy analyzer;code;model-driven engineering;prototype;software development	Defen Zhang;Shixian Li;Xianming Liu	2009	2009 Fifth International Joint Conference on INC, IMS and IDC	10.1109/NCM.2009.271	unified modeling language;model-driven architecture;alloy analyzer;verification;simulation;computer science;software development;prototype;programming language;object-oriented programming;computational model;weaving;language model	SE	-48.806048437369306	26.647747370927142	76382
d3d039ce3558cb7e18d62f85c92eb4d3c1452d92	requirements in digital forensics method definition: observations from a uk study		Abstract During a project to examine the potential usefulness of evidence of tool verification as part of method validation for ISO 17025 accreditation, the authors have examined requirements statements in several digital forensic method descriptions and tools. They have identified that there is an absence of clear requirements statements in the methods and a reluctance or inability to disclose requirements on the part of tool producers. This leads to a break in evidence of correctness for both tools and methods, resulting in incomplete validation. They compare the digital forensics situation with other ISO 17025 accredited organisations, both forensic and non-forensic, and propose a means to close the gap and improve validation. They also review existing projects which may assist with their proposed solution.		Angus M. Marshall;Richard Paige	2018	Digital Investigation	10.1016/j.diin.2018.09.004	data mining;accreditation;computer science;correctness;digital forensics	HCI	-57.48887985874472	23.4958600037273	76464
177ddea83b769eabb0727370bb4da9a04680091f	access to uml diagrams with the hutn	unified modeling language uml;human usable textual notation hutn;accessibility;modeling	Modern software development includes the usage of UML for (model-driven) analysis and design, customer communication etc. Since UML is a graphical notation, alternative forms of representation are needed to avoid barriers for developers and other users with low vision. Here, Human-usable Textual Notation (HUTN) is tested and evaluated in a user interface modeling concept to provide accessible model-driven software design.	diagram;graphical user interface;model-driven architecture;model-driven engineering;model-driven integration;software design;software development;unified modeling language;user interface modeling	Helmut Vieritz;Daniel Schilberg;Sabina Jeschke	2012		10.1145/2384916.2384971	natural language processing;systems modeling;uml state machine;systems modeling language;uml tool;computer science;accessibility;applications of uml;class diagram;shlaer–mellor method;programming language;node;world wide web;object constraint language	SE	-48.67640110149265	23.982287154220348	76563
72ee1d928bf85bb2179af44f060c07760c542722	automated support of the variability in configurable process models. (automatiser le support de la variabilité dans les modèles de processus configurables)		With the rapidly changing demands in today's business environments, modeling business processes from scratch becomes a time-consuming and error prone task. Motivated by the “Design by Reuse” paradigm, configurable process models are recently gaining momentum due to their capability of explicitly representing the common and variable parts of similar processes into one customizable model. A configurable process model needs to be configured to suit the specific requirements of an organization. Since configurable process models tend to be large and complex, their design and configuration without any assistance become tedious tasks. In this thesis, we propose an automated approach to assist the design and configuration of configurable process models. Our aim is to assist users (i) to complete the design of their configurable process models in a fine-grained way in order to avoid large and complex results and (ii) to configure existing models according to their specific needs. To do so, we propose to learn from the experience gained through previous process modeling and configuration in order to (i) recommend configurable fragments that can be integrated into an ongoing designed process and (ii) recommend configuration choices to customize an existing configurable process.	business process;cognitive dimensions of notations;linear algebra;process modeling;programming paradigm;requirement;spatial variability	Nour Assy	2015				SE	-54.65888576967454	25.116776907192296	76895
f1afc099242a16a6c0736609e9377dc7cf44db49	uml: abstraction as a criterion for defining class diagrams and object diagrams	concretization;abstraction;object diagram;uml;class diagram;information system;information technology	UML is undisputedly the most efficient and effective tool of information systems analysis and design. Abstraction as paradigm, represent the basis of an object-oriented approach to development of information system and software solutions. No matter what background team members have (i.e. information technology or problem domain experts), the capability of abstraction is of crucial importance, especially at the early phase of the system’s structure identification. Since class and object diagrams specify system’s structure, indicating how to identify and relate them, they are an issue for system analysts and designers. This paper examines the following issue: to what extent abstraction level influences the need for creating object diagrams in shaping class diagrams and vice versa to what extent concretization at the level of an object diagrams influences structural decomposition of class diagrams.	abstraction layer;class diagram;information system;noise shaping;object diagram;problem domain;programming paradigm;structured systems analysis and design method;unified modeling language	Ivan Pogarcic;Miro Francic;Vlatka Davidovic	2007			object diagram;story-driven modeling;method;interaction overview diagram;theoretical computer science;abstraction layer;class diagram;abstraction;computer science;problem domain;systems engineering	SE	-52.79794402108654	23.641827750823147	77180
69fa023e5e94c83b0f4cc97876c53f575a770456	additional knowledge based mof architecture layer for uml models generation process		As organizations grow and IS get bigger it is needed to create accurate and complicated analyzes for developing systems. This analyzes are base for design of business models and system architecture. Designers every day face new challenges when they need to collide and understand other designers’ and analytics’ made models. This process creates new problems and mistakes. Automatization of IS engineering process lets create better and more qualified models with less mistakes. The article is about MOF architecture’s role in IS engineering process and about possibilities to improve MOF architecture’s composition with new knowledge based layer. The main scope of the article is to analyze improved MOF architecture’s usage in UML models generation with transformation algorithms from enterprise model process.		Ilona Veitaite;Audrius Lopata	2015		10.1007/978-3-319-26762-3_6	reliability engineering;uml tool;systems engineering;engineering;applications of uml;engineering drawing	EDA	-57.44713434468683	22.080003026205457	77203
0aa4a8162fe891482092214d80b5e88adcf15806	information access tools for software reuse	outil logiciel;software tool;fonds;algoritmo busqueda;reutilizacion;algorithme recherche;program design;library holdings;search algorithm;query formulation;formulacion pregunta;conception programme;information access;ingenieria logiciel;formulation question;software engineering;reuse;selection automatique;fondo;herramienta controlada por logicial;seleccion automatica;software component;genie logiciel;acces information;cost effectiveness;acceso informacion;code;information need;software design;empirical evaluation;software reuse;codigo;concepcion programa;reutilisation;automatic selection	Software reuse has long been touted as an effective means to develop software products. But reuse technologies for software have not lived up to expectations. Among the barriers are high costs of building software repositories and the need for effective tools to help designers locate re-usable software. While many design-forreuse and software classification efforts have been proposed, these methods are cost-intensive and cannot effectively take advantage of large stores of design artifacts that many development organizations have accumulated. Methods are needed that take advantage of these valuable resources in a cost-effective manner. This paper describes an approach to the design of tools to help software designers build repositories of software components and locate potentially re-usable software in those repositories. The approach is investigated with a retrieval tool, named CodeFinder, which supports the process of retrieving software components when information needs are ill-defined and users are not familiar with vocabulary used in the repository. CodeFinder uses an innovative integration of tools for the incremental refinement of queries and a retrieval mechanism that finds information associatively related to a query. Empirical evaluation of CodeFinder has demonstrated the effectiveness of the approach. Information Access Tools for Software Reuse Scott Henninger -2August 1, 1995 1. Finding Examples in Software Repositories The goal of increasing programmer productivity through software reuse has proven to be elusive [1, 2, 3]. Although many approaches have been suggested [4], none of them have yet reached the critical point at which the cost of reuse is equal to or less than the effort to create new code. The problems are numerous, including the fact that an existing piece of code rarely fits exactly, that a programmer does not know what code is available, and that once the code is found it is difficult to understand how it works or how it can be used [3]. Although the research approaches are numerous, ranging from generative (languages, application generators, program transformations) to compositional approaches (libraries of components), most reuse efforts in place today center around libraries of reusable components in compositional frameworks. While current dissatisfaction with library-based reuse has caused many researchers to look for methods involving the reuse of larger components and different frameworks [1], libraries of software components will remain a viable technology with a broad base of applicability. But librarybased reuse faces an inherent conflict: to be useful, many components must exist, but when many examples are available, finding and choosing an appropriate one becomes troublesome. The large number and diversity of objects increases the chances that an object closely related to a problem task exists. However, finding such an object among so many becomes difficult. Improved retrieval systems for finding and exploring software repositories can potentially improve the overall effectiveness of library-based reuse. 1.1 Retrieving Software Components Most research on information retrieval systems have focused on searching for literature references, where pre-defined relationships between words and concepts or the regular structure of language can be used to effectively retrieve relevant documents [5, 6]. But little attention has been given to the representation of non-text data [7] such as software components, which present some special problems not found in text-based retrieval systems. Software source code has arbitrary rules of grammar that are different from natural language and allows the use of non-words and esoteric abbreviations. For example, the mail system described later in this paper uses the abbreviation ‘mp’ for a “message pointer” throughout the system’s source code and documentation. Information retrieval techniques that rely on pre-defined word meanings would not be able to accommodate such an abbreviation and will in general find it difficult to adapt to idiosyncratic word definitions used in source code. The differences in the linguistics of source code and the fact that clear and accurate documentation is often not readily available reduce the effectiveness of automatic indexing schemes, which rely on selfdescriptive document contents. The use of templates to ensure effective text for retrieval [8, 9] is a partial solution whose effectiveness is proportional to the quality of documentation. Free-text indexing has been applied to the domain of Unix man pages [10], where documentation for the code is conveniently available. But the circumstances surrounding this type of application, in which an Information Access Tools for Software Reuse Scott Henninger -3August 1, 1995 enormous effort has taken place over many years to document code for users, is rare and uncharacteristic of most software development efforts. Because of the difficulty of applying free-text methods to software, the conventional wisdom is that software components must be organized in some manner so they can be found. The most popular approach for augmenting representations of software components is to construct a classification scheme. Retrieval can then be accomplished by choosing the right category or browsing a graphical display of category hierarchies. The LaSSIE system [11] uses knowledge-based techniques in a frame-based approach to classifying software components. Retrieval is performed by classifying the query and returning objects subsumed by the query. The result is a weak form of inferencing based on inheritance (infer that everything subsumed by the query is relevant) and classification (frame instantiation). Sommerville and Wood [12] presented a similar frame-based approach based on conceptual dependency, an artificial intelligence representation scheme for natural language understanding. Prieto-Diaz’s [13] software classification scheme uses a faceted organization of classes consisting of groupings of terms. Instead of creating a static hierarchy of classes and subclasses, faceted classification allows the synthesis of facets into multi-element classes by choosing terms within each facet. Six facets are identified for describing software components. A user must construct a query consisting of six terms, one for each facet, which is then applied to a relational model to retrieve software components. AIRS (AI-based Reuse System) combines the faceted and frame-based classification systems to retrieve components by their similarity to a query represented by frame attributes [14] In spite of these efforts, software library classifications have proven to be notoriously cryptic and esoteric, causing library users to “feel more like a detective than a programmer” [15; p. 280]. Finding the “right” category is a difficult task because it involves a detailed understanding of the classification scheme, causing problems for all but the most expert user. Even well known classification systems, such as the Library of Congress, have been shown to be problematic for many users [16], and classifications that would seem to have one “correct” taxonomy, such as a biological species, need more than one structure to satisfy different information needs [17]. Effective use of faceted classification schemes requires an intimate understanding of the structure of the repository and the implications of query construction [15]. The need for extensive training procedures for both using and constructing facets remains a barrier to effectively applying faceted schemes for software retrieval [18]. While the main value of classification systems may be that they force developers to understand the problem and application domain [1], methods are needed that transcend strict hierarchical ordering of information in a flexible manner that better facilitates the process of finding relevant information. 1.2 Cost Effective Reuse Libraries The problems with classification systems do not end with usability issues. The challenge for software retrieval systems is to control the costs of creating and extending a repository while retaining enough structure to adequately support retrieval and the process of software reuse. Given the high costs of creating a classification scheme or knowledge bases, it is unclear how most software retrieval research Information Access Tools for Software Reuse Scott Henninger -4August 1, 1995 D2 D3	algorithm;application domain;artificial intelligence;code reuse;comparison and contrast of classification schemes in linguistics and metadata;component-based software engineering;critical point (network science);documentation;fits;faceted classification;generative model;graphical user interface;http 404;ian sommerville (technician);infographic;information access;information needs;information retrieval;library (computing);natural language understanding;null (sql);pointer (computer programming);program transformation;programmer;programming paradigm;programming productivity;refinement (computing);relational model;software design;software development;software repository;spreading activation;statistical classification;text corpus;text-based (computing);universal instantiation;unix;usability;vocabulary	Scott Henninger	1995	Journal of Systems and Software	10.1016/0164-1212(94)00136-B	information needs;personal software process;verification and validation;cost-effectiveness analysis;software engineering process group;software sizing;computer science;systems engineering;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;data mining;reuse;database;program design language;software walkthrough;programming language;software analytics;resource-oriented architecture;software deployment;computer-aided software engineering;code;goal-driven software development process;software metric;software system;search algorithm	SE	-56.085369926324844	30.268380085099206	77237
60bec7d8f2a0b99b749c991b3c44fc9839203ca2	comparing multiple matlab/simulink models using static connectivity matrix analysis		Model-based languages such as MATLAB/Simulink are crucial for the development of embedded software systems. To adapt to changing requirements, engineers commonly copy and modify existing systems to create new variants. Commonly referred to as clone-and-own, this reuse strategy is easy to apply and beneficial in the short term, but it entails severe maintenance and consistency issues in the long term, leading to a huge amount of redundant and similar assets. Moreover, a later transition towards structured reuse such as with software product lines inevitably requires the comparison of all existing variants prior to the actual migration. However, current work mostly revolves around the comparison of only two systems and despite approaches proposed that can cope with more, such are not applicable to embedded software systems such as MATLAB/Simulink. In this paper, we bridge this gap and propose Static Connectivity Matrix Analysis (SCMA), a novel comparison procedure that allows for the evaluation of multiple MATLAB/Simulink model variants at once. In particular, we transform models into a matrix form which is used to compare all models and to identify all similar structures between them, even with model parts being completely relocated during clone-and-own. We allow engineers to tailor results and to focus on any arbitrary variant subset, enabling individual reasoning prior to migration. We provide a feasibility study from the automotive domain, showing our matrix representation to be suitable and our technique to be fast and precise.	adjacency matrix;cluster analysis;embedded software;embedded system;matlab;matrix analysis;matrix representation;requirement;simulink;software product line;software system;undocumented feature	Alexander Schlie;Sandro Schulze;Ina Schaefer	2018	2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2018.00026	computer science;systems engineering;matlab;theoretical computer science;software;reuse;matrix representation;maintenance engineering;embedded software;matrix analysis;matrix (mathematics)	SE	-55.93254064000602	26.07303165340055	77280
5717173d3d99758624455f524588e99fda020977	dynamic evolution of distributed systems specifications using reflective language	distributed system;modules compatibility;software evolution;object oriented specifications;dynamic modifications;type modification;reflection	Recently, object-oriented specifications of distributed systems has gained more attention. The object-oriented approach is known for its flexibility for system construction. However, one of the major challenges is to provide facilities for the dynamic modifications of such specifications during the development and maintenance process. Yet, current work has not addressed the dynamic modifications of specifications of distributed systems. In this paper, we are concerned with formal description techniques that allow for the development and dynamic modification of executable specifications. A two-level model for the evolution of large object-oriented specifications is introduced. The first deals with the dynamic modifications of types (classes), while the second deals with modifications of modules. We have defined a set of structural and behavioral constraints to ensure specification consistency after modification at both levels. To allow dynamic modification of types and modules, we have developed a reflective object-oriented specification language which uses meta-objects to support the modification operations. In this language, types and modules are objects.	distributed computing	Issam A. Hamid;Mohammed Erradi	1995	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194095000253	reliability engineering;reflection;computer science;systems engineering;software evolution;software engineering;engineering drawing	SE	-48.67881625211738	28.86101792501702	77349
6981704692b4ecb77e4d77e016977dcf26fb90b9	how to improve the understanding of roles in modeling		A role is a powerful modeling concept in software modeling. Beginners in modeling, however, find it difficult to understand the role concept. They often confuse the role concept with the is-a relationship (generalization). Therefore, we address the semantic difference between (natural) objects and roles in object-oriented modeling by using a new teaching approach - the R-CRC Card Method which is a role-based extension of the CRC Card Method. This work provides an introduction to this new approach and reveals results from a case study with 178 undergraduate students comparing both card methods. It is shown that the R-CRC Card Method is more suitable for analyzing an application domain and the identification of roles. Further study findings depict the effectiveness of the method for education by teaching students and support the R-CRC Card Method as a didactic tool for teaching the role concept in object-oriented modeling.	application domain;class-responsibility-collaboration card;cyclic redundancy check;is-a;modeling language	Francis Anyanwu;J-F Petiot;Birgit Demuth	2018		10.1145/3270112.3270131	object-oriented modeling;modeling language;application domain;systems engineering;human–computer interaction;class-responsibility-collaboration card;computer science	SE	-52.28393339259189	23.187940791757875	77395
13e8b552f6e2dd915e2a867f771ec48afcf2234e	an architecture framework for enterprise it service availability analysis	systemvetenskap informationssystem och informatik;information systems;archimate;systems availability;system quality analysis;service availability;metamodel;ocl;noisy or;downtime;enterprise architecture	This paper presents an integrated enterprise architecture framework for qualitative and quantitative modeling and assessment of enterprise IT service availability. While most previous work has either focused on formal availability methods such as fault trees or qualitative methods such as maturity models, this framework offers a combination. First, a modeling and assessment framework is described. In addition to metamodel classes, relationships and attributes suitable for availability modeling, the framework also features a formal computational model written in a probabilistic version of the object constraint language. The model is based on 14 systemic factors impacting service availability and also accounts for the structural features of the service architecture. Second, the framework is empirically tested in nine enterprise information system case studies. Based on an initial availability baseline and the annual evolution of the 14 factors of the model, annual availability predictions are made and compared with the actual outcomes as reported in SLA reports and system logs. The practical usefulness of the method is discussed based on the outcomes of a workshop conducted with the participating enterprises, and some directions for future research are offered.	baseline (configuration management);capability maturity model;computational model;enterprise architecture framework;enterprise information system;fault tree analysis;metamodeling;object constraint language;service-level agreement	Ulrik Franke;Pontus Johnson;Johan König	2012	Software & Systems Modeling	10.1007/s10270-012-0307-3	enterprise architecture framework;metamodeling;reliability engineering;rm-odp;systems engineering;engineering;service-oriented modeling;software engineering;enterprise architecture management;database;enterprise architecture;view model;information system;object constraint language;downtime	Web+IR	-57.62579074915592	19.842977729395255	77458
14687abc5ee367a3161b9b9c5841de835a58e3a7	reuse with protégé-ii: from elevators to ribosomes	knowledge base;software development;development environment;cost effectiveness;knowledge based system;software component	This paper describes the PROTEGE-II environment which supports the construction of knowledge-base systems from reusable components. To assist developers with reuse, the terminologies of both problem-solving methods and knowledge bases should be described as formal ontologies. To connect pre-existing methods to new domains and knowledge bases, we dejine declarative mapping relations, which we use to translate information from domains to methods. It is critical that these mappings are simple, and we develop an ontology and a tool to constrain their construction. With PROTEGE-II and a set of mapping relations, we are able to reuse the same problem-solving method with two disparate tasks: (1) configuring the parts of an elevator system and (2) identzfling plausible con.gurations of helices in a ribosome molecular strand. 1. Reuse for Knowledge-Based Systems Software reuse is an appealing solution to the high cost of software construction and maintenance: If a library of reusable software components were available, then developers could use this library to greatly reduce software development time and effort. Since the goal of software reuse is to reduce development cost, it is valuable to view reuse from an economic perspective. Thus, the effort needed to build a software component library is the reuse investment cost, and the return on that investment is measured by the savings in effort achieved by exploiting reuse over the lifetime of each component. The benefit from a single instance of reuse is the difference between development costs with reuse and estimated development costs without reuse, Reuse is successful only when these benefits outweigh the investment costs. Barnes and Bollinger (1991) outline three ways to make reuse more cost-effective: (1) reduce the initial investment cost of constructing the component; (2) increase the number of times a component is reused; and (3) reduce the cost of sclmting, adapting and reusing a component. In this paper, we focus on the third approach, and especially on the cost of adapting a pre-existing component. We present PROTEGE-II, a development environment and methodology for the construction of knowledge-based sysPermission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association of Computing Machinery.To copy otherwise, or to republish, requires a fee and/or specific permission. SSR ’95, Seattle. WA. USA terns with reusable components. This environment has been developed within the knowledge-acquisition research community. Thus, it is designed to help developers build systems that include both a knowledge base of domain information, and a problem-solving method that operates on that knowledge base. For our purposes, these two types of components are the objects for reuse. In particular, we demonstrate the reuse of a problem-solving method across two domains: configuring the parts of an elevator system and finding plausible models for the positions of helices within a ribosome strand. The elevator-configuration task is a well-studied problem in the knowledge-acquisition research community, originally described and solved by Marcus, Stout, and McDermott (1988). 1 The task is a constraint-satisfaction problem: given a set of building specifications and requirements such as elevator speed and capacity, and given a large body of knowledge about available elevator components and safety constraints, find a configuration of elevator components so that no constraints are violated. This task was chosen for the Sisyphus-2 project: a benchmark for comparing knowledge modeling efforts in the knowledge-acquisition research community (see Schreiber and Birmingham, in press). The PROTEGE-II solution to this problem has been described in detail by Rothenfluh, Gennari, Eriksson, and Musen (1994), The ribosome topology task is another type of constraint-satisfaction problem, but in a very different domain. Given information about the secondary structure of components of the ribosome structure, such as helices and coils of RNA, and distance-constraint information among those components, the task is to locate the position and orientation of those components, relative to a set of known proteins, such that no distance constraints are violated. This problem has been described by Altman, Weiser, and Noller (1994). These two constraint-satisfaction problems are clearly very different in terminology, and notably different in the size of their search space. Thus, this pair of problems should be a good testbed for software reuse: if a solution can be constructed to solve one problem, it should be adaptable to solve the other. As we will show, PROTEGE-II allows developers to minimize adaptation costs when reusing a problemsolving method. 1. This problem was originally known as the VT task, for vertical transportation.	benchmark (computing);code reuse;component-based software engineering;constraint satisfaction problem;drew mcdermott;knowledge acquisition;knowledge base;knowledge modeling;knowledge-based systems;ontology (information science);problem solving;protégé;requirement;single-instance storage;software construction;software development;strand (programming language);testbed	John H. Gennari;Russ B. Altman;Mark A. Musen	1995		10.1145/211782.316710	domain analysis;reliability engineering;knowledge base;verification and validation;cost-effectiveness analysis;software engineering process group;software sizing;software mining;computer science;systems engineering;knowledge management;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;feature-oriented domain analysis;domain engineering;software construction;development environment;software deployment;software development process;domain knowledge;software system	SE	-56.765708996061505	25.62496331093735	77498
1ac0bd2df7d960df5e23b6fdeb1f0a4c36fa29a2	a systematic mapping study of mobile application testing techniques	combination;software testing;t technology general;technology;computer science software engineering;science technology;t10 5 communication of technical information;apps;systematic mapping;mobile application testing;computer science;usability;computer science theory methods;context	The importance of mobile application specific testing techniques and methods has been attracting much attention of software engineers over the past few years. This is due to the fact that mobile applications are different than traditional web and desktop applications, and more and more they are moving to being used in critical domains. Mobile applications require a different approach to application quality and dependability and require an effective testing approach to build high quality and more reliable software. We performed a systematic mapping study to categorize and to structure the research evidence that has been published in the area of mobile application testing techniques and challenges that they have reported. Seventy nine (79) empirical studies are mapped to a classification schema. Several research gaps are identified and specific key testing issues for practitioners are identified: there is a need for eliciting testing requirements early during development process; the need to conduct research in real-world development environments; specific testing techniques targeting application life-cycle conformance and mobile services testing; and comparative studies for security and usability testing.	categorization;conformance testing;dependability;desktop computer;display resolution;mobile app;mobile application testing;requirement;software engineer;software testing;usability testing	Samer Zein;Norsaremah Salleh;John Grundy	2016	Journal of Systems and Software	10.1016/j.jss.2016.03.065	test strategy;simulation;usability;software performance testing;system integration testing;combination;computer science;systems engineering;engineering;acceptance testing;software reliability testing;software engineering;software testing;non-functional testing;technology	SE	-60.57045128177683	26.035020024445085	77523
836a5065957589be2b43857eeaf4b6e07853f151	argopn: a case tool merging uml and petri nets	case tool;petri net		computer-aided software engineering;petri net;unified modeling language	Jérôme Delatour;Florent de Lamotte	2003			merge (version control);computer-aided software engineering;petri net;unified modeling language;systems engineering;process architecture;computer science	Logic	-49.54045790421603	27.83145293719302	77565
2c0906241676dac6da0b04423eae2830267cc34f	on the determination of an appropriate time for ending the software testing process	software reliability program testing;software testing;stopping rule;project manager;counting model appropriate time determination software testing process software reliability exhaustive testing stopping rule software error;statistical model;software testing software reliability predictive models informatics system testing project management costs accuracy error correction time measurement;software model;program testing;software reliability	Software testing is widely used as a means of increasing sofware reliability. The prohibitive nature of exhaustive testing has given rise to the problem of determining when a system has reached an acceptable reliabiliy stale and can be released 1-11, This has probably become the hardest probleni facing a project manager. In this paper, a stopping rule that indicates the appropriate time at which to stop testing is presented. The rule automatically adapts to niodi'cations in the assuniptions. since it can be applied under any sofmare error counting model. A n investigation of the properties of the rule is described and the results obtained a f e r applying it to a set of real data in conjunction with two sratistical models are presented.	software testing	Nicos Malevris;E. Petrova	2000		10.1109/APAQ.2000.883781	non-regression testing;test strategy;recovery testing;reliability engineering;black-box testing;verification and validation;regression testing;real-time computing;orthogonal array testing;software sizing;software performance testing;white-box testing;manual testing;system integration testing;computer science;acceptance testing;package development process;software reliability testing;software engineering;software construction;risk-based testing;software testing;stress testing;software quality analyst	SE	-62.80779850156406	31.951666209792116	77591
cb38559630103cfef7105d5a03e12423559744f1	web application development employing domain-specific languages	domain specific language;web application development	In Web application development projects, the specification of the envisioned solution is a timeconsuming task suffering from communication problems between the developers and the business. Based on our experiences gained in several real-world projects, we propose an approach combining Domain-Specific Languages and a supporting technical platform. Web application development can thus be performed by composing building blocks and configuring them with DSL programs.	digital subscriber line;domain-specific language;web application development	Martin Nussbaumer;Patrick Freudenstein;Martin Gaedke	2006			web service;web application security;web development;web modeling;web standards;computer science;systems engineering;database;programming language	SE	-49.91930161880966	25.052987447374317	77806
5e6da0caaab05d0fdb013f8440c2c4f17e26d1dd	sbse meets software maintenance: achievements and open problems	articulo;sbse meets software maintenance achievements and open problems	Search Based Software Engineering (SBSE) is an approach to software engineering in which search based optimization algorithms are used to identify optimal or near optimal solutions and to yield insight. SBSE techniques can cater for multiple, possibly competing objectives and/or constraints and applications where the potential solution space is large and complex. Such situations are common in software engineering, leading to an increasing interest in SBSE. This paper provides a brief overview of SBSE, explaining some of the ways in which it has already been applied to program–comprehension related activities. The paper also outlines some possible future applications of and challenges for the further application of SBSE to Program Comprehension.	algorithm;feasible region;list comprehension;mathematical optimization;program comprehension;search-based software engineering;software maintenance	Massimiliano Di Penta	2012		10.1007/978-3-642-33119-0_2	test data generation;simulation;software engineering process group;computer science;systems engineering;engineering;artificial intelligence;software development;software design description;software engineering;machine learning;data mining;software walkthrough;programming language;software metric;avionics software	SE	-60.006995394311915	30.28172639177945	77842
4ef05153278b05d8912c3ae22c1d3fc329e55cbe	generic programming redesign of patterns	design pattern;parametric polymorphism;software component;generic programming;polymorphism	ion. There should be one procedure for each algorithm. Because al gorithms should work for different types, procedures must feature a certain degree of abstraction: they must accept input of various types. Most of the algorithmic e ntiti s have to be represented in an abstract way. Efficiency. However, abstraction should not lead to a computational bur den, since scientific computing requires efficient implementations. These abstr ct implementations should be about as fast as implementations dedicated to a particular d at type. Design. Still, object-oriented modeling of abstraction typically relies on operation polymorphism, which imposes an efficiency penalty due to the huge num ber of dynamic bindings that usually occur in scientific computing. In particular, d esign patterns widely use operation polymorphism. Design quality. Yet, the core ideas captured in many design patterns are desi gn structures that have often proved useful in scientific computing. Sacri ficing design patterns simply because there might be efficiency problems is not justified.	algorithm;computational science;design pattern;electronic signatures in global and national commerce act;generic programming	Thierry Géraud;Alexandre Duret-Lutz	2000			implementation;component-based software engineering;systems engineering;data type;polymorphism (computer science);software design pattern;theoretical computer science;module pattern;virtual function;generic programming;reliability engineering;computer science	PL	-50.145147491521364	31.447596704136917	77917
0a9301fa04f9102eb2120dcbf74dcda6fcd57e35	challenges and opportunities of modularizing textual domain-specific languages		Over time, domain-specific languages (DSL) tend to grow beyond the initial scope in order to provide new features. In addition, many fundamental language concepts are reimplemented over and over again. This raises questions regarding opportunities of DSL modularization for improving software quality and fostering language reuse – similar to challenges traditional programming languages face but further complicated by the surrounding editing infrastructure and model transformations. Mature frameworks for developing textual DSLs such as Xtext provide a wealth of features but have only recently considered support for language composition. We therefore perform a case study on a large-scale DSL for model-driven development of mobile applications called MD2, and review the current state of DSL composition techniques. Subsequently, challenges and advantages of modularizing MD2 are discussed and generalized recommendations are provided.	code generation (compiler);digital subscriber line;domain-specific language;interoperability;legacy code;md2 (cryptography);microsoft outlook for mac;mobile app;model-driven architecture;model-driven engineering;modular programming;multiple inheritance;programming language	Christoph Rieger;Martin Westerkamp;Herbert Kuchen	2018		10.5220/0006601903870395	systems engineering;natural language processing;computer science;domain-specific language;artificial intelligence	PL	-49.746285144741975	25.240501351551448	78342
1b756dc276348a7d64e7da4b52621cc28afb171a	model oriented software architecture	formal specification;specification pattern model oriented software architecture formal modeling languages unified modeling language hierarchical predicate transitions nets diagrammatic syntactic theory;software systems;object oriented programming;modeling language;software architecture;levels of abstraction;unified modeling language;petri nets;software architecture object oriented modeling unified modeling language software systems software design petri nets costs software engineering timing aerospace electronics;object oriented programming software architecture formal specification unified modeling language petri nets	Software architectures are heterogeneous, multiple-dimensional entities that aim to reduce the cost and ease the complexity associated with the development of large, complex software systems. To fully realize the advantages of software architectures, they need to be specified by a blend of modeling notations at the same (or at different) levels of abstractions. We discuss the benefits of a multiformalism modeling approach that integrates existing modeling languages, such as UML (Unified Modeling Language), HPrTNs (Hierarchical Predicate Transitions Nets), with an ADL known as DST (Diagrammatic Syntactic Theory).	diagram;entity;software architecture;software system;unified modeling language	Hassan Reza;Emanuel S. Grant	2004	Proceedings of the 28th Annual International Computer Software and Applications Conference, 2004. COMPSAC 2004.	10.1109/CMPSAC.2004.1342651	functional software architecture;unified modeling language;reference architecture;software architecture;model-driven architecture;computer architecture;systems modeling language;uml tool;computer science;software design;theoretical computer science;software framework;component-based software engineering;software development;software design description;service-oriented modeling;software engineering;software construction;formal specification;software architecture description;modeling language;programming language;object-oriented programming;resource-oriented architecture;object-modeling technique;petri net;software development process;use case points;software system	SE	-49.78883966717301	27.057565480449398	78427
f8725e9d4685aef6b62e9e939f1872e609fa428d	formal methods in collaborative projects	collaboration;formal methods;industrial applications	In this paper we address particular aspects of integration of formal methods in large-scale industrial projects, namely collaborative aspects. We review recent works addressing such aspects, identify some current trends and discuss directions for further research.	academy;fm broadcasting;formal methods	Anna Zamansky;Guillermo Rodríguez-Navas;Mark Adams;Maria Spichkova	2016		10.5220/0005937403960402	formal methods;computer science;knowledge management;management science;programming language;collaboration	NLP	-62.69191742109785	19.56820429472623	78877
c61c796fe20116ae829e48c6480a192572f37553	design task in virtual environments development.	3d virtual environment;software systems;development process;software engineering;autonomous agent;virtual environment;point of view	The use of Inhabited Virtual Environments (IVEs), is growing very quickly and people demand easier and more believable ways to interact in these new sites [3] [4], [5], [10], [13]. We understand by IVE a special kind of 3D virtual environments inhabited by avatars, which are the representation either of real humans users of the IVE or autonomous agents. From the point of view of software engineering, IVEs can be seen as a special kind of software systems. In this sense, they must be analyzed, designed, implemented, etc., as any other software system. However, IVEs development requires special tasks and techniques, which are not provided by traditional software engineering methodologies. The question we would like to address in our research is: define the products to be developed during the construction of an IVE and how to manage that development. In addressing this question it is necessary to define a set of steps which will provide a well-defined IVEs development process. In this paper we focus on IVEs design, detailing the tasks needed to complete such design.	autonomous robot;point of view (computer hardware company);software development process;software engineering;software system;virtual reality	Maria Isabel Sánchez Segura;Angélica de Antonio Jiménez;Ricardo Imbert;Gonzalo Méndez;Antonio de Amescua Seco	2001			simulation;human–computer interaction;computer science;systems engineering;virtual machine;software design;social software engineering;autonomous agent;software development;instructional simulation;software engineering;systems development life cycle;software development process;software system	SE	-60.86270887847775	23.861146403915487	78935
ecaffd887a96f0a6f7f75798e9a9b26d9bd48d68	concepts for abstracting away object reification at the level of platform independent models (pims)	platform independent models;platform specific models;object constraint language object reification abstraction platform independent models object oriented software development model driven architecture platform specific models unified modeling language;object oriented modeling programming unified modeling language software systems context modeling conferences computer science computer architecture process design software quality;unified modeling language object oriented languages object oriented programming software architecture;object oriented programming;development process;software architecture;levels of abstraction;object reification abstraction;unified modeling language;platform specific model;object oriented software development;platform independent model;object oriented languages;model driven architecture;object constraint language	The object-oriented software development process is composed of a number of subprocesses, namely analysis, design, implementation and verification. In model driven architecture (MDA) the result of analysis are platform independent models (PIM). Platform specific models (PSM) are derived from the PIMs via transformations, representing the design phase. We observe a lack of expressiveness of the concepts at the higher levels of abstraction (base PIMs), forcing developers to take, or at least suggest, technical decisions too early in the development process. Reification is a technique often used in the analysis phase to hide this flaw, but suggests the use of objects to represent certain artefacts. We propose an extension of the Unified Modeling Language (UML) and the Object Constraint Language (OCL) to prevent the need of reification in base PIMs to model these artefacts. We further show how these base PIMs can be transformed into different, less abstract PIMs	flaw hypothesis methodology;model-driven architecture;object constraint language;principle of abstraction;reification (computer science);reification (knowledge representation);software development process;unified modeling language	Geert Delanote;Eric Steegmans	2006	Fourth Workshop on Model-Based Development of Computer-Based Systems and Third International Workshop on Model-Based Methodologies for Pervasive and Embedded Software (MBD-MOMPES'06)	10.1109/MBD-MOMPES.2006.7	computer science;theoretical computer science;reification;software engineering;database;programming language;object-oriented programming	SE	-48.93965338469306	26.992549600401233	78997
48ed69010af47dd6d1f0d4a4292629821113797e	a nonfunctional requirement tradeoff analysis approach for software product line architecture design	tradeoff analysis;nonfunctional requirements;software product line	Software product line development paradigm allows the development of intensive products simultaneously. Nonfunctional requirement analysis for the paradigm is a challenge problem, mainly due to the massive products that are involved. Especially in the situation where some products' nonfunctional requirements are not met, how do architects keep the revision, and the impact caused by the revision both minimal? This paper investigates the issue of nonfunctional requirement tradeoff analysis for software product lines at the architecture design stage, and proposes an architectural approach to assist architects in making optimal revision decisions based on nonfunctional tradeoff analysis results. In particular, the nonfunctional requirement supported in the approach at this stage is performance. The little's law has been adopted to support performance analysis for software product line architecture design. A Unified Modeling Language profile is also developed to support performance modeling for software product line architecture design, thus to facilitate architectural performance analysis.	software product line	Lirong Dai;Yan Bai	2011	J. Comput. Meth. in Science and Engineering	10.3233/JCM-2011-0378	reliability engineering;systems engineering;engineering;operations management	Logic	-60.08539748892492	27.634888108386477	79225
bbf3ba7708382c59eeee5eef62572827b4a772e9	iso9000 based advanced quality approach for continuous improvement of manufacturing processes	meta model	The continuous improvement in TQM is considered as the core value by which organisation could maintain a competitive edge. Several techniques and tools are known to support this core value but most of the time these techniques are informal and without modelling the interdependence between the core value and tools. Thus, technique formalisation is one of TQM challenges for increasing efficiency of quality process implementation. In that way, the paper proposes and experiments an advanced quality modelling approach based on meta-modelling the “process approach” as advocated by the standard ISO9000:2000. This meta-model allows formalising the interdependence between technique, tools and core value.	experiment;interdependence;metamodeling	Salah Deeb;Benoît Iung	2006	CoRR		metamodeling;computer science;management science	DB	-57.22600922686452	19.426583471200384	79298
fe33c940b97887340f80891363e9a81627c93408	decomposing models through dependency graphs		In Model-Driven Engineering (MDE), models are the primary artifacts of software development life cycles. Being an abstraction of the real systems, models are generally believed to be less complex and better suited for developing, comprehending, communicating, and analyzing systems. However, such an advantage is decreasing with the tendency of models themselves getting more and more complex. In this paper we propose a model decomposition technique for reducing model size and consequently complexity by exploiting the notion of dependency graphs. Compared to its predecessor, this new model decomposition technique is more effective in terms of both the number of derived sub-models (more), the size of sub-models (finer), and the quality of sub-models (better). We demonstrate the improved effectiveness by applying both the previous and the new algorithm to a common example and comparing the results.		Qin Ma;Pierre Kelsen	2018	2018 International Symposium on Theoretical Aspects of Software Engineering (TASE)	10.1109/TASE.2018.00026	theoretical computer science;software development process;dependency graph;computer science;abstraction;graph	SE	-54.71917944222884	29.519612857951806	79453
c89ea89b04086b623c169e1ce52cc6121411560e	using meta-model coverage to qualify test oracles		The definition of oracles is a significant part of model transformation testing. The tester has to ensure their quality. Mutation analysis that can be used to qualify test oracles is an expensive task which is also dependent on the transformation under test’s implementation. In this paper we propose to use the coverage of the transformation’s output meta-model by the oracles as an alternative to mutation analysis. This approach has been implemented and validated through experiments.	experiment;metamodeling;model transformation;mutation testing;oracle database;oracle machine	Olivier Finot;Jean-Marie Mottu;Gerson Sunyé;Thomas Degueule	2013			metamodeling;oracle;data mining;mutation testing;reliability engineering;model transformation;engineering	SE	-57.53926276568969	31.637244741869548	79471
69dc5e14a229149d2ede77fbec8a77f578d77eae	fiesta: a generic framework for integrating new functionalities into software architectures	verification;architecture description language;architecture description languages;software architecture;user requirements;analysis;patterns;domain analysis;transformation	Integrating new functionalities into a software architecture is necessary when the application must evolve to cope with new context and user requirements. The architect has thus to manually modify the architecture description, which is often tedious and error prone. In this paper, we propose FIESTA, a generic framework for automatically integrating new functionalities into an architecture description. Our approach is inspired by TranSAT, an integration framework. However, TranSAT is dedicated to a specific architecture description language (ADL) while our approach is ADL-independent. To do so, we have performed a domain analysis, studying for many ADLs how to integrate new functionalities. Based on our domain analysis, we have defined a generic ADL model to manipulate and reason about architectural elements that are involved in integration. Furthermore, we have defined high-level abstractions to describe different kinds of integration. Finally, we have developed a generic integration engine.	architecture description language;cognitive dimensions of notations;domain analysis;high- and low-level;requirement;software architecture;user requirements document	Guillaume Waignier;Anne-Françoise Le Meur;Laurence Duchien	2007	Int. J. Cooperative Inf. Syst.	10.1142/S021884300700169X	domain analysis;transformation;enterprise architecture framework;reference architecture;software architecture;architecture description language;computer architecture;verification;database-centric architecture;computer science;applications architecture;theoretical computer science;user requirements document;software engineering;analysis;solution architecture;software architecture description;pattern;programming language;data architecture;systems architecture	SE	-52.66092734512488	26.108072837847605	79527
87644594c666e4f78e6a18e766a27b19b9d6880b	oo design methodology of a dsl using emf: (demonstration for the telco revenue assurance domain)	software engineering;object oriented;ide;software development;eclipse;domain specific language;emf;eclipse modeling framework;domain specific languages;design methodology	The software engineering community has taken a great interest in using domain-specific languages (DSLs) [1] to improve the productivity of software development. We demonstrate the design of a DSL as a variant of object-oriented development by applying UML [2] via the Eclipse Modeling Framework (EMF) [3] [4], exposing significant software functionality to the non-programmer domain experts.	digital subscriber line;domain-specific language;eclipse modeling framework;programmer;software development;software engineering;unified modeling language	Uri Shani;Aviad Sela	2006		10.1145/1176617.1176680	domain analysis;model-driven architecture;computer science;domain-specific language;software design;software development;feature-oriented domain analysis;domain engineering;software construction;programming language	SE	-50.58659689488973	25.56989261356138	79560
4196ff73ee69b4e2805d40a3dd7eba813617d93c	reconstruction of runtime software architecture for object-oriented systems	parallel genetic algorithms;mapreduce;hadoop	"""According to L. Bass et al. [8], software architecture of a system is """"the set of structures needed to reason about the system, which comprise software elements, relations among them, and properties of both."""" Software architecture is often unavailable because of reasons like architecture erosion and absence of relevant documentations [13]. To recover software architecture for regaining its advantages, various methods for software architecture reconstruction (SAR) [1,3,5,6] were proposed [13]."""	beneath a steel sky;documentation;software architecture	Hwi Ahn	2015		10.1145/2695664.2696070	reference architecture;software visualization;software architecture;space-based architecture;parallel computing;real-time computing;database-centric architecture;computer science;applications architecture;cellular architecture;software design;theoretical computer science;software design description;operating system;software construction;hardware architecture;database;software architecture description;resource-oriented architecture;data architecture;systems architecture	SE	-51.84473542765625	29.414425070262226	79628
978e84215748e3536d21d2a6245778aa9a3b2222	the morabit approach to runtime component testing	business functionality execution;ad hoc systems;runtime automatic testing logic testing system testing built in self test performance evaluation software testing computer science software systems assembly systems;runtime component testing;004 informatik;software systems;software quality morabit approach runtime component testing software systems mobile systems ad hoc systems built in test business functionality execution;built in self test;program testing;software quality built in self test program testing;built in test;morabit approach;mobile systems;development time;software quality	Runtime testing is important for improving the quality of software systems. This fact holds true especially for systems which cannot be completely assembled at development time, such as mobile or ad-hoc systems. The concepts of built-in-test (BIT) can be used to cope with runtime testing, but to our knowledge there does not exist an implemented infrastructure for BIT. The MORABIT project realizes such an infrastructure and extends the BIT concepts to allow for a smooth integration of the testing process and the original business functionality execution. In this paper the requirements on the infrastructure and our solution are presented	eclipse;hoc (programming language);requirement;run time (program lifecycle phase);scheduling (computing);software deployment;software system;test case;test suite	Dima Suliman;Barbara Paech;Lars Borner;Colin Atkinson;Daniel Brenner;Matthias Merdes;Rainer Malaka	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.169	non-regression testing;test strategy;reliability engineering;black-box testing;regression testing;real-time computing;software performance testing;white-box testing;manual testing;system integration testing;integration testing;computer science;acceptance testing;software reliability testing;operating system;software engineering;software construction;cloud testing;smoke testing;software testing;real-time testing;system testing;test management approach;software quality;software system;computer engineering	SE	-57.185105068994815	31.64600828566369	79668
7cfb1a5a638a89db519d2e63433603ac7f515949	a modular requirements engineering framework for web-based toolchain integration	tool support;goal oriented requirements engineering;integration;saas	"""Requirements Engineering (RE) tools and more generally the whole Software Engineering toolchain follow the strong trend towards web-based interface. This allows the analyst to use their tools in a """"Software as a Service"""" mode either from a local company server or directly in the Cloud. Such deployments also ease toolchain integration by connecting their respective API through secured web-services, possibly using specific software lifecycle interoperability standards. In this tool demonstration, we illustrate the results of the rewrite process of a major Requirements Engineering tool towards this purpose. Our tooling has the following key features: (i) it supports rich requirements models based on goal-oriented RE, (ii) it is implemented as a collaborative concept server based on Eclipse Modelling technology and (iii) it exposes a REST interface supporting model building, diagram edition, history retrieval, snapshot management, collaborative mode, user authentication and project management. The following scenarios will be demonstrated (1) collaborative edition of a shared RE model, (2) rich service composition with application lifecycle management tools and (3) easy web-component integration in third-party web interfaces."""	application lifecycle management;application programming interface;authentication;diagram;eclipse;internet;interoperability;requirement;requirements engineering;rewrite (programming);server (computing);service composability principle;snapshot (computer storage);software as a service;software development process;software engineering;toolchain;user interface;web application	Robert Darimont;Wei Zhao;Christophe Ponsard;Arnaud Michot	2016	2016 IEEE 24th International Requirements Engineering Conference (RE)	10.1109/RE.2016.49	computer science;systems engineering;software engineering;software as a service;requirements engineering;application lifecycle management;world wide web	SE	-49.44045060636618	21.682251187620935	79676
5d6ddf2556f15621b750778e808433652e1d5bcc	inheritance of workflows: an approach to tackling problems related to change	dynamic change;management information;workflow management;adaptive workflow;petri nets;inheritance;petri net	"""Inheritance is one of the key issues of object-orientation. The inheritance mechanism allows for the definition of a subclass which inherits the features of a specific superclass. When adapting a workflow process definition to specific needs (ad-hoc change) or changing the structure of the workflow process as a result of reengineering efforts (evolutionary change), inheritance concepts are useful to check whether the new workflow process inherits some desirable properties of the old workflow process. Today's workflow management systems have problems dealing with both ad-hoc changes and evolutionary changes. As a result, a workflow management system is not used to support dynamically changing workflow processes or the workflow processes are supported in a rigid manner, i.e., changes are not allowed or handled outside of the workflow management system. In this paper, we propose inheritance-preserving transformation rules for workflow processes and show that these rules can be used to avoid problems such as the """"dynamic-change bug."""" The dynamic-change bug refers to errors introduced by migrating a case (i.e., a process instance) from an old process definition to a new one. A transfer from an old process to a new process can lead to duplication of work, skipping of tasks, deadlocks, and live locks. Restricting change to the inheritance-preserving transformation rules guarantees transfers without any of these problems. Moreover, the transformation rules can also be ~sed to extract aggregate management information in case more than one version of a workflow process cannot be avoided."""	aggregate data;code refactoring;deadlock;hoc (programming language);lock (computer science);management information system	Wil M. P. van der Aalst;Twan Basten	2002	Theor. Comput. Sci.	10.1016/S0304-3975(00)00321-2	computer science;knowledge management;business process management;management information systems;database;event-driven process chain;petri net;workflow management system;workflow technology	DB	-55.03526775534201	19.773354733196843	79788
13a0b9e385ab69641baaf83798412a0e8fa31940	the object management group standardization of object technology (abstract)	software development;noun;paradigm shift	Object technology (OT) which has been described by some as a remarkable paradigm shift in computing is in reality a technology that allows people to think, literally, in terms of nouns and verbs as they assemble software programs. Too often, contemporary software development is characterized as an artform with mystical heritage. The Object Management Group, with over 330 members, has become the industry focal point for the development of interface standards in distributed computing. The OMG focuses its attention on creating specifications for distributed applications using object technology. The group's first specification, the Object Request Broker, has already been endorsed and committed to by over one hundred (100) companies. OMG is funded by the top computer, software, networking, and end user organizations in the information processing business. Mr. Stone will discuss the rule of OT, the OMG, and the impact on the future of client server computing and distributed applications.	client–server model;distributed computing;focal (programming language);information processing;object request broker;programming paradigm;sms language;server (computing);software development	Christopher M. Stone	1994		10.1007/3-540-57818-8_34	knowledge management;database	SE	-50.79670716108673	20.33346764923702	79798
91fee21d6b9895bbff8af45683e8d982588fe67a	goals, workflow, and value: case study experiences with three modeling frameworks		It is beneficial to understand the benefits and drawbacks of enterprise modeling approaches in certain contexts. We report experiences applying different combinations of three modeling approaches to industrial cases. Specifically, we report on experiences from four companies using a combination of goal modeling, e3 value modeling, and workflow modeling. Our findings help to guide enterprise modeling approach selection in similar contexts, and can be used to make recommendations to improve future applications of the selected modeling approaches.	unified modeling language	Jennifer Horkoff;Imed Hammouda;Juho Lindman;Jamel Debbiche;Martina Freiholtz;Patrik Liao;Stephen Mensah;Aksel Strömberg	2017		10.1007/978-3-319-70241-4_7	management science;systems engineering;computer science;goal modeling;enterprise modelling;workflow	HCI	-57.723511705937376	19.771829743703282	79838
9df638fb7c6d58cd1208a80249d5a410025d32c1	a survey of combinatorial testing	verification;modelizacion;software testing;empirical study;fiabilidad;reliability;combinatorial testing ct;methode empirique;algorithm analysis;generic algorithm;echantillonnage;metodo empirico;empirical method;priorite;metric;program verification;sampling;modelisation;verificacion programa;test case generation;diagnostic panne;generation test;fiabilite;fault diagnostic;diagnostico pana;test generation;design;metrico;analyse algorithme;covering array;muestreo;experimentation;verification programme;priority;prioridad;modeling;generacion prueba;journal magazine article;analisis algoritmo;metrique	Combinatorial Testing (CT) can detect failures triggered by interactions of parameters in the Software Under Test (SUT) with a covering array test suite generated by some sampling mechanisms. It has been an active field of research in the last twenty years. This article aims to review previous work on CT, highlights the evolution of CT, and identifies important issues, methods, and applications of CT, with the goal of supporting and directing future practice and research in this area. First, we present the basic concepts and notations of CT. Second, we classify the research on CT into the following categories: modeling for CT, test suite generation, constraints, failure diagnosis, prioritization, metric, evaluation, testing procedure and the application of CT. For each of the categories, we survey the motivation, key issues, solutions, and the current state of research. Then, we review the contribution from different research groups, and present the growing trend of CT research. Finally, we recommend directions for future CT research, including: (1) modeling for CT, (2) improving the existing test suite generation algorithm, (3) improving analysis of testing result, (4) exploring the application of CT to different levels of testing and additional types of systems, (5) conducting more empirical studies to fully understand limitations and strengths of CT, and (6) combining CT with other testing techniques.	algorithm;interaction;sampling (signal processing);system under test;test suite	Changhai Nie;Hareton K. N. Leung	2011	ACM Comput. Surv.	10.1145/1883612.1883618	simulation;computer science;artificial intelligence;empirical research;algorithm	SE	-60.45530347752284	31.46123249618178	79861
6db01824961ecd926fa17af462cacd3fa116ff99	v3studio: a component-based architecture modeling language	coordination views;design process;specification languages control system synthesis object oriented programming robot vision software architecture software reusability software tools;component based meta model;v 3 studio;graphical modeling tools;object oriented programming;modeling language;model driven engineering computer architecture programming software architecture process design proposals machine vision robot vision systems conferences design engineering;software architecture;robot vision;component based architecture modeling language;specification languages;control system synthesis;reusable design;software reusability;model driven engineering;reactive system;graphical model;evolvable designs;software tools;component based software development;vision guided robotic system design;algorithmic views;vision guided robotic system design v 3 studio component based architecture modeling language component based software development reusable design extensible design evolvable designs model driven engineering component based meta model graphical modeling tools structural view coordination views algorithmic views;meta model;structural view;extensible design	Component-based software development (CBSD) has proven to obtain highly reusable, extensible and evolvable designs. This paper presents a model-driven engineering approach to CBSD which revolves around the definition of the V3Studio component-based meta-model and a set of graphical modeling tools implemented to support it. V3Studio has been designed to model the structure and behavior of a wide variety of reactive systems by means of three complementary views, namely: one for describing the components of the architecture (structural view), and two for describing their behavior (coordination and algorithmic views). Dividing the V3Studio meta-model into these three loosely coupled views considerably simplifies the overall design process, allowing designers to reuse previously defined models. In order to show the feasibility and the benefits of the proposal, a simple but complete case study regarding the design of a vision guided robotic system was presented.	abstraction layer;component-based software engineering;computer vision;executable;finite-state machine;general-purpose modeling;graphical user interface;heart rate variability;high-level programming language;loose coupling;metamodeling;model-driven architecture;model-driven engineering;modeling language;robot;robotics;software development;vision guided robotic systems	Diego Alonso;Cristina Vicente-Chicote;Olivier Barais	2008	15th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems (ecbs 2008)	10.1109/ECBS.2008.9	metamodeling;embedded system;software architecture;model-driven architecture;simulation;design process;reactive system;computer science;systems engineering;engineering;component-based software engineering;operating system;software engineering;graphical model;modeling language;programming language;object-oriented programming;computer engineering	Robotics	-50.105771548674284	26.87317111048082	79907
dbea76bc0ed66d6f14e2489895316adb0d852846	evolving architectural patterns for web applications	ajax;web application design;software architecture;web application;design pattern;software framework;the web 2 0;architectural pattern;web technology	Web application architectural component relationships have evolved over the last decade or so to the point where they have become well established both as common design patterns and embedded in software frameworks. However with the increasing adoption of Web 2.0 technologies and Ajax based web applications, new patterns are starting to emerge. These patterns have yet to become well established in the literature, though a number of new frameworks are beginning to appear. In this paper we review the core patterns of traditional web application architectures, as described in the literature. We then move on to collect some new patterns that have begun to emerge and integrate them into a larger architectural view of how contemporary web applications are evolving. Where it is necessary to illustrate these patterns within a specific web technology, we use components from the Java Enterprise Edition.		David Parsons	2007			web service;ajax;web application security;software architecture;web development;web application;web modeling;data web;web mapping;web-based simulation;web design;architectural pattern;web standards;computer science;software framework;web api;operating system;service-oriented architecture;web navigation;web page;database;design pattern;web intelligence;web 2.0;world wide web	SE	-48.68897714401685	21.181193843624644	79940
83f27e42ff822ef1a9add7aa6786f34f1626eae0	on posteriori integration of software tools		"""This paper tries to define and exampJify the concept of """"integration"""" in the context of soflware development support environments. TIle benefits of tight integration are discussed, together with different approaches on how to achieve this properlY under the constraint of having to include existing software components and tools. The paper finally reports on the initial experience gained in building an Ada programming support environment according to those principles. 1. The Role of Integration Much hope is today focussed on the use of tools as a way increasing productivity in software development, shown, for example, by the rapidly growing activity under the label """"CASE"""". While a substantial market of tools, supporting various parts of the software lifecycle, indeed exist, few people would claim that a corresponding major productivity breakthrough has occurred. In this paper, we will focus on what might be the major obstacle before substantial gains can be shown the lack' Of integration. The basic argument is that the semantic loss and overhead imposed by moving between tools that don't know about, and contribute to, each other, is so big that it cannot be bypassed. Another aspect of the problem is that the tasks perfonned during software development never are so phased and isolated from each other, as the body of existing tools seem to imply. Infact, software development is never is truly """"automatic"""", and the role of tools is therefore most often in providing the user with the infonnation he needs, and doing so WiUl short response time and without requiring him to engage in errorprone or context breaking dialogues with different other tools. The infonnation needed often spans over phases, obvious examples being the need for accessing requirements documents, and design descriptions, in direct connection to programming and maintenance. In building support systems, the approach has often been to concentrate on selecting the """"right"""" functions, quite independently of each other. While this decomposition-oricnted approach is easier to deal with, both from a teclmical and project administrative point of view, it usually fails to recognize tile large potential of cross-service cooperation, and the obvious fact that the value and usefulness of a service always is relative to its cost, tile latter which has tluec components: (I) The cost of activating a service in tcnns of finding it and providing tile light parameters. (2) The cost, in waiting time, for tile user while the computer is working. (3) The cost of finally""""utilizing and assimilating the result of the service in tile context where the user needs it. • We call the sum of those costs the tl4rnaround time, and the purpose of our work is to minimize it. Observe that we discuss not only the turnaround time of currenUy identified atomic services, but Ule minimization of the cost for any typical pattern of work. For example, if the looking up of an imported interface is a common task, one could expect its turnaround time to be large in a traditional environment since it probably involves leaving an editor to go out in a file system, explicitly locating a file holding the interface, studying the interface and remembering it, and then returning to the first point of editing without any oUler result than what could be memorized during the break. Given the above view of the goal, it is clear Ulat imegratioll is a a key issue. The first and third components of the turnaround cost can obviously be very effectively attacked by utilizing context information making one tool explicitly utilize knowledge about the detailed state and context of the other tool. As will be described later, it also turns out that much less CPUcycles are consumed in a carefully built integrated system, making it effective in reducing even the second cost component. 1.1. A Definition of Integration Despite Um fact that integration is often mentioned as a highly desirable property of support environments, it still lacks a more precise cOlnmonly agreed on definition, and most publications never even try to be more explicit on the nature and meaning of the concept. However, as a concluding remark on the subject of integration, we propose the following: In Ule context of software development environments, we discuss integration in terms of three characterizing properties of tools: IIIlijonllity, communicational ability, and openlless of representation. Each of UlOse are explained below together with examplcs. 1.1.1. Uniformity. Measures the degree to which different tools behave in a similar way in similar situations. This spans from reusing Ule same abstract concepts whcnever possible, to the unification of syntactical aspects of the user interface. The word external imegratioll has frequenUy been used to denote the latter part of this spectrum. Examples: * Use of Ule same command language and line editing conventions. * Use of the same conventions for managing windows and menues. * Use of the same user interaction style, such as pointing-at-object, iconization, parameter defaults, and command result reporting. * Use of the same editing, viewing, and searching tool for all texts. * Use of the same conceptual model for representation of data. In a Entity-RelationshipAttribute based environment it would be natural to view most data in terms of typed, attributed, directed graphs. Other environments present other conceptual models, like strings, lists, and (mathematical) relations. * Use of similar operations on diffcrent data represented using the same model. * Use of Ule same definitions of concepts; such as version, configuration, dependency, inheritance, relation, access privilege, transaction, icon, data key, Iype, etc. ("""	ada;circuit complexity;command language;component-based software engineering;data assimilation;directed graph;formal specification;functional dependency;microsoft windows;overhead (computing);relation (database);requirement;response time (technology);software development process;string (computer science);unification (computer science);unified model;user interface	Dick Schefström	1989			component-based software engineering;systems engineering;software;computer science;conceptual model;software development process;software engineering;software construction;command language;software development;user interface	SE	-52.96605200516046	21.051843952008152	79956
2170dba1aa2363778b148ee11b07e84d07a90759	towards efficiently checking compliance against automotive security and safety standards		The growing connectivity of the systems that we rely on e.g. transportation vehicles is pushing towards the introduction of new standards aimed at providing a baseline to address cybersecurity besides safety. If the interplay of the two normative spaces is not mastered, compliance management might become more time consuming and costly, preventing engineers from dedicating their energies to system engineering. In this paper, we build on top of previous work aimed at increasing efficiency and confidence in compliance management. More specifically, we contribute to building a terminological framework needed to enable the systematization of commonalities and variabilities within ISO 26262 and SAE J3061. Then, we focus our attention on the requirements for software design and implementation and we use defeasible logic to prove compliance. Based on the compliance checking results, we reveal reuse opportunities. Finally, we draw our conclusions and sketch future research directions.	atomic formula;baseline (configuration management);computer security;cyber security standards;defeasible logic;defeasible reasoning;reference implementation;requirement;sae j1939;selective area epitaxy;software design;systems engineering;theory;web standards	Julieth Patricia Castellanos Ardila;Barbara Gallina	2017	2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2017.33	safety standards;reliability engineering;computer science;software design;software;reuse;software architecture;defeasible logic;automotive industry;sketch	SE	-57.25616497589859	22.87776607829731	79963
797b1a69dbf2933de77e4867f64f018bf4cc36ef	quality in development process for software factories according to iso 15504	development process;software engineering;software development;ontology reuse;software process	Currently the concept of Software Factories (SF), where reuse plays a leading role, is being adopted. Due to the different approaches in this area, and although SF concept is not new in Software Engineering, it is still not mature enough to clearly identify the treatment of certain variables within the process. One of these variables is Quality. Therefore, this paper presents a historical review of the SF concept, proposes an ontology based on the most recent definitions and establishes a relationship between these concepts and the ISO 15504 standard, with the purpose of specifying the systemic quality in software developer companies that decide to implement an SF strategy.	iso/iec 15504;model-driven engineering;ontology (information science);software developer;software engineering;software factory;unified process	Kenyer Domínguez;María A. Pérez;Luis Eduardo Mendoza;Anna Grimán	2006	CLEI Electron. J.		reliability engineering;personal software process;medical software;verification and validation;software quality management;software engineering process group;software sizing;systems engineering;engineering;package development process;social software engineering;software development;software engineering;software construction;software walkthrough;software measurement;software deployment;software quality control;goal-driven software development process;software development process;software quality;software metric;software quality analyst;software peer review	SE	-60.23156646869492	24.71040149776127	80005
d00727f0077b26609f20a0b961de7b22dd6dd4f2	operation context and context-based operational transformation	distributed application;control algorithm;context based ot;theoretical framework;ot;collaborative application;collaborative engineering;distributed applications;group editors;operational transformation;consistency maintenance;undo;theoretical foundation;operation context	Operational Transformation (OT) is a technique for consistency maintenance and group undo, and is being applied to an increasing number of collaborative applications. The theoretical foundation for OT is crucial in determining its capability to solve existing and new problems, as well as the quality of those solutions. The theory of causality has been the foundation of all prior OT systems, but it is inadequate to capture essential correctness requirements. Past research had invented various patches to work around this problem, resulting in increasingly intricate and complicated OT algorithms. After having designed, implemented, and experimented with a series of OT algorithms, we reflected on what had been learned and set out to develop a new theoretical framework for better understanding and resolving OT problems, reducing its complexity, and supporting its continual evolution. In this paper, we report the main results of this effort: the theory of operation context and the COT (Context-based OT) algorithm. The COT algorithm is capable of supporting both do and undo of any operations at anytime, without requiring transformation functions to preserve Reversibility Property, Convergence Property 2, Inverse Properties 2 and 3. The COT algorithm is not only simpler and more efficient than prior OT control algorithms, but also simplifies the design of transformation functions. We have implemented the COT algorithm in a generic collaboration engine and used it for supporting a range of novel collaborative applications.	anytime algorithm;causality;correctness (computer science);operational transformation;requirement;undo	David Sun;Chengzheng Sun	2006		10.1145/1180875.1180918	human–computer interaction;telecommunications;computer science;artificial intelligence;operating system;data mining;communication;management;world wide web;algorithm	AI	-49.03339748679998	22.596352554858456	80018
d696e1cd36377dc0a27748c77626e9e45543c5ce	metamod: a modeling formalism with modularity at its core	software;complexity theory;industrial dsl modeling formalism model driven engineering field bootstrapping metamod;dsls modeling modularity;prototypes;dsls;computational modeling;calculus;statistical analysis formal specification;modularity;object oriented modeling documentation computational modeling complexity theory prototypes software calculus;modeling;object oriented modeling;documentation	Because modern engineering products require more and more functionality, the models used in the design of these products get larger and more complex. A way to handle this complexity would be a suitable mechanism to modularize models. However, current approaches in the Model Driven Engineering field have limited support for modularity. This is the gap that our research addresses. We want to tackle the gap by designing and creating a modeling formalism with modularity at its core - MetaMod. We are including the modeling formalism into a prototype such that we can experiment with it. Our evaluation plan includes bootstrapping MetaMod (defining MetaMod in MetaMod) and creating an industrial DSL in MetaMod.	circuit complexity;digital subscriber line;documentation;formal system;metamodeling;model transformation;model-driven engineering;modularity (networks);prototype;semantics (computer science)	Ana-Maria Sutîi	2015	2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2015.29	documentation;computer science;systems engineering;theoretical computer science;modularity	SE	-51.93336025951543	26.15075027711191	80112
0ae05f98c8bc62268fc94f5b52f5ed425a88f1d4	enabling the collaborative definition of dsmls	community member;change proposal;particular domain;active participation;community-aware language development process;domain-specific modeling languages;dsml specification process;collaborative definition;key role;dsml design;software development process	Software development processes are collaborative in nature. Neglecting the key role of end-users leads to software that does not satisfy their needs. This collaboration becomes specially important when creating Domain-Specific Modeling Languages (DSMLs), which are (modeling) languages specifically designed to carry out the tasks of a particular domain. While end-users are actually the experts of the domain for which a DSML is developed, their participation in the DSML specification process is still rather limited nowadays. In this paper we propose a more community-aware language development process by enabling the active participation of all community members (both developers and end-users of the DSML) from the very beginning. Our proposal is based on a DSML itself, called Collaboro, which allows representing change proposals on the DSML design and discussing (and tracing back) possible solutions, comments and decisions arisen during the collaboration.	directory services markup language;domain-specific language;domain-specific modeling;gamification;object constraint language;parse tree;recommender system;software development;well-formed element;whole earth 'lectronic link	Javier Luis Cánovas Izquierdo;Jordi Cabot	2013		10.1007/978-3-642-38709-8_18	computer science;systems engineering;engineering;knowledge management;artificial intelligence;software engineering;database;management science;management;world wide web	SE	-49.83023734510478	24.436098543403155	80127
22afbfb067c0a2521abec9626619d992e9cb02b3	defect evolution in a product line environment	software independent verification and validation;evolutionary software;software systems;metrics;product line;development process;process characterization;space shuttle program;software safety;product line development;software development;verification and validation;software safety and reliability;flight control;life and mission critical software	One mechanism used for monitoring the development of the Space Shuttle flight control software, in order to minimize any risks to the missions, is the independent verification and validation (IV&V) process. Using data provided by both the Shuttle software developer and the IV&V contractor, in this paper we describe the overall IV&V process as used on the Space Shuttle program and provide an analysis of the use of metrics to document and control this process over multiple releases of this software. Our findings reaffirm the value of IV&V, show the impact of IV&V on multiple releases of a large complex software system, and indicate that some of the traditional measures of defect detection and repair are not applicable in a multiple-release environment such as this one. 2003 Elsevier Inc. All rights reserved.	content-control software;software bug;software developer;software system;verification and validation	Marvin V. Zelkowitz;Ioana Rus	2004	Journal of Systems and Software	10.1016/S0164-1212(03)00013-X	reliability engineering;personal software process;long-term support;verification and validation;verification and validation;software sizing;software verification;systems engineering;engineering;package development process;backporting;software development;software design description;software engineering;software construction;software testing;software measurement;software deployment;software quality control;metrics;goal-driven software development process;software development process;software system;avionics software	SE	-62.6635713882799	30.869651120768204	80238
eeeea775b5306af389552ec95dde9edc1235af45	method fragments for agent design methodologies: from standardisation to research	method engineering;multiagent system;technical committee;software engineering process;design process;agent based systems;design reuse;agent design;mas;agent oriented software engineering;software engineering;standardisation;multi agent systems;agents;methodologies;sep;mass;design methodology	The method engineering paradigm enables designers to reuse portions of design processes (called method fragments or chunks in literature) to build processes that are expressly tailored for realizing a system that is specific for some problem or development context. This paper initially reports the standardization attempt carried out by the FIPA Methodology Technical Committee (TC) and then presents the research activities we did starting from that proposal; these resulted in a little different definition of some of the most important elements of the approach in order to support a multi-view representation of the fragment (the views are process, reuse, storing, and implementation). The paper also describes the documents we use for representing a fragment and concludes with an example.	brian henderson-sellers;documentation;experiment;free viewpoint television;interoperability;meta-process modeling;metamodeling;method engineering;programming paradigm;prototype;refinement (computing);universal instantiation;word lists by frequency	Massimo Cossentino;Salvatore Gaglio;Alfredo Garro;Valeria Seidita	2007	IJAOSE	10.1504/IJAOSE.2007.013266	method engineering;design process;design methods;computer science;artificial intelligence;software agent;software engineering;multi-agent system;methodology;mass;software development process;standardization	SE	-51.022420488293825	21.48942976443575	80441
978f38d25c996c9bc6c57f471222faf1452678db	employing linked data in building a trace links taxonomy		Software traceability provides a means for capturing the relationship between artifacts at all phases of software and systems development. The relationships between the artifacts that are generated during systems development can provide valuable information for software and systems Engineers. It can be used for change impact analysis, systems verification and validation, among other things. However, there is no consensus among researchers about the syntax or semantics of trace links across multiple domains. Moreover, existing trace links classifications do not consider a unified method for combining all trace links types in one taxonomy that can be utilized in Requirement Engineering, Model Driven Engineering and Systems Engineering. This paper is one step towards solving this issue. We first present requirements that a trace links taxonomy should satisfy. Second, we present a technique to build a trace links taxonomy that has well-defined semantics. We implemented the taxonomy by employing the Link data and the Resource Description Framework (RDF). The taxonomy can be configured with traceability models using Open Service for Lifecycle Collaboration (OSLC) in order to capture traceability information among different artifacts and at different levels of granularity. In addition, the taxonomy offers reasoning and quantitative and qualitative analysis about trace links. We presented validation criteria for validating the taxonomy requirements and validate the solution through an example.	formal verification;graphical user interface;human-readable medium;interoperability;linked data;model-driven engineering;open services for lifecycle collaboration;requirement;requirements engineering;resource description framework;software development process;software engineering;software portability;systematic review;systems engineering;taxonomy (general);traceability;uniform resource identifier;verification and validation	Nasser Mustafa;Yvan Labiche	2017		10.5220/0006471701860198	taxonomy (biology);data mining;computer science;linked data	SE	-55.344551672252585	23.274913704995807	80472
c520c2dabe23ae21b8c32cb0dc7cafe80ca1f256	developing and analyzing classification rules for predicting faulty software components	software component		component-based software engineering	Adam A. Porter	1993			data mining;component-based software engineering;computer science;machine learning;artificial intelligence	SE	-49.48775258367264	30.925474688277735	80560
f4607d86b4400aa1a301cc14e7fb10e885dc6564	a formal specification for product configuration in software product lines	formal specification	A bulking device for making loop yarn, comprising a base with a blowing chamber, a pin insert with a yarn feeding channel and a jet insert with a yarn delivery channel, followed by a diffusor, the axis of which runs at an angle to the jet axis and which is followed by a cylindrical channel section.	formal specification;knowledge-based configuration;software product line	Huilin Ye;Yuqing Lin	2007			product design specification;formal specification;engineering drawing;systems engineering;requirement;software;formal methods;software requirements specification;computer science;software product line;yarn	SE	-56.05637652785932	28.26591542394347	80666
509ddc5799765c0c4d71e621768e9d1d48f92dfe	component-based development using uml	component based development	Component-based software development (CBD) is a potential breakthrough for software engineering. Unified Modeling Language (UML) can potentially facilitate CBD design and modeling. Although many research projects concentrate on the conceptual interrelation of UML and CBD, few incorporate actual component frameworks into the discussion, which is critical for real-world software system design and modeling. This paper reviews component-based development, including the use of UML for modeling CBD. The paper then discusses the means by which UML extension mechanisms can be used to better support the popular component framework -CORBA. Two other important component frameworks, DCOM and Web Services, are also discussed.		Luyin Zhao;Keng Siau	2002	CAIS		reliability engineering;uml tool;systems engineering;engineering;applications of uml;engineering drawing	SE	-53.658120225735935	26.028325054890015	80674
278779372fb3db17a79e0f10d20af129b05f2791	multimodel-driven software engineering for evolving enterprise systems		We advocate the use of multimodel-driven software engineering for the principled evolution of enterprise systems whose stakeholder concerns are captured using multiple interdependent models. Enterprise systems that evolve are increasingly common in healthcare, transportation, e-government and defense. These important systems must be regularly extended with new components satisfying interdependent functional, governance and quality-of-service (QoS) requirements that are modelled using different domain-specific languages. We describe key challenges associated with modelling, reasoning about QoS properties, and evolving such systems. The concepts of this engineering paradigm are presented in the context of a statistical reporting project carried out in collaboration with healthcare organisations.	domain-specific language;e-government;enterprise system;functional programming;interdependence;programming paradigm;quality of service;requirement;software development;software engineering	Richard F. Paige;Radu Calinescu;Dimitrios S. Kolovos;Nicholas Drivalos Matragkas;Dave Cliff	2013			function model;software engineering;functional software architecture;enterprise integration;enterprise modelling;process management;software engineering process group;systems engineering;social software engineering;enterprise systems engineering;computer science;enterprise software	SE	-58.116337620334185	18.911562734442654	80877
8bbe5f36d1a9e551c1182c0e13bd680b264dbf90	enumerating message paths for interaction testing of object-oriented systems	coverage criteria;uml sequence diagram;control path generation;coverage model;mm path	MM path is integration artifact of object-oriented systems and is characterized by interleaved sequence of messages and method execution paths. In the context of UML sequence diagrams, an MM path is usually found common in many message paths and concatenation of one MM path with different MM paths results in distinct message paths. Adequate testing of all message paths in UML sequence diagrams implies the coverage of all possible concatenation of constituent MM paths in different object-states, which may not be fully achieved in practical situations. With limited test effort, practitioners are compelled to consider a subset of all message paths in ad-hoc manner or priority basis. It can be possible that the selected paths may not include at least one instance of highly critical MM path, whereas less critical MM paths may have been included with multiple instances. It is, therefore, necessary that the selected message paths would contain one instance of all MM paths and their additional instances as per their priorities. To address this problem, we propose two coverage criteria: all MM paths and prioritized MM paths and an MM path-based coverage model. To obtain such coverage model, we build a graph model called as sequence integration graph from the sequence diagram and thereafter, synthesize MM paths to merge them into a set of connected trees. Further, we capture priority information of the MM paths by means of edge weights and order of concatenation among the MM paths by means of connector edges between the trees. These information captured in the MM coverage model helps to determine effective coverage of the MM paths. Our experimental results substantiate usefulness of our MM path-based coverage model for selecting message paths to satisfy all MM paths and prioritized MM paths coverage criteria in the context of integration testing of object-oriented systems with the limited testing effort.	concatenation;coverage data;hoc (programming language);integration testing;sequence diagram;test effort;unified modeling language	Debasish Kundu;Debasis Samanta	2015	Innovations in Systems and Software Engineering	10.1007/s11334-015-0264-4	sequence diagram;basis path testing;real-time computing;any-angle path planning;computer science;engineering;theoretical computer science;distributed computing	SE	-57.60221347338598	30.82708403695463	80922
4b3b6744111622f504b2dd3ef01c109369639194	requirements-level programming for rapid software evolution	software system;typical business software system;important novel element;requirements-level programming;rapid software evolution;coherent set;appropriate code part;easy detection;code structure;case study;novel tool suite;executable code	Rapid development of evolving software systems is highly associated with the ability to react quickly to changing user requirements. This paper presents a coherent set of technologies for simplifying the path from evolving requirements to code. The most important novel element on this path is a language defined at the level of requirements (understandable for non-IT experts) that is equipped with operational semantics. This means that it is possible to translate specifications written in this language, automatically into executable code. The language also allows for easy detection of changes in requirements. This detection can be propagated down to the code structure and appropriate code parts (these that are not automatically generated) indicated for rework. It will be demonstrated that the presented approach is effective and suitable for a wide range of problem domains as opposed to domain-specific approaches. This will be shown through a case study for a typical business software system, performed with a novel tool suite.	requirement;software evolution	Michal Smialek	2010		10.3233/978-1-60750-688-1-37	software requirements specification;computer science;systems engineering;programming language;engineering drawing	SE	-54.31622159852532	29.229715367059526	81027
30252319bed840eb5ead0e7419f8fbe719e61c9e	a methodology for design and documentation of persistent object bases of information systems	design methodology documentation information systems object oriented modeling user interfaces process design iterative methods production planning costs database systems;iterative refinement;user interface documentation information systems object model persistent object base object classes class relationships iterative;design process;user interface;database management systems;system documentation;object oriented programming;system documentation database management systems object oriented programming;information system;object model	An object model and a methodology for designing a persistent object base with it are presented. The modeling constructs of the object model are object classes, class relationships, functions that relate objects (instances of classes), operations on classes and objects, and the dependency of operations. The methodology is iterative and assumes the existence of a set of predefined object classes. An information system is designed as having two object classes: user interface and persistent object base. Before the design process starts, all the operations on the user interface objects must have been defined. The goal of the design is to iteratively refine the persistent object base into a set of object classes so that it can support the operations defined in the user interface and be implemented using the predefined classes.<<ETX>>	documentation;information system;iterative method;user interface	Rafiul Ahad	1990	Digest of Papers Compcon Spring '90. Thirty-Fifth IEEE Computer Society International Conference on Intellectual Leverage	10.1109/CMPCON.1990.63696	object linking and embedding;method;object model;object code;computer science;systems engineering;data access object;object;theoretical computer science;object-relational mapping;object-oriented design;common object request broker architecture;database;data transfer object;distributed object;has-a;portable object;abstract factory pattern;object definition language	DB	-50.769144623183294	23.268155757968	81063
6562e0bf2674b8ec78b3ff293eb17cd6ff52d7b4	a state-based approach to testing aspect-oriented programs	state model;transition tree;software testing;aspect-oriented programming;aspect oriented programming;object oriented programming;incremental development;design pattern	This paper presents a state-based approach to testing aspect-oriented programs. Aspectual state models, as an extension to the testable FREE state model of classes, are exploited to capture the impact of aspects on the state models of classes. To generate test suites for adequately testing object behavior and interaction between classes and aspects in terms of message sequences, we transform an aspectual state model to a transition tree, where each path from the root to some leaf node indicates a template of test cases, i.e. message sequences. Since the statebased approach is directly built upon the test design patterns for object-oriented programs, it is not only applicable to the simultaneous development of classes and aspects, but also to the incremental development of aspects based on the existing classes.	aspect-oriented software development;cross-cutting concern;design pattern;expect;fits;iterative and incremental development;separation of concerns;test case;test design;test suite;tree (data structure);unified modeling language	Dianxiang Xu;Weifeng Xu;Kendall E. Nygard	2005			software construction;data mining;programming language;unit testing;iterative and incremental development;test case;computer science;machine learning;test design;module pattern;programming domain;design by contract;artificial intelligence	SE	-54.208601047760325	31.704121711773624	81142
75c546cf2616bae6994d056c0f0235560826799b	a regulatory software maintenance environment using agent-based software configuration management	control systems;nuclear power stations;nuclear engineering computing;instruments;nuclear facility regulation;agent based;software maintenance;regulatory software maintenance environment;software configuration management;digital instrumentation;agent based software configuration management;software agents;software architecture;digital instrumentation and control systems;software maintenance model;nuclear power plants;guidelines;xml configuration management digital control digital instrumentation nuclear engineering computing nuclear power stations software agents software architecture software maintenance;power system management;i c systems;xml;xml regulatory software maintenance environment agent based software configuration management nuclear power plants digital instrumentation and control systems i c systems nuclear safety related regulation software maintenance model agent based architecture;power generation;nuclear power plant;software maintenance environmental management power generation power system management instruments digital control control systems nuclear facility regulation energy management guidelines;digital control;agent based architecture;environmental management;configuration management;nuclear safety related regulation;energy management	When nuclear power plants adopt digital instrumentation and control (I&C) systems, the inherent complexity and unpredictable nature of software create an unprecedented challenge for software maintenance. The difficulty often comes from lacking consistence among the vendors and the requirement of nuclear safety-related regulation. The aim of regulatory software maintenance environment (RSME) with agent-based software configuration management discipline is to provide guidelines and procedures for carrying out a variety of software maintenance activities through the establishment of a systematic approach to support the operation of nuclear power plant. This paper describes a few requirements of software maintenance environment, software maintenance model, RSME with agent-based architecture with XML technology and a prototype application of the digital I&C of nuclear power plant	agent-based model;prototype;requirement;software configuration management;software maintenance;xml	I-Hsin Chou;Chin-Feng Fan	2006	2006 International Conference on Dependability of Computer Systems	10.1109/DEPCOS-RELCOMEX.2006.4	reliability engineering;long-term support;verification and validation;software sizing;software configuration management;systems engineering;engineering;package development process;backporting;social software engineering;software framework;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software maintenance;software deployment;software requirements;software system;software peer review	SE	-61.558896194855436	27.881563765669572	81214
374d5b337a922d10687073addf2bfce794738dea	evaluating disaster management knowledge model by using a frequency-based selection technique	frequency based selection;disaster;disaster management;selection;model transformation;evaluating;knowledge;metamodel;model;knowledge model;frequency;management;technique	Disaster Management (DM) is a multidisciplinary endeavour and a very difficult knowledge domain to model. It is a diffused area of knowledge that is continuously evolving and informally represented. Metamodel is the output artefact of metamodelling, a software engineering approach, which makes statements about what can be expressed in the valid models of the knowledge domain. It is an appropriate high level knowledge structure to facilitate it being communicated among DM stakeholders. A Disaster Management Metamodel (DMM) is developed. To satisfy the expressiveness and the correctness of a DMM, in this paper we present a metamodel evaluation technique by using a Frequency-based Selection. The objective of this technique is to evaluate the importance of the individual concepts used in the DMM, thus, the quality of the metamodel can be measured quantitatively.	code coverage;correctness (computer science);digital molecular matter (dmm);endeavour (supercomputer);function-behaviour-structure ontology;high-level programming language;kilobyte;knowledge representation and reasoning;metamodeling;prototype;software engineer;software engineering	Siti Hajar Othman;Ghassan Beydoun	2012		10.1007/978-3-642-32541-0_2	selection;disaster;software mining;knowledge management;artificial intelligence;frequency;data mining;knowledge	SE	-58.32789028706272	22.975053614832085	81224
406be1ec0c2e04231765794abff4139c46edd2bd	an object-oriented framework for modeling and designing intelligent training systems	intelligent training system;object-oriented framework	The use of a software engineering approach in the design and development of Intelligent Training/teaching Systems (ITS) can increase productivity and improve the quality of the resulting software systems. In this paper, we describe an object-oriented framework for modeling and designing an ITS. This framework is based on software engineering principles. To illustrate our discussion, we consider an ITS—the CAD Demonstrator—which we have designed using this framework.  1997 by John Wiley & Sons, Ltd.	computer-aided design;john d. wiley;software engineering;software system	Ahmed Seffah	1997	Softw., Pract. Exper.	10.1002/(SICI)1097-024X(199710)27:10%3C1233::AID-SPE131%3E3.0.CO;2-V	model-driven architecture;computer science;systems engineering;software engineering;systems development life cycle;computer engineering	SE	-62.05762408320149	24.57659716674629	81302
7da965d23d001ab1d062fe2f7b7028249427f810	a web system trace model and its application to web design	web system;journal article;informacion documentacion;web design;ciencias sociales	Traceability analysis is crucial to the development of web-centric systems, particularly those with frequent system changes, fine-grained evolution and maintenance, and high level of requirements uncertainty. A trace model at the level of the web system architecture is presented in this paper to address the specific challenges of developing web-centric systems. The trace model separates the concerns of different stakeholders in the web development life cycle into viewpoints; and classifies each viewpoint into structure and behaviour. Tracing relationships are presented along two dimensions: within viewpoints; and among viewpoints. Examples of tracing relationships are presented using UML. This trace model is demonstrated through its application to the design of a commercial web project using a web-design process. The design artifacts in each activity are transformed based on the artifacts tracing relationship in the trace model. The model provides mechanisms for verification of consistency, completeness and coverage within each viewpoint and the connectedness across viewpoints.		Xiaoying Kong;Li Liu;David B. Lowe	2007	J. Digit. Inf.		web modeling;simulation;web design;web standards;computer science;data mining;world wide web	SE	-51.469199008533096	19.969542719425114	81349
5c7abfb92d26129ffe81efe0b86de358e5864069	posd-a notation for presenting complex systems of processes	distributed system;retail data processing;very complex business systems;financial data processing;data flow diagrams;information systems;web pages;corporate modelling;data flow diagram;distributed processing;business process models;arbitrary component subcollections;flowcharting;large system behaviour;large enterprises;complex system;systems analysis;retail data processing flowcharting systems analysis business data processing corporate modelling distributed processing information systems financial data processing;business process models large system behaviour complex process systems business processes large enterprises diagramming techniques data flow diagrams arbitrary component subcollections very complex business systems;business data processing;business computer science web pages;business;process modelling;computer science;legacy system;diagramming techniques;complex process systems;business process;business processes	When trying to understand the behaviour of large systems, such as the business processes of large enterprises, we often adopt diagramming techniques based on derivatives of data flow diagrams. For very complex systems such diagramming techniques suffer from the inability to abstract uniformly from arbitrary subcollections of components. In this paper we present an extension to conventional diagramming techniques which solves this problem. We describe how we have applied this technique to some very complex business systems and illustrate its main points with a simple example. While we have used the notation to present process models we conclude that it is applicable to the description of behaviour in any complex system of processes. Background We are concerned with the nature of change in large and complex computer-based systems. In particular we are concerned with distributed systems, comprising many individually complex, legacy components. Such systems have become the basis of all large commercial or industrial enterprises. But the nature of the business in which these enterprises engage is constantly changing. So it is necessary to change the supporting computer systems if these enterprises are to remain competitive. We conjecture that the right way to go about such changes, given the constraints imposed by the legacy systems, is to model the business process which the enterprise system supports and to show how this process maps onto the legacy components [ 1].The model must be in a form which the owners of the business process can understand, so that the proposed changes can be properly discussed with them and so that the impact of alternative changes can be assessed by them. We take this need for business user involvement to imply that the model must be presented in diagrammatic form. We have used many types of diagramming technique in our work. Data flow diagrams of the SSADM, SADT, IDEF or Petri Net variety are probably the simplest for business users to comprehend intuitively [2].Consequently they are the kind of diagram we have made most use of over the years. But they each suffer from a drawback which we have come to call the “wire syndrome”. Usually such diagramming notations use two types of component, boxes (typically) to denote processing and lines to denote data flow. The notation usually allows boxes to be nested, but no matter how deeply the hierarchy is formed, usually the items flowing between processes are at the same level of abstraction from the most detailed to the highest level diagram. For large, complex systems this proves to be a drawback. Hardware engineers have noticed a similar phenomenon (hence our use of the term “wire syndrome”) in that all their diagrams whether of a low or high level of abstraction, the lines always correspond to physical wires, or at best bundles of wires, in the eventual implementation. Over the last two years we, along with colleagues, have developed models of a number of very large businesses. For example we have modeled a significant part of the business process of the Inland 1 Department of Electronics and Computer Science, University of Southampton, SO17 1BJ (UK) P.Henderson@ecs.soton.ac.uk http://louis.ecs.soton.ac.uk/~ph/cv.html 2 International Computers Ltd, Kidsgrove, Stoke on Trent, ST7 1TL (UK) G.D.Pratten@uk03.wins.icl.co.uk Draft of 26 April 1995 POSD a notation for presenting complex systems of processes P Henderson and G. D Pratten 2 Revenue. The most detailed models were indeed data flow models. But abstractions from them were presented in a new form which we have called POSD diagrams (for Process Oriented System Design). Figure 1 shows a POSD diagram of a part of another business system we have modeled for the retail sector. This will be described in the next section when POSD notation is discussed. Each of these business systems is modeled at many levels of abstraction and thus it is possible to show the mapping between levels. Also, different views of the same system are possible. In particular there is the low level view where the basic components map exactly on to services provided by the distributed support system. One can abstract from that in different ways, combining components into higher level collections based on the structure of the distributed system or based on the structure of the component business processes. These two views in particular allow one to judge the effect of proposed business process changes in terms of the changes required to the legacy systems. POSD Notation The name we have given the notation reflects our current use for it. We are using POSD (Process Oriented System Design) notation to model the business systems of large end-user organizations. We will normally model the existing business processes and, because proposed changes are the driver, we will then model alternative future reorganizations of the business process. By showing the mapping to the installed legacy computer systems we can discuss the cost/benefit of each proposal with the owners of the business process. POSD is always used in conjunction with some base-level modeling language, such as data flow diagrams. Typically, early attempts at modeling a business process, are at (or only a little above) the data flow (document flow, work flow) level. After a while our understanding of the model is such that we can begin to form more abstract views. The principal way in which this happens is by a process of abstraction from the low-level data flow diagram. Logically related components are combined into more abstract entities, and eventually a hierarchical view is arrived at bottom-up. It is this process of abstraction which the data flow diagram (and its relations) does not support sufficiently well. What we needed was a notation which allowed arbitrary subcollections of components to be combined to form a single new, more abstract component. The consequence of this observation is that whatever the nature of a collection of components there must be an abstract component of a suitable “type” to which we can abstract that collection. The simplest solution to this apparent dilemma is to have only a single type of component. Since we a primarily concerned with process modeling we have termed our single component type a “behaviour”. A behaviour is a system which has state, performs internal actions and interacts with other behaviours. Elsewhere we have given a more comprehensive description of this concept [ 3]. Clearly we can see that the usual process/activity element of a data flow diagram is a behaviour. So too are the usual data repository components. So too, with a little more thought, are the various means of data transfer among components. Promoter Inducement Consumer Redemption Retail Outlet Purchase Figure 1 POSD model of Retail Promotion Scheme Draft of 26 April 1995 POSD a notation for presenting complex systems of processes P Henderson and G. D Pratten 3 Consider the simple POSD model shown in Figure 1. This comes from our model of a business process in Retail where the Consumer will Purchase from a Retail Outlet. The fact that the Consumer’s interface with the Retail Outlet is a Purchase is denoted by the juxtaposition of the boxes. Each is a behaviour. At this level of detail we have not said whether the method of purchasing is direct or by mail order or any of a wide variety of schemes. There are other relationships shown in the diagram. A Promoter encourages the Consumer to make certain purchases by offering Inducements (typically the promise of a gift or a discount). The Consumer can subsequently redeem this inducement, apparently by an interaction (called Redemption) with the Promoter. This particular abstract model is only one of many views of the Retail business process derived from lower-level data flow diagrams. Some views are organised (as this one) to show the business oriented abstractions while others are organised to show the location of the distributed systems.which support this process. Each box in a POSD diagram is a behaviour. The behaviour of an outer box is implemented by the combined behaviours of the inner boxes. If two boxes touch this implies that there is direct interaction between them. If two boxes do not touch this implies there is no direct interaction between them. We have not restricted interaction to data (or other artifact) flow. Since behaviours will be made up of component behaviours we will expect interaction between touching behaviours to be realized in some way at the more detailed level. We refer to the fact that two behaviours touch as a promise that we will (in a more detailed diagram) define how that interaction is accomplished. There are basically three ways in which it can be accomplished as shown in Figure 2. A and B are behaviours which interact. This interaction is accomplished either by the fact that each contains a sub-behaviour which interact in turn (C interacts with D) or one contains a sub-behaviour which interacts with a parent (C interacts with B) or finally there is a shared sub-behaviour C which is common to both. These are all the core concepts of POSD. POSD is intended for use with a suitable base-level modeling notation. We have used it with DFD’s, with Role Interaction Diagrams, with Finite State Machine notations and with Petri Nets. As an illustration of how this interworking is accomplished we turn in the next section to a very simple example.	bottom-up parsing;business process;complex system;complex systems;computer science;data flow diagram;dataflow architecture;distributed computing;enterprise system;entity;finite-state machine;high- and low-level;high-level programming language;hoare logic;idef;inferring horizontal gene transfer;legacy system;level of detail;list of concept- and mind-mapping software;map;modeling language;petri net;principle of abstraction;process modeling;purchasing;research data archiving;state diagram;structured systems analysis and design method;top-down and bottom-up design;way to go;while;gift	Peter Henderson;Graham D. Pratten	1995		10.1109/ICECCS.1995.479317	data flow diagram;complex systems;computer science;systems engineering;software engineering;management science;business process	SE	-53.02184203294844	20.68263089528329	81442
f5b1040a412a5db2fd43286454f08394d2f062cb	web-based cooperative document understanding	hypermedia markup languages;information resources;document handling;xml html character recognition image recognition text recognition prototypes uniform resource locators java internet standards organizations;document understanding;cooperative systems;web technology;user interfaces;document processing applications web based cooperative document understanding web based framework document understanding environment cooperation support web technologies edelweiss framework;user interfaces information resources document handling cooperative systems hypermedia markup languages	This paper presents our ongoing work on the design of a Web-based framework for cooperative document understanding. We begin by exposing our motivations for designing a new document understanding environment. We then describe the different levels of cooperation we intend to support and how Web technologies can help us in this respect. Finally, we present Edelweiss, the framework we are currently developing based on this approach.	modular programming;webdav;world wide web	Nicolas Roussel;Oliver Hitz;Rolf Ingold	2001		10.1109/ICDAR.2001.953815	web modeling;html;web standards;computer science;user requirements document;web navigation;web page;database;document schema definition languages;multimedia;user interface;web 2.0;world wide web;vision document;design document listing	HCI	-49.31181176658089	19.42141563380862	81693
6235245c970f602d9d3edf94e277b07d3b12f12e	model based testing for web applications: a literature survey presented.		The World Wide Web has a great impact in the world of computing. Testing of web applications is becoming more challenging task with the tremendous growth, distributed nature, dynamic nature and heterogeneity of web applications. With the growing complexity and usage of web applications, there is a need of rigorous testing techniques for producing reliable applications. Model-based testing (MBT) is a promising paradigm for generating test cases from models of the system under test (SUT). Different techniques (based on model based testing) have been presented in the literature. The focus of this study is to present a survey of model based testing techniques with specific reference to web applications. Existing literature has been surveyed using a systematic literature review (SLR) approach. Applicability of MBT for web applications have been studied, comparison of existing approaches has been presented in the study, finally strengths and limitations of existing approaches have been highlighted.	model-based testing;programming paradigm;system under test;systematic review;test case;web application;world wide web	Hasan Javed;Nasir Mehmood Minhas;Ansar Abbas;Farhad Muhammad Riaz	2016	JSW	10.17706/jsw.11.4.347-361	computer science;data science;world wide web	SE	-60.375265489102325	25.815177913084646	81755
3a09d59b98e9204fd4d7cfac343f95e508f284a1	an application framework for business developers to create service based business applications	mvc;xml service based application business process web application web based service mvc;model view controller;application framework;application software;prototypes;collaboration;companies;runtime;application software business process re engineering marketing and sales costs runtime feedback xml companies collaboration middleware;feedback;engines;web application;business;xml;middleware;humans;business process re engineering;rendering computer graphics;service based application;context modeling;business process;marketing and sales;web based service	Enabling business developers to create business applications greatly reduces development cost and increases business adaptiveness. However, lacking of an application framework that is amenable to business people makes it hard for business developers to create decent business applications. This paper presents such a business application framework that consists of application components primarily including business artifacts, forms and tasks that business developers can easily work with. The different types of components are automatically composed into a service based application with Model-View-Controller (MVC) paradigm. The advanced business developers are allowed to write scripts to manipulate the behavior of the components and mash-up with external services for better customization and integration. The design considerations for the supporting tools and run-time are also discussed in detail in the paper. At the end, the feedback we got and consolidated from practitioners is analyzed for identifying potential enhancement and major future work.	application framework;artifact (software development);business process;business software;component-based software engineering;feedback;mash-1;model–view–controller;programming paradigm;prototype;run time (program lifecycle phase);runtime system	Jie Cui;Jing Min Xu	2010	2010 International Conference on Service Sciences	10.1109/ICSS.2010.70	business model;business analysis;business transformation;business domain;business requirements;business service provider;knowledge management;artifact-centric business process model;business process management;marketing;business case;database;business process model and notation;process management;business;business process;business software;business process discovery;business rule;new business development;business process modeling;business activity monitoring;business architecture	SE	-56.24059244206932	19.616069665776237	81849
2c740ddf7ca1afcc8808ee816cb58a4c3273da7f	architectural styles for early goal-driven middleware platform selection	internet;computer science	The selection of a suitable middleware platform is a critical task in developing modern software systems. It is critical to fulfil the systemu0027s quality requirements, e. g. availability. A systematic selection should be done as early as possible within a development project, i. e. on the architectural level. Up to now no adequate method for selecting a middleware product exists, thus often ad-hoc decisions are made. As a solution to this problem, this dissertation proposes the MidArch Method based on a pre-study of usages of architectural styles. The method is based on modelling middleware platforms by middlewareoriented architectural styles, evaluating candidate architectures that conform to these styles, as well as mapping these evaluations to the platform level. Two case studies using industial systems are presented. Furthermore, the thesis contains contributions in the areas of software architecture foundations and the definition of architectural styles and patterns.	middleware	Simon Giesecke	2008	Softwaretechnik-Trends		real-time computing;simulation;architectural pattern;computer science;systems engineering;middleware	SE	-55.86334699564636	27.16051008573779	81871
146f846c6149f8bd9641a312a391a78aebb2ad27	a model driven xml transformation framework for business performance management	business document;xml format;xml monitoring event detection runtime laboratories style sheet languages utility programs statistics humans buildings;machine readable xmi format xml format business document business process integration code reuse business performance management;machine readable xmi format;model driven development;model validation;code reuse;business data processing;xml;xml business data processing;business performance management;business process integration	As XML formats have been widely adopted for representing business documents both within and across enterprises, XML to XML translation becomes a common and critical component for business process integration. Due to limitations of popular approaches such as XSLT for XML translations, we designed a model driven development framework for XML to XML translation with the additional benefits of code re-use and strong built-in model validation. We further applied this framework to the domain of business performance management, converting documents from human-readable XML format to machine-readable XMI format	business process;human-readable medium;model-driven engineering;xml metadata interchange;xslt	Shyh-Kwei Chen;Michael Wahler;Kumar Bhaskaran;Hui Lei;Henry Chang;Joachim H. Frank	2005	IEEE International Conference on e-Business Engineering (ICEBE'05)	10.1109/ICEBE.2005.10	xml catalog;xml validation;binary xml;xml encryption;xml base;simple api for xml;xml;streaming xml;computer science;document type definition;document structure description;xml framework;data mining;xml database;xml schema;database;regression model validation;xml signature;ebxml;world wide web;xml schema editor;cxml;efficient xml interchange;statistics;sgml	DB	-52.325921353335545	20.824955831758405	81874
386b377993041d883c0d0218a18ce0c8aef83185	model-driven product consolidation into software product lines			model-driven integration;semiconductor consolidation;software product line	Benjamin Klatt;Klaus Krogmann	2012	Softwaretechnik-Trends		software;systems engineering;consolidation (soil);computer science	Crypto	-62.54704504823567	24.929966326381102	81919
9c5e6fc0d1ab674735c7319eb71f2c3a0109c17f	formulating the architectural design of enterprise applications as a search problem	architectural design;quality attributes;object oriented methods;financial system software architecture design enterprise application search problem decision making method design decision;search problems australia decision making process design application software computer science design engineering management information systems technology management engineering management;search trees;software architecture;financial system;software architecture design;tree searching;decision making software architecture software quality tree searching object oriented methods;software quality	Software architecture design is widely recognized to be a complex task. This is especially true when designing enterprise applications that require deciding about a number of architectural design issues, often involving selecting among various design alternatives that impact differently on a set of quality attributes. In order to facilitate the selection process, earlier research efforts have already investigated the use of quantitative decision-making methods for scoring and ranking design alternatives. These methods, however, treat individual architectural decisions independently without considering their synergistic interrelationships. We argue that many architectural decisions are highly interdependent with each other, and thus need to be treated jointly in the selection process. To support this claim, we have identified two types of dependencies that can occur among different design decisions. We show that in particular situations, these dependencies require employing unconventional methods in determining the appropriate design solution. For this purpose, we suggest formulating the architectural design task as a search problem, and also show how search trees can be useful in this regard. We apply these ideas on a financial system, in order to demonstrate their applicability in a real setting.	brute-force search;endeavour (supercomputer);enterprise software;interdependence;list of system quality attributes;principle of good enough;search problem;shadowrun;software architecture;synergy	Tariq Al-Naeem;Feras T. Dabous;Fethi A. Rabhi;Boualem Benatallah	2005	2005 Australian Software Engineering Conference	10.1109/ASWEC.2005.26	functional software architecture;connascence;reference architecture;software architecture;software design pattern;probabilistic design;architectural pattern;computer science;systems engineering;engineering;software design;component-based software engineering;software design description;object-oriented design;software engineering;interaction design pattern;software construction;enterprise architecture management;data mining;management science;resource-oriented architecture;computer-aided software engineering;high-level design	SE	-58.655176465565916	25.00737818869092	81921
75e8d571eb7e1c493a733a0e6cfc3ca7823ca788	feature-oriented analysis and specification of dynamic product reconfiguration	front end;dynamic reconfiguration;qa75 electronic computers computer science;product line engineering;dynamic adaptation	In many application domains, scenarios have been developed that benefit from the idea of ambience; Systems will not necessarily be activated by people anymore, but will react on their own to situations they recognize. It, thereby, must dynamically adapt itself to changes in the technical environment or user context. In addition, such dynamically reconfigurable products must be customized to the individual needs of particular users. Product line engineering can be applied to create these variants efficiently; however, means for handling adaptation capabilities at a generic level are required. This paper introduces the front-end of such a means by describing an approach for analysis and specification of features that vary as a part of reconfigurations at runtime.	application domain;reconfigurability;run time (program lifecycle phase)	Jaejoon Lee;Dirk Muthig	2008		10.1007/978-3-540-68073-4_14	real-time computing;simulation;engineering;operations management	SE	-49.55311349757405	22.928451469864935	81945
ae9ff56f1cd708a235a327e1f72daf7c20d37ad7	aaa: a modeling language for software production environments	software development process;modeling language;organizational design;execution environment;experience factory;process model;modeling methodology;reference architecture	If a software production environment wants to reap the benefits of reuse on an organizational level, it must itself be designed to optimize each resouce's access to reusable material and to efficiently implement a reuse-centered software development process. One approach to such redesign, the Experience Factory, divides the environment between the resources involved in reuse activities and the resources involved in current projects. There are many variations on the Experience Factory theme, based on the widely varying characteristics and needs of different environments. The Reference Architecture is used as a model for describing these variations in more detail. Besides explaining the Experience Factory and Reference Architecture models, this paper focuses on AAA, a process modeling language enhancement for modeling the configuration of resources, or the organization, of a software production environment. AAA is based on, and is meant to formalize, the Reference Architecture. The need for an organizational modeling methodology arises from research in incremental organizational design, organizational simulation, and experience packaging. As well as describing the syntax, semantics, and motivation of AAA, this paper also describes, at a high level, the AAA execution environment, which allows the modeler to analyze and modify a AAA model, to simulate projects executed by a modeled architecture, and to control processes currently executing in a modeled architecture. The last section of this paper presents a case study that illustrates some of the issues that arise in modeling organizations and demonstrates the modeling power of AAA.	aaa (video game industry);modeling language	Carolyn B. Seaman	1992		10.1145/962240	reference architecture;simulation;computer science;knowledge management;operating system;service-oriented modeling;software engineering;process modeling;database;distributed computing;modeling language;software development process;organizational architecture	PL	-56.301770338690815	21.37640673847355	81965
e86b3439cd7c8d86920ed6fe777f2ecec0ee37c4	identifying variability in process performance indicators		The performance perspective of business processes is concerned with the definition of performance requirements usually specified as a set of Process Performance Indicators (PPIs). Like other business process perspectives such as control-flow or data, there are cases in which PPIs are subject to variability. However, although the modelling of business process variability (BPV) has evolved significantly, there are very few contributions addressing the variability in the performance perspective of business processes. Modelling PPI variants with tools and techniques non-suitable for variability may generate redundant models, thus making it difficult its maintenance and future adaptations, also increasing possibility of errors in its managing. In this paper we present different cases of PPI variability detected as result of the analysis of several processes where BPV is present. Based on an existent metamodel used for defining PPIs over BPs, we propose its formal extension that allows the definition of PPI variability according to the cases identified.		Bedilia Estrada-Torres;Adela del-Río-Ortega;Manuel Resinas;Antonio Ruiz Cortés	2016		10.1007/978-3-319-45468-9_6	work in process;business process;systems engineering;performance indicator;metamodeling;computer science	SE	-56.48072982859881	23.576770159143084	82267
50f626e91d167fc5a11c759cacdbb1d68bd48a7b	describing variability with domain-specific languages and models		This tutorial will teach participants about domain-specific languages and models, where they can best be used (and where not), and how to apply them effectively to improve the speed and quality of product development within a product line.	domain-specific language;new product development;spatial variability	Juha-Pekka Tolvanen;Steven Kelly	2018		10.1145/3233027.3233059	new product development;control engineering;natural language processing;domain-specific modeling;computer science;domain-specific language;artificial intelligence	NLP	-51.06009784456824	24.52179184569292	82291
db7ef3b395e5387ffed7bfd06e42a4fb3a4825bf	mining and applying design patterns to agent-based systems	design pattern		agent-based model;design pattern	K. Palanivel;Marie Stanislas Ashok;S. Kuppuswami;V. Amouda	2003			artificial intelligence;machine learning;pattern recognition;computer science;software design pattern;design pattern;structural pattern	EDA	-50.84510766589094	26.123075439099058	82413
3b45fa568d421a3b08ce3b2fc0ea4661582a9855	object-oriented technology transfer to multiprocessor system-level synthesis	encapsulation;directed acyclic graph;multiprocessor system level synthesis;design management;design reuse;learning;software libraries;object oriented technology transfer;information science;system modeling;application software;building block;multiprocessor systems;information hiding;hardware engineering;high level synthesis object oriented programming multiprocessing systems technology transfer software engineering;object oriented programming;software engineering;synthesis;component design manageability;technology transfer;high level synthesis;object oriented systems;cost accounting;object oriented;hardware design;multiprocessing systems;object oriented technology;system reuse;design database;off the shelf;high level architecture;system reuse object oriented technology transfer multiprocessor system level synthesis hardware engineering software engineering hardware design system modeling design reuse design database component design manageability;object oriented modeling;technology transfer multiprocessing systems hardware software engineering application software software libraries object oriented modeling encapsulation cost accounting information science;hardware;design methodology	Technology transfers between software and hardware engineering date back to a decade and a half. Object-oriented technology from software engineering is one such successful transfer to hardware design. There is a natural correspondence between object-oriented concepts and hardware design. The work presented in this paper extends the basic application of object-oriented technology to system-level synthesis such that not only system modeling uses object-oriented technology, but the synthesis process itself is objectoriented. The basic object-oriented structures required for synthesis are defined. How designs can be reused by storing them in a design database and then retrieving them is explained. A simple implementation along with application example illustrate how object-oriented technology increases component design manageability, enforces synthesis efficiency, and saves design time and effort through the reuse of complete subsystems.	gadget (computer science);multiprocessing;software engineering;systems modeling	Pao-Ann Hsiung;Trong-Yen Lee;Sao-Jie Chen	1997		10.1109/TOOLS.1997.713555	real-time computing;computer science;systems engineering;hardware architecture;design technology;computer engineering	PL	-48.997107236263545	31.613942553520516	82453
b81596ff5951eed06e64f3d82e1abe87075459b7	design decisions for the incremental adage framework	data model;software maintenance;entity relationship model;software development;data models;environmental management;common data model;computer architecture;spectrum;programming	Adage is an incremental software development support environment**. Adage architecture is underlined by the concept of wide-spectrum services around a common data model, the GDL. This model extends the entity-relationships model and provides useful concepts to support genericity and incrementality like inheritance and self-reflexion. Services respond both to end-user and administrator requirements. The last point is achieved through an active help for tool integration and tool building and so for making the environment evolve to cover the needs.	data model;generic programming;global variable;jean;requirement;software development	Jean-Louis Giavitto;Guy Rosuel;Agnès Devarenne;Anne Mauboussin	1990			spectrum;incremental build model;entity–relationship model;data model;computer science;systems engineering;knowledge management;software framework;software development;operating system;software engineering;iterative and incremental development;data mining;programming language;goal-driven software development process	SE	-50.92829475720924	27.399311842926863	82542
21f43541264966ff9c4aa45a846207bbf899b2a3	a logical approach to systems engineering artifacts: semantic relationships and dependencies beyond traceability—from requirements to functional and architectural views		Not only system assurance drives a need for semantically richer relationships across various artifacts, work products, and items of information than are implied in the terms “trace and traceability” as used in current standards and textbooks. This paper deals with the task of working out artifacts in software and system development, their representation, and the analysis and documentation of the relationships between their logical contents—herein referred to as tracing and traceability; this is a richer meaning of traceability than in standards like IEEE STD 830. Among others, key tasks in system development are as follows: capturing, analyzing, and documenting system-level requirements, the step to functional system specifications, the step to architectures given by the decomposition of systems into subsystems with their connections and behavioral interactions. Each of these steps produces artifacts for documenting the development, as a basis for a specification and a design rationale, for documentation, for verification, and impact analysis of change requests. Crucial questions are how to represent and formalize the content of these artifacts and how to relate their content to support, in particular, system assurance. When designing multi-functional systems, key artifacts are system-level requirements, functional specifications, and architectures in terms of their subsystem specifications. Links and traces between these artifacts are introduced to relate their contents. Traceability has the goal to relate artifacts. It is required for instance in standards for functional system safety such as the ISO 26262. An approach to specifying semantic relationships is shown, such that the activity of creating and using (navigating through) these relationships can be supported with automation.	design rationale;functional specification;interaction;requirement;std bus;software documentation;system safety;systems engineering;traceability;tracing (software)	Manfred Broy	2017	Software & Systems Modeling	10.1007/s10270-017-0619-4	functional specification;computer science;architecture;documentation;systems engineering;traceability;requirements traceability;view model;tracing;reverse semantic traceability	SE	-55.49242359702168	23.593079690715424	82653
fa269bb4e6dc6434da7ee6798f25a8e00b18b5de	enabling collaborative modelling for a multi-site model-driven software development approach for electronic control units	computer science and informatics	Name of Author: Frank Grimm Thesis Title: Enabling collaborative modelling for a multi-site modeldriven software development approach for electronic control units An important aspect of support for distributed work is to enable users at different sites to work collaboratively, across different sites, even different countries but where they may be working on the same artefacts. Where the case is the design of software systems, design models need to be accessible by more than one modeller at a time allowing them to work independently from each other in what can be called a collaborative modelling process supporting parallel evolution. In addition, as such design is a largely creative process users are free to create layouts which appear to better depict their understanding of certain model elements presented in a diagram. That is, that the layout of the model brings meaning which exceed the simple structural or topological connections. However, tools for merging such models tend to do so from a purely structural perspective, thus losing an important aspect of the meaning which was intended to be conveyed by the modeller. This thesis presents a novel approach to model merging which allows the preservation of such layout meaning when merging. It first presents evidence from an industrial study which demonstrates how modellers use layout to convey meanings. An important finding of the study is that diagram layout conveys domain-specific meaning and is important for modellers. This thesis therefore demonstrates the importance of diagram layout in model-based software engineering. It then introduces an approach to merging which allows for the preservation of domain-specific meaning in diagrams of models, and finally describes a prototype tool and core aspects of its implementation.	diagram;modeller;model-driven architecture;model-driven engineering;prototype;software development process;software engineering;software system	Frank Grimm	2012			human–computer interaction;engineering informatics;computer science;systems engineering;informatics;materials informatics;computer engineering	SE	-54.8829591508073	24.304798579594912	83042
daa48b3aa41f2f17c64af0d2069e7c997bc8f372	on service-oriented architectural concerns and viewpoints	software;technological innovation;service orientation;service oriented architecture technological innovation software engineering computer science software architecture context aware services computer architecture systems engineering and theory fuzzy systems uncertainty;data mining;runtime;software engineering;computer architecture;software architecture;literature review;book reviews;service oriented architecture;software architecture service oriented architecture software engineering	Despite the many publications around the innovation and challenges introduced by SOSE and SOA, the ‘real’ differences with traditional software engineering and software architecture are still very fuzzy. To better understand the innovative points (if any), in this work we identified seven fundamental differences by conducting a literature review, linked them to some service relevant aspects and mapped the differences & service aspects on the well-known architecture-related concepts of ‘architectural concerns’ & ‘architectural viewpoints’. As such, we were able to identify an initial set of requirements for service-oriented viewpoints. If specialized in industrial contexts, we would be able to exemplify innovative points by capturing service relevant aspects. In perspective, this work seems to scale down ‘innovation’ of SOSE and SOA, to ‘relevance’ of service aspects to engineering and architecture.	exemplification;fuzzy logic;requirement;service-oriented device architecture;service-oriented modeling;software architecture;software engineering;whole earth 'lectronic link	Qing Gu;Patricia Lago	2009	2009 Joint Working IEEE/IFIP Conference on Software Architecture & European Conference on Software Architecture	10.1109/WICSA.2009.5290822	multilayered architecture;enterprise architecture framework;functional software architecture;reference architecture;software architecture;architecture tradeoff analysis method;database-centric architecture;architectural pattern;computer science;systems engineering;engineering;applications architecture;social software engineering;software development;service-oriented modeling;software engineering;service-oriented architecture;hardware architecture;service;solution architecture;software architecture description;view model;resource-oriented architecture;data architecture;systems architecture;computer engineering	SE	-60.163056080496055	19.93913718813541	83076
1b20e252ac5d42b3fb70ebaf2a66313a9c177572	supporting requirements modelling in the malay language using essential use cases	natural language interfaces;round trip engineering;keywords essential use case;malay natural language extraction requirement modelling natural language ambiguity english text semiformal modelling round trip refinement human centric approach requirement engineering essential use cases toolset essential interaction modelling;swinburne;abstracts natural languages libraries software conferences computational modeling educational institutions;text analysis;natural language processing systems essential use cases;natural languages;text analysis natural language interfaces natural language processing;requirements engineering;essential use cases;conference paper;human centric;visual languages;humancentric modelling;natural language requirements;toolsets;requirements modelling;natural language processing;roundtrip;humancentric modelling natural language requirements essential use cases requirements engineering round trip engineering;support requirements	Requirements are typically modelled in natural language, leading to inconsistencies, incompleteness and incorrectness due to inherent natural language ambiguities and lack of precise modelling rules. In previous work, we developed a technique and toolset to support extraction of requirements from English text and supporting semi-formal modelling and roundtrip refinement using Essential use cases, helping to mitigate some of these problems. In this paper we describe new work applying this human-centric approach to requirements engineering to the Malay language. We describe an extension of our original Essential Use Cases toolset to support requirements modelling in the Malay language essential interaction modelling, and results of a preliminary experiment to gauge our tool's effectiveness in supporting Malay natural language extraction and round-trip requirements refinement.	correctness (computer science);natural language;refinement (computing);requirement;requirements engineering;semiconductor industry	Massila Kamalrudin;John Grundy;John G. Hosking	2012	2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)	10.1109/VLHCC.2012.6344503	natural language processing;computer science;linguistics;programming language	SE	-53.51308780401838	21.39970465099278	83162
a82deb087b3b45596231ce27bfa8247bf9d6f11f	representation of variability in software product line using aspect-oriented programming	software variability representation;aspectj;formal specification;aspectj software variability representation software product line aspect oriented programming language software development methodology component asset reuse assembling process grammar elements mini system requirements;software reusability formal specification grammars object oriented programming product development software development management software process improvement;software process improvement;component asset reuse;object oriented programming;software development methodology;asset management assembly productivity programming time to market software development management engineering management costs design engineering product design;grammars;grammar elements;aspect oriented programming;software reusability;assembling process;aspect oriented programming language;mini system requirements;aspect oriented;time to market;software product line;software development management;product development	Software development methodology has been being developed for the goal of improvement in productivity and reduction in time-to-market through the reuse of component asset, and software product line is designed for the effective management and use of the asset through the separation of commonality and variability. The existing methods that implement software product line interfere massively with the core asset, which require high cost in assembling level reducing the effectiveness. This paper introduces aspect-oriented programming (AOP) as the method for the improvement of the assembling process in software product line. The method that assembles core asset and variabilities is described by grammar elements such as Join point, pointcut and advice without code-change. We analyze the requirements of the mini-system as an example adapting AOP and show its practicality by the implementation of aspect-oriented language, AspectJ	aspect-oriented programming;aspectj;heart rate variability;join point;pointcut;requirement;software development;software product line	Seung-hyun Heo;Eun Man Choi	2006	Fourth International Conference on Software Engineering Research, Management and Applications (SERA'06)	10.1109/SERA.2006.57	aspect-oriented programming;computer science;systems engineering;software development;software engineering;software construction;programming language	SE	-57.09457656039334	27.417972995567517	83339
fe2a862b27f61bf8efc3b21a2804d7ad66f0b01d	a synthesised approach to goal-oriented requirements engineering		Requirements engineering for complex socio-technical systems has frequently proved difficult and costly to undertake; and has often resulted in inappropriate applications being built. Despite research in requirements engineering, problems still exist. A new family of approaches from different academic stables—goaloriented requirements engineering, socio-technical systems development, and business process modelling—appears to offer potential for improving this situation. However, it has proved difficult to select and apply the appropriate parts of each of these approaches. To address this problem, a framework of requirements engineering method building principles and features has been created from a critical of these approaches. This framework has been used both to synthesise a new method, and to compare it to these new approaches. A large real-world case study was used to validate the new method. Critical evaluation has identified areas for further work on the new method.	business process;requirements engineering;sociotechnical system;software development process	Stewart John Marshall Green	2004				SE	-62.803354583090076	18.41840578857455	83855
61af92dca20ae0dc327610ea565ed08e06a865bc	the websa approach: applying model driven engineering to web applications	web engineering;uml;transformations;qvt;software architecture;model driven engineering;architectural patterns	The Web engineering research community has proposed several Web design methods that have proven successful in the specification of the functional aspects (such as domain, navigation and presentation) posed by Web applications. However, the architectural aspects are often ignored in the design and the Web application is not specified enough. This development process produces a gap between the Web design models and the final implementation. To overcome this limitation, we extend the different Web methodologies with a generic approach called WebSA. WebSA is based on the Model Driven Engineering (MDE) paradigm that promotes models as the primary artifacts needed to carry out a software project from beginning to end. To do this, WebSA proposes a Model Driven Development made up of a set of UML architectural models and QVT model transformations as a mechanism for (1) integrating the functional aspects of the current Web methodologies with the architectural models as well as for (2) defining a set of transformations from the architectural models to platform-specific models such as J2EE, .NET, etc. To illustrate our approach, in this paper we combine WebSA with the OO-H method, to tackle the design of a running example such as the Travel Agency system.		Santiago Meliá;Jaime Gómez	2006	J. Web Eng.		transformation;unified modeling language;software architecture;model-driven architecture;web modeling;simulation;architectural pattern;computer science;systems engineering;software engineering;database;web engineering	Web+IR	-53.50499852588493	24.936836609727074	83867
373e094c1f7c7ab7d7e72947062307614a3a4264	templates for textual use cases of software product lines: results from a systematic mapping study and a controlled experiment	information systems applications incl internet;software engineering programming and operating systems;programming languages compilers interpreters;software engineering;computer science general	Use case templates can be used to describe functional requirements of a Software Product Line. However, to the best of our knowledge, no efforts have been made to collect and summarize these existing templates and no empirical evaluation of the use cases’ comprehensibility provided by these templates has been addressed yet. The contributions of this paper are twofold. First, we present a systematic mapping study about the SPL variability description using textual use cases. From this mapping, we found twelve SPL use case templates and observed the need not only for the application of these templates in real SPL but also for supporting tools. Secondly, this work presents an evaluation of the comprehensibility of SPL use cases specified in these templates through a controlled experiment with 48 volunteers. The results of this experiment show that the specification of variabilities in the steps’ numeric identifiers of the textual use cases is better to the use case understanding than the other approaches identified. We also found evidence that the specification of variabilities at the end of the use cases favors the comprehension of them and the use of questions associated to the variation points in the use cases improves the understanding of use cases. We conclude that each characteristic of the existing templates has an impact on the SPL use case understanding and this should be taken into account when choosing one.	functional requirement;identifier;list comprehension;software product line;spatial variability	Ismayle de Sousa Santos;Rossana M. de Castro Andrade;Pedro de Alcântara dos Santos Neto	2015	Journal of Software Engineering Research and Development	10.1186/s40411-015-0020-3	systems engineering;engineering;software engineering	SE	-58.90988832433471	30.485990635332303	83925
75fda61b29f09df3abb8aa521c96d413ebc334c5	influencing generative design through continuous evaluation: associating costs with the coffeemaker shape grammar	continuous evaluation;product design;complete product;design process;grammar rule;final cost;generative design;associating cost;final shape;shape grammar;overall cost;final product;grammar rules expression;coffeemaker shape grammar	A grammatical approach to product design is demonstrated. In particular, shape grammars are shown to be especially useful for products that are differentiated primarily on the basis of form yet driven by function; they allow products to be designed as a sequence of well-defined steps. However, it is not always clear how to choose the sequence of rules that should be applied to generate the final shape. In this paper we demonstrate that at each stage during the process, partial designs of the final product can be used to provide feedback to the designer based on specific design objectives and thus suggest possible rule choices. We take advantage of the shape grammar for the generation of coffeemakers introduced by Agarwal and Cagan, and associate with the grammar rules expressions that model manufacturing costs. With each application of a shape grammar rule, an understanding of the overall cost of manufacturing the product is incrementally improved. Thus, at each stage of the design process the designer has an indication of what the overall cost of the product will be and how the selection of one grammar rule over another influences the final cost. Once the complete product is generated, an appraisal of its manufacturing cost is given to the designer. This evaluation methodology helps the designer understand the implications of decisions made early on in the design process. We have also verified the accuracy of this approach through the costs of some commercially available coffeemakers, generated by this method, which are comparable to the costs for those designs listed in the literature.		Manish Agarwal;Jonathan Cagan;Katherine G. Constantine	1999	AI EDAM		systems engineering;engineering;artificial intelligence;engineering drawing	AI	-56.473345880914934	24.763262707655585	83945
3754a0d69503f7f33fd6c3915a605b90b600ff7c	using similarity patterns in developing web applications - an approach to enhance reuse and maintainability			web application	Damith C. Rajapakse;Stan Jarzabek	2010				Web+IR	-48.46471197861048	22.391173434802855	84120
be49a950724354d65e72d1779a409c82b9101a47	a structured methodology for developing production systems	production system	Abstract   Issues such as project management, documentation, and maintenance, typically associated with large traditional sofware development projects have recently become important concerns in the development of expert systems. We describe a structured methodology for the development of production rule-based expert systems. The methodology prescribes a procedure to help knowledge engineers manage the complexity of a knowledge base by viewing rule and parameter dependencies at successive levels of abstraction. Parameters are clustered into modules, in manner analogous to functional decomposition in structured design. The modularization thus obtained provides three significant benefits: ease of subsequent knowledge base maintenance, enhancement of code reusability, and support for knowledge base verification. The visual tools used by the methodology facilitate communication between knowledge engineers and experts and provide ongoing documentation of the system.	production system (computer science)	Ritu Agarwal;Mohan Tanniru	1992	Decision Support Systems	10.1016/0167-9236(92)90042-N	legal expert system;knowledge base;computer science;knowledge management;artificial intelligence;knowledge-based systems;data mining;database;production system	Robotics	-56.45316346664386	22.68087257713381	84343
081052cf21df294b40a4e6588b1f4530131d441f	representational deficiency of process modelling languages: measures and implications	representation theory;080603 conceptual modelling;ontological analysis;process modelling;business process;process modelling languages	The large number of available process modelling languages has given rise to the need for evaluation and comparison of their representational capabilities. Over the last few years, the research community has risen to the challenge by carrying out a significant amount of work in the area of such analysis. Much of this effort is based on the Bunge-Wand-Weber representation model, a common benchmark used for the analysis of grammars that purport to model the real world and the interactions within it. However, the carried out BWW analyses of various process modelling languages exist largely separately from each other, with no comprehensive effort at the comparative measurement of their representational capability. This paper introduces four measures that, together, reflect the representational capacity and clarity of a process modelling language. These four measures are used in this paper to compare seven popular process modelling languages. The work provides insights into the representational deficiency similarities and differences between process modelling languages and also predicts some of their implications for practice.	angular defect;benchmark (computing);interaction;modeling language;process modeling	Marta Indulska;Jan Recker;Michael Rosemann;Peter F. Green	2008			natural language processing;representation theory;economics;computer science;artificial intelligence;process modeling;business process;management	SE	-55.2648040070616	21.208661107523316	84351
8173688fcdd290da4ecbd8aa6b45285f5298dc57	fundamental tasks in software development environments	conceptual framework;software development environment	After having established the basic terms of the eld of software development, we present a conceptual framework to help establish the key tasks to be performed in this eld. The eld is characterized by two orthogonal concepts: Programming-in-the-Large (PitL) and Programming-in-the-Many (PitM). These concepts can be further subdivided into the tasks of Connguration Management and Version Control (for PitL), and Personnel Management and Resource Management (for PitM). The main body of this paper is dedicated to a thorough analysis of these tasks. The conceptual framework is then applied to two systems to show how to use it to evaluate and compare systems. Finally is given a discussion of the presented framework, both in its own right and with relation to other work.	conceptual schema;integrated development environment;programming in the large and programming in the small;software development;version control	Lars Bendix	1995	Informatica (Slovenia)		software construction;resource-oriented architecture;software peer review;software design description;goal-driven software development process;systems engineering;software development;distributed computing;social software engineering;crowdsourcing software development;computer science;knowledge management	SE	-51.588801812520494	27.59107000129027	84352
8c5c5b992816aade2a85a5b6a2ea544a7659f767	model/analyzer: a tool for detecting, visualizing and fixing design errors in uml	model design;uml;software engineering;modeling language;design rules;integrated development environment;model error;ocl;consistency checking;modeling tool	Integrated development environments are widely used in industry and support software engineers with instant error feedback about their work. Modeling tools often react to changes at a coarse level of granularity that make reasoning about errors inefficient and late. Furthermore, there is often a lack of appropriate visualizations of model errors and information on how to fix them. This paper presents the Model/Analyzer tool, an eclipse-based plug-in for the IBM Rational Software Modeler (RSM). The tool lets software engineers define arbitrary design rules and provides instant feedback on their validity in context of a model. Design errors are then visualized together with the information on what parts of the model contributed to them and how to fix them. The tool is fully automated and currently supports OCL and Java as languages for defining the design rules; and UML as the modeling language. The main benefit for the software engineer is the tool's incremental nature if providing instant feedback for many kinds of design errors even for large models.	eclipse;integrated development environment;java;object constraint language;plug-in (computing);rational software modeler;response surface methodology;sensor;software engineer;uml tool;unified modeling language	Alexander Reder;Alexander Egyed	2010		10.1145/1858996.1859069	unified modeling language;real-time computing;uml tool;computer science;systems engineering;software engineering;applications of uml;errors-in-variables models;database;modeling language;programming language;object constraint language	SE	-54.49692732131065	29.831669155069402	84460
eb49dd6617a6bcd0b5c461ae6f6462b84dce34f2	preprocessor based approach for cross-platform development with qt quick components		In the paper we analyze the obstacles of cross-platform mobile development involving Qt Quick Components library. We provide the classification of the most common issues of such a development and propose resolution for them with the use of the specially developed tool — QML preprocessor. Our approach is proven to be successful in development of two mobile applications supporting both Harmattan and Symbian platforms.	android;application programming interface;deployment environment;fastest;meego;mobile app;norm (social);operating system;preprocessor;qml;qt (software);symbian	Ilya Paramonov;Andrew Vasilev;Denis Laure;Nikita Kozhemyakin	2012	2012 11th Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2012.8253118	visualization;data mining;data pre-processing;cross-platform;preprocessor;computer science	Robotics	-49.190223048257245	23.26374421590748	84622
c9287e8a53ba49487ad5246aee61266be9ca11d0	engineering the authoring of usable service front ends	user interface development;front end;service front ends;design and development;task model;web service;interactive application;web services;hci model based design;model based design;authoring tool	This paper presents a method and the associated authoring tool for supporting the development of interactive applications able to access multiple Web Services, even from different types of interactive devices. We show how model-based descriptions are useful for this purpose and describe the associated automatic support along with the underlying rules. The proposed environment is able to aid in the design of new interactive applications that access pre-existing Web Services, which may contain annotations supporting the user interface development. This is achieved through the use of task models as a starting point for the design and development of the corresponding implementations. We also provide an example to better illustrate the features of the approach, and report on two evaluations conducted to assess	consistency model;display resolution;download;end-user development;point of view (computer hardware company);progressive refinement;refinement (computing);software development process;usability;user interface;web service;world wide web	Fabio Paternò;Carmen Santoro;Lucio Davide Spano	2011	Journal of Systems and Software	10.1016/j.jss.2011.05.025	web service;web modeling;web design;human–computer interaction;computer science;multimedia;world wide web;model-based design	HCI	-48.5659265259087	22.194850192530687	84708
1d6528aad6555e2ab068645fe431ee9a8c16b40b	a feature model metrics-based approach to develop a software product line		In recent years, the Software Product Line (SPL) is becoming a mainstream strategy in software development. The high reusability and the great derivability by modelling common and variable artefacts are undoubtedly its significant strengths. Taking advantage of these strengths requires a design of efficient product line. Often, most existing SPL design approaches build on feature modelling by analysis of existing similar products. However, existing feature-based modelling techniques lack analysis support for building SPL with regard to different stakeholder’s views. In this paper, we propose an approach based on analyzing and assessing process for creating expressive structure of an SPL. Such a process provides stakeholders with a set of optimal structures of SPL in different models and a set of metrics. In doing so, we argue that we facilitate the selection of appropriate predefined products structures under the form of a set of configuration-views.	diagram;feature model;software development;software product line	Yacine Djebar;Mohamed Tahar Kimour;Nouredine Guersi	2017	Int. Arab J. Inf. Technol.		artificial intelligence;feature model;machine learning;computer science;software product line	SE	-56.106709729627994	25.366979043710188	84961
bfd452f69f3a5a8dbe82eff59e378ecf7e79f71d	the support of interface specifications in black-box components testing	software;programming language semantics;black box component testing;black box component;software reusability object oriented programming program testing programming language semantics software quality;semantics;test data generation;contracts;testing;object oriented programming;test method black box component interface specification model;semantic specification;program testing;test adequacy;syntactics;testing contracts semantics syntactics software web services object oriented modeling;component reuse;software reusability;web services;source code;model test;component based software development;interface specification model;test method;semantic specification interface specification support black box component testing component based software development test data generation test adequacy component interface specification model component reuse;interface specification support;object oriented modeling;software quality;component interface specification model	The adequate testing of black-box components is an important basis before they will be reused in the approach of Component Based Software Development. The test-data generation and test adequacy ensuring are difficult issues for the unavailability of the source code of black-box components. In this paper, an extended component interface specification model is proposed to support the component understanding, testing and reuse. Then the function of different kinds of specification elements in testing is defined. Based on the syntactic and semantic specifications, the proposed test-data generation method can produce test suite meeting a certain mutation score, which is viewed as a kind of effective test adequacy criterion. Finally, some experiments were carried and the results have shown that the different kinds of specification can support the testing of black-box components.	black box;experiment;software development;test data generation;test suite;unavailability	Ying Jiang;Ying-Na Li;Xiaodong Fu	2010	2010 Fifth International Conference on Frontier of Computer Science and Technology	10.1109/FCST.2010.64	non-regression testing;web service;test data generation;model-based testing;orthogonal array testing;white-box testing;manual testing;integration testing;computer science;component-based software engineering;functional testing;database;semantics;software testing;test method;programming language;object-oriented programming;test management approach;software quality;source code	SE	-55.50531033225028	31.86233829494599	85087
f7628bc18eb02ee7ce06ac0f38ca208166abc229	towards feature-oriented specification and development with event-b	b method;formal method;safety critical software	A proposal is made for the development of a feature-oriented reuse capability for safety-critical software construction using rigorous methods. We précis the Event-B language the evolution of the B-Method of J.-R. Abrial [1] a leading formal method for safety-critical software development. Current and new infrastructure for scalable development with Event-B is outlined, and contrasted with support required for feature-oriented development. The proposal is illustrated by a small example of feature-oriented construction and refinement with Event-B.	b-method;formal methods;jean-raymond abrial;refinement (computing);scalability;software construction;software development	Michael Poppleton	2007		10.1007/978-3-540-73031-6_28	b-method;reliability engineering;formal methods;computer science;systems engineering;engineering;software development;software engineering;software development process	SE	-53.83296484838379	26.852101747034162	85159
802663b62f9a280ad83ff1f9d0265ffbddd687ba	classifying variability modeling techniques	variability management;modeling technique;computacion informatica;software product family;grupo de excelencia;classification;ciencias basicas y experimentales;derivation;product family;software product families;lines;framework;variability modeling	Variability modeling is important for managing variability in software product families, especially during product derivation. In the past few years, several variability modeling techniques have been developed, each using its own concepts to model the variability provided by a product family. The publications regarding these techniques were written from diVerent viewpoints, use diVerent examples, and rely on a diVerent technical background. This paper sheds light on the similarities and diVerences between six variability modeling techniques, by exemplifying the techniques with one running example, and classifying them using a framework of key characteristics for variability modeling. It furthermore discusses the relation between diVerences among those techniques, and the scope, size, and application domain of product families. © 2006 Elsevier B.V. All rights reserved.	application domain;heart rate variability;spatial variability	Marco Sinnema;Sybren Deelstra	2007	Information & Software Technology	10.1016/j.infsof.2006.08.001	simulation;biological classification;computer science;systems engineering;software framework;line;programming language;derivation	SE	-54.87767455939114	25.294133106764992	85354
53549a2e6cf2e2a62f75de2f5d45b4524f7f9746	automating the software development process	developpement logiciel;automatisation;software development process;automatizacion;software engineering;software development;genie logiciel;arquitectura;architecture;automation	Demand for reliable software systems is stressing software production capability, and automation is seen as a practical approach to increasing productivity and quality. Discussed in this paper are an approach and an architecture for automating the software development process. The concepts are developed from the viewpoint of the needs of the software development process, rather than that of established tools or technology. We discuss why automation of software development must be accomplished by evolutionary means. We define the architecture of a software engineering support facility to support long-term process experimentation, evolution, and automation. Such a facility would provide flexibility, tool portability, tool and process integration, and process automation for a wide range of methodologies and tools. We present the architectural concepts for such a facility and examine ways in which it can be used to foster software automation.	software development process	Gene F. Hoffnagle;William E. Beregi	1985	IBM Systems Journal	10.1147/sj.242.0102	personal software process;verification and validation;team software process;software engineering process group;systems engineering;engineering;process automation system;package development process;backporting;social software engineering;software development;architecture;software design description;automation;software engineering;software construction;software walkthrough;empirical process;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software system;computer engineering;software peer review	SE	-61.4201802780063	28.15821729016582	85490
cec331294f28043d135a708f48df89fca3fb2a7c	an approach to modeling service-oriented development process	service provider;business domain service oriented development distributed systems enterprise environment service provider service requestor service repository use case model;service orientation;distributed processing;service requestor;software systems;service oriented development;conceptual model;software architecture business data processing distributed processing;development process;requirement analysis;business domain;software architecture;research and development;heterogeneous distributed system;business data processing;service oriented computing;it adoption;service oriented architecture guidelines object oriented modeling research and development software systems intelligent structures companies;use case model;service repository;development methodology;distributed systems;service oriented architecture;use case;enterprise environment	To integrate heterogeneous distributed systems, there exist various researches and developments for the purpose of its adoption into enterprise environment. However, when service-oriented technologies are applied, it is difficult to adopt directly existing software system development methodologies, because of the primary elements of service-oriented architecture such as service provider, service requestor and service repository. In this paper, we define a conceptual model for developing systems in service-oriented computing. The model involves procedures and guidelines based on the use case model that is elicited from a business domain in requirement analysis. We focus on how to identify and how to determine key realization decisions for each service. The benefit of the identification method based on the use case model is that the service has reflected the business of the domain well and is in its proper granularity. The assessment guideline can help the settlement of a problem that is to determine the implementation strategy	business domain;distributed computing;existential quantification;google book search settlement agreement;requirements analysis;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;software development process;software system	Yukyong Kim;Hongran Yun	2006	2006 IEEE International Conference on Services Computing (SCC'06)	10.1109/SCC.2006.19	systems engineering;knowledge management;service delivery framework;software engineering;service design;business;data as a service	SE	-57.54249624768787	19.142810352058333	86152
698d1cf1283ab79b1262efb0054972d48dc0901c	investigation of software patterns of user experience	software patterns of user experience;software pattern;small and medium size enterprise;user experience;software development;software developers;software patterns;information design;spux	Traditionally, work in user experience focuses primarily on designers. However, in small and medium sized enterprises, software developers tend to take on a number of important roles, including designers, user experience engineers and analysts and so have influence over the user experience for end-users.  We argue that in order to inform design and development to improve user experience for end-users, greater attention on software developers, especially in the HCI field, is vital. We believe pragmatic measures, in addition to user experience theories, frameworks, levels and guidelines are essential for aiding software developers. To this end, we propose the concept of software patterns of user experience and explain why it will serve the purpose.	human–computer interaction;software design pattern;software developer;theory;user experience	Yih-Lun Huang;Tim Marsh;Adrian David Cheok	2010		10.1145/1971630.1971669	user interface design;software review;user;personal software process;verification and validation;user experience design;human–computer interaction;user journey;computer science;systems engineering;package development process;software design;social software engineering;user requirements document;software development;software design description;software engineering;software construction;software walkthrough;software documentation;user analysis;software analytics;software deployment;software peer review	HCI	-60.816998086454525	24.84284939567448	86155
502205f7d5b44cb58898c9a0d75349e4831244e5	reconciling requirements and architectures with the cbsp approach in an iphone app project	software;goal question metric;goal question metric approach iphone app project software requirement software architecture component bus system property approach industrial project mobile application;formal specification;measurement;iphone app project;component bus system property cbsp approach;component bus system property approach;software requirement;requirements;connectors;software requirements;computer architecture;software architecture;graphical user interfaces;rationale capture;lessons learned;computer architecture software graphical user interfaces mobile communication connectors software architecture measurement;goal question metric approach;mobile communication;rationale capture requirements architecture component bus system property cbsp approach traceability;software architecture formal specification mobile computing;graphic user interface;industrial project;mobile computing;traceability;architecture;mobile application	There are only few methods available that help refining software requirements to software architectures. An example is the CBSP (Component-Bus-System-Property) approach that uses general architectural concerns to classify and refine requirements and to capture architectural trade-off issues and options. This paper reports about experiences of applying CBSP in an industrial project in the area of mobile applications. We illustrate CBSP using project examples. We discuss how the approach was tailored and present extensions we developed. In particular, we show how CBSP can be used together with the Goal-Question-Metric approach to guide architectural decisions. We close our paper with a discussion of lessons learned during this project.	design rationale;gqm;goal programming;mobile app;requirement;requirements elicitation;software architecture;software requirements	Harald Vogl;Klaus Lehner;Paul Grünbacher;Alexander Egyed	2011	2011 IEEE 19th International Requirements Engineering Conference	10.1109/RE.2011.6051625	embedded system;computer science;systems engineering;engineering;software engineering;graphical user interface;programming language;mobile computing;software requirements	SE	-54.898867986134256	26.876395673431624	86359
736143b50b0b2eba4703a829a253f55ecf5a817e	splicing tabasco: custom-tailored software product line variants from taxonomy-based toolkits	taxonomy based software construction tabasco toolkit;software product line spl adoption	Taxonomy-Based Software Construction (TABASCO) applies extensive domain analyses to create conceptual hierarchies of algorithmic domains. Those are used as basis for the implementation of software toolkits. The monolithic structure of TABASCO-based toolkits restricts their adoption on resource-constrained or special-purpose devices. In this paper, we address this problem by applying Software Product Line (SPL) techniques to TABASCO-based toolkits: We use software taxonomies as input to creating a conceptual representation of variability as feature models of an SPL. We apply the variability realization mechanism delta modeling to transform realization artifacts, such as source code, to only contain elements for a particular selection of features. Our method is suitable for proactive, reactive and extractive SPL development so that it supports a seamless adoption and evolution of an SPL approach for TABASCO-based toolkits. We demonstrate the feasibility of the method with three case studies by proactively, reactively and extractively transforming TABASCO-based toolkits to SPLs, which allow derivation of variants with custom-tailored functionality.	feature model;list of toolkits;seamless3d;software construction;software product line;spatial variability;splicing rule	Ina Schaefer;Christoph Seidl;Loek G. Cleophas;Bruce W. Watson	2015		10.1145/2815782.2815799	simulation;systems engineering;engineering;engineering drawing	SE	-53.81914780039664	25.960193395983868	86527
7f66f30a6140d6ee32a788fafba1c7a134950ef8	a model-driven approach to extract views from an architecture description language	architectural design;metamodel model driven approach architecture description language independent heterogeneous representations;high level languages;architecture description language;model driven approach;architecture description languages software architecture unified modeling language metamodeling computer science software systems scholarships aggregates software design concrete;software architecture;metamodel;independent heterogeneous representations;software architecture high level languages	A common approach to defining architectural views is to have independent heterogeneous representations that are tailored to each view's purpose, but this makes reconciling views into an overall architectural description harder. In this paper we put forward a complementary (not alternative) approach in which some views are derived from a given architecture description language (ADL) in a systematic way, by listing the design questions each view should answer. The approach is based on constructing the language's metamodel and extending it with the entities and associations needed to capture and explicitly relate the required views.	architecture description language;entity;metamodeling;model-driven integration	Cristóvão Oliveira;Michel Wermelinger	2007	2007 Working IEEE/IFIP Conference on Software Architecture (WICSA'07)	10.1109/WICSA.2007.3	multilayered architecture;enterprise architecture framework;metamodeling;reference architecture;software architecture;model-driven architecture;architecture description language;iso/iec 42010;computer architecture;database-centric architecture;architectural pattern;system model;architecture analysis & design language;computer science;systems engineering;engineering;architecture domain;applications architecture;theoretical computer science;software design description;darwin;service-oriented modeling;software engineering;solution architecture;software architecture description;programming language;view model;high-level programming language;systems architecture	SE	-53.42484208391608	27.238216071368104	86532
041431e0e53670c1c02b28ba904bfc11fa8564b9	experience modeling and analyzing medical processes: umass/baystate medical safety project overview	power analysis;selected works;finite state verification;property specifications;model checking;process definition and analysis;bepress;continuous medical process improvement;process model;process improvement;verification model	This paper provides an overview of the UMass/Baystate Medical Safety project, which has been developing and evaluating tools and technology for modeling and analyzing medical processes. We describe the tools that currently comprise the Process Improvement Environment, PIE. For each tool, we illustrate the kinds of information that it provides and discuss how that information can be used to improve the modeled process as well as provide useful information that other tools in the environment can leverage. Because the process modeling notation that we use has rigorously defined semantics and supports creating relatively detailed process models (for example, our models can specify alternative ways of dealing with exceptional behavior and concurrency), a number of powerful analysis techniques can be applied. The cost of eliciting and maintaining such a detailed model is amortized over the range of analyses that can be applied to detect errors, vulnerabilities, and inefficiencies in an existing process or in proposed process modifications before they are deployed.	amortized analysis;concurrency (computer science);erewhon;process modeling;vulnerability (computing)	George S. Avrunin;Lori A. Clarke;Leon J. Osterweil;Stefan Christov;Bin Chen;Elizabeth A. Henneman;Philip L. Henneman;Lucinda Cassells;Wilson Mertens	2010		10.1145/1882992.1883037	computer science;systems engineering;data mining;management science	SE	-57.135879771988485	25.6428945922389	86580
df308d8d51ec0c448eb9a89deb3b8e7c28080ee3	visual depiction of decision statements: what is best for programmers and non-programmers?	program comprehension;visual programming;graphical representation;software development;expert novice differences;decision structures	This paper reports the results of two experiments investigating differences in comprehensibility of textual and graphical notations for representing decision statements. The first experiment was a replication of a prior experiment that found textual notations to be better than particular graphical notations. After replicating this study, two other hypotheses were investigated in a second experiment. Our first claim is that graphics may be better for technical, non-programmers than they are for programmers because of the great amount of experience that programmers have with textual notations in programming languages. The second is that modifications to graphical forms may improve their usefulness. The results support both of these hypotheses.		James D. Kiper;Brent Auernheimer;Charles K. Ames	1997	Empirical Software Engineering	10.1023/A:1009797801907	natural language processing;cognitive dimensions of notations;computer science;engineering;software development;software engineering;visual programming language;programming language	SE	-59.21214897672845	30.504849774797254	86762
35b22cbc6e627e3978f1a468c41f336c18f587bc	are forward designed or reverse-engineered uml diagrams more helpful for code maintenance?: a family of experiments	software maintenance;controlled experiment;family of experiments;uml diagrams;maintainability;reverse engineering	Software maintenance	artifact (software development);class diagram;complex systems;computer science;documentation;experiment;high-level programming language;reverse engineering;sequence diagram;software developer;software development process;software maintenance;software system;state diagram;uml tool;undefined behavior;unified modeling language	Ana M. Fernández-Sáez;Marcela Genero;Michel R. V. Chaudron;Danilo Caivano;Isabel Ramos	2015	Information & Software Technology	10.1016/j.infsof.2014.05.014	reliability engineering;unified modeling language;computer science;systems engineering;engineering;software engineering;applications of uml;database;software maintenance;engineering drawing;maintainability;reverse engineering	SE	-53.63352588648666	30.610930658109787	86843
efda9c8b76caf960c593cfe27784ff5cac9abc40	a bdi agent-based software process	programming paradigm;agent based;belief desire intention;agent based model;software development process;software engineering;requirement analysis;object oriented;bdi agents;software development;next generation;use case;software process	Agent-based programming comes us as a next generation programming paradigm. However, we have not been ready yet to fully use it without having sound and concrete software engineering methods and tools to facilitate agent-based software development. In this paper we propose a new software engineering process based on the BDI agent concept. We have refined and extend substantially our previous work, Agent-based Modeling Technique (AMT) and Agent-based Software Development Process (ASP), so that a systematic and realistic process has been born to construct BDI agent-based software. This paper introduces our new approach to the BDI agent-based software development process. The Belief-Desire-Intention (BDI) model has been proved as a dominant view in contemporary philosophy of human mind and action. We utilize BDI as a tool to analyze agents’ environments, goals, and behaviors. Use cases have been proved as a useful tool for requirement analysis. However, use cases cannot be neither agent-oriented nor object-oriented even though it has been used as a tool for analysis for a while. We have extended the existing use cases, and use a new sort of use cases to identify BDIs of agents in the real-world problem. We use external use cases to get the basic behaviors (intentions) needed to provide the services in the system. We use then internal use cases to define goals (desires) of the system and to discover more specified behaviors (intentions) to achieve the goals. By analyzing the behaviors (intentions) for each goal (desire), we can obtain environments (beliefs) on which the system behaves to perform the goal. The goal of this paper is to provide a very practical and systematic way to analyze and design the agent software based on the BDI concepts. We have started by using the existing proven tools and methods such as the use case approach, however, we have made a substantial modifications and improvements to these existing techniques so that we can analyze and design the system very realistically based on the BDI agent concept. This paper provides a systematic and seamless approach to the BDI agent-based software development. The way we suggest here to find BDI agents through requirements analysis is a unique and novel approach. This technique suggests a new way of thinking for BDI agent-based modeling. A BDI AGENT-BASED SOFTWARE PROCESS 102 JOURNAL OF OBJECT TECHNOLOGY VOL. 4, NO. 9	agent-based model;belief–desire–intention software model;mind;next-generation network;programming paradigm;requirement;requirements analysis;seamless3d;software agent;software development process;software engineering;while	Chang-Hyun Jo;Jeffery M. Einhorn	2005	Journal of Object Technology	10.5381/jot.2005.4.9.a3	computer science;systems engineering;engineering;knowledge management;artificial intelligence;software design;software development;software engineering;belief–desire–intention software model;software development process	SE	-60.47399599939849	22.452963035981792	86868
2dfed4b04135a52e8a065677590f164d793729ab	model-based testing of video conferencing systems: challenges, lessons learnt, and results	articulo;aspect oriented modeling;test data generation;test case selection;model transformation;unified modeling language testing data models robustness software saturn standards;and results;model based testing of video conferencing systems challenges;model based test case generation tool model based testing video conferencing system mbt software system quality search algorithm test case selection test data generation aspect oriented modeling scalable modeling solution nonfunctional testing model transformation;model based testing;industrial applications;aspect oriented modeling model based testing industrial applications test data generation test case selection model transformation search algorithms;search algorithms;lessons learnt;teleconferencing aspect oriented programming program testing search problems software quality	Model-Based Testing (MBT) is a well-established and intense field of research in academia. It has attracted attention of many industries as it can be seen from many industrial experiences of MBT reported in the literature and availability of commercial and open source tools in recent years. The thorough and methodical approach of MBT facilitates automated testing with the intention of improving the quality of software systems. Every industrial application of MBT faces varied challenges depending on the application domain, the current testing practices and tools, and the type of testing. Reporting such challenges, their solutions, and lessons learnt provides a body of knowledge, which can direct practitioners of MBT for their future applications of MBT. With such aim in our mind, we present results from an MBT project that is being carried out for testing embedded video conferencing systems developed by Cisco Systems, Inc. Norway for the last several years. We present challenges faced while conducting MBT, our solutions, some of the key results, and lessons learnt from our experience. Our experience showed that search algorithms provide an efficient solution for test case selection and test data generation. In addition, aspect-oriented modeling provides a scalable modeling solution for non-functional testing. Finally, we learned that model transformation offers an elegant solution for developing a model-based test case generation tool. All of our results are based on a large number of rigorous empirical evaluations.	application domain;aspect-oriented software development;embedded system;experience;functional testing;high-level programming language;mind;model transformation;model-based testing;non-functional testing;open-source software;robustness testing;scalability;search algorithm;software system;test automation;test case;test data generation;veritas cluster server	Shaukat Ali;Hadi Hemmati	2014	2014 IEEE Seventh International Conference on Software Testing, Verification and Validation	10.1109/ICST.2014.48	non-regression testing;test strategy;test data generation;model-based testing;simulation;software performance testing;white-box testing;computer science;systems engineering;engineering;operating system;software engineering;test management approach;search algorithm	SE	-59.059638237895214	26.23565828032714	86873
fa087d423355908df0bc38ee2b948c835b64cd20	introduction: first international workshop on quality of service concerns in service oriented architectures (qoscsoa 2008)	quality attributes;design and development;modeling and simulation;software systems;quality requirement;qos management;service level agreement;software life cycle;quality of service;service oriented architecture;system management;service quality;business process	Service-Oriented Architecture (SOA) is having a substantial impact on the way software systems are developed. Today many systems are being designed and developed that use an SOA style. Although some progress has been made on several fronts on addressing Quailty-of-Service (QoS) concerns in SOAs much research is still needed in addressing QoS issues in the design, development and operation of SOA-based systems. This workshop focuses on techniques and approaches for managing QoS concerns throughout the entire lifecycle of SOA-based systems. The following topics are of interest in this workshop:#R##N##R##N##R##N#Techniques for determining quality requirements for SOA-based systems#R##N#Techniques, patterns and approaches for handling specific quality attribute requirements in the design of SOA-based systems#R##N#Techniques, patterns and approaches for handling specific quality attribute requirements in the implementation of SOA-based systems#R##N#Deployment and Monitoring of SOA-based systems#R##N#Resourcing models to guarantee specific QoS requirements (virtualisation, grid, etc)#R##N#QoS aspects of virtualised SOA-based systems#R##N#Assessment techniques and approaches for specific qualities of SOA-based systems including modeling and simulation of specific qualities#R##N#Service Level Agreements (SLAs) in an SOA context including their development and negotiation#R##N#Validation of properties/service qualities in SOA-based systems#R##N#Economics of handling specific QoS requirements in SOA-based systems#R##N#Managing QoS concerns for SOA-based systems throughout the entire software life cycle#R##N#Autonomic QoS management in SOA-based systems#R##N#Relationship of QoS of SOA-based systems to the underlying business processes	quality of service;service-oriented architecture	Liam O'Brien;Paul Brebner	2008		10.1007/978-3-642-01247-1_18	real-time computing;systems management;quality of service;computer science;service-oriented architecture;modeling and simulation;business process;management;law;service quality;software development process;oasis soa reference model;software system	Arch	-58.711454995808374	19.40977699264894	87173
3ee23e837b1a19efe31bff6ae71b5e54704cb96c	information system design based on a domain ontology and user requirements.		Domain ontologies can support the production of the conceptual schema of a database but lack the behavioral properties that are necessary to generate an operational Information System. We present an approach to enrich a domain ontology by properties extracted from the User Requirements. Besides determining the required subset of the ontology, we produce the database of the Information System and its API. This approach is implemented by the ISIS (Information System Initial Specification) platform that generates automatically an operational Information System, including a prototypical Graphical User Interface that enables the users to validate the expressed needs and refine them if necessary. Thanks to a reduction of the cycle « expressionrefinement of needs / production of target system / validation » the number of these cycles can increase without impacting the global cost of the project and the final result is closer to the real needs of the users.	application programming interface;conceptual schema;graphical user interface;isis;information system;ontology (information science);requirement	Ana Simonet;Michel Simonet	2011			user interface design;user experience design;domain;knowledge management;ontology;system requirements specification;database;ontology-based data integration;world wide web;process ontology;suggested upper merged ontology	DB	-51.795423912908156	19.782744705395288	87187
b091c1cae29b9b9c26f3ef6550caf8254b7e71b4	model-based testing	labelled transition system;on the fly;model based testing	Model Based Testing (MBT) plays an essential role in the software development. Developing applications requires a Model based design that needs to be tested in order guarantee that there are no serious bugs. In some applications like airplane navigation, health monitoring it would be fatal if the application crashes during its execution time. Thus the developed software must be tested carefully. In this seminar different presentations have been given from different experts that will be discussed in this seminar report.	model-based testing;test case	Ina Schieferdecker	2012	IEEE Software	10.1109/MS.2012.13	mathematics;forensic engineering;algorithm	SE	-60.454610098254534	30.914835035608768	87307
5337b9f040cec40cc5683187179015663b03f1b3	experience developing two ada applications for embedded real-time systems using different software processes	embedded real time systems;software process	Without Abstract	ada;embedded system;real-time transcription	Brian Gilbert;Michael Taylor;Greg Bek	1991		10.1007/BFb0018509	embedded operating system;computer architecture;verification and validation;real-time computing;computer science;package development process;backporting;social software engineering;software development;operating system;software engineering;software construction;software analytics;software deployment;goal-driven software development process;software development process;software system;avionics software	Embedded	-49.194408980527776	30.602414321890553	87325
51a66ff4482c666d4e11956c1c15f108a3943900	methodology for green certificates of service applications	environmental factors;service based business processes green certificates service applications energy aware services green performance indicators gpi service energy related performance service lifecycle service selection;green products catalogs measurement cost accounting monitoring organizations;methodology for green services;environmental science computing;methodology for green services green computing service systems green performance indicators green certificate;service systems;green certificate;business process re engineering;environmental science computing business process re engineering environmental factors;green performance indicators;green computing	Energy-aware services can be obtained by composing Green Performance Indicators (GPIs) into a Green Certificate (GC), a document showing a service's energy-related performance along all the service lifecycle. This paper describes a methodology to create the GC and to use it for service selection and in service-based business processes.	business process	Maria Grazia Fugini;José Antonio Parejo Maestre	2012	2012 IEEE 21st International Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises	10.1109/WETICE.2012.12	service level requirement;green computing;computer science;operating system;service design;computer security	Visualization	-58.102095494333824	19.605938137596127	87345
26b0c4266c36fe02f769460097c0e1e181926ac0	sofsem 2000: theory and practice of informatics	software engineering;artificial intelligent;operating system	Before software can be developed its requirements must be stated. Before requirements can be expressed the application domain must be understood. In this invited paper we outline some of the basic facets of domain engineering. Domains seem, it is our experience, far more stable than computing requirements, and these again seem more stable than software designs. Thus, almost like the universal laws of physics, it pays off to first develop theories of domains. But domain engineering, as in fact also requirements engineering, really is in need of thoroughly researched development principles, techniques and tools. The aim of this invited paper is to advocate: that researchers study these development method components, and that universities focus their education on basing well-nigh any course on the use of formal techniques: Specification and verification, and that software engineers take heed: Start applying formal techniques. A brief example of describing stake-holder perspectives will be given— on the background of which we then proceed to survey the notions of domain intrinsics, domain support technologies, domain management & organisation, domain rules & regulations, domain human behaviour, etc. We show elsewhere how to “derive” requirements from domain descriptions. Domain requirements: by domain projection, instantiation, extension and initialisation; interface requirements: multi-media, dialogue, etc.; and machine requirements: performance, dependability (reliability, availability, accessability, safety, etc.), and maintainability (adaptability, perfectability and correctability). The current paper presents work-in-progress. The text of the paper is therefore very schematic.	accessibility;application domain;computer performance;dependability;domain engineering;experience;formal methods;informatics;intrinsic function;reliability engineering;requirement;requirements engineering;schematic;software engineer;theory;universal instantiation	Jan van Leeuwen;Václav Hlavác;Keith G. Jeffery;Jirí Wiedermann	2000		10.1007/3-540-44411-4	computing;engineering informatics;computer science;theoretical computer science;computer engineering	SE	-58.11415252902342	26.284373951983525	87356
e96704a6179da6bb91edabed786fbdee7d485251	an mda-based generic framework to address various aspects of enterprise architecture	information technology;model driven architecture;enterprise architecture	With a trend toward becoming more and more information based, enterprises constantly attempt to surpass the accomplishments of each other by improving their information activities. Building an Enterprise Architecture (EA) undoubtedly serves as a fundamental concept to accomplish this goal. EA typically encompasses an overview of the entire information system in an enterprise, including the software, hardware, and information architectures. Here, we aim the use of Model Driven Architecture (MDA) in order to cover different aspects of Enterprise Architecture. MDA, the most recent de facto standard for software development, has been selected to address EA across multiple hierarchical levels spanned from business to IT. Despite the fact that MDA is not intended to contribute in this respect, we plan to enhance its initial scope to take advantage of the facilities provided by this innovative architecture. The presented framework helps developers to design and justify completely integrated business and IT systems which results in improved project success rate.	computer hardware;enterprise architecture;information system;model-driven architecture;software development	S. Shervin Ostadzadeh;Fereidoon Shams Aliee;S. Arash Ostadzadeh	2007		10.1007/978-1-4020-8741-7_81	enterprise architecture framework;functional software architecture;information technology architecture;reference architecture;the open group architecture framework;computer science;knowledge management;architecture domain;applications architecture;artificial intelligence;operating system;service-oriented modeling;software engineering;enterprise architecture management;service;solution architecture;enterprise architecture;enterprise integration;view model;management;information technology;computer security;enterprise information security architecture;enterprise information system;data architecture;business architecture;enterprise life cycle	SE	-59.21819144137291	18.560231492229082	87365
637eb667e5255e679b22bb3bc3a48dbdeb4dfe6b	combining requirements, use case maps and aadl models for safety-critical systems design	aadl;requirements engineering management handbook;rdal;use case maps urn;model driven requirements engineering;model integration;model management	Good requirements engineering practices are essentialfor developing correct safety-critical systems. In this paper, we report our experience in combining existing rich modelinglanguages such as AADL (Architecture Analysis and DesignLanguage), URN (User Requirements Notation) and RDAL(Requirements Definition and Analysis Language) to supporta requirements engineering and design process as promotedby the FAA Requirements Engineering Management Handbook(REMH). Each of the combined language is well suited for thecapture of specific concerns of the REMH practices allowingreusing the capability from the individual languages but alsofrom their combined use. Our approach has been applied to thespecification and analysis of a medical device example from theREMH and shows several benefits due to the early discovery oferrors resulting from each modeling language and from theircombination. This experience also identifies important needs for automated model management not covered by current state-of the-art modeling techniques.	architecture analysis & design language;best practice;cognitive dimensions of notations;kaos;modeling language;natural language;operation time;rational clearcase ucm;requirement;requirements engineering;sensor;systems design	Dominique Blouin;Holger Giese	2016	2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2016.15	reliability engineering;requirements analysis;requirements management;architecture analysis & design language;computer science;systems engineering;requirement;software engineering;needs analysis;requirements elicitation;requirements engineering;non-functional requirement	SE	-51.98132107997585	25.198627432640322	87527
21ee8e0b66b4af5d278976dcf4c075318bb9446e	ontorea© accounting and finance model: hedge portfolio representation of derivatives		OntoREA© is a specification of the Accounting and Finance domain in the OntoUML language [1]. In a previous article [2] the authors use a forward contract financial derivative instrument to demonstrate the validity of the OntoREA© model within the design science research methodology (DSRM) [3]. A forward contract does not change over time and therefore can be modelled as static hedge portfolio composition. However, it is of interest if the OntoREA© model can also hold true for dynamic hedge portfolio compositions, as induced by option contract financial derivative instruments. This article investigates on that and delivers proof that the OntoREA© model is suitable for option contracts as well. Through adequately refining the platform specific database model (PSM) the policy’s dynamic nature can be demonstrated. Moreover, including a Plan/Do/Check/Act (PDCA) process model for the specification of the option contract replication also demonstrates the information processing in the REA accounting infrastructure. The proposed approach is implemented into an R/Shiny software prototype where the 3-tier-architecture is used to integrate the database and the PDCA process model at the R/Shiny implementation specific model (ISM) level. The presented hedge portfolio representation of derivatives can be useful for business analysts in the finance and accounting domain as well as for teaching financial derivative instruments.		Christian Fischer-Pauzenberger;Walter S. A. Schwaiger	2018		10.1007/978-3-030-02302-7_24	conceptual model;forward contract;computer science;option contract;derivative (finance);database model;pdca;design science research;accounting;finance;portfolio	Vision	-54.42775362256702	19.59516280992143	87616
419ba9915c21bb56402a89e4d4612fb77ed6da2f	software design and architecture the once and future focus of software engineering	programming;systems analysis;computer architecture;computer science;concept formation;application software;informatics;software design;software engineering;software architecture;design research	"""The design of software has been a focus of software engineering research since the field's beginning. This paper explores key aspects of this research focus and shows why design will remain a principal focus. The intrinsic elements of software design, both process and product, are discussed: concept formation, use of experience, and means for representation, reasoning, and directing the design activity. Design is presented as being an activity engaged by a wide range of stakeholders, acting throughout most of a system's lifecycle, making a set of key choices which constitute the application's architecture. Directions for design research are outlined, including: (a) drawing lessons, inspiration, and techniques from design fields outside of computer science, (b) emphasizing the design of application """"character"""" (functionality and style) as well as the application's structure, and (c) expanding the notion of software to encompass the design of additional kinds of intangible complex artifacts."""	computer science;concept learning;emoticon;software design;software engineering	Richard N. Taylor;André van der Hoek	2007	Future of Software Engineering (FOSE '07)		reference architecture;software architecture;systems analysis;architecture tradeoff analysis method;verification and validation;concept learning;design research;computer science;systems engineering;engineering;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;computer engineering;software peer review	SE	-61.72168524166692	21.844025924983857	87761
618cd8d04c7d237777a64712123fe8368ca3fb4a	experience report: ssadm-designed system to object-oriented system			structured systems analysis and design method	S. Y. Liao;Y. P. Shao;W. H. Tsang	1998	JOOP		database;programming language;computer science;object-oriented programming;structured systems analysis and design method	PL	-50.85636151098859	28.530078284163373	87843
f098cd3d5dc7b2b3ac0232b62bf6662dca811185	towards an ontology of terms on technical debt	technical debt indicators;technical debt types;software maintenance;technical debt;ontologies software documentation organizations owl vocabulary computer architecture;research and development activities vocabulary ontology design quality criteria technical debt landscape;software quality ontologies artificial intelligence software development management;ontology;software maintenance technical debt technical debt types technical debt indicators ontology	Technical debt is a term that has been used to describe the increased cost of changing or maintaining a system due to shortcuts taken during its development. As technical debt is a recent research area, its different types and their indicators are not organized yet. Therefore, this paper proposes an ontology of terms on technical debt in order to organize a common vocabulary for the area. The organized concepts derived from the results of a systematic literature mapping. The proposed ontology was evaluated in two steps. In the first one, some ontology design quality criteria were used. For the second one, a specialist in the area performed an initial evaluation. This work contributes to evolve the Technical Debt Landscape through the organization of the different types of technical debt and their indicators. We consider this an important contribution for both researchers and practitioners because this information was spread out in the literature hindering their use in research and development activities.	technical debt;vocabulary	Nicolli S. R. Alves;Leilane Ferreira Ribeiro;Vivyane Caires;Thiago Souto Mendes;Rodrigo O. Spínola	2014	2014 Sixth International Workshop on Managing Technical Debt	10.1109/MTD.2014.9	systems engineering;engineering;knowledge management;software engineering;technical debt	HCI	-61.46596285842677	18.343577551806245	87895
ec848a547fe4300ac862dcd88b245971552613df	model driven development: integrating tools with practices	reservoirs;humans object oriented modeling software engineering history computer errors automation productivity testing project management reservoirs;project management;history;testing;software engineering;automatic generation;model driven development;model based software engineering model driven development;computer aided software engineering;model based software engineering;software tools;humans;productivity;object oriented modeling;computer errors;computer aided software engineering software engineering software tools;automation	Model-based software engineering is a reality whose time has come. This paper points out ways in which software can be automatically generated from models without taking the human out of the cycle. This paper illustrates the importance of integrating tools with practice.	model-driven engineering	Cecilia Haskins	1997		10.1109/ECBS.1997.581923	project management;productivity;computer science;systems engineering;engineering;automation;software engineering;software testing;computer-aided software engineering;computer engineering;reservoir	HCI	-62.313355816288144	25.308322005036306	87905
4057be2bc770c603847fbf55007ed54c3f6d53ad	awareness requirements		The functional specification of any software system operationalizes stakeholder requirements. In this paper we focus on a class of requirements that lead to feedback loop operationalizations. These Awareness Requirements talk about the runtime success/failure of other requirements and domain assumptions. Our proposal includes a language for expressing awareness requirements, as well as techniques for elicitation and implementation based on the EEAT requirements monitoring	adaptive system;feedback;functional specification;prototype;requirement;software system	Vítor Estêvão Silva Souza;Alexei Lapouchnian;William N. Robinson;John Mylopoulos	2010		10.1007/978-3-642-35813-5_6		SE	-57.88946227225914	21.794063308629752	88028
719ff7e6f6d31d87f96c5e618ee6ccf28f106650	change analysis on evolving plc software in automated production systems				Alexander Schlie;Safa Bougouffa;Juliane Fischer;Ina Schaefer;Birgit Vogel-Heuser	2018	Automatisierungstechnik	10.1515/auto-2018-0037		SE	-62.5446875556016	24.549526344323866	88308
24e0fe9fd2263bb92d532edb21170c8517fb42b6	reuse in reverse engineering	dynamic typing;proof of concept;reverse engineering data visualization computer architecture software tools information analysis software systems best practices performance analysis performance gain joining processes;software reusability;software reusability reverse engineering;program analysis reverse engineering software reused software integration software systems;reverse engineering	In this paper, we present a framework for reverse engineering allowing the integration and interaction of different analysis and visualization tools. The framework architecture that we propose uses a dynamic type system to guarantee the proper exchange of data between the tools and a set of wrapper classes to handle their communication. This allows for an easy and secure integration of tools that have originally not been designed to work together. In this sense, existing tools can be (re-)used and integrated. As a proof of concept we also present our own instantiation of the proposed framework architecture.	data structure;eclipse;plug-in (computing);reverse engineering;substitution (logic);type system	Thomas Panas;Jonas Lundberg;Welf Löwe	2004	Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004.	10.1109/WPC.2004.1311047	domain analysis;software visualization;reusability;architecture tradeoff analysis method;verification and validation;computing;type system;software engineering process group;software sizing;search-based software engineering;computer science;systems engineering;social software engineering;software framework;component-based software engineering;software development;operating system;feature-oriented domain analysis;software engineering;software construction;hardware architecture;programming language;resource-oriented architecture;computer-aided software engineering;proof of concept;software requirements;reverse engineering;software system;computer engineering	Visualization	-51.2221423062952	29.332663140272025	88335
129b275dbfe368d477555be4e22db03b776adb4e	improved metrics for encapsulation based on information hiding	encapsulation;software metrics;software;object oriented software metrics information hiding encapsulation;object oriented methods;software measurement;design and development;object oriented software design;method hiding factor;information hiding;object oriented software;metrics;satisfiability;software engineering;data encapsulation;manganese;software metrics data encapsulation object oriented methods;attribute hiding factor information hiding software quality software metrics software engineering object oriented software development object oriented software design method hiding factor;object oriented software development;mood;software quality;encapsulation mood software quality software engineering computer science software tools programming profession software measurement open source software software packages;attribute hiding factor	The contribution of metrics to the overall objective of software quality is understood and fully recognized by the software engineering community in general. In the design and development of object-oriented software we should keep information such as attributes and methods in a module or class invisible to external environment as possible. Although Method Hiding Factor (MHF) and Attribute Hiding Factor (AHF) in a suite of metrics MOOD have been adopted to measure the degree of information hiding. They are not sufficient, because they are method and attribute level that are only finely granular and they are incomplete. The information hiding metrics of class and system which are coarsely granular and medium granular should be needed. In this paper, improved metrics for encapsulation based on information hiding is proposed to satisfy the above need of different grains. The new measures are applied in an experiment to obtain results, and its validity, completeness and accuracy are proved. The new metrics will be impact on design and development of object-oriented software.	encapsulation (networking);software engineering;software quality	Yong Cao;Qingxin Zhu	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.76	encapsulation;computer science;manganese;software engineering;data mining;database;information hiding;software measurement;metrics;software quality	SE	-56.60886750054348	30.633486359257365	88518
5af3fec28cfabe8884c5bb6b87bf81116764d2db	an integrated tool support for the specification of transaction systems protocols.	tool support			Sylvanus A. Ehikioya	1999			computer science;data mining	DB	-50.51235963880066	25.09421270570188	88547
025c21482fefc3181c88dc6478bee77a7a18e20c	quality-impact assessment of software systems	user feedback;quality of experience;analytics;requirement elicitation;quality requirements;requirement monitoring;software quality	Runtime monitoring and assessment of software products, features, and requirements allow product managers and requirement engineers to verify the implemented features or requirements, and validate the user acceptance. Gaining insight into software quality and impact of the quality on user facilitates interpretation of quality against users' acceptance and vice versa. The insight also expedites root cause analysis and fast evolution in the case of threatening the health and sustainability of the software. Several studies have proposed automated monitoring solutions and assessment, however, none of the studies introduces a solution for a joint assessment of software quality and quality impact on users. In this research, we study the relation between software quality and the impact of quality on Quality of Experience (QoE) of users to support the assessment of software products, features, and requirements. We propose a Quality-Impact assessment method based on a joint analysis of software quality and user feedback. As an application of the proposed method in requirement engineering, the joint analysis guides verification and validation of functional and quality requirements as well as capturing new requirements. The study follows a design science approach to design Quality-Impact method artifact. The Quality-Impact method has been already designed and validated in the first design cycle. However, next design cycles will contribute to clarify problems of the initial design, refine and validate the proposed method. This paper presents the concluded results and explains future studies for the follow up of the Ph.D. research.	futures studies;requirement;requirements analysis;requirements engineering;software quality;software system;verification and validation;web design	Farnaz Fotrousi	2016	2016 IEEE 24th International Requirements Engineering Conference (RE)	10.1109/RE.2016.53	reliability engineering;requirements analysis;analytics;software requirements specification;verification and validation;requirement prioritization;software quality management;software verification;computer science;systems engineering;engineering;software design;user requirements document;software development;requirement;software engineering;requirements elicitation;software construction;software testing;software quality control;functional requirement;non-functional requirement;software requirements;software quality;software quality analyst	SE	-60.846858703606756	26.178698241793278	88689
b2d3cc82d30d27a530e3de3918829b8675a92405	a structured transformation approach for legacy information systems - a cash receipts/reimbursements example	conversation analysis;software maintenance;information systems management information systems platinum process planning postal services electrical capacitance tomography information analysis chromium identity based encryption companies;data analysis;large scale;functional analysis;structural transformation;management information systems accounts data processing systems re engineering software maintenance structured programming;structured programming;accounting information system;accounts data processing;management information systems;information system;conversion analysis structured transformation approach legacy information systems cash receipts reimbursements example upgraded information systems structured transit approach large scale legacy system transformation real world case study structured transit method transformation project company wide business process reengineering accounting information systems structured problem structured techniques scalability issues structural discrepancy analysis tasks functional analysis data analysis system flow analysis discrepancy analysis;legacy system;business process reengineering;flow analysis;systems re engineering	ch es Abstract Legacy information systems are difficult t transform into the new or upgraded informatio systems. Part of the reason is being t incompatibility and the unscalability between th systems. In this study, we propose and prese structured transit approach and process t provide an alternative in order to guide and eas the large scale legacy system transformation. this paper, we describe a real world case stu which we have applied the structured trans method successfully in 1997-1998. Th transformation project is a two-year company wide business process reengineering on th financial and accounting information system Through this project, We confirm our perceptio that the structured problem and solutio domains require the structured techniques tackle and to solve the compatablity an scalability issues because the structur discrepancy represents the core of the abo problems originally. We give the details of th application in five analysis tasks: the function analysis, the data analysis, the system flo analysis, the discrepancy analysis, and t conversion analysis.	accounting information system;adaptive binary optimization;business process;code refactoring;discrepancy function;information systems;legacy system;scalability;software incompatibility;source-to-source compiler	Jia-Lang Seng;Wayne Tsai	1999		10.1109/HICSS.1999.772847	functional analysis;business process reengineering;computer science;artificial intelligence;data-flow analysis;management science;accounting information system;data analysis;programming language;software maintenance;structured programming;legacy system;information system	AI	-52.31662768851868	21.085625859753105	88901
31a566ba79810c016caa21d32bacb19a71cb1e17	towards a hierarchical design and integration of programming projects	technical writing;communications skills;hierarchical structure;learning experience;object oriented design;software systems;writing;advanced courses;hierarchical design;software reuse	The idea of a hierarchical design and integration of programming projects in the computer science undergraduate curriculum is proposed and discussed. Research results in software reuse and object-oriented design and development may be used in the design and the development of the set of integrated programming projects. By a hierarchical design and integration of programming projects, this approach aims to increase the effectiveness of the undergraduate learning experience. Using the approach, programming projects in computer science courses may be developed in such a way that programming projects in the lower level courses are used as components (parts) to implement programming projects in the higher level courses. In this way, a hierarchical structure of programming projects can be built and a student's programming projects in different courses can be integrated. Such an integration may lead to the development of complex software systems in the senior year.	code reuse;computer science;software system	Wing Ning Li	1998		10.1145/273133.273175	technical writing;extreme programming practices;computer science;software development;extensible programming;object-oriented design;software engineering;programming paradigm;inductive programming;programming language theory;writing;software system	SE	-51.06114639220881	28.751564524816356	88925
e32d9e90ba9b16400a0602eb322ac86c023ee0d1	model-based requirements for integrating cloud services	computer and systems sciences;systemvetenskap informationssystem och informatik;information systems;data och systemvetenskap	Cloud-based services provide an alternative to the in-house implementation of various types of functionality. Organizations rely on such services to minimize the need for long-term commitments and enhance scalability and ubiquitous access to the services. However, achieving complex tasks that require a combination of services is not well studied, despite the potential added value. This paper investigates the requirements encountered when integrating cloud-based services in the modern organization. The paper proposes a modeldriven solution for capturing the requirements for integrating cloud-based services. The model is to be used within the larger context of the organizational design; modeling components used to describe requirements are related to other views of the organization. A prototype tool and an example business case are presented to illustrate how the requirements model can be elicited and designed. The models are capable of being transformed into an integration solution.	cloud computing;enterprise modelling;metamodeling;platform as a service;platform-specific model;prototype;provisioning;requirement;scalability	Iyad Zikra	2016			simulation;computer science;data mining;services computing;world wide web;information system	SE	-58.48283255283506	18.442638041057812	88931
4e73b389c72302800b91a8867b61a34d70cc582a	visualising the execution of concurrent object-oriented programes dynamically using uml	concurrent object oriented programming	Understanding the intricacies behind concurrency within object-oriented programming languages has always been a challenge for undergraduate students. This is particularly true since both are complex issues in their own rights. Visualisation, when used adequately, can be of tremendous assistance in expediting comprehension of such complex issues. The aim of this paper is to discuss the potential of UML, as a medium within visualisation, to assist the comprehension of the execution of a concurrent object-oriented program. We thus investigate the qualities of UML as a language; discuss some of the issues associated with concurrency and Java and finally discuss the design of our visualisation tool.	concurrency (computer science);java;programming language;scientific visualization;unified modeling language	Hugo Leroux;Christopher Exton	2001			computer architecture;expediting;visualization;concurrency;programming language;object-oriented programming;unified modeling language;computer science;comprehension;concurrent object-oriented programming;java	PL	-50.72345551566234	29.919314774049845	88983
e113a3db848570b7aaea927c755370f9642a3c39	scientific workflow management systems and workflow patterns	workflow design;management system;design reuse;scientific workflow;amruta rajkishor;development process;scientific workflows;rapid application development;triana;design pattern;software development;control flow;computer science scientific workflow management systems and workflow patterns purdue university john a springer shiroor;scientific workflow management systems;workflow management system;kepler;workflow patterns;taverna	Scientific workflow management systems primarily consist of data flow oriented execution models, and consequently, these systems provide a limited number of control flow constructs that are represented in dissimilar ways across different scientific workflow systems. This is a problem, since the exploratory nature of scientific analysis requires the workflows to dynamically adapt to external events and control execution of different workflow components. Hence some degree of control flow is necessary. The lack of standard specifications for specifying control flow constructs in scientific workflow management systems leads to workflows designed using custom developed components with almost no reusability. In this paper, we present a standard set of control flow constructs for scientific workflow management systems using workflow patterns. Firstly we compare the control flow constructs present in three scientific workflow management systems: Kepler, Taverna and Triana. Secondly these patterns are implemented ...	workflow pattern	Amruta Shiroor;John A. Springer;Thomas J. Hacker;Brandeis Marshall;Jeffrey Brewer	2010	IJBPIM	10.1504/IJBPIM.2010.033175	workflow patterns;workflow;xpdl;computer science;systems engineering;knowledge management;software development;management system;database;design pattern;windows workflow foundation;control flow;rapid application development;management;workflow management system;software development process;workflow engine;kepler;workflow technology	DB	-53.70398714254307	20.545054057896625	89196
2eb0f00bedfcb82476121e25eb35aa887962db8a	assigning ontological meaning to workflow nets	ontological semantics;business process models;workflow net wf net;rules;business processes	"""A common way to represent organizational domains is the use of business process models. A Workflow-net (WF-net) is an application of Petri Nets (with additional rules) that model business process behavior. However, the use of WF-nets to model business processes has some shortcomings. In particular, no rules exist beyond the general constraints of WF-nets to guide the mapping of an actual process into a net. Syntactically correct WF-nets may not provide meaningful models of how organizations conduct their business processes. Moreover, the processes represented by these nets may not be feasible to execute or reach their business goals when executed. In this paper, the authors propose a set of rules for mapping the domain in which a process operates into a WF-net, derived by attaching ontological semantics to WF-nets. The rules guide the construction of WF-nets, which are meaningful in that their nodes and transitions are directly related to the modeled (business) domains. Furthermore, the proposed semantics imposes on the process models constraints that guide the development of valid process models, namely, models that assure that the process can accomplish its goal when executed. tation) into process models. However, syntactically correct process models are not necessarily meaningful in terms of conveying the way the business conducts its activities. Moreover, a syntactically correct model might not even be feasible to execute, and even if it is, it cannot always be assured to reach its goal, namely, produce its required outcome. Some meaning can be represented in a process model via the semantics of the modeling language used. These semantics are believed to represent some realworld phenomena, and can be defined textually or mathematically. Either representation may DOI: 10.4018/jdm.2010070101 2 Journal of Database Management, 21(3), 1-35, July-September 2010 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. have shortcomings. Textual definitions are typically semi-formal or informal (e.g., “An event is something that “happens” during the course of a business process” (Object Management Group, 2006)), and therefore do not provide representations that are sufficiently precise for formal analysis. In contrast, mathematicallybased process representations (e.g., Petri nets (Petri, 1962), YAWL (van der Aalst & ter Hofstede, 2005), Pi Calculus (Milner, Parrow & Walker, 1992)), allow formal analysis and automated verification of models, but their semantics may not be readily associated with the problem domain. Much effort has been devoted to the formal analysis and verification of process models, leading to methods and tools for analyzing structural properties of process models and for detecting logical problems in them. In particular, Workflow nets (WF-nets)—a special case of Petri nets—have been proposed as tools for modeling the dynamics of processes (van der Aalst, 1998). A Workflow net is a Petri net which (1) has one input place and one output place; and (2) does not contain dangling transitions or places (namely, transitions that might not fire or places that might not be populated). This is equivalent to the net being strongly connected if the output place is interlinked to the input place via an additional transition (van der Aalst, 1998). Workflow nets employ a small set of constructs, yet possess an impressive expressive power and can be used to represent precisely the entire set of workflow patterns (van der Aalst et. al, 2003, Russel et al., 2006). An extensive body of work exists regarding the mathematical, structural, and behavioral properties of Petri nets, such as free choice, liveness, boundedness and strong connectedness (e.g., Esparza & Silva, 1990; Jensen, 1990; Desel & Esparza, 1995). These properties have been adapted for WF nets, and additional properties (such as soundness, relating to the process dynamics) have been defined (e.g., van der Aalst, 2000). Furthermore, these properties serve for formalizing and analyzing models in other process modeling languages (such as in EPC (van der Aalst, 1999) and in general workflow (van Hee et al., 2008). The mathematical semantics of Petri nets (and of WF-nets) is based on the dynamics of tokens that propagate through the net. While supporting formal analysis of process dynamics, Petri net token-based models have several disadvantages. First, they provide abstraction of transitions that can occur during the process. However, being abstract, the transitions in a net do not necessarily convey clearly the real world (dynamic) phenomena that occur in the domain in which the process operates. In other words, a transition does not necessarily reflect a change in the domain that has a clear meaning to stakeholders. In particular, no rules exist for mapping of the real world domain (part of an organization or a business) in which the process takes place into a WF-net beyond the general requirements of WF-nets. Hence, such models are not necessarily meaningful to stakeholders and, beyond that, processes represented by WF-nets might not even be feasible to execute in practice or might not be able to accomplish stakeholders’ goals. Second, an important advantage of WF-nets is that they possess several structural or behavioral properties which can be useful in formal analysis. Structural properties relate to the structure of the net, independent of its specific marking and include, in particular, free choice and well-structuredness (van der Aalst, 1998). Behavioral properties are initial marking dependent and include, in particular, soundness, separability and serialisability (van der Aalst, 1998; van Hee, Sidorova & Voorhoeve, 2008; Salimifard & Wright, 2001). However, without well-defined domain semantics assigned to places and transitions, the practical meaning of these properties, namely, what they imply about the domain phenomena they stand for, and their implication to process design is unclear. Finally, the formal analysis and verification of the above properties can be successfully applied to already developed models and identify potential problems in executing these models. However, without a clear mapping of these properties to the process domain, such analysis 33 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/assigning-ontological-meaningworkflow-nets/43728?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Library Science, Information Studies, and Education, InfoSci-Knowledge Discovery, Information Management, and Storage eJournal Collection, InfoSciSurveillance, Security, and Defense eJournal Collection, InfoSci-Select, InfoSci-Journal Disciplines Business, Administration, and Management, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Select. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	business process;petri net	Pnina Soffer;Maya Kaner;Yair Wand	2010	J. Database Manag.	10.4018/jdm.2010070101	semantics of business vocabulary and business rules;business domain;computer science;knowledge management;artifact-centric business process model;business process management;process modeling;data mining;database;management science;business process model and notation;business process;business process discovery;management;business rule;business process modeling	SE	-52.45095515840653	19.958419117011868	89358
ff0cc23cdb6d007f0ca3e3c77b059040a2ab05b2	an outline workflow for practical formal verification from software requirements to object code	iso 26262;formal workflow;model checking;formal requirements	This paper considers current state-of-the-art verification techniques that are based upon, or supported by, formal methods principles to ensure a high degree of assurance. It considers the practical application of such approaches in an industrial context so as to achieve an efficient, coherent and integrated workflow.#R##N##R##N#The key focus is a clear process that starts from software requirements and works through to the final object code on the target, ensuring key verification aims are fulfilled with a high-degree of confidence at each step. The process combines both analysis and testing to maximise the strengths and to cover the weaknesses of each.#R##N##R##N#For each step, a high-level description of the approach, potential benefits, prerequisites and limitations is given. The workflow outlined considers tools, methods and the supporting processes.	formal verification;object code;requirement;software requirements	Darren Sexton	2013		10.1007/978-3-642-41010-9_3	iso 26262;model checking;computer science;database;programming language;workflow management system;workflow engine;workflow technology	SE	-57.097249101103884	24.790071418156682	89424
ff9ecd1a710f2ecc244434a2042583d42aa512c5	an investigation into uml case tool support for the zachman framework	unified modeling language business data processing computer aided software engineering;computer aided software engineering;business data processing;case tools zachman framework uml;unified modeling language;zachmans criteria uml case tool support zachman framework enterprise architecture ea modeling evaluation criteria modeling notation;unified modeling language organizations standards organizations computer aided software engineering biological system modeling computer architecture complexity theory	Even though the Zachman Framework is a highly referenced framework for enterprise architecture (EA), there is still a lack of adoption by EA practitioners. Some of the factors that contribute towards this lack of adoption is the absence of accepted methodologies for adopting the Zachman Framework as an EA approach, as well as the lack of CASE tools supporting the practical use of the framework. In this paper we present the results of an investigation into methodological support when using UML together with the Zachman Framework for EA modeling. From this methodological study, we established evaluation criteria for tools that claim to support the Zachman Framework. We furthermore used these criteria to evaluate three popular CASE tools that claim to support the Zachman Framework. We focus specifically on the evaluation of the CASE tools' ability to assist a modeler with populating the cells of the Zachman Framework according to Zachman's criteria when using UML as a modeling notation.	applications of uml;computer-aided software engineering;enterprise architecture;modeller;population;profile (uml);requirement;unified modeling language;zachman framework	Aurona Gerber;Alta van der Merwe;Kevin Bayes	2013	Proceedings of the First International Conference on Enterprise Systems: ES 2013	10.1109/ES.2013.6690080	rm-odp;sherwood applied business security architecture;nist enterprise architecture model;computer science;systems engineering;knowledge management;software engineering;view model;information framework	SE	-55.977754152076805	21.12119715363675	89445
e6d6242c8d96e7196f32d030efbb012cbd106509	towards evaluation of security assurance during the software development lifecycle	software development lifecycle security assurance;trust;software;software performance evaluation security of data;application software;risk analysis;availability;probability density function;reconfigurable logic;software performance evaluation;software systems;data mining;software engineering;software security;trust software security assurance lifecycle evaluation;guidelines;evaluation methodology;security programming software systems application software reconfigurable logic software tools availability guidelines software engineering large scale systems;lifecycle;software development;security assurance;software security assurance;expert opinion;evaluation;software tools;tv;security;programming;security of data;software development lifecycle;context;software process;large scale systems	It is difficult to state whether a certain software productis developed securely enough. An evaluation methodology that takes the security assurance methods used during the software development lifecycle into account is one step closer to a solution to this problem. In this paper we discuss our first heuristics for security assurance evaluation that would give guidelines on the trustworthiness of the software development lifecycle. The input for evaluations include the context, expert opinions, outcome of the methods and reputation. Our evaluation heuristics are a step towards being able to deduce about the level of assurance for a software process, compared to a certain context-specific baseline.	application lifecycle management;baseline (configuration management);heuristic (computer science);software development process;trust (emotion)	Ilkka Uusitalo;Kaarina Karppinen;Pasi Ahonen;Heimo Pentikäinen	2009	2009 International Conference on Availability, Reliability and Security	10.1109/ARES.2009.124	software security assurance;reliability engineering;verification and validation;computer science;systems engineering;package development process;backporting;software engineering;application lifecycle management;software metric;software quality analyst	SE	-60.099525402166954	29.10386351642071	89470
c9f8032d1816a94636544f6dbdfb28053f30a92d	applying agile requirements engineering approach for re-engineering & changes in existing brownfield adaptive systems		Abstract. Requirements Engineering (RE) is a key activity in the development of software systems and is concerned with the identification of the goals of stakeholders and their elaboration into precise statements of desired services and behavior. The research describes an Agile Requirements Engineering approach for re-engineering & changes in existing Brownfield adaptive system. The approach has few modifications that can be used as a part of SCRUM development process for re-engineering & changes. The approach illustrates the re-engineering & changes requirements through introduction of GAP analysis & requirements structuring & prioritization by creating AS-IS & TO-BE models with 80 / 20 rule. An attempt to close the gap between requirements engineering & agile methods in form of this approach is provided for practical implementation.	adaptive system;agile software development;requirement;requirements engineering;software system	Abdullah Masood;M. Asim Ali	2014	CoRR		reliability engineering;requirements analysis;systems engineering;engineering;requirement;management science;requirements engineering	SE	-58.010491179134604	21.58193149414846	89480
ce403b31f6416f4fda025ddea0e41a6c5a8692d1	a methodology for eliciting and modeling exceptions	object process methodology;antibiotic treatment;exceptions;conceptual modeling;risk analysis;system analysis and design;conceptual model;conceptual design;elicitation methods;safety critical system;graphical model;modeling methodology;systems specification methodology	Exceptions in safety-critical systems must be addressed during conceptual design and risk analysis. We developed a conceptual model of exceptions, a methodology for eliciting and modeling exceptions, and templates for modeling them in an extension of the Object-Process Methodology (OPM)-a system analysis and design methodology and language that uses a single graphical model for describing systems, including their timing exceptions, which has been shown to be an effective modeling methodology. Using an antibiotics treatment guideline as a case study, we demonstrate the value of our approach in eliciting and modeling exceptions that occur in clinical care systems.	clinical use template;exception handling;graphical model;it risk management;object process methodology;system analysis	Mor Peleg;Judith Somekh;Dov Dori	2009	Journal of biomedical informatics	10.1016/j.jbi.2009.05.003	computer science;conceptual model;machine learning;data mining	SE	-54.52232372513213	20.62670675572686	89648
4f581e56b3202258b53a2100f13de2e36c291c3e	the data model of the configuration management assistant (cma)	configuration management;data model	In an environment in which systems are configured by reusing existing subsystems, the determination of complete and consistent configurations is a non-trivial and error-prone task, although considerable information about the subsystems may already be available from previous configurations. The Configuration Management Assistant is a tool that supports tracking and exploiting such information in the difficult process of re-configuration on a large scale. Its data model was designed to be as independent as possible of configuration management policies and procedures and yet provide substantive assistance in this process. The most important elements of this data model are described in this paper.1	application domain;cima: the enemy;cma-es;canonical account;cognitive dimensions of notations;configuration management;data model;database;programming language;software engineering;version control	Erhard Plödereder;A. Fergany	1989		10.1145/72910.73339	configuration management;configuration management database;data model;computer science;systems engineering;engineering;data mining;database;configuration management	SE	-55.962822455176315	25.925730499741178	89765
fca8fe90ce3ea041099cab17164233041f7a2f38	development of a modeling language to connect features, functions and components	features;development process	features;development process	modeling language	Axel Grewe;Marcel Ibe;Frank Nehuis;Andreas Rausch;Thomas Vietor	2014		10.1016/j.procs.2014.03.025	computer science;algorithm	NLP	-51.32275003080485	26.644073262925044	89917
4115b0f44b4526a4850bc2ecca31607e8309b05f	an exchange model for reengineering tools	programming language;tool support;object oriented systems;large scale;object oriented programming languages;legacy system	Tools support is recognised as a key issue in the reengineering of large scale object-oriented systems. However, due to the heterogeneity in today’s object-oriented programming languages, it is hard to reuse reengineering tools across legacy systems. This paper proposes a language independent exchange model, so that tools may perform their tasks independent of the underlying programming language. Beside supporting reusability between tools, we expect that this exchange model will enhance the interoperability between tools for metrics, visualization, reorganisation and other reengineering activities. The complete model is available at: h tp://www.iam.unibe.ch/~famoos/InfoExchFormat/ All comments are welcome: famoos@iam.unibe.ch .	code refactoring;interoperability;legacy system;programming language	Sander Tichelaar;Serge Demeyer	1998			fourth-generation programming language;first-generation programming language;method;declarative programming;very high-level programming language;programming domain;reactive programming;computer science;systems engineering;object;object-relational mapping;third-generation programming language;functional logic programming;database;programming paradigm;inductive programming;fifth-generation programming language;programming language theory;programming language;second-generation programming language;comparison of multi-paradigm programming languages	SE	-50.74106249755711	28.296809915049703	90391
e11147faed07c89620cd906939e641b65bb668f5	juggling in free fall: uncertainty management aspects of domain analysis methods	domain model;uncertainty management;artificial intelligent;domain analysis;software reuse;domain specificity	Although software reuse research has borrowed extensively from artificial intelligence techniques and methods, there has been little explicit discussion in reuse research of uncertainty management, an area of critical importance in many AI applications. Yet several fundamental reuse issues, particularly in domain analysis methods and processes, can be usefully framed as problems of uncertainty. This paper characterizes ad hoc reuse, design for reuse, domain-specific reuse and domain analysis from an uncertainty-based perspective, and presents and motivates key aspects of a specific DA method, Organization Domain Modeling (ODM) as examples of uncertainty management strategies in domain analysis methods and processes.	applications of artificial intelligence;code reuse;domain analysis;hoc (programming language);oracle data mining;uncertainty quantification	Mark A. Simos	1994		10.1007/BFb0035984	domain analysis;simulation;domain;business domain;feature-oriented domain analysis;domain engineering;domain model	AI	-59.648810999472566	24.82048182606488	90396
635826bf41a68ada2299b5be50dccf5651591386	exactly the information your subcontractor needs: desyre — decomposing system requirements	distributed development;formal specification;software systems;pipelines vehicles systematics natural languages routing calculators proposals;inference mechanisms formal specification formal verification;inference mechanisms;formal verification;requirement engineering;decomposition patterns subcontractor information need desyre software system development distributed development smooth integration requirements engineering systematically derive subsystem requirements	In software systems development, the increasing size and complexity of systems is handled by decomposition. Companies additionally sign up different subcontractors for subsystems. For distributed development and smooth integration, a major challenge is to deduce subsystem specifications from system specifications in order to deliver them to the subcontractors.	application domain;categorization;computer-aided software engineering;microsoft outlook for mac;natural deduction;refinement (computing);requirement;software development process;software system;system requirements	Birgit Penzenstadler	2011	2011 First International Workshop On Requirements Patterns	10.1109/RePa.2011.6046720	reliability engineering;formal methods;computer science;systems engineering;theoretical computer science;formal specification	SE	-53.1230689136903	26.63179924787412	90696
080f379eb99191e2fa1f324abb1c033fb767bb04	user-controlled reflection on join points	reflection;consumer product.;context;join point;index terms—aspect orientation;embedded system;domain knowledge;component model;indexing terms;aspect oriented	All aspect orientation languages provide a onesize-fits-all methodology for reflection on join points. However, the amount of resources necessary for this approach is too high to be applicable in the context of consumer products. In this industrial research paper, we describe a solution to this problem and prove via an experiment that it is suitable for our context. In particular, we advocate that in the context of consumer products the reflective information should be passed explicitly using dedicated reflection parameters. Furthermore, since reflective information should efficiently encode the relevant domain knowledge, the user must be in control of the type of the dedicated reflection parameters. We describe how we implemented user-controlled reflection on join points in our aspect-oriented framework AspectKoala [12] on top of the component model Koala [13]. We compare the resource consumption of different approaches to add reflective information on join points using this implementation. The difference in resource consumption clearly demonstrates the benefits of our solution for consumer products.	aspect-oriented software development;central processing unit;compiler;component-based software engineering;encode;experiment;fits;join point	Piërre van de Laar;Rob Golsteijn	2007	JSW		reflection;aspect-oriented programming;index term;computer science;data mining;component object model;database;programming language;domain knowledge	DB	-55.68374341671141	27.41542862684322	90732
8d9545064e651776049638d6df402b82d7acff8b	investigating maintenance processes in a framework-based environment	electrical capacitance tomography;empirical study;investments;application software;software maintenance;student project;object oriented framework;testing;object oriented programming;reuse;observational study;software reusability;electrical capacitance tomography application software software maintenance computer science educational institutions read only memory concrete testing documentation investments;object oriented framework maintenance processes framework based environment reuse;computer science;framework based environment;maintenance processes;object oriented programming software maintenance software reusability;similarity function;quantitative method;read only memory;documentation;concrete	The empirical study described in this paper focuses on the effectiveness of maintenance processes in an environment in which a repository of potential sources of reuse exists, e.g. a context in which applications are built using an object-oriented framework. Such a repository might contain current and previous releases of the system under maintenance, as well as other applications that are built on a similar structure or contain similar functionality. This paper presents an observational study of 15 student projects in a framework-based environment. We used a mix of qualitative and quantitative methods to identify and evaluate the effectiveness of the maintenance processes.	c++;code reuse;controlled vocabulary;design pattern;experiment;usability;wintel	Victor R. Basili;Filippo Lanubile;Forrest Shull	1998		10.1109/ICSM.1998.738517	reliability engineering;application software;concrete;documentation;computer science;systems engineering;engineering;operating system;software engineering;reuse;programming language;software maintenance;observational study	SE	-54.93197875337359	31.999073476034617	91546
d74b21d4c3625a8611d4d6d56336a37b28cee31a	extraction d'architecture à base de composants d'un système orienté objet	software component;orienté objet;mots-clés : architecture logicielle;ingénierie;composants logiciels;object-oriented;metrics;reverse en- gineering;métriques keywords:software architecture;extraction;rétro	Having a representation of the architecture of complex systems became p redominant during all the software life cycle phases. However, for many systems, ther e is no reliable representation of their architectures available.In order to avoid this lack which ca uses many difficulties, we suggest, in this paper, an approach aiming at extracting compone nt-based architectures from object-oriented systems. The main idea of this approach is to propose a semi-automated identification process of components based on their semantic and structur al haracteristics. MOTS-CLÉS : architecture logicielle, extraction, composants logiciels, orienté objet, rétro ingénierie, métriques	complex systems;semiconductor industry;software release life cycle;windows nt	Sylvain Chardigny;Abdelhak-Djamel Seriai;Mourad Chabane Oussalah;Dalila Tamzalit	2007			programming language;engineering drawing;architecture;component-based software engineering;software architecture;blank;paperboard;software development process;object-oriented programming;computer science	Arch	-51.503612030241925	27.97745345882921	91588
d6fbe926520ce1ac613941c591a1bd77e710723f	software engineering metrics for cots-based systems	software metrics;quality metric;investments;return on investment;cbs software engineering metrics cots based systems commercial off the shelf components software development business practices risk concerns cots based system design noncritical applications risk management metrics based approach return on investment quality improvement initiatives complex models quality metrics;application software;quality metrics;quality improvement initiatives;risk management;quality improvement;software engineering metrics;risk concerns;business practices;software development management software metrics software quality software packages risk management;software engineering;software engineering application software costs programming business risk management quality management software development management engineering management investments;metrics based approach;commercial off the shelf;paradigm shift;commercial off the shelf components;noncritical applications;system design;engineering management;business;software development;cbs;cots based systems;programming;software quality;software development management;quality management;software packages;cots based system design;complex models	The paradigm shift to commercial off-the-shelf components appears inevitable, necessitating drastic changes to current software development and business practices. Quality and risk concerns currently limit the application of COTS based system design to noncritical applications. New approaches to quality and risk management will be needed to handle the growth of CBSs. Our metrics based approach and software engineering metrics can aid developers and managers in analyzing the return on investment in quality improvement initiatives for CBSs. These metrics also facilitate the modeling of cost and quality, although we need more complex models to capture the intricate relationships between cost and quality metrics in a CBS.		Sahra Sedigh Sarvestani;Arif Ghafoor;Raymond A. Paul	2001	IEEE Computer	10.1109/2.920611	paradigm shift;programming;return on investment;quality management;application software;software development;software engineering;management;software quality;software metric;green chemistry metrics;systems design	Visualization	-62.033389613648644	27.192144440743554	91626
fdd44b55b2137afe761661f4cbb49f5abca322ed	object-oriented modeling approach of universal education software				Dalibor Petkovic;Srdjan Jovic;Zoran Golubovic	2018	Comp. Applic. in Engineering Education	10.1002/cae.21906	object-oriented modeling;human–computer interaction;software;computer science	SE	-50.505174009720434	27.773194173671197	91709
de260be58e6f393d5eb5217311f634cb9f87bf63	modeling approaches for the design and analysis of complex systems	settore ing inf 05 sistemi di elaborazione delle informazioni	"""The design of a complex system traditionally relies on a systems engineering process that makes use of text documents and engineering data in multiple formats. The inherent limitations of the document-based manual approach have been targeted by the model-based systems engineering (MBSE) approach, promoted by the International Council on Systems Engineering (INCOSE), which defines MBSE as """"the formalized application of modeling to support system requirements, design, analysis, verification, and validation activities beginning in the conceptual design phase and continuing throughout development and later life cycle"""" (INCOSE, 2007). In this respect, SysML (Systems Modeling Language) is the language that provides the modeling capability required in the systems engineering domain. SysML, which has been developed as an UML (Unified Modeling Language) extension, is now considered the standard modeling notation adopted in the MBSE context (OMG 2010). In addition, the recent adoption of the Business Process Modeling and Notation (BPMN) standard by the OMG (Object Management Group, the same body that defines and promotes UML and SysML), has introduced into the MBSE discipline the formalization of the business layer describing the interactions among the organizations that make use of systems at the context or operational scenario analysis level (OMG 2011). The advantages obtained by the MBSE approach, in terms of enhanced communications, reduced development risks, improved quality, increased productivity and enhanced knowledge transfer, can be further scaled up by innovative approaches that treat models as the primary artifacts of development, by increasing the level of automation throughout the system lifecycle. Such approaches have been introduced in the model-driven engineering (MDE) field and represent a radical shift from a merely contemplative use of models to a productive and more effective use (D. C. Schmidt, 2006). The application of MDE to systems engineering has been denoted as model-driven systems engineering (MDSE) (D. Gianni, A. D'Ambrogio and A. Tolk, 2014). MDSE applies metamodeling techniques and automated model transformations, introduced in the more general model-driven engineering context, to Copyright    ©    held    by    the    authors. the systems engineering domain, thus boosting the aforementioned advantages of the"""	business process model and notation;business logic;complex system;complex systems;interaction;msde;metamodeling;model-based systems engineering;model-driven engineering;process modeling;requirement;sms language;scenario analysis;schmidt decomposition;system lifecycle;system requirements;systems modeling language;unified modeling language;verification and validation	Andrea D'Ambrogio;Lucio Tirone	2014			simulation;systems modeling language;systems engineering;engineering	SE	-55.36022330862789	23.085067089548655	91772
a80bb7bfdc95af5d13d8e036081c3df690506dbc	three steps multiobjective decision process for software release planning	meta heuristic algorithms;requirements management;software project management;computer aided software engineering tools;requirements selection	This paper deals with how to determine which features should be included in the software to be developed. Metaheuristic techniques have been applied to this problem and can help software developers when they face contradictory goals. We show how the knowledge and experience of human experts can be enriched by these techniques, with the idea of obtaining a better requirements selection than that produced by expert judgment alone. This objective is achieved by embedding metaheuristics techniques into a requirements management tool that takes advantage of them during the execution of the development stages of any software development project. © 2015 Wiley Periodicals, Inc. Complexity, 2015	software release life cycle	Isabel María del Águila;José del Sagrado	2016	Complexity	10.1002/cplx.21739	requirements analysis;long-term support;software requirements specification;verification and validation;requirements management;requirement prioritization;software engineering process group;software sizing;software project management;search-based software engineering;computer science;software design;social software engineering;software development;software construction;management science;application lifecycle management;computer-aided software engineering;goal-driven software development process;software requirements;software system;software peer review	Robotics	-61.62615133815832	25.553707175652146	91960
f1094fbc8df6303193433219bc398a8b7dc1eb13	an approach to manage the concept phase of iso 26262	dspo;iso 26262;requirements;kaos;gsn;functional safety;hazard analysis	We face two difficulties when applying ISO 26262[1] in the concept phase. ISO 26262 is the functional safety standard in the automobile field and requires strict safety requirements. Usually, it is not easy to divide requirements into safety parts and non-safety parts because they are closely connected with each other. That is, we have to perform two activities, functional development and functional safety activity, simultaneously. Other difficulty is a term item. From the definition, the item is a 'system 1.129 or array of systems to implement a function at the vehicle level'. In concept phase, we apply hazard analysis to an item, not system. The system definition comes after item definition and hazard analysis and risk assessment. So, it is hard to use the conventional methods e.g. Failure Mode and Effect Analysis FMEA and Fault Tree Analysis FTA.		Masao Ito;Koichi Kishida	2014	Journal of Software: Evolution and Process	10.1002/smr.1670	iso 26262;reliability engineering;requirements analysis;systems engineering;engineering;operations management;hazard analysis;functional safety;system safety	Vision	-62.14588188232514	22.14464197066464	91967
f6e88823482de1729584acbfb450d4502f4d393d	architectural patterns for microservices: a systematic mapping study		Microservices is an architectural style increasing in popularity. However, there is still a lack of understanding how to adopt a microservice-based architectural style. We aim at characterizing different microservice architectural style patterns and the principles that guide their definition. We conducted a systematic mapping study in order to identify reported usage of microservices and based on these use cases extract common patterns and principles. We present two key contributions. Firstly, we identified several agreed microservice architecture patterns that seem widely adopted and reported in the case studies identified. Secondly, we presented these as a catalogue in a common template format including a summary of the advantages, disadvantages, and lessons learned for each pattern from the case studies. We can conclude that different architecture patterns emerge for different migration, orchestration, storage and deployment settings for a set of agreed principles.	architectural pattern;microservices;software deployment	Davide Taibi;Valentina Lenarduzzi;Claus Pahl	2018		10.5220/0006798302210232	database;computer science;microservices;architectural pattern	SE	-59.72296763957878	21.62547406374362	92096
cd5e530cc1e916c3eb520dcf151e48c47324395a	extending test templates with inheritance	formal specification;specification based testing;object oriented programming;reuse;program testing;object oriented;specification languages;object oriented languages program testing object oriented programming inheritance formal specification specification languages;test templates;software testing object oriented modeling information technology australia formal specifications clustering algorithms monitoring automatic testing;inheritance;object oriented languages;object oriented testing;eiffel queue classes test templates inheritance specification based testing test template framework object oriented programming object z	We are extending a framework for specification-based testing, the Test Template Framework, to include objectoriented features such as those provided in Object-Z. This paper reports on our work extending the Framework to include inheritance. In testing a subclass, the testing information for the parent class is inherited and thus reused. We have identified conditions under which testing information can be inherited without change, when it is inherited with modifications and when it must be derived from scratch. We illustrate the technique with an example based on the Eiffel Queue classes.	eiffel;encapsulation (networking);generic programming;merkle tree;object-z;process calculus;software testing;test template framework	Leesa Murray;David A. Carrington;Ian MacColl;Paul A. Strooper	1997		10.1109/ASWEC.1997.623757	multiple inheritance;real-time computing;computer science;database;programming language;object-oriented programming	SE	-53.92844266568326	31.93861116312782	92117
5076979a45714e984e93cc25125c7921df151990	uml4iot - a uml-based approach to exploit iot in cyber-physical manufacturing systems	industrial automation thing;manufacturing systems;cyber physical systems;internet of things iot;uml profile;mechatronics;industry 4 0	Using IoT protocols in the development process of manufacturing systems.An approach to automate the integration of mechatronic components in the IoT environment.An extension of UML to support the transformation of traditional OO interfaces of manufacturing components to REST-like ones.UML4IoT: A UML profile for the automatic generation of the LWM2M layer.Performance analysis and evaluation of a LWM2M based IoT solution for manufacturing systems. Internet of Things (IoT) is changing the world. The manufacturing industry has already identified that the IoT brings great opportunities to retain its leading position in economy and society. However, the adoption of the IoT changes the development process of the manufacturing system and raises many challenges. In this paper, the modern manufacturing system is considered as a composition of cyber-physical, cyber and human components, and IoT is used as a glue for their integration as far as their cyber interfaces are concerned. An approach based on a UML profile for the IoT is presented to fully automate the generation process of the IoT-compliant layer that is required for the cyber-physical component to be effectively integrated into the modern IoT manufacturing environment. The approach can also be applied at the source code level specification of the component in case that a UML design specification is not available. A prototype implementation of the myLiqueur production laboratory system is used to demonstrate the applicability and effectiveness of the UML4IoT approach.	unified modeling language	Kleanthis Thramboulidis;Foivos Christoulakis	2016	Computers in Industry	10.1016/j.compind.2016.05.010	mechatronics;computer science;systems engineering;engineering;applications of uml;database;cyber-physical system;internet of things;manufacturing engineering;mechanical engineering	Robotics	-56.33949254418825	25.670887143780398	92364
73df054cc388c0a848a686519c846cba258bbdd6	evolving a software products line for e-commerce systems: a case study	unifi;verification;reliability;e commerce;component based development;firenze;dependable systems;software evolution;affidabili;software architecture stability;ricerca;resilient computing lab;dependability;aspect oriented development;validation;rcl;affidabilita;florence;sistemi;software product lines;assessment	Software Product Lines engineering is a technique that explores systematic reuse of software artifacts in large scale to implement applications that share a common domain and have some customized features. For improving Product Line Architecture evolution, it is advisable to develop Software Product Lines using a modular structure. This demand can be satisfied by an aspect-oriented and component-based feature-architecture method that integrates components, aspects and variation point aspect-connectors. This approach allows minimization of feature scattering in the architectural model and supports modular modelling of crosscutting features. A case study mapping major features of significant e-commerce systems operating in Brazil and other countries was performed to evaluate this approach. The assessment of our solution was performed comparing its stability and modularity with other two approaches. Our results indicate that change impact in the architectural model is reduced when using our solution in the context of Software Product Lines evolution.	aspect-oriented software development;component-based software engineering;e-commerce payment system;numerical stability;software product line	Raphael P. Azzolini;Cecília M. F. Rubira;Leonardo P. Tizzei;Felipe Nunes Gaia;Leonardo Montecchi	2015		10.1145/2797433.2797460	domain analysis;e-commerce;reliability engineering;verification;software sizing;architectural pattern;computer science;systems engineering;engineering;software evolution;component-based software engineering;software development;software engineering;domain engineering;software construction;reliability;dependability;feature model;educational assessment;product engineering	SE	-57.541405408064975	27.890395391383347	92607
774b751812670fb9ddb8787d81631eb70d4062ef	iarch-u: interface-centric integrated uncertainty-aware development environment		Uncertainty can appear in all aspects of software development: uncertainty in requirements analysis, design decisions, implementation and testing. If uncertainty can be dealt with modularly, we can add or delete uncertain concerns to/from models, code and tests whenever these concerns arise or are fixed to certain concerns. To deal with this problem, we developed iArch-U, an IDE (Integrated Development Environment) for managing uncertainty modularly in all phases in software development. In this paper, we introduce an overview of iArch-U. The iArch-U IDE is open source software and can be downloaded from GitHub.	automaton;integrated development environment;local tangent space alignment;model checking;modular programming;open-source software;prototype;requirement;requirements analysis;software development	Keisuke Watanabe;Naoyasu Ubayashi;Takuya Fukamachi;Shunya Nakamura;Hokuto Muraoka;Yasutaka Kamei	2017	2017 IEEE/ACM 9th International Workshop on Modelling in Software Engineering (MiSE)	10.1109/MiSE.2017.7	reliability engineering;real-time computing;systems engineering;engineering	SE	-49.41981504713284	32.285480986861614	92612
b305ea8451a394a58fdef41f4a39fd7d5b81094c	empirical-based design — quality-driven assembly of components	software measurement;runtime;design quality;assembly;adaptation model;system integration;web services;production facilities;production facilities assembly adaptation model runtime data models web services software measurement;data models	The importance of providing integration architectures in every field of application is beyond controversy these days. Unfortunately existing solutions are mainly focusing on functionality. But for the success of Systems Integration in the long run, the quality of developed architectures is of substantial interest. Existing quality-related information can be reused to optimize this assembly of components to thereby always provide the best possible combination. For this purpose a framework for the quality-driven creation of architectures is proposed in this paper. Besides this quality-oriented characteristic, the usage of semantic knowledge and structured process descriptions enable an automatic procedure. Especially the combination of both is a promising approach.	entity;extensibility;ontology (information science);process modeling;software measurement;system integration;web service	Martin Kunz;Steffen Mencke;Dmytro Rud;Reiner R. Dumke	2008	2008 IEEE International Conference on Information Reuse and Integration	10.1109/IRI.2008.4583063	web service;data modeling;computer science;operating system;data mining;database;assembly;software measurement;system integration	Robotics	-48.53587089338126	19.268427072361444	92827
b5ba1d72574cb6a88bed6e236f17915b26997f1b	developing software components with the uml, enterprise java beans and aspects	component specification component based systems uml enterprise java beans complex systems end user application enhancement aspect oriented component engineering method;component based systems;uml;plug and play;aspect oriented design;computer aided software engineering;complex system;computer aided software engineering java specification languages;specification languages;software component;xml;unified modeling language java object oriented modeling application software xml runtime software standards standards development user interfaces computer science;aspect oriented component engineering;enterprise java beans;enterprise java bean;java	Component-based systems have become increasingly popular approaches to developing complex systems, offering well-formed abstractions, strong potential for reuse, dynamic plug-and-play and sometimes end-user application enhancement. Unfortunately the design, implementation and deployment of components is very challenging, particularly achieving appropriate division of responsibility among components, designing components and implementing components. We have developed the Aspect-Oriented Component Engineering method to help improve component development by the use of aspects during component specification, design, implementation and deployment. We describe our recent work extending the UML to facilitate aspect-oriented component design and the use of Enterprise Java Beans to implement these designs.	aspect-oriented software development;code generation (compiler);complex systems;component-based software engineering;cross-cutting concern;enterprise javabeans;gadget (computer science);java platform, enterprise edition;plug and play;prototype;run time (program lifecycle phase);software deployment;third-party software component;unified modeling language;well-formed element;xml	John C. Grundy;Rakesh Patel	2001		10.1109/ASWEC.2001.948506	unified modeling language;complex systems;xml;common component architecture;computer science;systems engineering;component-based software engineering;software engineering;programming language;java;computer-aided software engineering	SE	-50.29059234519778	26.33757592177999	92942
9b2a79787f5291119821b4469e192118c00b9aff	cmof-model semantics and language mapping for mof 2.0 implementations	java language mapping cmof model semantics mof 2 0 implementations metamodelling programming object oriented metamodels;computer languages;programming environments;object oriented metamodels;object oriented programming;metamodelling programming;modelling language;object oriented;specification languages;cmof model semantics;safety;unified modeling language;specification languages java object oriented programming;object oriented modeling computer languages unified modeling language java concrete programming environments conferences computer science object oriented programming safety;java language mapping;computer science;mof 2 0 implementations;object oriented modeling;type safety;meta model;conferences;property value;concrete;java language;java	Meta-modelling programming frameworks enable engineers to deal with models, defined through object-oriented meta-models, in the environment of programming languages. Existing frameworks use redefinition relationships between meta-model classes to encourage reusable meta-model design. In contrast to existing platforms the upcoming MOF 2.0 OMG recommendation proposes the meta-modelling language CMOF that also includes the possibility to define redefinition, and sub-setting constraints between the properties of meta-model classes. In this paper we extend existing implementation strategies and language mappings to realize these new features in a MOF 2.0 implementation. We propose a Java language mapping for the CMOF-model, based on method overwriting with changing return types and generic collection types that allow reasonable static type safety. Furthermore, we describe the semantics that are needed to implement functionality for adding and removing property values that automatically yields sub-setting constraints	apl;covariant return type;domain-specific language;embedded software;hoc (programming language);integrated development environment;integrated software;java metadata interface;meta-object facility;metamodeling;model-based definition;object constraint language;operational semantics;overwriting (computer science);profile (uml);programming language;request for proposal;run time (program lifecycle phase);software engineering;transformation language;type conversion;type safety;type system;unified modeling language;windows update	Markus Scheidgen	2006	Fourth Workshop on Model-Based Development of Computer-Based Systems and Third International Workshop on Model-Based Methodologies for Pervasive and Embedded Software (MBD-MOMPES'06)	10.1109/MBD-MOMPES.2006.4	computer science;theoretical computer science;database;programming language;object-oriented programming	PL	-48.59408238629322	27.280803260029806	92958
3b719d2447c81ebbcdb732ea8a917790ac49d059	cost-effective maintenance tools for proprietary languages	computer languages;high level languages;sdl grammar;lucent technologies;proprietary sdl dialect;software maintenance;unoperational toolset;construction industry;language dependent code generation;code generation;maintenance cost;software tools software maintenance high level languages software reusability program compilers systems re engineering;computer industry;development process;software engineering;language development process;standards development;short term solution;software reusability;re engineering;language centered software engineering approach;cost effectiveness;software standards;cost effective maintenance tools;software tools;sdl documentation generator;program compilers;proprietary languages;software reuse;documentation;costs software engineering documentation computer languages computer industry construction industry software maintenance software tools software standards standards development;sdl documentation generator cost effective maintenance tools proprietary languages short term solution unoperational toolset case study lucent technologies maintenance cost language development process language centered software engineering approach software reuse language dependent code generation proprietary sdl dialect re engineering sdl grammar;systems re engineering	Maintenance of proprietary languages and corresponding tooling is expensive. Postponing maintenance to reduce these costs is an often applied, short-term solution which eventually may lead to an unoperational toolset. This paper describes a case study carried out in cooperation with Lucent Technologies where maintenance cost is decreased by simplifying the development process of languages and tools. The development process is simplified by using a languagecentered software engineering approach which increases software reuse and language dependent code generation. The case study was concerned with Lucent’s proprietary SDL dialect and involved the re-engineering of an SDL grammar and the construction of an SDL documentation generator.	code generation (compiler);code reuse;documentation generator;simple directmedia layer;software engineering	Merijn de Jonge;Ramin Monajemi	2001		10.1109/ICSM.2001.972737	documentation;computer science;systems engineering;engineering;software engineering;programming language;software maintenance;code generation	SE	-50.37959873984897	31.91859129224988	93019
56190861f053e0299066c8c916dcfaec04c54d46	software specifications, data bases and knowledge bases	knowledge base;software specification		database	Stephen W. Smoliar	1983			software design description;software requirements specification;software mining;database;software development;software construction;package development process;software verification and validation;software design;computer science	DB	-51.60274906992437	26.02293730592507	93060
18154966ffd38ac777dcf3c81c02eb2e21448573	semantic adaptation of business information systems using human-centered business rule engines	intelligent user interface business information system business rules customizing semantic adaptation human centered business rule engine;intelligent user interface;information systems;customer relationship management;customizing;semantic web business data processing data mining graphical user interfaces human computer interaction management information systems ontologies artificial intelligence;semantics;semantic adaptation business information systems business information system customization erp crm decision making system components end users human centered business rule engines data mining intelligent user interfaces ontology vocabulary analysis mapping approach user oriented semantic types;business information system;human centered business rule engine;semantic adaptation;engines;information systems semantics engines ontologies semantic web customer relationship management;semantic web;ontologies;business rules	There is a strong need for customizing business information systems, such as ERP or CRM solutions. This paper focuses on emerging decisions and on business rules to support the decision making. The proposed business rules can be edited by end users as well as system components. Both - the users and the system - shall be able to learn business rules as well as integrate, and use them intelligently in the business information system. In order to address this concern, human-centered business rule engines are proposed, which integrate data mining support and provide intelligent user interfaces to collaborating users. An underlying ontology is used to specify the vocabulary for the business rules dependent on the business information system. We apply a mapping approach to map the concepts and relationships of the underlying ontology to user-oriented semantic types. Three usage scenarios give some examples of how the presented approach can be used.	artificial intelligence;big data;business process;business rules engine;context (computing);customer relationship management;data mining;erp;industry 4.0;intelligent user interface;management information system;semantic reasoner;vocabulary	Jessica Rubart	2016	2016 IEEE Tenth International Conference on Semantic Computing (ICSC)	10.1109/ICSC.2016.18	business rule management system;business analysis;business logic;semantics of business vocabulary and business rules;business domain;business requirements;computer science;knowledge management;artifact-centric business process model;business process management;ontology;artificial intelligence;semantic web;business case;data mining;database;semantics;business process model and notation;linguistics;business process;business software;business process discovery;business rule;new business development;world wide web;business process modeling;information system;business activity monitoring;business decision mapping;business architecture	DB	-53.48068230516118	19.369923596246775	93069
bd3a63bfcb680ac525aee325d893d3822f30ee1a	an embedded software component maturity model	reliability;certification;embedded design quality model maturity model quality verification embedded system;software systems;object oriented programming;software component maturity model;embedded system;risk levels;maturity model;accuracy;embedded software component maturity model;quality system;guidelines;capability maturity model;software component;component based software development;embedded design;selection evaluation levels;quality verification;software quality capability maturity model object oriented programming;embedded software software quality application software iso standards iec standards software systems guidelines certification software measurement runtime;quality model;software component maturity model embedded software component maturity model component based software development software quality systems selection evaluation levels risk levels;software quality;documentation;embedded software;software quality systems	Component-Based Software Development (CBSD) is focused on assembling existing components to build a software system, with a potential benefit of delivering quality systems more fast, thus, increasing its productivity. These benefits are just achieved if the software components used to compose the software system were previously evaluated in order to establish a certain quality level. However, there are a set of different risk levels associated to each software component, depending, mainly, on its application domain, mainly in embedded domain. In this way, we aim to propose an embedded software component maturity model in order to assure quality for each kind of embedded software component risk-level, describing its levels, techniques adopted and the guidelines for selection evaluation levels. A preliminary case study was accomplished in order to prove its real applicability and viability.	application domain;capability maturity model;component-based software engineering;domain-specific language;embedded software;embedded system;risk assessment;software development;software system	Fernando Luiz de Campos Carvalho;Silvio Romero de Lemos Meira;Elyda Xavier;Joao Eulino	2009	2009 Ninth International Conference on Quality Software	10.1109/QSIC.2009.63	reliability engineering;verification and validation;software sizing;computer science;systems engineering;engineering;package development process;backporting;software framework;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;programming language;software measurement;software deployment;software quality control;capability maturity model;software metric;software quality analyst;avionics software	SE	-57.674149120721445	27.863206418773434	93082
b8006c21f16e0bb4563e59581927f4729bdaa9cc	quality in ict reengineering and refactoring	topology;measurement;software systems;maintenance engineering;network topology;measurement software systems topology network topology software quality maintenance engineering;software quality	Software reengineering and refactoring are related but distinct activities. Reengineering a software system typically involves first reverse engineering it in order to extract a high-level design, and then forward engineering it to improve its design, add new functionality or correct errors. Refactoring differs from this in two ways. Firstly, refactoring is usually a code-to-code transformation and secondly, its goal is to improve design, not to change functionality. Reengineering has been a standard physical engineering process for a long time, coming into use as a software process in the early 1990s. The advent of refactoring is more recent, aided by the burgeoning popularity of Agile Processes that emphasize code quality and regard refactoring as a central part of the development process. Unlike software reengineering, refactoring has no equivalent in physical engineering.	agile software development;business process;code refactoring;high- and low-level;level design;model-driven architecture;reverse engineering;software development process;software quality;software system	Mel Ó Cinnéide	2010	2010 Seventh International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2010.57	maintenance engineering;reliability engineering;long-term support;verification and validation;software engineering process group;software sizing;computer science;systems engineering;engineering;social software engineering;software development;software engineering;software construction;resource-oriented architecture;software maintenance;software deployment;software requirements;network topology;software quality;measurement;software system	SE	-62.46266038015241	26.866858753043843	93091
e340c3f6e2e2656f36c9acea02f8aa770a43d136	separating concerns throughout the development lifecycle	aspect oriented programming;software development	Work on aspect-oriented programming [3] and subject-oriented programming [2,4] has identified difficulties associated with code tangling in software development. Each has provided solutions for separating code that affects many units of functionality in the system (i.e. cross-cutting code), with corresponding composition techniques to integrate cross-cutting and component code. Benefits common to both approaches include simplified code that is easier to develop and maintain.	align (company);aspect-oriented programming;concurrency (computer science);requirement;software development;software system;traceability	Siobhán Clarke;William H. Harrison;Harold Ossher;Peri L. Tarr	1999			reliability engineering;systems engineering;engineering;software development;application lifecycle management;engineering drawing;software development process;system lifecycle	SE	-55.18960563895489	27.88715069583073	93296
4079185e73b7a7975f0ccc9526a040ca7a04089c	a proposal for defining a set of basic items for project-specific traceability methodologies	software;power type pattern;iso standards;systems analysis software engineering;tmmis project specific traceability traceability information specific traceability requirements traceability structures software process iso iec 24744 tmm metamodel;data mining;software engineering;clabject;project specific traceability;tmmis;traceability structures;iec standards;quality requirement;metamodeling hierarchy traceability methodology traceability metamodel clabject power type pattern;systems analysis;specific traceability requirements;metamodeling hierarchy;metamodeling;traceability information;traceability methodology;structural design;traceability metamodel;metamodeling data mining software iso standards iec standards software engineering;tmm metamodel;software process;modeling tool;iso iec 24744	One widely accepted approach to implement traceability practices is the use of methodologies. But the information related to organization, stakeholders, product size, and quality requirements may change from one project to another. As a consequence, traceability information differs as well, which arises specific traceability requirements to each project.One common way to cope with this fact is the use of metamodels to underpin methodologies. However most of the traceability metamodeling approaches simply provide a predefined set of concepts, with no extension mechanism.Therefore, customizing a methodology for a specific project is often unsatisfactory. This paper justifies that this problem can be approached if traceability metamodels include a basic set of items, including concepts and traceability structures, designed to be extended according to project features. For this, the right modeling tools are required:that is, some metamodeling principles that support typing and extensibility, together with a general and extensible description of the software process. This second issue is obtained from ISO/IEC 24744 with some additional inputs.This paper explains how to use these tools in practice to define the so called TmM metamodel. Within this paper TmMis applied to a case study in which non-conventional work products have to be considered as part of the trace ability information.	agile software development;extensibility;iso/iec 42010;metamodeling;programming paradigm;requirement;requirements traceability;semiconductor consolidation;software development process;software engineering;usability	Angelina Espinoza;Juan Garbajosa	2008	2008 32nd Annual IEEE Software Engineering Workshop	10.1109/SEW.2008.23	metamodeling;reliability engineering;systems analysis;computer science;systems engineering;engineering;software engineering;reverse semantic traceability;traceability matrix;software development process;requirements traceability	SE	-56.834546961696766	23.733457837405265	93318
b154ffa352569b000300b63e897ee96d8f059039	semi-automated architectural abstraction specifications for supporting software evolution	uml;model transformation;software evolution;architectural component and connector views;architectural abstraction	In this paper we present an approach for supporting the semi-automated architectural abstraction of architectural models throughout the software lifecycle. It addresses the problem that the design and implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. Our approach provides concepts and tool support for the semiautomatic abstraction of architecture component and connector views from implemented systems and keeping the abstracted architecture models up-to-date during software evolution. In particular, we propose architecture abstraction concepts that are supported through a domain-specific language (DSL). Our main focus is on providing architectural abstraction specifications in the DSL that only need to be changed, if the architecture changes, but can tolerate nonarchitectural changes in the underlying source code. Once the software architect has defined an architectural abstraction in the DSL, we can automatically generate architectural component views from the source code using model-driven development (MDD) techniques and check whether architectural design constraints are fulfilled by these models. Our approach supports the automatic generation of traceability links between source code elements and architectural abstractions using MDD techniques to enable software architects to easily link between components and the source code elements that realize them. It enables software architects to compare different versions of the generated architectural component view with each other. We evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions of five open source systems and by analyzing the performance of our approach in these cases.	digital subscriber line;domain-specific language;evaporation;model-driven architecture;model-driven engineering;open-source software;semiconductor industry;software architect;software development process;software evolution;software system;traceability	Thomas Haitzer;Uwe Zdun	2014	Sci. Comput. Program.	10.1016/j.scico.2013.10.004	unified modeling language;real-time computing;architectural geometry;architectural pattern;computer science;software evolution;representational state transfer;programming language;presentation–abstraction–control	SE	-54.75744545995683	27.784894638755663	93367
3b90665040d4dfaa9c7162444dc05018e441376f	software modernization by recovering web services from legacy databases	mda;soa;software modernization;web services;adm;relational databases	Databases are considered to be a valuable asset for organizations because they contain all those organizations’ persistent pieces of data. Both databases and the information systems that use them undergo erosion as a consequence of uncontrolled maintenance over time. However, when information systems evolve to become modernized versions of them, existing databases must not be discarded because they contain much valuable business knowledge that is not present anywhere else. Some of the software industry’s current demands, such as time-to-market developments and the provision of software as services entail additional challenges in the reuse of legacy systems during software modernization. This paper addresses this problem and proposes a reengineering process that follows model-driven development principles to recover Web services from legacy databases. The Web services that are mined manage access to legacy databases without discarding them. Legacy databases can thus be used by modernized information systems in service-oriented environments. The adoption of this process is facilitated by the implementation of a support tool, which is used to conduct an industrial case study involving a real-life legacy database. The study demonstrates that the proposal reduces development efforts and improves the return of investment by extending the lifespan of legacy databases. Copyright © 2012 John Wiley & Sons, Ltd. Received 25 October 2011; Revised 12 January 2012; Accepted 14 February 2012	business process;business requirements;code refactoring;database model;floating-point unit;hoc (programming language);information system;john d. wiley;legacy system;metamodeling;mined;model-driven engineering;olami–feder–christensen model;qvt;real life;relational database;requirement;sql-92;service-oriented architecture;service-oriented device architecture;software industry;software modernization;uncontrolled format string;web application;web service;world wide web	Ricardo Pérez-Castillo;Ignacio García Rodríguez de Guzmán;Ismael Caballero;Mario Piattini	2013	Journal of Software: Evolution and Process	10.1002/smr.1554	web service;software modernization;relational database;computer science;systems engineering;engineering;software engineering;service-oriented architecture;data mining;database;management	DB	-59.25522485890537	22.605225434123213	93527
18fd73710b7cb0defc2d2f94c5bd5e3f5370b9d3	application modeling using reverse engineering techniques	content management;conceptual model;web applications;model driven development;webml;asp net;reverse engineering	In this work we present techniques and tools that enable effective reverse engineering procedures for web applications that were developed using the promising ASP.NET technology. We deal with model-driven development in its reverse aspect by implementing reverse engineering methods. Our implemented methods model web applications using a well-known, web oriented and robust language, namely WebML. This is, to the authors' best knowledge, a novel re-engineering transformation. In this paper we propose a method to reverse engineer web applications in order to extract their conceptual model using WebML notation. Moreover, we present an efficient tool we have developed in order to implement the proposed method, along with a study of the application of our tool to an exemplar, content-management web application. The overall results are quite encouraging and indicate that our approach is efficient.	asp.net;model-driven architecture;model-driven engineering;reverse engineering;web application;webml	T. Katsimpa;Yannis Panagis;Evangelos Sakkopoulos;Giannis Tzimas;Athanasios K. Tsakalidis	2006		10.1145/1141277.1141570	web application;web modeling;content management;computer science;knowledge management;conceptual model;data mining;database;programming language;world wide web;reverse engineering	SE	-51.85752239091114	23.221225094880634	93766
04a900c88982acbe2b6908bb110ab6fa316aa2bd	using the rita threats ontology to guide requirements elicitation: an empirical experiment in the banking sector	systems analysis bank data processing ontologies artificial intelligence program diagnostics;program diagnostics;empirical experiment rita threat ontology requirements elicitation banking sector systems development project non nominal system behaviour diagnosis;banking sector;probability density function;bank data processing;requirements elicitation;data mining;ontologies artificial intelligence;experience report;systems analysis;requirement engineering;system development;conferences;us department of transportation ontologies banking conferences knowledge management	Eliciting requirements is an important issue of systems development projects. One particular approach to requirements elicitation is to analyse non nominal cases of systems behaviour. Non nominal behaviours can be dealt with under different perspectives such as obstacles, conflicts, or risks. RITA is a requirements elicitation method that makes use of an ontology, which englobes these different perspectives using the concept of threat. The threats ontology can be used to diagnose non nominal system behaviours, and discover new requirements to overcome them. This paper reports an empirical experiment of the RITA threats ontology in the banking sector. The experiment was undertaken with the goal to demonstrate the effectiveness of using the RITA threats ontology to discover system requirements. The paper describes the experiment, reports a few results, and raises a few questions to address in the development of ontology-based requirements engineering methods.	nominal type system;requirement;requirements elicitation;requirements engineering;software development process;system requirements;threat (computer)	Camille Salinesi;Elena Ivankina;Willy Angole	2008	2008 First International Workshop on Managing Requirements Knowledge	10.1109/MARK.2008.11	systems engineering;engineering;knowledge management;requirements elicitation;data mining;process ontology	SE	-58.154394589888476	23.7478004067828	93916
3ee7c8ebdbeaa9557a1e770de8818e3fa10a0942	describing variability in service-oriented software product lines	level of service;service orientation;distributed computing;service oriented architectures;product line;software architecture;variability;service oriented architecture;software product line;modeling	Service-oriented architectures are a standard-based and technology-independent distributed computing paradigm for discovering, binding and assembling loosely-coupled software services. Software product lines on the other hand allow a generic architecture to be configured and deployed in different instances. Product lines facilitate systematic reuse through managing variability. In this paper, we combine ideas from the service domain and the product line domain and investigate what types of variability exist in service-oriented software architectures. Moreover, we suggest a way for representing variability in service-oriented architectures by formalizing the notion of variability. To allow different viewpoints on variability, we define stakeholder roles that occur in the context of service-oriented software architectures. By applying the proposed concepts, we hope to improve variability management at the software architecture level of service-oriented systems.	architectural pattern;distributed computing;heart rate variability;programming paradigm;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;software architecture;software product line;spatial variability	Matthias Galster	2010		10.1145/1842752.1842815	domain analysis;multilayered architecture;reference architecture;real-time computing;database-centric architecture;software sizing;computer science;systems engineering;engineering;component-based software engineering;software development;software design description;software engineering;domain engineering;service-oriented architecture;software construction;software as a service;software architecture description;resource-oriented architecture;software deployment	SE	-54.184270588043496	26.825712385260235	93973
57cc35a386df3392019b7e42b98c9b9bc20875c0	make software harder		Programming models should ideally let programmers express their ideas directly and explicitly. No such models are available for expert programmers, authors of machine-specific code optimizations, whose ideas often exploit architectural details invisible even at the assembly language level. In this paper we call for filling this void, and define performance transparency to evaluate the extent to which a programming model accommodates the expert programmer use case. We propose a specific approach to attaining performance transparency: make software harder by exposing the key components of the target architecture. The opportunities and challenges this approach brings are discussed.	assembly language;c++;critical section;digital subscriber line;domain-specific language;embedded system;iterative and incremental development;make;programmer;programming model	Benjamin A. Bjørnseth;Jan Christian Meyer;Lasse Natvig	2018		10.1145/3203217.3203271	real-time computing;architecture;theoretical computer science;computer science;assembly language;software;programmer;programming paradigm;exploit;transparency (graphic)	SE	-51.47992383205998	31.471632581914427	94107
5e1115765a35da399176df6bc9d001c5cba00331	using ontology reasoning for reverse engineering design patterns	program understanding;software ontology;conceptual knowledge;application framework;system modeling;software complexity;software systems;model transformation;model driven development;design knowledge;design pattern;semantic reasoning;design patterns;source code;knowledge representation;ontology design;reverse engineering;open source	Capturing design knowledge in large software systems reduces the complexity of understanding and reusing these systems. Model Driven Engineering (MDE) is seen by many as the new trend to cope with software complexity. MDE promotes the notion of modeling and model transformations in model-driven development. In this paper, we propose an approach that utilizes ontological modeling and reasoning for recovering design pattern information from source code. We thus provide a formal representation of the conceptual knowledge found in source code and match it to similar representation of design patterns. This proper matching is the basis for applying semantic reasoning to infer design pattern instances. We have tested our approach on multiple open source application frameworks. The results we obtained are promising and show an improvement in terms of recall and precision.	engineering design process;model-driven architecture;model-driven engineering;open-source software;precision and recall;programming complexity;reverse engineering;software design pattern;software system	Awny Alnusair;Tian Zhao	2009		10.1007/978-3-642-12261-3_32	knowledge representation and reasoning;software design pattern;systems modeling;computer science;systems engineering;engineering;knowledge management;software engineering;data mining;design pattern;programming complexity;reverse engineering;software system;source code	SE	-54.15742314447098	25.988872031359122	94181
98b434b466c354940ff8fd7454eac50a6cd99ec2	how responsibility modelling leads to security requirements	security requirements	When a technical system is placed in a social context organisational requirements arise in addition to the functional requirements on the system. Security is a good example of such an organisational requirement. A means of identifying these organisational requirements is needed and also a way of specifying them that is meaningful both to users and systems designers. This paper proposes that the concept of responsibility fills both these needs. Responsibilities embody requirements in that the responsibility holder needs to do things, needs to know things and needs to record things for subsequent audit. These needs form the basis of a ‘need-to-know’ security policy. Furthermore a model of responsibilities describes the context within the organisational structure in which the requirements, including those related to security, arise.	computer security;functional requirement	Ros Strens;John E. Dobson	1993		10.1145/283751.283828	requirements management;computer science;needs analysis;requirements elicitation;non-functional requirement	SE	-57.623144632062385	20.30786795037352	94520
19ceea57f2d6c27eb7e9169b1d7df40ac84af172	9th workshop on modelling in software engineering (mise 2017)		Summary form only given. MiSE 2017 Workshop Summary. The MISE workshop aims at promoting the use of models in the engineering of software systems. In particular, we are interested in the exchange of innovative technical ideas and experiences related to modeling. Engineers have used models to effectively manage complexity for centuries, and there is a growing body of work on the use of models to manage inherent problem and solution complexity in software development. The use of software models will become more prevalent as methodologies and tools that manipulate models at various levels of abstraction become available. Workshop activities will focus on analyzing successful applications of software-modeling techniques to gain insights into challenging modeling problems, including: (1) identifying, describing, and using appropriate abstractions, (2) supporting incremental, iterative development through the use of appropriate model composition, transformation and other model manipulation operators, and (3) automated analysis of possibly large, possibly incomplete models to determine the presence or absence of desired and undesired properties.	software engineering	Davide Di Ruscio;Marsha Chechik;Bernhard Rumpe	2017		10.1109/MiSE.2017.15	software system;operator (computer programming);software development;iterative and incremental development;software;systems engineering;abstraction;computer science	SE	-55.049261438295666	29.12000266508683	94575
863224c309871e8a90eca4a6417f65f19c98fc3f	on the benefits and difficulties of a maintainability via metrics methodology	software maintenance;metric analysis techniques;product evolution;software complexity metrics	A metrics methodology can dramatically reduce the problems associated with software maintenance. However, several issues must be addressed in order to develop and use these techniques successfully. This paper defines a metrics methodology which is designed to deliberately integrate maintainability into software as it is being developed. The benefits of using this approach are discussed. Then several issues which complicate the development and use of the methodology are examined. Previous maintenance studies which incorporate the methodology into two different commercial environments are used to demonstrate the difficulties in implementation and contrast the differences in approach.	object process methodology;software maintenance	John A. Lewis;Sallie M. Henry	1990	Journal of Software Maintenance	10.1002/smr.4360020203	reliability engineering;computer science;systems engineering;engineering;software engineering;management science;software maintenance;maintainability	SE	-61.536396856821504	27.69867843190027	94586
20a42b553327dad714901d3c199f2da95982e74b	model-driven rapid prototyping with umple	uml;model driven development;prototyping;rapid prototyping;umple;modeling	The emergence of model-driven software development brings new opportunities and challenges for rapid prototyping. On the one hand, the modeling process is inherently abstract, removing the prototyper from details, and letting him or her focus on exploring design alternatives for various aspects of the system. On the other hand, the most popular modeling languages and tools entirely omit the modeling and generating of user interfaces. As a result, the benefit of user interface prototypes as a medium for interaction with the user and customer is lost. This paper presents a model-oriented technology called Umple that can be used for prototyping and also supporting model driven engineering. Umple allows end users to quickly create class and state machine models and to incrementally embed implementation artifacts. At any point in the modeling process, users can quickly generate a fully functional prototype that exposes modeling implications on the user interface, and allows stakeholders to get a feel of how the full system will behave. Copyright © 2011 John Wiley & Sons, Ltd.	model-driven integration;rapid prototyping;umple	Andrew Forward;Omar Bahy Badreddin;Timothy Lethbridge;Julian Solano	2012	Softw., Pract. Exper.	10.1002/spe.1155	unified modeling language;simulation;systems modeling;human–computer interaction;computer science;systems engineering;engineering;operating system;prototype	HCI	-48.824286178601376	23.38552484217454	94656
74d5f08fdbc25f30bd0138f9f6c783cefd5d45d0	a quantitative evaluation model using the iso/iec 9126 quality model in the component based development process	artefacto;developpement logiciel;modelizacion;analytic hierarchy process;norme iso;processus hierarchie analytique;componente logicial;analisis cuantitativo;component based development;norma iso;composant logiciel;iso standard;artefact;modelisation;analyse quantitative;desarrollo logicial;software development;software component;software package;proceso jerarquia analitico;quantitative analysis;progiciel;practice guideline;quality model;modeling;paquete programa;qualite logiciel;software quality;quantitative evaluation;evaluation model;analytical hierarchical process	Recently, software quality evaluation based on ISO/IEC 9126 and ISO/IEC 14598 has been widely accepted in various areas. However, these standards for software quality do not provide practical guidelines to apply the quality model and the evaluation process of software products. Thus, we present a quantitative evaluation model using the ISO/IEC 9126 quality model in the Component Based Development (CBD) process. Particularly, our evaluation model adopts a quantitative quality model which uses the weights of quality characteristics obtained through carefully selected questionnaires for stakeholder and Analytic Hierarchical Process (AHP). Moreover, we have also examined the proposed evaluation model with applying the checklists for the artifacts of the CBD to a small-scale software project. As a result, we believe that the proposed model will be helpful for acquiring the high quality software.	iso/iec 9126	Kilsup Lee;Sung Jong Lee	2006		10.1007/11751632_99	iso/iec 9126;verification and validation;iso/iec 12207;computer science;component-based software engineering;programming language;software measurement;software quality control;quality of analytical results	SE	-61.42828800515021	28.671920376054935	94812
0c067eb9904cec13b150cd0f35880dd232246408	a process model of maintenance with reuse : an investigation and an implementation abstract	software configuration management	Sixty to eighty per cent of the software life-cycle cost is spent on the software maintenance phase because software maintenance is usually more difficult than original development and legacy systems are generally large and complex. Software reuse has recently been considered as a best solution to enhance the productivity of a software development team and to reduce maintenance costs. In addition, Software Configuration Management (SCM) is a central part of software maintenance as it is associated with changing existing software and is a discipline for controlling these changes. Thus, both software reuse and SCM have been proposed for making a significant improvement in productivity, quality and cost. However, so far these two technologies have been investigated separately. In order for software reuse and SCM to produce effects by synergy, both approaches require to be introduced into a maintenance environment together. Since software reuse and SCM, and software reuse and software maintenance have many similarities in their activities, these disciplines can be integrated within a software maintenance environment. This research has therefore developed an integrated process model for u0027Maintenance with Reuse (MwR)u0027, that supports SCM for a reuse library which is actively maintained for use in a software maintenance environment. This thesis addresses an integrated process model called the MwR model and its prototype tool TERRA (Tool for Evolution of a Reusable and Reconfigurable Assets Library) that consist of a configuration management (CM) process, reuse process, maintenance process and administration of a reuse library. The MwR model and TERRA provide reusers and maintainers with many activities of these four processes such as classifying, storing, retrieving, evaluating, and propagating reusable components, including controlling changes to both reusable components and existing systems. The process model of an integrated approach has been developed and validated using Process Weaver. The TERRA tool has been implemented on the WWW so that the prototype can provide portability, traceability, integration with existing tools, and a distributed maintenance environment. The TERRA prototype has been tested and evaluated through a scenario based case study. Several scenarios based on real data have been created and used for the case study so that an organisation can apply the model and tool to its maintenance environment without many problems. The software maintenance community is facing serious problems with legacy systems, such as a ever increasing frequency of changes and backlogs, lack of integrated tools and methods, and lack of software maintenance support environments. The control and management of changes to the software components in a reuse repository are crucial to successful software development and maintenance. If the component is being used in multiple systems effects of uncontrolled change are more critical. However, reuse libraries and servers currently available have not been successful as they do not support further development or maintenance of the reusable components. In addition, most of them are not sophisticated since they have not been linked to a development/maintenance environment. The integrated model of MwR can overcome many problems that exist in software maintenance and reuse through introduction of SCM functionalities into a maintenance environment. Thus, the integration of these common activities will greatly contribute to enhancing the productivity and quality of software, and will additionally lead to reducing the costs and backlogs of changes within a maintenance environment.	computer language;kilobyte;process modeling	Oh Cheon Kwon	1997			reliability engineering;reusability;long-term support;verification and validation;team software process;software engineering process group;software sizing;software configuration management;systems engineering;engineering;package development process;backporting;operations management;software framework;software development;domain engineering;software construction;software maintenance;software deployment;software metric;software system	Logic	-58.93115584079993	23.76925815919081	94916
960eb814041d05113f4731cfdd5e2404bb4d53c5	coordinating aspects and objects	formal specification;object oriented design;informing science;software architecture;aspect oriented programming;software component;architectural style	Abstract   Conventional software architectures emphasize individual software components and their interconnections. While offering many advantages this results in problems with concerns that cut across the component structure. The code addressing such concerns is scattered around the components and tangled with some other code inside the components. Approaches addressing such issues are emerging with new paradigms like  aspect-oriented programming.  However, aspects addressing cross-cutting concerns need to be incorporated in an object-oriented design without support from a higher-level design. We propose an approach where aspects and objects rely on coordination provided by a common high level specification. The common specification links the parts of specification that are refined independently and implemented using different techniques. We use the formal specification method DisCo, and demonstrate the approach by providing a specification of a simplified telecommunications system. In addition, we also sketch an Aspect J implementation built in the architectural style encouraged by the method.   Funding from Tampere Graduate School in Information Science and Engineering  (TISE) and the  Academy of Finland  (project 100005) is gratefully acknowledged.		Timo Aaltonen;Joni Helin;Mika Katara;Pertti Kellomäki;Tommi Mikkonen	2003	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)80372-X	software architecture;software requirements specification;simulation;aspect-oriented programming;computer science;component-based software engineering;object-oriented design;formal specification;programming language	ECom	-49.687862397902194	27.679444025694682	94962
22aefeded2e16ee5d886168076794a83b821c2a1	a model-driven approach for the automatic generation of system-level test cases		Systems at the basis of the modern society, as the as the homeland security, the environment protection, the public and private transportations, the healthcare or the energy supply depend on the correct functioning of one or more embedded systems.nIn several cases, such systems shall be considered critical, since the consequences of their failures may result in economic losses, damages to the environment or even injuries to human life.nPossible disastrous consequences of embedded critical systems, suggest that discover flaws during systems development and avoid their propagation to the system execution, is a crucial task.nIn fact, most of the failures found during the usage of embedded critical systems, is due to errors introduced during early stages of the system development. nThus, it is desiderable to start Verification and Validation (Vu0026V) activities during early stages of a system life cycle.nHowever such activities can account over the 50% of times and costs of a system life cycle and there is therefore the need to introduce techniques able to reduce the accounted resources without losses in term efficiency.nAmong the methodologies found in scientific and industrial literature there is a large interest in the automation.nIn particular, automatic verification can be performed during different stages of a system development life cycle and can assume different meanings.nIn this thesis, the focus is on the automation of the test cases generation phase performed at the System level starting from SUT and test specifications.nA recent research trend, related to this, is to support such process providing a flexible tool chain allowing for effective Model Driven Engineering (MDE) approaches.nThe adoption of a model-driven techniques requires the modelling of the SUT to drive the generation process, by using suitable domain-specific modelling languages and model transformations. nThus, a successful application of the MDE principles is related to the choice of the high-level language for SUT specification and the tools and techniques provided to support the Vu0026V processes.nAccording to this, the model-driven approach define in this thesis relies on three key factors: (1) the definition of new domain-specific modelling languages (DSMLs) for the SUT and the test specifications, (2) the adoption of model checking techniques to realize the generation of the test cases and (3) the implementation of a concrete framework providing a complete tool chain supporting the automation process.nThis work is partially involved in an ARTEMIS European project CRYSTAL (CRitical sYSTem engineering AcceLeration).nCRYSTAL is strongly industry-oriented and aims at achieving technical innovation by a user-driven approach based on the idea to apply engineering methods to industrially relevant Use Cases from the automotive, aerospace, rail and health-care sectors.nThe DSML that will be presented in this thesis, emerged as an attempt to address the modelling requirements and the design practices of the industrial partners of the project, within a rigorous and well-founded formal specification and verification approach. nIn fact, the main requirement that a modelling language suitable for the industry should have is to be small and as simple as possible.nThus, the modelling language should provide an adequate set of primitive constructs to allow for a natural modelling of the system of interest. nFurthermore, the larger the gap between the design specification and the actual implementation is, the less useful the results of the design analysis would be.nThe test case generation is supported by model checking techniques; the SUT and test models are in fact translated in specifications expressed by the language adopted by a model checker.nThe thesis discusses all the issues addressed in the mapping process and provides their implementations by means of model transformations.nA class of test specifications is addressed to exemplify the generation process over a common class of reachability requirements.nThe model-driven approach discussed in the thesis is applied in the contest of the railway control systems, and in particular on some of the key functionalities of the Radio Block Center, the main component of the ERTMS/ETCS standards for the interoperability of the railway control systems in the European Community.nnThe thesis is organized as follows. The first chapter introduces embedded critical systems and outlines the main research trends related to their process.nThe Chapter 2 outlines the state of the art in testing automation with a particular focus on model-driven approaches for automatic test generation. The same Chapter 2 provides also the necessary technical background supporting tonunderstand the development process of the supporting framework. The Chapter 3 describes the context of the CRYSTAL project and the proposed model-driven approach partially involved in its activities. The Chapter 4 describes the domains pecific modelling languages defined for the modelling of the SUT specifications and of the test generation outcomes. Moreover the guidelines defined for modelling test specifications are discussed. The Chapter 5 focuses on the mappingnprocess that enable the translation of the high-level language for the modelling of the SUT specification to the language adopted by the chosen model checker. The implementation of the overall framework is addressed in Chapter 6. Here model transformations realizing the defined mappings and the architecture of the Test Case Generator (TCG) framework are described and discussed. The Chapter 7 shows the results of the application of the approach in the context of the railway control systems and in particular to the Radio Block Centre system, a key component in the ERTMS/ETCS standard. Chapter 8 end the thesis, giving some conclusive remarks.		Ugo Gentile	2016			simulation;systems engineering;engineering	SE	-56.94284763634187	24.004511374522032	94993
8705c471c9e65d311d01addbc5022c7d40ea2954	the concerto methodology for model-based development of avionics software		The development of high-integrity real-time systems, includ- ing their certification, is a demanding endeavour in terms of time, skills and effort involved. This is particularly true in application domains such as the avionics, where composable design is to be had to allow subdividing monolithic systems into components of smaller complexity, to be outsourced to developers subcontracted down the supply chain. Moreover, the increasing demand for computational power and the conse- quent interest in multicore HW architectures complicates system deploy- ment. For these reasons, appropriate methodologies and tools need to be devised to help the industrial stakeholders master the overall sys- tem design complexity, while keeping manufacturing costs affordable. In this paper we present some elements of the CONCERTO platform, a toolset to support the end-to-end system development process from sys- tem modelling to analysis and validation, prior to code generation and deployment. The approach taken by CONCERTO is demonstrated for an illustrative avionics setup, however it is general enough to be applied to a number of industrial domains including the space, telecom and auto- motive. We finally reason about the benefits to an industrial user by comparing to similar initiatives in the research landscape.	avionics software	Andrea Baldovin;Alessandro Zovi;Geoffrey Nelissen;Stefano Puri	2015		10.1007/978-3-319-19584-1_9	simulation;computer science;systems engineering;engineering;software engineering	Robotics	-60.43064464735293	20.87365071646274	95034
cdb0b71e3962bd8d84663954e231ea43c33cdc5f	an approach to capture role-based access control models from spring web applications		To mitigate potential misinterpretation and security violations, software developers should use tools that reflect the state of web applications and visualise them as graphical models. Modelling helps to ensure that functionality and access control mechanisms are consistently interconnected. In this paper, we propose an approach to support Web application development using the Spring platform. Our proposal is supported by the Eclipse IDE plugin tool, which recognises Spring Security configuration captures, its notations, and visualises them in the role-based access control (RBAC) models. The RBAC models are represented using SecureUML modelling language. The plugin is validated through survey taken by software developers.	control system;diagram;eclipse;graphical model;graphical user interface;interoperability;modeling language;personalization;plug-in (computing);role-based access control;software developer;spring security;web application development	Andrey Sergeev;Raimundas Matulevicius	2017	2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)	10.1109/EDOC.2017.29	web application;systems engineering;web application development;data mining;access control;database;plug-in;interoperability;computer science;role-based access control;software;unified modeling language	SE	-48.613922929140415	24.798014325184017	95054
5cf164c95de8bc616ddcd2918eac31227400bed5	assessment of effort reduction due to model-to-model transformations in the web domain	web engineering domain;different phase;effort reduction;model-driven engineering;web domain;software development;different concern;software development life cycle;automated generation;web application;web engineer;web technology	Model-driven engineering (MDE) approaches provide the well-known advantage of software development at a higher level of abstraction. However, in the web engineering domain such approaches still encounter difficulties mainly due to applications that are continuously evolving and the heterogeneity of web technologies. Instead of fully automated generation, we look at MDE as assisting the web engineer in different phases of the software development life cycle. In particular, we use model-to-model transformations to support the generation of model sketches of the different concerns from a requirements specification. In this work, we present a metric to measure the effort reduction that results from applying this kind of model-driven approach. We use the metric to evaluate models of six web applications in the context of UML-based Web Engineering (UWE).	model-driven architecture;model-driven engineering;model-driven integration;requirement;software development process;software requirements specification;uml-based web engineering;unified modeling language;web application;whole earth 'lectronic link	Nora Koch;Alexander Knapp;Sergej Kozuruba	2012		10.1007/978-3-642-31753-8_16	web modeling;simulation;computer science;software engineering;social semantic web;web engineering;world wide web	SE	-53.524429022064	25.395459054778932	95216
ef6ff1367c454da857c4e104b6b7db5fe35a4dc2	self-adaptive quality requirement elicitation process for legacy systems: a case study in healthcare	g690 software engineering not elsewhere classified	Legacy systems need to be continuously maintained and re-engineered to improve their provision of services and improve quality attributes. An approach that promises to improve quality attributes and reduce human maintenance tasks is the self-adaptive approach, where software systems modify their own behaviour. However, there is little guidance in the literature on how to migrate to a self-adaptive system and evaluate which features should be designed/implemented with self-adaptive behaviour. In this paper, we describe a process called Self-Adaptive Quality Requirement Elicitation Process (SAQEP), a process that allows eliciting quality attribute requirements from legacy system stakeholders and specify which of these requirements can be taken account to be implemented in a self-adaptation system. The SAQEP has been applied to elicit the self-adaptive quality requirements of a legacy system in a Mexican hospital. We also discuss our experience applying this approach.		Nour Ali;Alfonso Martínez-Martínez;Lorena Ayuso-Pérez;Angelina Espinoza	2017		10.1145/3019612.3019751	reliability engineering;systems engineering;engineering;operations management;requirements elicitation;non-functional requirement	SE	-58.30296778957806	20.841943431597397	95236
f870b138d4029f576fb0c6731957a8de45409f05	stability assessment of evolving industrial object-oriented frameworks		Object-oriented framework technology has become a common reuse technology in software development. As with all software, frameworks evolve over time. Once the framework has been deployed, new versions of a framework potentially cause a high maintenance cost for the products built with the framework. This fact, in combination with the high costs of developing and evolving a framework, make it important for organizations to achieve a controlled and predictable evolution of the frameworku0027s functionality and costs. We present a metrics-based framework stability assessment method, which has been applied on two industrial frameworks from the telecommunication and graphical user interface domains. First, we discuss the framework concept and the frameworks studied. Then, the stability assessment method is presented including the metrics used. The results from applying the method, as well as an analysis of each of the frameworks, are described. We continue with a set of observations regarding the method, including framework differences that seem to be invariant with respect to the method. A set of framework stability indicators based on the results is then presented. Finally, we assess the method against issues related to the management and evolution of frameworks, framework deployment, change impact analysis and benchmarking. Copyright © 2000 John Wiley u0026 Sons, Ltd.		Michael Mattsson;Jan Bosch	2000	Journal of Software Maintenance	10.1002/(SICI)1096-908X(200003/04)12:2%3C79::AID-SMR204%3E3.0.CO;2-A	reliability engineering;software architecture;systems engineering;engineering;software framework;software engineering;data mining;information framework	SE	-57.838461252453186	28.149000776733725	95330
48a16a25ed726508767932c15f328b8f7a205c5a	capacity: an abstract model of control over personal data		"""While the control of individuals over their personal data is increasingly seen as an essential component of their privacy, the word """"control"""" is usually used in a very vague way, both by lawyers and by computer scientists. This lack of precision may lead to misunderstandings and makes it difficult to check compliance. To address this issue, we propose a formal framework based on capacities to specify the notion of control over personal data and to reason about control properties. We illustrate our framework with social network systems and show that it makes it possible to characterize the types of control over personal data that they provide to their users and to compare them in a rigorous way."""	computer scientist;personally identifiable information;privacy;social network;vagueness	Daniel Le Métayer;Pablo Rauzy	2018		10.1145/3176258.3176314	computer security;data mining;computer science;social network	DB	-57.467278930360486	21.73012761014267	95701
5abbead63bf620f7019fa23a0d3c8a120e4e8436	collaborative requirements elicitation in a european research project	elicitation;wiki;experience report;kj method	A relevant part of the research activities performed in European computer science institutions is funded through European Union (EU) projects. Eliciting and defining requirements for a software system in a distributed environment with heterogeneous stakeholders is generally challenging. In EU projects partners can have different objectives and views, needs are not sharply defined and communication is hampered both by differences in native spoken languages and by the physical distance of the stakeholders. This paper presents the definition and the results of applying an innovative requirements elicitation and refinement approach in the context of an EU financed project (Learn PAd). The approach combines the KJ-method and collaborative wiki-based requirement sessions to come to a set of consolidated requirements. The paper includes the lessons learnt from this experience, also it discusses both the advantages, and the drawbacks of the instantiated approach.	computer science;refinement (computing);requirement;requirements elicitation;software system;wiki	Guglielmo De Angelis;Alessio Ferrari;Stefania Gnesi;Andrea Polini	2016		10.1145/2851613.2851760	requirements management;computer science;knowledge management;software engineering;requirements elicitation;database;world wide web;affinity diagram	SE	-59.498332134041114	20.733715299604853	95766
415983eb19bc368e84e543a8bec3574cee9de48c	an aspect oriented approach for implementing situational driven adaptation of bpmn2.0 workflows		"""To address the issue of business process adaptation, we focus on handling adaptation needs as cross-cutting concerns because they rely or must affect many parts of a business process. Our research objective is to enhance aspect-oriented business process management with event-driven capabilities for discovering situations requiring adaptations. To this end, we develop an aspect- oriented extension to BPMN2.0 and we couple it with an event-driven approach for detecting and reasoning about situations that require adaptation of business processes. We use event processing in order to monitor the process execution environment and, when execution violates some quality """"threshold"""" or a problem arises, to detect it and trigger lookup for a suitable process adaptation, using a reasoning mechanism. We demonstrate that our approach is able to address simultaneously adaptation on process model and execution level."""	aspect-oriented programming	Ioannis Patiniotakis;Nikos Papageorgiou;Giannis Verginadis;Dimitris Apostolou;Gregoris Mentzas	2012		10.1007/978-3-642-36285-9_44	real-time computing;simulation;systems engineering;engineering;knowledge management;artifact-centric business process model;database	DB	-54.476515977736746	18.322441770496763	95886
360c2dc46bb1814d118a4dcf73bf6690b78f3201	a journey through the land of model-view-design patterns	software;user interfaces data models synchronization observers rendering computer graphics software collaboration;mvc;user interface;mvp;view;collaboration;controller;observers;software engineering;synchronization;mvvm;design pattern;datavetenskap datalogi;model;computer science;programvaruteknik;rendering computer graphics;user interfaces;data models;controller design pattern user interface mvc mvvm mvp model view	Every software program that interacts with a user requires a user interface. Model-View-Controller (MVC) is a common design pattern to integrate a user interface with the application domain logic. MVC separates the representation of the application domain (Model) from the display of the application's state (View) and user interaction control (Controller). However, studying the literature reveals that a variety of other related patterns exists, which we denote with Model-View- (MV) design patterns. This paper discusses existing MV patterns classified in three main families: Model-View-Controller (MVC), Model-View-View Model (MVVM), and Model-View-Presenter (MVP). We take a practitioners' point of view and emphasize the essentials of each family as well as the differences. The study shows that the selection of patterns should take into account the use cases and quality requirements at hand, and chosen technology. We illustrate the selection of a pattern with an example of our practice. The study results aim to bring more clarity in the variety of MV design patterns and help practitioners to make better grounded decisions when selecting patterns.	application domain;business logic;computer program;model–view–controller;model–view–presenter;model–view–viewmodel;point of view (computer hardware company);requirement;software design pattern;user interface;view model	Artem Syromiatnikov;Danny Weyns	2014	2014 IEEE/IFIP Conference on Software Architecture	10.1109/WICSA.2014.13	real-time computing;model–view–adapter;simulation;behavioral pattern;human–computer interaction;computer science;software engineering;user interface	SE	-54.49772362523814	30.934576955943292	95947
324fe8bafaaad84cec0005e4a223740c376bcc54	an object-oriented modelling approach to system software design	request flow diagram;object oriented design;entity refinement;object oriented modelling;software design;modeling;article;software reuse	Abstract   In this paper, a modelling method entitled MOOD (Modelling approach to Object-Oriented Design) is proposed for the design of object-oriented system software. The method employs  entity-refinement, functional modelling,  and  object modelling  techniques to model the world of solution-domain objects. The modelling result based on MOOD forms a set of graphic notations that describe the structure, functions, and client-server relationships among the entities. These graphic notations can be mapped directly into object-oriented programming constructs during the implementation phase. MOOD devotes special attention to the reuse of existing components or newly designed components for future reuse. Unlike other methods, which find objects from textual statements, the entity-refinement approach proposed here can identify all the entities and their operations within the solution domain. MOOD is compared with existing methods to show its feasibility and uniqueness.	software design	P. J. Lee;Deng-Jyi Chen;Chyan-Goei Chung	1994	Information & Software Technology	10.1016/0950-5849(94)90096-5	systems modeling;computer science;systems engineering;engineering;software design;theoretical computer science;object-oriented design;software engineering;data mining;database;programming language	SE	-50.1030747972306	26.95518510763153	95996
312dba9267cc38dc906bb10a756c6de9cdfebf95	toward a discipline of scenario-based architectural engineering	quality attributes;design criteria;software engineering;computer programs;requirements;computer architecture;large scale;software architecture;software architecture analysis;mathematical models;software development;cost effectiveness;mapping;software design;iteration method;scenarios;models;analytical model;maintainability;modification	Software architecture analysis is a cost-effective means of controlling risk and maintaining system quality throughout the processes of software design, development and maintenance. This paper presents a sequence of steps that maps architectural quality goals into scenarios that measure the goals, mechanisms that realize the scenarios and analytic models that measure the results. This mapping ensures that design decisions and their rationale are documented in such a fashion that they can be systematically explored, varied, and potentially traded off against each other. As systems evolve, the analytic models can be used to assess the impact of architectural changes, relative to the system’s changing quality goals. Although scenarios have been extensively used in software design to understand the ways in which a system meets its operational requirements, there has been little systematic use of scenarios to support analysis, particularly analysis of a software architecture’s quality attributes: modifiability, portability, extensibility, security, availability, and so forth. In this paper we present a unified approach to using scenarios to support both the design, analysis and maintenance of software architectures, and examples from large-scale software development projects where we have applied the approach. We also present a tool, called Brie, that aids in: scenario capture, mapping scenarios to software architectures, and the association of analytic models with particular portions of architectures. The approach that we have devised, and that Brie supports, is a foundation for a discipline of architectural engineering. Architectural engineering is an iterative method of design, analysis and maintenance where design decisions are motivated by scenarios, and are supported by documented analyses.	computer security;consistency model;design rationale;extensibility;iterative method;list of system quality attributes;map;requirement;software architecture;software design;software development;software maintenance;software portability	Rick Kazman;S. Jeromy Carrière;Steven G. Woods	2000	Ann. Software Eng.	10.1023/A:1018964405965	reliability engineering;software architecture;requirements analysis;cost-effectiveness analysis;architectural pattern;computer science;systems engineering;engineering;software design;software development;software engineering;software construction;mathematical model;iterative method;maintainability	SE	-60.335281461161294	27.558133527058693	96046
ef27524caa1cd9a228581e44fb07e3f3e8fdfdac	an object-oriented methodology for end-user logical database design: the structured entity model approach	structured entity model approach;database system;object oriented methods;logic design;database management systems;object oriented databases object oriented modeling relational databases database systems data models power system modeling educational institutions energy management technology management power system management;object oriented programming;object oriented methodology;technology management;end user logical database design;systems analysis;object oriented;power system management;database system development object oriented methodology end user logical database design structured entity model approach;systems analysis database management systems object oriented programming;database systems;relational databases;object oriented databases;database design;power system modeling;database system development;object oriented modeling;energy management;data models	The effective use of information to manage organizational resources is the key to an organization’s competitive power. Thus, a database plays a major role in the Information Age. However, a well designed database that contains relevant, nonredundant, and consistent data, is rarely achieved in practice. One major reason for this is the lack of effective support for logical database design. Since the late 1980s. various methodologies for database design have been introduced. based on the relational model, the functional model, the semantic database model, and the entity structure model. All of these have a common drawback: their successful design requires the experience, skills, and competence of a database analyst/designer. Unfortunately, database analyst/designers are a scarce resource in organizations. The Structured Entity Model (SEM) method, an objectoriented method developed by this research, facilitates the logical design phases of database system development. Because, unlike most methods, SEM does not require designers to understand normalization theory in order to design a logical database, an end user (or a novice designer) can successfully complete logical database design using the method.	database design;database model;function model;relational model	Kunihiko Higa;Olivia R. Liu Sheng	1989		10.1109/CMPSAC.1989.65109	database theory;entity–relationship model;computer science;systems engineering;technology management;database model;data mining;database;object-oriented programming;view;database schema;physical data model;logical data model;database testing;database design	DB	-52.17595022035061	21.2238249978904	96089
e99ad1342ec79bb833ae31be2f6dbef07c2c4d57	the software engineering of agent-based intelligent adaptive systems	new engineering;smart home network;future software system;traditional software engineering approach;agent-based intelligent adaptive system;agent concept;mainstream software engineer;software engineering practice;software engineering perspective;engineering challenge;agent development;protocols;multiagent systems;software engineering;concrete;software systems;adaptive system;multi agent systems;application software;intelligent systems;knowledge based systems;software agents;smart home;intelligent agent;artificial intelligence;adaptive systems;knowledge engineering	Future software systems will be intelligent and adaptive. They will have the ability to seamlessly integrate with smart applications that have not been explicitly designed to work together. Traditional software engineering approaches offer limited support for the development of intelligent systems. To handle the tremendous complexity and the new engineering challenges presented by intelligence, adaptiveness and seamless integration, developers need higher-level development constructs. Agent concepts are natural to describe intelligent adaptive systems. Agent-based technologies have been incorporating software engineering practices, and have matured to offer useful insights and concrete practices to mainstream software engineers.This tutorial presents the state of the art in agent development from a software engineering perspective, focusing on practices that are applicable today. We will walk the audience through analysis, design and verification of a portion of a real-world problem: a Smart Home Network. We show how agent concepts more naturally match the engineering challenges of such systems like trust between adaptive components. The audience will have hands-on experience with analyzing and designing parts of the Smart Home Network and learn how to incorporate agent technologies into their current projects.	adaptive system;agent-based model;software engineering	Leon Sterling;Thomas Juan	2005		10.1109/ICSE.2005.1553672	agent architecture;communications protocol;personal software process;application software;simulation;software engineering process group;concrete;computer science;systems engineering;engineering;knowledge management;social software engineering;software development;adaptive system;software agent;software construction;systems development life cycle;intelligent agent;software system;computer engineering	AI	-61.087009526054906	22.16907526301065	96128
71740c6918c6f4b387c9ace8eab519e002e012ed	experiences with using the systematic method for architecture recovery (symar)	software architecture;software architecture analysis;architecture recovery;architectural patterns;tactics	This paper provides an introduces the Systematic Method for software Architecture Recovery (SyMAR) and discusses some experiences in applying the method to an industrial case study.  SyMAR is used to recover a software architecture description which is consistent with the view that software architecture provides the software infrastructure addressing non-functional requirements within which application components addressing functional requirements can be specified, deployed and executed. The resultant architectural description includes the identification of architectural components addressing non-functional concerns, the abstractions into architectural patterns introducing infrastructural constraints, the tactics through which quality attributes are realized, and the description of concepts and constraints which the architecture introduces for application components.  When applying the method to a large industrial case study, it is found that the method does assist in exposing important architectural decisions, but that it is labour-intensive and that it is difficult to assess the completeness of the architectural description produced by using this method.	architectural pattern;component-based software engineering;functional requirement;non-functional requirement;resultant;software architecture description;software architecture recovery	Fritz Solms	2013		10.1145/2513456.2513505	multilayered architecture;enterprise architecture framework;functional software architecture;reference architecture;software architecture;space-based architecture;computer architecture;database-centric architecture;architectural geometry;architectural pattern;computer science;systems engineering;applications architecture;software design description;service-oriented modeling;software engineering;hardware architecture;solution architecture;software architecture description;view model;resource-oriented architecture;presentation–abstraction–control;data architecture;systems architecture	SE	-54.596340540177465	27.347636416726925	96132
f4eae9bd5c2ec2925355681878d303e5ec782809	panning requirement nuggets in stream of software maintenance tickets	mining software repositories;requirements;text clustering	There is an increasing trend to outsource maintenance of large applications and application portfolios of a business to third parties, specialising in application maintenance, who are incented to deliver the best possible maintenance at the lowest cost. To do so, they need to identify repeat problem areas, which cause more maintenance grief, and seek a unified remedy to avoid the costs spent on fixing these individually. These repeat areas, in a sense, represent major, evolving areas of need, or requirements, for the customer. The information about the repeating problem is typically embedded in the unstructured text of multiple tickets, waiting to be found and addressed. Currently, repeat problems are found by manual analysis; effective solutions depend on the collective experience of the team solving them. In this paper, we propose an approach to automatically analyze problem tickets to discover groups of problems being reported in them and provide meaningful, descriptive labels to help interpret these groups. Our approach incorporates a cleansing phase to handle the high level of noise observed in problem tickets and a method to incorporate multiple text clustering techniques and merge their results in a meaningful manner. We provide detailed experiments to quantitatively and qualitatively evaluate our approach	application domain;cluster analysis;coherence (physics);ecosystem;embedded system;emoticon;experiment;high-level programming language;information processing;java;local-density approximation;outsourcing;requirement;software maintenance	Senthil Mani;Karthik Sankaranarayanan;Vibha Sinha;Premkumar T. Devanbu	2014		10.1145/2635868.2635897	requirements analysis;document clustering;computer science;engineering;software engineering;data mining;database;world wide web	SE	-60.26710787754722	23.098428338803895	96136
23758c6b0a42a98a04d2e071698e457706996898	an argouml metamodel extension for the workflow systems	argouml;uml;nsuml;workflow;activity diagrams	The Unified Model Language (UML) has nine diagrams. One of them is the activity diagram. This allows the modeling of business processes. A business process is a set of logically related tasks executed to achieve a business result. Workflow systems are those systems based on software that allow automating total or partially a business process. Workflow is defined as a set of methods and technologies that offer facilities for the modeling and administration of diverse processes that happen inside a company.#R##N##R##N#The Workflow Management Coalition (WfMC) has established a standard that allows the interoperability among applications workflow. The proposed standard includes a model of the workflow processes, Workflow Metamodel, and a language of specification of processes in XML (XPDL).#R##N##R##N#ArgoUML is a CASE tool for the analysis and design of objects oriented software systems. ArgoUML uses NSUML metamodel implementing the UML metamodel defined by the Objet Management Group (OMG). The ArgoUML tool is open source and it allows building all the types of defined diagrams in UML. In this work, we propose an extension of the NSUML, the core of ArgoUML metamodel. In this way, the ArgoUML incorporates the possibility to model and to simulate workflow processes.	argouml;metamodeling	Narayan C. Debnath;Daniel Riesco;German Montejano	2006	J. Comput. Meth. in Science and Engineering		unified modeling language;workflow;xpdl;activity diagram;computer science;knowledge management;workflow management coalition;database;workflow management system;workflow engine;workflow technology	Logic	-53.6845591480403	20.091616269168803	96155
593fffec12195bfc647795dcb9c0c81340ddc434	the 4x6 tiered architecture method: an approach to the design of enterprise solutions		Enterprise architecture software design is all about composing applications to assemble value-added solutions rather than standalone products. Yet, each product and technology may have been designed and developed separately because of software engineering practices, management control over the deliverables, or technology acquisitions. To promote efficient assembly, solutions must be architected in a similar style, adhering to fundamental design principles while leveraging capabilities available in modern environments and relevant platforms. Furthermore, business agility and cost requirements dictate the identification of common capabilities and their development as reusable components across products and solutions. The 4x6 Tiered Architecture Method presented in this paper imposes a structured design, in terms of steps to follow, structure and documentation, for the logical view of an enterprise solution. Application of the 4x6 method to the analysis of an enterprise solution yields a six-tiered architecture structure and an abstract architecture specification. This specification expresses the various components, dependencies and design patterns using a graph-based data model (or “architecture catalog”) and blueprint, the latter expressed as both a diagram and XML document. The 4x6 Method has been applied in practice; this experience indicates that this method results in higher quality architecture and requires lower effort for both constructing and reviewing the architecture and its documentation.	enterprise architecture	Ethan Hadar;Irit Hadar;Gabriel M. Silberman;John J. Harrison	2012		10.1007/978-3-642-31069-0_16	enterprise architecture framework;functional software architecture;reference architecture;the open group architecture framework;real-time computing;systems engineering;architecture domain;applications architecture;service-oriented modeling;software engineering;enterprise architecture management;service;solution architecture;enterprise architecture;enterprise integration;view model;data architecture;business architecture	EDA	-54.66315338223205	22.1038939066639	96394
a12eb66c9b2f2a0597489fda5ce3c8109174abd7	software behavior description of real-time embedded systems in component based software development	automotive engineering;signal flows;software behavior description;mode dependent signal flows;embedded software real time systems embedded system programming automotive engineering software architecture vehicle dynamics software systems object oriented modeling engines;software productivity;bosch;real time embedded system;software complexity management;object oriented programming;automotive real time embedded applications;real time embedded systems;software behavior;embedded systems;software architecture;levels of abstraction;software reusability automotive engineering embedded systems object oriented programming software architecture software quality;software reusability;software development;software component;component model;source code;component based software development;software constructions;product quality;software product line;software reuse;real time embedded systems component based software development software behavior signal flows mode dependent signal flows;software quality;complex source code;complex source code software behavior description real time embedded systems component based software development automotive real time embedded applications bosch software product line software reuse software productivity software quality software complexity management software constructions	Component based software development (CBSD) has been established in the development of automotive real-time embedded applications at Bosch. CBSD together with software product line (SPL) practice has improved software reuse, productivity, quality and complexity management, by raising the level of abstraction for software constructions and by sharing services. Although CBSD has contributed to the aforementioned improvement in the software development practice, the existing Bosch component model often requires software developers to take a close look at the implementation including models (e.g., ASCET-MD ) and even complex source code to understand software behavior and dependencies when reusing and adapting software components. This hinders the realization of the full benefits of CBSD, as the available information on the component level does not sufficiently describe important aspects of software behavior. This paper presents the concepts and case studies of 'signal flows' and 'mode dependent signal flows', which provide crucial software behavior information for real time embedded systems at the component level.	code reuse;collegehumor;component-based software engineering;control system;embedded system;real-time clock;real-time transcription;software developer;software development;software product line	Ji Eun Kim;Rahul Kapoor;Martin Herrmann;Jochen Härdtlein;Franz Grzeschniok;Peter Lutz	2008	2008 11th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing (ISORC)	10.1109/ISORC.2008.69	embedded system;personal software process;verification and validation;real-time computing;software sizing;computer science;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;software engineering;software construction;software walkthrough;programming language;software analytics;resource-oriented architecture;software deployment;software development process;software system;avionics software	Embedded	-48.65813681505343	31.46210627340043	96467
26b5a2b2206b118b9d22a7f09d476c95605b31ef	a method for case tool evaluation	developpement logiciel;ciclo desarrollo;life cycle;ingenieria logiciel;software engineering;evaluation criteria sets;criterio;software process model;criterion;desarrollo logicial;software development;case tool;critere;computer aid;cycle developpement;genie logiciel;software development life cycle;asistencia ordenador;evaluation;evaluacion;case evaluation method;assistance ordinateur;case	Abstract   An epistomology for CASE that defines the current CASE technologies is presented. Its influence on traditional software process models is considered, and its support throughout a typical software development life cycle is identified. A four stage software process model is used as a basis for classifying CASE technology. A method for evaluating CASE products that follows a procedural framework is presented. Five evaluation criteria sets are used when applying the method to determine the CASE requirements for an organization.	computer-aided software engineering	Annette L. du Plessis	1993	Information & Management	10.1016/0378-7206(93)90051-T	use-case analysis;biological life cycle;simulation;systems engineering;engineering;operations management;software development;evaluation;systems development life cycle;management	Logic	-61.42596746317761	28.593585170162935	96550
5757dd47fd69fdc09538d7f114fdbca587484251	the design of a conceptual framework and technical infrastructure for model management language engineering	analytical models;generators;engineering management design engineering dsl model driven engineering buildings conference management computer science costs concrete domain specific languages;dsl;domain specific language conceptual framework design technical infrastructure model management language engineering model driven engineering;probability density function;code generation;object oriented programming;data mining;conceptual framework;domain specific languages model driven engineering model management;design and implementation;specification languages;specification languages object oriented programming;model driven engineering;transforms;domain specific language;model management;technical infrastructure;conceptual framework design;language engineering;context;model management language engineering;domain specific languages	Model management is the discipline of managing artefacts used in Model-Driven Engineering (MDE). A model management framework defines and implements the operations (such as transformation or code generation) required to manipulate MDE artefacts. Modern approaches to model management generally implement these operations via domain-specific languages (DSLs). This paper presents and compares the principles behind three approaches to implementing DSLs for model management and identifies some of the key differences between DSL engineering in general and for model management. It then shows how theory relates to practice by illustrating how DSL design and implementation approaches have been used in practice to build working languages from the Epsilon model management framework. A set of questions for guiding the development of new model management DSLs is summarised, and data on development costs for the different approaches is presented.	code generation (compiler);digital subscriber line;domain-specific language;experiment;graphical user interface;model-driven architecture;model-driven engineering;operational semantics;preprocessor;requirement;source lines of code;triune continuum paradigm	Richard F. Paige;Dimitrios S. Kolovos;Louis M. Rose;Nicholas Drivalos Matragkas;Fiona A. C. Polack	2009	2009 14th IEEE International Conference on Engineering of Complex Computer Systems	10.1109/ICECCS.2009.14	computer science;systems engineering;domain-specific language;software engineering;programming language	SE	-52.1106916933276	25.510626395141	96576
87321b6b84f47c5806b973d360ff12912411aa49	quality of service models for microservices and their integration into the switch ide		As demands on new software increase, new approaches are needed to help developers ensure Quality of Service (QoS) for their offered service. In this paper we present a QoS modeling approach that complements and extends the standard microservice and component-based software engineering tools by giving the software engineer information on what Non-Functional Requirements (NFRs) and quality constraints have critical influence on QoS. This concept extends the co-programing concept of programing the software and infrastructure with the ability to do this in a more informed manner. The result of this are Qualitative Metadata Markers (QMM) that provide guidelines for changing the infrastructure that can be used by humans or specialized decision-making algorithms.	algorithm;cloud computing;component-based software engineering;functional requirement;graphical user interface;integrated development environment;microservices;non-functional requirement;quality of service;software deployment;software development;software engineer;switch	Polona Stefanic;Matej Cigale;Andrew Jones;Vlado Stankovski	2017	2017 IEEE 2nd International Workshops on Foundations and Applications of Self* Systems (FAS*W)	10.1109/FAS-W.2017.150	software construction;software quality control;software quality;microservices;software;software verification and validation;systems engineering;software as a service;software quality analyst;computer science	SE	-56.03395482351564	26.576769828447283	96611
38824298b5b527066d1d3854ec2fbc698566ff2c	multiagent systems as software architecture: another perspective on software engineering with multiagent systems	architectural design;multiagent system;agent programming languages;agent oriented software engineering;software engineering;software architecture;agent chips;programvaruteknik;agent architecture;software technology;reference architecture	The trend in agent-oriented software engineering is to consider multiagent systems (MASs) as a radically new way of engineering software. This position isolates agent-oriented software engineering from mainstream software engineering and could be one important reason why MASs are not widely adopted in industry yet.In this paper, we present another perspective on software engineering with MASs. We put forward MASs as software architecture. We give an overview of a reference architecture for situated MAS. This reference architecture extracts and generalizes common functions and structures from various applications we have studied and built. The reference architecture provides a blueprint for architectural design of MAS applications that share the come base of the systems it is derived from. Considering MASs essentially as software architecture paves the way to integration with mainstream software engineering.	agent-based model;agent-oriented software engineering;blueprint;multi-agent system;reference architecture;situated;software architecture	Danny Weyns;Tom Holvoet;Kurt Schelfthout	2006		10.1145/1160633.1160875	multilayered architecture;functional software architecture;agent architecture;reference architecture;software architecture;architecture tradeoff analysis method;verification and validation;software engineering process group;architectural pattern;computer science;applications architecture;software design;social software engineering;component-based software engineering;software development;software design description;software construction;software architecture description;resource-oriented architecture;software requirements;systems architecture;software system	SE	-52.87208940403323	26.845572306922847	96639
5fb68a8ec8fc68296b040f2c7aee01a251a7cbec	exploring domain requirements and technology solutions: a goal modeling approach		As a requirement engineering technique i* has been used to model requirements for a single system. In this paper, we consider whether i* can be used to explore and map user needs and requirements for an entire application domain rather than for a single system. A domain-wide requirements model can be used to assess the suitability of various technology architectures and solutions for that domain. The domain of Ambient Assisted Living (AAL) is characterized by a large variety of stakeholders with different professional and socio-cultural backgrounds. The domain is highly heterogeneous and thus suitable for our purpose of demonstrating domain exploration. We discuss the challenges in mapping that domain, and our attempts to adapt i* concepts and usage for this purpose.	atm adaptation layer;application domain;goal modeling;requirement;requirements engineering	Davide Calvaresi;Arnon Sturm;Eric Kai-Hsiang Yu;Aldo Franco Dragoni	2014			application domain;requirements engineering;management science;goal modeling;systems engineering;computer science	SE	-60.40122790585292	19.07141723948916	96786
ed9bc6b879327a005e0ec81d733f1b42cb106f63	a new algorithm in assembly for component-based software using dependency chart	cdr;information systems;component based software engineering;cbsd;component based software;software components;component assembly;cbse;commercial off the shelf;erp;component dependency rating;enterprise resource planning;commercial off;component coupling;component based software development;dependency charts;cots;the shelf	Component-Based Software Development (CBSD) promises to reduce development cost and time by enabling rapid development of highly flexible and easily maintainable software modules. CBSD is based on the idea that software systems can be developed by selecting and integrating appropriate components which have already been developed and then assembling them to obtain the functionality desired in target application. Improper assembly of software components will lead to more number of defects, increase in complexity, development time, less reliability, etc. So, correct assembly of software components is an important issue. The aim of this paper is to develop a systematic procedure to assemble software components to build high quality software. The proposed algorithm is based on dependency chart in which the interaction between the components is considered as the major criteria. The proposed algorithm is applied in a component-based Enterprise Resource Planning software system to discuss the implications of the proposed algorithm.	algorithm;component-based software engineering	K. Vijayalakshmi;N. Ramaraj;R. Amuthakkannan;S. Senthamarai Kannan	2007	IJISCM	10.1504/IJISCM.2007.015599	verification and validation;software sizing;computer science;package development process;backporting;software design;software reliability testing;software framework;component-based software engineering;software development;software design description;software construction;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software metric;software system;avionics software	Robotics	-61.47371138464017	27.597788897297292	97092
cc4ef1ab39a8a0d14efad2d7c66a72980677f379	sharing software tools on the web: the idea web lab	developpement logiciel;outil logiciel;interfase usuario;software tool;red www;user interface;production process;deductive database;base dato deductiva;herramienta controlada por logicial;desarrollo logicial;software development;world wide web;interface utilisateur;computer application;reseau www;base donnee deductive;information system;software design;systeme information;sistema informacion	With the spreading of the World Wide WEB as a uniform and ubiquitous interface to computer applications and information, novel opportunities are offered for introducing significant changes in all organizations and their processes. This paper describes the IDEA Web Laboratory (Web Lab), a WEB-based software design environment available on Internet, which demonstrates a novel approach to the software production process on the WEB. The IDEA Methodology is a novel proposal for designing database applications taking advantage of the most advanced features of modern database technology, especially objects and rules. The IDEA development process proceeds through the steps of analysis, design, prototyping and implementation. All these activities are supported, although to a variable degree, by the CASE tools collected in the Web Lab. Users can register to the Lab and develop their applications in a protected workspace, from requirements to the generation of code for the Oracle relational DBMS. A number of other resources can be accessed from within the Web Lab for assisting the learning process of the methodology, including the documentation of selected applications developed by the industrial partners of the IDEA project, an on-line tutorial of the methodology, technical and user's manuals, and downloadable software tools.	world wide web	Stefano Ceri;Piero Fraternali;Stefano Paraboschi;Giuseppe Psaila	1997		10.1007/3-540-63792-3_3	web service;web application security;web development;web modeling;data web;web analytics;web mapping;web-based simulation;web design;human–computer interaction;web accessibility initiative;web standards;computer science;web navigation;social semantic web;web page;database;web intelligence;web engineering;web 2.0;world wide web;web server;mashup	HCI	-49.19587023627509	19.70678388872043	97163
2aa1653cd487e311d321b8c5b52d844bd7c3b8ea	a generic framework for distributed components-based software systems deployment - case study and tool description	component based software	The life cycle of distributed component-based software systems raises a new challenge due to architecture and environment complexity. Hence there is an increased need for new techniques and tools to manage these systems mainly their deployment. Following our previous publications (Dibo and Belkhatir, 2010b, Dibo and Belkhatir, 2010a, Dibo and Belkhatir, 2009). This paper deals with software deployment and focuses first on UDeploy (Unified Deployment architecture), a generic framework for distributed component based software system. Secondly, we present a deployment case study to illustrate our approach.	component-based software engineering;distributed element model;enterprise javabeans;experiment;model-driven architecture;positive feedback;prototype;software deployment;software system	Mariam Dibo;Noureddine Belkhatir	2010			reliability engineering;long-term support;verification and validation;software sizing;computer science;systems engineering;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;software construction;distributed computing;software architecture description;software analytics;resource-oriented architecture;software deployment;software quality;software system	SE	-58.29061398455767	25.485581286712367	97185
f780dae0334c535457cb535580c9ae0bd815778c	personal data management: an abstract personal data lifecycle model		It is well understood that processing personal data without effective data management models may lead to privacy violations. Such concerns have motivated the development of privacy-aware practices and systems, as well as legal frameworks and standards. However, there is a disconnect between policy-makers and software engineers with respect to the meaning of privacy. In addition, it is challenging: to establish that a system underlying business processes complies with its privacy requirements; to provide technical assurances; and to meet data subjects’ expectations. We propose an abstract personal data lifecycle (APDL) model to support the management and traceability of personal data. The APDL model represents data-processing activities in a way that is amenable to analysis. As well as facilitating the identification of potentially harmful data-processing activities, it has the potential to demonstrate compliance with legal frameworks and standards.	personal information management	Majed Alshammari;Andrew C. Simpson	2017		10.1007/978-3-319-74030-0_55	systems engineering;business process;traceability;information privacy;software;data management;knowledge management;computer science	DB	-57.43080910765516	20.74044381014543	97337
9b2450bff104f88069427662f08ff207fb589182	software architecture design by stepwise model transformations: a comparative case study		Software architecture design is a critical task as lots of requirements can be taken into account on which many decisions can be made. The maintenance and evolution of resulting models often become tricky, even impracticable when their rationale is lost. In a previous work, we introduced a set of languages used in a transformation-centric design method meant to tackle this scattering of requirements and to facilitate further model evolutions. But, we did not provided a formal validation of our proposal yet. The present work depicts a comparative case study we conducted on a group of students. The participants were asked to develop an online book store in two phases, the second one simulating an evolution of the system. We evaluated the functional completeness of the created software as well as the traceability of design decisions and rationale. The participants were also asked to criticize the design method and language they used in a textual report and through a questionnaire. Even if the size of the case study is rather limited, it clearly highlighs the advantages of our approach regarding, among others, its expressiveness and decisions traceability.	agile software development;correctness (computer science);design rationale;functional completeness;graphical user interface;in re boucher;library classification;online book;prototype;requirement;scalability;simulation;software architecture;software engineering;stepwise regression;systems modeling language;traceability	Fabian Gilson;Vincent Englebert	2015	2015 3rd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)		functional software architecture;reliability engineering;unified modeling language;reference architecture;software architecture;model-driven architecture;architecture tradeoff analysis method;verification and validation;database-centric architecture;design methods;idef6;computer science;systems engineering;software design;software development;software design description;service-oriented modeling;software engineering;software construction;hardware architecture;database;software architecture description;iterative method;programming language;resource-oriented architecture;computational model;computer-aided software engineering;design rationale;server;systems architecture;systems design	SE	-52.66840462495422	26.10403034207266	97512
737c33120376999bed02027eb6f373dcf0684810	a theoretical framework for the maintainability model of aspect oriented systems		Aspect Oriented Software Development is gaining wide attention because of its key feature modularization. Aspect Oriented paradigm supports the separation of concerns that are scattered over the system which helps in achieving modularity. Aspect Oriented Software Development encompasses software engineering abstractions and complexity at new and different dimensions. So Aspect Oriented Software Development requires models to assess its external quality attributes. The quality attribute maintainability is vital, because maintenance tasks employs major chunk of the total software development cost. The quality, maintainability is indicated using metrics. This paper proposes a framework to build maintainability model for aspect oriented systems using already defined software measures. © 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of organizing committee of The 2015 International Conference on Soft Computing and Software Engineering (SCSE 2015).	aspect-oriented programming;aspect-oriented software development;cost estimation in software engineering;li-chen wang;list of system quality attributes;organizing (structure);programming paradigm;separation of concerns;soft computing;software testability	Ananthi Sheshasaayee;Roby Jose	2015		10.1016/j.procs.2015.08.523	verification and validation;software development;software construction;maintainability	SE	-60.522422169868776	26.241873159668543	97582
e7cf6bcfd28f0680c123e4102b699a5af8c8aa15	optimal allocation of testing effort considering software architecture	software;system reliability;optimisation;architecture based optimization;software reliability architecture based optimization effort minimization optimization software architecture;software maintenance;resource allocation;resource manager;resource management;software systems;software reliability optimization computer architecture testing resource management software;testing;computer architecture;software architecture;program testing;effort reliability relationship optimal resource allocation software architecture software testing software reliability software system architecture based optimization software development software maintenance system reliability system architecture;effort minimization;expert opinion;optimization;resource availability;system architecture;software reliability;software reliability optimisation program testing resource allocation software architecture software maintenance	The growing dependence of society on software systems places a high premium on their reliable operation. Moreover, the stringent reliability expectations imposed on these systems must be achieved despite their increasing size and complexity, and decreasing resources available for their development and maintenance. To mitigate these dual challenges, a systematic approach to guide the allocation of resources to the components of a software system is necessary. This paper presents an optimization framework which considers the contribution of each component to system reliability to determine the amount of effort to be allocated to each component, towards the ultimate objective of achieving the specified system reliability target with minimal effort. We assume that the contribution of a component to system reliability is governed by two factors: the system architecture, and the effort-reliability relationship of the component. This characterization is referred to as “architecture-based optimization” because it considers the system architecture explicitly in the effort allocation process. It is demonstrated that the architecture-based optimization framework outperforms other effort allocation strategies, including equal component weighting, and expert opinion.	mathematical optimization;reliability engineering;software architecture;software system;systems architecture;third-party software component	Lance Fiondella;Swapna S. Gokhale	2012	IEEE Transactions on Reliability	10.1109/TR.2012.2192016	reliability engineering;software architecture;real-time computing;resource allocation;computer science;systems engineering;engineering;resource management;software testing;software maintenance;software quality;software system	SE	-60.814205128561845	27.897624131217242	97766
dc3fff2d002312de34b40a921cbe79245808c753	scientific software as workflows: from discovery to distribution	developpement logiciel;groupware;workflow management;propulsion instruments mathematical model nasa gas insulated transmission lines chemical technology space technology testing computer simulation distributed computing;programming environments and construction tools;scientific workflow;software construction;in silico research;scientific workflows;desarrollo logicial;software development;script based orchestration;workflow management software;workflow;model of computation;software construction workflow management programming environments and construction tools;natural sciences computing;scientific software;collecticiel;workflow management software natural sciences computing;in silico research scientific software scientific workflows script based orchestration;in silico	Scientific workflows-models of computation that capture the orchestration of scientific codes to conduct in silico research-are gaining recognition as an attractive alternative to script-based orchestration. Even so, researchers developing scientific workflow technologies still face fundamental challenges, including developing the underlying science of scientific workflows. You can classify scientific-workflow environments according to three major phases of in silico research: discovery, production, and distribution. On the basis of this classification, scientists can make more-informed decisions regarding the adoption of particular workflow environments.	code;model of computation	David Woollard;Nenad Medvidovic;Yolanda Gil;Chris Mattmann	2008	IEEE Software	10.1109/MS.2008.92	workflow;computer science;bioinformatics;systems engineering;data science;software engineering;management	HPC	-52.48863225008752	27.761520418156035	98072
021d768d0d7ef6db68315991b8ca343e545ae247	extending bpmn 2.0 for modelling the combination of activities that involve data constraints		The combination of activities to achieve optimal goals sometimes has a complex solution. Business Process Model and Notation (BPMN) 2.0 facilitates the modelling of business processes by providing new artifacts, such as various types of tasks, source of data and relations between tasks. Sometimes, although the order of the activities can be known, the concrete data values that the activities interchange to optimize their behaviour needs to be found, specially when input parameters of an activity affect to the input parameter of the others. Taking into account the lack of priority and clear sequential relationship between the activities of such combination, a deep analysis of possible models and data input values for the activities is necessary. For that reason, an extension of BPMN 2.0 with a new type of sub-process and its associated marker is proposed. The aim of this new sub-process is to define, in an easy way, a combination of several activities to find out, in an automated way, the concrete values of the data handling that optimize an overall objective.	business process model and notation	Luisa Parody;María Teresa Gómez López;Rafael M. Gasca	2012		10.1007/978-3-642-33155-8_6	real-time computing;data mining;database	HCI	-53.87798912769509	18.475498784866865	98097
a0972f73bf36144fc4321df3ab1e185f7f7b877a	a practical approach to quality assurance in critical systems	quality assurance;software quality assurance;software engineering;good practice;critical system;configuration management	  Software is safe when it works in the context of a greater system without contributing to hazard conditions. Several factors  should be considered to achieve that condition, specially the use of software engineering good practices for development and  maintenance. Among those we can emphasize the adoption of standards and processes of software quality assurance and configuration  management.    		Carlos A. T. Moura;Carlos Henrique Netto Lahoz;Martha A. D. Abdala	2003		10.1007/978-3-540-45214-0_30	program assurance;software security assurance;reliability engineering;quality assurance;qa/qc;quality control;verification and validation;software project management;systems engineering;configuration management;quality audit;software quality control;software quality;software quality analyst	Logic	-62.2720477194322	27.650194766649243	98098
0ff38a71bff8d091501e477a144efb8c286e6d60	implementing product line variabilities	implementation approaches;product line context;product line;software product line engineering;software product lines;end various implementation approach;product line variability;software product line;code level;traceability;implementing variabilities;individual product;instantiate generic product line;product line infrastructure;implementing product line variability;software systems;domain model	Software product lines have numerous members. Thus, a product line infrastructure must cover various systems. This is the significant difference to usual software systems and the reason for additional requirements on the various assets present during software product line engineering. It is imperative that they support the description of the product line as a whole, as well as its instantiation for the derivation of individual products. Literature has already addressed how to create and instantiate generic product line assets, such as domain models and architectures to generate instance specific ones [1, 2, 3], yet little attention has been given on how to actually deal with this genericity at the code level. This paper addresses the issue of handling product line variability at the code level. To this end various implementation approaches are examined with respect to their use in a product line context.	code refactoring;generic programming;heart rate variability;imperative programming;no silver bullet;object language;programmer;refinement (computing);requirement;scalability;software product line;software system;spatial variability;substitution (logic)	Cristina Gacek;Michalis Anastasopoules	2001		10.1145/375212.375269	domain analysis;reliability engineering;traceability;requirement prioritization;software quality management;systems engineering;engineering;product design specification;software engineering;domain engineering;domain model;new product development;feature model;software system;product engineering	SE	-57.00719436541829	27.69109508904231	98241
16538c1a8a278531caa37ae355c14ca0b9fc183c	on the applicability scope of model driven engineering	software development practices model driven engineering;software engineering;software development practices;software development;model driven engineering;model driven engineering proposals reverse engineering history systems engineering and theory programming application software automation dsl emp radiation effects	Model driven engineering (MDE) is frequently presented as an important change in software development practices. However behind this new trend, one may recognize a lot of different objectives and solutions. This paper studies the multiple facets of MDE and its evolution in the recent period. It concludes by emphasizing the broad potential application scope of MDE and suggests some new areas of usage and a classification scheme for related applications	comparison and contrast of classification schemes in linguistics and metadata;model-driven engineering;software development	Jean Bézivin;Mikaël Barbero;Frédéric Jouault	2007	Fourth International Workshop on Model-Based Methodologies for Pervasive and Embedded Software (MOMPES'07)	10.1109/MOMPES.2007.16	domain analysis;metamodeling;personal software process;model-driven architecture;verification and validation;software engineering process group;information engineering;extreme programming practices;search-based software engineering;systems engineering;engineering;social software engineering;component-based software engineering;software development;feature-oriented domain analysis;software engineering;software construction;computer-aided engineering;requirements engineering;software development process;software requirements;computer engineering	SE	-59.99244103510609	25.22261633865847	98293
3f8173611ee77817ed077eae49b7463fed83376d	systematic use case interviews for specification of automotive systems	automotive engineering;formal specification;systematic use case interview automotive software system requirements engineering formal specification formal verification;software systems;computer aided software engineering automotive engineering programming software systems application software software quality computer industry engineering management computer science design engineering;formal verification;complex system;automotive engineering formal specification formal verification;requirement engineering;user requirements;use case	Automotive software systems are becoming increasingly complex, driven both by advances in technology and by demands for more powerful applications. The design of such complex systems calls for advanced techniques in requirements engineering. This paper is concerned with developing and validating a new concept in order to elicit and specify user requirements of automotive software functions. Text-based use cases are considered to represent the requirements. The goal of the developed approach is to make the use case creation process more systematic and thereby more efficient (increased quality, reduced time and cost). The concept is based on a systematic expert interview process. After the interview process is completed, use cases are generated automatically. After describing the approach theoretically we show and compare results of an experiment where we applied different parts of the concept in practice.	automotive software;complex systems;requirement;requirements engineering;software system;text-based (computing);user requirements document	Shariful Islam;Hannes Omasreiter	2005	12th Asia-Pacific Software Engineering Conference (APSEC'05)	10.1109/APSEC.2005.102	use case;requirements analysis;software requirements specification;complex systems;verification and validation;computing;formal methods;software engineering process group;formal verification;software verification;computer science;systems engineering;software design;social software engineering;user requirements document;software development;requirement;software engineering;software construction;formal specification;functional specification;computer-aided engineering;requirements engineering;programming language;software requirements;software system;computer engineering	SE	-57.035856118924286	28.63747939955908	98945
05db146becdd2b4cb92e0e8d92d1356b34789e3a	comprehension and utilization of core assets models in software product line engineering		In software product line engineering, core assets are reusable artifacts that are intended to be used by a family of software products in order to improve development productivity and quality of particular software products. In order to support the construction and maintenance of core assets, various modeling methods have been proposed. However, the assessment of these methods is still in an incubation stage. In fact, only several frameworks for comparing and evaluating these methods have been suggested. These mainly refer to lists of criteria whose examination is sometimes subjective and opinion-dependent. In this paper, we call for empirical evaluation of the comprehension and utilization of core assets and report the initial results of a series of studies we performed in this context.	artifact (software development);domain engineering;domain model;domain-specific language;heart rate variability;list comprehension;resultant;self-replicating machine;software developer;software product line	Iris Reinhartz-Berger;Arnon Sturm;Arava Tsoury	2011			software;comprehension;reusability;reliability engineering;social software engineering;systems engineering;software product line;engineering	SE	-60.68919622599323	27.057060466745682	98978
528693e1d1c9d9c429005890d45b4b86ba9882bf	aligning requirements and acceptance tests via automatically generated guidance		Keeping requirements and acceptance test documents aligned and up-to-date plays an important role in the success of software projects. In practice, these documents are not always aligned with each other, nor with the actual system behavior. A previous study showed that even when requirements are updated, acceptance tests might stay outdated, which often leads to quality problems and unintended costs. In order to keep the requirements and test documents in a consistent state, we are developing an approach that automatically generates guidance on how to change impacted acceptance tests when changes in requirements occur. In this paper, we briefly present our approach and a prototype tool that implements it. A preliminary evaluation of our approach yielded encouraging results.	acceptance testing;correctness (computer science);notification system;prototype;requirement;test engineer;traceability	Sofija Hotomski;Eya Ben Charrada;Martin Glinz	2017	2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2017.37	software;acceptance testing;software bug;systems engineering;engineering	SE	-59.137238780230646	29.21272436696596	99129
c814afdcc223fb2e939a9c625552c9215930763b	machine learning 2.0 : engineering data driven ai products		"""ML 2.0: In this paper, we propose a paradigm shift from the current practice of creating machine learning models – which requires months-long discovery, exploration and “feasibility report” generation, followed by re-engineering for deployment – in favor of a rapid, 8-week process of development, understanding, validation and deployment that can executed by developers or subject matter experts (non-ML experts) using reusable APIs. This accomplishes what we call a “minimum viable data-driven model,” delivering a ready-to-use machine learning model for problems that haven’t been solved before using machine learning. We provide provisions for the refinement and adaptation of the “model,"""" with strict enforcement and adherence to both the scaffolding/abstractions and the process. We imagine that this will bring forth a second phase in machine learning, in which discovery is subsumed by more targeted goals of delivery and impact."""	machine learning;programming paradigm;refinement (computing);software deployment;subject matter expert turing test;subject-matter expert	James Max Kanter;Benjamin Schreck;Kalyan Veeramachaneni	2018	CoRR		artificial intelligence;subject-matter expert;computer science;software deployment;machine learning;enforcement;data-driven;paradigm shift;abstraction;scaffold	AI	-60.90335293634309	21.62734035531402	99189
02ee8c861e8ce4cc0b555c1e08aa7dcde0ce5fb6	bridging the gap between the quality requirements and implementation	quality attributes;quality driven software development model driven development domain specific modelling;formal specification;domain specific modelling approach;software systems;model driven development;quality driven software development;computational modeling;adaptation model;quality requirement;specification languages formal specification product development software quality;specification languages;customer group;software development;unified modeling language;product family;formal language software product software quality attribute functional requirement requirement specification domain specific modelling approach customer group;domain specific modelling;software quality attribute;functional requirement;quality of service;requirement specification;software product;software quality;domain specificity;formal language;software systems software quality laboratories software engineering programming computer architecture iso standards iec standards usability maintenance;product development	There is an increasing need for providing software products with different quality attributes. Especially in the context of product families each customer group may demand different quality attributes from a product while functional requirements remain the same. Although there are many languages for expressing quality requirements, still there is a gap between the requirements specification and their implementation. In this paper, the means for expressing quality attributes and affecting the qualities in software systems are scrutinized and illustrated in a laboratory case of stream-oriented computing system. We take a Domain-Specific Modelling approach in order to express qualities in software models explicitly. As a result, there is a comprehensive link between the quality attributes in a software system and the quality requirements. In addition, modifying a software system according to the quality requirements is facilitated.	bridging (networking);domain-specific modeling;entity;functional requirement;list of system quality attributes;non-functional requirement;software requirements specification;software system	Janne Merilinna;Tomi Räty	2009	2009 Fourth International Conference on Software Engineering Advances	10.1109/ICSEA.2009.9	reliability engineering;unified modeling language;requirements analysis;quality function deployment;software requirements specification;formal language;requirement prioritization;software quality management;quality of service;business requirements;computer science;systems engineering;software development;requirement;software engineering;system requirements specification;formal specification;non-functional testing;computational model;software quality control;functional requirement;non-functional requirement;software quality;new product development;software quality analyst;software system	SE	-56.36354870824513	27.451641076199202	99196
5995ecd0e7dc5e688318b8845640824c3d451510	don't worry about it: managing variability on-the-fly		Software-product-line engineering (SPLE) has become a widely adopted concept to implement reusable source code. However, instead of using SPLE from the beginning (the proactive approach), a software product line (SPL) is often only introduced after a set of similar systems is already developed (the extractive approach). This can lead to additional costs, new bugs introduced by refactoring, and an overall inconsistent SPL. In particular, inconsistencies between the variability implemented in the source code and the one represented in a variability model can become a major problem. To address this issue, we propose the concept of variability management derivation: We aim to (semi-)automatically model features and their dependencies while developers implement variable source code to facilitate the initial development, reusability, and later maintainability of SPLs, utilizing the reactive approach. In this paper, we demonstrate our concept by means of preprocessors. However, we claim that it can be adapted for other SPLE implementation techniques to facilitate SPL development.	code refactoring;feature model;heart rate variability;line level;preprocessor;software bug;software product line;spatial variability;static program analysis;traceability;usability testing	Sebastian Krieter;Jacob Krüger;Thomas Leich	2018		10.1145/3168365.3170426	systems engineering;on the fly;maintainability;worry;computer science;source code;software product line;code refactoring;reusability	SE	-55.23580119303899	28.77291528466212	99208
1af79b60385df494a68e3eafcc59d379f08baec8	model-based web components testing: a prioritization approach		Web applications testing and verification is becoming a highly challenging task. A number of model-based approaches has been proposed to deal with such a challenge. However, there is no criteria that could be used to aid practitioners in selecting appropriate approaches suitable for their particular effort. In this paper we present a set of attributes to serve as criteria for classifying and comparing these approaches and provide such aid to practitioners. The set of attributes is also meant to guide researchers interested in proposing new model-based Web application testing and verification approaches. The paper discusses a number of representative approaches against the criteria. Analysis of the discussion highlights some open issues for future research. In response to one of the issues, we present an approach for prioritizing components for testing to maximize confidence given a limited number of test cases to be executed. Some initial results are reported in the paper.	web components	Ahmed Al-Herz;Moataz Ahmed	2011		10.1007/978-3-642-22203-0_3	web application;data mining;test case;model-based testing;prioritization;web testing;computer science	SE	-59.87629198163723	26.190631804301546	99250
991a8483526e3262b0ead4bd65880a8a0f95506b	umm: a maturity model for ui-pattern languages	tui;user interface;maturity model;umm;pattern language	The set of tests developed to assess the internal validity of a user interface (UI) pattern languages [27, 28] form the basis of the proposed UI pattern language maturity model (UMM). UMM uses the UI pattern modelling technique developed for describing example UIs [26]. By building these models a UI pattern language's structure can be improved - a generative process. The UI pattern language maturity model is evaluated by using it to rate a selection of general UI pattern languages, plus two versions of a pattern language developed specifically for teaching purposes.	capability maturity model;internal validity;pattern language;user interface	Elisabeth G. Todd;Elizabeth A. Kemp;Chris Phillips	2011		10.1145/2000756.2000761	natural language processing;computer science;operating system;software engineering;pattern language;programming language;user interface;capability maturity model	SE	-48.520135464523754	24.44021082813974	99479
d55fe106d0b697bcc962ab1b2ea6fd083f299b5e	tool users requirements classification: how software visualization tools measure up	user requirements;software visualization	Various ways of categorizing software visualization tools have been developed in the past. This paper presents a hybrid tools requirements classification for tool developers that builds onto the previous taxonomies and research results. Ten software visualization tools that differ in their functionalities are then measured on the categorization in order to show the extent to which they fulfill the requirements that are desired by tool users. It is not an extensive in-depth coverage of the tools but a comparison of the tools with the perceived requirements in an effort to address the tool adoption issue.	categorization;requirement;software visualization	Mariam Sensalire;Patrick Ogao	2007		10.1145/1294685.1294705	software visualization;requirements analysis;software requirements specification;computer science;user requirements document;data mining;world wide web;software requirements	SE	-60.18072855037748	25.97818873406287	99716
b2135b05d04b4d5ac06cf535beb92f869e495dc5	product line use cases: scenario-based specification and testing of requirements	product line;use case	Use Cases can be employed in system requirements engineering to capture requirements from an external point of view. In product line modeling, commonalities and variabilities of a family of systems have to be described. To this purpose, we have defined extensions and modifications of the Use Cases notation, called Product Line Use Cases (PLUCs). In order to guarantee the conformance of the derived product with respect to the product line we add the capability of expressing constraints over the Product Use Cases that can be derived from a PLUC. Using this notation, it is possible to express in the requirements specification of the product line not only the possible variant characteristics that can differentiate products of the same line, but also which combinations of variant characteristics are “legal” and which are not. Testing is another activity in which PLUCs show their utility. Indeed, for a product belonging to a product line, testing is a crucial and expensive part of software development. Yet the derivation of test cases for product lines has so far received little attention. We outline a simple methodology for this purpose, which relies on the early requirements specification expressed as PLUCs.	conformance testing;requirement;requirements analysis;requirements engineering;software development;software requirements specification;system requirements;test case	Antonia Bertolino;Alessandro Fantechi;Stefania Gnesi;Giuseppe Lami	2006		10.1007/978-3-540-33253-4_11	use case;software requirements specification;computer science;engineering;product design specification;software engineering	SE	-55.795353072706746	24.87415708386033	99831
00ab71f2ceba7912666d05533bc5dd727564f303	a systematic review of software architecture evolution research	systematic review;evolvability analysis;software architecture;engineering and technology;teknik och teknologier;architecture analysis;architecture evolution;software evolvability	Context: Software evolvability describes a software system’s ability to easily accommodate future changes. It is a fundamental characteristic for making strategic decisions, and increasing economic value of software. For long-lived systems, there is a need to address evolvability explicitly during the entire software lifecycle in order to prolong the productive lifetime of software systems. For this reason, many research studies have been proposed in this area both by researchers and industry practitioners. These studies comprise a spectrum of particular techniques and practices, covering various activities in software lifecycle. However, no systematic review has been conducted previously to provide an extensive overview of software architecture evolvability research. Objective: In this work, we present such a systematic review of architecting for software evolvability. The objective of this review is to obtain an overview of the existing approaches in analyzing and improving software evolvability at architectural level, and investigate impacts on research and practice. Method: The identification of the primary studies in this review was based on a pre-defined search strategy and a multi-step selection process. Results: Based on research topics in these studies, we have identified five main categories of themes: (i) techniques supporting quality consideration during software architecture design, (ii) architectural quality evaluation, (iii) economic valuation, (iv) architectural knowledge management, and (v) modeling techniques. A comprehensive overview of these categories and related studies is presented. Conclusion: The findings of this review also reveal suggestions for further research and practice, such as (i) it is necessary to establish a theoretical foundation for software evolution research due to the fact that the expertise in this area is still built on the basis of case studies instead of generalized knowledge; (ii) it is necessary to combine appropriate techniques to address the multifaceted perspectives of software evolvability due to the fact that each technique has its specific focus and context for which it is appropriate in the entire software lifecycle. 2011 Elsevier B.V. All rights reserved.	emoticon;knowledge management;mechatronics;software architecture;software development process;software evolution;software system;systematic review;value (ethics)	Hongyu Pei Breivold;Ivica Crnkovic;Magnus Larsson	2012	Information & Software Technology	10.1016/j.infsof.2011.06.002	reliability engineering;reference architecture;software architecture;verification and validation;software engineering process group;systematic review;architectural pattern;systems engineering;engineering;social software engineering;software development;software design description;software engineering;software construction;software architecture description;management science;software technical review;software walkthrough;software analytics;resource-oriented architecture;software quality;software metric;software peer review	SE	-60.472749242961434	25.66439861045482	100003
1667c9329b5419d74ce970e7319cbf4224f6e505	extending the interaction flow modeling language (ifml) for model driven development of mobile applications front end		Front-end design of mobile applications is a complex and multidisciplinary task, where many perspectives intersect and the user experience must be perfectly tailored to the application objectives. However, development of mobile user interactions is still largely a manual task, which yields to high risks of errors, inconsistencies and inefficiencies. In this paper we propose a model-driven approach to mobile application development based on the IFML standard. We propose an extension of the Interaction Flow Modeling Language tailored to mobile applications and we describe our implementation experience that comprises the development of automatic code generators for cross-platform mobile applications based on HTML5, CSS and JavaScript optimized for the Apache Cordova framework. We show the approach at work on a popular mobile application, we report on the application of the approach on an industrial application development project and we provide a productivity comparison with traditional approaches.	cascading style sheets;design pattern;interaction flow modeling language;javascript;mobile app;model-driven architecture;model-driven engineering;sms language;user experience	Marco Brambilla;Andrea Mauri;Eric Umuhoza	2014		10.1007/978-3-319-10359-4_15	embedded system;simulation;human–computer interaction;computer science	SE	-49.2971207697454	23.186428065196047	100045
dbb6ebe2286ac978005eabd7eda5dced6718664f	reverse engineering of complex legacy telecommunication systems.		Kurzfassung: Reverse and reengineering of large and complex software systems is a difficult task. As a result, many methods and tools for reverse and reengineering have been developed so far. However, the work in this field has concentrated on sequential, and untimed systems, mainly for business applications. The majority of the approaches deals with decomposing monolithic systems, decoupling user interface/presentation from application logic and data handling/database management, or with identifying reusable components. In particular, numerous approaches have addressed the migration of legacy business applications to an object-based or object-oriented architecture. To a large extent, the corresponding methods are data-centered since they focus on structuring the data maintained by an application. Another stream of research has dealt with migration to code of programming languages such as C++ and Java which already provide language support for object-oriented programming. Reverse and Reengineering of process-oriented applications has been addressed less extensively. For example, a telecommunication system is composed of a set of distributed communicating processes which are instantiated dynamically for handling calls requested by the users of the system. Such a system is designed in terms of services provided by entities which communicate according to protocols. Understanding a telecommunication system requires the recovery of these concepts from the current source code and other sources of information. Furthermore, analyzing and visualizing the dynamic behavior is a key to system understanding. This dissertation describes the concepts and the implementation of integrated tools for reverse and reengineering of telecommunication systems which were developed in close cooperation with ERICSSON in the ECARES project (Ericsson Communication ARchitecture for Embedded Systems). The concepts are based on studies and evaluation of a real telecommunication system Ericsson’s Mobile-service Switching Center (MSC) for GSM networks called AXE10. These studies led to specific requirements. These requirements and an abstract system structure are described within a conceptual framework, which specifies the problem domain and identifies and interrelates the necessary concepts, thus building the terminological and conceptual foundation of this dissertation. To guarantee the suitability and applicability of the methods and tools developed in this thesis, tool support was developed step by step in response to the requirements and questions stated by telecommunication experts. This approach implied an iterative and incremental analysis and development process. Each pass of this process concentrates on a subset of the overall functionality and delivers appropriate analysis functionality and result documents, thus providing another portion of the final reverse and reengineering environment. The essential contributions (concepts, methods, and tools) to reverse engineering of telecommunication systems are as follows:	business logic;c++;code refactoring;coupling (computer programming);current source;database;embedded system;entity;iterative and incremental development;iterative method;java;object-based language;problem domain;process (computing);programming language;requirement;reverse engineering;software system;telephone exchange;user interface	André Marburger	2007	Softwaretechnik-Trends		systems engineering;software engineering	SE	-50.304256543492855	27.836716789892957	100063
f5332b92a9dcdc9743f97e32000ec3b65bc8475c	reqdl: a requirements description language to support requirements traces generation		It is important to manage traceability between requirements and other artifacts, including stakeholders, sources, and system development elements. Requirements are often expressed independently from those artifacts using textual and model approaches. This fact makes hard and tedious the inference of trace links between them. This paper proposes a new Domain Specific Language (DSL), called REQDL, for describing requirements, and at the same time, capturing bi-directional traceability data, which concerns especially SYSML modeling elements. Using REQDL expressions, we aim at assisting the traceability operation by applying a model-to-model transformation of both REQDL and SYSML constructs. The main result is the generation of requirements trace models, which incorporate intention and viewpoint concepts in conformance with a predefined trace metamodel. We use a car cooling system to illustrate the paper contributions.	algorithm;bi-directional text;complex system;computer cooling;conformance testing;digital footprint;digital subscriber line;domain-specific language;graph (discrete mathematics);metamodeling;model transformation;requirement;semiconductor industry;systems modeling language;trace (psycholinguistics);traceability	Saida Haidrar;Hatime Bencharqui;Adil Anwar;Jean-Michel Bruel;Ounsa Roudiès	2017	2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2017.72	traceability;metamodeling;traceability matrix;requirements traceability;unified modeling language;systems engineering;requirements analysis;systems modeling language;domain-specific language;computer science	SE	-53.12296838732483	20.500424288041515	100130
3cd016131204a7562446dbab224a275766a233d2	ranking software components for pragmatic reuse	program testing;program verification;recommender systems;search engines;software reusability;pragmatic software reusability;recommendation tools;software component ranking;software search engines;software verification;test-driven search engines	"""Pragmatic software reuse, in which existing software components are invasively adapted for use in new projects, involves three main activities -- selection, adaptation and integration. Most of the academic research into pragmatic research to date has focused on the second of these activities, adaptation, especially the definition of reuse plans and verification of invasive changes, even though the selection activity is arguably the most important and effort-intensive of the three activities. There is therefore a great deal of scope for improving the level of support provided by software search engines and recommendation tools to pragmatic reusers of software components. Test-driven search engines are particularly promising in this regard since they possess the inherent ability to """"evaluate"""" components from the perspective of users' reuse scenarios. In this paper we discuss some of the main issues involved in improving the selection support for pragmatic reuse provided by test-driven search engines, describe some new metrics that can help address these issues, and present the outline of an approach for ranking software components in search results."""	code reuse;component-based software engineering;web search engine	Marcus Kessel;Colin Atkinson	2015	2015 IEEE/ACM 6th International Workshop on Emerging Trends in Software Metrics		reusability;long-term support;verification and validation;software engineering process group;software sizing;software verification;search-based software engineering;computer science;systems engineering;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software construction;data mining;database;software walkthrough;software analytics;resource-oriented architecture;software deployment;software system;software peer review	SE	-59.90362237825795	26.335347954734658	100154
4cc2901875de89e5d75e8e288c7d33e5dca63312	model-driven quality assurance for end users	behavior flexibly;application domain;model-based technique;end user;policy problem;model-driven quality assurance;software quality assurance problem;regression problem;policy satisfaction;end users;modified version;iorules system;satisfiability;quality assurance;software quality	The ioRules system uses model-based techniques to solve two classes of software quality assurance problems: policy satisfaction, and regression. In a policy problem, the user wants to know whether a program being evaluated satisfies a policy that is critical in the application domain. In a regression problem, the user wants to know whether a modified version of a program implements the same functionality as some original baseline. The system also allows the end user to browse a model of their program, viewing its behavior flexibly from multiple perspectives.	application domain;baseline (configuration management);browsing;model-driven integration;software quality assurance	Steven Bucuvalas;Clayton Lewis	2007	IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2007)	10.1109/VLHCC.2007.29	program assurance;software security assurance;reliability engineering;quality assurance;qa/qc;verification and validation;quality policy;software quality management;software sizing;software project management;computer science;systems engineering;software development;software engineering;software construction;software testing;software deployment;software quality control;software quality;software metric;software quality analyst;software system;software peer review	SE	-58.993586076955836	28.29482421004931	100408
d5f8ffa96df91139480c69ddafc56c9b0ae34e13	designing software product lines with the unified modeling language (uml)	design model;feature modeling;dynamic model;product line;state dependence;component based software architecture;requirement analysis;object oriented;unified modeling language;interaction model;functional requirement;composite structure;software product line;use case;communication pattern	 This tutorial addresses how to develop object-oriented requirements, analysis, and design models of software product lines using the Unified Modeling Language (UML) 2.0 notation. During requirements modeling, the tutorial covers how to develop kernel, optional, and alternative use cases for defining the software functional requirements of the system. The tutorial also describes the feature model for capturing product line requirements and how it relates to the use case model. During analysis, the tutorial covers how to develop static models for defining kernel, optional, and variant classes and their relationships. It also describes how to create dynamic models in which interaction models describe the dynamic interaction between the objects that participate in each kernel, optional, and alternative use case, and in which statecharts define the state-dependent aspects of the product line. The tutorial then covers how to develop component-based software architecture for the product line using the new UML 2.0 notation for structured classes and composite structure diagrams. That notation allows components, ports, and connectors, as well as provided and required interfaces, to be depicted. The tutorial gives an overview of the architectural structure patterns and architectural communication patterns that can be used in designing component-based product lines. The tutorial is illustrated by several examples and based on the book by Hassan Gomaa titled Designing Software Product Lines with UML to be published by Addison-Wesley in July 2004.	software product line;unified modeling language	Hassan Gomaa	2004		10.1007/978-3-540-28630-1_29	use case;reliability engineering;unified modeling language;requirements analysis;model-driven architecture;communication diagram;systems modeling language;uml tool;computer science;systems engineering;engineering;unified process;software design;component-based software engineering;software development;software engineering;applications of uml;class diagram;domain model;modeling language;programming language;object-oriented programming;object-modeling technique;node;functional requirement;use case points;feature model;component diagram;object constraint language	SE	-49.953966339696066	27.0419362374462	100577
357cd361cb2d53666bed19d62981593775f2e12d	templatable metamodels for semantic variation points	state machine;formal verification;eclipse modeling framework;language engineering	In the field of Domain Languages Engineering, Semantic Variation Points are an important issue. This crucial information is often related to the dynamic semantics of systems. Identifying and understanding it is a requisite for all model-based activities (design, simulation, test, formal verification, etc.). Most of the time, semantic variation points are only informally identified in a documentation associated with a metamodel: they are not part of the metamodel itself, and there is currently no mechanism to capture them explicitly. We propose a template-based notation enabling semantic variation points to be clearly and explicitly identified within the metamodel, using template parameter definitions. Semantic variation points can then be intuitively fixed by parameter binding at both model and metamodel levels. We illustrate our proposal with a templated version of the UML 2 state machine metamodel. Finally, we describe a prototype implementation of our mechanisms in the context of the Eclipse Modeling Framework. 1	bertrand (programming language);design pattern;documentation;eclipse modeling framework;formal verification;generic programming;meta-object facility;metamodeling;model transformation;plug-in (computing);programming language;prototype;request for proposal;simulation;unified modeling language	Arnaud Cuccuru;Chokri Mraidha;François Terrier;Sébastien Gérard	2007		10.1007/978-3-540-72901-3_6	model-driven architecture;computer science;systems engineering;theoretical computer science;programming language	SE	-52.885095491126144	25.476364010419537	100663
270ff1e97e50bb15f669b233e06516bbb63c6d63	a quality assurance methodology for chebi ontology focusing on uncommonly modeled concepts				Hao Liu;Ling Chen;Ling Zheng;Yehoshua Perl;James Geller	2018			quality assurance;systems engineering;ontology;computer science	Vision	-62.84579788922774	21.511856981797063	100693
54f99b5bfa50894a6c10cd550e1ffb86846ba509	on the effect of mixing text and diagrams on business process model use		A picture is worth a thousand words, but a few words can greatly enhance a picture. It is common to find textual and diagrammatic components complement each other in enterprise models in general, and business process models in particular. Previous work has considered the question of the relative understandability of diagrammatic versus textual representations of process models for different types of users. However, the effect of combining textual and diagrammatic components on the actual use of process models has to the best of our knowledge not been considered. This paper addresses the question of how the mix of diagrammatic and textual components in business process models affects their sustained use. This question is approached via a case study in a telecommunications company where models with different mixtures of text and diagrams have been collected over time. The study shows that models, in which the ordering relations between tasks are captured in diagrammatic form, while the details of each task are captured in textual form, are more likely to be used on a sustained basis.	a picture is worth a thousand words;business process;diagram;graphical user interface;knowledge base;process architecture;process modeling;structured text;usability	Toomas Saarsen;Marlon Dumas	2017			function model;business process modeling;artifact-centric business process model;process management;business process model and notation;computer science;process modeling	Web+IR	-54.49808198973944	21.0127470437216	100769
53cb0ac5f858b2f9744bd641da0aa5571054fd9b	towards a technique for extracting microservices from monolithic enterprise systems		The idea behind microservices architecture is to develop a single large, complex, application as a suite of small, cohesive, independent services. On the other way, monolithic systems get larger over the time, deviating from the intended architecture, and becoming tough, risky, and expensive to evolve. This paper describes a technique to identify and define microservices on a monolithic enterprise system. As the major contribution, our evaluation demonstrate that our approach could identify good candidates to become microservices on a 750 KLOC banking system, which reduced the size of the original system and took the benefits of microservices architecture, such as services being developed and deployed independently, and technology independence.	enterprise system;microservices	Alessandra Levcovitz;Ricardo Mingarini Terra;Marco Tulio Valente	2016	CoRR		simulation;systems engineering;engineering	OS	-60.40252947313035	21.942400778112685	100885
9255b19d7680fc4ea6de9969eeb42f9adb401d4d	improving the developer experience with a low-code process modelling language		"""Context: The OutSystems Platform is a development environment composed of several DSLs, used to specify, quickly build and validate web and mobile applications. The DSLs allow users to model different perspectives such as interfaces and data models, define custom business logic and construct process models. Problem: The DSL for process modelling (Business Process Technology (BPT)), has a low adoption rate and is perceived as having usability problems hampering its adoption. This is problematic given the language maintenance costs. Method: We used a combination of interviews, a critical review of BPT using the """"Physics of Notation"""" and empirical evaluations of BPT using the System Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a new version of BPT, taking these inputs and Outsystems' engineers culture into account. Results: Evaluations conducted with 25 professional software engineers showed an increase of the semantic transparency on the new version, from 31% to 69%, an increase in the correctness of responses, from 51% to 89%, an increase in the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from 36.50 to 20.78. These differences were statistically significant. Conclusions: These results suggest the new version of BPT significantly improved the developer experience of the previous version. The end users background with OutSystems had a relevant impact on the final concrete syntax choices and achieved usability indicators."""	business logic;business process;correctness (computer science);data model;digital subscriber line;mobile app;modeling language;parse tree;process modeling;software engineer;system usability scale	Henrique Henriques;Hugo Lourenço;Vasco Amaral;Miguel Goulão	2018		10.1145/3239372.3239387	business logic;business process;software engineering;systems engineering;end user;system usability scale;correctness;usability;computer science;data modeling;process modeling	HCI	-55.069115749463386	23.70604484522082	100906
b0ac7f16199a201b004b2208fe0bacbac11173ef	snets: the core formalism for an object-oriented case tool.	object oriented;case tool			Jean Bézivin;J. Lanneluc;Richard Lemesle	1994			theoretical computer science;computer-aided software engineering;object-oriented programming;formalism (philosophy);computer science	Logic	-49.944628786015805	27.266771894448656	101280
4eeedc46258caf8c68a3f255b8a4dfef55fd5ff9	introduction to the track on variability modeling for scalable software evolution	theoretical computer science;computer science all	Information and communication technology today is increasingly integrated into the environment we live in, distributed on cars, appliances and smart infrastructures. The software running on these devices is increasingly individualized, adapted to the preferences and needs of the specific customer and must be able to evolve after deployment by means of software patches. Upgrades are becoming individualized; software patches used to upgrade the software are selected and adapted depending on the configuration and external constraints of the host device. The objective of the European project HyVar is to develop techniques and tools for fast and customizable software design, for the management of highly distributed applications, for continuous software evolution of remote devices, and scalable infrastructure to accommodate a large number of devices. The track Variability Modeling for Scalable Software Evolution aims to foster cooperation opportunities and create synergies between related research directions to address challenges stemming from software variability, evolution, and cloud technology for highly distributed applications in heterogeneous environments. This paper introduces the track and its individual contributions. 1 Context and Background Software is an essential part of information and communication technology so that it is becoming increasingly integrated into our everyday environment, distributed on cars, appliances and a wide variety of devices. The struggle between the ideal fit of software resulting from individual development and the low cost of off-the-shelf software creates tension for developers and customers of software products alike. With the advent and rise of the Internet of Things (IoT) [2] and its devices (e.g., smartphones, tablets), the need for software that can be used on many similar yet slightly different devices and that can be individualized in This paper contains an introduction to the ISoLA’16 track organized in the context of the EU H2020 project 644298 HyVar: Scalable Hybrid Variability for Distributed Evolving Software Systems (http://www.hyvar-project.eu). c © Springer International Publishing AG 2016 T. Margaria and B. Steffen (Eds.): ISoLA 2016, Part II, LNCS 9953, pp. 423–432, 2016. DOI: 10.1007/978-3-319-47169-3 35 424 F. Damiani et al. functionality has further increased this tension towards favoring customizable software but still having to keep development costs at a reasonably low level. Furthermore, highly configurable software systems are a major asset in a wide range of areas from business software (e.g., SAP ERP with its configurable modules for enterprise resource planning) to the transportation domain (e.g., cars with different on board electronics and specific integrated navigation systems desired by customers). Due to the sheer number of variants resulting from the configuration options, it is infeasible to develop, maintain or test all individual variations of the respective software families independent of one another and in isolation. A Software Product Line (SPL) [18,21,22] is an approach to software reuse in the large where a set of related software systems is perceived as a software family consisting of a common core and variable parts often referred to as features [14]. A product or variant of the SPL is created by combining the common core with the functionality associated with a set of selected features. However, not all combinations of features form valid products, e.g., due to technical incompatibilities of the features’ realization or due to business constraints that do not allow combining certain features. To define the principally valid constellations of features, a variability model, such as a feature model [14] is employed, which represents all valid configurations (sets of selected features) in a compact representation on a conceptual level. To create executable software system from this selection of conceptual features, a variability realization mechanism collects the realizations associated with each feature (e.g., source code or design models) and assembles them with the common core. Delta modeling [4,20] is a transformational variability realization mechanism that realizes variation of a software artifact by adding, modifying or removing parts of a software artifact in accordance with a feature’s functionality, e.g., a feature might add certain methods to a class written in Java to realize additional functionality. Modern software systems outgrow the scope of a traditional SPLs. When a software family consists of multiple SPLs, the software family may be managed by a Multi-software Product Line (MSPL) [10,12]. In a MSPL, several SPLs are composed in order to build a larger system of configurable components. These variable components need to be configured together to build a common system configuration but still depend on a common notation for a variability model. A Software Ecosystem (SECO) [5,26] is similar to an SPL or even a MSPL in the sense that it also manages a set of closely related software systems. However, a SECO is different from an SPL, in the sense that it does not have a variability model as central configuration knowledge and that multiple independent developers create and maintain the variable parts of the SECO. SPLs, MSPLs and SECOs are subject to change over the course of time when their products have to adapt to altered or new requirements. This procedure is called software evolution [16] and poses a major challenge for SPLs, MSPLs and SECOs as not only single software systems but entire families of software systems have to be evolved [23,24]. Software evolution is especially difficult for SECOs 1 http://go.sap.com/product/enterprise-management/erp.html. Variability Modeling for Scalable Software Evolution 425 where independent developers release new features or versions thereof in unsynchronized intervals and, possibly, without explicitly notifying other developers or users so that awareness of the current state of evolution of a SECO becomes a further challenge. As both configuration and evolution are sources of variability within the set of related software systems, it is also customary to denote them as variability in space and variability in time, respectively [18]. Due to the level of maturity of cloud technology and the wide variety of offered services, SPLs, MSPLs and SECOs become heavily based on cloud technology. Features may be realized as webservices [1] accessible by customers over the web and end-users may contribute features to shared platforms for various domains similar to apps for smartphones. In the automotive domain, utilizing the web for over-the-air update of entire products as well as individual features receives increasing attention. This combination of challenges stemming from configuration, evolution and cloud technology is at the center of the research conducted within the European Union H2020 project HyVar. To foster opportunities for cooperation on the topics of HyVar and to capitalize on synergies of related research directions, we organized the special track Variability Modeling for Scalable Software Evolution at the International Symposium on Leveraging Applications of Formal Methods, Verification and Validation (ISoLA). This paper introduces the track and provides and overview of its sessions and their respective contributions. 2 The European Union H2020 Project HyVar The EU H2020 project HyVar plans to integrate and enhance state-of-the-art techniques for the management of complex software systems from software product lines with cutting edge technology for over-the-air software upgrades and scalable cloud solutions from European industry to support highly individualized and reconfigurable distributed applications. HyVar’s objectives are: 1. To develop a Domain Specific Variability Language (DSVL) and a tool chain to support software variability of highly distributed applications in heterogeneous environments, which allows developers to encompass unanticipated evolution as a standard feature of software systems in production. 2. To develop a cloud infrastructure that exploits the software variability supported by the DSVL and a tool chain to track the exact software configurations deployed on remote devices to enable the collection of data from the devices to monitor their behavior and perform statistical analyses. 3. To develop a technology for supporting over-the-air updates of distributed applications in heterogeneous environments and enabling continuous software evolution after deployment on complex remote devices that incorporate a system of systems. 4. To test HyVar’s approach as described in the above objectives in an industryled demonstrator in the automotive domain to assess in quantifiable ways the benefits of the approach. 2 http://www.wired.com/2014/02/teslas-air-fix-best-example-yet-internet-things/. 426 F. Damiani et al. HyVar aims to create a development framework for continuous and highly individualized evolution of distributed software applications, which can be integrated into existing software development processes. The framework, which is currently under development, will consist of advanced methods and tools that support – modeling of both variability in space and time in all phases of the software lifecycle, – scalable, elastic solutions to accommodate numerous individualized application instances, and – secure and efficient over-the-air software update on remote devices. This framework will be realized by combining variability modeling from SPL engineering with formal methods and software upgrades for distributed applications. HyVar goes beyond the state-of-the-art in devising and assessing the feasibility of the notion of hybrid variability, i.e., the automatic generation and deployment of software updates by relying on both 1. the variability model that describes the possible software variants that may be deployed to a remote device; and 2. the sensor data c		Ferruccio Damiani;Christoph Seidl;Ingrid Chieh Yu	2016		10.1007/978-3-319-47169-3_35	computational science;computing;computer science;theoretical computer science	SE	-59.9600766099923	22.130184595549743	101323
62e45ec025ac4390bebfcfad1450ffb5c7899166	an extensible meta-model for program analysis	analytical models;front end;program diagnostics;programming environments;programming language;software maintenance;technology;computer and information science;language independent metamodel extensible metamodel program analysis software maintenance tools program refactoring;maintenance engineering;teknikvetenskap;proof of concept;extensible metamodel;computer architecture;natural sciences;computational modeling;program refactoring;computer and information sciences computer science;data structures;language independent metamodel;metamodels;unified modeling language;information analysis independent component analysis data mining computer languages computer architecture software systems software maintenance costs software tools computer interfaces;datavetenskap datalogi;software tools;program analysis;computer science;data och informationsvetenskap;software tools program diagnostics software maintenance;meta model;software maintenance tools;data models	Software maintenance tools for program-analysis and refactoring rely on a meta-model capturing the relevant properties of programs. However, what is considered relevant may change when the tools are extended with new analyses and refactorings, and new programming languages. This paper proposes a language independent meta-model and an architecture to construct instances thereof which is extensible for new analyses, refactorings, and new front-ends of programming languages. Due to the loose coupling between analysis-, refactoring-, and front-end-components, new components can be added independently and reuse existing ones. Two maintenance tools implementing the meta-model and the architecture, VizzAnalyzer and X-DEVELOP, serve as a proof of concept	code refactoring;loose coupling;metamodeling;program analysis;programming language;software maintenance	Dennis Strein;Rüdiger Lincke;Jonas Lundberg;Welf Löwe	2006	2006 22nd IEEE International Conference on Software Maintenance	10.1109/TSE.2007.70710	program analysis;maintenance engineering;unified modeling language;data structure;computer science;systems engineering;software engineering;programming language;software maintenance;proof of concept;technology	SE	-51.33307385448203	29.431239564913085	101519
d765a89649ea5b5221b99370e3a1b7b8ca205090	a model-based ontology of the software interoperability problem: preliminary results	software engineering;software development;software systems;meta model	Interoperability usually refers to software system communication. Although there is no widely accepted definition, and therefore no common understanding of the context, there are multiple solutions (protocols, architectures, components) that promise to solve integration issues. The INTEROP network of excellence aims at proposing a large view of interoperability issues, and hence requires a unified definition. As an INTEROP participant, we suggest in this paper, as a first attempt, an ontology of interoperability. We first present the general software engineering concepts our work is based on. We then propose the decisional meta-model and the technical aspects meta-model, as prerequisite to the introduction of the actual interoperability model. Finally, we discuss the pros and cons, as well as different ways the model can be used.	communications protocol;interoperability;metamodeling;ontology (information science);software engineering;software system	Vincent Rosener;Thibaud Latour;Eric Dubois	2004			software system;resource-oriented architecture;data mining;systems engineering;software engineering;component-based software engineering;software requirements;computer science;software development;software construction;interoperability;social software engineering	AI	-54.75681350233005	22.726546203485903	101843
f5fea227e3595f6357e33aaf8d7cf213b7996e28	towards systematic mutations for and with atl model transformations	atlas transformation language;analytical models;atl;software;higher order transformations systematic mutations atl model transformation software engineering task automation transformation engines software artifact quality model transformation languages transformation rules quality practical testing approach atlas transformation language comprehensive language centric synthesis approach generic mutation operators;comprehensive language centric synthesis approach;higherorder transformations mutation model transformations atl;testing;generic mutation operators;higherorder transformations;model transformations;computational modeling matched filters automation software testing analytical models computational efficiency;computational modeling;practical testing approach;program testing;transformation engines;transformation rules quality;atl model transformation;model transformation languages;matched filters;software engineering task automation;computational efficiency;software artifact quality;software quality program testing programming languages;systematic mutations;higher order transformations;software quality;mutation;programming languages;automation	Model transformation is a key technique to automate software engineering tasks, such as generating implementations of software systems from higher-level models. To enable this automation, transformation engines are used to synthesize various types of software artifacts from models, where the rules according to which these artifacts are generated are implemented by means of dedicated model transformation languages. Hence, the quality of the generated software artifacts depends on the quality of the transformation rules applied to generate them. Thus, there is the need for approaches to certify their behavior for a selected set of test models. As mutation analysis has proven useful as a practical testing approach, we propose a set of mutation operators for the ATLAS Transformation Language (ATL) derived by a comprehensive language-centric synthesis approach. We describe the rationale behind each of the mutation operators and propose an automated process to generate mutants for ATL transformations based on a combination of generic mutation operators and higher-order transformations. Finally, we describe a cost-effective solution for executing the obtained mutants.	atlas transformation language;design rationale;imperative programming;metamodeling;model transformation language;mutation testing;object constraint language;prototype;redundancy (engineering);software engineering;software system	Javier Troya;Alexander Bergmayr;Loli Burgueño;Manuel Wimmer	2015	2015 IEEE Eighth International Conference on Software Testing, Verification and Validation Workshops (ICSTW)	10.1109/ICSTW.2015.7107455	mutation;computer science;systems engineering;theoretical computer science;automation;software engineering;software testing;matched filter;programming language;computational model;algorithm;software quality	SE	-56.71335684572049	29.11638406452485	101923
8e66938d2fed031c72e9f5b50f9716fe636958f2	decompositional verification of component-based systems-a hybrid approach	decompositional verification;traditional software testing;decompositional verification approach;component-based system;formal analysis;component-based systems-a hybrid approach;formal verification;object oriented programming;model checking;component based software development;quality assurance;safety critical systems;software testing	Component-based software development has been increasingly adopted as a standard engineering practice to build large systems with prefabricated components. Although this development method enjoys the great benefits of reusing valuable software assets, reducing development costs, improving productivity, etc., it also poses serious challenges to the quality assurance problem of component-based systems, since prefabricated components can not be simply trusted and they could be a new source of system failures. Solving this problem is of vital importance to safety-critical and mission-critical systems. This paper introduces a decompositional verification approach for component-based systems through both formal analysis (model-checking) and traditional software testing	component-based software engineering;mission critical;model checking;software development;software testing	Gaoyan Xie	2004	Proceedings. 19th International Conference on Automated Software Engineering, 2004.	10.1109/ASE.2004.10007	model checking;reliability engineering;quality assurance;formal verification;computer science;systems engineering;engineering;component-based software engineering;software engineering;software testing;life-critical system;programming language;object-oriented programming	SE	-58.07867647329579	27.771641399089837	101946
aed572722d975ad5c6a1ae3dd2fd26dfa30ce329	assessing the complexity of software architecture	coupling;architecture complexity;building block;architecture assessment;satisfiability;software architecture;problem complexity;full function points;software architecture design;functional size measurement	A central activity of software architecture design is decomposing the system into subsystems (i.e. components) that work together to satisfy the required functionality. The purpose of this activity is to reduce problem complexity into smaller manageable parts. Complexity can never be totally eliminated; however the designer/architect can reduce it.The decomposition process is an art form; the architect must decide whether to assign a specific functionality to a given component or to defer some or all of the functionality to other components, with a goal of minimizing complexity. Deferring work decreases the responsibilities of a component (intracomponent complexity) but also may increase the dependencies between components (inter-component complexity).In this paper, our goal is to formulate an approach that identifies and measures those complexity factors that reflect interand intra-complexity for the purpose of introducing a new metric for assessing the overall complexity of software architecture. To accomplish this, we have chosen to use Full Function Points (FFP) methodology, which is the latest form of Functional Size Measure (FSM), as a building block for measuring complexity.However, since FFP was designed to measure the size of architecture; it fails to address some important issues with regard to complexity. Therefore, we identify those areas of weakness for FFP and exploit them to measure overall system complexity. The main feature of the approach is the integration of Full Function Points measure with a specification of the architecture to evaluate its overall complexity.	complexity;function point;radiation pattern;software architecture	Mohsen N. AlSharif;Walter P. Bond;Turky N. Al-Otaiby	2004		10.1145/986537.986562	reference architecture;real-time computing;database-centric architecture;computer science;systems engineering;theoretical computer science;worst-case complexity;complexity management;descriptive complexity theory	SE	-55.0494636929535	27.143248896246412	101953
bbb43b562c333f78d63d3f8ea036ad8f35e9ef39	a change impact model for changeability assessment in object-oriented software systems	software metrics;electrical capacitance tomography;software testing;software metrics software maintenance management of change object oriented programming c language software quality;object oriented modeling software systems costs software maintenance iso standards electrical capacitance tomography software engineering application software software testing computer industry;changeability assessment;maintenance;application software;software maintenance;iso standards;large industrial software;software systems;object oriented software;maintenance cost;change impact;object oriented programming;computer industry;software engineering;design metrics change impact model changeability assessment object oriented software software maintenance software changes high level design software quality classes c language large industrial software experiment telecommunications system;c language;object oriented;classes;software metric;management of change;design;software changes;experiment;change impact model;telecommunications system;high level design;design metrics;object oriented modeling;software quality	Growing maintenance costs have become a major concern for developers and users of software systems. Changeability is an important aspect of maintainability, especially in environments where software changes are frequently required. In this work, the assumption that high-level design has an influence on maintainability is carried over to changeability and investigated for that quality characteristics. The approach taken to assess the changeability of an object-oriented (OO) system is to compute the impact of changes made to classes of the system. A change impact model is defined at the conceptual level and mapped on the C++ language. In order to assess the practicality of the model on large industrial software systems, an experiment involving the impact of one change is carried out on a telecommunications system. The results suggest that the software can easily absorb that kind of change and that well chosen conventional OO design metrics can be used as indicators of changeability.	c++;high- and low-level;level design;software system	M. Ajmal Chaumun;Hind Kabaili;Rudolf K. Keller;François Lustman	1999	Sci. Comput. Program.	10.1016/S0167-6423(02)00058-8	computer science;engineering;software engineering;change management;object-oriented programming;software metric	SE	-60.747075699061405	30.147509845990403	102118
06ef26b3f8c31aec982ff5fc3da5da156b56e0fd	extending a uml and ocl tool for meta-modeling: applications towards model quality assessment		For developing software in a model-driven style, metaand multi-level modeling is currently gaining more and more attention. In this contribution, we propose an approach to extend a two-level modeling tool to three-level modeling by adding a meta-model at the topmost level. Standard OCL does not support reflective constraints, i.e., constraints concerning properties of the model like the depth of inheritance. By adding an auto-generated instance of the topmost level to the middle level, we can offer an option for writing reflective constraints and queries. We apply the extension to demonstrate the usefulness of meta-modeling for model querying and model quality assessment. A first proposal towards level-crossing constraints is also put forward.	class diagram;constraint (mathematics);metamodeling;model-driven integration;multi-level governance;object constraint language;object diagram;reflection (computer programming);schedule (computer science);unified modeling language;universal instantiation;user interface	Khanh-Hoang Doan;Martin Gogolla	2018			systems engineering;unified modeling language;computer science	SE	-48.27557731279815	26.55026156263934	102163
b5970c5866530a38f6aea8638372588c66d8d40d	an approach to define and apply collaboration process patterns for software development		Complex system developments are more and more collaborative. Collaboration strategies largely depend on the development context at modelling, instantiation or enactment time. To put collaboration in action, we propose collaboration process patterns to define, reuse and enact collaborative software development processes. In this paper we describe the definition and application of collaboration patterns. Our patterns, inspired from workflow patterns of Van der Aalst, are described in CMSPEM, a Process Modelling Language developed in our team in 2014. In this paper, we briefly describe the CMSPEM metamodel and focus our presentation on two collaboration patterns: Duplicate in Sequence with Multiple Actors, Duplicate in Parallel with Multiple Actors and Merge. The approach is illustrated by a case study concerning the collaborative and representative process “Review a deliverable”.	process patterns;software design pattern;software development	Thuan Tan Vo;Bernard Coulette;Hanh Nhi Tran;Rédouane Lbath	2015		10.1007/978-3-319-27869-8_14	systems engineering;knowledge management;software development;data mining;empirical process;goal-driven software development process;software development process	SE	-54.434370339498145	23.269729107914145	102214
69254421a3b3ff5371d6b64df38c4b774224019e	integrating platform selection rules in the model driven architecture approach	application development;domain model;trading system;platform specific model;platform independent model;domain analysis;model driven architecture	A key issue in the MDA approach is the transformation of platform independent models to platform specific models. Before transforming to a platform specific model, however, it is necessary to select the appropriate platform. Various platforms exist with different properties and the selection of the appropriate platform for the given application requirements is not trivial. An inappropriate selection of a platform, though, may easily lead to unnecessary loss of resources and lower the efficiency of the application development. Unfortunately, the selection of platforms in MDA is currently implicit and lacks systematic support. We propose to integrate so-called platform selection rules in the MDA approach for systematic selection of platforms. The platform selection rules are based on platform domain models that are derived through domain analysis techniques. We show that the selection of platforms is important throughout the whole MDA process and discuss the integration of the platform selection rules in the MDA approach. The platform selection rules have been implemented in the prototypical tool MDA Selector that provides automated support for the selection of a platform. The presented ideas are illustrated for a stock trading system.	algorithmic trading;domain analysis;electronic trading;feature selection;model-driven architecture;platform-specific model;requirement;selection rule	Bedir Tekinerdogan;Sevcan Bilir;Cem Abatlevi	2004		10.1007/11538097_11	simulation;bioinformatics;engineering	Web+IR	-55.44073510188659	25.56286567967752	102244
7c398407db70aa06be2a3de7e008c7215e4d6665	identifying traceability between feature model and software architecture in software product line using formal concept analysis	regression analysis predictive models data analysis data mining linear regression computer science information technology sensor phenomena and characterization space technology economic forecasting;regression model;one dimensional stream data;data mining;regression analysis data analysis data mining;data analysis;time series data;regression analysis;prediction model;data handling;time series data one dimensional stream data data mining data analysis regression model	Feature models have been used to support requirements analysis and domain engineering in Software Product Line. By identifying the mapping between feature model and architecture model by capturing the relationships among elements in the models, we can establish the traceability between the two models. The identified traceability can be used to verify consistency between feature model and architecture model. On small scale models, the relationships among elements can be easily identified by manually analyzing the descriptions of models. But when the complexity of a model is high, a more formal approach will be useful to help identifying the traceability. In this paper, we develop an approach to identify traceability between feature model and component and connector view of software architecture using formal concept analysis (FCA) technique. This technique constructs a concept lattice structure. We propose several analysis criteria for concept lattice structure to identify traceability between the two models.	crystal structure;domain engineering;feature model;formal concept analysis;requirement;requirements analysis;software architecture;software product line;traceability	Tonny Kurniadi Satyananda;Danhyung Lee;Sungwon Kang;Sajid Ibrahim Hashmi	2007	2007 International Conference on Computational Science and its Applications (ICCSA 2007)	10.1109/ICCSA.2007.59	data stream clustering;computer science;data science;machine learning;data mining;database;data stream mining;data analysis;regression analysis;statistics	SE	-52.25869791986604	22.591883071503517	102262
f62061ea5e21e0421990c70d9f3808a1071f7c28	information systems work quality	computacion informatica;software libraries;grupo de excelencia;quality of information;system evolution;ciencias basicas y experimentales;interest groups;information system;quality model;software quality;work practice	It is suggested that the multi-perspective nature of information systems (IS) quality, representing the manifold interest groups involved, is the very reason why attempts to develop any general purpose quality model for information systems tend to be fruitless. This paper develops the concept is IS work quality by utilising the existing SOLE (Software Library Evolution) quality model by Eriksson and Tom (1991), and builds upon the elements which particularly address the quality of IS work practices by discussing the management issues that affect those elements and are necessary to assure and maintain the quality of systems evolution and use. The model of information systems work quality proposed in this article provides a framework that allows the consideration of different work contexts and the specific needs of an organisation when evaluating the quality of the information system at hand and its benefits to the organisation. The IS work quality construct broadens the software quality concepts as it caters for the diverse needs of organisations and work contexts.	computer program;evolution;information management;information system;library (computing);software quality;systems management;tom	Thorbjorn Andersson;Liisa von Hellens	1997	Information & Software Technology	10.1016/S0950-5849(97)00042-6	quality policy;software quality management;data quality;computer science;systems engineering;engineering;knowledge management;software engineering;database;information quality;management;software quality control;information system;software quality;software quality analyst	SE	-60.527562147306924	24.19748020097039	102288
cab934f6d76354ec5c707a6f79f2f414a1d1e79a	panel: systematic software reuse - objects and frameworks are not enough		Ensuring that object technology will achieve its promise of significant software reuse requires that special attention be paid to a combination of people, process and technology issues. Reuse will not happen automatically. The panelists will describe their experience with OO reuse and their views on the issues.	code reuse	Martin L. Griss;Ivar Jacobson;Chris Jette;Robert R. Kessler;Doug Lea	1995		10.1145/211782.213969	domain analysis;feature-oriented domain analysis;software deployment;software construction;software development;domain engineering;software verification and validation;package development process;systems engineering;computer science	HCI	-62.04985142156638	26.365121879494513	102373
51c87379b635334e27cba7db56fb2422723af539	the complexity of unified modeling language: a goms analysis	unified modeling language	Although the unified modeling language (UML) is becoming the de facto industry standard for object-oriented system development, it is not short of critics. Both researchers and practitioners have agreed that much work needs to be done to enhance UML. This research evaluates the nine UML diagrams using GOMS. GOMS, beginning as a theoretical model in HCI, describes the procedures required for accomplishing a general set of tasks by decomposing the tasks into four elements: Goals, Operators, Methods, and Selection rules. We use a special type of GOMS, NGOMSL, for analyzing UML. This research attempts to find ways to enhance the ease of use of UML diagrams and contribute to the evolution of UML.		Keng Siau;Yuhong Tian	2001			unified modeling language;simulation;communication diagram;uml tool;computer science;artificial intelligence;applications of uml;class diagram;database;object constraint language	HCI	-52.82330931366888	23.217364036805133	102420
14769b26d1c431677a0388497e6ee12747ed41e4	a methodological approach to developing model transformations.	model transformation	In Model Driven Engineering (MDE) model-to-model transformations are a key means for developing software systems. Manual manipulation of models can become unmanageable and expertise in model manipulation would need to be put in practice again and again. This technique has the potential to save a considerable amount of work from developers, as well as to avoid errors associated with manual processes. The research to be carried out in the PhD thesis here described focuses on the definition of a methodology for developing model transformations.	model transformation;model-driven engineering;software system	Andrés Vignaga	2007			computer science	SE	-55.034188586890046	25.336515778380004	102593
4b017321913a146ddf28a6d9967a6af461c6edd3	modelling variant user requirements in domain engineering for reuse	user requirements;domain analysis;domain engineering	 . In domain engineering, one attempts to analyse requirements for a family ofsimilar systems and then design a generic architecture to be reused during systemdevelopment. We conducted domain engineering projects in the domains of facilityreservation systems, library systems and software project support tools. We identified anumber of problems during domain analysis as well as during the design of genericsoftware architectures for which we could not find solutions in the literature.... 	domain engineering;requirement	Yu Chye Cheong;Stan Jarzabek	1998			domain model;domain analysis;mathematics;discrete mathematics;feature-oriented domain analysis;reuse;requirement;domain engineering;user requirements document;theoretical computer science;domain (software engineering)	SE	-54.27083575614955	26.87206229819008	102881
1f66bdc33cda37423332bd8590e342cbc3300caf	implementing osa model instances in ada	programming language;object oriented systems;product quality	Object-oriented Systems Analysis (OSA) [EKW92] is an analysis model whose purpose is to provide a way for analysts to capture and record real-world, system-application information. To produce software, OSA model instances must be mapped into code using some programming language. This paper shows how to map OSA model instances into production-quality Ada code. The technique uses templates that directly and efficiently support OSA concepts. We give basic templates, show how to map OSA concepts directly into the templates, and explain and discuss efficiency considerations. We illustrate our ideas with two sample applications.	ada;map;multiple inheritance;programming language;programming paradigm;software developer	Susan Bodily;David W. Embley;Scott N. Woodfield	1994		10.1145/197694.197734	real-time computing;computer science;programming language;algorithm	SE	-53.65417999604001	30.170061651712526	102973
41671c298d21cfd8549b901b4cdb51c8468b19ae	a flexible stochastic differential equation model in distributed development environment	ecuacion estocastica;distributed development;software testing;equation differentielle;stochastic equation;reliability;coefficient of variation;stochastic process;ito equation;componente logicial;cout developpement;development cost;sistema informatico;differential equation;software systems;composant logiciel;software development process;environnement developpement logiciel reparti;computer system;stochastic differential equation;program verification;satisfiability;equation stochastique;ecuacion diferencial;distributed development environment;software requirements;verificacion programa;detection defaut;stochastic processes;software development environment;fault detection;equation ito;software development;processus stochastique;software component;systeme informatique;stochastic model;fiabilite logiciel;proceso estocastico;fiabilidad logicial;verification programme;software reliability;modelo estocastico;deteccion imperfeccion;modele stochastique;defect detection;optimal software release problems;ecuacion ito	In recent years, the dependence on a computer system has become large in our social life. Especially, a software development environment has been changing into distributed development environment interconnected with work-stations. Therefore, it becomes more difficult for software developers to produce highly reliable software systems efficiently, because of the more diversified and complicated software requirements. Also, in the software development process, the software testing-cost occupies more than a half of the total development cost.#R##N##R##N#In this paper, we derive a flexible stochastic differential equation model describing a fault-detection process during the system testing phase of the distributed development environment by applying a mathematical technique of stochastic differential equations of an Itoˆ type. Moreover, we discuss optimal software release problems based on the reusable rate of software components minimizing the expected total software cost, and also minimizing the cost with satisfying a software reliability requirement based on the coefficient of variation.		Yoshinobu Tamura;Shigeru Yamada	2006	European Journal of Operational Research	10.1016/j.ejor.2004.04.034	stochastic process;stochastic differential equation;simulation;software sizing;computer science;software development;iterative and incremental development;reliability;mathematics;software testing;goal-driven software development process;differential equation;coefficient of variation;software development process;software requirements;algorithm;software metric;statistics;satisfiability;avionics software	Robotics	-62.15776551958302	31.73899465148047	103081
54505406ee8ef089f813d4f07a6013856d18acc7	support for object-oriented testing	software engineering tools;system testing software testing large scale systems software libraries process design programming profession computer science software engineering information technology costs;object oriented design;information hiding;development environment object oriented testing large scale system design information hiding classes tools;abstract data types;qa 76 software;large scale system;testing;object oriented programming;computer programming;development environment;program testing;software tools abstract data types object oriented programming program testing;object oriented;object oriented approach;object orientation;software tools;object oriented testing	Object-orientation has rapidly become accepted as the preferred paradigm for large scale system design. There is considerable literature describing approaches to object-oriented design and implementation. However discussion of testing in an object-oriented environment has been conspicuous by its absence. At first sight it appears that decomposition of a system into a potentially large number of information-hiding classes greatly increases the cost of testing. However, in this paper we show that by taking an object-oriented approach to testing, and the inclusion of appropriate tools in the development environment, testing time can be greatly reduced and special purpose test code can be virtually eliminated.	java;programming paradigm;software development process;systems design	Michael Kölling;John Rosenberg	1998		10.1109/TOOLS.1998.750036	computer science;systems engineering;database;programming language	SE	-52.254372636678035	31.139484926020174	103162
9c9c470d325bcefc502aea2097b78d31c15fa274	extensibility in ecosystem architectures: an initial study	api;ecosystem;quality attribute	Organizations that build software-intensive products participate in socio-technical ecosystems that encompass their collaborators, competitors, customers, and suppliers. STREAM, an ecosystem modeling method, provides three views of that ecosystem: business, software, and innovation. In the software view the architecture is the primary structuring element. It is our hypothesis that certain quality attributes of the architecture, such as expressiveness and extensibility, are important factors in the success of the ecosystem. Extensibility is normally presented through the API. We examine the APIs of three platforms, one that is increasing in use, one that is in steady use, and one that is declining in use. We use these initial results to generate hypotheses for further exploration.	application programming interface;ecosystem model;extensibility;list of system quality attributes;sociotechnical system;software engineering;structuring element	Simone da Silva Amorim;Eduardo Santana de Almeida;John D. McGregor	2013		10.1145/2501585.2501588	simulation;systems engineering;engineering;world wide web	SE	-62.3481676849225	21.87842153874717	103182
c118b7cf1445cff3f5a7f61c4dd0811628382b39	evaluation of an application ontology		The work presented in this paper demonstrates an evaluation procedure for a real-life application ontology, coming from the avionics domain. The focus of the evaluation has specifically been on three ontology quality features, namely usability, correctness and applicability. In the paper, the properties of the three features are explained in the context of the application domain, the methods and tools used for the evaluation of the features are presented, and the evaluation results are presented and discussed. The results indicate that the three quality features are significant in the evaluation of our application ontology, that the proposed methods and tools allow for the evaluation of the three quality features and that the inherent quality of the application ontology can be confirmed.	application domain;avionics;correctness (computer science);real life;usability	He Tan;Anders Adlemo;Vladimir Tarasov;Mats E. Johansson	2017			avionics;systems engineering;ontology;computer science	Web+IR	-59.43061690320913	26.00386252606225	103308
6e394818476e5b75cf7dfc73ef404d58260c0035	on the comprehension of workflows modeled with a precise style: results from a family of controlled experiments	workflow modeling;family of experiments;precise and ultra light styles;uml activity diagrams	In this paper, we present the results from a family of experiments conducted to assess whether the level of formality/precision in workflow modeling, based on UML activity diagrams, influences two aspects of construct comprehensibility: correctness of understanding and task completion time. In particular, we have considered two styles for workflow modeling with different levels of formality: a precise style (with specific rules and imposed constraints) and an ultra-light style (no rules, no imposed constraints). Experiments were conducted with 111 participants (Bachelor and Master students). In each experiment, participants accomplished comprehension tasks on two workflows, modeled either with the precise style or with a lighter variant. The main results from our data analysis can be summarized as follows: (i) all participants achieved a significantly better comprehension of workflows written in the precise style, (ii) the style had no significant impact on task completion time, (iii) more experienced participants benefited more, with respect to less experienced ones, from the precise style, as for their correctness of understanding, and (iv) all participants found the precise style useful in comprehending workflows.	activity diagram;correctness (computer science);experiment;object constraint language;software engineer;unified modeling language	Gianna Reggio;Filippo Ricca;Giuseppe Scanniello;Francesco Di Cerbo;Gabriella Dodero	2013	Software & Systems Modeling	10.1007/s10270-013-0386-9	simulation;computer science;programming language;engineering drawing	SE	-58.88507239263441	30.22192371957556	103367
b25391d02b59aaeb0b3176caa384e059b43a3ed8	a self-healing technique based on encapsulated operation knowledge	traditional operational cost;system-specific information;self-healing technique;component-level operation knowledge;specific system structure;operation knowledge;self-healing functionality;system specific information;self-healing system;dependency injection mechanism;encapsulated operation knowledge;cost factor;encapsulation;prototypes;fault detection;autonomic computing;weaving;application software;cost function	Although autonomic computing reduces traditional operational cost, it introduces another cost factor related to operation knowledge. This paper focuses on self-healing functionality and proposes a technique which improves reusability of component-level operation knowledge for self-healing systems. Operation knowledge which attains reusability becomes independent of a specific system structure and therefore it can be reused across organizations and adapted to changes. To achieve reusability, operation knowledge is encapsulated in components whereas system specific information is excluded. To cope with the remaining problem of dependency among components, a dependency injection mechanism is introduced. The dependency injection mechanism works out needed recovery actions by relating component and system-specific information. Furthermore, this paper describes an implemented prototype together with an application example.	aspect-oriented programming;autonomic computing;constraint logic programming;constraint satisfaction;dependency injection;embedded system;encapsulation (networking);java platform, enterprise edition;propagation of uncertainty;prototype;scalability;self-management (computer science);software propagation;warez	Teruyoshi Zenmyo;Hideki Yoshida;Tetsuro Kimura	2006	2006 IEEE International Conference on Autonomic Computing		reliability engineering;application software;simulation;encapsulation;computer science;engineering;electrical engineering;operating system;prototype;weaving;fault detection and isolation;computer engineering;autonomic computing	Robotics	-55.89635541894016	28.97841267513264	103608
ad7cb08df8d8dd8fa905c2a1f9349a7a70889826	constraint programming heuristics for configuring optimal products in multi product lines		Nowadays, complex application domains require configuring multi-product lines where product features and constraints among them are specified in several variability models. These variability models are enriched with inter-model constraints representing the existing relations among domain concerns, and with non-functional properties modeled as attributes attached to product features. Multiple techniques use constraint programming to automate the cumbersome task of manually configuring a suitable product. Currently, there are some proposals to improve the performance of constraint solvers when configuring single-model product lines, however configuration scenarios with multiple interrelated and attributed models are not yet targeted. This paper proposes and evaluates three search heuristics used to configure optimal products regarding multi-objective criteria. Results are compared against the default search strategy of the Choco constraint solver. We evaluated the performance for configuring optimal products in four state-of-the-art product lines and 130 generated variability models representing multi-product lines that scale up to 6400 features and 960 constraints. As a result, we observe that the proposed heuristics perform better than the default solver strategy when the variability models scale in terms of features. In contrast, the default strategy and one of the proposed heuristics perform better as the number of interdependencies between variability models increases. © 2018 Elsevier Inc. All rights reserved.	algorithm;cloud computing;computation;computational problem;constraint programming;experiment;heart rate variability;heuristic (computer science);image scaling;interdependence;knowledge-based configuration;local search (constraint satisfaction);multiphoton lithography;program synthesis;scalability;solver;spatial variability	Lina Ochoa;Oscar González Rojas;Nicolás Cardozo;Alejandro Guerrero Gonzalez;Jaime Chavarriaga;Rubby Casallas;Juan Francisco Díaz	2019	Inf. Sci.	10.1016/j.ins.2018.09.042	machine learning;constraint programming;artificial intelligence;configuration management;mathematical optimization;mathematics;interdependence;heuristics;constraint satisfaction problem;solver	AI	-55.666265661564346	26.4176704709589	103653
75c8c05a702eb9f8e686b808e165574c4025df9e	improving model-based regression test selection		Existing model-based regression test selection approaches are based on analyzing changes performed at the model level. These approaches have three limitations. First, they cannot detect all types of changes from design models. Second, they do not identify the impact of changes to the inheritance hierarchy of the classes. Third, their applicability is limited due to the abstraction gap between the code-level regression test cases and the models that represent the software system at a high level of abstraction. This paper discusses two model-based RTS approaches to overcome these limitations, the evaluation plan, and the current status.	high-level programming language;regression testing;software design;software system;test case	Mohammed Al-Refai	2017			regression testing;statistics;computer science	SE	-57.99420101942549	31.240247878615943	103739
076d458297b8bfa31dda61dc857ab62713b258ea	evaluating the cost-effectiveness of inspecting the requirement documents: an empirical study				Narendar Mandala;Gursimran Singh Walia	2012			empirical research;computer science;systems engineering;data mining	SE	-62.41307427226393	26.908339732365725	103802
0166e11f7c555a0aa7ea25220041d89c5737b266	engineering graphical domain specific languages to develop embedded robot applications			domain-specific language;embedded system;graphical user interface;robot	Daniel B. F. Conrado;Valter Vieira de Camargo	2012			computer science;domain analysis;robot;theoretical computer science;domain-specific language	Embedded	-48.88947299410401	29.225743697068186	103912
26a6bf2a33bd072b4e952b3a4f918a603aeb6fb5	value-based quality processes and results	cost effectiveness	Cost effectiveness is one of the important issues for developing products in a life cycle. And review is a key activity that can detect defects from the early stage and fix them. This paper provides Value-based review techniques adding cost effectiveness into review processes and reports on an experiment on Value-based review. Through the experiment, the Value-based review is shown to have higher cost effectiveness in review processes.	enterprise life cycle;value (ethics)	Barry W. Boehm	2005		10.1145/1083292.1083294	cost-effectiveness analysis;computer science;engineering;management science;operations research	SE	-62.76836928940719	27.286026702018884	104057
12661a0cb19332eff581b6a79314757d35d955c7	towards an operational framework for architectural prototyping	software prototyping;prototypes;computer architecture;prototypes computer architecture lab on a chip software prototyping buildings programming profession proposals space technology costs computer science;programming profession;lab on a chip;space technology;computer science;proposals;buildings	We use a case study in architectural prototyping as input for presenting a first, tentative, framework describing key concepts and their relationships in architectural prototyping processes.	abc;paper prototyping;programming model;prototype	Henrik Bærbak Christensen	2005	5th Working IEEE/IFIP Conference on Software Architecture (WICSA'05)	10.1109/WICSA.2005.73	computer architecture;lab-on-a-chip;computer science;systems engineering;engineering;software engineering;prototype;space technology;computer engineering	SE	-52.173565142076214	28.353104255318534	104092
c4d8235ad1287b87dbf547c76b80101a827c0657	uncovering the organisational modelling and business process modelling languages in the aris method	aris method;metamodelling;enterprise architecture modelling;business process modelling	In this paper, we propose an approach to excavate and define the metamodels of the organisational modelling and business process modelling languages of ARIS method. This approach uses information obtained with user interactions over the modelling environment called ARIS toolset and extra information from tool documentation. The application of this approach results on well-defined language metamodels, clarifying the language’s main modelling elements and their relationships. The metamodels serve as a starting point for the definition of the semantics of the language and allow the construction of tools to manage modelling, simulation, analysis and transformation of organisational models and business processes. To validate the metamodels we define a set of transformations which enables one to create instances of the metamodels using as a starting point models in the ARIS toolset serialisation format (the ARIS markup language-AML).	aris express;abstract syntax;business process;correctness (computer science);documentation;electronic product code;enterprise architecture;event-driven process chain;high-level programming language;interaction;markup language;metamodeling;model-driven engineering;model-driven integration;modeling language;occam's razor;ontology (information science);process modeling;programming tool;serialization;simulation;xslt	Paulo Sérgio Santos;João Paulo A. Almeida;Thiago Lavarezi Pianissolla	2011	IJBPIM	10.1504/IJBPIM.2011.040205	enterprise modelling;computer science;systems engineering;data mining;management science;business process modeling	AI	-53.906677683367505	19.5961115709373	104106
6e449b3865b9903e4a378b1354cd4c7db4bb0c7e	test programming environment in a modular, open architecture test system	open architecture;automatic test equipment;modules;open systems	This work addresses two key concepts in device test program development: test class programming and pattern management. These are explored in the context of an open architecture test system, where the primary requirement is the flexibility to integrate externally developed capabilities into the system. Development against an open architecture test system includes the integration of software-based solutions (such as user-developed test classes) and third party hardware modules, including the software necessary to support the modules. This work focuses on the open architecture facets of test programming and pattern management, as embodied in the OPENSTAR/spl trade/ specification. The software for Advantest Corporation's T2000 system is used as a concrete example for highlighting these concepts.	algorithm;ccir system a;consortium;entity–relationship model;integrated development environment;iterative and incremental development;iterative method;leon;object lifetime;open architecture;scalability;semiconductor;test template framework	Ankan K. Pramanick;Ramachandran Krishnaswamy;Mark Elston;Toshiaki Adachi;Harsanjeet Singh;Bruce R. Parnas	2004	2004 International Conferce on Test	10.1109/ITC.2004.175	test strategy;reliability engineering;module pattern;reference architecture;embedded system;automatic test equipment;model-based testing;white-box testing;open architecture;integration testing;computer science;systems engineering;engineering;software development;operating system;software engineering;modular programming;software testing;open system;resource-oriented architecture;test management approach;computer engineering;test harness	SE	-51.183518993871296	28.396393535969462	104128
f1deb075f0345b57636cab2d58c14b2fd46ba822	formal ensemble engineering	working group;agent oriented software engineering;software engineering;080309 software engineering;levels of abstraction;890299 computer software and services not elsewhere classified	The ‘ensembles’ identified by the InterLink working group on Software Intensive Systems comprise vast numbers of components adapting and interacting in complex and even unforseen ways. If the analysis of ensembles is difficult, their synthesis, or engineering, is downright intimidating. We show, following a recent three-level approach to agent-oriented software engineering, that it is possible to specialise that intimidating task to three levels of abstraction (the ‘micro’, ‘macro’ and ‘meso’ levels), each potentially manageable by interesting extensions of standard formal software engineering. The result provides challenges for formal software engineering but opportunites for ensemble engineering.	agent-oriented software engineering;interaction;principle of abstraction	Jeff W. Sanders;Graeme Smith	2008		10.1007/978-3-540-89437-7_8	domain analysis;computing;software engineering process group;computer science;systems engineering;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;software walkthrough;resource-oriented architecture;software requirements;software system;computer engineering	SE	-52.65405043991272	26.83828736606222	104211
56160a67a000d4f9485ba7c66d6a14b987e3fc88	eclipse modeling framework for document management	logistic model;model based approach;standard model;logistics;it;business transformation;indexation;eclipse;documents;emf;process;roi;eclipse modeling framework;modeling;dms;framework;modeling tool;document management	The lifecycle of document management applications typically comprises a set of loosely coupled subsystems that provide capture, index, search, workflow, fulfillment and archival features. However, there exists no standard model for composing these elements together to instantiate a complete application. Therefore, every application invariably incorporates custom application code to provide the linkages between each of these loosely coupled subsystems. This paper proposes a model-based approach to instantiating document management applications. An Eclipse Modeling Framework (EMF) based model is used to formalize the variable elements in the document management applications. The modeling tool supports the instantiation of an EMF model for every new application and supports the generation of runtime artifacts - this includes code, XML configurations, scripts and business logic. This approach to creating new instances of document management applications with a formal EMF model has been validated with a real-world document management application.	archive;business logic;eclipse modeling framework;instance (computer science);loose coupling;universal instantiation;xml	Neil Boyette;Vikas Krishna;Savitha Srinivasan	2005		10.1145/1096601.1096653	well-formed document;simulation;computer science;document management system;data mining;database;information technology;world wide web;design document listing	SE	-51.923749516087675	20.690175284579805	104288
c196f775680b105237fd7e69ee2f27c848ecbc0e	linguistic patterns and linguistic styles for requirements specification (i): an application case with the rigorous rsl/business-level language		"""System requirements specification describes technical concerns of a system and is used throughout the project life-cycle. Requirements specification helps sharing the system vision among its stakeholders, as well facilitating the communication, project management and system development processes. For an effective communication, everyone communicates by means of a common language, and natural language provides the foundations for such language. Although natural language is the most common and preferred form of requirements representation, it also exhibits intrinsic characteristics that often present themselves as the root cause of many requirements quality problems, such as incorrectness, inconsistency, incompleteness and ambiguousness.  This paper presents the RSL (short name for """"Requirements Specification Language"""") which is a language to improve the production of requirements specifications in a more systematic, rigorous and consistent way. RSL includes constructs logically arranged into views according to the specific requirement engineering concerns they address. These constructs are defined as linguistic patterns and are represented textually by multiple linguistic styles. Due to space constraints, this paper focuses only on its business level constructs and views, namely on glossary terms, stakeholders, business goals, processes, events and flows. RSL can be used and applied by different types of users such as requirement engineers, business analysts, or domain experts. They can produce system requirements specifications with RSL at different level of detail, considering different writing styles and different types of requirements (e.g., business goals, system goals, functional requirements, quality requirements, constraints, user stories, and use cases). In addition, they can use other types of constructs (e.g., terms, stakeholders, actors, data entities) that, in spite of not being requirements, are important to complement and enrich the specification of such requirements. Based on a simple running example, we also show how RSL users (i.e., requirements engineers and business analysts) can produce requirements specifications in a more systematic and rigorous way."""	compute node linux;correctness (computer science);eclipse xtext;entity;functional requirement;glossary;international symposium on fundamentals of computation theory;itbox;item unique identification;level of detail;multiple inheritance;natural language;raise;renderman shading language;requirements analysis;requirements engineering;software requirements specification;specification language;spreadsheet;system requirements specification;user story;view (sql);web application	Alberto Rodrigues da Silva	2017		10.1145/3147704.3147728	systems engineering;software requirements specification;computer science;spite;linguistics;requirements engineering;functional requirement;use case;user story;system requirements specification;system requirements	SE	-53.48322096601886	21.84260135124076	104310
1ee444e5f2372f904af6fd87936b464788bd0880	podim: a language for high-level configuration management	high level language;configuration management	The high rate of requirement changes make system administration a complex task. This complexity is further influenced by the increasing scale, unpredictable behaviour of software and diversity in terms of hardware and software. In order to deal with this complexity, configuration management solutions have been proposed. The processes that many configuration management solutions advocate are kept close to manual system administration. This approach has failed to address the complexity of system administration in the real world. In this paper, we propose PoDIM: a high-level language for configuration management. In contrast to many existing configuration management solutions, PoDIM allows modeling of cross machine constraints. We provide an overview of the PoDIM notation, describe a case study and present a prototype. We believe that high-level languages are needed to reduce system administration complexity. PoDIM is one step in that direction.	configuration management;high- and low-level;high-level programming language;prototype;system administrator	Thomas Delaet;Wouter Joosen	2007			simulation;software configuration management;computer science;operations management;sociology;configuration management;configuration item;high-level programming language	SE	-59.703634589942396	21.965309966428784	104780
de4b2d6177d899da6ba07de90f28417b6dab08d8	evolving critical systems: a research agenda for computer-based systems	software;software systems costs runtime software performance software quality conferences systems engineering and theory software engineering buildings telecommunication control;evolving critical systems ecs;research agenda;telecommunication control;software systems;evolving critical system;computer systems;runtime;software engineering;systems software;systems engineering and theory;software performance;softwware evolution evolving critical systems ecs;conference item;critical system;design and implementation;multicore processing;softwware evolution;safety critical software;business;evolving critical system computer based system software systems;computer based system;communities;security;software reliability;software quality;buildings;conferences;systems software safety critical software	Increasingly software can be considered to be critical, due to the business or other functionality which it supports. Upgrades or changes to such software are expensive and risky, primarily because the software has not been designed and built for ease of change. Expertise, tools and methodologies which support the design and implementation of software systems that evolve without risk (of failure or loss of quality) are essential. We address a research agenda for building software in computer-based systems that (a) is highly reliable and (b) retains this reliability as it evolves, either over time or at run-time.	emoticon;software evolution;software system	Michael G. Hinchey;Lorcan Coyle	2010	2010 17th IEEE International Conference and Workshops on Engineering of Computer Based Systems	10.1109/ECBS.2010.56	long-term support;software quality management;computer science;systems engineering;engineering;information security;package development process;software framework;software development;software design description;software engineering;systems development life cycle;software deployment;software quality;software metric;software quality analyst;computer engineering;avionics software	SE	-61.795199717434976	28.010382150039554	104838
4bfe3951c20acfb05d4c9e746a591411804fe03d	a generic high-level specification language for non-functional properties of component-based systems		The component-based software development is helpful in providing reuse of the components and reducing complexity of software systems. Di erent components work together to produce a complete system that needs a good understanding of the way the components interact with each other. The components' reuse requires a high level speci cation, among other things for non-functional properties (NFPs) as these properties control the way these components co-ordinate with each other. The complexity of modern software systems demands a generic and exible language for formal specication of the functional and NFPs of the system so that the di erent components in a system can have a well-de ned behaviour expectation. The non-functional properties of component-based system are important part of speci cation because they highlight the non-functional perspective of the system. They also help in implementation of functional elements with constraints on the NFPs in consideration. The absence of speci cation of NFPs can render the system not usable because the functional implementation may not have considered the constraints for working environment of the system. This is because the component developer will have no clearly de ned non-functional objectives of the system. The formal speci cation of NFPs for components and their interaction with each other can help implement reliable systems. Incorporating these design concepts in the language speci cation would describe the usage context of language features in clear and precise manner. In this thesis, we developed a novel generic speci cation language (QML/CS) for NFPs of component-based systems. De ning such a high level speci cation language using a standard meta-modelling approach is challenging because its de nition requires multi levels modelling. We employed deep meta-modelling technique to address this complex problem. We begin by discussing the key concepts used, then show how our meta-model is de ned. In addition, we show how our meta-model for QML/CS overcame the issues of the standard meta-modelling language like UML and the mapping of a measurement to a concrete application. Finally, we show a prototype for QML/CS and discuss how the mapping of QML/CS expressions into TLA+ speci cations can de ne the QML/CS semantics. keywords: Non-functional properties; Model-Driven Engineering; Weaving Models; Multilevel modelling; Domain-Speci c Languages; Component-Based Systems.	component-based software engineering;domain-specific language;high- and low-level;high-level programming language;metamodeling;model-driven engineering;model-driven integration;non-functional requirement;prototype;qml;software development;software system;specification language;tla+;unified modeling language	Abdulrahman Alreshidi	2016			interface description language;specification language;component;programming language specification;language of temporal ordering specification	SE	-50.64928459294945	25.706070444416422	104962
1666e27d79c3f26a536b143500be9bed0e725db2	simulation data management and reuse: toward a verification and validation approach			simulation;verification and validation	Anaïs Ottino;Thomas Vosgien;Julien Le Duigou;Nicolas Figay;Pascal Lardeur;Benoît Eynard	2015		10.1007/978-3-319-33111-9_43	verification and validation of computer simulation models;verification;software verification;systems engineering	EDA	-62.36154177441511	24.708482027360777	105059
affb29d0a88e81d38b24fa815c4fd54469612cae	a methodology for automated test generation guided by functional coverage constraints at specification level	formal specification;functional testing;automatic testing system testing formal specifications software testing automation aerospace electronics embedded software real time systems certification flow graphs;automated test generation;formal specification automated test generation functional coverage constraints;program testing;test generation;functional coverage constraints;program testing formal specification	This paper presents an approach to automate test generation from a formal specification and a set of functional test objectives while taking into account coverage constraints at the specification level. We use existing test generation techniques and tools, our contribution is on the methodological side. We define an innovative approach adapted to the industrial domain and its constraints	formal specification;functional testing;test automation	Odile Laurent;Christel Seguin;Virginie Wiels	2006	21st IEEE/ACM International Conference on Automated Software Engineering (ASE'06)	10.1109/ASE.2006.6	keyword-driven testing;reliability engineering;test data generation;formal methods;white-box testing;manual testing;computer science;systems engineering;software engineering;functional testing;formal specification;functional specification;session-based testing;software testing;test management approach	SE	-57.16702906200398	30.087680955088103	105113
c597c7ca2b75c017dd9debb2f6c74951c338e1d6	business rules in the real world: a decision support approach	decision support;business rules	Many enterprises have recognized that in order to be flexible in an increasing competitive environment, it is important to have a clear understanding of the business rules underlying the enterprise. This paper asserts that it is not practical, nor even desirable for a set of business rules to be consistent, complete and unambiguous. Rather we argue that to deal with these problems naturally occurring in the real world and to allow flexibility, business rules need to be supported by a decision making methodology which addresses all aspects of the business process life cycle. We describe the role that such a methodology should play in the elicitation, deployment and evolution of business rules.		Daniela Rosca;J. Christian Wild	1996			business rule management system;business analysis;business transformation;semantics of business vocabulary and business rules;business domain;decision support system;computer science;knowledge management;artifact-centric business process model;business process management;business case;management science;business process;business process discovery;management;business rule;new business development;business process modeling;line of business;business decision mapping;business architecture	ML	-55.31348181075774	18.552739306708627	105123
69469a1204098c873498c99d1beb575f667b44df	a comparison of size estimation techniques applied early in the life cycle	developpement logiciel;aplicacion militar;ciclo desarrollo;application militaire;sistema temporizado;life cycle;estimation method;logiciel a securite critique;timed system;application intensive;intensive application;desarrollo logicial;safety critical software;software development;military application;cycle developpement;request for proposal;systeme temporise;aplicacion intensiva	Timing is one of the most critical factors of software size estimation. We need to know quite a bit about the software project to make a meaningful size estimate. However, most of the software estimates should be performed at the beginning of the life cycle, when we do not yet know the problem we are going to solve. In the literature, there are few early size estimation methods. This study demonstrates the results of size estimation methods utilized on a large software intensive military application within the boundary of a project for Request for Proposal (RFP) preparation.	enterprise life cycle;need to know;request for proposal;software project management;software sizing	Onur Demirörs;Çigdem Gencel	2004		10.1007/978-3-540-30181-3_17	biological life cycle;simulation;request for proposal;software development;operations research	SE	-62.533130424727936	28.86594273217207	105209
69251516855c2b163eed03417025c06a53792ed5	reusing base product features to develop product line architecture	building block;feature oriented domain analysis base product feature reuse product line architecture object oriented feature based conceptual frame base product architectural assets unified software development process;feature modeling;software development process;product line;object oriented programming;conceptual framework;object oriented programming software architecture software reusability;software architecture;object oriented;software reusability;product line architecture;feature oriented domain analysis;computer architecture software architecture feature extraction systems engineering and theory object oriented modeling programming software systems application software information analysis drives;product architecture	This paper deals with three things - extract features from a base product (legacy or new), extend the features, and organize them into a product line. As a result, an object oriented feature-based conceptual frame has been developed. The framework organizes base product architectural assets in such a way as to lend them to substantial reuse. Mechanisms are provided for instantiating multiple products from a single architecture. The building blocks for the conceptual framework are the USP (unified software development process) and the feature model of FODA (feature-oriented domain analysis).	feature model;feature-oriented domain analysis;instance (computer science);legacy system;software development process;unified process;universal storage platform	Samuel Ajila	2005	IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.	10.1109/IRI-05.2005.1506488	domain analysis;multilayered architecture;enterprise architecture framework;functional software architecture;reference architecture;software architecture;reusability;model-driven architecture;computer science;applications architecture;software framework;component-based software engineering;software development;software design description;feature-oriented domain analysis;software engineering;domain engineering;software architecture description;object-oriented programming;resource-oriented architecture;feature model;systems architecture	Robotics	-52.74773522726392	27.580946221603902	105269
6b19ba2121d0a0444bbdbd72c86e10edbceb726b	preventing user errors by systematic analysis of deviations from the system task model	safety and usability;air traffic control;task models;model based evaluation;task model;system design;inspection based evaluation	Interactive safety-critical applications have specific requirements that cannot be completely captured by traditional evaluation techniques. In this paper, we discuss how to perform a systematic inspection-based analysis to improve both usability and safety aspects of an application. The analysis considers a system prototype and the related task model and aims to evaluate what could happen when interactions and behaviours occur differently from what the system design assumes. We also provide a description and discussion of an application of this method to a case study in the air traffic control domain. # 2002 Elsevier Science Ltd.	enterprise software;high- and low-level;interaction;prototype;requirement;software developer;software development;systems design;usability;user error	Fabio Paternò;Carmen Santoro	2002	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.2001.0523	cognitive walkthrough;simulation;operating system;air traffic control;task analysis;usability inspection;systems design	SE	-57.8910005870589	30.128481354244535	105357
9f85f969ff6df3768424c066e521d7df37b23aec	object-oriented enhancement of real-time software using a heterogeneous re-engineering approach	incremental enhancement;object structure;software prototyping;application software;software maintenance;heterogeneous reengineering approach;real time;modelling levels;interactive validation;iterative validation;object oriented programming;software configurability;software engineering;additional new features;visualization;graphical models;object design;object oriented;software reusability;animation;object design real time software heterogeneous reengineering approach incremental modernisation incremental enhancement object oriented paradigm software maintainability software reusability software configurability object structure interactive validation additional new features iterative validation heterogeneous graphical animation modelling levels software partitioning object derivation;software engineering real time systems computer animation object oriented programming;software partitioning;incremental modernisation;computer animation;real time software;software maintainability;object oriented modeling animation real time systems graphical models software maintenance object oriented programming visualization software reusability application software software prototyping;heterogeneous graphical animation;object oriented modeling;object oriented paradigm;real time systems;object derivation	A technique for incremental modernisation and enhancement of an existing procedural real-time software to an object-oriented one is presented. The incremental enhancement enables the real-time system designer to make use of the advantages of object-oriented paradigm: the resulting re-engineered software is more maintainable, reusable and conjigurable. In this approach, object structure and additional new features can be validated interactively and iteratively using heterogeneous graphical animation. Different parts of the system may present different modelling levels during the enhancement, thus making the incremental process of software partitioning, object derivation and object design easier to manage.	graphical user interface;interactivity;programming paradigm;real-time clock;real-time computing;real-time transcription;systems design	Reijo Savola;Tuomas Ihme;Marko Heikkinen;Marko Salmela;Petri Pulli	1994		10.1109/EMWRTS.1994.336858	real-time computing;computer science;object-oriented design;iterative and incremental development;programming language;object-oriented programming;goal-driven software development process	SE	-49.231172190312364	27.476645649017417	105403
92f8d0604364d839edd0be213efa2d625c908d62	examining usage patterns of the fit acceptance testing framework	developpement logiciel;programmation agile;agile programming;extreme programming;programacion extrema;observational study;desarrollo logicial;software development;programmation extreme;programacion agil	Executable acceptance testing allows both to specify customers’ expectations in the form of the tests and to compare those to actual results that the software produces. The results of an observational study identifying patterns in the use of the FIT acceptance testing framework are presented and the data on acceptance-test driven design is discussed.	acceptance testing;executable;test-driven development	Kris Read;Grigori Melnik;Frank Maurer	2005		10.1007/11499053_15	simulation;extreme programming;engineering;software development;software engineering;agile software development;observational study	SE	-62.034130080933174	28.783969078383112	105944
6d202d8e278193376bbcf51d80b0aa46c1518bfb	towards a task-oriented, policy-driven business requirements specification for web services	gestion entreprise;processus metier;service web;firm management;abstraction;web service;abstraccion;service utilisateur;levels of abstraction;proceso oficio;coordinacion;administracion empresa;servicio usuario;user service;requirement specification;business process;servicio web;coordination	Dynamic assembly of complex software is possible through automated composition of web services. Coordination scripts identify and orchestrate a number of services to fulfil a user or business goal. The automated process begins at the business requirement stage, thus there exists a need for expressing high level business requirements, in such a way that is accessible by businesses. Current solutions (such as BPMN and UML) fail to include specifications at the appropriate level of abstraction. Our approach defines a graphical notation to depict a business goal in terms of objectives, which are refined by tasks, where the specifics of each task as well as overarching business constraints are encapsulated in a descriptive way in policies.	business requirements;graphical user interface;high-level programming language;map;refinement (computing);requirement;service-oriented software engineering;unified modeling language;web service;workbench	Stephen Gorton;Stephan Reiff-Marganiec	2006		10.1007/11841760_40	web service;business analysis;business process execution language;business domain;economics;business requirements;artifact-centric business process model;operating system;business case;database;abstraction;business process model and notation;services computing;business process;business software;management;business rule;new business development;law;world wide web;business process modeling;business activity monitoring	SE	-52.65541531233751	19.492798754427493	106363
3621eac63003c54f20ab387f6d4b5fbfd0624cfd	global software engineering: the future of socio-technical coordination	distributed processing;software architecture;global software engineering;globally-distributed projects;large software systems;socio-technical coordination;software architecture	Globally-distributed projects are rapidly becoming the norm for large software systems, even as it becomes clear that global distribution of a project seriously impairs critical coordination mechanisms. In this paper, I describe a desired future for global development and the problems that stand in the way of achieving that vision. I review research and lay out research challenges in four critical areas: software architecture, eliciting and communicating requirements, environments and tools, and orchestrating global development. I conclude by noting the need for a systematic understanding of what drives the need to coordinate and effective mechanisms for bringing it about.	requirement;software architecture;software engineering;software system	James D. Herbsleb	2007	Future of Software Engineering (FOSE '07)		software architecture;computer science;systems engineering;engineering;software engineering;collaborative software;software system;computer engineering	SE	-62.15144719247183	21.074275251113818	106427
a211b3a25c709c68cb9052cbeb0f09f8a53a3cfa	bidirectional translation between ocl and jml for round-trip engineering	bidirectional translation;software prototyping;unified modeling language java object oriented modeling syntactics software contracts natural languages;model driven development;public domain software;ocl;jml;software prototyping java public domain software;jml model driven development bidirectional translation ocl;open source projects bidirectional translation ocl jml round trip engineering model driven development mdd object constraint language java modeling language rte;java	In recent years, Model-driven development (MDD) based techniques have emerged, and thus translation techniques such as translation from Object Constraint Language (OCL) to Java Modeling Language (JML) have gained much attention. We have been studying not only translation techniques from OCL to JML but also from JML to OCL in order to support Round-trip Engineering (RTE). Two directions of translation among OCL and JML are performed independently without considering unified and iterative translations in our previous work. For an OCL statement and another OCL statement which is obtained from a JML statement which was translated from the original OCL, our previous framework preserves only the meaning of the two statements, however, the forms of the OCL statements may change. It prevents us from RTE-based development. This paper proposes a translation technique between OCL and JML maintaining OCL code by describing their original forms in the comment area of the target languages. Our implementation has been evaluated on two projects used in our previous work and also seven additional open source projects.	iterative method;java modeling language;model-driven engineering;model-driven integration;object constraint language;open-source software;round-trip engineering	Hiroaki Shimba;Kentaro Hanada;Kozo Okano;Shinji Kusumoto	2013	2013 20th Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2013.111	real-time computing;computer science;database;programming language;java;public domain software;object constraint language	SE	-48.524169726774765	27.147607002041127	106560
d52c0c42c6924336b9a6f9bcf8c4ce4c74f297b7	an overview of the knowledge discovery meta-model	architecture driven modernization;model driven reverse engineering;knowledge discovery meta model	Modernization of existing software systems is expensive and not always successive process that involves many challenging activities. In order to support these activities, the Object Management Group within the Architecture-Driven Modernization initiative proposes a number of standard representations of views on existing software systems. The Knowledge Discovery Meta-model plays the fundamental role in this set of representations as it defines common concepts of software assets and their operational environments. This paper addresses issues related to the extraction of knowledge from the software assets and the representation according to the Knowledge Discovery Meta-model in order to abstract the business logic implemented in the system. It observes that although this meta-model minimizes the effort required to obtain representation, it has several drawbacks that limits its capability to express domain specific knowledge. It is believed that this paper will enable researchers and practitioners to get a better understanding of this kind of representation, prepare for the modernization activities, and provide a basis for the further research.	architecture-driven modernization;business logic;metamodeling;metaobject;software modernization;software system	Kestutis Normantas;Sergejus Sosunovas;Olegas Vasilecas	2012		10.1145/2383276.2383286	software mining;knowledge management;artificial intelligence;body of knowledge;data mining;database;knowledge extraction;management;world wide web;domain knowledge	AI	-59.03966387176443	23.385779568564843	106627
feee1ac6ce34704fc0f8aa3d59f474a0df5ecc11	towards including layout properties for modeling graphical user interfaces - generic properties for gui metamodels		Software applications have come to simplify the task for users and offer them automated functionalities. These applications must therefore contain high-performance and efficient user interfaces in order to translate correctly the user’s needs. Indeed, several elements contribute to the ergonomics of these interfaces, among them the position and layout of the graphical components which play a very important role to ensure this. However, the design and implementation of such user interfaces for different platform using several programming languages can be tedious and time consuming, especially when the application gathers a large number of interfaces or screens. Since the model driven engineering aims at automating the process of development and raising the level of abstraction, we can use model driven principles to help users choose the right component in the right position on the interface. That is why we present an approach that combines model driven engineering principles and the graphical user interfaces to handle automated layout and position.	algorithm;graphical user interface;human factors and ergonomics;layout manager;metamodeling;model-driven engineering;programming language	Sarra Roubi;Mohammed Erramdani;Samir Mbarki	2017		10.5220/0006272505560560	theoretical computer science;generic property;computer science;graphical user interface	SE	-48.991231852263496	23.758243974535958	106637
a7b3c59b4dcaa768f119f7fc47c27c4ff7916019	acknowledging insufficiency in the evaluation of legal knowledge-based systems: strategies towards a broad based evaluation model	verification;school of management and information systems;knowledge based system;artificial intelligent;development environment;280000 information computing and communication sciences;evaluation methodology;1801 law;validation;evaluation;methodology;0806 information systems;respubid12244;verification and validation;evaluation model;legal knowledge based systems	This paper considers the need for evaluation of knowledge-based systems in general and legal knowledge-based systems in particular. Some special features of legal knowledge-based systems pertinent to their evaluation are presented. The expected benefits of such evaluations are discussed. and some of the difficulties likely to be encountered are outlined. The proceedings of four International Conferences on Artificial Intelligence and Law are analysed to determine the rate of reporting evaluations in non-theoretical papers. These papers had a low rate of consideration of evaluation issues reflecting common practice in research biased development environments. These results confirm that more attention to evaluation is needed in the legal knowledge based systems domain. This paper foreshadows the development of an evaluation methodology tailored specifically for legal knowledge-based systems. Evaluation strategies beyond verification and validation are drawn upon, both from the international ISO/IEC 14598 and 9126 standards and also from previous work on evaluation models for knowledge-based systems.	artificial intelligence and law;convergence insufficiency;knowledge-based systems;relevance;trusted computer system evaluation criteria;verification and validation	Jean Hall;John Zeleznikow	2001		10.1145/383535.383553	verification and validation;verification;computer science;knowledge management;artificial intelligence;evaluation;knowledge-based systems;methodology;development environment;management science	SE	-57.344613230077265	22.908039903431188	106658
60f27bf46cfb02c6c1ca8027bb5899c2bcd03bcb	towards a metamodel for a requirements engineering process of embedded systems	requirements engineering;embedded systems;metamodel	In the embedded systems (ES) area, more than 50% of problems occur at system delivery and are related to misconceptions in capturing requirements. According to our systematic literature review (SLR), no evidence explicitly depicts how an embedded system must be elicited and specified. However, understanding the embedded systems and their environment is a strenuous activity. Even though current approaches present some contributions, the definition of a systematic requirements engineering process remains a challenging issue. Based on this shortcoming, we developed a metamodel that defines concepts and relationships that must be taken into account the development of an ES. From the metamodel, we define a precise requirements engineering process. This research presents the main results of a SLR, a resource model, and a sketch of a process to guide the requirements development of embedded systems.	embedded system;metamodeling;requirement;requirements engineering;systematic review	Tarcísio Pereira;Deivson Albuquerque;Aêda Sousa;Fernanda M. R. Alencar;Jaelson Brelaz de Castro	2016	2016 VI Brazilian Symposium on Computing Systems Engineering (SBESC)	10.1109/SBESC.2016.022	reliability engineering;systems engineering;engineering;requirements engineering	Embedded	-56.17775819623122	23.841998792730507	106977
032e00607e01af39b3ea9fe74e024fad9d1eabec	automated integration of service-oriented software systems	theoretical computer science;computer science all	In the near future we will be surrounded by a virtually infinite number of software applications that provide services in the digital space. This situation radically changes the way software will be produced and used: (i) software is increasingly produced according to specific goals and by integrating existing software; (ii) the focus of software production will be shifted towards reuse of third-parties software, typically black-box, that is often provided without a machine readable documentation. The evidence underlying this scenario is that the price to pay for this software availability is a lack of knowledge on the software itself, notably on its interaction behaviour. A producer will operate with software artefacts that are not completely known in terms of their functional and non-functional characteristics. The general problem is therefore directed to the ability of interacting with the artefacts to the extent the goal is reached. This is not a trivial problem given the virtually infinite interaction protocols that can be defined at application level. Different software artefacts with heterogeneous interaction protocols may need to interoperate in order to reach the goal. In this paper we focus on techniques and tools for integration code synthesis, which are able to deal with partial knowledge and automatically produce correct-by-construction service-oriented systems with respect to functional goals. The research approach we propose builds around two phases: elicit and integrate. The first concerns observation theories and techniques to elicit functional behavioural models of the interaction protocol of black-box services. The second deals with compositional theories and techniques to automatically synthesize appropriate integration means to compose the services together in order to realize a service choreography that satisfies the goal.	service-oriented device architecture;software system	Marco Autili;Paola Inverardi;Massimo Tivoli	2015		10.1007/978-3-319-24644-4_2	simulation;software quality management;software sizing;computer science;artificial intelligence;package development process;software design;software framework;component-based software engineering;software development;software design description;operating system;machine learning;middleware;software construction;database;mathematics;distributed computing;software walkthrough;programming language;resource-oriented architecture;software deployment;computer security;algorithm;software metric;software system;avionics software	SE	-54.12160884468139	27.03025972281301	106993
ccdfe3e013f54b0deffd8fcfafda64eb337daa80	applying industrial-strength testing techniques to critical care medical equipment	keyword driven;embedded system;testing hardware;medical device;domain specific language;safety critical	Hardware and software development of embedded systems interdependently gear into each other. Even more so if the device under development is intended for use in critical care facilities such as intensive care units. Especially in this case, safety measures and risk mitigation techniques are implemented using both hardware and software components. Thus applying hardware and software testing approaches in combination is inevitable as well.#R##N##R##N#The increasing utilization of test domain-specific languages (Test DSLs), code generators and keyword-driven interpreters tends to raise the level of abstraction in test development. This approach aims to enhance productivity by generating executable tests from a non-programming language created for describing test cases. A second goal is to increase coverage by generating tests for as many as possible combinations of input values (black box test) or for all reasonable paths of a program flow (white box test). In combination with hardware-supported signal generation and fault injection this can be a very powerful strategy for testing safety-critical embedded devices. This article introduces an example of this strategy - the usage of a keyword-driven testing technique in cooperation with additional test hardware - in the context of an embedded medical device development, all the while emphasizing the benefit of combining different approaches. It discusses the utilization of commercial off-the-shelf (COTS) testing hardware as well as the application of an in-house developed test box. It also highlights the integration of commercial software - for requirements engineering, test management and continuous integration - with a self-developed testing framework powered by its own keyword-based test DSL.		Christoph Woskowski	2012		10.1007/978-3-642-33678-2_6	non-regression testing;test strategy;reliability engineering;embedded system;black-box testing;test data generation;real-time computing;simulation;fuzz testing;white-box testing;manual testing;system integration testing;integration testing;computer science;domain-specific language;engineering;software engineering;dynamic testing;smoke testing;software testing;programming language;system testing;test case;computer security;test management approach;test harness	SE	-58.79556604277116	28.964987049593297	107059
7fd395f6b038d648f67faded5b5795bb0834aa97	the shell model - a method for system boundary analysis		The application of analysis methods in systems and safety engineering depends on the available depth of knowledge about a system in the respective lifecycle phases. However, the analysis method chain shows gaps as it should support system analyses during the whole lifecycle of a system. The aim of this paper is to discuss the Shell Model Analysis method, which aims at closing a gap in early system lifecycle phases, like the concept phase. The Shell Model Analysis is a graphical method that splits up a system and groups its parts into concentric shells, built around a selected system part under consideration. A set of rules and guidelines has been defined in order to enable a proper shell build-up. Originally, the method was intended to assist the analysis of electronic system parts, like e.g. an embedded control unit for a braking system, by supporting the definition and analysis of the system’s boundary and its environment only. Meanwhile, it has been extended to also produce results that can be starting points for consecutive analysis methods.		Walter Sebron;Hans Tschürtz;Peter Krebs	2018		10.1007/978-3-319-97925-0_6	system lifecycle;concentric;shell model;control unit;control engineering;safety engineering;computer science	Robotics	-55.74943860115838	23.276965705669156	107306
562dfbf025baddfbcf0214a067ff84dcb94f01e4	template-based extensible prototyping for creativity- and usability-oriented knowledge systems development		In knowledge-based systems (KBS) development, there still is a lack of research regarding user interface (UI) design and (usability) evaluation. Thus, especially KBS UIs still often are developed in a rather ad hoc manner, lacking reusability of proven solutions and potentially valuable experimentation with design alternatives and their thorough evaluation. We propose the tailored KBS prototyping and engineering tool ProKEt for practically supporting Template-based Extensible Prototyping, a technique for more efficient, affordable, and UI design/usability evaluation oriented KBS development. Further, we report current projects where both the approach and the tool provided valuable support.	hoc (programming language);knowledge-based systems;mouse tracking;prototype;software engineering;usability;user interface design	Martina Freiberg;Frank Puppe	2012				SE	-49.32503175990086	23.688802874202533	107315
0d741217840d4fcb126786e536a7de41edb288eb	a framework for acquisition and application of software architecture evolution knowledge: 14	architecture evolution knowledge;architecture centric software evolution;info eu repo semantics article;software architecture;software evolution;evolution pattern;evolution patterns	Software systems continuously evolve as a consequence of frequent changes in their functional requirements and the environment surrounding them. Architecture-centric software evolution (ACSE) enables changes in software structure and behaviour while abstracting the complex implementation-specific details. However, due to recurring evolution there is a need for solutions that enable a systematic reuse of frequent changes in software architectures. In recent years, architecture change patterns and evolution styles proved successful in promoting reuse expertise to tackle architecture evolution. However, there do not exist any solutions that enable a continuous acquisition and application of architecture evolution knowledge to systematically address frequent changes in software architectures. In this paper, we propose a framework PatEvol that aims to unify the concepts of i) software repository mining and ii) software evolution to enable acquisition and application of architecture evolution knowledge. In the proposed PatEvol framework, we present knowledge acquisition (architecture evolution mining) to enable post-mortem analysis of evolution histories to empirically discover evolution-centric knowledge. Furthermore, we support reuse of discovered knowledge to enable knowledge application (architecture evolution execution) that enables evolution-off-the-shelf in software architectures. Tool support facilitates the knowledge acquisition and knowledge application processes in the PatEvol framework.	association control service element;functional requirement;knowledge acquisition;software architecture;software evolution;software repository;software system	Aakash Ahmad;Pooyan Jamshidi;Claus Pahl	2013	ACM SIGSOFT Software Engineering Notes	10.1145/2507288.2507301	enterprise architecture framework;reference architecture;software visualization;software architecture;space-based architecture;database-centric architecture;software mining;computer science;systems engineering;engineering;knowledge management;applications architecture;software evolution;software framework;software development;software design description;software engineering;software construction;data mining;software architecture description;resource-oriented architecture;systems architecture	SE	-60.055248630458905	22.836715474736074	107446
409ad62e11c65713c299cbb6592109b8058827d2	advanced queueing models for quantitative business process analysis		Quantitative analysis of business processes facilitates the computation of quantitative properties of a business process, such as the average sojourn time and cost of cases of the process. Moreover, it allows for what-if analysis, by enabling the computation of such properties for alternative business process designs, without requiring those designs to be implemented in practice. This paper presents a novel technique for quantitative analysis that is both fast and generally applicable. The technique is developed as an extension of the state-of-the-art in queueing network analysis, by lifting some of the restrictions that are imposed by existing techniques. In particular, it enables precise quantitative analysis of business process models that contain many-to-many relations between tasks and resources (via roles). As a consequence, the technique presented in this paper allows for quantitative analysis that is more generally applicable than existing queueing network analysis techniques and only takes a fraction of the execution time required by existing simulation techniques. In doing so, it paves the way to advanced analysis techniques, such as prescriptive analytics.	approximation algorithm;business analysis;business process;computation;ergodic theory;fork (software development);lifting scheme;many-to-many;mathematical optimization;network theory;oracle advanced queuing;parallel computing;process modeling;queueing theory;run time (program lifecycle phase);simulation;time complexity;usability	Remco M. Dijkman;Ivo Adan;Sander Peters	2018	2018 44th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2018.00050	business process;task analysis;systems engineering;computer science;network analysis;prescriptive analytics;business process modeling;computation;queueing theory;business analysis	SE	-59.7966204585783	18.480813443679885	107447
576426fbcd9e603deca42d2ee803dc659452d7b7	essential use cases and responsibility in object-oriented development	object oriented;use case;user interface design	"""#"""" %$ !#"""" & """" '# '#! (*),+. '#! /' + 0 1 ' 2 . (* 34 56'# 7 8( """" / 0+9) +9 :& 7(; 5 * < = 7 3> ? @+A' 1 +A . ! CB 3D) 5 ' (* !E F G H %(*5 '# ?I )J' ? .K. :& 7) ' 5 3> L5 ' ; =? 7 . ! M 'N D """" 3O ? ' '# ?:& '# / 2 P '# !N 3> # @ 3>56'# !> $ ' Q6 C . . ( !F$R' QE' S """" M' *I% )J' .S. :& ' 5 3> 6 """" D +A . ! T U '#3>5 #BWVX . 6 N"""" ' $Y ) * / . :# '# ?I )J' .F. :& ' 5 3> . 7 7( $Z 7 """" '# L ([ :& !F '# \ 6 ' $Z ![ ] +^ . :& ' 5 3> < . '# ?I )J' ? .[. :& ' 5 3> 'G5 ' . 5 ^B_VK' Q? !S$Z 7 """"X > 2(* . ; '#3> > *) 0` 56 . +A """" N 6 a bS 7(* [ c Q& S . : !# _' + !d5 W 4 2 K U . """" K '#3>3>'# T:#' (c' +L 56' 7 > 0 . !# F . 7 7(W+9 ' 3e """" 2 U M '[ """" U' *I% G f """" 7 . !# \B 1. INTRODUCTION g M ] L """" G 5 . 6 Z5 L+9' ] 5* !2 ) = 3> N+9' S'# ?I )J' ? . ' +9 8$ . :# '#5 3> ? . """" (N ]$Z . (N 5 56' . E3>' . !; ! ! Z . . ) :# '#5 3> ? ;5* ' Bih ' ? S .Xj ' 0Q $R' ' .@k dl\m n o p q r p0s t8p0u p vKwUp0m x o szy { | ' . . p0m m p0s t^x^n#} ~?m pW n m p0mE $ 7 > 56 7(D 'G 6 ] ? !#"""" %$ !#"""" * . 0""""*) '# '#! (?)J+[ 'f 5 56' F F +A . !# \Bi '# ' $Z ! X '# ?:& '# ]5 ' ] ? L W [$R'# . 6 W . 'F5 ' . L """" L 0 +A . !# C * """" C *'# L """" . ! $R > ' 3>5 #  ? ] S D ' . 6 E . ? ' 3>' K ' ?:& '# M i S3U """"z3>' f '# K . . .. 5 ' >' +G i (* 3 . 7 > +^ . ! CB g +9' 7( !; ]  '; M3>' ' ) :# ' +9' 3 = 7 G 0@' / ' G 3> 1 .K. ( G$ ' Q ' W """" 2'# ?I )J' ? .f. :& ' 5 3> C """" 2 0 M +^ . !# _ ] '#3>5 #B 8 W """" L5 56 @$R U `*5 ' ; """" U 5 5 ' K' +< Copyright  . . L' # P 3>56 '*  #?#B . 7 0 (E '>'# ?I 0 )8' . ' +9 8$ . :& '#5 3> BRVX 56 . """" P * < 1$ '# . $R' QRI / 1$R * ' *:# ' * <  L !L56'# /+A' ' *I% )J' . . ! C\ """" L """" '# '#! (H . 56 . ; ' . 6 0 M 5 56' = 7 3> ? F!& """" !* 6 _ """" 0 S$R' . 6 _ N . 'S 56 7+9( . G """" ; D'# (W :# ? G 'N """" . !# \/ . """" Z """" M * :? 8([' +/ ? P G Z$R' . 6 ] 5 56' ' 3>3F '# E 6 %$ . :& ' 56 ] . Q# """" ' . B VX 2 6 !# H !N ?  U G M'# * M5* 3> G = 0) 3> >!& """" !K ' '# ^BVX W ' $ !#!# [ """" [ ; U 7 2+A' G'# ?I 0 )8' . ' +9 8$ . :& ' 5 3> E! 0 ^ . . . """" :& ] !# a ] . : ! ' :& R '# *) :& '# \ M B VX ;"""" :# ;+9'# * M!# 1 7 '> 56' B R"""" ;a ]$Z"""" $R f 56 . bT """" S M i _ . :& H'# ?I ) ' .[. ! . 7 7( $Z 7 """" '# * Ra $ !F3>' ] ' ' *:# ' G f BOR"""" K' """" _ 7 S$R i 7) 5 . BL f S """" _ ; i W5 ' :? . f5 ^ '#56 0 '# 1! . ;'# S"""" ' $ '>3>' :& 'N _' *I% )J' . . ! _+9 ' 3 """" G = 7 3> B< ' """" 0 Z """" ] 56'# 7) M5* ' :? . G > '#3>3>' W:&' (W """" L 5 56' M 3> 7 %(T+9' $R . D . Q $ . F 6 8$R  N . ' *I% BdR"""" E N F """" 6 E ] ; """" ' $'# 7(H """" F F U' + """" D D # 1$ > ; '> . +-(S5 ' + ; $Z"""" """"W W 6 G . ' 3N Q# L """" L =? 7 3> R!& """" !>3>' M D B R"""" 5 56 0 L ]' !&  . Z+A' ' $Z B VX G 6 ! W$Z 7 """"H W *) ' . '# F 'L R . !L """" 5 """" '# '#5 """" ( . :& ' 56 . (Eh '# G .[j ' Q $R' ' . . '#3>5 ! """" 3 '[ '# ?:& ? ' P F B2R"""" C @ H '# K* 6$ . 0) 6 ;"""" ' $ 'F$ 7 ; P G @ . M ' )J5 (E ' :& 7+-([ """" R """" ([ L ' 0 ] . ' B  * ' S¡F """" ' $Z """" ' $c ? R  F 6 . ' . ! F' *I% )J' . (* 3> & ¢ !G' D """" '# ]' +@ 56' 7 +A' R 6' """"> )  > 2 . '# ?I )J' .X. !# C 1 . . ! U """" ' ] ` 3>5 #B * '# W£25 5 R+A' Z$ 7 !D ) Z E Bz ? '# d¤H """" . > '#3> [5 0 """"H !N / ; ]+A' G (* 3> $Z """" '# * """"? 3N i . :& '#5 3> G5 '  . 25 ' . ! CB1VK / """" . P . $ ' QG ; '# F¥? . a 7( 5 Z'# ] ' ' B"""	agile software development;emoticon;google+;query expansion;rpgツクールvx value! +ツクールシリーズ素材集 和;shebang (unix)	Robert Biddle;James W Noble;Ewan D. Tempero	2002			user interface design;simulation;systems engineering;engineering;user interface;engineering drawing	Theory	-49.662988683528944	23.02491115735064	107501
893180b078ab1469ba40f32f07204bd88bb9db89	software engineering for large-scale multi-agent systems: selmas'2002	multi agent system;maintenance;software agent;software engineering large scale systems multiagent systems software agents security scalability maintenance permission object oriented modeling production systems;satisfiability;software configuration management;software engineering;software agents;large scale;permission;agent technology;production systems;scalability;large scale distributed systems;security;object oriented modeling;research impact;large scale systems;multiagent systems	Objects and agents are abstractions that exhibit points of similarity, but the development of agent-based software poses other challenges to software engineering since software agents are inherently more complex entities. In addition, a large-scale multi-agent system needs to satisfy multiple stringent requirements such as reliability, security, interoperability, scalability, reusability, and maintainability. This workshop brought together researchers and practitioners to discuss the current state and future direction of research in software engineering for large-scale multi-agent systems. A particular interest was to understand those issues in the agent technology that difficult and/or improve the production of large-scale distributed systems.	agent-based model;distributed computing;entity;interoperability;multi-agent system;requirement;scalability;software agent;software engineering	Carlos José Pereira de Lucena;Alessandro F. Garcia;Andrea Omicini;Jaelson Brelaz de Castro;Franco Zambonelli	2002		10.1145/581339.581428	software security assurance;reliability engineering;reusability;software engineering process group;computer science;systems engineering;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software agent;software engineering;multi-agent system;software construction;systems development life cycle;software walkthrough;resource-oriented architecture;software deployment;software requirements;software metric;software system	SE	-61.184377442436414	24.15455382624288	107512
a5f854b73d08e93d609590903b088ea85dc76024	liquidml: a model based environment for developing high scalable web applications		The scalability of modern Web applications has become a key aspect for any business in order to support thousands of concurrent users while reducing its computational costs. However, existing model driven web engineering approaches have been focus on building Web applications that satisfy functional requirements while disregarding “technological” aspects such as scalability and performance. As a consequence, the applications derived from these approaches may not scale well and need to be adapted. In this paper we present the LiquidML environment, which allows building Web applications using a model-based approach. In contrast with existing approaches, aspects that help to improve the scalability of a Web application are modeled as first class citizens and as a consequence the applications obtained scale better than its counterparts.	web application	Esteban Robles Luna;José Matías Rivero;Matias Urbieta	2014		10.1007/978-3-319-08245-5_41	web modeling;world wide web	Web+IR	-58.93455837729476	21.15515633005071	107544
c3738967021b82731739c550bb52bb1d508d7e50	re-engineering blue financial system using round-trip engineering and java language conversion assistant	financial system;information and communication technology;application development;programming language;software architecture;object oriented;legacy software	Conversion of legacy software applications into a new technology platform is common in many of today’s ICT (Information and Communication Technologies) companies. The objective is to improve performance, as a result of modeling important aspects and features through the development of conversion technologies. Much focus has been made on devising efficient methodologies in software architecture research. This paper presents a combination of round-trip engineering (RTE) and use of JAVA Language Conversion Assistant (JLCA) to migrate legacy software applications developed in multiple programming languages into a uniform object-oriented platform. This re-engineering process is applied to MB-Risk Management’s BLUE Financial System software. An automated process is derived to migrate code from VJ++ (Visual JAVA TM ), C, and C++ (as used in BLUE ) to a consistent C# platform. The results of conversion show an overall efficiency of 93% of full code conversion for this automated process.	c++;java;legacy system;programming language;risk management;round-trip engineering;software architecture	Salem Y. Al-Agtash;Tamer Al-Dwairy;Adnan El-Nasan;Bruce Mull;Mamdouh Barakat;Anas Shqair	2006			programming language;application programming interface;software engineering;first-generation programming language;real time java;java annotation;round-trip engineering;strictfp;java;java modeling language;computer science	SE	-53.48201635070167	28.329586992682064	107758
b5104435bac4f814887c93e528e0823428adb81d	model-driven separation of concerns for service robotics	code generation;service robotics;separation of concerns;domain specific languages	Robotics currently adopts model-driven engineering focusing software modeling languages. This forces domain experts to employ these languages instead of enabling application of more appropriate DSLs. This ultimately produces monolithic, hardly reusable applications. We present an infrastructure for the development of service robotics applications employing DSLs aimed at domain experts and tailored to domain challenges. It facilitates separation of concerns of participating robotics, domain, and software engineering experts and integrates their models via a component & connector reference architecture and a combined code generation framework. The infrastructure was successfully deployed and evaluated with robotics manufacturers, caregivers, and software engineers in a German hospital. We believe that model-driven engineering with languages tailored to the various stakeholders’ needs can greatly facilitate robotic application engineering.	actor model;application domain;code generation (compiler);model-driven architecture;model-driven engineering;model-driven integration;modeling language;reference architecture;robot;robotics;separation of concerns;software architecture;software engineer;software engineering	Kai Adam;Arvid Butting;Robert Heim;Oliver Kautz;Bernhard Rumpe;Andreas Wortmann	2016		10.1145/3023147.3023151	domain analysis;simulation;computer science;systems engineering;domain engineering;computer engineering	SE	-51.258177394437915	23.499981822894426	107773
b6ce0ba24844a9b6d206ac3eb38d54d64a2630db	simprocess iii: object-oriented business process simulation	system configuration;aerodynamics;business graphics;object oriented programming;companies;object oriented modeling business process re engineering costs computational modeling aerodynamics animation process planning computer simulation companies predictive models;business process simulation;computational modeling;object oriented;business data processing;animation;object oriented business process simulation;simprocess iii;predictive models;proposed changes;technical report;process planning;business graphics software packages digital simulation object oriented programming systems re engineering business data processing computer animation;computer animation;business process re engineering;animated graphics;model configuration simprocess iii object oriented business process simulation business process re engineering animated graphics proposed changes;computer simulation;object oriented modeling;business process;digital simulation;software packages;model configuration;systems re engineering	SIMPROCESS III combines the principles of business process re-engineering, the power of simulation, and the clarity of animated graphics to help understand and predict the consequences of proposed changes to business systems. SIMPROCESS III is designed to answer questions quickly-with no programming. You pose a question, graphically configure a model, run the simulation, and reach conclusions. You then run the model with proposed changes to close in on the system configuration that best suits your needs. This paper describes who should use SIMPROCESS III, the types of systems SIMPROCESS III can model, and how a model is constructed.	business process;computer animation;graphics;simulation;system configuration	Jeffry Jones	1995		10.1145/224401.224683	computer simulation;simulation;aerodynamics;computer science;systems engineering;software engineering;programming language;object-oriented programming	Robotics	-59.263004000312165	19.686169273804996	107810
1f8480041bf2b630d963a8dd117245013004a6a6	methodology support for the model driven architecture	formal specification;software systems;systems analysis formal specification software architecture;software engineering;model driven development;software architecture;agile methodologies;systems analysis;formal specification model driven architecture software engineering object management group software system development model driven software development methodology agile methodology;software development;model driven software development;programming context modeling computer architecture software engineering standards development concrete software standards engineering management software systems abstracts;model driven architecture	Model-driven approaches to software engineering have expanded their influence in recent years, with Object Management Group's model-driven architecture (MDA) being the major force behind this boost. However, despite its merits, MDA remains insufficient for software system development, in the sense that it does not provide a concrete and comprehensive process for governing software development activities. There is therefore a strongly felt need for new model-driven software development methodologies. In this paper we review a number of existing model-driven methodologies, and propose a general framework for model-driven development (MDD) based on MDA. The framework can be used for assessing and comparing methodologies, engineering new methodologies, and adapting existing ones so that they meet the special requirements of the model-driven approach. We have used the framework herein to show how agile methodologies fare in this model-driven development context.	agile software development;model-driven architecture;model-driven engineering;requirement;software development process;software engineering;software system	Fatemeh Chitforoush;Maryam Yazdandoost;Raman Ramsin	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.69	software architecture;systems analysis;personal software process;architecture tradeoff analysis method;verification and validation;computer science;systems engineering;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;formal specification;agile software development;software architecture description;empirical process;resource-oriented architecture;lean software development;software deployment;software development process;software system;computer engineering;software peer review	SE	-58.13871537100324	26.29821837425094	108186
a6a256b462bdf53fada7c68794bdbabc3b64e345	a formal model of design-patterns based design	model design;formal model;specification;design pattern;design patterns	In this paper we present a formal model to represents pattern-based design of an application. We represent Design-patterns in form of their Structural, Behavioral and Contractual aspect. We have modeled design in terms of Design-patterns, their Instances, Glue: additional code required to bind patterns together in the design, Operators: instantiation, evolution and composition and their required Parameter-Sets.	formal language;mathematical model;software design pattern;universal instantiation	Pushpendra Bahadur Singh;Banshi Dhar Chaudhary	2009		10.1145/1506216.1506245	software design pattern;probabilistic design;computer science;systems engineering;design pattern;programming language;structural pattern;engineering drawing;specification;algorithm;specification pattern	EDA	-49.7643183843704	27.205411748254996	108218
e8b9f39b49124ea1acc3f8af7c9ba367a595cbeb	dealing with non-functional requirements in distributed control systems engineering	manufacturing systems;distributed control system;industrial plants;informing science;manufacturing systems distributed control industrial plants;distribution automation system;non functional requirement;industrial production;automation distributed control software inductors software engineering fault tolerance;point of view;distributed control;mechatronic systems;automation technology nonfunctional requirement distributed control systems engineering industrial production plant mechatronic system automation system	Industrial production plants are highly complex mechatronic systems. In today's automation systems a trend for distribution of control functions can be observed. The hereby emerging challenges lead to delays and interruptions in automation projects. Especially non-functional requirements are hard to specify for later engineering phases. Therefore, a holistic engineering approach will be developed. As a first step, important challenges for the development of distributed automation systems are identified in this paper. Based on this, non-functional requirements derived from an information science point of view are adapted to the specifics of automation technology.	control engineering;control function (econometrics);distributed control system;functional requirement;holism;information science;mechatronics;non-functional requirement;systems engineering	Timo Frank;Martin Merz;Karin Eckert;Thomas Hadlich;Birgit Vogel-Heuser;Alexander Fay;Christian Diedrich	2011	ETFA2011	10.1109/ETFA.2011.6059132	control system security;industrial production;industrial control system;systems engineering;engineering;computer-automated design;process automation system;instrumentation and control engineering;control theory;distributed control system;industrial technology;non-functional requirement;production engineering;totally integrated automation;manufacturing engineering;computer engineering	SE	-60.82774224435563	19.057388152450784	108228
41dfda7bc94eec947228cd49a099735a2cdd5005	foundations for software configuration management policies using graph transformations	graph transformation;software configuration management;configuration management	Existing software configuration management systems embody a wide variety of policies for how artifacts can evolve. New policies continue to be introduced. Without a clean separation of configuration management policies from configuration management mechanisms, it is difficult to understand the policies as well as difficult to reason about how they relate. We introduce a formal foundation for specifying configuration management policies by viewing the policies in terms of graph transformation systems. Not only are we able to precisely capture the semantics of individual policies, we can, for the first time, describe formal properties of the relationship between policies.	graph rewriting;software configuration management	Francesco Parisi-Presicce;Alexander L. Wolf	2000		10.1007/3-540-46428-X_21	configuration management database;software configuration management;computer science;systems engineering;knowledge management;management science;configuration management;configuration item	SE	-54.152427031848696	22.690212674663357	108553
b46878a4d0071224350315b7f3b6a70f863fca3d	a distributed service oriented system for gui map generation	automatic gui map generator;service oriented system;user interface;service orientation;distributed computing;software architecture;distributed computations;gui;gui map	Contemporary programs come with complex user interfaces hard to analyze without automated support. There are many applications when precise analysis of a system GUI organization is needed and required --- e.g. generation of GUI map. Unfortunately it requires a lot of complex computations. In this paper we show how this task can be automatically accomplished by using specific software architecture --- distributed service oriented one.	computation;graphical user interface;software architecture	Pawel Brach;Jacek Chrzaszcz;Janusz Jablonowski;Jakub Swiatly	2011		10.1145/2023607.2023621	software architecture;computer science;operating system;software engineering;graphical user interface;database;programming language;user interface	SE	-49.837520067519456	29.166922592552886	108626
fbadc659e76b53fd8d31e8cb9f290641b4f3ba39	docline: a method for software product lines documentation development	software product line	The DocLine method designed for developing documentation for software product lines is presented. The method makes it possible to reuse document fragments with adaptation to a particular usage context. The method provides the Documentation Reuse Language (DRL) that has a graphical part (for designing the structure of documentation packages) and a text part (for implementing the documentation). It also describes a process for developing documentation and a toolset architecture based on the DSM approach and Eclipse GMF technology.	documentation;driven right leg circuit;eclipse;graphical modeling framework;graphical user interface;software product line	D. V. Koznov;Konstantin Romanovsky	2008	Programming and Computer Software	10.1134/S0361768808040051	common source data base;computer science;technical documentation;database;internal documentation;programming language;software documentation;software system	SE	-48.75440822947002	25.201780495597994	108758
f5878e749eca6b7aa1391ee6cd90210e476a5a0f	design space abstraction and metamodeling for embedded systems design space exploration	uml;model transformation;design space;embedded system;embedded system design;graph products;model driven engineering;design space exploration	In this paper, we present a design space exploration (DSE) method for embedded systems, which represents the design space as a categorical graph product, in order to overcome the challenge of performing multiple DSE activities, such as task mapping, processor allocation, and software binding. Moreover, the method adopts a Model-Driven Engineering (MDE) approach, defining a design space metamodel to represent the categorical graph product and other DSE concepts, such as solutions, costs, and DSE activities. Furthermore, exploiting the MDE approach, we use model-to-model transformation rules to implement the design constraints, which guide and prune the design space. The method is applied to the design of a real-life application, and experiments demonstrate its effectiveness.	algorithm;design space exploration;embedded system;experiment;exploration problem;functional requirement;graph product;interdependence;mathematical optimization;metamodeling;model transformation;model-driven architecture;model-driven engineering;modeling and analysis of real time and embedded systems;non-functional requirement;object constraint language;qvt;real life;systems design;type system	Marcio F. da S. Oliveira;Francisco Assis M. do Nascimento;Wolfgang Müller;Flávio Rech Wagner	2010		10.1145/1865875.1865880	unified modeling language;embedded system;model-driven architecture;real-time computing;computer science;systems engineering;theoretical computer science;software engineering	EDA	-48.40457532821443	29.66873277331697	109013
bc0f07c6eef022d1c2870dd1626ebf7b8283d59e	using simulation to evaluate error detection strategies: a case study of cloud-based deployment processes	simulation;process modeling;deployment process	The processes for deploying systems in cloud environments can be the basis for studying strategies for detecting and correcting errors committed during complex process execution. These cloud-based processes encompass diverse activities, and entail complex interactions between cloud infrastructure, application software, tools, and humans. Many of these processes, such as those for making release decisions during continuous deployment and troubleshooting in system upgrades, are highly error-prone. Unlike the typically well-tested deployed software systems, these deployment processes are usually neither well understood nor well tested. Errors that occur during such processes may require time-consuming troubleshooting, undoing and redoing steps, and problem fixing. Consequently, these processes should ideally be guided by strategies for detecting errors that consider trade-offs between efficiency and reliability. This paper presents a framework for systematically exploring such trade-offs. To evaluate the framework and illustrate our approach, we use two representative cloud deployment processes: a continuous deployment process and a rolling upgrade process. We augment an existing process modeling language to represent these processes and model errors that may occur during process execution. We use a process-aware discrete-event simulator to evaluate strategies and empirically validate simulation results by comparing them to experiences in a production environment. Our evaluation demonstrates that our approach supports the study of how error-handling strategies affect how much time is taken for task-completion and error-fixing. © 2015 Elsevier Inc. All rights reserved.	cloud computing;cognitive dimensions of notations;continuous delivery;deployment environment;error detection and correction;interaction;modeling language;process modeling;sensor;simulation;software deployment;software system	Jie Chen;Xiwei Xu;Leon J. Osterweil;Liming Zhu;Yuriy Brun;Leonard J. Bass;Junchao Xiao;Mingshu Li;Qing Wang	2015	Journal of Systems and Software	10.1016/j.jss.2015.08.043	real-time computing;simulation;computer science;systems engineering;engineering;operating system;software engineering;process modeling	SE	-55.6667493657724	29.395578420177014	109191
9f89d8172fcedfcc16c03919399d0fbe4bdab3cb	managing unanticipated evolution of software architectures	software architecture;software evolution	Few existing approaches towards architectural evolution deal with unanticipated evolution. This is an important restriction, since a lot of architectural changes are very di cult to anticipate. The reuse contract formalism has been designed speci cally to deal with unanticipated software evolution, and has already proven its practical use in di erent domains. We claim that the reuse contract approach can be applied to the domain of software architectures, to manage unanticipated evolution of software architectures.	design by contract;semantics (computer science);software architecture;software evolution	Kim Mens;Tom Mens;Bart Wouters;Roel Wuyts	1999			reference architecture;software visualization;computer architecture;systems engineering;package development process;software evolution;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;resource-oriented architecture;software deployment;software system	SE	-53.89878977991247	27.195969300488088	109279
439e27244c07e996f45e8a460c54095efbea5b99	a framework for web applications testing	testing framework;software metrics;software testing;software metrics internet program testing;web testing process web application testing framework process modeling;testing;requirement analysis;web testing process;internet web applications testing software testing process testing requirement analysis test case generation test case selection testing result analysis testing result measurement;test case generation;internet;program testing;web application;process modeling;process model	Web application testing is concerned with numerous and complicated testing objects, methods and processes. So a testing framework fitting for the properties of Web application is needed to guide and organize all the testing tasks. Based on the analysis for Web application characters and traditional software testing process, the process for Web application testing is modeled, which describes a series of testing flows such as the testing requirement analysis, test cases generation and selection, testing execution, and testing results analysis and measurement. Furthermore, the realization techniques are also investigated so as to integrate each testing step and implement the whole testing process harmoniously and effectively. Thus the framework is suitable for the Internet environment and can guide the Web application testing actively and availably.	internet;requirements analysis;software testing;test case;web application;world wide web	Lei Xu;Baowen Xu	2004	2004 International Conference on Cyberworlds	10.1109/CW.2004.7	non-regression testing;test strategy;keyword-driven testing;black-box testing;software performance testing;white-box testing;manual testing;system integration testing;integration testing;computer science;acceptance testing;software reliability testing;functional testing;cloud testing;process modeling;software testing;real-time testing;system testing;world wide web;web testing	SE	-56.372009744772754	31.34559969141178	109326
a0702c7354f2347cadffb8aaad83c4708f3185a6	came: component assembly metrics extraction using uml	software metrics;uml;xml;cbs;component diagram;sax parser;xmi	In Object-Oriented software development, complexity metrics help software engineers to identify the deficiencies in the design of the software system that are likely to become problem points in the subsequent phases of the SDLC, like testing and maintenance. Metrics for Component Based Software Development (CBSD) have also been proposed by the researchers. Lately the emphasis has been on metrics that are applicable during early phases of the SDLC. The XML Meta Data Interchange (XMI) standard has been implemented in most of the commercial and open source UML tools. It is now possible to automate the metrics extraction procedure right from the UML design documents. Detection of design deficiencies early in the design phase saves a lot of time and effort and results in a more maintainable design. In the present paper, we discuss the design and implementation of a metrics tool for CBSD. We have implemented component based metrics in a parserbased tool, which hereafter we refer to as CAME (Component Assembly Metrics Extraction), to calculate metrics from UML design documents. CAME is capable of generating software metrics proposed by researchers for Component Based Software Systems. We demonstrate our tool using UML component assembly diagrams for a University Case Registration System (UCRS) and its representation in UML and metrics extraction procedure.	diagram;information extraction;list of unified modeling language tools;open-source software;software development;software engineer;software metric;software system;synchronous data link control;xml metadata interchange	Jawwad Wasat Shareef;R. K. Pandey	2013	ACM SIGSOFT Software Engineering Notes	10.1145/2492248.2492273	reliability engineering;unified modeling language;simple api for xml;xml;uml tool;computer science;systems engineering;software engineering;applications of uml;database;component diagram;software metric	SE	-58.730186626217666	31.54005638804488	109420
99573856c283ed51b9bae32a4515621e29d874f2	quality function deployment usage in software development	developpement logiciel;levantamiento;quality function deployment;qualite;total quality management;quality;desarrollo logicial;leve;software development;controle qualite;quality control;survey;calidad;control calidad	The authors survey major software vendors' use of quality improvement techniques during the early stages of the system development life cycle.	quality function deployment;software deployment;software development process;systems development life cycle	Stephen Haag;M. K. Raja;Lawrence L. Schkade	1996	Commun. ACM	10.1145/234173.234178	quality function deployment;quality control;total quality management;software development	SE	-62.06815487433381	28.17517514756041	109544
dddebeded8aded2ea4ee6d7bf3e9034599cabc10	applying code analysis and 3d design pattern grouping to facilitate program comprehension	modeling technique;3d visualization;uml;visual design;program comprehension;software systems;3d design pattern grouping;object oriented programming;design pattern visualization;information overload;forward engineering;programming model;unified modeling language data flow analysis object oriented programming program visualisation;source code reverse engineering;design pattern;unified modeling language;data flow analysis;design pattern visualization 3d design pattern grouping program comprehension software systems source code abstractions forward engineering source code reverse engineering information overload 3d representation uml source code analysis;3d representation;design patterns;source code;source code analysis;program visualisation;source code abstractions;reverse engineering;design patterns 3d visualization program comprehension;pattern analysis data visualization unified modeling language algorithm design and analysis bridges reverse engineering pattern recognition concrete production facilities computer science	The increasing size and complexity of software systems introduces new challenges in comprehending the overall structure of programs. Modeling languages and notations were introduced to provide abstractions from existing source code during forward engineering. However, these same modeling techniques and notations fail during source code reverse engineering due to: (1) Information overload; and (2) the existence of a conceptual gap between the abstractions derived during forward and reverse engineered. Our tool uses a 3D representation for UML in combination with source code analysis to facilitate the comprehension process. We also address issues of crosscutting, navigation, and the use of animation to visualize design patterns	information overload;list comprehension;model-driven architecture;program comprehension;reverse engineering;software design pattern;software system;static program analysis;unified modeling language	Juergen Rilling;Vu-Loc Nguyen	2005	3rd IEEE International Workshop on Visualizing Software for Understanding and Analysis	10.1109/VISSOF.2005.1684320	unified modeling language;computer science;systems engineering;theoretical computer science;programming language;static program analysis;source code	SE	-53.70352361627893	31.17505971727478	109569
20d0bd6eaa309dc2fcf64e378d2489d8e6da9378	design patterns in enterprise application integration for e-learning arena	dependency injection;e learning;web services;design patterns;enterprise service bus;service oriented architecture;enterprise application integration	Pattern based design is an effective way to avoid an expensive process of reinventing, rediscovering and revalidating agnostic software artifacts. The Enterprise Application Integration (EAI) leverages the reusability factor of an application by applying decoupling and location transparency in the communication of the disparate applications and services. Design patterns are reusable solutions to solve recurring issues pertaining to the Functional, Non-Functional and Implementation tasks. The e-Learning is an ever growing and expanding arena. It has huge number of disparate applications and services that can be exposed over a ubiquitous media, such as the Internet, to the various kinds of end users. Therefore, the EAI is an important aspect in the e-Learning Arena in order to increase the high reusability and application decoupling factors. In this paper, we are imitating the ModelView-Controller (MVC) design patterns in order to explore the other composite patterns for an efficient integration of the applications and services. The demarcation of a Functional (View) and an Implementation (Model) task can be achieved deliberately by inducing an Integrator (Controller). The Controller can be further enriched to encapsulate certain Non-Functional activities such as security, reliability, scalability, and routing of request. This enables the separation of an Integration Logic from that of a Functional Logic (Client Application) and an Implementation Logic (Service). The Controller can be viewed by using the compound design pattern of the Enterprise Service Bus (ESB). This paper discusses how the Dependency Injection pattern is used in the ESB pattern for the integration of the e-Learning applications.	controller (control theory);coupling (computer programming);demarcation point;dependency injection;enterprise application integration;enterprise service bus;functional requirement;internet;model–view–controller;routing;scalability;software design pattern	Sidhant Rajam;Ruth Cortez;Alexander Vazhenin;Subhash Bhalla	2010			real-time computing;engineering;operations management;database	SE	-48.80934303843856	21.795661215948236	109712
39ca1e8ddc91d1441d0346e20b6ffaf8429ce450	validation and verification of simulation models	model verification;computational modeling performance evaluation computer simulation educational institutions data engineering computer science accreditation testing large scale systems costs;conceptual model;computational modeling accreditation random variables computer simulation educational institutions computer science problem solving decision making application software testing;model validation;formal verification digital simulation;formal verification;data validity simulation models formal verification formal validation model validity operational validity;model development;accreditation;technical report;data validity simulation model validation simulation model verification conceptual model validity operational validity;simulation model;data validation;validation and verification;digital simulation;accreditation digital simulation decision making formal verification	In this paper we discuss validation and verfication of simulation models. Four different approaches to deciding model validity are described; two different paradigms that relate validation and verification to the model development process are presented; various validation techniques are defined; conceptual model validity, model verification, operational validity, and data validity are discussed; a way to document results is given; a recommended procedure for model validation is presented; and accreditation is briefly discussed.	simulation;verification and validation	Robert G. Sargent	1992	Proceedings of the 2004 Winter Simulation Conference, 2004.	10.1145/167293.167311	reliability engineering;verification and validation of computer simulation models;verification and validation;simulation;formal verification;computer science;systems engineering;conceptual model;technical report;data validation;simulation modeling;accreditation;regression model validation;programming language;validation rule	EDA	-60.85328785776199	31.156066325354356	110000
f62378103f81372794969d1bc1e680a159958eea	workshop preview of the 15th workshop on domain specific modeling (dsm 2015)	modeling languages;code generation;metamodeling;domain specific languages	Domain-specific languages provide a viable and time-tested solution for continuing to raise the level of abstraction, and thus productivity, beyond coding, making systems development faster and easier. When accompanied with suitable automated modeling tools and generators it delivers to the promises of continuous delivery and devops. In domain-specific modeling (DSM) the models are constructed using concepts that represent things in the application domain, not concepts of a given programming language. The modeling language follows the domain abstractions and semantics, allowing developers to perceive themselves as working directly with domain concepts. Together with frameworks and platforms, DSM can automate a large portion of software production. This paper introduces Domain-Specific Modeling and describes the SPLASH 2015 workshop, to be held on 27th of October in Pittsburgh, PA, which is the 15th anniversary of the event.	application domain;continuous delivery;devops;domain-specific language;domain-specific modeling;modeling language;programming language;software development process	Jeffrey G. Gray;Jonathan Sprinkle;Juha-Pekka Tolvanen;Matti Rossi	2015		10.1145/2814189.2833204	metamodeling;computer science;domain-specific language;electrical engineering;artificial intelligence;operating system;modeling language;programming language;code generation	SE	-50.880228123191216	24.96798224919296	110017
0c89f3b12994ed5bda3b2af6f69dd37f4777960e	a model of component-based programming	protocols;components;composition;programming paradigm;program design;contracts;refinement;glue codes;protocol composition;application programs	Component-based programming is about how to create application programs from prefabricated components with new software that provides both glue between the components, and new functionality. Models of components are required to support black-box compositionality and substitutability by a third party as well as interoperability. However, the glue codes and programs designed by users of the components for new applications in general do not require these features, and they can be even designed in programming paradigms different from those of the components. In this paper, we extend the rCOS calculus of components with a model for glue programs and application programs that is different from that of components. We study the composition of a glue program with components and prove that the components glued by the glue program yield a new component.	black box;common object request broker architecture;component-based software engineering;glue code;interoperability;lu decomposition;process modeling;programming paradigm;rcos (computer sciences);web service;yang	Xin Chen;Jifeng He;Zhiming Liu;Naijun Zhan	2007		10.1007/978-3-540-75698-9_13	composition;computer science;refinement;programming paradigm;programming language;algorithm	SE	-48.416046874680944	27.409166168514922	110171
466af35346cdc86d05766ba34ff72ce13ae3abae	guest editor’s introduction to the special section on the 2nd workshop on advances in model-based software testing (a-most’06)	software testing	The 2nd Workshop on Advances in Model-based Software Testing was held in Raleigh, North Carolina, 6 November 2006, co-located with the 17th IEEE International Symposium on Software Reliability Engineering ISSRE 2006. Workshop Proceedings have been published in the ACM Digital Library (in the ACM SIGSOFT Software Engineering Notes). Of the 10 papers submitted to the workshop, two of the best were selected and invited for revision and extension. Model-based testing automation is a promising approach for achieving effective software testing. Models of systems under test and their environments may focus on particular aspects of the requirements and thus facilitate productive testing. The approach stems from the Object Management Group’s Model Driven Architecture (OMG MDA) modelling of software systems, from the increasing availability of tools for modelling, industry standards using the OMG’s Meta-Object Facility (MOF) and its popular instance, the Unified Modelling Language (UML). In their paper ‘‘Using communication coverage criteria and partial model generation to assist software integration testing’’ Christopher Robinson-Mallett, Robert M. Hierons, Jesse Poore, and Peter Liggesmeyer consider the problem of integration testing for the components of a timed distributed software system. They assume that communication between the components is specified using timed interface automata and use computational tree logic (CTL) to define communication-based coverage criteria that refer to sendand receive-statements and communication paths. The proposed method enables testers to focus on such parts of the specification, e.g. behavior specifications or Markovian usage models that are involved in the communication between components to be integrated. A model checker is used in order to determine the coverage or generate test sequences that achieve the goal. While the process of deriving the test sequences could suffer from a combinatorial explosion, the effort required to generate the partial model is polynomial in the number of test sequences and their length. A potential additional benefit of the	automata theory;computation tree logic;digital library;distributed computing;issre;integration testing;meta-object facility;metaobject;model checking;model-based testing;model-driven architecture;polynomial;reliability engineering;requirement;sms language;software engineering notes;software reliability testing;software system;software testing;system integration;unified modeling language	Mikhail Auguston	2007	Software Quality Journal	10.1007/s11219-007-9043-2	computer science;engineering;software engineering;software testing	SE	-51.546757619059086	24.93097954834558	110257
cecd95c3ee3d378fc9fa4528c980b7d7bfbf3b61	using tactic traceability information models to reduce the risk of architectural degradation during system maintenance	program diagnostics;sensors;software maintenance;heart beat robots maintenance engineering moon computer architecture monitoring sensors;maintenance engineering;software reusability program diagnostics safety critical software software architecture software maintenance;computer architecture;software architecture;monitoring;architectural tactic tactic traceability information models software maintenance software architectures safety critical software ttim software reusable infrastructure mapping points mission critical system software intensive system;moon;safety critical software;software reusability;robots;traceability;traceability software architecture tactics;tactics;heart beat	The software architectures of safety and mission-critical systems are designed to satisfy and balance an exacting set of quality concerns describing characteristics such as performance, reliability, and safety. Unfortunately, practice has shown that long-term maintenance activities can erode these architectural qualities. In this paper we present a novel solution for preserving architectural qualities through the use of Tactic Traceability Information Models (tTIMs). A tTIM provides a reusable infrastructure of traceability links focused around a commonly implemented architectural tactic, as well as a set of mapping points for tracing the tactic into the architectural design and the implemented code. The use of tTIMs significantly reduces the effort needed to create and maintain traceability links, provides support for visualizing the rationale behind various architectural components, and delivers timely information to maintainers so that they can preserve critical architectural qualities while implementing modifications. Our approach is described and evaluated within the context of a mission-critical software-intensive system.	design rationale;elegant degradation;floor and ceiling functions;information model;mission critical;open-source software;software development;traceability	Mehdi Mirakhorli;Jane Cleland-Huang	2011	2011 27th IEEE International Conference on Software Maintenance (ICSM)	10.1109/ICSM.2011.6080779	maintenance engineering;robot;reliability engineering;software architecture;traceability;architectural pattern;systems engineering;engineering;natural satellite;sensor;software engineering;software maintenance	SE	-61.57212125673227	29.817938300025116	110327
09e37dabeab3bb8e827aaa1a6d4052903a1a9d7d	four dark corners of requirements engineering	implementation bias;domain knowledge;body of knowledge;requirement engineering;refinement of requirements;control of actions;requirement specification	Research in requirements engineering has produced an extensive body of knowledge, but there are four areas in which the foundation of the discipline seems weak or obscure. This article shines some light in the “four dark corners,” exposing problems and proposing solutions. We show that all descriptions involved in requirements engineering should be descriptions of the environment. We show that certain control information is necessary for sound requirements engineering, and we explain the close association between domain knowledge and refinement of requirements. Together these conclusions explain the precise nature of requirements, specifications, and domain knowledge, as well as the precise nature of the relationships among them. They establish minimum standards for what information should be represented in a requirements language. They also make it possible to determine exactly what it means for requirements and engineering to be successfully completed.	dark web;refinement (computing);requirement;requirements engineering	Pamela Zave;Michael Jackson	1997	ACM Trans. Softw. Eng. Methodol.	10.1145/237432.237434	software requirements specification;requirements management;business requirements;computer science;systems engineering;engineering;requirement;body of knowledge;system requirements specification;data mining;requirements engineering;engineering drawing;functional requirement;non-functional requirement;domain knowledge;requirements traceability	SE	-56.60148313693815	23.21630942054001	110385
fc0a1111e12f8f0917dc42ef741dd06fa3d68395	dynamic metrics for object oriented designs	module cohesion;software metrics;design model;early development phase;static metrics;electrical capacitance tomography;phase measurement;complex dynamics;empirical study;software design quality assessment;object oriented designs;object oriented design;application software;software complexity;real time;analysis and design;execution scenarios;dynamic software metrics;static metrics dynamic software metrics object oriented analysis object oriented design software design quality assessment software complexity module coupling module cohesion real time applications early development phase dynamic complexity object coupling execution scenarios executable design models pacemaker application case study;pacemakers;dynamic complexity;object oriented programming;executable design models;medical computing object oriented programming software metrics software quality real time systems pacemakers;dynamic metrics;design quality;medical computing;object oriented modeling electrical capacitance tomography application software electronic switching systems unified modeling language computer science read only memory ear software quality phase measurement;ear;object oriented;empirical validation;unified modeling language;object coupling;electronic switching systems;real time applications;pacemaker application;computer science;early development;object oriented analysis;and real time oo modeling;real time application;read only memory;object oriented modeling;software quality;module coupling;comparative statics;real time systems	As object oriented analysis and design techniques become widely used, the demand on assessing the quality of object-oriented designs substantially increases. Recently, there has been much research effort to develop and empirically validate metrics for OO design quality. Complexity, coupling, and cohesion have received a considerable interest in the field. Despite the rich body of research and practice in developing design quality metrics, there has been less emphasis on dynamic metrics for object-oriented designs. The complex dynamic behavior of many real-time applications motivates a shift in interest from traditional static metrics to dynamic metrics. This paper addresses the problem of measuring the quality of object-oriented designs using dynamic metrics. We present a metrics suite to measure the quality of designs at an early development phase. The suite consists of metrics for dynamic complexity and object coupling based on execution scenarios. The proposed measures are obtained from executable design models. We apply the dynamic metrics to assess the quality of a pacemaker application. Results from the case study are used to compare static metrics to the proposed dynamic metrics and hence identify the need for empirical studies to explore the dependency of design quality on each.	artificial cardiac pacemaker;cohesion (computer science);complexity;executable;real-time clock	Sherif M. Yacoub;Hany H. Ammar;Tom R Robinson	1999		10.1109/METRIC.1999.809725	reliability engineering;real-time computing;computer science;systems engineering;software engineering;programming language;object-oriented programming	EDA	-52.697575288271445	32.02550833022668	110393
44791df46c09248f24ef34145fb766fe597488c4	self-testability in unit testing	built in self test automatic testing software testing software quality costs application software finance programming software tools runtime;software quality unit testing software development project software reusability third party software self testability;unit testing;program testing;software reusability;software development;source code;software quality;software reusability program testing software quality	An often-proposed approach to decrease costs of software development projects is to reuse existing software units. Reusing software units has indeed the potential to decrease costs, but this decrease of costs has to be put in relation to the risks inherent in third-party software. In particular, third-party software units can have a high inherent complexity complicating testing, even worse, source code and other information required for testing might not be available at all. In such cases, self-testability, if the software unit has been augmented appropriately, can be a method for ensuring that the software unit reused fits into the system to be developed with respect to its quality.	algorithm;fits;norm (social);software development;test case;third-party software component;unit testing	Sami Beydeda	2005	29th Annual International Computer Software and Applications Conference (COMPSAC'05)	10.1109/COMPSAC.2005.139	reliability engineering;personal software process;medical software;long-term support;verification and validation;regression testing;software sizing;computer science;systems engineering;package development process;backporting;social software engineering;software reliability testing;software framework;software development;software engineering;software construction;software testing;unit testing;software walkthrough;programming language;software measurement;software deployment;software quality;software quality analyst;source code;software peer review	SE	-60.9962298578455	29.538692698519572	110522
068f5ba96bb94619489670da24c292954ff37ddd	survey of works that transform requirements into uml diagrams	software;pragmatics;artificial intelligence requirements transformation uml diagrams requirement engineering requirement analysis;unified modeling language artificial intelligence formal specification formal verification systems analysis;measurement;learning;inspection;requirements engineering;requirements;uml diagrams;computational modeling;state of the art;unified modeling language;artificial intelligence;unified modeling language software inspection pragmatics requirements engineering computational modeling measurement;learning requirements transformation uml diagrams state of the art artificial intelligence;transformation	In this paper, we aim to cover works that are related to the process of transforming requirements into UML diagrams, from the first works which were manual techniques in 1976, to automatic tools in 2015. In this context, we try to exhibit different approaches and to indicate their strength as well as their shortcomings. This work will help us to evaluate existing approaches and propose other alternatives for Requirement Engineering. The objective of this paper is to present an overview of various works dedicated to requirement analysis and a comparative study of these works. Also, we tried to discuss the combination of Artificial Intelligence with Requirement Engineering.	artificial intelligence;diagram;requirement;requirements analysis;requirements engineering;uml state machine	Mariem Abdouli;Wahiba Ben Abdessalem Karaa;Henda Hajjami Ben Ghézala	2016	2016 IEEE 14th International Conference on Software Engineering Research, Management and Applications (SERA)	10.1109/SERA.2016.7516136	unified modeling language;computer science;systems engineering;artificial intelligence;software engineering;applications of uml;requirements engineering;management;pragmatics	SE	-57.56237756917819	24.950754273217395	110536
6fdeac1dc3d6625e429a942898bfcf23eb10fca1	software requirements change analysis and prediction			requirement;software requirements	S. E. McGee	2014				SE	-62.771260795281876	24.671417620421163	110546
e014c9cb9e4a247613bef56a0702d17293bec62a	coverage-driven automated compiler test suite generation		Abstract   The paper presents a novel approach to automated compiler test suite generation based on the source level specification. Several coverage criteria are introduced. The application of the proposed methodology to testing the realistic programming language is discussed.	compiler;test suite	Alexey Kalinov;Alexander S. Kossatchev;Alexander K. Petrenko;Mikhail Posypkin;Vladimir Shishkov	2003	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)82625-8	computer architecture;compiler;model-based testing;compiler correctness;computer science;programming language	PL	-56.76591322823219	32.31368353402879	110639
234194281cc8a2c1c29bb50d5285bcc54c9fe87b	modeling the application domains of software engineering technologies	systematic software engineering technology reuse;software project planning;software engineering technologies;project management;software development management software reusability planning project management;software engineering;application domain modelling;improvement program planning application domain modelling software engineering technologies software development practices systematic software engineering technology reuse software project planning;improvement program planning;software development practices;software reusability;software development;application software software engineering context modeling programming technology planning project management technology management best practices packaging software measurement;planning;software development management	The effectiveness of software engineering technologies depends very much on the situation in which they are applied. In order to further improve software development practices we need to explicitly describe and utilise our knowledge about application domains of software engineering technologies. This paper suggests a modelling formalism for supporting systematic reuse of software engineering technologies during planning of software projects and improvement programmes.	semantics (computer science);software development;software engineering	Andreas Birk	1997		10.1109/ASE.1997.632850	planning;project management;personal software process;verification and validation;software engineering process group;software project management;computer science;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;management;software deployment;software development process;software requirements;software system;computer engineering;software peer review	SE	-57.60284596226327	26.946258274828008	110838
0103d51f05829b4a810a795d18e4dc3114f51f50	an automated testing framework for statistical testing of gui applications		It is known to be inherently more difficult and laborintensive to functionally test software applications that employ a graphical user interface front-end, due to the vast GUI input space. We propose an automated testing framework for functional and statistical testing of GUI-driven applications, using a combination of two rigorous software specification and testing methods and integrating them with an automated testing tool suitable for testing GUI applications. With this framework we are able to achieve fully automated statistical testing and software certification. We report an elaborate case study that demonstrates a pathway towards lowered cost of testing and improved product quality for this type of applications.	automated testing framework;formal specification;gene regulatory network;graphical user interface;hp unified functional testing;ibm notes;oracle (software testing);software engineering;test automation;test case;test plan	Lan Lin;Jia He;Yufeng Xue	2015		10.18293/SEKE2015-119	non-regression testing;test strategy;keyword-driven testing;reliability engineering;black-box testing;regression testing;orthogonal array testing;software performance testing;white-box testing;manual testing;system integration testing;integration testing;computer science;systems engineering;acceptance testing;software reliability testing;functional testing;database;software testing;system testing;graphical user interface testing	SE	-56.33698369907751	31.739178596826296	110869
3f7e29628c728b0a31517ddcddcfb9ef22b10f66	towards a refactoring catalogue for knowledge discovery metamodel	empirical study;refactoring;empirical study refactoring kdm adm;object oriented modeling software aging standards unified modeling language measurement feature extraction;software quality data mining java software architecture software maintenance;open source java application refactoring catalogue knowledge discovery metamodel quality attribute reengineering process legacy system architecture driven modernization kdm metamodel source code level fowler catalogue;adm;kdm	Refactorings are a well known technique that assist developers in reformulating the overall structure of applications aiming to improve internal quality attributes while preserving their original behavior. One of the most conventional uses of refactorings are in reengineering processes, whose goal is to change the structure of legacy systems aiming to solve previously identified structural problems. Architecture-Driven Modernization (ADM) is the new generation of reengineering processes; relying just on models, rather than source code, as the main artifacts along the process. However, although ADM provides the general concepts for conducting model-driven modernizations, it does not provide instructions on how to create or apply refactorings in the Knowledge Discovery Metamodel (KDM) metamodel. This leads developers to create their own refactoring solutions, which are very hard to be reused in other contexts. One of the most well known and useful refactoring catalogue is the Fowler's one, but it was primarily proposed for source-code level. In order to fill this gap, in this paper we present a model-oriented version of the Fowler's Catalogue, so that it can be applied to KDM metamodel. In this paper we have focused on four categories of refactorings: (j') renaming, (w) moving features between objects, (iii) organizing data, and (iv) dealing with generalization. We have also developed an environment to support the application of our catalogue. To evaluate our solution we conducted an experiment using eight open source Java application. The results showed that our catalogue can be used to improve the cohesion and coupling of the legacy system.	architecture-driven modernization;code refactoring;cohesion (computer science);java;kde display manager;knowledge discovery metamodel;language-independent specification;legacy system;list of system quality attributes;metamodeling;model-driven architecture;model-driven integration;open-source software;organizing (structure)	Rafael Serapilha Durelli;Daniel S. M. Santibáñez;Márcio Eduardo Delamaro;Valter Vieira de Camargo	2014	Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)	10.1109/IRI.2014.7051940	software mining;computer science;operating system;software engineering;data mining;database;programming language;empirical research;world wide web;code refactoring	SE	-53.75270486396442	30.53654232943322	111130
c66eb71de5320ebae86c1a0d7a832138b19f50ee	net components for the integration of process mining into agent-oriented software engineering	complexity analysis;agent oriented software engineering;data mining;software engineering;process mining;net components;process mining chains;visual modeling;software development;petri nets;petri net;modeling	Process mining is increasingly used as an analysis technique to support the understanding of processes in software engineering. Due to the close relation to Petri nets as an underlying theory and representation technique, it can especially add to Petri net-based approaches. However, the complex analysis techniques are not straightforward to understand and handle for software developers with little data mining background. In this paper, we first discuss possibilities to integrate process mining into our Petri net-based agent-oriented software engineering approach. As the main contribution, we focus on enhancing its usability and introduce a technique and tool for visually modeling process mining algorithms with net components. These can be used to build new complex algorithms as a patch-work of existing procedures and new compositions. Furthermore, they allow for an easy integration with standard tools such as ProM.	agent-oriented software engineering	Lawrence Cabac;Nicolas Denz	2008	Trans. Petri Nets and Other Models of Concurrency	10.1007/978-3-540-89287-8_6	verification and validation;software mining;computer science;systems engineering;software development;software construction;data mining;database;process architecture;goal-driven software development process	SE	-52.880467289029504	25.77864540791852	111132
6b61726de9302c2c614ca8847c0344ac746e5e8a	towards a megamodel to model software evolution through transformations	mda;complex structure;conceptual framework;large scale;megamodel;software evolution;model driven engineering;meta model	Model Driven Engineering is a promizing approach that could lead to the emergence of a new paradigm for software evolution, namely Model Driven Software Evolution. Models, Metamodels and Transformations are the cornerstones of this approach. Combining these concepts leads to very complex structures which revealed to be very difficult to understand especially when different technological spaces are considered such as XMLWare (the technology based on XML), Grammarware and BNF, Modelware and UML, Dataware and SQL, etc. The concepts of model, metamodel and transformation are usually ill-defined in industrial standards like the MDA or XML. This paper provides a conceptual framework, called a megamodel, that aims at modelling large-scale software evolution processes. Such processes are modeled as graphs of systems linked with well-defined set of relations such as RepresentationOf (μ), ConformsTo (χ) and IsTransformedIn (τ ).	beta normal form;emergence;metamodeling;model-driven architecture;model-driven engineering;programming paradigm;sql;software evolution;unified modeling language;xml	Jean-Marie Favre;Tam Nguyen	2005	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2004.08.034	metamodeling;model-driven architecture;computer science;artificial intelligence;software evolution;data mining;conceptual framework;generalized complex structure	SE	-51.431637575806924	25.657783927699327	111153
89da7643bdad594ebb9b9fece4449a7e690c03ab	the 3rd international workshop on non-functional system properties in domain specific modeling languages (nfpindsml2010)	challenging issue;model-driven engineering;international workshop;domain specific modeling language;non-functional system property;domain specific modeling languages;nfpindsml2010 topic;non-functional system properties	  The NFPinDSML2010 is the 3rd issue in the series of workshops discussing a challenging issue: principles and methods of integrating estimation and evaluation  of Non-functional System Properties (NFP), in Model-driven Engineering (MDE) with Domain Specific Modeling Languages (DSML).  Particularly, NFPinDSML2010 topic was integration of certification and compliance in MDE.    	domain-specific modeling	Marko Boskovic;Daniela Cancila;Claus Pahl;Bernhard Schätz	2010		10.1007/978-3-642-21210-9_29		Robotics	-51.754017350452465	25.09055901483096	111303
101a71ab7acd385bcad4411cacba6c10430d7afa	design of intelligent business applications based in bpm and mde		An architecture has been designed for the generation of intelligent applications of business, that allows to confront the increasing need on the part of the business users to adapt their processes to the constant change. Up to the moment all the architectures based to a great extent on SOA allow to modify the processes in a short period of time, but we go beyond and give the possibility to the business user of modifying their processes. To confront such a challenge, we rely on the fundamental use of two technologies: BPM (Business Process Modeling) and MDE (Model Driven Engineering). Inside these technologies we focus on the creation of a business process extended notation that is simpler, capable of being understood and modified by the business user to achieve the proposed goal.	beam propagation method;business process;model-driven engineering;process modeling;service-oriented architecture	Hector Fernandez;Elías Palacios-González;Vicente García-Díaz;B. Cristina Pelayo García-Bustelo;Juan Manuel Cueva Lovelle	2008			systems engineering;business process;architecture;business process modeling;model-driven architecture;notation;computer science	AI	-56.41963865725193	19.016121194299792	111317
654bfdb6e65acacda44cc11512fe4dd8db24919c	specifying and analyzing institutions in multi-agent systems using answer set programming	multi agent system;answer set programming	It is recognised that normative systems, and in particular electronic institutions and contracts are a potentially powerful means for making agent interactions in multi-agent systems effective and efficient. However, correctly specifying the behaviour of such systems is a difficult problem. Designers are faced with two concurrent, complex tasks: firstly they must specify the relationships (over time) between agents’ actions and their effects, and secondly they must also consider how agents’ actions are to be regulated through the definition of agents’ permissions and obligations. Such systems are typi- cally complex, and given this complexity it may be difficult for a designer to determine whether their original objectives have been captured by the specification of the system. In this dissertation we seek to address some of the problems associated with institu- tional specification. In order to do this we present a model for specifying institutions based on the notion of socially constructed reality that accounts not only for how the action and events which constitute the institution are described, but also how they are regulated. Institutions may be used in a number of ways, and may account for concepts at varying levels of abstraction. Recognising this we also investigate how several insti- tutions, each accounting for a particular aspect of a society may be composed and how the relationships between these institutions may be expressed. Given this model, we then demonstrate how, using the answer set programming paradigm institutional spec- ifications based on our model may be checked for the absence or presence of certain (un)desirable properties.	answer set programming;multi-agent system;stable model semantics	Owen Cliffe	2009	Knowledge Eng. Review	10.1017/S0269888909990270	computer science;knowledge management;artificial intelligence;answer set programming;multi-agent system;algorithm	AI	-52.20202424299843	19.9418973741737	111403
49a8067c13fc0feb8d980351d6e594fc94e4c850	rule-based runtime monitoring of instance-spanning constraints in process-aware information systems		Instance-spanning constraints (ISC) constitute a crucial instrument to establish coordination between multiple instances in Process-Aware Information Systems. ISC need to be verified and monitored at design as well as runtime. In this work we propose a rule-based approach for runtime monitoring of ISC. We base our work on the well known Rete algorithm and research ways structure the network in such a way that improves matching speed for ISC. We show through a technical evaluation that (1) a rule-based approach is feasible for performing runtime monitoring of ISC and (2) that the heuristics we extract for structuring the Rete network improve the rule matching speed.	file spanning;information system	Conrad Indiono;Juergen Mangler;Walid Fdhila;Stefanie Rinderle-Ma	2016		10.1007/978-3-319-48472-3_22	runtime verification	Logic	-54.200241695804756	18.87562722025613	111407
0aa2ffb29b4cf21b399f4b5a49deb5474bd0fb16	ontology-based domain engineering for trajectory simulation reuse	ontology based domain engineering;domain engineering;simulation reuse;trajectory simulation;model driven engineering;engineering ontology	We apply an ontology based knowledge and software reuse methodology adhering to domain engineering principles. Our domain is trajectory simulation. A trajectory simulation is a piece of software to calculate the flight path and other parameters of a munition, such as its orientation and angular rates, from launch to impact. Trajectory Simulation ONTology (TSONT) has been constructed as part of the domain analysis. Object oriented and function oriented reuse infrastructures have been built based upon TSONT following a model-driven development approach. Use of these infrastructures in simulation development has been demonstrated.	domain engineering;simulation	Umut Durak;Halit Oguztüzün;S. Kemal Ider	2009	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194009004532	domain analysis;model-driven architecture;simulation;domain;computer science;systems engineering;feature-oriented domain analysis;software engineering;domain engineering;domain model;mechanical engineering	SE	-53.98047968272666	25.177220010802127	111424
404fb1029295c3e19a0753b745819e1508f344a5	creating a family of collaborative applications for emergency management in the firefighting sub-domain	mobility;collaboration;emergency management;domain analysis;software product line	Software Product Lines allow creating a set of applications that share a set of common features. This makes software product lines appropriate for implementing a family of software products when each stakeholder has different needs and requirements evolve constantly. In the case of emergency management, firefighters have begun using their own smartphones to collaborate and access information during emergencies. However, each firefighter role requires different information and the firefighters’ requirements are constantly evolving. We propose a well-defined process to help stakeholders in this domain specify the products they require, showing that it is possible to apply this software engineering process to extract collaborative requirements common to a set of applications. To confirm whether it was useful for real software implementation, we defined and implemented two applications for this domain. This paper presents the process used to systematically define the domain model and determine the domain scope, which may be used for other domains. We found the process to be appropriate for identifying features related to the domain Pedro O. Rossel prossel@ucsc.cl Valeria Herskovic vherskov@ing.puc.cl Erika Ormeño esormeno@ing.ucsc.cl 1 Departamento de Ingenierı́a Informática, Universidad Católica de la Santı́sima Concepción, Concepción, Chile 2 Departamento de Ciencia de la Computación, Pontificia Universidad Católica de Chile, Santiago, Chile and its collaborative aspects. The results are promising; the process allowed us to create two working applications which were positively received by two types of stakeholders.	activity diagram;artifact (software development);domain analysis;domain model;erika enterprise;feature model;interaction;linear algebra;natural language;requirement;scope (computer science);smartphone;software development process;software engineering;software product line;xojo	Pedro O. Rossel;Valeria Herskovic;Erika Ormeño	2016	Information Systems Frontiers	10.1007/s10796-015-9575-0	domain analysis;requirement prioritization;computer science;marketing;operations management;software development;operating system;domain engineering;data mining;database;mobile computing;management;world wide web;computer security;software requirements;emergency management;collaboration	SE	-59.86352434133587	23.20939287997578	111451
d45854801593ba6b8248755d0af0178949af4a88	patterns in the analysis, design and implementation of frameworks	libraries;virtual machine;pattern analysis application software jacobian matrices programming software reusability collaborative software computer science virtual machining libraries collaboration;object oriented methods;framework analysis;application software;virtual machining;collaboration;software development process;software engineering virtual machines object oriented programming object oriented methods;object oriented programming;development process;software engineering;frameworks design;virtual machines;design and implementation;object oriented;software reusability;framework implementation;object oriented approach;pattern analysis;patterns;computer science;jacobian matrices;programming;collaborative software;domain structure;virtual machines patterns framework implementation framework analysis frameworks design	Patternsare investigatedin relationto developmentof applicationsand frameworks in the context of analysis,design, and implementation. The resultsare basedon a framework for virtual machines.Differentpatterncharacteristicsare identifiedin analysis,design,andimplementation of applicationsandframeworks.	virtual machine	Eyðun Eli Jacobsen;Bent Bruun Kristensen;Palle Nowack	1997		10.1109/CMPSAC.1997.624982	computer science;systems engineering;virtual machine;software engineering;object-oriented programming;management;software development process;computer engineering	PL	-51.97920541670741	28.381520119468046	111627
2abd355b08dc0b224e185b3a32c945e839da3d0f	towards an engineering change in agent oriented software engineering	multiagent system;multi agent system;agent oriented software engineering;object oriented programming;development process;software engineering application software computer architecture control systems software tools multiagent systems communication system control weapons encapsulation automation;software abstraction;multi agent systems;object oriented programming command and control systems multi agent systems;agent based computing;c4i system agent oriented software engineering agent based computing software abstraction multiagent system;c4i system;command and control systems;software implementation;software engineering practices;engineering change	Despite a great deal of research in the area, a number of challenges still need to be faced before making agent-based computing a widely accepted paradigm in software engineering practice. In order to realize engineering change in agent oriented software engineering: it's necessary to turn agent oriented software abstractions into practical tools for facing the complexity of modern application areas. The paper presents universal development architecture for multi-agent system to provide straight connection between agent oriented analysis and software implementation. A detailed agent structure plays a key role in the process. The development process presented fulfills our requirements in the construction of C4I system	agent-based model;agent-oriented software engineering;multi-agent system;programming paradigm;requirement;software engineering	Xiao Xue;Junfang Zeng;Liu Liding	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.542	software engineering process group;computer science;artificial intelligence;package development process;software design;social software engineering;component-based software engineering;software development;feature-oriented domain analysis;multi-agent system;software construction;requirements engineering;object-oriented programming;resource-oriented architecture;software development process;software requirements;software system	SE	-53.09414156817515	27.10463958108262	111981
230e742c0b36d0dbc9bf547bc5a708ce3dbcffb0	automatic source code generation for web-based process-oriented information systems		Software development life cycle (SDLC) activities include: requirements analysis, design, development, testing and maintenance. The first two steps have wide impact in the project success, and errors in these stages can have large impact in the project duration and budget. To mitigate these problems, strategies like fast prototyping using natural language to specify software requirements have been proposed. These approaches can make the SDLC faster. In this context, this paper presents an approach to automatically generate a web application prototype running business processes using a restricted natural language specification. A comprehensive case study is presented to validate the proposal and demonstrate its applicability.	automatic programming;business process model and notation;class diagram;code generation (compiler);executable;granular computing;integrated development environment;natural language;programming language specification;prototype;requirement;requirements analysis;requirements elicitation;sequence diagram;software development process;software maintenance;software requirements;software testing;specification language;synchronous data link control;uml state machine;unified modeling language;web application	Jean Pierre Alfonso Hoyos;Felipe Restrepo-Calle	2017		10.5220/0006333901030113	kpi-driven code analysis;web service;web modeling;data web;programming language;information retrieval;source code	SE	-57.01971205927246	24.757956602313538	112095
d3db945213bf9882c9cbe22819c5ff42f953eaa0	freeflow: mediating between representation and action in workflow systems	process description;workflow system;process support;workflow;dependencies;temporal organisation;constraints	In order to understand some problems associated with workflow, we set out an analysis of workflow systems, identifying a number of basic issues in the underlying technology. This points to the conflation of temporal and dependency information as the source of a number of these problems. We describe Freeflow, a prototype which addresses these problems using a variety of technical innovations, including a rich constraint-based process modelling formalism, and the use of declarative dependency relationships. Its focus is on mediation between process “and action, rather than the enactment of a process. We outline the system and its design principles, and illustrate the features of our approach with examples from ongoing work.	declarative programming;process modeling;prototype;semantics (computer science)	Paul Dourish;Jim Holmes;Allan MacLean;Pernille Marqvardsen;Alex Zbyslaw	1996		10.1145/240080.240252	workflow;xpdl;computer science;knowledge management;database;management;workflow management system;workflow engine;workflow technology	AI	-54.146706530103714	18.841079732620322	112311
7fb19b68938133dd7f371bb7db6b764e0b5813f4	structural integration testing of aspect-oriented programs: a pointcut-based approach for aspectj			aspect-oriented software development;aspectj;integration testing;pointcut	Otávio Augusto Lazzarini Lemos	2009				SE	-53.09873503011145	31.014263408806997	112459
1a6fcef940aed0b1b5db200b1887a9db2c7eb72c	fsmtest-1.0: a manual for researches		"""In this paper we describe software tool """"FSMTest-1.0"""" that was developed by group of authors from the department of Computer science of Tomsk State University. The tool contains implementations of well-known and original test suites generation methods for different models with finite numbers of transitions. The main contribution of our tool is that it derives test suites with the guaranteed fault coverage."""	computer science;fault coverage;programming tool;test suite	Natalia Shabaldina;Maxim Gromov	2015	2015 IEEE East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2015.7493141	simulation;engineering;mechanical engineering	Logic	-57.01981322800042	31.68399728691646	112657
c15b352180273c95cee457feabc31cf09d5dabf6	composing crosscutting concerns : a service-oriented view			cross-cutting concern;service-oriented architecture;service-oriented device architecture	Massimiliano Menarini	2012				HCI	-51.34310907761943	26.767966431516992	112787
527c800c32c67f9652882dc9435b744cd977acff	model-driven reverse engineering	algebraic specification;algebraic specifications;project management;formal specification;domain engineering;reverse engineering engineering management formal specifications software maintenance documentation quality management performance evaluation software systems technology management application software;software maintenance;software systems;software maintenance project model driven reverse engineering software system modeling technology formal specification automatic code generation slang application domain;project management reverse engineering formal specification software maintenance software development management systems re engineering software quality;software engineering;65;design representation;structure and function;levels of abstraction;performance model;point of view;models;software quality;software development management;domain engineering reverse engineering models algebraic specifications design representation;modeling tool;reverse engineering;systems re engineering	Reverse engineering is the process of comprehending software and producing a model of it at a high abstraction level, suitable for documentation, maintenance, or reengineering. But from a manager's viewpoint, there are two painful problems: 1) It's difficult or impossible to predict how much time reverse engineering will require. 2) There are no standards to evaluate the quality of the reverse engineering that the maintenance staff performs. Model-driven reverse engineering can overcome these difficulties. A model is a high-level representation of some aspect of a software system. MDRE uses the features of modeling technology but applies them differently to address the maintenance manager's problems. Our approach to MDRE uses formal specification and automatic code generation to reverse the reverse-engineering process. Models written in a formal specification language called SLANG describe both the application domain and the program being reverse engineered, and interpretations annotate the connections between the two. The ability to generate a similar version of a program gives managers a fixed target for reverse engineering. This, in turn, enables better effort prediction and quality evaluation, reducing development risk.	abstraction layer;application domain;automatic programming;code generation (compiler);code refactoring;documentation;formal specification;high- and low-level;model-driven integration;reverse engineering;software system;specification language	Spencer Rugaber;R. E. Kurt Stirewalt	2004	IEEE Software	10.1109/MS.2004.23	project management;reliability engineering;computer science;systems engineering;engineering;software engineering;domain engineering;reverse semantic traceability;formal specification;programming language;software maintenance;software quality;reverse engineering;software system	SE	-53.51249569368428	28.791552939157953	112917
45f9a0ceba5d4aaa56525fa7beb4a9537bfe011c	an overview of feature-oriented software development	software systems;large scale;software development	Feature-oriented software development (FOSD) is a paradigm for the construction, customization, and synthesis of large-scale software systems. In this survey, we give an overview and a personal perspective on the roots of FOSD, connections to other software development paradigms, and recent developments in this field. Our aim is to point to connections between different lines of research and to identify open issues.	programming paradigm;software development;software system	Sven Apel;Christian Kästner	2009	Journal of Object Technology	10.5381/jot.2009.8.5.c5	personal software process;verification and validation;software sizing;package development process;backporting;social software engineering;software framework;software development;software design description;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software system;software peer review	SE	-61.719608658522326	24.00119099437298	113046
3a972d539b44dcbbc05d3339be03f4d6384dc747	a methodology for model-driven web application composition	class diagram;model view controller;model parsing tools;composition;application software;user interface;web and internet services;uml;business layer components;uml state transition;web service;development process;composition model driven architecture uml web services;application modeling;computer networks;web service composition;software architecture;standards development;springs;uml profile;model driven web application composition;unified modeling language;web services;class diagrams;user interface flow;web services software architecture unified modeling language user interfaces;xml;service design;source code;architectural pattern;model view controller architectural pattern;development automation;reusable component;reusable components;user interfaces;model driven architecture;state transition;model parsing tools model driven web application composition reusable components model view controller architectural pattern business layer components web services user interface flow development automation application modeling uml state transition class diagrams;automation	Web application composition can greatly benefit from the utilization of existing frameworks and reusable components, in order to reduce development effort. Frameworks implementing the model-view-controller architectural pattern standardize the development process to a great extent, while business layer components may consist of consumers of existing Web services. On this line of thought a Web application can be seen as a composition of Web services around a user interface flow. In this paper, an approach for the application of model-driven techniques for the automation of the development of such a Web application is presented. Specifically, we present a methodology for the modeling of the application using UML state transition and class diagrams and the generation of the appropriate source code and configuration files. The appropriate UML profiles to assist the service design are defined and the final transformation is performed exploiting model parsing tools.	architectural pattern;business logic;class diagram;model-driven architecture;model-driven integration;model–view–controller;parsing;profile (uml);software framework;state transition table;unified modeling language;user interface;web application;web service	Dimitrios A. Kateros;Georgia M. Kapitsaki;Nikolaos D. Tselikas;Iakovos S. Venieris	2008	2008 IEEE International Conference on Services Computing	10.1109/SCC.2008.58	web service;web development;web modeling;web-based simulation;web design;web standards;computer science;systems engineering;applications of uml;ws-policy;service-oriented architecture;database;world wide web;rewrite engine;mashup	SE	-49.77164492411232	25.599074631038086	113049
d85fac116edb02848883399fb9bb4531b942290f	integrating the designer in-the-loop for metamodel/model co-evolution via interactive computational search		Metamodels evolve even more frequently than programming languages. This evolution process may result in a large number of instance models that are no longer conforming to the revised meta-model. On the one hand, the manual adaptation of models after the metamodels' evolution can be tedious, error-prone, and time-consuming. On the other hand, the automated co-evolution of metamodels/models is challenging especially when new semantics is introduced to the metamodels. In this paper, we propose an interactive multi-objective approach that dynamically adapts and interactively suggests edit operations to developers and takes their feedback into consideration. Our approach uses NSGA-II to find a set of good edit operation sequences that minimizes the number of conformance errors, maximizes the similarity with the initial model (reduce the loss of information) and minimizes the number of proposed edit operations. The designer can approve, modify, or reject each of the recommended edit operations, and this feedback is then used to update the proposed rankings of recommended edit operations. We evaluated our approach on a set of metamodel/model coevolution case studies and compared it to fully automated coevolution techniques.	cognitive dimensions of notations;computation;conformance testing;conformity;converge;evolution;feedback;fitness function;interactive media;interactivity;metamodeling;model transformation;programming language;semantic similarity	Wael Kessentini;Manuel Wimmer;Houari A. Sahraoui	2018		10.1145/3239372.3239375	theoretical computer science;programming language;metamodeling;coevolution;semantics;computer science;search-based software engineering	SE	-55.507343158072935	29.391348079885258	113460
2baecb706b320cd11857137798abdf2158897733	object-oriented software design utilizing quality function deployment	project management;quality function deployment;langage c;object oriented design;implementation;qualite;program design;object oriented software;conception programme;organizacion proyecto;ingenieria logiciel;software engineering;prototipo;ejecucion;c language;estudio caso;object oriented;quality;etude cas;genie logiciel;oriente objet;gestion projet;orientado objeto;prototype;concepcion programa;calidad;lenguaje c	This paper puts forward Quality Function Deployment (QFD) technique as an effective tool for requirements acquisition and design analysis of a ground software intensive project. The paper shows how QFD focused our effort to produce a product for customers with diverse needs and also how to tailor the technique for use with modern Object-Oriented Design (OOD) software technology. The results show that the QFD process enabled us to capture requirements and produce specifications and designs that are efficient, robust, and consistent. Requirements captured with QFD were faster compared with other classical methods by a factor of 50%; more robust by a factor of 60% with respect to identification of conflicting requirements or protential bottlenecks; and more consistent by a factor of 70%.	quality function deployment;requirement;software deployment;software design	Mekki I. Elboushi;Joseph S. Sherif	1997	Journal of Systems and Software	10.1016/S0164-1212(96)00117-3	project management;quality function deployment;simulation;computer science;systems engineering;engineering;object-oriented design;program design language;prototype;programming language;object-oriented programming;implementation;engineering drawing	SE	-61.388498582535696	28.691834524000544	113548
eb1ff8c5c4512517facae5e2ac52fa436a3de305	uml: the language of blueprints for software? (panel)	weak pointers;resource management;garbage collection;standardisation;object oriented;case tool;unified modeling language;object management group;finzlization;object oriented analysis and design;software specification;language design;meta model	"""The Unified Method was launched by Grady Booch and Jim Rumbaugh at an OOPSLA'95 Conference Fringe meeting organised by Rational Software Corporation. In 1996 the Unified Method was re-scoped to a notation, and renamed the Unified Modeling Language (UML).Earlier this year, UML was submitted to the Object Management Group for standardisation and has been endorsed by Microsoft, IBM, HP, Platinum Technologies, ObjectTime and many other corporations. No wonder UML is the leading contender as the de facto standard notation for object-oriented analysis and design.The panel will take a sanity check, and will go beyond the hype and newsgroup flames and attempt to form an objective view of UML and its prospects.The members of the panel have been working closely with UhL in many different roles, including that of UML language designer, end-user, consultant, CASE tool expert, and object-oriented methodologist. The discussion will focus on how LJML matches up in practice against one of its original. raisons d'etre as """"the language of blueprints for software"""".Specific issues to be addressed include:&bull; What is the advantage of UML over existing OOA/D notations?&bull; Can UML be used on real projects today?&bull; Is the language sufficiently simple, and well-enough defined, to become the de facto standard?&bull; Will UML lead to improved OOA/D methods and CASE tools?&bull; What is the importance of the meta-model in UML?"""	blueprint;computer-aided software engineering;james rumbaugh;metamodeling;sanity check;unified modeling language	Derek Coleman;John Artim;Victor Ohnjec;Erick Rivas;James E. Rumbaugh;Rebecca Wirfs-Brock	1997		10.1145/263698.263736	object-oriented analysis and design;metamodeling;unified modeling language;software requirements specification;systems modeling language;uml tool;computer science;resource management;element;applications of uml;shlaer–mellor method;garbage collection;programming language;object-oriented programming;standardization;object constraint language	PL	-51.90683229626952	24.091104375920914	113622
282a25bdd7042c57de50459727a6d1e550d584b3	gail: the gen-it (r) abstract integration layer for b2b application integration solutions	application framework;code generation;object oriented programming;application integration;explicit knowledge;specification languages;business data processing;program compilers business data processing specification languages object oriented programming;sun trademarks unified modeling language protocols plugs business databases technology management xml time to market;time to market;object oriented programming gail gen it abstract integration layer business to business application application integration solutions microsoft biztalk sun open net environment sun one protocols model driven architecture uml parameterized architecture code generator standards knowledge management;program compilers;modeling tool	Dffirent solutions exist in the market for 828 application frameworks, including Microsoft@ Biztalk Sun mopen Net Environment (Sun ONE)'. These supply a set of standard technologies and protocols for 8 2 8 application integration. However, all of these solutions require nianiml coding to integrate the different layers of B2B applications. Given the niulti-tier nature of B2B applications, where each tier has to be developed separately, it becomes a vety complex task to develop these applications without an integrated visual and code generator environment to customize the generation process for a given B2B architecture. GAIL (the Gen-it @ Abstract Integration Layer) provides B2B application franiework vendors a customized model-driven architectirreTM approach for deploying B2B applications. Indeed, GAIL (1) plugs into most ofthe leading UML modeling tools and (2) provides a parameterized architecture rkf blueprint to generate most of the code needed in deploying B2B applications. The benefits of integrating GAIL with B2B application solutions are: time-to-market solution delivety, custoniization and integration performed visually andgenerated systematically, enforced corporate standards in each project, drastic reduction of ongoing maintenance, and explicit knowledge management.	blueprint;code generation (compiler);knowledge management;microsoft biztalk server;model-driven architecture;multitier architecture;sun one;unified modeling language	Ismaïl Khriss;Michel Brassard;Neil Pitman	2001		10.1109/TOOLS.2001.941661	computer science;systems engineering;software engineering;database	SE	-50.32916862980329	25.980126574840472	113643
3296b623752550cd66723af1ed841d6226038267	model-driven approach to software architecture design	software;software system quality attribute;architectural design;quality attributes;application software;design for quality;software systems;model transformation;object oriented programming;data mining;computer architecture;software architecture;design method;model transformation software architecture design model driven engineering software system quality attribute software system design software development enterprise application;systems analysis;software development;unified modeling language;relational model;software system design;model driven engineering;software architecture design;software design;software architecture software design design methodology design for quality software systems programming proposals computer architecture application software model driven engineering;proposals;programming;software quality;systems analysis object oriented programming software architecture software quality;enterprise application;marketing and sales;design methodology	Software Architecture (SA) allows for early assessment of and design for quality attributes of a software system, and it plays a critical role in current software development. However, there is no consensus on fundamental issues such as design methods and representation organization and languages, and current proposals lack specificity and preciseness. Thus, it is extremely difficult to build a complete and appropriate software architecture, even though it is recognized as a fundamental artifact. In this paper we define an architecture design method that enables the systematic and assisted construction of the SA of Enterprise Applications, taking into account major quality attributes involved in this family of systems. We apply Model-Driven Engineering techniques to achieve this goal. The architecture is treated as a mega-model (a model composed of related models) and the application of design decisions is encoded in terms of model transformations. The architectural rationale is explicitly registered as the set of transformations that yields the complete SA from scratch. We illustrate the application of the approach by designing the SA of a case study from the literature.	design rationale;enterprise software;list of system quality attributes;model transformation;model-driven engineering;model-driven integration;sensitivity and specificity;software architecture;software development;software system	Daniel Perovich;M. Cecilia Bastarrica;Cristian Rojas	2009	2009 ICSE Workshop on Sharing and Reusing Architectural Knowledge	10.1109/SHARK.2009.5069109	enterprise architecture framework;functional software architecture;reference architecture;software architecture;space-based architecture;database-centric architecture;architectural pattern;computer science;systems engineering;software design;software design description;software engineering;software construction;solution architecture;software architecture description;view model;resource-oriented architecture;data architecture;systems architecture;computer engineering	SE	-53.97565378657004	27.20604342462957	113702
9211ad8a52af02b6b209b4d16109f53af0a168d9	maintaining configurations of evolving software systems	software systems;module and subsystem interfaces;software configuration management;module and subsystem families;system integration;upward compatibility configuration module and subsystem families module and subsystem interfaces software configuration maintenance system;software configuration maintenance system;system architecture;configuration;upward compatibility;software systems software maintenance software prototyping control systems computer science computer architecture mechanical factors large scale systems application software information systems	Software configuration management ( SCM) is an emerging discipline. An important aspect of realizing SCM is the task of maintaining the configurations of evolving software systems. In this paper, we provide an approach to resolving some of the conceptual and technical problems in maintaining configurations of evolving software systems. The approach provides a formal basis for existing notions of system architecture. The formal properties of this view of configurations provide the underpinnings for a rigorous notion of system integrity, and mechanisms to control the evolution of configurations. This approach is embodied in a language, NuMIL, to describe software system configurations, and a prototype environment to maintain software system configurations. We believe that the approach and the prototype environment offer a firm base to maintain software system configurations and, therefore, to implement SCM.	abstraction layer;correctness (computer science);forward compatibility;prototype;software configuration management;software system;system integrity;systems architecture	K. Narayanaswamy;Walt Scacchi	1987	IEEE Transactions on Software Engineering	10.1109/TSE.1987.233163	reliability engineering;long-term support;verification and validation;software sizing;software configuration management;computer science;systems engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;real-time control system software;systems development life cycle;configuration;resource-oriented architecture;software deployment;systems architecture;software system;system integration;computer engineering	SE	-53.20297763713196	27.874699308473616	113714
4d5ce9eb608e54c259da9a1b2687033731e9c630	tool support for the evaluation of matching algorithms in the eclipse modeling framework		In the field of model-driven development, sophisticated support for comparing model versions is urgently needed. Unfortunately, algorithms for model matching have been rarely evaluated so far. This paper deals with two extensions to the Eclipse Modeling Framework (EMF) that facilitate the evaluation of matching algorithms for EMF models, with the goal to combine user involvement and automated testing in the evaluation process. First a tree editor is presented that allows for the manual and semi-automated creation of match models which formalize the intended matching result. Second a benchmarking procedure is implemented which – given the intended match and the actual results of matching algorithms – automatically derives the number of a and b errors in a target-performance comparison. These results are valuable for drawing conclusions about the specific qualities of matching algorithms or for finding an adequate set of parameters for a configurable algorithm.	algorithm;benchmark (computing);eclipse modeling framework;graphical user interface;interpretation (logic);level of detail;metamodeling;model-driven engineering;partial application;quality of results;semiconductor industry;test automation;test case;test set	Sabrina Uhrig;Felix Schwägerl	2013		10.5220/0004310801010110	real-time computing;computer science;theoretical computer science;machine learning	DB	-56.322292857528	29.833386448667483	113783
c77cc0b07e956ade6f16f44037b2a79ee8531a4e	how automotive engineering is taking product line engineering to the extreme	product portfolio;automotive product lines;feature modeling;feature profiles;bill of features;product configurator;variation points;product line engineering;software product lines;second generation product line engineering	Automotive manufacturing ranks among the most extreme instances of systems and software product line engineering (PLE). The product family numbers in the millions, each product is highly complex in its own right, and the variation across products is literally astronomical in scale. This paper explores the aspects that make the domain extreme and the very specific implications they have for PLE. These implications include the need for efficient manufacturing, complexity management, concurrent development streams, globally distributed engineering and production, a hierarchical product family tree, multi-level variation binding, constraint management, and a highly robust and integrated PLE tooling environment. Happily, the PLE paradigm supporting these implications brings about a number of opportunities for analysis and automation that provide efficiencies of production previously unattainable. We focus on one example in depth: The management and automated generation of the many thousands of calibration parameters that determine vehicle-specific software behavior. Throughout, we use the vehicle product line at General Motors, which we believe to be the world's largest, to illustrate and ground our journey through automotive PLE.	automotive navigation system;end-to-end encryption;end-to-end principle;family tree;inter-domain;multistage amplifier;product engineering;programming paradigm;requirement;separation of concerns;software deployment;software product line	Len Wozniak;Paul Clements	2015		10.1145/2791060.2791071	systems engineering;engineering;operations management;product design specification;software engineering;domain engineering;product design;new product development;manufacturing engineering;product engineering	DB	-62.71087393096908	21.85729594512764	114000
c01f720878d1c1d139ade92a0bd7837bc0535cf8	comparing grl and kaos using the ueml approach	bunge wand weber;goal orientation;software systems;integrated management;modelling language;information system;enterprise modelling	Goal-oriented modelling languages are central in the information systems (IS) field, both for aligning new IS with organisational  needs and for developing agent-oriented software systems. However, existing goal-oriented languages differ significantly in  both syntax and semantics. The paper analyses and compares the syntax and semantics of GRL and KAOS using the UEML approach,  providing a systematic and detailed comparison of the two languages, in part based on the Bunge-Wand-Weber (BWW) model and  Bunge’s ontology. The work offers a path towards integrated management and use of models expressed in GRL and KAOS, it contributes  to incorporating GRL and KAOS into version 2 of the unified enterprise modelling language, which is currently being developed.  	extended enterprise modeling language;goal-oriented requirements language;kaos	Raimundas Matulevicius;Patrick Heymans;Andreas L. Opdahl	2007		10.1007/978-1-84628-858-6_7	simulation;computer science;systems engineering;artificial intelligence	Vision	-55.327131271100335	20.79478187810602	114004
4bc766a2b521c9e92502afb474fb1782b85ffdd7	experiences with model-centred design methods and tools in safe robotics	object oriented methods;software prototyping;model centred design method v model development artifact reusability object oriented systems engineering method robotic wheelchair design safety critical robot sysml design information management zipc code generation code verification safety critical system development agile model waterfall model structured development work products task range management well structured process model centred design tools;systems engineering;object oriented modeling mobile robots unified modeling language wheelchairs solid modeling;mobile robots;program verification;task analysis;safety critical software;software reusability;wheelchairs control engineering computing mobile robots object oriented methods program compilers program verification safety critical software software development management software prototyping software reusability sysml systems engineering task analysis user centred design;user centred design;control engineering computing;program compilers;software development management;wheelchairs;sysml	Development of a system is complex, requiring a well-structured process to manage the range of tasks involved and their work products. There are many models and processes available for structured development, including the well-known Waterfall and Agile models. Recent standards for safety-critical system development utilise the V-model, such as the process given in the ISO 26262 standard for functional safety of road vehicles. However, the process clashes with the commonly-expressed desire for greater reuse of development artifacts in robotics. We have experimented with applying a process, the Object-Oriented Systems Engineering Method, to the design of a robotic wheelchair. This paper describes our application of the process to a safety-critical robot, as well as our use of SysML for managing design information and ZipC for code generation and verification. We discuss our experiences, both good and bad, in order to inform other robot developers of what to consider when choosing a process and tools.	agile software development;code generation (compiler);component-based software engineering;critical system;finite-state machine;iteration;model-driven engineering;real-time clock;robot;robotics;software developer;system lifecycle;systems modeling language;systems design;systems engineering;usability;v-model;waterfall model;whole earth 'lectronic link	Geoffrey Biggs;Takeshi Sakamoto;Kiyoshi Fujiwara;Keiju Anada	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696916	mobile robot;simulation;systems modeling language;computer science;systems engineering;engineering;task analysis;computer engineering	Robotics	-50.58369405453766	23.766125907478944	114026
9c26362129d408f9c0802fc402a733d16ddda2ab	a case study on a specification approach using activity diagrams in requirements documents		Rising complexity of systems has long been a major challenge in requirements engineering. This manifests in more extensive and harder to understand requirements documents. At the Daimler AG, an approach is applied that combines the use of activity diagrams with natural language specifications to specify system functions. The approach starts with an activity diagram that is created to get an early overview. The contained information is then transferred to a textual requirements document, where details are added and the behavior is refined. While the approach aims to reduce efforts needed to understand a system's behavior, the application of the approach itself causes new challenges on its own. By examining existing specifications at Daimler, we identified nine categories of inconsistencies and deviations between activity diagrams and their textual representations. In a case study, we examined one system in detail to assess how often these occur. In a follow-up survey, we presented instances of the categories to different stakeholders of the system and let them asses the categories regarding their severity. Our analysis indicates that a coexistence of textual and graphical representations of models without proper tool support results in inconsistencies and deviations that may cause severe maintenance costs or even provoke faults in subsequent development steps.	activity diagram;coexist (image);graphical user interface;natural language;requirement;requirements engineering;resultant;unified modeling language	Martin Beckmann;Andreas Vogelsang;Christian Reuter	2017	2017 IEEE 25th International Requirements Engineering Conference (RE)	10.1109/RE.2017.28	systems engineering;requirements engineering;management science;natural language;computer science;activity diagram;unified modeling language;graphical model	SE	-55.95425745129392	23.56636018709591	114164
82516aed526c39333b5af4da62e1bbe50e53fddb	development of a software tool to support traceability-based inspection of sofl specifications	conformance;sofl;specification;inspection;traceability;article	When developing a formal specification for a software project using the SOFL three-step modeling approach, it is essential to ensure the conformance relation between every two level specifications. Inspection is an important technique to verify the specifications. In this paper, we describe an inspection method through building traceability for rigorously verifying the conformance relation. The method consists of two steps: (1) traceability establishment and (2) inspection of the target specifications through the built traceability. We also provide some inspection strategies such as checklists based on SOFL features to help the inspector find errors and keep the consistency. Our tool provides a convenient interface to separate components in different specifications and save their relationships to keep the consistency. We describe the design and implementation of our supporting tool in this paper. A case study to inspect the specifications of a travel plan booking system is given to show how the proposed method can be applied in practice .	programming tool;traceability	Jinghua Zhang;Shaoying Liu	2014		10.1007/978-3-319-17404-4_3	reliability engineering;systems engineering;engineering drawing	SE	-56.59993333848087	29.655940729321554	114242
9d4e97c79075cf67994ab47e00bb21cd9ed9d37f	structuring and refinement of class diagrams	unified modeling language electrical capacitance tomography hip read only memory computer aided software engineering software systems ip networks joining processes application software design engineering;class diagram;information resources;object oriented model;diagrams;object oriented programming;computer aided software engineering;visual languages;case tool;computer aided software engineering object oriented programming object oriented languages diagrams visual languages information resources;object oriented languages;documentation systems class diagrams graphical object oriented modeling languages structured interfaces attribute templates operation templates relation templates case study web based distributed editor case tools	The class diagram notation of current graphical objectoriented modeling languages does not scale well with the increasing complexity of modern systems. To overcome this weakness, we propose the concept of structured interfaces, a flexible refinement relationship between class diagrams and the use of attribute, operation and relation templates to abstract from implementation details. The usefulness of thefrom implementation details. The usefulness of the introduced concepts is illustrated by the development case study of a web-based distributed editor. Finally, we present suggestions for the integration of the presented structuring and refinement concepts into CASE tools and documenta-	class diagram;computer-aided software engineering;graphical user interface;high- and low-level;level design;low-level design;modeling language;principle of abstraction;programming tool;reference implementation;refinement (computing);scalability;software development;web application	Klaus Bergner;Andreas Rausch;Marc Sihling;Alexander Vilbig	1999		10.1109/HICSS.1999.772616	computer science;theoretical computer science;component-based software engineering;database;programming language;object-oriented programming;story-driven modeling;computer-aided software engineering	SE	-48.388825816883916	27.669332054812873	114342
1b7230a3445ee10f7a70e244e0b08fd73957a669	dimensions and forms of knowledge collaboration in software development	software systems;software engineering;software development;collaborative software programming software systems java software engineering magnetic heads application software operating systems libraries computer science;software development technology knowledge collaboration;knowledge based systems;knowledge based systems software engineering	Nowadays few software systems can be produced by a single software developer. Most software systems require collaborative development due to the required brawn power brought by multiple hands. At the same time, because software systems are knowledge artifacts that involve knowledge from multiple domains that a single software developer often does not possess, collaboration also becomes a necessity due to the required brainy power brought by multiple minds. Merging the above two lines of requirements, we view knowledge collaboration as an essential elements in future software development technology and support environments. This paper discusses different forms of knowledge collaboration that exist in software development and suitable conditions for successful knowledge collaboration.	requirement;software developer;software development;software system	Yunwen Ye	2005	12th Asia-Pacific Software Engineering Conference (APSEC'05)	10.1109/APSEC.2005.62	personal software process;verification and validation;software engineering process group;computer science;systems engineering;knowledge management;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;knowledge-based systems;software construction;software walkthrough;software analytics;resource-oriented architecture;software deployment;software development process;software requirements;software system;software peer review	SE	-61.25037270410813	22.926915658791053	114447
43f7eb56915aecf6f0d8d48b0b30a9dfb4fb9292	a mapping approach for confguration management tools to close the gap between two worlds and to regain trust				Roy Meissner;Marcus Kastne	2017		10.18420/in2017_186	systems engineering;orchestration (computing);reverse engineering;configuration management;digital subscriber line;computer science	HCI	-61.50909758301291	22.456193461554694	114449
2969c8e70512453de0be3aa742b4fffa25d91c93	strategies for integrating case environments	application development;software tools knowledge based systems programming environments;programming environments;esprit program;conceptbase process information repository technical environments object management case environments information system environment daida development assistance integrated database applications esprit program knowledge based techniques process oriented model dependencies social environments development tasks process management;development assistance;conceptbase process information repository;integrable model;integrated database applications;technical environments;process management;object management;traditional knowledge;case environments;process oriented model;knowledge based techniques;software tools;dependencies;daida;information system;computer aided software engineering information systems multimedia databases quality assurance process design process control multimedia systems application software knowledge management project management;development tasks;information system environment;knowledge based systems;social environments;social environment	An experimental information-system environment, called DAIDA (development assistance for integrated database applications), developed as part of the European Community's ESPRIT program is described. DAIDA goes beyond traditional knowledge-based techniques for CASE by addressing three important dimensions of integration in a process-oriented model: how to handle dependencies among development stages, how to manage the evolving relationship among systems and their technical and social environments, and how to integrate development tasks-from both development in the small, in which the focus is the content of actions and results, and development in the large, which is concerned with object and process management and the collaboration of people involved in developing and using systems. This threefold integration strategy is discussed, along with the DAIDA architecture and a development example. The ConceptBase process information repository, which is used to define the process-oriented integration model, is also discussed.<<ETX>>	computer-aided software engineering;conceptbase;environment variable;information repository	Matthias Jarke	1992	IEEE Software	10.1109/52.120602	social environment;traditional knowledge;computer science;systems engineering;knowledge management;knowledge-based systems;database;rapid application development;information system	Robotics	-51.104754945162846	18.853481433875537	114624
edf8a85ac3af761617bf99ef4c231fbe6ae1c117	user interface specification for interactive software systems			software system;user interface specification	Thomas Memmel	2009				SE	-49.62854747075962	28.73654580532787	114643
dfc9d32321bac9d107fc36df7034617b0ce9480e	feature relation and dependency management: an aspect-oriented approach	animals;object oriented methods;object oriented modeling engines animals java calculators atmospheric modeling aggregates;product line assets;articulo;calculators;feature relation and dependency management an aspect oriented approach;object oriented programming;feature dependency;feature model;dependency management;engines;aspect oriented approach;aspect oriented programming;aggregates;code scattering;software reusability;object oriented approach;dependency management feature dependency feature model software product line aspect oriented programming;code tangling;software reusability object oriented methods object oriented programming product development;atmospheric modeling;software product line;feature relation;code tangling dependency management feature relation aspect oriented approach product line assets object oriented approach code scattering;object oriented modeling;java;product development	Product line assets must be designed so that inclusion or exclusion of variable features causes little changes to components implementing other features. In order to achieve this goal, various relationships or dependencies that variable features have with other features must be analyzed thoroughly before designing product line assets. An object-oriented approach has been proposed to manage operational dependencies between features. However, it still suffers from code scattering and tangling problems. To address these problems, this paper introduces aspect-oriented implementation patterns which separate feature relations and dependencies from components implementing core functionality of features. Using these patterns, we can improve adaptability, scalability (modifiability in general), and configurability of product line assets. A simple calculator product line example is used to validate this approach.	aspect-oriented programming;aspect-oriented software development;coupling (computer programming);scalability	Hojin Cho;Kwanwoo Lee;Kyo Chul Kang	2008	2008 12th International Software Product Line Conference	10.1109/SPLC.2008.23	atmospheric model;aspect-oriented programming;computer science;systems engineering;programming language;object-oriented programming;java;engineering drawing;new product development;feature model	DB	-55.17184735469027	28.330527689363613	114699
0ed6e074d3bf7f53d45425191dc0d1c83907aaa4	a test automation framework for collaborative testing of web service dynamic compositions		The dynamic composition of services owned by different vendors demands a high degree of test automation, which must be able to cope with the diversity of service implementation techniques and to meet a wide range of test requirements on-the-fly. These goals are hard to achieve because of the lack of software artefacts of the composed services and the lack of the means of control over test executions and the means of observations on the internal behaviours of composed services. Yet, such integration testing on-the-fly must be non-intrusive and non-disruptive while the composed services are in operation. This chapter presents a test automation framework for such on-the-fly testing of service compositions to facilitate the collaboration between test services through utilisation of Semantic Web Services techniques. In this framework, an ontology of software testing called STOWS are used for the registration, discovery and invocation of test services. The composition of test services is realized by using test brokers, which are also test services but specialized in the coordination of other test services. The ontology can be extended and updated through an ontology management service so that it can support a wide open range of test activities, methods, techniques and types of software artefacts. We also demonstrate the uses of the framework by two running examples.	test automation;web service	Hong Zhu;Yufeng Zhang	2014		10.1007/978-1-4614-7535-4_8	web testing;test harness	SE	-54.83861362699465	26.321476302926495	114819
1732b9da32146164bbfab298f568ecaeddfe2c21	ensuring architecture conventions in multi-site development	distributed development;software computer architecture xml unified modeling language java converters programming;software;validational tool support;software tools program verification software architecture software engineering;converters;tool support;multi site development software architecture software quality;validational tool multisite software development setting distributed development setup component interaction rules software engineering practice software validation validational tool support software creation;program verification;software engineering;component interaction rules;computer architecture;software engineering practice;software architecture;distributed development setup;multisite software development setting;global software engineering;software development;unified modeling language;xml;software tools;system architecture;multi site development;software validation;programming;software quality;validational tool;software engineering practices;software creation;java	In a multi-site software development setting, creational and validational activities can be distributed and carried out by separate teams. An example of such a distributed development setup is when a system implemented in site A needs to be validated in a remote site B with regard to the component interaction rules dictated by the system architecture. In the current software engineering practice, support has mainly focused on the software creation paying less attention to the needs of the validation phase, which however is becoming increasingly important due to global software engineering practices. This paper argues that systematic support should be provided to the software validation based on the assumptions used in the software creation using the example of component interactions. Furthermore, the paper presents validational tool support for such a systematic process applied to an industrial project. The findings and experiences of the case study are also reported.	anti-pattern;application release automation;experience;feedback;interaction;software development;software engineering;software system;software verification and validation;systems architecture;usability	Jakub Rudzki;Imed Hammouda;Tommi Mikkonen	2008	2008 32nd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2008.38	unified modeling language;software architecture;programming;personal software process;verification and validation;xml;software engineering process group;computer science;systems engineering;package development process;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;java;software deployment;goal-driven software development process;software development process;software requirements;software quality;systems architecture;software system;computer engineering;software peer review	SE	-53.15512757793763	28.54500914645908	115066
fb532cff22b4d9342b673f63b4d7a32eda6c03df	a tool suite for evolving legacy software	control systems;software tool;legacy software;software evolution tools;software tools computer architecture programming data mining strontium educational institutions control systems design methodology information analysis user interfaces;mission oriented architectural legacy evolution software reengineering process esprit de corps suite software evolution tools;software systems;data mining;strontium;software architecture systems re engineering software tools;development tool;computer architecture;software architecture;software evolution;mission oriented architectural legacy evolution software reengineering process;software tools;esprit de corps suite;legacy system;programming;reengineering;information analysis;user interfaces;before present;design methodology;systems re engineering	Evolving an existing software system is fundamentally different from developing one from scratch. Consequently, tools to support evolution must go beyond traditional development tools. This paper describes the Esprit de Corps Suite (EDCS) of software evolution tools. EDCS supports the Mission Oriented Architectural Legacy Evolution (MORALE) software reengineering process. The paper briefly describes MORALE before presenting the individual tools and how they interoperate to support legacy system evolution.	code refactoring;estimation of signal parameters via rotational invariance techniques;interoperability;legacy system;programming tool;software evolution;software system	Spencer Rugaber	1999		10.1109/ICSM.1999.792496	computer science;systems engineering;engineering;control system;software engineering;legacy system;computer engineering	SE	-52.198033262599694	28.1099141360544	115083
a0b3c1cf168776050ba278ac23ebbbdc0a4f1e7e	the brave new world of development in the internetwork computing architecture (internca): or how distributed computing platforms will change systems development	systems development methods;network computing architecture;distributed computing;computer architecture;new world;world wide web;system development;computing platforms;systems development	This essay is a speculation of the impact of the next generation technological platform — the internetwork computing architecture (InterNCA) — on systems development. The impact will be deep and pervasive and more substantial than when computing migrated from closed computer rooms to ubiquitous personal computers and flexible client-server solutions. Initially, by drawing upon the notion of a technological frame, the InterNCA, and how it differs from earlier technological frames, is examined. Thereafter, a number of hypotheses are postulated with regard to how the architecture will affect systems development content, scope, organization and processes. Finally, some suggestions for where the information systems research community should focus its efforts (if the call for relevance is not to be taken lightly) are proposed.	computer architecture;distributed computing;internetworking;software development process	Kalle Lyytinen;Gregory M. Rose;Richard J. Welke	1998	Inf. Syst. J.	10.1046/j.1365-2575.1998.00037.x	context-aware pervasive systems;simulation;computer science;engineering;theoretical computer science;software engineering;end-user computing;distributed computing;utility computing;world wide web;autonomic computing;systems design	HPC	-50.77262870608444	20.181856455566187	115101
36c03d850de63da9bc5d856b1e193bdb9077c1f5	using a foundational ontology for reengineering a software process ontology	unified foundational ontology;ontology reengineering;domain ontology;foundational ontology;software process	During project planning, knowledge about software processes is useful in several situations: software processes are defined, activities are scheduled, and people are allocated to these activities. In this context, standard software processes are used as basis for defining project processes, and tools are used to support scheduling, people allocation, and so on. Ideally, people and tools should share a common conceptualization regarding this domain for allowing interoperability, and correct use of the tools. A domain ontology can be used to define an explicit representation of this shared conceptualization. Moreover, for a domain ontology to adequately serve as a reference model, it should be built explicitly taking foundational concepts into account. This paper discusses the reengineering of part of a Software Process Ontology based on the Unified Foundational Ontology (UFO). The part reengineered concerns standard processes, project processes, and activities, which are analyzed at the light of UFO concepts.	code refactoring;conceptualization (information science);interoperability;ontology (information science);process ontology;reference model;scheduling (computing)	Ana Christina de Oliveira Bringuente;Ricardo de Almeida Falbo;Giancarlo Guizzardi	2011	JIDM		upper ontology;conceptualization;ontology alignment;bibliographic ontology;ontology inference layer;computer science;systems engineering;knowledge management;ontology;data mining;ontology chart;ontology-based data integration;process ontology;suggested upper merged ontology	SE	-54.27921307103557	19.75356994921855	115126
32fee5bf0ad95e6556e0f4cceb778491d35ce9fb	an 'extended execution time' software reliability model	software reliability predictive models software measurement software testing delay effects life testing parameter estimation product design availability velocity measurement;product life cycle;musa okumoto logarithmic model basic execution time model extended execution time model nonuniform program instruction execution software reliability growth models software product life cycle software characteristics branches loops measurable characteristics;software reliability growth model;software reliability	The use of sofhvare reliability growth models have become popular. However, the use of most such models is delayed until late in the sojiware product life-cycle (i.e., during testing) as they require failure time data to determine the model parameters. Currently, there is only one model, the Basic Execution Time (BET) model that can be applied earlier in the product life-cycle as its parameters can be related directly to sojiware characteristics. The derivation of the BET model implies uniform execution of program instructions. However, branches and loops in sofnvare programs result in non-uniform execution of program instructions. This paper introduces an extension of the BET model, the Extended Execution Time (EET) model that takes into account non-uniform execution of instructions. The non-uniform execution is accounted for by a parameter in the EET model that can be related to measurable characteristics of the sofhvare product. This paper further shows the EET model reduces to the BET when instruction execution is uniform and has behavior similar to the Musa-Okumto Logarithmic Model in the limit as instruction execution becomes highly non-uniform	run time (program lifecycle phase);software quality;software reliability testing	W. W. Everett	1992		10.1109/ISSRE.1992.285863	reliability engineering;real-time computing;simulation;software sizing;computer science;engineering;software reliability testing;product lifecycle;operating system;software construction;software testing;programming language;software quality;software metric;avionics software	Metrics	-62.562185764712936	32.02740920923473	115154
801259d87418442e8135b721608fafb23d819353	semi-automation for ambiguity resolution in open source software requirements	computers;requirements semi automation;ambiguity resolution mechanism;ossd ambiguity resolution mechanism open source software requirements requirements engineering re open source software development;software engineering;requirements engineering;public domain software;software engineering public domain software;human factors;communities context open source software computers algorithm design and analysis human factors;ossd;re;recommender based requirements;open source software development;ambiguity resolution;recommender based requirements requirements semi automation ambiguity resolution;communities;context;algorithm design and analysis;open source software requirements;open source software	The critical phase of Requirements Engineering (RE) is an active research domain for decades. The evolutions in RE over the years have improved them considerably but still many anomalies exist. It is especially true for the case of Open Source Software Development (OSSD) where most informal requirements and communications exist. With growing problems and extreme participant heterogeneity, the usual methods of ambiguity resolution do not seem to cater needs of OSSD community. For this purpose, various interdisciplinary mechanisms can be used to aid the community members and reach a consensus based agreement along with reaching unambiguous requirements sets. A framework is proposed for resolving the burdening problems of OSSD context. Framework components are discussed in detail to give an overview of developable ambiguity resolution strategies.	open-source software;reaching definition;requirement;requirements engineering;semiconductor industry;software development;software requirements	Kanwal Daud Gill;Arif Raza;Athar Mohsin Zaidi;Muhammad Muneeb Kiani	2014	2014 IEEE 27th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2014.6900955	algorithm design;computer science;systems engineering;software engineering;database;requirements engineering;public domain software	SE	-62.77784396855519	21.676405720721153	115490
32a070c5905f1cd74dc3a18ea74b7f790ecbafad	in search of the system concept	project management;mediated communication;requirements document;software systems;software development management project management;software project development;system concepts;requirements;motion pictures urban planning programming process design information management time factors supply and demand environmental economics computer science cities and towns;software development;software system design;software development requirements system concepts;system concept;software development management;software system design requirements document software project development system concept	Requirements documents are often tedious to construct, difficult to manage, and poor for mediating communication between stakeholders during a software development project. Using system concepts can simplify the way you determine, handle, and communicate requirements in a busy world. They could even help you design more innovative software systems	requirement;software development;software system	Olly Gotel	2006	IEEE Software	10.1109/MS.2006.17	project management;requirements analysis;personal software process;software requirements specification;verification and validation;software project management;computer science;systems engineering;engineering;knowledge management;package development process;software design;social software engineering;software development;software design description;software engineering;software construction;systems development life cycle;software walkthrough;resource-oriented architecture;management;software deployment;goal-driven software development process;software development process;software requirements;software system;software peer review	SE	-58.817636657331136	19.951816771843603	115513
63001f47b161ff2a301198160643f1af20c7c158	service-oriented architectures testing: a survey	integration testing;regression testing;performance test;functional testing;service oriented architecture;automated negotiation	Testing of Service Oriented Architectures (SOA) plays a cri tical role in ensuring a successful deployment in any enterprise. SOA t esting must span several levels, from individual services to inter-enterpr ise federations of systems, and must cover functional and non-functional aspects. SOA unique combination of features, such as run-time discov ery of services, ultra-late binding, QoS aware composition, and SLA automat ed negotiation, challenge many existing testing techniques. As an example, runtime discovery and ultra-late binding entail that the actual configuration of a system is known only during the execution, and this makes many existing integrat ion testing techniques inadequate. Similarly, QoS aware composition and SLA autom a ed negotiation means that a service may deliver with different performance s in different contexts, thus making most existing performance testing techn iques to fail. Whilst SOA testing is a recent area of investigation, the lit era ure presents a number of approaches and techniques that either extend traditi onal testing or develop novel ideas with the aim of addressing the specific problems o f testing servicecentric systems. This chapter reports a survey of recent res ea ch achievements related to SOA testing. Challenges are analyzed from the vie wpoints of different stakeholders and solutions are presented for different lev els of testing, including unit, integration, and regression testing. The chapter cov ers both functional and non-functional testing, and explores ways to improve the te stability of SOA.	cri adx;functional testing;late binding;non-functional testing;quality of service;regression testing;service-level agreement;service-oriented architecture;software deployment;software performance testing;while;xilinx ise	Gerardo Canfora;Massimiliano Di Penta	2008		10.1007/978-3-540-95888-8_4	test strategy;reliability engineering;simulation;software performance testing;system integration testing;systems engineering;engineering;acceptance testing;software testing;non-functional testing;system testing	SE	-59.304699080892	21.124504654808636	115556
1f8c174e213284b89d64b8923166068799082c46	applying a model driven approach to an e-business environment	whi;business environment;palabras clave;business process;high risk	Resumen. Traditionally, the implementation of business processes in IT systems is based on the oral transmission of requirements between business and IT experts. This involves a high risk of misunderstanding and loss of information, which may result in the failure of the project, losing time and money. This paper presents the application of a MDA approach to bridge the gap between these domains, business and IT. This is done by applying of a set of automatic transformations, which ensure the coherence between business processes and IT systems. In addition, this paper concludes with several adoption problems and benefits of this approach.	automatic control;business process execution language;business requirements;eclipse modeling framework;electronic business;list of unified modeling language tools;metamodeling;model transformation;model-driven architecture;platform-independent model;profile (uml);requirement;separation of concerns;sourceforge;traceability;web services description language	Xabier Larrucea;Gorka Benguria	2006			simulation;engineering;artifact-centric business process model;operations management;management	SE	-56.57070860174421	20.221587569880132	115700
ee001b2a8dc4adb95540db09399983b3706df9e8	ontologies as knowledge representation structures for cacsd software	lead lag controller design;knowledge representation structure;control systems;software engineering control system cad ontologies artificial intelligence;control theory;lead lag controller design ontology knowledge representation structure cacsd software model based software development artificial intelligence software engineering conceptual structure computer aided control system design control engineering;control engineering;usa councils;model based software development;control system cad;software engineering;ontologies artificial intelligence;artificial intelligent;conceptual structure;software development;cacsd software;control systems usa councils;artificial intelligence;computer aided control system design;knowledge representation;domain ontology;ontology;knowledge modeling	In the software building practice there is today a shift toward model based software development, rooted in the ideas coming from artificial intelligence and software engineering. The so-called domain ontologies are the conceptual structures where the knowledge models are represented. This paper shows the possibilities of the use of ontologies as the main components for computer-aided control system design applications. The paper shows how control engineering knowledge can be represented into an ontology and how this representation can be used inside a software application. An example is presented based on the development of an ontology and an application for the design of lead-lag controllers with techniques from the classical control theory.	artificial intelligence;control engineering;control system;control theory;knowledge representation and reasoning;ontology (information science);software development;software engineering;systems design	Carmen Benavides;Isaías García;Héctor Alaiz-Moretón;Javier Alfonso-Cendón;Carlos Redondo;Ángel Alonso	2008	2008 IEEE International Conference on Computer-Aided Control Systems	10.1109/CACSD.2008.4627365	domain analysis;idef5;software mining;computer science;systems engineering;knowledge management;ontology;software design;social software engineering;software framework;component-based software engineering;software development;software design description;domain engineering;software construction;data mining;commonsense knowledge;resource-oriented architecture;software development process;software requirements;process ontology;software system	SE	-51.66100806444178	25.722245881155686	115824
c92fffe0de09b229567525dc8f3c287a03a9c73d	ontology based method engineering	domain knowledge;requirement engineering;ontology;method engineering;process model;process modelling	We need conceptual modelling languages to gain domain knowledge in the requirements engineering and analysis phases of an IS development project. These languages should serve an IS expert as means of communication between him or her and the domain expert. Many different modelling languages have been used for conceptual modelling. Consequently, questions relating to the quality of these languages have arisen. Wand, Weber and others have evaluated these languages using an ontology. Each of the languages was found to contain certain deficits. Because our aim is to construct a language without such deficits, we propose the opposite technique. We develop an ontologically clear modelling language for process modelling with the help of the BWW representational model. In addition to this modelling language, we introduce a process model which guides model creation. Both components form a conceptual modelling method.		Andreas Gehlert;Uta Buckmann;Werner Esswein	2005			conceptual model (computer science);knowledge management;domain knowledge;computer science;domain model;subject-matter expert;requirements engineering;natural language processing;method engineering;process modeling;artificial intelligence;ontology language	SE	-53.7208565411869	21.80133988052172	115881
41b85b01abf0c05cc46cf1e0aeb7802a78190c72	component deployment optimisation with bayesian learning	swinburne;posterior probability;bayesian learning;component deployment;design space exploration;embedded software;architecture optimisation	Implementing embedded software systems involves many important design decisions, such as finding (near) optimal component deployment architectures, that have a strong influence on the quality of the final system perceived by its users. These decisions are difficult not only because of the complexity of current systems, but also due to the large number of possible design options. An automation of the design space exploration will help to make better decisions and to reduce the time of this process. In this paper, a new method called Bayesian Heuristic for Component Deployment Optimisation (BHCDO) is proposed. BHCDO constructs solutions based on a Bayesian learning mechanism which guides the search for assignments that result in new deployment architectures with an improved quality. This is achieved by calculating the posterior probability that a particular component/host assignment is a good decision, resulting in a high quality deployment architecture, given some observed evidence during the search. Experiments on a series of randomly generated problems show that BHCDO efficiently automates the search for component deployment design alternatives and outperforms state of the art optimisation methods.	design space exploration;display resolution;embedded software;embedded system;experiment;heuristic;mathematical optimization;procedural generation;software deployment;software system	Aldeida Aleti;Indika Meedeniya	2011		10.1145/2000229.2000232	simulation;embedded software;deployment diagram;computer science;engineering;machine learning;data mining;posterior probability;bayesian inference	AI	-56.49964193595031	30.616444468575786	115893
bc74fc0ef40daed7c91c4bc84a3507de949aa06b	constructing a toolset for software maintenance with ooag	attribute grammars;ag;extensibility;electrical capacitance tomography;application framework;reusability;software prototyping;software maintenance;prototypes;general techniques;object oriented programming;object oriented attribute grammar;attribute grammar;rapid prototyping;graphical user interfaces;object oriented;incomplete program fragments software maintenance object oriented attribute grammar model view shape ag object oriented extension rapid prototyping reusability extensibility associated flow information program slicer;proceedings paper;software maintenance prototypes laboratories object oriented modeling electrical capacitance tomography computer science electronic switching systems context modeling graphical user interfaces information analysis;incomplete program fragments;electronic switching systems;program slicer;object oriented extension;computer science;attribute grammars software maintenance software prototyping object oriented programming;context modeling;information analysis;object oriented modeling;model view shape;associated flow information	This paper presents a model called object-oriented attribute grammar (OOAG) that can be used to construct a toolset for software maintenance. The kernel of OOAG consists of two inter-related parts: a model-view-shape (MVS) application framework and an AG++, an object-oriented extension to traditional AGs. By combining compositional and generative techniques seamlessly, OOAG preserves both advantages introduced by respective OO and AG models, such as rapid prototyping, reusability, extensibility, and incrementality. So far, a toolset prototype consisting of a number of programming and maintenance tools were implemented using OOAG on the Windows environment. The editors developed can be used to construct programs by specifying the associated flow information in explicit (visual) or implicit (textual) ways, while the (incremental) maintenance tools, such as DU/UD tools and a program slicer, can help analyze incomplete program fragments to locate and inform the user of useful information.	programming tool;software maintenance	Chung-Hua Hu;Ji-Tzay Yang;Feng-Jian Wang;William C. Chu	1998		10.1109/APSEC.1998.733740	computer science;theoretical computer science;software engineering;database;programming language;object-oriented programming	SE	-48.384092543792164	27.40874785053126	115929
8f47a6ff94fd885b45ffcb68dce1caaa398f4cfc	simulated satisfaction of coverage criteria on uml state machines	coverage criteria;software testing;semantic preserving state machine transformations;simulated satisfaction relations;uml state machines testing coverage criteria model transformations;compounds;articulo;model based test generation tools;automatic testing;semantics;model transformation;state machine;unified modeling language system testing automatic testing software testing embedded system costs;testing;satisfiability;semantic preserving state machine transformations uml state machines simulated satisfaction relations model based test generation tools;embedded system;uml state machines;model transformations;finite state machines;adaptation model;simulated satisfaction of coverage criteria on uml state machines;program testing;pattern matching;unified modeling language finite state machines program testing;unified modeling language;transforms;system testing;model based testing	UML state machines are widely used as test models in model-based testing. Coverage criteria are applied to them, e.g. to measure a test suite's coverage of the state machine or to steer automatic test suite generation based on the state machine. The model elements to cover as described by the applied coverage criterion depend on the structure of the state machine. Model transformations can be used to change this structure. In this paper, we present semantic-preserving state machine transformations that are used to influence the result of the applied coverage criteria. The contribution is that almost every feasible coverage criterion that is applied to the transformed state machine can have at least the same effect as any other feasible, possibly stronger coverage criterion that is applied to the original state machine. We introduce simulated satisfaction as a corresponding relation between coverage criteria. We provide formal definitions for coverage criteria and use them to prove the correctness of the model transformations that substantiate the simulated satisfaction relations. The results of this paper are especially important for model-based test generation tools, which are often limited to satisfy a restricted set of coverage criteria.	code coverage;correctness (computer science);finite-state machine;model transformation;model-based testing;test suite;uml state machine;unified modeling language	Stephan Weißleder	2010	2010 Third International Conference on Software Testing, Verification and Validation	10.1109/ICST.2010.28	modified condition/decision coverage;reliability engineering;computer science;theoretical computer science;software engineering;data mining;software testing;finite-state machine;programming language	SE	-57.1270372311306	29.950933176264506	116072
4323ad0a7786d7a4b9fec88d1753447aca53a87b	towards a model of user-centered privacy preservation		The growth in cloud-based services tailored for users means more and more personal data is being exploited, and with this comes the need to better handle user privacy. Software technologies concentrating on privacy preservation typically present a one-size fits all solution. However, users have different viewpoints of what privacy means to them and therefore, configurable and dynamic privacy preserving solutions have the potential to create useful and tailored services without breaching any user's privacy. In this paper, we present a model of user-centered privacy that can be used to analyse a service's behaviour against user preferences, such that a user can be informed of the privacy implications of that service and what fine-grained actions they can take to maintain their privacy. We show through study that the user-based privacy model can: i) provide customizable privacy aligned with user needs; and ii) identify potential privacy breaches.	access control;adobe flash player;algorithm;business process model and notation;cloud computing;computation;control system;extensibility;fits;formal language;information privacy;internet privacy;model transformation;model-driven architecture;ontology (information science);personally identifiable information;privacy;user (computing);user-centered design;vocabulary	Paul Grace;Mike Surridge	2017		10.1145/3098954.3104054	privacy by design;computer security;software;computer science;information privacy;internet privacy;cloud computing;privacy software	Security	-56.81327617943074	20.252227944024607	116079
dda512323cad3e2d4c7e1a6178bc05b63579b317	the growth of software testing	debugging;puesta a punto programa;software testing;test programa;metodologia;mise au point programme;ingenieria logiciel;software engineering;methodologie;prevention;genie logiciel;process model;methodology;test programme;program test;prevencion	We can trace the evolution of software test engineering by examining changes in the testing process model and the level of professionalism over the years. The current definition of a good software testing practice involves some preventive methodology.	process modeling;software testing;unit testing	David Gelperin;Bill Hetzel	1988	Commun. ACM	10.1145/62959.62965	non-regression testing;test strategy;black-box testing;verification and validation;regression testing;simulation;preventive healthcare;software performance testing;white-box testing;manual testing;system integration testing;computer science;acceptance testing;package development process;software reliability testing;software development;software engineering;software construction;process modeling;methodology;risk-based testing;software testing;debugging;test management approach;software quality analyst	SE	-62.10130421416712	31.31854686101032	116085
702130bdb9a848619683ea6d0c1ece92bb3484de	editorial: special issue on verification and validation	knowledge based system;artificial intelligent;verification and validation;knowledge engineering	As for any software , users of knowledge-based systems (KBS) need to know that they can rely on the system to do its job properly. Assuring the reliability of knowledge-based systems has become an important issue in the development of the knowledge engineering discipline. The processes employed directly to assure the reliability of software are called verification and validation (V & V). Roughly speaking , ␷ alidation is the process of determining if a KBS meets its users' requirements ; ␷ erification is the process of determining if a KBS has been constructed to comply with certain formally-specified properties , such as consistency and irredundancy. Implicitly , validation includes verification. Verification and validation techniques for KBS have been discussed and debated in workshops at many of the predominant artificial intelligence conferences in recent years. The purpose of this special issue is to provide ''snapshots'' of the current state of the V & V area for KBS , by collecting together representative works from three of the most recent workshops : These workshops succeeded in highlighting many of the significant issues and trends within their area of concern. These issues and trends are reflected in the articles selected for this issue , the authors of which have expanded and updated their original workshop papers. The purpose of this introduction is to highlight some of the issues and trends in KBS V & V , to put this collection in its context. In recent years , the main technological theme in the KBS validation area has been the development of tools for automatic verification of knowledge bases. Within this sub-area , the dominant concern has been with the ''first generation'' type of rule-based systems , and the verification has been aimed at detecting anomalies — such as subsumed or conflicting rules—which are symptomatic of logical faults in the knowledge base. The paper by Murrel and Plant of fers a mature view of this kind of verification , wherein the rule base is modelled using graph theory , and the anomalies are defined in graph-theoretic terms .	artificial intelligence;graph theory;knowledge-based systems;need to know;requirement;rule-based system;sensor;verification and validation	Robert Plant;Alun D. Preece	1996	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1996.0006	verification and validation;computer science;artificial intelligence;knowledge engineering;data mining;operations research	AI	-62.303592023478366	18.76624898466939	116232
400a971c04db63aa2ab86e41b20b4874878a3cc6	towards domain-driven development: the smarttools software factory	software configuration management;object oriented;domain specific language;version control	Nowadays, software needs to be more open, flexible, and capable of evolving quickly to meet new user or technology requirements. It should be easy to adapt, even by none computer-specialists. To tackle these challenges for DSL (<i>Domain-Specific Language</i>) tools, we have developed a software factory, named <sc>SmartTools</sc>.	digital subscriber line;requirement;software factory	Didier Parigot	2004		10.1145/1028664.1028685	software configuration management;computer science;revision control;domain-specific language;software development;software construction;programming language;object-oriented programming	SE	-52.42156946727474	29.509296620703374	116276
1a76b415214f40cece31ddfdea38d426e0ff4b61	a model driven development platform for service-oriented applications	libraries;mda;mda development platform soa;service orientation;contracts;soa;model driven development platform;model driven development;computer architecture;software architecture;computational modeling;adaptation model;unified modeling language;service oriented architecture application software computer architecture software systems programming buildings helium computer science laboratories software tools;service oriented applications;service oriented architecture;model driven architecture;development platform;model driven architecture model driven development platform service oriented applications service oriented architecture	A great deal of the achievement on model driven development and service-oriented architecture has been gained, but there are few tools for systematically supporting model driven development for service-oriented applications. This paper presents a model driven development platform for service-oriented applications. The paper first sets forth the architecture of the platform, and then discusses the infrastructure and implementation technologies of the platform in detail. On the basis of above work, the paper expatiates on a set of tools that constitute the platform and the relations between tools.	business process definition metamodel;metamodeling;model-driven engineering;profile (uml);service-oriented architecture;service-oriented device architecture;unified modeling language	Zhiyi Ma;Xiao He;Lianghuan Kang	2009	2009 World Conference on Services - II	10.1109/SERVICES-2.2009.14	systems engineering;engineering;software engineering;computer engineering	Robotics	-52.51706303100249	27.70074478680702	116357
6657de3910a666cc72d8a1941faf13f1981916ae	rewriting rule-based model for aspect-oriented software evolution	source code modelling;aop;graph rewriting;software evolution;aspect oriented programming;software development;attributed coloured graphs;reverse engineering	Software is evolutionary in nature. From the time a software product is defined until it is no longer used, it changes. We focus in this paper on the aspect-oriented (AO) software evolution. Although AO software engineering is the subject of ongoing research, AO software evolution has received less attention. AO programming is a mature technology that modularises the crosscutting concerns. Unfortunately, it produces new dependencies between them; restricts the evolvability of the software system. In order to cope with all types of AO program's dependencies, we converge toward a new evolution modelling approach. In our proposal, the AO source code is modelled in a more abstract and formal format as an attributed coloured graph, where the different dependencies in the software system are well defined. Then, the change requests are presented as rewritten rules on this coloured graph. We give here the details of our approach as well as its implementation. And, we provide an empirical evaluation to prove the e...	aspect-oriented software development;logic programming;rewriting;software evolution	Hanene Cherait;Nora Bounour	2016	IJCAT	10.1504/IJCAT.2016.10001314	software visualization;aspect-oriented programming;software sizing;computer science;systems engineering;artificial intelligence;software design;software framework;component-based software engineering;software development;software design description;operating system;software construction;programming language;algorithm;static program analysis	SE	-54.62185879450339	29.62684240098751	116460
2e247ca34f408e3ae5aeb415d29f4c88aa078d3b	a large-scale technology evaluation study: effects of model-based analysis and testing		Besides model-based development, model-based quality assurance and the tighter integration of static and dynamic quality assurance activities are becoming increasingly relevant in the development of software-intensive systems. Thus, this paper reports on an empirical study aimed at investigating the promises regarding quality improvements and cost savings. The evaluation comprises data from 13 industry case studies conducted during a three-year large-scale research project in the transportation domain (automotive, avionics, rail system). During the evaluation, we identified major goals and strategies associated with (integrated) model-based analysis and testing and evaluated the improvements achieved. The aggregated results indicate an average cost reduction of between 29% and 34% for verification and validation and of between 22% and 32% for defect removal. Compared with these cost savings, improvements regarding test coverage (~8%), number of remaining defects (~13%), and time to market (~8%) appear less noticeable.	avionics;fault coverage;model-driven engineering;software bug;software quality assurance;verification and validation	Michael Kläs;Thomas Bauer;Andreas Dereani;Thomas Soderqvist;Philipp Helle	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering		program assurance;reliability engineering;qa/qc;verification and validation;model-based testing;simulation;systems engineering;engineering;software reliability testing;software engineering;functional testing;software construction;software testing;empirical research;software quality control;software metric;software quality analyst	SE	-62.782566040479125	29.70409628015633	116525
c5c573e9b704aa3f1980605ec8457ce5090697fe	an evolutionary lifecycle model with agile practices for software development at abb	cycle time;programming application software process control software quality face humans software prototyping prototypes predictive models collaboration;technology development;software development lifecycle models evolutionary lifecycle model agile practices agile development in evolutionary prototyping technique adept software development abb organization industrial it initiative;software engineering;agile development;human resource;software development;research initiatives software engineering;research initiatives	"""Current software environments face increased pressure to develop products under evolving requirements, changing technologies, scarce human resources, and the need to develop high quality applications. ABB has similar pressures, especially as the organization embraces the Industrial IT initiative that aims at the development of interoperable and intelligent products. A new generation of software development lifecycle models has emerged lately called """"Agile"""" and they embrace change, reduce development cycle time, and attempt a useful compromise between no process and too much process. The Agile Development in Evolutionary Prototyping Technique (ADEPT) presented in this paper, was developed at the ABB US Corporate Research Center, and incorporates """"Agile"""" practices to streamline the technology development lifecycle of Industrial IT products."""	adobe streamline;agile software development;display resolution;interoperability;requirement;software development process;software prototyping	Aldo Dagnino	2002	Eighth IEEE International Conference on Engineering of Complex Computer Systems, 2002. Proceedings.	10.1109/ICECCS.2002.1181514	requirements analysis;personal software process;verification and validation;agile unified process;extreme programming practices;agile usability engineering;human resources;cycle time variation;systems engineering;engineering;package development process;social software engineering;software development;requirement;software engineering;iterative and incremental development;software construction;agile software development;systems development life cycle;application lifecycle management;empirical process;lean software development;goal-driven software development process;software development process;best coding practices	Robotics	-62.594452184814	23.507808758586446	116561
8c5ef99bc5b8a9d8eab75f88ad14e93c082678a2	distributed case-based support for the architectural conceptualization phase		For the early phase of conceptualization in the architectural design a case-based retrieval approach for finding building designs that have similar semantic and topological structures to a currently created one, can provide a helpful tool for inspiration and comparison of architect’s own ideas with the solutions available in a case base of previously created designs. The approach presented in this research summary is aimed to provide such a tool that can deal with queries and cases that can be represented as graphs. Moreover, in the late phases of the research, the approach should be extended for application beyond architectural design and provide a generic framework for distributed case-based search of similar graphs for other suitable domains. Constraints of the search, explanations, initialization of the case base, and the knowledge about user behaviour are the important aspects of the concept of the framework.	conceptualization (information science);graph (discrete mathematics);software architecture	Viktor Ayzenshtadt	2015			conceptualization;systems engineering;engineering	AI	-53.12904094928093	23.90773978055074	116686
2f8a4ae486bad8e4f9f72af85463ca72ed4e89f7	hardware/software co-training lab: from vhdl bit-level coding up to case-tool based system modeling	hardware software codesign;system modeling;inter disciplinary lab course hardware software co training lab vhdl bit level coding case tool based system modeling hardware development education software development education university courses;hardware description languages;hardware modeling computer industry software design mathematical model laboratories software tools industrial training design engineering programming profession;software engineering;computer science education;computer aided software engineering;educational courses;software development;case tool;electronic engineering education;educational courses hardware software codesign hardware description languages computer aided software engineering electronic engineering education software engineering computer science education	This paper focuses on the combination of educating hardware as well as software development in one laboratory. The needs to offer such a co-training concept arise from the demands of industry towards the desired skills of today's engineers. Their view must no longer be restricted to his/her own work, but has to be widened to a complete system view. To provide an appropriate educational scheme, the university courses have to adapt to these changes. Therefore an innovative lab concept is presented here. The goal is to improve student's skills in multiple directions to deliver an efficient inter-disciplinary hardware/software lab course, based on the training of state-of-the-art industrial architectures and relevant tools.	bit-level parallelism;co-training;industrial robot;software development;systems modeling;vhdl	Carsten Bieser;Klaus D. Müller-Glaser;Jürgen Becker	2005	2005 IEEE International Conference on Microelectronic Systems Education (MSE'05)	10.1109/MSE.2005.34	personal software process;verification and validation;computing;software engineering process group;computer science;systems engineering;package development process;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;hardware architecture;software walkthrough;resource-oriented architecture;software deployment;computer-aided software engineering;software requirements;software system;computer engineering;software peer review	Robotics	-49.2576307161851	32.01208487752444	117431
0da420e1a6b752b4e855472d7dc7f8f057598188	saam: a method for analyzing the properties of software architectures	formal specification;software engineering;systems analysis;user interfaces;saam;software architecture analysis method;modifiability quality;organization life cycle;software architecture analysis;software maintainability;software modularity;software portability;software quality;software reusability;user interface	While software architecture has become an increasingly important research topic in recent years, insufficient attention has been paid to methods for evaluation of these architectures. Evaluating architectures is difficult for two main reasons. First, there is no common language used to describe different architectures. Second, there is no clear way of understanding an architecture with respect to an organization’s life cycle concerns—software quality concerns such as maintainability, portability, modularity, reusability, and so forth. This paper addresses these shortcomings by describing three perspectives by which we can understand the description of a software architecture and then proposing a five-step method for analyzing software architectures called SAAM (Software Architecture Analysis Method). We illustrate the method by analyzing three separate user interface architectures with respect to the quality of modifi-	software architecture analysis method;software portability;software quality;user interface	Rick Kazman;Leonard J. Bass;Mike Webb;Gregory D. Abowd	1994			reference architecture;quality assurance;software architecture;database-centric architecture;computer science;systems engineering;component-based software engineering;software design description;software engineering;software construction;software architecture description;user interface;resource-oriented architecture;computer engineering	SE	-52.69542969529135	28.487689362416532	117576
445db9c33639e4b14daa9852074510d01f071460	tube: interactive model-integrated object-oriented programming.	programming language;topic maps;object oriented programming;software design and development;software engineering;model integration;interaction model	Software engineering is hampered by the fact that software systems quickly become so complex that they are hard to understand, evolve and maintain. Closer integration of code and model helps, because the model serves as a map to the code and the code fills in the details for the model. Simultaneously, one avoids consistency problems. T UBE, a programming language and an integrated environment, achieves this integration by using topic mapsto manage both code and data (including meta-data and non-code artifacts). This enhanced expressiveness is complemented by an interactive way of system construction that cannot be achieved by static programming languages.	apl;comparison of command shells;dynamic programming;integrated development environment;knowledge representation and reasoning;object language;programming language;prototype;python;software engineering;software system;synergy	Axel Rauschmayer;Patrick Renner	2004			natural language processing;first-generation programming language;very high-level programming language;extreme programming practices;programming domain;reactive programming;functional reactive programming;computer science;software design;theoretical computer science;component-based software engineering;software development;extensible programming;functional logic programming;software construction;computer programming;programming paradigm;procedural programming;symbolic programming;inductive programming;programming language theory;programming language;system programming;programming in the large and programming in the small	SE	-50.659800891624585	28.85255609470269	117593
060ea9d14167f2d1b29097d79cd854960efea167	activity-centered domain characterization for problem-driven scientific visualization		Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage—and its evaluation—of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature.	data visualization;end-to-end principle;functional specification;imagery;nih roadmap initiative tag;programming paradigm;requirement;requirements engineering;scientific visualization;software engineering;user-centered design	G. Elisabeta Marai	2018	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2017.2744459	data visualization;theoretical computer science;requirements engineering;visualization;scientific visualization;functional specification;data modeling;visual analytics;computer science;information visualization	Visualization	-55.17521820003706	23.74696047566992	117635
43cff872c115119ace4fbeb1709d5df5efa74c6e	multi-paradigm process management.	system engineering;multiple instance;process management;method integration;process support;system integration;enterprise information system;enterprise system;process model;business process	Automation and integration of business processes are at the heart of contemporary enterprise systems. In the pursuit of this goal, process automation technology is employed at varying levels of the enterprise information systems architecture. Larger organizations are faced with multiple instances of process management systems, each of which may provide a different paradigm for capturing, representing and executing processes. Still, each of these systems provides unique process support functionality that may not be covered by the other systems. Current systems integration methods focus mainly on the technical connectivity between these disparate systems. They do not address the integration of multiple process modeling methods that may exist in enterprise applications. This paper discusses the method integration necessary to bridge the gap between the high-level process models and the executable workflow definitions. We propose a structured methodology for the systematic design of enterprise processes that takes advantage of the capabilities of different modeling methods, while maintaining a consistent view of enterprise processes across multiple platforms. Using such an approach, business analysts and system engineers can follow a stepwise procedure that will minimize overlap and redundancy in enterprise processes, and maximize integration potential between applications. We call this approach Multi-Paradigm Process Management (MPM).	automation;business process;cognitive dimensions of notations;enterprise architecture;enterprise information system;enterprise software;enterprise system;executable;high- and low-level;material point method;modeling language;process modeling;programming paradigm;software framework;stepwise regression;system integration;systems architecture	Michael zur Muehlen;Michael Rosemann	2004			manufacturing execution system;enterprise system;enterprise application integration;enterprise systems engineering;enterprise software;computer science;systems engineering;knowledge management;business process management;digital firm;process modeling;database;business process model and notation;process management;business process;event-driven process chain;process mining;enterprise integration;management process;management;business process modeling;enterprise planning system;enterprise information system;enterprise information integration;system integration;enterprise life cycle	DB	-56.32799696027286	18.25610718511927	117675
9e030c2e138fd05710527a85006be8a0ef09dc1a	seaflows - a compliance checking framework for supporting the process lifecycle		Compliance-awareness is undoubtedly of utmost importance for companies nowadays. Even though an automated approach to compliance checking and enforcement has been advocated in recent literature as a means to tame the high costs for compliance-awareness, the potential of automated mechanisms for supporting business process compliance is not yet depleted. Business process compliance deals with the question whether business processes are designed and executed in harmony with imposed regulations. In this thesis, we propose a compliance checking framework for automating business process compliance verification within process management systems (PrMSs). Such process-aware information systems constitute an ideal environment for the systematic integration of automated business process compliance checking since they bring together different perspectives on a business process and provide access to process data. The objective of this thesis is to devise a framework that enhances PrMSs with compliance checking functionality. rnAs PrMSs enable both the design and the execution of business processes, the designated compliance checking framework must accommodate mechanisms to support these different phases of the process lifecycle.rnA compliance checking framework essentially consists of two major building blocks: a compliance rule language to capture compliance requirements in a checkable manner and compliance checking mechanisms for verification of process models and process instances. Key to the practical application of a compliance checking framework will be its ability to provide comprehensive and meaningful compliance diagnoses. rnBased on the requirements analysis and meta-analyses, we developed the SeaFlows compliance checking framework proposed in this thesis. We introduce the compliance rule graph (CRG) language for modeling declarative compliance rules. The language provides modeling primitives with a notation based on nodes and edges. A compliance rule is modeled by defining a pattern of activity executions activating a compliance rule and consequences that have to apply once a rule becomes activated.rnIn order to enable compliance verification of process models and process instances, the CRG language is operationalized.rnKey to this approach is the exploitation of the graph structure of CRGs for representing compliance states of the respective CRGs in a transparent and interpretable manner. For that purpose, we introduce execution states to mark CRG nodes in order to indicate which parts of the CRG patterns can be observed in a process execution. By providing rules to alter the markings when a new event is processed, we enable to update the compliance state for each observed event.rnThe beauty of our approach is that both design and runtime can be supported using the same mechanisms. Thus, no transformation of compliance rules in different representations for process model verification or for compliance monitoring becomes necessary. At design time, the proposed approach can be applied to explore a process model and to detect which compliance states with respect to imposed CRGs a process model is able to yield. At runtime, the effective compliance state of process instances can be monitored taking also the future predefined in the underlying process model into account. As compliance states are encoded based on the CRG structure, fine-grained and intelligible compliance diagnoses can be derived in each detected compliance state. Specifically, it becomes possible to provide feedback not only on the general enforcement of a compliance rule but also at the level of particular activations of the rule contained in a process. rnIn case of compliance violations, this can explain and pinpoint the source of violations in a process. In addition, measures to satisfy a compliance rule can be easily derived that can be seized for providing proactive support to comply.rnAltogether, the SeaFlows compliance checking framework proposed in this thesis can be embedded into an overall integrated compliance management framework.		Linh Thao Ly	2013			reliability engineering;engineering;operations management;data mining	Robotics	-55.252601253018426	19.8934010621816	117894
0d497cdadd8d90c32c83e444e39917dd5d177177	assessing diagnostics for fault tolerant software	fault tolerant;safety critical system	Reliability is of prime importance in computer-based safety critical systems where failure can lead to fatal consequences. Fault tolerant techniques in software have a vital role to play, because veri cation and validation techniques cannot guarantee that software is error free. Fault tolerance further improves the reliability of the system by ensuring it continues to operate safely when residual software errors are encountered. On line diagnosis is a critical aspect of software fault tolerance. At the present time however, there is a lack of any real guidance or understanding of how in practice to use online diagnostics e ectively and e ciently. For a particular program design it is di cult to reason about what an e ective diagnostic strategy should be, because our current level of understanding of software design errors is so poor. This thesis proposes that through a controlled process of experimentation, aimed at investigating the way software behaves in the presence of simulated faults, our understanding can be improved. In this thesis an empirical method is developed, and demonstrated, which aims to increase our understanding of the key factors in uencing the fault detection capabilities of on-line diagnostics. The experiments presented illustrate the potential of this approach and provide new insights of signi cance into the relevance of these factors. These experiments lay the foundations for a longer term progressive and controlled process of experimentation. Only by continuing the experimental process in this way will it be possible to move towards a better understanding of how to design e ective diagnostics for fault tolerant software.	experiment;fault detection and isolation;fault-tolerant software;online and offline;relevance;software design;software fault tolerance	John Napier	2001			reliability engineering;software fault tolerance	SE	-61.443393009009505	31.26965077980441	118062
3a8bfe70f2a052e1a12fef419d64de3c6afb12f1	on the use of genetic programming for automated refactoring and the introduction of design patterns	software metrics;automated design;genetic program;evolutionary computation;refactoring;object oriented design;search based software engineering;software engineering;design pattern;software metric;design patterns;software design;intelligent search;evolutionary computing	Maintaining an object-oriented design for a piece of software is a difficult, time-consuming task. Prior approaches to automated design refactoring have focused on making small, iterative changes to a given software design. However, such approaches do not take advantage of composition of design changes, thus limiting the richness of the refactoring strategies that they can generate. In order to address this problem, this paper introduces an approach that supports composition of design changes and makes the introduction of design patterns a primary goal of the refactoring process. The proposed approach uses genetic programming and software engineering metrics to identify the most suitable set of refactorings to apply to a software design. We illustrate the efficacy of this approach by applying it to a large set of published models, as well as a real-world case study	code refactoring;experiment;genetic programming;iteration;principle of abstraction;software design pattern;software engineering;software metric;software system	Adam C. Jensen;Betty H. C. Cheng	2010		10.1145/1830483.1830731	software design pattern;software sizing;architectural pattern;search-based software engineering;computer science;software design;component-based software engineering;software development;software design description;object-oriented design;continuous design;software construction;distributed design patterns;programming language;resource-oriented architecture;software maintenance;structural pattern;computer-aided software engineering;goal-driven software development process;code refactoring;software metric;evolutionary computation	SE	-55.05518096014191	30.398476955086082	118096
1b0adcf3ad6532fc913fab4879fbbbaf5aaa0fb3	a classification and survey of analysis strategies for software product lines	software analysis;theorem proving;product line analysis;type checking;model checking;program family;static analysis;software product line	Software-product-line engineering has gained considerable momentum in recent years, both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques, such as type checking, model checking, and theorem proving, in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible, due to the potentially exponential number of valid feature combinations. Recently, researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account, for example, by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse, so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles, we develop a research agenda to guide future research on product-line analyses.	automated theorem proving;correctness (computer science);model checking;software product line;spatial variability;text corpus;time complexity;type system	Thomas Thüm;Sven Apel;Christian Kästner;Ina Schaefer;Gunter Saake	2014	ACM Comput. Surv.	10.1145/2580950	domain analysis;model checking;verification and validation;software sizing;computer science;package development process;software framework;software development;software design description;software analysis pattern;software construction;data mining;database;automated theorem proving;software walkthrough;programming language;static analysis;feature model;software metric	SE	-58.94158535408517	29.725355979856126	118200
9975d6c3dded538f12b80c03be10a2a497aba2dc	future directions in program transformations	program transformation	The program transformation methodology can provide valuable techniques and tools for the development of programs from specifications and the reuse and customization of software products. Also various approaches to program optimization and program verification can be based on transformation techniques.	program transformation	Robert Paige	1996	ACM Comput. Surv.	10.1145/242224.242444	computer science	Theory	-55.1567510096949	31.495455040661508	118255
9909a2c67b38a836d86e2d32d46ef31c3bd3f7a5	casde: an environment for collaborative software development	context aware;software systems;software development environment;software development;collaborative software development;activity theory	Collaborative software development is called for to meet the requirement of the increasingly expanding software scale. A more advanced software development environment is needed to support the collaborative software development activity. The contribution of this paper is an architecture of process-centered context-aware software development environment, called CASDE, which effectively supports the collaborative development activity. We first discuss the software development activity using activity theory, and highlight its collaborative features. We then present the architecture of CASDE with a brief introduction to its key elements. The focus of the architecture lies in its support to the three levels of collaboration, i.e., co-ordinated level, cooperative level, and co-constructive level. Due to its supportive and integrated nature, the architecture can support collaboration effectively. CASDE is believed to be able to play a positive role in supporting the collaborative software development activity and improving the quality of software systems.	collaborative software;integrated development environment;software development;software system	Tao Jiang;Jing Ying;Minghui Wu	2006		10.1007/978-3-540-72863-4_38	personal software process;long-term support;verification and validation;activity theory;knowledge management;package development process;social software engineering;software framework;software development;software design description;software engineering;software construction;development environment;software walkthrough;software analytics;resource-oriented architecture;lean software development;software deployment;goal-driven software development process;software development process;software system;software peer review	SE	-61.37972085148029	21.81034993628319	118397
3ba66e05b7323299bc37ed18dce720f72e76ede8	component based visual software engineering	software engineering	"""In an effort to manage increasing complexity and to maximise the reuse of code, the software engineering community has in recent years put considerable effort into the design and development of component-based software development systems and methodologies. The concept of building software from existing components arose by analogy with the way that hardware is now designed and built, using cheap, reliable standard """" off-the-shelf """" modules. Because of the analogy with wiring hardware components , component-based software development is a natural candidate for visual expression. Various component software technologies have emerged as a result of this attention, but their evolution has been rather ad hoc. In fact, some systems are defined purely by their implementation with little or no precise definition. In an attempt to address this shortcoming, we propose a well-defined syntax and semantics for a component software model that captures the essential concepts."""	component-based software engineering;hoc (programming language);software development;wiring	Stewart Thomson;John A. W. McCall;David Crossen	2000			component-based software engineering;software engineering;resource-oriented architecture;software construction;computer science;computer engineering;computer-aided engineering;social software engineering;software measurement;release engineering;software sizing	SE	-53.78806674902304	28.054714219503495	118514
eca64ac1021da984dc8402dbdd971039cc19d855	tml: an xml-based test modeling language	quality assurance;software testing;global requirements engineering;outsourcing;global product management;quality improvement;software systems;modeling language;distributed product development;distributed software engineering;globalization;open source	Quality is a key property of modern software systems. In addition, to quality improvement strategies such as CMM or CMMI and manual checking approaches such as reviews or inspections, software testing is the major quality assurance activity in most projects. Literally speaking, software testing is nearly as essential as writing code itself. Due to its prominent role there are quite a number of commercial and open-source test tools available. However, the question remains if an organisation should rely on a single tool or if it should follow a more general strategy using several tools? Practical experience has shown that the latter strategy is more promising by covering multiple quality aspects that cannot be covered by a single tool, although it requires a means of communication between tools (i.e., a tool independent test language). This paper introduces a XML-based and test tool independent test modeling language that support creating general test cases. The language separates test logic from test tool specific code. Thus, a test case only has to be specified once and can then be executed by several test tools.	capability maturity model integration;modeling language;open-source software;software system;software testing;test automation;test case;xml	Rüdiger Foos;Christian Bunse;Hagen Höpfner;Torsten Zimmermann	2008	ACM SIGSOFT Software Engineering Notes	10.1145/1350802.1350809	reliability engineering;quality assurance;verification and validation;test data generation;software quality management;computer science;systems engineering;engineering;software development;software engineering;globalization;software construction;software testing;modeling language;programming language;software quality control;test case;test management approach;software quality;outsourcing;software quality analyst	SE	-62.19818954768607	26.937950039863917	118706
df72aea74ce4416f8b4a062a123265b468941fe8	realizing the open-closed principle	multi threading;javabeans;component based software engineering;sorting;software maintenance;multithreading component based software engineering software reuse software architecture javabeans;sorting software systems software maintenance animation java costs computer science design methodology multithreading software design;software systems;open closed principle software engineering component based software software reuse software architecture javabeans multithreading;first principle;multi threading object oriented programming software reusability software architecture distributed object management java;object oriented programming;component based software;software engineering;software architecture;software reusability;animation;distributed object management;open closed principle;computer science;software design;software reuse;multithreading;java;design methodology	The first principle in developing large software systems is the open-closed principle (OCP). This principle seems asking for two conflict goals. How to realize the principle in the real software practice? What are the enabling technologies that can be used to implement the principle? This paper uses a case study to demonstrate the importance of the principle, the design methodology for realizing the principle, and its enabling technologies.	data structure;experiment;graph (abstract data type);open core protocol;protégé;software architecture;software system;sorting algorithm;video game design;xojo	Chong-wei Xu;Jose Hughes	2005	Fourth Annual ACIS International Conference on Computer and Information Science (ICIS'05)	10.1109/ICIS.2005.107	computer architecture;computer science;software engineering;programming language	Visualization	-50.98992920107199	29.512709691477447	118728
9eb94f09e52c7605782f3abc121fecdb56a9e277	traceability between run-time and development time abstractions - a case study on aosd and debugging		Traceability throughout the software life cycle of requirements, architecture, design, development, testing and maintenance is an important research problem. Being able to relate effects to their causes is fundamental to any software engineering process. However this is still a challenge. Keeping track of all software artifacts, abstractions, relations and transformations throughout this life cycle requires sophisticated relationship management. The software engineering life cycle is a process of gradual creation, transformation and refinement, where the artifacts of one phase are translated and transformed into those of the next phase (see Fig. 1). In the requirements phase, the functional and non-functional requirements are described. The architecture phase selects tactics to fulfill these requirements and documents the overall structure of the solution in various architectural views. During the design phase, the architecture is further refined into implementable components. Finally in the development phase, the designs are implemented and compiled into an actual system. Each of these phases uses its own abstractions. Many implicit associations exist between these different abstractions, which are vital to relate the actual system to its origins. At run-time, the higher level abstractions used during development are no longer present. Even the artifacts used in the intermediate phases are no longer present in the actual system. They were lost in the process of translation and transformation. All there is left is a complex, synthetic run-time structure that is optimized for efficient execution and often too complex to understand. In this chapter we focus on traceability in the final phases of the software life cycle: between the development and run-time phases. Between these phases, an abstraction gap exists: the various high level abstractions used during development are no longer present in the run-time environment. This often makes inspection of the complex, synthetic run-time structure impossible.	debugging;traceability	Wouter De Borger;Bert Lagaisse;Wouter Joosen	2012		10.1007/978-1-4471-2239-5_13	real-time computing;systems engineering;software engineering;requirements traceability	SE	-55.1056810137361	27.694595199520887	118751
38cc1f998c69fb1f4be31fdbf499a88a6c2309fc	recovering design rationale from email repositories	software;electronic mail;information extraction;rationale retrieval;email repositories;software maintenance;information retrieval;document repository design rationale email repositories software development software lifecycle software maintenance rationale retrieval;presses;software development process;natural languages;usa councils;software maintenance electronic mail information retrieval;development process;data mining;software engineering;document repository;data mining information retrieval process design programming costs software engineering information resources project management software tools design engineering;software lifecycle;design and implementation;cognition;software development;design rationale	Rationale is the justification behind decisions taken during the software development process. The usefulness of rationale pervades the entire software lifecycle. However, it is during maintenance that the benefits of rationale management are most evident, as it provides an insight into the motivations and the reasoning behind decisions taken during the original design and implementation. One of the strongest limitation to the capturing of rationale information during development concerns its time-consuming and disruptive nature that cause many organizations to consider rationale management costs excessive. A possible solution is to extract and capture rationale information when it is needed. This can be done by analyzing documents shared or exchanged among software engineers during the development process. In this paper, we propose to supports the software engineer during the rationale capturing by automatically identifying candidate rationale information extracted from email repositories. Besides this, we also support the designer during the rationale retrieval by identifying possible rational information within a document repository starting from a query represented by a source document.	design rationale;email;software development process;software engineer	Andrea De Lucia;Fausto Fasano;Claudia Grieco;Genny Tortora	2009	2009 IEEE International Conference on Software Maintenance	10.1109/ICSM.2009.5306388	idef6;computer science;systems engineering;engineering;software engineering;data mining;database;information extraction;software development process	SE	-59.02373700875363	23.431843558324733	118766
c2839050299b2aa07a7153f40abf1470cfa219b8	the deltaprocess approach to systematic software process change management	process model;crucial role;software process model;systematic change management;deltaprocess approach;high flexibility;full versioning;process model comparison;complex process description;systematic software process change;deltaprocess approach;software development process	Software process models play a crucial role in managing and controlling the software development process. This work introduces the DeltaProcess approach for process model comparison, which makes it possible to compare versions of a process model with high flexibility regarding the schema and the types of changes that must be identified. By allowing for full versioning of a process model, DeltaProcess strongly contributes to systematic change management of large and complex process descriptions.	change management (engineering);software development process	Martín Soto	2010			reliability engineering;change management;design process;software engineering process group;computer science;systems engineering;knowledge management;business process management;software development;empirical process;business process modeling;goal-driven software development process;software development process	SE	-56.406397239839784	21.197457027150374	118814
6092894d8cad4bd994e8fd6b57c0e70f96ee3d71	metrics for evaluation of aspect-oriented middleware	software metrics;software;lua source code;cometa lua;aspect oriented software development;aspect oriented software development middleware system software metrics;static properties;ao oil;oil;data mining;petroleum;software metric;middleware petroleum software metrics software engineering programming weaving;software tools middleware software metrics;middleware;aspect oriented;software tools;source code;weaving;couplings;aspect oriented middleware;computer integrated manufacturing;middleware systems;ao oil aspect oriented middleware dynamic properties static properties software metrics cometa lua lua source code middleware systems oil;middleware system;dynamic properties	We present a set of metrics to assess aspect oriented (AO) middleware aiming at evaluating the benefits of applying the AO paradigm in middleware design. We adopt a strategy based on defining a list of static and dynamic properties which are relevant to a middleware and associating metrics to each property. The adopted strategy allows the developer to analyze relevant middleware features from the results of software metrics. Besides the proposed metrics, this paper also presents CoMETA-Lua, a tool to collect coupling and size metrics in a Lua source code. The set of metrics is applied in two middleware systems implemented in Lua: OiL and AO-OiL.	ambient occlusion;aspect-oriented programming;aspect-oriented software development;lua;middleware;programming paradigm;red rescue team'';software metric	Tássia Freitas;Thaís Vasconcelos Batista;Flávia Coimbra Delicato;Paulo F. Pires	2009	2009 XXIII Brazilian Symposium on Software Engineering	10.1109/SBES.2009.13	middleware;real-time computing;computer science;operating system;middleware;database	SE	-53.747277832210855	31.21417523338944	118850
097d07d96572ceb7c9597890009fe0f857450c89	early performance assessment in component-based software systems	software qualitative characteristics;queuing theory;uml;software verification;risk management;software performance evaluation;testing phase;component based software systems;software architecture;software security;early performance assessment;static structure;interface automata;unified modelling language;informal description methods;component diagram;early software development process;software reliability;sequence diagram;formal foundation;formal language;lightweight language	Most techniques used to assess the qualitative characteristics of software are done in testing phase of software development. Assessment of performance in the early software development process is particularly important to risk management. Software architecture, as the first product, plays an important role in the development of the complex software systems. Using software architecture, quality attributes (such as performance, reliability and security) can be evaluated at the early stages of the software development. In this study, the authors present a framework for taking the advantages of architectural description to evaluate software performance. To do so, the authors describe static structure and architectural behaviour of a software system as the sequence diagram and the component diagram of the Unified Modelling Language (UML), respectively; then, the described model is automatically converted into the ‘interface automata’, which provides the formal foundation for the evaluation. Finally, the evaluation of architectural performance is performed using ‘queuing theory’. The proposed framework can help the software architect to choose an appropriate architecture in terms of quality or remind him/her of making necessary changes in the selected architecture. The main difference among the proposed method and other methods is that the proposed method benefits the informal description methods, such as UML, to describe the architecture of software systems; it also enjoys a formal and lightweight language, called ‘interface automata’ to provide the infrastructure for verification and evaluation.	component-based software engineering;software system	Jaber Karimpour;Ayaz Isazadeh;Habib Izadkhah	2013	IET Software	10.1049/iet-sen.2011.0143	reliability engineering;unified modeling language;reference architecture;software architecture;personal software process;verification and validation;software sizing;risk management;architectural pattern;software verification;computer science;systems engineering;package development process;backporting;software design;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;resource-oriented architecture;software quality;software metric;software system;software peer review	SE	-57.29378045106374	28.410447768382838	118933
197e843f6702790555623b1e5544d15cadce3104	beyond information silos - an omnipresent approach to software evolution	ambient software development environment;semantic web technology;software evolution;software development;knowledge modeling;semantic web technologies	Nowadays, software development and maintenance are highly distributed processes that involve a multitude of supporting tools and resources. Knowledge relevant for a particular software maintenance task is typically dispersed over a wide range of artifacts in different representational formats and at different abstraction levels, resulting in isolated ‘information silos’. An increasing number of task-specific software tools aim to support developers, but this often results in additional challenges, as not every project member can be familiar with every tool and its applicability for a given problem. Furthermore, historical knowledge about successfully performed modifications is lost, since only the result is recorded in versioning systems, but not how a developer arrived at the solution. In this research, we introduce conceptual models for the software domain that go beyond existing program and tool models, by including maintenance processes and their constituents. The models are supported by a pro-active, ambient, knowledge-based environment that integrates user, tasks, tools, and resources, as well as processes and history-specific information. Given this ambient environment, we demonstrate how maintainers can be supported with contextual guidance during typical maintenance tasks through the use of ontology queries and reasoning services.	automated reasoning;blog;context-sensitive grammar;context-sensitive language;extensibility;formal ontology;gene ontology term enrichment;knowledge base;mathematical model;problem solving;sparql;software development;software engineering;software evolution;software maintenance;software release life cycle;version control;web ontology language	Juergen Rilling;René Witte;Philipp Schügerl;Philippe Charland	2008	Int. J. Semantic Computing	10.1142/S1793351X08000567	long-term support;verification and validation;software mining;computer science;knowledge management;package development process;backporting;software evolution;social software engineering;software framework;software development;software design description;software construction;software as a service;data mining;database;software walkthrough;software analytics;resource-oriented architecture;software deployment;world wide web;goal-driven software development process;software development process;software metric;software system	SE	-58.49019504267043	22.897821392786	119222
1fa2a473dce7880bc796ce22a7c6170b9b38c6d4	making formal methods more relevant to software engineering students via automated test generation	software testing;formal methods;automated test generation;software engineering education	"""The use of formal methods in software engineering has been advocated for a long time, by a lot of people. Unfortunately, advocates of formal methods remain a distinct minority among software engineering educators, as well as industrial practitioners. A number of reasons have been cited for the lack of acceptance of formal methods. Popular among these reasons is that formal methods lack relevance and utility to the everyday work of software engineers.  This paper presents a tool intended to increase the practical value of formal methods for software engineering students. The tool, called """"Spest'', generates unit testing code from a formal program specification. There have been other such tools developed in the past, but all have been difficult for us to use in our educational setting. With Spest, we hope to overcome some of the difficulties with a tool that is easy to use and which generates readable and extendible testing code. Initial results of using Spest in our classes are promising and we are planning continued development."""	extensibility;formal methods;formal specification;list of tools for static code analysis;relevance;software engineer;software engineering;unit testing	Gene Fisher;Corrigan Johnson	2016		10.1145/2899415.2899424	personal software process;verification and validation;formal methods;software engineering process group;system integration testing;computer science;design by contract;package development process;social software engineering;software development;software engineering;software construction;formal specification;software testing;software walkthrough;programming language;static program analysis	SE	-60.117289761748	30.94292041133082	119397
898f330cb8f90a9e249a83b8728b4185f3e01ed9	extraction of viewpoints for eliciting customer's requirements based on analysis of specification change records	customer requirements elicitation;formal specification;finance;customer services;design engineering;specification change records;requirements elicitation;software engineering;systems engineering and theory;process design;communication industry;formal specification customer services;guidelines;system integration;costs guidelines systems engineering and theory process design design engineering software engineering laboratories concrete finance communication industry;system development;viewpoint extraction;specification change records viewpoint extraction customer requirements elicitation;concrete	Eliciting customer's requirements is the most important issue for a system integration project. Failure to elicit the customer's requirements can cause an enormous correction cost. However there are only a few practical, concrete guidelines to do. In this paper, we describe a method to extract viewpoints and checklists for eliciting customer's requirements more effectively based on analyzing specification change records. The flow of the method is 1) representing the records in an easy-readable format, 2) identifying the causes and the phases, 3) categorizing them, 4) putting a name to a category, namely a viewpoint and 5) deriving check-items for each viewpoint. We applied the method to 135 records from 4 system development cases, and we derived 39 check-items in total. We found 78% of the specification change cases could have been prevented by only 10 check-items of requirements elicitation process. This result shows that the proposed method works effectively to extract the viewpoints for eliciting customer's requirements.	categorization;human-readable medium;requirement;requirements elicitation;simulation;system integration	Kouji Aoyama;Takanori Ugai;Shigeru Yamada;Akihiko Obata	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.54	reliability engineering;process design;software requirements specification;requirements management;concrete;systems engineering;engineering;software engineering;system requirements specification;requirements elicitation;formal specification;system integration	SE	-52.620310901699476	21.22740943700622	119420
284347e6935af280b6d2432cca6adee57b2f1865	the ocon approach for object-oriented distributed software systems modeling		The problems of todays software engineering for complex distributed software systems with control as well as data processing aspects are manifold. Besides the general problem of software complexity we additionally have to deal with the problems of concurrency and distribution. A set of well evolved formalisms especially w.r.t. concurrency exists, while their integration into the common software engineering framework is still missing and related attempts have often not gained the intended acceptance. But ever increasing system complexity as well as a fast growing market for distributed software effectuate a shift towards high level behavior modeling. The presented OCoN approach does provide a high level behavior modeling as extension to the UML de-facto standard for object-oriented modeling. It is an approach to integrate an adjusted Petri net formalism with the software engineering world.	application domain;behavior model;concurrency (computer science);distributed computing;embedded system;high- and low-level;high-level programming language;microsoft outlook for mac;petri net;programming complexity;semantics (computer science);simulation;software architecture;software engineering;software system;systems modeling;uml tool;unified modeling language;π-calculus	Holger Giese;Guido Wirtz	2001	Comput. Syst. Sci. Eng.		software construction;component-based software engineering;software system;resource-oriented architecture;model-driven architecture;software development;object-modeling technique;distributed computing;computer science;software sizing	SE	-50.0110928009496	27.80824837903748	119559
f73f7c6556c7ef998383c470b4ddc0ada8f6ff91	product line requirements reuse based on variability management	modeling educational institutions software computer architecture buildings natural languages software engineering;formal specification;software reusability formal specification;software reusability;software tool product line requirement reuse variability management software product customer requirement product line architecture reusable requirement consistent combination	As organizations respond to changing environments new software products emerge as a compromise between customer requirements, extensions of existing products and commercial needs. Success emanates from the processes and technology used to capture, adapt and manage the deep knowledge of existing products or services. In this tutorial we describe how requirements for a product line can be captured, managed and reused to generate the requirements for innovative new products, and how requirements selections for new products are often constrained by the design of the existing product line architecture. A key technical issue is the efficient management of the commonality and variability of requirements between products. One approach is to establish a pool of reusable requirements and to construct the requirements for a new product by making a selection from the pool. A concern of this approach is the efficient and clean selection of a consistent combination of requirements. A consistent combination is one in which the requirements selected satisfy all constraints imposed by the pool of reusable requirements. Critical issues are the management of requirements variability across different products, the management of inter-dependencies between selection decisions from the pool, the constraints placed upon these selections by existing architectures and being able to manage each of these issues when the number of requirements is very large. We address these concerns, present results of using these techniques for real-world applications, and describe some software tools that can be used to support them.	heart rate variability;requirement;spatial variability	Mike Mannion;Hermann Kaindl	2012	2012 19th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2012.158	reliability engineering;software architecture;reusability;software requirements specification;verification and validation;requirement prioritization;computer science;systems engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;product design specification;requirement;software engineering;software construction;formal specification;programming language;resource-oriented architecture;software measurement;software deployment;software requirements;software system	SE	-57.26361596700184	27.435770719109357	119689
b3e671fe7cb59ede977c778aea73b2cdd8bebd20	combining the continuous integration practice and the model-driven engineering approach	continuous integration;experience report;model driven engineering;domain specific language;business users	The software development approach called model-driven engineering has become increasingly widespread. The continuous integration practice has also been gaining the importance. Some works have shown that both can improve the software development process. The problem is that the model-driven engineering is still a very active research topic lacking its maturity, what translates into difficulties in optimal incorporation of the continuous integration practice in the process. We present an experience report in which we show the problems we have detected in a real project and how we have solved them. Thus, we increase the productivity of development and the non-technical people are able to modify already deployed applications. Finally, we incorporate an evaluation that shows the benefits of the proposed union.	capability maturity model;continuous integration;model-driven architecture;model-driven engineering;software development process	Vicente García-Díaz;Jordán Pascual Espada;Edward Rolando Núñez-Valdéz;B. Cristina Pelayo García-Bustelo;Juan Manuel Cueva Lovelle	2016	Computing and Informatics		model-driven architecture;computer science;domain-specific language;knowledge management;artificial intelligence;database;programming language	SE	-59.10955439221547	25.651831441187305	119840
3863a5c66da0ca8a8d960b91e36f3984ea419ee2	ockham's razor of design: an heuristic for guiding design and development of a clinical information systems generator	ockham s razor;change management;generic model;design and development;user interface;design criteria;clinical information systems;real time;first principle;clinical information system;enterprise system;natural language processing;generative systems;business process	"""This paper presents a rationale, created from first principles, for the design criteria for the architecture of clinical information systems. The criteria are developed according to the heuristic axiom of Ockham's Razor, presented here for the first time and operationalised in the form of three principles; Generalization, Minimalization and Coverage. The minimal set of characteristics of the application is defined as -- the context, roles of physician, the nature of the data, the business processes, the change management program, and the criteria for success. This set of characteristics is developed to demonstrate how they define the details of a proposed architecture, which can be used to create not a clinical information system (CIS) but a generator of clinical information systems. The generator creates CISs that have the characteristics of complete user control of the design of all input and output presentations and workflow with real-time adaptability, ad hoc analytics with natural language processing of all free-text, all information automatically coded in a lingua franca terminology(s) of clinical choice, and native level interoperability between CISs An example of a CIS generated for the Trauma Service of an Australian hospital is described. The """"generative"""" model is presented as a superset of the strategies for building best-of-breed and enterprise systems and thereby representing a new paradigm in Clinical Information System development. The parsimonious model is demonstrated by creating CISs requiring only 11 objects for designing the users interfaces along with their business logic."""	business logic;business process;design rationale;enterprise system;generative model;heuristic;hoc (programming language);information management system (ims);information system;input/output;interoperability;natural language processing;occam's razor;prince;programming paradigm;real-time locating system;software release life cycle;user interface;μ operator	Jon D. Patrick;Peter Budd	2010		10.1145/1882992.1882998	computer science;artificial intelligence;data mining	HCI	-53.1004972675515	19.518372678489776	120002
27e7121d74f0387cafeabd684993a7e09c524582	using coding patterns in a model-driven approach to teaching object oriented programming	software tool;conceptual model;object oriented programming;design;patterns	This poster presents an approach used within object-oriented programming classes which focus explicitly on the transition from conceptual model classes to code. This approach is supported by a software tool which has been developed to provide support in the selection and implementation of appropriate coding patterns.	model-driven architecture;programming tool	James H. Paterson;John Haddow;Ka Fai Cheng	2009		10.1145/1562877.1563000	design;software design pattern;reactive programming;computer science;conceptual model;theoretical computer science;component-based software engineering;software development;programming paradigm;programming language;object-oriented programming	SE	-50.773452362626145	28.582601290974754	120010
260c64027434aa1b2382e26d242962f92e243b27	analysing reusability aspects in java connector architecture	application development;formal specification;integrated software java object oriented programming software architecture software reusability software libraries formal specification;software libraries;object oriented programming;application integration;software architecture;software reusability;design pattern;java connectors application software computer architecture australia contracts computer science pattern analysis libraries sun;integrated software;time to market;enterprise application integration;class libraries software reusability java connector architecture jca specification enterprise application integration oo framework design pattern software component;java	With the growing needs of Enterprise Application Integration (EAI), flexibility has been the main issue these days. This paper guides the readers to view how this flexibility has been achieved in Java Connector Architecture (JCA). JCA provides the integration framework that encapsulates the integration component from other enterprise components. The claimed advantages of this framework are increased-reusability and reduced-time to market for applications. This paper analyses JCA in the aspect of OO framework, design patterns, components and class libraries to evaluate its advantage. The details of JCA specification and its competitiveness in the market are not discussed here. We believe that this study will benefit both application developers and researchers working in application integration area.	application programming interface;application server;code refactoring;component-based software engineering;design pattern;enterprise application integration;java ee connector architecture;library (computing);server (computing);software deployment;technical support	Piyush Maheshwari;Ji-Ho Kim	2004	11th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2004.31	enterprise architecture framework;functional software architecture;reference architecture;software architecture;enterprise application integration;enterprise software;computer science;systems engineering;software design;software framework;component-based software engineering;software development;software engineering;software construction;formal specification;software architecture description;design pattern;programming language;object-oriented programming;resource-oriented architecture;java;rapid application development;software deployment	SE	-53.188829155896585	28.16978715411429	120044
05da3b19b22c8e74ae7dc03ba6d16a3b47748154	comparing source codes generated by case tools with hand coded	software quality c language computer aided software engineering software metrics software prototyping;software metrics;case tools;static metrics;software testing;software prototyping;application software;information technology;aerospace software prototype;real time embedded system;real time embedded systems;automatic generation;aerospace software prototype case tools hand coded c source code c source code software static metrics source code evaluation software quality;c source code;computer aided software engineering;c language;computer aided software engineering software quality satellites software prototyping application software software testing information technology embedded software embedded computing real time systems;satellites;case tool;case tools real time embedded systems source code static metrics software quality;software static metrics;source code;source code evaluation;hand coded;software quality;embedded computing;embedded software;real time systems	This paper presents a comparison between C and C+ + source code automatically generated by CASE tools, and those hand made. In order to compare these two different kinds of implementation, some software static metrics were chosen, due to its soundness and confidence when applied to source code evaluation. A critical real time embedded software for a student satellite onboard computer was considered. Finally, this work points to some preliminary differences between those two implementations, related to software quality applied to an aerospace software prototype.	compatibility of c and c++;embedded software;prototype;software prototyping;software quality	Denis S. Loubach;Diogo B. Ramos;Osamu Saotome;Adilson Marques da Cunha	2008	Fifth International Conference on Information Technology: New Generations (itng 2008)	10.1109/ITNG.2008.198	kpi-driven code analysis;real-time computing;software sizing;computer science;software engineering;software construction;information technology;computer-aided software engineering;static program analysis	Embedded	-58.78423686280908	31.744799604941264	120170
f35617371dfbe3905acbd0693ffd9524ec98b323	aura-cfg/e: an object-oriented approach for acquisition and decomposition of dfds from end users			aura;context-free grammar	O. A. Al-Saadoon;W. T. Tsai;H. El-bedour	1995			end user;computer science;theoretical computer science;aura;object-oriented programming;distributed computing	HCI	-49.969558927432814	28.503272700831683	120381
1c651da29dcbb82103eca0cac23c2dcc0c3f83e5	a model-based repository for open source service and component integration		Open source is a software development paradigm that has seen a huge rise in recent years. It reduces IT costs and time to market, while increasing security and reliability. However, the difficulty in integrating developments from different communities and stakeholders prevents this model from reaching its full potential. This is mainly due to the challenge of determining and locating the correct dependencies for a given software artifact. To solve this problem we propose the development of an extensible software component repository based upon models. This repository should be capable of solving the dependencies between several components and work with already existing repositories to access the needed artifacts transparently. This repository will also be easily expandable, enabling the creation of modules that support new kinds of dependencies or other existing repository technologies. The proposed solution will work with OSGi components and use OSGi itself.	artifact (software development);cloud computing;component-based software engineering;eclipse;faceted classification;federation (information technology);information model;license compatibility;osgi;open-source software;platform as a service;programming paradigm;software as a service;software deployment;software development;software repository;topological sorting	Rodrigo García-Carmona;Félix Cuadrado;Juan C. Dueñas;Álvaro Navas	2011			computer science;systems engineering;component-based software engineering;software;software development;extensibility;time to market	SE	-52.571841159984935	29.42969359179632	120479
1d05cbd13388dd9b62346c87af95876f7fba74ea	an integrated model of workflows, e-contracts and solution implementation	structural model;integrable model;e contract;workflows;business process	Electronic-contracts (e-contracts) are structured models of business contracts. Business transactions between enterprises can be supported by inter-workflows based on standards. However, exceptions, namely problematic situations whose solutions are not specified in the workflow design, are not well supported in the proposed models. Such exceptions need to be resolved observing e-contracts. Discussion and decision-making by participants are necessary for interpreting e-contracts and agreeing on a solution. In this paper, we propose Workflow-Contract-Solution model (WCS model) to support such e-contract oriented execution of business processes.	business process;web coverage service	Mizuho Iwaihara;Haiying Jiang;Yahiko Kambayashi	2004		10.1145/967900.968179	workflow;business domain;computer science;knowledge management;artifact-centric business process model;database;management science;business process model and notation;business process;management;business rule;business process modeling	DB	-54.450910561223424	19.117820172096486	120659
42ab70f28689d9465302a37ea37d2b1397dd2034	encapsulation of legacy software: a technique for reusing legacy software components	legacy software;driving force;distributed architecture	The following paper reviews the possibilities of encapsulating existing legacy software for reuse in new distributed architectures. It suggests wrapping as an alternative strategy to reengineering and redevelopment. It then defines the levels of granularity at which software can be encapsulated before going on to describe how to construct a wrapper and how to adapt host programs for wrapping. Some wrapping products are discussed and the state of the art summarized. The advantage of wrapping over conventional reengineering is the low cost and even lower risks involved. This is the driving force in the search for improved wrapping technology.	central processing unit;code refactoring;common object request broker architecture;component-based software engineering;database;distributed component object model;distributed computing;e-commerce;encapsulation (networking);legacy system;software system;subroutine;warez;wrapper library;wrapping (graphics)	Harry M. Sneed	2000	Ann. Software Eng.	10.1023/A:1018989111417	computer science;systems engineering;engineering;software engineering;legacy system;computer engineering	SE	-52.20989194827778	28.843249701882286	120792
c1a616e92692b676ed614e3c2ad0796f35d4e2c0	practical application of a translation tool from uml/ocl to java skeleton with jml annotation	ocl;jml;design by contract;model driven architecture	In recent years, MDA techniques have been strongly develope d. Thus, translation techniques such as UML to some program languages have gained a lot of attention. Tra slation techniques such as OCL to JML have been also researched. OCL is a language to describe detail pr operties of UML and standardized by OMG, while, JML is a language to specify properties of Java progra m. Both OCL and JML are based on DbC and able to provide properties of classes or methods. There are, however, not many researches on translating automatically OCL into JML and past researches often pay lit tle attention to collection features, especially iteration. Our research group has proposed a concrete metho d w ich translates UML class diagram with OCL into Java skeleton with JML. This paper presents an imple entation tool based on the technique. To evaluate the quality of the tool, we applied the tool to two re al examples, a warehouse management program and a syllabus management system. As a result, we found that e very OCL constraint described manually was translated successfully into JML. Also, we found some defec ts xisted in the design of a syllabus management system.	class diagram;eclipse xtext;iteration;java modeling language;library (computing);object constraint language;standard library;unified modeling language	Kentaro Hanada;Kozo Okano;Shinji Kusumoto;Kiyoyuki Miyazawa	2012			computer science;design by contract;software engineering;database;programming language;object constraint language	SE	-48.415899465599665	27.001936406713952	120895
0055890dbae698416e291e32ff793ef852a2aa19	business collaboration models and their business context-dependent web choreography in bpss	e business;reference model;indexing terms;business collaboration models;business model;e business models;process development;context dependent;un cefact modeling methodology;web commerce;architectures;business process	Prior to conducting business via the Web, business partners agree on the business processes they are able to support. In ebXML, the choreography of these business processes is described as an instance of the so-called business process specification schema (BPSS). For execution purposes the BPSS must be defined in the exact business context of the partnership. Reference models for B2B processes developed by standard organizations usually span over multiple business contexts to avoid a multitude of similar processes. In this paper we present how business collaboration models following the UN/CEFACT Modeling Methodology (UMM) are expressed in ebXML BPSS. To allow a mapping from multi-context business collaboration models to a context-specific choreography in ebXML BPSS we extend UMM to capture constraints for different business contexts.	agent-based model;business process execution language;business process;context-sensitive language;diagram;ebxml;fits;object constraint language;process specification;un/cefact;web service;world wide web	Birgit Hofreiter;Christian Huemer;Werner Winiwarter	2005	IJWIS	10.1108/17440080580000081	business model;business analysis;reference model;business process execution language;index term;business domain;process development execution system;business requirements;knowledge management;artifact-centric business process model;business process management;context-dependent memory;process modeling;electronic business;business process model and notation;process management;business system planning;business process;business process discovery;business rule;new business development;business process modeling;business activity monitoring;business architecture	Web+IR	-54.54214618400581	18.33380165291613	120919
d05c4a914742504f5973316eefa48977d2f93398	a model for reusing requirements using examples from open source software	domain engineering;requirements engineering;reusing requirements	The quality of requirements is one of the key factors in the success of a project. One of the studies on successful projects is the reuse of requirements. However, the rate of failed projects is about 70%, and these projects often fail because of improper requirements. The current techniques for software reuse may not perform requirement engineering appropriately or develop requirements having good characteristics. In order to improve this situation, we propose a model for reusing requirements. We expect that our model will contribute toward increasing project productivity using requirement reuse in existing projects, and reusing requirements that have good quality.	code reuse;internationalized domain name;non-functional requirement;norm (social);open-source software;requirements engineering;sourceforge;spatial variability	Jong-Bae Kim	2012	J. Inform. and Commun. Convergence Engineering	10.6109/jicce.2012.10.3.284	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;business requirements;systems engineering;engineering;requirement;software engineering;domain engineering;system requirements specification;requirements elicitation;requirements engineering;non-functional testing;functional requirement;non-functional requirement;software requirements;requirements traceability	SE	-61.82510898535228	26.39490945856053	121221
441ef62f4aa4264cff60a6e54977565f503126d5	the learning stable analysis pattern	learning model;pattern analysis application software birds software design humans documentation stability analysis education software reusability design engineering;object oriented programming;analysis pattern;business objects learning stable analysis pattern software stability concepts enduring business themes;software reusability;object oriented programming software reusability	Learning is an important aspect of every life. This paper proposes a stable analysis pattern for learning independent of a specific domain. This learning model can be reused instead of developing it from scratch for each new application by using the software stability concepts. Identified the core of a system in terms of enduring business themes (EBT) and business objects (BO). The stable and reusable nature of these EBTs and BOs allow the learning pattern to be applied to all applications. A detailed documentation of the learning analysis pattern is provided.	business object;documentation;electron beam tomography;software analysis pattern	Mohamed Fayad;Sujatha Telu	2005	IRI -2005 IEEE International Conference on Information Reuse and Integration, Conf, 2005.	10.1109/IRI-05.2005.1506539	module pattern;reusability;software design pattern;simulation;state pattern;software sizing;architectural pattern;computer science;artificial intelligence;software design;component-based software engineering;software development;software analysis pattern;object-oriented design;software engineering;machine learning;software construction;data mining;database;adapter pattern;programming language;object-oriented programming;world wide web;specification pattern;software system	Robotics	-59.06813280901154	27.037390943842734	121426
698fb0f88bfd33b1b11cc077a2c7b1309128b953	the use of interpretation for data acquisition and control: its impact on software development and project management		For over a decade, I and a number of other software engineers introduced, developed, improved, and expanded the principle of interpretation for data acquisition and control task descriptions; initially a simple description and execution tool to assist plant engineers, but in the end a software development framework for modeling, managing, and executing large, complex projects in this domain.	data acquisition;software development;software engineer	Otto Vinter	2010		10.1007/978-3-642-23315-9_34	verification and validation;software project management;systems engineering;software development;software engineering;database;application lifecycle management;project management triangle;software development process;software peer review	SE	-61.4224779589038	24.679755687106656	121466
61059d267d8adb079fdc8c7852f137f9f7ab8ae7	design-time product line architectures for any-time variability	life cycle;software systems;product line architecture;software life cycle	Most solutions for introducing variability in a software system are singular: they support one particular point in the software life cycle at which variability can be resolved to select a specific instance of the system. The presence of significantly increased and dissimilar levels of variability in today’s software systems requires a flexible approach that supports selection of a system instance at any point in the life cycle—from statically at design time to dynamically at run time. This paper introduces our approach to supporting any-time variability, an approach based on the ubiquitous use of a product line architecture as the organizing abstraction throughout the lifetime of a software system. The product line architecture specifies the variabilities in a system, both in terms of space (captured as explicit variation points) and time (captured as explicit versions of architectural elements). A system instance can be selected at any point in time by providing a set of desired features, expressed as name-value pairs, to an automated selector tool. We introduce our overall approach, discuss our representation and tools for expressing and managing variability, and demonstrate their use with three representative examples of any-time variability.	algorithm;autoregressive integrated moving average;enterprise life cycle;floor and ceiling functions;heart rate variability;microsoft forefront;organizing (structure);run time (program lifecycle phase);software configuration management;software deployment;software engineering;software release life cycle;software system;spatial variability;system deployment	André van der Hoek	2004	Sci. Comput. Program.	10.1016/j.scico.2003.04.003	biological life cycle;real-time computing;simulation;software development process;software system	SE	-54.66840784756704	27.636048332281987	121633
4a4b2fdadfdc6f547b641b0b5da28c6733907dfc	binary pattern for nested cardinality constraints for software product line of iot-based feature models	cost estimation models;internet of things iot;feature model;software product line;software product line feature model internet of things iot cost estimation models	Software product line (SPL) is extensively used for reusability of resources in family of products. Feature modeling is an important technique used to manage common and variable features of SPL in applications, such as Internet of Things (IoT). In order to adopt SPL for application development, organizations require information, such as cost, scope, complexity, number of features, total number of products, and combination of features for each product to start the application development. Application development of IoT is varied in different contexts, such as heat sensor indoor and outdoor environment. Variability management of IoT applications enables to find the cost, scope, and complexity. All possible combinations of features make it easy to find the cost of individual application. However, exact number of all possible products and features combination for each product is more valuable information for an organization to adopt product line. In this paper, we have proposed binary pattern for nested cardinality constraints (BPNCC), which is simple and effective approach to calculate the exact number of products with complex relationships between application’s feature models. Furthermore, BPNCC approach identifies the feasible features combinations of each IoT application by tracing the constraint relationship from top-to-bottom. BPNCC is an open source and tool-independent approach that does not hide the internal information of selected and non-selected IoT features. The proposed method is validated by implementing it on small and large IoT application feature models with “n” number of constraints, and it is found that the total number of products and all features combinations in each product without any constraint violation.	binary pattern (image generation);complexity;feature model;heart rate variability;internet of things;open-source software;sensor web;software product line	Asad Abbas;Isma Farah Siddiqui;Scott Uk&#x2013;Jin Lee;Ali Kashif Bashir	2017	IEEE Access	10.1109/ACCESS.2017.2680470	computer science;operating system;data mining;internet of things;feature model	SE	-57.04528213151586	28.09514207095903	121707
4493f92b38dcf6694b48abde60b98a83f1f7e43f	enhancing requirements reusability through semantic modeling and data mining techniques		ABSTRACTEnhancing the requirements elicitation process has always been of added value to software engineers, since it expedites the software lifecycle and reduces errors in the conceptualization phase of software products. The challenge posed to the research community is to construct formal models that are capable of storing requirements from multimodal formats (text and UML diagrams) and promote easy requirements reuse, while at the same time being traceable to allow full control of the system design, as well as comprehensible to software engineers and end users. In this work, we present an approach that enhances requirements reuse while capturing the static (functional requirements, use case diagrams) and dynamic (activity diagrams) view of software projects. Our ontology-based approach allows for reasoning over the stored requirements, while the mining methodologies employed detect incomplete or missing software requirements, this way reducing the effort required for requirements elicitation at an earl...		Themistoklis Diamantopoulos;Andreas L. Symeonidis	2018	Enterprise IS	10.1080/17517575.2017.1416177	software development process;systems engineering;data mining;computer science;requirements elicitation;software;systems design;functional requirement;software requirements;reusability;added value	DB	-57.49597751124076	23.697838218377225	121805
85130a119cb31674033fa2a565acb3a550f8b1b2	knowledge analysis on process models	process model;knowledge base	Helping end users build and check process models is a challenge for many science and engineering fields. Many AI researchers have investigated useful ways of verifying and validating knowledge bases for ontologies and rules, but it is not easy to directly apply them to checking process models. Other techniques developed for checking and refining planning knowledge tend to focus on automated plan generation rather than helping users author process information. In this paper, we propose a complementary approach which helps users author and check process models. Our system, called KANAL, relates pieces of information in process models among themselves and to the existing KB, analyzing how different pieces of input are put together to achieve some effect. It builds interdependency models from this analysis and uses them to find errors and propose fixes. Our initial evaluation shows that KANAL was able to find most of the errors in the process models and suggest useful fixes including the fixes that directly point to the sources of the errors.	autonomous robot;end system;end-to-end principle;interdependence;knowledge base;knowledge representation and reasoning;ontology (information science);software engineering;verification and validation;victor basili	Jihie Kim;Yolanda Gil	2001			knowledge base;computer science;knowledge management;artificial intelligence;process modeling;data mining	AI	-57.34384857048122	24.465006788970335	121817
594975404f52432980579a47ef3c456bdc3d0530	feature-model interfaces: the highway to compositional analyses of highly-configurable systems	automotive engineering;analytical models;software systems;stakeholders;indexes;feature model;compositionality;configurable software;modularity;software product line;load modeling;variability modeling	Today's software systems are often customizable by means of load-time or compile-time configuration options. These options are typically not independent and their dependencies can be specified by means of feature models. As many industrial systems contain thousands of options, the maintenance and utilization of feature models is a challenge for all stakeholders. In the last two decades, numerous approaches have been presented to support stakeholders in analyzing feature models. Such analyses are commonly reduced to satisfiability problems, which suffer from the growing number of options. While first attempts have been made to decompose feature models into smaller parts, they still require to compose all parts for analysis. We propose the concept of a feature-model interface that only consists of a subset of features, typically selected by experts, and hides all other features and dependencies. Based on a formalization of feature-model interfaces, we prove compositionality properties. We evaluate feature-model interfaces using a three-month history of an industrial feature model from the automotive domain with 18,616 features. Our results indicate performance benefits especially under evolution as often only parts of the feature model need to be analyzed again.	compile time;compiler;feature model;loader (computing);software system	Reimar Schröter;Sebastian Krieter;Thomas Thüm;Fabian Benduhn;Gunter Saake	2016	2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)	10.1145/2884781.2884823	database index;stakeholder;computer science;systems engineering;engineering;operating system;software engineering;data mining;modularity;engineering drawing;principle of compositionality;feature model;software system	SE	-56.16245890078381	25.70687184351574	121973
f5e9649eb370c2882b9d8cd312f77efd1bcf8c0b	an integrated environment for building large software systems			software system	Bill Curtis	1989			software system;computer engineering;engineering	SE	-62.347074585428416	24.66755195203316	122037
53e43479e945ec365fe3527d1096f2a6bf937c5c	reverse engineering: a roadmap	program understanding;software analysis;software tool;software maintenance;user interface;program comprehension;software engineering;software evolution;software migration;cost effectiveness;software tools;software reengineering;tool adoption;tool evaluation;legacy system;data reverse engineering;reverse engineering	By the early 1990s the need for reengineering legacy systems was already acute, but recently the demand has increased significantly with the shift toward web-based user interfaces. The demand by all business sectors to adapt their information systems to the Web has created a tremendous need for methods, tools, and infrastructures to evolve and exploit existing applications efficiently and cost-effectively. Reverse engineering has been heralded as one of the most promising technologies to combat this legacy systems problem. This paper presents a roadmap for reverse engineering research for the first decade of the new millennium, building on the program comprehension theories of the 1980s and the reverse engineering technology of the 1990s.	code refactoring;information system;legacy system;program comprehension;reverse engineering;user interface;web application;world wide web	Hausi A. Müller;Jens H. Weber;Dennis B. Smith;Margaret-Anne D. Storey;Scott R. Tilley;Kenny Wong	2000		10.1145/336512.336526	software modernization;cost-effectiveness analysis;computer science;systems engineering;engineering;software evolution;software analysis pattern;software engineering;user interface;software maintenance;legacy system;reverse engineering;computer engineering	SE	-61.92330396768773	23.209132448644638	122044
f9aaa218bd452d9b0727301d7f816a94c306d2b8	a cmms-based formal conceptual modeling approach for team simulation and training	conceptual modeling;cmms;conceptual model;ebat;team simulation and training;subject matter expert;workflow patterns	For the conceptual modeling of team simulation and training based on EBAT (Event-Based Approach to Training), it is crucial to solve the problem of effective communication between subject matter experts, training experts and simulation technologists, and the problem of conceptual modeling quality and reuse. By analyzing modeling elements of team training, a layered logical structure of the simulation and training conceptual model based on CMMS (Conceptual Model of the Mission Space) and a formal description approach are proposed. Based on the workflow patterns and interactive features of team training, the event causality patterns and formal description approach are presented for the process of event response. The results of the formal conceptual modeling of training cases show the validity of the proposed formal conceptual modeling approach.	capability maturity model;simulation	Jian Wang;Hongwei Wang	2009		10.1007/978-3-642-01507-6_107	conceptual model;simulation;computer science;knowledge management;conceptual model;management science	AI	-52.30103414272651	21.835185333210088	122079
1e143dfad52f6cc7008b2cc15175976e69859574	an understandable and configurable domain-specific framework for industrial automation applications	automation application software java elevators programming object oriented modeling usability automatic control costs control systems;javabeans;component models;frameworks;tool support;learning curve;computerised control;object oriented framework;object oriented programming;software architecture;lifts software architecture software reusability object oriented programming computerised control;lifts;software reusability;javabeans domain specific framework industrial automation software software development time costs plug in components object oriented frameworks software reuse usability elevator control;component model;industrial automation;development time;domain specificity	Modern industrial automation software is growing more and more complex. At the same time development time and costs have to be reduced. In order to reconcile these opposing demands a new approach is needed based on domain-specific architectures with appropriate plug-in components. Object-oriented frameworks offer a reuse efficiency not achievable with other techniques. Unfortunately, framework comprehension and use is normally difficult due to a steep learning curve and the lack of tool support. This work proposes the use of component models for structuring frameworks in order to simultaneously improve usability and comprehension of object-oriented frameworks. The approach is illustrated with a framework for elevator control software complying to the JavaBeans component model. This paper discusses the structure and the advantages of the approach but also reveals problematic points which should be considered in similar projects.	automation;domain-specific language	Stjepan Dujmovic	2000		10.1109/TOOLS.2000.848774	real-time computing;computer science;systems engineering;software engineering	EDA	-52.00439713122538	30.599067592610595	122153
3eb5f1d98d5c7ff34ead0315572698bfb54edcb5	special issue: real time software architecture			software architecture	Doohyun Kim;Arif Ghafoor	2007	Comput. Syst. Sci. Eng.		functional software architecture;resource-oriented architecture;software design description;architecture tradeoff analysis method;computer science;real-time computing;reference architecture;applications architecture;space-based architecture;software architecture description	DB	-52.11371905717286	26.732398596472837	122357
9247e25a08a5c8a833163559d8aa11f9f7d6585b	an interoperability design model: lessons learned in computer communication standardization	design model;architectural design;protocols;processing model selection;protocol design;standardization process design internet guidelines research and development access protocols computational modeling communication standards best practices computer networks;computer networks;process design;standardisation;computer communication standardization;computational modeling;research and development;internet;evolution tolerant protocol design;guidelines;lessons learned;telecommunication standards;best practices;communication standards;access protocols;communication protocol;process model;logical model;standardisation open systems protocols telecommunication standards;open systems;evolution tolerant protocol design interoperability design computer communication standardization logical model architectural design processing model selection;standardization;interoperability design	Interoperability is one of the top priority issues in the computer communication standardizations. The computer communication protocol design becomes complicated in order to cover both of the communication parts and content parts. The content parts need more flexibility for the future evolution. The author uses the underlying assumptions, architectural aspects and processing model aspects in order to identify the protocol design strategy with lessons learned in the past. The author describes existing extensibility frameworks. Then the author proposes a logical model for architectural design and processing model selection. This model gives a measure to verify the overall consistency for the evolution-tolerant protocol design. The author compares the fits among the logical model components and the possible interoperability strategies.	communications protocol;extensibility;fits;file spanning;interoperability;logical data model;model selection;service-oriented device architecture	Toshihiko Yamakami	2005	19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)	10.1109/AINA.2005.113	communications protocol;computer science;database;standardization;computer network	Networks	-54.02603804363103	22.62342175266107	122401
5780c8a4e12707e96b79b1de2176197abf9cd136	towards an automation of software evolution good practices	good practice;software evolution	It is well known that software evolution is an inescapable activity in the software lifecycle. In order to prevent the negative effects of this activity (decreased quality, increased complexity, etc.), some good practices have been recommended in the past. In this paper, we present a method which aims at automating a kind of assistance to software evolution. This assistance makes it possible to guide the developer when applying changes on a given software by making persistent some good practices, which can be considered as some kind of knowledge in the software engineering practice. In this method, a domain metamodel is firstly introduced. A set of constraints formalizing the good practices are then associated to this metamodel. Together, these two elements compose the basis upon which the automatic support for the evolution assistance has been built.	automation;complexity;domain model;metamodeling;software development process;software engineering;software evolution	Chouki Tibermacine;Soraya Sakhraoui;Vincent Le Gloahec;Régis Fleurquin;Salah Sadou	2010			personal software process;verification and validation;software quality management;software engineering process group;software sizing;software mining;extreme programming practices;computer science;systems engineering;engineering;knowledge management;artificial intelligence;package development process;backporting;software evolution;software design;social software engineering;software framework;software development;software design description;software engineering;software construction;management science;software walkthrough;management;software deployment;software metric;software quality analyst	SE	-59.560016564295765	24.13750946037906	122542
d049e085270a13111c05dca554f3e553eb1c3468	enforcing structural regularities in source code using intensive	institutional repositories;software;architectural design;fedora;software system;structural regularities;tool suite structural regularities source code intensive software system coding conventions design patterns architectural design rules intensional views environment object oriented software systems;software systems;object oriented software;intensive;object oriented programming;vital;software architecture;design and implementation;intensional views environment;design pattern;production facilities;architectural design rules;source coding object oriented programming software architecture software tools;design patterns;coding conventions;software tools;source code;vtls;production facilities programming software systems encoding software object oriented modeling documentation;encoding;programming;object oriented modeling;tool suite;ils;documentation;source coding;object oriented software systems	The design and implementation of a software system is often governed by many different coding conventions, design patterns, architectural design rules, and other so-called structural regularities. To prevent a deterioration of the system's source code, it is important that these regularities are verified and enforced in subsequent evolutions of the system. The Intensional Views Environment (IntensiVE), which is the subject of this demonstration, is a tool suite for documenting such structural regularities in (object-oriented) software systems and verifying their consistency in later versions of those systems.	design pattern;intensional logic;software documentation;software system;verification and validation	Johan Brichau;Andy Kellens;Kim Mens	2008	2008 23rd IEEE/ACM International Conference on Automated Software Engineering	10.1109/ASE.2008.76	computer science;systems engineering;software engineering;database;programming language;software system;source code	SE	-51.64244947852779	31.28193026333968	122712
ce905f61d1740a63af9331911d5d52cb5099c6ce	model-driven test case construction by domain experts in the context of software system families		This thesis presents MTCC (Model-Driven Test Case Construction), an approach to the construction of acceptance tests by domain experts for testing system families based on feature models. MTCC is applied to the application domain of Digital Libraries. The creation and maintenance of high quality systems that fulfill both formal requirements and meet the needs of users is one of the primary goals of software engineering. A prerequisite for the quality is the absence of faults. Software engineering has defined a number of techniques for avoiding faults, identifying them or fixing them. Testing identifies faults by exercising an implementation artifact and comparing its actual and expected behavior. MTCC is an approach the automate acceptance tests for the members of system families. The basic hypothesis of this thesis is that the involvement of domain experts in the testing process for members of system families is possible on the basis of feature models and that such a testing approach has a positive influence on the efficiency and effectiveness of testing. Application quality benefits from the involvement of domain experts because tests specified by domain experts reflect their needs and requirements and therefore can serve as an executable specification. One prerequisite for the inclusion of domain experts is tooling that supports the specification of automated tests without formal modeling or programming skills. In MTCC, models of automated acceptance tests are constructed with a graphical editor based on models that represent the test-relevant functionality of a system under test as feature models and finite state machines. Feature models for individual testable systems are derived from domain-level systems for the system family. The use of feature models by the test reuse system of MTCC facilitates the systematic reuse of test models for the members of system families. MTCC is a Model-Driven test automation approach that aims at increasing the efficiency of test execution by automation while keeping independence from the implementation of the testee or the test harness in use. Because tests in MTCC are abstract models that represent the intent of the test independent from implementation specifics, MTCC employs a template-based code generation approach to generate executable test cases. In order to validate the approach, MTCC is applied to the Digital Library application domain. Digital Libraries are Information Retrieval systems that aim to provide the scientific community with relevant information. A MTCC prototype is designed and realized for a system family of three Digital Libraries and an Information Retrieval system. The capability of representing tests relevant for the application domain, for reusing these tests for multiple systems and for generating executable tests from the abstract test models are validated. An assessment of the understandability by domain experts and of the usability of the editor is conducted. The feasibility and practicality are shown by a validation involving domain experts for a system family of Digital Libraries.	acceptance testing;application domain;code generation (compiler);digital library;display resolution;executable;feature model;finite-state machine;graphical user interface;information retrieval;library (computing);microsoft outlook for mac;model-driven integration;prototype;requirement;software engineering;software system;subject-matter expert;system under test;test automation;test case;test harness;test set;usability;vii	Stefan Bärisch	2009			domain analysis;test data generation;computer science;systems engineering;package development process;theoretical computer science;software development;feature-oriented domain analysis;software engineering;domain engineering;software construction;data mining;dynamic testing;software testing;programming language	SE	-57.39238303150924	28.935286669716724	122851
7064cf37ebeb64218a6cdaef3a4c25011713d448	uplatnění systémového myšlení v analytické fázi vývoje aplikací	system thinking;system dynamics;systemova dynamika;vývoj softwaru;systemove mysleni;software development;model;models	This paper presents the proposal for application of systems thinking in the application development process. The models of systems thinking present to the reader the possibility of their use and application in the software application development process. The proposal does not mandate the creation of a specific model at some point, but suggests how the selected models can be used. Authorial intention is to change the mental model of the reader – particularly the part that contains an image of the application of systems thinking in developing applications.	mental model;software development process	Anna Exnarová	2013	Acta Informatica Pragensia	10.18267/j.aip.16	computer science;artificial intelligence;cartography	Robotics	-50.487300216453015	22.419607938657776	122904
c17930e8c12f355bc203d41a4ed7e62b2206e3c3	a preliminary empirical assessment of similarity for combinatorial interaction testing of software product lines		Extensive work on Search-Based Software Testing for Software Product Lines has been published in the last few years. Salient among them is the use of similarity as a surrogate metric for t-wise coverage whenever higher strengths are needed or whenever the size of the test suites is infeasible because of technological or budget limitations. Though promising, this metric has not been assessed with real fault data. In this paper, we address this limitation by using Drupal, a widely used open source web content management system, as an industry-strength case study for which both variability information and fault data have been recently made available. Our preliminary assessment corroborates some of the previous findings but also raises issues on some assumptions and claims made. We hope our work encourages further empirical evaluations of Combinatorial Interaction Testing approaches for Software Product Lines.	software product line	Stefan Fischer;Roberto Erick Lopez-Herrejon;Rudolf Ramler;Alexander Egyed	2016		10.1109/SBST.2016.011	reliability engineering;verification and validation;regression testing;test data generation;software sizing;software performance testing;white-box testing;system integration testing;computer science;systems engineering;package development process;software reliability testing;software development;software construction;data mining;software testing;software walkthrough;empirical process;software quality;software metric	SE	-62.48357702440357	30.15568772146529	122920
1718da28cdcab39f98050adb1ca300fcfd7cfeb9	usability and the software production life cycle	software testing;life cycle;product life cycle;software development process;usability engineering;capability maturity model;software quality	For many types of systems it is as important that the usability is as good as the functionality. There have been various attempts during the last fifteen years or more to encourage developers to focus on usability during the life cycle. These have had only limited success in that they have affected certain companies without fundamentally changing the overall software development process. The aim of this study is to improve software quality by finding ways to integrate usability with software quality measurements throughout the life cycle and especially at early stages of development.	software development process;software quality;usability	Suziah Sulaiman	1996		10.1145/257089.257140	biological life cycle;personal software process;long-term support;architecture tradeoff analysis method;verification and validation;social software engineering;software reliability testing;product lifecycle;software development;usability engineering;software construction;software testing;systems development life cycle;software deployment;capability maturity model;software development process;software quality;software quality analyst	HCI	-62.05170015619623	27.04607479925723	123138
ff9be24bd97f37442114a8f7ef3e9585d110c8ad	compreensão visual de frameworks através da introspeção de exemplos	reutilizacao software;framework orientado objetos;engenharia software;visualizacao software;computational reflection;object oriented frameworks;software reuse;tese;software visualization			Marcelo R. Campo	1997			computer science;systems engineering;software engineering;programming language	Vision	-51.00799560616006	27.784268824205967	123163
408342f3081d70265b65b84916cc4419c15889f4	test data generation for model transformations combining partition and constraint analysis		Model-Driven Engineering (MDE) is a software engineering paradigm where models play a key role. In a MDE-based development process, models are successively transformed into other models and eventually into the final source code by means of a chain of model transformations. Since writing model transformations is an error-prone task, mechanisms to ensure their reliability are greatly needed. One way of achieving this is by means of testing. A challenging aspect when testing model transformations is the generation of adequate input test data. Most existing approaches generate test data following a black-box approach based on some sort of partition analysis that exploits the structural features of the source metamodel of the transformation. However, these analyses pay no attention to the OCL invariants of the metamodel or do it very superficially. In this paper, we propose a mechanism that systematically analyzes OCL constraints in the source metamodel in order to fine-tune this partition analysis and therefore, the generation of input test data. Our mechanism can be used in isolation, or combined with other black-box or white-box test generation approaches.	black box;cognitive dimensions of notations;invariant (computer science);metamodeling;model transformation;model-driven engineering;model-driven integration;norm (social);object constraint language;programming paradigm;software engineering;test data generation;turing test;white-box testing	Carlos A. González;Jordi Cabot	2014		10.1007/978-3-319-08789-4_3	computer science;data mining;engineering drawing;algorithm	SE	-55.571483323393956	28.38768057521694	123264
6cada40d010a2aafb3a0eee976a1dff316cca629	intelligent assistance in german software development: a survey	developpement logiciel;integrated development environments;software organizations intelligent assistance german software development software engineers;intelligent assistance;reactive systems intelligent assistance software engineering survey integrated development environments;software engineering;software engineers;integrated development environment;computer aided software engineering;german software development;desarrollo logicial;software development;reactive system;reactive systems;survey;software engineering automatic programming skeleton software systems design engineering software design software quality gettering usability systems engineering and theory;software organizations	Although many environments explicitly or implicitly use ideas from intelligent assistance research, users aren't always aware of its existence and potential. A survey of 135 German participants sheds light on the usage of and demand for intelligent assistance in software engineering activities. The project aimed to clarify intelligent assistance concepts, describe such systems' motivation, review examples of intelligent assistance, and present the results of a survey about the attitude toward and the demand for intelligent assistance in German software organizations.	assistive technology;document;executable;information needs;requirement;requirements management;software development;software engineer;software engineering;unobtrusive javascript;version control	Jörg Rech;Eric Ras;Björn Decker	2007	IEEE Software	10.1109/MS.2007.110	reactive system;computer science;systems engineering;engineering;software engineering;computer engineering	SE	-50.731418137957306	23.588140133711622	123424
4cb07ef97bc617bd044eacc7a34028c50d1e25a8	a cost-benefit framework for making architectural decisions in a business context	software metrics;developer productivity;quality attributes;measurement;dependency structure matrix;training;risk reduction;system architecture decisions;commerce;software components;computer architecture;software architecture;software architecture commerce cost benefit analysis decision making;estimation;structural transformation;architectural decisions;design structure matrix;software component;software metric;it intensive organization;vistaprint corporation;organizations;business context;couplings;cost benefit framework;system architecture;architecture;couplings computer architecture measurement organizations estimation training;software components cost benefit framework architectural decisions business context it intensive organization system architecture decisions structural transformation risk reduction developer productivity decision making vistaprint corporation;cost benefit analysis;software metrics architecture cost benefit analysis dependency structure matrix design structure matrix quality attributes software architecture	"""In any IT-intensive organization, it is useful to have a model to associate a value with software and system architecture decisions. More generally, any effort---a project undertaken by a team---needs to have an associated value to offset its labor and capital costs. Unfortunately, it is extremely difficult to precisely evaluate the benefit of """"architecture projects""""---those that aim to improve one or more quality attributes of a system via a structural transformation without (generally) changing its behavior. We often resort to anecdotal and informal """"hand-waving"""" arguments of risk reduction or increased developer productivity. These arguments are typically unsatisfying to the management of organizations accustomed to decision-making based on concrete metrics. This paper will discuss research done to address this long-standing dilemma. Specifically, we will present a model derived from analyzing actual projects undertaken at Vistaprint Corporation. The model presented is derived from an analysis of effort tracked against modifications to specific software components before and after a significant architectural transformation to the subsystem housing those components. In this paper, we will discuss the development, implementation, and iteration of the model and the results that we have obtained."""	component-based software engineering;iteration;list of system quality attributes;systems architecture	S. Jeromy Carrière;Rick Kazman;Ipek Ozkaya	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1810295.1810317	reliability engineering;systems engineering;engineering;component-based software engineering;software engineering;design structure matrix;management;software metric;systems architecture	SE	-60.900977623757335	27.784959381145917	123648
a13aaa998f6e7e052948c654ca605b21d1ee47df	on software reference architectures and their application to the space domain	articulo;on software reference architectures and their application to the space domain	In high-integrity systems a rising portion of software assets and development activities address quality and conformance issues in several non-functional dimensions. For those systems the software architecture acquires a prominent role: it does in fact express the framework that hosts the required functionalities, while the principles and guarantees that underpin its definition assure the desired non-functional quality on the software product. A software reference architecture holds for a set of systems and prescribes the form that concrete software architectures have to have for those systems. The software reference architecture can thus be seen as a generic software architecture, whose assets are recognized by domain stakeholders as befitting the construction of a given class of systems, for which they have been proven to meet the applicable industrial needs and technical requirements. This paper discusses the rationale for the understanding and definition of a software reference architecture and present its use in an initiative promoted by the European Space Agency for its future satellite systems.		Marco Panunzio;Tullio Vardanega	2013		10.1007/978-3-642-38977-1_10	domain analysis;reference architecture;application domain;real-time computing;component-based software engineering;feature-oriented domain analysis;domain engineering	Vision	-59.53694832000187	21.055353348143363	123726
3d364ec8981ca418ed76aa11a445e344beb78c5c	towards effective sysml model reuse.	conferenceobject;bookpart	The Systems Modeling Language (SysML) is spreading very fast. Most modelling tool vendors support it and practitioners have adopted it for Systems Engineering. The number of SysML models is growing, increasing the need for and the potential benefit from platforms that allow a user to reuse the knowledge represented in the models. However, SysML model reuse remains challenging. Each tool has its own implementation of SysML, hindering reuse between tools. The search capabilities of most tools are also very limited and finding reusable models can be difficult. This paper presents our vision and initial work towards enabling an effective reuse of the knowledge contained in SysML models. The proposed solution is based on a universal information representation model called RSHP and on existing technology for indexing and retrieval. The solution has been used to index models of all SysML diagram types and preliminary validated with requirements diagrams. The results from the validation show that the solution has very high precision and recall. This makes us confident that the solution can be a suitable means for effective SysML model reuse.	apple rhapsody;diagram;magicdraw;mathematical model;papyrus;precision and recall;requirement;systems modeling language;systems engineering;usability;xml	Roy Mendieta;Jose Luis de la Vara;Juan Llorens Morillo;Jose María Álvarez Rodríguez	2017		10.5220/0006267605360541	computer science;systems engineering	SE	-56.96361822431903	24.319845675435392	123796
2de96af9d30ccadc89d45abac635b1c262cdd2d9	implicit constraints in partial feature models	feature model;configurable software	Developing and maintaining a feature model is a tedious process and gets increasingly difficult with regard to large product lines consisting of thousands of features and constraints. In addition, these large-scale feature models typically involve several stakeholders from different domains during development and maintenance. We aim at supporting such stakeholders by deriving and explaining implicit constraints for partial feature models. A partial feature model can either be a submodel of a feature model representing the full product line or a specific feature model in a set of interrelated models. For every implicit constraint, we generate an explanation exposing which other model parts and constraints interfere with the partial model of interest. Thus, stakeholders are only confronted with a small part of the feature model reducing the complexity while preserving the necessary information about dependencies. Our approach is implemented in the open-source framework FeatureIDE.	constraint (mathematics);constraint logic programming;feature model;open-source software;physics processing unit;scalability;usability testing	Sofia Ananieva;Matthias Kowal;Thomas Thüm;Ina Schaefer	2016		10.1145/3001867.3001870	feature recognition;computer science;machine learning;pattern recognition;data mining;feature model	SE	-55.85511419572551	25.491596829473828	123830
406462cb1407133c0040b939978a6866c3e66ee5	a context-driven development methodology for context-aware systems	context aware system;unified process up;development methodology	Context-aware systems demand a customized development methodology because they have their own features such as ambiguous system scope, context modeling, and implementing context-dependent services. Furthermore, it has been known that these systems are more complex than traditional systems. In this paper, we meet this challenge by extending the unified process (UP), and add three workflows: context requirements, context modeling, and context testing. At each workflow, stakeholders analyze, model, and test for the perspective context. We also provide guidelines for task performance, artifact production and development specifications for each stage of the context. Our methodology supports the full development process and the best practice technologies including OOP, UML, and UP.	best practice;context switch;context-aware network;context-aware pervasive systems;context-sensitive help;context-sensitive language;non-functional requirement;programmer;software engineering;software testing controversies;unified modeling language;unified process;unit testing	Jongmyung Choi;Rosa I. Arriaga;Hyun-Joo Moon;Eun-Ser Lee	2011		10.1007/978-3-642-24082-9_53	computer science;knowledge management;context model	SE	-55.68500248123776	26.237802551815637	123999
8a8f0c069e674f746abe85dca5d0deacbd8162d6	application frameworks: how they become your enemy	coupling;application framework;application frameworks;software engineering practices;evolution	Application frameworks have become a de-facto standard to implement business systems. In most organizations, when choosing either a development platform or a commercial solution, an application framework is part of the overall solution. This paper reviews my personal experience developing a proprietary application framework, its lifecycle, software engineering practices, successes and mistakes through its releases.	application framework;business domain;contract management;object-relational database;object-relational mapping;open-source software;requirement;software engineering;software publisher	Martin Mailloux	2010		10.1145/1869542.1869561	knowledge management;software framework;evolution;coupling	SE	-59.3470604343011	22.327920263843836	124000
b3b127b65649b6ebdbc5134218b9a60346ce00f4	communications software design for testability: specification transformations and testability measures	design for testability;computacion informatica;grupo de excelencia;software development process;testing;communications software;ciencias basicas y experimentales;testability measure;specification transformation;software design;finite state machine	To deal with the increased complexity related to the testing of communications software, we propose the integration and application of finite state machine based specification transformations and testability measures early in the communications software development process. Based on this integration, the testability of a given design is estimated and appropriate specification transformations are defined and applied iteratively to enhance the testability of the product implementation. q 1999 Elsevier Science B.V. All rights reserved.	design for testing;finite-state machine;software design;software development process;software testability	Rachida Dssouli;Kamel Karoui;Kassem Saleh;Omar Cherkaoui	1999	Information & Software Technology	10.1016/S0950-5849(99)00033-6	reliability engineering;real-time computing;computer science;systems engineering;engineering;software design;software engineering;software construction;design for testing;software testing;finite-state machine;software development process	SE	-60.984425384892894	28.4785136101734	124249
1794894d6bc5b719bfa63adcd33db8414a1f78a0	using uml modeling to facilitate three-tier architecture projects in software engineering courses	three tier architecture;comparative analysis;student projects;computer science education;model based development;mapping techniques;computer software;visual aids;instructional effectiveness;models;undergraduate students;java	This article presents the use of a model-centric approach to facilitate software development projects conforming to the three-tier architecture in undergraduate software engineering courses. Many instructors intend that such projects create software applications for use by real-world customers. While it is important that the first version of these applications satisfy the customer by providing the functionality the customer expects and perform reliably and efficiently, it is equally important to be able to accommodate the customer's change requests over the period of the product's lifetime. The challenges in achieving these goals include the lack of real-world software development experience among the student developers and the fact that postdeployment change requests will almost certainly have to be handled by students who are not among the original developers. In this article, we describe how a model-centric approach using UML has been effective in enabling students to develop and maintain eight software applications for small businesses over a 9-year period. We discuss the characteristics of our modeling technique, which include the application of modeling patterns and quality check rules that enable students to create a model that can be clearly and consistently mapped to code. We also describe the nature of these mapping-to-code techniques, emphasizing how they reduce coupling among the implementation's classes. We then discuss our experiences in the classroom with these techniques, focusing on how we have improved our teaching over the years based on the analysis of student performance and feedback. Finally, we compare our approach to related work teaching modeling and the development and maintenance of code in software engineering courses with both extensive and minimal modeling.	feedback;multitier architecture;software development;software engineering;uml tool;unified modeling language	Sandeep Mitra	2014	TOCE	10.1145/2635831	personal software process;model-driven architecture;verification and validation;team software process;simulation;computer science;systems engineering;package development process;social software engineering;software framework;software development;software design description;software engineering;software construction;resource-oriented architecture;software quality;software system	SE	-59.81442269261614	27.10546117854318	124255
26cf8005b7d29a13a81dbe98cc4544bb9971eede	supporting the end users' views	design environments;software tool;human computer interaction;knowledge based system;software development process;cognitive theory;organizational memory;event monitoring;software engineering;usability engineering;design environment;software development;design;point of view;activity theory;knowledge based systems;social theory	End users of software have the right to systems that are both useful and usable, a property termed usability in the software and human-computer interaction communities. Unfortunately, it is not obvious what methods or techniques developers of software should adopt in order to achieve good usability in a product. There are a confounding number of questions. How can different points of view among end users be incorporated into a software development process? What does it mean to treat software developers as end users, namely of software tools? How do the limitations of software practice, such as minimizing time to release, affect what information can be collected and used to make usability decisions? This paper presents a variety of possibilities for supporting all the end users' views in a software development activity. Both tools and methods are suggested, roughly organized according to the different activities in software development. Moreover, end users are defined to be a variety of stakeholders in a software development project, including at the very least the end users of a product but also developers who are end users of software tools.	human–computer interaction;software developer;software development process;usability	David F. Redmiles	2002		10.1145/1556262.1556266	software review;design;medical software;long-term support;activity theory;software quality management;human–computer interaction;computer science;knowledge management;package development process;backporting;software development;software design description;software engineering;knowledge-based systems;social theory;software walkthrough;software documentation;user analysis;software analytics;software deployment;world wide web;software development process;software metric	SE	-60.60385697786011	24.18167457623495	124427
e1460df7eed240be8922eef8feadf1d09f6a2a7d	an approach for automated service selection and ranking using services choreography	service choreography;service selection;adaptive system;soc;service ranking;article	In today’s highly competitive market, it is critical to provide customers services with a high level of configuration to answer their business needs. Knowing in advance the performance associated with a specific choreography of services (e.g., by taking into account the expected results of each component service) represents an important asset that allows businesses to provide a global service tailored to customers’ specific requests. This research work aims at advancing the state-of-the-art in this area by proposing an approach for service selection and ranking using services choreography, predicting the behavior of the services considering customers’ requirements and preferences, business process constraints and characteristics of the execution environment.	business process;business requirements;chorography;closed innovation;closing (morphology);complex adaptive system;control system;focal (programming language);high-level programming language;interaction;requirement;scalability;system on a chip;systems theory	Firmino Silva;Claudia-Melania Chituc;Paul W. P. J. Grefen	2015		10.5220/0005461202590266	system on a chip;computer science;artificial intelligence;service delivery framework;adaptive system;service design;data mining;database;world wide web	Metrics	-59.46495711054144	18.620177143360845	124444
62531ac78bcba5d67529b45e737176fa4c5f1e5e	modelling requirements in service to plm for long lived products in the nuclear field	system engineering;plm;requirements engineering;large scale;long life cycle;ontology	Requirements engineering in usually considered a first step before design that is to evolve with each generation or version in a prod- uct line. Nuclear plants however, are subject to modifications during their lifetime, in their design and implementation as well as in the re- quirements they have to satisfy. Economic, technical and safety reasons lead to extending the requirements engineering process through the whole life-cycle of the nuclear plants. This article presents an ontology-based approach to integrating the requirements engineering into a PLM ap- proach for such long-lived, large-scale products.	requirement	Albéric Cornière;Virginie Fortineau;Thomas Paviot;Samir Lamouri;Jean-Louis Goblet;Audrey Platon;Cecile Dutertre	2014		10.1007/978-3-662-44736-9_79	requirements analysis;systems engineering;engineering;operations management;requirements engineering;manufacturing engineering	HPC	-61.903468210078856	20.39471162059316	124548
f73768d3ebb26207cdf7ef8ac2f1ef8646745802	component-oriented agile software development	agile software development;developpement logiciel;component based development;software systems;composant logiciel;object oriented programming;systems software;agile development;model driven development;desarrollo logicial;software development;software component;programmation extreme;developpement agile;programmation orientee objet;qualite logiciel;software quality;logiciel exploitation	Agile Development (AD), Model-Driven Development (MDD) and Component-Based Development (CBD) have been proposed, each on its own, as the ways to build quality software systems fast and be able to easily adapt to frequently changing requirements in the environment. This paper presents how component concepts can support and strengthen AD principles and practice, help in overcoming AD limitations, as well as bridge the gap between AD and MDD by combining certain elements from both sides.	agile software development;component-based software engineering;model-driven engineering;model-driven integration;requirement;software system	Zoran Stojanovic;Ajantha Dahanayake;Henk G. Sol	2003		10.1007/3-540-44870-5_38	computer science;engineering;component-based software engineering;software engineering;agile software development;programming language	SE	-55.06466801449958	26.453286046472503	124789
82a748cdd6cd5aa5ea930a5cb7692f59c84ddcb9	bda information management and decision support based on dw	design model;stream function analysis;black box reuse;mssql;rdl;state transition machines;white box reuse;object oriented programming;graduate student information system;component based software;software engineering;state;software architecture;real world application;graduate student reporting system;software reusability object oriented programming software architecture;component reuse;software reusability;transformational design models;gui;software design databases software engineering computer science councils statistics artificial intelligence distributed computing mathematical model mathematics;dbms;black box reuse component based software design software engineering graduate student information system graduate student reporting system transformational design models stream function analysis state transition machines white box reuse;dbms component reuse stream function state rdl c mssql gui;c;component based design;stream function;state transition;component based software design;graduate student;component software	Component software design has been a trend in software engineering. In this paper, the theory of component based design is applied to a real world application, the Graduate Student Information and Reporting system at Trent University. This paper demonstrates how existing components can be used and modified to develop a highly functional and user friendly system in a short amount of time. Transformational design models, analysis by stream functions and state transition machines, white-box and black-box reuse on reporting are discussed in details.	broadcast driver architecture;decision support system;dreamwidth;information management	Zhijun Ma;Li Chen;Yizhen Zhang	2007		10.1109/SNPD.2007.364	software architecture;state;computer science;software design;component-based software engineering;operating system;software engineering;software construction;database;programming language;stream function;software system	DB	-50.90484306876528	27.899781682651827	124847
d4e6c6c59467a84e9875e402685cf35dba5857c8	statistical testing of software based on a usage model	verification;modelizacion;software;software testing;operational use;usage model;chaine markov;cadena markov;logiciel;statistical test;statistical model;modelisation;inferencia;defaillance;modele statistique;logicial;modelo estadistico;statistical testing;failures;fiabilite logiciel;verificacion;fiabilidad logicial;modeling;software reliability;fallo;inference;markov chains;markov chain	In statistical testing, a model is developed to characterize the population of uses of the software, and the model is used to generate a statistically correct sample of all uses of the software. A software ‘usage model’ characterizes the population of intended uses of the software in the intended environment. Statistical testing based on a software usage model ensures that the failures that will occur most frequently in operational use will be found early in the testing cycle. The usage model is based on the software specification. The model can be developed in parallel with the software, thus shortening the elapsed time required to develop the deliver software. Usage modeling has been demonstrated to be an activity that improves the specification, gives an analytical description of the specification, quantifies the testing costs and, with statistical testing, provides a basis from which inferences of software reliability may be made. This paper describes the justification for statistical testing of software using a usage model, describes procedures for developing and using a usage model and discusses several usage modeling issues and recent advances in usage model applications.	formal specification;software reliability testing	Gwendolyn H. Walton;Jesse H. Poore;Carmen J. Trammell	1995	Softw., Pract. Exper.	10.1002/spe.4380250106	non-regression testing;reliability engineering;markov chain;statistical hypothesis testing;software requirements specification;verification and validation;regression testing;test data generation;simulation;software sizing;software performance testing;white-box testing;system integration testing;computer science;package development process;software reliability testing;software development;software design description;software construction;risk-based testing;software testing;software deployment;stress testing;software metric;statistics;software quality analyst	SE	-61.85549496717905	31.65277508001791	124946
d8e54254382281a97a1ced25b4dbd89937e11894	towards an incremental bidirectional partial model synchronization between organizational and functional requirements models	organizational models;model synchronization engines;software development process incremental bidirectional partial model synchronization organizational model functional requirement model driven software development model transformation semantic difference bidirectional approach general mapping scheme;requirements models model driven architecture model synchronization engines triple graph grammar organizational models;triple graph grammar;requirements models;synchronization software engines computational modeling computer integrated manufacturing companies;formal specification business data processing;model driven architecture	Model-driven software development proposes model transformations as a key system design principle. However, devel-opment of model transformations can be considered as a complex task because of the semantic difference in involved models. In par-ticular, we are interested in the improvement of transformations between organizational and functional requirements models be-cause the current best approaches support only forward and semi-automatic derivation of the later from the former and do not ad-dress different workflow patterns, lack of traceability and tool support, besides not taking advantage of incremental and bidirec-tional approaches. Model synchronization techniques are pro-posed to address these challenges. In this paper, we present an analysis of the main model synchronization engines reported in the literature as well as their tool-support based on a defined set of problem-specific requirements. We present also an approach to achieve these requirements by defining a general mapping scheme and model synchronization rules to be used in the context of soft-ware development process. Initial results and further research steps on it are finally reported.	business process model and notation;functional requirement;key;metamodeling;model-driven engineering;model-driven integration;semiconductor industry;sequence diagram;software development;systems design;traceability;transformational grammar;warez;workflow pattern	Marat Abilov;Tariq Mahmoud;Jorge Marx Gómez;Manuel Mora Tavarez	2015	2015 IEEE International Model-Driven Requirements Engineering Workshop (MoDRE)	10.1109/MoDRE.2015.7343870	simulation;computer science;systems engineering;theoretical computer science;synchronization	SE	-55.879276347603984	18.806021655767577	124972
83f0b6e500dd579d4951e64d1877220d9c5f68de	application of model-integrated computing in manufacturing execution systems	software systems;site productivity;general motors manufacturing execution systems model integrated computing constraint management sspf business processes saturn plants;manufacturing execution system;production engineering computing;manufacturing data processing;model integrated computing;automobile industry production engineering computing manufacturing data processing;computer aided manufacturing computer applications virtual manufacturing microwave integrated circuits saturn space technology throughput globalization application software impedance;general motors;work in progress;automobile industry;business process	Manufacturing Execution Systems (MESs) are those systems that exist between the plant floor and the business systems of the front office. There is work in progress to support this application space but tends to become impeded by the complexity of the dynamics of the plant. Model-Integrated Computing (MIC) is a software/system integration technology that provides the ability to build IS solutions to complex problems at low cost. The MIC approach and the MGA tools have been applied to the domain of constraint management in Saturn manufacturing via the research, development, and deployment of Saturn Site Production Flow (SSPF). Constraint management involves identifying bottlenecks in the manufacturing process and then focusing plant resources on removing that bottleneck (constraint) which in turn provides an improved throughput for the plant. Through the use of SSPF in conjunction with strong business processes, 10% throughput improvement in Saturn plants has been achieved. General Motors (GM) is undergoing a globalization process that involves the use of common processes and systems throughout the whole corporation. To achieve globalization will involve rapid, consistent deployment along with business process understanding and attendant training. To understand the magnitude of this problem one must understand that all these 400 plants have, to some degree, different processes, systems, and plant cultures. There is some degree of common (which is strategic) and some degree of difference (which represents the degree of local practice). These differences must be taken into account in achieving a common set of processes, practices, and systems although the focus is to support and deploy the common strategic business practices. In this paper, we will discuss how MIC could be used to address these issues.	abstraction layer;bottleneck (software);business process;degree (graph theory);design for manufacturability;discrete manufacturing;hardware description language;hercules graphics card;ieee software;information system;misra c;manufacturing execution system;multigraph;programming tool;software deployment;system integration;throughput;visual programming language	Earl Long;Amit Misra;Janos Sztipanovits	1999		10.1109/ECBS.1999.755861	manufacturing execution system;embedded system;integrated computer-aided manufacturing;process development execution system;computer science;systems engineering;engineering;artificial intelligence;operating system;software engineering;work in process;computer-integrated manufacturing;business process;management;advanced manufacturing;manufacturing engineering;software system	Robotics	-52.491312597495906	28.291330376807977	125087
6b1b1e67290f401db1f8b36e0674794fc0863b6f	where enterprise architecture and early software engineering meet: an approach to use cases definition		Software development involves the resolution of technical problems related to a certain domain. However, in order to provide a suitable technical solution, it is necessary to take the organizational environment related to the software into account. Use cases have been often used to elicit requirements and represent functionalities that the software must provide to its users. However, use cases are not expressive enough to represent the organizational environment. Moreover, this is not the purpose of use cases. In this context, Enterprise Architecture (EA) emerges as a way to describe the organization's domain. EA provides architectural descriptions that support the alignment between information technology (IT) and organizational processes and, thus, helps developers to properly understand the requirements the software must meet. In this paper, we propose an approach that uses EA models as a basis to define use cases, named CEA (use Cases definition oriented by Enterprise Architecture modeling). To demonstrate the proposal use, we applied it in a project in the Public Security domain. Additionally, CEA was evaluated in an experimental study. The results indicate that EA models helped requirements engineers to define use cases.	application domain;archimate;business process;business requirements;carcinoembryonic antigen;correctness (computer science);description;diagram;e-government;each (qualifier value);enterprise architecture;ethacrynic acid;experiment;information sciences;information systems;information system;name;process (computing);requirement;requirements engineering;resolution (logic);rule (guideline);software development;software engineering;software requirements;usability;anatomical layer;cell transformation	Gabriel M. Miranda;Mingzhan Chen;Lucas A. Santos;Monalessa Perini Barcellos	2018		10.1145/3275245.3275271	software engineering;software development;software;enterprise architecture;requirements engineering;security domain;use case;information technology;computer science	SE	-57.89948547089218	18.456562408468958	125115
bd439732c9db7d3ce765ed5d92a682fb1033d769	concurrent development of model and implementation	model checking;evolutionary development	This paper considers how a formal mathematically-based model can be used in support of evolutionary software development, and in particular how such a model can be kept consistent with the implementation as it changes to meet new requirements. A number of techniques are listed can make use of such a model to enhance the development process, and also ways to keep model and implementation consistent. The effectiveness of these techniques is investigated through two case studies concerning the development of small e-business applications, a travel agent and a mortgage broker. Some successes are reported, notably in the use of rapid throwaway modelling to investigate design alternatives, and also in the use of close team working and modelbased trace-checking to maintain synchronisation between model and implementation throughout the development. The main areas of weakness were seen to derive from deficiencies in tool support. Recommendations are therefore made for future improvements to tools supporting formal models which would, in principle, make this co-evolutionary approach attractive to industrial software developers. It is claimed that in fact tools already exist that provide the desired facilities, but these are not necessarily production-quality, and do not all support the same notations, and hence cannot be used together.	electronic business;evolutionary algorithm;evolutionary computation;iterative and incremental development;recommender system;requirement;software developer;software development	Andrew M. Gravell;Yvonne Howard;Juan Carlos Augusto;Carla Ferreira;Stefan Gruner	2003	CoRR		simulation;systems engineering;engineering;software engineering;management	SE	-58.84134581727583	25.672326725168713	125142
435526d7288b1f82db9274176c3fd8c3f43ae8e6	towards aspectual problem frames: an example	requirements;problem frame;problem frames;crosscutting model elements;aspects	Abstract: Problem frames provide an approach to an initial requirements structure which can subsequently help the developer to analyse a problem and to understand its nature. Aspect-oriented software development offers complementary techniques to handle crosscutting concerns in a systematic and effective way, providing improved support for software maintenance and evolution. This paper explores the integration of aspect concepts with problem frames with the eventual aim of providing a more modular, evolvable requirements structure.	problem frames approach	Maria Lencastre;João Araújo;Ana Moreira;Jaelson Brelaz de Castro	2008	Expert Systems	10.1111/j.1468-0394.2008.00453.x	requirements analysis;computer science;algorithm	NLP	-54.73232502753767	27.14123933805405	125161
d51cf84e57b60f0a0c63a38304b68e7e20f77859	rapid application lifecycle management: a new approach with tool support	tool support	Software lifecycle is the process by which software is conceived, developed, maintained, and decommissioned. To the development team, initiating effective application lifecycle management (ALM) is challenging for three reasons. (1) ALM definition is hard since lifecycle activities are interdependent and complex in nature that involves product, project, people, process, tool and technology. (2) ALM activities require the support of correctly tailored tools. (3) Effective ALM activities execution requires discipline. To take on the three challenges of initiating ALM, we present a new approach called Rapid Application Lifecycle Management (RALM). RALM provides a reference model with a number of templates for ALM activity definition. Once customized, the templates are converted into platform-specific process definition files with tool support. Observations from a field application of RALM are presented and discussed.	application lifecycle management	Jung-Sing Jwo;Yu Chin Cheng;Tien-Song Hsu;Chun Ting Liu	2010		10.3233/978-1-60750-629-4-212	reliability engineering;computer science;systems engineering;engineering;application lifecycle management	SE	-56.01367229042918	24.135138870835704	125173
ec7d79438ec7ff283c3846fb8036b38b272db32c	test data generation for complex data types using imprecise model constraints and constraint solving techniques	quality assurance;software testing;test data generation;model based testing	Number of software applications is growing rapidly, as well as their importance and complexity. The need of quality assurance of these applications is increasing. Testing is one of the key processes to ensure the quality of software and object-oriented applications in particular. In order to test large and complex systems, test automation methods are needed, which evaluate whether the software is working properly. The main goal is to improve effectiveness of object-oriented applications testing by creating an automated test data generation method for complex data structures.  This paper presents a test data generation method by adhering to software under test static model and its model constraints. The method provides an algorithm that allows generating test data for complex data structures, by analysing software under test model, its constraints and using constraint solving techniques for building corresponding test data objects and their hierarchies. The presented method is exemplified by simple case studies as well as a large I++ protocol implementing web service project.  DOI:  http://dx.doi.org/10.5755/j01.itc.42.2.1855	constraint satisfaction problem;test data generation	Sarunas Packevicius;Greta Krivickaite;Dominykas Barisas;Robertas Jasaitis;Tomas Blazauskas;Evaldas Guogis	2013	ITC	10.5755/j01.itc.42.2.1855	quality assurance;verification and validation;regression testing;test data generation;model-based testing;white-box testing;manual testing;system integration testing;computer science;engineering;software reliability testing;software engineering;functional testing;software construction;data mining;database;software testing;system under test;test method;test case;test management approach;test harness	SE	-57.329760562355396	31.047674096667247	125306
49d779f30d7ab3ecb88546235c7ae1773b6ffc25	model-driven development for scientific computing. an upgrade of the rheedgr program	reflection high energy electron diffraction;61 14 hg;02 60 cb;model driven architecture mda;uml;model transformation;reflection high energy electron diffraction rheed;model driven development mdd;software engineering;model driven development;software development;model driven engineering;scientific computing;model driven engineering mde;model driven architecture	Model-Driven Engineering (MDE) is the software engineering discipline, which considers models as the most important element for software development, and for the maintenance and evolution of software, through model transformation. Model-Driven Architecture (MDA) is the approach for software development under the Model-Driven Engineering framework. This paper surveys the core MDA technology that was used to upgrade of the RHEEDGR program to C++0x language standards.	computational science;model-driven engineering	Andrzej Daniluk	2009	Computer Physics Communications	10.1016/j.cpc.2009.07.003	metamodeling;unified modeling language;model-driven architecture;simulation;software development	HPC	-51.80365943444289	27.465181371688367	125349
8f04bc427fc0c62e1db9ab541715c3832b2d21cc	real time multi-user interaction with 3d graphics via communication networks	protocols;groupware;engineering graphics;cad;real time;communication networks layout protocols electrical capacitance tomography visualization real time systems samarium computer graphics computer science electronic switching systems;multi user;communication model;computer networks;engineering information systems groupware data visualisation real time systems multi access systems engineering graphics computer networks cad protocols;data visualisation;engineering information systems;design and implementation;community networks;information management;multi access systems;user interaction;multicast protocol real time multi user interaction 3d graphics communication networks cooperative visualization minimal user interaction real time cooperative interaction 3d scene design communication model protocol implementation database consistency techniques 3d editor interface 3d cooperative design cscw cooperative information management;3d graphics;cooperative work;real time systems;cooperative design	There is a lot of development on cooperative visualization via communication networks. User interaction is kept to minimum in this kind of development such as only making marks on the transmitted images etc. There are relatively less work done on cooperative complicated interaction especially on real time cooperative interaction via network. The work presented in this paper is a challenge to the second type of cooperative work. The objective of the system is to allow multiple users to design a 3D scene cooperatively via communication networks in real time. The paper describes the design and communication model of the system, the design and implementation of the protocol to transmit changes in the 3D-scene, the database consistency techniques and the implementation of the 3D-editor interface. The current implementation status of the system shows that a real time, full user interaction in 3D cooperative design via communication networks is achievable by our design strategy.	3d computer graphics;acid;multi-user;telecommunications network	Yuhua Luo;Ricardo Galli;Miquel Mascaró;Pere A. Palmer;F. J. Riera;C. Ferrer;S. F. Alves	1998		10.1109/IV.1998.694200	simulation;human–computer interaction;computer science;distributed computing	HCI	-49.71080005341634	19.701736875146672	125451
2eb884b2dfa6545f1d2825023e062cfce2753453	dynamic trust assessment of software services	algebraic specifications;difference operator;monitoring;bpel;services	Trust assessment is a key prerequisite for the adoption of software services but poorly supported by existing methods and technology especially when it comes to trust in dynamically composed and deployed software services. In this position paper, we discuss why this is the case and outline a programme of research focusing on the development of platform for dynamic trust assessment of software services.		George Spanoudakis	2007		10.1145/1294928.1294937	service;business process execution language;computer science;systems engineering;knowledge management;software engineering;services computing	SE	-59.14777157499464	20.667658248902725	125472
a369365f4dcfb81c79da241ed185cd6205478944	on the relationship between software processes and software products	automatic control;control systems;data structures;programming profession;error correction;production;artificial intelligence;programming profession automatic control control systems error correction automation data structures software design production artificial intelligence;software design;software process;automation	A primary objective of having formal and enactable models of software processes is to extend software development environments to provide assistance to programmers following those processes. The GRAPPLE system [Huff and Lesser, 1988; Huff, 19891 implements one approach to intelligent assistance, where the programmer can retain control of executing a process or the system can take over to automate parts of the process. GRAPPLE provides error detection and correction, generation of summaries of tasks completed and agendas of tasks to do, as well as automation of tasks. A data structure, called a plan, is used to represent the rationale for and status of all activities in progress; these plans are incrementally elaborated and executed.	agile software development;data structure;design rationale;error detection and correction;grapple;high-frequency direction finding;mike lesser;programmer	Karen E. Huff	1990		10.1109/ISPW.1990.659585	personal software process;verification and validation;software sizing;computer science;systems engineering;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;real-time control system software;software analytics;resource-oriented architecture;software measurement;software deployment;goal-driven software development process;software development process;software system;computer engineering	SE	-61.54360978167108	24.790743126757505	125566
5cc6ace3611bf79f06a32775c87b94470cce9287	contribution à l'élaboration d'architectures logicielles à hiérarchies multiples. (multi- hierarchical levels based software architecture)			software architecture	Amirat Abdelkrim	2010				Robotics	-51.552478089878925	26.811044390663586	125647
21617c1faf81998c36461288ae25aed8311e123c	forensic software engineering and the need for new approaches to accident investigation	developpement logiciel;ingenieria logiciel;traffic safety;software engineering;erreur humaine;error humano;desarrollo logicial;seguridad trafico;software development;genie logiciel;securite trafic;fiabilite logiciel;fiabilidad logicial;human error;software reliability	Accident reports are intended to explain the causes of human error, system failure and managerial weakness. There is, however, a growing realization that existing investigation techniques fail to meet the challenges created by accidents that involve software failures. This paper argues that existing software development techniques cannot easily be used to provide retrospective information about the complex and systemic causes of major accidents. In consequence, we must develop specific techniques to support forensic software engineering.	forensic software engineering	Chris Johnson	2000		10.1007/3-540-40891-6_36	simulation;human error;engineering;software development;software engineering;computer security;software quality	SE	-61.77695403500323	31.070566361017832	125738
0c92bbe82d42064c35f5c0197ac0718549ef06a0	using dsl for automatic generation of software connectors	connectors source code software connectors automatic generation component based engineering reusable components collection business logic modern component systems domain specific language rewriting system;rewriting system;connectors source code;composition;component;modern component systems;code generation;connector;component composition;business logic;term rewrite system;automatic generation;rewriting systems;software reusability;semantic gap;software connectors automatic generation;domain specific language;dsl connectors application software runtime software reusability computer architecture middleware network servers software systems software engineering;source code;interoperability;reusable component;code generation composition interoperability component connector;component based engineering;software reusability rewriting systems;reusable components collection	Component-based engineering is a recognized paradigm, which models an application as a collection of reusable components. The key idea behind components is that they contain only the business logic and communicate with one another only via well-defined interfaces. The communication paths among components (so called bindings) are in modern component systems realized by software connectors, which allow explicit modeling of communication and also its implementation at runtime. An important aspect of using connectors is the possibility of their automatic generation, which saves a significant amount of development work. However, the generation itself is not a trivial task, since there is a big semantic gap between the abstract specification of a connector at design time and its implementation at runtime. In this paper, we present an approach to generating implementations of software connectors. The approach is based on a new domain specific language for describing templates of connector implementations and a transformation framework using the Strate-go/XT term rewriting system for generating source code of connectors.	business logic;compiler;component-based software engineering;digital subscriber line;domain-specific language;explicit modeling;high- and low-level;java;language binding;partial template specialization;programming language;programming paradigm;rewriting;run time (program lifecycle phase);sofa;stratego/xt	Tomás Bures;Michal Malohlava;Petr Hnetynka	2008	Seventh International Conference on Composition-Based Software Systems (ICCBSS 2008)	10.1109/ICCBSS.2008.17	real-time computing;computer science;database;programming language	SE	-49.812066196135106	29.31210164288285	125852
477656f42cbd8d99859d44b4363f792291969213	cross organizational service based workflows - solution strategies for quality of service optimization		By the application of the Service-oriented Architecture (SOA) paradigm on business processes, workflows can be decomposed into basic activities that can be realized by reusable services offering a specific business functionality. In order to compose cross-organizational service-based workflows, services can be sourced from internal as well as from external providers. On a large service market, services are offered with varying Quality of Service (QoS) levels and several pricing models. Providing a high level of QoS concerning composite services or service-based workflows is of high importance for an intermediary, acting as a service orchestrator, selling composed service-based workflows to his consumers. Besides efficient workload predictions, fast and efficient solution strategies for QoS and cost optimization are mandatory for the intermediary in order to stay competitive and to enable fast reaction strategies on varying demands of workflow execution requests. This thesis provides several contributions to the QoS optimization of servicebased workflows from the intermediary’s point of view. The main contribution is the development and the evaluation of efficient resource planning heuristics, facilitating the fast computation of invocation plans out of services with limited execution capacities, offered by a specific pricing model. Thus, a resource planning optimization model, solved by mathematical optimization with an exact solution as well as by the application of the developed heuristics, is introduced. Additional contributions address several challenges in the field of QoS optimization of service-based workflows. As a foundation, a classification of pricing models for services is developed and the impact of several pricing models on the service selection process for service-based workflows is presented. Several solution strategies for the QoS optimization are developed supporting the intermediary in the worstand average-case performance analysis of servicebased workflows. In an average-case analysis, key findings of queuing theory are adapted to the concept of service-based workflows and several optimization approaches are developed. These support the intermediary by the optimization of the service utilization incorporating constraints such as the overall response time. Furthermore, major concepts of network calculus are identified and adapted to the concept of service-based workflows. Consequently, optimization approaches are developed facilitating the optimization of QoS parameters such as the delay or the throughput in the worst-case. Finally, an architectural extension for generic QoS management systems for service-based workflows is proposed, facilitating the realization and implementation of the developed solution strategies for the resource planning of service-based workflows.	best, worst and average case;business process;computation;enterprise resource planning;heuristic (computer science);high-level programming language;mathematical optimization;network calculus;probabilistic analysis of algorithms;programming paradigm;quality of service;queueing theory;response time (technology);service-oriented architecture;service-oriented device architecture;throughput	Julian Eckert	2009				HPC	-59.73577014066937	18.53226703870393	125921
e6469b8721ba47268e4facf4cc8a76cbf315cccd	exploratory self-adaptation in software systems	quality attributes;biocomputing;self adaptive software systems;software systems;software systems taxonomy adaptive systems control systems communities monitoring;software evolution self adaptive software systems bio inspired computing;software evolution;bio inspired computing;functional characteristics self adaptive software systems exploratory self adaptation quality attributes;software quality;software quality biocomputing	This paper applies the concept of exploratory change to self-adaptive software systems and proposes and briefly specifies a new paradigm for self-adaptation named exploratory self-adaptation. In exploratory self-adaptation exploratory changes are continuously introduced into the software system as hypothetical improvements of its functional characteristics or quality attributes. Once introduced, these changes are evaluated: if the evaluation is positive, they remain and the system has self-adapted, otherwise the changes are rolled back.	exploratory testing;list of system quality attributes;programming paradigm;rollback (data management);software system	Stavros Stavru;Sylvia Ilieva	2011	2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2011.36	software visualization;personal software process;bio-inspired computing;verification and validation;software sizing;computer science;package development process;software evolution;social software engineering;component-based software engineering;software development;software construction;software analytics;resource-oriented architecture;software deployment;software quality;software system	SE	-54.85298271864494	30.552338093198856	126080
6f08f4ef0765e8e811dcad87613fbb7a36ad8fbe	designing business processes in e-commerce applications	object oriented hypermedia design method;e commerce;web application design;design technique;business process	Business processes play an important role in E-commerce Web applications as they form an important part of the B2C domain and dominate the B2B domain. However, E-commerce application modeling and design techniques have eluded the special characteristics of business processes by treating them just as a special case of navigation. As a consequence, the resulting E-commerce applications have design and usability problems as well as erroneous results from business process execution. We propose a solution to E-commerce Web application design where business processes are considered first class citizens. In this paper we first demonstrate why modeling business processes is important. After a brief introduction, we extend the Object-Oriented Hypermedia Design Method (OOHDM) with business processes. We show that our approach to E-commerce Web application design involving both hypermedia navigation and business processes is easy and clear and does not cause the listed problems.	business process;e-commerce payment system;first-class function;hypermedia;oohdm;usability;web application	Hans Albrecht Schmid;Gustavo Rossi	2002		10.1007/3-540-45705-4_37	e-commerce;web modeling;simulation;business process execution language;business domain;web design;business requirements;computer science;knowledge management;artifact-centric business process model;business process management;business case;process modeling;database;business process model and notation;process management;business system planning;business process;business process discovery;management;business rule;world wide web;business process modeling;business activity monitoring;business architecture	Web+IR	-51.95658295464056	22.835585684406723	126154
66fe7c0d34e51f65aa3a1def12a9c97f2a056d7e	atomi ii - framework for easy building of object-oriented embedded systems	embedded system design process;object oriented methods;hardware software codesign;atomi objects atomi ii framework embedded system design process embedded object concept object oriented methods lego like software hardware entities;lego like software hardware entities;embedded system;atomi ii framework;object oriented methods embedded systems hardware software codesign logic cad;embedded systems;embedded system design;object oriented;atomi objects;embedded system hardware embedded software prototypes buildings system testing software design software maintenance embedded computing design engineering;embedded object concept;logic cad	Traditionally, an embedded system design process demands a considerable amount of expertise, time and money. This makes developing embedded systems difficult for many companies, and in research facilities it hinders the testing of new research results with real embedded systems. We have earlier presented an easy and fast embedded system development concept based on embedded objects. The embedded object concept (EOC) utilizes common object-oriented methods used in software by applying them in combined Lego-like software-hardware entities. This concept enables fast prototyping with target hardware, incremental device development and high-level device building for nonexperts. The EOC requires a modularly extendable architecture along with mechanical and technical definitions in order to enable physical and electrical interconnectivity with versatile signaling between embedded objects. This paper presents the Atomi II framework, which is our solution for this need. The framework has been tested and implemented with so-called Atomi objects	embedded system;entity;extensibility;high- and low-level;systems design	Tero Vallius;Juha Röning	2006	9th EUROMICRO Conference on Digital System Design (DSD'06)	10.1109/DSD.2006.26	embedded system;real-time computing;computer science;object-oriented programming	EDA	-49.24614297020346	31.472456161448807	126336
789342f6350f4a34e61513a451856ff49c57d284	employing object-oriented design principles in the design of learning objects in a software engineering course	software design principle;learning objects;object development process;object-oriented software engineering principle;object-oriented design principle;high-quality learning object;key result;software engineering principle;instructional design;software engineering course;object-oriented design principles;standardization;application software;object oriented design;production;object oriented design principles;software maintenance;software design;software engineering;object oriented programming;computer science education;computer science;development process;object oriented software engineering;electronic learning	This paper describes a study aimed at exploring the design of learning objects based on object-oriented design principles. We present and discuss experiences gained in applying object-oriented software engineering principles to the development of learning objects. While key results indicate that the approach leads to the production of high-quality learning objects, results also reveal that the application of software engineering principles is not sufficient by itself. There is a need to integrate both instructional design and software design principles during the learning object development process	software design;software engineering	Permanand Mohan;A. Bucarey SandraBucarey;Ben Daniel	2006	Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)	10.1109/ICALT.2006.159	personal software process;computer science;software design;social software engineering;component-based software engineering;software development;object-oriented design;software construction;instructional design;resource-oriented architecture	SE	-59.10633239566415	27.126529972052957	126583
197abbbcb48e16324bfdc4a39dbd91a014086128	automatische optimierung und evaluierung modellbasierter testfälle für den komponenten- und integrationstest		This thesis presents a tool-supported approach which enables the automatic test case generation from UML models and allows evaluating the fault detection potential of the generated test cases. The test case generation method supports both the model-based component and the integration testing phase. The considered coverage criteria include established coverage criteria for component testing as well as a series of so-called state-based integration testing criteria. By using genetic algorithms the developed tool automatically generates optimized test cases, maximizing the coverage achieved with regard to considered coverage criteria and minimizing the number of test cases. In addition, coverage visualization and model-based regression testing are also supported. For the purpose of evaluating the fault detection capability both component and integration test cases are considered. On the one hand, mutation testing is used for evaluating to which extent such test cases allow the detection of modeling faults. To do so, as a first step several mutants of the model are automatically generated; successively the proportion of mutants detected is determined by executing the test cases on the mutants and on the initial model. On the other hand, the generated test cases were compared to manually created test cases in order to evaluate their potential for detecting implementation faults.	code coverage;fault detection and isolation;genetic algorithm;integration testing;mutation testing;regression testing;sensor;test case;unified modeling language;unit testing	Florin Pinte	2012				SE	-57.00101212982893	31.67895203896387	126636
55d332d1c2037417cfc70c9698b21f6454df7892	survey on the applicability of textual notations for the unified modeling language		The Unified Modeling Language (UML) is the most commonly used software description language. Today, textual notations for UML aim for a compact representation that is suitable for developers. Many textual notations exist but their applicability in engineering teams varies because a standardized textual notation is missing. Evaluating notations in order to find a suitable one is cumbersome and guidelines found in surveys do not report on applicability. This survey identifies textual notations for UML that can be used instead of or in combination with graphical notations, e.g. by collaborating teams or in different contexts. Additionally, it rates the notation’s applicability with respect to UML coverage, user editing experience, and applicability focused on engineering teams. Our results facilitate the otherwise unclear selection of a notation tailored for specific scenarios and enables trade-off decisions. We identified and characterized 21 known notations and 12 notations that were not covered in previous surveys. We used 20 categories to characterize the notations. Our findings show that a single notation does not cover more than 3 UML diagram types (mean 2.6), supports all surveyed state of the art editing features (only one notation supports all), and fits into existing tool chains.	unified modeling language	Stephan Seifermann;Henning Groenda	2016		10.1007/978-3-319-66302-9_1	notation;cognitive dimensions of notations;programming language;computer science;natural language processing;software;unified modeling language;artificial intelligence	NLP	-55.665608287841145	24.645329127272113	126683
1d34c1a26162c6b936a08615df7c025066bf7a2e	handling nonfunctional and conflicting requirements with design patterns	requirements analysis design pattern software quality software engineering object oriented design;formal specification;object oriented design;formal specification object oriented programming software quality;object oriented programming;software engineering;design quality;pattern analysis object oriented modeling software design software quality software engineering software systems iec application software pattern recognition buildings;design pattern;software quality	In recent years, the influences of design patterns on software quality have attracted an increasing attention in the area of software engineering, as design patterns encapsulate valuable knowledge to resolve design problems, and more importantly to improve the design quality. One of the key challenges in object-oriented design is how to apply appropriate design patterns for addressing various design problems. In this paper, a design pattern is analyzed from quality and tradeoff perspectives for investigating its capability on handling nonfunctional and conflicting requirements. Based on the analysis, the application of design patterns is integrated with a goal-driven approach to guiding developers in constructing the object-oriented design model systematically. The major benefit of our approach is to provide a pattern-aided approach to handling the nonfunctional requirements and to assisting the resolution of conflicting requirements.	executable;functional requirement;model-driven architecture;model-driven engineering;non-functional requirement;platform-independent model;software design pattern;software engineering;software quality	Nien-Lin Hsueh;Wen-Hsiang Shen	2004	11th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2004.57	connascence;reliability engineering;requirements analysis;software requirements specification;verification and validation;software design pattern;software sizing;architectural pattern;computer science;systems engineering;software design;social software engineering;component-based software engineering;software development;software design description;object-oriented design;software engineering;software construction;formal specification;design pattern;distributed design patterns;programming language;object-oriented programming;resource-oriented architecture;structural pattern;software quality control;software requirements;software quality	SE	-54.99086203222836	28.229469940527338	126739
5d48b2247ad4c26e3b9f19a4a1dcd3ae71cd0187	testing web applications by modeling with fsms	testing of web applications;student information system;state machine;finite state machines;system testing;test generation;state space explosion;finite state machine	Researchers and practitioners are still trying to find effective ways to model and test Web applications. This paper proposes a system-level testing technique that combines test generation based on finite state machines with constraints. We use a hierarchical approach to model potentially large Web applications. The approach builds hierarchies of Finite State Machines (FSMs) that model subsystems of the Web applications, and then generates test requirements as subsequences of states in the FSMs. These subsequences are then combined and refined to form complete executable tests. The constraints are used to select a reduced set of inputs with the goal of reducing the state space explosion otherwise inherent in using FSMs. The paper illustrates the technique with a running example of a Web-based course student information system and introduces a prototype implementation to support the technique.	aggregate data;aspect-oriented software development;bekenstein bound;beta normal form;computer science;constraint (mathematics);constraint logic programming;executable;experimental software engineering;finite-state machine;formal methods;higher-order function;ieee transactions on software engineering;information science;integration testing;java;mason;password;program analysis;prototype;requirement;reverse engineering;scalability;semiconductor industry;software testing, verification & reliability;software and systems modeling;software industry;software maintenance;software propagation;software quality;software testing;state space;string (computer science);student information system;user space;web application;world wide web	Anneliese Amschler Andrews;A. Jefferson Offutt;Roger T. Alexander	2004	Software & Systems Modeling	10.1007/s10270-004-0077-7	web modeling;real-time computing;simulation;computer science;engineering;finite-state machine;programming language;system testing;engineering drawing	SE	-56.01805731151171	31.94004231518811	127377
3594e6e8a9343933a7c39c3f7bd72e333239af68	designing compliant business processes with obligations and permissions. business process management workshops	gestion integrada;gestion integree;logica deontica;gestion entreprise;proceso concepcion;design process;sistema temporizado;validacion;availability;disponibilidad;reutilizacion;processus metier;business process design;timed system;service web;firm management;semantics;integrated management;web service;logique deontique;flow models;semantica;semantique;deontic logic;reuse;preparacion serie fabricacion;modele ecoulement;control proceso;control flow;process control;systeme temporise;proceso oficio;administracion empresa;validation;process model;process planning;preparation gamme fabrication;disponibilite;commande processus;business process;reutilisation;servicio web;processus conception;time constraint	The sequence and timing constraints on the activities in business processes are an important aspect of business process compliance. To date, these constraints are most often implicitly transcribed into controlflow-based process models. This implicit representation of constraints, however, complicates the verification, validation and reuse in business process design. In this paper, we investigate the use of temporal deontic assignments on activities as a means to declaratively capture the controlflow semantics that reside in business regulations and business policies. In particular, we introduce PENELOPE, a language to express temporal rules about the obligations and permissions in a business interaction, and an algorithm to generate compliant sequence-flow-based process models that can be used in business process design. 1 Motivation and Methodology Nowadays there is an increased pressure on companies to guarantee compliance of their business processes with business policy, the whole of internally defined business constraints, and business regulations, the whole of externally imposed business constraints. The obligation to guarantee compliance, whether imposed by management, customers, governments or financial markets, is often the main driver for business process automation. The downside to automating business processes, however, is that ill-conceived automation can make business processes more difficult to adapt to ever changing business policies and regulations. As such, automated business processes risk to become in time an impediment to compliance, rather than a enabler. Consequently, reconciling compliance and flexibility is a major concern in business process design. Companies often only implicitly think about business policy and regulations when they design business processes and pay little attention to avoid hardcoding policies and regulations directly in control-flow based process models. What is lacking is a more declarative approach in business process design in which business policy and regulations are made explicit in terms of definitions and constraints. The sequence and timing constraints on the activities in business processes, known as control flow, are an important aspect of compliance. In a software-release process, for instance, a new version may only be put in production after it has been tested and approved. Similarly, in an order-to-cash J. Eder, S. Dustdar et al. (Eds.): BPM 2006 Workshops, LNCS 4103, pp. 5–14, 2006. c © Springer-Verlag Berlin Heidelberg 2006 6 S. Goedertier and J. Vanthienen process, an order may only be shipped by the dispatching office after it has been accepted by a salesperson. Designers often think implicitly about these kinds of permissions and obligations when modeling the control-flow perspective of business processes. In this paper we show how the logic behind the obligations and permissions can be made explicit in the form of temporal deontic assignments that can be (re)used in business process design. To verify and validate such a set of deontic assignments, we show how to generate a compliant control-flow-based process model from it. The generated process model is not intended for process execution, but can rather be used by the process designer for verification and validation. Moreover, the generated process model allows the designer to identify the decision points and all possible violations of obligations, i.e. exceptions, that can occur. The remainder of this article is structured as follows. In section 2 we discus the relevant literature on the use of constraints in obtaining business process compliance and flexibility. In section 3, we formally introduce PENELOPE (Process ENtailment from the ELicitation of Obligations and PErmissions), a language to express temporal deontic assignments. Next, we discuss some issues in the verification and validation of temporal deontic assignments. Finally, in section 5 we define and illustrate the algorithm to generate control-flow based process models from a rule set of obligations and permissions.	algorithm;beam propagation method;business process;control flow;discus;declarative programming;deontic logic;hard coding;lecture notes in computer science;process modeling;software development;springer (tank);verification and validation	Stijn Goedertier;Jan Vanthienen	2006		10.1007/11837862_2	web service;availability;simulation;semantics of business vocabulary and business rules;design process;business domain;business requirements;engineering;artifact-centric business process model;business process management;process control;business case;process modeling;reuse;deontic logic;semantics;business process model and notation;business process;control flow;business process discovery;management;business rule;business process modeling;business architecture	AI	-52.858525291159225	19.764394157854532	127400
a78696905cf08c3a4b4dac907c037662c7c0439d	case study on critical infrastructures: assessment of electric power systems		Critical Infrastructures (CI) are increasingly responsible for vital services our society relies on; therefore, assessing their resilience is of utmost importance for improving trustworthiness on their services. Given the many challenges and open issues involved, a number of initiatives have been ongoing in the last decade, researching methods and developing tools for resilience assessment of critical infrastructures. Moving from the major challenges posed by CI from the point of view of resilience assessment and assessment needs, this chapter overviews a modelling framework for the analysis of interdependencies in Electric Power Systems (EPS), adopting a state-based stochastic approach. First, it is shown how the selected approach deals with the interdependencies, complexity, heterogeneity and scalability dictated by the infrastructures involved in framework implementation are then discussed, and some illustrative examples of different typologies of analysis are provided on selected EPS scenarios.	ibm power systems	Silvano Chiaradonna;Felicita Di Giandomenico;Paolo Lollini	2012		10.1007/978-3-642-29032-9_18	systems engineering	HCI	-61.54503521989291	19.822414102333486	127570
0c0152d53b3308dabf8141737493b11eabf93599	towards a comparative analysis of meta-metamodels	comparative analysis;domain specific modeling;comparison;modeling language;domain specific language;metamodeling;selection criteria	A cornerstone in Domain-Specific Modeling is the definition of modeling languages. A widely used method to formalize domain-specific languages is the metamodeling approach. There are a huge number of metamodeling languages. The choice of a suitable metamodeling approach is a challenging task because there is often a lack of knowledge about the selection criteria and the offered metamodeling features. In this paper, we analyze a set of metamodeling languages (ARIS, Ecore, GME, GOPPRR, MS DSL Tools, and MS Visio), define a comparison framework, and compare the selected meta-metamodels. The comparison forms a first foundation for solving the selection problem.	aris express;digital subscriber line;domain-specific language;domain-specific modeling;meta-process modeling;metamodeling;microsoft visio;modeling language;qualitative comparative analysis;selection algorithm	Heiko Kern;Axel Hummel;Stefan Kühne	2011		10.1145/2095050.2095053	natural language processing;metamodeling;metadata modeling;qualitative comparative analysis;computer science;domain-specific language;modeling language;programming language;algorithm	SE	-49.70588628809514	24.63545647681518	127639
f55cc8acebea4cb1e7f8e02e51469ed08cf6709e	finding structure in unstructured processes: the case for process mining	concurrent computing;unstructured processes;clustering techniques;bismuth;enterprise resource planning data mining;hospitals;abstraction;data mining;process mining;embedded system;event logs;incomplete information;visualization;roads;clustering techniques unstructured processes process mining event logs abstraction;enterprise resource planning;humans;process model;petri nets;prom;petri net;bismuth petri nets concurrent computing hospitals embedded system visualization roads humans prom design methodology;design methodology	"""Today there are many process mining techniques that allow for the automatic construction of process models based on event logs. Unlike synthesis techniques (e.g., based on regions), process mining aims at the discovery of models (e.g., Petri nets) from incomplete information (i.e., only example behavior is given). The more mature process mining techniques perform well on structured processes. However, most of the existing techniques fail miserably when confronted with unstructured processes. This paper attempts to """"bring structure to the unstructured"""" by using an integrated combination of abstraction and clustering techniques. The ultimate goal is to present process models that are understandable by analysts and that lead to improved system/process redesigns."""	cluster analysis;electromagnetically induced transparency;map;open-source software;overfitting;petri net;programmable read-only memory;real life	Wil M. P. van der Aalst;Christian W. Günther	2007	Seventh International Conference on Application of Concurrency to System Design (ACSD 2007)	10.1109/ACSD.2007.50	concurrent computing;computer science;data science;data mining;database;process mining;business process discovery;petri net	SE	-58.9052889408007	23.10903930258158	127676
36d797259cb2ba4a2ca7594a791b5a35036f0680	embedding architectural practices into extreme programming	software system;important matter;popular approach;popular agile method;agile method;different kind;development process;high quality;xp process model;extreme programming;architectural technique;embedding architectural practices;software design;writing;profitability;software architecture;pair programming;software engineering;process model;software systems;satisfiability;system architecture;feedback;customer satisfaction;embedded systems;agile methods;process design	Today, agile methods become a popular approach to develop software systems. They try to satisfy customer, respond to changes, release in less time and achieve suitable profits for developers. XP is one of the most popular agile methods which is currently being used and different kinds of research have been accomplished about its various aspects such as pair programming. In spite of all benefits known of XP, it does not involve architectural techniques yet. As it is mentioned in many technical reports, the way to achieve high quality of system is to consider its architecture as an important matter in the development process. This paper introduces two practices in order to empower XP's development process toward improving system's architecture. The main characteristic of proposed solution is that it is derived from values and practices of XP in order to be compatible with XP process model and to keep its agility intact.	agile software development;display resolution;extreme programming;pair programming;process modeling;software system	Amir Azim Sharifloo;Amir S. Saffarian;Fereidoon Shams Aliee	2008	19th Australian Conference on Software Engineering (aswec 2008)	10.1109/ASWEC.2008.65	software architecture;extreme programming;pair programming;extreme programming practices;systems engineering;engineering;software engineering;process modeling;agile software development;software development process;profitability index;systems architecture;software system;computer engineering;satisfiability	SE	-61.3988156795095	26.804274875319702	127814
04c14b1ac49cd5fb46213766df9d7fcbf0a32e41	a goal oriented approach to identify and configure feature models for software product lines		A goal oriented approach can be used as a way to discover variable and common requirements of a software product line (SPL), as well as to reduce costs associated with the configuration of a specific product in a product family. A goal oriented requirements engineering approach which has been used to develop complex system is the i* framework. It provides a manner to identify and specify the stakeholders’ goals in relation to the intended system, as well as the characteristics of the system itself. This work proposes an extension of the i* modeling language, called i*-c (i* with cardinality), that allows inserting cardinality in some of its modeling elements. The G2SPL (Goals to Software Product Line) approach defines a process to identify and model common and variable features of a SPL using i* models with cardinality, as well as guides the configuration of a specific product in the SPL.	complex system;feature model;modeling language;requirement;requirements engineering;software product line;spatial variability	Carla Schuenemann;Clarissa Borba;Jaelson Brelaz de Castro	2011			software engineering;software;complex system;cardinality;modeling language;feature model;requirements engineering;goal orientation;systems engineering;software product line;computer science	SE	-55.86696483775226	25.399109180053404	127933
acc65ba207d1108c5e76feed914544161fb780d9	empirical validation of a usability inspection method for model-driven web development	articulo;web applications;family of experiments;model driven development;usability inspection	Web applications should be usable in order to be accepted by users and to improve the success probability. Despite the fact that this requirement has promoted the emergence of several usability evaluation methods, there is a need for empirically validated methods that provide evidence about their effectiveness and that can be properly integrated into early stages of Web development processes. Model-driven Web development processes have grown in popularity over the last few years, and offer a suitable context in which to perform early usability evaluations due to their intrinsic traceability mechanisms. These issues have motivated us to propose a Web Usability Evaluation Process (WUEP) which can be integrated into model-driven Web development processes. This paper presents a family of experiments that we have carried out to empirically validate WUEP. The family of experiments was carried out by 64 participants, including PhD and Master’s computer science students. The objective of the experiments was to evaluate the participants’ effectiveness, efficiency, perceived ease of use and perceived satisfaction when using WUEP in comparison to an industrial widely-used inspection method: Heuristic Evaluation (HE). The statistical analysis and meta-analysis of the data obtained separately from each experiment indicated that WUEP is more effective and efficient than HE in the detection of usability problems. The evaluators were also more satisfied when applying WUEP, and found it easier to use than HE. Although further experiments must be carried out to strengthen these results, WUEP has proved to be a promising usability inspection method for Web applications which have been developed by using model-driven development processes.	computer science;email;ext js javascript framework;fax;interactive visual analysis;ke software;linear algebra;lua;model-driven architecture;symbolically isolated linguistically variable intelligence algorithms;tegra;uniform resource identifier;usability inspection;web development;web usability	Adrian Fernandez;Silvia Mara Abrahão;Emilio Insfrán	2013	Journal of Systems and Software	10.1016/j.jss.2012.07.043	usability goals;pluralistic walkthrough;web usability;cognitive walkthrough;web application;simulation;usability;computer science;systems engineering;software engineering;usability engineering;programming language;heuristic evaluation;world wide web;usability lab;usability inspection	SE	-59.55998485279389	26.35215887545097	127937
44635cae2d0c82f9449f63f70b2dfb36f650cddb	design patterns detection using sop expressions for graphs	program understanding;sop form;software maintenance;uml;object oriented software;boolean function;design pattern;software reuse	Several recurring patterns of classes exist in many object oriented software as an experience of developers. Design Pattern Detection is an important part of many solutions to Software Reuse practices. Design pattern instances are highly important and useful for program understanding and software maintenance. Hence an automatic and reliable design pattern mining capability is required. Here we are proposing a new method for design pattern detection based on Boolean functions.	code reuse;data mining;graph (discrete mathematics);pattern recognition;program comprehension;software design pattern;software maintenance	Manjari Gupta;Akshara Pande;Anil Kumar Tripathi	2011	ACM SIGSOFT Software Engineering Notes	10.1145/1921532.1921541	unified modeling language;module pattern;mediator pattern;verification and validation;software design pattern;state pattern;software sizing;architectural pattern;computer science;systems engineering;engineering;software design;component-based software engineering;software development;software design description;object-oriented design;software engineering;software construction;database;adapter pattern;design pattern;distributed design patterns;boolean function;programming language;resource-oriented architecture;software maintenance;structural pattern;specification pattern	SE	-54.03296838262221	31.216330616893078	127975
fd3d81f72fef1d9f59ec11b39612181b42e3dec3	towards the initial conceptual database model through the uml metamodel transformations	atl;activity diagram;class diagram;source business model;generators;conceptual database model;logic design;database management systems;uml;uml metamodel transformation;semantics;automatic generator;uml business activity diagram class diagram conceptual database model atl;physical design;relational database;indexing terms;development process;automatic generation;business activity diagram;uml class diagram;requirement analysis;business model;semantic data model;conceptual design;source business model conceptual database model uml metamodel transformation atl automatic generator uml business activity;business process modeling notation;business;unified modeling language;unified modeling language database management systems;unified modeling language business generators semantics data models relational databases;relational databases;uml business activity;data models	This paper presents an ATL-based automatic generator of the initial conceptual database model. The implemented generator takes the detailed UML business activity diagram as the source business model and generates the UML class diagram representing the target initial conceptual database model.	activity diagram;business process model and notation;class diagram;database design;database model;entity;metamodeling;open-source software;process modeling;relational database;unified modeling language	Drazen Brdjanin;Slavko Maric	2011	2011 IEEE EUROCON - International Conference on Computer as a Tool	10.1109/EUROCON.2011.5929148	unified modeling language;uml tool;relational database;computer science;systems engineering;conceptual schema;applications of uml;class diagram;data mining;database;semantics	DB	-52.28631981655889	21.185359975988195	128170
2bb1425fac90bc86d159eeee4c63ccf595bae79a	towards modeling and analyzing variability in evolving software ecosystems	temporal perspective;software product line spl;software ecosystem seco;analysis;variability;technical ecosystem modeling notation tecmo;evolution	A software ecosystem (SECO) encompasses a set of interdependent software systems where individual products are created by combining a common software platform with variable extensions. Examples are the SECOs surrounding Eclipse or Android. Due to independent release cycles of the multiple vendors for platform and extensions, SECOs are evolving frequently. This makes it hard to get a concise impression of the structure of a SECO and its variable artifacts during a given period of time. We contribute a metamodel to capture the variability in an arbitrary SECO and its evolution based on the notion of real time. We further present a procedure to create temporal perspectives on the SECO. Additionally, we provide means to analyze evolution of variability in between explicit releases of the platform, e.g., in accordance with the different release cycles of individual extensions. We demonstrate feasibility of our approach by modeling a part of the Eclipse SECO over a period of three years.	android;eclipse;ecosystem model;heart rate variability;interdependence;metamodeling;real-time computing;release consistency;software ecosystem;software system;spatial variability	Christoph Seidl;Uwe Aßmann	2013		10.1145/2430502.2430507	real-time computing;simulation;systems engineering;engineering;analysis;evolution	SE	-54.27009467783309	28.741791508551096	128347
185f57efe0603d150c574be3b17a2dce2d07f721	software engineering	client/server;data warehouse and repository;java;languages;management;modules and interfaces;security;training	The need for automation of software development is discussed in the context of next-generation computing. The lag in the use of available tools is pointed out. Rapid prototyping and the reuse of existing program components are two solutions discussed here. Finally, the elements needed for an effective integrated, automated programming environment are considered.	integrated development environment;rapid prototyping;software development;software engineering	Raymond T. Yeh	1975	IEEE Spectrum	10.1109/C-M.1975.218950		SE	-51.167805495101604	28.339789891625653	128395
270af6cd6c2d7388e3e72b17480176312c527217	realizing business agility requirements through soa and cloud computing	significant ramifications;software;iaas;busiess agility;software solutions;busiess agility soa cloud computing utility computing iaas paas;soa;software architecture;internet;business agility requirements;it community;business data processing;clouds;software development;paas;service oriented architecture software cloud computing organizations clouds;service oriented architecture business agility requirements soa cloud computing it community significant ramifications software solutions software development;organizations;utility computing;service oriented architecture;software architecture business data processing internet;cloud computing	In the past five years, the IT community has witnessed the adoption of two major trends that had significant ramifications on how software solutions are developed and deployed. The first trend is focused on the software development side and is manifested through the popular use and adoption of software services and service oriented architecture (SOA). The second trend provides support to SOA and changes many views on how software is deployed and developed as well. Both trends are here to stay and pose many challenges for both business and IT on how to leverage them to enhance the overall productivity, agility and efficiency of the overall organization. More specifically, how to realize business agility requirements through the potential synergies between SOA and cloud computing.	cloud computing;requirement;software development;synergy	Mamoun Hirzalla	2010	2010 18th IEEE International Requirements Engineering Conference	10.1109/RE.2010.70	computer science;systems engineering;software engineering;service-oriented architecture;distributed computing	SE	-60.26668255996794	20.74798194196695	128489
b88ae6754b655c7e28a304ec7ed977b24b86b579	models, domains and abstraction in software development	domain model;abstract data types;abstract data types software engineering systems analysis;software development process;development process;software engineering;programming jacobian matrices production electronic mail concrete skeleton electrical capacitance tomography information systems qualifications;software architecture;software development methodologies;systems analysis;software development;object oriented software development;modeling;influencing forces software development technology underlying model development process domains abstraction supplementary perspective actors	"""Any softwaredevelopmenttechnologyhasanunderlyingmodel—explicit or implicit—of thedevelopment process.In orderto understandmoreaboutthedevelopmentprocessandthemethodologiesweabstractfrom these.The perspecti ve chosenfor the abstractionincludesdomains,modelsdevelopedduring the process andthekind of abstractioninvolvedin thephasesof theprocess.A supplementaryperspecti ve includesthe phasesin the process,the actorsduring the development,andthe influencingforcesof the quality of the resultingmodelsandsystems.In generaltheperspecti ve controlsthenatureof theknowledgeachievedby meansof abstraction.Thenatureof our resultfrom theabstractionover processesandmethodologiesis the structureandtheinteractionof thedevelopmentprocess—corresponding to thetwo chosenperspecti ves. Existingmethodologiesprescribehow to conductthesoftwaredevelopmentprocess—the y implicitly assumevariousmodelsof thedevelopmentprocess.Eachmethodologyhasits ownuniqueunderstandingof the process,that is expressedimplicitly or explicitly astheunderlyingmodelof themethodology. This uniquenessis very importantwhenyou arelooking at a givenmethodology, however it is not thepurposeof this articleto go into suchspecialties.Rather , thepurposeis to describethecommonalitiesof themethodologies in abstractform. The presentationis a generalizedview of the methodologies, togetherwith a numberof additionalcontributionsat theabstract,generalevel of description. In our abstract,generaldescriptionof thedevelopmentprocesswe have chosena certainperspecti ve on the process.The perspecti ve includesthe models, the domainsandthe abstraction forms involved in the overallunderstandingof thedevelopmentprocess.Thecontentof thisarticleis amodelof theunderstanding of theentire developmentprocess.By themodelsin theprocesswe refer to thedifferentkindsof models createdduringtheprocess.Sucha modelreflectsanunderstandingof a domainof which we eitherconduct analyticor constructi vework duringthedevelopmentprocess—wemodelthedomain.By domainswemean suchdomainsidentifiedandusedduring the softwaredevelopmentprocess.By abstractionwe meanthe kind of abstractionprocesseswe conductduring thesekinds of modeling. By our perspecti ve we focus of theseconceptsin our abstract,generaldescription.Modeling is essentialfor the softwaredevelopment process—bothmodelsthat supportour understandingof the logical phasesof the processincluding the domainsinvolved in this process,and models(of someof thesedomains)that are producedduring the process.Thesemodelsproducedareof eithera abstractor technicalnature:a modelof a problemdomain capturesa logical understandingof theconceptsin this domain,whereasthedescriptionorganizationof the systemcanbeseenasa modelof thearchitectureof thesystem.In bothcasesthemodelsareabstractions over theconcretedomain—asabstractionsthey capturetheessential understandingof thedomain1. The models,the domainsandthe abstractionsarethe mainelementsin our perspecti ve—they form the skeletonof the """"structure""""in developmentprocess.In addition,we focuson thephases, theactorsandthe This researchwassupportedin partby DanishNationalCenterfor IT Research, ProjectNo. 74. Themodelof thesoftwaredevelopmentprocessdiscussedis primarily intendedfor informationsystems. forcesin ourmodelof thedevelopmentprocess, thatheavily influencetheresultingsystem.Thephaseseach havea processaspect(theactivities in thephase),a notationaspect(thediagrams/language for description), and a patternaspect(the term patternis usedhereto cover a distilled, abstractform of experienceand qualificationswithin abstractformationsover eitherprocessor notation). The actorsaredescribedin the form of characteristicroles, that areplayedduring the process.The rolesdeterminethe actualchoiceof certaindomains,therequirementsto theprocess,andactualinteractionactivities of theprocess—the y form the skeletonof the interactionin the developmentprocess.Still a numberof forcesdeterminethe actual outcomeof theprocess—forexampleenvironment,skills andexperienceareessentialfor the functionality andqualityof theresultingsystem. The logical phasesof theprocess,i.e. analysis,designandimplementation,eachhave differentpurpose andcharacteristics. In object-orientedsoftwaredevelopmenttheanalysisphaseis to someextentconstructive by the building of diagrammaticmodelsof domainsthat arepartsof the real world. The challenges duringtheconstructionarethechoiceof perspecti veon thedomains,theformationof theconcepts,andthe selectionof theproperties.Theimplementationphaseis alsoconstructi ve by the transformingandrefining of existing descriptionsat a moreabstractlevel into theprogramminglanguagelevel. Thechallengeis the simplenessandefficiency of thetransformationbetweenthelevels.In bothcasestheoutsetis given(domains or descriptions)andthe importantskill is knowledgeaboutthe notationin which the constructi ve work is expressed(diagramsor programminglanguage). Thedesignphaseis evenmorechallenging,andthereforeanotherfocuspoint of the this article. During designwe createanabstractmodelof thesystemalmostfrom scratch,andwith two aspects.Oneaspects of themodelcapturestheoverallarchitectureof thesystem,while theotheraspectcapturestheactualfunctionality of thecomingsystem.Embeddedin themodelis theessensof thenon-functionalqualitiesof the system. The importanceof theseaspectsmakesthe designphasemoredemandingthan the analysisand implementationphases.Furthermorethe typeof the fundamentalwork in the designphaseis creati ve and in somecasesinnovative. Essentiallywe createmodelsalmostout of nothing—wedo not just """"mirror"""" existing domainsor """"transform""""form onelevel to another —we form new artifactsby creati ve work basedon experienceandskills. The SoftwareDevelopmentProcess. We focuson theanalysis,designandimplementationphasesof the softwaredevelopmentprocess.The testing,documentationand maintenancephasesarenot discussedin this article,althoughthephasesalsoarecloselyrelatedto themodelsproducedduringanalysis,designand implementation.We discusssoftwaredevelopmentmethodologies, including theprocessandthenotation, but thesupportof themethodologiesandtechniquesby tools. Analysis Design Implementation Model Model Model (a)PhasesandModels. Customer Organization Development Organization Developer Customer User System Idea"""	programming language;software development process;typeof	Eyðun Eli Jacobsen;Bent Bruun Kristensen;Palle Nowack	1998		10.1109/TOOLS.1998.713585	domain analysis;verification and validation;software engineering process group;computer science;systems engineering;package development process;software design;social software engineering;software framework;software development;software engineering;domain engineering;iterative and incremental development;software construction;systems development life cycle;software walkthrough;empirical process;software analytics;resource-oriented architecture;goal-driven software development process;software development process;software system;computer engineering	SE	-49.769301589849334	27.453320080393322	128573
3b164816ab29c228b8b8f4146b28f7ea25abbf4f	constructing patterns verification criteria based on quality attributes: web security context patterns case study	software;quality attributes;electronic mail;goals;standards;software quality formal verification internet object oriented programming security of data;transformations;software engineering;web security context patterns;security context software user interfaces standards electronic mail software engineering;web security context patterns quality attributes verification criteria goals sources representations transformations applications;pattern application software pattern verification quality attribute web security context pattern verification criteria establishment experimental design experimental execution knowledge transformation;representations;sources;security;user interfaces;context;applications;verification criteria	The proposed patterns for a specific domain were widely used for the concept of reusing of the resolved problems to similar ones. The verification criteria for proposed patterns evaluation are one of the important factors that affect the patterns quality. This research proposed patterns verification method and criteria based on quality attributes in order to improve patterns validity. The method was composed of 4 steps, verification criteria establishment, experimental design, experimental execution and results analysis and report. The two additional verification criteria, Knowledge Transformation and Patterns Application were proposed while three criteria, Goal, Source and Representation were proposed by Breaux (2012). In addition, the quality attributes of 5 verification criteria were introduced and applied in a case study. They were Achievement, Functionality, Understandability, Completeness and Consistency, and Clarification and Application. From our previous work, the construct patterns of Web Security Context Patterns (WSCP) were used as a case study. Experts in both academia and industry sectors were selected to evaluate the WSCP patterns using the 5 evaluation criteria based on the proposed quality attributes as a list of issues. By using these verification criteria, the experimental results indicated that the quality of WSCP patterns was assessed in a high level of satisfaction with an overall mean above 4 from a 5 scale.	best practice;conformance testing;consistency model;context switch;design of experiments;high-level programming language;internet security;lazy evaluation;list of system quality attributes;non-functional requirement;software requirements specification;user agent;verification and validation	Pattariya Singpant;Nakornthip Prompoon	2016	2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2016.7550839	transformation;computer science;information security;mental representation;data mining;database;user interface;information technology	SE	-56.96402669793319	30.555036112611315	128602
ea377f21d8fa8cb940976306da2371b6e78a8dcf	software reliability modeling with logistic test coverage function	software reliability modeling;logistic test coverage function;software reliability modeling test coverage logistic function fault detection;formal specification;completeness testing;effectiveness testing;fault detection software reliability modeling logistic test coverage function completeness testing effectiveness testing;testing;logistics;program testing;test coverage;fault detection;software reliability formal specification program testing;software reliability logistics software testing fault detection system testing reliability engineering systems engineering and theory equations engineering students application software;mathematical model;model test;logistic function;software reliability;data models	Test coverage is a good indicator for testing completeness and effectiveness. This paper utilizes the logistic function to describe the test coverage growth behavior. Based on the logistic test coverage function, a model that relates test coverage to fault detection is presented and fitted to one actual data set. The experimental results show that, compared with three existing models, the evaluation performance of this new model is the best at least with the experimental data. Finally, the logistic test coverage function is applied to the NHPP software reliability modeling for further research.	fault coverage;fault detection and isolation;reliability engineering;software quality;software reliability testing	Haifeng Li;Qiuying Li;Minyan Lu	2008	2008 19th International Symposium on Software Reliability Engineering (ISSRE)	10.1109/ISSRE.2008.51	modified condition/decision coverage;logistic function;reliability engineering;logistics;data modeling;computer science;systems engineering;software engineering;mathematical model;data mining;formal specification;software testing;code coverage;fault detection and isolation;software quality	SE	-62.05051472407493	31.979249189127582	128916
194467603bc9829c2d45611ad9c3d077ff933f11	rt-component object model in rt-middleware&#8212;distributed component middleware for rt (robot technology)	software platform;component based systems;object oriented programming;control engineering computing robot programming middleware object oriented programming;component middleware;support system;component development distributed component middleware robot technology robot system integration software platform robotic system development;system integration rt robot technology software component middleware robot system;system integration;software component;system development;middleware;control engineering computing;middleware service robots intelligent robots robot control application software humans software libraries intelligent systems performance evaluation ubiquitous computing;robot programming	"""This paper proposes RT-component object model in RT-middleware for robot system integration. """"RT"""" means """"robot technology"""", which is applied not only to industrial field but also to nonindustrial field such as human daily life support systems. RT-middleware is a software infrastructure for RT systems. We have studied modularization of RT elements at software level. For that reason, RT-middleware, which promotes application of RT in various field, have been developed. Robotic system development methodology and our RT-middleware concepts was discussed. RT-component, which is a basic software unit of RT-middleware based system integration, is derived from that discussion. Next, the object model and the interface definition of RT-component architecture was discussed. Finally conclusion and future work are described"""	black box;cap gemini sdm;component-based software engineering;distributed object middleware;functional genomics;japan robot association;rt middleware;software development process;software release life cycle;system integration;usability	Noriaki Ando;Takashi Suehiro;Kosei Kitagaki;Tetsuo Kotoku;Woo-Keun Yoon	2005	2005 International Symposium on Computational Intelligence in Robotics and Automation	10.1109/IROS.2005.1545521	embedded system;middleware;real-time computing;system integration testing;computer science;systems engineering;component-based software engineering;software development;middleware;ubiquitous robot;object-oriented programming;software system;system integration	Robotics	-51.195131671889996	27.99324275167911	128993
86b9394bf6673a12ddbda2644a78a9fb073631f9	conditional workflow management: a survey and analysis	conference paper	Workflows form the essential part of the process execution both in a single machine and in distributed environments. Although providing conditional structures is not mandatory for a workflow management system, support for conditional workflows is very important in terms of error handling, flexibility and robustness. Several of the existing workflow management systems already support conditional structures via use of different constructs. In this paper, we study the most widely used workflow management systems and their support for conditional structures such as if, switch, and while. We compare implementation of common conditional structures using each of these workflow management systems via case studies, and discuss capabilities of each system.		Emir M. Bahsi;Emrah Ceyhan;Tevfik Kosar	2007	Scientific Programming		computer science;data science;data mining;database	HPC	-52.15225779392903	18.260296677422463	129100
6cb24fdb1d947de108dcd0c71ef98ea677dff8b2	large heterogeneous knowledge bases	software development process;user requirements;knowledge base	This paper discusses large knowledge bases as software development tools which support the creativity of programming in the large. User requirements, architecture and internal knowledge representation language of large knowledge bases are considered. Higher order constraint networks are proposed for representing knowledge about computability. 1 Software reusability An important characteristic of the software development process is the degree of reusability of software. Simply speaking, knowledge once encoded in the form of programs must be reusable every time it would be needed in programming new problems. A natural way to reuse programs is to apply large software libraries. It is expected that this increases the productivity of software development and reliability of the software produced. However, with the exception of a small number of speciic applications, the software libraries of today tend to be very diicult to use. They lack comprehensive user interface, and require from the users too much eeorts of studying of documentation. One can use the following analogy. From a usability standpoint , software library is like an ordinary library of literature containing a large number of books, except that it has no comprehensive catalogue, the books dont have title pages, and they are stored in a random order and are accessible only by numbers which are their formal addresses. Attempts are being made to build knowledge bases which could provide a guidance in selecting suitable software from software libraries (Devanbu 1991). The goal of the present work is to propose a design for a knowledge base which would support automatic construction of large programs from their declarative speciications. Roughly speaking, we shall build a software library which contains two layers of knowledge, Figure 1.1. The lower layer is a repository of programs. These programs are not directly visible in the software development process. They are covered by the layer of knowledge about their applicability for solving diierent problems. This knowledge is visible to users (software developers) and it is represented in terms of concepts of a problem domains, not in terms of programs. Besides that, we distinguish between the internal knowledge 1	book;computability;documentation;knowledge base;knowledge representation and reasoning;library (computing);outline of software engineering;problem domain;programming in the large and programming in the small;programming tool;requirement;software developer;software development process;software repository;usability;user interface	Enn Tyugu	1994			knowledge base;software requirements specification;software mining;computer science;systems engineering;knowledge management;requirement;knowledge-based systems;open knowledge base connectivity;database;knowledge extraction;goal-driven software development process;domain knowledge	SE	-53.93930237743234	28.392863331107115	129332
7ee1c671a017165c8b84c901bc1e9da91205c76e	sharing the design information in a distributed concurrent development of large-scale software systems	distributed development;change management design information sharing distributed concurrent development large scale software systems classification management structuredness structural characteristics temporal characteristics semi structured design information wide area information network intranet;parallel programming information networks local area networks software engineering;large scale software systems;change management;design engineering;wide area information network;design information sharing;software systems;parallel programming;classification;information network;software engineering;structuredness;technology management;distributed concurrent development;large scale;semi structured design information;software engineering environment;temporal characteristics;large scale systems software systems software development management information management design engineering information analysis engineering management programming internet technology management;internet;information networks;engineering management;information management;structural characteristics;intranet;data warehouse;management;programming;information analysis;structural design;local area networks;software development management;large scale systems;document management	The paper analyzes the characteristics of the design information in a distributed concurrent development of large-scale software systems, and proposes a method for the classification and management based on the concept of structuredness in terms of structural and temporal characteristics of the design information. With the classification method, we discovered that many pieces of design information involved in the upper processes are semi-structured. To share and manage the semi-structured design information, we developed a wide area information network (WAIN) on our intranet. It was also possible to verify the changes in those pieces of design information requiring a strict change management.	software system	Mikio Aoyama	1996		10.1109/CMPSAC.1996.544159	local area network;programming;the internet;information engineering;biological classification;computer science;systems engineering;knowledge management;technology management;data warehouse;change management;document management system;management information systems;database;information management;distributed design patterns;data analysis;management;information architecture;information system;software system	SE	-50.9838083476286	18.89231351707574	129335
ac2934985a688fbbdeea3670e59a60a1fd4fa15a	architectural framework modeling in telecommunication domain	distributed system;application framework;design reusability;object oriented methods;domain partitioning;network traffic data analysis;component based approach;product line development architectural framework modeling telecommunication domain design reusability large scale object oriented systems complex software systems development domain partitioning architectural framework layering component based approach design patterns;service management;software systems;object oriented framework;telecommunication computing;large scale object oriented systems;product line;object oriented programming;communication system software;network and service management;architectural framework layering;object oriented systems;data analysis;large scale;software architecture;object oriented modeling application software computer architecture software systems pattern analysis telecommunication traffic traffic control data analysis large scale systems software architecture;network traffic;product line development;architectural framework modeling;software reusability;design pattern;telecommunication domain;design patterns;domain analysis;architectural pattern;distributed systems;complex software systems development;architectural patterns;software reuse;object oriented methods software architecture telecommunication computing software reusability object oriented programming	Architectural frameworks have shown to increase the design reusability in large-scale object-oriented systems. Drawing on experience in complex software systems development in telecommunication domain, we present concepts and -techniques for domain partitioning and architectural -framework modeling and layering. In particular, we discuss <how a component-based approach, architectural modeling styles, and the systematic usage of architectural and design patterns provide a common framework for product-line development. Two application frameworks based on this model are presented as case studies. -	application framework;component-based software engineering;design pattern;software development process;software system	Giulio Fregonese;Alessandro Zorer;Giovanni Cortese	1999		10.1145/302405.302686	real-time computing;architectural geometry;architectural pattern;computer science;systems engineering;software engineering;architectural technology;representational state transfer;computer engineering	SE	-49.55945545409299	30.488484042146602	129372
909b04e9892e30edcd42bc17b3d226c551f8b3c5	modeling and verifying combinatorial interactions to test data intensive systems: experience at the norwegian customs directorate	standards;testing;data mining;testing data models business relational databases standards data mining;business;relational databases;testing classification tree modeling combinatorial interaction testing data interactions e governance human in the loop relational databases;data models	Data-intensive systems in e-governance collect and process data to ensure conformance to a set of business rules. Testers meticulously verify data in test databases, extracted from different steps of a live production stream , for correct application of business rules. We simplify the process by allowing testers to model a test domain on a relational database and automatically generate test cases representing data interactions satisfying combinatorial interaction coverage criteria. This paper also introduces test cases with self-referential interactions, which is a necessity in real-world databases. We verify these test cases using our human-in-the-loop tool, Depict. Depict, with expert assistance, generates complex SQL queries for test cases and produces a visual report of test case satisfaction. We apply the approach to two scenarios: 1) simplify and optimize a periodic archiving operation and 2) verify fault codes within the testing environment of the Custom directorate's TVINN system.	archive;code;conformance testing;e-governance;interaction;relational database;sql;self-reference;test case;test data	Sagar Sen;Dusica Marijan;Carlo Ieva;Astrid Grime;Atle Sander	2017	IEEE Transactions on Reliability	10.1109/TR.2016.2618121	reliability engineering;data modeling;relational database;computer science;engineering;data science;data mining;database;software testing;test management approach	SE	-57.43748526970863	30.285126886168566	129382
20432b430dea347c0a88763140a249dbd88ea92a	search-based design of large software systems-of-systems	software;uml;unified modeling language computer architecture stakeholders software algorithm design and analysis system analysis and design software engineering;system analysis and design;search based software engineering;large software systems;stakeholders;software engineering;and large software systems;computer architecture;engineering and technology;teknik och teknologier;uml search based software engineering automatic design and large software systems ocl;automatic design;ocl;unified modeling language;utility theory probability search problems software architecture systems analysis unified modeling language;search algorithm search based design large software systems of systems automatic designer core formalism fitness function nonfunctional requirements utility theory stakeholder requirements ocl based predictive probabilistic architecture modeling framework p2amf uml model;algorithm design and analysis	This work in progress paper presents the foundation for an Automatic Designer of large software systems-of-systems. The core formalism for the Automatic Designer is UML. The Automatic Designer extends UML with a fitness function, which uses analysis of non-functional requirements, utility theory, and stakeholder requirements, as the basis for its design suggestions. This extension logic is formalized using an OCL-based Predictive, Probabilistic Architecture Modeling Framework (called P2AMF). A set of manipulation operators is used on the UML model in order to modify it. Then, from a component library (with OTS products), new components will be introduced to the design. Using operators, a search algorithm will look for an optimal solution.	component-based software engineering;fitness function;functional requirement;non-functional requirement;object constraint language;predictive modelling;search algorithm;semantics (computer science);software system;system of systems;unified modeling language;utility	Robert Lagerström;Pontus Johnson;Mathias Ekstedt	2015	2015 IEEE/ACM 3rd International Workshop on Software Engineering for Systems-of-Systems	10.1109/SESoS.2015.15	uml tool;computer science;systems engineering;software engineering;applications of uml;database	SE	-56.48529578013901	29.060235748110927	129605
241b0f2f0b35171cf6acf63ff8ba593249eb2f72	complementary use of modeling grammars	conceptual modeling	Conceptual modeling continues to be an important means for graphically capturing the requirements of an information system. Observations of modeling practice suggest that modelers often use multiple modeling grammars in combination to articulate various aspects of real-world domains. We extend an ontological theory of representation to suggest why and how users employ multiple conceptual modeling grammars in combination. We provide an empirical test of the extended theory using survey data and structured interviews about the use of traditional and structured analysis grammars within an automated tool environment. We find that users of the analyzed tool combine grammars to overcome the ontological incompleteness that exists in each grammar. Users further selected their starting grammar from a predicted subset of grammars only. The qualitative data provides insights as to why some of the predicted deficiencies manifest in practice differently than predicted.	information system;requirement;structured analysis	Peter F. Green;Michael Rosemann;Marta Indulska;Jan Recker	2011	Scandinavian J. Inf. Systems		empirical research;conceptual model;information system;structured interview;survey data collection;data mining;natural language processing;structured analysis;artificial intelligence;rule-based machine translation;computer science;grammar	HCI	-54.78325028791969	21.237068354736948	129617
dbac9b43790630e5322e9a18a9d01439967258bb	separation and composition of concerns in the object-oriented model	object oriented model;programming language;software engineering;software composition	This is a position statement for the workshop on strategic directions in computing research held at MIT in June 1996. In the (conventional) OO model, the separation of concerns principle is supported basically in three ways: 1. By defining objects as the models of real-world concepts that arè`naturally'' separated from each other 2. By separating the concerns of providing an abstract object interface and its implementation 3. By grouping functions together around objects so that functions that are less related are structurally separated from one another To be able to construct complex software systems, the separate concerns must be put together with minimum effort. The OO model provides various ways in composing concerns together: 1. In the implementation part of an object, the structure and the behavior of the nested implementation objects can be composed under the definition of the encapsulating object; 2. Both inheritance and delegation mechanisms define composition of behavior. For example, in inheritance, the operations defined within a subclass is composed with the operations of its superclass(es);	separation of concerns;software system	Mehmet Aksit	1996	ACM Comput. Surv.	10.1145/242224.242413	model-driven architecture;computing;software sizing;separation of concerns;computer science;software design;social software engineering;software framework;component-based software engineering;software development;software construction;function composition;programming language;resource-oriented architecture;software development process;software system	PL	-51.334653441876384	27.61530260575333	129892
b786128f42e34900ef1fdfbacf4d98e5e4d67571	mining collaboration patterns of software development processes based on trace alignment		Developing large-scale software usually involves the interaction of a great number of engineers over a long period. To discover the collaboration patterns from developing logs helps improve the software development processes. Traditional techniques of process mining can be employed to identify such patterns. Unfortunately, due to the high uncertainty of software development process, they tend to obtain “spaghetti” models which are difficult to comprehend or even misleading. As a remedy, in this paper we propose an approach to the discovery of collaboration patterns existing in software development process by aligning development logs. It considers not only the sequence of activities, but also the collaboration of actors who perform activities. Instead of using time-consuming graph mining techniques, it employs the trace alignment, which is much more straightforward. Moreover, unlike some traditional approaches, the discovered patterns are determined because we do not depend on the mined process model that is usually uncertain due to the unstructured nature of software development process. The experimental results based on a large dataset generated from CPNTools demonstrate the effectiveness of our approach.	high- and low-level;mined;process modeling;real life;software development process;structure mining;tracing (software)	Dongjin Yu;Jiaojiao Wang	2017		10.1145/3084100.3084103	software development process;goal-driven software development process;software;software development;process mining;empirical process (process control model);data mining;iterative and incremental development;software engineering process group;systems engineering;engineering	SE	-59.50724766879654	23.341854712809003	129937
371f7aff8b18b274e629593c0cc9d6c746f77e0f	estimating software development effort based on use cases-experiences from industry	developpement logiciel;industrial case study;behavioral analysis;lenguaje uml;langage modelisation unifie;use cases;analisis programa;effort estimation;estimation;estudio caso;application industrielle;object oriented;desarrollo logicial;unified modelling language;analyse comportementale;software development;etude cas;industrial application;oriente objet;analisis conductual;expert knowledge;program analysis;industrial experience;functional requirement;object oriented analysis;analyse programme;orientado objeto;use case;aplicacion industrial	Use case models are used in object-oriented analysis for capturing and describing the functional requirements of a system. Several methods for estimating software development effort are based on attributes of a use case model. This paper reports the results of three industrial case studies on the application of a method for effort estimation based on use case points. The aim of this paper is to provide guidance for other organizations that want to improve their estimation process applying use cases. Our results support existing claims that use cases can be used successfully in estimating software development effort. The results indicate that the guidance provided by the use case points method can support expert knowledge in the estimation process. Our experience is also that the design of the use case models has a strong impact on the estimates.	cost estimation in software engineering;functional requirement;software development;use case points	Bente Anda;Hege Dreiem;Dag I. K. Sjøberg;Magne Jørgensen	2001		10.1007/3-540-45441-1_35	use case;use-case analysis;simulation;computer science;analysis effort method;operations research;use case points	SE	-61.59421114231412	28.768921966679397	130103
326753a572f41b00b392ed918c770f240aac84f2	a software framework for agricultural and forestry robots	computer vision and robotics autonomous systems;agriculture industries;forestry;forestry industries;datorseende och robotik autonoma system;computer and information science;architecture view;software architecture;data och systemvetenskap;robots;industrial robotics;middleware;agriculture;computer software	Purpose – The purpose of this paper is to describe a generic software framework for development of agricultural and forestry robots. The primary goal is to provide generic high-level functionality and to encourage distributed and structured programming, thus leading to faster and simplified development of robots. A secondary goal is to investigate the value of several architecture views when describing different software aspects of a robotics system. Design/methodology/approach – The framework is constructed with a hybrid robot architecture, with a static state machine that implements a flow diagram describing each specific robot. Furthermore, generic modules for GUI, resource management, performance monitoring, and error handling are included. The framework is described with logical, development, process, and physical architecture views. Findings – The multiple architecture views provide complementary information that is valuable both during and after the design phase. The framework has been shown to be efficient and time saving when integrating work by several partners in several robotics projects. Although the framework is guided by the specific needs of harvesting agricultural robots, the result is believed to be of general value for development also of other types of robots. Originality/value – In this paper, the authors present a novel generic framework for development of agricultural and forestry robots. The robot architecture uses a state machine as replacement for the planner commonly found in other hybrid architectures. The framework is described with multiple architecture views.	control flow diagram;exception handling;finite-state machine;graphical user interface;high- and low-level;robot;robotics;software framework;structured programming;view model	Thomas Hellström;Ola Ringdahl	2013	Industrial Robot	10.1108/01439911311294228	software architecture;agriculture;simulation;computer science;systems engineering;engineering;software engineering;middleware;future of robotics	Robotics	-55.62208353243392	21.41389584946027	130131
076e954d1267fab973be5acc14461225bcb2aaed	refactoring object-oriented specifications with inheritance-based polymorphism	electronic mail;object oriented methods;formal specification;annealing;games annealing software engineering programming context educational institutions electronic mail;software engineering formal languages formal specification object oriented methods;object z;formal languages;software engineering;object oriented refactoring;object oriented;specification notations inheritance based polymorphism program code formal object oriented software development specification refactoring rules object z specification language jml spec;polymorphism;games;object z object oriented refactoring;programming;context	Specification notations such as JML and Spec# which are embedded into program code provide a promising approach to formal object-oriented software development. If the program code is refactored, however, the specifications need also to be changed. This can be facilitated by specification refactoring rules which allows such changes to be made systematically along with the changes to the code. A set of minimal and complete set of refactoring rules have been devised for the Object-Z specification language. This paper reviews these rules as a basis for a similar approach for languages like JML and Spec#. Specifically, it modifies the rules for introducing and removing inheritance and polymorphism from specifications. While these concepts are orthogonal in Object-Z, they are closely intertwined in the other notations.	code refactoring;definition;embedded system;invariant (computer science);java modeling language;metamodeling;object-z;software development;spec#;specification language;z notation	Graeme Smith;Steffen Helke	2011	2011 Fifth International Conference on Theoretical Aspects of Software Engineering	10.1109/TASE.2011.31	games;polymorphism;programming;formal language;annealing;computer science;software engineering;formal specification;database;programming language;object-oriented programming;code refactoring	SE	-53.22894270308161	32.269783948727486	130360
b5480b97502679422806b9b8d59210bdb05dd5e7	towards a reference framework for cots-based development: a proposal	cots based development;reference model;cots components	The literature about COTS-based development suffers from two main problems: there is no common terminology and it is not clear whether different techniques address the same issues and to which extend they overlap. In this paper we describe a reference model that sets the basis for a COTS-based development ontology and terminology. It should allow a systematic organization of published studies and an easier comparison of proposed approaches.		Xavier Franch;Marco Torchiano	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1082952	reliability engineering;reference model;computer science;systems engineering;software engineering;data mining	SE	-58.7288935862135	22.52063590080673	130384
721d2bc22860dde15476c1d25bdd3b1b35ed4746	open source software ecosystems: towards a modelling framework	conference report;modeling;software ecosystem;framework;open source software	Open source software ecosystem modelling has emerged as an important research area in software engineering. Several models have been proposed to identify and analyse the complex relationships in OSS-ecosystems. However, there is a lack of formal models, methodologies, tool support, and standard notations for OSS-ecosystems. In this paper we propose a general framework for support the OSS-ecosystems modelling process. This framework will allow the representation, synthesis, analysis, evaluation, and evolution of OSS-ecosystems. Design science methodology is proposed to create several artefacts and investigating the suitability of these artefacts in the OSS-ecosystem context.		Oscar Franco-Bedoya	2015		10.1007/978-3-319-17837-0_16	systems modeling;computer science;systems engineering;software design;social software engineering;software framework;software development;software design description;software analysis pattern;software engineering;software construction;data mining;programming language	SE	-53.62864741136652	25.596432478599976	130536
4b4b514e2d5e3f4df0337bd26ecd8d08396c0270	capturing data quality requirements for web applications by means of dq_webre	web engineering;requirements engineering;model driven web engineering;requirements modeling;data quality	The number of Web applications which are part of Business Intelligence (BI) applications has grown exponentially in recent years, as has their complexity. Consequently, the amount of data used by these applications has also increased. The larger the number of data used, the greater the chance to make errors is. That being the case, managing data with an acceptable level of quality is paramount to success in any organizational business process. In order to raise and maintain adequate levels of Data Quality (DQ), it is indispensable for Web applications to be able to satisfy specific DQ requirements. To do so, DQ requirements should be captured and introduced into the development process of the Web Application, together with the other software requirements needed in the applications. In the field of Web application development, however, there appears to us to exist a lack of proposals aimed at managing specific DQ software requirements. This paper considers the MDA (Model Driven Architecture) approach and, principally, the benefits provided by Model Driven Web Engineering (MDWE), putting forward a proposal for two artifacts. These consist of a metamodel and a UML profile for the management of Data Quality Software Requirements for Web Applications (DQ_WebRE).	data quality;requirement;web application	César Guerra-García;Ismael Caballero;Mario Piattini	2013	Information Systems Frontiers	10.1007/s10796-012-9401-x	requirements analysis;web modeling;data quality;business requirements;computer science;ws-policy;data mining;database;requirements engineering;web engineering;management;world wide web	SE	-58.24613613009304	21.325911773563945	130576
211c9fddc7bbacc34c361bec79443e89a98048f9	domain frameworks for ollaborative systems: lessons learned from engineering maintenance management	domain frameworks;architectural design;groupware;platformsfor collaboration;knowledge rich systems domain frameworks collaborative systems engineering maintenance management civil engineers civil infrastructure maintenance management;software systems;civil infrastructure maintenance management;experience report architecture design of collaborative systems collaboration enabling technologies platformsfor collaboration;maintenance engineering;collaborative system;architecture design of collaborative systems;experience report;civil engineering computing;lessons learned;collaborative systems;engineering maintenance management;knowledge rich systems;maintenance engineering civil engineering computing groupware;maintenance management;collaboration enabling technologies;civil engineers	The authors, working with civil engineers, have developed multiple software systems for different areas of civil infrastructure maintenance management. Over the last decade, those systems have evolved from stand-alone applications towards a loosely-coupled federation of collaborating systems. In this paper we outline the lessons learned from our experience with this evolution. Based on these lessons we present five general principles for constructing knowledge-rich systems that can collaborate with one another. These principles have two complementary themes: fostering emergence/evolution while capturing common structure. These themes form the basis of our approach to building loosely-coupled collaborative systems.	emergence;emergent evolution;experience;loose coupling;software system;user interface	Robert E. Reinke;Vincenzo D'Andrea;Arthur B. Baskin	2007	2007 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2007.4621780	maintenance engineering;knowledge management;management;collaborative software;software system;collaboration	SE	-61.5861876507942	21.441316261404875	130642
2aabcb225937160708c83e9428de982c26758c98	a meta-model to support the integration of dependability concerns into systems engineering processes: an example from power production	uml class diagram dependability markov chain phased mission system redundancy policy system engineering;redundancy;unified modeling language;power generation;redundancy unified modeling language context modeling power generation proposals;modeling;proposals;system dysfunctional dynamic behavior meta model dependability concerns systems engineering processes complex systems se processes power production systems phased mission systems multistate components repairable components power plant markov chains;unified modeling language markov processes power engineering computing power plants power systems systems engineering;context	Systems engineering (SE) is a very promising approach to facilitate the development of complex systems. This explains why several SE processes have been already proposed. However, these proposals focus mainly on systems with faultless components. Integration of dependability concerns into SE processes must be supported by a suitable organization of the data which are dealt with during the system life-cycle. A meta-model which defines the concepts used during this cycle as well as the relations between these concepts is a way to rigorously describe this organization. This article proposes such a meta-model developed for power production systems. These systems are phased mission systems composed of repairable and multi-state components; moreover, several redundancy policies shall be defined for each phase. This proposal is illustrated on a small example from a power plant. Last, the merit of this contribution to support the integration of dependability concerns is shown by proposing a method to build systematically, from the instance diagrams derived from the proposed meta-model, the Markov Chains which represent the dysfunctional dynamic behavior of a system.	automatic taxonomy construction;bitwise operation;complex systems;control system;correctness (computer science);critical system;dependability;full scale;markov chain;metamodeling;metaobject;object diagram;scalability;systems engineering	Pierre-Yves Piriou;Jean-Marc Faure;Gilles Deleuze	2016	IEEE Systems Journal	10.1109/JSYST.2014.2328663	reliability engineering;unified modeling language;electricity generation;real-time computing;systems modeling;system of systems;systems engineering;engineering;redundancy	SE	-58.22198205936687	24.56116980758954	130698
e2b94d499e3e4c85193416aa98ff3cf14e5eb816	extending model based systems engineering for human machine interaction analysis and fault tolerant design		Complex systems pose unprecedented challenges for system architects and engineers. In particular, they require multi-disciplinary approaches to manage system complexity from conception to verification and validation. Model Based System Engineering offers system architects and engineers a systematic framework to develop and use both descriptive and analytical models, to analyze and design systems. To meet human machine interaction and fault tolerance requirements, common semantics are needed to ensure effective and unambiguous communication among systems architects, safety/supportability engineers, and human factors engineers. This paper presents how MBSE can be extended for effective human-machine interaction and fault-tolerant design.	complex systems;control system;data validation;diagram;fault tolerance;formal verification;human factors and ergonomics;human–computer interaction;human–machine system;requirement;specialty engineering;system lifecycle;systems design;systems engineering;verification and validation	Douglas W. Orellana;Azad M. Madni	2012		10.2514/6.2012-2537	reliability engineering;systems engineering;engineering	SE	-61.322138910228745	19.33917885134705	130739
2e76940b30ad6823f93f3df798052cba83dda2e4	software reengineering for reusability	lifecycle phases software reengineering program migration reusability maintainability aging business systems strategic goals organization program re design;software platform;software maintenance;systems analysis software reusability software maintenance systems re engineering;systems analysis;software reusability;software reusability aging costs maintenance information systems computer science electronic mail companies computer interfaces databases;systems re engineering	Programs are ofen reengineered for better maintainability or in order to migrate programs into newer computerlsofhuare platforms. However, many of the aging business systems must be also upgraded in order to meet strategic goals of an organization. To meet such ambitious objectives, we must fundamentally redesign programs, rather than merely restructure them for improved maintainability. When much program re-design is involved, reengineering option becomes challenging at technical level, expensive and risky. To increase the value of a reengineering solution, we propose to address reusability issues in the context of reengineering. In this paper, we discuss lifecycle phases and outline a possible technical scenario for reengineering for reusability.	code refactoring	Stan Jarzabek	1993		10.1109/CMPSAC.1993.404221	reliability engineering;reusability;systems analysis;verification and validation;systems engineering;engineering;software development;software engineering;software maintenance;software system	SE	-62.09926644326057	23.097400044671183	130750
dc12b4b05ff35d5a7f1762b70d7c28b8b8f4a8b4	identifying classes via cognitive approach in object-oriented system	software;object oriented modeling software systems humans formal specifications conferences computational intelligence computer industry application software grid computing computer science;two step identification method;object recognition;linguistic method;construction industry;software systems;object oriented programming fuzzy set theory;object oriented programming;fuzzy set theory;object oriented systems;computational modeling;two step identification method object oriented system cognitive approach fuzzy set theory linguistic method;object oriented system;object oriented;cognitive approach;humans;object oriented modeling	One major problem in applying object-oriented (OO) methodologies is the difficulty of identifying classes for a system. Many tried to use fuzzy set theory to model the objected-oriented system and many proposed linguistic method to do the object analysis. However, little work has been done to identify the classes in OO systematically. After carefully analyzing the cognitive procedure of human being, this paper proposes a two-step identification method: First, tracing the source (the entities in a real world) of a given system. Second, identifying classes via viewpoints based on the source. The method could help people find the intrinsic information and extrinsic concepts epistemologically and employs an informal procedure to get the classes of an OO system easily.	entity;fuzzy set;set theory;view model	Zhibin Yu;Hai Jin	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.287	computer science;theoretical computer science;machine learning;programming language;object-oriented programming	AI	-55.52344351236402	30.119248341078904	130857
59860bcc2ca8bf47323577bf22dda20e7b671fa0	sustainability evaluation of software architectures: a systematic review	design principle;systematic review;life cycle;evaluation method;software systems;sustainability;software architecture;critical reflection;architecture evaluation;systematic literature review;literature review;cost efficiency;evolution scenario;survey;architectural metric;empirical research	Long-living software systems are sustainable if they can be cost-efficiently maintained and evolved over their entire life-cycle. The quality of software architectures determines sustainability to a large extent. Scenario-based software architecture evaluation methods can support sustainability analysis, but they are still reluctantly used in practice. They are also not integrated with architecture-level metrics when evaluating implemented systems, which limits their capabilities. Existing literature reviews for architecture evaluation focus on scenario-based methods, but do not provide a critical reflection of the applicability of such methods for sustainability evaluation. Our goal is to measure the sustainability of a software architecture both during early design using scenarios and during evolution using scenarios and metrics, which is highly relevant in practice. We thus provide a systematic literature review assessing scenario-based methods for sustainability support and categorize more than 40 architecture-level metrics according to several design principles. Our review identifies a need for further empirical research, for the integration of existing methods, and for the more efficient use of formal architectural models.	categorization;consistency model;software architecture;software system;systematic review	Heiko Koziolek	2011		10.1145/2000259.2000263	reliability engineering;systematic review;systems engineering;engineering;software engineering;management science	SE	-60.408199989517954	25.625005216117504	130912
4bd215e7dd61f305664b398a9e13e081c4a385cc	weaving in patterns into it infrastructure models: industry case and exemplary approaches	it infrastructure;software architecture	Architectural patterns are a helpful means for designing IT architectures, as they facilitate re-using proven knowledge (good practices) from previous exercises. Furthermore referencing a pattern in an architecture model helps improving the understandability of the model, as it directs to a comprehensive description of the pattern, but does not require to include the full description into the model. In this paper we describe how patterns can be woven into architecture models, focusing on deployment views of the IT infrastructure. Two different modeling approaches, Fundamental Modeling Concepts (FMC) and ArchiMate, are compared based on a real-world case concerning the infrastructure architecture of a large data center. This paper provides practical insights for IT architects from the industry by discussing the practical case and comparing both modeling approaches. Furthermore, it is supposed to intensify the exchange between industry experts and scientific researchers and it should motivate pursuing further research concerning patterns and IT infrastructure models.	archimate;architectural pattern;data center;flight management system;fundamental modeling concepts;microsoft outlook for mac;software deployment	Frank J. Frey;Roland Bijvank;Michael Pöttker	2015		10.1145/2855321.2855350	simulation;systems engineering;engineering;operations architecture;management science	Web+IR	-60.6526260634978	20.223051942329672	130934
ce3513669076ec8d3358ea4e76765560148362fb	standard-based strategy to assure the quality of the mobile software product	mobile;markets;standards;metrics;product;quality;iso 9126;process	The high relevance gained by mobile software applications, the large number of users, and the growing development competition, trigger a need for a method to measure and track the quality of mobile software products from a domain-specific, quantitative point of view. We pursue the implementation of a strategy to extend software quality standards to supply mechanisms to measure the quality of mobile software products, for developers to have a well-founded understanding of whether their applications meet the market's demands and user expectations	mobile app;relevance;software quality	Luis Corral	2012		10.1145/2384716.2384755	iso/iec 9126;product;verification and validation;team software process;software quality management;software engineering process group;computer science;package development process;software development;operating system;mobile technology;software deployment;software quality control;metrics;software quality;software metric;software quality analyst;process	SE	-61.811841666610995	26.92703418481383	131126
0c0315fe72a480f478f6acb1c5e63889ce245bb2	door-an approach for reusing and retrieving domain-oriented components	domain oriented component retrieval;kernel;object oriented programming software reusability software tools;door;application software;generic software architectures;object oriented programming;computer architecture;software architecture;interactive tool;software reusability;domain oriented component reuse;taxonomy;application software software architecture programming buildings supercapacitors kernel taxonomy computer architecture information analysis humans;generic software architectures door domain oriented component reuse domain oriented component retrieval system development domain analysis software architectures interactive tool;system development;software tools;humans;domain analysis;programming;information analysis;software architectures;buildings;supercapacitors	This paper describes an approach to system development based on domain analysis and software architectures. The approach combines developments for reuse and development with reuse together, and offers an integrated process which is supported by an interactive tool for modelling and retrieving reusable assets. Reusable objects are identified within narrow application scopes and relationships among them are modelled using generic software architectures.	domain analysis;software architecture	Adil Al-Yasiri;C. Bambord	1998		10.1109/EMWRTS.1998.685090	domain analysis;software architecture;programming;application software;kernel;computer science;door;supercapacitor;data analysis;object-oriented programming;taxonomy	SE	-52.23206268441824	27.711442861802016	131164
93d4a21c865c038cc94d501142603a6f5dfe8b6a	multimodal pattern-oriented software architecture for self-optimization and self-configuration in autonomic computing system using multi objective evolutionary algorithms	multi objective evolutionary algorithm;autonomic computing systems;uml class diagram;software architecture;system design;design pattern;pattern language;genetic algorithm;genetic algorithms;design patterns;service oriented architecture;autonomic computing	Current autonomic computing systems are ad hoc solutions that are designed and implemented from the scratch, and there are no universal standard (or well established) software methodologies to develop. There are also significant limitations to the way in which these systems are validated. When designing software, in most cases two or more patterns are to be composed to solve a bigger problem. A composite design patterns shows a synergy that makes the composition more than just the sum of its parts which leads to ready-made software architectures. As far as we know, there are no studies on composition of design patterns and pattern languages for autonomic computing domain.In this paper we propose multimodal pattern-oriented software architecture for self-optimization and self-configuration in autonomic computing system using design patterns composition, multi objective evolutionary algorithms, and service oriented architecture (SOA) that software designers and/or programmers can exploit to drive their work. We evaluate the effectiveness of our architecture with and without design patterns compositions. The use of composite design patterns in the architecture and quantitative measurements are presented. A simple UML class diagram is used to describe the architecture.	autonomic computing;class diagram;evolutionary algorithm;hoc (programming language);mathematical optimization;multimodal interaction;pattern language;programmer;service-oriented architecture;software architecture;software design pattern;software development process;synergy;unified modeling language	Vishnuvardhan Mannava;T. Ramesh	2012		10.1145/2345396.2345595	multilayered architecture;reference architecture;software architecture;space-based architecture;software design pattern;real-time computing;genetic algorithm;database-centric architecture;behavioral pattern;architectural pattern;computer science;systems engineering;applications architecture;software design;theoretical computer science;software design description;service-oriented modeling;software architecture description;distributed design patterns;resource-oriented architecture;structural pattern;systems architecture;autonomic computing;systems design	SE	-52.49740800660541	29.273886269700775	131165
1a45f60bc3d166783e068e76411066dbd78576e7	formal specification techniques as a catalyst in validation	air traffic control;formal specification;vienna development method;voice communication formal specification formal verification vienna development method air traffic control;air traffic control formal specification techniques complex systems validation textual requirement documents vienna development method voice communication;formal verification;formal specifications air traffic control natural languages dictionaries chemical processes chemical technology fault detection system testing communication system traffic control knowledge engineering;complex system;voice communication;functional requirement;chemical reaction	The American Heritage Dictionary defines a catalyst as a substance, usually present in small amounts relative to the reactants, that modifies and especially increases the rate of a chemical reaction without being consumed in the process. This article reports on the experience gained in an industrial project that formal specification techniques form such a catalyst in the validation of complex systems. These formal development methods improve the validation process significantly by generating precise questions about the system’s intended functionality very early and by uncovering ambiguities and faults in textual requirement documents. This project has been a cooperation between the IST and the company Frequentis. The Vienna Development Method (VDM) has been used for validating the functional requirements and the existing acceptance tests of a network node for voice communication in air traffic control. In addition to several detected requirement faults, the formal specification highlighted how additional test-cases could be derived systematically. Figure 1 gives an overview of the processes which were carried out. The shaded processes and documents were performed or created by the formal methods engineer using IFAD’s commercial VDMTools.	acceptance testing;complex systems;dictionary;document;formal methods;formal specification;functional requirement;shading;vienna development method	Bernhard K. Aichernig;Andreas Gerstinger;Robert Aster	2000		10.1109/HASE.2000.895462	reliability engineering;complex systems;real-time computing;formal methods;chemical reaction;vienna development method;formal verification;computer science;systems engineering;operating system;software engineering;air traffic control;formal specification;refinement;programming language;computer security;functional requirement	SE	-59.153830494701104	24.781673903813452	131438
a231345acb9e9fd5532be4b2c12eff9cbe437d5c	compliant business process design using refinement layers	business process design;business process	In recent years compliance has emerged as one of the big IT challenges enterprises are faced with. The management of a multitude of regulations and the complexity of current business processes are problems that need to be addressed. In this paper we present an approach based on so-called compliance templates to develop and manage compliant business processes involving different stakeholders. We introduce the concept of a refinement process. In the refinement process each compliance template is refined in a layered way to get an executable business process. The refinement steps are executed on refinement layers by different stakeholders. Compliance constraints are used to restrict the way a compliance template can be refined. Introduced in a certain refinement layer of the refinement process, compliance constraints are propagated to higher refinement layers.	business process;executable;refinement (computing)	Daniel Schleicher;Tobias Anstett;Frank Leymann;David Schumm	2010		10.1007/978-3-642-16934-2_11	systems engineering;engineering;artifact-centric business process model;operations management;business process model and notation;process management;business process discovery;engineering drawing;business process modeling	AI	-56.251878353689385	18.60461983201334	131460
0ada32ebec232df8567bf61af488941b6600822e	knowledge-based user interface migration	software portability;software maintenance;user interface;intelligent systems software design development software maintenance computer aided software engineering user interfaces;software portability knowledge engineering knowledge based systems software maintenance software tools user interfaces;graphic user interface;software tools;user interfaces;knowledge based systems knowledge based user interface migration systems reengineering text based system workstation graphical user interface software tools software techniques knowledge engineering reverse engineering;knowledge based systems;reverse engineering;knowledge base;knowledge engineering	A signifrcant problem in reengineering large systems is adapting the user interface to a new environment. Open, drastic changes in the user ititerface are inevitable, as in migrating a text-based system to a workstation with Graphical User Inretface capabilities. This experience report chronicles a study of user interface migration issues, examining and evaluaring current tools and techniques. I t also describes a case study undertaketi to explore the use of knowledge engineering to aid in migrating interfaces across pla#orms.	code refactoring;graphical user interface;knowledge engineering;text-based (computing);workstation	Melody Moore Jackson;Spencer Rugaber;Phil Seaver	1994		10.1109/ICSM.1994.336788	user interface design;look and feel;user;knowledge base;interactive systems engineering;software engineering process group;interface metaphor;software mining;human–computer interaction;computer science;systems engineering;software design;social software engineering;user requirements document;component-based software engineering;software development;operating system;monolithic application;knowledge engineering;software construction;interface control document;natural user interface;user interface;resource-oriented architecture;graphical user interface testing;software system;computer engineering	HCI	-49.88083665147725	29.12522694720122	131483
8553af5998f186f27bbc82b2ed20e3eba5814340	transform from models to service description based on mda	web service description language;system modeling;wsdl document;abstract model;web service;web services unified modeling language computer architecture programming protocols computer science arithmetic software engineering research and development code standards;unified modeling language;web services;system model;wsdl document web service description language model driven architecture system model abstract model web service application unified modeling language wsdl modeling process;web service application;web services unified modeling language;wsdl modeling process;model driven architecture	Within MDA framework, system models can be built up on an abstract level that is independent from the platform. Later on, this abstract model can be transmitted into service description, which is related to specific platform on the implementation level. In Web services applications, this transition has a great advantage. Because, while the model of implementation changes from one case to another to fit the different platforms, the model of whole system, on a higher abstract level, stays the same. Thus, the efficiency is promoted. This paper firstly discusses the extension of UML for Web services, and then it presents the modeling process of WSDL. Finally, it gives the rules and arithmetic of transition from models to WSDL documents in detail	diagram;mda framework;programming language;reversing: secrets of reverse engineering;unified modeling language;web services description language;web service	Bin Yu;Yang Zhao	2006	2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)	10.1109/APSCC.2006.110	web service;web application security;java api for xml-based rpc;web development;web modeling;business process execution language;data web;web standards;computer science;ws-policy;service-oriented architecture;database;programming language;ws-i basic profile;web 2.0;law;world wide web;devices profile for web services;universal description discovery and integration	SE	-49.163679701460296	26.195001423474928	131504
a72da963d7978f6f7a1026a5db2eba809f747717	subject-oriented modeling and execution of multi-agent business processes	subject oriented business process management s bpm;multi agent systems business process re engineering;multi agent systems agent based business process management subject oriented business process management s bpm;multi agent systems;business unified modeling language multi agent systems semantics software object oriented modeling electronic mail;business process re engineering;agent based business process management;subject oriented modeling meta model agent concurrent interaction agent autonomy process centric layer mas model s bpm subject oriented business process management conceptual modeling approach multiagent business process execution	This paper addresses a gap in handling multi-agent business processes that has prevented their larger-scale adoption in practice: the lack of a conceptual modeling approach that is easily understandable by business domain experts and sufficiently formal for direct transformation into executable systems. The emerging paradigm of subject-oriented business process management (S-BPM), which has been evaluated through academic research and is increasingly deployed in commercial applications, has the potential to augment multi-agent system (MAS) models with a process-centric layer that preserves autonomy and concurrent interaction of agents as essential system characteristics. In this paper we provide an aligned meta-model and illustrate its operational benefits with examples from business process applications.	business domain;business process;executable;metamodeling;multi-agent system;programming paradigm	Albert Fleischmann;Udo Kannengiesser;Werner Schmidt;Christian Stary	2013	2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)	10.1109/WI-IAT.2013.102	semantics of business vocabulary and business rules;business domain;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;function model;process modeling;business process model and notation;process management;business process;event-driven process chain;process mining;business process discovery;business rule;business process modeling;business activity monitoring;business architecture	AI	-55.17858540671005	18.745029806809068	131697
657ab50576e95dada330b9143a7307bc7713f971	discovering and understanding multi-dimensional correlations among certification requirements with application to risk assessment	security properties;information systems;certification;information security;application software;department of defense;government;risk management;software systems;natural languages;usa councils;certification risk management software systems information security application software government accreditation natural languages information systems usa councils;multi dimensional;accreditation;risk assessment	In this paper we outline our approach to discover and understand multi-dimensional correlations among regulatory security certification requirements in the context of a complex software system. A thorough understanding of these correlations is necessary to assure that diverse constraints imposed by numerous certification requirements are adequate for collectively contributing to emergent security properties in a highly interconnected socio-technical environment. We elaborate on methodological support to discover an exhaustive set of applicable certification requirements in a given operational scenario of the target software system. We then describe techniques to systematically understand the multi-dimensional correlations among these requirements with application to security risk assessment. The case study of applying our approach to a regulatory certification process of The United States Department of Defense (DoD) is presented.	emergence;requirement;risk assessment;sociotechnical system;software system	Robin A. Gandhi;Seok Won Lee	2007	15th IEEE International Requirements Engineering Conference (RE 2007)	10.1109/RE.2007.46	software security assurance;certified information security manager;risk assessment;certified information systems security professional;application software;global information assurance certification;economics;risk management;computer science;systems engineering;engineering;information security;software engineering;accreditation;certification;certification and accreditation;management;computer security;risk management framework;government	SE	-62.463625233929534	20.65130804933776	131710
7a55f09a965d4fbea5eb9e7f00b90bc7a36bdc04	perspectives on service-oriented computing and service-oriented system engineering	systems engineering and theory service oriented architecture reliability engineering application software conferences analytical models collaborative software collaborative work international collaboration manufacturing;system engineering;service orientation;software engineering;computer science education;research and development;service oriented computing;software development;service oriented system engineering;computing system;software engineering computer science education research and development;software development service oriented computing service oriented system engineering computing system	The service-oriented computing (SOC) paradigm leads the innovation of today's computing system and software development, and it can transform the human society into a new republic of all-to-all connected world. There are a number of interesting and innovative research challenges involved in achieving this vision of service-oriented system engineering (SOSE). This paper highlights some of these significant research opportunities and also the need for enhanced education in this emerging area	computer hardware;pervasive informatics;programming paradigm;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;singularity sky;software development;systems engineering	Wei-Tek Tsai;Miroslaw Malek;Yinong Chen;Farokh B. Bastani	2006	2006 Second IEEE International Symposium on Service-Oriented System Engineering (SOSE'06)	10.1109/SOSE.2006.24	personal software process;computing;software engineering process group;information engineering;computer science;systems engineering;engineering;social software engineering;component-based software engineering;software development;feature-oriented domain analysis;civil engineering software;software engineering;service-oriented architecture;software construction;software as a service;systems development life cycle;resource-oriented architecture;software development process;software requirements;software system;computer engineering	SE	-62.43620837296883	21.097919766843972	131735
adf8580183365f81777aa24ae55f16d36efe5c57	a semiotic approach to quality in specifications of software measures	software measurement;database design;software quality	Each software entity should have as high quality as possible in the context of limited resources. A specification of a software quality measure is a kind of software entity. Existing studies about the evaluation of software measures do not pay enough attention to the quality of specifications of measures. Semiotics has been used as a basis in order to evaluate the quality of different types of software entities. In this paper, we propose a multidimensional, semiotic quality framework of specifications of software quality measures. We apply this framework in order to evaluate the syntactic and semantic quality of two sets of specifications of database design measures. The evaluation shows that these specifications have some quality problems.	database design;display resolution;entity;metamodeling;object-relational database;relational database;sql;semiotics;software quality	Erki Eessaar	2008		10.1007/978-3-642-00670-8_6	personal software process;medical software;long-term support;verification and validation;software sizing;computer science;package development process;software design;social software engineering;software development;software design description;software engineering;software construction;database;software walkthrough;software measurement;software deployment;software quality control;database design;software quality;software quality analyst;software system;software peer review	SE	-59.35203762909953	28.207819958335502	131798
550664fdd37d02142f391d17ee3bc09c03293699	can the generation of test cases for unit testing be automated with rules		In this paper a proposal of a new black-box unit testing method based on decision tables is given. Its main part is an automatic generation of test cases using rule-based specification of a module. The tables containing rules are described in a formalized way using the XTT2 design method for rule-based systems. The paper also provides a presentation of a prototypical framework uses proposed method. This tool was designed as an Eclipse plugin which generates JUnit test cases. The proposed method can automate and improve the software testing process.		Grzegorz J. Nalepa;Krzysztof Kutt;Krzysztof Kaczor	2014		10.1007/978-3-319-07176-3_47	keyword-driven testing;white-box testing;manual testing;integration testing;test suite;dynamic testing;smoke testing	SE	-56.82524542134875	31.635092351083024	132069
699fa850a2e0c0bbf0bc9915bf3a433d68545719	pattern based methodology for uml profiles evolution management	evolutionary computation;pattern based methodology evolution pattern modeling language abstract syntax uml profile evolution management;unified modeling language adaptation models biological system modeling automotive engineering ports computers context standards;unified modeling language;unified modeling language evolutionary computation;evolution patterns uml profile evolution classification change analyze change operationalization	UML profiles are a frequently used alternative to describe the abstract syntax of modeling languages. As any abstract syntax, UML profiles evolve through time. As UML profiles are used for models definition, their evolutions may have a direct impact on them. The adaptation costs of these models may be as important as redefining a complete new model from scratch. In this paper, we deal with reducing the cost of models adaptation fitting the conducted evolution of the UML profiles. We want to offer a pattern-based solution to recurrent evolution problems. So, we specify evolution patterns in four aspects: the sequence of change operations needed to describe an evolution, the classification according to the evolution impact, a reusable solution for each category and, finally, the relations towards other evolution patterns. This paper is illustrated on standard UML profiles used in the automotive domain.	abstract syntax;definition;evolution;futures and promises;meta-object facility;metamodeling;papyrus;profile (uml);property (philosophy);prototype;semantics (computer science);software design pattern;unified modeling language	Fadoi Lakhal;Hubert Dubois;Dominique Rieu	2013	IEEE 7th International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2013.6577681	unified modeling language;simulation;systems modeling language;uml tool;computer science;systems engineering;artificial intelligence;applications of uml;class diagram;node;object constraint language;evolutionary computation	SE	-54.432603558479286	20.442117661163437	132262
36371d254354aa25c2ea9d8e9b80cb465636d99d	the evolution of the technological ecosystems: an architectural proposal to enhancing learning processes	technological ecosystem;elearning ecosystem;web services;architectural pattern;software open source	Currently, there exist very powerful Open Source software applications that cover most of the ICT needs of any institution, both for its operation and internal processes management. In this context, the technological effort of companies and institutions is not in the development of new software tools but to create their own technological ecosystem using available software components. This paper presents an architectural pattern to implement learning technological ecosystems with the ability to adapt to the changing requirements of the organizations.	architectural pattern;component-based software engineering;ecosystem;existential quantification;open-source software;requirement	Alicia García Holgado;Francisco J. García-Peñalvo	2013		10.1145/2536536.2536623	architectural pattern;systems engineering;engineering;knowledge management;environmental resource management	SE	-59.22032472812748	20.563890632163066	132381
353aa9d1631a15e7f45af65970767a79bfc3260f	towards a security requirements management framework for open-source software		Security refers to a class of non-functional requirements (NFRs) related to system confidentiality, integrity, and availability. It plays a critical role in many open source software (OSS) projects. Experience indicates that considering security early in the software life cycle can help address security problems, such as reducing information breach and unauthorized data access. However, unlike up-front requirements engineering (RE), requirements are fully discussed and become elaborated in OSS projects only after the implementation begins. Therefore, security management approaches which based on up-front RE shall be modified or improved while applied to OSS projects. To make OSS projects more secure, this research extends existing security requirements management approaches and proposes a new security management framework for OSS projects. I also describe obstacles for building our framework and formulate their conquering as research questions. Analysis and discussion of research questions will enable me to gain valuable insights, which I will use to improve the proposed framework.	authorization;confidentiality;data access;functional requirement;non-functional requirement;open sound system;open-source software;requirements engineering;requirements management;security management;software release life cycle	Wentao Wang	2018	2018 IEEE 26th International Requirements Engineering Conference (RE)	10.1109/RE.2018.00065	systems engineering;management science;unified modeling language;software development process;requirements management;software;requirements engineering;data access;security management;computer science	SE	-58.16387987236052	21.803477174613406	132546
50abd2015fa6fe30b6cb1bda539b4280a34fd50b	an object-oriented methodology for analyzing, designing, and prototyping office procedures	office procedures;object oriented methods;formal specification;executable code;organizational effectiveness;software prototyping;object models;specification;formal specification object oriented methods software prototyping office automation commerce;system designers;procedural modeling;commerce;object oriented methodology;domain experts object oriented methodology office procedures object models organizational effectiveness specification frame based object definition language executable code enterprise wide repository design environment system designers;frame based object definition language;object oriented;design environment;system design;business data processing;domain experts;software requirements and specifications;enterprise wide repository;office automation;object oriented methods office automation business data processing software requirements and specifications;object model	The paper presents a methodology for designing office procedure models in interaction with object models. The proposed models of office procedures are conceptualized in a way that helps to analyze the organizational effectiveness of procedures. Furthermore the methodology supports identification, specification, and refinement of classes in the object model. Integration is accomplished by establishing references from the office procedure models to the object model and by specifying the management of a procedure within classes of the object model. The specification can be partially transformed into a frame-based object definition language which in turn can be compiled into execut-able code. The models are thought to be located within an enterprise-wide repository. The methodology is supported by a design environment that provides various levels of abstraction not only for system designers but also for domain experts.	compiler;principle of abstraction;refinement (computing)	Ulrich Frank	1994		10.1109/HICSS.1994.323453	method;object model;computer science;software engineering;organizational effectiveness;formal specification;database;programming language;object-oriented programming;executable;procedural modeling;specification;systems design	SE	-50.75903633518411	23.507285889238233	132624
e439dc05a42543250dfa12c7edea5472f0323dcf	the cri-model: a domain-independent taxonomy for non-conformance between observed and specified behaviour		Anomaly detection is the process of identifying nonconforming behaviour. Many approaches from machine learning to statistical methods exist to detect behaviour that deviate from its norm. These non-conformances of specifications can stem from failures in the system or undocumented changes of the system during its evolution. However, no generic solutions exist for classifying and identifying these non-conformances. In this paper, we present the CRI-Model (Cause, Reaction, Impact), which is a taxonomy based on a study of anomaly types in the literature, an analysis of system outages in major cloud companies and evolution scenarios which describe and implement changes in Cyber-Physical Production Systems. The goal of the taxonomy is to be usable for different objectives like discover gaps in the detection process, determine components most often affected by a particular anomaly type or describe system evolution. While the dimensions of the taxonomy are fixed, the categories can be adapted to different domains. We show and validate the applicability of the taxonomy to distributed cloud systems using a large data set of anomaly reports and cyber-physical production systems by categorizing common changes of an evolution benchmarking plant.	anomaly detection;categorization;conformance testing;data store;database;distributed computing;documentation;downtime;extensibility;machine learning;map;model-based specification;production system (computer science);software bug;software evolution;taxonomy (general);undocumented feature;vocabulary	Christopher Haubeck;Alexander Pokahr;Kim Reichert;Till Hohenberger;Winfried Lamersdorf	2018	Comput. Sci. Inf. Syst.		taxonomy (biology);artificial intelligence;machine learning;data mining;computer science	SE	-58.872978446862085	22.228660033697953	132630
79e0bc50fe25b3f4f81c7247ae89c28ac4971ccb	a natural, tiered and executable uidl for 3d user interfaces based on concept-oriented design	3d user interface;design and development;non wimp interfaces;interaction techniques;concept oriented design;user interface description language;software development;chasm;natural programming;3dui;uims;uidl;interaction technique	3D User Interface (3DUI) design and development requires practitioners (designers and developers) to represent their ideas in representations designed for machine execution rather than natural representations, hampering development of effective 3DUIs. As such, Concept-Oriented Design (COD) was created as a theory of software development for both natural and executable design and development. Instantiated in the toolkit Chasm, Chasm is a natural, tiered, executable User Interface Description Language (UIDL) for 3DUIs resulting in improved understandability, as well as reduced complexity and reuse. Chasm's utility is shown through evaluations by domain experts, case studies of long-term use, and an analysis of spaces.	3d user interaction;executable;interface description language;software development;theory;user interface	Chadwick A. Wingrave;Joseph J. LaViola;Doug A. Bowman	2009	ACM Trans. Comput.-Hum. Interact.	10.1145/1614390.1614396	user interface design;natural language programming;human–computer interaction;computer science;software development;natural user interface;programming language;interaction technique	HCI	-48.563069268283904	23.762967948266624	132710
b16d48962e60057877e5c6436da578292d079543	specifying and analysing static and dynamic patterns of administrative processes	quality assurance;activity diagram;structural model;analysis pattern;software development;group decision	In the last decade, patterns have proved their effectiveness for the reuse of software development artifacts from early as well as late phases of the process. This paper proposes analysis patterns based on accurate and thorough observations of administrative processes such as organizing meetings, making group decisions, hiring of personnel, etc. The patterns proposed in this work are characterized by coming equipped with a basic workflow, captured in the form of an UML activity diagram, aside of providing an object structure modeled as UML static structure diagram. Besides serving as analysis models for subsequent software development, the primary intent behind administrative patterns is to visualize and to standardize frequently reoccurring processes and thus to support quality assurance and control. Furthermore, administrative patterns lay the basis for various ways of evaluating the underlying processes in order to improve them.	activity diagram;class diagram;european conference on information systems;organizing (structure);partial template specialization;process patterns;software design pattern;software development;unified modeling language	Renate Motschnig;Philipp Randa;Günther Vinek	2002			quality assurance;activity diagram;computer science;knowledge management;software development;data mining;database;world wide web	SE	-55.3435488293737	23.247964875294908	132814
0686d98c04417b934cd4327afa74391b507cfdeb	a built-in test language for prolog to validate knowledge-based systems	knowledge based system;object oriented;built in test;knowledge base;expert system	This paper refines and completes the results of our previous work represented in /3/. Our present work concentrates on the implementation of a uniform, white-box test environment PROTest (PROLOG Test Environment). PROTest supports the development of object-oriented, rule and knowledge-based expert systems which will be implemented in PROLOG. PROTest assists the programmer - as well as the quality engineer - in particular to generate test cases, to exercise his or her programs by means of these test cases, to produce test reports after the test execution etc (Testing in the Large). The special feature of PROTest as a novelty in the field stems from its built-in object-oriented logic test language (TL) which is being used. The major benefit of this approach is given through the high adaptability potential of the test procedures whenever the functional part of the programs has been changed.	deployment environment;expert system;knowledge-based systems;programmer;prolog;test case;transform, clipping, and lighting;white-box testing	Fevzi Belli;Ismael Camara;Alfred Schmidt	1990		10.1145/98894.98922	knowledge base;simulation;computer science;artificial intelligence;machine learning;test suite;object-oriented programming;test case;expert system;test management approach;algorithm;test harness	SE	-54.82794314757425	32.127340878305176	132827
227377d5b123f15a8e116ffc2a3f61de71a0f542	reuse in object-oriented information systems	object-oriented information systems	An approach for supporting reuse in object-oriented Information System conceptual design is presented, Reusable components are introduced as generic object classes with associated guidelines providing suggestions for their adaptation and tailoring in given contexts. Reusable components are derived from the analysis of similar object classes. Affinity criteria to classify object classes are presented, based on structural and contextual properties.	information system	Silvana Castano;Valeria De Antonellis	1994		10.1007/BFb0014035	information engineering	PL	-52.09366863872835	23.343476439978424	132958
705677f6a1b414a3d797bf5476ac0e81f2fbec0c	quantitative functional complexity analysis of commercial software systems	software systems;complexity analysis	Nacreous pigment exhibiting interference colors and a high degree of opacity, composed of a metal oxide, such as titanium dioxide, in particulate form on mica substrate, at least part of the mica substrate being calcined; and a process of preparing the pigment.	analysis of algorithms;commercial software;software system	Stephen G. MacDonell	1992			domain analysis;verification and validation;software sizing;system of systems;search-based software engineering;software reliability testing;software development;software construction;systems development life cycle;software deployment;software metric	SE	-62.41727712817289	25.0893147078121	133095
658093b5261c4e8ef8fbe6d87a2b33a2a6cc169f	goals and scenarios based web requirements engineering			requirements engineering	Shailey Chawla;Sangeeta Srivastava;Punam Bedi	2016	Comput. Syst. Sci. Eng.		web modeling;systems engineering;database;requirements engineering;goal modeling;computer science	DB	-57.524215707825384	20.864633662023355	133111
67d7343c545f11cd20a8dee331ce3603105e8320	domain-specific design of patient classification in cancer-related cachexia research		We apply an IDE for user-level process design and composition to a real-life case study: a complex workflow from an ongoing global cancer-related cachexia research project. Originally buried in a manually operated spreadsheet, the process is now fully automated and integrated into the project database, ensuring the immediate availability, consistency and reproducibility of the outcomes. Our integrated solution enables the scientists to immediately execute the processes and easily customize both processes and data model to continuously changing experimental setups. The data modeling is provided by the Dynamic Web Application framework and the process modeling functionalities by the Java Application Building Center, both following the paradigm of eXtreme Model-Driven Design for model-driven software development.	application framework;data model;data modeling;java;model-driven architecture;model-driven engineering;model-driven integration;process (computing);process modeling;programming paradigm;real life;software development;spreadsheet;user space;web application;web framework	Alexander Wickert;Anna-Lena Lamprecht;Tiziana Margaria	2018	2018 IEEE/ACM 6th International FME Workshop on Formal Methods in Software Engineering (FormaliSE)	10.1145/3193992.3194002	domain-specific modeling;real-time computing;process design;data model;systems engineering;software development;data modeling;computer science;workflow;process modeling;java	SE	-50.80560933676101	24.4995296253449	133205
e9c7f69c5214cc95763f9d918933326354b4fc44	a model-based software development kit for the sensorcloud platform		The development of software for the cloud is complicated by a tight entanglement of business logic and complex non-functional requirements. In search of a solution, we argue for the application of model-based software engineering to a particular class of cloud software, namely interactive cloud software systems. In particular, we outline an architecture-driven, model-based method that facilitates an agile, top-down development approach. At its core it employs a software architecture model that is augmented with additional aspect-specific models. These models serve as concise, formal, first-class specification documents and, thus, as foundation for tool-supported analysis and synthesis, in particular, code generation. We hypothesize that many crucial cloud-specific non-functional requirements can be satisfactory addressed on the architecture level such that their realization in the system can be synthesized by tools with small impact on the business logic.	agile software development;business logic;cloud computing;code generation (compiler);functional requirement;non-functional requirement;quantum entanglement;s60 (software platform);software architecture;software development kit;software engineering;software system;top-down and bottom-up design	Lars Hermerschmidt;Antonio Navarro Pérez;Bernhard Rumpe	2014		10.1007/978-3-319-12718-7_8	computer engineering;architecture;software system;business logic;software;cloud computing;software development;agile software development;software architecture;distributed computing;computer science	SE	-52.821786854362024	26.258663694430336	133285
1b5eef83c3b8c2913ab2e3b4cf58fa4b0e6a0ebd	a framework for software product engineering	software engineering;acoustical engineering software engineering continuous improvement process design product design engineering drawings software systems design engineering programming mathematical model;production process;continuous improvement;software development;mathematical model;theoretical foundation;knowledge domain software product engineering process maturity process engineering software development	Software engineering today is heavily focused on the ideas of process maturity and continuous improvement. Processes are designed to deliver products. Process engineering should ideally rest on theoretical foundations of sound product engineering; however the field is currently lacking such foundations. Drawing inspiration from compiler design, we present a systematic framework for software product engineering that develops the product through successive levels of realization. The framework separates the concerns in software development by relating each level to a knowledge domain and localizing exactly on those qualities that become manifest in that knowledge domain. The basis of the framework is a mathematical model for reasoning about the correctness of realization schemes as well as the transformations between levels, so that each level preserves previously created qualities while adding new desired qualities. We also discuss some of the practical aspects of implementing this approach.	capability maturity model;compiler;correctness (computer science);mathematical model;product engineering;software development process;software engineering;software inspection;software testing	Kesav V. Nori;N. Swaminathan	2006	2006 13th Asia Pacific Software Engineering Conference (APSEC'06)	10.1109/APSEC.2006.5	domain analysis;personal software process;verification and validation;software engineering process group;leancmmi;search-based software engineering;computer science;systems engineering;engineering;software design;social software engineering;component-based software engineering;software development;requirement;feature-oriented domain analysis;software engineering;domain engineering;software construction;mathematical model;scheduling;software measurement;software development process;software requirements;product engineering;mechanical engineering	SE	-58.60218323691373	26.118932959894394	133397
17b1addb04fe002e7f18df15185187cc8f72827f	getting back to basics: promoting the use of a traceability information model in practice	analytical models;software;unified modeling language project management software tools;customized project specific traceability information models;information model;project management;uml based representation;certification;software development project;probability density function;prototypes;uml based representation customized project specific traceability information models software development project software development artifacts software development tools;software systems;data mining;software development artifacts;software development;unified modeling language;industrial relations;software development tools;software tools;programming context modeling prototypes tagging unified modeling language software systems computer science industrial relations buildings certification;computer science;context modeling;programming;object oriented modeling;buildings;modeling tool;tagging	It is widely assumed that following a process is a good thing if you want to achieve and exploit the benefits of traceability on a software development project. A core component of any such process is the definition and use of a traceability information model. Such models provide guidance as to those software development artifacts to collect and those relations to establish, and are designed to ultimately support required project analyses. However, traceability still tends to be undertaken in rather ad hoc ways in industry, with unpredictable results. We contend that one reason for this situation is that current software development tools provide little support to practitioners for building and using customized project-specific traceability information models, without which even the simplest of processes are problematic to implement and gain the anticipated benefits from. In this paper, we highlight the typical decisions involved in creating a basic traceability information model, suggest a simple UML-based representation for its definition, and illustrate its central role in the context of a modeling tool. The intent of this paper is to re-focus attention on very practical ways to apply traceability information models in practice so as to encourage wider adoption.	baseline (configuration management);hoc (programming language);information model;iteration;programming tool;software development;traceability;unified modeling language	Patrick Mäder;Olly Gotel;Ilka Philippow	2009	2009 ICSE Workshop on Traceability in Emerging Forms of Software Engineering	10.1109/TEFSE.2009.5069578	computer science;systems engineering;software engineering;data mining;requirements traceability	SE	-54.071745920032065	24.351010060176513	133448
71177a1bf2dfbc3812ea52c7a9ed50b525bbf10b	derivation of local software quality metrics (software quality circles)	software;local metrics;metric;quality;controle qualite;metrico;fiabilite logiciel;fiabilidad logicial;quality control;circle;software reliability;software quality;metrique;control calidad	Abstract#R##N##R##N#Software is a product in serious need of quality control technology. Major effort notwithstanding, software engineering has produced few metrics for aspects of software quality that have the potential of being universally applicable. The present paper suggests that, although universal metrics are elusive, metrics that are applicable and useful in a fully defined setting are readily available. A theory is presented that a well-defined software work group can articulate their operational concept of quality and derive useful metrics for that concept and their environment.		Jesse H. Poore	1988	Softw., Pract. Exper.	10.1002/spe.4380181102	reliability engineering;verification and validation;software sizing;computer science;systems engineering;software quality control;engineering drawing;software quality;software metric;software quality analyst	SE	-61.73988778170509	28.4069671491804	133639
1667de9b43913fc1b9a3654e966908ba44db175d	potentials and challenges of recommendation systems for software development	software testing;error correcting graph matching ecgm algorithm;context aware;random walks;recommender system;software evolution;software development;knowledge sharing	"""By surveying recommendation systems in software development, we found that existing approaches have been focusing on """"you might like what similar developers like"""" scenarios. However structured artifacts and semantically well-defined development activities bear large potentials for further recommendation scenarios. We introduce a novel """"landscape"""" of software development recommendation systems and line out several scenarios for knowledge sharing and collaboration. Basic challenges are improving context-awareness and particularly addressing information providers."""	context awareness;line level;recommender system;software development	Hans-Jörg Happel;Walid Maalej	2008		10.1145/1454247.1454251	computer science;knowledge management;software design;software development;iterative and incremental development;software construction;data mining;software walkthrough;software analytics;resource-oriented architecture;software deployment;world wide web;goal-driven software development process;software development process;software system	SE	-60.78943803291004	22.964866894697966	133657
881044958867ac565aeb28bcd25201434a31a92e	a unified model of optimisation problems	conceptual software model;unified model;optimisation problems	In this work, a conceptual software model of optimisation problems is developed. Problem-specific aspects are clearly identified as such. To achieve the desired separation between problems and solvers, the details of the problem are encapsulated, and \emph{mechanisms} capable of supporting the optimisation process are provided in a problem-independent way, allowing optimisers to be formulated at a more abstract level. The proposed model has been prototyped in Python.	mathematical optimization;python;unified model	Cristina C. Vieira;Carlos M. Fonseca	2007		10.1145/1276958.1277266	simulation;computer science;unified model;management science	Robotics	-54.18342798774484	30.20460134124648	133848
a7102a12901c7a4c6713a841fa826e32b99b0e40	quality-oriented product line modeling using feature diagrams and preference logic		Current domain analysis methods for product line engineering usually focus on the implementation of functional requirements for product lines while neglecting the quality aspects. However, in modern software system development the non-functional requirements, such as dependability, maintainability and, especially, quality, have become more important. Furthermore, quality is one of essentials dimensions of variability and there are complex direct and indirect relationships between functional and quality features of systems. The aim of this paper is to extend feature modeling for modeling software quality using elements of preference logic to aid the designer in the decision making process when selecting alternative (optional) features from a feature diagram. Preference logic is used to compactly represent and reason about preference relations between features and quality aspects in integrated feature-quality models represented using extended feature diagrams.	diagram	Paulius Paskevicius;Robertas Damaševičius;Vytautas Stuikys	2012		10.1007/978-3-642-33308-8_20	reliability engineering;computer science;systems engineering;engineering drawing;feature model	EDA	-56.079071974296966	25.20096642327261	133868
d6fd2592794267763287ad2bc9ce2502cb76d6d0	integrated generation of specification- and program-based test cases			test case	Sami Beydeda	2004			test case;test suite;reliability engineering;computer science	SE	-56.98698215178898	31.949275560371063	134300
88b7aecdc09aebe5099e490ff43ae40336371dcb	software performance engineering: a case study including performance comparison with design alternatives	software reliability quality control real time systems software quality;prediccion;software performance design engineering computer aided software engineering application software performance analysis maintenance engineering programming delay design methodology real time systems;metodologia;reusability;ada;understandability;analisis cuantitativo;real time;performance;real time properties;performance objectives;object oriented software;performance comparison;conception;estrategia;ingenieria logiciel;indexing terms;software engineering;design quality;methodologie;analyse;software performance;strategy;software performance engineering;reusability software performance engineering performance objectives real time properties design alternatives spe performance requirements understandability maintainability;design alternatives;design method;analyse quantitative;almacenamiento;spe;stockage;diseno;genie logiciel;quantitative analysis;design;analysis;rendimiento;methodology;ada language;quality control;performance requirements;software reliability;strategie;prediction;storage;software quality;maintainability;real time systems;analisis	Software performance engineering (SPE) provides an approach to constructing systems to meet performance objectives. The authors illustrate the application of SPE to an example with some real-time properties and demonstrate how to compare performance characteristics of design alternatives. They show how SPE can be integrated with design methods and demonstrate that performance requirements can be achieved without sacrificing other desirable design qualities such as understandability, maintainability, and reusability. >	performance engineering;software performance testing	Connie U. Smith;Lloyd G. Williams	1993	IEEE Trans. Software Eng.	10.1109/32.238572	reliability engineering;performance engineering;computer science;systems engineering;engineering;operating system;software engineering;analysis;software quality	SE	-61.38286854274829	28.861233167154385	134330
026dcc5f4b64a8355ce87a2ac27c7bd9e2a88174	domain analysis for supporting commercial off-the-shelf components selection	domain model;modelizacion;markets;mercado;reutilizacion;conceptual analysis;software systems;sistema complejo;analisis conceptual;reuse;modelisation;commercial off the shelf;systeme complexe;complex system;marche;software package;domain analysis;progiciel;information system;analyse conceptuelle;market segmentation;modeling;paquete programa;qualite logiciel;systeme information;software quality;reutilisation;sistema informacion	Though new technological trends and paradigms arise for developing complex software systems, systematic reuse continues to be an elusive goal. As a consequence, the need for designing effective strategies for enabling largescale reuse, whilst overcoming the risks involved in the use of a particular technology, still remains. In this context, the adoption of the Commercial OffThe-Shelf (COTS) technology introduces many challenges that still have not been fully overcome, such as the lack of comprehensive mechanisms to record and manage the required information for supporting COTS components selection. In this paper we present a domain analysis strategy for gathering the information needed to describe COTS market segments in a way that COTS components selection becomes more effective and efficient. Due to the diversity of the information to capture, we propose different dimensions of interest for COTS selection that are covered by different domain models. These models are articulated by means of a single framework based on a widespread software quality standard.	code reuse;domain analysis;domain model;software quality;software system;while	Claudia P. Ayala;Xavier Franch	2006		10.1007/11901181_27	domain analysis;complex systems;simulation;systems modeling;software engineering;domain model;reuse;information system;software quality;market segmentation;software system	SE	-61.106163454679695	28.362084529855224	134392
d41c2cebe0cba1650a4dbe8defa00d377624bdab	multi-level tests for model driven web applications	inf;model transformation;levels of abstraction;software development;model driven engineering;multiple model	"""Model Driven Engineering (MDE) advocates the use of models and transformations to support all the tasks of software development, from analysis to testing and maintenance. Modern MDE methodologies employ multiple models, to represent the different perspectives of the system at a progressive level of abstraction. In these situations, MDE frameworks need to work on a set of interdependent models and tranformations, which may evolve over time. This paper presents a model transformation framework capable of aligning two streams of transformations: the forward engineering stream that goes from the Computation IndependentModel to the running code, and the testing stream that goes from the Computation Independent Test specification to an executable test script. The """"vertical"""" transformations composing the two streams are kept aligned, by means of """"horizontal"""" mappings that can be applied after a change in the modeling framework (e.g., an update in the PIM-to-code transformation due to a change in the target deployment technology). The proposed framework has been implemented and is under evaluation in a real-world MDE tool."""	web application	Piero Fraternali;Massimo Tisi	2010		10.1007/978-3-642-13911-6_11	model-driven architecture;real-time computing;simulation;computer science;theoretical computer science;software development;software engineering	Web+IR	-53.15922722299287	25.320786118496933	134393
ee22a4bf30ba2bdc31a2ea4683a9bcdda36c0737	dsias: a software architectural style for distributed software integration systems	distributed software integration architectural style;distributed graphical parking lot management system;software systems software design software architecture topology guidelines middleware design engineering electronic mail internet software engineering;topology;structure topology;electronic mail;management system;software integration;design engineering;commercial off the shelf products;distributed software integration architectural style dsias;distributed processing;software systems;corba;software engineering;cots based system cbs;software architecture;commercial off the shelf;internet;guidelines;distributed object management;distributed graphical parking lot management system distributed software integration architectural style corba software architecture commercial off the shelf products structure topology;middleware;distributed processing software architecture distributed object management;software design;software reuse;architectural style	In this paper, we proposed a Distributed Software Integration Architectural Style (DSIAS) to provide a blueprint and reference document. that would be useful to software system designers when integrating commercial off-the-shelf (COTS) products under distributed and Internet environment. DSIAS provides a framework indicating the structure topology to put lots of originally unrelated COTS products together into a COTS based system (CBS). We then successfully applied DSIAS to the design of an example, a Distributed Graphical Parking Lot Management System (DGPLMS).	blueprint;graphical user interface;internet;management system;reference work;software architectural style;software system;system integration	Zeng-Wei Hong;Jim-Min Lin;De-Sheng Chen;Hewijin Christine Jiau	2001		10.1109/CMPSAC.2001.960629	software architecture;real-time computing;the internet;architectural pattern;computer science;systems engineering;software design;operating system;software engineering;common object request broker architecture;middleware;management system;database;distributed design patterns;software system;system integration	SE	-50.73220545322205	19.206246913776308	134651
00891eafb33f07394a817110fd3079198059d5d2	experience with traits in the xerox star workstation	software;workstations software design application software software systems joining processes software engineering printers postal services graphics;reusability;printers;application software;user interface;color;probability density function;traits human interface multiple inheritance object orientation reusability software engineering subclassing;software systems;systeme integre;data mining;software engineering;systeme star xerox;human interface;postal services;object oriented;image color analysis;subclassing;workstations;multiple inheritance;joining processes;genie logiciel;object orientation;interface utilisateur;reutilisabilite;software design;traits;integrated system;office automation;bureautique;graphics	The Xerox Star (8010) is an integrated office workstation. Its software is written in an object-oriented style. Often, different applications will impose slightly different requirements on nominally similar objects which they use. Customization of object definitions for different applications is achieved by attaching modifiers called traits to pre-existing object defintions. This paper describes the approach and recounts our experience with traits.	access modifiers;requirement;workstation;xerox star	Gael A. Curry;Robert M. Ayers	1984	IEEE Transactions on Software Engineering	10.1109/TSE.1984.5010276	multiple inheritance;reusability;probability density function;application software;workstation;computer science;engineering;graphics;software design;operating system;software engineering;programming language;object-oriented programming;user interface;object-orientation;engineering drawing;human interface device;software system;computer engineering	SE	-49.03752504662995	28.528864044421994	134792
e0dea883905ca7344ec4493c907f9a85b0b6dffa	model-driven development: assets and reuse	information technology;model driven development;time to market	ions in code as well as in models are used to hide detail, but by doing so, one may not be able to understand what the code does or what the model means. The question to ask is, ‘‘At what point in my modeling do I make heavy use of abstraction and at what point do I make light use of it?’’ Part of the answer lies in the intended use of the model. When a model is intended to reach an audience that is making decisions which are not based upon the fine details of the model, then the heavy use of abstraction is justified. If the model is intended to communicate the essence of the solution and guide the user through the details, then less abstraction is justified. For instance, to whom is it valuable to reverse engineer some Java classes into a UML class diagram? The answer depends on what is being captured in the model and who expects to use it. If the essence of the class structure and relationships is communicated visually and if the intent is to communicate to software engineers and architects the static nature of the class design so that they can conduct impact analysis and review the overall software design, then this is likely to be a proper abstraction. However, one would never show this to a business analyst seeking an IT solution to a business problem. One of the challenges we face is increasing complexity. Abstraction in models is a powerful means to rise above complexity, but it must be used in a manner appropriate to a specific audience. Properly organized models reduce the effort to understand the abstractions they communicate. Consumability: Model organization and metadata Consumability is the ease of use by which a model can be approached, its organization understood, and a determination made concerning how to apply it to one’s needs. To be consumable, both a model’s structure and its diagrams should be well organized, and it should be packaged with metadata that further describe its intent and intended reuse context. Time to market: Finding the model, getting at the value Value is created by discovering and understanding the right model for the relevant context in a timely manner to achieve productivity improvements. For this to happen, a model must be organized, packaged, and shared as an asset with minimal effort. The focus now shifts to examining how to organize models as reusable assets and the impact that can have on models and their users. ORGANIZING MODELS TO BE REUSED The structure of our model is shown in Figure 3. It is organized with two top-level elements: a documentation folder and the model file itself, p4eb_patterns.emx. A document that discusses the modeling conventions to which the model adheres should be included in the documentation folder to aid in the reuse of the model. It can be seen that we use a UML package called zAssocations. In it, we place the associations exposed by the RSA Model IBM SYSTEMS JOURNAL, VOL 45, NO 3, 2006 LARSEN 547 Explorer view to make navigating the Model Explorer easier. Under the 2 Business Patterns package is another set of packages that follow the major categorization of the P4eb patterns: Collaboration, Extended Enterprise, Information Aggregation, and Self Service. This structure is used throughout the model in each of the major pattern packages: Business Pattern package, under which are Application Pattern packages, under which are Runtime Pattern packages. We chose this structure to focus the user on the relevant subset of patterns, thereby reinforcing previous decisions and not overwhelming the user with all possible patterns from which to choose. One of the first questions to ask is, ‘‘With whom do we intend to share this candidate asset?’’ It is very important to understand the anticipated skill level of the target consumer. The answer for our example model is that it is intended to be shared with architects. The next question is, ‘‘How do we expect the architects to approach the problem of determining which pattern to use in the model?’’ The following are the assumptions we made about the use of this model: 1. We assume that architects will be fairly new to these patterns; as such, we expect they will first review high-level information about the patterns to become familiar with them. Hence, some documentation or pointers to the P4eb site should be included. 2. Next, we assume that architects will determine the nature of the business problem to be solved, evaluate the business patterns, and select the relevant one. From there, the constituent application and runtime patterns will be selected. 3. Finally, we assume architects will use the runtime pattern models as a template to refine for their environment and to map products that will be used. Understanding the cascading structure of this set of patterns is important because once a business pattern is chosen, we immediately ignore a whole set of other application and runtime patterns that are not relevant. Thus, this is a guide on how to organize the model. Right now our model is organized according to the preceding categories, but our objective is to align the model closer to the reuse boundaries. Thus, we adjust the model organization with the following packages: Overview of patterns	align (company);categorization;class diagram;complexity;consumability;documentation;extended enterprise;high- and low-level;ibm research;java;model-driven engineering;reverse engineering;software design;software engineer;unified modeling language;usability	Grant Larsen	2006	IBM Systems Journal	10.1147/sj.453.0541	computer science;systems engineering;engineering;database;management science;management;law;information technology	Web+IR	-53.13295731468594	21.134123511403036	134843
f13c2c6d4bef0d5a38c6445c731685c99ae295f2	business component identification - a formal approach	fabrication;formal approach;cluster algorithm;business components;pattern clustering;formal specification;clustering algorithm;application software;insurance data processing;analysis level object model;compmaker;auto insurance claims domain;object oriented programming;application software assembly fabrication buildings object oriented modeling clustering algorithms process design costs software reusability insurance;process design;car insurance business component identification formal approach component based software development component building application assembly business components analysis level object model business domain clustering algorithm predefined rule heuristics compmaker auto insurance claims domain;assembly;business component identification;business domain;business data processing;car insurance;software reusability;predefined rule;clustering algorithms;application assembly;formal specification object oriented programming business data processing pattern clustering java insurance data processing;component based software development;heuristics;object oriented modeling;buildings;insurance;component building;object model;java	Component Based Software Development is carried out in two phases: Component Building and Application Assembly. The key to building business components is a formal approach for identifying the components. This paper describes such an approach, which assists in identifying the components from an Analysis Level Object Model, representing a business domain. The approach makes use of a clustering algorithm, certain constraints, a predefined rule and a set of heuristics. The approach has been implemented in a tool named ‘CompMaker’ and was used for identifying components for an auto insurance claims domain.	algorithm;business domain;cluster analysis;heuristic;software development	Hemant K. Jain;Naresh Chalimeda;Navin Ivaturi;Balarama Reddy	2001		10.1109/EDOC.2001.950437	business domain;computer science;systems engineering;data mining;database;cluster analysis;programming language	SE	-49.40200505145429	26.762654555523515	135142
58a3c16f1655ab328997b477c7caf998ecc06b63	usability meanings and interpretations in iso standards	tool support;software usability;iso 9241;software measures;iso 9126;usability models;usability;software quality;software engineering practices	The usability of a software product has recently become a key software quality factor. The International Organization for Standardization (ISO) has developed a variety of models to specify and measure software usability but these individual models do not support all usability aspects. Furthermore, they are not yet well integrated into current software engineering practices and lack tool support. The aim of this research is to survey the actual representation (meanings and interpretations) of usability in ISO standards, indicate some of existing limitations and address them by proposing an enhanced, normative model for the evaluation of software usability.	software engineering;software quality;usability	Alain Abran;Adel Khelifi;Witold Suryn;Ahmed Seffah	2003	Software Quality Journal	10.1023/A:1025869312943	usability goals;pluralistic walkthrough;web usability;reliability engineering;component-based usability testing;medical software;cognitive walkthrough;verification and validation;usability;agile usability engineering;computer science;systems engineering;engineering;system usability scale;software engineering;usability engineering;software construction;software testing;software documentation;heuristic evaluation;usability lab;software quality;usability inspection	SE	-60.4486205507444	26.10369648474035	135143
7bab9531d01e7ecfa3c0a0c510a136c3911f88c9	distributed and concurrent development environment via sharing design information	groupware;workflow management;page description languages;document handling;software quality sgml programming standards development software standards software development management application software large scale systems software design product design;system documentation;work environment;sgml;information sharing;concurrent distributed development;computer aided software engineering;development environment;software development;concurrency control;project support environments;document management system;standard generalized markup language;groupware page description languages document handling project support environments configuration management concurrency control computer aided software engineering system documentation;sgml concurrent development environment sharing design information global environment distributed concurrent software development communication gaps distributed sites latest information design resources flexible coordination project tasks concurrent development concurrent workflow management standard generalized markup language electronic documents design document standard document management system;global software development;configuration management;internal standard;document management	This paper discusses a global environment for support of distributed concurrent sojiware development with an emphasis on sharing design information. There are many issues to be resolved in global sofhvare development such as communication gaps between distributed sites, guaranteed access to the latest information and spec8cation and design resources, accurate and flexible coordination of project tasks, and a work environment that is independent of the infrastructure at the sites. The mechanism whereby concurrent development and concurrent workjlow management are synchronized should be the key point. We will propose our approach to sharing design information with respect to the above issues. We adopt Standard Generalized Markup Language (SGML), the international standard for document description and exchange of electronic documents, as our design document standard. We will introduce a sophisticated document management system to support information sharing, and many information-sharing applications that can be effectively realized by using the features of SGML.	global variable;software design description;standard generalized markup language	Kiyoh Nakamura;Yoshinobu Fujii;Yukio Kiyokane;Masami Nakamura;Katsuhiko Hinenoya;Yeo Hua Peck;Siow Choon-Lian	1997		10.1109/CMPSAC.1997.624814	computer science;systems engineering;operating system;software engineering;document management system;database;programming language;management;sgml	HCI	-50.582020499626985	18.95043039576514	135154
606c6428781e97e031807ea514fd9d26bbf1dc99	mobile communications system simulator development using structured analysis	structured programming digital simulation graphical user interfaces telecommunication computing software reliability software maintenance mobile communication;software maintenance;mobile communication system;telecommunication computing;mobile communication network;simulation software;graphical user interfaces;mobile communication;structured programming;mobile communication analytical models context modeling mathematical model signal analysis laboratories documentation signal processing software maintenance modems;software reliability;digital simulation;structure analysis;hut mobile communications system simulator development structured analysis simulation software development well defined easily maintainable structure reliability maintainability automatic update netsim helsinki university of technology	In this paper, Structured Analysis (SA) is employed in mobile communications system simulation software development. Programming via SA provides a well-defined and easily maintainable structure for the software in a graphical form, also revealing any hidden dependencies in the software. Thus, the resulting simulator is more reliable and maintainable over its whole lifecycle. With modern SA tools, documentation can be automatically updated. Also, a mobile communications network simulator “Netsim”, developed at Helsinki University of Technology (HUT) since 1994, is described in the paper.	cognitive dimensions of notations;component-based software engineering;documentation;graphical user interface;simulation software;software development;software development process;structured analysis;system programming;telecommunications network	Jarno M. A. Tanskanen;Matti Rintamäki	2001		10.1109/VTC.2001.957210	software distribution;personal software process;verification and validation;mobile telephony;human–computer interaction;simulation software;computer science;systems engineering;package development process;backporting;software design;social software engineering;software framework;software development;operating system;software construction;graphical user interface;structural analysis;resource-oriented architecture;software maintenance;structured programming;mobile computing;software deployment;software quality;software system;computer engineering;avionics software	SE	-48.52617747033216	30.630114791198267	135216
861b9416cb953e0117e6484a7f8923288501e588	a conceptual framework for large-scale ecosystem interoperability and industrial product lifecycles	conceptual models;multilevel modelling;ecosystem interoperability;metamodelling	One of the most significant challenges in information system design is the constant and increasing need to establish interoperability between heterogeneous software systems at increasing scale. The automated translation of data between the data models and languages used by information ecosystems built around official or de facto standards is best addressed using model-driven engineering techniques, but requires handling both data and multiple levels of metadata within a single model. Standard modelling approaches are generally not built for this, compromising modelling outcomes. We establish the SLICER conceptual framework built on multilevel modelling principles and the differentiation of basic semantic relations (such as specialisation, instantiation, specification and categorisation) that dynamically structure the model. Moreover, it provides a natural propagation of constraints over multiple levels of instantiation. The presented framework is novel in its flexibility towards identifying the multilevel structure, the differentiation of relations often combined in other frameworks, and a natural propagation of constraints over multiple levels of instantiation.	categorization;coherence (physics);data model;ecosystem;electronic signature;information management;information model;information processing;information system;interoperability;machine translation;model-driven engineering;multilevel model;ontology (information science);refinement (computing);software propagation;software system;systems design;universal instantiation	Matt Selway;Markus Stumptner;Wolfgang Mayer;Andreas Jordan;Georg Grossmann;Michael Schrefl	2017	Data Knowl. Eng.	10.1016/j.datak.2017.03.006	computer science;conceptual model;data mining;database	SE	-51.598233518639546	18.358826872537847	135227
b220a66870d82fc17bef292aeefa8bc5c6037383	a comprehensive view on quality characteristics of the iot solutions		Categorization of quality characteristics helps in a more effective structuring of the testing process and in the determination of properties, which can be verified in the system under test. In the emerging area of Internet of Things (IoT) systems, several individual attempts have been made to summarize these aspects, but the previous work is rather heterogenic and focuses on specific subareas. Hence, we consolidated the quality characteristics into one unified view, which specifically emphasizes the aspects of security, privacy, reliability and usability, as these aspects are of often quoted as major challenges in the quality of contemporary IoT systems. The consolidated view also covers other areas of system quality, which are relevant for IoT system testing and quality assurance. In the paper, we also discuss relevant synonyms of particular quality characteristics as presented in the literature or being used in the current industry praxis. The consolidated view uses two levels of characteristics to maintain a suitable level of granularity and specificity in the discussed quality characteristics.		M. Bures;Xavier J. A. Bellekens;Karel Frajták;Bestoun S. Ahmed	2018	CoRR			SE	-58.99381907761029	22.466167643892916	135233
f854b173b21a31b53087ff4afee8bc15755dad47	ui-design driven model-based testing	user interface;unit testing;formal methods;journal article;prototyping;model based testing;computer science	Testing interactive systems is a notoriously difficult task. Not only do we need to ensure that the functionality of the developed system is correct with respect to the requirements and specifications, but also we need to ensure that the user interface (UI) to the system is correct (enables a user to access the functionality correctly) and is usable. These different requirements of interactive system testing are not easily combined within a single testing strategy. We investigate the use of models of interactive systems, which have been derived from design artefacts, as the basis for generating tests for an implemented system. We show how automatically generated abstract tests can be used as the basis for a model-based method for testing interactive systems which has low overhead in terms of the models required and which enables testing of UI and system functionality from the perspective of user interaction. We also examine other testing strategies which use the same abstract tests as their basis and discuss general problems in the area of interactive system testing and propose some solutions.	formal methods;interactivity;junit;java virtual machine;method stub;modality (human–computer interaction);model-based testing;oracle machine;overhead (computing);requirement;swing (java);system testing;test suite;test-driven development;usability testing;user interface design;user-centered design;white-box testing	Judy Bowen;Steve Reeves	2013	Innovations in Systems and Software Engineering	10.1007/s11334-013-0199-6	non-regression testing;test strategy;embedded system;black-box testing;model-based testing;simulation;formal methods;orthogonal array testing;software performance testing;human–computer interaction;white-box testing;manual testing;system integration testing;integration testing;computer science;systems engineering;operating system;functional testing;dynamic testing;prototype;software testing;unit testing;non-functional testing;user interface;system testing;graphical user interface testing	SE	-55.70398290648398	32.15196693625456	135261
ea69e57b8a72a3dd44d814c435895300ef5ac748	mimos, system model-driven migration project	software maintenance business data processing data mining;migration;business information systems aging computational modeling mimo software maintenance;software maintenance;data mining;architecture driven modernization;legacy systems migration architecture driven modernization business process;business data processing;legacy systems;business knowledge retrieval mimos system model driven migration project volatile it industry legacy information system business knowledge high level design model business process mining technique;business process	The volatile IT industry often tempts companies to replace legacy information systems with new ones. However, legacy systems cannot always be completely discarded because they gradually store a significant amount of valuable business knowledge as a result of progressive maintenance over time. Most migration techniques are proposed and applied in an ad hoc way. As a result, most migration techniques have a lack of automation and formalization, which makes it difficult to reuse such techniques to large, complex legacy information systems. This paper introduces MIMOS, a third-year project aimed at developing a methodological and technological modernization framework to facilitate the migration of legacy systems based on high-level design models. The work in progress during the first year mainly focused on the definition of a business process mining technique to retrieve the business knowledge embedded in source code so that it can be reused in the target system.	business process;embedded system;formal system;high- and low-level;hoc (programming language);information system;legacy system;level design;model-driven integration	Ricardo Pérez-Castillo;Ignacio García Rodríguez de Guzmán;Mario Piattini	2013	2013 17th European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2013.68	software modernization;data migration;computer science;systems engineering;human migration;engineering;knowledge management;artifact-centric business process model;business process management;software engineering;business case;data mining;business process model and notation;process management;business process;business software;business process discovery;software maintenance;management;business rule;new business development;business process modeling;legacy system;business activity monitoring;business architecture	SE	-59.525051091634026	23.35737314034622	135314
65ef79c7952452a00d90f05fe34e03f9bacf727b	application of collaborative scenarios in a process-based industrial environment	distributed development;groupware;process based;collaborative process environment collaborative scenario application process based industrial environment distributed development;quality management groupware production engineering computing;collaboration;industrial;software engineering;production engineering computing;collaborative scenario application;computer architecture;business environment;mediator;environment;graph;unified modeling language;process based industrial environment;book reviews;time to market;interoperability;organizations;application;scenarios;organizations collaboration book reviews unified modeling language software engineering computer architecture;quality management;application collaboration mediator interoperability graph;collaborative process environment;collaborative	The necessity of having processes for distributed development is a well known but still very challenging topic in the context of globalization. In order to stay competitive in a rough business environment, attractive products need to be developed constantly, which makes the products itself more and more complex. To be able to handle the development of complex products, several organizations participate to ensure the products’ quality and adequate time to market. Therefore, appropriate collaboration processes need to be established that are able to handle the complexity of the overall development. This paper defines a structured approach for setting up a collaborative process environment which enables organizations for collaborations from a process perspective. Furthermore, an example of how this approach is applied in practice is provided.	prototype;software prototyping	Harald Klein;Andreas Rausch;Martin Künzle;Edward Fischer	2010	2010 36th EUROMICRO Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2010.62	quality management;computer science;systems engineering;engineering;knowledge management;software engineering;management;collaboration	SE	-61.00839880754449	22.515330207252983	135336
7dab68be94a918f3e07e0319dd3a8ac767663e8b	testing non-functional requirements with aspects: an industrial case study	testing non-functional requirements;average software project;common goal;industrial case study;industrial system;non-functional requirement;functional testing;industrial adoption;aspect-oriented technique;functional requirement;conventional technique;efficient testing;formal verification;satisfiability;object oriented programming;software verification;non functional requirement;aspect oriented;industrial engineering	Testing is regarded as one of the most resource consuming tasks of an average software project. A common goal of testing related activities is to make sure that requirements are satisfied by the implementation. Although existing tools are often effective in functional testing, emerging nonfunctional requirements set new demands. Aspect-oriented techniques offer a promising approach for capturing such issues under verification. However, prior to industrial adoption more pragmatic guidelines on applying aspects are required. In this paper, we evaluate aspect-oriented techniques in testing non-functional requirements of an industrial system. In addition, we discuss the types of requirements that lend themselves for more efficient testing using aspects than conventional techniques.	aspect weaver;aspect-oriented programming;aspect-oriented software development;context (computing);cross-cutting concern;functional requirement;functional testing;non-functional requirement;software design;software project management;software testability;systems architecture;test case;test harness	Jani Metsä;Mika Katara;Tommi Mikkonen	2007	Seventh International Conference on Quality Software (QSIC 2007)	10.1109/QSIC.2007.62	test strategy;reliability engineering;aspect-oriented programming;software performance testing;white-box testing;formal verification;software verification;computer science;systems engineering;acceptance testing;software engineering;functional testing;software testing;non-functional testing;programming language;object-oriented programming;system testing;non-functional requirement;satisfiability	SE	-58.01383941601405	28.3849146729901	135695
f0bcd4612cfb6297524388560f8fea1abca5c781	geco: a generator composition approach foraspect-oriented dsls		Code and model generators that are employed in modeldriven engineering usually face challenges caused by complexity and tight coupling of generator implementations, particularly when multiple metamodels are involved. As a consequence maintenance, evolution and reuse of generators is expensive and error-prone. We address these challenges with a two fold approach for generator composition, called GECO, which subdivides generators in fragments and modules. (1) fragments are combined utilizing megamodel patterns. These patterns are based on the relationship between base and aspect metamodel, and define that each fragment relates only to one source and target metamodel. (2) fragments are modularized along transformation aspects, such as model navigation, and metamodel semantics. We evaluate our approach with two case studies from different domains. The obtained generators are assessed with modularity and complexity metrics, covering architecture and method level. Our results show that the generator modularity is preserved during evolution utilizing GECO.	aspect-oriented software development;cognitive dimensions of notations;control system;digital subscriber line;embedded system;information system;metamodeling;model-driven engineering;modularity (networks);self-propelled particles;software evolution;software quality	Reiner Jung;Robert Heinrich;Wilhelm Hasselbring	2016		10.1007/978-3-319-42064-6_10	computer science;systems engineering;engineering drawing;algorithm	AI	-54.61783730764459	27.953142352197794	135724
5668ca1afd3f091e50b7b791a84706464c10964c	model-driven management of services	performance measure;model driven management;key performance indicator;software engineering tools;web services service oriented architecture;reliability;systemvetenskap informationssystem och informatik;information systems;service provider;sensors;model driven engineering management distributed internet based software engineering tools and techniques performance measures quality analysis and evaluation;biological system modeling;service management;development process;requirements elicitation;time management;distributed internet based software engineering tools and techniques;quality analysis and evaluation;computational modeling;business;web services;model driven engineering;performance measures;run time management;ecoware;ecoware remote services requirements elicitation run time management service management service engineering model driven management;quality of service;service oriented architecture;management;service engineering;remote services;biological system modeling data models sensors reliability computational modeling business quality of service;data models	Applications are increasingly composed of remote services provided by independent parties. This distributed ownership makes it problematic to measure and control quality of service indicators. Management activities must become an integral part of the system’s development process, from requirements elicitation, where users identify the quality dimensions of interest, to the implementation, where the actual composition must be paired with suitable means for its run-time management. This paper presents MDMS (Model-Driven Management of Services), a model-driven approach for engineering manageable services. The approach supports the explicit modeling of quality dimensions, management objectives, and key performance indicators, and the transformations required to exploit these concepts at runtime. The methodology is supported by ECo Ware, an innovative prototype framework for the deployment and operation of managed services.	experiment;explicit modeling;floor and ceiling functions;model-driven architecture;model-driven integration;prototype;quality of service;requirement;requirements elicitation;run time (program lifecycle phase);service-oriented architecture;service-oriented device architecture;software deployment	Luciano Baresi;Mauro Caporuscio;Carlo Ghezzi;Sam Guinea	2010	2010 Eighth IEEE European Conference on Web Services	10.1109/ECOWS.2010.10	service provider;web service;data modeling;model-driven architecture;quality of service;time management;service management;computer science;knowledge management;sensor;performance indicator;service-oriented architecture;requirements elicitation;reliability;services computing;management;computational model;software development process;information system	DB	-58.037526080972334	19.812007986250727	135803
af0e40b1578edbc58244d0241c603b180bfdb80a	assuring safety for component based software engineering	component based software engineering;safety critical software program testing;context contracts software standards testing hazards;engineering and technology;teknik och teknologier;assurance;program testing;assurance safety component based software engineering;safety critical software;safety;safety assurance component testing system testing safety argument patterns cost reduction cbse mbd model based development system design scs safety critical systems component based software engineering	Developing Safety-Critical Systems (SCS) is an expensive activity largely due to the cost of testing both components and the systems produced by integrating them. In more mainstream system design, Model-Based Development (MBD) and Component-Based Software Engineering (CBSE) are seen as complementary activities that can reduce these costs, however their use is not yet well supported in the safety critical domain, as safety is an emergent property. The contributions of this paper are to describe some of the challenges of using these approaches in SCS, and then argue how through appropriate safety argument patterns the challenges can be addressed.	avionics;component-based software engineering;context-sensitive grammar;emergence;hazard (computer architecture);model-based definition;outline (list);requirement;shortest seek first;systems design;variadic template	Philippa Conmy;Iain Bate	2014	2014 IEEE 15th International Symposium on High-Assurance Systems Engineering	10.1109/HASE.2014.25	safety engineering;software security assurance;reliability engineering;verification and validation;software engineering process group;software performance testing;system integration testing;computer science;systems engineering;engineering;acceptance testing;social software engineering;software reliability testing;component-based software engineering;software development;software engineering;software construction;software testing;programming language;software deployment;software requirements;software quality analyst;software system;avionics software	SE	-58.143845522500065	26.88081434871582	135835
9ef6d7e7f9be3842cc4aaefaf3479bb6b0b7abd2	design and development of a real-time system - a case study	real time systems		real-time operating system;real-time transcription	P. C. Lee;S. P. Schaaf;T. Y. Tsai;N. Srinivasan	1982			real-time computing;iterative design;distributed computing;v-model;real-time operating system;systems design;computer science;design technology;systems development life cycle	Embedded	-50.947847611440395	21.024427142518437	135885
09cae37e5297a5cff316f3a613e8209ca717b087	rewamp: rapid web migration prototyping leveraging webassembly		Web Migration is a challenge, in particular for Small and Medium-sized Enterprises (SMEs). In previous collaborations with SMEs we noticed an initial resistance to migrate legacy desktop applications to the web, due to concerns about the risk and lack of developers with web expertise . This initial hurdle can be mitigated by the ability to rapidly create running web prototypes based on the existing desktop codebase and expertise of the developers. Therefore, we outline a rapid prototyping approach for Web Migration and present a solution architecture, process and supporting infrastructure based on WebAssembly. We describe challenges and report on an experiment applying WebAssembly on a scenario desktop application derived from real-world industrial code.	webassembly	Sebastian Heil;Valentin Siegert;Martin Gaedke	2018		10.1007/978-3-319-91662-0_6	world wide web;computer engineering;computer science;solution architecture;codebase;rapid prototyping	HCI	-49.30532456123764	21.188055628438967	136068
8c340c824d1e4e567dde09ac11648450bb18ba4a	an overview on analysis tools for software product lines	tool support;testing;theorem proving;sampling;non functional properties;type checking;model checking;static analysis;software product lines;code metrics	A software product line is a set of different software products that share commonalities. For a selection of features, specialized products of one domain can be generated automatically from domain artifacts. However, analyses of software product lines need to handle a large number of products that can be exponential in the number of features. In the last decade, many approaches have been proposed to analyze software product lines efficiently. For some of these approaches tool support is available. Based on a recent survey on analysis for software product lines, we provide a first overview on such tools. While our discussion is limited to analysis tools, we provide an accompanying website covering further tools for product-line development. We compare tools according to their analysis and implementation strategy to identify underrepresented areas. In addition, we want to ease the reuse of existing tools for researchers and students, and to simplify research transfer to practice.	domain model;software product line;time complexity	Jens Meinicke;Thomas Thüm;Reimar Schröter;Fabian Benduhn;Gunter Saake	2014		10.1145/2647908.2655972	domain analysis;model checking;sampling;verification and validation;software sizing;computer science;systems engineering;package development process;theoretical computer science;software framework;software development;software design description;software engineering;domain engineering;software construction;software testing;automated theorem proving;software walkthrough;programming language;software deployment;computer-aided software engineering;static analysis;product engineering	SE	-58.73643565495211	29.853535360588907	136408
b00fe7393d38c25d76bbd1d5c399501d8d438136	process model adaptation using semantic technologies	automatic planning approaches process model adaptation business process software life cycles semantic annotation;semantic annotation;semantic technologies;semantic process modeling sbpm token;sbpm;software requirements;computational modeling;adaptation model;business data processing;automatic planning approaches;business;unified modeling language;semantic;planning;software life cycles;ontologies;software life cycle;process model;process;process model adaptation;modeling;adaptation model process planning business humans globalization technology planning technology management companies context modeling automatic control;business process;labeling;token;planning business data processing	Modeling and executing business processes with the help of software requires so much human work that the software life-cycles can not keep up with the fast changing demands of today's global markets. Therefore, a mechanism is required to adapt these process models automatically. In this paper we introduce a novel approach for the adaptation of existing process models using semantic technologies, thereby building on semantic annotation of process models as well as on automatic planning approaches.	algorithm;automated planning and scheduling;business process;process modeling;software release life cycle	Florian Lautenbacher;Thomas Eisenbarth;Bernhard Bauer	2009	2009 13th Enterprise Distributed Object Computing Conference Workshops	10.1109/EDOCW.2009.5331985	planning;unified modeling language;labeling theory;systems modeling;security token;computer science;systems engineering;knowledge management;ontology;process modeling;data mining;database;business process;semantic technology;management;computational model;software development process;software requirements;process	SE	-55.336641496025585	18.696468604985714	136860
3673adf65934f3a32e408310135c2e204617ec5d	multi-perspective business process monitoring	computer and systems sciences;systemvetenskap informationssystem och informatik;information systems;data och systemvetenskap	Monitoring business processes is an important area in Business Process Management. This area not only supports monitoring but also enables flexibility. Thus, it has been investigated in many other areas like Business Activity Monitoring, Exception Handling, Aspect Oriented Business Process Management, etc. These areas require to define how a process instance should be monitored from different perspectives. However, current definitions are coupled to control-flow perspective, which applies some limitations. For example, we cannot define a rule to capture situations in which an account balance is read regardless of its process. To capture such situations, we propose an approach to define monitoring rules. This approach enables composition of rules in a way to be decoupled from a specific perspective. To validate the result, we implemented a rule editor and a monitoring service, called Observer Service. These artefacts are used to support the definition of monitoring rules and track process instances, correspondingly. Finally, we investigated the validity and relevancy of the artefacts through a banking case study.	aspect-oriented programming;business activity monitoring;business process;business rule management system;control flow;exception handling;relevance;separation of concerns;visual artifact	Amin Jalali;Paul Johannesson	2013		10.1007/978-3-642-38484-4_15	computer science;systems engineering;knowledge management;business process management;operations management;business process modeling;business activity monitoring	DB	-56.84526215493053	19.699761939571637	137102
2741369df6288bbace37cdff52899c8339e65c43	an overview of the state of the art in software architecture	yarn;iterative development;software systems;metrics;code standards;software architecture computer architecture permission yarn buildings software systems software engineering pattern analysis code standards standards development;software engineering;computer architecture;software architecture;standards development;permission;pattern analysis;process;buildings	Introduction The problem of software architecture has long been a concern for those building and evolving large software systems. Aspects of software architecture are included in both system architecture and requirements speci cation. Typically, the software architecture is in place before the requirements are passed on to the system developers for implementation. The architecture functions as the overall structure within which the requirements are to be met.	requirement;software architecture;software system;systems architecture	Dewayne E. Perry	1997		10.1145/253228.253487	multilayered architecture;reference architecture;software architecture;personal software process;architecture tradeoff analysis method;verification and validation;computer science;systems engineering;package development process;social software engineering;software development;software design description;software engineering;iterative and incremental development;software construction;software architecture description;software walkthrough;resource-oriented architecture;software measurement;metrics;software development process;software quality;process;software system;computer engineering;software peer review	SE	-53.04362571219016	28.02996801313881	137201
5fd1422202987cf28fd9e0d02083f54ad5be3dd2	combining ontologies with domain specific languages: a case study from network configuration software	software engineering;network configuration;model driven engineering;domain specific language;network management;software quality	"""One of the important aspects of Model-Driven Engineering (MDE) is to consider application-domain variability, which leads to creation of Domain Specific Languages (DSL). As with DSLs models are concise, easy to understand and maintain, this approach greatly increases the productivity and software quality. Usually, the DSLs in MDE are described with a metamodel and a concrete syntax definition. The models expressed in the DSL are linguistic instantiations of the language concepts found in the metamodel.#R##N##R##N#However, for some of the application domains it's not enough to consider the linguistic dimension of the instantiation. The problem arises when the domain itself contains the aspect of typing. This leads to another view on instantiation, called ontological instantiation . Since both aspects are present simultaneously, we refer to the combined approach with the term """"two-dimensional metamodelling"""".#R##N##R##N#In the following, we will exemplify the problem with a case study based on a real challenge found in the domain of network management. The solution we propose benefits from ontology technology which is applied to enforce the semantics of ontological instantiation. Our approach presents significant differences comparing to the existing 2D metamodelling solution, although the motivations are similar. Thus, we consider our work as a case study of applying ontology enabled software engineering in the area of DSL engineering, rather than a new metamodelling technology or an application of existing 2D metamodelling architecture.#R##N##R##N#The article is a result of joint work of the MOST project partners, applied within the case study provided by Comarch."""		Krzysztof Miksa;Pawel Sabina;Marek Kasztelnik	2010		10.1007/978-3-642-15543-7_4	domain analysis;computer science;systems engineering;knowledge management;domain engineering;data mining	SE	-54.02487346345499	23.079979682571768	137507
17a01257a08c614457da281e6314862099dcb09d	object-oriented component identification method using the affinity analysis technique	developpement logiciel;component based development;composant logiciel;object oriented;desarrollo logicial;software development;software component;oriente objet;orientado objeto;use case	In this paper, we will propose the component identification method using the class and use case affinity analysis technique (CUAT). CUAT has two types, which are class and class analysis, and use case and class analysis. For applying this technique, we firstly defined component, component interface and component taxonomy for our organization. We also performed case study of OSGi system for verifying the research results. This method reflects the low coupling-high cohesion principles for good modularization of reusable software component.	affinity analysis;cohesion (computer science);component-based software engineering;osgi;processor affinity;verification and validation	Yon-Jung Jang;Eun-Young Kim;Kyung-Whan Lee	2003		10.1007/978-3-540-45242-3_33	simulation;computer science;component-based software engineering;programming language;algorithm	SE	-51.72320325504884	28.312404133611096	137524
7d12124b184617c442f922425ef766e03974fe42	conceptual modeling of a procurement process: case study of rfp for public key infrastructure		Procurement refers to a process resulting in delivery of goods or services within a set time period. The process includes aspects of purchasing, specifications to be met, and solicitation notifications as in the case of Request For Proposals (RFPs). Typically such an RFP is described in a verbal ad hoc fashion, in English, with tables and graphs, resulting in imprecise specifications of requirements. It has been proposed that BPMN diagrams be used to specify requirements to be included in RFP. This paper is a merger of three topics: (i) Procurement development with a focus on operational specification of RFP, (ii) Public key infrastructure (PKI) as an RFP subject, and (iii) Conceptual modeling that produces a diagram as a supplement to an RFP to clarify requirements more precisely than traditional tools such as natural language, tables, and ad hoc graphs. Keywords—Procurement; RFP; Public Key Infrastructure; conceptual modeling; diagrammatic representation		Sabah S. Al-Fedaghi	2018	CoRR			SE	-53.615167879881476	20.629313943860396	137561
9b281fd27c15a2f633844eab994f55ea69700caa	theories of software reliability: how good are they and how can they be improved?	model verification;software failure;program error;software bug count;software life cycle cost;satisfiability;reliability growth;software failure rate;software reliability measurement;failure rate;software life cycle;software reliability software measurement testing predictive models hardware battery powered vehicles mathematical model roads computer errors costs;software reliability;debugging software;software reliability measurement debugging software program error reliability growth software bug count software failure software failure rate software life cycle cost	An examination of the assumptions used in early bug-counting models of software reliability shows them to be deficient. Suggestions are made to improve modeling assumptions and examples are given of mathematical implementations. Model verification via real-life data is discussed and minimum requirements are presented. An example shows how these requirements may be satisfied in practice. It is suggested that current theories are only the first step along what threatens to be a long road.	real life;requirement;software quality;software reliability testing;theory	Bev Littlewood	1980	IEEE Transactions on Software Engineering	10.1109/TSE.1980.230790	reliability engineering;personal software process;long-term support;verification and validation;real-time computing;software sizing;software verification;computer science;package development process;backporting;software reliability testing;software development;software engineering;failure rate;software construction;software testing;software deployment;software regression;software development process;software quality;software metric;software quality analyst;satisfiability;avionics software	SE	-62.49911875300219	31.900084884688145	137562
101133e89142d233018b71d523595422e81b2de8	control and definition modularization: an improved software design technique for organizing programs	developpement logiciel;definition modularization;software design technique;programming language;maintenance;program design;structured design methodology;conception programme;ingenieria logiciel;data type;software engineering;orientado objecto;object oriented;organizing programs;desarrollo logicial;structured design methodology definition modularization software design technique organizing programs control and definition modularization systematic program layout conceptual data object execution flow programs maintainability;modificacion;software development;structured programming;conceptual data object;genie logiciel;mantenimiento;oriente objet;software design organizing design methodology software maintenance concrete programming profession control systems process control computer languages costs;programmation structuree;software design;control and definition modularization;structural design;execution flow;systematic program layout;concepcion programa;programacion estructurada;programs maintainability;modification	The author proposes a technique called control and definition modularization (CDM), which derives a systematic program layout from a given structure chart using the concepts of 'control' and 'definition' modules. A control module includes processes for handling a conceptual data object not directly implementable. A definition module defines operations associated with a concrete data object implementable using a primitive or derived data type of a programming language. Grouping the operations available for each concrete data object, and keeping them separated from execution flow, improves programs maintainability. This technique extends the structured design methodology and provides designers with a systematic way of deriving informational strength modules as well as a structured physical layout from the structure chart. A program based on the CDM technique is easier to understand and maintain. This research makes a significant contribution toward bridging the gap between structured design and object-oriented concepts. >	organizing (structure);software design	Surya B. Yadav	1990	IEEE Trans. Software Eng.	10.1109/32.44367	data type;computer science;systems engineering;software design;software development;operating system;software engineering;database;program design language;programming language;object-oriented programming;structured programming;structured analysis;structure chart	SE	-50.55901007315074	30.972391881933245	137658
00618c511a0f4bc254397cc253a134739126b2bb	software architectural design meets security engineering	software;security engineering;quality attributes security engineering security requirements security policies security models software architecture design method non functional requirements;security policies;quality attributes;security model;design engineering;software design security design engineering software engineering computer architecture design methodology computer applications enterprise resource planning web services companies;software systems;web service;development process;software architecture security of data;companies;software engineering;security models;erp system;computer applications;non functional requirement;non functional requirements;software architectural design;distributed enterprise resource planning systems;computer architecture;software architecture;design method;enterprise resource planning system;security requirements;business;business processes software architectural design security engineering security requirements complex it systems software engineering security architecture distributed enterprise resource planning systems web services;enterprise resource planning;web services;security architecture;software architecture design;trusted computing base;software design;system architecture;security;security policy;complex it systems;security of data;business process;business processes;design methodology	Security requirements strongly influence the architectural design of complex IT systems in a similar way as other non-functional requirements. Both security engineering as well as software engineering provide methods to deal with such requirements. However, there is still a critical gap concerning the integration of the methods of these separate fields. In this paper we close this gap with respect to security requirements by proposing a method that combines software engineering approaches with state-of-the-art security engineering principles. This method establishes an explicit alignment between the non-functional goal, the principles in the field of security engineering, and the implementation of a security architecture. The method aims at designing a system's security architecture based on a small, precisely defined, and application-specific trusted computing base. We illustrate this method by means of a case study which describes distributed enterprise resource planning systems using web services to implement business processes across company boundaries.	business process;common criteria;computer security;coupling (computer programming);enterprise resource planning;function model;functional requirement;interaction;list comprehension;non-functional requirement;prospective search;reduction (complexity);refinement (computing);relevance;requirements traceability;security engineering;software architecture;software engineering;software system;trusted computing base;usability testing;web service	Stephan Bode;Anja Fischer;Winfried E. Kühnhauser;Matthias Riebisch	2009	2009 16th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems	10.1109/ECBS.2009.17	software security assurance;computer security model;web service;software architecture;requirements analysis;sherwood applied business security architecture;security engineering;design methods;computer science;systems engineering;engineering;security policy;requirement;software engineering;security service;requirements engineering;business process;security testing;non-functional requirement;software requirements;enterprise information security architecture;computer engineering	SE	-54.122282555115135	27.26211514774581	137762
ddfa52d43b4ce0c723d0f026cd0b4f476dd9118d	an early look at defining variability requirements for system of systems platforms	formal specification;probability;system of systems architecture;software economics computer architecture context conferences context modeling;software reusability formal specification probability product development;system of systems;system of systems architecture system of systems software requirements platform engineering software product lines;platform engineering;software requirements;software reusability;probabilistic models variability requirements system of systems platforms platform based approach economical reuse system of systems capability sos platforms variation points variation ranges variation decision binding times software product lines economic models real options;software product lines;product development	In the commercial domain, platform-based approaches, in which a set of functions or services are bundled to form the basis of many products, have enabled efficient development of systems and their composition into systems of systems. A successful platform must balance sufficient commonality to support economical reuse, while also providing variability and extensibility to enable innovation in system and system of systems (SoS) capabilities. These commonality/variability tradeoffs for SoS platforms are frequently tacit decisions, since there are no accepted techniques for analyzing such decisions at the scale and degree of requirements uncertainty that characterize most SoSs. The objective of our work is to develop a method for analyzing decisions about requirements for common platforms for SoSs. The method begins with the requirements tasks of identifying and selecting appropriate variabilities (variation points, variation ranges, and variation decision binding times) to support immediate SoS needs, and also enable innovation and controlled evolution. We are currently conducting a workshop and interviews with SoS experts to define the essential technical problems in SoS common platform development and identify solution constraints. We will then define a simplified SoS with limited capability requirements to use as a model problem. We will use the model problem to assess the fit of existing scope, commonality, and variability methods from software product lines to the SoS context, and extend existing economic models using real options and probabilistic models to model uncertainty in evolution requirements. While it is too early to draw firm conclusions about the effectiveness of our approach, it is based on proven technologies from the mature field of software product lines and so we have confidence that we can build successful SoS techniques from this foundation.	apple sos;common platform;extensibility;heart rate variability;image scaling;nonlinear gameplay;requirement;software engineering institute;software product line;spatial variability;system of systems	John Klein;Gary J. Chastek;Sholom Cohen;Rick Kazman;John D. McGregor	2012	2012 Second IEEE International Workshop on Requirements Engineering for Systems, Services, and Systems-of-Systems (RESS)	10.1109/RES4.2012.6347693	reliability engineering;requirements analysis;software requirements specification;requirement prioritization;systems engineering;engineering;requirement;software engineering;software system;systems design	SE	-57.51440317469153	27.04605261729201	137788
1d900052425f1bfea7622a2ee935abd97767e13f	organization-ontology based framework for implementing the business understanding phase of data mining projects	data mining delta modulation databases phased arrays mining industry decision making surges navigation costs information systems;data mining;ontologies artificial intelligence;ontologies artificial intelligence data mining;semi automated integration organization ontology based framework data mining projects cross industry standard process for data mining;tools and techniques	CRISP-DM is a detailed and widely used data mining methodology that aims to provide explicit guidance regarding how the various phases of a data mining project could be executed. The 'business understanding' phase marks the beginning of a data mining project and forms the foundation for the execution of the remaining phases. Unfortunately, the real-world implementation of this pivotal phase is performed in a rather unstructured and ad-hoc manner. We argue that the reason for this lies in the lack of support in form of appropriate tools and techniques that can be used to execute the large number of activities (=67) prescribed within this phase. This paper presents an organization-ontology based framework that not only incorporates the applicable tools and techniques, but also provides the ability to present the output of activities in a form that allows for at least their semi-automated integration with activities of this phase and succeeding phases.	concurrent computing;cross industry standard process for data mining;dm-crypt;hoc (programming language);linkage (software);mission critical;ontology (information science);semiconductor industry	Sumana Sharma;Kweku-Muata Osei-Bryson	2008	Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)	10.1109/HICSS.2008.339	concept mining;text mining;computer science;knowledge management;artificial intelligence;data science;data mining;database;data stream mining;world wide web	DB	-59.062588213245746	23.173374148223605	137862
0651e49f62c35ce8ac8130627df19f6c464f5079	attribute-based cots product interoperability assessment	program diagnostics;commercial off the shelf products;software performance evaluation;software systems;software systems costs job shop scheduling performance analysis software reusability application software prototypes packaging java software engineering;interoperability conflicts;interoperability analysis;commercial off the shelf;software performance evaluation open systems program diagnostics software packages;attribute based cots product interoperability assessment;conflicts identification;interoperability analysis attribute based cots product interoperability assessment commercial off the shelf products software systems interoperability conflicts conflicts identification;open systems;similarity function;software packages	Software systems today are frequently composed from prefabricated commercial components that provide complex functionality and engage in complex interactions. Such projects that utilize multiple commercial-off-the-shelf (COTS) products often confront interoperability conflicts resulting in budget and schedule overruns. These conflicts occur because of the incompatible assumptions made by developers of these products. Identification of such conflicts and planning strategies to resolve them is critical for developing such systems under budget and schedule constraints. Unfortunately, acquiring information to perform interoperability analysis is a time-intensive process. Moreover, increase in the number of COTS products available to fulfill similar functionality leads to hundreds of COTS product combinations, further complicating the COTS interoperability assessment landscape. In this paper we present a set of attributes that can be used to define COTS interoperability-specific characteristics. COTS product definitions based on these attributes can be used to perform high-level and automated interoperability assessment to filter out COTS product combinations whose integration will not be feasible within project constraints. In addition to above stated attributes, we present a tool that can be used to assess COTS-based architectures for interoperability conflicts, reducing the overall effort spent in performing interoperability analysis. Our preliminary experience in using the framework indicates an increase in interoperability assessment productivity by 50% and accuracy by 20%	high- and low-level;interaction;interoperability;planning;software system	Jesal Bhuta;Barry W. Boehm	2007	2007 Sixth International IEEE Conference on Commercial-off-the-Shelf (COTS)-Based Software Systems (ICCBSS'07)	10.1109/ICCBSS.2007.6	reliability engineering;interoperability;systems engineering;engineering;database	SE	-56.77002394418315	27.45406795847658	137931
34cd1b81b3228dc0e4ce88b46e69753dd15a72d1	software verification — a scalable, model-driven, empirically grounded approach		    Software is present in most systems across all industries, including energy, automotive, health care, maritime, aerospace,  and banking, to name just a few. Software systems are increasingly taking on safety- and business-critical roles and growing  in complexity. One crucial aspect of software development is therefore to ensure the dependability of such systems, that is,  their reliability, safety, and robustness. This is achieved by several complementary means of verification, ranging from early  analysis of system specifications and designs to systematic testing of the executable software. Such verification activities  are, however, difficult and time-consuming. This stems in part from the sheer complexity of most software systems and because  they must accommodate changing requirements from many stakeholders.      	criticality matrix;formal verification;heuristic;mda framework;model-based testing;model-driven engineering;model-driven integration;open-source software;requirement;scalability;search algorithm;software engineer;software system;software verification;unified modeling language;verification and validation	Lionel C. Briand	2010		10.1007/978-3-642-01156-6_28	robustness (computer science);software system;system under test;systems engineering;software;software development;software verification;ranging;computer science;dependability	Logic	-58.5062491864055	26.35102103066014	137980
7a33f8a480634f3d98b881d7bb5bc427b0c37e1f	architecture and design intent in component & cots based systems	component based systems;software systems;software architecture cots based system component based system software system development software system evolution commercial off the shelf;object oriented programming;systems analysis object oriented programming software architecture software packages;software architecture;systems analysis;software packages	Architecture and design intent are critical elements in the development and evolution of software systems. They are critical in two ways. First, there must be a shared understanding of them to adequately and effectively build and evolve our systems. Second, this shared understanding is needed to coordinate the various developers and teams of developers, especially in evolving our systems. The lack of access to internal implementation details makes the issue of architecture and design intent even more critical in COTS and component based systems. We explore the issues involved in supporting the reification and use of architecture and design intent, discuss a selection of approaches, and present some ideas we have about its use in both planned and agile contexts.	agile software development;reification (knowledge representation);software system	Dewayne E. Perry;Paul Grisham	2006		10.1109/ICCBSS.2006.6	multilayered architecture;reference architecture;software architecture;architecture tradeoff analysis method;real-time computing;computer science;systems engineering;applications architecture;package development process;software design;component-based software engineering;software development;software design description;software construction;hardware architecture;software architecture description;systems development life cycle;resource-oriented architecture;software deployment;software development process;systems architecture;software system;computer engineering;systems design	SE	-53.36673210687784	27.758879603167152	138013
fe86c2527f916154fb77db38e6a9f5ca884184be	towards a formal, model-based framework for control systems interaction prototyping	automatic code generation;formal model;serveur institutionnel;three dimensional;control system;archive institutionnelle;complex system;high energy physics;open access;graphic user interface;archive ouverte unige;cybertheses;institutional repository	This paper provides an overview of a starting project called BATIC3S (Building Adaptive Three-dimensional Interfaces for Critical Complex Control Systems). This project aims to bring a more viable approach in the fields of Graphical User Interfaces (GUI), software modeling and verification, automatic code generation, and adaptivity. The goal is to build a comprehensive methodology for semi-automated, formal model-based generation of effective, reliable and adaptive 3D GUIs for diagnosing control systems. This can be used to assist in GUI development for very complex systems, like industrial systems, high energy physics experiments and similar. RISOLDI, Matteo, AMARAL, Vasco. Towards a formal, model-based framework for control systems interaction prototyping. In: Nicolas Guelfi & Didier Buchs. Rapid Integration of Software Engineering techniques. Third International Workshop, RISE 2006. Berlin : Springer, 2006. p. 144-159 DOI : 10.1007/978-3-540-71876-5_10	automatic programming;code generation (compiler);complex systems;control system;domain-specific language;experiment;graphical user interface;mathematical model;metamodeling;modeling language;prototype;requirement;scalability;semiconductor industry;software engineering;software verification;springer (tank)	Matteo Risoldi;Vasco Amaral	2006		10.1007/978-3-540-71876-5_10	simulation;human–computer interaction;computer science;software engineering	SE	-48.68579334639703	29.00964482133101	138029
31fb7a18f86fe3c5a01e7d2db4668be4f4476c3a	specifying customized versioning facilities of software engineering repositories by using uml-based design templates	software engineering repositories;uml model enhancement;versioning;software engineering	Software engineering repositories are often deployed in different environments, which may pose environment-specific demands related to repository services. Since most repository products do not support any significant modification of their services, the possibilities of customizing the repository to the requirements of an environment are limited. To overcome this problem, our approach assists the software engineers in delivering a UML-based specification of the repository product with its services customized to the requirements of the environment. On the basis of this specification, a customized repository to be used in the environment is generated. This paper primarily deals with the specification phase of the process for the domain of customizing the repository’s version and configuration control services.	component-based software engineering;configuration management;requirement;semiconductor industry;software engineer;unified modeling language	Jernej Kovse	2002			software construction;software engineering;software development;software verification and validation;applications of uml;database;package development process;uml tool;software requirements;systems engineering;social software engineering;engineering	SE	-55.48192220941154	26.69311545681785	138092
6a023e366fed58dc8d1c92eeb75fd942778c2b2b	bvr - better variability results		We present BVR (Base Variability Resolution models), a language developed to fulfill the industrial needs in the safety domain for variability modeling. We show how the industrial needs are in fact quite general and that general mechanisms can be used to satisfy them. BVR is built on the OMG Revised Submission of CVL (Common Variability Language), but is simplified and enhanced relative to that language.	heart rate variability;name binding;spatial variability	Øystein Haugen;Ommund Øgård	2014		10.1007/978-3-319-11743-0_1	simulation;computer science;algorithm	Logic	-51.79505550562292	24.927141879391986	138103
931caf497cee8f95631350fe68998f2cf5dc7b1f	leveraging semantic web technologies for consistency management in multi-viewpoint systems engineering		Systems modeling is an important ingredient for engineering complex systems in potentially heterogeneous environments. One way to deal with the increasing complexity of systems is to offer several dedicated viewpoints on the system model for different stakeholders, thus providing means for system engineers to focus on particular aspects of the environment. This allows them to solve engineering tasks more efficiently, although keeping those multiple viewpoints consistent with each other (e.g., in dynamic multiuser scenarios) is not trivial. In the present chapter, we elaborate how Semantic Web technologies (SWT) may be utilized to deal with such challenges when models are represented as RDF graphs. In particular, we discuss current developments regarding a W3C Recommendation for describing structural constraints over RDF graphs called Shapes Constraint Language (SHACL) which we subsequently exploit for defining intermodel constraints to ensure consistency between different viewpoints represented as RDF graphs. Based on a running example, we illustrate how SHACL is used to define correspondences (i.e., mappings) between different RDF graphs and subsequently how those correspondences can be validated during modeling time.	semantic web;systems engineering	Simon Steyskal;Manuel Wimmer	2016		10.1007/978-3-319-41490-4_13	web modeling;data web;knowledge management;semantic web;social semantic web;semantic web stack;database;information retrieval;semantic analytics	Web+IR	-50.441113223196915	22.254200340482537	138170
525b984d293d4ba2a925237b7ac25bc77b29cd98	shared data services: an architectural approach	corporate acquisitions;data integrity;heterogeneous systems;customer relationship management;etl activities;service orientation;meta data business data processing;shared data services;software systems;service oriented approach;companies;software engineering;supply chains;business case;meta data based architecture;companies corporate acquisitions enterprise resource planning costs software engineering software systems supply chain management supply chains customer relationship management environmental management;enterprise data integration;business data processing;end to end architectural approach;enterprise resource planning;data access;heterogeneous system;meta data;environmental management;etl activities shared data services enterprise data integration heterogeneous system service oriented approach end to end architectural approach meta data based architecture business process;supply chain management;business process	The growing need for enterprises to have instantaneous access and visibility to data is fuelling the need for enterprise data integration. An enterprise having fragmented systems on varied technologies is a very commonly occurring scenario. In this paper we take a business case scenario with heterogeneous systems and describe a non-intrusive service oriented approach for achieving enterprise wide data integration. We take a holistic view of the problem statement and propose an end to end architectural approach that encompasses the ETL activities to the shared data access layer. This meta-data based architecture is highly extensible requiring minimal change in existing applications and business process yet adhering to the long term architectural strategy. We also propose the creation of fine grained shared business services which are supported by underlying shared data services.	business process;coupling (computer programming);data access;distributed computing;holism;service-oriented architecture	V. Niranjan;Sriram Anand;Krishnendu Kunti	2005	IEEE International Conference on Web Services (ICWS'05)	10.1109/ICWS.2005.112	data access;supply chain management;computer science;knowledge management;business case;data integrity;database;supply chain;business process;enterprise integration;metadata;enterprise information integration;software system	DB	-56.31225897044077	18.67570338574148	138181
908f861bd50f2747513ead723acbb4ebf0281be6	the feature pack approach: systematically managing implementations in software ecosystems	architecture;software product lines;software ecosystem;variability modeling	In an information system ecosystem customers integrate features, which are independently developed and evolved by multiple organizations. These features need to work together although there is little to no coordination among developer organizations.  The handling of such ecosystems becomes the more challenging, the more the solutions provided by the different parties are intertwined. In this paper, we propose to handle implementations on a per-feature basis, and introduce an approach towards this goal, which we call feature packs. We discuss the requirements on such an approach and emphasize in particular the kind of analysis relevant to ensure that the system resulting from a corresponding aggregation of feature packs works reliably. We also illustrate a realization of the approach using a real-world ecosystem case study.	information system;requirement;service pack;software ecosystem	Markus Keunecke;Hendrik Brummermann;Klaus Schmid	2014		10.1145/2556624.2556639	simulation;systems engineering;engineering;architecture;software engineering;data mining;management	SE	-60.627863971167145	20.68296753853631	138237
018e9d164cac19d9876b6f620d34ad14ef9b8d93	architecture and design intent: an experience report	graduate course;architectural design;application software;software architecture computer science education public domain software;notation systems;software architecture software design computer architecture documentation software engineering feedback laboratories application software decision making pattern analysis;software engineering tasks;software engineering;experience report;public domain software;computer architecture;software architecture;computer science education;feedback;design approaches;intent based modeling approaches;intent based modeling approaches graduate course software architecture software engineering tasks open source project architectural design notation systems design approaches architectural design features;open source project;pattern analysis;functional requirement;software design;system architecture;architectural design features;documentation;student performance;open source	As part of a graduate course on software architecture and design intent, we designed a class project in which teams of students performed software engineering tasks that required them to understand the design of an open source project and evolve the architectural design in response to a set of additional functional requirements. The students used intent-based design approaches and notation systems to document intent for architectural design features. We use the students' experiences with these methodologies to explore the potential usefulness of intent-based modeling approaches to system architecture, and also to gain insight into directions for further research.	experience;functional requirement;open-source software;software architecture;software design;software engineering;systems architecture	Paul Grisham;Matthew J. Hawthorne;Dewayne E. Perry	2007	Second Workshop on Sharing and Reusing Architectural Knowledge - Architecture, Rationale, and Design Intent (SHARK/ADI'07: ICSE Workshops 2007)	10.1109/SHARK-ADI.2007.4	software architecture;application software;documentation;computer science;systems engineering;software design;software engineering;feedback;public domain software;functional requirement;systems architecture;computer engineering	SE	-56.104706302944464	28.80665024748769	138270
3dedefe9c5e6a713ef79a6f2b8804a4d6f050c3b	integrating network technique into distributed agent-oriented software development projects		The management of local software projects is challenging, due to its complexity. In case of distributed development projects, the complexity in project management increases even more [1]. In this publication we introduce and adapt the well-proven network technique into Paose, a distributed agent-oriented software development approach, by directly integrating a modeling tool for network technique into the development environment of Paose. We support the project participants in modeling their interdependent project activities and reason about them more easily, using an illustrative, graphical syntax. By providing the mapping of network technique diagrams onto Petri nets, we utilize formal semantics and improve integration into our development approach, which is based on Petri nets. The participants of distributed software development projects have to tackle several challenges: Project members, which are organized in sub-teams, perform activities at spacial and temporal distance from one another. These distances have an impact on communication, coordination and control [1]. If, in order to counter these challenges, concepts from agile project management that value self-responsibility are applied, the sub-teams are required to self-organize and self-manage their own activities. Therefore, the sub-teams require support. Naturally, a sub-team has to plan and perform a large number of activities. These activities may depend logically and temporally. Furthermore, not only may dependencies exist between the activities of one single sub-team, but also between activities of multiple sub-teams. Quantities and interdependencies of activities complicate the sub-teams capabilities of planning and scheduling: Statements regarding the duration of the overall project or about efficiently scheduling activities are not made easily by participants of the sub-teams. In order to ease	agile software development;automated planning and scheduling;complexity;diagram;distributed computing;graphical user interface;interdependence;petri net;scheduling (computing);self-organization;semantics (computer science);temporal logic;whole earth 'lectronic link	Christian Röder;Lawrence Cabac	2015			package development process;distributed development;project management;goal-driven software development process;systems engineering;team software process;agile software development;distributed design patterns;software development;computer science	SE	-54.63481038569491	23.436524696114606	138436
a10e0d04ea781b83a725072fa6d1b3f4738b8b4f	building automated data driven systems for it service management	it service management;autonomic computing;feedback control;simulation-based optimization;recommender system	Enterprises and service providers are increasingly challenged with improving the quality of service delivery while containing the cost. However, it is often difficult to effectively manage the complex relationships among dynamic customer workloads, strict service level requirements, and efficient service management processes. In this paper, we present our progress on building autonomic systems for IT service management through a collection of automated data driven methodologies. This includes the design of feedback controllers for workload management, the use of simulation-optimization methodology for workforce management, and the development of machine learning models for event management. We demonstrate the applicability of the presented approaches using examples and data from a large IT service delivery environment.	autonomic computing;itil;machine learning;mathematical optimization;operating system service management;quality of service;requirement;simulation	Yixin Diao;Larisa Shwartz	2017	Journal of Network and Systems Management	10.1007/s10922-017-9430-3	service delivery framework;service provider;systems engineering;it service management;service product management;service level requirement;computer science;service management;distributed computing;service design;customer service assurance;knowledge management	OS	-59.739494579009076	18.875233672935984	138520
e94467ef73b9370b2a78591519eda9facf490dab	reuse contracts as component interface descriptions	reuse contracts;reuse contract;last year;components interact;component interface description;component interface descriptions;external view;current interface description	Current interface descriptions are poor in describing components, because they only provide an external view on a component and they do not lay down how components interact with each other. Suggestions to improve component interface descriptions at last year's workshop are reconsidered and reuse contracts are put forward as a solution that goes one step further.	component-based software engineering;design by contract;floor and ceiling functions;interaction design;modular programming;naruto shippuden: clash of ninja revolution 3	Koen De Hondt;Carine Lucas;Patrick Steyaert	1997		10.1007/3-540-69687-3_69	real-time computing;simulation;computer science	SE	-50.691011470196166	24.705342709372754	138676
b18e54828c877c79955263e96cf28c79009b0b88	the essential components of software architecture design and analysis	information systems;software process improvement;software development process;software architecture;design method;software reusability;software process improvement software development process software lifecycle stakeholder software reuse commercial information system software architecture design;architecture analysis;software architecture design;software process improvement software architecture software reusability information systems;information system;software architecture software design computer architecture design methodology companies software standards standards development programming business information systems;new combination	Architecture analysis and design methods such as ATAM, QAW, ADD and CBAM have enjoyed modest success in recent years and are being adopted by many companies as part of their standard software development processes. They are used in the software lifecycle, as a means of understanding business goals and stakeholder concerns, mapping these onto an architectural representation, and assessing the risks associated with this mapping. These methods have evolved a set of shared component techniques. In this talk I will show how these techniques can be combined in countless ways to create needs-specific methods. I will demonstrate the generality of these techniques by describing a new architecture improvement method called APTIA (Analytic Principles and Tools for the Improvement of Architectures). APTIA almost entirely reuses pre-existing techniques but in a new combination, with new goals and results. Lastly, I will exemplify APTIA’s use in improving the architecture of a commercial information system.	architecture tradeoff analysis method;exemplification;information system;software architecture;software development process	Rick Kazman	2005		10.1109/APSEC.2005.103	reference architecture;software architecture;personal software process;architecture tradeoff analysis method;verification and validation;computer science;systems engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;software walkthrough;resource-oriented architecture;software deployment;goal-driven software development process;software development process;information system;software system;computer engineering;software peer review	SE	-61.00345372442702	23.612390937657207	138684
a21951e86f9289c78c70a9e56f1cb8aab41a7378	classification of and experimentation on tool interfacing in software development environments	databases;mechanism based classification;programming environments;data integrity;software measurement;user interface;uniform tool interfacing architecture;computer architecture;tool interfacing classification;uniform tool interfacing architecture tool interfacing experimentation tool interfacing classification software development environments tool integration user productivity improvement user interface user control data integration mechanism based classification;user productivity improvement;software development environment;software tools;tool integration;programming user interfaces communication system control databases software tools productivity computer architecture computer interfaces software measurement broadcasting;broadcasting;productivity;communication system control;computer interfaces;programming;user interfaces;human resource management;user interfaces software tools programming environments human resource management;software development environments;data integration;tool interfacing experimentation;user control	The eflectiveness of tool integration in software development environments is ultimately measured by its ability in improving the productivity of the user. Traditionally, issues related to tool in&egration are often classified according to aspects of such mechanisms as user interface, control, and data integration which are purely from the viewpoint of the environment developer. This mechanism-based classification has worked well in analying the relevant issues of tool integration. However, its usefulness as a guide to achieving efsective tool integration is limited. In this paper, we introduce an alternative classification scheme aimed at gradual improvement to the eflectiveness of tool integration. As such, this classification scheme provides a guide to tool integration along the line of improving the user’s productivity. In terms of this classification, we compare and experim,ent in depth a variety of integration techniques using a uniform tool interfacing	cellular automaton;comparison and contrast of classification schemes in linguistics and metadata;integrated development environment;software development;user interface	Yun Yang;Jun Han	1996		10.1109/APSEC.1996.566740	human–computer interaction;computer science;systems engineering;human resource management;development environment;user interface;computer engineering	SE	-51.284968781661114	23.583889472630183	138873
6be4ebd74b7434a5e45094372960574c382a67b0	redesigning cscw-systems for network computing-experience from the hotcon project	distributed system;groupware;systems analysis groupware computer networks software reusability client server systems;client server systems;consulting environment cscw systems redesign network computing hotcon project cscw research proprietary cscw systems interoperation comprehensive integration networked global computer environment distributed systems client server paradigm application architectures hotline;global computing;computer networks;computer networks costs application software systems engineering and theory computer architecture distributed computing context software systems videoconference databases;standardisation;client server;systems analysis;software reusability;network computing	The emphasis in CSCW research is currently shifting towards the integration of different existing tools into comprehensive CSCW systems and the interoperation of proprietary CSCW systems. A suitable basis for this integration is provided by concepts from network computing. Comprehensive integration can be achieved by means of the standardisation of components which are to be offered in a totally networked global computer environment. This can cut costs considerably due to the resulting high degree of reusability and opens up the possibility of developing a new quality of distributed systems. Most of today's CSCW systems are constructed according to the traditional client/server paradigm. The migration of these systems towards network computing usually requires a redesign of their architecture. Key features of application architectures for network computing and possibilities to migrate existing software are discussed. The reported experience is based on the HotCon system, a hotline and consulting environment developed at the Fraunhofer ISST.	computer-supported cooperative work	Kurt Sandkuhl;Lutz Nentwig;Sonia Manhart;Petra Lafrenz	1998		10.1109/EMPDP.1998.647215	computer science;systems engineering;database;distributed computing	Theory	-50.854816746945225	19.388512091914926	138983
bb48be500ca887afa40af6cd8a045afef03dd317	impact of aspect-oriented programming on software development efficiency and design quality: an empirical study	developpement logiciel;legibility;empirical study;methode empirique;red www;metodo empirico;orientado aspecto;empirical method;software development efficiency;reseau web;metric;modularite;object oriented programming;software engineering;design quality;web based system development;internet;systems analysis;object oriented;aspect oriented programming;desarrollo logicial;web based system development aspect oriented programming software development efficiency design quality object oriented programming;software development;oriente objet;world wide web;metrico;aspect oriented;modularity;legibilidad;lisibilite;modularidad;systems analysis internet object oriented programming software engineering;orientado objeto;metrique;oriente aspect	The aspect-oriented programming approach is supposed to enhance a system’s features, such as its modularity, readability and simplicity. Due to a better modularization of crosscutting concerns, the developed system implementation would be less complex, and more readable. Thus software development efficiency would increase, so the system would be created faster than its object-oriented equivalent. An empirical study of a web-based manuscript submission and a review system is carried out to examine aspect-oriented vs. object-oriented approach with regard to software development efficiency and design quality. The study reveals that the aspect-oriented programming approach appears to be a fullfledged alternative to the pure object-oriented approach. Nevertheless, the impact of aspect-oriented programming on software development efficiency and design quality was not confirmed. In particular, it appeared that design quality metrics were not significantly associated with using aspect-oriented programming, instead of object-oriented programming. It is possible that the benefits of aspect-oriented programming will exceed the results obtained in this study for experiments with larger number of subjects.	aspect-oriented programming;cross-cutting concern;experiment;human-readable medium;web application	Lech Madeyski;Lukasz Szala	2007	IET Software	10.1049/iet-sen:20060071	simulation;aspect-oriented programming;computer science;systems engineering;software engineering;programming language;object-oriented programming;empirical research	SE	-59.787836340914495	29.8321569787749	139000
c0cb216e4a7ca473487981d3b9fa3aeeecb13bfc	wrapping client-server application to web services for internet computing	wrapping;investments;application software;web and internet services;code standards;web service;emerging technology;business environment;standards development;internet computing;client server;wrapping web services web and internet services service oriented architecture application software investments code standards software standards standards development software packages;web services;software standards;source code;service oriented architecture;legacy system;software packages	Legacy systems are valuable assets for organisations. They have been evolving with new emerged technologies in rapidly changing business environment. Web Services technology and Service-Oriented Architectures (SOA) are rapidly developed and widely supported. It is a very efficient way for developers to reuse existing core business in a legacy system. Reengineering a legacy system to provide Web Services is a great challenge. A tool was developed and called Web Services Wrapper (WSW). The WSW is composed of an Analyser and a Wrapper, which focuses on client-server legacy system with Microsoft .Net. A developer can generate Web Services and related source code according to the rules and constraints step by step with the help of WSW.	.net framework;client–server model;code refactoring;legacy system;programming language;prototype;server (computing);service-oriented architecture;service-oriented device architecture;software developer;visual basic[.net];web service;wrapper function;wrapping (graphics)	He Guo;Chunyan Guo;Feng Chen;Hongji Yang	2005	Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)	10.1109/PDCAT.2005.256	web service;computer science;database;services computing;world wide web	DB	-61.63893209535756	23.217188338283187	139074
ddd13edcc6a6d5e3de94784a9d17bfd7a44d4f6f	scope management of non-functional requirements	de facto standard;project scope;realistic assessment;project risk;project management;cosmic ffp;risk analysis;resource allocation;dp industry;user defined project requirements;resource manager;resource management;software development process;scope management;software engineering;non functional requirement;software development management dp industry project management resource allocation risk analysis;effort estimation;effort estimation process;software projects;software industry;programming size measurement knowledge management engineering management knowledge engineering research and development management software development management resource management taxonomy measurement standards;functional requirement;nonfunctional requirements;software industry scope management nonfunctional requirements software projects realistic assessment project scope user defined project requirements project priorities project risk software development process resource management effort estimation process functional size measurement method cosmic ffp de facto standard;functional size measurement method;software development management;functional size measurement;project priorities	"""In order to meet commitments in software projects, a realistic assessment must be made of project scope. Such an assessment relies on the availability of knowledge on the user-defined project requirements and their effort estimates and priorities, as well as their risk. This knowledge enables analysts, managers and software engineers to identify the most significant requirements from the list of requirements initially defined by the user. In practice, this scope assessment is applied to the functional requirements (FRs) provided by users who are unaware of, or ignore, the non-functional requirements (NFRs). This paper presents ongoing research which aims at managing NFRs during the software development process. Establishing the relative priority of each NFR, and obtaining a rough estimate of the effort and risk associated with it, is integral to the software development process and to resource management. Our work extends the taxonomy of the NFR framework by integrating the concept of the """"hardgoal"""". A functional size measure of NFRs is applied to facilitate the effort estimation process. The functional size measurement method we have chosen is COSMIC-FFP, which is theoretically sound and the de facto standard in the software industry."""	cosmic;cost estimation in software engineering;functional requirement;non-functional requirement;radiation pattern;requirements analysis;software development process;software engineer;software industry	Mohamad Kassab;Maya Daneva;Olga Ormandjieva	2007	33rd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO 2007)	10.1109/EUROMICRO.2007.53	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;business requirements;software project management;systems engineering;engineering;resource management;requirement;software engineering;non-functional testing;management;non-functional requirement;software requirements	SE	-60.26276666032025	27.539112110314907	139181
9505d126b6c9b0c0550373b01dddda5a7946b4d5	defining and validating metrics for assessing the understandability of entity-relationship diagrams	entity relationship diagrams;conceptual data model;model quality;understandability;empirical software engineering;metrics;data model;structural complexity;business environment;conceptual modelling;er diagram;empirical validation;measurement theory;cost efficiency;experimental validation;data modelling;conceptual data modelling;prediction model;experimental research;database design;business and economics;experimentation;theoretical validation;prediction;measure theory;structural properties;entity relationship;maintainability;model evolution	Database and data model evolution cause significant problems in the highly dynamic business environment that we experience these days. To support the rapidly changing data requirements of agile companies, conceptual data models, which constitute the foundation of database design, should be sufficiently flexible to be able to incorporate changes easily and smoothly. In order to understand what factors drive the maintainability of conceptual data models and to improve conceptual modelling processes, we need to be able to assess conceptual data model properties and qualities in an objective and cost-efficient manner. The scarcity of early available and thoroughly validated maintainability measurement instruments motivated us to define a set of metrics for Entity–Relationship (ER) diagrams. In this paper we show that these easily calculated and objective metrics, measuring structural properties of ER diagrams, can be used as indicators of the understandability of the diagrams. Understandability is a key factor in determining maintainability as model modifications must be preceded by a thorough understanding of the model. The validation of the metrics as early understandability indicators opens up the way for an in-depth study of how structural properties determine conceptual data model understandability. It also allows building maintenance-related prediction models that can be used in conceptual data modelling practice. 2007 Elsevier B.V. All rights reserved.	agile software development;conceptual schema;cost efficiency;data model;data modeling;database design;diagram;entity–relationship model;erdős–rényi model;requirement;smoothing	Marcela Genero;Geert Poels;Mario Piattini	2008	Data Knowl. Eng.	10.1016/j.datak.2007.09.011	conceptual model;entity–relationship model;computer science;data mining;database	DB	-56.684531870076334	21.866225267043994	139291
3d3e392a8a2f349f6380a446927ff45be13fac52	eating our own dog food: dsls for generative and transformational engineering	model driven engineering;generative programming;source transformation systems;domain specific languages	"""Languages and systems to support generative and transformational solutions have been around a long time. Systems such as XVCL, DMS, ASF+SDF, Stratego and TXL have proven mature, efficient and effective in a wide range of applications. Even so, adoption remains a serious issue - almost all successful production applications of these systems in practice either involve help from the original authors or years of experience to get rolling. While work on accessibility is active, with efforts such as ETXL, Stratego XT, Rascal and Colm, the fundamental big step remains - it's not obvious how to apply a general purpose transformational system to any given generation or transformation problem, and the real power is in the paradigms of use, not the languages themselves.  In this talk I will propose an agenda for addressing this problem by taking our own advice - designing and implementing domain specific languages (DSLs) for specific generative, transformational and analysis problem domains. We widely advise end users of the need for DSLs for their kinds of problems - why not for our kinds? And we use our tools for implementing their DSLs - why not our own? I will outline a general method for using transformational techniques to implement transformational and generative DSLs, and review applications of the method to implementing example text-based DSLs for model-based code generation and static code analysis. Finally, I will outline some first steps in implementing model transformation DSLs using the same idea - retaining the maturity and efficiency of our existing tools while bringing them to the masses by """"eating our own dogfood""""."""	asf+sdf meta-environment;accessibility;capability maturity model;code generation (compiler);digital multiplex system;domain-specific language;eating your own dog food;ibm personal computer xt;model transformation;problem domain;rascal;static program analysis;txl;text-based (computing)	James R. Cordy	2009		10.1145/1621607.1621609	model-driven architecture;simulation;computer science;domain-specific language;knowledge management;artificial intelligence;programming language	PL	-49.40858733395722	24.458182367794265	139309
b7b70b73adf2af7a412cffc0dee5a440f65f667d	suitability of bpmn correct usage by users with different profiles: an empirical study		A declared purpose of the BPMN standard was to provide a business process modeling language, amenable of being used for modelers regardless of their technical background. This aim was intended to be achieved by extensive documentation of the syntax rules of the notation, as well as by proposed best practices for process modeling from practitioners. The wide acceptance of BPMN standard seems to accomplished the mentioned purpose, namely when considering its usage in business oriented process documentation and improvement scenarios, as well as in IT implementation of process diagrams supported by software tools. However, a relevant question can be raised regarding the correctness of business process diagrams produced by modelers with different profiles. This issue is important since the conformance of produced process diagrams to the syntax rules of the language determines the quality of the modeling process whatever its purpose is. Therefore, the main aim of this work was to gather statistical evidence that could validate the assertion that, BPMN diagrams, they have the same level of correctness, irrespective of the technical profile of people involved in modeling tasks. This paper reports a between-groups empirical study with business-oriented and IT-oriented profiles modelers.		Anacleto Correia;António Gonçalves	2017		10.1007/978-3-319-62392-4_49	software engineering;computer science;mathematical optimization;business process;documentation;empirical research;correctness;business process modeling;business process model and notation;process flow diagram;process modeling	HCI	-55.68149060918118	23.091336942228704	139313
66f19d03d5bb7e9ac8b5e7c785b8ebed8373eaa6	understanding requirements driven architecture evolution in social networking saas: an industrial case study	databases;androids;会议论文;computer architecture;servers;humanoid robots;monitoring;evolving requirements;architecture evolution social netwroking saas sns evolving requirements;architecture evolution;social netwroking saas sns;scalability;computer architecture monitoring servers androids humanoid robots databases scalability	Recently many companies have featured their applications as SaaS (Software as a Service) applications where applications will be treated as services and provided online for thousands and millions of users. Social Networking SaaS (SNS) is one of the most popular kinds of SaaS. The key to the success of a SNS heavily relies on the scale of users. With the explosive growth of users, SNS's architecture should be able to change according to the demand. To better understand what kind of requirements influences SNS's architecture most, and learn the relationships between these requirements and the evolution progress of architecture, this paper carried out a dedicated analysis on a popular SNS application, Instagram. The lessons learned show that: 1) Demands on scalability and real-time are the main driven forces to architecture redesign, 2) Data coming from extensive monitoring is one of the most important sources of evolutionary requirements/issues, which drives different types of architecture evolution, 3) Reusing existing components is the key factor to evolve architecture rapidly and costly. The lessons learned can help engineers and researchers understand the co-evolution progress between requirements and architectures, and how to devise appropriate architectures to meet the possible evolution challenges for SNS.	collective intelligence;commercial software;evolution;instagram;open sound system;real-time clock;real-time computing;real-time transcription;requirement;scalability;software as a service	Dong Sun;Rong Peng;Wei-Tek Tsai	2014	2014 IEEE 8th International Symposium on Service Oriented System Engineering	10.1109/SOSE.2014.27	reference architecture;space-based architecture;scalability;simulation;database-centric architecture;computer science;systems engineering;engineering;humanoid robot;applications architecture;software engineering;database;solution architecture;world wide web;computer security;server	SE	-60.31871680453047	20.829404187591773	139613
0fa56d8a8d66dd8e175a1e2707441d2887d22ae1	quality improvements by integrating development processes	software metrics;software process improvement;software maintenance;software quality software process improvement software metrics configuration management software maintenance quality management;quality improvement;product data management;development process;software configuration management;hardware development quality improvement automatic integrated process product data management hardware products software configuration management software development;process support;software development;datavetenskap datalogi;hardware programming computer science software development management cultural differences software systems engineering management data engineering production collaborative software;configuration management;software quality;quality management	Software is an increasing and important part of many products and systems. Software, hardware, and system level components have been developed and produced following separate processes. However, in order to improve the quality of the final complex product, requirements and prospects for an automatic integrated process support are called for. Product data management (PDM) has focused on hardware products, while software configuration management (SCM) has aimed to support software development. Several attempts to integrate tools from these domains exist, but they all show small visible success. The reason for this is that integration goes far beyond tool issues only. According to our experiences, three main factors play a crucial role for a successful integration: tools and technologies, processes, and people. This paper analyses the main characteristics of PDM and SCM, describes the three integration factors, identifies a model for the integration process, and pin-points the main challenges to achieve a successful integration of hardware and software development. The complexity of the problems is shown through several case studies.	experience;process (computing);requirement;software configuration management;software development	Annita Persson Dahlqvist;Ivica Crnkovic;Ulf Asklund	2004	11th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2004.80	reliability engineering;quality management;software configuration management;computer science;systems engineering;software development;software engineering;software construction;hardware architecture;configuration management;software maintenance;goal-driven software development process;software development process;software quality;software metric;system integration	SE	-62.14650478181817	26.959425504175492	139757
cca569ffdbdd1ef084a2213bd2875df873b96686	a state-based modelling approach to develop component-based control software for flexible manufacturing systems	component based software engineering;java programming;building block;visual design;component based software;ease of use;simulation software;flexible manufacturing;flexible manufacturing system;object oriented;software component;component model;manufacturing system;computer integrated manufacturing	In recent years, component-based software engineering has emerged as an approach to create control software for flexible and adaptive manufacturing systems. This paper presents a state-based approach to model and design software components that can be used as building blocks for flexible manufacturing control software. Adiga and Cogez’s (1993) framework for modelling object-oriented manufacturing software is extended to component-based modelling and work cell control programming. The benefits of using component-based software were fully demonstrated during configuration, integration and execution of Flexible Manufacturing System (FMS) work cell operation in the Miami University Computer Integrated Manufacturing Laboratory (CIMS Lab) by using the control software described in this paper. The software was developed using the Java Programming language and the JavaBeans component model. We emphasized generic features, reusability, ease of use, and ease of maintenance in the design of these software components. We also created simulated software components that can interact with, or replace, real system components for planning, debugging and testing purposes. Once generic software components are developed and stored in a library, users with little or no programming background can rapidly integrate them into control software by using visual design tools.	component-based software engineering;computer-integrated manufacturing;content-control software;debugging;java;library (computing);list of version control software;programming language;simulation;usability	Yu T. Morton;Douglas Troy;George A. Pizza	2003	Int. J. Computer Integrated Manufacturing	10.1080/0951192031000089192	personal software process;verification and validation;software sizing;software verification;computer science;systems engineering;engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;real-time control system software;computer-integrated manufacturing;resource-oriented architecture;software measurement;software deployment;software requirements;manufacturing engineering;software system	Robotics	-49.80252474956363	29.75582587778931	139940
6a86ff3fff5543b4ec2d107a09fc03a4dfd058a1	towards a model-driven iec 61131-based development process in industrial automation*	system modeling;uml;industrial automation systems;iec 61131;development process;model driven development;iec 61499;sysml	The IEC 61131-3 standard defines a model and a set of programming languages for the development of industrial automation software. It is widely accepted by industry and most of the commercial tool vendors advertise compliance with it. On the other side, Model Driven Development (MDD) has been proved as a quite successful paradigm in general-purpose computing. This was the motivation for exploiting the benefits of MDD in the industrial automation domain. With the emerging IEC 61131 specification that defines an object-oriented (OO) extension to the function block model, there will be a push to the industry to better exploit the benefits of MDD in automation systems development. This work discusses possible alternatives to integrate the current but also the emerging specification of IEC 61131 in the model driven development process of automation systems. IEC 61499, UML and SysML are considered as possible alternatives to allow the developer to work in higher layers of abstraction than the one supported by IEC 61131 and to more effectively move from requirement specifications into the implementation model of the system.	abstraction layer;automation;complexity;fully buffered dimm;general-purpose modeling;graphical model;graphical user interface;iec 61131;iec 61131-3;model-driven engineering;model-driven integration;principle of abstraction;programming language;programming paradigm;programming tool;software development process;systems modeling language;unified modeling language	Kleanthis Thramboulidis;Georg Frey	2011	JSEA	10.4236/jsea.2011.44024	reliability engineering;unified modeling language;embedded system;iso/iec 42010;systems modeling;iso/iec 12207;systems modeling language;systems engineering;engineering;software development process;totally integrated automation	SE	-50.51363068478817	25.67174222673597	140052
4e34be3664bb0f59b60cc8c543b1f51ad3dc9023	behavioral conformance of artifact-centric process models	process model	The use of process models in business information systems for analysis, execution, and improvement of processes assumes that the models describe reality. Conformance checking is a technique to validate how good a given process model describes recorded executions of the actual process. Recently, artifacts have been proposed as a paradigm to capture dynamic, and inter-organizational processes in a more natural way. In artifact-centric processes, several restrictions and assumptions of classical processes are dropped. This renders checking their conformance a more general problem. In this paper, we study the conformance problem of such processes. We show how to partition the problem into behavioral conformance of single artifacts and interaction conformance between artifacts, and solve behavioral conformance by a reduction to existing techniques.	artifact (software development);conformance testing;management information system;process modeling;programming paradigm;rendering (computer graphics)	Dirk Fahland;Massimiliano de Leoni;Boudewijn F. van Dongen;Wil M. P. van der Aalst	2011		10.1007/978-3-642-21863-7_4	computer science;process modeling	SE	-54.5805038843663	18.334595826641326	140128
e3235e770de403f82f6a56fd112b457ab184d373	the female contribution in architecting a set of tools for a formal method: role of women in software architecture (short paper)		This paper presents the female contribution on engineering a reference software architecture for ASMETA, a framework for an integrated use of tools developed around the Abstract State Machine formal method. Based on our experience in such a development project, we discuss how feminine mindset and skills can bring concrete advantages, but some disadvantages too, in the creative process of metamodeling, architecting and maintaining software.	abstract state machines;formal methods;metamodeling;software architecture;warez	Silvia Bonfanti;Valentina Centurelli;Elvinia Riccobene;Patrizia Scandurra	2017		10.1145/3129790.3129823	systems engineering;architecture tradeoff analysis method;resource-oriented architecture;computer science;reference architecture;formal methods;software architecture;database-centric architecture;software architecture description;systems architecture	SE	-62.689001321673956	25.000628793767962	140249
0cfbcf98b7071bffe6bfc43940a0a70a22b0ffff	supporting workspace-mediated interaction in collaborative presentations with copowerpoint	technical presentation groupware;groupware;collaborative work;copowerpoint;conference output;workspace mediated interaction;presentation participants interactions;collaborative work sun software systems computer networks collaboration australia software quality hardware collaborative software costs;presentation slides;engineering and technology;faculty of engineering and information technology;collaborative presentation systems;technical presentation;collaborative presentation systems workspace mediated interaction copowerpoint presentation slides presentation participants interactions;299999;effective interaction;professional communication	Effective interaction among participants is crucial to the success of a presentation. The workspace of a presentation, which is the presentation slides, is a natural and effective medium of interactions among presentation participants. However, due to the insufficient support from existing collaborative presentation systems, workspace-mediated interaction is inconvenient in presentations, especially in collaborative presentations. In this paper, we explore typical workspace-mediated interaction forms and analyze their characteristics. Based on this analysis, we present a series of approaches to supporting workspace-mediated interaction in the context of the CoPowerPoint system	algorithm;bruce ellis;causality;coword;communications of the acm;computer-supported cooperative work;entity–relationship model;human factors and ergonomics;human–computer interaction;mixed reality;multi-user;mutual exclusion;operational transformation;real-time transcription;requirement;sigchi;software system;workspace;yang	Steven Xia;David Sun;Chengzheng Sun;David Chen	2005	2005 International Conference on Collaborative Computing: Networking, Applications and Worksharing	10.1109/COLCOM.2005.1651233	human–computer interaction;computer science;multimedia;management;world wide web;collaborative software	HCI	-49.8404218959267	20.492513832759435	140385
15f16cc0d2ca11a4c045cd97f664f7e03fde6f6d	security and safety of assets in business processes	service composition;tool support;bpmn;business process model;monitoring;safety;supply chain;security;resource modeling;business process	Business processes and service compositions are defined independent of the realizing systems. The visualization of security and safety constraints on the business process model level appears to be a promising approach to system independent specification of the security and safety requirements. Such requirements can be realized through business process annotation and used for communication or documentation, but they also can have an execution semantics that allows for automating the security and safety controls.  In this paper, we present a tool-supported framework that extends modeling and execution of business processes with specification, execution and monitoring of the security and safety constraints that are used to protect business assets. We illustrate our approach on basis of a case study modeling a supply chain for perishable goods.	business process;documentation;process modeling;programming language;requirement	Ganna Monakova;Achim D. Brucker;Andreas Schaad	2012		10.1145/2245276.2232045	computer security model;business analysis;business domain;business requirements;goal modeling;computer science;artifact-centric business process model;business process management;information security;business case;process modeling;security service;business process model and notation;supply chain;process management;business process;business process discovery;management;business rule;new business development;business process modeling;business activity monitoring;business architecture	SE	-55.43745745405309	19.943635229331086	140680
295d46ad81c70304c770dd0265850ad4102b4c89	towards a commercial it service delivery	service delivery	The figure illustrates the scope of the project. On the one hand, we analyse Grids by modelling them in terms of Petri nets. Similar models are used for the configuration of the process perspective of Grid middleware (in our case a mixture of Globus and YAWL). On the other hand, we collect event logs via the middleware layer and use these for process mining, process discovery (automatically deriving models by observing the Grid), conformance checking (to check whether ‘the Grid’ is behaving as expected) and model extension (eg to project performance indicators onto a process model).	itil	Christophe Ponsard;Gautier Dallons;Stéphane Mouton;Philippe Massonet	2007	ERCIM News		business process discovery;data mining;performance indicator;grid;service delivery framework;petri net;process mining;conformance checking;computer science;middleware	OS	-53.67984662452016	20.15363093344793	140690
657b637de2b246a660523e25bde60e5c852960a7	towards a precise description of reverse engineering methods and tools	design model;program understanding;cognitive science;formal specification;information systems;software maintenance;reverse engineering techniques;reverse engineering methods;data mining;explicit knowledge;use object recovery scenarios reverse engineering methods reverse engineering techniques design abstractions program understanding incomplete program documentation reverse engineering tools automatic recovery explicit knowledge source language formal mapping source language design model;incomplete program documentation;automatic recovery;reverse engineering tools;data structures;programming profession;source language;humans;computer science;design abstractions;building design;formal specification reverse engineering software maintenance;formal mapping;buildings;use object recovery scenarios;documentation;reverse engineering;source language design model;reverse engineering buildings programming profession information systems computer science documentation data mining humans data structures cognitive science	The potential and limitations of reverse engineering techniques is still a matter of a debate and investigation. Both experimental studies and commonsense tell us that design abstractions are useh1 in program understanding and maintenance. In the case of incomplete program documentation, reverse engineering tools can recover some of the design abstractions from code. However, it is not clear which design abstractions can and which cannot be automatically recovered. This can be attributed to the understandable reluctance of industry to publicize explicit knowledge of this process due to its enormous commercial value and the fact that reverse engineering is a fairly new research discipline. As a start to formalizing what we already know about reverse engineering, we propose a framework for describing and evaluating reverse engineering methods and tools. First, we build design models for a source language and for the recovered design. Then, we describe what a given reverse engineering method or tool achieves as a formal mapping from the source language design model into the recovered design model.. We show use object recovery scenarios to illustrate the presented concepts.	documentation generator;program comprehension;reverse engineering	Stan Jarzabek;Irene Woon	1997		10.1109/CSMR.1997.582995	data structure;computer science;systems engineering;software engineering;programming language;reverse engineering	DB	-55.781133690509044	30.38010020991209	140835
70e8935e7eda7e5ae89e0a9385dbe3553db38811	executable graphic specifications in automation projects			automation;executable	Kari Kaarela;Ari Okkonen	1993			automation;software engineering;systems engineering;executable;computer science	EDA	-49.725761337525746	28.934884061202947	140977
4b0fa6e4e3ffabae6c7ecd2805ca16ee3d7fb6d1	modeling service orchestrations with a rule-enhanced business process language	service composition;best practice;business process model;business process modeling notation;control flow;markup language;business rules;business process	Business process modeling has been a promising direction in developing service compositions, including both service orchestrations and choreographies. This paper fully focuses on the problem of modeling service orchestrations. Despite many promising aspects of using business process modeling (BPM) languages for modeling service orchestrations, this paper aims to demonstrate that: i) best practices (workflow patters) for control flows (primary concern of service orchestrations) are not fully covered in present languages; ii) complete service compositions cannot be completely generated from business process models; and iii) BPM languages have limited support for representing logical expressions, business vocabularies, and business rules, which severely limits their flexibility and expressivity. To address these challenges, we have integrated business rule modeling constructs of the REWERSE Rule Markup Language (R2ML) with the Business Process Modeling Notation (BPMN), resulting in our rBPMN proposal.	beam propagation method;best practice;business process model and notation;markup language;process modeling;r2ml;ruleml;vocabulary	Milan Milanovic;Dragan Gasevic;Gerd Wagner;Vladan Devedzic	2009		10.1145/1723028.1723039	semantics of business vocabulary and business rules;business domain;computer science;knowledge management;artifact-centric business process model;business process management;process modeling;database;business process model and notation;markup language;process management;business process;control flow;business process discovery;management;business rule;business process modeling;business activity monitoring;best practice;business architecture	Web+IR	-55.01396128155367	19.11781016750325	141091
04061c359db0949997af86840de873f33f57b968	open source software for workflow management: the case of yawl	workflow management;lgpl;business process design;yet another workflow language open source software yawl workflow management systems business process design;yawl;industries;public domain software;yet another workflow language;yawl workflow open source workflow management system lgpl;internet;workflow management software;workflow;workflow management system;workflow management systems;software development management industries internet java workflow management software open source software;workflow management software programming languages public domain software;software development management;programming languages;open source software;java;open source	Workflow management systems support business process design, execution, and analysis. They must guarantee that work is conducted at the right time-and by the right person or software application-through the execution of a workflow process model. YAWL (Yet Another Workflow Language) was developed in 2002 to show that comprehensive support for workflow patterns is achievable. Soon after the lan guage's inception, a prototype system was built to show that system support for such a complex language was possible. From that initial prototype, YAWL has grown into a full-fledged open source workflow management system and support environment.	business process;open-source software;process modeling;prototype;workflow pattern;yet another	Michael Adams;Arthur H. M. ter Hofstede;Marcello La Rosa	2011	IEEE Software	10.1109/MS.2011.58	workflow;xpdl;computer science;systems engineering;knowledge management;workflow management coalition;database;windows workflow foundation;programming language;workflow management system;workflow engine;workflow technology	DB	-51.25521629938082	22.13965072329265	141261
2719505559b8167224aa762c492547ae239c18c5	contribution à la gestion de l'évolution des processus métiers. (contribution to the business process evolution management)		The evolution management of the business processes requires an exhaustive understanding of the change. An evolution engineer needs to understand reasons of a change, its application levels, and subsequently its impact on the whole system. In this thesis, we propose an approach for an a priori change impact analysis, to better control the business process evolution. This may help the business experts and the process designers to evaluate change impact in order to reduce the associated risks and estimate the related costs. It may also help to improve the service and quality of the business processes. This work contributes an eventual improvement, in regard, to verify the coherence and the compliance of the business process models, after each change. It leads to evaluate an a priori change impact analysis in structural and qualitative aspects. The multipleperspectives of the proposed approach have been reviewed experimentally. The validation of the approach is evaluated by extending the Eclipse Development Environment, with the help of a set of plug-ins, as a prototype plate-form.	bibliothèque de l'école des chartes;business process;eclipse;evolution;experiment;linear algebra;plug-in (computing);prototype;software engineer	Oussama Mohammed Kherbouche	2013				SE	-56.985278966221976	20.719281194743097	141417
04eaa110ad6bd20fc6baa3c1e4177360b402bb74	robust embedded software design through early analysis of quality faults	fault tolerant;model based approach;quality analysis;software component;design space exploration;software design;fault model;robust design;embedded software	While providing correct functionality has been the thrust of most software design efforts, embedded software poses several additional challenges. Among them is designing robust software which can tolerate inaccurate inputs (coming from degraded sensors), failure of software components, and wearing-out of electro-mechanical parts it controls. For this, a design space exploration is performed and several design options are evaluated for their ability to tolerate quality (or accuracy degradation) faults. While a model-based approach enables an early analysis of quality faults, modeling and analyzing the effects of quality faults is a challenge. In this work we propose a quality fault-tolerance analysis framework which is used on operation-level models of embedded software, and an abstraction of quality-faults suitable for this analysis. The proposed method consists of characterizing individual components of the model, and then using the pre-characterized behaviors to quickly evaluate the software design. Characterization is a one-time effort and results of the same can be reused when a new design is evaluated. This results in additional speedup of upto 6-10X faster evaluation of designs, thereby facilitating a quick early evaluation of design options.	component-based software engineering;design space exploration;elegant degradation;embedded software;fault tolerance;robustness (computer science);sensor;simulation;software design;speedup;thrust	Dipankar Das;P. P. Chakrabarti;Purnendu Sinha	2011		10.1145/1953355.1953360	reliability engineering;fault tolerance;verification and validation;real-time computing;software sizing;embedded software;computer science;systems engineering;engineering;package development process;software design;software reliability testing;software framework;component-based software engineering;software development;software design description;operating system;software engineering;software construction;fault model;programming language;resource-oriented architecture;software fault tolerance;software metric;avionics software	Embedded	-62.0257793272355	31.120059220906946	141703
e7bb76e30f9edcf9afc393c57faabc7fa8733e28	a pattern story for combining crosscutting concern state machines	state machine;state machines;design pattern;crosscutting concerns;design patterns	This paper describes a solution to a real world problem using a combination of well-known patterns. The problem deals with combining state machines that represent core concerns and crosscutting concerns in a loosely coupled manner. The state based behaviors are modeled with state machines and implemented with the State Pattern[3]. The coordination between the loosely coupled state machines is achieved with the Interceptor Pattern[9][11]. The Abstract Factory Pattern[3] is used to shield the original state machine developers from being aware that their state machines are being combined in new and different ways.	abstract factory pattern;cross-cutting concern;finite-state machine;interceptor pattern;loose coupling	Mark Mahoney;Tzilla Elrad	2007	Trans. Pattern Languages of Programming	10.1145/1772070.1772080	real-time computing;state pattern;engineering;data mining;engineering drawing;abstract state machines	SE	-53.513117398473035	29.758719372234594	141775
cd19b09cdc0ee3eb5a20e1d15517e41913042c52	testing of object-oriented programming systems (oops): a fault-based approach	programming language;object oriented software;object oriented programming;object oriented systems;object oriented;test methods	The goal of this paper is to examine the testing of object-oriented systems and to compare and contrast it with the testing of conventional programming language systems, with emphasis on fault-based testing. Conventional system testing, object-oriented system testing, and the application of conventional testing methods to object-oriented software will be examined, followed by a look at the differences between testing of conventional (procedural) software and the testing of objectoriented software. An examination of software faults (defects) will follow, with emphasis on developing a preliminary taxonomy of faults specific to object-oriented systems. Test strategy adequacy will be briefly presented. As a result of these examinations, a set of candidate testing methods for object-oriented programming systems will be identified.	black box;black-box testing;integration testing;programming language;system testing;test set;test strategy;unit testing;verification and validation	Jane Huffman Hayes	1994		10.1007/BFb0014026	first-generation programming language;method;programming domain;reactive programming;object;component-based software engineering;object-relational mapping;common object request broker architecture;programming paradigm;symbolic programming;inductive programming;programming language;object-oriented programming;object-modeling technique;object definition language	PL	-54.64579747918534	32.07774694060901	141821
6529280fd3c4ce43637401d5f3ba00af7da60479	modeling alternatives in exception executions	design tool;search space;business process design;modeling language;automatic generation;execution environment;workflow management system;process model	To date, the ability of a business process designer to produce a solid, well-validated workflow models is limited, especially since all necessary scenarios that need to be covered by the workflow are hard to predict. Workflow management systems (WfMSs), serving as the main vehicle of business process execution, should recognize those limits, and increase its support to designers in this task. One aspect of such assistance is in exception handlers generation. In this paper we propose a model language enrichment for expressing workflow semantics, in the context of alternative solutions, within the process model. Thus, enabling the designer to state which possible alternatives and their applicability to changing execution paths states. Using this enrichment, an inference algorithm can efficiently find an adequate alternative. The model language is used as a basis for a design tool and an execution environment, which semi-automatically generates exception handlers, resulting, due to a reduced search space, in a smaller set of exceptions for the designer/user to choose from.	algorithm;boolean satisfiability problem;business process;design tool;exception handling;gene ontology term enrichment;microsoft outlook for mac;process modeling;prototype;semiconductor industry;workflow engine	Mati Golani;Avigdor Gal;Eran Toch	2007		10.1007/978-3-540-78238-4_7	workflow;real-time computing;computer science;systems engineering;engineering;business process management;software engineering;process modeling;database;windows workflow foundation;modeling language;business process modeling;workflow management system;workflow engine;workflow technology	SE	-53.03289944621338	25.532826933281502	142302
c6b1125afeec4072959a1b3aae74f711112e4c16	on instantiation and integration commutability of design pattern	design pattern	Design patterns capture expert design experience in generic design structure and behavior. To reuse design experience, a design pattern needs to be instantiated from its generic template to the application design in a particular context. It can be integrated with other patterns to solve multiple design problems. The instantiation and integration of design patterns are two important processes when a designer reuses design experience in an application. It is important to know whether the instantiation and integration commute because it can save considerable time and effort of software designers for trial-and-error. In this paper, we investigate the commutability of the instantiation and integration of design patterns. We provide rigorous proofs on the conditions when the order of these two design processes does not matter. Our results allow the software designers to choose the design processes with assurance of their equivalence. The benefits of our work include helping the designers to make informed design decisions based on the convergence of different design processes and reducing the possible design choices, and thus the complexity of software development.	software design pattern;software development;turing completeness;universal instantiation	Jing Dong;Tu Peng;Yajing Zhao	2011	Comput. J.	10.1093/comjnl/bxp125	software design pattern;probabilistic design;behavioral pattern;computer science;software design;design review;conceptual design;management science;design language;design pattern;design education;programming language;design technology;structural pattern;high-level design;design brief;generative design	EDA	-54.64950783217031	26.39348932830001	142443
2555429984169de232c615e3ad8ca1193074398c	essence-based, goal-driven adaptive software engineering		The OMG Essence standard has recently been published as the kernel for software engineering methods [1]. We show that the Essence view of software engineering is reminiscent of a nondeterministic, multidimensional finite state machine, and that the Essence lends support to a semi-Markov decision process model of software engineering which, in practice, facilitates a goal-driven adaptive software engineering. We develop an activity-state mapping algorithm and a goal-activity cover algorithm based on the Essence, which can help automate the health monitoring of project states and the adaptive planning of project activities in a software engineering project.	finite-state machine;markov chain;markov decision process;nondeterministic algorithm;process modeling;semiconductor industry;software engineering	June Sung Park	2015	2015 IEEE/ACM 4th SEMAT Workshop on a General Theory of Software Engineering		domain analysis;verification and validation;software sizing;software verification;search-based software engineering;computer science;systems engineering;software design;theoretical computer science;component-based software engineering;software development;software construction;computer-aided engineering;resource-oriented architecture;goal-driven software development process;software development process;software requirements;software system	SE	-52.004870314576756	26.515768122514913	142524
b6669748fee1a4f885d29b7d6070dd2f314b6306	cedar studio: an ide supporting adaptive model-driven user interfaces for enterprise applications	adaptive behavior;devising example adaptive enterprise;adaptive model-driven user interface;model-driven engineering;adaptive user interface;user interface;adaptive model-driven;ui model;enterprise application;adaptive model-driven enterprise uis;adaptive uis;cedar studio;model driven engineering	Support tools are necessary for the adoption of modeldriven engineering of adaptive user interfaces (UI). Enterprise applications in particular, require a tool that could be used by developers as well as I.T. personnel during all the development and post-development phases. An IDE that supports adaptive model-driven enterprise UIs could further promote the adoption of this approach. This paper describes Cedar Studio, our IDE for building adaptive model-driven UIs based on the CEDAR reference architecture for adaptive UIs. This IDE provides visual design and code editing tools for UI models and adaptive behavior. It is evaluated conceptually using a set of criteria from the literature and applied practically by devising example adaptive enterprise user interfaces.	adaptive behavior;adaptive user interface;attachment unit interface;description logic;enterprise software;integrated development environment;mesa;model-driven architecture;model-driven integration;real life;reference architecture;text simplification;xml	Pierre A. Akiki;Arosha K. Bandara;Yijun Yu	2013		10.1145/2480296.2480332	human–computer interaction;computer science;software engineering;world wide web	HCI	-48.663966861408646	23.624471609377853	142769
c98213d6cb64c808dfd2123a64b6701b7599e1ba	computation independent modeling within the mda	domain model;application software;graph transformation;computer architecture;computational modeling;functional model;mathematical model;computational modeling object oriented modeling computer architecture application software computer integrated manufacturing power system modeling mathematical model programming open systems computer science;computer science;functional requirement;object oriented analysis;power system modeling;formal analysis;open systems;programming;computer integrated manufacturing;use case;model driven architecture;object oriented modeling	"""Object oriented analysis suggests semiformal use case driven techniques for problem domain modeling from a computation independent viewpoint. The proposed approach called Topological Functioning Modeling for Model Driven Architecture (TFM4MDA) increases the degree of formalization. It uses mathematical foundations of Topological Functioning Model (TFM) that holistically represents complete functionality of the system. The TFM4MDA introduces more formal analysis of a business system, namely enables defining not what the client wants, but what the client needs, and also enables textual functional requirement checking, missing requirement checking in conformance with the problem domain """"as is"""" model. A use case model of the application is defined with the help of a goal-based method. A domain concept model is defined by graph transformation of the TFM. The paper also suggests an Eclipse plug-in conception for the implementation of the TFM4MDA."""	computation;conformance testing;eclipse;functional requirement;graph rewriting;holism;model-driven architecture;plug-in (computing);problem domain	Janis Osis;Erika Asnina;Andrejs Grave	2007	IEEE International Conference on Software-Science, Technology & Engineering (SwSTE'07)	10.1109/SwSTE.2007.20	object-oriented analysis and design;use case;programming;application software;computer science;systems engineering;function model;theoretical computer science;software engineering;domain model;mathematical model;computer-integrated manufacturing;open system;programming language;management;computational model;functional requirement	Robotics	-49.585120160109426	26.091595009152268	143010
c601b629389ecd0ca9bd2e451eca0c4dcaeb61f2	combined analysis of user interface and domain requirements	domain model;formal specification;user interface;direct manipulation;task model;formal specification user interfaces user centred design;development process;automatic generation;requirement analysis;user interfaces object oriented modeling software prototyping prototypes performance analysis error analysis interactive systems software design visualization;levels of abstraction;intermediate stages user interface domain requirements requirements analysis method fluid direct manipulation user interfaces task model basic dialog behavior domain model components screen layout dialog behavior requirements analysis semi automatic generation user interface prototypes;allgemeine werke;000 informatik;user centred design;user interfaces;informationswissenschaft	A requirements analysis method called FLUID is proposed which in contrast to conventional methods explicitly captures the requirements of direct manipulation user interfaces. The main concepts addressing the user interface requirements comprise a task model and a UIA model. The latter reveals the essential structure of the user interface and defines the basic dialog behavior, the presentation of domain model components on the screen, and links to the domain model. User interface requirements are described on a level of abstraction similar to that of conventional requirements, e.g. details of screen layout and dialog behavior are deferred to later development stages. The result of the entire requirements analysis-a combination of domain model and UIA model-serves as a basis for the further development process. The method also provides for (semi) automatic generation of user interface prototypes at intermediate stages of the analysis.	requirement;user interface	Georg Kösters;Hans-Werner Six;Josef Voss	1996		10.1109/ICRE.1996.491445	user interface design;simulation;human–computer interaction;computer science;systems engineering;engineering;software engineering;user interface	SE	-48.31073661597965	23.44708611780712	143111
64552bc4165cee2830d76664210dc14c7a206128	yazilim test simulatorleri gelistirilmesinde yazilim urun hatti yaklasiminin kazanimlarina dair bir eylem arastirmasi		Software Product Line approach enables improved variability management by handling similar software products as a whole and expressing commonalities and variabilities implicitly which leads to high software reuse levels. This approach increases product quality, decreases costs and time-tomarket. In this work, firstly, problems encountered in software development efforts performed in scope of simulator development for software testing of RADAR projects are discussed. Later, SPL approach is proposed to deal with these problems. It is observed that having much similarities between software products enabled increased SPL benefits. Reuse levels and quality of products are improved, costs are reduced and common look-and-feel is ensured. In this paper, convenience of SPL approach to the software development for software testing and its benefits are examined by measurements and analysis. Anahtar Kelimeler: Yazılım Test, Yazılım Ürün Hattı, Simülatör, Yazılım Geliştirme İyileştirmesi	code reuse;common look and feel;radar;software development;software product line;software testing;spatial variability	Muhittin Erdem Ergul;Halil Ibrahim Balci	2016				SE	-59.36383823737227	28.814957261288406	143301
e4a3c99bfb1f9634cc030699cb16e33d7baa1610	capis model based software design method for sharing experts' thought processes	expert systems;causality of problem issue solution;conceptual model;software engineering;uml class diagram;large scale;uml class diagram software design causality of problem issue solution;software engineering causality expert systems;software design ontologies reliability engineering design engineering large scale systems real time systems buildings unified modeling language computer integrated manufacturing computer science;software design;causality;real time systems	"""In large-scale, real-time systems, the software design process is still highly dependent on the skills of the developers. To enable the efficient, speedy design of reliable software products, we require a means of conveying design decisions from experts to other engineers. Our approach involves the development of the """"causality of problem-issue-solution"""" (CAPIS) model which can be used to represent experts' thought processes. The CAPIS model divides a thought process that includes complexity and diversity into problems, issues, and solutions (PIS), and then describes conceptual models based on the knowledge hierarchy of data, information, knowledge, and wisdom. The PIS ontology is used to describe items in the conceptual models. This paper describes a software design method that is based on this CAPIS model. As an example, we consider the thought processes involved in building reliability into a UML class diagram"""	causality;class diagram;dikw pyramid;design rationale;real-time computing;real-time locating system;software design;software portability;uml tool;unified modeling language;usability	Katsunori Oyama;Atsushi Takeuchi;Hiroshi Fujimoto	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.34	personal software process;model-driven architecture;software engineering process group;causality;uml tool;computer science;systems engineering;engineering;function model;artificial intelligence;conceptual model;software design;social software engineering;theoretical computer science;component-based software engineering;software development;software design description;software engineering;applications of uml;class diagram;domain model;software construction;data mining;database;systems development life cycle;software walkthrough;programming language;computer-aided software engineering;expert system;goal-driven software development process;software development process;software system	SE	-60.8001785907614	23.171134559290575	143685
abdc3af152af8bca51fecaeaeeefb9b60b086d4e	applying a selection method to choose quality attribute techniques	risk management;quality attribute techniques;ahp;technique selection	Context: Software products have requirements on various software quality attributes such as safety and performance. Development teams use various specific techniques to achieve these quality requirements. We call these “Quality Attribute Techniques” (QATs). QATs are used to identify, analyse and control potential product quality problems. Although QATs are widely used in practice, there is no systematic approach to represent, select, and integrate them in existing approaches to software process modelling and tailoring. Objective: This research aims to provide a systematic approach to better select and integrate QATs into tailored software process models for projects that develop products with specific product quality requirements. Method: A selection method is developed to support the choice of appropriate techniques for any quality attribute, across the lifecycle. The selection method is based on three perspectives: 1) risk management; 2) process integration; and 3) cost/benefit using Analytic Hierarchy Process (AHP). An industry case study is used to validate the feasibility and effectiveness of applying the selection method. Results: The case study demonstrates that the selection method provides a more methodological and effective approach to choose QATs for projects that target a specific quality attribute, compared to the ad hoc selection performed by development teams. Conclusion: The proposed selection method can be used to systematically choose QATs for projects to target specific product qualities throughout the software development lifecycle.	computer performance;hoc (programming language);list of system quality attributes;process modeling;requirement;risk management;selection (genetic algorithm);software development process;software quality	Yin Kia Chiam;Mark Staples;Xin Ye;Liming Zhu	2013	Information & Software Technology	10.1016/j.infsof.2013.02.001	reliability engineering;analytic hierarchy process;risk management;computer science;systems engineering;engineering;data mining;management	SE	-60.69180822924373	26.174489527377126	143729
a97e4702e2c1b09051a907f44240d4a7a2205b57	policy-directed coordination and cooperation	model specification;concurrent computing;software systems;testing;communication system software;communication system software process design software systems laboratories programming profession concurrent computing humans testing;process design;programming profession;active objects;humans;process model;partial order	Modeling such a process requires design decisions about the granularity of the process activities, about the degree of prescription defined within those activities, and about the policies that govern the triggering and termination of the activities and that define the nature of interaction and communication among the programmers evolving the system. Whatever choices are made for these issues, the resulting process is of necessity one with concurrent, independent, and asynchronous activities — that is, there will be multiple and different activities acting on the multiple and different states of the product. The critical issue is that of coordinating and synchronizing these independent activities.	asynchronous i/o;concurrent computing;programmer	Dewayne E. Perry	1991		10.1109/ISPW.1991.637546	real-time computing;simulation;computer science;systems engineering	HCI	-50.14488508025896	30.269775596841203	144047
98ef301caaf4b5f42334cb4f9716894a86fe7dcc	livelock and deadlock detection for pa inter-organizational business processes	suitable approach;deadlock detection;inter-organizational business processes;specific bpmn;business process result;business process;eclipse platform;public administration officies;inter-organizational business process detection;eclipse bpmn;pa inter-organizational business process;public administration domain	The Public Administration domain is characterized by the dominance of inter-organizational Business Processes. These are a set of interrelated and sequential activities shared and executed by two or more Public Administration officies to achieve a business objective that is of value to citizens or companies in term of services. A Business Process results from the un-trivial integration of internal administration processes, so that structural problems such as livelock or deadlock may easily occur and in reality they are generally solved by involved civil servants. Nevertheless with the shift versus an electronic government this problem becomes particularly relevant. The paper presents a suitable approach for inter-organizational Business Process detection of livelock and deadlock situations. In particular, we introduce an approach to directly verify a Business Process modeled using the BPMN 2.0 semi-formal notation. The verification uses a state evaluation technique with an optimized unfolding algorithm considering specific BPMN 2.0 characteristics. A plugin for the Eclipse platform has been also developed, which permits to have an integrated environment in which to design Business Process, using the Eclipse BPMN 2.0 Modeler, and to automatically verify it. The approach and the tool prototype have been successfully applied to real scenarios such as family reunion, grant citizenship and buoncer registra-	algorithm;anti-pattern;business process model and notation;comparison of command shells;deadlock;e-government;eclipse;harsh realm;interaction;modeling language;pa-risc;prototype;semiconductor industry;tracing (software);unfolding (dsp implementation)	Damiano Falcioni;Andrea Polini;Alberto Polzonetti;Barbara Re	2012		10.1007/978-3-642-32701-8_12	simulation;business domain;computer science;artifact-centric business process model;artificial intelligence;operations management;management science;business process model and notation;public administration;business process discovery;management;business rule;world wide web;computer security;business process modeling	SE	-54.51720837432464	18.737606279244464	144056
20dfaaa3a7fe0a272a3da830d77a1556326e8e10	modeling regulatory ambiguities for requirements analysis		Lawyers and policy makers regularly and intentionally use ambiguous language in laws, regulations, and other legal texts. Although ambiguity has important policy benefits, such as interpretive resilience in an ever-changing world, it frustrates engineers and businesses seeking to build software systems that are demonstratively compliant with legal obligations. In this vision paper, we propose a method for modeling legal texts alongside models of software requirements or design artifacts. Our approach allows engineers to reason about regulatory ambiguity separately from their system under development and then trace interpretive decisions made about the legal text to affected requirements models. When a regulation is updated or case law demands a new interpretation of a regulation, engineers can evaluate the effect of the changes on the current design and respond appropriately. Inspired by User Requirements Notation, our proposed method can be implemented as an extension to Legal-GRL.	requirement;requirements analysis	Aaron K. Massey;Eric Holtgrefe;Sepideh Ghanavati	2017		10.1007/978-3-319-69904-2_19	software system;computer science;ambiguous grammar;data mining;management science;ambiguity;requirements engineering;notation;software requirements;user requirements document;requirements analysis	Logic	-57.134986995859634	20.86869441941351	144058
486f6668bba94b2dfcc8b227fd57656ae80b49fe	supporting the evolution of model-driven service-oriented systems: a case study on qos-aware process-driven soas	domain model;incremental development;requirement change;industrial case study;requirement change model driven service oriented system qos aware process driven soa service oriented architecture compliance requirement quality of service qos constraint service level agreement incremental development model driven development telecom service;formal specification;telecom service;dsl;availability;service orientation;model driven development;service oriented architecture formal specification quality of service;monitoring;compliance requirement;syntactics;domain specific language;telecommunication services;service level agreement;qos constraint;quality of service;quality of service dsl availability service oriented architecture telecommunication services syntactics monitoring;service oriented architecture;model evolution service oriented architecture case study domain specific language model driven development;qos aware process driven soa;model evolution;model driven service oriented system	Process-driven service-oriented architectures (SOA) need to cope with constant changing requirements of various compliance requirements, such as quality of service (QoS) constraints within service level agreements (SLA). To the best of our knowledge, only little evidence is available if and in how far process-driven SOAs deal with the evolution of the requirements. In this work, we evaluate an incremental and model-driven development approach on the evolution of the requirements and the domain model in the context of an industrial case study. The case study focuses on advanced telecom services that need to be compliant to QoS constraints. This paper answers questions about the applicability of the incremental development approach, the impact of requirement changes, possible drawbacks of using a non-incremental development approach, and general recommendations based on the findings. Our results provide guidelines for dealing with the evolution of model-driven service-oriented systems.	domain model;evolution;iterative and incremental development;model-driven architecture;model-driven engineering;model-driven integration;programming paradigm;quality of service;requirement;service-level agreement;service-oriented architecture;service-oriented device architecture	Ernst Oberortner;Uwe Zdun;Schahram Dustdar;Agnieszka Betkowska Cavalcante;Marek Tluczek	2010	2010 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)	10.1109/SOCA.2010.5707172	availability;real-time computing;digital subscriber line;quality of service;computer science;domain-specific language;telecommunications service;service-oriented architecture;iterative and incremental development;domain model;formal specification;programming language	SE	-55.03814283647195	19.407663841348096	144163
12798993cdee2f6a6860d7653c57801c78af83ea	a method level based approach for oo integration testing: an experimental study	software testing;object oriented software integration testing;wireless networks;integration testing;object interaction;java programs object oriented software integration testing class integration testing class dependency model;java programming;automatic testing;distributed computing;object oriented software;object oriented programming;software engineering;program testing;object oriented;integrated software;artificial intelligence;java programs;class integration testing;java object oriented programming program testing integrated software;class dependency model;automatic testing software testing software engineering artificial intelligence distributed computing conferences wireless networks;conferences;java	Objects interact in order to implement behavior. One important problem when integrating and testing object-oriented software is to reduce the number of required test stubs and to determine an effective class integration order. The strong connectivity between classes complicates this task. We present, in this paper, a new class integration testing strategy based on a new class dependency model (CDM). The CDM model takes into account the interactions between classes. In order to validate our approach and to compare it to some of the existing object-oriented integration strategies, we conducted an experimental study on several real-world Java programs. The obtained results show that the strategy we propose reduce considerably the number of required test stubs.	conceptual schema;experiment;integration testing;interaction;java;test stub;trionic	Linda Badri;Mourad Badri;Velou Stéphane Blé	2005	Sixth International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing and First ACIS International Workshop on Self-Assembling Wireless Network	10.1109/SNPD-SAWN.2005.4	real-time computing;white-box testing;computer science;operating system;software engineering;distributed computing;programming language;object-oriented programming	SE	-54.30121145336257	31.78536262744268	144176
d4746fa0a86cf5d144720e32643a1480dea3525e	an optimization model for software component selection under multiple applications development	application development;developpement logiciel;modelizacion;ajustamiento modelo;selection problem;model selection;optimisation;entreprise;problema seleccion;experimental analysis;domain engineering;reusability;optimizacion;component based software engineering;components selection;componente logicial;cout developpement;multi applications development;optimal method;development cost;empresa;composant logiciel;compatibilidad;selection modele;software engineering;ajustement modele;modelisation;seleccion modelo;component based software development components selection reusability multi applications development optimization model experimental analysis;desarrollo logicial;model matching;software reusability;firm;software development;software component;reutilizacion de logicial;compatibility;reutilisation logiciel;genie logiciel;cost effectiveness;compatibilite;optimization;component based software development;modeling;ingenieria informatica;journal magazine article;optimization model;probleme selection	Component based software development (CBSD) is well acknowledged as a methodology which establishes reusability of software and reduce development cost effectively. While developing enterprise application using component based software engineering (CBSE) methods, software component selection plays a very important role in the process of component retrieval, adaptation and assembly. However, most of current researches focus on technical aspects from domain engineering and application engineering to improve reusability and system efficiency rather than application of optimization methods in CBSD management, especially application in component selection. Moreover, few existing researches have concerned about the situation where a software developer or enterprise develops multi-applications at the same time. By introducing the concept of reusability and a new formulation of compatibility matrix, an optimization model is proposed to solve component selection problem considering reusability and compatibility simultaneously. The model can be used to assist software developers in selecting software components when multi-applications are undertaken concurrently. Four experiments are conducted with the purpose to provide some insights in management perspective. 2011 Elsevier B.V. All rights reserved.	assembly language;component-based software engineering;domain engineering;enterprise software;experiment;mathematical optimization;selection algorithm;software developer;software development	Jiafu Tang;Li-Feng Mu;Chun-Kit Kwong;Xinggang Luo	2011	European Journal of Operational Research	10.1016/j.ejor.2011.01.045	reusability;verification and validation;simulation;software engineering process group;software sizing;search-based software engineering;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software construction;resource-oriented architecture;software deployment;software development process;software requirements;software metric;software system	SE	-61.23739940308101	28.57951852503092	144205
6c3171368373ced98bad0b598445ffed5e82dcb5	decision-model-based code generation for sple	analytical models;software;graph theory;fast process;decision model based code generation for sple;articulo;code generation;decision model based code generation;software reusability decision theory graph theory product development program compilers;testing;flow graphs;java analytical models computer architecture software book reviews testing flow graphs;software product line engineering;code generation software product line engineering decision model;computer architecture;graph walking algorithms decision model based code generation sple software product line engineering fast process;graph walking algorithms;decision theory;software reusability;decision model;book reviews;program compilers;sple;java;product development	Software product line engineering (SPLE) takes advantage of the commonalities and predicts variabilities among members of a family to create efficient means of producing those members. Different approaches use different methods for defining the product line and producing members of the product line. We describe and demonstrate through a case study the FAST process for achieving generation of members of the product line. The case study introduces the idea of representing constraints among variabilities as edges in a graph and using different graph walking algorithms to generate members of the product line.	algorithm;software product line	David M. Weiss;J. Jenny Li;J. Hamilton Slye;Trung T. Dinh-Trong;Hongyu Sun	2008	2008 12th International Software Product Line Conference	10.1109/SPLC.2008.42	decision model;decision theory;computer science;systems engineering;graph theory;theoretical computer science;operating system;software engineering;software testing;programming language;java;code generation;new product development	SE	-54.48962196781576	32.12825169939065	144510
d8dcd4f9e1d8887161833726f7c96788a765716e	a culture for small frameworks		Object-oriented frameworks play an important role in many IT projects these days as they allow to reuse not only code, but also concepts and designs. Ideally, a framework evolves from experiences made while building several similar applications (Brugali Menga Aarsten 1997, Johnson Roberts 1998). A team that can rely on year-long experiences in an application domain stands the best chance for finding the right abstractions for a framework. Sometimes, however, the need for a framework arises on a much shorter timescale. Think of a large development project in which several applications are going to be built. In its initial stage, the project might identify a certain functionality that several applications will require. The idea of building a framework springs to mind, so that this functionality can be reused wherever it is needed. It might therefore be an option to decide to build a framework dynamically during the project. Such a context, however, is tricky. Building a framework requires generalisation from concrete problems. But as the framework and the applications will be built more or less simultaneously, such generalisation will be particularly difficult. In addition, the time frame for developing the framework is rather short, since the framework must become available during application development. Is this even possible? Is there a chance that in such a context a framework can live up to its promise — the reuse of concepts and designs? This paper presents a collection of patterns that address these questions, focusing on principles and strategies that offer a clear benefit when you are to develop a framework on the fly.	application domain;data access;mind;on the fly;plop;software framework	Andreas Rüping	2003			systems engineering;actuator;bearing (mechanical);computer science;mechanical engineering;receptacle	PL	-59.96159458543788	22.16416542529603	144543
161ed562cf1b2573e54aa78a8893229d2cef8759	visualizing composition and behavior of the iso/iec 33000 assessment framework through a multi-layer model		Abstract Software Process Improvement (SPI) models are a very important topic for SPI practitioners and software engineering students hence is required to improve comprehension about process assessment models. This paper proposes a visual tracking of the ISO/IEC 33000 Assessment Framework through a multi-layered representational model describing the standard in a highly practical way via structural and behavioral views and graphical reporting. This kind of representation comprises several semantic layers according to model dimensions and including, besides an additional dimension for specifying measurements. The structural elements of the model are assigned on distinct layers and connected among them with connectors of dependence and co-occurrence when applying the Assessment Model to software processes. The representation model was tested by software developers, academic experts and software students.		Alvaro Fernández del Carpio	2018	Computer Standards & Interfaces	10.1016/j.csi.2018.04.008	software development process;computer science;real-time computing;systems engineering;software;comprehension;composition (visual arts)	HCI	-54.7004522518641	23.590769622207983	144698
ac3fef6e2818dd2ef107a7621ded35b72ab4af4e	formal engineering methods for software quality assurance	shaoying liu 传统软件工程 质量保证 软件开发方法 形式化方法 软件工程技术 软件生产率 软件质量 数学符号 formal engineering methods for software quality assurance	Conventional software engineering on the basis of informal or semi-formal methods is facing tremendous challenges in ensuring software quality. Formal methods have attempted to address these challenges by introducing mathematical notation and calculus to support formal specification, refinement, and verification in software development. Their theoretical contributions to the discipline of software engineering are significant. However, in spite of their potential in improving the controllability of software process and reliability, formal methods are generally difficult to apply to large-scale and complex systems in practice because of many constraints (e.g., limited expertise, complexity, changing requirements, and theoretical limitations). Researches on the integration of formal methods into conventional software engineering technologies and processes are likely to create effective ways to transfer formal methods to industry for software productivity and quality. One of the examples is the development of the structured object-oriented formal language (SOFL) and its associated SOFL method for industrial software development. To promote this kind of research, the terminology “formal engineering methods (FEM)” was formally proposed when the first international conference on formal engineering methods (ICFEM’97) was organized in Hiroshima in November 1997. Due to many research activities over the last twenty years, formal engineering methods have gradually become an exciting and important research area. Its further development is expected to ultimately lead to a breakthrough in overcoming the problem of the software crisis in software engineering. As the first special issue on formal engineering methods in the field, this issue includes four articles contributed by excellent individual researchers or groups, reporting their progress in research or experience in application. In his article “The use of mathematics in software quality assurance”, Parnas points out that ultimately, the quality of software rests on three legs: rigour, testing, and qualified personnel, and describes how rigour can be achieved by using mathematics on the basis of his past experiences. The article “rCOS: a formal model-driven engineering method for component-based software” by Liu and Stolz introduces a formal model-driven software engineering method rCOS. The focus of this paper is on how the method can be used in a software development process, illustrating what models need to be constructed, what and how validation can be done for them, and which major model transformations can effectively support the design activities. The article “An institution theory of formal meta-modelling in graphically extended BNF” by Zhu emphasizes the importance of building a theoretical foundation for a meta-modeling approach that supports model-driven software development. The paper points out that meta-modelling can be performed by defining the abstract syntax of a modelling language in graphically extended BNF (GEBNF) and by formally specifying the constraints on models in the formal logic language induced from GEBNF. The article “SeVe: automatic tool for verification of security protocols” by Luu et al. is concerned with a framework for specifying security protocols in the labeled transition system (LTS) semantics model, which embeds the knowledge of the participants and parameterizes the ability of attacker. The paper describes the formal definitions for three types of privacy properties based on	abstract syntax;beta normal form;complex systems;component-based software engineering;finite element method;formal language;formal methods;formal specification;mathematical model;metamodeling;model-driven engineering;modeling language;privacy;refinement (computing);requirement;semiconductor industry;software crisis;software development process;software quality assurance;transition system	Shaoying Liu	2012	Frontiers of Computer Science	10.1007/s11704-012-2900-6	program assurance;software security assurance;quality assurance;verification and validation;software engineering process group;computer science;social software engineering;software development;software engineering;software construction;software quality control;software requirements;software quality;software quality analyst	SE	-58.24494736942474	26.050716305116584	144716
34fe3c7d22b17e4856fdf4c20f70343e79d86be6	using quality models for assessing cots selection		We present in this paper a framework embracing different aspects involved in COTS component selection that influence the success of this activity. Playing a crucial role in this framework appears the concept of quality model, aimed at structuring the description of the quality of COTS components. We propose a methodology for building quality models based on the ISO/IEC 9126-1 standard which allows to create hierarchies of models appropriate for categories and domains of COTS components, and also for particular contexts of COTS selection activities. Such quality models facilitate the expression and refinement of quality requirements during COTS selection. We present also a formal notation for expressing these quality models, the quality requirements and the product descriptions themselves; the notation supports model analysis and makes feasible tool support during COTS selection. Last, we enumerate at the conclusions some issues matter of current and future research.	enumerated type;iso/iec 42010;iso/iec 9126;refinement (computing);requirement	Pere Botella;Xavier Burgués Illa;Juan Pablo Carvallo;Xavier Franch;Carme Quer	2002			notation;reliability engineering;computer science;systems engineering	SE	-56.049959317252664	24.861292606385998	144830
92796048c51583e7a10f6c74e3f13d7b4921d585	an extensible model-based framework for robotics software development	software;robot sensing systems;mobile robots;computer architecture;unified modeling language;robot kinematics	In order to promote reuse of software in robotics, standardization, benchmarking, and formalization activities in robotics are being undertaken by many technical working groups and independent agencies. Absence of integrated tools is the real barrier that exists between early adopters of such efforts and early majority of research and industrial community. In this paper, we provide a detailed discussion on how frameworks for designing robotic systems can be formally specified and developed using our meta-framework - SafeRobots. We have demonstrated this process using a mobile robot case study.	feasible region;integrated development environment;mobile robot;relevance;robotics;software deployment;software development;software system;vii	Arunkumar Ramaswamy;Bruno Monsuez;Adriana Tapus	2017	2017 First IEEE International Conference on Robotic Computing (IRC)	10.1109/IRC.2017.21	outline of robotics;robot learning;embedded system;simulation;computer science;systems engineering;robotic paradigms;adaptable robotics;geography of robotics;future of robotics	Robotics	-55.34339993582639	21.619657255732452	144872
3f49adafbec3e5fa494242f445c1f69d483b2a43	towards explicit representation of architectural design assumptions	architectural design;formal specification;architecture description language;software systems;adl architecture description languages software architecture structural software aspects domain knowledge formal specification software reuse;domain knowledge;software architecture;specification languages;software development;formal specification software architecture specification languages;software systems software architecture programming ontologies architecture description languages computer architecture application software information technology electronic mail costs;requirement specification	Architecture Description Languages (ADLs) are means to specify software architectures. During the last years, a nuniber of ADLs addressed structural aspects of software systems. However, constructing Architecture Descriptions (ADS) requires specific types of domain knowledge and introduces specific restrictions on the problems to be solved. Such requirements and restrictions play a key role in specibing, reusing and evolving ADS, in acquiring domain knowledge, and in defining the problems to be tackled by the software systems. In this paper, we discuss the different roles that assumptions play in architecture-centered software development and we derive the requirements for capturing them as part of an ADL We show how such requirements introduce bias for ADL formalisms.	architecture description language;requirement;software architecture;software development;software system	John J. Kyaruzi;Jan van Katwijk	2000		10.1109/ASE.2000.873670	domain analysis;multilayered architecture;functional software architecture;reference architecture;software architecture;software requirements specification;architecture description language;computer architecture;database-centric architecture;architectural pattern;computer science;applications architecture;software design;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;formal specification;software architecture description;programming language;resource-oriented architecture;domain knowledge;systems architecture;software system	SE	-53.0607139960795	27.682802131768156	145181
6156dc1a3d4cf809d939b5073611b2e180317547	reuse in hazard analysis: identification and support	argument structure;adaptacion;problema reemplazo;tool support;securite;analisis estructural;reutilizacion;replacement problem;riesgo accidente;reuse;probleme remplacement;risque accidentel;adaptation;safety;analyse structurale;structural analysis;seguridad;hazard;hazard analysis;reutilisation	This paper investigates the nature of hazard analysis reuse over two case studies. Initially reuse in an existing safety argument is described. Argument structures within the hazard analysis are identified and the amount of verbatim reuse examined. A second study is concerned with how reuse changes as a result of tool support. In contrast to the first case, the defined arguments are more diverse reuse has occurred but is less verbatim in nature. Tool supported argument adaptation has aided the customisation of the reused arguments.	hazard analysis;personalization	Shamus P. Smith;Michael D. Harrison	2003		10.1007/978-3-540-39878-3_30	hazard;engineering;hazard analysis;reuse;structural analysis;adaptation	SE	-59.69059671700567	31.036514785650663	145230
4f49e98e5bc336b6c3fe0e9667a20259c1b585b4	towards efficient functional safety certification of construction machinery using a component-based approach	automotive electronics;certification;construction equipment;machinery;safety;automotive domain implement safety critical functionality;component-based approach;construction equipment industry;construction machinery;cost modeling;development project;electronic automotive system;electronic system;functional safety certification;functional safety standard;product line approach;safety certification process;safety critical product variant;time consuming;vehicle variants;vehicles;component based development;cost modeling;functional safety;safety certification	Electronic systems in the automotive domain implement safety critical functionality in vehicles and the safety certification process according to a functional safety standard is time consuming and a big part of the expenses of a development project. We describe the functional safety certification of electronic automotive systems by presenting a use case from the construction equipment industry. In this context, we highlight some of the major challenges we foresee, while using a product line approach to achieve efficient functional safety certification of vehicle variants. We further elaborate on the impact of functional safety certification when applying the component-based approach on developing safety critical product variants and discuss the implications by cost modeling and analysis.	component-based software engineering;embedded system	Stephan Baumgart;Joakim Fröberg;Sasikumar Punnekkat	2012	2012 Third International Workshop on Product LinE Approaches in Software Engineering (PLEASE)		systems engineering;engineering;automotive engineering;functional safety;manufacturing engineering	SE	-57.025733031498035	24.20037991156753	145293
337baaac2268834a710bac5b90ac14bc8a75a281	a framework design for connected television	performance test;telecommunication computing;television receivers;reference set top box framework design software framework connected television framework television receivers remote processing free software tools;software framework;software tools;software digital tv delay effects time measurement internet user interfaces;set top box;free software;television receivers software tools telecommunication computing	This paper presents a software framework to implement connected television. The connected television framework is responsible to support applications running on the television receivers, but also to take advantage of remote processing. It was developed a framework based on free software tools and implemented on a reference set-top box. Sample applications were developed and a set of performance tests was ran. The work results show a framework that is based on free software and that had satisfactory performance.	set-top box;software framework	Laisa Caroline de Paula Costa;Alfredo Maruffa;Wellington Carvalho;Marcelo Knörich Zuffo	2012	2012 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2012.6162030	embedded system;real-time computing;computer science;package development process;backporting;software framework;software development;software design description;operating system;software construction;software deployment;software quality;software system;computer engineering	Robotics	-48.97683802082937	30.7956794734322	145589
8ac2b6a0457798e9bbe9c9a96a17636142e09720	an automatic system modeling framework for information system engineering	object oriented model;object oriented methods;information systems;system modeling;rule based;systems engineering;object transformation object oriented automatic system modeling framework information system engineering software process modelling incremental guidance rule based object model domain knowledge;information systems systems engineering and theory object oriented modeling guidelines stability navigation computer science specification languages impedance feedback;information systems systems engineering object oriented methods knowledge based systems computer aided software engineering;engineering system;domain knowledge;computer aided software engineering;object oriented;information system;knowledge based systems;software process;modeling tool;object model	System modeling is considered as a key issue in information system engineering (ISE). According to the problems in current ISE, we propose seven guidelines for creating a modeling tool to solve them. Considering the achievements in the field of modeling the software process, we present the Object-Oriented Automatic System Modeling Framework (OOAMF) to meet those guidelines. OOAMF is rule-based, and it can guide users incrementally to create a rule-based object model (RBOM) of a target system. OOAMF remembers the domain knowledge obtained from the previous modeling activities and uses it to guide the following activities. This paper describes OOAMF, presents a formal description of the RBOM and demonstrates how the RBOM view is mapped by an object transformation.	information system;systems engineering	Wei Tao;L. Zhengding;C. Huagong;H. Liqin	1997		10.1109/TOOLS.1997.713565	computer science;systems engineering;knowledge management;software engineering;modeling language;electro-mechanical modeling	DB	-51.43798470387183	24.039585929018756	145737
348737221e76c4c3043e0f9e1b7081a807fb49c5	validating and evolving software requirements in a systematic framework	formal specification;executable specification;production quality system;software prototyping;application software;prototypes;formal specifications;software systems;program verification;software engineering;software performance;software prototyping prototypes formal specifications software systems production systems software engineering application software programming software performance real time systems;executable specifications;software requirements;conventional implementation descriptions;production systems;systematic framework;evolution software requirements systematic framework executable specifications specification descriptions conventional implementation descriptions production quality system validation;software prototyping formal specification program verification;validation;product quality;programming;specification descriptions;real time systems;evolution	The concern is with validation and evolution of software requirements based on the notion of executable specifications. A fundamental premise of this approach is that it is possible to use executable specification descriptions and conventional implementation descriptions interchangeably. This allows a prototype system to be transformed into a production quality system by incrementally replacing specifications with implementations which conform to them. >	requirement;software requirements	Mehmet Bülent Özcan;Jawed I. A. Siddiqi	1994		10.1109/ICRE.1994.292384	reliability engineering;software requirements specification;computer science;systems engineering;engineering;software engineering;formal specification	SE	-49.910005311283875	30.216262865010993	145773
05beaf33dc3d7710fb641456d88467b6b6554c56	model-driven software refactoring		In this chapter, we explore the emerging research domain of model-driven software refactoring. Program refactoring is a proven technique that aims at improving the quality of source code. Applying refactoring in a model-driven software engineering context raises many new challenges such as how to define, detect and improve model quality, how to preserve model behavior, and so on. Based on a concrete case study with a state-of-the-art model-driven software development tool, AndroMDA, we explore some of these challenges in more detail. We propose to resolve some of the encountered problems by relying on well-understood techniques of meta-modeling, model transformation and graph transformation.	code refactoring;graph rewriting;metamodeling;model transformation;model-driven architecture;model-driven engineering;model-driven integration;programming tool;software development;software engineering	Tom Mens;Gabriele Taentzer;Dirk Müller	2007			software construction;programming language;model transformation;source code;code refactoring;model-driven architecture;software development;software maintenance;computer science;unified modeling language	SE	-54.81797277276968	29.411817322874114	145816
11633b70814614c860f50508ffec4b71f78d7874	software development with imperfect information	decision support;software systems;imperfect information;storm surge;software development;fuzzy estimations;software design;requirement specification;fuzzy requirements	Delivering software systems that fulfill all requirements of the stakeholders is very difficult, if not at all impossible. We consider the problem of coping with imperfect information, like interpreting incomplete requirement specifications or vagueness in decisions, one of the main reasons that makes software design difficult. We define a method for tracing design decisions under imperfect information. To model and compare requirements with estimations, we present fuzzy and stochastic techniques. This approach offers adequate decision support that can deal with imperfect information during software design. The approach is illustrated by a real-world example, based on a storm surge barrier system.	decision support system;requirement;software design;software development;software system;vagueness	Joost Noppen;Pim van den Broek;Mehmet Aksit	2008	Soft Comput.	10.1007/s00500-007-0214-7	software requirements specification;verification and validation;software sizing;decision support system;software verification;computer science;software design;software development;software design description;perfect information;software construction;data mining;storm surge;goal-driven software development process;software requirements;software system	SE	-58.277860765589615	24.002698064839574	145989
14051049b1f1ede35bd56bcbd81ad942aac9a7c6	an architecture for www-based hypercode environments	collaborative work;software libraries;digital library;software engineering;service operation;html;computer architecture;software engineering environment;permission;software development;web sites;world wide web;lifting equipment;software tools;source code;software engineering permission computer architecture software libraries web sites html lifting equipment computer science programming software tools;computer science;programming;software process	A hypercode software engineering environment repre sents all plausible multimedia artifacts concerned with software development and evolution that can be placed or generated on line from source code to formal doc umentation to digital library resources to informal email and chat transcripts A hypercode environ ment supports both internal hypertext and external link server links among these artifacts which can be added incrementally as useful connections are discov ered project speci c hypermedia search and browsing automated construction of artifacts and hyperlinks ac cording the software process application of tools to the artifacts according to the process work ow and collab orative work for geographically dispersed teams We present a general architecture for what we call hyper media subwebs and groupspace services operating on shared subwebs based on World Wide Web technology which could be applied over the Internet or within an intranet We describe our realization in OzWeb	algorithm;archive;atomicity (database systems);attribute–value pair;backlink;baseline (configuration management);categorization;columbia (supercomputer);common object request broker architecture;compiler;computer science;concurrency control;configuration management;cross-reference;data definition language;data flow diagram;data model;data recovery;database;design rationale;digital library;display resolution;distributed computing environment;document;documentation;durability (database systems);email;embedded system;entity;focus group;functional specification;graphical user interface;html editor;hyperlink;hypermedia;hypertext transfer protocol;icse;include directive;internet;intranet;language code;library (computing);markup language;modeling language;object linking and embedding;object code;online and offline;organizing (structure);point of sale;postscript;process modeling;programming language;prototype;proxy server;server (computing);software development process;software engineering;software system;structured analysis;tracing (software);www;web page;web server;world wide web	Gail E. Kaiser;Stephen E. Dossick;Wenyu Jiang;Jack Jingshuang Yang	1997	Proceedings of the (19th) International Conference on Software Engineering	10.1145/253228.253231	programming;digital library;html;computer science;software development;software engineering;world wide web;software development process;lifting equipment;computer engineering;source code	SE	-50.396882833906794	18.64307170768052	146242
bd91c10d43ef48a7e1ece60593c2738116e5eb02	automatized test item generation in moodle	question bank;test module;e test;accumulative test item;e learning;moodle;test items generation	Creating reliable, reusable and efficient tests is a long and time-consuming process. One of the most important stages is creating a question bank. An approach to automatized generation of test items of different types is presented in this paper. It is based on the accumulative method that uses stored and assessed test items in the process of doing the test. An important role is played by the so-called accumulative question type (AQT), which, along with its attributes is described as a base of design, specifications and realization of a software test module implemented in Moodle. The presented module provides possibilities to enrich question banks with test items of different types and use the learning and assessing process in automatized test generation.	advanced query tool;software testing	Mariana Raykova;Hristina Kostadinova;Georgy Totkov	2014		10.1145/2659532.2659606	simulation;computer science;artificial intelligence;test suite;multimedia;etest;item bank;test management approach;test harness	SE	-56.828924665454466	31.55847312097735	146374
e487ef70b32f213e5394337f70c18e6d3dc227cb	preface: new software composition concepts	software composition		function composition (computer science)	Elke Pulvermüller;Gerhard Goos;Uwe Aßmann	2005	Sci. Comput. Program.	10.1016/j.scico.2004.11.001	computer science;function composition;programming language	Logic	-51.36236232661404	27.38703042406442	146387
504c5cbfc555338367e03b1793fce8e5a76d7614	traveling architects - a new way of herding cats	developpement logiciel;distributed system;architecture systeme;systeme reparti;localization;localizacion;software architecture;research and development;sistema repartido;localisation;desarrollo logicial;software development;datavetenskap datalogi;system development;arquitectura sistema;participatory design;system architecture;user involvement;qualite logiciel;software quality;architecture logiciel	Making software developers work towards a common goal may be likened to herding cats. If we further spread developers around the globe, we run increased risks of being unable to design and impose coherent software architectures on projects, potentially leading to lower quality of the resulting systems. Based on our experiences in a large, distributed research and development project, PalCom, we propose that employing techniques from active user involvement in general (and from participatory design in particular) may help in designing and sharing quality software architectures. In particular, we present the Traveling Architects technique in which a group of architects visit development locations in order to engage developers and end users in software architecture work. We argue that using techniques such as these may potentially lead to higher quality of software architectures in particular for systems developed in a distributed setting.	coherence (physics);software architecture;software developer	Aino Vonge Corry;Klaus Marius Hansen;David Svensson	2006		10.1007/11921998_12	software architecture;simulation;internationalization and localization;computer science;engineering;software development;operating system;software engineering;software quality;systems architecture	SE	-60.89397942661734	28.90741515652309	146686
a5aa8bd014c91307a2da5d3e299bf2fa146c746a	feature-oriented refinement of models, metamodels and model transformations	xak;ahead;model transformations;metamodels;modeling;models;refinements	Done well, the blend of Model Driven Development (MDD) and Software Product Lines (SPL) offers a promising approach, mixing abstraction from MDD and variability from SPL. Although Model Driven Product Lines have flourished recently, the focus so far has been mostly on how to cope with the variability of models. This focus on model variability has limited however the extension of variability to further artifacts apart from models such as metamodels and model transformations, that may cope with variability too in a product line setting. In this paper, we address the application of feature-oriented refinement to models, metamodels and model transformations. We illustrate our work with a case study of an embedded system.	conformance testing;embedded system;feature-oriented programming;heart rate variability;lockstep (computing);metamodeling;model-driven engineering;model-driven integration;refinement (computing);software development;software product line;spatial variability	Salvador Trujillo;Ander Zubizarreta;Xabier Mendialdua;Josune De Sosa	2009		10.1145/1629716.1629734	simulation;computer science;systems engineering;algorithm	SE	-53.97390801342367	25.97814100735946	146796
8a98a3ee365648010953e04724c2aa0011514a2b	evolving an integrated curriculum for object-oriented analysis and design	model design;integrated approach;design process;case studies;object oriented design;software development process;integrated curriculum;object oriented analysis and design;architectural pattern	Object-Oriented Analysis and Design has established itself as an integral and critically vital part of the software development process. In this paper, we describe an integrated approach to teaching this subject so that it covers vital components of this vast field: analysis, object-oriented design principles such as the Liskov Substitution Principle, the design process, which shows how and where the rules are applied, modeling, design and architectural patterns, language features, and refactoring. The course has evolved over the past 10 years to one that revolves around three major case studies. This evolution has resulted in a course that covers all important aspects of OOAD in a manner that emphasizes their inter-relatedness and hence their relevance to overall design process. Feedback suggests that this approach has improved students' understanding of the OOAD concepts.	architectural pattern;code refactoring;relevance;software development process	Sarnath Ramnath;Brahma Dathan	2008		10.1145/1352135.1352252	object-oriented analysis and design;simulation;design process;architectural pattern;computer science;object-oriented design;software engineering;interaction design pattern;design education;software development process	SE	-53.40319667168467	23.794839103417786	146800
158a4e45a83d2040a0133f08c32490f465114740	comparing design alternatives from field-tested systems to support product line architecture design	architecture evaluation and reconstruction;design comparison;dca field tested systems product line architecture design field tested design solutions design comparison approach eclipse plug ins reverse engineering;product lines;object oriented methods;design engineering;software prototyping;software maintenance;product lines architecture evaluation and reconstruction design comparison reverse engineering;field test;software systems;product line architecture design;product line;software engineering;systems engineering and theory;computer architecture;software architecture;field tested systems;software reusability;product line architecture;architecture evaluation;dca;time to market;software reusability software architecture software prototyping object oriented methods reverse engineering;product design;design comparison approach;product design computer architecture software systems reverse engineering software engineering design engineering systems engineering and theory costs time to market software maintenance;field tested design solutions;reverse engineering;new products;eclipse plug ins	This paper introduces an approach to mine field-tested design solutions when defining the architecture of a new product line. The design comparison approach (DCA) compares design solution alternatives implemented in existing systems and analyzes their advantages and drawbacks. This explicit comparison and analysis enables the development of high quality product line architectures by incorporating field-tested, proven concepts and strategies. We show the applicability and usefulness of the approach in two case studies concerned with the design of Eclipse plug-ins.	display resolution;eclipse;plug-in (computing)	Jens Knodel;Thomas E. Forster;Jean-Francois Girard	2005	Ninth European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2005.18	software architecture;probabilistic design;systems engineering;engineering;software engineering;product design;software maintenance;high-level design;reverse engineering;software system;computer engineering;systems design	EDA	-57.25670083571741	27.50121311060002	147170
5a6559c970892171581dc1e1874e4c9a9913ca1a	modular aspect-oriented design with xpis	information hiding;program comprehension;limited enforcement;aspect oriented design;software engineering;design rules;design method;aspect oriented programming;options;software design;qualitative and quantitative analysis;design methodology	The emergence of aspect-oriented programming (AOP) languages has provided software designers with new mechanisms and strategies for decomposing programs into modules and composing modules into systems. What we do not yet fully understand is how best to use such mechanisms consistent with common modularization objectives such as the comprehensibility of programming code, its parallel development, dependability, and ease of change. The main contribution of this work is a new form of information-hiding interface for AOP that we call the crosscut programming interface, or XPI. XPIs abstract crosscutting behaviors and make these abstractions explicit. XPIs can be used, albeit with limited enforcement of interface rules, with existing AOP languages, such as AspectJ. To evaluate our notion of XPIs, we have applied our XPI-based design methodology to a medium-sized network overlay application called Hypercast. A qualitative and quantitative analysis of existing AO design methods and XPI-based design method shows that our approach produces improvements in program comprehensibility, in opportunities for parallel development, and in the ease when code can be developed and changed.	ambient occlusion;application programming interface;aspect-oriented programming;aspectj;dependability;emergence;hypercast;overlay network	Kevin J. Sullivan;William G. Griswold;Hridesh Rajan;Yuanyuan Song;Yuanfang Cai;Macneil Shonle;Nishit Tewari	2010	ACM Trans. Softw. Eng. Methodol.	10.1145/1824760.1824762	reliability engineering;design methods;computer science;systems engineering;software engineering;programming language	SE	-53.124768164422	30.648521493908166	147358
a3238cbc328f7100730dc5427b2e3ba00ea2307d	change impact analysis and software evolution specification for continually evolving systems	architectural design;change management;software maintenance;architecture description language;rule based;software architecture;impact analysis;software evolution;data dependence;adl change impact analysis techiques software evolution specification program code analysis data flow extraction data control flow information change management module dependency architecture design level coding technique metamodel data dependency temporal control flow rule based architecture tecfra model architecture description language design;control flow;architecture description language adl;software maintenance data flow analysis management of change software architecture;data flow analysis;management of change;change impact analysis;data flow;architecture description language adl change impact analysis software evolution;architectural style	Precision in change impact analysis ensures the correctness and completeness of the software evolution. Current research on impact analysis is based on the program code analysis. Also these techniques extract the data flow and control flow information at the statement and variable level which is too granular to be of use at higher levels of change management. The change impact analysis techniques need to be applied initially at the architecture design level to capture module dependencies without being dependent on coding style and/or coding technique. But the current architecture models do not explicitly capture the module dependencies. Hence the architectural style needs to explicitly capture the module and data dependencies in its metamodel. This will facilitate the precise change impact analysis. We have defined Temporal Control Flow Rule-based Architecture (TeCFRA) to provide for the same. TeCFRA models these dependencies using control flow rules as connectors. We have also designed an architecture description language (ADL), which supports the specification of TeCFRA-based system as well as specification of its evolutions. The approach allows us to enhance the precision in change impact analysis and in the evolution specification.	architecture description language;business process;component-based software engineering;control flow;correctness (computer science);data dependency;dataflow;downtime;emergence;metamodeling;problem domain;programming style;requirement prioritization;software evolution;specification language;static program analysis	Urjaswala Vora	2010	2010 Fifth International Conference on Software Engineering Advances	10.1109/ICSEA.2010.43	data flow diagram;software architecture;architecture description language;real-time computing;computer science;systems engineering;engineering;software evolution;software engineering;data-flow analysis;change management;database;control flow;software maintenance;change impact analysis	SE	-53.49043075625842	29.173962042761264	147397
080e754320825a1c4f55efa6280b0e4f8e770824	modelling a cps swarm system: a simple case study		The CPSwarm workbench is a toolchain that facilitates the entire design process of swarms of CPS including modelling, design, optimization, simulation and deployment. This paper highlights part of the work of the CPSwarm workbench in the context of the CPSwarm H2020 project. In particular, the CPSwarm workbench allows to create a generic swarm library that can be customized by developers to design new swarm environments, new swarm members and new swarm goals. This paper shows an application of the initial CPSwarm workbench by the example of a reference problem called EmergencyExit. In this example a swarm of robots needs to find an exit in an unmapped environment and leave this room through the exit as soon as possible. The example problem is further used to show the integration of Modelio, a UML/SysML modelling tool, and FREVO, an optimization tool in the CPSwarm workbench.	code generation (compiler);embedded system;mathematical optimization;modelio;open-source software;robot;search algorithm;simulation;software deployment;sourceforge;swarm;swarm robotics;systems modeling language;toolchain;unified modeling language;workbench	Melanie Schranz;Alessandra Bagnato;Etienne Brosse;Wilfried Elmenreich	2018		10.5220/0006731106150624	theoretical computer science;swarm behaviour;computer science	Robotics	-54.28520128641773	30.330777572705205	147438
716d543e341ac49ecc59ec07122faa566ea8fb48	interconnectivity analysis techniques for error localization in large systems	modelizacion;system structure;test programa;interconnection;analisis sistema;ingenieria logiciel;software engineering;analisis programa;modelisation;structure systeme;interconnexion;genie logiciel;system analysis;analyse systeme;program analysis;fiabilite logiciel;analyse programme;fiabilidad logicial;test programme;modeling;program test;software reliability;interconeccion;estructura sistema	Abstract   Software systems contain multiple types of interrelations among components — data, control, and sequencing, among others. We are developing interconnectivity analysis techniques that derive multiple views of the structure of large-scale software systems. These techniques calculate interconnections among components and then recursively group the components into sets according to their degree of interconnection. These techniques are especially suited to large-scale systems (e.g., > 100,000 lines) since numerous types of interconnections can be determined automatically in a tractable manner. Interconnectivity analysis techniques produce visualizations of system structure and can be used to document systems, model their evolution over time, compare system structure, guide regression testing, or localize error-prone structure. This article summarizes two studies using interconnectivity analysis. In earlier work, one such technique was applied effectively in a feasibility study to characterize the error-prone components in a large-scale system from a production environment. Routines with the highest coupling/cohesion ratios had 8.1 times more errors per 1,000 source lines of code that did routines with the lowest coupling /cohesion ratios. A second validation study is currently underway. In this study, we are applying interconnectivity analysis techniques to the design specification of a large distributed command and control system. Tools supporting interconnectivity analysis will be integrated into the Amadeus measurement-driven analysis and feedback system.		Richard W. Selby	1993	Journal of Systems and Software	10.1016/0164-1212(93)90070-E	program analysis;systems modeling;computer science;interconnection;software engineering;system analysis;operations research;algorithm;software quality	SE	-60.79274533700376	30.219576261549758	147595
326d7320547af774a5f80cb60d1f0544a0970acd	a use case modeling approach to facilitate the transition towards analysis models: concepts and empirical evaluation	class diagram;restriction rules;controlled experiment;use case modeling;analysis model;use case template;empirical evaluation;use case	Use case modeling, including use case diagrams and use case specifications, is commonly applied to structure and document requirements. Use case specifications are usually structured, textual documents complying with a certain use case template. However, because use case specifications remain essentially textual, ambiguity is inevitably introduced. In this paper, we propose a use case modeling approach, which is composed of a set of well-defined restriction rules and a use case template. The goal is two-fold: (1) restrict the way users can document use case specifications in order to reduce ambiguity and (2) facilitate automated analysis in order to provide tool support to derive initial analysis models, which in UML are typically composed of class diagrams, interaction diagrams, and possibly other types of diagrams and constraints. Though the proposed restriction rules and template are based on a clear rationale, two main questions need to be investigated. Do users find them too restrictive or impractical in certain situations? Second, do the rules and template have a positive, significant impact on the quality of the resulting analysis models? To investigate these questions, we performed and report on a controlled experiment, which evaluates the restriction rules and use case template in terms of whether they are easy to apply while developing use case models and whether they help obtain higher quality analysis models in terms of correctness, completeness, redundancy, and understandability. Results show that, the restriction rules are overall easy to apply and that our use case modeling approach result Carleton University, TR SCE-09-05 May 2009 2 in significant improvements regarding the correctness of derived class diagrams and the understandability of use case specifications.	class diagram;correctness (computer science);design rationale;document;requirement;unified modeling language	Tao Yue;Lionel C. Briand;Yvan Labiche	2009		10.1007/978-3-642-04425-0_37	use case;computer science;systems engineering;engineering;software engineering;data mining;database;algorithm	SE	-55.3196974665562	24.261504688383216	147819
58be8aff0e38938cfcbe41d4bf2bc5522d4dd9dc	contractcml - a contract aware component modeling language	software;integrated approach;four level contract specification;mandatory syntactic level;domain specific modeling language contractcml contract aware component modeling language software components four level contract specification mandatory syntactic level academic model component contracts;design by contract component based software development model driven engineering domain specific modeling languages;contract aware component modeling language;domain specific modeling languages;formal specification;biological system modeling;contracts;object oriented programming;data mining;software components;domain specific modeling language;academic model;specification languages;specification languages formal specification object oriented programming;unified modeling language;model driven engineering;software component;component model;component based software development;design by contract;weaving;quality of service;context;contracts packaging assembly computer science software quality quality of service proposals model driven engineering software algorithms scientific computing;contractcml;component contracts	Providing software components with a four level contract specification - syntax, semantics, synchronization, quality of service - is important to their correct (re)use. The mandatory syntactic level is included by all current component models. Academic models also employ one of the others, but use different formalisms to represent it. Through this paper, we propose an integrated approach for handling component contracts. We focus on introducing ContractCML (Contract Component Modeling Language), a domain specific modeling language that ensures the basis of our proposal.	component-based software engineering;directory services markup language;domain-specific modeling;general-purpose modeling;model-driven engineering;quality of service;unified modeling language	Vladiela Petrascu;Dan Ioan Chiorean;Dragos Petrascu	2008	2008 10th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2008.35	computer science;component-based software engineering;component;database;programming language	SE	-49.70036299598229	26.787655644354594	148298
766f5678e8331a3ed3bf06a50f43d12d0913b750	a methodology for modeling ambient intelligence applications using i* framework		At present time, Ambient Intelligence (AmI) is a revolutionary computing paradigm that promises to have a deep effect on the way we interact with the computers, devices, physical spaces, and other people. The development of applications for this paradigm represents a new challenge for analysts and software engineers due to the complexity to consider physical, human and system actors interacting among them to give support to existing human activities. In this context, requirements engineering plays a very relevant role in AmI applications development because it allows the analysts to contextualize the expected functionalities of the system to-be before its implementation. In this paper, a technology modeling method, based on i*, has been proposed as a tool to model the software requirements for Ambient Intelligence applications.	actor model;ambient intelligence;computer;interaction;programming paradigm;requirement;requirements engineering;software engineer;software requirements	Alejandro Guzman;Alicia Martínez Rebollar;Fabio Vargas Agudelo;Hugo Estrada-Esquivel;Joaquín Pérez Ortega;Javier Ortiz	2016			data science;ambient intelligence;engineering	SE	-49.991875513471626	22.49765884753126	148390
a0034c38fc8499ecd311f89f659959f43a6fb2bf	a uml-based variability specification for product line architecture views		In this paper we present a rigorous and practical notation for specifying variability in product line architecture views expressed in the Unified Modeling Language (UML). The notation has been used for the explicit representation of variations and their locations in software product line architectures based on a design method already established. The improvement consists in a service orientation of architectural models. The benefit of a more familiar and widely used notation facilitates a broader understanding of the architecture and enables more extensive tool support for manipulating it. The specification notation paves the way for the development of tools.	computer-aided software engineering;diagram;extensibility;heart rate variability;profile (uml);programmable logic array;rational rose;refinement (computing);software design;software evolution;software product line;spatial variability;unified modeling language	Liliana Dobrica;Eila Niemelä	2008			product design specification;computer science;systems engineering;architecture;software architecture;reference architecture;software architecture description;unified modeling language	SE	-53.12763723794669	26.02823152241007	148772
