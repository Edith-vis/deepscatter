id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
6ae92bcccbc4118765ef509a5a3df0d8b29b6862	analysis of variance in statistical image processing	image processing;efficient algorithm;image restoration;pattern recognition;analysis of variance;image analysis;object detection;graduate student	Preface 1. Introduction 2. Statistical linear models 3. Line detection 4. Edge detection 5. Object detection 6. Image segmentation 7. Radial masks in line and edge detection 8. Performance analysis 9. Some approaches to image restoration References Index.	image processing	Ranjan Maitra;Thomas Mathew	2000	Technometrics	10.1080/00401706.2000.10486012	corner detection;image texture;image restoration;feature detection;scale space;image analysis;object-class detection;edge detection;analysis of variance;image gradient;binary image;image processing;morphological gradient;digital image processing;standard test image	Robotics	41.83991042771526	-65.88561234531734	47683
506653429701f37b6692c2836b0cfa05497d6ea7	space curve representation and recognition based on wavelet transform zero-crossings	reference systems;wavelet transform;space curve recognition;zero crossing representation;dyadic wavelet transform;string matching technique;string matching	A method to construct a representation of space curves based on the zero-crossings of the dyadic wavelet transform is introduced. The principal axes of inertia of these space curves, referred to as objects, are considered as the reference system. The representation is translation, rotation and size invariant. Instances of objects in images are recognised by matching their representations with those of the models. A string-matching technique is adapted and used for this purpose. Experimental results show that the representation is robust and efficient in extracting and matching object information.	computation;dhrystone;dyadic transformation;grammar-based code;robustness (computer science);smoothing;string searching algorithm;time complexity;torsion (gastropod);type signature;wavelet transform;zero crossing	Quang Minh Tieng;Wageeh W. Boles	2000	Journal of Mathematical Imaging and Vision	10.1023/A:1008315505537	wavelet;real representation;discrete mathematics;harmonic wavelet transform;topology;second-generation wavelet transform;continuous wavelet transform;pattern recognition;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform;string searching algorithm	Vision	41.49115156241177	-58.87211484305893	47938
0809a09686baeee4951576cb20cca6f27493bb45	evolutionary algorithm for pcb inspection	circuit inspection;computer vision;pattern recognition;evolutionary algorithm	An important inspection task in the automated assembly of printed circuit boards (PCBs) is that of detecting if all components have been placed correctly on the board. This paper describes a constrained evolutionary search based inspection technique for simultaneously detecting multiple component objects in a source image. The approach has the advantage that it does not rely on image alignment (registration) as do conventional optical inspection methods such as image subtraction. It is a template based search method which achieves speed and quality requirements by making use of an evolutionary algorithm and a simultaneous search for multiple objects in a source image using a generalised template. The generalised template matching method defines a template model that takes into account the statistical variations between the grey-level appearances of components. The evolutionary search for specific components is constrained to Canny edges making this a fast method for locating multiple targets. Results are presented for locating multiple surface mount resistors on a PCB so that missing components can be reported.	algorithmic efficiency;canny edge detector;computation;edge enhancement;evolutionary algorithm;image subtraction;object detection;outline of object recognition;printed circuit board;printing;requirement;sensor;surface-mount technology;template matching	A. J. Crispin;V. Rankov	2009	KES Journal	10.3233/KES-2009-0177	computer vision;automated x-ray inspection;computer science;machine learning;evolutionary algorithm	Vision	46.33858582520312	-53.55460133231837	48017
b64584efbfed8a544ce6e0b81462d85f6158f193	fast and robust skew correction in scanned document images based on low-rank matrix decompositon	matching pursuit algorithms;matrix rank minimization problem skew correction scanned document image low rank matrix decompositon skew angle estimation affine transformation;hough transformation low rank matrix decomposition scanned document images skew correction;matrix decomposition abstracts robustness lead approximation methods transforms matching pursuit algorithms;matrix decomposition;lead;abstracts;transforms;robustness;approximation methods;minimisation affine transforms document image processing matrix decomposition	The most important of skew correction for scanned document image is to estimate the skew angle. Traditional methods mostly based on its linear check, such as Hough transformation and so on. However, it is often affected by its texture structure or other noise. In this paper, a fast and robust skew estimation method is proposed based on low-rank matrix decomposition, which seeks an affine transformation that can be used to implement the correction. As the rank of a matrix is a natural measure of regularity and symmetry of images, a misaligned scanned document image is assumed to be correct when the rank of the texture extracted from the image itself is the minimum. Therefore, the skew correction problem can be considered as a matrix rank minimization problem. As experiment illustrated, our method works efficiently and robustly overcoming corruptions, such as lines, circles and so on.	hough transform	Hengyou Wang;Rui-Zhen Zhao;Jing-An Cui	2014	2014 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2014.7009726	mathematical optimization;lead;combinatorics;discrete mathematics;computer science;mathematics;matrix decomposition;robustness	Vision	51.09576613738683	-53.50286895710373	48042
c94ea58797549720299d83877d7ca0ed4b41adef	efficient color transformations on quantum images	image processing;complexity;quantum computation		quantum	Phuc Quang Le;Abdullah M. Iliyasu;Fangyan Dong;Kaoru Hirota	2011	JACIII	10.20965/jaciii.2011.p0698	computer vision;complexity;image processing;computer science;theoretical computer science;quantum computer;quantum imaging	Crypto	50.686654191299084	-63.868923237972616	48217
093280281f887149b27301fbbb87c2963061e9b7	robust rotation angle estimator	eigenvalues and eigenfunctions;image recognition;estimation theory;object recognition;zernike moments;robust rotation angle estimator;phase;principal axes;eigenvalues;noise robustness;polynomials;belts;estimation theory eigenvalues and eigenfunctions zernike polynomials image recognition;machine vision;phase estimation;eigenvalues and eigenfunctions pattern recognition phase estimation robots covariance matrix noise robustness machine vision belts polynomials object recognition;zernike moment;robots;rotation angle;robust method;pattern recognition;zernike moments robust rotation angle estimator circular symmetric patterns phase information;covariance matrix;zernike polynomials;circular symmetric patterns;phase information	The conventional method of estimating the rotation angle of a pattern using the principal axes is not suitable for circular symmetric patterns since their eigenvalues are similar in both directions. In the paper, a robust method of estimating a rotation angle using the phase information of Zernike moments is presented. The experimental results show that the proposed method estimates the rotation angle of the circular symmetric patterns more accurately than the principal axes method, even in the presence of noise.		Whoi-Yul Kim;Young-Sung Kim	1999	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.784290	robot;principal axis theorem;computer vision;covariance matrix;mathematical optimization;rotation of axes;plane of rotation;machine vision;eigenvalues and eigenvectors;computer science;cognitive neuroscience of visual object recognition;zernike polynomials;mathematics;geometry;euler's rotation theorem;phase;estimation theory;axis–angle representation;statistics;polynomial	Vision	50.7337846246283	-52.500851664306175	48223
1100ca703973533df3371abaf62a8dd9ba547b5b	gesture classification and recognition using principal component analysis and hmm	modelo markov oculto;two dimensional shape;analisis componente principal;forme bidimensionnelle;reconnaissance geste;modele markov cache;hidden markov model;extraction forme;classification;forma bidimensional;extraccion forma;feature extraction;principal component analysis;indexation;image sequence;analyse composante principale;pattern extraction;clasificacion;gesture recognition	In this paper, we describe the method that can automatically compose gesture models and recognize those gestures using 2D features extracted from gesture image sequences. In the conventional gesture recognition algorithms, previously well-known patterns are introduced by the hand or the model indexing algorithm. However, our method automatically composes the model space by clustering arbitrary input image sequences. The models are recognized as gesture using probability calculation of HMM. Our method can compose the models fast and robustly and is easy to learn on new image sequences.	gesture recognition;hidden markov model;principal component analysis	Hyun-Ju Lee;Yong Jae Lee;Chil-Woo Lee	2001		10.1007/3-540-45453-5_97	computer vision;speech recognition;feature extraction;biological classification;computer science;machine learning;pattern recognition;gesture recognition;hidden markov model;principal component analysis	Vision	45.08930733496123	-58.809094979596985	48338
567b207ee6906ac30c0fa88b4b4651fa27ccaefc	multiscale feature extraction from the visual environment in an active vision system	vision system;sistema activo;systeme vision;methode echelle multiple;extraction forme;exploracion;metodo escala multiple;systeme actif;similitude;processing time;active system;extraccion forma;feature extraction;frequence spatiale;similarity;pattern recognition;exploration;temps traitement;multiscale method;vision active;reconnaissance forme;similitud;information system;methode domaine temps frequence;frecuencia espacial;reconocimiento patron;pattern extraction;tiempo proceso;metodo dominio tiempo frecuencia;systeme information;spatial frequency;time frequency domain method;active vision;sistema informacion	This paper presents a visual architecture able to identify salient regions in a visual scene and to use them to focus on interesting locations. It is inspired by the ability of natural vision systems to perform a differential processing of spatial frequencies both in time and space and to focus their attention on a very local part of the visual scene. The present paper analyzes how this differential processing of spatial frequencies is able to provide an artificial system with the information required to perform an exploration of its visual world based on a center-surround distinction of the external scene. It shows how the salient locations can be gathered on the basis of their similarities to form a high level representation of the visual scene.	active vision;feature extraction;high-level programming language	Youssef Machrouh;Jean-Sylvain Liénard;Philippe Tarroux	2001		10.1007/3-540-45129-3_35	computer vision;similarity;active vision;exploration;machine vision;feature extraction;computer science;artificial intelligence;similitude;spatial frequency;human visual system model;information system	Vision	46.98941062291708	-59.94881527574213	48462
77a21a5d378e2660a0767e38b2342375fd198ac4	biometric recognition using feature selection and combination	bayes estimation;analisis imagen;decision tree;image processing;redundancia;biometrie;decision bayes;naive bayes;extraction forme;biometrics;biometria;procesamiento imagen;pequena dimension;arbol decision;bayes decision;classification;traitement image;small dimension;identificacion sistema;plan classement;estimacion bayes;performance improvement;redundancy;petite dimension;system identification;extraccion forma;feature extraction;feature subset selection;pattern recognition;image analysis;feature selection;plan clasificacion;reconnaissance forme;extraction caracteristique;reconocimiento patron;analyse image;pattern extraction;arbre decision;clasificacion;identification systeme;redondance;classification scheme;estimation bayes	Most of the prior work in biometric literature has only emphasized on the issue of feature extraction and classification. However, the critical issue of examining the usefulness of extracted biometric features has been largely ignored. Feature evaluation/selection helps to identify and remove much of the irrelevant and redundant features. The small dimension of feature set reduces the hypothesis space, which is critical for the success of online implementation in personal recognition. This paper focuses on the issue of feature subset selection and its effectiveness in a typical bimodal biometric system. The feature level fusion has not received adequate attention in the literature and therefore the performance improvement in feature level fusion using feature subset selection is also investigated. Our experimental results demonstrate that while majority of biometric features are useful in predicting the subjects identity, only a small subset of these features are necessary in practice for building an accurate model for identification. The comparison and combination of features extracted from hand images is evaluated on the diverse classification schemes; naive Bayes (normal, estimated, multinomial), decision trees (C4.5, LMT), k-NN, SVM, and FFN.	biometric device;biometrics;c4.5 algorithm;computational complexity theory;decision tree;feature extraction;feature selection;handwritten biometric recognition;k-nearest neighbors algorithm;logistic model tree;multinomial logistic regression;naive bayes classifier;probabilistic turing machine;relevance;statistical classification	Ajay Kumar;David Zhang	2005		10.1007/11527923_85	image analysis;naive bayes classifier;system identification;image processing;feature extraction;biological classification;classification scheme;computer science;machine learning;decision tree;pattern recognition;data mining;mathematics;redundancy;feature selection;feature;biometrics	AI	44.10560016498633	-60.108952188543356	48674
841e4333819b4ffedc52d4254c520c7aab8010f6	space curve recognition based on the wavelet transform and string-matching techniques	image recognition;object recognition;wavelet transforms space technology signal processing algorithms object recognition australia additive noise robot vision systems image recognition robustness biological cells;ordered set;image matching;zero crossing representations;additive noise;complex numbers;wavelet transforms;algorithm;similarity transformation;object recognition complex numbers string matching techniques space curve recognition 3d space curves representation algorithm zero crossing representations dyadic wavelet transform compact representation experimental results similarity transformation additive noise;biological cells;wavelet transform;compact representation;space curve recognition;string matching techniques;image representation;robustness;3d space curves representation;space technology;dyadic wavelet transform;string matching;signal processing algorithms;experimental results;robot vision systems;string matching object recognition wavelet transforms image representation image matching;australia	A technique for representing and recognising 3-D or space curves is presented. In the proposed algorithm, space curves are represented by a set of two zero-crossing representations which are constructed based on the dyadic wavelet transform. These representations are then described in the form of an ordered set of complex numbers which is referred to as the compact representation of the space curves. A string-matching technique is adapted for comparing two curves using their compact representations. Experimental results show that the proposed technique can be used for recognising space curves under similarity transformation with and without additive noise.	additive white gaussian noise;dyadic transformation;grammar-based code;string searching algorithm;utility functions on indivisible goods;wavelet transform;zero crossing	Quang Minh Tieng;Wageeh W. Boles;Mohamed A. Deriche	1995		10.1109/ICIP.1995.537561	computer vision;discrete mathematics;computer science;pattern recognition;mathematics;family of curves;wavelet transform	Robotics	41.17727408982213	-59.00365199219812	48696
53d6e43b62f34b4d2d5857fe61eed4affb135102	a new sparse feature-based patch for dense correspondence	digital signal processing;patch match;computer vision;optical imaging;patch match dense correspondence optimization;image color analysis;image reconstruction;optimization;computer vision sparse feature based patch dense correspondence energy optimization framework energy optimization dense matching process feature based patches perturbation matched patches;algorithm design and analysis;optimization image reconstruction image color analysis algorithm design and analysis digital signal processing optical imaging education;dense correspondence	This paper presents a new method to compute the dense correspondences between two images by using the sparse feature-based patches in an energy optimization framework. Many transformation and deformation cues such as color, scale and rotation should be considered when we finding dense correspondences between images. However, most existing methods only consider part of these transformations, which will introduce the uncorrect correspondence results. In terms of the property of the sparse feature and the principle that nearest sub-scenes and neighbors are much more similar, we design a new energy optimization to guide the dense matching process. Both transformation and deformation are considered in our energy optimization framework since we design the feature-based patches. Thus, our algorithm can match the complicated scenes and objects robustly. At last, a local refinement technique is proposed to solve the perturbation of the matched patches. Experimental results demonstrate that our method outperforms the state-of-the-art algorithms.	algorithm;color;global optimization;mathematical optimization;refinement (computing);sparse matrix	Xiameng Qing;Jianbing Shen;Xuelong Li;Yunde Jia	2014	2014 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2014.6890288	iterative reconstruction;algorithm design;computer vision;computer science;digital signal processing;machine learning;pattern recognition;optical imaging	Vision	52.12614556911741	-53.35221522334653	48805
08f311db6c776f22cc8ad255d4b3e61da1e75b86	optical flow back-projection for genuine motion vector estimation	horn schunck optical flow constraint;moving object;traitement signal;estimation mouvement;image segmentation;image processing;flux optique;gradient method;estimacion movimiento;erreur quadratique moyenne;procesamiento imagen;motion estimation;traitement image;approche deterministe;similitude;deterministic approach;methode gradient;estimation erreur;flujo optico;metodo gradiente;error estimation;erreur estimation;mean square error;motion vector;signal processing;estimacion error;segmentation image;similarity;enfoque determinista;pattern recognition;error estimacion;optical flow;region based matching;estimation error;similitud;error medio cuadratico;procesamiento senal;optical flow computation	Motion vector plays one significant feature in MPEG-4 video object segmentation. However, the motion vector in this application is required to represent the actual motion displacement, rather than regions of visually significant similarity. Optical flow back-projection (OFB), which back-projects optical flows in a cluster to restore the region's motion vector from gradient-based optical flows, is proposed to obtain genuine motion displacement. The back-projection is performed based on minimizing the projection mean square errors of the motion vector on gradient directions. As optical flows of various magnitudes and directions provide various degrees of reliability in the genuine motion restoration, the optical flows to be used in the OFB are selected based on high gradient. With this approach, the interference by similar blocks, which frequently results in irrational motion displacement in the traditional block matching approach, can be avoided and more reliable motion vectors can be obtained	circuit restoration;displacement mapping;gradient;interference (communication);mean squared error;optical flow	Chieh-Ling Huang;E-Liang Chen;Pau-Choo Chung;Yuh-Ren Choo	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)	10.1016/j.patcog.2006.06.019	computer vision;structure from motion;similarity;image processing;quarter-pixel motion;computer science;gradient method;similitude;signal processing;motion estimation;optical flow;mathematics;motion system;mean squared error;geometry;image segmentation;motion field;deterministic system;statistics;linear motion	Vision	51.4807074568884	-58.80314970893295	48821
e3f4c8c0d2bad9bdf0309881d5104e4937ac24af	two-dimensional discriminant transform based on scatter difference criterion for face recognition	reconnaissance visage;analisis imagen;sample size;analisis bidimensional;high dimensionality;schema differences;image processing;small sample size;facies;image databank;tamano muestra;extraction forme;procesamiento imagen;taille echantillon;traitement image;calcul analogique;discriminant analysis;analyse discriminante;difference scheme;fisher discriminant analysis;analisis discriminante;analyse bidimensionnelle;face recognition;extraccion forma;image representation;feature extraction;esquema diferencias;banco imagen;banque image;two dimensional analysis;pattern recognition;image analysis;reconnaissance forme;extraction caracteristique;reconocimiento patron;computational efficiency;analyse image;pattern extraction;analog calculus;calculo analogico	In this paper, a novel image discriminant analysis method, coined two-dimensional discriminant transform based on scatter difference criterion (2DSDD), is developed for image representation. The proposed 2DSDD scheme adopts the difference of both between-class scatter and within-class scatter as discriminant criterion. In this way, the small sample size problem usually occurred in the traditional Fisher discriminant analysis (LDA) is essentially avoided. In addition, the developed method directly depends on image matrices. That is to say, it is not necessary to convert the image matrix into high-dimensional image vector like those conventional linear discriminant methods prior to feature extraction so that much computational time would be saved. Finally, the experimental results on the ORL face database indicate that the proposed method outperforms Fisherfaces, the standard scatter difference discriminant analysis, not only in the computation efficiency, but also in its recognition performance.	discriminant;facial recognition system	Cai-Kou Chen;Jingyu Yang	2006		10.1007/11881223_85	sample size determination;computer vision;kernel fisher discriminant analysis;image analysis;facies;image processing;feature extraction;computer science;pattern recognition;optimal discriminant analysis;mathematics;linear discriminant analysis;multiple discriminant analysis;statistics	Vision	44.3935494040599	-60.19523660408133	49023
d66ba3f2c0250d7ac2e1217943e8f25ae73b4eb3	range image segmentation: adaptive grouping of edges into regions	analisis imagen;image segmentation;image processing;algoritmo adaptativo;edge detection;analisis forma;procesamiento imagen;traitement image;range image segmentation;deteccion contorno;detection contour;adaptive algorithm;algorithme adaptatif;range image;segmentation image;image analysis;pattern analysis;analyse image;analyse forme	In this paper we propose an adaptive grouping algorithm to achieve a complete range image segmentation from an edge map. Its effectiveness has been extensively evaluated on three range image sets used in recent range image segmentation comparison studies. It turned out that our approach almost consistently outperforms all the region-based segmentation algorithms tested on the image sets with respect to both segmentation quality and computation time.		Xiaoyi Jiang;Horst Bunke	1998		10.1007/3-540-63931-4_230	image texture;computer vision;range segmentation;image analysis;edge detection;image processing;computer science;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	46.14167424097735	-63.78369976717693	49238
4716f39ba8ea796f659e788fb9d7c106a90822c6	evaluating the performance in automatic image annotation: example case by adaptive fusion of global image features	performance measure;analisis imagen;anotacion;image features;analisis contenido;evaluation performance;global image features;performance evaluation;system configuration;automatic image annotation;evaluacion prestacion;informacion mutual;annotation;organisation systeme;carte autoorganisatrice;organizacion sistema;content analysis;information mutuelle;self organising feature maps;mutual information;image analysis;analyse contenu;analyse image;self organising map	In this work we consider two traditional metrics for evaluating performance in automatic image annotation, the normalised score (NS) and the precision/recall (PR) statistics, particularly in connection with a de facto standard 5000 Corel image benchmark annotation task. We also motivate and describe another performance measure, de-symmetrised termwise mutual information (DTMI), as a principled compromise between the two traditional extremes. In addition to discussing the measures theoretically, we correlate them experimentally for a family of annotation system configurations derived from the PicSOM image content analysis framework. Looking at the obtained performance figures, we notice that such kind of a system, based on adaptive fusion of numerous global image features, clearly outperforms the considered methods in literature. r 2007 Elsevier B.V. All rights reserved.	automatic image annotation;benchmark (computing);experiment;mutual information	Ville Viitaniemi;Jorma Laaksonen	2007	Sig. Proc.: Image Comm.	10.1016/j.image.2007.05.003	computer vision;image analysis;content analysis;computer science;artificial intelligence;data mining;mutual information;automatic image annotation;feature	Vision	43.23192432533123	-61.0086316016578	49355
a9a9dbdd5a2b7c6f96706997c75706e78e3f7d70	towards a better comprehension of the role of image registration in face recognition algorithms	databases;eigenvalues and eigenfunctions;image recognition;gaussian function image registration face recognition algorithms dimension reduction eigen decomposition principal component analysis euclidean distance cosine similarity measurements;gaussian processes;euclidean distance;face face recognition euclidean distance databases feature extraction principal component analysis image recognition;face recognition;principal component analysis eigenvalues and eigenfunctions face recognition gaussian processes image registration;feature extraction;principal component analysis;image registration;face	Automatic face recognition systems have currently reached high hit rates. Nevertheless, simple steps like image registration are not being considered in several methods. The alignment of the set of images in a same coordinated system must be seen as an initial and crucial step in algorithms that are based on dimensionality reduction. This work aims at analyzing the importance of registration as a preprocessing step in recognition algorithms based on eigen decomposition. A set of experiments was conducted, in which images of publicly available databases were processed under rotation and translation. These operations put the images on controlled non-registered form for precise evaluation of three recognition methods — Principal Component Analysis, Two-dimensional Principal Component Analysis and FisherFaces, combined with the Euclidean distance and cosine similarity measurements. The experiments revealed the best combination of methods. Moreover, the behavior of hit rate with respect to rotation and translation misalignments were characterized as a Gaussian function.	algorithm;cosine similarity;database;dimensionality reduction;eigen (c++ library);euclidean distance;experiment;facial recognition system;image registration;preprocessor;principal component analysis	Breno Santos Araujo;Alexei Manso Corrêa Machado	2011	2011 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS)	10.1109/BIOMS.2011.6052384	computer vision;machine learning;pattern recognition;mathematics;3d single-object recognition;eigenface	Vision	40.25741402690721	-56.85445669067025	49456
e3efbf91fc3e54a98fcf8f7330f869ffd2f236ee	bayesian texture classification method using a random sampling scheme	probability;texture classification;bayes methods;random sampling;bayesian inference;image classification;matrix algebra;maximum likelihood estimation;image texture;property a;classifier accuracy bayesian texture classification random sampling scheme bayesian inference procedure gray level co occurrence matrices maximum a posteriori probability gray level intensity pair brodatz database;sampling methods;majority voting;image texture bayes methods image classification matrix algebra maximum likelihood estimation sampling methods probability;bayesian methods sampling methods testing voting robots pixel electronic mail image databases phase estimation image sampling	We present a texture classification approach that uses a Bayesian inference procedure using local co-occurrence properties over a set of randomly sampled points as evidence. Prior probabilities are modelled using gray level co-occurrence matrices (GLCMs) in a number of distances and orientations. By using Bayes' rule, we find texture class that maximizes a posteriori probability of the observed gray level intensity pair in a randomly chosen point. Each point casts a vote for the texture that best explains observed co-occurrence properties. A majority voting procedure assigns a winning label for a texture class. Our approach results in a fast classifier because it does not need to compute GLCM for the texture under test. Our method was tested on a subset of textures from Brodatz database and the classifier accuracy was estimated at about 85% even when a small fraction of points in the image under test were used for the classification phase.	bayesian network;sampling (signal processing)	Víctor Ayala-Ramírez;Mateusz Obara-Kepowicz;Raúl Enrique Sánchez-Yáñez;René Jaime-Rivas	2003		10.1109/ICSMC.2003.1244188	sampling;machine learning;pattern recognition;mathematics;statistics	Vision	44.31434337758986	-54.70823770619425	49479
6b52645eeacb12bafef6a08f460ed03a5a9b2952	hypergeometric filters for optical flow and affine matching	filtering;image recognition;reconocimiento imagen;filtrage;transformation affine;algorithm performance;image processing;etude experimentale;image matching;implementation;filtrado;procesamiento imagen;traitement image;algorithme;algorithm;ejecucion;translation;resultado algoritmo;affine transformation;reconnaissance image;performance algorithme;optical flow;translacion;frequency domain;estudio experimental;transformacion afin;exhaustive search;image warping;algoritmo	This paper proposes new “hypergeometric” filters for the problem of image matching under the translational and affine model. This new set of filters has the following advantages: (1) High-precision registration of two images under the translational and affine model. Because the window effects are eliminated, we are able to achieve superb performance in both translational and affine matching. (2) Affine matching without exhaustive search or image warping. Due to the recursiveness of the filters in the spatial domain, We are able to analytically express the relation between filter outputs and the six affine parameters. This analytical relation enables us to directly compute these affine parameters. (3) Generality. The approach we demonstrate here can be applied to a broad class of matching problems as long as the transformation between the two image patches can be mathematically represented in the frequency domain.	brute-force search;image registration;image warping;optical flow;recursion (computer science)	Yalin Xiong;Steven A. Shafer	1997	International Journal of Computer Vision	10.1023/A:1007915105826	filter;image warping;translation;affine space;computer vision;combinatorics;discrete mathematics;affine coordinate system;affine involution;image processing;computer science;affine geometry of curves;affine hull;brute-force search;affine arithmetic;optical flow;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;affine combination;implementation;frequency domain	Vision	49.46983745128411	-59.807806904122145	49738
717b210ba2b5e9bfaa68b4c6886af42379e6cb28	improvement and invariance analysis of orthogonal fourier-mellin moments	trademark;metodo momento;evaluation performance;invariance echelle;performance evaluation;moment method;recherche image;analyse fourier;information retrieval;evaluacion prestacion;invarianza escala;scale;orthogonal fourier mellin moments;invariance;moment fourier melin orthogonal;shape;recherche information;methode moment;pattern recognition;fourier analysis;analisis fourier;rotacion;recuperacion informacion;reconnaissance forme;reconocimiento patron;rotation;scale invariance;image retrieval	YE BIN, PENG JIA-XIONG, REN QIU-SHI and LI WAN-RONG Institute for Laser Medicine & Bio-Photonics, College of Life Science & Technology, Shanghai Jiao Tong University, Shanghai 200030, P.R. China State Key Lab. for Image Processing & Intelligent Control, Institute for Pattern Recognition & Artificial Intelligence, Huazhong University of Science & Technology, Wuhan, Hubei, 430074, P.R. China Binyee@sina.com	artificial intelligence;image processing;intelligent control;pattern recognition;wan optimization	Bin Ye;Jia-Xiong Peng;Qiu-Shi Ren;Wan-Rong Li	2003	IJPRAI	10.1142/S0218001403002757	velocity moments;scale;rotation;image retrieval;shape;computer science;invariant;scale invariance;calculus;pattern recognition;mathematics;geometry;fourier analysis;statistics	AI	42.58298706962822	-62.136624160134254	49864
d89ce5ecb9813faed7d721e3bf110facfc2ee8f3	multiple-angle 3d video technology for distant live concerts	systeme video multiangle;image tridimensionnelle;eficacia sistema;systeme multicamera;networks;affichage;image processing;modelo 3 dimensiones;visualizacion;music performance;high speed networks;modele 3 dimensions;real time;performance systeme;procesamiento imagen;stereoscopic cameras;three dimensional model;stereoscopic displays;stereoscopy;system performance;traitement image;display;image transmission;transmission video;video cameras;camera video;stereoscopie;tridimensional image;estereoscopia;video;transmission image;3d video;stereoscopic display;cameras;imagen tridimensional;transmision imagen	We are developing a multiple-angle 3D-video system that will allow an audience to enjoy a concert in real time at a distant location by simultaneously shooting multiple stereoscopic images from different angles and transmitting them through a high-speed network. At the receiving side, a decoder restores the original image signals from the received data, and different video images are shown on multiple stereoscopic displays. As a result, the audience can enjoy multiple images of a concert at the same time. The purpose of this system is to give a remote audience the opportunity to enjoy a live concert as though they were at the concert site. This paper examines the technical requirements for the camera arrangement and the transmission rate needed to transmit images of a musical performance with this system. We have built an experimental system with four stereo cameras, and have experimentally transmitted musical performance images to test the system performance. In this paper, we also propose a method for transmitting multiple camera images more efficiently..	data compression;download;experiment;experimental system;gigabit;internet backbone;requirement;stereo camera;stereo cameras;stereoscopy;transmitter	Tetsuri Inoue;Kazumi Komiya;Keiko Momose;Yoshiyori Urano;Hideyoshi Tominaga	2002		10.1117/12.460175	computer vision;geography;multimedia;computer graphics (images)	Vision	48.98163381244754	-55.40563506304249	50008
9298ae100a75ec856f295e929fdd997141457cff	fast image alignment using anytime algorithms	image alignment;mean square;anytime algorithm;fast imaging;mutual information;image similarity	Image alignment refers to finding the best transformation from a fixed reference image to a new image of a scene. This process is often guided by similarity measures between images, computed based on the image data. However, in time-critical applications state-of-the-art methods for computing similarity are too slow. Instead of using all the image data to compute similarity, one can use a subset of pixels to improve the speed, but often this comes at the cost of reduced accuracy. This makes the problem of image alignment a natural application domain for deliberation control using anytime algorithms. However, almost no research has been done in this direction. In this paper, we present anytime versions for the computation of two common image similarity measures: mean squared difference and mutual information. Off-line, we learn a performance profile specific to each measure, which is then used on-line to select the appropriate amount of pixels to process at each optimization step. When tested against existing techniques, our method achieves comparable quality and robustness with significantly less computation.	anytime algorithm;application domain;computation;computer vision;mathematical optimization;mean squared error;modal logic;mutual information;online and offline;pixel;real-time clock;window of opportunity	Rupert Brooks;Tal Arbel;Doina Precup	2007			computer vision;feature detection;theoretical computer science;machine learning;mathematics;mutual information;non-local means;statistics	AI	53.73704238283951	-58.67438830790212	50142
b3ec4ceea040b7b4129ee5d71b4f95539bf876b7	a robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry	metodo relajacion;metodo correlacion;image processing;robust matching;geometrie algorithmique;correlation method;image matching;least median of squares;computational geometry;procesamiento imagen;fundamental matrix;methode relaxation;traitement image;epipolar geometry;relaxation method;relaxation;geometria computacional;correlation;geometric constraints;methode correlation;exhaustive search	"""This paper proposes a robust approach to image matching by exploiting the only available geometric constraint, namely, the epipolar constraint. The images are uncalibrated, namely the motion between them and the camera parameters are not known. Thus, the images can be taken by diierent cameras or a single camera at diierent time instants. If we m a k e an exhaustive search for the epipolar geometry, the complexity is prohibitively high. The idea underlying our approach is to use some classical techniques (correlation and relaxation methods in our particular implementation) to nd an initial set of matches, and then use a robust technique|the Least Median of Squares (LMedS)|to discard false matches in this set. The epipolar geometry can then be accurately estimated using a well adapted criterion. More matches are eventually found, as in stereo matching, by using the recovered epipolar geometry. A large number of experiments have been carried out, and very good results have been obtained. Regarding the relaxation technique, we deene a new measure of matching support, which allows a higher tolerance to deformation with respect to rigid transformations in the image plane and a smaller contribution for distant matches than for nearby ones. A new strategy for updating matches is developed, which only selects those matches having both high matching support and low matching ambiguity. The update strategy is diierent from the classical \winner-take-all"""", which is easily stuck at a local minimum, and also from \looser-take-nothing"""", which is usually very slow. The proposed algorithm has been widely tested and works remarkably well in a scene with many repetitive patterns. Mise en correspondance robuste d'images non calibr ees par recouvrement d e l a g eom etrie epipolaire R esum e : Dans cet article, nous proposons une approche robuste au probl e m e d e l a m i s e en correspondance de primitives dans le cas d'images non calibr ees i.e on ne dispose ni du mouvement e n tre les cam eras ni des param etres intrins eques associ es a c hacune des cam eras. Les images peuvent ainsi ^ etre consid er ees comme prises par une m^ eme cam era a d i erents instants ou par un syst eme st er eoscopique de 2 cam eras. D^ u u a la complexit e d e l a t ^ ache, une recherche exhaustive d e l a g …"""	algorithm;brute-force search;computer stereo vision;council for educational technology;entity–relationship model;epipolar geometry;experiment;image plane;image registration;linear algebra;linear programming relaxation;maxima and minima;param;relaxation (iterative method)	Zhengyou Zhang;Rachid Deriche;Olivier D. Faugeras;Quang-Tuan Luong	1995	Artif. Intell.	10.1016/0004-3702(95)00022-4	computer vision;mathematical optimization;image processing;computational geometry;computer science;artificial intelligence;relaxation;brute-force search;mathematics;geometry;fundamental matrix;correlation;relaxation;epipolar geometry	Vision	49.752795621048634	-56.40671151416506	50294
a292f1c71830a5ecc0f88915b935fdac243e12ee	explosives detection systems (eds) for aviation security	analisis imagen;traitement signal;computer aided analysis;aeronautique;analyse assistee;articulo sintesis;analisis datos;securite;pattem recognition;article synthese;screening;captador quimico;chemical sensor;data analysis;signal processing;gas detector;detecteur de gaz;safety;explosives;capteur chimique;pattern recognition;terrorisme;aeronautica;analyse donnee;analisis asistido;image analysis;explosivo;reconnaissance forme;reconocimiento patron;aeronautics;review;terrorismo;security;seguridad;procesamiento senal;analyse image;detector de gas;terrorism;explosif	The detection of explosives and illicit material for the purposes of aviation security is an important area for preventing terrorism and smuggling. A number of di-erent methods of explosive detection have been developed in the past that can detect such material from a very small up to a very large quantity. For the purposes of aviation security, the checks are performed on passengers, their carry on luggage, checked baggage, and cargo containers. Similar technology is used in post-o2ces for detecting dangerous substances in mail. In this paper we review some of these technologies and in particular discuss the application of computers for the analysis of data and images generated from security equipment. ? 2002 Elsevier Science B.V. All rights reserved.	airport security;computer;extended data services;sensor	Peng Wang;Maneesha Singh	2003	Signal Processing	10.1016/S0165-1684(02)00391-2	computer vision;image analysis;explosive material;computer science;engineering;signal processing;terrorism;forensic engineering;data analysis;computer security	Security	45.95956684899557	-61.34858531745655	50331
bea61ad8545b2f67d92fa9fac8f5a86779da6977	image analysis for advertisement purposes: a computational model of visual perception	analisis imagen;modele mathematique;systeme nerveux central;computer model;simulation;hombre;simulacion;modelo matematico;encefalo;corteza visual;sistema nervioso central;encephale;fourier transformation;retina;cognition;transformation fourier;human;retine;mathematical model;aparato visual;cognicion;cerebral cortex;appareil visuel;image analysis;visual perception;cortex cerebral;publicidad;publicite;analyse image;visual system;vision;corteza cerebral;cortex visuel;visual cortex;central nervous system;homme;transformacion fourier;advertising;brain vertebrata	-The present contribution describes a new procedure to evaluate the optical conspicuousness of advertisement boards in a natural environment. The object of this procedure is the computer-aided positioning of advertisements, as well as optimizing the layout of individual boards or posters. For this purpose, the scenario to be examined within a modelling process is first geometrically described. The geometric models thus created contain additional attributes, such as color and luminance at calibrated illumination. A ray casting process then creates an image of the board to be evaluated and of its environment from an observer position to be analyzed. To evaluate the optical conspicuousness a two-pass-model of the human visual system is presented, modelling the retina by way of isotropic Laplace-filters and simple cells of the visual cortex by anisotropic edge extractors and Fourier transform. The image analysis giving a quantitative measure for optical conspicuousness is carried out on the image presentations appearing in the individual model phases. The method of the procedure described here is documented with examples and compared with classical methods of eye-tracking in psychology of advertising.	computational model;eye tracking;image analysis;ray casting	Markus H. Gross	1992	Computers & Graphics	10.1016/0097-8493(92)90049-2	fourier transform;vision;computer vision;image analysis;cognition;visual system;visual perception;computer science;central nervous system;mathematical model	Vision	51.76789889558937	-58.44566512390537	50341
7c59b5108bde12448a07aeb06d1c222973d6505a	joint point and line segment matching on wide-baseline stereo images	image segmentation three dimensional displays junctions motion segmentation robustness image matching feature extraction;image segmentation;image matching;junctions;motion segmentation;3d line segment reconstruction joint point matching line segment matching wide baseline stereo images v junctions epipolar line constraint topological distribution constraint;three dimensional displays;feature extraction;topology image matching image reconstruction stereo image processing;robustness	This paper presents an method that matches points and line segments jointly on wide-baseline stereo images. In both two images to be matched, line segments are extracted and those spatially adjacent ones are intersected to generate V-junctions. To match V-junctions from the two images, we extract for each of them an affine and scale invariant local region and describe it with SIFT. The putative V-junction matches obtained from evaluating their description vectors are refined subsequently by the epipolar line constraint and topological distribution constraint among neighbor V-junctions. Since once a pair of V-junctions are matched, the two pairs of line segments forming them are matched accordingly. A part of line segments from the two images are therefore matched along with V-junction matches. To get more line segment matches, we further match those left unmatched line segments by the local homographies estimated from their adjacent V-junction matches. Experiments verify the robustness of the proposed method and its superiority to both some famous point and line segment matching methods on wide-baseline stereo images. In addition, we also show the proposed method can make it easier for 3D line segment reconstruction.	baseline (configuration management);epipolar geometry;geographic information system;image registration;information engineering;p–n junction;scale-invariant feature transform	Kai Li;Jian Yao;Menghan Xia;Li Li	2016	2016 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2016.7477734	computer vision;feature extraction;computer science;machine learning;pattern recognition;mathematics;image segmentation;line segment intersection;robustness	Vision	44.80913307751723	-53.0536834505668	50352
619c826349903ff5fa6d8269736ebffb0d4e5b80	facial expression synthesis based on expressional feature space and expression decomposition	mouth;space technology costs facial features humans computer science software engineering helium educational institutions robustness image generation;expression decomposition;vector space;feature space;facial vector space facial expression synthesis expression decomposition feature space face image;face recognition;facial vector space;facial features;face;humans;space technology;facial expression;face image;facial expression synthesis;nose	In this paper, we present a robust facial expression synthesis approach according to expression decomposition which based on the concept of expressional feature space. Decompose face image into facial features and expressional features, and locate facial features points and expressional landmarks automatically through ASM technology. We establish expressional vector space and facial vector space by set basic expressional vector and basic facial vector. Finally establish mapping from expressional vector space to facial vector space, and generate facial expression image. Experiment shows that the approach can synthesize arbitrary intensity new expressions based on the original expressions rapidly and effectively.	experiment;feature vector;regular expression	Dongjian He;Jinglei Tang;Xu Jing	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1010	facial recognition system;face;computer vision;speech recognition;feature vector;vector space;computer science;pattern recognition;mathematics;space technology;facial expression	Graphics	39.21848022928602	-57.501460097774405	50380
0908aacc5a57da5b69db08da18858dea98a8d24d	a mean shift based small target tracking algorithm in colored video	target tracking image color analysis histograms interpolation entropy algorithm design and analysis kernel;image features;histograms;kernel;interpolation;time complexity;video signal processing;kernel density estimation;target location mean shift based small target tracking algorithm colored video target image information bilinear interpolation algorithm histogram equalization algorithm target model kernel density estimation algorithm equalized image space time complexity;mean shift;small target;computational complexity;image color analysis;image colour analysis;kernel density estimate;kernel density estimation small target interpolation histogram equalization mean shift;entropy;target tracking;algorithm design;algorithm design and analysis;histogram equalization;video signal processing computational complexity image colour analysis interpolation target tracking	It is difficult to track small targets in colored videos using traditional tracking algorithms because of the lack of the target image information. A tracking algorithm was proposed to track small targets in colored videos whose size was from 7×7 pixels to 25×25 pixels. The algorithm included five steps: (1) a bilinear interpolation algorithm was applied to enlarge the target and the surrounding region; (2) a histogram equalization algorithm was used to enhance the image features of the enlarged region; (3) the target model and the target candidates were established by kernel density estimation algorithm in the enlarged and equalized image space; (4) the target location in the enlarged image was obtained by mean shift method; and (5) the location of target was transformed from the enlarged image to the original image. The time complexity of the proposed algorithm is O(n). The testing results showed that the algorithm was able to track the small targets steadily, accurately and quickly. The deviation of target location was zero for most frames and no more than 2 pixels for a few frames in which the target rotated at a large angle. The time spent in tracking the small target in a frame was 15 and 16 ms for the two testing cases in this study.	algorithm;bilinear filtering;dvd region code;histogram equalization;interpolation;kernel density estimation;mean shift;pixel;time complexity	Yimei Kang;Guan Wang;Jiang Hu	2011	2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SoCPaR.2011.6089278	kernel density estimation;algorithm design;computer vision;mathematical optimization;computer science;pattern recognition;mathematics	Vision	45.51137271369052	-53.84534104752274	50494
4b980a63914a43dcd36513599e8c2c21a4eafd43	a class of generalized median contour problem with exact solution	analisis imagen;modelizacion;dynamic programming;vision ordenador;programacion dinamica;metric space;espace metrique;analisis estadistico;image processing;analisis estructural;espacio metrico;edge detection;exact solution;metodo formal;methode formelle;procesamiento imagen;dynamic program;segmentation;solucion exacta;mediane;median;traitement image;formal method;computer vision;deteccion contorno;optimization problem;modelisation;detection contour;analyse syntaxique;statistical analysis;realite terrain;mathematical programming;analisis sintaxico;syntactic analysis;analyse statistique;programmation dynamique;borne inferieure;parameter space;methode moyenne;pattern recognition;realidad terreno;image analysis;vision ordinateur;ground truth;mediana;reconnaissance forme;analyse structurale;solution exacte;reconocimiento patron;structural analysis;modeling;analyse image;programmation mathematique;averaging method;programacion matematica;segmentacion;lower bound;metodo medio;cota inferior	The ability to find the average of a set of contours has several applications in computer vision including prototype formation and computational atlases. While contour averaging can be handled in an informal manner, the formal formulation within the framework of generalized median as an optimization problem is attractive. In this work we will follow this line. A special class of contours is considered, which start from the top, pass each image row exactly once, and end in the last row of an image. Despite of the simplicity they frequently occur in many applications of image analysis. We propose a dynamic programming approach to exactly compute the generalized median contour in this domain. Experimental results will be reported on two scenarios to demonstrate the usefulness of the concept of generalized median contours. In the first case we postulate a general approach to implicitly explore the parameter space of a (segmentation) algorithm. It is shown that using the generalized median contour, we are able to achieve contour detection results comparable to those from explicitly training the parameters based on known ground truth. As another application we apply the exact median contour to verify the tightness of a lower bound for generalized median problems in metric space.	contour line	Pakaket Wattuya;Xiaoyi Jiang	2006		10.1007/11815921_11	optimization problem;computer vision;image analysis;systems modeling;edge detection;image processing;ground truth;metric space;computer science;median cut;artificial intelligence;dynamic programming;parsing;mathematics;geometry;structural analysis;parameter space;upper and lower bounds;segmentation;median;algorithm	ECom	50.092308553219176	-60.68194936389392	50550
cb60d34cef9e2d1b103a7a29b55d297b37e4ea93	video adaptation for small display based on content recomposition	hand held device;analisis contenido;traitement signal;video object;evaluation performance;navegacion informacion;video adaptation;performance evaluation;visual attention model;visual attention model content recomposition media aesthetics region of interest video adaptation;video signal processing;content recomposition;navigation information;video attention model;evaluacion prestacion;information browsing;media aesthetics;base connaissance;reseau omnipresent;region interes;qualite image;atencion visual;ubiquitous network;displays video sharing video on demand layout streaming media adaptation model internet application software cellular phones smart phones;content analysis;video attention model video adaptation small display content recomposition small hand held devices pervasive media environment;portable equipment;red ubicua;feature extraction;signal processing;region of interest;image quality;small display;object extraction;base conocimiento;small hand held devices;calidad imagen;extraccion objeto;attention visuelle;region interet;extraction caracteristique;analyse contenu;pervasive media environment;visual attention;procesamiento senal;appareil portatif;extraction objet;aparato portatil;interest region;knowledge base	The browsing of quality videos on small hand-held devices is a common scenario in pervasive media environments. In this paper, we propose a novel framework for video adaptation based on content recomposition. Our objective is to provide effective small size videos which emphasize the important aspects of a scene while faithfully retaining the background context. That is achieved by explicitly separating the manipulation of different video objects. A generic video attention model is developed to extract user-interest objects, in which a high-level combination strategy is proposed for fusing the adopted three types of visual attention features: intensity, color, and motion. Based on the knowledge of media aesthetics, a set of aesthetic criteria is presented. Accordingly, these objects are well reintegrated with the direct-resized background to optimally match the specific screen sizes. Experimental results demonstrate the efficiency and effectiveness of our approach	high- and low-level;mobile device;pervasive informatics	W.-H. Cheng;C.-W. Wang;J.-L. Wu	2007	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2006.885717	image quality;computer vision;knowledge base;content analysis;feature extraction;computer science;signal processing;multimedia;computer graphics (images);region of interest	Vision	42.95092894789335	-62.2890690850154	50567
31f05700d0699f3a51aa27e03ed17a8a177084a0	multiscale handwriting characterization for writers' classification	document structure;analisis imagen;text;linearity;analisis datos;estructura documental;caracter manuscrito;methode echelle multiple;structure document;linearite;manuscript character;text analysis;courbure;metodo escala multiple;texte;analyse multiresolution;classification;linearidad;analyse texte;data analysis;curvatura;analyse donnee;curvature;image analysis;multiscale method;texto;multiresolution analysis;caractere manuscrit;analyse image;clasificacion;analisis multiresolucion	In this paper, we propose a method for handwritten text characterization based on a multiscale and multiresolution drawing analysis. The approach lies on the definition of four complementary handwritten text visual dimensions: the macro and micro orientation (obtained with a frequencies multiscale image analysis), the text linearity (defined by the merge of connected components), the curvature (measured as a multiresolution high profile deformation) and the complexity (expressed as multiscale drawing distribution entropy). Each feature is studied in an evolution graph that can be expressed as a unique handwritten curve signature. It leads to a description in separable writers families having individual visual characteristics. The results are very promising.	connected component (graph theory);image analysis	Véronique Eglin;Stéphane Bres;Carlos Rivero	2004		10.1007/978-3-540-28640-0_32	multiresolution analysis;computer vision;image analysis;speech recognition;biological classification;computer science;document structure description;mathematics;linearity;curvature;data analysis;algorithm	Vision	43.715092362918256	-61.927748020268844	50710
f49fd630b63ece165bdc6cd22b1c3c33216c5541	separability based tree structured local basis selection for texture classification	libraries;wavelet analysis;filtering;decomposition;image segmentation;filter bank;2d signals;texture classification;image segmentation image texture image classification wavelet transforms signal detection;signal detection;image classification;wavelet packet trees;segmentation;detection;classification tree analysis wavelet packets filter bank wavelet analysis filtering acoustic waves performance analysis libraries frequency wavelet domain;wavelet packet;image texture;task dependent selection;wavelet transforms;algorithm;1d signals separability based tree structured local basis selection texture classification algorithm task dependent selection wavelet packet trees signal classification parent node decomposition subband local trigonometric basis functions detection segmentation 2d signals;local trigonometric basis functions;subband;tree structure;signal classification;performance analysis;classification tree analysis;acoustic waves;wavelet packets;parent node;wavelet domain;frequency;1d signals;separability based tree structured local basis selection	A new algorithm for task dependent selection of wavelet packet trees for signal classification is suggested. The algorithm is based on a class separability measure rather than energy or entropy. At each level the class separabilities obtained from a parent node and its children are computed and compared. The decomposition of the node (or subband) is performed if it provides larger separability. The suggested algorithm is tested for texture classification. The method can also be used with other tree structured local basis e.g. local trigonometric basis functions. Also it can be applied to detection, classification or segmentation of different l-D and 2-D signals. >	linear separability;statistical classification	Kamran Etemad;Rama Chellappa	1994		10.1109/ICIP.1994.413768	filter;image texture;wavelet;acoustic wave;computer vision;contextual image classification;speech recognition;computer science;machine learning;frequency;pattern recognition;filter bank;mathematics;wavelet packet decomposition;image segmentation;tree structure;decomposition;segmentation;detection theory;wavelet transform	Vision	39.522061788992154	-63.47489981090136	50888
2f867911f0ce8fd0e13211025e20e830f06a4353	human visual perception, gestalt principles and duality region-contour - application to computer image analysis of human cornea endothelium	image analysis;human visual perception	The human visual system is far more efficient than a computer to analyze images, especially when noise or poor acquisition process make the analysis impossible by lack of information. To mimic the human visual system, we develop algorithms based on the gestalt theory principles: proximity and good continuation. We also introduce the notion of mosaic that we reconstruct with those principles. Mosaics can be defined as geometry figures (squares, triangles), or issued from a contour detection system or a skeletonization process. The application presented here is the detection of cornea endothelial cells. They present a very geometric structure that give enough information for a non expert to be able to perform the same analysis as the ophthalmologist, that mainly consists on counting the cells and evaluating the cell density.	algorithm;continuation;gestalt psychology;human visual system model;image analysis;image noise;ncsa mosaic	Yann Gavet;Jean-Charles Pinoli;Gilles Thuret;Philippe Gain	2007			computer vision;image analysis;visual perception;computer science	ML	51.403458714531844	-59.90503186276245	51043
b79e40cd241ac7d8a64a4a4ee455ea1050d0d5cc	orientation-based discrete hough transform for line detection with low computational complexity	voting space reduction;parameter space reduction;line detection;accuracy;computational complexity;hough transform	Using discrete representation of line segments, recently Lee and Park presented an efficient discrete Hough transform (DHT) to improve the robustness of the standard HT (SHT). However, the DHT has much higher computational complexity than the SHT. In this paper, we present an orientation-based DHT (ODHT) which consists of two strategies, the parameter space-selection strategy and the voting space-reduction strategy, to substantially reduce the computational complexity of the DHT. Besides its low computational merit, the proposed ODHT can also improve the detection accuracy of the DHT. Experimental results demonstrated that the proposed ODHT leads to 79.26%79.26% average execution-time improvement ratio and better detection accuracy when compared with the state-of-the-art DHT by Lee and Park.	computational complexity theory;edge detection;hough transform	Kuo-Liang Chung;Yong-Huai Huang;Shiang-Ren Tsai	2014	Applied Mathematics and Computation	10.1016/j.amc.2014.03.128	hough transform;computer vision;theoretical computer science;machine learning;mathematics;accuracy and precision;computational complexity theory;algorithm	Vision	40.50002061371021	-56.52379291352919	51214
50ef1c3208579948ea3034f92ab0ce0d82d459f6	affine invariant for 2d image representation: a wavelet approach	discrete wavelet transforms;object recognition;object recognition affine transforms image representation discrete wavelet transforms;signal starting point affine invariant for 2d image representation 2d shape representation discrete dyadic wavelet transform stationary wavelet transform;shape representation;wavelet transform;image representation;affine transformation;affine transforms;image representation discrete wavelet transforms shape object oriented databases spatial databases signal processing algorithms discrete transforms testing marine animals object recognition;stationary wavelet transform;invariant feature	The aim of this paper is to propose a method for 2D shape representation under affine transform using the discrete dyadic wavelet transform invariant to translation known as stationary wavelet transform or SWT. The main problem of this transform is its dependence to the signal starting point i.e (the same signal may have several representations depending on the starting point). The choice of the starting point is then necessary to match two descriptors. The method we propose is developed in three steps, a) the contour is first parameterized by enclosed area, b) the affine invariant feature is then calculated to finally c) determine the natural axis which enable to fix the starting point. The knowledge of the orientation of the natural axis enables to adjust the starting point on the contour between the query and the models given in the database. Furthermore, the method can select a subset of useful invariant features for the matching step. The method is tested on a database of 5000 fish species and the results are very probate.	apache axis;dyadic transformation;emoticon;standard widget toolkit;stationary process;stationary wavelet transform	Kimcheng Kith;El-hadi Zahzah	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1529795	multiresolution analysis;wavelet;computer vision;constant q transform;discrete mathematics;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;cognitive neuroscience of visual object recognition;pattern recognition;cascade algorithm;affine transformation;harris affine region detector;mathematics;wavelet packet decomposition;stationary wavelet transform;affine shape adaptation;affine combination;discrete wavelet transform;lifting scheme;wavelet transform	Vision	41.68528779330191	-59.51206572330292	51229
3bfbaad014a9c893128c64706572963b06d7b49b	object segmentation within microscope images of palynofacies	microfossils;computadora;tratamiento datos;computers;image processing;vitrinita;ordinateur;palynomorphe;call centre;data processing;traitement donnee;segmentation;palinomorfo;traitement image;algorithme;object segmentation;multiple objectives;inertinita;palynomorphs;inertinite;algorithms;analyse automatisee;watershed;microfosil;microfossile;algoritmo;automated analysis;vitrinite	Identification of fossil material under a microscope is the basis of micropalentology. Our task is to locate and count the pieces of inertinite and vitrinite in images of sieve sampled rock. The classical watershed algorithm oversegments the objects because of their irregular shapes. In this paper we propose a method for locating multiple objects in a black and white image while accounting for possible overlapping or touching. The method, called Centre Supported Segmentation (CSS), eliminates oversegmentation and is robust against differences in size and shape of the objects. Crown Copyright r 2008 Published by Elsevier Ltd. All rights reserved.	algorithm;cascading style sheets;controlled grammar;crown group;dust: an elysian tail;experiment;fossil;image resolution;maxima;online and offline;pollen;sieve (mail filtering language);sputter cleaning;watershed (image processing)	J. J. Charles;Ludmila I. Kuncheva;B. Wells;Ik Soo Lim	2008	Computers & Geosciences	10.1016/j.cageo.2007.09.014	computer vision;watershed;data processing;image processing;computer science;mineralogy;segmentation	AI	46.42687911350593	-63.2969234542375	51248
a91d9d3427aabdf592c9aefa1fd7f209a7cf830a	centralized and distributed multi-view correspondence	tolerancia falta;modelizacion;graph theory;distributed system;random graph;sistema multiple;evaluation performance;crash failure;correspondence;teoria grafo;systeme reparti;failure;performance evaluation;image processing;averia franca;correction erreur;evaluacion prestacion;grafo aleatorio;heuristic method;false negative;procesamiento imagen;image multiple;probabilistic algorithm;multiple system;metodo heuristico;imagen multiple;graphe aleatoire;probabilistic approach;theorie graphe;mathematical analysis;traitement image;multiple image;distributed vision;multiple view;random graphs;modelisation;distributed multi camera system;detectabilidad;sistema repartido;fracaso;wide baseline stereo;detectabilite;detectability;enfoque probabilista;approche probabiliste;error correction;robustesse;fault tolerance;vue multiple;coordinacion;robustness;methode heuristique;correccion error;panne franche;false positive;computational efficiency;modeling;multi view;tolerance faute;vista multiple;coordination;robustez;echec;systeme multiple	A probabilistic algorithm is presented for finding correspondences across multiple images in systems with large numbers of cameras and considerable overlap. The algorithm employs the theory of random graphs to provide an efficient probabilistic algorithm that performs Wide-baseline Stereo (WBS) comparisons on a small number of image pairs, and then propagates correspondence information among the cameras. A concrete mathematical analysis of its performance is given. The algorithm is extended to handle false-positive and false-negative failures of the WBS computations. We characterize the detectability of the existence of such failures, and propose an efficient method for this detection. Based on this, we propose a heuristic method for discarding false matches, and demonstrate its effectiveness in reducing errors. Since in many multi-camera applications cameras are attached to processors that handle local processing and communication, it is natural to consider distributed solutions that make use of the local processors and do not use a central computer. Our algorithm is especially suited to run in a distributed setting. If the local processors are sufficiently powerful, this allows an order of magnitude increase in computational efficiency. More importantly, a distributed implementation provides strong robustness guarantees, and eliminates the existence of a single point of failure that is inherent when the application is coordinated by a central computer. We show how to efficiently overcome processor crashes and communication failures with a minimal reduction in the quality of the algorithm’s results.	baseline (configuration management);central processing unit;centralized computing;computation;heuristic;negative feedback;random graph;randomized algorithm;reliability engineering;single point of failure;work breakdown structure	Shai Avidan;Yael Moses;Yoram Moses	2005	International Journal of Computer Vision	10.1007/s11263-005-4888-y	random graph;distributed algorithm;image processing;computer science;artificial intelligence;graph theory;theoretical computer science;mathematics;algorithm	Vision	48.24308151881129	-58.01677090956386	51396
7e6c5b2408479d433cb5cf815559edc834bc9ebf	sequence matching of images	query processing;image matching;feature extraction image sequences image matching visual databases query processing indexing;large data sets;indexing method;image sequences matched filters optical filters layout shape evolution biology data mining feature extraction query processing information filtering;indexing;feature extraction;indexation;image sequence;scientific databases;image database image sequence matching similarity matching longest common sequence method feature based indexing query sequence large data set feature based indexing methods feature extraction hypothesis verification query processing;sequence matching;feature based indexing;images;matching method;image sequences;visual databases	We propose an inter-sequence matching method for exact and similarity matching of image sequences. Our method transforms the image sequence matching problem into matching sequences of real numbers. The method does not require sequences t o be of the same length. It uses a modified version of the Longest Common Subsequence (LCS) method for actually matching two sequences. We also propose a feature-based indexing mechanism to filter out those sequences which are matching candidates with a given query sequence from a large d a t a set. Like all ofher feature-based indexing methods, our method maps each sequence into a point in K dimensional space, where K is the number of extracted features for ihe sequence. It operates in two phases, hypothesizing and verification. Lengths and moments (mean and variance) of sequences are used as features. Experimental results indicate that the features and proposed method for query processing do well as a filter.	database;formal verification;longest common subsequence problem;map	Nasser Yazdani;Z. Meral Özsoyoglu	1996		10.1109/SSDM.1996.505915	search engine indexing;feature extraction;computer science;optimal matching;pattern recognition;data mining;information retrieval	DB	41.023143319417436	-58.92355681070169	51544
b4fc427d3d599e6427ad1bb4faf6d9e95c107412	pattern width description through disk cover - application to digital font recognition		"""We consider the concept of """"the width of a figure"""" for objects of complex shapes in order to use it as an integral morphological descriptor in image recognition tasks. In this article we propose a new approach to the description of this concept on the basis of the figures covering by disks of a certain size. The area of the disk cover as a function of the covering disc size is a shape descriptor. Original method for analytical calculation the area of disk cover of polygonal shapes is presented. The method is universal because there is always the possibility of polygonal approximating of complex digital binary images and geometric objects with nonlinear boundary. The method is based on the medial representation of the polygonal figure as a skeleton and a radial function. Our approach ensures high accuracy and computational efficiency calculate the area of disk cover. The effectiveness of the proposed approach is demonstrated for applications in computer font’s recognition problem."""	algorithm;approximation;binary image;computation;computational geometry;computer vision;image analysis;medial graph;nonlinear system;radial (radio);real-time clock	Nikita Lomov;Leonid Mestetskiy	2017		10.5220/0006128804840492	computer vision;speech recognition;computer science	Vision	49.46387120634907	-62.33472375531962	51661
7bbbd3ee3eff45c9b2e76804b668ec42240254c7	a hough transform for detecting the location and orientation of three-dimensional surfaces via color encoded spots	surface location;image recognition;three dimensional acquisition;image recognition knowledge acquisition hough transforms;geometry;vocal tract;structured light;layout;orientation;speech enhancement;surface reconstruction;data mining;three dimensional;shape;optical arrays;voting;knowledge acquisition;hough transforms;shape layout voting speech enhancement surface reconstruction optical arrays geometry spatial resolution data mining face detection;hough transform;face detection;spatial ambiguity hough transform color encoded spots three dimensional acquisition surface location orientation;spatial ambiguity;color encoded spots;spatial resolution	Video-rate three-dimensional (3-D) acquisition is desirable, in particular for capturing the mouth's shape when modeling the vocal tract. In a new structured light technique, scenes are illuminated by an array of circular spots which are color encoded to resolve spatial ambiguity. The position and shape of the imaged spots depend on the location and orientation of the illuminated 3-D surface. We present a novel 3-D Hough transform (HT) to detect 3-D surface location and orientation via the imaged spots, with voting constraints applied to maximize potential accuracy. This new technique is demonstrated to successfully extract the 3-D data for a moving face from images acquired at video-rate.		C. J. Davies;Mark S. Nixon	1998	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/3477.658582	hough transform;vocal tract;layout;three-dimensional space;computer vision;face detection;structured light;image resolution;surface reconstruction;voting;shape;computer science;pattern recognition;mathematics;orientation	Vision	52.95229655507824	-55.3509116846498	51838
453fabcaabfe142faf4394c587a9cbbeda78c85f	an affine invariance contour descriptor based on filtered enclosed area		In this study, we present a one dimensional descriptor for the two dimensional object silhouettes which in theory remains absolutely invariant under affine transforms. The proposed descriptor operates on the affine enclosed area. We design a normalizing contour method. After this normalization, the number of points on a contour between two appointed positions doesnu0027t change with affine transforms. We proof that for the filtered contour, the area of a triangle whose vertices are the centroid of the contour and a pair of successive points on the normalized contour is linear under affine transforms. Experimental results indicate that the proposed method is invariant to: boundary starting point variation, affine transforms even in the case of high deformations and noise on shapes in a given. We also propose a method to simulate the noise contaminating the test shapes and define the signal-to-noise ratio for a shape. In addition, the proposed normalization method can be associated to other algorithms for increasing their robustness to affine transforms and decreasing their complexity in similarity measurements.	contour line	Mingqiang Yang;Kidiyo Kpalma;Joseph Ronsin	2007			affine combination;affine hull;harris affine region detector;affine shape adaptation;affine transformation;affine coordinate system;affine plane;topology;mathematics;affine geometry of curves	Vision	48.23853200968551	-62.54618984225306	52075
3e657a8f71e5da24e6f4f9264db68651c34ddf9c	a computational-geometry approach to digital image contour extraction	image processing;polygonal chain simplification;computational geometry;edge linking;computer science a computational geometry approach to digital image contour extraction utah state university minghui jiang tejada;pedro j;contour extraction;hausdorff distance;point linking	A Computational Geometry Approach to Digital Image Contour Extraction	computation;computational geometry;contour line;digital image	Minghui Jiang;Xiaojun Qi;Pedro J. Tejada	2011	Trans. Computational Science	10.1007/978-3-642-22619-9_2	computer vision;computer science;pattern recognition;computer graphics (images)	Graphics	48.62401301023179	-62.9576699892944	52076
8d2eeee927c0acb19049ab87ae1351ad105cbf59	robust and efficient fourier-mellin transform approximations for gray-level image reconstruction and complete invariant description	image database;visual inspection;image representation;image reconstruction;pattern recognition;numerical approximation;content based image retrieval;image retrieval;mellin transform	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Robust and efficient Fourier-Mellin transform approximations for invariant grey-level image description and reconstruction Stéphane Derrode, F. Ghorbel	algorithm;approximation;archive;comefrom;cartesian closed category;content-based image retrieval;digital image;digital watermarking;distortion;experiment;grayscale;hal;iterative reconstruction;linear algebra;mpeg-7;numerical analysis;pattern recognition;robustness (computer science)	Stéphane Derrode;Faouzi Ghorbel	2001	Computer Vision and Image Understanding	10.1006/cviu.2001.0922	iterative reconstruction;image texture;computer vision;feature detection;visual word;image retrieval;computer science;theoretical computer science;pattern recognition;mathematics;mellin transform;visual inspection	Vision	41.17659909853948	-64.90746351807675	52105
fda8fe7b023451aa75f08a1dfcfa967aef6cee7f	fingerprint minutiae matching without global alignment using local structures	translation invariant;local structures;higher order;local structure;word alignment;minutiae matching;alignment;fingerprint identification	This paper presents a method of minutiae based fingerprint matching that is robust to deformations and does not do fingerprint alignment. It concentrates on comparing rotation and translation invariant local structures defined by minutiae point and its neighboring minutiae points. Then the collection of most probable correspondences of matched minutiae is found. Finally, the local structures of higher order are validated. All three steps are completely rotation and translation invariant, robust to nonlinear deformations and do not use any fingerprint alignment. Experimental results on publicly available as well as internal databases show an improved performance of the proposed method in comparison with the traditional minutiae based algorithms that perform fingerprint registration.	algorithm;database;fingerprint recognition;matched filter;minutiae;nonlinear system;point set registration;rejection sampling	Andrej Kisel;Alexej Kochetkov;Justas Kranauskas	2008	Informatica, Lith. Acad. Sci.		fingerprint;computer vision;speech recognition;higher-order logic;computer science;pattern recognition;mathematics;programming language	Vision	40.95845704623346	-57.0974341428599	52129
682c871722d467d8da24fced78ab216640387ef3	lie-algebraic averaging for globally consistent motion estimation	computer vision;lie groups;epipolar geometry;lie group;motion estimation;lie algebra;system of equations;lie algebras	While motion estimation has been extensively studied in the computer vision literature, the inherent information redundancy in an image sequence has not been well utilised. In particular as many as N(N-1)/2 pairwise relative motions can be estimated efficiently from a sequence of N images. This highly redundant set of observations can be efficiently averaged resulting in fast motion estimation algorithms that are globally consistent. In this paper we demonstrate this using the underlying Lie-group structure of motion representations. The Lie-algebras of the Special Orthogonal and Special Euclidean groups are used to define averages on the Lie-group which in turn gives statistically meaningful, efficient and accurate algorithms for fusing motion information. Using multiple constraints also controls the drift in the solution due to accumulating error. The performance of the method in estimating camera motion is demonstrated on image sequences.	algorithm;computer vision;lie derivative;linear algebra;motion estimation;redundancy (information theory);robot;sensor	Venu Madhav Govindu	2004	Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.	10.1109/CVPR.2004.147	lie algebra;computer vision;structure from motion;topology;quarter-pixel motion;motion estimation;mathematics;geometry;motion field;lie group	Vision	52.213211423622504	-52.557774050865575	52166
a3373a8f63470327831042e76a141b764f3cd23f	content-based image retrieval using a composite color-shape approach	databases;analisis contenido;cluster;forma;visual stimuli;amas;information retrieval;color;image database;image;computer system design;pairing;vecteur;test;ensayo;algorithme;algorithm;essai;content analysis;cluster analysis;shape;imagen;recherche information;information processing;couleur;vector;monton;recuperacion informacion;emparejamiento;analyse contenu;electrical engineering;content based image retrieval;appariement;forme;information seeking;similarity measure;algoritmo	We have proposed a composite feature measure which combines the shape and color features of an image based on a clustering technique. We have also developed a similarity measure to compute the degree of match between a given pair of images. This technique can be used for content-based image retrieval of images using shape and/or color. We have tested our technique on two image databases: one consisting of 100 synthetic images, and another database consisting of 500 actual trademarks images. Test results of the proposed scheme for retrieval of images using only shape, only color, and a weighted combination of the two are presented. The efficiency of retrieval is found to be very high and the experimental results are promising for practical applications.	cluster analysis;color;content-based image retrieval;database;similarity measure;synthetic data	Babu M. Mehtre;Mohan S. Kankanhalli;Wing Foon Lee	1998	Inf. Process. Manage.	10.1016/S0306-4573(97)00049-6	color histogram;computer vision;visual word;content analysis;information processing;vector;visual perception;shape;computer science;artificial intelligence;machine learning;image;pairing;software testing;cluster analysis;automatic image annotation;information retrieval;cluster	Vision	43.495177292245536	-61.58232586234581	52505
19bf971a1fb6cd388c0ba07834dc4ddcbc442318	automatic registration method for optical remote sensing images with large background variations using line segments	main shape contour;remote sensing;image registration;line segment;background variation	Image registration is an essential step in the process of image fusion, environment surveillance and change detection. Finding correct feature matches during the registration process proves to be difficult, especially for remote sensing images with large background variations (e.g., images taken pre and post an earthquake or flood). Traditional registration methods based on local intensity probably cannot maintain steady performances, as differences are significant in the same area of the corresponding images, and ground control points are not always available in many disaster images. In this paper, an automatic image registration method based on the line segments on the main shape contours (e.g., coastal lines, long roads and mountain ridges) is proposed for remote sensing images with large background variations because the main shape contours can hold relatively more invariant information. First, a line segment detector called EDLines (Edge Drawing Lines), which was proposed by Akinlar et al. in 2011, is used to extract line segments from two corresponding images, and a line validation step is performed to remove meaningless and fragmented line segments. Then, a novel line segment descriptor with a new histogram binning strategy, which is robust to global geometrical distortions, is generated for each line segment based on the geometrical relationships,including both the locations and orientations of theremaining line segments relative to it. As a result of the invariance of the main shape contours, correct line segment matches will have similar descriptors and can be obtained by cross-matching among the descriptors. Finally, a spatial consistency measure is used to remove incorrect matches, and transformation parameters between the reference and sensed images can be figured out. Experiments with images from different types of satellite datasets, such as Landsat7, QuickBird, WorldView, and so on, demonstrate that the proposed algorithm is automatic, fast (4 ms faster than the second fastest method, i.e., the rotationand scale-invariant shape context) and can achieve a recall of 79.7%, a precision of 89.1% and a root mean square error (RMSE) of 1.0 pixels on average for remote sensing images with large background variations.	algorithm;distortion;fastest;image fusion;image registration;mean squared error;performance;pixel;product binning;segment descriptor;shape context;thin plate spline;time complexity	Xiaolong Shi;Jie Jiang	2016	Remote Sensing	10.3390/rs8050426	computer vision;line segment;image registration;remote sensing	Vision	52.46670648128263	-55.33816586797914	52632
a751ab7dd38524f8557d5ada0d7817efeec631c3	on invariance analysis of zernike moments in the presence of rotation with crop and loose modes	crop rotation;zernike moments;loose rotation;digital image	Zernike moments are widely applied in digital image processing fields based on many desirable properties, such as rotational invariance, noise robust and efficient representation of pattern. On the computational analysis of Zernike moment is challenging issue. From an algorithmic aspect, in this paper we investigate the effect of image rotation (including crop rotation and loose rotation) operations on Zernike moments in both theoretical and experimental ways. For the crop rotation, we suggest to extract the Zernike moments by mapping the image over a disc instead of inside a circle since the outside of an image after the crop rotation will be distorted. Referring to the loose rotation, we propose a preprocessing step (which is called image size normalization) to embed an image and its rotated versions into a predefined size of zero-value image in such a way that the effect of image size change due to loose rotation can be eliminated. By incorporating the proposed image size normalization operation, we introduce an effective extraction method of image Zernike moments against loose rotation operation. Experimental results show the validity of the proposed extraction method.	algorithm;computation;digital image processing;image resolution;preprocessor	Shijun Xiang	2010	Multimedia Tools and Applications	10.1007/s11042-010-0539-6	velocity moments;computer vision;computer science;crop rotation;digital image	Vision	41.55843472488695	-60.224448713602314	52721
9207b69a714114703b10f61ad4c1f183fb499364	raising local density for object reconstruction using auxiliary points	image sampling;mls surface;add point algorithm;sampling point;high risk point set identification;optical scanners;solid modelling computational geometry feature extraction image reconstruction image sampling mesh generation optical scanners;computational geometry;surface roughness;laser scanner sampling;laser scanner;sampling methods surface reconstruction shape laser modes multilevel systems rough surfaces surface roughness feature extraction computer errors computer vision;triangular mesh;surface reconstruction;triangular mesh construction;multilevel systems;computer vision;rough surfaces;nonfeature points;nonindigenous holes;shape;feature point extraction;feature extraction;image reconstruction;auxiliary points;object reconstruction;local density;sampling methods;mesh generation;laser modes;computer errors;irregular density distribution;solid modelling;nonfeature points local density object reconstruction auxiliary points high risk point set identification surface reconstruction triangular mesh construction laser scanner sampling irregular density distribution nonindigenous holes sampling point add point algorithm mls surface feature point extraction;high risk	"""This investigation proposes a novel method for identifying high-risk point sets before surface reconstruction. Given a set of points P sampled from some unknown surface M, triangular meshes are constructed to approximate the scanned model. The point sets are obtained by laser scanner sampling on the object, so increasing the variance of the object shape increases the likelihood of irregular density distribution and the occurrence of non-indigenous holes. To solve this problem, this study proposes an algorithm to raise density, and to judge whether a new sampling point is required. The add-point algorithm discovers the locations of add-points, and maps them to the MLS surface on the basis of """"feature points extracted"""" and """"non-feature points with insufficient density"""" point sets. The test results demonstrate that the proposed strategy of adding auxiliary points improves the point distribution, and helps prevent the formation of non-indigenous holes. Finally, the auxiliary points are removed and returned to the original point set"""	approximation algorithm;map;sampling (signal processing);triangle mesh;triangulated irregular network	Bin Shyan Jong;Pai-Feng Lee;Juin-Ling Tseng	2006	5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06)	10.1109/ICIS-COMSAR.2006.71	laser scanning;iterative reconstruction;mesh generation;sampling;computer vision;mathematical optimization;surface reconstruction;surface roughness;feature extraction;computational geometry;shape;computer science;triangle mesh;engineering drawing	Vision	47.84617020121424	-65.46388716318367	52741
1d78d29161ed897c11a5e6bb0d66779746dc0d22	fast content-based search of vrml models based on shape descriptors	shape descriptor;virtual reality languages;image matching;performance evaluation content based database search shape descriptors vrml 3d models database querying geometric measurements aspect ratio binary 3d shape mask edge paths similarity measures 3d model matching algorithm;image matching virtual reality languages visual databases content based retrieval image retrieval;3d model;shape measurement solid modeling spatial databases content based retrieval iterative algorithms information processing laboratories data engineering data mining computer networks;shape description;similarity measure;content based retrieval;aspect ratio;visual databases;image retrieval	Thepaper proposes a novel method for content-based search in a database of VRML 3D models. The proposed technique is based on a querying-by-3D-model approach. A set of shape-based descriptors are extracted from the reference 3D model and compared to the corresponding descriptors of the VRML models contained in the database. The descriptors used vary from simple geometric measurements such as the aspect ratio or a binary 3D shape mask to more complex and sophisticated shape-based criteria such as the edge paths of each 3D model. Similarity measures are then introduced for the specific descriptors and introduced into a 3D model-matching algorithm. Experimental results are presented, evaluating the performance of the proposed method.		Ilias Kolonias;Dimitrios Tzovaras;Sotiris Malassiotis;Michael G. Strintzis	2001		10.1109/ICIP.2001.958442	active shape model;computer vision;aspect ratio;visual word;image retrieval;computer science;data mining;information retrieval	Vision	40.08583883451575	-59.47833044354054	53078
490020c0d4fa1eb85fe353add5713e49f08c628d	surf: speeded up robust features	object recognition;vision ordenador;repetabilite;image processing;convolution;repetibilidad;procesamiento imagen;convolucion;reconnaissance objet;traitement image;computer vision;robustesse;pattern recognition;invariante;robustness;vision ordinateur;reconnaissance forme;reconocimiento patron;matrice hessienne;invariant;repeatability;hessian matrices;robustez	We demonstrate the performance of our interest point detector/descriptor scheme SURF – Speeded Up Robust Features – in an application that finds correspondences to a reference image in realtime. The user takes a reference image with a handheld video camera and then moves the camera around the object. The system identifies interest points in every newly acquired image and matches them with the ones in the reference image. The matches are then displayed on a computer screen. This is repeated subsequently for every frame. This application shows the speed and accuracy of SURF. We don’t exploit tracking. For every new image an independent set of interest points is computed and matched with the ones in the reference image, using standard wide baseline matching techniques.	baseline (configuration management);computer monitor;handheld game console;independent set (graph theory);interest point detection;speeded up robust features	Herbert Bay;Tinne Tuytelaars;Luc Van Gool	2006		10.1007/11744023_32	computer vision;repeatability;simulation;image processing;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;invariant;mathematics;convolution;robustness	Vision	48.331863609006795	-57.620916465008	53097
98d6ddb3d11e013550db2a0055642d693a2ba1fa	recursive interpolation technique for binary images based on morphological median sets	image processing;interpolation;mathematical morphology;image analysis;median set.	Interpolation is an important step in many applications of image processing. This paper presents a morphological interpolation technique for binary images based on the median set concept. A characteristic of our method is that it treats recursively the connected components of input slices. This technique uses the minimal skeleton by pruning (MSP) as reference points for translating connected components; this fact guarantees the non-empty intersection between them.	binary image;connected component (graph theory);image processing;interpolation;max;recursion (computer science);rough set	Javier Vidal;José Crespo;Victor Maojo	2005		10.1007/1-4020-3443-1_6	mathematical optimization;bilinear interpolation;stairstep interpolation;nearest-neighbor interpolation;multivariate interpolation	Graphics	48.95633501035436	-64.33474536405998	53100
0fe9d9548e021174aa600bb3b0c4be31dd2bc187	efficient multiple model recognition in cluttered 3-d scenes	object recognition;clutter;shape descriptor;robust performance multiple model recognition cluttered 3 d scenes 3 d shape based object recognition system simultaneous recognition clutter occlusion matching points spin image representation data level shape descriptor surface meshes;layout shape object recognition surface fitting robustness libraries propulsion laboratories information analysis performance analysis;computer vision;multiple objectives;image representation;robust performance;multiple model;computer vision object recognition clutter image representation	We present a 3-D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching sugaces by matching points using the spin-image representation. The spin-image is a data level shape descriptor that is used to match surfaces represented as su$ace meshes. We present a compression scheme for spinimages that results in eficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes.	clutter;outline of object recognition;polygon mesh	Andrew Edie Johnson;Martial Hebert	1998		10.1109/CVPR.1998.698676	computer vision;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;clutter;3d single-object recognition	Vision	42.59933369568792	-57.00316713502614	53117
46857bf4a9e772ee0b34d17a9095bea161f16979	parametric shape recognition using a probabilistic inverse theory	informative viewpoints;object recognition;formation image tridimensionnelle;methode parametrique;3d imaging;probabilidad condicional;metodo parametrico;reference model;parametric method;probabilite conditionnelle;shape recognition;probabilistic approach;probabilistic model;fonction densite;inverse theory;density function;enfoque probabilista;approche probabiliste;funcion densidad;pattern recognition;cpdf;informative viewpoint;reconnaissance forme;reconocimiento patron;formacion imagen tridimensional;conditional probability;belief distribution;density functional	This paper describes a new framework for parametric shape recognition based on a probabilistic model of inverse theory rst introduced by Tarantola. The key result is a method for generating classiiers in the form of conditional probability densities for recognizing an unknown from a set of reference models. Our procedure is automatic. OO-line, it invokes an autonomous process to estimate reference model parameters and their statistics. On-line, during measurement, it combines these with apriori context-dependent information, as well as the parameters and statistics estimated for an unknown object, into a single description. That description, a conditional probability density function, represents the likelihood of correspondence between the unknown and a particular reference model. The paper also describes the implementation of this procedure in a system for automatically generating and recognizing 3-D part-oriented models. Speciically we show that recognition performance is near perfect for cases in which complete surface information is accessible to the algorithm, and that it falls oo gracefully (minimal false-positive response) when only partial information is available. This leads to the possibility of an active recognition strategy in which the belief measures associated with each classiication can be used as feedback for the acquisition of further evidence as required. Abstract. This paper describes a new framework for parametric shape recognition based on a probabilistic model of inverse theory rst introduced by Tarantola. The key result is a method for generating classiiers in the form of conditional probability densities for recognizing an unknown from a set of reference models. Our procedure is automatic. OO-line, it invokes an autonomous process to estimate reference model parameters and their statistics. On-line, during measurement, it combines these with apriori context-dependent information, as well as the parameters and statistics estimated for an unknown object, into a single description. That description, a conditional probability density function, represents the likelihood of correspondence between the unknown and a particular reference model. The paper also describes the implementation of this procedure in a system for automatically generating and recognizing 3-D part-oriented models. Speciically we show that recognition performance is near perfect for cases in which complete surface information is accessible to the algorithm, and that it falls oo gracefully (minimal false-positive response) when only partial information is available. This leads to the possibility of an active recognition strategy in which the belief measures associated with each classiication can be used as feedback for the acquisition of further evidence as …	apriori algorithm;autonomous robot;context-sensitive language;reference model;statistical model	Tal Arbel;Peter Whaite;Frank P. Ferrie	1996	Pattern Recognition Letters	10.1016/0167-8655(96)00008-6	stereoscopy;statistical model;probability density function;reference model;conditional probability;artificial intelligence;cognitive neuroscience of visual object recognition;mathematics;algorithm;statistics	Vision	47.63715099211555	-58.75018232887171	53336
a4490e0dd8619741b1d2932cdbffd183721f6665	dynamic texture analysis and synthesis using tensor decomposition	modelo dinamico;modelizacion;regularite;vision ordenador;image processing;analisis textura;regularidad;tensor calculus;texture synthesis;signal analysis;texture image;dynamic model;regularity;procesamiento imagen;analisis de senal;traitement image;image texture;computer vision;modelisation;calculo tensorial;psychometrie;tensor decomposition;texture analysis;dynamic texture;ivrg;modele dynamique;image sequence;video synthesis;psychometrics;image analysis;vision ordinateur;secuencia imagen;psicometria;imagen color;modeling;analyse texture;image couleur;analyse signal;calcul tensoriel;sequence image;compact model;color image	Dynamic textures are sequences of images showing temporal regularity, such as smoke, flames, flowing water, or moving grass. Despite being a multidimensional signal, existing models reshape the dynamic texture into a 2D signal for analysis. In this article, we propose to directly decompose the multidimensional (tensor) signal, free from reshaping operations. We show that decomposition techniques originally applied to study psychometric or chemometric data can be used for this purpose. Since spatial, time, and color information are analyzed at the same time, such techniques permit to obtain more compact models. Only one third or less model coefficients are needed for the same quality and synthesis cost of 2D based models, as illustrated by experiments on real dynamic textures.	approximation algorithm;coefficient;color;experiment;linear model;mobile device;multidimensional signal processing;sampling (signal processing);singular value decomposition;texture synthesis;tucker decomposition	Roberto Costantini;Luciano Sbaiz;Sabine Süsstrunk	2006		10.1007/11919629_26	image texture;computer vision;tensor calculus;image analysis;systems modeling;color image;image processing;computer science;mathematics;psychometrics;texture synthesis;computer graphics (images)	Vision	51.76941141809013	-62.24269274992341	53454
b4ae38f1786c8c063ea6385e63977ed98b3c8039	model-based human shape reconstruction from multiple views	ajustement surface;modelizacion;animacion por computador;shape from silhouette;hierarchical system;ajustamiento modelo;vision ordenador;image processing;ajustamiento curva;traitement image stereoscopique;detail level;vision estereoscopica;systeme hierarchise;surface fitting;vision stereoscopique;procesamiento imagen;image multiple;model based approach;imagen multiple;forma geometrica;surface reconstruction;traitement image;modele multiple;multiple resolution mesh;niveau detail;multiple views;animal;repere visuel;multiple image;computer vision;multiple view;ajustement modele;modelisation;reconstruction image;sistema jerarquizado;reconstruction surface;vie artificielle;image based modelling;level of detail;realite terrain;reconstruccion imagen;surface deformation;image reconstruction;shape reconstruction;visual cues;surface model;multimodel;model matching;geometrical shape;stereo image processing;stereo vision;architecture basee modele;character animation;vue multiple;preservation;ajustement courbe;realidad terreno;vision ordinateur;ground truth;forme geometrique;modele donnee;reconstruccion superficie;curve fitting;computer animation;modelo multiple;stereopsis;modeling;deformable model;preservacion;animal model;model driven architecture;artificial life;hierarchical model;vista multiple;data models;arquitectura basada modelo;visual cue;marca visual;animation par ordinateur;nivel detalle	Image-based modelling allows the reconstruction of highly realistic digital models from real-world objects. This paper presents a model-based approach to recover animated models of people from multiple-view video images. Two contributions are made, a multiple-resolution model-based framework is introduced that combines multiple visual cues in reconstruction. Secondly a novel mesh parameterisation is presented to preserve the vertex parameterisation in the model for animation. A prior humanoid surface model is first decomposed into multiple levels of detail and represented as a hierarchical deformable model for image fitting. A novel mesh parameterisation is presented that allows propagation of deformation in the model hierarchy and regularisation of surface deformation to preserve vertex parameterisation and animation structure. The hierarchical model is then used to fuse multiple shape cues from silhouette, stereo and sparse feature data in a coarse-to-fine strategy to recover a model that reproduces the appearance in the images. The framework is compared to physics-based deformable surface fitting at a single resolution, demonstrating an improved reconstruction accuracy against ground truth data with a reduced model distortion. Results demonstrate realistic modelling of real people with accurate shape and appearance while preserving model structure for use in animation.	baseline (configuration management);computer graphics;distortion;feature data;geometric modeling;graphics pipeline;ground truth;hierarchical database model;mathematical optimization;maxima and minima;multivariate interpolation;rendering (computer graphics);shape context;signal-to-noise ratio;software propagation;sparse matrix	Jonathan Starck;Adrian Hilton	2008	Computer Vision and Image Understanding	10.1016/j.cviu.2007.10.001	computer vision;image processing;computer science;stereopsis;computer graphics (images)	Vision	51.26720310029153	-56.60536004707119	53592
a5f4bb3cda5241cb684daa3d92e611852e06bf8e	robust signatures for 3d face registration and recognition	electronic engineering;thesis	Biometric authentication through face recognition has been an active area of research for the last few decades, motivated by its application-driven demand. The popularity of face recognition, compared to other biometric methods, is largely due to its minimum requirement of subject co-operation, relative ease of data capture and similarity to the natural way humans distinguish each other. 3D face recognition has recently received particular interest since three-dimensional face scans eliminate or reduce important limitations of 2D face images, such as illumination changes and pose variations. In fact, three-dimensional face scans are usually captured by scanners through the use of a constant structured-light source, making them invariant to environmental changes in illumination. Moreover, a single 3D scan also captures the entire face structure and allows for accurate pose normalisation. However, one of the biggest challenges that still remain in three-dimensional face scans is the sensitivity to large local deformations due to, for example, facial expressions. Due to the nature of the data, deformations bring about large changes in the 3D geometry of the scan. In addition to this, 3D scans are also characterised by noise and artefacts such as spikes and holes, which are uncommon with 2D images and requires a pre-processing stage that is specific to the scanner used to capture the data. The aim of this thesis is to devise a face signature that is compact in size and overcomes the above mentioned limitations. We investigate the use of facial regions and landmarks towards a robust and compact face signature, and we study, implement and validate a region-based and a landmark-based face signature. Combinations of regions and landmarks are evaluated for their robustness to pose and expressions, while the matching scheme is evaluated for its robustness to noise and data artefacts.		Prathap M. Nair	2010			computer vision;speech recognition;computer science;pattern recognition	Vision	42.179806294510534	-54.281164018676165	53612
1ac83d48a7648135ae2921df68cc2a196e6b05f4	interpolation and extrapolation of image partitions using fourier descriptors: application to segmentation-based coding schemes	fourier domain;interpolated partition;image partitions;mathematical morphology;mathematical morphology image segmentation image sequences image coding interpolation extrapolation fourier transforms;interpolation;image coding;image segmentation;region interpolation;morphological tools;sequence partitions;delay effects;extrapolation;deformable models;interpolated regions;morphological tools image partitions fourier descriptors segmentation based coding schemes extrapolation sequence partitions region parametrization region interpolation region ordering partition creation regular motion random deformations fourier domain interpolated partition interpolated regions;regular motion;fourier descriptors;shape;partition creation;region parametrization;discrete cosine transforms;segmentation based coding schemes;conference report;fourier transforms;coherence;random deformations;interpolation extrapolation image sequences image coding coherence image segmentation discrete cosine transforms shape delay effects deformable models;region ordering;image sequences	This paper presents an interpolation/extrapolation technique for sequence partitions. It consists of four steps: region parametrization, region interpolation, region ordering and partition creation. The evolution of each region is divided into two types: regular motion and random deformations. Both types of evolution are parametrized by means of the Fourier descriptors of the regions and they are separately interpolated in the Fourier domain. The nal interpolated partition is built from the ordered combination of the interpolated regions, using morphological tools.	extrapolation;fast fourier transform;interpolation	Ferran Marqués;Bernat Llorens;Antoni Gasull	1995		10.1109/ICIP.1995.537702	fourier transform;computer vision;mathematical optimization;discrete mathematics;mathematical morphology;coherence;interpolation;shape;mathematics;geometry;image segmentation;extrapolation;statistics	Vision	51.94517253511551	-64.87750348122886	53804
1327add23d4bd20f8391d761b18d207b81c45fa9	high-resolution video from series of still photographs	image filtering;filtering;vision ordenador;filtrage;streaming;high resolution;video streaming;image segmentation;image processing;image resolution;esqueleto;imagen fija;flux optique;gauchissement;filtrado;procesamiento imagen;digital camera;image optique;traitement image;skeleton;computer vision;sintesis imagen;image synthesis;haute resolution;transmission en continu;resolucion imagen;senal video;fixed image;signal video;flujo optico;video synthesis;segmentation image;torcimiento;alta resolucion;squelette;video signal;synthese image;imagen optica;image fixe;vision ordinateur;optical flow;transmision fluyente;optical image;resolution image;warping;image warping	In this paper, we explored the problem of creating a highresolution video from a series of still photographs. Instead of enhancing the resolution from the video stream, we consider the problem of generating a high-resolution video as an image synthesis problem. Using the continuous shot in the digital camera, we can get a series of still photographs at 2 to 3 frames pre second. The main challenge in our approach is to synthesize the in between frames from two consecutive still images. The image synthesis approach varies based on the scene motion and image characteristics. We have applied optical flow, image segmentation, image filtering and skeleton based image warping techniques to generate high-resolution video.	algorithm;alpha compositing;computation;digital camera;digital video;filter (signal processing);graphics processing unit;image resolution;image segmentation;image warping;maximum flow problem;optical flow;rendering (computer graphics);stereo camera;streaming media	Ge Jin;James K. Hahn	2006		10.1007/11919476_90	image warping;computer vision;image resolution;image processing;computer science;video tracking;motion compensation;computer graphics (images)	Vision	50.709374841116315	-56.69526538738713	53976
4576912b682357f5e198db425b91f97dcad50563	a descriptor-less well-distributed feature matching method using geometrical constraints and template matching		The problem of feature matching comprises detection, description, and the preliminary matching of features. Commonly, these steps are followed by Random Sample Consensus (RANSAC) or one of its variants in order to filter the matches and find a correct model, which is usually the fundamental matrix. Unfortunately, this scheme may encounter some problems, such as mismatches of some of the features, which can be rejected later by RANSAC. Hence, important features might be discarded permanently. Another issue facing the matching scheme, especially in three-dimensional (3D) reconstruction, is the degeneracy of the fundamental matrix. In such a case, RANSAC tends to select matches that are concentrated over a particular area of the images and rejects other correct matches. This leads to a fundamental matrix that differs from the correct one, which can be obtained using the camera parameters. In this paper, these problems are tackled by providing a descriptor-less method for matching features. The proposed method utilises the geometric as well as the radiometric properties of the image pair. Starting with an initial set of roughly matched features, we can compute the homography and the fundamental matrix. These two entities are then used to find other corresponding features. Then, template matching is used to enhance the predicted locations of the correspondences. The method is a tradeoff between the number and distribution of matches, and the matching accuracy. Moreover, the number of outliers is usually small, which encourages the use of least squares to estimate the fundamental matrix, instead of RANSAC. As a result, the problem of degeneracy is targeted at the matching level, rather than at the RANSAC level. The method was tested on images taken by unmanned aerial vehicles (UAVs), with a focus on applications of 3D reconstruction, and on images taken by the camera of a smartphone for an indoor environment. The results emphasise that the proposed method is more deterministic rather than probabilistic and is also robust to the difference in orientation and scale. It also achieves a higher number of accurate and well-distributed matches compared with state-of-the-art methods.	template matching	Hani Mahmoud Mohammed;Naser El-Sheimy	2018	Remote Sensing	10.3390/rs10050747	ransac;3d reconstruction;geology;computer vision;probabilistic logic;artificial intelligence;fundamental matrix (computer vision);epipolar geometry;degeneracy (mathematics);template matching;least squares	Robotics	44.05162715090548	-52.813246791715095	54079
d3889f3986a6323f50d3cc997432c642b84d8039	edge-detector resolution improvement by image interpolation	deteccion borde;detectors;kernel;image numerique;interpolation;digital image processing;image segmentation;image processing;image resolution;edge detection;interpolacion;search methods;image interpolation;procesamiento imagen;segmentation;digital filter;traitement image;computer applications;algorithme;algorithm;resolution improvement;algorritmo;image edge detection;filter;image reconstruction;pixel;imagen numerica;filtre;cross section;step edges and line edges;digital image;image resolution interpolation image edge detection image processing graphics detectors biomedical computing kernel computer applications search methods;step edges and line edges digital image processing edge detection image interpolation image segmentation resolution improvement;detection bord;filtro;segmentacion;graphics;biomedical computing;noise	Most step-edge detectors are designed to detect locally straight edge-segments which can be isolated within the operator kernel. While it can easily be demonstrated that a cross-sectional support of at least 4 pixels is required for the unambiguous detection of a stepedge, edges which cannot be isolated within windows having this width can nevertheless be resolved. This is achieved by preceding the stepedge detection process by image-intensity interpolation. Although resolution can be improved in this fashion, the step-edge position and intensity estimates thus determined may be subject to systematic biases. Also, the higher resolution performance is accompanied by lower robustness to noise.	cross-sectional data;detectors;edge detection;estimated;interpolation imputation technique;microsoft windows;pixel;width	Vishvjit S. Nalwa	1987	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1987.4767926	computer vision;image processing;interpolation;computer science;theoretical computer science;digital image processing;mathematics;computer graphics (images)	Vision	48.228428371461305	-65.4667133543646	54159
a0205be0fd0e9ddbbda4fdff1ec73966c58d58e4	fast multi model motion segmentation on road scenes		We propose a novel motion clustering formulation over spatio-temporal depth images obtained from stereo sequences that segments multiple motion models in the scene in an unsupervised manner. The motion models are obtained at frame rates that compete with the speed of the stereo depth computation. This is possible due to a decoupling framework that first delineates spatial clusters and subsequently assigns motion labels to each of these cluster with analysis of a novel motion graph model. A principled computation of the weights of the motion graph that signifies the relative shear and stretch between possible clusters lends itself to a high fidelity segmentation of the motion models in the scene. The fidelity is vindicated through accuracies reaching 89.61% on KITTI and complex native sequences.	binocular disparity;cluster analysis;computation;coupling (computer programming);depth perception;spectral clustering	A. K. Jaiswal;Nazrul Haque;Avinash Sharma;K. Madhava Krishna;Shanti Medasani	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500442	decoupling (cosmology);optical imaging;computation;fidelity;frame rate;cluster analysis;computer vision;segmentation;graph;artificial intelligence;mathematics	Vision	52.83705910086993	-53.73967469186193	54488
66126ec1fe61b833ae695db9c5bac54641fab482	evaluation of binarization methods for document images	background noise;stochastic resonance;metodo adaptativo;low contrast;image processing document image processing;locally adaptive binarization;image processing;seuil;locally adaptative binarization;availability;digitizing;engineering drawings;document images;threshold;text analysis;variable background intensity;methode adaptative;gray scale images;numerisation;data mining;image bruitee;algorithme;local adaptation;imagen sonora;algorithm;postal services;locally adaptive binarization methods;noisy image;pixel;utility maps;adaptive method;document image processing;postprocessing;numerizacion;image analysis;evaluation;thresholding;umbral;evaluacion;pixel background noise stochastic resonance text analysis image analysis data mining engineering drawings postal services labeling availability;postprocessing document images locally adaptive binarization methods gray scale images low contrast variable background intensity noise;labeling;noise;algoritmo	This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack’s method with the addition of the postprocessing step of Yanowitz and Bruckstein’s method added performed the best, and was also one of the fastest binarization methods. Keywords— Locally adaptive binarization, Thresholding, Evaluation, Utility maps, Document images.	binary image;fastest;grayscale;map;thresholding (image processing)	Øivind Due Trier;Torfinn Taxt	1995	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.368197	computer vision;availability;labeling theory;image analysis;speech recognition;image processing;computer science;noise;evaluation;background noise;thresholding;stochastic resonance;pixel;computer graphics (images)	Vision	46.64081406251758	-64.16231631740634	54536
316943e72d892710a7707b27bcd95841959e161b	a method of vehicle license plate de-noising and location in low light level	low light level;edge detection;vehicle license plate location;wavelet de noising	License plate recognition system (LPRS) is one of the most important parts of the intelligent transportation system (ITS), and the license plate location is the key part of the LPRS, it affects the latter phase of the character segmentation and recognition directly. According to the characteristic of the vehicle license plate which contains the slat and pepper noise in low light level, we take wavelet transform to vehicle license plate in low light level, then reconstruct the high frequency coefficient based on characteristic of noise, and use the soft-threshold method to do threshold processing of the reconstructed image, and obtain the effect of image de-noising. Finally, we use the method of edge detection and projection to locate the vehicle license plate area for de-noising vehicle license plate image. The simulation results show that the wavelet soft-threshold method can de-noise the low light level image greatly and the method of edge detection with projection can locate the vehicle license plate area fast and accurately.	automatic number plate recognition;coefficient;edge detection;lenstra–lenstra–lovász lattice basis reduction algorithm;matlab;noise reduction;preprocessor;projection method (fluid dynamics);salt-and-pepper noise;second level address translation;simulation;wavelet transform	Pan Duan;Kaigui Xie;Na Song;Qi-chang Duan	2010	2010 WASE International Conference on Information Engineering	10.4304/jnw.5.12.1393-1400	embedded system;computer vision;speech recognition;edge detection;computer science	Robotics	39.321118028477706	-65.36685818002965	54690
48ab839eceef1c4a395a8dac764a7b17e9efb958	geometric invariants for 2d/3d face recognition	reconnaissance visage;analisis imagen;3d face recognition;geometric invariants;vision ordenador;analisis bidimensional;image processing;securite;availability;disponibilidad;biometrie;authentication;biometrics;video analysis;biometria;procesamiento imagen;traitement image;computer vision;authentification;automatic recognition;analyse bidimensionnelle;autenticacion;face recognition;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;safety;two dimensional analysis;pattern recognition;advanced technology;image analysis;vision ordinateur;reconnaissance forme;reconocimiento patron;technologie avancee;seguridad;analyse image;disponibilite;reconocimiento automatico;tecnologia avanzada;reconnaissance automatique	In the last decade, security aspects such as biometrics have become one of the most central topics for governments as well as researchers, while the availability of more and more advanced technologies at lower costs has made image and video analysis also applicable for this aim. In particular, the 2D image analysis has been widely used in trying to overcome the main drawbacks of the face biometric (pose and illumination). Face is more attractive than most other biometrics, since it is fairly easy to use and well accepted by people, even if not yet robust enough to be used in most practical security applications. One possible way of overcoming this limitation is to work in 3D instead of 2D. But 3D is costly and more difficult to manipulate and then ineffective in authenticating people in most contexts. Hence, to solve this problem, a novel face recognition approach is proposed, using an asymmetric protocol: enrollment in 3D but identification performed from 2D images. So that the goal is to make more robust face recognition while keeping the system practical. To make this 3D/2D approach possible, geometric invariants used in computer vision are introduced within the context of face recognition. Results obtained in terms of identification rate are encouraging. 2007 Elsevier B.V. All rights reserved.	2d computer graphics;authentication;biometrics;computer vision;control point (mathematics);experiment;facial recognition system;feature (computer vision);illumination (image);image analysis;invariant (computer science);mathematical optimization;multimodal interaction;outline of object recognition;video content analysis	Daniel Riccio;Jean-Luc Dugelay	2007	Pattern Recognition Letters	10.1016/j.patrec.2006.12.017	computer vision;image analysis;simulation;image processing;computer science;artificial intelligence;authentication	Vision	45.01764139797403	-59.66079834635492	54748
b37925e10c614f8ea42bb7c71f0c64903e9dd648	using shaded views in 3d multiview representation of monotonous polyhedron	k m view space model;mathematics;image representation computational geometry;perspective projection;computational geometry;conference management;testing;layout;computer industry;concavities occlusions;monotonous polyhedron;image representation;informatics testing solids mathematics layout information analysis algorithm design and analysis management information systems computer industry conference management;management information systems;3d multiview representation;shaded views;informatics;b rep;depth map;visual identification b rep shaded views 3d multiview representation monotonous polyhedron concavities occlusions k m view space model;information analysis;algorithm design and analysis;visual identification;solids	The article concerns the 3D multiview representation of monotonous polyhedrons generated on the base of their Brep and including shaded views as a result of concavities occlusions in the views. The algorithm acts according to viewing sphere with perspective projection concept (called K-M view space model). Those models are used for visual identification based on them and a scene depth map. The results of algorithm testing are presented (the resulting views with shaded views) for some solids.	3d projection;algorithm;boundary representation;depth map;polyhedron;shading	Wojciech S. Mokrzycki;Andrzej Salamonczyk	2007	6th International Conference on Computer Information Systems and Industrial Management Applications (CISIM'07)	10.1109/CISIM.2007.71	layout;algorithm design;computer vision;perspective;computational geometry;computer science;theoretical computer science;solid;software testing;data analysis;informatics;depth map;computer graphics (images)	Vision	52.364647594718846	-52.26359060430979	54784
ca6fe6fe4c61516897b41839e75a605c6098cff7	use of monocular groupings and occlusion analysis in a hierarchical stereo system	hierarchical system;texture;image recognition;reconocimiento imagen;vision ordenador;formation image tridimensionnelle;image processing;occlusion;3d imaging;stereo image;edge detection;systeme hierarchise;vision stereoscopique;procesamiento imagen;oclusion;perceptual grouping;segmentation;constraint satisfaction;systeme adaptatif;traitement image;multiple views;computer vision;deteccion contorno;detection contour;satisfaction contrainte;sistema jerarquizado;retroaccion;binocular vision;retroaction;stereo vision;textura;stereo correspondence;reconnaissance image;adaptive system;feedback regulation;sistema adaptativo;vision ordinateur;vision binocular;formacion imagen tridimensional;image stereoscopique;vision binoculaire;segmentacion	We describe a hierarchical stereo system that computes a hierarchy of descriptions up the surface level from each view using a perceptual grouping technique and matches these features at the different levels. With the description and correspondence processes going hand in hand, we allow high-level abstract features to help reduce correspondence ambiguities, and we exploit the multiple views to help confirm the different levels of descriptions in the scene. Occlusion is a major problem in stereo analysis and is often not treated explicitly. We present a basic property of occlusions in stereo views and show how we can use this property incorporated with the structural descriptions to identify different types of occlusions in the scene. In particular, we identify depth discontinuities and limb boundaries and infer properties of surfaces that are visible only in one of the stereo views. We give some experimental results on scenes with curved objects and with multiple occlusions.		Ronald Chung;Ramakant Nevatia	1995	Computer Vision and Image Understanding	10.1006/cviu.1995.1053	binocular vision;stereoscopy;computer vision;edge detection;constraint satisfaction;image processing;computer science;stereopsis;adaptive system;hierarchical control system;texture;segmentation;computer graphics (images)	Vision	48.05638544325222	-58.48724720027031	54982
6dccab5ded75be7f5578302afb9a2eea48322112	local edge matching for seamless adjacent spatial datasets with sequence alignment	edge matching;corresponding point pair;sequence alignment;string matching;adjacent spatial dataset	This study proposes a local edge matching method with a sequence alignment technique for adjacent spatial datasets. By assuming that the common boundary edges of the datasets are point strings, the proposed method obtains the sequence for point edit operations to align the edges by using the string matching algorithm with the following operations: (1) snapping two points from each string to their average position, (2) removing a point from one string and (3) removing a point from the other string. The costs for these operations are derived from the deformation of the involved line segments in terms of the angle and length changes. The corresponding point pairs are then considered point pairs for which the snapping operation is chosen in a sequence. Based on these pairs, a border area of adjacent spatial datasets can be partitioned into sub-border areas where distinctive matching and alignment processes can be performed.	align (company);seamless3d;sequence alignment;string searching algorithm	Yong Huh	2015	ISPRS Int. J. Geo-Information	10.3390/ijgi4042061	combinatorics;topology;mathematics;engineering drawing	Vision	49.2606313947167	-54.262791419373116	55281
332828f02d52303f31dccc1aa47eae7e64626482	a comparison of probabilistic, possibilistic and evidence theoretic fusion schemes for active object recognition	object representation;parametric eigenspace;object recognition;selection problem;problema seleccion;algorithm complexity;complexite calcul;system dynamics;complejidad algoritmo;dempster shafer theory of evidence;uncertain information fusion;reconnaissance objet;action plan;complejidad computacion;complexite algorithme;computational complexity;fuzzy fusion;probability theory;active objects;pattern recognition;theorie probabilite;possibility theory;teoria probabilidad;information fusion;maquina fotografica;action planning;reconnaissance forme;robust fusion;reconocimiento patron;appareil photographique;teoria posibilidad;camera;theorie possibilite;activity recognition;probleme selection	One major goal of active object recognition systems is to extract useful information from multiple measurements. We compare three frameworks for information fusion and view-planning using different uncertainty calculi: probability theory, possibility theory and Dempster-Shafer theory of evidence. The system dynamically repositions the camera to capture additional views in order to improve the classification result obtained from a single view. The active recognition problem can be tackled successfully by all the considered approaches with sometimes only slight differences in performance. Extensive experiments confirm that recognition rates can be improved considerably by performing active steps. Random selection of the next action is much less efficient than planning, both in recognition rate and in the average number of steps required for recognition. As long as the rate of wrong object-pose classifications stays low the probabilistic implementation always outperforms the other approaches. If the outlier rate increases averaging fusion schemes outperform conjunctive approaches for information integration. We use an appearance based object representation, namely the parametric eigenspace, but the planning algorithm is actually independent of the details of the specific object recognition environment.	active object;algorithm;automated planning and scheduling;autostereogram;best, worst and average case;database;experiment;oracle fusion middleware;outline of object recognition;possibility theory;sum rule in quantum mechanics;whole earth 'lectronic link	Hermann Borotschnig;Lucas Paletta;Axel Pinz	1999	Computing	10.1007/s006070050026	probability theory;possibility theory;computer vision;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;mathematics;3d single-object recognition;system dynamics;computational complexity theory;algorithm;statistics;activity recognition	Vision	47.23999905527763	-57.83105607112374	55336
28202c8bc7566fe6af729f5c64f4cc427ca09278	lbp-based degraded document image binarization	historical document binarization lbp based degraded document image binarization threshold based methods spatial pixel values local binary pattern texture measure contrast information lbp operator dibco datasets;degradation;frequency modulation;image segmentation;performance evaluation;mathematical operators document image processing history image segmentation image texture;estimation;pattern recognition;ink;lbp binarization degraded document texture;degradation ink frequency modulation estimation image segmentation pattern recognition performance evaluation	Most of the classical threshold-based methods for document image binarization use simple features carried out from the spatial pixels values of the document images. In this paper, we present a new binarization method for degraded documents, based on Local Binary Pattern (LBP) as a texture measure. The mean and variance of pixels are computed respectively from both the original document image and the LBP image. Then, these features are used within a threshold-based method. Another variant is computed by combining a contrast information with the LBP operator to overcome the drawback caused by the poor contrasted document images. Experimental results conducted on DIBCO datasets and compared against some state-of-the-art methods, prove the effective use of the LBP for binarizing historical documents.	binary image;historical document;local binary patterns;pixel;simple features;thresholding (image processing)	Abdenour Sehad;Youcef Chibani;Rachid Hedjam;Mohamed Cheriet	2015	2015 International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2015.7367131	frequency modulation;image texture;computer vision;estimation;local binary patterns;speech recognition;degradation;computer science;pattern recognition;image segmentation;statistics	Vision	40.021415060281846	-64.32478335200769	55418
b622c4a14b210cb7294b47786cdbc058d39c1f2f	steerable wavelet frames based on the riesz transform	transformation ondelette;wavelet analysis;analisis imagen;contrast enhancement;traitement signal;contrast enhanced;image reconstruction riesz transform steerable wavelet frames monogenic wavelet hypercomplex monogenic signal isotropic wavelets frames clifford frames contrast enhancement image analysis;wavelet transforms image reconstruction;hilbert transformation;phase direction;monogenic wavelet;tensile stress;image processing;hypercomplex monogenic signal;steerable wavelet frames;descreening;wavelet frame;ondelette;signal analysis;analytic signal;wavelet analytical signal clifford algebra contrast enhancement descreening hilbert transform monogenic signal phase phase direction riesz transform steerable filters;transformation hilbert;filters;procesamiento imagen;phase;analisis de senal;transformacion hilbert;traitement image;clifford frames;wavelet transforms;riesz transform;hilbert transform;reconstruction image;clifford algebra;algebra;reconstruccion imagen;image color analysis;image reconstruction;signal processing;isotropic wavelets frames;image analysis;image texture analysis;transformacion ondita;steerable filters;monogenic signal;procesamiento senal;analyse image;wavelets;analytical signal;wavelet coefficients;wavelet;analyse signal;wavelet transformation;wavelet transforms signal analysis wavelet analysis tensile stress image texture analysis wavelet coefficients image color analysis image reconstruction algebra filters	We consider an extension of the 1-D concept of analytical wavelet to n-D which is by construction compatible with rotations. This extension, called a monogenic wavelet, yields a decomposition of the wavelet coefficients into amplitude, phase, and phase direction. The monogenic wavelet is based on the hypercomplex monogenic signal which is defined using Riesz transforms and perfectly isotropic wavelets frames. Employing the new concept of Clifford frames, we can show that the monogenic wavelet generates a wavelet frame. Furthermore, this approach yields wavelet frames that are steerable with respect to direction. Applications to descreening and contrast enhancement illustrate the versatility of this approach to image analysis and reconstruction.	coefficient;frame (physical object);image analysis;stationary wavelet transform	Stefan Held;Martin Storath;Peter Massopust;Brigitte Forster-Heinlein	2010	IEEE Transactions on Image Processing	10.1109/TIP.2009.2036713	wavelet;computer vision;mathematical analysis;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;signal processing;cascade algorithm;mathematics;geometry;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;statistics;wavelet transform	Vision	51.89679729243557	-63.37978777453189	55436
233b3914ffb8554ea509a0a7da83e8c50b1f5465	on pencils of tangent planes and the recognition of smooth 3d shapes from silhouettes	shape from silhouette;feature space;movi;geometric approach;feature vector	This paper presents a geometric approach to recognizing smooth objects from their outlines. We define a signature function that associates feature vectors with objects and baselines connecting pairs of possible viewpoints. Feature vectors, which can be projective, affine, or Euclidean, are computed using the planes that pass through a fixed baseline and are also tangent to the object’s surface. In the proposed framework, matching a test outline to a set of training outlines is equivalent to finding intersections in feature space between the images of the training and the test signature functions. The paper presents experimental results for the case of internally calibrated perspective cameras, where the feature vectors are angles between epipolar tangent planes.	baseline (configuration management);epipolar geometry;feature vector	Svetlana Lazebnik;Amit Sethi;Cordelia Schmid;David J. Kriegman;Jean Ponce;Martial Hebert	2002		10.1007/3-540-47977-5_43	computer vision;topology;feature vector;computer science;machine learning;mathematics;geometry;feature	Vision	41.62289095083655	-55.70545768951732	55536
d8e26c29d6898e3eb773c9c550f39046e2bdf758	analysing and simplifying histograms using scale-trees	scale trees;tree encoding;histograms;quantization;histogram decomposition;image coding;sieve algorithm scale trees image histogram analysis probability level sets histogram decomposition tree encoding compressed feature image retrieval;probability;information systems;high dimensionality;image resolution;data compression;level set;probability level sets;compressed feature;tree data structures;set theory;scale space;statistical analysis;image colour analysis;machine vision;feature extraction;sieve algorithm;image resolution tree searching tree data structures image retrieval probability statistical analysis image coding data compression image colour analysis feature extraction set theory;image analysis;histograms level set quantization multidimensional systems information systems image analysis information analysis image coding image retrieval machine vision;tree searching;information analysis;image histogram analysis;multidimensional systems;image retrieval	A new method f o r analysing image histograms is introduced. The technique decomposes a histogram into probability level sets. The relationships between these level sets are encoded using a tree. The tree has fewer nodes than the histogram and so is a compressed feature. When used in image retrieval experiments the tree is shown to have a pegormanee that is superior to many methods and no worse than the best alternatives. The tree is eficient because it can be built using a computationally eficient algorithm known	algorithm;binary tree;experiment;image histogram;image retrieval;tree (data structure)	Stuart E. Gibson;Richard Harvey	2001		10.1109/ICIAP.2001.956989	data compression;segment tree;computer vision;scale space;image analysis;image resolution;quantization;multidimensional systems;machine vision;feature extraction;image retrieval;computer science;histogram matching;level set;machine learning;pattern recognition;probability;incremental decision tree;interval tree;histogram;mathematics;fractal tree index;tree;data analysis;information system;statistics;set theory	Vision	40.176039092231626	-61.01020037186865	55560
675c695e0245a8bc797c3e1d92b3379de8697351	video compression for remotely controlled vehicles	image features;largeur bande;controlled vehicle;image processing;implementation;real time;video compression;compresion senal;procesamiento imagen;traitement image;compression signal;experimental result;ejecucion;reconstruction image;senal video;signal video;reconstruccion imagen;relacion compresion;image reconstruction;frequence spatiale;temps reel;signal compression;anchura banda;video transmission;resultado experimental;video signal;tiempo real;bandwidth;compression ratio;system development;log polar;taux compression;frecuencia espacial;resultat experimental;imagen color;image couleur;spatial frequency;color image;vehicule controle	In this paper we describe a video compression system developed for remotely controlled vehicles. Unlike most video compression systems, the component algorithms here are designed to match the informational properties of human color and contrast channels. The algorithms have been implemented on a four-processor real-time compression hardware system. The implemented system significantly reduces the bandwidth of video transmission but still keeps the important images features constructable in high accuracy.	data compression	Yi Lu;Tie Qi Chen;Carl F. R. Weiman;Brian Novak	1999	Real-Time Imaging	10.1006/rtim.1997.0109	video compression picture types;data compression;iterative reconstruction;computer vision;color image;telecommunications;image processing;computer science;video tracking;compression ratio;video processing;spatial frequency;implementation;motion compensation;feature;bandwidth;computer graphics (images)	Robotics	48.65058036181859	-55.539726822134526	55592
d54f6e851df65f002b93fb1eea24d354ea793a3f	a method for determining three-dimensional surface orientation of objects with textures	texture;image recognition;reconocimiento imagen;photometric stereo method;surface normal;erreur quadratique moyenne;coefficient reflexion;stereoscopy;normal vector;segmentation;surface reconstruction;three dimensional;surface reflectance;reconstruction surface;reflectance;mean square error;textura;reconnaissance image;stereoscopie;estereoscopia;reconstruccion superficie;error medio cuadratico;segmentacion;coeficiente reflexion	Abstract#R##N##R##N#To reconstruct the shape of an object from its image, the conventional photometric stereo method requires a preprocessing (e.g., region segmentation based on gray levels) unless the reflectance of its surface is uniform and known; and the method is applicable only to a part of the surface illuminated by more than three light sources.#R##N##R##N##R##N##R##N#This paper proposes a method based on the photometric stereo method, but with the newly introduced restriction conditions so that the method can be applied without preprocessing to an object with surface texture including regions illuminated by fewer than three light sources. The method has been applied successfully to two spherical objects: the mean square error in the reconstruction of an object where surface texture is 0.01723, and that without texture is 0.002063.		Koichi Shinmoto;Tsunenori Honda;Shun'ichi Kaneko	1996	Systems and Computers in Japan	10.1002/scj.4690270607	computer vision;normal;photometric stereo;geometry;computer graphics (images)	Robotics	50.81868967751494	-57.72792023591901	55744
0ddbd11179d1a39c06c0a365d06d482979d12ce9	3d grouping by viewpoint consistency ascent	object recognition;vision ordenador;algoritmo busqueda;image processing;grouping;geometrie solide;viewpoint consistency constraint;algorithme recherche;sistema informatico;search algorithm;procesamiento imagen;geometria solidos;computer system;modele 4 dimensions;reconnaissance objet;pose recovery;traitement image;computer vision;four dimensional model;consistance point de vue;pattern recognition;vision ordinateur;systeme informatique;agrupamiento;reconnaissance forme;reconocimiento patron;solid geometry;groupage;modelo 4 dimensiones	Abstract   The viewpoint consistency constraint (VCC) provides a powerful way to discover extended feature groups, and to test hypotheses in object recognition. Lowe's incremental method fails in complex scenes, and an exhaustive tree search (e.g. Grimson and Lozano-Perez) is too expensive. We present a state space approach in which transitions are made which monotonically ascend a measure of viewpoint consistency.	times ascent	Li Du;Geoffrey D. Sullivan;Keith D. Baker	1992	Image Vision Comput.	10.1016/0262-8856(92)90046-6	computer vision;image processing;computer science;artificial intelligence;consistency model;cognitive neuroscience of visual object recognition;solid geometry;algorithm;local consistency;search algorithm	Vision	47.86099370369723	-58.31320867398652	55768
074e69d5fcad7a669a5ccdee85a79d490ca2f508	recognitive aspects of moment invariants	image recognition;pattern recognition additive noise noise robustness performance analysis redundancy image analysis information theory pattern analysis image recognition;pattern recognition circular harmonics complex moments feature space image analysis information theory moment invariants;moment;circular harmonics;information loss;probability density function;moment invariants;additive noise;bruit additif;harmonic;data mining;feature space;noise robustness;redundancy;complex moments;harmonique;fourier transforms;performance analysis;harmonique circulaire;pattern recognition;image analysis;pattern analysis;reconnaissance forme;theorie information;analyse image;invariant;information theory;redondance;noise;moment invariant;harmonic analysis	Moment invariants are evaluated as a feature space for pattern recognition in terms of discrimination power and noise tolerance. The notion of complex moments is introduced as a simple and straightforward way to derive moment invariants. Through this relation, properties of complex moments are used to characterize moment invariants. Aspects of information loss, suppression, and redundancy encountered in moment invariants are investigated and significant results are derived. The behavior of moment invariants in the presence of additive noise is also described.	additive white gaussian noise;feature vector;immune tolerance;linear discriminant analysis;noise-induced hearing loss;pattern recognition;sensorineural hearing loss (disorder);utility functions on indivisible goods;zero suppression	Yaser S. Abu-Mostafa;Demetri Psaltis	1984	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1984.4767594	fourier transform;computer vision;probability density function;image analysis;feature vector;information theory;computer science;noise;machine learning;invariant;harmonic analysis;harmonic;pattern recognition;image moment;mathematics;moment;redundancy;statistics	Visualization	42.899962680992	-60.20860607969464	55959
7fc22978da37780e25a34eebec78bf75ac2e4d06	trinocular stereo matching with composite disparity space image	stereo image processing image matching optimisation;optimisation;image matching;graph cut techniques;computer vision;stereo vision interpolation image segmentation cost function optimization methods computer vision taxonomy yield estimation;stereo matching;three dimensional displays;image color analysis;heuristic algorithms;graph cut;pixel;stereo image processing;stereo vision;global optimization;optimization;disparity space image;cumulant;graph cut techniques stereo vision;high performance;global optimization problem trinocular stereo matching composite disparity space image occlusion handling occluded region matched stereo pair middle left images middle right images disparity space images	In this paper we propose a method that smartly improves occlusion handling in stereo matching using trinocular stereo. The main idea is based on the assumption that any occluded region in a matched stereo pair (middle-left images) in general is not occluded in the opposite matched pair (middle-right images). Then two disparity space images (DSI) are merged in one composite DSI. The proposed integration differs from the known approach that uses a cumulative cost. The experimental results are evaluated on the Middlebury data set, showing high performance of the proposed algorithm especially in the occluded regions. Our method solves the problem on the base of a real matching cost, in such a way a global optimization problem is solved just once, and the resultant solution does not have to be corrected in the occluded regions. In contrast, the traditional methods that use two images approach have to complicate a lot their algorithms by additional add hog or heuristic techniques to reach competitive results in occluded regions.	algorithm;binocular disparity;computer stereo vision;global optimization;heuristic;mathematical optimization;optimization problem;resultant	Mikhail Mozerov;Jordi Gonzàlez;F. Xavier Roca;Juan José Villanueva	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5414393	computer vision;cut;computer science;stereopsis;pattern recognition;mathematics;pixel;global optimization;cumulant;computer graphics (images)	Robotics	50.50063992587306	-52.88036240545975	56046
8a721b27c6800b673814cb05f50b11f8f7c3ac8a	fast alignment using probabilistic indexing	image recognition;alignment method;object recognition;object transformations;probability;image databases;uncertainty;probability density function;testing;running time probabilistic indexing alignment method model based object recognition object transformations hypothesized matches;indexing;probability image recognition image sequences;indexation;indexing image recognition computer science probability density function uncertainty image databases testing reflection tires object detection;probabilistic indexing;running time;tires;computer science;hypothesized matches;model based object recognition;reflection;object detection;image sequences	The alignment method [4] is a model-based object recognition technique that determines possible object transformations from three hypothesized matches of model and image points. For images and/or models with many features, the running time of the alignment method can be large. This paper presents methods of reducing the number of matches that must be examined. The techniques we describe are: Using the probabilistic peaking e ect [1] to eliminate unlikely matches (implemented in a probabilistic indexing system [6]) and eliminating groups of model points that produce large errors in the transformation determined by the alignment method. Results are presented that show we can achieve a speedup of over two orders of magnitude while still nding a correct alignment.	ibm notes;outline of object recognition;probabilistic database;speedup;time complexity	Clark F. Olson	1993		10.1109/CVPR.1993.341101	computer vision;search engine indexing;probability density function;reflection;uncertainty;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;probability;mathematics;software testing;statistics	Vision	43.434094649777975	-54.7086898039726	56077
4094f6dffffb9412647ba6ffe845cfd67263b7b8	exploiting spatial-temporal coherence in the construction of multiple perspective videos	contraste;modelizacion;view morphing;multiple perspectives;image tridimensionnelle;sistema multiple;vision ordenador;image processing;occlusion;coherencia temporal;spatial coherence;occultation;procesamiento imagen;coherence temporelle;oclusion;multiple system;qualite image;traitement image;computer vision;multiple view;modelisation;reconstruction image;virtual view;3d model;senal video;signal video;reconstruccion imagen;coherencia espacial;vue virtuelle;image reconstruction;spatial temporal coherence;image quality;active objects;occlusion recovery;video signal;vue multiple;tridimensional image;vision ordinateur;etalonnage;calidad imagen;digital video;vista virtual;temporal coherence;ocultacion;multiple perspective video;3d video;modeling;off the shelf;calibration;coherence spatiale;imagen tridimensional;vista multiple;active object movie;systeme multiple	We implement an image-based system that constructs multiple perspective videos with active objects using an off-the-shelf PC and digital video camcorders without the need of advanced calibration and 3D model reconstruction. Especially, temporal coherence is exploited to speedup the correspondence search. Spatial coherence is exploited for occlusion recovery to improve the quality of the generated images. The proposed system can automatically establish dense correspondence and construct virtual views on-line according to user instructions.	coherence (physics)	Mau-Tsuen Yang;Shih-Yu Huang;Kuo-Hua Lo;Wen-Kai Tai;Cheng-Chin Chiang	2006		10.1007/11949534_132	iterative reconstruction;image quality;computer vision;calibration;simulation;systems modeling;occultation;image processing;computer science;computer graphics (images)	Vision	51.20654074646572	-56.57977738199342	56169
402fb94591ea0fceda6171ec165aa5ede7fe87c6	automatic detection of circular objects by ellipse growing	two dimensions;robust estimation;outlier detection;automatic detection;shape reconstruction;hough transform;lmeds;ellipse fitting	We present a new method for automatically detecting circular objects in images: we detect an osculating circle to an elliptic arc using a Hough transform, iteratively deforming it into an ellipse, removing outlier pixels, and searching for a separate edge. The voting space is restricted to one and two dimensions for efficiency, and special weighting schemes are introduced to enhance the accuracy. We demonstrate the effectiveness of our method using real images. Finally, we apply our method to the calibration of a turntable for 3-D object shape reconstruction.	hough transform;pixel;sensor	Kenichi Kanatani;Naoya Ohta	2004	Int. J. Image Graphics	10.1142/S0219467804001282	hough transform;computer vision;anomaly detection;two-dimensional space;computer science;pattern recognition;mathematics;geometry	Vision	47.782411483692435	-65.40347131644292	56414
842309af1ad45cd92082b34e1842b4aca1dfdd64	evaluating the segmentation result of a gray-level image	evaluation performance;performance evaluation;classification non supervisee;evaluacion prestacion;texture image;disparity;segmentation;imagen nivel gris;disparidad;image texture;clasificacion no supervisada;image niveau gris;signal classification;classification signal;unsupervised classification;grey level image;disparite;segmentacion	We propose in this communication an unsupervised criterion that enables to quantify the quality of a segmentation result of a gray-level image. The originality of this method lies in the possibility to evaluate the segmentation results for all kinds of images including textured ones. This method is based upon a new criterion that takes into account the intra-region and inter-regions disparities by considering the type of region (textured or uniform). These two disparity measures are computed from adaptive attributes calculated from the segmentation result. Experimental results show the efficiency of this technique for synthetic and natural images with textured regions.	binocular disparity;synthetic intelligence;unsupervised learning	Sébastien Chabrier;Christophe Rosenberger;Hélène Laurent;Bruno Emile;Patrice N Marche	2004	2004 12th European Signal Processing Conference	10.5281/zenodo.38270	computer vision;geography;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation;cartography	Vision	45.00516650121325	-62.8269905581445	56548
007673fe281e58fbbdca687c4d7d72dfe2240451	scan context: egocentric spatial descriptor for place recognition within 3d point cloud map		Compared to diverse feature detectors and descriptors used for visual scenes, describing a place using structural information is relatively less reported. Recent advances in simultaneous localization and mapping (SLAM) provides dense 3D maps of the environment and the localization is proposed by diverse sensors. Toward the global localization based on the structural information, we propose Scan Context, a non-histogram-based global descriptor from 3D Light Detection and Ranging (LiDAR) scans. Unlike previously reported methods, the proposed approach directly records a 3D structure of a visible space from a sensor and does not rely on a histogram or on prior training. In addition, this approach proposes the use of a similarity score to calculate the distance between two scan contexts and also a two-phase search algorithm to efficiently detect a loop. Scan context and its search algorithm make loop-detection invariant to LiDAR viewpoint changes so that loops can be detected in places such as reverse revisit and corner. Scan context performance has been evaluated via various benchmark datasets of 3D LiDAR scans, and the proposed method shows a sufficiently improved performance.		Giseop Kim;Ayoung Kim	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593953	artificial intelligence;point cloud;computer vision;visualization;computer science;encoding (memory);simultaneous localization and mapping;ranging;search algorithm;histogram;lidar	Robotics	42.87006719507599	-53.99230351808098	56633
d39da088e7e3ef8d913b34069d718292c8d5903e	eigen transformation based edge detector for gray images	analisis imagen;gray image;comprension imagen;eigenvalue problem;comparative analysis;detecteur image;edge detection;matrice covariance;probleme valeur propre;matriz covariancia;imagen nivel gris;eigenvalues;deteccion contorno;statistical properties;detection contour;image niveau gris;comprehension image;image analysis;detector imagen;computer science;small eigenvalue;eigen image;image comprehension;grey level image;analyse image;image sensor;covariance matrix;problema valor propio	In this paper, a simple and a robust algorithm to detect edges in a gray image is proposed. The statistical property of the small eigenvalue of the covariance matrix of a set of connected pixels over a small region of support is explored for the purpose of edge detection. The gray image is scanned from the top left corner to the bottom right corner with a moving mask of size k xk, for some integer k. At every stage, the small eigenvalue of the covariance matrix of the connected pixels that are having approximately same intensity as that of the center pixel of the mask is computed. This small eigenvalue is used to decide if a pixel is a potential edge pixel based on a pre-defined threshold value. The set of all identified potential edge pixels are then subjected to a pruning process where true edge pixels are selected. Experiments have been conducted on benchmark gray images to establish the performance of the proposed model. Comparative analysis with the Canny edge detector [1] and Sun et al. [15] is made to demonstrate the implementation simplicity and suitability of the proposed method in vision applications.	edge detection;eigen (c++ library)	P. Nagabhushan;D. S. Guru;B. H. Shekar	2005		10.1007/11590316_67	qualitative comparative analysis;computer vision;covariance matrix;image analysis;edge detection;eigenvalues and eigenvectors;computer science;deriche edge detector;image sensor;mathematics;geometry;canny edge detector	Vision	47.13890310868478	-63.982091202059316	56752
d0ec4717271e0d11f508d49f3cde5b7705a2e4f1	a multi-view approach to object tracking in a cluttered scene using memory	modelizacion;filtering;filtrage;clutter;short term memory;pistage;mise a jour;occlusion;occultation;filtrado;rastreo;oclusion;intelligence artificielle;multiple view;actualizacion;modelisation;fouillis echo;particle filter;confusion eco;object tracking;poursuite cible;court terme;vue multiple;artificial intelligence;model updating;inteligencia artificial;target tracking;ocultacion;modeling;corto plazo;short term;updating;tracking;vista multiple	In this paper, we propose a new multi-view approach to object tracking method that adapts itself to suddenly changing appearance. The proposed method is based on color-based particle filtering. A short-term memory and a global appearance memory are introduced to handle sudden appearance changes and occlusions of the object of interest in multi-camera environments. A new target model update method is implemented for multiple camera views. Our method is robust and versatile for a modest computational cost. Desirable tracking results are obtained.	free viewpoint television	Hang-Bong Kang;Sang-Hyun Cho	2005		10.1007/11538356_90	computer vision;simulation;computer science;artificial intelligence;short-term memory	Vision	47.651835242699676	-56.86572314048863	57061
88d201f39122e496d240596326553331ab270097	a frequency domain approach to registration of aliased images with application to super-resolution	artefacto;baja resolucion;signal image and speech processing;interpolation;high resolution;super resolution imaging;image processing;image resolution;low frequency;aliasing;interpolacion;simulation;low resolution;nccr mics;basse resolution;procesamiento imagen;performance standard;digital camera;simulacion;norma calidad;indexing terms;qualite image;traitement image;artefact;algorithme;registro imagen;algorithm;haute resolution;resolucion imagen;quantum information technology spintronics;recalage image;methode domaine frequence;frequency domain method;image registration;ivrg;image quality;basse frequence;alta resolucion;super resolution;norme performance;calidad imagen;baja frecuencia;high resolution imager;superresolution;metodo dominio frecuencia;frequency domain;resolution image;superresolucion;nccr mics cl1;repliegue espectro;algoritmo;repliement spectre	Super-resolution algorithms reconstruct a high resolution image from a set of low resolution images of a scene. Precise alignment of the input images is an essential part of such algorithms. If the low resolution images are undersampled and have aliasing artifacts, the performance of standard registration algorithms decreases. We propose a frequency domain technique to precisely register a set of aliased images, based on their low-frequency, aliasing-free part. A high resolution image is then reconstructed using cubic interpolation. Our algorithm is compared to other algorithms in simulations and practical experiments using real aliased images. Both show very good visual results and prove the attractivity of our approach in the case of aliased input images. A possible application is to digital cameras where a set of rapidly acquired images can be used to recover a higher resolution final image. Index Terms Super-resolution imaging, image registration, aliasing	algorithm;aliasing (computing);cubic hermite spline;digital camera;experiment;image registration;image resolution;interpolation;simulation;super-resolution imaging;undersampling	Patrick Vandewalle;Sabine Süsstrunk;Martin Vetterli	2006	EURASIP J. Adv. Sig. Proc.	10.1155/ASP/2006/71459	computer vision;image resolution;image processing;computer science;computer graphics (images)	Vision	52.901915344500864	-60.74075646671572	57510
841846a713c10bc9703c107b1fd0e9f7b5d1a1bf	structural indexing: efficient 2d object recognition	computational complexity;database management systems;image recognition;image segmentation;cluttered environment;complexity bound;consecutive segment groups;database;efficient 2d object recognition;multiple flat objects;multiple line tolerances;noise;occlusion;polygonal approximation;robustness;rotation-insensitivity;scale-insensitivity;scene segmentation;structural indexing;super segments;translation-insensitivity;weak perspective	The problem of recognition of multiple flat objects in a cluttered environment from an arbitrary viewpoint is addressed. The models are acquired automatically and approximated by polygons with multiple line tolerances for robustness. Groups of consecutive segments (super segments) are then encoded and entered into a table. This provides the essential mechanism for indexing and fast retrieval. Once the database of all models is built, the recognition proceeds by segmenting the scene into a polygonal approximation; the code for each super segment retrieves model hypotheses from the table. Hypotheses are clustered if they are mutually consistent and represent the instance of a model. Finally, the estimate of the transformation is refined. This methodology makes it possible to recognize models despite noise, occlusion, scale rotation translation, and a restricted range of weak perspective. A complexity bound is obtained	outline of object recognition	Fridtjof Stein;Gérard G. Medioni	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.177385		Vision	43.44104796437533	-54.73571253053267	57516
b566b9cbf3f80f5f4d0aa43b28e860159f944235	optimal multivariate gaussian fitting for psf modeling in two-photon microscopy		Fitting multivariate Gaussian functions constitutes a fundamental task in many scientific fields. However, most of the existing approaches for performing such fitting are restricted to 2 dimensions and they cannot be easily extended to higher dimensions. One of the main applicative areas where it is necessary to go beyond the existing techniques is the modeling of Point Spread Functions in 3D imaging. In this paper, a novel variational approach is proposed to fit multivariate Gaussians from noisy data in arbitrary dimensions. The proposed FIGARO algorithm is applied to two-photon fluorescence microscopy where its excellent performance is demonstrated.	3d reconstruction;algorithm;applicative programming language;calculus of variations;curve fitting;signal-to-noise ratio	Tim Tsz-Kit Lau;Emilie Chouzenoux;Claire Lefort;Jean-Christophe Pesquet	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363621	fluorescence microscope;image restoration;artificial intelligence;noisy data;computer vision;computer science;pattern recognition;two-photon excitation microscopy;multivariate statistics;multivariate normal distribution	Vision	51.67141405014206	-63.142040664862186	57725
159152b5ea5c09b5d875290d8c13f07ad4df54b7	accurate camera calibration from multi-view stereo and bundle adjustment	top down method;methode descendante;contraste;analisis imagen;modelizacion;reseau capteur;bottom up method;vision ordenador;high resolution;bottom up;silhouette;metodo ascendente;image processing;top down;image matching;procesamiento imagen;digital camera;stereoscopy;courbure;image based modeling;fidelity;traitement image;methode ascendante;computer vision;multiple view;modelisation;estructura segun moviemento;haute resolution;red sensores;fidelite;metodo descendente;alta resolucion;sensor array;ajustement de faisceaux;visual hull;curvatura;vue multiple;multi view stereo;stereoscopie;curvature;image analysis;vision ordinateur;etalonnage;estereoscopia;ajuste de haces;fidelidad;parameter estimation;camera calibration;modeling;analyse image;structure from motion;calibration;silueta;appariement image;vista multiple;bundle adjustment;structuration d apres le mouvement	The advent of high-resolution digital cameras and sophisticated multi-view stereo algorithms offers the promise of unprecedented geometric fidelity in image-based modeling tasks, but it also puts unprecedented demands on camera calibration to fulfill these promises. This paper presents a novel approach to camera calibration where top-down information from rough camera parameter estimates and the output of a multi-view-stereo system on scaled-down input images is used to effectively guide the search for additional image correspondences and significantly improve camera calibration parameters using a standard bundle adjustment algorithm (Lourakis and Argyros 2008). The proposed method has been tested on six real datasets including objects without salient features for which image correspondences cannot be found in a purely bottom-up fashion, and objects with high curvature and thin structures that are lost in visual hull construction even with small errors in camera parameters. Three different methods have been used to qualitatively assess the improvements of the camera parameters. The implementation of the proposed algorithm is publicly available at Furukawa and Ponce (2008b).	algorithm;bottom-up parsing;bundle adjustment;camera resectioning;digital camera;image resolution;top-down and bottom-up design;visual hull	Yasutaka Furukawa;Jean Ponce	2008	2008 IEEE Conference on Computer Vision and Pattern Recognition	10.1007/s11263-009-0232-2	smart camera;stereo camera;computer vision;camera auto-calibration;image analysis;camera resectioning;image processing;computer science;top-down and bottom-up design;pinhole camera model;computer graphics (images)	Vision	49.928755456572276	-56.95719433635254	57879
75470784f698138f7e76e61957c785da16dd23b1	smire: similar medical image retrieval engine	busqueda informacion;transformation ondelette;analisis imagen;image features;feedback mechanism;search engine;vision ordenador;medical imagery;buscador;medical image retrieval;recherche image;information retrieval;spatial coherence;interrogation base donnee;interrogacion base datos;tratamiento lenguaje;color histogram;information access;computer vision;histogram;histogramme;medical image;language processing;coherencia espacial;recherche information;traitement langage;proceedings paper;imagineria medica;imagerie medicale;visual features;acces information;image analysis;vision ordinateur;acceso informacion;transformacion ondita;moteur recherche;multilinguisme;histograma;analyse image;mean average precision;article;database query;coherence spatiale;multilingualism;wavelet transformation;multilinguismo;image retrieval	This paper aims at finding images that are similar to a medical image example query. We propose several image features based on wavelet coefficients, including color histogram, gray-spatial histogram, coherence moment, and gray correlogram, to facilitate the retrieval of similar medical images. The initial retrieval results are obtained via visual feature analysis. An automatic feedback mechanism that clusters visually and textually similar images among these initial results was also proposed to help refine the query. In the ImageCLEF 2004 evaluation, the experimental results show that our system is excellence in mean average precision.	coefficient;color histogram;computation;content-based image retrieval;defective pixel;feedback;general-purpose modeling;grayscale;image retrieval;information retrieval;institute of radio engineers;medical imaging;radiography;wavelet	Pei-Cheng Cheng;Been-Chian Chien;Hao-Ren Ke;Wei-Pang Yang	2004		10.1007/11519645_73	color histogram;computer vision;visual word;image analysis;speech recognition;image retrieval;computer science;feedback;histogram;feature;information retrieval;search engine	Vision	43.18124630996962	-61.82405411026382	58020
9a1d27475782b33a1bb2ab3de8e759284f16b442	enhanced fourier shape descriptor using zero-padding	analisis imagen;image processing;recherche image;shape descriptor;remplissage;procesamiento imagen;image classification;compacite;spectrum;filling;classification;traitement image;shape classification;image analysis;compactness;shape description;classification accuracy;zero padding;analyse image;content based retrieval;clasificacion;recherche par contenu;relleno;compacidad;image retrieval	The shapes occurring in the images are essential features in image classification and retrieval. Due to their compactness and classification accuracy, Fourier-based shape descriptors are popular boundary-based methods for shape description. However, in the case of short boundary functions, the frequency resolution of the Fourier spectrum is low, which yields to inadequate shape description. Therefore, we have applied zero-padding method for the short boundary functions to improve their Fourier-based shape description. In this paper, we show that using this method the Fourier-based shape classification can be significantly improved.		Iivari Kunttu;Leena Lepistö;Ari Visa	2005		10.1007/11499145_90	active shape model;spectrum;computer vision;contextual image classification;image analysis;image processing;biological classification;image retrieval;computer science;heat kernel signature;pattern recognition;shape analysis;mathematics;geometry;compact space	Vision	43.08119977609043	-61.512136431671564	58194
67c9b3471f984fcdfd810f53dd4744a0cee4b85b	rule based segmentation and subject identification using fiducial features and subspace projection methods	skin color segmentation;color feret database;rule based;projection method;feature extraction;subspace analysis methods;geometric normalization	This paper describes a framework for carrying out face recognition on a subset of standard color FERET database using two different subspace projection methods, namely PCA and Fisherfaces. At first, a rule based skin region segmentation algorithm is discussed and then details about eye localization and geometric normalization are given. The work achieves scale and rotation invariance by fixing the inter ocular distance to a selected value and by setting the direction of the eye-to-eye axis. Furthermore, the work also tries to avoid the small sample space (S3) problem by increasing the number of shots per subject through the use of one duplicate set per subject. Finally, performance analysis for the normalized global faces, the individual extracted features and for a multiple component combination are provided using a nearest neighbour classifier with Euclidean and/or Cosine distance metrics.	3d projection;algorithm;component-based software engineering;computation;cosine similarity;experiment;feret (facial recognition technology);feret database;facial recognition system;fiducial marker;image scaling;interpolation;optic axis of a crystal;pixel;principal component analysis	Erhan AliRiza Ince;Syed Amjad Ali	2007	JCP	10.4304/jcp.2.4.68-75	rule-based system;computer vision;feature extraction;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;projection method	Vision	40.77440680550481	-57.56096582606602	58382
3a77d9485fddfd94f7590f73673085a25184aaaf	human skeleton extraction of depth images using the polygon evolution		This paper proposes a novel skeleton extraction approach in the depth image based on the polygon evolution. The external contour of person is firstly extracted from the depth image and evolved to a external polygon using a polygon evolution method. Subsequently, the depth histogram is used to extract internal self-occlusion body parts, and contours of these parts are evolved to internal polygons. In external and internal polygons, skeleton points are extracted under different criterias respectively. Finally, all skeleton points are linked to a complete skeleton. Experimental results on a variety of postures demonstrate the robustness and reasonability of our skeleton extraction approach.		Huan Du;Jian Wang;Xue-xia Zhong;Ying He;Lin Mei	2014		10.1007/978-3-319-07725-3_2	computer vision;morphological skeleton	Vision	44.1831836537337	-64.43109734768244	58566
55a58470248c63c56b5f42cf26154db4d568fbdc	a pixel-based evaluation method for text detection in color images	protocols;inexplicitly defined text bounding boxes;performance evaluation;color;pixel based performance evaluation method;evaluation method;text analysis;text analysis binary sequences image colour analysis;skeleton;color images;pixel videos skeleton protocols performance evaluation pattern recognition color;image colour analysis;pixel;binary sequences;pattern recognition;binarization algorithm;text detection;binarization algorithm pixel based performance evaluation method text detection color images inexplicitly defined text bounding boxes;color images performance evaluation text detection;color image;videos	This paper proposes a performance evaluation method for text detection in color images. The method, contrary to previous approaches, is not based on the inexplicitly defined text bounding boxes for the evaluation of the text detection result but considers only the text pixels detected by binarizing the image and applying a color inversion if needed. Moreover, in order to gain independence from the chosen binarization algorithm, the method uses the skeleton of the binarized image. The results produced by the proposed evaluation protocol proved to be quite representative and reasonable compared to the corresponding optical result.	algorithm;minimum bounding box;performance evaluation;pixel	Marios Anthimopoulos;Nikolaos Vlissidis;Basilios Gatos	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.798	communications protocol;computer vision;text mining;color image;computer science;pattern recognition;skeleton;pixel;computer graphics (images)	Vision	39.69836192508496	-65.24264461704962	58611
64a44e1d5cbefbb403811360a88f4d93e569ffbd	perspective distortion modeling, learning and compensation	optical distortion;databases;training;learning artificial intelligence face recognition;face distortion face recognition optical distortion training cameras databases;distortion;face recognition;face;cameras;multiview validation perspective distortion modeling image compensation one parameter warping function family face recognition face synthesis perceived face characteristics image warp learning focal lengths image editing video conferencing	We describe a method to model perspective distortion as a one-parameter family of warping functions. This can be used to mitigate its effects on face recognition, or synthesis to manipulate the perceived characteristics of a face. The warps are learned from a novel dataset and, by comparing one-parameter families of images, instead of images themselves, we show the effects on face recognition, which are most significant when small focal lengths are used. Additional applications are presented to image editing, videoconference, and multi-view validation of recognition systems.	distortion;explicit modeling;focal (programming language);facial recognition system;image editing;warp (information security)	Joachim Valente;Stefano Soatto	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2015.7301314	facial recognition system;face;computer vision;face detection;speech recognition;distortion;computer science;three-dimensional face recognition;geometry;multimedia	Vision	41.594377518749056	-53.07417338925607	58672
2c8f86b5fd38e257a6e7af99f8977c550e1c324e	global transformations in pattern recognition of bubble chamber photographs	image processing;bubble chamber photographs;clustering techniques;angle curvature space bubble chamber photographs clustering techniques global tracking image processing orthogonal transformations pattern recognition;global tracking;pattern recognition;orthogonal transformation;orthogonal transformations;angle curvature space	In this paper we present some new ideas on pattern recognition of bubble chamber photographs. We have found global transformations that reduce circular tracks to a point in a two-dimensional angle-curvature space. The performance of this tracking method on a sample of bubble chamber events is presented and planned improvements are discussed.	pattern recognition	Pierre L. Bastien;Lawrence A. Dunn	1971	IEEE Transactions on Computers	10.1109/T-C.1971.223394	computer vision;image processing;computer science;mathematics;geometry;orthogonal transformation	Vision	48.1819632710421	-62.75273766002409	58783
c48f43bb81831e1a49f570d5cc43867ac8c7652d	visual alphabets on different levels of abstraction for the recognition of deformable objects	deformable objects;levels of abstraction;geometric constraints	Recognition systems for complex and deformable objects must handle a variety of possible object appearances. In this paper, a compositional approach to this problem is studied which splits the set of possible appearances into easier sub-problems. To this end, a grammar is introduced that represents objects by a hierarchy of increasingly abstract visual alphabets. These alphabets store features, complex patterns and different views of objects. The geometrical constraints are optimised to the respective level of abstraction. The performance of the method is demonstrated on a cartoon data base with high intra-class variance.		Martin Stommel;Klaus-Dieter Kuhnert	2010		10.1007/978-3-642-14980-1_20	computer vision;computer science;artificial intelligence;communication	AI	41.080959774249855	-53.36054315881416	58984
7dcbdb680d78e21c8e70690633081b079507299e	fast hand detection using posture invariant constraints	high dimensionality;degree of freedom;real time;configuration space;skin color;hand tracking	The biggest challenge in hand detection and tracking is the high dimensionality of the hand's kinematic configuration space of about 30 degrees of freedom, which leads to a huge variance in its projections. This makes it difficult to come to a tractable model of the hand as a whole. To overcome this problem, we suggest to concentrate on posture invariant local constraints, that exist on finger appearances. We show that, besides skin color, there is a number of additional geometric and photometric invariants. This paper presents a novel approach to real-time hand detection and tracking by selecting local regions that comply with these posture invariants. While most existing methods for hand tracking rely on a color based segmentation as a first preprocessing step, we integrate color cues at the end of our processing chain in a robust manner. We show experimentally that our approach still performs robustly above cluttered background, when using extremely low quality skin color information. With this we can avoid a user- and lighting-specific calibration of skin color before tracking.	poor posture	Nils Petersen;Didier Stricker	2009		10.1007/978-3-642-04617-9_14	computer vision;simulation;mathematics;communication	Vision	43.025106349296934	-52.99882507108435	58994
e4d979cf8f8c5101a4a3d0f5595c8ceac7642ddf	exploiting unbroken surface congruity for the acceleration of fragment reassembly		"""Virtual reassembly problems are often encountered in the cultural heritage domain. The reassembly or """"puzzling"""" problem is typically described as the process for the identification of corresponding pieces within a part collection, followed by the clustering and pose estimation of multiple parts that result in a virtual representation of assembled objects. This work addresses this problem with an efficient, user-guided computational approach. The proposed approach augments the typical reassembly pipeline with a smart culling step, where geometrically incompatible fragment combinations can be quickly rejected. After splitting each fragment into potentially fractured and intact facets, each intact facet is examined for prominent linear or curved structures and a heuristic test is employed to evaluate the plausibility of facet pairs, by comparing the number of feature curves associated with each facet, as well as the geometric texture of associated intact surfaces. This test excludes many pairwise combinations from the remaining part of the reassembly process, significantly reducing overall time cost. For all facet pairs that pass the initial plausibility test, pairwise registration driven by enhanced simulated annealing is applied, followed by multipart registration. The proposed reassembly approach is evaluated on real scanned data and our experiments demonstrate an increase in efficiency that ranges from 30% to more than 500% in some cases, depending on the number of culled combinations. CCS Concepts •Computing methodologies → Shape analysis; •Applied computing → Arts and humanities;"""	algorithmic efficiency;cluster analysis;computation;erosion (morphology);eurographics;experiment;graphics;heuristic;plausibility structure;segmentation and reassembly;shape analysis (digital geometry);simulated annealing;usability	Michalis A. Savelonas;Anthousis Andreadis;Georgios Papaioannou;Pavlos Mavridis	2017		10.2312/gch.20171305	acceleration;shape analysis (digital geometry);computer graphics (images);computing methodologies;computer science	Vision	49.10151504743014	-52.728301078597966	59009
9fe9d374669eca6c6a61d83dbf7ee102f3a0d156	generalizations of binary morphological shape decomposition	mathematical morphology;computer simulations	We address the representation of binary images using mathematical morphology. One of the main image representations in binary mathematical morphology is the shape decomposition representation, useful for image compression, pattern recognition, and image interpolation. The binary Morphological shape decomposition (MSD) representation can be developed and generalized. With these generalizations, the binary MSDu0027s role as an efficient image decomposition tool is extended. Initially the MSD representation is based on only one-parameter families of elements. A new branch is added by introducing a multistructuring element MSD based on the decomposition of images into multiparameter families of elements. The MSD representation contains redundant points. Examples are presented and illustrated by computer simulations.		Nicolae Vizireanu	2007	J. Electronic Imaging	10.1117/1.2712464	computer vision;mathematical optimization;combinatorics;mathematical morphology;computer science;theoretical computer science;mathematics	Vision	51.86027598164645	-64.14344260469218	59060
3654835dd8b037b0ff667ebbcadb3f79c2cfeddd	robust object extraction with illumination-insensitive color descriptions	feature extraction;image colour analysis;image matching;lighting;noise;object recognition;active search method;color ratios;efficient upper bound pruning;experiments;extended histogram;focal color matching;focused color matching;illumination-insensitive color descriptions;local color histogram matching;noise error;object recognition;quantification error;real images;robust object extraction;weighted histogram matching	The color histogram is a powerful cue for object extraction and recognition. Local color histogram matching is robust to changes in location, and size and to complex backgrounds, and can be sped up considerably by the active search method using efficient upper bound pruning. This strategy, however, has significant limitations in the event of changes in illumination. In an effort to overcome these limitations, we have focused on color ratios. This paper describes an extended histogram for focused (focal) color matching. Called a weighted histogram, it is based on color ratios from neighboring locations and evaluates each of them individually according to their significance. This histogram is relatively insensitive to illumination changes and can reduce the influence of noise or quantification errors. We present a series of experiments that show the effectiveness of this weighted histogram matching with real images taken under different illuminations		Chie Hashizume;Vasudevan V. Vinod;Hiroshi Murase	1998			color histogram;computer vision;color normalization;color image;feature extraction;computer science;noise;histogram matching;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;balanced histogram thresholding;lighting;mathematics;adaptive histogram equalization;upper and lower bounds;histogram equalization;image histogram	NLP	41.15661693686089	-54.99069393562863	59194
f999d56a0ad6468eb5cb2fe9778d6b550b2299fb	color space analysis in color image segmentation	fuzzy c means algorithm;color space;low pass filter;color image segmentation	This paper describes two classic style methods to analyze and segment the color space. The RGB space method includes color space pyramiding, low-pass filtering, 3-D object labeling and property calculation to acquire a proper number of colors and a good initial estimate of center positions, then fuzzy cmeans algorithm can be used to optimally cluster the color space distribution points. The second method introduced is a less complicated YIQ~YθS system which is in the category of histogram thresholding to achieve color segmentation.	algorithm;color image;color space;fuzzy clustering;image segmentation;low-pass filter;thresholding (image processing)	David X. Zhong	2000			demosaicing;color histogram;rgb color model;computer vision;icc profile;color quantization;color normalization;color depth;color image;rgb color space;high color;mathematics;color balance;optics;color space;computer graphics (images)	Robotics	46.77391100781198	-65.38799438355673	59201
060bf4181f668f106f822c12b7886f3025fe9330	a fast algorithm for sequential machines to compute pattern spectrum via chess-board distance transform	algorithme rapide;objet;sequential machine;mathematical morphology;morfologia matematica;image processing;binary objects;procesamiento imagen;machine sequentielle;object;spectrum;traitement image;maquina secuencial;fast algorithm;donnee binaire;pattern recognition;pattern spectrum;dato binario;binary data;reconnaissance forme;reconocimiento patron;distance transform;objeto;algoritmo rapido;morphologie mathematique	Abstract   Computing pattern spectrum is one of the key methods for determining shape-size distribution of objects in the image. Morphological algorithm for computing the pattern spectrum by successive opening and area computing is very costly on sequential machines. In this paper a fast algorithm for the same using the chess-board distance transform is proposed.	algorithm;distance transform;granulometry (morphology)	Pinaki Ghosh;Bhabatosh Chanda	1995	Pattern Recognition Letters	10.1016/0167-8655(94)00072-B	spectrum;computer vision;mathematical morphology;image processing;computer science;artificial intelligence;object;theoretical computer science;mathematics;distance transform;algorithm	Vision	47.35673133628295	-63.21875326379554	59209
eee69704bde40ab20090c19a21487f7ca5bcc674	on the effect of perspective distortions in face recognition		Face recognition is one of the widely studied topics in the literature image processing and pattern recognition. Generally for the face images, the distance between camera and face is larger than the face size, hence in practice the effects of perspective distortions on the face edges are often ignored by the researchers. While these effects become more prominent if faces are viewed from different angles. In this paper, we study effects of perspective distortion and obtain improved results for face recognition against varying view-points. The approach follows by fitting a 3D model to the face images and creating a texture map by texture rectification at each triangle level. We compare our results with active appearance models (AAM) on two standard face databases.	3d modeling;active appearance model;automatic acoustic management;database;distortion;facial recognition system;image processing;image rectification;pattern recognition;polygonal modeling;sparse matrix;texture mapping	Zahid Riaz;Michael Beetz	2012			computer vision;artificial intelligence;computer science;facial recognition system	Vision	42.113259700706934	-53.131994376051495	59443
99b51082a39dc35df1681144fbe121d495563d59	fast phase-based registration of multimodal image data	motion analysis;traitement signal;image processing;complexite calcul;methode echelle multiple;localization;metodo imagen;procesamiento imagen;phase;transformation polynomiale;analyse mouvement;outlier;metodo escala multiple;localizacion;feature space;sintonizacion fase;traitement image;transformacion fourier rapida;fast fourier transform;registro imagen;etat actuel;observacion aberrante;nube;accuracy;complejidad computacion;precision;localisation;recalage image;methode domaine frequence;computational complexity;frequency domain method;feature extraction;signal processing;clouds;image registration;state of the art;transformacion polinomial;image method;pattern recognition;multimodal;observation aberrante;estado actual;keypoints;multiscale method;methode reechantillonnage;reconnaissance forme;extraction caracteristique;metodo dominio frecuencia;resampling method;nuage;analisis movimiento;reconocimiento patron;coarse grained;frequency domain;phase tuning;methode image;transformation fourier rapide;procesamiento senal;polynomial transformation;fast fourier transformation;accord phase;dynamic sub clouds	An interesting problem in pattern recognition is that of image registration, which plays an important role in many vision-based recognition and motion analysis applications. Of particular interest among registration problems are multimodal registration problems, where the images exist in different feature spaces. State-of-the-art phased-based approaches to multimodal image registration methods have provided good accuracy but have high computational cost. This paper presents a fast phase-based approach to registering multimodal images for the purpose of initial coarse-grained registration. This is accomplished by simultaneously performing both globally exhaustive dynamic phase sub-cloud matching and polynomial feature space transformation estimation in the frequency domain using the fast Fourier transform (FFT). A multiscale phase-based feature extraction method is proposed that determines both the location and size of the dynamic sub-clouds being extracted. A simple outlier pruning based on resampling is used to remove false keypoint matches. The proposed phase-based approach to registration can be performed very efficiently without the need for initial estimates or equivalent keypoints from both images. Experimental results show that the proposed method can provide accuracies comparable to the state-of-the-art phase-based image registration methods for the purpose of initial coarse-grained registration while being much faster to compute. & 2008 Elsevier B.V. All rights reserved.	algorithm;algorithmic efficiency;computation;computational complexity theory;fast fourier transform;feature extraction;feature vector;image registration;multimodal interaction;mutual information;pattern recognition;polynomial;resampling (statistics)	Alexander Wong;Paul W. Fieguth	2009	Signal Processing	10.1016/j.sigpro.2008.10.028	computer vision;fast fourier transform;image processing;computer science;image registration;kanade–lucas–tomasi feature tracker;signal processing;mathematics;accuracy and precision;algorithm;statistics	Vision	46.018094149503135	-59.85511277074225	59462
fc9779050142272f13cde4989ed0e445ad9b44d4	a method for restoration of low-resolution document images	modelizacion;discontinuity;optimisation;discontinuite;text;non linear programming;restauration image;image processing;image resolution;optimizacion;programacion no lineal;repartition bimodale;optical character recognition;low resolution;procesamiento imagen;image restoration;programmation non lineaire;texte;traitement image;experimental result;algorithme;modelisation;algorithm;restauracion imagen;aproximacion esplin;reconnaissance caractere;linear interpolation;spline approximation;approximation spline;reconocimento optico de caracteres;resultado experimental;distributed models;pattern recognition;interpolation lineaire;optimization;esplin cubico;spline cubique;discontinuidad;reconnaissance forme;reconocimiento patron;resultat experimental;nonlinear optimization;texto;modeling;character recognition;resolution image;reconocimiento caracter;reconnaissance optique caractere;interpolacion lineal;cubic spline;algoritmo	 Abstract. Image restoration using resolution expansion is important in many areas of image processing. This paper introduces a restoration method for low-resolution text images which produces expanded images with improved definition. This technique creates a strongly bimodal image with smooth regions in both the foreground and background, while allowing for sharp discontinuities at the edges. The restored image, which is constrained by the given low-resolution image, is generated by iteratively solving a nonlinear optimization problem. Low-resolution text images restored using this technique are shown to be both quantitatively and qualitatively superior to images expanded using the standard methods of linear interpolation and cubic spline expansion. Experimental results demonstrate that text images created by this new algorithm improve optical character recognition accuracy more than images obtained by existing expansion methods.	algorithm;chart;circuit restoration;cubic hermite spline;cubic function;fingerprint;frame (video);grayscale;image processing;image resolution;image restoration;linear interpolation;mathematical optimization;nonlinear programming;nonlinear system;optical character recognition;optimization problem;pixel;scoring functions for docking;spline (mathematics)	Paul D. Thouin;Chein-I Chang	2000	International Journal on Document Analysis and Recognition	10.1007/PL00021526	image restoration;computer vision;image resolution;nonlinear programming;computer science;algorithm	Vision	47.17783909336979	-64.02179667410122	59473
8740333d1c7c62f6c7a2290d8e54658c3912015e	structure and motion estimation from dynamic silhouettes under perspective projection	image features;curva;image tridimensionnelle;eficacia sistema;architecture systeme;estimation mouvement;image processing;occlusion;perspective projection;edge detection;implementation;estimacion movimiento;epipolar curves;performance systeme;procesamiento imagen;oclusion;courbe;motion estimation;stereoscopy;trinocular stereo;curve;system performance;traitement image;frontier points;deteccion contorno;algorithme;algorithm;ejecucion;detection contour;local structure;image sequence;silhouettes;stereoscopie;tridimensional image;arquitectura sistema;secuencia imagen;occluding contours;estereoscopia;system architecture;3d structure estimation;structure and motion;3d structure;sequence image;imagen tridimensional;algoritmo	We address the problem of estimating the structure and motion of a smooth curved object from its silhouettes observed over time by a trinocular stereo rig under perspective projection. We first construct a model for the local structure along the silhouette for each frame in the temporal sequence. The local models are then integrated into a global surface description by estimating the motion between successive time instants. The algorithm tracks certain surface features (parabolic points) and image features (silhouette inflections and frontier points) which are used to bootstrap the motion estimation process. The entire silhouettes along with the reconstructed local structure are then used to refine the initial motion estimate. We have implemented the proposed approach and report results on real images.	3d projection;algorithm;iterative method;motion estimation;normal (geometry);parabolic antenna	Tanuja Joshi;Narendra Ahuja;Jean Ponce	1999	International Journal of Computer Vision	10.1023/A:1008042709602	stereoscopy;computer vision;perspective;edge detection;image processing;computer science;motion estimation;geometry;curve;implementation;feature	Vision	49.80547556670453	-57.401966679443234	59498
278db1bfe32ea02fb8f6b0355d3f4548d767de15	emotracker: eyes and mouth tracker based on energy minimization criterion	template matching;energy minimization	We introduce a novel approach for online facial components tracking based on energy minimization criterion. The tracker, known asEMoTracker, employs template matching as the principal technique. As feature appearance changes during tracking, template matching suffers in providing good detection results. Therefore, instead of utilizing only the similarity (correlation values) independently, we add global constraints of facial components placement on face as additional parameters when searching corresponding components. In order to define the correct areas, we first list out n areas (which are the candidates) for eyes and mouth employing template matching technique. These candidates are arranged in high to low correlation order. Selections of correct candidates among these candidates are made based on energy minimization criterion. Additionally, an automatic feature selector and an adaptive face model have been incorporated with EMoTracker to handle tracking from multiple type of faces and non-frontal faces, respectively. Our proposed method also requires no manual initialization and parameter tuning.	embedded system;energy minimization;pose (computer vision);real-time clock;template matching;window-eyes	Shahrel A. Suandi;Shuichi Enokida;Toshiaki Ejima	2004			computer science;computer vision;artificial intelligence;pattern recognition;initialization;energy minimization;template matching	Vision	46.16847176097711	-53.42101554955659	59717
b28691ecaa0a0673cd71ed45834d03d4d18a4fdd	image processing, computer vision and pattern recognition in latin america	image processing;pattern recognition;latin america	Image processing, computer vision and pattern recognition are hot research topics in Latin America. SIBGRAPI is the most important Brazilian conference on visual computing, including computer graphics, image processing, computer vision, and pattern recognition. It attracts submissions from several Latin American authors, as well as contributors from North America, Europe, and Asia. This special issue presents extended versions of papers originally submitted to the 2008 edition of SIBGRAPI. Fifteen best evaluated papers in the areas of image processing, computer vision and pattern recognition were invited for this special issue. We had 12 submissions with considerably improved and extended versions of these works, and 10 of these papers were accepted after a thorough a peer-reviewing process. Four of the selected papers cover applications of pattern matching. The first paper tackles the problem of structural matching of 2D electrophoresis gels based on graph matching. In their approach, each image is represented as a graph, and a new quadratic assignment formulation together with a correspondence estimation algorithm is used to find the maximum common subgraph. The second paper explores Bayesian inference in the context of brain tissue classification. The paper examines the Discrete Model, in which every voxel belongs to a single tissue class, and the Partial Volume Model, where two classes may be present in a single voxel with a certain probability. An approximate algorithm based on the Maximum Evidence criterion is proposed to estimate the most probable parameters describing each model. The third paper uses Hidden Markov Models (HMMs) to classify agricultural crops in remote sensing image sequences. The authors assign each image segment to the crop class whose corresponding HMM delivers the highest probability of emitting the observed sequence of spectral values, and validated their approach using a set of 12 co-registered and radiometrically corrected LANDSAT images of region in southeast Brazil. The fourth paper of this special issue deals with content-based image retrieval with relevance feedback based on genetic programming. More precisely, the paper explores two different relevance feedback frameworks: in the first one, the user indicates only relevant images, while in the second both relevant and not relevant images are marked. The approach was tested on three databases using color, shape, and texture descriptors to characterize the images, and it outperformed six other relevance feedback methods. Another set of papers of this special issue cover topics mostly focused on computer vision and image processing. The fifth paper presents a robust technique for temporally aligning multiple video sequences that have no spatial overlap between their fields of view. The proposed approach reduces the problem of synchronizing several non-overlapping sequences to the problem of robustly estimating a single line from a set of appropriately-generated points in a multidimensional space, being able to handle arbitrarily-large misalignments between the sequences and does not require any a priori information about their temporal relations. The sixth paper also explores multiple cameras, but in the context of people detection and tracking. Background subtraction is used to compute evidence of the location of people on a reference ground plane for each calibrated camera, and homography constraints are used to integrate information from different cameras. Results conducted on benchmarked datasets from PETS’06 confirm the robustness of the method. The authors of the seventh paper proposed a methodology for the production of static video summaries based on color cues and k-means clustering, allowing faster browsing of large video collections and also more efficient content indexing and access. Another contribution of the paper was the development of a novel approach for the evaluation of video static summaries, used to validate the experiments. The eighth paper presents a method for automatic determination of the regularization parameters for the class of simultaneous super-resolution algorithms, that aims to allow zoom-ins without the introduction of significant image artifacts. The proposed approach is based on modeling the joint maximum a posteriori hyperparameters with a gamma prior distribution, and experimental results indicated their approach as a very attractive alternative for estimating the regularization parameters. The last two papers of this special issue present contributions to mathematical morphology, which has proven useful in a variety of applications in image processing, computer vision and patter recognition problems. In the ninth paper of this special issue, the authors consider grayscale image as a topographical surface, and represent it as a component tree. They propose three new extinction values that help the characterization of the topographical surface, and also describe an efficient computation of these extinction values based on the incremental determination of attributes from the component tree construction in quasi-linear time. The last paper proposes a new discrete Euclidean medial axis, which can be useful for shape description and analysis. More precisely, the author defines the High-resolution Reduced Discrete Medial Axis, which can be computed in optimal time. Skeletons obtained by combining the proposed approach with thinning algorithms present strong characteristics, not found in other approaches related in the literature. Finally, I would like to thank Dr. Gabriella Sanniti di Baja (Editor-in-Chief, Special Issues) for supporting this special issue and helping me with the decision process, and also Gary Anderton (former Journal Manager) for all the technical support. I would also like to thank all the reviewers for their careful work and all authors of submitted papers for their valuable contributions.	apache axis;approximation algorithm;background subtraction;benchmark (computing);cluster analysis;computation;computer graphics;computer vision;content-based image retrieval;database;experiment;gamma correction;genetic programming;graph (discrete mathematics);grayscale;http 404;hidden markov model;homography (computer vision);image processing;image segmentation;k-means clustering;markov chain;matching (graph theory);mathematical morphology;medial graph;norm (social);pattern matching;pattern recognition;relevance feedback;software framework;super-resolution imaging;technical support;temporal logic;texture filtering;thinning;time complexity;topography;visual artifact;visual computing;voxel	Cláudio Rosito Jung	2011	Pattern Recognition Letters	10.1016/j.patrec.2010.09.015	computer vision;speech recognition;image processing;computer science;latin americans	Vision	39.61756435953228	-54.03278918299672	59741
c82edf06df592ecf9f33b723c419428c14fd3e94	probabilistic model for quick detection of dissimilar binary images	databases;displays;video	We present a quick method to detect dissimilar binary images. The method is based on a “probabilistic matching model” for image matching. The matching model is used to predict the probability of occurrence of distinct-dissimilar image pairs (completely different images) when matching one image to another. Based on this model, distinct-dissimilar images can be detected by matching only a few points between two images with high confidence, namely 11 points for a 99.9% successful detection rate. For image pairs that are dissimilar but not distinct-dissimilar, more points need to be mapped. The number of points required to attain a certain successful detection rate or confidence depends on the amount of similarity between the compared images. As this similarity increases, more points are required. For example, images that differ by 1% can be detected by mapping fewer than 70 points on average. More importantly, the model is image size invariant; so, images of any sizes will produce high confidence levels with a limited number of matched points. As a result, this method does not suffer from the image size handicap that impedes current methods. We report on extensive tests conducted on real images of different sizes.	binary image;statistical model	Adnan A. Y. Mustafa	2015	J. Electronic Imaging	10.1117/1.JEI.24.5.053024	computer vision;video;computer science;internet privacy;computer graphics (images)	Vision	44.0180387454718	-53.93277825712638	59918
e341b45e673dc7208ea5b4ae14904325854acfb5	the vector-gradient hough transform	transversal luminosity profile vector gradient hough transform elongated shapes gray scale images;object recognition;vector space;shape detection;ing inf 01 elettronica;feature extraction hough transforms object recognition;visual inspection;feature extraction;shape image edge detection image reconstruction object detection us department of transportation gray scale inspection feature extraction object recognition pattern recognition;hough transforms;image analysis;hough transform;ing inf 07 misure elettriche e elettroniche	The paper presents a new transform, called Vector– Gradient Hough Transform, for identifying elongated shapes in grayscale images. This goal is achieved not only by collecting information on the edges of the objects, but also by reconstructing their transversal profile of luminosity. The main features of the new approach are related to its vector space formulation and the associated capability of exploiting all the vector information of the luminosity gradient.	algorithm;angularjs;branch (computer science);computation;computational complexity theory;discretization;emoticon;gradient descent;grayscale;hough transform;regular grid;selectivity (electronic);tree accumulation;turing completeness;weight function;xfig	Rita Cucchiara;Fabio Filicori	1998	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.689304	hough transform;computer vision;image analysis;vector space;feature extraction;computer science;cognitive neuroscience of visual object recognition;pattern recognition;scale-invariant feature transform;mathematics;computer graphics (images);visual inspection	Vision	41.962493084464526	-65.37815807182447	59963
e0388081929f856c37cc9fc99a9d07c5d63cdc9e	efficient iris-region normalization for a video surveillance system	transformation ondelette;funcion haar;video surveillance;calculateur embarque;coordenada polar;integrated circuit;fonction haar;surveillance;biometrie;haar function;authentication;extraction forme;biometrics;biometria;hombre;iris recognition;circuito integrado;embedded system;authentification;vigilancia;autenticacion;internet;senal video;signal video;monitoring;extraccion forma;human;boarded computer;video signal;polar coordinate;monitorage;transformacion ondita;monitoreo;coordonnee polaire;haar wavelet transform;pattern extraction;calculador embarque;wavelet transformation;circuit integre;homme	An efficient approach for iris recognition is presented in this paper. An efficient iris region normalization consists of a doubly polar coordinate and noise region exclude. And then a Haar wavelet transform is used to extract features from iris region of normalized. From this evaluation, we obtain iris code of small size and very high recognition rate. This effort is intended to enable a human authentication in small embedded systems, such as an integrated circuit card.		Jin Ok Kim;Bong Jo Joung;Chin Hyun Chung;Jun Hwang	2005		10.1007/11527725_39	computer vision;speech recognition;telecommunications;computer science;authentication;computer security	Vision	45.021282329950466	-60.3378399306822	60225
071f65ceded5c984016ef871e542aee6afe09276	finding the extrema of a region	convergence;application software;convolution;extrema;gravity;scene analysis computer vision extrema pattern recognition region growing;search strategy;statistical method;data mining;computer vision;assembly;optical character recognition software;distance measurement;computational modeling;shape;statistical analysis;extreme point;image analysis shape statistical analysis application software pattern recognition computational modeling computer simulation assembly optical character recognition software optical sensors;pattern recognition;image analysis;optical sensors;convex hull;region growing;computer simulation;algorithm design and analysis;scene analysis	The computational difficulty of finding the extreme points (those two points furthest from each other) in a region of an image is examined. Various approaches are described, including computation of convex hulls, sophisticated search strategies, and a statistical method. Suitability of the various methods to particular applications is discussed.	computation;tree traversal	Wesley E. Snyder;D. Allen Tang	1980	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1980.4767016	computer simulation;algorithm design;computer vision;extreme point;application software;image analysis;convergence;gravity;shape;computer science;convex hull;machine learning;pattern recognition;mathematics;assembly;geometry;region growing;convolution;computational model	Vision	48.06810475939066	-64.9088476050865	60278
32c702b517a304ceb41da34533d844abf61498cd	real-time hough transform based circular shape extraction	real time;hough transform	In this paper, two circular shape extraction methods based on C A M (Content Addressable M e m o y ) concept are proposed. The first method based on Hough Transform uses only the gradient amplitude infonnation, while the second uses in addition preselected gradient direction to estimate the center coordinates of the circle and then apply the H T circle extraction to extract i t 's mdius. The advantages of both our propositions consist of their performance to keep low both the hardware amount, and the computation time for extraction of unknown, noisy circular shapes.	computation;gradient;hough transform;real-time clock;shape context;the circle (file system);time complexity	Mahmoud Meribout;Takeshi Ogura;Mamoru Nakanishi	1996			computer vision;amplitude;computation;mathematics;artificial intelligence;hough transform	Vision	45.06053314504982	-64.75204866463157	60333
2ae7713c6d04a7737dd363cf6460b4bae573d227	hybrid dynamical models of human motion for the recognition of human gaits	modelizacion;image recognition;reconocimiento imagen;mouvement corporel;pistage;classification algorithm;estimation mouvement;analisis estadistico;image processing;modelo autorregresivo;estimacion movimiento;hybrid systemidentification;dynamic model;modelo hibrido;gait;rastreo;procesamiento imagen;auto regressive;motion estimation;marcha;gait recognition;probabilistic approach;classification;modele hybride;computer imaging vision pattern recognition and graphics;linear system;traitement image;synthesis;autoregressive model;hybrid model;modelisation;posture;recognition;statistical analysis;dynamical models;enfoque probabilista;approche probabiliste;human motion;analyse statistique;postura;reconnaissance image;hybrid system;gait analysis;artificial intelligence incl robotics;pattern recognition;image processing and computer vision;computer science;modele autoregressif;movimiento corporal;hybrid system identification;allure;modeling;clasificacion;body movement;human motion estimation;tracking	We propose a hybrid dynamical model of human motion and develop a classification algorithm for the purpose of analysis and recognition. We assume that some temporal statistics are extracted from the images, and use them to infer a dynamical model that explicitly represents ground contact events. Such events correspond to “switches” between symmetric sets of hidden parameters in an auto-regressive model. We propose novel algorithms to estimate switches and model parameters, and develop a distance between such models that explicitly factors out exogenous inputs that are not unique to an individual or his/her gait. We show that such a distance is more discriminative than the distance between simple linear systems for the task of gait recognition.	algorithm;dynamical system;gait analysis;kinesiology;linear system;network switch	Alessandro Bissacco;Stefano Soatto	2009	International Journal of Computer Vision	10.1007/s11263-009-0248-7	computer vision;image processing;computer science;artificial intelligence;mathematics;autoregressive model;statistics	Vision	46.66048079950549	-57.15801852211615	60387
54906f0a4f14ebed5b601d4cacf17a064565e883	a salient region detector for structured images		Finding correspondences between two images of the same scene or object, taken from different viewpoints and in different conditions, is a challenging task. Furthermore, in the analysis of scientific imagery, it must be possible in terms of human perception to appreciate detected local features, thus making the task even more complex. A renowned generic feature detector, Maximally Stable Extremal Regions (MSER), performs very well on structured images, but has difficulties with blur, lighting and increased resolution. The detected regions do not always correspond to semantically meaningful image structures, and the large number of regions hampers scalability. This paper proposes a Data-driven Morphology Salient Regions (DMSR) detector which overcomes these limitations. We present a new binarization algorithm which uses a threshold derived from the data; the resulting binary image is analyzed for saliency using morphology. DMSR shows transformation invariance and comparable repeatability to MSER on several evaluation benchmarks while obtaining better invariance to lighting, blur and resolution. This is achieved via significantly fewer regions, leading to better scalability. Preliminary results on animal and plant images indicate that DMSR could be a suitable approach for wild-life biometric applications as the detected regions correspond well to the semantic image structures. We also introduce OxFrei — a dataset for transformation-independent detection evaluation.	algorithm;binary image;biometrics;experiment;galaxy morphological classification;gaussian blur;image resolution;mathematical morphology;maximally stable extremal regions;repeatability;scalability	Elena Ranguelova	2016	2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2016.7945643	computer science;robustness (computer science);binary image;salience (neuroscience);maximally stable extremal regions;object detection;feature extraction;scalability;computer vision;artificial intelligence;pattern recognition;image resolution	Vision	39.280941341082624	-55.82226233563227	60465
302bf028487b50bed33bc6d36971b8ecf06393ab	landmark localisation in 3d face data	databases;ssr histograms;distance to local plane node property;graph theory;3d face recognition;mahalanobis distance;histograms;3d face data;shape descriptor;inner eye corners;image matching;3d face recognition grand challenge database landmark localisation 3d face data graph matching cascade filtering relaxation by elimination distance to local plane node property euclidean distance arc property minimum mahalanobis distance state of the art pose invariant feature descriptors inner eye corners root mean square errors;training;cascade filtering;minimum mahalanobis distance;3d feature descriptors;graph matching;euclidean distance arc property;face recognition;shape;facial landmark localisation;nose face recognition shape eyes support vector machines support vector machine classification robustness filtering filters spatial databases;three dimensional displays;feature extraction;stereo image processing;cascade filter;landmark localisation;state of the art pose invariant feature descriptors;ground truth;ssr histograms 3d feature descriptors facial landmark localisation cascade filter relaxation by elimination;3d face recognition grand challenge database;stereo image processing face recognition graph theory image matching;root mean square errors;invariant feature;nose;exhaustive search;relaxation by elimination	A comparison of several approaches that use graph matching and cascade filtering for landmark localization in 3D face data is presented. For the first method, we apply the structural graph matching algorithm “relaxation by elimination” using a simple “distance to local plane” node property and a “Euclidean distance” arc property. After the graph matching process has eliminated unlikely candidates, the most likely triplet is selected, by exhaustive search, as the minimum Mahalanobis distance over a six dimensional space, corresponding to three node variables and three arc variables. A second method uses state-of-the-art pose-invariant feature descriptors embedded into a cascade filter to localize the nose tip. After that, local graph matching is applied to localize the inner eye corners. We evaluate our systems by computing root mean square errors of estimated landmark locations against ground truth landmark localizations within the 3D Face Recognition Grand Challenge database. Our best system, which uses a novel pose-invariant shape descriptor, scores 99.77% successful localization of the nose and 96.82% successful localization of the eyes.	algorithm;brute-force search;coarse space (numerical analysis);computer vision;digital light processing;embedded system;euclidean distance;face recognition grand challenge;feature model;ground truth;linear programming relaxation;matching (graph theory);maxima;mean squared error;simple features;test set;three-dimensional face recognition;triplet state;v-optimal histograms;variable (computer science)	Marcelo Romero;Nick Pears	2009	2009 Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance	10.1109/AVSS.2009.90	facial recognition system;computer vision;ground truth;feature extraction;shape;computer science;graph theory;mahalanobis distance;machine learning;pattern recognition;brute-force search;histogram;mathematics;matching	Vision	41.385040609780816	-57.638277491617295	60536
45f04a838877a782231d10ded758fe09c855bff2	"""a comment on """"a note on 'distance transformations in digital images'"""""""	universiteitsbibliotheek;digital image;distance transform		digital image	A. L. D. Beckers;Arnold W. M. Smeulders	1989	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(89)90056-X	computer vision;computer science;theoretical computer science;distance transform;digital image;computer graphics (images)	Vision	48.4699137383119	-63.16572730399879	60538
98ee459d5b4745b2f48e926cbafb3a125e169343	thresholding and enhancement of text images for character recognition	morphological filter text images character recognition graytone images bi level images spatial resolution scene images variable thresholding image enhancement ocr;mathematical morphology;interpolation;image resolution;optical character recognition;spatial resolution character recognition image recognition image converters text recognition layout;image enhancement;interpolation optical character recognition image enhancement mathematical morphology filtering theory image resolution;character recognition;filtering theory;spatial resolution	A scheme which converts graytone text images of low spatial resolution to bi-level images of higher spatial resolution for character recognition are presented. Higher recognition rates are achieved when text images are processed using the proposed scheme. A good application of the proposed scheme is the recognition of characters in scene images.	optical character recognition;thresholding (image processing)	Wei W. Cindy Jiang	1995		10.1109/ICASSP.1995.479975	computer vision;speech recognition;image resolution;computer science;pattern recognition	Vision	39.21792567796153	-65.63478666173758	60556
1ec5dead13fddaae70be8ac9df184a167ae728cf	image segmentation based on transformations with reconstruction criteria	fiabilidad;reliability;image segmentation;image processing;binary image;procesamiento imagen;transformacion;ouverture;traitement image;marqueur;marcador;fiabilite;segmentation image;image binaire;abertura;imagen binaria;transformation;marker;opening	In this paper, a class of transformations with reconstruction criteria is investigated. This class of transformations was initially proposed for obtaining intermediate results between the morphological opening and the opening by reconstruction. Here, the transformations are presented in the general case, as in the reconstruction transformations case, by imposing some conditions on the marker. The form of selecting the markers to build these transformations is particularly described for binary images. Since the transformations studied in this work use a reconstruction criterion, we illustrate how it can be modified in order to have a better control of the output image. Finally, the interest of these transformations in image segmentation is also shown.	binary image;image segmentation;opening (morphology);reconstruction filter	Iván R. Terol-Villalobos;Jorge D. Mendiola-Santibañez	2003		10.1007/978-3-540-45179-2_45	transformation;computer vision;binary image;image processing;computer science;reliability;mathematics;image segmentation;opening;algorithm	Vision	47.7344962623927	-64.12155517335258	60687
19aca01bafe52131ec95473dac105889aa6a4d33	robust method for road sign detection and recognition	analisis imagen;kalman filtering;pistage;traffic signs;filtrage kalman;image processing;edge detection;improvement;gestion trafic;rastreo;traffic control;edge extraction;automatisation;road signalling;imagen nivel gris;senalizacion trafico;traffic management;automatizacion;image bruitee;signalisation routiere;deteccion contorno;imagen sonora;detection contour;a priori knowledge;noisy image;amelioration;image niveau gris;robust method;pattern recognition;gestion trafico;mejoria;image analysis;reconnaissance forme;regulation trafic;reconocimiento patron;grey level image;analyse image;filtrado kalman;regulacion trafico;tracking;color image;automation	This paper describes a method for detecting and recognizing road signs in gray-level and color images acquired by a single camera mounted on a moving vehicle. The method works in three stages. First, the search for the road sign is reduced to a suitable region of the image by using some a priori knowledge on the scene or color clues (when available). Secondly, a geometrical analysis of the edges extracted from the image is carried out, which generates candidates to be circular and triangular signs. Thirdly, a recognition stage tests by cross-correlation techniques each candidate which, if validated, is classi ed according to the data-base of signs. An extensive experimentation has shown that the method is robust against low-level noise corrupting edge detection and contour following, and works for images of cluttered urban streets as well as country roads and highways. A further improvement on the detection and recognition scheme has been obtained by means of temporal integration based on Kalman ltering methods of the extracted information. The proposed approach can be very helpful for the development of a system for driving assistance.	color;cross-correlation;database;edge detection;high- and low-level;kalman filter;robustness (computer science);sensor	Giulia Piccioli;Enrico De Micheli;Pietro Parodi;Marco Campani	1996	Image Vision Comput.	10.1016/0262-8856(95)01057-2	kalman filter;computer vision;active traffic management;image analysis;a priori and a posteriori;simulation;edge detection;color image;image processing;computer science;automation;tracking	Vision	48.44437298738177	-57.774455873486254	60820
bc47c39388baf5105b0cdddc4eb5cabd438dd7b0	computing three-dimensional motion parameters: a hypothesis testing approach	test hypothese;analisis imagen;robot movil;vision ordenador;movimiento;test hipotesis;motion;three dimensional;computer vision;algorithme;algorithm;robot mobile;mouvement;image sequence;motion problems algorithms;estimacion parametro;image analysis;vision ordinateur;secuencia imagen;parameter estimation;estimation parametre;analyse image;article;3d motion;moving robot;sequence image;algoritmo;hypothesis test	Despite great advances in the analysis of motion problems, implementing or searching for correct and robust algorithms is still challenging and elusive. The main purpose of this paper is to show that a hypothesis testing paradigm can provide an effective and robust way for computing solutions to motion problems. In particular, we show that computing a solution to a motion problem is equivalent to selecting a correct hypothesis from a set of possible ones, and rejecting or validating a hypothesis involves similar computations. The proposed method is inherently suitable for implementations in parallel machines. We use a variety of real images, like outdoors scenes, truck motion, and robot scenes to test and evaluate our method.	algorithm;computation;programming paradigm;robot	Chia-Hoang Lee	1993	Image Vision Comput.	10.1016/0262-8856(93)90053-J	three-dimensional space;computer vision;statistical hypothesis testing;image analysis;simulation;computer science;artificial intelligence;motion;mathematics;estimation theory	Vision	49.251186493098906	-57.24027009011639	60874
32cf8af53289948cad5215e01ba6c6cf0901839a	3d object recognition using invariants of 2d projection curves	image tridimensionnelle;object recognition;transformation affine;implicit polynomials;raisonnement base sur cas;razonamiento fundado sobre caso;euclidean theory;t technology general;distance measure;reconnaissance objet;principal axes;curva algebraica;3d object recognition;equation polynomiale;polynomial equation;invariants;algebraic geometry;courbe algebrique;recognition;algebraic surfaces;ecuacion polinomial;object oriented;affine transformation;theorie euclidienne;tridimensional image;invariante;oriente objet;geometria algebraica;cross section;reconocimiento de objetos;case based reasoning;orientado objeto;invariant;transformacion afin;imagen tridimensional;tk electrical engineering electronics nuclear engineering;teoria euclidiana;geometrie algebrique;algebraic curve	This paper presents a new method for recognizing 3D objects based on the comparison of invariants of their 2D projection curves. We show that Euclidean equivalent 3D surfaces imply affine equivalent 2D projection curves that are obtained from the projection of cross-section curves of the surfaces onto the coordinate planes. Planes used to extract cross-section curves are chosen to be orthogonal to the principal axes of the defining surfaces. Projection curves are represented using implicit polynomial equations. Affine algebraic and geometric invariants of projection curves are constructed and compared under a variety of distance measures. Results are verified by several experiments with objects from different classes and within the same class.	3d single-object recognition;algebraic equation;experiment;invariant (computer science);linear algebra;outline of object recognition	Mustafa Unel;Octavian Soldea;Erol Ozgur;Alp Bassa	2010	Pattern Analysis and Applications	10.1007/s10044-010-0179-5	discrete mathematics;projection plane;geometric design;topology;projection;algebraic geometry;isometric projection;invariant;affine geometry of curves;mathematics;geometry;family of curves;orthographic projection;planar projection;graphical projection;projection	Vision	48.937103751645914	-60.259811146044065	61232
5116ec5bc957324cc13d692815e24c31b646061c	space- and time-variant estimation approaches and the segmentation of the resulting optical flow fields	image sequence;optical flow	A Gaussian-blob model for local spatiotemporal gray value variations is exploited in order to simultaneously estimate an optical flow vector and the dominant spatiotemporal scale of the gray value variation which forms the basis for this estimation. A two-step, non-iterative, local estimation approach is developed which does not include any explicit smoothness term. Various experiments with real world image sequences nevertheless yield smooth optical flow fields with surprisingly good results, even close to discontinuities of the optical flow field along occluding contours. Close in this context means within one to three pixels, i. e. much less than the width of the weight masks employed to estimate the spatiotemporal gradient of the gray value variation.	optical flow	Hans-Hellmut Nagel;A. Gehrke;Michael Haag;Michael W. Otte	1995		10.1007/3-540-60793-5_64	computer vision;mathematical optimization;computer science;optical flow;mathematics;geometry;scale-space segmentation	Vision	52.678337562200056	-54.48220248811355	61536
dbdefa063aae324f23e8a0999a7f8eb29d0c3156	texture-based pattern recognition algorithms for the robocup challenge	image understanding;pattern recognition;visual perception;spatial frequency	Since texture is a fundamental character of images, it plays an important role in visual perception, image understanding and scene interpretation. This paper presents a texture-based pattern recognition scheme for Sony robots in the RoboCup domain. Spatial frequency domain algorithms are adopted and tested on a PC while simple colour segmentation and blob-based recognition are implemented on real robots. The experimental results show that the algorithms can achieve good recognition results in the RoboCup Pattern Recognition challenge.	algorithm;color vision;computer vision;outline of object recognition;pattern recognition;personal computer;real-time clock;real-time locating system;requirement;robot	Bo Li;Huosheng Hu	2003		10.1007/978-3-540-25940-4_58	computer vision;simulation;visual perception;computer science;spatial frequency	Vision	41.51911428772571	-65.4398499318392	61570
5d6039736394b8117af77915ef6db199450bd6e3	adaptive elimination of false edges for first order detectors	first order	In this paper, we propose a new rule for the elimination of false edges produced by gradient detectors. This rule is based on the characteristics of the image and the properties of the detector used. The rule has been tested on realistic images using multi-scale edge detectors.	edge detection;gradient;sensor	Djemel Ziou;Salvatore Tabbone	1995		10.1007/3-540-60298-4_241	computer science;first-order logic;mathematics;algorithm	Vision	49.387169329194656	-65.31679343972152	61598
5142dc02140c8ac24a31a4c55d9d2c2ff1c605a5	overlapped-triangle analysis with hierarchical ranking of dominance	overlapped triangle detection;gestalt theory;plane geometric figure;plane geometric figure overlapped triangle detection visual dominance analysis gestalt theory;object detection geometry;pgf overlapped triangle analysis hierarchical dominance ranking overlapped triangle detection gestalt theory convex triangle interior auxiliary triangles;visual dominance analysis	Plane geometric figures (PGFs) are essential diagrams that regularly appear in mathematics documents. To understand PGFs profoundly and intuitively, it is necessary to decompose them into visual elements rather than traditional line segments. In this paper, we present a method for detection and analysis of overlapped triangles on the basis of dominance rank. Overlapped triangles lead to a large quantity of redundant sub-triangles or incident triangles. The most important and representative triangles must be detected and adopted to reduce redundancy. Diverse types of relationships among potential triangles present at least three obstacles: (1) how to precisely detect all potential triangles, (2) how to select predominant triangles, and (3) how to verify that the combination of these predominant triangles can reconstruct the original figure. Based on Gestalt theory, we propose a method for selecting predominant triangles, including selection of the main convex triangle and composition of interior auxiliary triangles. Experiments show that our algorithm can detect most of the potential triangles and can present reasonable decomposition solutions using only few predominant elements.	algorithm;diagram;experiment;gestalt psychology;redundancy (engineering)	Xiaoqing Lu;Lu Liu;Zhi Tang;Haibin Ling	2015	2015 13th International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2015.7333870	ideal triangle;cpctc;algorithm;degeneracy;gestalt psychology	DB	43.55842420712032	-64.00064997676137	61714
52f197116bb8ccfc9029bc24c12b63322f00cd46	a fast and robust cluster update algorithm for image segmentation in spin-lattice models without annealingvisual latencies revisited	modelizacion;image features;tecnologia electronica telecomunicaciones;estimator robustness;cluster;computacion informatica;algorithm performance;image segmentation;image processing;fonction energie;amas;estudio comparativo;echantillonnage;procesamiento imagen;grupo de excelencia;segmentation;etiquetage;traitement image;gray scale;energy function;etiquetaje;sampling;algorithme;modelisation;etude comparative;algorithm;vecino mas cercano;robustez estimador;resultado algoritmo;ciencias basicas y experimentales;comparative study;performance algorithme;labelling;funcion energia;plus proche voisin;nearest neighbour;monton;reseau neuronal;tecnologias;muestreo;grupo a;local minima;echelle gris;lattice model;modeling;red neuronal;segmentacion;escala gris;neural network;algoritmo;robustesse estimateur	Image segmentation in spin-lattice models relies on the fast and reliable assignment of correct labels to those groups of spins that represent the same object. Commonly used local spin-update algorithms are slow because in each iteration only a single spin is flipped and a careful annealing schedule has to be designed in order to avoid local minima and correctly label larger areas. Updating of complete spin clusters is more efficient, but often clusters that should represent different objects will be conjoined. In this study, we propose a cluster update algorithm that, similar to most local update algorithms, calculates an energy function and determines the probability for flipping a whole cluster of spins by the energy gain calculated for a neighborhood of the regarded cluster. The novel algorithm, called energy-based cluster update (ECU algorithm) is compared to its predecessors. A convergence proof is derived, and it is shown that the algorithm outperforms local update algorithms by far in speed and reliability. At the same time it is more robust and noise tolerant than other versions of cluster update algorithms, making annealing completely unnecessary. The reduction in computational effort achieved this way allows us to segment real images in about 15 sec on a regular workstation. The ECU-algorithm can recover fine details of the images, and it is to a large degree robust with respect to luminance-gradients across objects. In a final step, we introduce luminance dependent visual latencies (Opara & Wrgtter, 1996; Wrgtter, Opara, Funke, & Eysel, 1996) into the spin-lattice model. This step guarantees that only spins representing pixels with similar luminance become activated at the same time. The energy function is then computed only for the interaction of the regarded cluster with the currently active spins. This latency mechanism improves the quality of the image segmentation by another 40. The results shown are based on the evaluation of gray-level differences. It is important to realize that all algorithmic components can be transferred easily to arbitrary image features, like disparity, texture, and motion.	algorithm;binocular disparity;class;computer vision;energy drift;engine control unit;gradient;high- and low-level;image segmentation;iteration;large;lattice model (physics);mathematical optimization;maxima and minima;physical object;pixel;real-time clock;requirement;simulated annealing;texture mapping;version;workstation;biologic segmentation	Ralf Opara;Florentin Wörgötter	1998	Neural Computation	10.1162/089976698300017304	sampling;lattice model;systems modeling;image processing;computer science;artificial intelligence;maxima and minima;comparative research;mathematics;image segmentation;segmentation;feature;artificial neural network;algorithm;grayscale;cluster	Vision	47.54115856391622	-64.33904777103976	61800
b124ec22174d005e2bb043daad5bc8df64041d82	recognition and localization of objects with curved surfaces	tratamiento paralelo;vision ordenador;modeling technique;constraint propagation;range data;gaussian curvature;image processing;traitement parallele;localizacion objeto;object location;espacio 3 dimensiones;procesamiento imagen;segmentation;traitement image;range image segmentation;three dimensional;superficie curva;computer vision;curved surface;multiple objectives;connection machine;range image;feature extraction;espace 3 dimensions;three dimensional space;pattern recognition;surface courbe;vision ordinateur;reconnaissance forme;reconocimiento patron;localisation objet;segmentacion;parallel processing;object model	This paper concerns the problem of recognition and localization of three-dimensional objects from range data. Most of the previous approaches suffered from one or both of the following shortcomings: (1) They dealt with single object scenes and/or (2) they dealt with polyhedral objects or objects that were approximated as polyhedra. The work in this paper addresses both of these shortcomings. The input scenes are allowed to contain multiple objects with partial occlusion. The objects are not restricted to polyhedra but are allowed to have a piecewise combination of curved surfaces, namely, spherical, cylindrical, and conical surfaces. This restriction on the types of curved surfaces is not unreasonable since most objects encountered in an industrial environment can be thus modeled. This paper shows how the qualitative classification of the surfaces based on the signs of the mean and Gaussian curvature can be used to come up withdihedral feature junctions as features to be used for recognition and localization. Dihedral feature junctions are robust to occlusion, offer a viewpoint independent modeling technique for the object models, do not require elaborate segmentation, and the feature extraction process is amenable to parallelism. Hough clustering on account of its ease of parallelization is chosen as the constraint propagation/ satisfaction mechanisms. Experimental results are presented using the Connection Machine. The fine-grained architecture of the Connection Machine is shown to be well suited for the recognition/localization technique presented in this paper.	approximation algorithm;cluster analysis;connection machine;feature extraction;hough transform;local consistency;parallel computing;polyhedron	Suchendra M. Bhandarkar;Minsoo Suk	1990	Machine Vision and Applications	10.1007/BF01240388	three-dimensional space;parallel processing;computer vision;image processing;computer science;mathematics;geometry	Robotics	48.5007173644941	-59.156061233463824	61828
5c5e41ab425f58c2deb133def3341182e1555bcd	polygonal approximation of closed curves across multiple views		Polygon approximation is an important step in the recognition of planar shapes. Traditional polygonal approximation algorithms handle only images that are related by a similarity transformation. The transformation of a planar shape as the viewpoint changes with a perspective camera is a general projective one. In this paper, we present a novel method for polygonal approximation of closed curves that is invariant to projective transformation. The polygons generated by our algorithm from two images, related by a projective homography, are isomorphic. We also describe an application of this in the form of numeral recognition. We demonstrate the importance of this algorithm for real-life applications like number plate recognition, aircraft recognition and metric rectification.	approximation algorithm;automatic number plate recognition;homography (computer vision);outline of object recognition;planar (computer graphics);real life;rectifier	M. Pawan Kumar;Saurabh Goyal;C. V. Jawahar;P. J. Narayanan	2002			polygonal chain;numeral system;artificial intelligence;computer vision;computer science;rectification;approximation algorithm;isomorphism;polygon;invariant (mathematics);topology;mathematical optimization;homography	Vision	50.47553389156341	-53.621200967615444	61881
ad439721b4cc898adc4f420b7cf43e59f53451e0	visual loop closure detection with a compact image descriptor	correlation methods;slam robots correlation methods image sequences object detection particle filtering numerical methods principal component analysis robot vision;visualization;loop closure candidates visual loop closure detection compact image descriptor locally extracted keypoint descriptors low dimension image descriptor similarity measures pca high dimensional gabor gist descriptor computational efficiency discriminative power image sequences particle filtering oxford city dataset slam robots simultaneous localization and mapping;robot vision;feature extraction;principal component analysis;visualization feature extraction simultaneous localization and mapping principal component analysis coherence;simultaneous localization and mapping;coherence;slam robots;object detection;particle filtering numerical methods;image sequences	In this paper, we present a method for visual loop closure detection using a compact image descriptor, Gabor-Gist. In contrast to the Bag-of-Words (BoW) approach, which is dominant in recent studies of the loop closure detection problem that derives an image descriptor from locally extracted keypoint descriptors, our method relies on a single efficient image descriptor of low dimension to describe and measure similarities among images. We employ PCA to transform a high dimensional Gabor-Gist descriptor to a lower dimensional form to improve both the computational efficiency of our method and the discriminative power of the image descriptor. In addition, we use a particle filter to exploit the correlation among images in a sequence captured by the robot in the process of identifying loop closure candidates. Our method is highly scalable due to the compactness of the image descriptor and the simplicity of particle filtering. To validate our method, we used the Oxford City dataset. Our experimental results show that for this dataset, high recall (up to 87%) can be obtained at 100% precision, with only a few particles.	bag-of-words model in computer vision;computation;gist;particle filter;principal component analysis;scalability;visual descriptor	Yang Liu;Hong Zhang	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6386145	computer vision;visualization;coherence;feature extraction;gloh;computer science;machine learning;pattern recognition;mathematics;principal component analysis;simultaneous localization and mapping	Robotics	39.41320683694988	-55.036719475263354	61900
e2d3118e07ae3e62681e143e14595bb79f34deee	calibrating an automatic zoom camera with moving least squares	metodo cuadrado menor;contraste;modelizacion;employment;methode moindre carre;vision ordenador;least squares approximations;interpolation;cameras least squares methods multilevel systems polynomials clustering algorithms lenses machine vision employment parameter estimation computational complexity;image processing;least squares method;ajustamiento curva;complexite calcul;computational complexity automatic zoom camera calibration zoom camera lens machine vision parameter estimation moving least squares multiple regression polynomial function;fonction polynomiale;modeling interpolation least squares methods lenses machine vision;zoom;procesamiento imagen;least square method;indexing terms;multilevel systems;traitement image;remote operation;polynomials;computer vision;modelisation;complejidad computacion;automatic zoom camera calibration;zoom camera lens;moving least square;computational complexity;machine vision;regresion multiple;teleaccion;image sequence;retard;lenses;estimacion parametro;regression analysis calibration cameras computational complexity computer vision least squares approximations parameter estimation;clustering algorithms;ajustement courbe;vision ordinateur;etalonnage;regression analysis;secuencia imagen;moving least squares multiple regression;modele amas;parameter estimation;estimation parametre;cluster model;curve fitting;funcion polinomial;polynomial function;retraso;modeling;regression multiple;calibration;least squares methods;cameras;sequence image;teleoperation;multiple regression	The application of zoom camera lenses in machine vision has gained a lot of attention lately. The main difficulty in their employment lies in the accurate estimation of their intrinsic parameters. In this paper, we propose novel approaches to determine these parameters by estimating continuous models of their variations as the focus and the zoom change. The first method is based on the moving least squares (MLS) multiple regression scheme which determines from a predefined number of samples, the complete model of the intrinsic parameters. MLS fits a polynomial function at each focus and zoom setting by using the measured neighboring points. In order to reduce the computational complexity of MLS, we propose another algorithm in which the MLS generated curves are clustered. Then, each cluster is modeled with a single polynomial function. This decreases the complexity of computations for the applications where delay is critical, e.g., telepresence, to the evaluation of simple polynomials. Compared to previous techniques, the proposed algorithms lead to a noticeable increase in the estimation accuracy of the intrinsic parameters. In addition, they are able to generate accurate models of these parameters with only a few measurement points.	algorithm;camera resectioning;computation;computational complexity theory;concatenation;digital zoom;fits;interpolation;machine vision;missing data;moving least squares;pixel;polynomial;reprojection error;robotic mapping;virtual reality headset;on-line system	Michel Sarkis;Christian T. Senft;Klaus Diepold	2009	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2009.2021350	computer vision;mathematical optimization;machine vision;image processing;computer science;mathematics;least squares;statistics	Vision	49.73331038155267	-56.56278314891312	61984
43dea19856bf21d1817c7d0cadb098db00c0cc2e	topological image analysis and (normalised) representations for plant phenotyping	topology;image segmentation;normalised representation plant phenotyping topological image analysis root system features branch overlapping 2d image computational topology root images reeb graph based representation;application for computational topology topological image analysis root phenotyping reeb graphs normalised root representation;length measurement;skeleton;image representation botany graph theory;level measurement;image segmentation level measurement topology length measurement skeleton image analysis soil;image analysis;soil	This paper discusses the use of topological image analysis to derive characteristics needed in plant phenotyping. Due to certain features of root systems (deformation over time, overlaps of branches in a 2D image of the root system) a topological analysis is needed to correctly derive these characteristics. The advantages of such a topological analysis are highlighted in this paper and root phenotyping is presented as a new application for computational topology. Characteristics used in plant phenotyping that can be derived from root images using methods of topological image analysis are further presented. A Reeb graph based representation of root images is shown as an example for such a topological analysis. Based on a graph representation a new, normalised representation of root images is introduced.	computational topology;graph (abstract data type);image analysis;persistence (computer science)	Ines Janusch;Walter G. Kropatsch;Wolfgang Busch	2014	2014 16th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2014.83	combinatorics;discrete mathematics;image analysis;topology;length measurement;computer science;mathematics;image segmentation;skeleton	Arch	49.5931996068246	-63.08908340610431	62021
ced7811f2b694e54e3d96ec5398e4b6afca67fc0	illumination compensation and normalization for robust face recognition using discrete cosine transform in logarithm domain	erbium;sensitivity and specificity;histograms;cmu;lighting robustness face recognition discrete cosine transforms histograms image databases adaptive equalizers erbium shape;image databases;helium;low frequency;real time;photography;discrete cosine transforms face recognition feature extraction lighting;cmu pie database;discrete cosine transform;illumination normalization;signal processing computer assisted;logarithm transform;image enhancement;algorithms artificial intelligence face humans image enhancement image interpretation computer assisted information storage and retrieval lighting pattern recognition automated photography photometry reproducibility of results sensitivity and specificity signal processing computer assisted;face recognition;shape;logarithm transform discrete cosine transform face recognition illumination normalization;image interpretation computer assisted;photometry;discrete cosine transforms;feature extraction;lighting conditions;reproducibility of results;robust real time face recognition system;artificial intelligence;algorithms;robustness;pattern recognition automated;face;humans;cmu pie database illumination compensation illumination normalization approach robust real time face recognition system discrete cosine transform dct logarithm transform lighting conditions yale b database;lighting;illumination compensation;information storage and retrieval;dct;illumination normalization approach;adaptive equalizers;yale b database	This paper presents a novel illumination normalization approach for face recognition under varying lighting conditions. In the proposed approach, a discrete cosine transform (DCT) is employed to compensate for illumination variations in the logarithm domain. Since illumination variations mainly lie in the low-frequency band, an appropriate number of DCT coefficients are truncated to minimize variations under different lighting conditions. Experimental results on the Yale B database and CMU PIE database show that the proposed approach improves the performance significantly for the face images with large illumination variations. Moreover, the advantage of our approach is that it does not require any modeling steps and can be easily implemented in a real-time face recognition system.	coefficient;discrete cosine transform;face;facial recognition system;feature extraction;frequency band;global illumination;illumination (image);logarithm;real-time clock;rough set;shadowing (histology);specularity	Weiteng Chen;Meng Joo Er;Shiqian Wu	2006	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2005.857353	facial recognition system;computer vision;speech recognition;computer science;discrete cosine transform;computer graphics (images)	Vision	43.53333380646079	-58.25599345535991	62068
0f5228e3caa7f8824c3be24bb35361c7670e9592	object recognition with color cooccurrence histograms	false alarm;image colour analysis object recognition;histograms;image recognition;object recognition;false alarm color cooccurrence histogram object recognition color histogram background clutter partial occlusions;object recognition histograms pixel image recognition solid modeling orbital robotics abstracts information geometry testing mathematical model;computer model;color cooccurrence histogram;color histogram;testing;orbital robotics;information geometry;image colour analysis;abstracts;pixel;solid modeling;mathematical model;partial occlusions;false alarm probability;point of view;background clutter	We use the color cooccurrence histogram (CH) for recognizing objects in images. The color CH keeps track of the number of pairs of certain colored pix els that occur at certain separation distances in image space. The color CH adds geometric information to t he normal color histogram, which abstracts away all geometry. We compute model CHs based on images of known objects taken from different points of view. These model CHs are then matched to subregions in test images to find the object. By adjusting the number of colors and the number of distances used in the CH, we can adjust the tolerance of the algorithm to change s in lighting, viewpoint, and the flexibility of the obj ect. We develop a mathematical model of the algorithm’s fal e alarm probability and use this as a principled way of picking most of the algorithm’s adjustable paramete rs. We demonstrate our algorithm on different objects, showing that it recognize objects in spite of confu sing background clutter, partial occlusions, and flexing of the object.	approximation algorithm;cisco pix;clutter;color histogram;outline of object recognition;pixel	Peng Chang;John Krumm	1999		10.1109/CVPR.1999.784727	computer simulation;color histogram;computer vision;speech recognition;color normalization;computer science;cognitive neuroscience of visual object recognition;pattern recognition;mathematical model;histogram;mathematics;software testing;solid modeling;information geometry;pixel;statistics	Vision	43.528276094749614	-53.91698305554131	62094
bc97cfe8b8b6b518d0e8f00ac64daa0bad7b2e3d	multiresolution image dynamic thresholding	analisis imagen;vision ordenador;multiresolucion;image processing;seuil;hierarchized structure;procesamiento imagen;threshold;pyramide;search strategy;structure hierarchisee;segmentation;traitement image;computer vision;dynamic threshold;pyramid;strategie recherche;multiresolution;image analysis;vision ordinateur;bottom of the pyramid;umbral;piramide;analyse image;estructura jerarquizada;segmentacion;estrategia investigacion	A pyramid-based method of dynamic thresholding where the Gaussian pyramid is used to support a “coarse-to-fine” search strategy is presented. At the top level of the pyramid the image is divided into four subimages, and in each subimage, the gray-level variance is analyzed to find whether there is an edge. The hierarchical search is continued until the bottom level of the pyramid, or the original image, is reached. At the bottom level the threshold values of those subimages where an edge is present are estimated, and the value of zero is assigned to those subimages where no edge is present. Finally, by using interpolations of subimage and pixel threshold values, the dynamic threshold values are found.	gaussian blur;interpolation;multiresolution analysis;pixel;thresholding (image processing)	Shuwu Song;Mengyang Liao;Jiamei Qin	1988	Machine Vision and Applications	10.1007/BF01211448	computer vision;pyramid;image analysis;image processing;computer science;pyramid;computer graphics (images)	Vision	47.06182480521066	-63.90304145532538	62181
4832f70845f00ced3f0aa7e87d0c7c28f0aba510	robustifying correspondence based 6d object pose estimation		We propose two methods to robustify point correspondence based 6D object pose estimation. The first method, curvature filtering, is based on the assumption that low curvature regions provide false matches, and removing points in these regions improves robustness. The second method, region pruning, is more general by making no assumptions about local surface properties. Our region pruning segments a model point cloud into cluster regions and searches good region combinations using a validation set. The robustifying methods are general and can be used with any correspondence based method. For the experiments, we evaluated three correspondence selection methods, Geometric Consistency (GC) [1], Hough Grouping (HG) [2] and Search of Inliers (SI) [3] and report systematic improvements for their robustified versions with two distinct datasets.	3d pose estimation;autonomous robot;branch and bound;cross-validation (statistics);experiment;hough transform;point cloud;robustification;xslt/muenchian grouping	Antti Hietanen;Jussi Halme;Anders Glent Buch;Jyrki Latokartano;Joni-Kristian Kämäräinen	2017	2017 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2017.7989091	3d pose estimation	Robotics	42.832723875420655	-54.47026830612501	62270
bdc4107207ee6f457b4b3ea9e297a949b984b1c1	application of edge and line detection to detect the near surface anomalies in potential data		Presented paper is focused on fast near surface anomaly detection in potential data. Our aim is to find fast and semi –automated anomaly detection technique for the near surface anomalies with defined geometry. The proposed algorithm is based on the shape recognition. The edge and line detection is used on acquired data to detect the typical shape of the anomaly. Shape geometry parameters are converted into the anomaly parameters and location information. The technique was tested using a set of noise-free and noisy synthetic gravity data; satisfactory results were obtained.	algorithm;anomaly detection;edge detection;semiconductor industry;shape context;synthetic intelligence	Lenka Kosková Trísková;Josef Novák	2013			artificial intelligence;computer science;pattern recognition	Vision	47.71436021701831	-65.54580008746464	62290
5cca6507c2710eec1bb982d1f247b431559fb722	range image segmentation based on differential geometry: a hybrid approach	deteccion borde;depth values;region based method;geometry computerised pattern recognition computerised picture processing curve fitting;edge based method;local biquadratic surface fit;partial derivatives;vision ordenador;range data;image segmentation;image processing;edge detection;differential geometry;geometry;surface fitting;procesamiento imagen;3d object;range data analysis;computerised pattern recognition;segmentation;traitement image;range image segmentation;computer vision;data analysis;hybrid approach;shape;image edge detection;range image;pattern recognition;surface primitives;geometrie differentielle;computerised picture processing;councils;cities and towns;image analysis;vision ordinateur;depth values region based method 3d object edge based method computerised picture processing pattern recognition differential geometry image segmentation range data analysis surface primitives surface orientation partial derivatives local biquadratic surface fit curvature sign map;geometria diferencial;curve fitting;mean curvature;detection bord;image segmentation geometry image edge detection surface fitting shape laboratories image analysis data analysis councils cities and towns;segmentacion;surface orientation;curvature sign map	One of the most significant problems arising out of range data analysis is image segmentation. This correspondence describes a hybrid approach to the problem, where hybrid refers to a comhination of both regionand edge-based considerations. The range image of 3-D objects is divided into surface primitives which are homogeneous in their intrinsic differential geometric properties and do not contain discontinuities in either depth or surface orientation. The method is based on the computation of partial derivatives which are obtained by a selective local hiquadratic surface fit. Then by computing the Gaussian and mean curvatures, an initial region-based segmentation is obtained in the form of a curvature sign map. Two additional initial edge-based segmentations are also computed from the partial derivatives and depth values: jump and roof edge maps. The three image maps are then combined to produce the final segmentation. Experimental results were obtained for both synthetic and real range data of polyhedral and curved	computation;glossary of computer graphics;image map;image segmentation;polyhedron;range imaging;range segmentation;synthetic data	Naokazu Yokoya;Martin D. Levine	1989	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.24798	computer vision;range segmentation;image analysis;edge detection;topology;image processing;shape;computer science;segmentation-based object categorization;mean curvature;mathematics;geometry;image segmentation;partial derivative;data analysis;scale-space segmentation;segmentation;curve fitting	Vision	49.93720572468335	-58.83292756200132	62403
6c0f0064afd2ce0a0a231b80de611ca34e208222	shape normalisaiton for face recognition	lts1	This paper presents methods for shape normalisation of face images. Localisation and shape normalisation are prerequisites for face recognition algorithms like the eigenface approach. Other established face recognition methods like labeled graph matching can also be accelerated by providing normatised face image databases. We present results on translational normalisation of face images and evaluate a method for matching face images by applying affine transformations using robust estimations. The results of the transformations are evaluated with the eigenface method. 1 I n t r o d u c t i o n The detection and precise localisation of faces is a prerequisite for successful face recognition applications. Shape normalisation is an important pre-processing step for face recognition especially for the normalisation of face image databases. Shape normalised face images have the advantage that face recognition techniques like the eigenface method [9] can be applied directly. Other techniques can also benefit from a shape normalised database of face images. A survey of face recognition research prior to 1991 can be found in [7]. Research results since 1991 are presented in [3]. A survey about connectionist methods for face recognition is presented in [i0]. In [5] a method based on simple face templates so-called mosaics is used to detect faces on different resolution levels. With this method it is possible to detect frontal and unrotated faces with different scales. While first attempts of face recognition deal with the problem by recognising and describing real human features like eyes, nose, skin etc., several more recent approaches have applied correlations with feature templates. A comparison of different template based methods is presented in [2]. In [8] a method for the segmentation of the human face based on an edge map approach is presented. It relies upon faces that are centred and that have the same scale. The approach in [9] applies either a motion-based algorithm for face detection or a method based on eigenvectors. We focus on methods that use translation models and affine transformations. Such methods can be used if only one face is present in the image, and if the background is uniform. Robust estimators also allow for the use of images with non-uniform background. We consider normalisation of faces as a procedure that comprises the follow-	algorithm;connectionism;database;eigenface;face detection;facial recognition system;graph labeling;matching (graph theory);preprocessor;shape context	Stefan Fischer;Benoît Duc	1997		10.1007/BFb0015975	computer vision;pattern recognition;data mining	Vision	42.37692200848635	-56.49179105729505	62513
95c81eebbda4d25e6fb9d142be9da20ab0f10aa8	affine-invariant geometric constraints-based high accuracy simultaneous localization and mapping		In this study we describe a new appearance-based loop-closure detection method for online incremental simultaneous localization and mapping (SLAM) using affine-invariant-based geometric constraints. Unlike other pure bag-of-words-based approaches, our proposed method uses geometric constraints as a supplement to improve accuracy. By establishing an affine-invariant hypothesis, the proposed method excludes incorrect visual words and calculates the dispersion of correctly matched visual words to improve the accuracy of the likelihood calculation. In addition, camera’s intrinsic parameters and distortion coefficients are adequate for this method. 3D measuring is not necessary. We use the mechanism of Long-Term Memory and Working Memory (WM) to manage the memory. Only a limited size of the WM is used for loop-closure detection; therefore the proposed method is suitable for large-scale real-time SLAM. We tested our method using the CityCenter and Lip6Indoor datasets. Our proposed method results can effectively correct the typical false-positive localization of previous methods, thus gaining better recall ratios and better precision.	simultaneous localization and mapping	Gangchen Hua;Xu Tan	2017	J. Sensors	10.1155/2017/1969351	computer vision;machine learning;mathematics;statistics	Robotics	41.15965078940238	-55.859754552415666	62600
19a4967105b9b8816de916468c4a1753c7322041	volume measure in 2dpca-based face recognition	reconnaissance visage;traitement signal;evaluation performance;metodo estadistico;analisis componente principal;base donnee;high dimensionality;performance evaluation;image processing;distance measure;biometrie;evaluacion prestacion;biometrics;database;biometria;dimensional analysis;procesamiento imagen;base dato;statistical method;euclidean distance;traitement image;feature vector;distance measurement;automatic recognition;face recognition;modelo 2 dimensiones;methode statistique;medicion distancia;feature extraction;signal processing;principal component analysis;two dimensional pca 2dpca;analyse dimensionnelle;modele 2 dimensions;analyse composante principale;pattern recognition;analisis dimensional;volume measurement;volume measure;reconnaissance forme;extraction caracteristique;reconocimiento patron;procesamiento senal;two dimensional model;reconocimiento automatico;mesure de distance;reconnaissance automatique	Two-dimensional principal component analysis (2DPCA) is based on the 2D images rather than 1D vectorized images like PCA, which is a classical feature extraction technique in face recognition. Many 2DPCA-based face recognition approaches pay a lot of attention to the feature extraction, but fail to pay necessary attention to the classification measures. The typical classification measure used in 2DPCA-based face recognition is the sum of the Euclidean distance between two feature vectors in a feature matrix, called distance measure (DM). However, this measure is not compatible with the high-dimensional geometry theory. So a new classification measure compatible with high-dimensional geometry theory and based on matrix volume is developed for 2DPCA-based face recognition. To assess the performance of 2DPCA with the volume measure (VM), experiments were performed on two famous face databases, i.e. Yale and FERET, and the experimental results indicate that the proposed 2DPCA + VM can outperform the typical 2DPCA + DM and PCA in face recognition. 2007 Elsevier B.V. All rights reserved.	database;euclidean distance;experiment;feret (facial recognition technology);facial recognition system;feature extraction;principal component analysis	Jicheng Meng;Wenbin Zhang	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.01.015	computer vision;speech recognition;feature vector;feature;image processing;feature extraction;computer science;artificial intelligence;machine learning;dimensional analysis;signal processing;euclidean distance;three-dimensional face recognition;mathematics;biometrics;principal component analysis	Vision	44.384651070899864	-60.075101303479855	62630
4fcc4d59da3432c0f6f31eb087bac5d9aac91210	robust moving object segmentation on h.264/avc compressed video using the block-based mrf model	analisis imagen;moving object;traitement signal;teledetection;campo desplazamiento;evaluation performance;video surveillance;deteccion blanco;estimation mouvement;image coding;displacement field;image segmentation;transcodage;champ vectoriel;performance evaluation;image processing;data compression;transcodificacion;modelo markov;televigilancia;video signal processing;format video;evaluacion prestacion;estimacion movimiento;video analysis;compresion senal;procesamiento imagen;technique video;motion estimation;probabilistic approach;blanco movil;tecnica video;motion vector field;traitement image;compression signal;markov random field;detection cible;algorithme;video indexing;algorithm;codage image;campo vectorial;detection objet;video coding;video transcoding;remote supervision;compression image;markov model;campo aleatorio;image compression;codage video;indexing;telesurveillance;enfoque probabilista;approche probabiliste;signal processing;remote sensing;indexation;signal compression;object tracking;segmentation image;object extraction;teledeteccion;poursuite cible;moving object detection;indizacion;champ deplacement;traitement signal video;cible mobile;video technique;image analysis;extraccion objeto;compresion dato;modele markov;target tracking;vector field;procesamiento senal;target detection;analyse image;transcoding;real time application;video format;moving target;extraction objet;compression donnee;object detection;compressed video;champ aleatoire;algoritmo;compresion imagen;random field	Moving object segmentation in compressed domain plays an important role in many real-time applications, e.g. video indexing, video transcoding, video surveillance, etc. Because H.264/AVC is the up-to-date video-coding standard, few literatures have been reported in the area of video analysis on H.264/AVC compressed video. Compared with the former MPEG standard, H.264/AVC employs several new coding tools and provides a different video format. As a consequence, moving object segmentation on H.264/ AVC compressed video is a new task and challenging work. In this paper, a robust approach to extract moving objects on H.264/ AVC compressed video is proposed. Our algorithm employs a block-based Markov Random Field (MRF) model to segment moving objects from the sparse motion vector field obtained directly from the bitstream. In the proposed method, object tracking is integrated in the uniform MRF model and exploits the object temporal consistency simultaneously. Experiments show that our approach provides the remarkable performance and can extract moving objects efficiently and robustly. The prominent applications of the proposed algorithm are object-based transcoding, fast moving object detection, video analysis on compressed video, etc. r 2005 Elsevier Ltd. All rights reserved.	academy;algorithm;bitstream;closed-circuit television;codec;data compression;experiment;fast fourier transform;global motion compensation;h.264/mpeg-4 avc;mpeg-1;mpeg-2;markov chain;markov random field;moving picture experts group;object detection;object-based language;real-time locating system;sparse matrix;video coding format;video content analysis;video processing	Wei Zeng;Jun Du;Wen Gao;Qingming Huang	2005	Real-Time Imaging	10.1016/j.rti.2005.04.008	video compression picture types;scalable video coding;computer vision;image analysis;simulation;transcoding;image processing;computer science;signal processing;video tracking;block-matching algorithm;motion compensation;video denoising;multiview video coding;computer graphics (images)	Vision	47.78734773002631	-56.79609333582947	62658
a47eaa8f0a773c36f2c3c993d9126adbecfaf518	image segmentation in compressed domain	image segmentation;feature extraction;cosine transform	n 2 amEG the the 200 Abstract. We propose a direct image segmentation algorithm in the JPEG compressed domain. The algorithm features extracting statistical parameters from direct cosine transform (DCT) coefficients without its inverse transform, and growing regions in line with JPEG compression seamlessly in blocks of 838 pixels. In comparison with the latest research efforts in region-based image segmentation, our proposed algorithm achieves significant advantages, including (1) no iteration is involved, (2) no full decompression is required, and (3) segmentation performance is competitive. © 2003 SPIE and IS&T. [DOI: 10.1117/1.1579699]	algorithm;coefficient;data compression;discrete cosine transform;fast fourier transform;image segmentation;iteration;jpeg;pixel	Guo-Can Feng;Jianmin Jiang	2003	J. Electronic Imaging	10.1117/1.1579699	computer vision;range segmentation;feature extraction;computer science;segmentation-based object categorization;discrete cosine transform;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;computer graphics (images)	Vision	52.885119651385665	-65.346574675192	62742
f88dd812773a13ba07419870b4aac954226036c6	robust image matching based on wavelet transform and sift	discrete wavelet transforms;corner detection;discrete wavelet transform;cross correlation;low frequency;image matching;interest points;k d tree;wavelet transforms;wavelet transform;algorithms;template matching	Template matching is the process of determining the presence and the location of a reference image or an object inside a scene image under analysis by a spatial cross-correlation process. Conventional cross-correlation type algorithms are computationally expensive. In this paper, an algorithm for a robust template matching method based on the combination of the wavelet transform method and SIFT is proposed. Discrete wavelet transform is done firstly on a reference image and a template image, and low frequency parts of them is extracted, then we use harris corner detection to detect the interesting point in low frequency parts of them to determined the matching candidate region of template image in reference image, extracting SIFT features on the matching candidate region and template image, The extracted SIFT features are matched by k-d tree and bidirectional matching strategy. Experiment show that, the algorithm can improve the accuracy of matching and at the same time to reduce the computation load.	algorithm;analysis of algorithms;bidirectional search;computation;corner detection;cross-correlation;discrete wavelet transform;harris affine region detector;image registration;scale-invariant feature transform;template matching	Jianfang Dou;Jianxun Li	2011		10.1117/12.896080	wavelet;computer vision;template matching;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;machine learning;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Vision	40.01006377202002	-58.568804761888536	62907
66205b1a634a428113749347bd5cfdb7ad34a24a	tsallis entropy-based information measures for shot boundary detection and keyframe selection	keyframe selection;image processing;imatge processament;video processing;journal;info eu repo semantics article;entropia teoria de la informacio;informacio teoria de la;entropy information theory;tsallis entropy;information theory;shot boundary detection	Automatic shot boundary detection and keyframe selection constitute major goals in video processing. We propose two different information-theoretic approaches to detect the abrupt shot boundaries of a video sequence. These approaches are, respectively, based on two information measures, Tsallis mutual information and Jensen–Tsallis divergence, that are used to quantify the similarity between two frames. Both measures are also used to find out the most representative keyframe of each shot. The representativeness of a frame is basically given by its average similarity with respect to the other frames of the shot. Several experiments analyze the behavior of the proposed measures for different color spaces (RGB, HSV, and Lab), regular binnings, and entropic indices. In particular, the Tsallis mutual information for the HSV and Lab color spaces with only 8 regular bins for each color component and an entropic index between 1.5 and 1.8 substantially improve the performance of previously proposed methods based on mutual information and Jensen–Shannon divergence. M. Vila · A. Bardera (B) · M. Feixas · M. Sbert Institut d’Informàtica i Aplicacions, University of Girona, Girona, Spain e-mail: abardera@ima.udg.edu M. Vila e-mail: marius.vila@ima.udg.edu M. Feixas e-mail: feixas@ima.udg.edu M. Sbert e-mail: mateu@ima.udg.edu Q. Xu School of Computer Science and Technology, Tianjin University, Tianjin, China e-mail: qingxu@tju.edu.cn	color space;computer science;email;experiment;information theory;jensen's inequality;key frame;mutual information;shannon (unit);shot transition detection;similarity measure;spatial variability;tsallis entropy;video processing	Màrius Vila;Anton Bardera;Qing Xu;Miquel Feixas;Mateu Sbert	2013	Signal, Image and Video Processing	10.1007/s11760-013-0452-3	computer vision;image processing;information theory;artificial intelligence;pattern recognition;mathematics;video processing;tsallis entropy;statistics;entropy	Vision	43.439533967394894	-63.3072396311083	63344
500fc12e8790e40fc43f3f4341b077888e175a34	characterization of surfaces with sonars using time of flight and triangulation	occupation time;time of flight;image processing;speech processing;tratamiento palabra;procesamiento imagen;traitement parole;traitement image;temps occupation;triangulacion;metrologia superficie;methode temps vol;metrologie surface;tiempo ocupacion;pattern recognition;triangulation;reconnaissance forme;reconocimiento patron;surface metrology;metodo tiempo vuelo;time of flight method;sonar	This paper presents a simple and original method that uses a configuration of only two sonars to measure and characterize surfaces. The method uses simultaneously the Time Of Flight (TOP) technique and basic triangulation, and characterizes the obtained sonar data into corners, edges and planes, along with non-classified points. The characterization is based on a simple trigonometric evaluation. A commutation system with two sonars that use a configuration with a transmitter and two receivers was built to verify the proposed methodology. Experiments and satisfactory results are also presented.		Carlos Albores-Borja;José Luis Gordillo	2003		10.1007/978-3-540-24586-5_25	computer vision;time of flight;image processing;triangulation;computer science;pattern recognition;speech processing;sonar	Robotics	49.63326604891416	-58.79575843765233	63347
02178cb387f224f5d6d69328acddfb1bf2ef5a65	generation, verification and localization of object hypotheses based on colour		This paper presents a model-based method for colour-based recognition of objects from a large database. The algorithm is based on the assumption that surface reflectances of objects in the model database follow the extended dichromatic model proposed by Shafer [Sha84]. Adoption of the dichromatic model allows recovery of body colour the component, of sensor responses (RGB-values) that is independent of scene geometry and illumination intensity. Both theoretical studies [Hea89b] and experiments [LB90][KSK88] confirm that Shafer's model gives a suitable approximation for reflectances of a wide range of materials. Instead of using traditional techniques (eg. clustering, split-and-merge) to obtain regions of 'similarly' coloured pixels followed by classification a novel approach is argued for. First, for each pixel a list of models with nonzero aposteriori probabilities P(modeU\body colotir) is computed using Bayes formula. Next, regions are formed by grouping pixels with identical most probable hypothesis. Probabilities P(modeli\region) are obtained trough a standard group decision rule [FT80]. We show that the proposed scheme can be used for a number of visual tasks localization of objects, generation and verification of object hypotheses. Experiments on images of complex indoor scenes confirm that the proposed method can provide reliable information about the surrounding environment.	algorithm;approximation;cluster analysis;experiment;pixel	Jiri Matas;Radek Marik;Josef Kittler	1993		10.5244/C.7.54	computer vision;artificial intelligence;machine learning;mathematics;statistics	Vision	44.209051195776084	-52.38724218063346	63377
0a1e3d271fefd506b3a601bd1c812a9842385829	face recognition using 3d directional corner points	institute for integrated and intelligent systems;conference output;faculty of science environment engineering and technology;computer vision;3d object recognition novel face recognition approach 3d directional corner points 3d dcp matching method similarity metric spatial information structural information general 3d object representation;image representation face recognition image matching;3d face recognition 3d directional corner points 3d directional corner point matching;three dimensional displays face face recognition vectors databases probes cost function;080104	In this paper, we present a novel face recognition approach using 3D directional corner points (3D DCPs). Traditionally, points and meshes are applied to represent and match 3D shapes. Here we represent 3D surfaces by 3D DCPs derived from ridge and valley curves. Then we develop a 3D DCP matching method to compute the similarity of two different 3D surfaces. This representation, along with the similarity metric can effectively integrate structural and spatial information on 3D surfaces. The added information can provide more and better discriminative power for object recognition. It strengthens and improves the matching process of similar 3D objects such as faces. To evaluate the performance of our method for 3D face recognition, we have performed experiments on Face Recognition Grand Challenge v2.0 database (FRGC v2.0) and resulted in a rank-one recognition rate of 97.1%. This study demonstrates that 3D DCPs provides a new solution for 3D face recognition, which may also find its application in general 3D object representation and recognition.	experiment;face recognition grand challenge;facial recognition system;outline of object recognition;three-dimensional face recognition	Xun Yu;Yongsheng Gao;Jun Zhou	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.483	computer vision;computer science;machine learning;pattern recognition;3d single-object recognition	Vision	39.76046875356619	-57.59710730850488	63537
cd947fe19445a459ba991b6d3a2dc58da6efb832	an efficient iterative pose estimation algorithm	metodo cuadrado menor;methode moindre carre;linear estimation;vision ordenador;estimation mouvement;algorithm performance;decomposition;image processing;least squares method;etude experimentale;real time;relacion hombre maquina;estimacion movimiento;singular value decomposition;head tracking;procesamiento imagen;man machine relation;motion estimation;traitement image;three dimensional;computer vision;algorithme;algorithm;resultado algoritmo;real time vision;temps reel;image sequence;performance algorithme;tiempo real;nonlinear estimation;vision ordinateur;secuencia imagen;relation homme machine;descomposicion;estudio experimental;sequence image;human computer interface;algoritmo;pose estimation	A novel model-based pose estimation algorithm is presented which estimates the motion of a three-dimensional object from a image sequence. The nonlinear estimation process within iteration is divided into two linear estimation stages, namely the depth approximation and the pose calculation. In the depth approximation stage, the depths of the feature points in three-dimensional space are estimated. In the pose calculation stage, the rotation and translation parameters between the estimated feature points and the model point set arer calculated by a fast singular value decomposition method. The whole process is executed recursively until the result is stable. Since both stages can be solved efficiently, the computational cost is low. As a result, the algorithm is well-suited for real computer vision applications. We demonstrate the capability of this algorithm by applying it to a real time head tracking problem. The results are satisfactory.	3d pose estimation;algorithm;iterative method	Siu-Hang Or;W. S. Luk;Kin Hong Wong;Irwin King	1998	Image Vision Comput.	10.1016/S0262-8856(97)00073-5	three-dimensional space;computer vision;pose;3d pose estimation;image processing;computer science;artificial intelligence;motion estimation;mathematics;decomposition;singular value decomposition;least squares;algorithm	Vision	49.76123966165425	-56.652940951607874	63840
360e950792176bcf44a8cda6fe2d2098ded3494f	robust acquisition of 3d informations from short image sequences	background noise;3d image reconstruction;dynamic programming;partial differential equation;mathematical morphology;layer by layer;robustness image sequences image reconstruction cameras image segmentation layout background noise surface texture morphological operations geometry;image segmentation;occlusion;differential geometry;geometry;mathematical mor phology;morphological operation;motion estimation;dynamic program;layout;surface texture;differential geometry image reconstruction stereo image processing dynamic programming motion estimation image sequences mathematical morphology partial differential equations;morphological operations;partial differential equations;partial differential equation filter;image reconstruction;image sequence;stereo image processing;multiple pass process;robustness;voxel space;structure from motion;occlusion structure from motion 3d image reconstruction multiple pass process differential geometry voxel space image sequences dynamic programming mathematical morphology partial differential equation;3d reconstruction;cameras;image sequences	This paper addresses the problem of 3D reconstruction from a set of viewpoints on a short baseline. Its main contribution is the development of a robust algorithm which can extract 3D informations from a set of images taken with a very small baseline, even in the presence of significant occlusion. To achieve this goal, we use a multi-pass process that works layer by layer. In each pass we begin with a “space carving” step which is made robust through some morphological operations. Then we introduce an original technique to solve the ambiguity inherent to “space carving” in the case of short baseline. Once we have a voxel representation of the objects, we propose a method based on differential geometry to build a smooth mesh. Results are presented, demonstrating the efficiency and usefulness of the method.	3d reconstruction;algorithm;baseline (configuration management);mathematical morphology;t-spline;voxel	Sylvain Paris;François X. Sillion	2003	Graphical Models	10.1016/S1524-0703(03)00041-9	differential geometry;computer vision;mathematical optimization;computer science;mathematics;geometry;partial differential equation	Vision	53.24146479540959	-53.07508074752579	63874
217c1db91eaf37a7417cfa9b8cfd097e9dcb81a8	multiresolution analysis for meshes with appearance attributes	adaptive denoising multiresolution analysis framework irregular meshes lifting scheme surface prediction operator attribute analysis geometrical analysis adaptive visualization;multiresolution analysis signal resolution signal processing algorithms wavelet analysis smoothing methods solid modeling information analysis noise reduction frequency wavelet transforms;image resolution;geometry;lifting scheme;image denoising;multiresolution analysis;image denoising image resolution geometry	We present a new multiresolution analysis framework for irregular meshes with attributes based on the lifting scheme. We introduce a surface prediction operator to compute the detail coefficients for the geometry and the attributes of the model. Attribute analysis gives appearance information to complete the geometrical analysis of the model. A set of experimental results are given to show the efficiency of our framework. We present two applications to adaptive visualization and denoising.	coefficient;lifting scheme;multiresolution analysis;noise reduction	Michaël Roy;Sebti Foufou;Andreas F. Koschan;Frédéric Truchetet;Mongi A. Abidi	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1530517	multiresolution analysis;computer vision;mathematical optimization;image resolution;computer science;pattern recognition;mathematics;lifting scheme	Visualization	52.71374849633832	-65.91638142885049	63921
bebb7f8c4035a954d5eed869d8648d7b18b4f7d4	on recognition of three-dimensional objects using curvature information	image recognition;object recognition;two dimensional image three dimensional object recognition curvature information line laser projectors web camera depth collection fourier components self organizing map object classification multidimensional data toy block recognition;neural networks;training;mathematical model;self organising feature maps cameras fourier analysis image classification object recognition optical projectors;self organizing map object recognition;cameras image recognition training object recognition neural networks mathematical model labeling;cameras;labeling	A recognition system for three-dimensional objects is proposed in this paper. This system consists of line laser projectors and a web camera in order to collect depth and curvature information of objects, leading to a compact and cost-effective system compared to light coding-based systems such as Microsoft Kinect. Curvature information of objects can be obtained through calculation of Fourier components from deformed lines of laser beam that are projected onto the curves of objects. Self-Organizing Map is used for classification of objects for dealing with multidimensional data of Fourier components. Performances of the proposed system are explored through the recognition of toy blocks with the same size in two-dimensional image and with various curves.	kinect;movie projector;organizing (structure);performance;self-organizing map;webcam	Keisuke Kubo;Teijiro Isokawa;Nobuyuki Matsui	2015	2015 7th International Conference on Emerging Trends in Engineering & Technology (ICETET)	10.1109/ICETET.2015.29	computer vision;machine learning;mathematics;3d single-object recognition;computer graphics (images)	Robotics	43.01355109767253	-56.68842050336156	64090
43a6675c6062526e4ac9fe4f2ec979ade5252c7c	instance-based object recognition in 3d point clouds using discriminative shape primitives	3d local shape;discriminative shape representation;instance-based object recognition;3d pose estimation;3d point cloud	3D local shapes are a critical cue for object recognition in 3D point clouds. This paper presents an instance-based 3D object recognition method via informative and discriminative shape primitives. We propose a shape primitive model that measures geometrical informativity and discriminativity of 3D local shapes of an object. Discriminative shape primitives of the object are extracted automatically by model parameter optimization. We achieve object recognition from 2.5/3D scenes via shape primitive classification and recover the 3D poses of the identified objects simultaneously. The effectiveness and the robustness of the proposed method were verified on popular instance-based 3D object recognition datasets. The experimental results show that the proposed method outperforms some existing instance-based 3D object recognition pipelines in the presence of noise, varying resolutions, clutter and occlusion.	3d modeling;3d single-object recognition;algorithm;clutter;computer vision;high- and low-level;ibm notes;information;mathematical optimization;outline of object recognition;pipeline (computing);point cloud;robotics;scalability;time complexity	Jie Zhang;Junhua Sun	2017	Machine Vision and Applications	10.1007/s00138-017-0885-8	pattern recognition;discriminative model;computer vision;computer science;robustness (computer science);point cloud;artificial intelligence;3d pose estimation;clutter;cognitive neuroscience of visual object recognition	Vision	45.234822447790194	-52.12670362344529	64127
1d8c30d9a304f733d9b8b6817cf1c07baebbe509	spatio-temporal analysis of kinematic signals in classical ballet	complexity of movements;automatic classification of movements;92 06;83 10 bb;87 85 ng;92b10;92b25;complexity of shape changes;87 85 gj	Motions of markers arranged on a dancer’s body can be approximated by the sum of a minimal set of linear trajectories with given accuracy. The composition of approximating linear trajectories features the movement traits and discloses the level of movement expertise in the dancers. We suggest the computationally simple methods for the analysis of trajectories and body shape changes attested directly from the motion capture data. We have tested our approach for 6 figures from the classical ballet repertoire performed by 24 dancers varying in expertise. The methods allow to estimate the level of movement expertise, to draw the detailed structure of movements, and to classify movements into a given repertoire automatically. © 2012 Elsevier B.V. All rights reserved.	approximation algorithm;motion capture	Dimitri Volchenkov;Bettina Bläsing	2013	J. Comput. Science	10.1016/j.jocs.2012.06.008	simulation;computer science;artificial intelligence	ML	47.644854006547	-54.66512073271414	64340
68a2fe6afef97c4e41d2f7bfac4ca09dcc522c65	globally optimal grouping for symmetric closed boundaries by combining boundary and region information	closed boundaries detection;graph theory;sensitivity and specificity;polynomials computer vision edge detection graph theory image segmentation;vision ordenador;teoria grafo;human vision;grupo simetria;image segmentation;algorithms artificial intelligence image enhancement image interpretation computer assisted imaging three dimensional pattern recognition automated reproducibility of results sensitivity and specificity;grouping;temps polynomial;imaging three dimensional;cost function;edge detection;analisis forma;cost function image edge detection computer vision image segmentation humans polynomials testing animal structures image analysis pixel;remplissage;error sistematico;testing;intelligence artificielle;filling;theorie graphe;edge grouping;polynomials;computer vision;deteccion contorno;graph models;detection contour;image enhancement;graph models perceptual organization edge grouping boundary detection boundary symmetry edge detection;proximite;polynomial time human vision computer vision closed boundaries detection grouping cost function graph model;proximidad;image interpretation computer assisted;image edge detection;bias;symmetry group;pixel;proximity;reproducibility of results;polynomial time;groupe symetrie;segment droite;graph algorithm;artificial intelligence;algorithms;segmento recta;boundary symmetry;image analysis;global optimization;vision ordinateur;pattern recognition automated;line segment;pattern analysis;humans;inteligencia artificial;agrupamiento;graph model;synthetic data;animal structures;boundary detection;grouping cost function;analyse forme;perceptual organization;groupage;erreur systematique;relleno;tiempo polinomial	Many natural and man-made structures have a boundary that shows a certain level of bilateral symmetry, a property that plays an important role in both human and computer vision. In this paper, we present a new grouping method for detecting closed boundaries with symmetry. We first construct a new type of grouping token in the form of symmetric trapezoids by pairing line segments detected from the image. A closed boundary can then be achieved by connecting some trapezoids with a sequence of gap-filling quadrilaterals. For such a closed boundary, we define a unified grouping cost function in a ratio form: the numerator reflects the boundary information of proximity and symmetry, and the denominator reflects the region information of the enclosed area. The introduction of the region-area information in the denominator is able to avoid a bias toward shorter boundaries. We then develop a new graph model to represent the grouping tokens. In this new graph model, the grouping cost function can be encoded by carefully designed edge weights, and the desired optimal boundary corresponds to a special cycle with a minimum ratio-form cost. We finally show that such a cycle can be found in polynomial time using a previous graph algorithm. We implement this symmetry-grouping method and test it on a set of synthetic data and real images. The performance is compared to two previous grouping methods that do not consider symmetry in their grouping cost functions.	algorithm;bilateral filter;computer vision;denominator;experiment;graph - visual representation;list of algorithms;loss function;new type;polynomial;sensor;synthetic data;time complexity;weight;xslt/muenchian grouping	Joachim S. Stahl;Song Wang	2008	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2007.1186	time complexity;computer vision;image analysis;symmetry group;edge detection;line segment;computer science;artificial intelligence;graph theory;machine learning;bias;mathematics;geometry;software testing;image segmentation;distance;pixel;polynomial;global optimization;synthetic data	Vision	50.64039548734743	-60.454062474818116	64520
fe66464c7793cd1dcb3833818571627440feadf7	an automatic image registration scheme based on the nonsubsampled contourlet transform	image sampling;image processing automatic image registration scheme nonsubsampled contourlet transform feature point extraction method nsct transform geometric transformation;geometric transformation;image processing;image resolution;geometry;image registration feature extraction pixel parameter estimation spatial resolution image resolution image representation noise robustness algorithm design and analysis image processing;nsct transform;feature extraction;image registration;pixel;nonsubsampled contourlet transform;transforms;transforms geometry image registration image sampling;feature point extraction method;automatic image registration scheme;extraction method;noise	In this paper, a new feature points extraction method based on the nonsubsampled contourlet transform (NSCT) is proposed for image registration. The primary motivation of this work is to determine the effectiveness of the NSCT transform for feature points extraction for the use of image registration. The performance of the proposed NSCT-based registration algorithm is demonstrated and validated in a series of carefully designed synthetic experiments. The preliminary experimental results show the robustness and efficiency of the algorithm in the presence of noise and common image processing operations as well as rigid geometric transformations, and confirm the success of the proposed NSCT-based feature points extraction approach.	algorithm;contourlet;estimation theory;experiment;feature model;image processing;image registration;randomness extractor;similarity measure;synthetic intelligence	Chahira Serief;Mourad Barkat;Youcef Bentoutou	2007	2007 9th International Symposium on Signal Processing and Its Applications	10.1109/ISSPA.2007.4555446	computer vision;image resolution;geometric transformation;image processing;feature extraction;computer science;noise;image registration;pattern recognition;pixel;computer graphics (images)	Vision	42.711787071564494	-58.04615250542942	64524
117d9adb4172b59f0dce40e3fe906864f3c71436	pseudo two-dimensional shape normalization methods for handwritten chinese character recognition	line density projection interpolation;pseudo 2d nonlinear normalization;moment method;pseudo 2d bi moment normalization;handwritten chinese character recognition;pseudo 2d moment normalization;pseudo 2d centroid boundary alignment;real time computing	The nonlinear normalization (NLN) method based on line density equalization is popularly used in handwritten Chinese character recognition. To overcome the insufficient shape restoration capability of one-dimensional NLN, a pseudo two-dimensional NLN (P2DNLN) method has been proposed and has yielded higher recognition accuracy. The P2DNLN method, however, is very computationally expensive because of the line density blurring of each row/column. In this paper, we propose a new pseudo 2D normalization method using line density projection interpolation (LDPI), which partitions the line density map into soft strips and generate 2D coordinate mapping function by interpolating the 1D coordinate functions that are obtained by equalizing the line density projections of these strips. The LDPI method adds little computational overhead to one-dimensional NLN yet performs comparably well with P2DNLN. We also apply this strategy to extending other normalization methods, including line density projection fitting, centroid-boundary alignment, moment, and bi-moment methods. The latter three methods are directly based on character image instead of line density map. Their 2D extensions provide real-time computation and high recognition accuracy, and are potentially applicable to gray-scale images and online trajectories.	optical character recognition	Cheng-Lin Liu;Katsumi Marukawa	2005	Pattern Recognition	10.1016/j.patcog.2005.04.019	arithmetic;computer vision;speech recognition;computer science;mathematics	Vision	52.76487470166471	-62.06106704326668	64803
c5aab547a3acab2bd8fa47c283be1549f56014bc	multimodal facial gender and ethnicity identification	ethnic difference;reconnaissance visage;base donnee;analisis estadistico;facies;biometrie;depth of field;biometrics;database;biometria;base dato;profondeur champ;registro imagen;face recognition;statistical analysis;recalage image;image registration;machine exemple support;analyse statistique;profundidad campo;support vector machine;maquina ejemplo soporte;vector support machine	Human faces provide demographic information, such as gender and ethnicity. Different modalities of human faces, e.g., range and intensity, provide different cues for gender and ethnicity identifications. In this paper we exploit the range information of human faces for ethnicity identification using a support vector machine. An integration scheme is also proposed for ethnicity and gender identifications by combining the registered range and intensity images. The experiments are conducted on a database containing 1240 facial scans of 376 subjects. It is demonstrated that the range modality provides competitive discriminative power on ethnicity and gender identifications to the intensity modality. For both gender and ethnicity identifications, the proposed integration scheme outperforms each individual modality.	ct scan;database;experiment;facial recognition system;information;modality (human–computer interaction);multimodal interaction;support vector machine	Xiaoguang Lu;Hong Chen;Anil K. Jain	2006		10.1007/11608288_74	facial recognition system;support vector machine;computer vision;facies;computer science;image registration;archaeology;machine learning;depth of field;database;biometrics	AI	44.704623929944916	-58.597841020057686	64889
3f0549b74ede40707e36fbd67f4a32a38569ad9c	face localization and tracking in the neural abstraction pyramid	reconnaissance visage;ojo;videocommunication;iterative refinement;local recurrence;calcul neuronal;videocomunicacion;neural computation;base donnee;eye;red local;aplicacion;real time;database;hierarchical networks;base dato;abstraction;hierarchical network;abstraccion;gray scale;face tracking;recurrence;local network;graph connectivity;face recognition;neural net work;temps reel;image sequence;conectividad grafo;continuous attractors;modele hierarchique;tiempo real;local connectivity;secuencia imagen;reseau neuronal;face localization and tracking;application;reseau local;echelle gris;connectivite graphe;oeil;red neuronal;computacion neuronal;hierarchical model;escala gris;sequence image;human computer interface;neural network	One of the major tasks in some human–computer interface applications, such as face recognition and video telephony, is to localize a human face in an image. In this paper, we propose to use hierarchical neural networks with local recurrent connectivity to solve this task not only in unambiguous situations, but also in the presence of complex backgrounds, difficult lighting, and noise. The networks are trained using a database of gray-scale still images and manually determined eye coordinates. They are able to produce reliable and accurate eye coordinates for unknown images by iteratively refining initial solutions. Because the networks process entire images, there is no need for any time-consuming scanning across positions and scales. Furthermore, the fast network updates allow for real-time face tracking. In this case, the networks are trained using still images that move in random directions. The trained networks are able to accurately track the eye positions in the test image sequences.	artificial neural network;convolutional neural network;face detection;facial motion capture;facial recognition system;grayscale;human–computer interaction;real-time web;standard test image;videotelephony	Sven Behnke	2004	Neural Computing & Applications	10.1007/s00521-004-0444-x	local area network;facial recognition system;computer vision;facial motion capture;computer science;artificial intelligence;connectivity;machine learning;abstraction;artificial neural network;grayscale;hierarchical database model;models of neural computation	Vision	44.96910624199346	-58.0414100035567	65025
834a113155d29975854d1df2581e49d8b7733742	self-recalibration of a structured light system via plane-based homography	busqueda informacion;second order;vision system;simulation ordinateur;contraste;relative position;self recalibration;metodo analitico;optimisation;vision ordenador;image processing;modelo 3 dimensiones;optimizacion;systeme vision;recherche image;information retrieval;relative pose;image matching;implementation;modele 3 dimensions;cheirality constraint;procesamiento imagen;orden 2;three dimensional model;structured light;second order equation;multipoint method;eigenvalue decomposition;traitement image;three dimensional;computer vision;projective plane;eigenvalue;plane based homography;methode multipoint;metodo multipunto;recherche information;analytical method;robustesse;valor propio;methode analytique;robustness;vision ordinateur;etalonnage;valeur propre;optimization;simulacion computadora;ordre 2;implementacion;structured light system;analytic solution;computer simulation;calibration;sistema vision;appariement image;constrained system;robustez;image retrieval	Self-recalibration of the relative pose in a vision system plays a very important role in many applications and much research has been conducted on this issue over the years. However, most existing methods require information of some points in general three-dimensional positions for the calibration, which is hard to be met in many practical applications. In this paper, we present a new method for the selfrecalibration of a structured light system by a single image in the presence of a planar surface in the scene. Assuming that the intrinsic parameters of the camera and the projector are known from initial calibration, we show that their relative position and orientation can be determined automatically from four projection correspondences between an image and a projection plane. In this method, analytical solutions are obtained from second order equations with a single variable and the optimization process is very fast. Another advantage is the enhanced robustness in implementation via the use of over constrained systems. Computer simulations and real data experiments are carried out to validate our method. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	autostereogram;camera resectioning;computation;computer simulation;experiment;homography (computer vision);mathematical optimization;mobile robot;online and offline;pattern recognition;plasma cleaning;projection plane;robotic mapping;stereopsis;structured light;video projector	Beitong Zhang;Youfu Li;Yihong Wu	2007	Pattern Recognition	10.1016/j.patcog.2006.04.001	projective plane;computer simulation;homography;three-dimensional space;computer vision;closed-form expression;eigendecomposition of a matrix;calibration;simulation;structured light;image processing;eigenvalues and eigenvectors;image retrieval;computer science;implementation;second-order logic;robustness	Vision	49.765694090921315	-57.99425333959529	65815
2079046e7936b727fe4e6b3bcdb7fbe3ebdf644b	local single-patch features for pose estimation using the log-polar transform	analisis imagen;image features;clutter;image processing;occlusion;occultation;procesamiento imagen;oclusion;traitement image;posture;engineering and technology;fouillis echo;teknik och teknologier;confusion eco;postura;pattern recognition;invariante;image analysis;reconnaissance forme;reconocimiento patron;ocultacion;analyse image;invariant;pose estimation	This paper presents a local image feature, based on the logpolar transform which renders it invariant to orientation and scale variations. It is shown that this feature can be used for pose estimation of 3D objects with unknown pose, with cluttered background and with occlusion. The proposed method is compared to a previously published one and the new feature is found to be about as good or better as the old one for this task.	3d pose estimation;cluster analysis;feature (computer vision);hidden surface determination;rendering (computer graphics)	Fredrik Vikstén;Anders Moe	2005		10.1007/11492429_6	computer vision;image analysis;speech recognition;pose;3d pose estimation;occultation;image processing;computer science;invariant;articulated body pose estimation;clutter;feature;computer graphics (images)	Vision	46.47210955072465	-58.67671390037583	65828
0f60fca5deb8db808762072b87a1d9bb3b466c2f	performance evaluation criterion for characterizing video-surveillance systems	moving object;traitement signal;eficacia sistema;evaluation performance;object recognition;video surveillance;performance evaluation;criterio resultado;receiver operator characteristic;surveillance;surveillance system;evaluacion prestacion;evaluation method;performance systeme;performance requirement;critere performance;reconnaissance objet;work environment;blanco movil;working conditions;system performance;detection objet;vigilancia;senal video;signal video;signal processing;poursuite cible;roc curve;video signal;cible mobile;target tracking;procesamiento senal;moving target;object detection	I n the last decade, video surveillance systems have been developed to guard remote environments in order to detect and prevent dangerous situations. In general, such systems are very complex and their performances rely strongly on the values taken on by the parameters regulating the behavior of surveillance algorithms. This makes it difficult to compare performances to select the most suitable system for the problem considered. Moreover, parameters are set during the installation phase, but a good selection requires time and experience. In this paper, we present an evaluation method for characterizing video-surveillance systems in order to provide an easy way of system installation. The proposed procedure is based on the definition of Receiver Operating Characteristic (ROC) curves traced for different parameter sets and for different system working conditions. Examples are given that concern an indoor video-based surveillance system for detecting, recognizing and tracking moving objects; the system has been characterized and evaluated for different scenarios. Results prove the validation of the proposed evaluation procedure though a comparison of the performances obtained in a laboratory with the ones achieved in real working environments, after system installation following the guidelines provided by the proposed methodology.	algorithm;closed-circuit television;experience;object detection;performance evaluation;receiver operating characteristic;sensor	Franco Oberti;Elena Stringa;Gianni Vernazza	2001	Real-Time Imaging	10.1006/rtim.2000.0213	embedded system;computer vision;simulation;computer science;signal processing;receiver operating characteristic	Robotics	48.020618852828335	-56.46966791599442	65886
8734b7c9d55b8383a32262de6d32d771496b31c0	shape matching using relaxation techniques	filtering;image segmentation;image processing;probability density function;relaxation methods;search procedures;testing;shape measurement;data mining;springs;shape;shape matching;remote sensing;matching;satellites;relaxation techniques;noise shaping;image analysis;approximate matching;polygonal approximation;noise shaping shape measurement relaxation methods testing computer science image segmentation image analysis satellites remote sensing labeling;computer science;correlation;figure of merit;titanium;labeling;shape image processing matching relaxation techniques search procedures	The problem of finding approximate matches of pieces of shapes to parts of larger shapes is investigated. The shapes are represented by polygonal approximations. Initially, figures of merit are assigned to the matches between pairs of angles on the two shapes. Relaxation methods are then used to find acceptable combinations of these matches. This approach was tested on a data base consisting of digitized coastlines in various map projections. In nearly all cases, all matches except the correct one were eliminated by the relaxation processes.	approximation algorithm;coastline paradox;database;databases;large;linear programming relaxation;map projection;personnameuse - assigned;projections and predictions;relaxation (approximation);relaxation (iterative method)	Larry S. Davis	1979	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1979.4766876	filter;matching;titanium;computer vision;mathematical optimization;labeling theory;figure of merit;probability density function;image analysis;noise shaping;image processing;shape;computer science;machine learning;mathematics;software testing;image segmentation;correlation;satellite	Vision	47.90459550981709	-65.24870322962421	65890
9c64bdc47fc661c22b8264e67e28ba07cce640b0	application of nonlinear texture dynamics for image classification	vision system;systeme vision;texture image;dynamique non lineaire;image classification;image texture;human subjects;percepcion visual;dynamique psychophysique non lineaire;human visual system;nonlinear dynamics;classification image;perception visuelle;computing systems;algorithms;visual perception;classification accuracy;visual processing;sistema vision	Visual processing is a psychophysical process. In this paper, it is shown that texture processing by the human visual system shows nonlinear dynamic patterns. This is done by developing recursion equations that describe the dynamics in the perception and maps input texture patterns to output observables. The recursion variables are complex where the real and imaginary parts signify the signal and noise parts of the perception process, respectively. The output of the dynamics is used to perform texture discrimination between pairs of textures. These results are compared with results from experiments with human subjects. A good correlation is obtained between the results using texture dynamics and that of experimental data. This shows that texture perceptual dynamics is an important ingredient in developing computer algorithms that preserve perceptual similarity with human visual system processing of texture. Based on this an algorithm is developed to perform classification of textures. The algorithm is applied to classify natural and synthetic textures. This algorithm shows an improvement in the classification accuracy over traditional methods.	algorithm;computer vision;experiment;imaginary time;map;nonlinear system;observable;process philosophy;recursion;synthetic intelligence	Vidya B. Manian;Ramón E. Vásquez	2004		10.1117/12.548277	image texture;computer vision;computer science;artificial intelligence;communication;texture compression;texture filtering	Robotics	52.70329943519101	-63.130074844494146	65929
d4a7dccaf2ce4ca364a10675e8df93ea3d3508b5	object category recognition with projected texture	image recognition;object recognition;structured lighting patterns;projected texture;shape recovery;image classification;structured light;robustness image recognition lighting focusing information technology pattern recognition shape measurement cameras object recognition computer vision;object category recognition;deformations;object recognition image classification image texture;information presentation;deformations object category recognition projected texture depth information structured lighting patterns object classification;image texture;shape;three dimensional displays;classification algorithms;depth information;projected texture object recognition;robustness;object classification;lighting;cameras	Recognition of object categories from their images is extremely challenging due to the large intra-class variations, and variations in pose, illumination and scale, in addition to lack of depth information of the object. Recovering the depth information from multiple images or from image cues such as variations in illumination or focus, is both computationally intensive and error prone. In contrast, the appearance based approaches are more robust and computationally efficient. However, they lack the potential accuracy of 3D feature based approaches due to the lack of shape information. We propose the use of structured lighting patterns projected on the object, which gets deformed according to the shape of the object for recognition. Since our goal is object classification and not shape recovery, we characterize the deformations using simple texture measures, thus avoiding depth recovery step. Moreover, the shape information present in the deformations is implicitly used for classification. We show that the information thus derived can significantly improve the accuracy of object category recognition from arbitrary-pose images.	algorithmic efficiency;cognitive dimensions of notations;structured light	Avinash Sharma;Anoop M. Namboodiri	2008	2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing	10.1109/ICVGIP.2008.62	computer vision;computer science;machine learning;pattern recognition;3d single-object recognition	Vision	42.80522606797085	-52.94874680973804	65991
01a89a9dadedd9ab68a22fec831d737494962712	combining intensity and motion for incremental segmentation and tracking over long image sequences	image sequence;time use	This paper presents a method for incrementally segmenting images over time using both intensity and motion information. This is done by formulating a model of physically signi cant image resgions using local constraints on intensity and motion and then nding the optimal segmentation over time using an incremental stochastic minimization technique. The result is a robust and dynamic segmentation of the scene over a sequence of images. The approach has a number of bene ts. First, discontinuities are extracted and tracked simultaneously. Second, a segmentation is always available and it improves over time. Finally, by combining motion and intensity, the structural properties of discontinuities can be recovered; that is, discontinuities can be classi ed as surface markings or actual surface boundaries.	computation;image segmentation;motion estimation	Michael J. Black	1992		10.1007/3-540-55426-2_54	computer vision;computer science;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	Vision	48.763571793973156	-53.591797132455525	66107
2c4a7d5ed0f3bd5071345ef093ec0ec9e174091f	improving histogram-based image registration in video sequences through warping	image processing;institute for integrated and intelligent systems;conference output;faculty of science environment engineering and technology;consistent regions;080106;dynamic time warping;histogram based	This paper presents two computationally efficient dynamic-time warping algorithms for image registration in video sequence through histogram based image segmentation. The key idea is to warp the histogram in an input frame to create an approximation of a reference frame. Any histogram based thresholding method can then be applied to create consistent regions in both the input and the approximated reference frames. Experiments of the proposed algorithm are used to demonstrate that more consistent matches can found after thresholding.	algorithmic efficiency;approximation algorithm;computation;dynamic time warping;experiment;image registration;image scaling;image segmentation;reference frame (video);requirement;thresholding (image processing)	Xuesong Le;Ruben Gonzalez	2013		10.1007/978-3-319-03731-8_25	image warping;computer vision;image processing;computer science;histogram matching;machine learning;dynamic time warping;balanced histogram thresholding;multimedia;region growing;adaptive histogram equalization;histogram equalization;image histogram;computer graphics (images)	Vision	53.614192094665874	-63.91206867300941	66354
d0dce6f742ec56611c2555d6e3e6ba23e6e34166	interpretation of ambiguous zone to improve thinning results of handwritten chinese characters	handwriting recognition;skeleton;fork point;ambiguous zone;thinning algorithm	The skeleton representation of characters is a fundamental step to handwriting recognition, but traditional skeletonization algorithms always produce unwanted artifacts or pattern distortions at regions with intersections or junctions of strokes. In this paper, we propose a novel method to eliminate these unreliable skeleton segments and improve the skeletonization of handwritten Chinese characters on the basis of ambiguous zone interpretation. This method consists of two main phases. In the ̄rst phase, the parts of characters which contain the distortions of skeleton, called ambiguous zones, are detected. Instead of exploiting any corner or dominant point detection, a set of feature points from the original skeleton and the contour information around them are manipulated in our approach. In the phase of interpretation, the continuity of skeleton segments of substrokes is estimated based on the minimum curvature variation criterion, and compensations are made to ̄x interstices of terminated skeleton segments. Finally, the distorted parts of characters are reconstructed by applying a cubic B-spline interpolation. Experimental results show that the proposed method can detect ambiguous zones with arbitrary shapes accurately, and produce skeletons that are close to human perceptions.	algorithm;ambiguity function;ambiguous grammar;b-spline;computation;computational complexity theory;cubic function;distortion;handwriting recognition;printing;scott continuity;spline interpolation;thinning;time complexity;topological skeleton	Zhe-Wen Su;Zhong-sheng Cao;Yuan-Zhen Wang	2010	IJPRAI	10.1142/S0218001410007932	computer vision;computer science;handwriting recognition;skeleton	AI	43.564955453387896	-65.09915989296563	66417
233ec33a6aed4d753a4c21acf874f9688403a5c7	mathematical morphology and binary geodesy for robot navigation planning	navegacion;mathematical morphology;morfologia matematica;geodesic structure;trajectoire optimale;estructura geodesica;robot navigation;robotics;data mining;camino optimo;info eu repo semantics article;geodesic distance;chemin optimal;geodesique;navigation;planificacion;optimal path;geodesic;fouille donnee;optimal trajectory;structure geodesique;geodesico;trayectoria optima;pattern recognition;robotica;planning;robotique;reconnaissance forme;planification;reconocimiento patron;algoritmo optimo;algorithme optimal;optimal algorithm;busca dato;binary;morphologie mathematique	In this paper, we present a new application of the mathematical morphology: a single-image approach for the automatic detection and elimination of highlights in colour images. We use a 2D-histogram that allows us to relate the achromatic and saturation signals of a colour image and to identify interior brightness. To eliminate the highlights detected, we use an image-inpainting method, by means of connected vectorial filters of the mathematical morphology. This new filter operates exclusively on bright zones, reducing the high cost of processing the connected filters and avoiding over-simplification. The new method proposed here achieves good results, which are similar to those obtained from other multimedia techniques, yet does not require either costly multiple-view systems or stereo images.	autostereogram;circuit restoration;color image;color space;inpainting;level of detail;mathematical morphology;multiprocessing;real-time clock;robotic mapping;visual inspection	Francisco Ortiz;Santiago T. Puente Méndez;Fernando Torres Medina	2005		10.1007/11551188_13	computer vision;geodesic;simulation;computer science;artificial intelligence;mathematics;robotics	Robotics	49.230997398649414	-58.67225242429928	66425
ed7cd52478e1e98327397ef9ba159614880ad066	shape based co-segmentation repairing by segment evaluation and object proposals	co segmentation;segmentation evaluation	Repairing co-segmentation results by consistency evaluation shows the improvement of the co-segmentation performance. However, the existing co-segmentation refinement methods focus on color feature, while the mid-level features based repairing, such as shape, is ignored. In this paper, we propose a new shape based co-segmentation refinement method. An edge map based segment completeness evaluation and a shape based segment consistency evaluation are firstly proposed. Then, we use the initial segments and their evaluation scores to refine each result by employing the object proposals. By repeating such two evaluation and refinement steps, final refined results are obtained. Compared with traditional methods where only the bad segment is repaired, all segments are simultaneously evaluated and refined in an iteration process in our method to achieve better results. We verify our method based on Icoseg dataset. The results show larger IOU values than the original results.	consistency model;experiment;iteration;refinement (computing);segment tree	Wen Shi;Hongyuan Zhu;Lei Yang;Yuanqing Luo	2016	2016 Visual Communications and Image Processing (VCIP)	10.1109/VCIP.2016.7805590	computer science;data mining;mathematics;algorithm	AI	43.68242301394379	-54.12519736202841	66445
a769118110cc96eb2aa2cd7f1390a7022f66a902	the medial feature detector: stable regions from image boundaries	graph theory;detectors;image segmentation;edge detection;image matching;shape feature extraction image edge detection transforms euclidean distance detectors image segmentation;computational geometry;linear time algorithm;euclidean distance;object detection computational geometry feature extraction graph theory image matching image reconstruction image representation image retrieval;scale space;shape;image edge detection;local features;image representation;feature extraction;image reconstruction;transforms;euclidean space;medial axis;object detection;image retrieval;retrieval experiments medial feature detector image boundaries local feature detector weighted distance map image gradient linear time algorithm euclidean space weighted medial axis group marching voronoi skeletons graph image structure representation saddle points peak points duality property shape fragmentation factor matching experiments;saddle point	We present a local feature detector that is able to detect regions of arbitrary scale and shape, without scale space construction. We compute a weighted distance map on image gradient, using our exact linear-time algorithm, a variant of group marching for Euclidean space. We find the weighted medial axis by extending residues, typically used in Voronoi skeletons. We decompose the medial axis into a graph representing image structure in terms of peaks and saddle points. A duality property enables reconstruction of regions using the same marching method. We greedily group regions taking both contrast and shape into account. On the way, we select regions according to our shape fragmentation factor, favoring those well enclosed by boundaries—even incomplete. We achieve state of the art performance in matching and retrieval experiments with reduced memory and computational requirements.	distance transform;experiment;fragmentation (computing);greedy algorithm;image gradient;medial graph;optic axis of a crystal;requirement;scale space;time complexity;voronoi diagram	Yannis S. Avrithis;Konstantinos Rapantzikos	2011	2011 International Conference on Computer Vision	10.1109/ICCV.2011.6126436	iterative reconstruction;computer vision;detector;scale space;edge detection;topology;medial axis;feature extraction;computational geometry;image retrieval;shape;computer science;graph theory;euclidean space;euclidean distance;mathematics;geometry;saddle point;image segmentation	Vision	48.97184889413384	-63.969328993247	66449
5cd71a603cd023ecd41e4cd67e3b57729d268568	constructing intrinsic parameters with active models for invariant surface reconstruction	invariant surface reconstruction;splines mathematics image reconstruction invariance;range data;surface parameterization;principio variacional;surface reconstruction spline deformable models computer vision shape biomembranes reconstruction algorithms bayesian methods nonlinear equations monte carlo methods;invarianza;surface reconstruction;splines mathematics;invariance;reconstruction surface;membrane spline plaque mince;reparameterization;plaque mince;thin plate membrane spline;controlled continuity spline;principe variationnel;principal vectors curvature lines active models invariant surface reconstruction canonical invariant representation controlled continuity spline deformable model force field;principal vectors;image reconstruction;force field;modele deformable;curvature lines;pattern recognition;active models;thin plate;canonical invariant representation;reconnaissance forme;reconstruccion superficie;reconocimiento patron;ligne of curvature;reparametrisation;deformable model;variational principle;ligne courbure;placa delgada	Three-dimensional viewpoint invariance is an important requirement on the representation of surfaces for recognition tasks. Parameterized surfaces possess this desirable property. In general, the parameters in a parametric surface representation can be arbitrarily defined. A canonical, intrinsic parameterization provides us with a consistent, invariant form for describing surfaces. Our goal here is to define and construct such a parameterization. In this paper, we present two new techniques within the framework of active modeling [29] to achieve this goal. Canonical parameterization of a surface in these techniques is defined by the surface lines of curvature. The problem is formulated as a variational principle with the associated energy expression consisting of a parameterized stabilizer term and a penalty term. In the first method, we use a static instance of the controlled continuity spline for the stabilizer and show how to modifv it to reflect a change of parameters to the lines of curvature. In the second method, we use the dynamic instance of the controlled continuity spline called the deformable model. A force field defined in terms of the principal vectors is synthesized and applied to the parameter curves of the deformable model to coerce them along the lines of curvature. In essence, any transformation of parameters requires a modification of the stabilizer in the first method, whereas in the second method, it is tantamount to synthesizing a new force field. We present experimental results with real and synthetic range data. Zndex TermsDeformable model, invariance, lines of curvature, reparameterization, surface reconstruction, thin-platemembrane splines, variational principle.	calculus of variations;force field (chemistry);intrinsic dimension;mesh parameterization;scott continuity;spline (mathematics);stabilizer code;synthetic intelligence;variational principle	Baba C. Vemuri;Ravi Malladi	1993	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.221168	iterative reconstruction;computer vision;topology;surface reconstruction;variational principle;invariant;force field;mathematics;geometry	Vision	52.191660336572674	-56.417807878010265	66618
21ddeea880c133c3921b4a7b831728417118a0ff	a vision system to identify occluded industrial parts	vision system;image recognition;object recognition;degradation;feeds;machine vision image recognition layout computer vision object recognition assembly feeds marine vehicles needles degradation;layout;computer vision;assembly;multiple objectives;marine vehicles;machine vision;coordinate transformation;polygonal approximation;needles	"""A vision system is presented that recognizes occluded industrial parts. The unknown image may contain multiple objects that may touch or overlap giving rise to partial occlusion. The vision system uses stored models to locate and identify the objects in the scene. The models are based on the boundary of the object, since we assume that the objects are rigid and planar. From the polygon approximation of the boundary, vertices of high curvature are identified as """"corners."""" These corners are used as features in detecting the model in the image. A globally consistent coordinate transform that takes the model into the image is found by using a Hough like transform and the corner features."""		Mark W. Koch;Rangasami L. Kashyap	1985		10.1109/ROBOT.1985.1087319	layout;computer vision;degradation;machine vision;computer science;engineering;coordinate system;cognitive neuroscience of visual object recognition;assembly;3d single-object recognition;engineering drawing;computer graphics (images)	Robotics	49.4674304073368	-53.33009592138394	66827
580e0f29ceda973df2e1abbf88381a24609e3cdc	a robust detection method of control points for calibration and measurement with defocused images		This paper presents a detection method of control points for the camera calibration and measurement applications, which is robust to defocus. Our method is based on a ground truth, which we call ridge invariance. That is, the positions of broad-brush lines’ ridge lines are invariant to defocus blur. First, the ridge invariance is deduced in theory. Then, the methods for ridge point’s detection including defocus degree estimation and salience enhancement are deduced. In calibration and measurement experiments, new marks are designed and control points are determined at intersects of the ridge curves. Experiments show that our method can obtain precise calibration and measurement results with images in a large defocus amount range. In the effective defocus amount range, the accuracy of the proposed method almost keeps unchanged to the best values. The proposed method has approximated the same performance as conventional methods at good focus values.	approximation algorithm;camera resectioning;control point (mathematics);correctness (computer science);experiment;ground truth;speech enhancement	Wendong Ding;Xilong Liu;De Xu;Dapeng Zhang;Zhengtao Zhang	2017	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2017.2709561	calibration;ridge;deconvolution;camera resectioning;mathematics;point spread function;feature extraction;distortion;invariant (mathematics);computer vision;optics;artificial intelligence	Vision	53.49289405134322	-55.36966690175594	66882
19c8b5cc832b511196588741f8deae01c38e0ff7	an efficient shape feature extraction, description and matching method using gpu		Shape information is an important cue for many computer vision applications. In this work we propose an invariant shape feature extraction, description and matching method for binary images, named LISF. The proposed method extracts local features from the contour to describe shape and these features are later matched globally. Combining local features with global matching allows us to a obtaining a trade-off between discriminative power and robustness to noise and occlusion in the contour. The proposed extraction, description and matching methods are invariant to rotation, translation, and scale and present certain robustness to partial occlusion. The conducted experiments in the Shapes99, Shapes216, and MPEG-7 datasets support the mentioned contributions, where different artifacts were artificially added to obtain partial occlusion as high as 60 %. For the highest occlusion levels LISF outperformed other popular shape description methods, with about 20 % higher bull’s eye score and 25 % higher accuracy in classification. Also, in this paper, we present a massively parallel implementation in CUDA of the two most time-consuming stages of LISF, i.e., the feature extraction and feature matching steps; which achieves speed-ups of up to 32x and 34x, respectively.	feature extraction;graphics processing unit	Leonardo Chang;Miguel O. Arias-Estrada;José Hernández Palancar;Luis Enrique Sucar	2014		10.1007/978-3-319-25530-9_14	pattern recognition	AI	40.34882612795219	-56.69474620745014	67031
4834ef7df6b94ad2d5ccf5c4714be1f98c54b69e	gaussian-based edge-detection methods - a survey	edge detection;gaussian processes image edge detection filters detectors image processing computer vision layout object recognition smoothing methods;indexing terms;computer vision;image processing gaussian based edge detection methods gaussian filter computer vision survey nonlinear methods linear methods;filtering theory edge detection computer vision;filtering theory	The Gaussian filter has been used extensively in image processing and computer vision for many years. In this survey paper, we discuss the various features of this operator that make it the filter of choice in the area of edge detection. Despite these desirable features of the Gaussian filter, edge detection algorithms which use it suffer from many problems. We will review several linear and nonlinear Gaussian-based edge detection methods.	algorithm;computer vision;edge detection;gaussian blur;image processing;nonlinear system	Mitra Basu	2002	IEEE Trans. Systems, Man, and Cybernetics, Part C	10.1109/TSMCC.2002.804448	computer vision;feature detection;scale space;object-class detection;edge detection;index term;mean-shift;histogram of oriented gradients;computer science;machine learning;deriche edge detector;gaussian blur;pattern recognition;multi-scale approaches;canny edge detector;marr–hildreth algorithm;interest point detection	Vision	50.66514162536085	-65.3569992425627	67060
07987290df4cf34a59099fd68a9d7cd368679269	a flexible client-driven 3dtv system for real-time acquisition, transmission, and display of dynamic scenes	signal image and speech processing;analisis imagen;sistema interactivo;evaluation performance;streaming;analisis escena;analyse scene;performance evaluation;television 3 dimensiones;sintesis control;display equipment;flexibilidad;information transmission;implementation;real time;evaluacion prestacion;three dimensional television;image multiple;telecommunication network;metric;stereoscopy;imagen multiple;region interes;multiple image;systeme conversationnel;algorithme;feasibility;algorithm;codificacion;transmission en continu;quantum information technology spintronics;senal video;signal video;interactive system;red telecomunicacion;synthese commande;temps reel;image sequence;coding;reseau telecommunication;equipement affichage;video signal;tiempo real;stereoscopie;metrico;image analysis;flexibilite;secuencia imagen;estereoscopia;transmision fluyente;transmision informacion;region interet;transmission information;equipo visualizacion;implementacion;television 3 dimensions;analyse image;practicabilidad;faisabilite;control synthesis;metrique;sequence image;flexibility;codage;interest region;scene analysis;dynamic scenes;algoritmo	3D experience and free-viewpoint navigation are expected to be two essential features of next generation television. In this paper, we present a flexible 3DTV system in which multiview video streams are captured, compressed, transmitted, and finally converted to high-quality 3D video in real time. Our system consists of an 8× 8 camera array, 16 producer PCs, a streaming server, multiple clients, and several autostereoscopic displays. The whole system is implemented over IP network to provide multiple users with interactive 2D/3D switching, viewpoint control, and synthesis for dynamic scenes. In our approach, multiple video streams are first captured by a synchronized camera array. Then, we adopt a lengthened-B-field and region of interest(ROI-) based coding scheme to guarantee a seamless view switching for each user as well as saving per-user transmission bandwidth. Finally, a convenient rendering algorithm is used to synthesize a visually pleasing result by introducing a new metric called Clarity Degree (CD). Experiments on both synthetic and real-world data have verified the feasibility, flexibility, and good performance of our system.	3d television;algorithm;autostereoscopy;experiment;multi-user;real-time transcription;seamless3d;server (computing);streaming media;synthetic intelligence	Xun Cao;Yebin Liu;Qionghai Dai	2009	EURASIP J. Adv. Sig. Proc.	10.1155/2009/351452	stereoscopy;computer vision;image analysis;simulation;metric;telecommunications;computer science;coding;implementation;algorithm;telecommunications network;computer graphics (images)	Graphics	48.941865340828485	-55.40229238281007	67072
bf29da3a31805bcc59296dda7af2126a40d4d0f5	visual attention model for target search in cluttered scene	gabor filters image resolution search problems band pass filters low pass filters object detection vehicles;image resolution;saliency map;model generation;visual perception gabor filters image resolution;gabor filters;orientation conspicuity map;gabor filter;feature integration;target search;visual perception;visual attention;image resolution visual attention target search cluttered scene saliency map generation orientation conspicuity map gabor filter orthogonal orientations search tasks;target search visual attention saliency map feature integration orientation conspicuity map	Visual attention models generate saliency maps in which attentive regions are more distinctive with respect to remaining parts of the scene. In this work, a new model of orientation conspicuity map (OCM) is presented for the computation of saliency. The proposed method is based on the difference of the Gabor filter outputs with orthogonal orientations because vehicles are the targets for the search tasks in this study. Moreover, as another contribution, selective resolution for the input image, according to the distance of the target in the scene, is also utilized with the proposed scheme for the benefit to target search. Experimental results demonstrate that both the OCM model and selective resolution for input images yield promising results for the target search in cluttered scenes.	computation;gabor filter;map	Nevrez Imamoglu;Weisi Lin	2011	2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis	10.1109/IVMSPW.2011.5970370	computer vision;geography;pattern recognition;computer graphics (images)	Vision	39.86044112095418	-59.12278487316349	67177
51a872b9c729a56739ffa8bbb820b6b8d09ca063	background subtraction based on cooccurrence of image variations	image updating;image morphing;input image analysis;image segmentation;turning;image variation cooccurrence;dynamic environment background subtraction image variation cooccurrence foreground object detection dynamic scene swaying tree fluttering flag background image variation detection sensitivity input image analysis neighboring image block correlation image updating morphological postprocessing;variational techniques image segmentation image morphing object detection image colour analysis;detection sensitivity;variational techniques;layout;foreground object detection;systems engineering and theory;fluttering flag;dynamic environment;layout object detection lighting pixel research and development systems engineering and theory image analysis statistical analysis wiener filter turning;research and development;neighboring image block correlation;statistical analysis;swaying tree;image colour analysis;pixel;background subtraction;image analysis;lighting;wiener filter;dynamic scene;background image variation;morphological postprocessing;object detection;dynamic scenes	This paper presents a novel background subtraction method for detecting foreground objects in dynamic scenes involving swaying trees and fluttering flags. Most methods proposed so far adjust the permissible range of the background image variations according to the training samples of background images. Thus, the detection sensitivity decreases at those pixels having wide permissible ranges. If we can narrow the ranges by analyzing input images, the detection sensitivity can be improved. For this narrowing, we employ the property that image variations at neighboring image blocks have strong correlation, also known as “cooccurrence”. This approach is essentially different from chronological background image updating or morphological postprocessing. Experimental results for real images demonstrate the effectiveness of our method.	background subtraction;block cellular automaton;pixel;sensor	Makito Seki;Toshikazu Wada;Hideto Fujiwara;Kazuhiko Sumi	2003		10.1109/CVPR.2003.1211453	layout;computer vision;image analysis;background subtraction;computer science;pattern recognition;lighting;mathematics;image segmentation;wiener filter;pixel;computer graphics (images)	Vision	44.68259025973265	-65.85746416581863	67302
df293eddd027f860b3b87cbcb412ecbc30d003be	a fused features approach on content-based image retrieval based on fuzzy rule-set	fuzzy heuristics fused features approach content based image retrieval fuzzy rule set image location low level features color feature shape feature texture feature cbir image processing computer vision image matching block color histogram gray level co occurrence matrix glcm gabor wavelets texture features human visual system;fuzzy content based image retrieval texture color shape glcm gabor filter histogram image processing;wavelet transforms computer vision content based retrieval feature extraction fuzzy set theory image colour analysis image fusion image retrieval image texture matrix algebra statistical analysis;computers manuals visualization	Research in content-based image retrieval today is a lively discipline, expanding in breadth. Discovering new and innovative processes of locating a desired image from an expanding collection of images has been a major area of interest for many professional fields. This has led to the increasing use of a technique called Content Based Image Retrieval which is used to retrieve images based on low-level features which are automatically driven such as color, shape and texture. CBIR draws many of its methods from the field of image processing and computer vision and can be regarded as subset of that field. Using this technique, the entire database may be searched to find the most closely matching image. In this paper, color and texture features of an image have been used to retrieve all the similar images from the image database. For this purpose, Block Color Histogram as color feature and Gray-level Co-occurrence Matrix (GLCM) and Gabor wavelets as texture features have been used. The proposed approach is very efficient since it uses the prominent and distinct features of an image useful for effective image retrieval using fuzzy heuristics according to human visual system.	co-occurrence matrix;color histogram;computer vision;content-based image retrieval;fuzzy logic;fuzzy rule;gabor atom;heuristic (computer science);high- and low-level;image processing;lively kernel;requirement;usability;wavelet	Nikita Raina;Neeshu Roshi;Rashmi Chauhan;R. H. Goudar	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968407	color histogram;image texture;computer vision;feature detection;visual word;color image;image processing;machine learning;pattern recognition;mathematics;automatic image annotation;feature;image histogram	Vision	39.27973265654962	-61.18730048913419	67312
8babc61ed6142ad383bad27ab910398dd33f3bec	automatic selection of optimal views in multi-view object recognition	object representation;object recognition;curvature scale space;shape descriptor;standardisation	A shape-based method for multi-view 3-D object representation and recognition is introduced and explored in this paper. 3-D objects are recognised by a small number of images taken from different views. The paper addresses the issue of automatic selection of the best and the optimum number of views for each object. The object boundary of each view is considered as a 2-D shape and is represented effectively by less than ten pairs of integer values. These values include the locations of the maxima of its Curvature Scale Space (CSS) image contours. The CSS shape descriptor is expected to be selected for MPEG-7 standardisation. An unknown object is then recognised by a single image taken from an arbitrary viewpoint. The method has been tested on a collection of 3-D objects consisting of 15 aircrafts of different shapes. Each object has been modelled using an optimised number of silhouette contours obtained from different view points. This number varies from 5 to 25 depending on the complexity of the object and the measure of expected accuracy. A comprehensive analysis of the performance of the system has been given in this paper as the number of views varies. Around ten silhouette contours corresponding to random views are separately used as input for each object. Results indicated that robust and efficient 3-D free-form object recognition through multi-view representation can be achieved using the CSS representation even for large database retrieval applications.	autostereogram;cascading style sheets;contour line;free viewpoint television;mpeg-7;maxima;outline of object recognition;scale space;shape context	Farzin Mokhtarian;Sadegh Abbasi	2000		10.5244/C.14.28	computer vision;method;object model;cognitive neuroscience of visual object recognition;pattern recognition;mathematics;geometry;3d single-object recognition;standardization	Vision	42.643123015362654	-55.35145190065939	67425
786ca17bda73746a89dab3bb6d1efdae8dba020e	a novel real-time proficient algorithm for edge detection	real time;edge detection		algorithm;edge detection;real-time transcription	Ankur Gupta;Pradip K. Das	2010			canny edge detector;deriche edge detector;computer vision;computer science;edge detection;artificial intelligence	Vision	41.62965665295893	-65.56490875992657	67467
e21afa8e05425543a35241ab72f700bd93f078ac	image analysis and computer vision: 1998	analisis imagen;vision ordenador;feature detection;computational techniques;revue bibliographique;revista bibliografica;bibliografia;bibliography;three dimensional;computer vision;artificial intelligent;bibliographic review;bibliographie;pattern recognition;image analysis;visual perception;vision ordinateur;analyse image;neural network;scene analysis	This paper presents a bibliography of over 2250 references related to computer vision and image analysis, arranged by subject matter. The topics covered include computational techniques; feature detection and segmentation; image and scene analysis; two-dimensional shape; pattern; color and texture; matching and stereo; three-dimensional recovery and analysis; three-dimensional shape; and motion. A few references are also given on related topics, including geometry and graphics, compression and processing, sensors and optics, visual perception, neural networks, artificial intelligence and pattern recognition, as well as on applications. c © 1999 Academic Press	artificial intelligence;artificial neural network;computation;computer vision;data compression;feature detection (computer vision);feature detection (web development);graphics;image analysis;image segmentation;pattern recognition;sensor;subject matter expert turing test	Azriel Rosenfeld	1999	Computer Vision and Image Understanding	10.1006/cviu.1999.0746	three-dimensional space;computer vision;feature detection;image analysis;visual perception;computer science;artificial intelligence;feature detection;bibliography;feature;computer graphics (images)	Vision	48.15519250000397	-61.85447693422414	67723
add7720fff29303f1350b5828cade6c9cfecc1f8	curve based stereo matching using the minimum hausdorff distance	three dimensions;stereo matching;subdivisions;hausdorff distance;topological data structures;traversal algorithms;windowing	Binocular stereo vision involves recovering 3d information from two 2d images of the same scene. A crucial step in the stereo analysis is establishing a correspondence between the projections of objects in the two images. This correspondence is called stereo matching. There are two general methods of stereo matching: areabased matching and jeature-based matching (see, e.g., [Ay]). In area based matching a patch in one image is matched to patches in the other image according, e.g., to the brightness of the pixels in the patches. In feature based matching, corners, junctions, curved segments or other features are extracted from the images, and they are matched by various methods. Area-baaed matching deals with all the pixels in the image, thus with a large amount of data. It produces a slightly blurred matching and is sensitive to photogrametric changes. Feature-based matching deals with extracted features in the image, thus with less data, it is not sensitive to photogrametric changes and has better accuracy. However, once the features are matched, an interpolation step is needed to evaluate the heights of the areas. Most of the contemporary stereo algorithms match features. We propose a new feature-based method of stereo matching. The met hod matches curved segments in the images, using the minimum Hausdorff dist ante to find the best match for each curved segment. We use a neighborhood graph to propagate the disparity results to neighboring curved segments and to resolve ambiguous mat things. We present some	algorithm;binocular disparity;binocular vision;computer stereo vision;hausdorff dimension;interpolation;photogrammetry;pixel;stereopsis	Klara Kedem;Yana Yarmovski	1996		10.1145/237218.237420	three-dimensional space;hausdorff distance;discrete mathematics;topology;hausdorff dimension;subdivision;mathematics;geometry	Vision	48.31944683623639	-62.67921647762279	67789
f93afde78fcea19f868a203457e4378d59819af0	a multitemporal uav images registration approach using phase congruency		If there are great illumination and contrast changes for multitemporal unmanned aerial vehicle (UA V) images, common image matching and registration methods may not work well on these images. To improve matching effects, this paper conduct the image registration using the structure consistency between the images to be matched, first, use phase congruency(PC) to describe images' structure characteristics and generate the PC images for both images to be matched; then, conduct the image matching by extracting the features from accelerated segment test (FAST) in the PC images; finally, use the method of randomized sample consensus (RANSAC) to eliminate the mismatches and obtain the affine transformation matrix between the two images. We use this method to pick out known control points on new UAV images on the basis of old image database of ground control points (GCP), the test proves that the method is independent of the radiation information and has a good effect on multitemporal UAV images registration.		Xujie Zhang;Qingwu Hu;Mingyao Ai;Xiaochun Ren	2018	2018 26th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2018.8557189	phase congruency;remote sensing;computer vision;ransac;affine transformation;radiation;computer science;image registration;artificial intelligence	Robotics	53.52485151754257	-56.16124241157711	67878
d70330198d7a56959a554c44825c3da164f4b9d1	pattern regularity as a visual key	invariant measure;image filtering;texture classification;periodic structure;human perception;defect detection	This paper gives a summary of our research on pattern regularity. Periodic structures are perceived by humans as regular in a wide range of viewing angles. This observation motivates the development of a regularity based feature vector whose affine invariance is justified theoretically and tested experimentally. The vector is derived from the interaction map of a pattern. Several alternative but closely related definitions of the interaction map are discussed. The maximal regularity, a component of the feature vector, is shown to be consistent with human judgement on regularity. This feature can be implemented as a run filter, allowing for regularity based image filtering. Three applications of the regularity approach are presented. First, it is used for affine-invariant texture classification. Then, detection of periodic structures in aerial images is demonstrated. Finally, the texture inspection problem is addressed and structural defects are found as locations of low regularity.		Dmitry Chetverikov	2000	Image Vision Comput.	10.1016/S0262-8856(00)00041-X	computer vision;discrete mathematics;topology;invariant measure;mathematics;perception	Vision	40.094606229599954	-56.364167104072884	67971
cfc4e71fd586fac8d03db99d016393502d3ccf38	performance measures for video object segmentation and tracking	video object;multimedia authoring;video signal processing;automatic segmentation;segmentation;algorithme;algorithm;detection objet;video editing;image sequence;poursuite cible;traitement signal video;target tracking;segmentacion;object detection;algoritmo	We propose measures to evaluate quantitatively the performance of video object segmentation and tracking methods without ground-truth (GT) segmentation maps. The proposed measures are based on spatial differences of color and motion along the boundary of the estimated video object plane and temporal differences between the color histogram of the current object plane and its predecessors. They can be used to localize (spatially and/or temporally) regions where segmentation results are good or bad; and/or they can be combined to yield a single numerical measure to indicate the goodness of the boundary segmentation and tracking results over a sequence. The validity of the proposed performance measures without GT have been demonstrated by canonical correlation analysis with another set of measures with GT on a set of sequences (where GT information is available). Experimental results are presented to evaluate the segmentation maps obtained from various sequences using different segmentation approaches.	algorithm;color histogram;distortion;frame (physical object);ground truth;map;numerical analysis;performance evaluation;performance engineering;portion of ground substance;biologic segmentation	Sung-Hoon Hong;Mike Myung-Ok Lee	2003	IEEE Transactions on Image Processing	10.1007/978-3-540-45076-4_28	computer vision;computer science;segmentation-based object categorization;multimedia;image segmentation;scale-space segmentation;segmentation;algorithm;computer graphics (images)	Vision	50.411757302527356	-57.94590077390047	68109
3bbf66f6e2b988bd355ca7a5f69bfea928ad458c	image filtering in the compressed domain	image filtering;problema valor limite;vision ordenador;condiciones limites;image processing;condition aux limites;filtrage lineaire;convolution;espace lineaire;filtrado lineal;boundary value problem;transformation cosinus discrete;espacio lineal;procesamiento imagen;convolucion;codigo bloque;traitement image;linear filtering;computer vision;boundary condition;efecto bloque;discrete cosine transforms;effet bloc;code bloc;vision ordinateur;convolution operator;linear space;probleme valeur limite;block code;blocking artifact	Linear filtering of images is usually performed in the spatial domain using the linear convolution operation. In the case of images stored in the block DCT space, the linear filtering is usually performed on the sub-image obtained by applying an inverse DCT to the block DCT data. However, this results in severe blocking artifacts caused by the boundary conditions of individual blocks as pixel values outside the boundaries of the blocks are assumed to be zeros. To get around this problem, we propose to use the symmetric convolution operation in such a way that the operation becomes equivalent to the linear convolution operation in the spatial domain. This is achieved by operating on larger block sizes in the transform domain. We demonstrate its applications in image sharpening and removal of blocking artifacts directly in the compressed domain.	blocking (computing);convolution;discrete cosine transform;pixel;unsharp masking	Jayanta Mukherjee;Sanjit K. Mitra	2006		10.1007/11949619_18	discrete mathematics;mathematics;geometry;algorithm	Vision	51.958913054900265	-62.131509527441295	68195
07d2319bad838fbedf33c4e54ae31e51a41e439a	face detection using pso template selection	video sequence;pso template selection;video signal processing;image database;face recognition;particle swarm optimizer;visual databases face recognition image sequences object detection particle swarm optimisation video signal processing;particle swarm optimization;face detection;face detection eyebrows nose mouth particle swarm optimization optimization methods testing image databases spatial databases video sequences;particle swarm optimisation;object detection;image sequences;visual databases;image database face detection pso template selection particle swarm optimization video sequence	In this work we present a new method based on PSO (particle swarm optimization) to optimize templates for frontal face detection. In the past, several methods for face detection have been developed using face templates. These templates are based on common face features such as eyebrows, nose and mouth. Templates have been applied to a directional image containing faces computing a line integral to detect faces with high accuracy. In this paper, the PSO is used to select new templates optimizing its size and response to a face in the directional image. The method was tested on a database composed of two video sequences and compared to the results of the traditional anthropometric templates that contain features from the eyebrow, nose and mouth. Results show that templates selected by PSO have significant better performance in the estimation of face size and the line integral value. In both sequences face detection reached 99% and 100%. The templates have fewer number of points compared to the traditional anthropometric templates which will lead to lower processing time.	anthropometry;database;face detection;floor and ceiling functions;mathematical optimization;particle swarm optimization	Claudio A. Perez;Juan I. Vallejos	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.384797	facial recognition system;computer vision;face detection;object-class detection;computer science;machine learning;pattern recognition;particle swarm optimization	Vision	39.930006255602045	-58.380478096227456	68777
87e72abe69c1e9efd559fb5072fd992a7c114797	a novel segmentation algorithm of fingerprint images based on mean shift		The segmentation of fingerprint images is an important step in an au- tomatic fingerprint identification system (AFIS). It is used to identify the fore- ground of a fingerprint image. Existing methods are usually based on some point features such as average gray level, variance, Gabor response, etc, while they ignored the local information of foreground regions. In this paper, a novel segmentation approach is proposed based on the mean shift algorithm, which not only take advantage of the traditional features, but also use the local information. In order to segment the fingerprint image better, we modified the original mean shift segmentation algorithm. First we calculate some effective features of fingerprint images and determine the parameters adaptively, and then we process the image based on the mean shift algorithm and get some di- vided regions, finally the foreground are selected from these regions. The accu- racy and effectiveness of our method are validated by experiments performed on FVC database.	algorithm;fingerprint;mean shift	Zhe Xue;Tong Zhao;Min Wu;Tiande Guo	2012		10.1007/978-3-642-31837-5_30	computer vision;machine learning;pattern recognition	Vision	41.591319919585395	-54.759448256219514	68877
e7cd37555b841481f80ef2e4933572d604c09a6d	visual attention identification using random walks based eye tracking protocols	damping;visualization damping tracking clustering algorithms convergence signal processing mobile communication;convergence;viewer visual attention visual attention identification random walk based eye tracking protocols user visual perception behavior fixation cluster random walks region of interest roi distance matrix point to point distances transition probability probability distribution convergent coefficients fixation cluster center mean position based method;visualization;signal processing;mobile communication;clustering algorithms;random walks visual attention identification eye tracking fixation;visual perception gaze tracking pattern clustering random processes statistical distributions;tracking	The identification of visual attention is an essential part of analyzing the user's visual perception behavior. In this paper, a novel measurement of the center in the fixation cluster based on random walks is developed. In the proposed method, we generate the cluster which includes fixations for a particular region-of-interest (ROI). We form a distance matrix by calculating the point-to-point distances in each cluster and discover the center of the fixation cluster utilizing random walks. Based on the obtained distance matrix, the matrix referring to their transition probability among each other is thereafter constituted. The density of the points in the cluster is also calculated. We utilize the density as the initial coefficient for each fixation and update the coefficients with the consideration of their transition probability and distribution in the cluster. Finally, the generated convergent coefficients are used to weight the fixations and produce the position of the center based on their weighted average. Experimental results demonstrate that the center of the fixation cluster produced by the proposed method outperforms the traditional mean position based method and describes the feature of the viewer's visual attention more accurately.	cluster analysis;coefficient;damping factor;distance matrix;experiment;eye tracking;markov chain;point-to-point protocol;region of interest;the matrix	Xiu Chen;Zhenzhong Chen	2015	2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2015.7416925	computer vision;simulation;computer science;communication	Vision	40.81050945660145	-53.528885766131445	68885
0dff2fdc54c356a1fc55240ada8af3418d916abe	3-d analysis of projective textures using structural approaches	analisis imagen;image tridimensionnelle;image processing;analisis textura;etude experimentale;extraction forme;procesamiento imagen;segmentation;traitement image;power spectrum;three dimensional;algorithme;algorithm;texture analysis;extraccion forma;vanishing point;superficie;tridimensional image;surface;image analysis;analyse image;analyse texture;estudio experimental;pattern extraction;segmentacion;imagen tridimensional;algoritmo	This paper presents a new algorithm that obtains the surface orientation of the texture image using structural approaches. The proposed method has shown that structural information can be effectively used in three-dimensional (3-D) analysis of textures as well as description and segmentation. By examining Fourier power spectrum of the texture image, we determine the tilt of the textured surface. Then, 1-D projection information of the texture in the obtained tilt direction is used to compute the slant. Using the obtained information, we can compute a vanishing point, and rearrange the textured surface with the lines converging to the vanishing point and the lines perpendicular to the tilt. In the experimental results, we have ascertained the proposed method can make a precise 3-D analysis of structural textures. ( 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	algorithm;computation;distortion;grayscale;pattern recognition;spectral density;texel (graphics);vanishing point	Hyun-Ki Hong;Yun-Chan Myung;Jong-Soo Choi	1999	Pattern Recognition	10.1016/S0031-3203(98)00083-1	three-dimensional space;computer vision;image analysis;vanishing point;image processing;computer science;mathematics;geometry;surface;spectral density;segmentation	Vision	49.3242381743198	-60.80957365257181	69164
25b56ceac1d873d5a484810706f865cf1984b47c	filter banks for improved lcd motion	moving image;traitement signal;sistema 2 canales;reconstruccion senal;echantillonneur bloqueur;filter bank;image formation;motion pictures;liquid crystal display;video signal processing;banc filtre;two channel system;video processing;liquid crystal displays;imagen movil;qualite image;desconvolucion;image mobile;algorithme;algorithm;motion blur;imagen borrosa;sample and hold circuit;flat panel displays;human visual system;blurred image;signal processing;banco filtro;image quality;imaging;deconvolution;traitement signal video;formation image;signal reconstruction;muestreador mantenedor;calidad imagen;formacion imagen;image floue;reconstruction signal;flat panel display;systeme 2 canaux;procesamiento senal;perfect reconstruction;affichage cristaux liquides;algoritmo	In the past several years much attention has been placed on improving the motion picture quality of liquid crystal displays (LCDs). One pervasive problem is motion blur which occurs due to the inherent sample-and-hold nature of LCD image formation. In this work, we take a signal processing approach to motion blur reduction by pre-processing the data before it is sent to the display. We develop a two-channel non-perfect reconstruction filter bank that is able to reduce the amount of perceivable motion blur. In addition, as in similar works, we discriminate between different regions of the scene and weight the application of the algorithm based on their susceptibility to motion blur. Perceptual tests indicate that our algorithm reduces the amount of perceivable motion blur on LCDs.	filter bank;liquid-crystal display	Shay Har-Noy;E. Martinez;Truong Q. Nguyen	2010	Sig. Proc.: Image Comm.	10.1016/j.image.2009.09.005	computer vision;quarter-pixel motion;computer science;motion interpolation;signal processing;motion estimation;liquid-crystal display;computer graphics (images)	Vision	53.58903402314137	-60.11395239191901	69169
670d8f2da1f615636e3ecae8413a325e218d0d57	determination of face position and pose with a learned representation based on labelled graphs	eficacia sistema;object recognition;sistema experto;learning algorithm;formal specification;position;high dimensionality;image processing;prior probability;learning;geometrie algorithmique;etude experimentale;probabilite a priori;computational geometry;performance systeme;procesamiento imagen;posicion;graph matching;system performance;traitement image;specification formelle;algorithme;aprendizaje;algorithm;especificacion formal;apprentissage;neural system;face recognition;probabilidad a priori;pattern recognition;geometria computacional;reconnaissance forme;systeme expert;estimation statistique;reconocimiento patron;estimacion estadistica;statistical estimation;estudio experimental;algoritmo;pose estimation;expert system	We present a new system for the automatic determination of the position, size and pose of the head of a human figure in a camera image. The system is an extension of the well-known face recognition system [15] to pose estimation. The pose estimation system is characterized by a certain reliability and speed. We improve this performance and speed with the help of statistical estimation methods. In order to make these applicable, we reduce the originally very high dimensionality of our system with the help of a number of a priori principles. We discuss a possible extension of the learning algorithm aiming an autonomous object recognition system at the end of the paper.		Norbert Krüger;Michael Pötzsch;Christoph von der Malsburg	1997	Image Vision Comput.	10.1016/S0262-8856(97)00012-7	computer vision;simulation;pose;prior probability;3d pose estimation;image processing;computational geometry;computer science;position;artificial intelligence;cognitive neuroscience of visual object recognition;formal specification;articulated body pose estimation;expert system;matching	Vision	47.591871014834545	-58.847980740103786	69253
09a81d4cc16f0310599640af47cfc968e9180057	3d depth analysis of human faces	face modeling facial depth analysis;three dimensional displays shape solid modeling principal component analysis vectors image reconstruction correlation;3d face reconstruction 3d depth analysis human face depth variation 3d face shape 3d depth information generic depth information gender specific average depth model ethnicity specific average depth model face image 3d face modeling;image reconstruction;solid modelling image reconstruction;solid modelling	We provide an important analysis of depth variation of human faces. Throughout an extensive analysis of 3D face shapes, we claim that 3D depth information (z) of faces is not significantly changing and can be synthesized from another person's depth or a generic depth information. We also show that gender and ethnicity specific average depth models can approximate the 3D shape of the input face image more accurately, achieving a better generalization of 3D face modeling and reconstruction compared to a global average depth model.	approximation algorithm	Jingu Heo	2013	IVMSP 2013	10.1109/IVMSPW.2013.6611920	computer vision;pattern recognition;mathematics;communication	Vision	41.95749577791608	-53.08439907341326	69449
4b5eef90835f3ad884fda6ad92548ca7c61156d9	directional interpolation using neural networks	nuclear magnetic resonance imaging;image tridimensionnelle;interpolation;brain;imagineria rmn;image processing;magnetism;systeme nerveux central;neural networks;cost function;3d imaging;interpolacion;procesamiento imagen;normal coordinate;hombre;encefalo;traitement image;distortion;sistema nervioso central;mr imaging;encephale;magnetic resonance;human;coordonnee normale;brain imaging;tridimensional image;algorithms;imagerie rmn;reseau neuronal;red neuronal;central nervous system;imagen tridimensional;homme;neural network;brain vertebrata;coordenada normal	In this paper, we propose a 3-dimensional directional interpolation algorithm for brain magnetic resonance (MR) images using neural networks. Typically, brain images consist of a number of two-dimensional images. Although the sequences of two-dimensional images provide basic information on structure, abnormality and etc., further processing on the sequences provides far more information. In processing 3 dimensional images, interpolation operation is one of the most widely used operations. In most conventional interpolation algorithms in the three-dimensional space, the interpolation operation is performed separately in each coordinate that is orthogonal to each other. However, since the shape of the brain is roughly a sphere, interpolation along three orthogonal coordinates may result in some distortion, particularly in the vicinity of the boundary. In order to address this problem, we propose a new 3-dimensional interpolation algorithm. In the proposed method, we first perform the interpolation along two orthogonal coordinates. In order to find the best interpolation in the remaining coordinate, we search various directions that are not orthogonal to the two orthogonal coordinates using a cost function. Then we use neural networks to determine the final direction for interpolation. Experiments with brain MR images show improved results. Keyword: directional interpolation, brain magnetic resonance (MR) images, 3 dimensional interpolation, neural networks, orthogonal coordinates. Visual Information Processing X, Stephen K. Park, Zia-ur Rahman, Robert A. Schowengerdt, Editors, Proceedings of SPIE Vol. 4388 (2001) © 2001 SPIE · 0277-786X/01/$15.00 227 Downloaded From: http://proceedings.spiedigitallibrary.org/ on 07/13/2016 Terms of Use: http://spiedigitallibrary.org/ss/TermsOfUse.aspx	algorithm;artificial neural network;brain implant;distortion;information processing;interpolation;loss function;resonance	Chulhee Lee;Bongjun Lee;Kwanghoon Sohn	2001		10.1117/12.438261	spline interpolation;interpolation;computer vision;bilinear interpolation;interpolation;artificial intelligence;stairstep interpolation;tricubic interpolation;bicubic interpolation;nearest-neighbor interpolation;multivariate interpolation;artificial neural network;trilinear interpolation;image scaling	Vision	45.731331018351995	-63.81465518898226	69579
f548b4b514b5b5c3f6c99aafdbb0f34293bc11a4	application of neural networks for automated x-ray image inspection in electronics manufactoring	analisis imagen;image processing;x ray imaging;heuristic method;procesamiento imagen;image classification;industrie electronique;traitement image;imagerie rx;visual inspection;electronics industry;classification image;industria electronica;system development;image analysis;reseau neuronal;analyse image;red neuronal;artificial neural network;neural network	Artific ial neural networks have proven to be valuable tools in industrial problems, e.g. for image processing, and classification in visual inspection tasks. Typically, todays successful systems have a heterogeneous structure, applying small and specialised neural networks together with classical and heuristic methods in a hybrid framework. This paper reports on the practical application of such a system, developed in prior work, which efficiently employs selected neural networks in an innovative framework. In particular, the application in electronics manufacturing with advanced sensor technology was subject of investigation.	artificial neural network	Andreas Koenig;Andreas Herenz;Klaus Wolter	1999		10.1007/BFb0100526	computer vision;contextual image classification;simulation;computer science;artificial intelligence;machine learning;artificial neural network;visual inspection	Vision	46.10889629134287	-61.81190813276764	69692
3f2e2b7c1b09723ad1ffae3dda861b58b82a1f20	pose sampling for efficient model-based recognition	image features;object recognition;real time;object model;pose estimation	In model-based object recognition and pose estimation, it is common for the set of extracted image features to be much larger than the set of object model features owing to clutter in the image. However, another class of recognition problems has a large model, but only a portion of the object is visible in the image, in which a small set of features can be extracted, most of which are salient. In this case, reducing the effective complexity of the object model is more important than the image clutter. We describe techniques to accomplish this by sampling the space of object positions. A subset of the object model is considered for each sampled pose. This reduces the complexity of the method from cubic to linear in the number of extracted features. We have integrated this technique into a system for recognizing craters on planetary bodies that operates in real-time.	algorithm;cluster analysis;clutter;cubic function;effective complexity;generalised hough transform;norm (social);outline of object recognition;planetary scanner;randomness;real-time clock;real-time computing;sampling (signal processing)	Clark F. Olson	2007		10.1007/978-3-540-76856-2_77	computer vision;pose;object model;3d pose estimation;haar-like features;computer science;viola–jones object detection framework;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;3d single-object recognition;feature	Vision	41.0334361914567	-53.991074807682025	69725
53facd4da5f1d1f98f876211421957f5fbe8a29a	the mesh-lbp: a framework for extracting local binary patterns from discrete manifolds	standards;manifolds;mesh generation computational geometry feature extraction image classification image texture;bridges;surface texture;shape;three dimensional displays;feature extraction;local shape descriptor mesh lbp descriptors mesh local binary pattern local binary pattern extraction discrete manifolds local binary like patterns triangular mesh manifold 2d lbp variants 2d image analysis uniformity aspect repeatability experiments rotation invariance 3d texture classification triangular mesh surfaces public data sets depth images mesh irregularity 3d surface digitizer scans;three dimensional displays manifolds surface texture shape feature extraction standards bridges;3d texture analysis local binary patterns ordered ring facets mesh manifold	In this paper, we present a novel and original framework, which we dubbed mesh-local binary pattern (LBP), for computing local binary-like-patterns on a triangular-mesh manifold. This framework can be adapted to all the LBP variants employed in 2D image analysis. As such, it allows extending the related techniques to mesh surfaces. After describing the foundations, the construction and the main features of the mesh-LBP, we derive its possible variants and show how they can extend most of the 2D-LBP variants to the mesh manifold. In the experiments, we give evidence of the presence of the uniformity aspect in the mesh-LBP, similar to the one noticed in the 2D-LBP. We also report repeatability experiments that confirm, in particular, the rotation-invariance of mesh-LBP descriptors. Furthermore, we analyze the potential of mesh-LBP for the task of 3D texture classification of triangular-mesh surfaces collected from public data sets. Comparison with state-of-the-art surface descriptors, as well as with 2D-LBP counterparts applied on depth images, also evidences the effectiveness of the proposed framework. Finally, we illustrate the robustness of the mesh-LBP with respect to the class of mesh irregularity typical to 3D surface-digitizer scans.	binary pattern (image generation);circuit complexity;digitizer device component;experiment;foundations;image analysis;information privacy;local binary patterns;repeatability;manifold;negative regulation of trichome patterning	Naoufel Werghi;Stefano Berretti;Alberto Del Bimbo	2015	IEEE Transactions on Image Processing	10.1109/TIP.2014.2370253	surface finish;computer vision;local binary patterns;topology;manifold;feature extraction;shape;computer science;mathematics	Vision	40.296065535499416	-56.35253707644016	69779
6267fd7912e7e0b3b95ef54ecde864948d8a50da	video-based face recognition using bayesian inference model	reconnaissance visage;bayes estimation;modelizacion;video databases;image processing;temporal dynamics;distance measure;facies;maximum likelihood;technology;computer science artificial intelligence;bayesian inference;maximum vraisemblance;procesamiento imagen;base donnee video;manifold learning;traitement image;modelisation;estimacion bayes;face recognition;science technology;senal video;signal video;nonlinear dimensionality reduction;image sequence;pattern recognition;video signal;secuencia imagen;reconnaissance forme;computer science;reconocimiento patron;video database;modeling;computer science theory methods;maxima verosimilitud;local linear embedding;sequence image;estimation bayes	There has been a flurry of works on video sequence-based face recognition in recent years. One of the hard problems in this area is how to effectively combine the facial configuration and temporal dynamics for the recognition task. The proposed method treats this problem in two steps. We first construct several view specific appearance submanifolds learned from the training video frames using locally linear embedding (LLE). A general Bayesian inference model is then fit on the recognition task, transforming the complicated maximum likelihood estimation to some elegant distance measures in the learned sub-manifolds. Experimental results on a middle-scale video database demonstrate the effectiveness and flexibility of our proposed method.	arc diagram;bayesian network;facial recognition system;nonlinear dimensionality reduction	Wei Fan;Yunhong Wang;Tieniu Tan	2005		10.1007/11527923_13	computer vision;image processing;computer science;artificial intelligence;machine learning;pattern recognition;nonlinear dimensionality reduction;statistics	Vision	46.73013549114339	-57.22902355592315	69945
03a99c9ec6d40d4f2fa15264747c97813042aa46	range data acquisition using color structured lighting and stereo vision	image tridimensionnelle;structured lighting;range data;algorithm performance;image processing;coloration;etude experimentale;edge detection;range data acquisition;extraction forme;procesamiento imagen;search method;structured light;correspondence problem;stereoscopy;dynamic program;traitement image;deteccion contorno;algorithme;algorithm;detection contour;coloracion;extraccion forma;resultado algoritmo;stereo vision;performance algorithme;stereoscopie;tridimensional image;estereoscopia;winner take all;estudio experimental;pattern extraction;imagen tridimensional;algoritmo	This paper presents a new color-lighting/stereo method for 3D range data acquisition by combining color structured lighting and stereo vision. A major advantage of using stereo vision together with color stripes lighting is that there is no need to solve the problem of finding the correspondence between the color stripes projected by the light source and the color stripes observed in the images. That is, the more difficult problem of finding the correct color stripe correspondence problem between the light source and the image is replaced by an easier image-to-image stereo correspondence which is not only easier than the above lighting-to-image correspondence problem, but also easier than the traditional stereo correspondence because a good color pattern has been projected onto the object. Another advantage of using stereo vision is that there is no need to calibrate the position and orientation for each of the projected light stripes in 3D space. In this work, a pattern of color stripes is projected onto the objects when taking images, after which edge segments are extracted from the acquired stereo image pair, and then used for finding the correct stereo correspondence. A systematic procedure is proposed in this paper for generating good color stripe patterns. To find the correct stereo correspondence, a global search method based on in&a-scanline dynamic programming is adopted. A winner-take-all scheme using edge-based interscanline consistency is then proposed to refine the results obtained from intra-scanline search. Experimental results have shown that the proposed method can successfully generate a dense range map with only one pair of stereo images.	correspondence problem;data acquisition;dynamic programming;magnetic stripe card;scan line;stereopsis;stripes;structured light	Chu-Song Chen;Yi-Ping Hung;Chiann-Chu Chiang;Ja-Ling Wu	1997	Image Vision Comput.	10.1016/S0262-8856(96)01148-1	computer stereo vision;winner-take-all;stereoscopy;stereo cameras;stereo camera;computer vision;edge detection;structured light;image processing;computer science;stereopsis;correspondence problem;computer graphics (images)	Vision	49.59566548509395	-57.652897955535714	69950
816a29cf9bf3fcbe7fa5698fcd85344edcca887e	a novel scheme for progressive polygon approximation of shape contours	vertex based shape representation;object based video;algorithm efficiency;approximation error;approximation algorithms;edge detection;efficient algorithm;low computational complexity;shape approximation error approximation algorithms computational complexity euclidean distance indexing content based retrieval;shape contours;euclidean distance;approximation theory;video coding;video coding edge detection approximation theory computational complexity image representation;progressive polygon approximation;shape;indexing;computational complexity;image representation;vertex based shape coding;initial vertex;polygonal approximation;video coding progressive polygon approximation shape contours efficient algorithm approximation error initial vertex low computational complexity algorithm efficiency experimental results object based video vertex based shape representation vertex based shape coding polygonal shape descriptors mpeg 7;polygonal shape descriptors;experimental results;content based retrieval;mpeg 7	This paper presents an efficient algorithm for polygon approximation of shape contours. The proposed algorithm approximates a shape contour by a polygon with minimal number of vertices for given allowable approximation error and initial vertex. Furthermore, it is designed to provide low computational complexity and simple implementation. The efficacy of the proposed algorithm is demonstrated through experimental results.	algorithm;approximation error;computational complexity theory	Prabhudev I. Hosur;Kai-Kuang Ma	1999		10.1109/MMSP.1999.793854	search engine indexing;mathematical optimization;approximation error;combinatorics;complex polygon;edge detection;visibility polygon;shoelace formula;shape;rectilinear polygon;computer science;star-shaped polygon;euclidean distance;mathematics;geometry;affine-regular polygon;monotone polygon;algorithmic efficiency;computational complexity theory;polygon covering;polygon triangulation;approximation algorithm;pick's theorem;algorithm;approximation theory	Vision	48.30746776303109	-62.373194971708095	69998
fced478a349d6df4078d110c6a38c006d4cef1ed	a simple and accurate camera calibration for the f180 robocup league	contraste;vision ordenador;metric;movie camera;robotics;high precision;robocup;high field;computer vision;camara;precision elevee;precision elevada;robotica;metrico;vision ordinateur;etalonnage;robotique;campo intenso;camera calibration;champ intense;calibration;metrique;camera	Camera calibration is a very important issue in computer vision each time extracting metrics from images is needed. The F180 camera league offers an interesting problem to solve. Camera calibration is needed to locate robots on the field with a very high precision. This paper presents a method specially created to easely calibrate a camera for the F180 league. The method is easy to use and implement, even for people not familiar with computer vision. It gives very acurate and efficient results.	camera resectioning	Ryad B. Benosman;Jerome Douret;Jean Devars	2001		10.1007/3-540-45603-1_30	smart camera;computer vision;camera auto-calibration;calibration;camera resectioning;simulation;metric;computer science;robotics;computer graphics (images)	Vision	49.72148351393203	-57.01818403177197	70233
9b8c2ea1f0abb2202db38bd84ecb928f2c316e0a	a robust algorithm for feature point matching	assignment problem;object recognition;image alignment;image matching;3d model;matrix computation;global optimization	 Proposed method – A new feature point matching algorithm • Main contributions – Choosing a feature response function that is different from the one given by Harris – Presenting a new constraint » Match strength – Extending the traditional assignment algorithm 3 3 /29 /29	algorithm;frequency response;harris affine region detector	Ji Zhou;Jiaoying Shi	2002	Computers & Graphics	10.1016/S0097-8493(02)00086-9	computer vision;mathematical optimization;feature detection;template matching;3-dimensional matching;cognitive neuroscience of visual object recognition;machine learning;optimal matching;mathematics;assignment problem;numerical linear algebra;feature;global optimization	Vision	50.240528746131275	-52.67364130227632	70290
5c1748e2db8545b32a38f8b4fa1fdb4234b0cc6e	automatic human face modeling in model-based facial image coding	model based reasoning;artificial neural networks automatic human face modeling model based facial image coding realistic 3d structure texture description 3d general wire frame facial model 2d image facial colour active contour models snakes;image coding;texture mapping;humans image coding face detection wire feature extraction color mouth eyes active contours artificial neural networks;face recognition model based reasoning feature extraction image coding;facial modeling;facial feature extraction;3d model;face recognition;feature extraction;face modeling;3d structure;active contour model;artificial neural network	The paper describes a method for automatically modelling the human face. The model provides a realistic 3D structure and texture description of a specific face for model-based facial image coding. The modelling process fits a 3D general wire frame facial model (WFM) to a 2D image using important features extracted from the image, and finally imposes facial colour by a texture mapping process. Our method is novel in two aspects. The facial-feature-extracting algorithm has been developed to automate the process of fitting the general WFM to the specific real facial image. This is done by locating the boundaries of the face, mouth, and eyes, using active contour models (snakes) guided by artificial neural networks. Secondly, by introducing face orientation detection during the fitting process, the facial model construction method is robust with respect to its ability to adjust the specific facial 3D model for arbitrary orientations.		Suhuai Luo;Robin W. King	1996		10.1109/ANZIIS.1996.573926	texture mapping;computer vision;feature extraction;computer science;model-based reasoning;machine learning;pattern recognition;active contour model;three-dimensional face recognition;artificial neural network;face hallucination	Vision	41.68245850501822	-53.996876627444344	70312
3bebff841ce7d40f0309bbc0e8cc454694061e82	segmenting scenes by matching image composites	data gathering;image compositing;image similarity	In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.	labelme;markov random field;sensor	Bryan C. Russell;Alexei A. Efros;Josef Sivic;Bill Freeman;Andrew Zisserman	2009			computer vision;scene statistics;computer science;machine learning;pattern recognition;mathematics;statistics;data collection	ML	45.81879886734401	-54.70314036308763	70470
d067ece7f43642a9d60d1978a670de3fe6beaf59	matching point features with ordered geometric, rigidity, and disparity constraints	intensity based matching algorithm;focusing;two dimensional geometrical relationships;rigidity test;detectors;feature detection;disparity constraints;image motion analysis;geometry computational complexity feature extraction image sequences;geometry;matching algorithm;testing;layout;indexing terms;three dimensional;computer vision;indoor images;computational complexity;feature extraction;heuristic tests;indoor images point features disparity constraints geometric constraints rigidity constraints matching algorithm feature detectors intensity based matching algorithm heuristic tests two dimensional geometrical relationships rigidity test disparity test epipolar line computational complexity;disparity test;rigidity constraints;sun;robustness;feature detectors;point features;geometric constraints;epipolar line;computer vision testing layout detectors geometry computational complexity focusing image motion analysis robustness sun;image sequences	1041 and then the line invariant (6) was computed for each pair of line sets and compared using the metric (7). The sets of lines chosen are given in the following table (refer to Fig. I). The table in (9) shows the results. The only bad entry in this matnx is in the position (4, 4). This is because of the fact that the four lines chosen,contained three coplanar lines (lines B. D and E). This causes the values of the invariant to be indeterminate (that is (0, 0, O)), and shows that such instances must be detected and avoided. Once again, the four-line invariant is shown to be a useful discriminator between sets of four lines. ACKNOWLEDGMENT I am indebted to J. Mundy for introducing me to the subject of projective invariants, and for many enlightening conversations during the preparation of this correspondence.	binocular disparity;discriminator;indeterminacy in concurrent computation	Xiaoping Hu;Narendra Ahuja	1994	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.329004	computer vision;mathematical optimization;computer science;feature detection;mathematics;geometry;feature	Vision	50.32320051622383	-54.41827221605509	70494
7d22fd5a57387fe92740cf3c59375a23972b6b13	a hierarchical approach to high-quality partial shape registration	image resolution;shape recognition;shape kernel feature extraction heat recovery computer graphics educational institutions;image registration;multi resolution method high quality partial shape registration hierarchical shape registration algorithm coarse to fine manner local shape parameterization isometric deformation;shape recognition image registration image resolution	This paper presents a feature-driven, hierarchical shape registration algorithm. The central idea is to generate correspondences in multiple levels in a coarse-to-fine manner, with additional features incrementally inserted in each level. The registration starts from the coarsest resolution. Registration results obtained in one level serve as references for the registration in the next level. We adopt the heat kernel coordinates [3] for local shape parameterization, giving rise to a complete solution capable of registering partial shapes undergoing isometric deformation with higher accuracy. Through experiments, we demonstrate the effectiveness of this multi-resolution method and its advantages over the single-resolution method.	algorithm;experiment;isometric projection	Ming Zhong;Tingbo Hou;Hong Qin	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		active shape model;computer vision;image resolution;computer science;image registration;heat kernel signature;mathematics;computer graphics (images)	Vision	52.56604843959592	-53.293906006103875	70542
a25c91e044f7f89100bf5bafd26cd883572b6bbb	indoor-outdoor image classification	image features;texture;scene classification;image resolution;query processing;image classification layout histograms computer vision image databases image retrieval color discrete cosine transforms diversity reception spatial databases;color space;software performance evaluation;image classification;color histogram;autoregressive model;sar;statistical analysis;discrete cosine transforms;image colour analysis;indoor;outdoor;software performance evaluation image classification visual databases query processing image colour analysis image resolution statistical analysis discrete cosine transforms;kodak consumer image database indoor outdoor image classification high level scene properties low level image features indoor outdoor scene retrieval histograms ohta color space multiresolution simultaneous autoregressive model shift invariant dct performance stacking single feature methods;shift invariant;visual databases;image retrieval	We show how high level scene properties can be in ferred from classi cation of low level image features speci cally for the indoor outdoor scene retrieval prob lem We systematically studied the features his tograms in the Ohta color space multiresolution si multaneous autoregressive model parameters coef cients of a shift invariant DCT We demonstrate that performance is improved by computing features on sub blocks classifying these subblocks and then combining these results in a way reminiscent of stacking State of the art single feature methods are shown to result in about performance while the new method re sults in correct classi cation when evaluated on a diverse database of over consumer images provided by Kodak	autoregressive model;color space;computer vision;discrete cosine transform;high-level programming language;stacking	Martin Szummer;Rosalind W. Picard	1998		10.1109/CAIVD.1998.646032	computer vision;computer science;pattern recognition;computer graphics (images)	Vision	39.296845294987236	-60.56423844960783	70723
693def182d56b7d4cd875e5da68d8fe4bbfb09b0	a structure-preserved local matching approach for face recognition	reconnaissance visage;traitement signal;evaluation performance;performance evaluation;image processing;biometrie;evaluacion prestacion;biometrics;database;biometria;procesamiento imagen;base dato;metodo subespacio;traitement image;methode sous espace;algorithme;algorithm;local matching;automatic recognition;face recognition;feature extraction;signal processing;base de donnees;structure preserved projections;pattern recognition;structure preservation;subspace method;reconnaissance forme;extraction caracteristique;reconocimiento patron;procesamiento senal;reconocimiento automatico;reconnaissance automatique;matching method;algoritmo	In this paper, a novel local matching method called structure-preserved projections (SPP) is proposed for face recognition. Unlike most existing local matching methods which neglect the interactions of different sub-pattern sets during feature extraction, i.e., they assume different sub-pattern sets are independent; SPP takes the holistic context of the face into account and can preserve the configural structure of each face image in subspace. Moreover, the intrinsic manifold structure of the sub-pattern sets can also be preserved in our method. With SPP, all sub-patterns partitioned from the original face images are trained to obtain a unified subspace, in which recognition can be performed. The efficiency of the proposed algorithm is demonstrated by extensive experiments on three standard face databases (Yale, Extended YaleB and PIE). Experimental results show that SPP outperforms other holistic and local matching methods.	facial recognition system	Jianzhong Wang;Zhiqiang Ma;Baoxue Zhang;Miao Qi;Jun Kong	2011	Pattern Recognition Letters	10.1016/j.patrec.2010.11.014	computer vision;image processing;feature extraction;computer science;artificial intelligence;signal processing;algorithm;biometrics	Vision	44.66134784416052	-59.581719661659704	70854
20be8e307ddc4c1c7d439e27203119ccdbb043d3	bayesian selection of the neighbourhood order for gauss-markov texture models	neighbourhood order;information retrieval;texture synthesis;image database;gauss markov random fields;spatial interaction;image classification;posterior probability;gauss markov random field;classification;model complexity;higher order;statistical properties;institut fur methodik der fernerkundung;gaussian approximation;bayesian model selection;machine vision;feature extraction;query by image content	9 Gauss–Markov random fields have been successfully used as texture models in a host of applications, ranging from 10 synthesis, feature extraction, classification and segmentation to query by image content and information retrieval in 11 large image databases. An issue that deserves special consideration is the selection of the neighbourhood order (model 12 complexity), which should faithfully reflect the Markovianity of spatial interactions. Estimating the parameters for the 13 wrong model will not capture the essential statistical properties of the texture in question: a lower order model will not 14 be informative enough, while a higher order will clutter the description with superfluous information, fitting the noise 15 rather than the data. 16 We give a full Bayesian solution for estimating the model complexity, using an appropriate set of prior probabilities 17 on the parameters. The closed-form decision criterion is derived by employing a Gaussian approximation of the posterior 18 probability around the mode. The validity and benefits of this approach are demonstrated on two important problems 19 arising in machine vision: texture replication and image classification. 2002 Published by Elsevier Science B.V.	approximation;clutter;computer vision;content-based image retrieval;database;feature extraction;information retrieval;interaction;machine vision;markov chain;markov random field	S. Stan;Gintautas Palubinskas;Mihai Datcu	2002	Pattern Recognition Letters	10.1016/S0167-8655(02)00070-3	computer vision;contextual image classification;higher-order logic;machine vision;feature extraction;biological classification;computer science;machine learning;pattern recognition;mathematics;posterior probability;texture synthesis;statistics	Vision	40.599739976775794	-62.61009952711326	70866
184dadebe63a33e57886cbe72e14bb2322753908	feature localization and search by object model under illumination change	databases;image recognition;object recognition;reconocimiento imagen;illumination;localization;localizacion;methode;task difficulty;light;algorithme;dificultad tarea;variations;chromaticity;algorithm;difficulte tâche;localisation;matrices;luz;indexing;indexation;least square;reconnaissance image;indizacion;chromaticite;algorithms;cromaticidad;variacion;variation;lumiere;imagen color;metodo;eclairement;method;image couleur;color image;alumbrado;object model;algoritmo;image retrieval	Color object recognition methods that are based on image retrieval algorithms can handle changes of illumination via image normalization, e.g. simple color-channel-normalization or by forming a doubly-stochastic image matrix. However these methods fail if the object sought is surrounded by clutter. Rather than directly trying to nd the target, a viable approach is to grow a small number of feature regions called locales. These are de ned as a nondisjoint coarse localization based on image tiles. In this paper, locales are grown based on chromaticity, which is more insensitive to illumination change than is color. Using a diagonal model of illumination change, a least-squares optimization on chromaticity recovers the best set of diagonal coe cients for candidate assignments from model to test locales stored in a database. If locale centroids are also stored then, adapting a displacement model to include model locale weights, transformed pose and scale can be recovered. Tests on databases of real images show promising results for object query.	algorithm;clutter;color;database;displacement mapping;image retrieval;least squares;mathematical optimization;outline of object recognition	Mark S. Drew;Zinovi Tauber;Ze-Nian Li	2000		10.1117/12.373572	computer vision;mathematics;cartography;computer graphics (images)	Vision	48.605488855688094	-59.07037704082977	71198
af42cc46f93bc9cf413770af4f7243f54a31336e	evaluating the performance of table processing algorithms	acoplamiento grafo;detection forme;algorithm performance;document analysis;performance evaluation;mesa;optical character recognition;edit distance;shape detection;graph matching;document understanding;form defect;deteccion forma;couplage graphe;reconnaissance caractere;resultado algoritmo;traitement document;analyse performance;performance analysis;table;performance algorithme;pattern recognition;completitud;ground truth;document processing;reconnaissance forme;defaut forme;completeness;defecto forma;reconocimiento patron;completude;character recognition;reconocimiento caracter;tratamiento documento;analisis eficacia	While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, “graph probing,” for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well.	algorithm;directed acyclic graph;document object model;experiment;feedback;graph edit distance;ground truth;hash table;optical character recognition;performance evaluation;programming paradigm	Jianying Hu;Ramanujan S. Kashi;Daniel P. Lopresti;Gordon T. Wilfong	2002	International Journal on Document Analysis and Recognition	10.1007/s100320200074	decision table;speech recognition;document processing;edit distance;ground truth;completeness;computer science;artificial intelligence;table;optical character recognition;algorithm;statistics;matching	Vision	47.83696874864492	-59.47927381740247	71322
27275a17acb02d36915a8b2e148e47eba58cb6e1	a fuzzy scale-space approach to feature-based image representation and retrieval	busqueda informacion;teoria imagen;analisis imagen;modelizacion;image features;texture;image theory;image processing;recherche image;methode echelle multiple;information retrieval;theorie image;extraction forme;logique floue;multiscale analysis;gradiente;image database;procesamiento imagen;logica difusa;image indexing;metodo escala multiple;intelligence artificielle;espacio escala;gradient;traitement image;fuzzy logic;unified model;modelisation;scale space;analisis morfologico;extraccion forma;indexing;recherche information;image representation;feature extraction;indexation;textura;morphological analysis;indizacion;pattern recognition;analyse morphologique;artificial intelligence;image analysis;multiscale method;inteligencia artificial;reconnaissance forme;extraction caracteristique;reconocimiento patron;modeling;analyse image;pattern extraction;espace echelle;image retrieval	We propose an image indexing and retrieval method which is based on the multiscale image analysis theory in conjunction with fuzzy image feature extraction. The main idea is based on the assumption that the fundamental cues for image description such as shape and textures should be considered together within a unified model. Here the multiscale analysis is modeled by a differential morphological filter, and the feature are extracted by a multiscale fuzzy gradient operation applied to the detail images, which are the differences between images at successive scales. Experiments with large image databased and comparisons with classical methods are reported.	scale space	Michele Ceccarelli;Francesco Musacchia;Alfredo Petrosino	2005		10.1007/11565123_36	fuzzy logic;computer vision;search engine indexing;feature detection;visual word;scale space;image analysis;systems modeling;image processing;feature extraction;image retrieval;morphological analysis;computer science;artificial intelligence;unified model;mathematics;texture;gradient;feature;algorithm	Vision	43.66601308940955	-61.57083092327741	71662
c80617c8fc5bacfacebe1aa17a22c411c16eb87d	solving three-dimensional small-rotation motion equations: uniqueness, algorithms, and numerical results	image processing;motion;traitement image;three dimensional;mouvement;image analysis;rotation;analyse image;sequence image	In the first part of this paper, a theorem on the uniqueness of the solution to a set of overdetermined nonlinear equations obtained by T. S. Huang and R. Y. Tsai [l] for approximately determining 3-D motion parameters when the rotation angle is small is presented. The main result is that if nine points which are not on a second-order surface passing through the viewing point, are correspondingly selected from two sequential images of a moving object, then the solution of the motion equations can be uniquely determined. In the second part, the practical aspects of solving these overdetermined nonlinear equations are discussed. A modified Newton method for solving nonlinear equations and a modified Levenberg-Marquardt method for solving the nonlinear least-squares problem, which are better than the original Newton and Levenberg-Marquardt methods when applied to the problem of motion estimation, are proposed. The effects on convergence and solution accuracy of the number of corresponding image point pairs, the geometrical configuration of the points in object space, the distance of the object from the image plane, the initial guess solution, and image resolution are also studied experimentally.	3d computer graphics;experiment;image plane;image resolution;least squares;levenberg–marquardt algorithm;motion estimation;newton;newton's method;nonlinear system;numerical analysis;tuple space;uniqueness type	Jia-Qi Fang;Thomas S. Huang	1983	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(84)90182-8	three-dimensional space;computer vision;mathematical optimization;mathematical analysis;image analysis;image processing;rotation;computer science;motion;motion estimation;mathematics;geometry;motion field	Vision	50.78300579505189	-56.92560050217858	71794
e7a0cd3ee1c2b1ced1a165bd3339c27fcdfff49f	fast image matching algorithm based on template partitioning and subtemplate matching	template partitioning;image processing;image matching;pixel grey value;subtemplate matching;computational complexity	Matching algorithms based on pixel grey value are very popular and widely used in image matching. However, these algorithms have high time complexity and are sensitive to the size of image. To reduce the time complexity and sensitivity to the size of image of the matching algorithms based on pixel grey value, a fast image matching algorithm based on template partitioning and subtemplate matching is proposed. The algorithm divides the template into multiple subtemplates, then the eigenvalue of every subtemplate is calculated and the optimal one is chosen when the difference between the eigenvalues of the subtemplates and the subimage is minimum, and finally the best matching position for the reference image is determined by adopting non-ergodic search during image matching processing. The algorithm’s time complexity is reduced to 2 2 (( 1) ) O S N N    . Experimental results show that the proposed algorithm is superior to the circular projection algorithm and the NCC algorithm and has low computational complexity.	algorithm;computational complexity theory;ergodicity;fast fourier transform;image registration;jump search;neural correlates of consciousness;pixel;time complexity	Zhaoming Wu;Chengzhi Deng;Xiaowei Sun	2015	IJWMC	10.1504/IJWMC.2015.070943	template matching;image processing;computer science;theoretical computer science;machine learning;pattern recognition;computational complexity theory	Vision	42.302154677352625	-58.34058862151969	72050
831b542cd6508154c989a1ed833e54d8dbe78afe	motion capture of arm from a monocular image sequence	motion analysis;analisis imagen;vision ordenador;estimation mouvement;image segmentation;image processing;estimacion movimiento;procesamiento imagen;motion estimation;traitement image;computer vision;motion capture;image sequence;segmentation image;image analysis;vision ordinateur;analyse image;voronoi diagram	The paper develops a new motion capture method from a monocular sequence of 2D perspective images. Our starting point is arm motion. We first extract and track the feature points from image sequence based on watershed seqmentation and Voronoi diagram, then by rigidity constraint and motion modelling constraint we use motion analysis method to yield 3D information of feature points. Finally the obtained data is attuned to simulate motion of model. A experiment with real images are included to demonstrate the validity of the theoretic results.		Chunhong Pan;Songde Ma	1999		10.1007/3-540-48762-X_44	computer vision;motion capture;image analysis;voronoi diagram;image processing;computer science;motion estimation;image segmentation;motion field;computer graphics (images)	Vision	49.670770027911026	-57.744117292781795	72185
794acc97fa993b7829b362e7f505bb511efd1b91	iterative closest sift formulation for robust feature matching	iterative method;vision ordenador;image processing;scale transformation;procesamiento imagen;feature matching;traitement image;transformation echelle;computer vision;metodo iterativo;scale invariant feature transform;methode iterative;iterative closest point;invariante;vision ordinateur;transformacion escala;invariant	This paper presents a new feture matching algorithm. The proposed algorithm integrates the Scale Invariant Feature Transform (SIFT) local descriptor in the Iterative Closest Point (ICP) scheme. The new algorithm addresses the problem of finding the appropriate match between repetitive patterns that appear in manmade scenes. The matching of two sets of points is computed integrating appearance and distance properties between putative match candidates. To demonstrate the performance of the new algorithm, the new approach is applied on real images. The results show that the proposed algorithm increases the number of correct feature correspondences and at the same time reduces significantly matching errors when compared to the original SIFT and ICP algorithms.	iterative method	Rafael Lemuz-López;Miguel Arias-Estrada	2006		10.1007/11919629_51	computer vision;image processing;computer science;machine learning;invariant;pattern recognition;scale-invariant feature transform;mathematics;iterative method;iterative closest point	Vision	48.72677834723083	-59.00622663406488	72304
677f1f52b601027378fb9f39a02582f065396c7b	a note on minimum error thresholding	entropia;entropy expression;image processing;seuil;teoria shannon;procesamiento imagen;threshold;segmentation;traitement image;error threshold;minimo;minimum;shannon theory;entropie;theorie shannon;entropy;umbral;critere erreur;minimum error thresholding;segmentacion	Image thresholding based on gray level histogram information is a simple and important technique for segmentation, whose purpose is to identify the regions of image objects correctly. Kittler and Illingworth [1] introduced a subtle thresholding method named minimum error threshoMing in which appropriate thresholds are selected by the minimum error criterion. Its criterion is designed to minimize the classification error probability approximately on condition that histograms are governed by a mixture of Gaussian densities. Ye and Danielsson [2] also provided another derivation of the criterion by using the correlation. In this note, introducing an additive Gaussian noise channel, we present a new expression of the minimum error criterion by the Shannon entropy [3]. Compared to the other thresholding methods using the entropy [4, 5], it is interesting that its expression has a different form. Suppose that we treat a set A of discrete images in which each image has N gray levels and it is composed of two classes Cl, C2, i.e., objects and their background or vice versa. To extract the objects from the background, we deal with a thresholding process in which pixels are classified into Ci or C2 by thresholding the gray levels of pixels on the basis of histogram information. We use the following pixel classification: Assign pixels satisfying (gray level) ~< t to C l ; assign the other pixels to c2. The derivation of the minimum error criterion begins with assuming that the set ~ of normalized histograms corresponding to A is governed by a mixture of Gaussian probability densities given by	entropy (information theory);friedrich kittler;grayscale;pixel;shannon (unit);thresholding (image processing);utility functions on indivisible goods	Fujiki Morii	1991	Pattern Recognition Letters	10.1016/S0167-8655(05)80004-2	entropy;image processing;calculus;mathematics;statistics	Vision	46.41572276070769	-64.13761294666007	72328
f53dfbb0423582ae6a4e395379ab8d1dcd749a2a	the hough transform versus the upwrite	complex objects;upwrite;randomized hough transform;speckle noise;testing speckle object detection pixel noise robustness web sites histograms image segmentation solid modeling covariance matrix;probabilistic hough transform;hierarchical hough transform;feature extraction;feature extraction hough transforms noise;hough transforms;hough transform;speckle noise hough transform upwrite line detection circle detection ellipse detection noisy images perturbation noise;noise	This paper compares the Hough Transform and the UpWrite for the detection of lines, circles, and ellipses. Both ideal and noisy images are tested. The UpWrite is found to be more robust for images containing perturbation noise. For ideal images and images with speckle noise, the results are found to depend on the complexity of the object being detected, with more complex objects favoring the UpWrite. A program allowing the reader to experiment with these algorithms can be found at the following World Wide Web address: http://ciips.ee.uwa.edu.au/Papers/Journal_Papers/1998/02/Index.html.	algorithm;hough transform;noise shaping;vector graphics editor;www;world wide web	Robert A. McLaughlin;Michael D. Alder	1998	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.677267	hough transform;speckle noise;computer vision;speech recognition;feature extraction;computer science;noise;pattern recognition;scale-invariant feature transform;mathematics	Vision	48.390617991712226	-65.935324349502	72568
5f7fe9631d892fd5e9819a2b1080cfa620e924fe	automatic on-the-fly extrinsic camera calibration of onboard vehicular cameras	street;contraste;interfase usuario;vision ordenador;realite virtuelle;onboard vehicular cameras;realidad virtual;securite;conduccion vehiculo;user interface;traffic lane;voie circulation;virtual reality;conduite vehicule;infraestructura transporte;virtual road signs;a la volee;road signalling;infrastructure transport;vehicle driving;senalizacion trafico;systeme information trafic;signalisation routiere;experimental result;computer vision;user assistance;realite augmentee;realidad aumentada;assistance utilisateur;traffic information systems;route;video cameras;marquage chaussee;image sequence;asistencia usuario;safety;camera video;resultado experimental;on the fly;carretera;interface utilisateur;vision ordinateur;etalonnage;secuencia imagen;highway;maquina fotografica;al vuelo;camera calibration;augmented reality;transportation infrastructure;resultat experimental;calle;camara de video;seguridad;rue;marcacion calzada;carriageway marking;calibration;lane detection;appareil photographique;sequence image;camera;driver assistance system;virtual camera;via trafico	This paper presents an on-the-fly procedure for obtaining extrinsic camera parameters of onboard vehicular cameras, as well as augmented reality applications for driver assistance systems and road inspection. The proposed approach employs a lane detection algorithm to extract the lane boundaries of the road, and estimates the distance between adjacent lane markings based on the speed of the vehicle. Then, a rectangular portion of the road is used to obtain the desired extrinsic camera parameters. With the complete set of camera parameters, virtual objects can be coherently inserted into the video sequence captured by the camera, so that synthetic traffic signs may be added to increase safety. Experimental results illustrate the performance of the proposed camera calibration systems, as well as possible applications involving augmented reality. 2013 Elsevier Ltd. All rights reserved.	approximation error;ar (unix);augmented reality;camera resectioning;coherence (physics);dijkstra's algorithm;experiment;glossary of computer graphics;motion estimation;round-off error;synthetic data;vanishing point;yaws	Mauricio Braga de Paula;Cláudio Rosito Jung;L. G. da Silveira	2014	Expert Syst. Appl.	10.1016/j.eswa.2013.08.096	smart camera;route;embedded system;computer vision;camera auto-calibration;augmented reality;calibration;camera resectioning;simulation;computer science;virtual reality;user interface	Vision	48.992064033890884	-56.740717196272314	72864
38af17bfe49f35b592d6b3a0576db52137a729ab	recognition of single 3d curved objects using 2d cross-sectional slice shapes	cross section;article	In this paper a new approach to recognition of single 3D curved objects is proposed. Horizontal cross-sectional slice shapes are used for 3D object representation. 3D object recognition is accomplished by matching the cross-sectional slice shapes of an input object with those of each object model. Thus, 2D image analysis techniques can be used for slice shape matching, including the use of the distance-weighted correlation for shape similarity measurement and the construction of a decision tree for decision-making. Instead of computing all the slice shapes for each input object in the recognition process, only those involved in the decision tree are computed by a data acquisition system. This increases recognition speed. Experimental results with a high recognition rate prove the feasibility of the proposed approach.	3d single-object recognition;cross-sectional data;data acquisition;decision tree;image analysis;outline of object recognition	Meng-Chien Yang;Wen-Hsiang Tsai	1989	Image Vision Comput.	10.1016/0262-8856(89)90046-2	computer vision;computer science;machine learning;shape analysis;cross section;3d single-object recognition	Vision	41.593400378915554	-57.802712941318866	73168
fa03361c9718899894da9db8b27182a78a547342	background updating for visual surveillance	modelizacion;subtraction;moving object;tabla codificacion;vision ordenador;background modeling;analisis escena;analyse scene;modeling technique;mise a jour;image processing;surveillance;sustraccion;procesamiento imagen;soustraction;traitement image;computer vision;actualizacion;modelisation;visual surveillance;vigilancia;monitoring;codebook;table codage;background subtraction;court terme;vision ordinateur;monitorage;monitoreo;modeling;corto plazo;short term;updating;scene analysis	Scene changes such as moved objects, parked vehicles, or opened/closed doors need to be carefully handled so that interesting foreground targets can be detected along with the short-term background layers created by those changes. A simple layered modeling technique is embedded into a codebook-based background subtraction algorithm to update a background model. In addition, important issues related to background updating for visual surveillance are discussed. Experimental results on surveillance examples, such as unloaded packages and unattended objects, are presented by showing those objects as short-term background layers.	algorithm;background subtraction;codebook;embedded system;experiment;stationary process	Kyungnam Kim;David Harwood;Larry S. Davis	2005		10.1007/11595755_41	computer vision;speech recognition;systems modeling;background subtraction;subtraction;image processing;computer science;codebook;short-term memory	Vision	47.37743747510551	-57.202607722870965	73384
b568e3d010f4082f4f67b31a4a024ee8692b72db	hyperbolization of euclidean ornaments		In this article we outline a method that automatically transforms an Euclidean ornament into a hyperbolic one. The necessary steps are pattern recognition, symmetry detection, extraction of a Euclidean fundamental region, conformal deformation to a hyperbolic fundamental region and tessellation of the hyperbolic plane with this patch. Each of these steps has its own mathematical subtleties that are discussed in this article. In particular, it is discussed which hyperbolic symmetry groups are suitable generalizations of Euclidean wallpaper groups. Furthermore it is shown how one can take advantage of methods from discrete differential geometry in order to perform the conformal deformation of the fundamental region. Finally it is demonstrated how a reverse pixel lookup strategy can be used to obtain hyperbolic images with optimal resolution.	fundamental domain;lookup table;pattern recognition;pixel	Martin von Gagern;Jürgen Richter-Gebert	2009	Electr. J. Comb.		euclidean domain;hyperbolic manifold;hyperbolic equilibrium point;combinatorics;hyperbolic coordinates;topology;hyperbolic space;euclidean distance;mathematics;geometry;euclidean distance matrix;hyperbolic tree;algebra	Vision	49.75292325769383	-62.293957940597956	73541
d6d6e81ae28b04a9fea2dd8459e77bf588144a5b	on improving the accuracy of the hough transform	mejoramiento procedimiento;tratamiento paralelo;straight shape;image processing;forme rectiligne;measurement;traitement parallele;localizacion objeto;deteccion;object location;forma rectilinea;procesamiento imagen;least square method;detection;line detection;high precision;traitement image;amelioration procede;medida;precision elevee;least square;precision elevada;hough transform;transformation hough;process improvement;mesure;parameter estimation;localisation objet;parallel processing	The subject of this paper is very high precision parameter estimation using the Hough transform. We identify various problems that adversely affect the accuracy of the Hough transform and propose a new, high accuracy method that consists of smoothing the Hough arrayH(ρ, θ) prior to finding its peak location and interpolating about this peak to find a final sub-bucket peak. We also investigate the effect of the quantizations Δρ and Δθ ofH(ρ, θ) on the final accuracy. We consider in detail the case of finding the parameters of a straight line. Using extensive simulation and a number of experiments on calibrated targets, we compare the accuracy of the method with results from the standard Hough transform method of taking the quantized peak coordinates, with results from taking the centroid about the peak, and with results from least squares fitting. The largest set of simulations cover a range of line lengths and Gaussian zero-mean noise distributions. This noise model is ideally suited to the least squares method, and yet the results from the method compare favorably. Compared to the centroid or to standard Hough estimates, the results are significantly better—for the standard Hough estimates by a factor of 3 to 10. In addition, the simulations show that as Δρ and Δθ are increased (i.e., made coarser), the sub-bucket interpolation maintains a high level of accuracy. Experiments using real images are also described, and in these the new method has errors smaller by a factor of 3 or more compared to the standard Hough estimates.	estimation theory;experiment;high-level programming language;hough transform;interpolation;least squares;simulation;smoothing	Wayne Niblack;Dragutin Petkovic	1990	Machine Vision and Applications	10.1007/BF01212193	hough transform;parallel processing;computer vision;image processing;computer science;mathematics;least squares;statistics	Vision	51.66824517211019	-59.199899140860445	73573
1dea91ed4be19c47451dd1d21f031eaf1ad7eebf	manhattan-pyramid distance: a solution to an anomaly in pyramid matching by minimization	minimisation;image resolution;object detection computer vision image matching image resolution minimisation;image matching;image datasets manhattan pyramid distance pyramid matching minimization computer vision field classification approaches multiresolution measurement mpd systematic evaluations instance based object classification;computer vision;minimization histograms vectors shape extraterrestrial measurements computer vision standards;object detection	In the field of computer vision, pyramid matching by minimization has gained increasing popularity. This paper points out and discusses an inherent anomaly in pyramid matching by minimization that can affect the performance of classification approaches based on this type of matching. As a solution, a new multiresolution measure, called Manhattan-Pyramid Distance (MPD), is proposed. Systematic evaluations are carried out at the task of instance-based object classification on four object image datasets. Results show that MPD improves object classification performance with respect to a standard approach based on pyramid matching by minimization.	anomaly detection;computer vision;experiment	Aneesh Chauhan;Luís Seabra Lopes	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer vision;minimisation;pyramid;image resolution;computer science;machine learning;pattern recognition;mathematics	Vision	39.989435075038756	-54.717379713093685	73586
16762923de7cf03d26e2007e04baaaf01bc2ca4a	ror: rejection of outliers by rotations	estimation theory;robustness impedance matching computational efficiency computer errors image matching testing web sites computer vision pixel layout;image matching;ror algorithm;correspondence problem;feature matching;robust estimation;computer vision;false matches;outliers;image rotations;estimation theory computer vision image matching feature extraction;machine vision;feature extraction;robust estimation outlier rejection false matches image rotations image matching ror algorithm feature extraction;outlier rejection	ÐWe address the problem of rejecting false matches of points between two perspective views. The two views are taken from two arbitrary, unknown positions and orientations. Even the best algorithms for image matching make some mistakes and output some false matches. We present an algorithm for identification of the false matches between the views. The algorithm exploits the possibility of rotating one of the images to achieve some common behavior of the correct matches. Those matches that deviate from this common behavior turn out to be false matches. Our algorithm does not, in any way, use the image characteristics of the matched features. In particular, it avoids problems that cause the false matches in the first place. The algorithm works even in cases where the percentage of false matches is as high as 85 percent. The algorithm may be run as a postprocessing step on output from any point matching algorithm. Use of the algorithm may significantly improve the ratio of correct matches to incorrect matches. For robust estimation algorithms which are later employed, this is a very desirable quality since it reduces significantly their computational cost. We present the algorithm, identify the conditions under which it works, and present results of testing it on both synthetic and real images. The code for the algorithm is available through the World Wide Web. Index TermsÐCorrespondence problem, feature matching, false matches, outliers, outlier rejection, robust estimation.	algorithmic efficiency;approximation algorithm;computation;image registration;mean shift;orientation (graph theory);preprocessor;rejection sampling;robustness (computer science);sampling (signal processing);synthetic intelligence;world wide web	Amit Adam;Ehud Rivlin;Ilan Shimshoni	2001	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.899948	computer vision;outlier;machine vision;feature extraction;computer science;machine learning;pattern recognition;mathematics;correspondence problem;estimation theory;statistics	Vision	45.966668660248075	-53.42801164103174	73680
334f36bc6c13ae943d2f72ba52e8ec00cfe744d3	credence estimation and error prediction in biometric identity verification	evaluation performance;control de calidad;biometric identity verification;enfoque credal;performance evaluation;biometrie;evaluacion prestacion;biometrics;biometria;credal approach;automatic recognition;evaluation subjective;estimation erreur;error estimation;erreur estimation;estimacion error;statistical pattern recognition;error handling;pattern recognition;controle qualite;error estimacion;reconnaissance forme;estimation error;quality measures;reconocimiento patron;quality control;subjective evaluation;approche credibiliste;credence;traitement erreur;reconocimiento automatico;reconnaissance automatique;evaluacion subjetiva	This paper focuses on the estimation of credence in the correctness of classification decisions produced by a biometric identity verification system. We adopt the concept of decision credence defined in terms of subjective Bayesian degree of belief. We demonstrate how credence estimates can be used to predict verification errors and to rectify them, thus improving the classification performance. We also show how the framework of credence estimation helps handle erroneous classification decisions thanks to seamless incorporation of quality measures. Further, we demonstrate that credence information can be effectively applied to perform fusion of decisions in a multimodal scenario. r 2007 Elsevier B.V. All rights reserved.	authentication;biometrics;correctness (computer science);data structure;discretization;error message;fingerprint;identity verification service;multimodal interaction;protein structure prediction;rectifier;relevance;seamless3d	Krzysztof Kryszczuk;Andrzej Drygajlo	2008	Signal Processing	10.1016/j.sigpro.2007.10.007	exception handling;econometrics;quality control;computer science;artificial intelligence;computer security;biometrics	Vision	45.38650288610913	-60.589546233148155	73916
2ba753e7c21e8c53a5b7bea55eccbc9fe9f71255	intrinsic line features and contour metric for locating 3-d objects in sparse, segmented range images	image tridimensionnelle;object recognition;sistema experto;architecture systeme;time of flight;image processing;edge detection;noisy data;localization;intrinsic feature;procesamiento imagen;laser scanner;pairing;localizacion;traitement image;deteccion contorno;detection contour;contour metric;multiple objectives;localisation;range image;pattern recognition;tridimensional image;arquitectura sistema;reconnaissance forme;emparejamiento;systeme expert;reconocimiento patron;system architecture;appariement;direct method;imagen tridimensional;expert system	This paper presents a new, direct method for locating 3-D objects reliably from sparse, noisy data: segmented range images with polygonal patch boundaries. Non-iterative locating methods require accurate point correspondences, and do not tolerate significant occlusion. Therefore, we propose rules to select intrinsic contours relevant to the locating task in a multiple-object configuration. For matching intrinsic boundaries and finding correspondences, we develop a 3-D version of Arkin’s contour metric using the signatures of turning and torsion angles, and extend it to contours consisting of multiple parts. The metric is robust to quantization and segmentation errors. We integrate the method into a complete system for 3-D object recognition and report on experience gained from a gantry robot test site equipped with timeof-flight laser scanners. q 1999 Elsevier Science Ltd. All rights reserved.	apache axis;autonomous robot;cartesian coordinate robot;computer-aided design;direct method in the calculus of variations;feedback;image analysis;instability;iterative method;least squares;maximal set;model-driven integration;numerical stability;outline of object recognition;patch (computing);pixel;quantization (signal processing);range imaging;real-time transcription;relevance;signal-to-noise ratio;sparse matrix;torsion (gastropod);type signature	Peter Kohlhepp;Daniel Fischer;Ekkehard Hoffmann	1999	Image Vision Comput.	10.1016/S0262-8856(98)00129-2	laser scanning;direct method;computer vision;time of flight;edge detection;internationalization and localization;image processing;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;pairing;mathematics;expert system	Robotics	49.11451855635081	-58.07727427018722	74056
d5e52f34fb53a0ed63d0b1a99e2d654b36d5d1cc	model-based joint motion and structure estimation from stereo images	modelizacion;discontinuity;optimisation;discontinuite;movimiento;algorithm performance;image processing;optimizacion;etude experimentale;image matching;estructura;procesamiento imagen;stereoscopy;motion;traitement image;finite element;algorithme;modelisation;algorithm;reconstruction image;triangulacion;reconstruccion imagen;resultado algoritmo;smoothing;image reconstruction;mouvement;performance algorithme;alisamiento;superficie;stereoscopie;surface;optimization;estereoscopia;triangulation;discontinuidad;structural estimation;modeling;estudio experimental;structure;lissage;algoritmo	in order to exploit their coherence. We propose an algorithm gulation error modeling [5–9]. However, the steps of mothat uses models for object surfaces and their motion and estition and structure estimation remain disjoint. mates the model parameters using the image intensity matching Structure estimation mainly involves correspondence criterion. The visible scene surface is represented with a paraanalysis, interpolation of usually sparse disparity values metrically deformable, spatially adaptive, wireframe model. and surface reconstruction [10, 11]. The accuracy of the Object motion is first modeled using the well-known rigid moreconstructed surface depends highly on the estimated distion assumption along with the quaternion rotation representaparity field [12]. Methods for finding correspondences in tion. Nonrigid motion modeling using the finite element techstereo images may be classified as feature based and area nique is also investigated as an alternative to rigid motion based [13], while recently there is a trend to combine these modeling or as a refinement of it. A functional containing image methods [14, 15]. matching and surface smoothness constraints is minimized with respect to the unknown model parameters. A discontinuity In our approach we integrate motion and structure estidetection scheme allowing deactivation of smoothness conmation in order to exploit their coherence. The correlation straints across object boundaries, is investigated. A regularizaof binocular flows and stereo disparity is considered in [16] tion scheme using a coarse to fine strategy is employed.  1997 in an attempt to coherently estimate motion and structure.	algorithm;binocular disparity;binocular vision;finite element method;interpolation;quaternions and spatial rotation;refinement (computing);reflections of signals on conducting lines;sparse dictionary learning;sparse matrix;whole earth 'lectronic link;wire-frame model	Sotiris Malassiotis;Michael G. Strintzis	1997	Computer Vision and Image Understanding	10.1006/cviu.1996.0481	iterative reconstruction;stereoscopy;computer vision;structure;mathematical optimization;structure from motion;systems modeling;image processing;triangulation;computer science;discontinuity;motion;finite element method;motion estimation;mathematics;geometry;motion field;surface;smoothing	Vision	51.274964539672	-56.68868338431706	74103
4481e87e72cf33fa22c4e8765d05297f5e4a16d4	detection of the mandibular canal in orthopantomography using a gabor-filtered anisotropic generalized hough transform	gabor transform;generalized hough transform;mandibular canal	In this paper, we explore the possibility of applying the anisotropic generalized Hough transform (AGHT) enhanced with a Gabor based time-frequency filtering (GTF) for the determination of the mandibular canal in digital dental panoramic radiographs. The proposed method is based on template matching using the fact that the shape of the mandibular canal is usually the same, followed by a filtering of the accumulator space in the Gabor domain for a precise detection of the position. The proposed procedure consists of a detailed description of the shape of the canal in its canonical form and on preserving Gabor filtering information for sorting the hierarchy of location candidates after applying anisotropically the extraction algorithm. The experimental results show that the proposed procedure is robust to recognition under occlusion and under the presence of additional structures e.g. teeth, projection errors.		Darian Onchis-Moaca;Simone Zappalá;Smaranda Laura Gotia;Pedro Real Jurado;Marius Pricop	2016	Pattern recognition letters	10.1016/j.patrec.2015.12.001	computer vision;speech recognition	Vision	39.56896110229371	-64.5949483971712	74191
0ac086bac423bd058fa6e47b85159f95f74c541e	image fusion using steerable dyadic wavelet transform	arbitrary orientations;scale position;input image;image fusion;multiscale analysis;wavelet transforms;image fusion wavelet transforms filter bank discrete wavelet transforms nonlinear filters wavelet analysis image reconstruction image analysis computer vision humans;wavelet transform;biomedical engineering;multisensor image decomposition;image reconstruction;image registration;steerable dyadic wavelet transform;image fusion algorithm;image registration steerable dyadic wavelet transform image fusion algorithm multiscale analysis arbitrary orientations multisensor image decomposition maximum local oriented energy spatial position scale position local dominant orientation transform coefficients input image image reconstruction modified coefficient;local dominant orientation;difference set;wavelet transforms sensor fusion image reconstruction image registration;sensor fusion;transform coefficients;modified coefficient;maximum local oriented energy;spatial position	An image fusion algorithm based on multiscale analysis along arbitrary orientations is presented. After a steerable dyadic wavelet transform decomposition of multi-sensor images is carried out, the maximum local oriented energy is determined at each level of scale and spatial position. Maximum local oriented energy and local dominant orientation are used to combine transform coeecients obtained from the analysis of each input image. Reconstruction is accomplished from the modiied coeecients, resulting in a fused image. Examples of multi-sensor fusion and fusion using diierent settings of a single sensor are demonstrated.	algorithm;dyadic transformation;fast fourier transform;image fusion;steerable filter;wavelet transform	Iztok Koren;Andrew F. Laine;Fred J. Taylor	1995		10.1109/ICIP.1995.537623	computer vision;mathematical optimization;pattern recognition;mathematics;stationary wavelet transform;image fusion;wavelet transform	Vision	51.38437275651195	-63.43593574508778	74385
1c308b6d63af568febb15d527b9137e79ca81bd2	an efficient descriptor based on radial line integration for fast non-invariant matching and registration of microscopy images		Descriptors such as SURF and SIFT contain a framework for handling rotation and scale invariance, which generally is not needed when registration and stitching of images in microscopy is the focus. Instead speed and efficiency are more important factors. We propose a descriptor that performs very well for these criteria, which is based on the idea of radial line integration. The result is a descriptor that outperforms both SURF and SIFT when it comes to speed and the number of inliers, even for rather short descriptors.	radial (radio)	Anders Hast;Gustaf Kylberg;Ida-Maria Sintorn	2017		10.1007/978-3-319-70353-4_61	computer vision;artificial intelligence;radial line;microscopy;pattern recognition;computer science;scale-invariant feature transform;scale invariance;image stitching;invariant (mathematics)	Vision	41.189737638332254	-55.88512027989631	74445
46e811582e11a649b36a47821108b2e6a1962db9	deformable registration using patch-wise shape matching	nonlinear shape deformation;non rigid registration	We present a novel approach for non-rigid registration of partially overlapping surfaces acquired from a deforming object. To allow for large and general deformations our method employs a nonlinear physics-inspired deformation model, which has been designed with a particular focus on robustness and performance. We discretize the surface into a set of overlapping patches, for each of which an optimal rigid motion is found and interpolated faithfully using dual quaternion blending. Using this discretization we can formulate the two components of our objective function-a fitting and a regularization term-as a combined global shape matching problem, which can be solved through a very robust numerical approach. Interleaving the optimization with successive patch refinement results in an efficient hierarchical coarse-to-fine optimization. Compared to other approaches our as-rigid-as-possible deformation model is faster, causes less distortion, and gives more accurate fitting results.		Francesco Bonarrigo;Alberto Signoroni;Mario Botsch	2014	Graphical Models	10.1016/j.gmod.2014.04.004	computer vision;mathematical optimization;computer science;mathematics;geometry	Vision	52.33581828950979	-53.03492346141999	74525
5660d6c1a5ce14ab8293c287b877dc93dfdb3617	content-based retrieval of historical watermark images: i-tracings	image features;analisis contenido;analisis componente principal;image processing;filigrana;image matching;strain control;procesamiento imagen;tracing;filigrane;traitement image;content analysis;shape matching;principal component analysis;tracage;watermark;analyse composante principale;analyse contenu;controle deformation mecanique;content based retrieval;recherche par contenu;appariement image;trazado	Providing content-based access to archives of historical watermarks involves a number of problems. This paper describes the development and evaluation of SHREW, a shape-matching system for watermark images based on techniques developed for the ARTISAN trademark retrieval system. Encouraging retrieval results have been obtained using tracings of watermark images, whether whole-image features or component-based measures are used for matching. Further development of the system is continuing.		K. Jonathan Riley;John P. Eakins	2002		10.1007/3-540-45479-9_27	computer vision;tracing;content analysis;image processing;computer science;watermark;feature;principal component analysis;computer graphics (images)	Vision	43.140060571953654	-61.26277595558391	74530
8f21398ede170b671aba9227069acfb1df586420	statistical processing of large image sequences	scientific application;prediccion;metodo estadistico;surface temperature;estimation mouvement;filtro kalman;image processing;estimation method;algorithms artificial intelligence cluster analysis computer graphics computer simulation image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval models biological models statistical movement numerical analysis computer assisted pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted subtraction technique video recording;methode approchee;estimacion movimiento;filtre kalman;kalman filters;procesamiento imagen;metodo aproximado;kalman filter;motion estimation;statistical method;positive definite;approximate method;correlation methods;traitement image;large scale;statistical analysis;stochastic processes;computational complexity;methode statistique;single frame estimation statistical image processing large scale stochastic image sequence estimation remote sensing dynamic estimation method kalman filter ocean surface temperature static estimation step computational complexity correlation structure;remote sensing;image sequence;correlation methods statistical analysis image sequences stochastic processes remote sensing kalman filters computational complexity;secuencia imagen;prediction;sequence image;image sequences image storage ocean temperature extraterrestrial measurements sea measurements motion estimation remote sensing statistics large scale systems stochastic processes;image sequences	The dynamic estimation of large-scale stochastic image sequences, as frequently encountered in remote sensing, is important in a variety of scientific applications. However, the size of such images makes conventional dynamic estimation methods, for example, the Kalman and related filters, impractical. We present an approach that emulates the Kalman filter, but with considerably reduced computational and storage requirements. Our approach is illustrated in the context of a 512 /spl times/ 512 image sequence of ocean surface temperature. The static estimation step, the primary contribution here, uses a mixture of stationary models to accurately mimic the effect of a nonstationary prior, simplifying both computational complexity and modeling. Our approach provides an efficient, stable, positive-definite model which is consistent with the given correlation structure. Thus, the methods of this paper may find application in modeling and single-frame estimation.	computational complexity theory;emulator;frame language;kalman filter;requirement;stationary process	Fakhry M. Khellah;Paul W. Fieguth;M. J. Murray;M. Allen	2005	IEEE Transactions on Image Processing	10.1109/TIP.2004.838703	kalman filter;computer vision;image processing;computer science;machine learning;mathematics;statistics	Vision	52.27081776392708	-59.21283754844489	74584
20d510b650f4d3937f63c47c31e4329bc54b7a5a	transformed polynomials for global registration of point clouds	correspondence;shape analysis;matching;registration	In this paper, we introduce a novel approach for global registration of partially overlapping point clouds. The approach identifies feature points of matching objects based on surface-approximating polynomials and finds an initial transformation depending on these polynomials. We compute an extended set of rotationally-invariant features for polynomials. In contrast to purely feature-based approaches, we do not only compute transformations based on the invariant properties of polynomials, but actually transform the polynomials into a common coordinate system and compare the transformed coefficients. This results in an improved correspondence analysis of local surfaces. Hence, using transformed polynomials, we gain more discriminating information about different structures. Therefore, the approach can handle partial scans of different objects simultaneously. Each partial scan is assigned to one of the objects and registered accordingly. Moreover, the approach is robust against noise and can process real data.	coefficient;correspondence analysis;point cloud;polynomial	Ruediger Schmedding;Barbara Frank;Wolfram Burgard;Matthias Teschner	2011		10.1145/2461217.2461242	matching;computer vision;mathematical optimization;combinatorics;discrete mathematics;computer science;shape analysis;mathematics;geometry	Vision	50.08640638149219	-53.9601155036964	74633
26580fb218aaf1f65f8dd0a55e878338c9dea103	learning a color distance metric for region-based image segmentation	mahalanobis distance;teleenseignement;distance metric learning;image segmentation;image processing;learning;distance de mahalanobis;image databank;image database;procesamiento imagen;mumford shah algorithm;analisis objetivos;metric;optimum global;global optimum;discriminant function;traitement image;energy function;algorithme;aprendizaje;algorithm;apprentissage;banco imagen;empirical validation;banque image;segmentation image;distance metric;region based color image segmentation;metrico;global optimization;ground truth;teleensenanza;cluster validity;remote teaching;imagen color;discriminacion;analyse objective;optimo global;image couleur;objective analysis;metrique;discrimination;color image;color image segmentation;algoritmo	In this paper we describe an experiment where we studied empirically and in depth the application of a global adaptive color space to be used in the similarity function of an established region-growing color image segmentation algorithm. To perform this experiment we chose the Mumford-Shah energy functional and the Mahalanobis distance metric. The objective was to test the approach empirically and in an objective and quantifiable way on this specific algorithm when using this particular distance model, without making any generalization claims. The empirical validation of the results was performed applying the resulting segmentation method on a subset of the Berkeley Image Database, an exemplar image set possessing groundtruths and validating the results against the ground-truths using two well-known segmentation validation methods, the Rand and BGM indexes. The obtained results suggest that to employ this adaptive color distance approach provides better and more robust segmentations, even if no other modification of the segmentation algorithm is performed.	algorithm;bayesian network;color image;color space;image segmentation;rand index;region growing;similarity measure	Antonio Carlos Sobieranski;Daniel Duarte Abdala;Eros Comunello;Aldo von Wangenheim	2009	Pattern Recognition Letters	10.1016/j.patrec.2009.08.002	computer vision;metric;image processing;computer science;machine learning;pattern recognition;mathematics;image segmentation;distance transform;scale-space segmentation;global optimization	Vision	45.07636696646333	-62.87445903333408	74710
2a23f3eb96cbfa22530d824cc8b112826cff294c	point-based medialness for 2d shape description and identification	planar articulated movement;information retrieval;medialness representation;shape compression;dominant points;2d shape analysis	We propose a perception-based medial point description of a natural form (2D: static or in articulated movement) as a framework for a shape representation which can then be efficiently used in biological species identification and matching tasks. Medialness is defined by adapting and refining a definition first proposed in the cognitive science literature when studying the visual attention of human subjects presented with articulated biological 2D forms in movement, such as horses, dogs and humans (walking, running). In particular, special loci of high medialness for the interior of a form in movement, referred to as “hot spots”, prove most attractive to the human perceptual system. We propose an algorithmic process to identify such hot spots. In this article we distinguish exterior from interior shape representation. We further augment hot spots with extremities of medialness ridges identifying significant concavities (from outside) and convexities (from inside). Our representation is strongly footed in results from cognitive psychology, but also inspired by know-how in art and animation, and the algorithmic part is influenced by techniques from more traditional computer vision. A robust shape matching algorithm is designed that finds the most relevant targets from a database of templates by comparing feature points in a scale, rotation and translation invariant way. The performance of our method has been tested on several databases. The robustness of the algorithm is further tested by perturbing the data-set at different levels.	algorithm;cognitive science;computer vision;database;hotspot (wi-fi);medial graph	Prashant Aparajeya;Frederic Fol Leymarie	2015	Multimedia Tools and Applications	10.1007/s11042-015-2605-6	computer vision;simulation;computer science;machine learning	ML	47.415702976466086	-53.963463941542045	74733
81f4e7982776113b0d3dccfe52956869c6df8516	model-based shape matching with structural feature grouping	high level features model based shape matching structural feature grouping online handwriting recognition shape variation stroke number stroke order topological deformations top down approaches shape matching algorithm;prototypes character recognition topology noise shaping data mining feature extraction computer science handwriting recognition structural shapes deformable models;top down;online handwriting recognition;local structure;shape matching;character recognition	An essential problem in online handwriting recognition is in the shape variation along with the variety of stroke number and stroke order. This paper presents a clear and systematic approach to shape matching based on structural feature grouping. To cope with topological deformations caused by stroke connection and breaking, we incorporate some aspects of top-down approaches systematically into the shape matching algorithm. The grouping of local structural features into high-level features is controlled by high-level knowledge as well as the simple geometric conditions. The shape matching algorithm requires a small number of prototypes and has the following properties from the viewpoint of online character recognition: (a) The order of strokes is free; (b) The number of strokes is free; (c) Stroke connection and breaking are allowed.		Hirobumi Nishida	1994		10.1109/ICPR.1994.577052	computer vision;computer science;machine learning;pattern recognition;top-down and bottom-up design;shape analysis;mathematics	Vision	41.973893240686984	-57.38624405691931	74914
f06283509654a8e958a9fb2c66a56ca1a8f89262	a maximum likelihood framework for determining moving edges	motion analysis;occlusion contours;vision ordenador;analisis escena;analyse scene;image motion analysis;movimiento;moving edges;image segmentation;information extraction;maximum likelihood;maximum vraisemblance;displacement magnitude picture processing information extraction maximum likelihood framework moving edges hypothesis testing surface patch 3 d spatiotemporal space spatiotemporal segmentation occlusion contours;picture processing;3 d spatiotemporal space;testing;intelligence artificielle;spatiotemporal segmentation;indexing terms;motion;maximum likelihood estimation;computer vision;image edge detection;mouvement;image sequence;likelihood ratio test;hypothesis testing;maximum likelihood detection;spatiotemporal phenomena;spatiotemporal phenomena image segmentation image sequences motion analysis testing image motion analysis maximum likelihood detection maximum likelihood estimation image edge detection image analysis;artificial intelligence;image analysis;vision ordinateur;secuencia imagen;inteligencia artificial;displacement magnitude;surface patch;maximo semejanza;use case;maximum likelihood framework;sequence image;scene analysis;image sequences;hypothesis test	The determination of moving edges in an image sequence is discussed. An approach is proposed that relies on modeling principles and likely hypothesis testing techniques. A spatiotemporal edge in an image sequence is modeled as a surface patch in a 3-D spatiotemporal space. A likelihood ratio test enables its detection as well as simultaneous estimation of its related attributes. It is shown that the computation of this test leads to convolving the image sequence with a set of predetermined masks. The emphasis is on a restricted but widely relevant and useful case of surface patch, namely the planar one. In addition, an implementation of the procedure whose computation cost is merely equivalent to a spatial gradient operator is presented. This method can be of interest for motion-analysis schemes, not only for supplying spatiotemporal segmentation, but also for extracting local motion information. Moreover, it can cope with occlusion contours and important displacement magnitude. Experiments have been carried out with both synthetic and real images. >		Patrick Bouthemy	1989	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.24782	computer vision;statistical hypothesis testing;image analysis;computer science;pattern recognition;mathematics;maximum likelihood;information extraction;statistics	Vision	48.16108791793127	-58.69859360236395	74958
949ce78ce43ea15c23e242fa81b112553c2de604	classifying textures when seen from different distances	image resolution surface texture image texture image classification image colour analysis stereo image processing photometry;4 source colour photometric stereo;image resolution;image databases;reflectivity;surface roughness;image classification;different distances;surface colour information;image texture recognition;surface texture;image texture;rough surfaces;surface texture classification;surface shape information;image resolution modification;photometry;photometric stereo;image colour analysis;stereo image processing;lambertian surfaces;tiles;textured surfaces;lighting;surface texture lighting image texture rough surfaces surface roughness tiles image resolution cameras reflectivity image databases;cameras;lambertian surfaces surface texture classification different distances image resolution modification 4 source colour photometric stereo surface shape information surface colour information textured surfaces image texture recognition	The purpose of this work is to analyse what happens to the surface information when the image resolution is modified. We deduce how the same surface appears if seen from different distances. Using 4-source Colour Photometric Stereo, which provides the surface shape and colour information, a method for predicting how surface texture looks like when changing the distance of the camera is presented. We demonstrate this technique by classifying textured surfaces seen from different distances than the textured surfaces in the database.	computer vision;image resolution;lambertian reflectance;photometric stereo;test data;texture mapping	Xavier Lladó;Maria Petrou	2002		10.1109/ICPR.2002.1048452	image texture;surface finish;computer vision;contextual image classification;photometric stereo;image resolution;surface roughness;photometry;computer science;lighting;reflectivity	Vision	53.06678963603277	-56.57927076643261	75468
a249808f3880e66c811a7a3072d316a3e29f27ad	maximum likelihood training of the embedded hmm for face detection and recognition	maximum likelihood detection hidden markov models face detection face recognition pattern recognition computer vision probability distribution image recognition signal processing image processing;image recognition;maximum likelihood detection hidden markov models face recognition computer vision;image processing;maximum likelihood;two dimensional data modelling;hidden markov model;model performance;embedded hidden markov model;statistical model;maximum likelihood training;model performance face detection face recognition maximum likelihood training embedded hidden markov model statistical model pattern recognition applications computer vision applications partial size invariance standard hmm pseudo two dimensional structure two dimensional data modelling continuous mixture embedded hmm;computer vision;partial size invariance;face recognition;hidden markov models;standard hmm;computer vision applications;signal processing;probability distribution;maximum likelihood detection;pattern recognition;pseudo two dimensional structure;face detection;pattern recognition applications;continuous mixture embedded hmm	The embedded hidden Markov model (HMM) is a statistical model that can be used in many pattern recognition and computer vision applications. This model inherits the partial size invariance of the standard HMM, and, due to its pseudo two-dimensional structure, is able to model two-dimensional data such as images, better than the standard HMM. We describe the maximum likelihood training for the continuous mixture embedded HMM and present the performance of this model for face detection and recognition. The experimental results are compared with other approaches to face detection and recognition.	embedded system;face detection;hidden markov model	Ara V. Nefian;Monson H. Hayes	2000		10.1109/ICIP.2000.900885	probability distribution;statistical model;computer vision;face detection;speech recognition;computer science;machine learning;pattern recognition;maximum likelihood;hidden markov model	Vision	40.64532586707142	-53.12258319568727	75793
4b1131fe99886c4744e6c020bfd5a8b1c22259bb	real-time registration of paper watermarks	electronic engineering;vision ordenador;image segmentation;image processing;analyse fourier;localizacion objeto;real time;object location;procesamiento imagen;real time processing;filigrane;traitement image;computer vision;watermarks;tratamiento tiempo real;traitement temps reel;detection defaut;analisis morfologico;machine vision;feature extraction;identification;segmentation image;morphological analysis;watermark;analyse morphologique;fourier analysis;identificacion;analisis fourier;vision ordinateur;extraction caracteristique;localisation objet;deteccion imperfeccion;defect detection	Real-time Registration of Paper Watermarks The aim of this article is to outline the issues involved in the application of machine vision to the automatic extraction and registration of watermarks from continuous web paper. The correct identification and localisation of watermarks are key issues in paper manufacturing. As well as requiring the position of the watermark for defect detection and classification, it is necessary to insure its position on the paper prior to the cutting process. Two paper types are discussed, with and without laid and chain lines (these lines appear as a complex periodic background to the watermark and further complicate the segmentation process). We will examine both morphological and Fourier approaches to the watermark segmentation process, concentrating specifically on those images with complex backgrounds. Finally we detail a system design suitable for real-time implementation.	machine vision;real-time clock;real-time computing;real-time transcription;software bug;systems design	Paul F. Whelan;Pierre Soille;Alexandru Drimbarean	2001	Real-Time Imaging	10.1006/rtim.2000.0239	identification;computer vision;machine vision;image processing;feature extraction;morphological analysis;computer science;image segmentation;fourier analysis;watermark;computer graphics (images)	Vision	46.77714355390207	-60.98004484453912	75882
9d1e7fe1959642ec620239369f78289f2ec7e27f	salient region extraction based on local extrema of natural images	scale space image representation salient region extraction local extrema natural image human vision peripheral vision behavioral plausibility multiresolutional 2d distribution region detection image resolution;peripheral vision model;scale space image representation;human vision;peripheral vision;image resolution;multiresolutional 2d distribution;natural images;behavioral plausibility;object detection computer vision feature extraction image representation image resolution natural scenes;observers;data mining;peripheral vision model salient region local extrema;computer vision;visualization;local extrema;scale space;image representation;feature extraction;salient region extraction;humans;natural image;visual system;humans feature extraction image resolution observers visualization data mining visual system;salient region;region detection;natural scenes;extraction method;object detection	We present a method to extract salient regions in natural images based on local extrema. Behavioral and physiological studies on human vision indicate that the peripheral vision has an important role to get salient regions into the fovea to obtain detailed information from the environment. Modeling of the peripheral is the key to create a salient region extraction method with the behavioral plausibility. To extract salient regions in a natural image, we focus on the multiresolutional 2-D distribution of local extrema. Local extrema detect regions in the image that are either brighter or darker than the surroundings. They will provide useful information to extract salient regions regardless of the image resolution. As for the function of human vision, an image is more blurred in more peripheral. So we model the peripheral using scale-space image representation. In this study, we define the saliency based on the stability of local extrema on scale-space and create a method to extract salient regions. Comparing the human map of fixations, we ensure that our method successfully extracts salient regions.	image resolution;maxima and minima;multiresolution analysis;peripheral vision;plausibility structure;scale space	Hidenori Maruta;Masahiro Ishii;Makoto Sato	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5649294	computer vision;scale space;visualization;image resolution;peripheral vision;visual system;feature extraction;computer science;maxima and minima;pattern recognition;computer graphics (images)	Vision	41.254861448086096	-62.366751756194844	75912
d4014ec87714b2491aebda5afae866607c635ada	adaptive human motion analysis and prediction	motion analysis;prediction method;traitement signal;methode recursive;metodo adaptativo;ar model;evaluation performance;pattern clustering;performance evaluation;modelo autorregresivo;evaluacion prestacion;metodo recursivo;long term prediction;recursive method;auto regressive;analyse mouvement;methode adaptative;predictor;autoregressive model;predicteur;accuracy;precision;signal processing;human motion;adaptive method;signal classification;auto regressive models;prediction accuracy;pattern classification;human motion analysis;pattern recognition;classification signal;reconnaissance forme;human motions;motion pattern;classification automatique;analisis movimiento;reconocimiento patron;automatic classification;modele autoregressif;procesamiento senal;clasificacion automatica;article;prediction;quantitative evaluation;long term future;classification forme	Human motion analysis and prediction is an active research area where predicting human motion is often performed for a single time step based on historical motion. In recent years, longer term human motion prediction has been attempted over a number of future time steps. Most current methods learn motion patterns (MPs) from observed trajectories and then use them for prediction. However, these learned MPs may not be indicative due to inadequate observation, which naturally affects the reliability of motion prediction. In this paper, we present an adaptive human motion analysis and prediction method. It adaptively predicts motion based on the classified MPs in terms of their credibility, which refers to how indicative the learned MPs are for the specific environment. The main contributions of the proposed method are as follows: First, it provides a comprehensive description of MPs including not only the learned MPs but also their evaluated credibility. Second, it predicts long-term future motion with reasonable accuracy. A number of experiments have been conducted in simulated scenes and real-world scenes and the prediction results have been quantitatively evaluated. The results show that the proposed method is effective and superior in its performance when compared with a recursively applied Auto-Regressive (AR) model, which is called the Recursive Short-term Predictor (RSP) for long-term prediction. The proposed method has 17.73% of improvement over the RSP in prediction accuracy in the experiment with the best performance. On average, the proposed method has 5% improvement over the RSP in prediction accuracy over 10 experiments.		Zhuo Chen;Lu Wang;N. H. C. Yung	2011	Pattern Recognition	10.1016/j.patcog.2011.04.022	simulation;speech recognition;artificial intelligence;signal processing;mathematics;autoregressive model;statistics	Vision	46.16814223769868	-57.04964258256266	75931
4a0e37948dfd2dbb7f8542d164e0469f31a17d32	a systematic approach towards reconstruction 3d curved models from multiple 2d views	concepcion asistida;object recognition;computer aided design;analisis forma;engineering drawings;reconstitution forme;search method;reconnaissance objet;reconstitucion forma;reconocimiento grafico;dessin ingenierie;conception assistee;pattern analysis;reconnaissance graphique;pattern recovery;analyse forme;graphical recognition	In this paper, we present a robust and systematic scheme that automatically interprets 3-view engineering drawings as central quadric surface mechanical parts. Initially a 3D wireframe, with no face information in it, is reconstructed from the three orthographic projections. Next, all candidate faces are found within the wire-frame, using a minimum-internal-angle searching method. Then, pseudo elements that could be generated from back-projection are detected and deleted using a Decision-Chaining method. Finally, all true faces are assembled to form an oriented 3D object.		M. H. Kuo	1997		10.1007/3-540-64381-8_55	computer vision;computer science;computer aided design;cognitive neuroscience of visual object recognition;pattern recognition	Vision	49.26897845396321	-59.59736817808803	76062
78867bdd76060cb2734864d12091333dbadf08a9	radial tchebichef moment invariants for image recognition	image recognition;images reconstruction;orthogonal fourier mellin moments;complex moments;polar coordinate;orthogonal moments;radial tchebichef moments;invariant moments	Radial Tchebichef moments as discrete orthogonal moments in the polar coordinate have been successfully used in the field of image recognition. However, the scale invariant property of these moments has not been studied due to its complexity of the problem. In this paper, we present a method to construct a set of scale and rotation invariants extracted from radial Tchebichef moments, named radial Tchebichef moment invariants (RTMI). Experimental results show the efficiency and the robustness to noise of the proposed method for recognition tasks. 2011 Elsevier Inc. All rights reserved.	computer vision;radial (radio);radial basis function	Bin Xiao;Jian-Feng Ma;Jiangtao Cui	2012	J. Visual Communication and Image Representation	10.1016/j.jvcir.2011.11.008	velocity moments;computer vision;mathematical analysis;polar coordinate system;topology;method of moments;computer science;mathematics;geometry	Vision	49.72665603542529	-61.604206713935795	76120
4035bdb71cb12790ec49bea5ee769b1a4982718b	fast and cheap object recognition by linear combination of views	linear combination;object recognition;mobile device;real time;2d views;spatial relationships;real time application;invariant feature	In this paper, we present a real-time algorithm for 3D object detection in images. Our method relies on the Ullman and Basri [13] theory which claims that the same object under different transformations can often be expressed as the linear combinations of a small number of its views. Thus, in our framework the 3D object is modelized by two 2D images associated with spatial relationships described by local-invariant feature points. The recognition is based on feature points detection and alignment with the model. Important theoretical optimizations have been introduced in order to speed up the original full alignment scheme and to reduce the model size in memory. The recognition process is based on a very fast recognition loop which quickly eliminates outliers. The proposed approach does not require a segmentation stage, and it is applicable to cluttered scenes. The small size of the model and the rapidity of the detection make this algorithm particularly suitable for real-time applications on mobile devices.	feature vector;mobile device;object detection;outline of object recognition;real-time clock;sethi–ullman algorithm	Jérôme Revaud;Guillaume Lavoué;Yasuo Ariki;Atilla Baskurt	2007		10.1145/1282280.1282313	spatial relation;computer vision;simulation;linear combination;computer science;viola–jones object detection framework;cognitive neuroscience of visual object recognition;machine learning;mobile device;3d single-object recognition	Vision	42.89561011137923	-53.00995716915181	76324
3a2f4384deea25d9d3da77cad528e0d8ede50c7b	ground target recognition using rectangle estimation	rectangle estimation;complex shape;traitement signal;concepcion asistida;evaluation performance;metodo estadistico;ajustamiento modelo;object recognition;computer aided design;deteccion blanco;detection forme;radar target recognition image matching image representation image segmentation military radar monte carlo methods optical radar;metodo monte carlo;image segmentation;performance evaluation;estimation method;image matching;electrical engineering electronic engineering information engineering;technology;evaluacion prestacion;military radar;target recognition laser radar shape radar imaging laser modes object recognition sensor phenomena and characterization radar scattering high resolution imaging radar applications;simulacion numerica;mesure position;methode monte carlo;size measurement;laser radar;statistical method;control engineering;teknikvetenskap;reconnaissance objet;rectangular shape;segmentation;shape detection;rectangle estimation automatic target recognition laser radar;scattered data;medicion posicion;detection cible;ajustement modele;detection objet;forma compleja;radar optico;deteccion forma;engineering and technology;automatic recognition;reglerteknik;estudio caso;optical radar;target recognition;4279q;methode statistique;image representation;feature extraction;signal processing;monte carlo method;model matching;simulation numerique;reconnaissance cible radar;position measurement;automatic target recognition;radar target recognition;etude cas;pattern recognition;conception assistee;reconnaissance forme;mesure dimension;extraction caracteristique;reconocimiento patron;algorithms artificial intelligence image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval lasers pattern recognition automated radar reproducibility of results sensitivity and specificity;monte carlo simulation;orientation estimation;procesamiento senal;target detection;forme complexe;segmentacion;radar optique	We propose a ground target recognition method based on 3-D laser radar data. The method handles general 3-D scattered data. It is based on the fact that man-made objects of complex shape can be decomposed to a set of rectangles. The ground target recognition method consists of four steps; 3-D size and orientation estimation, target segmentation into parts of approximately rectangular shape, identification of segments that represent the target's functional/main parts, and target matching with CAD models. The core in this approach is rectangle estimation. The performance of the rectangle estimation method is evaluated statistically using Monte Carlo simulations. A case study on tank recognition is shown, where 3-D data from four fundamentally different types of laser radar systems are used. Although the approach is tested on rather few examples, we believe that the approach is promising	computer-aided design;leucaena pulverulenta;matching;monte carlo method;part dosing unit;physical object;radar;simulation;biologic segmentation	Christina Grönwall;Fredrik Gustafsson;Mille Millnert	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.881965	computer vision;computer science;signal processing;largest empty rectangle;statistics;monte carlo method	Robotics	49.83431518158289	-59.909244207767635	76345
26bf7b4d3c8432f0c067fece0c6b2fd886fd5a81	a novel approach for affine point pattern matching	analisis imagen;acoplamiento grafo;image recognition;reconocimiento imagen;transformation affine;graphe biparti;image processing;cost function;grafo bipartido;procesamiento imagen;graph matching;traitement image;couplage graphe;generic point;pattern matching;affine transformation;reconnaissance image;pattern recognition;invariante;image analysis;concordance forme;reconnaissance forme;reconocimiento patron;bipartite graph;analyse image;invariant;transformacion afin;point pattern matching	Affine point pattern matching (APPM) is an integral part of many pattern recognition problems. Given two sets P and Q of points with unknown assignments pi → qj between the points, no additional information is available. The following task must be solved: – Find an affine transformation T such that the distance between P and the transformed set Q′ = TQ is minimal. In this paper, we present a new approach to the APPM problem based on matching in bipartite graphs. We have proved that the minimum of a cost function is an invariant under special affine transformations. We have developed a new algorithm based on this property. Finally, we have tested the performance of the algorithm on both synthetically generated point sets and point sets extracted from real images.	algorithm;barycentric subdivision;euclidean distance;floor and ceiling functions;geographic coordinate system;geometric hashing;hungarian algorithm;least absolute deviations;loss function;p (complexity);pattern matching;pattern recognition;time complexity;tree accumulation	Herbert Süße;Wolfgang Ortmann;Klaus Voss	2006		10.1007/11867661_39	computer vision;combinatorics;discrete mathematics;image analysis;topology;affine coordinate system;bipartite graph;image processing;computer science;invariant;pattern matching;affine hull;generic point;affine transformation;harris affine region detector;mathematics;affine shape adaptation;affine combination;matching	Theory	48.85872401295478	-59.66198448175292	76625
5848f16f7a700829fa49ce3dd18e0073b11d4169	multiresolution stereo image matching using complex wavelets	discrete wavelet transforms;offset robustness;fractionally accurate matching results;discrete wavelet transform;image formation;image resolution;image formation perturbations;identity based encryption;facial images multiresolution stereo image matching complex wavelets complex discrete wavelet transform dense disparity field hierarchical refinement cdwt feature space fractionally accurate matching results image formation perturbations offset robustness global scaling robustness additive noise robustness feature similarity disparity field continuity feature sensitive smoothing;image matching;complex discrete wavelet transform;additive noise;surface reconstruction;feature space;neutron spin echo;feature sensitive smoothing;global scaling robustness;cdwt feature space;disparity field continuity;signal processing;stereo image processing;information processing;dense disparity field;multiresolution stereo image matching;signal resolution;complex wavelets;discrete wavelet transforms stereo image processing image matching;image resolution image matching signal resolution discrete wavelet transforms identity based encryption surface reconstruction signal processing information processing australia neutron spin echo;feature similarity;additive noise robustness;facial images;hierarchical refinement;australia	This paper describes a multiresolution image-matching strategy, based on the Complex Discrete Wavelet Transform (CDWT), to derive a dense disparity field with hierarchical (coarse-to-fine) refinement. The CDWT feature space efficiently provides fractionally accurate matching results which are robust to typical image formation perturbations such as offsets, global scaling, and additive noise. A t each level of the hierarchy, the disparity field is regularised to provide a global compromise between feature similarity and disparity field continuity, resulting in feature-sensi tive smoothing. The algorithm is well suited to analysing facial images, for which we demonstrate striking reconstruction	additive white gaussian noise;algorithm;binocular disparity;discrete wavelet transform;feature vector;image formation;image registration;image scaling;map;multiresolution analysis;offset (computer science);refinement (computing);scott continuity;sensible soccer;smoothing;utility functions on indivisible goods	Julian Magarey;Anthony R. Dick	1998		10.1109/ICPR.1998.711065	computer vision;image resolution;feature vector;surface reconstruction;information processing;computer science;machine learning;signal processing;pattern recognition;mathematics;discrete wavelet transform;image formation;neutron spin echo	Vision	50.574895697308655	-64.58468577600652	76816
af6516a0682a1612badacdc6afd719fd3a67ed55	segment-based stereo matching	two dimensional shape;forme bidimensionnelle;analyse scene;shape from shading;image processing;image understanding;disparity;stereomapping;image;depth;recovery;2 dimensional;three dimensional;pictures;symposia;stereo matching;imagen;industrial robots;matching;identification;two dimensional;comprehension image;quantitative analysis;algorithms;identificacion;3 dimensional;image comprehension;disparite;images;scene analysis	"""Images are 2-dimensional projections of 3-dimensional scenes, therefore depth recovery is a crucial problem in image understanding, with applications in passive navigation, cartography, surveillance, and industrial robotics. Stereo analysis provides a more direct quantitative depth evaluation than techniques such as shape from shading, and its being passive makes it more applicable than active range finding imagery by laser or radar. This paper addresses the subproblem of identifying corresponding points in the two images. The primitives we use are groups of collinear connected edge points called segments, and we base the correspondence on the """"minimum differential disparity"""" criterion. The result of this processing is a sparse array disparity map of the analyzed scene. 9 1985 Academic Press, Inc."""	binocular disparity;cartography;computer stereo vision;computer vision;industrial robot;photogrammetry;photometric stereo;radar;robotics;shading;sparse matrix	Gérard G. Medioni;Ramakant Nevatia	1985	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(85)80073-6	three-dimensional space;computer vision;two-dimensional space;simulation;image processing;computer science;mathematics;geometry;computer graphics (images)	Robotics	50.26011812451634	-57.50331114007238	76875
421a67f53a01ef40e6b3b241928b9d494753430a	a coding scheme for indexing multimodal biometric databases	database indexing;index code multimodal biometric database indexing biometric identification systems large scale multimodal biometric databases reference images;large scale multimodal biometric databases;index code;biometrics access control;search space;image matching;biometric identification systems;data mining;large scale;multimodal biometric database indexing;indexing;feature extraction;indexation;face;image matching biometrics access control database indexing;correlation;reference images;indexing biometrics fingerprint recognition iris large scale systems bioinformatics delay image databases information retrieval filtering	In biometric identification systems, the identity associated with the input data is determined by comparing it against every entry in the database. This exhaustive matching process increases the response time of the system and, potentially, the rate of erroneous identification. A method that narrows the list of potential identities will allow the input data to be matched against a smaller number of identities. We describe a method for indexing large-scale multimodal biometric databases based on the generation of an index code for each enrolled identity. In the proposed method, the input biometric data is first matched against a small set of reference images. The set of ensuing match scores is used as an index code. The index codes of multiple modalities are then integrated using three different fusion techniques in order to further improve the indexing performance. Experiments on a chimeric face and fingerprint bimodal database indicate a 76% reduction in the search space at 100% hit rate. These results suggest that indexing has the potential to substantially improve the response time of multimodal biometric systems without compromising the accuracy of identification.	biometrics;code;database;fingerprint;multimodal interaction;response time (technology)	Aglika Gyaourova;Arun Ross	2009	2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2009.5204311	face;database index;search engine indexing;feature extraction;computer science;pattern recognition;data mining;geometry;correlation;information retrieval	Vision	39.68987588825477	-58.98207333874067	76883
87f43ebeff809f5988be59a29080e9b6071d3b32	3-d shape approximation using parametric geons	object representation;modelizacion;representation;geons;parametric model;optimisation;vision ordenador;3d object representation;range data;methode parametrique;optimizacion;shape approximation;geometrie algorithmique;metodo parametrico;three dimensional shape;parametric method;computational geometry;global optimisation;forma tridimensional;computer vision;modelisation;shape representation;superellipsoids;forme tridimensionnelle;object description;parametric models;geometria computacional;vision ordinateur;optimization;modeling;multiview range data;representacion;volumetric primitives	This paper presents a new approach to 3D shape representation { approximating the shapes of object parts by a set of prescribed volumetric models using single-and multi-view range data. We deene a new set of volumetric part models , called parametric geons. These are seven qualitative shapes, each of which is formulated by a restricted globally-deformed superellipsoid. Model recovery is performed by tting all parametric geons to a part and selecting the best model for the part based on the minimum tting residual. A newly-deened objective function and a fast global optimisation technique are employed to obtain robust model tting results. Parametric geons provide a global shape constraint that allows model recovery to explicitly verify the resultant part descriptions. Through systematic experiments, we examine the eeciency of the objective function, the discriminative ability of parametric geons, the eeects of object shape imperfection to model recovery, and the importance of multiview data for shape approximation. The experimental results demonstrate that this approach can successfully recover qualitative shape models from object parts, especially when a part shape is not fully consistent with model shapes.	approximation;experiment;global optimization;loss function;mathematical optimization;optimization problem;parametric oscillator;parametric polymorphism;resultant;shape context;superellipsoid;volume mesh	Kenong Wu;Martin D. Levine	1997	Image Vision Comput.	10.1016/S0262-8856(96)01124-9	active shape model;computer vision;parametric model;computational geometry;mathematics;geometry;statistics	Vision	50.82493983498485	-56.06429771147312	76906
513f06859c6276ed63912e31dcfafaafd5249469	region-based color image indexing and retrieval	database indexing;information resources;search engine;image segmentation;search engines;k means;very large databases region based indexing color image indexing image retrieval k means segmentation algorithm region coherence color distance region extraction characteristic feature estimation image texture shape information similarity based querying internal image representation image query performance intelligent search engine content based search world wide web image databases;indexing and retrieval;visual databases database indexing content based retrieval image retrieval image colour analysis image segmentation feature extraction image texture image representation search engines knowledge based systems information resources very large databases;image texture;image colour analysis;image representation;feature extraction;indexation;world wide web;color indexing image retrieval information retrieval image segmentation data mining feature extraction shape search engines web sites;very large databases;content based retrieval;knowledge based systems;color image;visual databases;image retrieval	In this paper a region-based color image indexing and retrieval algorithm is presented. As a basis for the indexing, a novel K-Means segmentation algorithm is used, modified so as to take into account the coherence of the regions. A new color distance is also defined for this algorithm. Based on the extracted regions, characteristic features are estimated using color, texture and shape information. An important and unique aspect of the algorithm is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Experimental results demonstrate the performance of the algorithm. The development of an intelligent image content-based search engine for the World Wide Web is also presented, as a direct application of the presented algorithm.	algorithm;color image;k-means clustering;web search engine;world wide web	Yiannis Kompatsiaris;Evagelia Triantafillou;Michael G. Strintzis	2001		10.1109/ICIP.2001.959131	image texture;computer vision;image retrieval;computer science;pattern recognition;information retrieval;search engine	Vision	39.302003889895495	-60.74146282194713	76907
6bcf4f329cf39a0b01e99e4975a4569d4adc6d12	using local convexities as anchor points for 3d curve skeletonization	topology;filtering;skeleton;surface treatment;shape;three dimensional displays;transforms	A new algorithm is introduced to compute the curve skeleton of 3D objects by using the notion of local convexity. The centers of maximal balls detected on the distance transform of the object are filtered to select as anchor points only those located on sharp local convexities of the object's boundary. Then, the skeleton is obtained by means of topology preserving removal operations. Pruning is finally accomplished to remove from the skeleton scarcely significant peripheral branches.	algorithm;distance transform;format-preserving encryption;iteration;maximal set;peripheral;speeded up robust features;stress ball;voxel	Luca Serino;Gabriella Sanniti di Baja	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7900069	filter;mathematical optimization;morphological skeleton;topology;shape;computer science;mathematics;geometry;topological skeleton;skeleton	Robotics	49.09720067740242	-64.41031385024927	76968
232170a2268e2958e10d51c9561137bb291cd909	object recognition and localization via pose clustering	3d;complexite;object recognition;vision ordenador;image processing;localizacion objeto;geometrie algorithmique;etude experimentale;echelle;object location;complejidad;computational geometry;procesamiento imagen;imagerie;intelligence artificielle;complexity;escala;scale;traitement image;computer vision;algorithme;algorithm;algorritmo;imagery;translation;pattern recognition;artificial intelligence;vision ordinateur;transformation hough;rotacion;imagineria;translacion;inteligencia artificial;2d;reconnaissance forme;reconocimiento patron;rotation;localisation objet;estudio experimental;pose clusternig	"""The general paradigm of pose clustering is discussed and compared to other techniques applicable to the problem of object detection. Pose clustering is also called hypothesis accumulation and generalized Hough transform and is characterized by a """"parallel"""" accumulation of low level evidence followed by a maxima or clustering step which selects pose hypotheses with strong support from the set of evidence. Examptes are given showing the use of pose clustering in both 2D and 3D problems. Experiments show that the positional accuracy of points placed in the data space by a model pose obtained via clustering is comparable to the positional accuracy of the sensed data from which pose candidates are computed. A specific sensing system is described which yields an accuracy of a few millimeters. Complexity of the pose clustering approach relative to alternative approaches is discussed with reference to conventional computers and massively parallel computers. It is conjectured that the pose clustering approach can produce superior results in real time on a massively parallel machine."""	cluster analysis;computer;dataspaces;experiment;generalised hough transform;maxima;object detection;outline of object recognition;parallel computing;programming paradigm;tree accumulation	George C. Stockman	1987	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(87)80147-0	translation;correlation clustering;constrained clustering;computer vision;scale;2d computer graphics;complexity;pose;3d pose estimation;fuzzy clustering;image processing;computational geometry;rotation;computer science;artificial intelligence;canopy clustering algorithm;cognitive neuroscience of visual object recognition;cure data clustering algorithm;cluster analysis;algorithm;clustering high-dimensional data	Vision	47.74651628818658	-59.61367211281474	77040
d5603b6f5581057aa7f9efe2ac1694d11e2d37b8	structure and motion from straight line segments	image segmentation;straight segments;structure and motion	A method to determine both the camera location and scene structure from im age straight segment correspondences is presented The proposed method considers the nite segment length in order to use stronger constraints than do those that use the in nite line that supports the image segment The constraints between image segments involve a weak pairing between image segment midpoints This al lows deviations of the midpoint only in the segment direction Experimental results are presented of structure and motion computations from the image straight line segment matching using two real images	computation;image segmentation	J. M. M. Montiel;Juan D. Tardós;Luis Montano	2000	Pattern Recognition	10.1016/S0031-3203(99)00117-X	computer vision;line segment;computer science;mathematics;geometry;image segmentation;line segment intersection	Vision	50.18378868409942	-54.42207903787233	77348
92e06831ea86742bf2534448b56bcfc7ea11e34a	illumination invariant intensity-based image registration using chaos theory	image registration chaos computer vision fractals;fractals;nonlinearities image registration image sequence analysis chaos;mutual information measurement illumination invariant intensity based image registration computer vision medical diagnostics surveillance voxel based approach area based approach nonfractal phase space behavior complex fractal region chaos theoretic approach;chaos;lighting mutual information image registration fractals phase measurement chaos biomedical imaging;computer vision;image registration	Accurate and robust registration of image pairs is of interest in many fields that use computer vision such as surveillance and medical diagnostics. In each of these fields the area-based (or voxel-based) approach to image registration is popular, however it is known that these methods are sensitive to illumination change where incorrect results are common. Past work in applying chaos theory to computer vision has demonstrated that the underlying physics of illumination change versus contextual change result in very different behavior when analyzed in phase space. Illumination is deterministic and results in non-fractal phase space behavior, while contextual change is chaos-like and results in complex fractal regions in phase space. A chaos-theoretic approach to image registration is presented with favorable results compared to the traditional and very popular Mutual Information measure.	chaos theory;computer vision;fractal;image registration;in-phase and quadrature components;mutual information;voxel	Michael E. Farmer	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638023	computer vision;simulation;fractal;computer science;image registration;mathematics;computer graphics (images)	Vision	49.900644247946786	-65.11984658583833	77717
d49bda084838422bb801d8e6c5f357727a4fe7bf	on characterizing ribbons and finding skewed symmetries	obliqueness;ruban brady;generation;obliquite;forma planaria;image processing;generacion;deteccion;computer graphics;espacio 2 dimensiones;procesamiento imagen;segmentation;detection;traitement image;symetrie;symmetry;planar form;two dimensional space;oblicuidad;ruban blum;characterization;forme planaire;espace 2 dimensions;caracterisation;simetria;ruban brooks;grafico computadora;infographie;caracterizacion;segmentacion;ribbon	Following Rosenfeld, we compare Blum, Brooks, and Brady ribbons. We prove that Blum and Brady ribbons are not, in general, Brooks ribbons. Conversely, we prove that Brooks ribbons are, in general, neither Blum nor Brady ribbons. For Blum and Brady ribbons, it is in principle trivial to decide whether two contour points may form a ribbon pair: they have to form a local symmetry. This property is not true for Brooks ribbons. It is possible to characterize locally the pairs of contour points which form a Brooks ribbon pair? Using the curvature of the contour of a Brooks ribbon, we show that the answer to this question is yes for some classes of Brooks ribbons, including skewed symmetries. This result is used in an implemented algorithm for finding skewed symmetries in an image, and examples of segmentation of real images are given.		Jean Ponce	1990	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(90)90079-B	computer vision;two-dimensional space;generation;image processing;computer science;calculus;mathematics;geometry;symmetry;computer graphics;segmentation;algorithm	Robotics	50.6564065317352	-60.448017777948124	77768
828a519a8d059cbc4d2b8e01778aa74a93305d1f	face localization based on wavelet extrema	faceof interest foi;head contour detection hcd;face localization;face of interest;head corner detection;extrema density	The human face localization task upon upright vertical frontal views faces in complex scenes is formulated as a wavelet-based problem and developed a novel approach using the extrema density aims to determine a single face position. Face-of-interest region is firstly located and framed by finding facial edges using the inter-orientation wavelet subbands and the anthropometric measure. Then, a refinement using the proposed head corner detection approach is carried to further improve the localization accuracy. Comparisons with existing state-of-the-art face detection works, showing that our system has a comparable performance in terms of face localization rate and quality.	face detection;wavelet	Jing-Wein Wang	2008	IEICE Electronic Express	10.1587/elex.5.516	computer vision;speech recognition;object-class detection;pattern recognition;mathematics	DB	40.022833663378954	-58.650391792708525	77899
fafa3f9cf9d3fa029f509bae79ee8828439ea05a	improved weber’s law based local binary pattern for dynamic texture recognition		Dynamic texture is the moving sequence of images that shows some form of temporal regularity. Various static texture descriptors have been extended to spatiotemporal domain for dynamic texture classification. Local Binary Pattern (LBP) is a simple descriptor computationally but sensitive to noise and sometimes fails to capture different patterns. In view of this, a novel approach for dynamic texture classification is introduced that maintains the advantageous characteristics of uniform LBP. Inspired by the Weber’s law, a simple yet very powerful, robust texture descriptor, i.e., Weber’s law based LBP with center pixel (WLBPC) is proposed from the local patches based on the conventional Local Binary Pattern approach. A noise resistant variant of Weber’s law based LBP with center pixel (NR-WLBPC) is also proposed. To do this, WLBPC is extended to a 3-valued code based on a new threshold. Proposed noise resistant variant of WLBPC descriptor makes use of the indecisive bit and the uniform pattern to compute the feature vector. Center pixel information is fused with both the dynamic texture descriptors to improve the discriminative power. Extensive experimental evaluations on representative dynamic texture databases (DynTex++ and UCLA) show that the proposed descriptors show better performance in comparison to recent state-of-the-art LBP variants and other methods under both normal and noisy conditions. Noise invariant of the proposed descriptor also performs better in the presence of noise due to its robustness and discriminating capabilities.	belief propagation;binary pattern (image generation);code;computer vision;database;feature vector;image noise;local binary patterns;noise reduction;pixel	Deepshika Tiwari;Vipin Tyagi	2016	Multimedia Tools and Applications	10.1007/s11042-016-3362-x	computer vision;local binary patterns;machine learning;pattern recognition;texture filtering	Vision	39.52857820100817	-55.61255859320688	78102
08d7342b4960d38795c401489885b9e1d9156ef2	performance modeling and algorithm characterization for robust image segmentation	bayesian theory;bayes estimation;analisis imagen;modelizacion;image features;evaluation performance;contenu image;image content;image segmentation;performance evaluation;image processing;loi probabilite;behavioral analysis;ley probabilidad;evaluacion prestacion;procesamiento imagen;algorithm selection;probabilistic approach;curva gauss;traitement image;information content;algorithm characterization;modelisation;estimacion bayes;enfoque probabilista;approche probabiliste;probability distribution;analyse comportementale;segmentation image;image segmentation performance modeling;performance model;loi normale;performance prediction;image analysis;analisis conductual;algoritmo optimo;algorithme optimal;contenido imagen;optimal algorithm;modeling;analyse image;performance modeling;gaussian distribution;estimation bayes	This paper presents a probabilistic framework based on Bayesian theory for the performance prediction and selection of an optimal segmentation algorithm. The framework models the optimal algorithm selection process as one that accounts for the information content of an input image as well as the behavioral properties of a particular candidate segmentation algorithm. The input image information content is measured in terms of image features while the candidate segmentation algorithm’s behavioral characteristics are captured through the use of segmentation quality features. Gaussian probability distribution models are used to learn the required relationships between the extracted image and algorithm features and the framework tested on the Berkeley Segmentation Dataset using four candidate segmentation algorithms.	algorithm selection;image segmentation;kerrison predictor;performance prediction;self-information	Shishir Shah	2008	International Journal of Computer Vision	10.1007/s11263-008-0130-z	normal distribution;probability distribution;image texture;computer vision;image analysis;systems modeling;self-information;image processing;bayesian probability;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;feature;statistics	Vision	45.00912051156665	-62.059788027053635	78109
4d1cff5fa9053d9b1a82befdaf9d34796f4ccb48	kernel tv-based quotient image employing gabor analysis and its application to face recognition	reconnaissance visage;analisis imagen;television;traitement signal;evaluation performance;metodo estadistico;analisis componente principal;tecnologia electronica telecomunicaciones;performance evaluation;filter bank;image processing;illumination;banc filtre;methode noyau;kpca;biometrie;evaluacion prestacion;biometrics;database;biometria;procesamiento imagen;base dato;outlier;statistical method;filtro gabor;traitement image;observacion aberrante;gabor filter;automatic recognition;masquage;face recognition;methode statistique;feature extraction;enmascaramiento;signal processing;principal component analysis;gabor analysis;banco filtro;metodo nucleo;filtre gabor;base de donnees;analyse composante principale;pattern recognition;masking;observation aberrante;kernel method;image analysis;total variation;reconnaissance forme;extraction caracteristique;tecnologias;reconocimiento patron;grupo a;procesamiento senal;eclairement;analyse image;reconocimiento automatico;reconnaissance automatique;alumbrado	In order to overcome the drawback of TVQI and to utilize the property of dimensionality increasing techniques, a novel model for Kernel TV-based Quotient Image employing Gabor analysis is proposed and applied to face recognition with only one sample per subject. To deal with illumination outliers, an enhanced TV-based quotient image (ETVQI) model is first adopted. Then for preprocessed images by ETVQI, a bank of Gabor filters is built to extract features at specified scales and orientations. Lastly, KPCA is introduced to extract final high-order and nonlinear features of extracted Gabor features. According to experiments on the CAS-PEAL face database, our model could outperform Gabor-based KPCA, TVQI and Gabor-based TVQI when they face most outliers (illumination, expression, masking etc.). key words: face recognition, total variation, Gabor analysis, KPCA		Gaoyun An;Jiying Wu;Qiuqi Ruan	2008	IEICE Transactions	10.1093/ietisy/e91-d.5.1573	computer vision;kernel method;outlier;image analysis;speech recognition;image processing;feature extraction;computer science;machine learning;signal processing;masking;filter bank;television;total variation;gabor wavelet;biometrics;principal component analysis	Vision	44.68168462098313	-60.306668584008555	78227
6a9664c523a1ce88991381854b2a851ce667c541	planning sequences of views for 3-d object recognition and pose determination	object representation;image tridimensionnelle;eficacia sistema;object recognition;sistema experto;image processing;learning;etude experimentale;performance systeme;procesamiento imagen;intelligence artificielle;orientation;system performance;traitement image;multiple views;aprendizaje;feature vector;apprentissage;pattern recognition;orientacion;tridimensional image;artificial intelligence;inteligencia artificial;reconnaissance forme;systeme expert;reconocimiento patron;estudio experimental;imagen tridimensional;expert system	We present a method for planning sequences of views for recognition and pose (orientation) determination of 3-D objects of arbitrary shape. The approach consists of a learning stage in which we derive a recognition and pose identiication plan and a stage in which actual recognition and pose identiication take place. In the learning stage, the objects are observed from all possible views and each view is characterized by an extracted feature vector. These vectors are then used to structure the views into clusters based on their proximity in the feature space. To resolve the remaining ambiguity within each of the clusters, we designed a strategy which exploits the idea of taking additional views. We developed an original procedure which analyzes the transformation of individual clusters under changing viewpoints into several smaller clusters. This results in an optimal next-view planning when additional views are necessary to resolve the ambiguities. This plan then guides the actual recognition and pose determination of an unknown object in an unknown pose.	feature vector;outline of object recognition	Stanislav Kovacic;Ale&#x0161; Leonardis;Franjo Pernus	1998	Pattern Recognition	10.1016/S0031-3203(98)00012-0	computer vision;pose;feature vector;3d pose estimation;image processing;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;orientation;expert system	Vision	47.67868242115896	-58.96280229200236	78556
d87e75363f8b69379ae70fd32da671ec6c644dd9	recognition of english calling card by using multiresolution images and enhanced art1-based rbf neural networks	image recognition;reconocimiento imagen;pistage;image processing;image resolution;fonction base radiale;rastreo;procesamiento imagen;analyse multiresolution;traitement image;similitude;resolucion imagen;vigilancia;masquage;reconnaissance caractere;radial basis function;vigilance;rbf neural network;enmascaramiento;similarity;reconnaissance image;pattern recognition;masking;reconnaissance forme;similitud;reseau neuronal;reconocimiento patron;funcion radial base;multiresolution analysis;rbf network;character recognition;resolution image;red neuronal;reconocimiento caracter;tracking;analisis multiresolucion;neural network	A novel hierarchical algorithm is proposed to recognize English calling cards. The algorithm processes multiresolution images of calling cards hierarchically to firstly extract individual characters and then to recognize the characters by using an enhanced neural network method. The horizontal smearing is applied to a 1/3 resolution image in order to extract the areas. The second vertical smearing and contour tracking masking is applied to a 1/2 resolution image to extract individual characters. And lastly, the original image is used in the recognition step because the image accurately includes the morphological information of the characters precisely. The enhanced RBF network is also proposed to recognize characters with diverse font types and sizes, by using the enhanced ART1 network adjusting the vigilance parameter dynamically according to the similarity between patterns. The results of experiments show that the proposed algorithm greatly improves the character extraction and recognition compared with traditional recognition algorithms.	neural networks;radial basis function	Kwang-Baek Kim;Sungshin Kim	2006		10.1007/11760023_44	multiresolution analysis;vigilance;computer vision;radial basis function;speech recognition;similarity;image resolution;image processing;computer science;artificial intelligence;similitude;machine learning;masking;tracking;artificial neural network	NLP	44.43512297073892	-62.721201546861934	78657
a4b488b0b9715c97f92b3414c87003a053ce06aa	applying perceptual organization to the detection of man-made objects in non-urban scenes	estructura geometrica;geometrical structure;vision ordenador;analisis escena;analyse scene;structure geometrique;informacion incompleta;sistema informatico;extraction forme;computer system;segmentation;relacion jerarquica;organisation perception;computer vision;relation hierarchique;incomplete information;extraccion forma;information incomplete;hierarchic relation;pattern recognition;vision ordinateur;systeme informatique;reconnaissance forme;reconocimiento patron;pattern extraction;segmentacion;perceptual organization;scene analysis	-A new approach for the detection of large man-made objects in a non-urban area using a single monochrome image is presented. In this study, the man-made objects may be unspecified and the appearance of the objects is unpredictable. Prominent features that distinguish man-made objects from natural objects are identified. A computational framework of applying perceptual organization and using the prominent features is presented. Techniques are developed to group low level image features hierarchically into a region-of-interest (ROI) likely to enclose man-made objects or a substantial part of the man-made objects. These techniques include feature extraction, primitive structure formation, and segmentation. Some of these methods are novel and others present unique properties and advantages compared to previous related works. Experimental results are presented using real images that include several different man-made objects in complex backgrounds or a natural scene without man-made objects. It is shown that the located ROIs properly enclose the man-made objects in the scenes. Object recognition Perceptual organization Feature representation Geometric structures Feature extraction 1. I N T R O D U C T I O N The computer perception of man-made objects in non-urban scenes is a challenging task in computer vision research. It also presents additional complexities and difficulties beyond the computer perception of objects in a well-controlled laboratory or factory environment. This paper presents a new approach for the automatic detection of large man-made objects in outdoor non-urban scenes. The methodology presented here is based on perceptual organization. The approach hierarchically organizes low level image features to higher level structures to find a region of interest in a given image. The environment we consider for image acquisition is a non-urban area in daylight hours. Large manmade objects, such as bridges and electric transmission towers, may be present in the area among natural objects, such as trees, bushes, and vegetation. The man-made objects are unspecified and their appearance is unpredictable. Thus, we do not know what manmade objects may appear or whether there is a man-made object in the scene. Given a single monochrome image of such a scene, the goal is to automatically detect large man-made objects in the image. Because of the complexity and variation of man-made objects and the uncertainty of the natural environment, t Present address: Schlumberger Austin Systems Center, Austin, Texas, U.S.A. Author to whom all correspondence should be addressed. the intermediate goal is to find in the image a region-ofinterest (ROI) most likely to enclose man-made objects or a substantial part of the man-made objects. Most computer vision research on object recognition has focused on problems with specified objects in controlled environments. For example, many of the current vision systems try to recognize objects in a given image with a uniform background and one or more objects whose exact models are known to the system/x~ Even with such seemingly well-defined problems, many obstacles exist and considerable research efforts are being made. Locating man-made objects in a natural outdoor environment adds yet another dimension of complexity. One cannot arrange the natural environment. Natural objects, such as trees, vegetation, rivers, rocks, and clouds, co-exist in the scene with the possible man-made objects. As Fischler and Strat 12~ observed, it is seldom possible to establish complete boundaries between objects of interest in natural scenes, and very few natural objects have compact shape descriptions. Therefore, the problem of detecting man-made objects in a natural environment is, in general, much more difficult than the object recognition tasks in a well-controlled environment. Many researchers have investigated the automatic interpretation of outdoor natural scenes. Some of them have investigated the detection of man-made objects t3-7~ other than buildings and roads. These studies, in general, use additional information about the scene, such as color or range, or have better knowledge (models) about the objects. Most of the	color;complexity;computation;computational linguistics;computer vision;dvd region code;daylight;feature extraction;monochrome;outline of object recognition;region of interest;sensor;yet another	H. Q. Lu;Jake K. Aggarwal	1992	Pattern Recognition	10.1016/0031-3203(92)90037-J	computer vision;computer science;artificial intelligence;pattern recognition;segmentation;complete information	Vision	47.61534701306898	-60.032019012566444	78687
fd936b6d9014e9d21aab8b3eb27baefe5e22ecd2	multiscale edge detection via normal changes	analisis imagen;deteccion multiespectral;detection multispectrale;edge detection;analisis forma;range image;image analysis;pattern analysis;analyse image;analyse forme;multispectral detection	A new edge detection technique based on detection of normal changes is proposed. Most of the existing range image-based edge detection algorithms base their detection criterion on depth or curvature changes. However, the depth change-based approach does not have keen sensitivity in detecting roof ( or crease ) edges, and the curvature change-based approach suffers from a complicated and tedious principal curvature derivation process. Using normal changes as a detecting criterion, on the other hand, the existence of an edge can be easily detected, even when the change across a boundary is slight. Experimental results using both synthetic and real images demonstrate that the proposed method can efficiently detect both step and roof edges.	edge detection	Chwen-Jye Sze;Hong-Yuan Mark Liao;Hai-Lung Hung;Kuo-Chin Fan;Jun-Wei Hsieh	1997		10.1007/3-540-63507-6_180	computer vision;image analysis;edge detection;topology;computer science;mathematics;geometry	Vision	48.101650014525816	-65.41828582296898	78835
ba4c97ffab4cd9dbf99a09375c35e2fa8edd34ca	fast image registration based on geometric correspondence between two levels of pyramid structure	fast imaging	Abstract#R##N##R##N#The use of a pyramid structure has been known to reduce the time required for image registration. Discussions on a required search range without backtracking, however, have been mostly experimental. In Tanimoto's example the range of 2 × 2 was insufficient, and he suggested the use of a 4 × 4 range, namely, the choice of the best of 16. However, his discussion was not complete. This paper presents a theory based on geometric rather than analog correspondence between levels. First, the upper left corner candidate and best estimate positions in template images of each level, respectively, are defined. Then a required search range is considered. It is shown that even a range of 4 × 4 is insufficient. The discussion is extended to cover the case of analog correspondence. Results obtained are applied to the registration of dynamic images using SSDA (Sequential Similarity Detection Algorithm). A substantial reduction of time is achieved by the use of a pyramid structure in comparison with a conventional method, which uses only the lowest level.	image registration	Morio Onoe;Mitsuo Sone	1987	Systems and Computers in Japan	10.1002/scj.4690181109	computer vision;mathematical optimization;computer science;mathematics;geometry	Vision	42.770143633791605	-55.552439185758224	78892
6da4cf832554b384f00dc9ee888b0c1dce429fd6	fuzzy fusion for face recognition	reconnaissance visage;imageria termica;image processing;facies;logique floue;procesamiento imagen;logica difusa;spectrum;data fusion;fuzzy integral;teoria medida;traitement image;fuzzy logic;face recognition;thermal imaging;fusion donnee;fonction appartenance;membership function;pattern recognition;imagerie thermique;reconnaissance forme;funcion pertenencia;infrared;reconocimiento patron;fusion datos;theorie mesure;measure theory	Face recognition based only on the visual spectrum is not accurate or robust enough to be used in uncontrolled environments. This paper describes a fusion of visible and infrared (IR) imagery for face recognition. In this paper, a scheme based on membership function and fuzzy integral is proposed to fuse information from the two modalities. Recognition rate is used to evaluate the fusion scheme. Experimental results show the scheme improves recognition performance substantially.	facial recognition system;uncontrolled format string	Xuerong Chen;Zhongliang Jing;Gang Xiao	2005		10.1007/11539506_83	fuzzy logic;spectrum;computer vision;infrared;facies;membership function;measure;image processing;computer science;artificial intelligence;three-dimensional face recognition;sensor fusion	Vision	45.66219272373461	-60.6999561831981	79008
55ba38e0e10f435131f77f817470c8eab1d0b983	efficient search and verification for function based classification from real range images	modelizacion;arbre recherche;image tridimensionnelle;3d segmentation;vision ordenador;base donnee;image processing;function based reasoning;validacion;analyse fonctionnelle;depth of field;database;procesamiento imagen;base dato;image classification;probabilistic approach;profondeur champ;classification;traitement image;computer vision;modelisation;probabilistic model;recognition;arbol investigacion;functional analysis;range image;enfoque probabilista;approche probabiliste;real function;classification image;fonction reelle;profundidad campo;tridimensional image;validation;vision ordinateur;object classification;functional requirement;search tree;modeling;funcion real;raw range images;imagen tridimensional;analisis funcional	In this work we propose a probabilistic model for generic object classification from raw range images. Our approach supports a validation process in which classes are verified using a functional class graph in which functional parts and their realization hypotheses are explored. The validation tree is efficiently searched. Some functional requirements are validated in a final procedure for more efficient separation of objects from non-objects. The search employs a knowledge repository mechanism that monotonically adds knowledge during the search and speeds up the classification process. Finally, we describe our implementation and present results of experiments on a database that comprises about one-hundred-and-fifty real raw range images of object instances from ten classes	algorithm;cellular automaton;class diagram;computation;database;design pattern;expect;experiment;finite-state machine;formal verification;function model;functional programming;functional requirement;high- and low-level;instance (computer science);machine learning;speedup;statistical model;verification and validation;web search engine	Guy Froimovich;Ehud Rivlin;Ilan Shimshoni;Octavian Soldea	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1016/j.cviu.2006.10.003	functional analysis;statistical model;computer vision;contextual image classification;systems modeling;image processing;biological classification;computer science;artificial intelligence;depth of field;mathematics;search tree;functional requirement;algorithm	Robotics	47.61825297956496	-58.64378950635589	79167
ebb4a3c410a1fd48e03452a45714b21c5b782aba	retrieval by shape similarity with perceptual distance and effective indexing	database indexing;indexing structures;database indexing image retrieval;distance function;comparative analysis;image databases;retrieval by shape similarity;shape indexing image databases information retrieval spatial databases image retrieval visual databases prototypes content based retrieval euclidean distance;information retrieval;prototypes;index structure;shape indexing;euclidean distance;indexing terms;large databases;shape representation;retrieving visual information;shape;indexing;computer experiment;shape similarity;indexation;spatial databases;shape retrieval;perceptual distance;content based retrieval;effective indexing;shape representation shape similarity perceptual distance effective indexing retrieving visual information large databases retrieval by shape similarity indexing structures shape retrieval image retrieval shape indexing;visual databases;image retrieval	An important problem in accessing and retrieving visual information is to provide efficient similarity matching in large databases. Though much work is being done on the investigation of suitable perceptual models and the automatic extraction of features, little attention is given to the combination of useful representations and similarity models with efficient index structures. In this paper we propose retrieval by shape similarity using local descriptors and effective indexing. Shapes are partitioned into tokens in correspondence with their protrusions, and each token is modeled according to a set of perceptually salient attributes. Shape indexing is obtained by arranging shape tokens into a suitably modified -tree index structure. Two distinct distance functions model respectively, token and shape perceptual similarity. Examples from a prototype system and computational experiences are reported for both retrieval accuracy and indexing efficiency. Shape retrieval has been tested under shape scaling, orientation changes, and partial shape occlusions. A comparative analysis of different indexing structures, for shape retrieval is presented.	database;image scaling;information retrieval;prototype;qualitative comparative analysis;shape context	Stefano Berretti;Alberto Del Bimbo;Pietro Pala	2000	IEEE Trans. Multimedia	10.1109/6046.890058	active shape model;database index;qualitative comparative analysis;computer vision;search engine indexing;computer experiment;index term;metric;image retrieval;shape;computer science;pattern recognition;euclidean distance;mathematics;prototype;world wide web;information retrieval	Vision	40.38095735135953	-59.71704492283667	79384
2d40833cef2530e9d416ad6a853bf8da3a2e9a7d	mise en correspondance de pixels pour la stéréovision binoculaire par propagation d'appariements de points d'intérêt et sondage de régions. (pixel matching for binocular stereovision by propagation of feature points matches and region-based randomized voting scheme)		Stereo matching is one of the main topics in computer vision. It consists in finding in two images of a same scene, taken from different viewpoints, the pairs of pixels which are the projections of a same scene point. Since the last twenty years, many local and global methods have been proposed to solve this problem. More recently, according to a reference evaluation protocol in the community, region-based methods showed interesting result in small-baseline binocular stereo (where images are taken nearby). The idea is to apply a colour segmentation algorithm on the images assuming that each pixel within a segment belongs to a same object surface. Then, the parameters of a surface model are computed, in the disparity space, for each segment according to initial disparities usually computed with a local method. Finally, a global optimization is performed to refine the results. A contribution of this thesis deals with a special kind of local method called seeds propagation. The search area of a correspondent is reduced to the neighbourhoods of reliable matches called seeds. This can help to reduce the computation time and to avoid some ambiguities. However, the succes of such a method depends on the choice of these seeds. In this dissertation, we give a study of the seeds selection step. We focus on feature points matching. These are special points in the image with interesting characteristics for a given application. In our case, we need pixels that can be matched with high confidence. We compare fourteen different well-known detectors linked to five correlation measures. Some of these measures are meant to be robust to one of the main challenge in stereo matching: depth discontinuities. Besides, this study gives advice on the choice of the parameters of the different techniques to be able to find the best solutions according some given criteria. Then, these seeds are used with two approaches of propagation and the results are evaluated. Another contribution deals with a new region-based approach for dense stereo matching. Different colour segmentations are used. Then, many instances of a surface model are computed for the different regions according to initial disparities selected randomly. For each pixel, each instance gives a disparity value regarded as a vote. Finally, the most voted value is selected as the final disparity. This approach is relatively easy to implement and very effective giving competitive results among the state of the art.	baseline (configuration management);binocular disparity;binocular vision;computation;computer stereo vision;computer vision;global optimization;linear algebra;mathematical optimization;pixel;randomized algorithm;randomness;scope (computer science);seeds (cellular automaton);sensor;software propagation;stereopsis;time complexity	Guillaume Gales	2011				Vision	46.14099453223161	-64.24603003777193	79509
6d43dfeb7eaa01f4ded8433e0c9987815943bae2	local sharpness distribution-based feature points matching algorithm	image processing;matrices;algorithms	An efficient descriptor and a complete scheme for removing incorrect correspondences are two essentials for accurate feature points matching in image processing and pattern recognition. This paper proposes a new rigid feature points matching algorithm. First, a new feature descriptor based on the local sharpness distribution is proposed to extract features, which leads to a feature set of extremely low dimensionality. With these features, the normalized cross-correlation coefficient and a bidirectional matching strategy are employed to generate the initial feature point correspondences. Then a complete scheme with two rules is proposed to remove the probable incorrect correspondences. Owing to these two rules based on the voting strategy and the ratio of the distances, respectively, the accuracy of feature points matching is remarkably improved. Experimental results show that the proposed algorithm is efficient for feature matching and comparisons with other algorithms show its better comprehensive performance. © 2014 SPIE and IS&T [DOI: 10.1117/1.JEI.23.1 .013011]	algorithm;coefficient;cross-correlation;feature model;image processing;image registration;image retrieval;outline of object recognition;pattern matching;pattern recognition;visual descriptor	Yue Zhao;Jianbo Su	2014	J. Electronic Imaging	10.1117/1.JEI.23.1.013011	computer vision;mathematical optimization;image processing;feature extraction;computer science;machine learning;pattern recognition;mathematics;feature;algorithm;matrix	Vision	40.5565956433924	-56.97567233259719	79722
80c83ce6bad894017683f04e787951580f6cc989	an iterative multi-scale tensor voting scheme for perceptual grouping of natural shapes in cluttered backgrounds	second order;iterative method;object recognition;vision ordenador;clutter;unm;image segmentation;protocole transmission;grouping;sorting;methode echelle multiple;edge detection;tensor voting;texture image;perceptual grouping;metodo escala multiple;reconnaissance objet;posterior probability;segmentation;tria;power method;gray scale;electronic vote;image texture;computer vision;deteccion contorno;metodo iterativo;detection contour;detection objet;protocolo transmision;fouillis echo;percepcion visual;methode iterative;confusion eco;triage;probabilite a posteriori;segmentation image;probabilidad a posteriori;pattern recognition;perception visuelle;group process;visual perception;vision ordinateur;multiscale method;agrupamiento;reconnaissance forme;multi scale analysis;reconocimiento patron;boundary detection;echelle gris;escala gris;vote electronique;object detection;groupage;voto electronico;transmission protocol	Grouping processes, which ‘‘organize” a given data by eliminating the irrelevant items and sorting the rest into groups, each corresponding to a particular object, can provide reliable pre-processed information to higher level computer vision functions, such as object detection and recognition. In this paper, we consider the problem of grouping oriented segments in highly cluttered images. In this context, we have developed a general and powerful method based on an iterative, multiscale tensor voting approach. Segments are represented as second-order tensors and communicate with each other through a voting scheme that incorporates the Gestalt principles of visual perception. The key idea of our approach is removing background segments conservatively on an iterative fashion, using multi-scale analysis, and re-voting on the retained segments. We have performed extensive experiments to evaluate the strengths and weaknesses of our approach using both synthetic and real images from publicly available datasets including the Williams and Thornber’s fruit-texture dataset [L. Williams, Fruit and texture images. Available from: <http://www.cs.unm.edu/~williams/saliency.html>, 2008 (last viewed in July 2008)] and the Berkeley segmentation dataset [C.F.P. Arbelaez, D. Martin, The berkeley segmentation dataset and benchmark. Available from: <http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/>, 2008 (last viewed in July 2008)]. Our results and comparisons indicate that the proposed method improves segmentation results considerably, especially under severe background clutter. In particular, we show that using the iterative multiscale tensor voting approach to post-process the posterior probability map, produced by segmentation methods, improves boundary detection results in 84% of the grayscale test images in the Berkeley segmentation benchmark. 2008 Elsevier Inc. All rights reserved.	advanced audio coding;benchmark (computing);clutter;color vision;computer vision;experiment;f1 score;gaussian blur;gestalt psychology;grayscale;ip multimedia subsystem;iteration;iterative method;object detection;real-time locating system;relevance;sensitivity and specificity;sorting;synthetic intelligence;thresholding (image processing);xslt/muenchian grouping;xfig	Leandro A. Loss;George Bebis;Mircea Nicolescu;Alexei N. Skurikhin	2009	Computer Vision and Image Understanding	10.1016/j.cviu.2008.07.011	image texture;computer vision;edge detection;power iteration;visual perception;computer science;sorting;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;clutter;iterative method;image segmentation;posterior probability;segmentation;second-order logic;group dynamics;grayscale	Vision	46.868707674933304	-59.50009781317758	79812
2b38a3c0360286bfaf4bf9ca6ca7ab1a3a488950	constrained active region models for fast tracking in color image sequences	modelizacion;image features;vision ordenador;algorithm performance;image segmentation;image processing;complexite calcul;etude experimentale;edge detection;procesamiento imagen;active region;aperture problem;search method;least square method;segmentation;traitement image;computer vision;algorithme;modelisation;algorithm;robot arm;complejidad computacion;gradient descent;computational complexity;resultado algoritmo;affine transformation;image sequence;least square;performance algorithme;vision ordinateur;secuencia imagen;imagen color;region growing;shear force;modeling;deformable model;estudio experimental;segmentacion;image couleur;sequence image;color image;algoritmo	Image segmentation is a fundamental problem in computer vision, for which deformable models offer a partial solution. Most deformable models work by performing some kind of edge detection; complementary region growing methods have not often been used. As a result, deformable models that track regions rather than edges have yet to be developed to a great extent.Active region modelsare a relatively new type of deformable model driven by aregion energythat is a function of the statistical characteristics of an image. This paper describes the use ofconstrainedactive region models for frame-rate tracking in color video images on widely available computer hardware. Two of the many color representations now in use are reviewed for this purpose: the intensity-based RGB space and the more intuitive HSV space.NormalizedRGB, which is essentially a measure of hue and saturation, emerges as the preferred representation because it is invariant to illumination changes and can be obtained from many frame-grabbers via a simple fast software transformation. Three types of motion are examined for constraining deformable models:rigidmodels can only translate and rotate to fit image features;conformalmodels can also change size;affinemodels exhibit two kinds of shearing in addition to the other components. Two methods are described for producing affine motion, given the desired unconstrained motion calculated by searching for local energy minima lying perpendicular to the model boundary. An existing method, based on iterative gradient descent, computes translating, rotating, scaling, and shearing forces which can be combined to produce affine and other types of motion. A faster, more accurate method uses least-squares minimization to approximate the desired motion; with this method it is also possible to derive specific equations for rigid and conformal motion and to correct for the aperture problem associated with the perpendicular search method. The advantages of the new least-squares method are illustrated by using it to drive an active region model via an affine transformation which tracks the movements of a robot arm at frame rate in color video images.	color image	James P. Ivins;John Porrill	1998	Computer Vision and Image Understanding	10.1006/cviu.1997.0653	computer vision;image processing;computer science;mathematics;geometry;least squares;computer graphics (images)	Vision	50.36241380405715	-57.449603948656744	79830
51f969f4361af607bb5bed3706ea4376fc8a15d8	multiple camera people detection and tracking using support integration	faux positif;teledetection;homography constraint;evaluation performance;video surveillance;deteccion blanco;performance evaluation;filtro kalman;multi view technology;televigilancia;evaluacion prestacion;localization;multiple view integration;filtre kalman;technique video;kalman filter;arriere plan;localizacion;tecnica video;falso positivo;multiple views;detection cible;algorithme;algorithm;remote supervision;background;localisation;foreground;video cameras;telesurveillance;remote sensing;robustesse;homographie;homography;background subtraction;teledeteccion;poursuite cible;camera video;avant plan;video technique;robustness;ground truth;people tracking;target tracking;false positive;target detection;technologie multi vues;robustez;video surveillance and monitoring;algoritmo	This paper proposes a method to locate and track people by combining evidence from multiple cameras using the homography constraint. The proposed method use foreground pixels from simple background subtraction to compute evidence of the location of people on a reference ground plane. The algorithm computes the amount of support that basically corresponds to the “foreground mass” above each pixel. Therefore, pixels that correspond to ground points have more support. The support is normalized to compensate for perspective effects and accumulated on the reference plane for all camera views. The detection of people on the reference plane becomes a search for regions of local maxima in the accumulator. Many false positives are filtered by checking the visibility consistency of the detected candidates against all camera views. The remaining candidates are tracked using Kalman filters and appearance models. Experimental results using challenging data from PETS’06 show good performance of the method in the presence of severe occlusion. Ground truth data also confirms the robustness of the method.	accumulator (computing);algorithm;background subtraction;ground truth;homography (computer vision);kalman filter;maxima and minima;pixel	Thiago T. Santos;Carlos Hitoshi Morimoto	2011	Pattern Recognition Letters	10.1016/j.patrec.2010.05.016	kalman filter;computer vision;simulation;internationalization and localization;background subtraction;homography;type i and type ii errors;ground truth;computer science;foreground-background;robustness;computer graphics (images)	Vision	48.826244053500666	-57.00873521357211	79946
ae1de0359f4ed53918824271c888b7b36b8a5d41	low-cost automatic inpainting for artifact suppression in facial images		Facial images are often used in applications that need to recognize or identify persons. Many existing facial recognition tools have limitations with respect to facial image quality attributes such as resolution, face position, and artifacts present in the image. In this paper we describe a new low-cost framework for preprocessing low-quality facial images in order to render them suitable for automatic recognition. For this, we first detect artifacts based on the statistical difference between the target image and a set of pre-processed images in the database. Next, we eliminate artifacts by an inpainting method which combines information from the target image and similar images in our database. Our method has low computational cost and is simple to implement, which makes it attractive for usage in low-budget environments. We illustrate our method on several images taken from public surveillance databases, and compare our results with existing inpainting techniques.	algorithmic efficiency;circuit restoration;computation;database;facial recognition system;image quality;image resolution;inpainting;list of system quality attributes;preprocessor;requirement;zero suppression	André Sobiecki;Alexandru Telea;Gilson A. Giraldi;Luiz Antônio Pereira Neves;Carlos E. Thomaz	2013			computer vision;computer science;pattern recognition;data mining;face hallucination	Vision	45.997130335237955	-55.192868266081746	80004
2fcd0a06f1c9b943f7afd019a3aa72c706f9f96e	an optimum solution for scale-invariant object recognition based on the multiresolution approximation	transformation ondelette;analisis imagen;object recognition;learning algorithm;image processing;curvature scale space;etude experimentale;edge detection;aproximacion;procesamiento imagen;pairing;algorithme apprentissage;traitement image;approximation;deteccion contorno;detection contour;wavelet transform;pattern matching;fast algorithm;pattern recognition;image analysis;transformacion ondita;reconnaissance forme;continuous wavelet transform;emparejamiento;reseau neuronal;reconocimiento patron;appariement;algoritmo aprendizaje;analyse image;estudio experimental;red neuronal;scale invariance;wavelet transformation;neural network	This paper presents a multiresolution approximation approach to obtaining boundary representations for object recognition. Our technique combines a multiresolution approximation and the curvature scale-space representation for obtaining representations. Our research consists of two main parts. In the first part of our research, we introduce the continuous multiresolution approximation (CMA) in terms of the continuous wavelet transform (CWT). Then we implement a fast algorithm to compute the CMA. We apply the CMA to a boundary to obtain approximations of the boundary at various resolutions. The CMA provides a consistent interpretation of objects with scale-variations. Moreover, we can quickly compute our representations by using the fast algorithm for the CMA. In the second part, we propose three representations for object recognition which cover most boundary-based object recognition problems. All three representations use the approximations obtained by the CMA. Each representation has different features and covers different types of matching problems but all representations are constructed by using curvature zero crossings of the approximations. Our representations provide a general but reliable solution to most boundary based object matching problems. Finally, we investigate the properties of our representations such as validity, efficiency, and reliability. We verified our results experimentally to demonstrate the feasibility of using our representations for object recognition. ( 1998 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved Object recognition Wavelet transform Neural network Pattern matchinmg Multiresolution approximation Image analysis	apple a5;apple a7;approximation algorithm;artificial neural network;cma-es;coefficient;complex wavelet transform;continuous wavelet;decimation (signal processing);discrete wavelet transform;expanded memory;experiment;image analysis;image scaling;kilobyte;medical ultrasound;outline of object recognition;pattern recognition;reliability engineering;scale space;sharp mz;time complexity	Sung H. Yoon;Jung H. Kim;Winser E. Alexander;Seong M. Park;Kwang H. Sohn	1998	Pattern Recognition	10.1016/S0031-3203(97)00111-8	computer vision;image analysis;edge detection;continuous wavelet transform;image processing;computer science;cognitive neuroscience of visual object recognition;approximation;scale invariance;pattern matching;pairing;mathematics;geometry;algorithm;wavelet transform	Vision	47.143873990163144	-61.48179224119262	80067
3889606fd5afa9eadd0075eaa8329b8e4450549c	wireless body area sensor network authentication using voronoi diagram of retinal vascular pattern	basn security;authentication;biometrics;retina;body area networks;voronoi diagram	This paper focuses on the problem of human authentication in Body Area Sensor Network using retina. In this proposed method, Voronoi Diagram (VD), a well known technique in computational geometry, is generated from the topological structure of the bifurcation points, considered as vertices, obtained from the blood vessels found in the retina which can further be used in the process of identification and verification. Since the structure formed by bifurcation points is unique in every retina, hence the calculated VD is also unique and provides the foundation of developing the system of retina based identification. The approach presented in this paper rejects any non-similar retina instantly while maintaining excellent accuracy and performance. Another advantage of using this approach is that it does not require the localization of Optic Disc and the Fovea, which most of the existing algorithms have required, and, experimental results proved that VD is efficient in template matching and storage requirements. Additionally, our proposed algorithm is invariant against any geometric transformation (i.e. scaling, translation and rotation).	algorithm;authentication;bifurcation theory;computation;computational geometry;image scaling;requirement;template matching;voronoi diagram	M. Ghazanfar Ullah;Bhawani Shankar Chowdhry;A. Q. Rajput;A. K. Baloch;Ahsan Ahmad Ursani;Shiraz Latif	2014	Wireless Personal Communications	10.1007/s11277-014-1726-y	computer vision;voronoi diagram;computer science;theoretical computer science;authentication;computer security;biometrics	Robotics	41.587103529282174	-63.82552311632239	80184
5e245060719e3fb7353b28d7e7ef56c64ba508e6	a continuous linear optimal transport approach for pattern analysis in image datasets	optimal transport;pattern visualization;generative image modeling;linear embedding	We present a new approach to facilitate the application of the optimal transport metric to pattern recognition on image databases. The method is based on a linearized version of the optimal transport metric, which provides a linear embedding for the images. Hence, it enables shape and appearance modeling using linear geometric analysis techniques in the embedded space. In contrast to previous work, we use Monge's formulation of the optimal transport problem, which allows for reasonably fast computation of the linearized optimal transport embedding for large images. We demonstrate the application of the method to recover and visualize meaningful variations in a supervised-learning setting on several image datasets, including chromatin distribution in the nuclei of cells, galaxy morphologies, facial expressions, and bird species identification. We show that the new approach allows for high-resolution construction of modes of variations and discrimination and can enhance classification accuracy in a variety of image discrimination problems.	arc diagram;body dysmorphic disorders;computation (action);embedding;geometric analysis;image resolution;pattern recognition;published database;supervised learning;transportation theory (mathematics)	Soheil Kolouri;Akif Burak Tosun;John A. Ozolek;Gustavo K. Rohde	2016	Pattern recognition	10.1016/j.patcog.2015.09.019	computer vision;mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics;algorithm;statistics	Vision	41.23201987080228	-53.10052509793638	80259
999d02b03e9bb2f6d4289a2ad9fe3564f83495fe	zerotree wavelet based image quilting for fast texture synthesis	transformation ondelette;analisis imagen;image processing;image matching;texture synthesis;texture image;procesamiento imagen;pattern synthesis;analyse multiresolution;traitement image;automatic generation;limit set;image texture;synthese forme;pattern matching;pattern recognition;image analysis;transformacion ondita;concordance forme;reconnaissance forme;reconocimiento patron;multi resolution;multiresolution analysis;sintesis forma;analyse image;wavelet transformation;appariement image;analisis multiresolucion	In this paper we propose a fast DWT based multi-resolution texture synthesis algorithm in which coefficient blocks of the spatio-frequeny components of the input texture are efficiently stitched together (quilted) to form the corresponding components of the synthesised output texture. We propose the use of an automatically generated threshold to determine the significant coefficients which acts as elements of a matching template used in the texture quilting process. We show that the use of a limited set of, visually significant coefficients, regardless of their level of resolution, not only reduces the computational cost, but also results in more realistic texture synthesis. We use popular test textures to compare our results with that of the existing state-or-the-art techniques. Many application scenarios of the proposed algorithm are also discussed.	computable function;regular grid;texture synthesis;wavelet	Dhammike Saranath Wickramanayake;Eran A. Edirisinghe;Helmut E. Bez	2005		10.1007/11492429_47	multiresolution analysis;image texture;limit set;computer vision;image analysis;image processing;computer science;pattern matching;mathematics;texture compression;texture synthesis;texture filtering;computer graphics (images)	Graphics	50.95534623095626	-62.35052550279208	80340
ca85cff4be5d337d5a18ee5c13017d0183dfecf1	a multiresolution frequency domain method for estimating affine motion parameters	affine motion parameters;synthetic image sequences;synthetic image sequences multiresolution frequency domain method affine motion parameters motion estimation 2 d motion six parameter affine model coarse fine tracking algorithm global motion natural image sequences;image motion analysis;image resolution;optical noise;six parameter affine model;natural image sequences;frequency domain analysis;multiresolution modeling;frequency estimation;motion estimation;coarse fine tracking algorithm;natural images;frequency domain analysis frequency estimation motion estimation parameter estimation optical noise spatial resolution image sequences tracking optical sensors image motion analysis;2 d motion;quadtrees motion estimation tracking image sequences frequency domain analysis parameter estimation image resolution;optical sensors;parameter estimation;frequency domain;global motion;quadtrees;tracking;multiresolution frequency domain method;image sequences;spatial resolution	A n o vel approach to motion estimation is presented. The scheme employs a multiresolution model of 2-D motion, in which the motion within local regions at diierent scales is described in terms of a six parameter aane model. A frequency domain method is used to estimate the local aane motion parameters and a coarse-ne tracking algorithm is used to determine the global motion eld. Results of experiments performed on synthetic and natural image sequences illustrate the eeectiveness of the approach.	algorithm;elemental;experiment;fast fourier transform;kinetic data structure;media foundation;motion estimation;synthetic intelligence	Stefan Krüger;Andrew Calway	1996		10.1109/ICIP.1996.559445	computer vision;mathematical optimization;image resolution;computer science;motion estimation;mathematics;geometry;affine shape adaptation;motion field;frequency domain	Vision	52.502484063110025	-59.693965200156434	80513
9b97e5fe35bd2fddc6ae39fe160061355cbd81c5	a new learning strategy for stereo matching derived from a fuzzy clustering method	mahalanobis distance;learning process;fuzzy c mean;analyse amas;cluster;comparative analysis;processus apprentissage;learning;gestion;amas;image understanding;correspondence problem;prise decision;operations research;classification;systeme adaptatif;similitude;aprendizaje;fuzzy clustering;apprentissage;cluster analysis;learning methods;stereo matching;minimum distance;recherche operationnelle;multiple decision;similarity;adaptive system;pattern recognition;sistema adaptativo;distance mahalanobis;decision multiple;monton;reconnaissance forme;similitud;reconocimiento patron;toma decision;management;learning strategies;clasificacion;investigacion operacional	This paper presents an approach to the local stereo correspondence problem. The primitives or features used are groups of collinear connected edge points called segments. Each segment has several associated attributes or properties. We have veri ed that the di erences of the attributes for the true matches cluster in a cloud around a center. Then for each current pair of primitives we compute a distance between the di erence of its attributes and the cluster center. The correspondence is established in the basis of the minimum distance criterion (similarity constraint). We have designed an image understanding system to learn the best representative cluster center. For such purpose a new learning method is derived from the Fuzzy cMeans (FcM) algorithm where the dispersion of the true samples in the cluster is taken into account through the Mahalanobis distance. This is the main contribution of this paper. A better performance of the proposed local stereo-matching learning method is illustrated with a comparative analysis between classical local methods without learning. c © 2000 Elsevier Science B.V. All rights reserved.	algorithm;cluster analysis;computer stereo vision;computer vision;correspondence problem;fuzzy clustering;qualitative comparative analysis	Gonzalo Pajares;Jesús Manuel de la Cruz	2000	Fuzzy Sets and Systems	10.1016/S0165-0114(97)00382-5	qualitative comparative analysis;similarity;fuzzy clustering;biological classification;computer science;artificial intelligence;mahalanobis distance;similitude;adaptive system;machine learning;pattern recognition;mathematics;cluster analysis;correspondence problem;cluster	AI	44.90740040133015	-62.7672167356463	80582
a408bb358344b25c606f16dfcd7677688706307c	a robust fuzzy local information c-means clustering algorithm	fuzzy c means algorithm;cluster algorithm;evaluation performance;pattern clustering;fuzzy c mean;spatial constraints;image segmentation;performance evaluation;image processing;pattern clustering fuzzy set theory image segmentation;c means clustering algorithm;image detail preservation;algoritmo borroso;evaluacion prestacion;spatial constraints clustering fuzzy c means fuzzy constraints gray level constraints image segmentation;procesamiento imagen;imagen nivel gris;image bruitee;noise robustness;traitement image;image clustering;fuzzy set theory;similitude;noise measurement;gray level information;imagen sonora;smoothing methods;algorithms cluster analysis fuzzy logic image enhancement image interpretation computer assisted pattern recognition automated reproducibility of results sensitivity and specificity;noise level;image edge detection;clustering;image color analysis;fuzzy algorithm;robustesse;noisy image;fuzzy c means;image niveau gris;segmentation image;signal classification;similarity;clustering algorithms image segmentation clustering methods smoothing methods noise robustness image edge detection noise measurement noise level image color analysis image texture analysis;classification signal;algorithme flou;image segmentation robust fuzzy local information c means clustering algorithm image clustering gray level information local spatial information image detail preservation;clustering algorithms;robustness;gray level constraints;image texture analysis;similitud;robust fuzzy local information;classification automatique;fuzzy constraints;clustering methods;automatic classification;grey level image;clasificacion automatica;similarity measure;spatial information;local spatial information;robustez	This paper presents a variation of fuzzy c-means (FCM) algorithm that provides image clustering. The proposed algorithm incorporates the local spatial information and gray level information in a novel fuzzy way. The new algorithm is called fuzzy local information C-Means (FLICM). FLICM can overcome the disadvantages of the known fuzzy c-means algorithms and at the same time enhances the clustering performance. The major characteristic of FLICM is the use of a fuzzy local (both spatial and gray level) similarity measure, aiming to guarantee noise insensitiveness and image detail preservation. Furthermore, the proposed algorithm is fully free of the empirically adjusted parameters (a, ¿g, ¿s, etc.) incorporated into all other fuzzy c-means algorithms proposed in the literature. Experiments performed on synthetic and real-world images show that FLICM algorithm is effective and efficient, providing robustness to noisy images.	algorithm;biologic preservation;cluster analysis;experiment;fuzzy clustering;fuzzy cognitive map;grayscale;population parameter;precomputation;radiology information systems;similarity measure;synthetic intelligence;statistical cluster	Stelios Krinidis;Vassilios Chatzis	2010	IEEE Transactions on Image Processing	10.1109/TIP.2010.2040763	computer vision;fuzzy clustering;image processing;fuzzy classification;computer science;machine learning;pattern recognition;mathematics;cluster analysis	Vision	45.89933037967046	-64.0913159056901	80693
0f821e2e666a5a2fd8bd406c53d80f18f3cdfb4a	motion segmentation using an occlusion detector	aperture problem;motion segmentation;scale space;synthetic data	We present a novel method for the detection of motion boundaries in a video sequence based on differential properties of the spatio-temporal domain. Regarding the video sequence as a 3D spatio-temporal function, we consider the second moment matrix of its gradients (averaged over a local window), and show that the eigenvalues of this matrix can be used to detect occlusions and motion discontinuities. Since these cannot always be determined locally (due to false corners and the aperture problem), a scale-space approach is used for extracting the location of motion boundaries. A closed contour is then constructed from the most salient boundary fragments, to provide the final segmentation. The method is shown to give good results on pairs of real images taken in general motion. We use synthetic data to show its robustness to high levels of noise and illumination changes; we also include cases where no intensity edge exists at the location of the motion boundary, or when no parametric motion model can describe the data.	gradient;moment matrix;scale space;synthetic data	Doron Feldman;Daphna Weinshall	2006		10.1007/978-3-540-70932-9_3	computer vision;structure from motion;scale space;motion perception;quarter-pixel motion;computer science;motion estimation;mathematics;geometry;motion field;motion compensation;synthetic data	Vision	51.87453090145541	-54.22697812832039	80700
013f8aca85caa23cf9d726e7ba9c01b14a4fc374	determination of the reference point of a fingerprint based on multiple levels of representation	paints;fingerprint recognition quantization computer graphics image processing image analysis error analysis testing image databases nist estimation error;image quality fingerprint reference point determination morphologic characteristics quantized orientation image;orientation image fingerprint singular points;fingerprint reference point determination;morphologic characteristics;singular points;data mining;reference point;error analysis;indexes;orientation image;quantized orientation image;image quality;error rate;fingerprint;coherence;estimation error;fingerprint identification;noise;singular point	In this article we propose a technique to detect the reference point of a fingerprint based on the main supposition that the crests belonging to the superior area of reference point usually have a orientation quantized of 0o. To take advantage of this fact it is accomplished an analysis of the orientation image considering their multiple levels of representation in relation to their values of quantization. This is a new approach that allows the use the morphologic characteristics of the quantized orientation image for each value of quantization. The technique presents some important characteristics: adaptability according to the quality of the image and the possibility of detecting the reference point of the fingerprints A and TA with acceptable error rate for these type of fingerprint. The technique is tested in the whole database of DB4 of NIST getting an estimation error of the reference point of 8:32% for a total of 4;000 images.	fingerprint;sensor	Jorge L. A. Samatelo;Evandro O. T. Salles	2009	2009 XXII Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI.2009.35	computer vision;theoretical computer science;pattern recognition;mathematics	Vision	42.91984250421307	-63.60441248754681	80739
2b435ee691718d0b55d057d9be4c3dbb8a81526e	surf-face: face recognition under viewpoint consistency constraints	cmu;interest points;speeded up robust features;face recognition;local features;feature extraction	We analyze the usage of Speeded Up Robust Features (SURF) as local descriptors for face recognition. The effect of different feature extraction and viewpoint consistency constrained matching approaches are analyzed. Furthermore, a RANSAC based outlier removal for system combination is proposed. The proposed approach allows to match faces under partial occlusions, and even if they are not perfectly aligned or illuminated. Current approaches are sensitive to registration errors and usually rely on a very good initial alignment and illumination of the faces to be recognized. A grid-based and dense extraction of local features in combination with a block-based matching accounting for different viewpoint constraints is proposed, as interest-point based feature extraction approaches for face recognition often fail. The proposed SURF descriptors are compared to SIFT descriptors. Experimental results on the AR-Face and CMU-PIE database using manually aligned faces, unaligned faces, and partially occluded faces show that the proposed approach is robust and can outperform current generic approaches.	benchmark (computing);experiment;facial recognition system;feature extraction;interest point detection;michael j. fischer;random sample consensus;scale-invariant feature transform;speeded up robust features;switzerland;viewpoint	Philippe Dreuw;Pascal Steingrube;Harald Hanselmann;Hermann Ney	2009		10.5244/C.23.7	facial recognition system;computer vision;speech recognition;feature extraction;computer science;machine learning;pattern recognition;three-dimensional face recognition	Vision	42.967073737873285	-53.338999876613066	80740
26657f2212e37b5947940a0bb91eb09ca802efec	key point reduction in sift descriptor used by subtractive clustering	object recognition;pattern clustering;illumination;time complexity key point reduction subtractive clustering rotation scale affine illumination image extraction matching phases recognition phases data set aloi base sift descriptor;time complexity;matching phases;data set aloi;image matching;base sift descriptor;training;subtractive clustering object recognition sift descriptor;subtractive clustering;data mining;scale;key point reduction;image extraction;accuracy;vectors;computational complexity;feature extraction;affine;recognition phases;clustering algorithms;pattern clustering computational complexity feature extraction image matching;rotation;vectors clustering algorithms feature extraction accuracy training object recognition data mining;sift descriptor	The SIFT descriptor is one of the most widely used descriptors and is very stable in regard to changes in rotation, scale, affine, illumination, etc. This method is based on key points extracted from the image. If there are many such points, a lot of time will be needed in the matching and recognition phases. For this reason, we have tried in this article to use the clustering technique in order to reduce the number of key points by omitting similar points. In other words, subtractive clustering is used to select key points which are more distinct from and less similar to other points. In the section on conclusions, a successful implementation of this method is presented. The efficiencies of the proposed algorithm and of the base SIFT algorithm on the data set ALOI were investigated and it was observed that by adding this method to the base SIFT descriptor the rate of recognition increases by two percent and the time complexity decreases by 1.035728 seconds.	algorithm;cluster analysis;illumination (image);scale-invariant feature transform;time complexity	Reza Javanmard Alitappeh;Kossar Jeddi Saravi;Fariborz Mahmoudi	2012	2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)	10.1109/ISSPA.2012.6310683	time complexity;computer vision;scale;feature extraction;rotation;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;affine transformation;mathematics;accuracy and precision;cluster analysis;computational complexity theory;algorithm	Robotics	40.486586315299405	-57.12811829349322	80807
8664a0eb70aefd83cbda806b3879319ad9fc951c	3d pose estimation by directly matching polyhedral models to gray value gradients	modelizacion;eficacia sistema;architecture systeme;estimation mouvement;polyedre;image processing;automatic vehicle monitoring;etude experimentale;edge detection;poliedro;estimacion movimiento;3d pose estimation;extraction forme;performance systeme;procesamiento imagen;polyhedron;motion estimation;system performance;traitement image;computer vision;deteccion contorno;algorithme;modelisation;algorithm;detection contour;polyhedral model;extraccion forma;feature extraction;image sequence;arquitectura sistema;secuencia imagen;system architecture;modeling;estudio experimental;pattern extraction;sequence image;algoritmo;pose estimation	This contribution addresses the problem of pose estimation and tracking of vehicles in image sequences from traffic scenes recorded by a stationary camera. In a new algorithm, the vehicle pose is estimated by directly matching polyhedral vehicle models to image gradients without an edge segment extraction process. The new approach is significantly more robust than approaches that rely on feature extraction since the new approach exploits more information from the image data. We successfully tracked vehicles that were partially occluded by textured objects, e.g., foliage, where a previous approach based on edge segment extraction failed. Moreover, the new pose estimation approach is also used to determine the orientation and position of the road relative to the camera by matching an intersection model directly to image gradients. Results from various experiments with real world traffic scenes are presented.	3d pose estimation;algorithm;experiment;feature extraction;image gradient;polyhedral;stationary process	Henner Kollnig;Hans-Hellmut Nagel	1997	International Journal of Computer Vision	10.1023/A:1007927317325	computer vision;simulation;systems modeling;pose;edge detection;3d pose estimation;image processing;feature extraction;computer science;motion estimation;polyhedron	Vision	48.44411074687237	-57.2315307910557	80831
e7583277c82f556e9bd0db06f9b77d70daf1f212	facial expression recognition based on multiple base shapes		Geometric variation is one of the important components deteriorating the facial expression recognition performance. Aligning the face image to a base shape is a commonly used preprocess step to alleviate the variation. However, the assumption of single base shape can not necessarily guarantee the best performance. In this paper, we propose for the first time a facial expression recognition framework based on multiple base shapes, which aims to minimize the geometric variation between face images with the same facial expression and retain the geometric shape difference between face images with different facial expressions. For a new sample, a weighed vote based criterion is used to give the final predicted facial expression given multiple base shapes. Experimental results on CK+ (Extended Cohn-Kanade) and JAFFE (Japanese Female Facial Expression databases) show the effectiveness of proposed method.		Lijun Cai;Lei Huang;Changping Liu	2015		10.1007/978-3-319-25417-3_45	geometric shape;facial expression;mathematics;artificial intelligence;pattern recognition	Vision	42.69694573207665	-53.213169829569935	80888
00521c4bec2d3cf277263574513a1bc30f9f5986	two novel real-time local visual features for omnidirectional vision	vision omnidirectionnelle;traitement signal;evaluation performance;vision ordenador;omnidirectional vision;vision robot;performance evaluation;panoramic photography;real time;evaluacion prestacion;database;base dato;local visual feature;photographie panoramique;fotografia panoramica;computer vision;fast;algorithme;algorithm;robot vision;cs lbp;feature extraction;signal processing;vision omnidireccional;temps reel;base de donnees;lbp;visual features;pattern recognition;tiempo real;vision ordinateur;panoramic image;feature descriptor;reconnaissance forme;extraction caracteristique;reconocimiento patron;procesamiento senal;feature detector;algoritmo	Two novel real-time local visual features, namely FAST+LBP and FAST+CSLBP, are proposed in this paper for omnidirectional vision. They combine the advantages of two computationally simple operators by using FAST as the feature detector, and LBP and CS-LBP operators as feature descriptors. The matching experiments of the panoramic images from the COLD database were performed to determine their optimal parameters, and to evaluate and compare their performance with SIFT. The experimental results show that our algorithms perform better, and features can be extracted in real-time. Therefore our local visual features can be applied to those computer/robot vision tasks with high real-time requirements.	algorithm;belief propagation;cs-cipher;experiment;feature model;local binary patterns;real-time clock;real-time locating system;requirement;scale-invariant feature transform;tom;timo sirainen	Huimin Lu;Zhiqiang Zheng	2010	Pattern Recognition	10.1016/j.patcog.2010.06.020	computer vision;local binary patterns;simulation;feature extraction;computer science;signal processing;feature detection;computer graphics (images)	Vision	46.813558485553564	-58.19501708069437	81139
8ab96996217199c23930948034611395d4caa7fa	sparse patch-guided deformation estimation for improved image registration		This paper presents a novel patch-guided initial deformation estimation framework for improving performance of the existing registration algorithms. It is challenging for the registration algorithm to directly align two images with large anatomical shape difference, when no good initial deformation is provided. Inspired by the patch-based multi-atlases segmentation method, we propose to estimate the initial deformation between two images (under registration) in a patch-by-patch fashion. Specifically, after obtaining the sparse representation for each local patch in the subject by using the training patches in the over-complete dictionary that include both patches and their associated deformations from the training images, the initial deformation for each local subject patch can be predicted by those estimated sparse coefficients. More specifically, after registering all training images to the template in the training stage, the following three steps can be used to register any given subject image. First, for each key point in the subject, we can construct a coupled dictionary from the nearby patches in the training images and their associated deformations, and can then use this dictionary to seek for sparse representation of the respective subject patch. The estimated sparse coefficients can be used to fuse the associated deformations in the dictionary, for estimating the initial deformation for the respective subject key point. Second, after estimating the initial deformations on a small number of key points in the subject, thin-plate spline (TPS) can be applied to interpolating the dense deformation field. Finally, we can apply any existing deformable registration method (with reasonable performance) to estimate the remaining deformation from the template to subject. Experimental results on both simulated and real data show that our patchguided deformation estimation framework can allow for more accurate registration than the direct use of the original methods for registration.	algorithm;align (company);b-spline;coefficient;dictionary;image registration;interpolation;sparse approximation;sparse matrix;thin plate spline	Minjeong Kim;Guorong Wu;Dinggang Shen	2012		10.1007/978-3-642-35428-1_7	artificial intelligence;pattern recognition;deformation (mechanics);computer science;computer vision;interpolation;sparse approximation;small number;image registration;spline (mathematics)	Vision	51.80341291206533	-52.91809561670767	81342
9d11b5465e40046ddf034409995a297b9b264066	retrieving multispectral satellite images using physics-based invariant representations	satellite images;texture;color constancy;information retrieval;color;image database;search strategy;spatial structure;image texture;computer vision;physical characteristic;recognition;image retrieval satellites image databases remote sensing content based retrieval lighting atmospheric modeling information retrieval spatial databases application software;machine vision;remote sensing;satellite image;united states multispectral satellite images physics based invariant representations robust content based retrieval ground cover multispectral distributions multispectral spatial structure labeled classes;physical model;content based retrieval;geometric structure;information retrieval visual databases remote sensing image texture;visual databases;image retrieval	We present a set of algorithms and a search strategy for the robust content-based retrieval of multispectral satellite images. Since the property of interest in these images is usually the physical characteristics of ground cover, we use representations and methods that are invariant to illumination and atmospheric conditions. The representations and algorithms are derived for this application from a physical model for the formation of multispectral satellite images. The use of several representations and algorithms is necessary to interpret the diversity of physical and geometric structure in these images. Algorithms are used that exploit multispectral distributions, multispectral spatial structure, and labeled classes. The performance of the system is demonstrated on a large set of multispectral satellite images taken over different areas of the United States under different illumination and atmospheric conditions.	algorithm;multispectral image	Glenn Healey;Amit Jain	1996	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.531804	image texture;computer vision;machine vision;image retrieval;physical model;computer science;multispectral pattern recognition;texture;color constancy;information retrieval	Vision	39.98931987541764	-60.70945390154684	81358
0217380908642d79a05d8db92a775081c94f684a	finding boundaries in natural images: a new method using point descriptors and area completion	analisis imagen;traitement signal;vision ordenador;image segmentation;edge detection;analisis forma;texture image;natural images;image texture;computer vision;deteccion contorno;detection contour;signal processing;segmentation image;image analysis;vision ordinateur;pattern analysis;procesamiento senal;analyse image;analyse forme	We develop an approach to image segmentation for natural scenes containing image texture. One general methodology which shows promise for solving this problem is to characterize textured regions via their responses to a set of filters. However, this approach brings with it many open questions, including how to combine texture and intensity information into a common descriptor and how to deal with the fact that filter responses inside textured regions are generally spatially inhomogeneous. Our goal in this paper is to introduce two new ideas which address these open questions and to demonstrate the application of these ideas to the segmentation of natural images. The first idea consists of a novel means of describing points in natural images and an associated distance function for comparing these descriptors. This distance function is aided in textured regions by the use of the second idea, a new process introduced here which we have termed area completion. Experimental segmentation results which incorporate our proposed approach into the Normalized Cut framework of Shi and Malik are provided for a variety of natural images.	data descriptor;digital library;experiment;feature model;feature vector;ibm notes;image segmentation;image texture;synthetic data	Serge J. Belongie;Jitendra Malik	1998		10.1007/BFb0055702	image texture;computer vision;image analysis;edge detection;computer science;signal processing;image segmentation;computer graphics (images)	Vision	46.084560030805605	-62.45298441245918	81687
c5b8266e4bb174e775b2d6db5c920ec9aee3f2f4	efficient detection and extraction of color objects from complex scenes	image recognition;object recognition;optimisation;false positive identification avoidance color object detection color object extraction complex scenes cluttered scene statistical color similarity spatial color similarity color region adjacent graphs rag 1d histograms rgb color space his color space histogram intersection hi similarity measure statistical color distribution;color space;object detection layout histograms shape image segmentation robustness application software surveillance computer industry inspection;region adjacency graph;statistical analysis;image colour analysis;spatial relationships;optimisation object detection object recognition image recognition image colour analysis statistical analysis;false positive;similarity measure;object detection	An efficient method to detect and extract color objects from a cluttered scene based on statistical and spatial color similarity is proposed. Color region adjacent graphs (RAG) and six 1D histograms corresponding to the RGB and HIS color spaces are used to represent models and scenes. A histogram intersection (HI) strategy is applied to a similarity measure of statistical color distribution between them and the RAG are exploited to guide the search for the interesting object regions at which a global maximal value of histogram intersection is available. The color spatial relationships among the RAG are also used to check the matching result to avoid the false positive identifications, which may be caused by a normal HI method. This strategy of combining RAG and HI makes the detection robust and precise. The experiments conducted have shown that known color objects in a complex scene can be accurately identified and extracted from the background.		Jian Cheng;Siegbert Drüe;Georg Hartmann;Jörg Thiem	2000		10.1109/ICPR.2000.905476	spatial relation;color histogram;false color;computer vision;color quantization;hsl and hsv;color normalization;color image;type i and type ii errors;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;color balance;color space;histogram equalization;statistics	Vision	44.618943475675955	-53.72921550904923	81692
6147a461c76d7f5acfa64c3f83dc67ee09ebfb49	motion blur estimation at corners	motion blur	In this paper we propose a novel algorithm to estimate motion parameters from a single blurred image, exploiting geometrical relations between image intensities at pixels of a region that contains a corner. Corners are significant both for scene and motion understanding since they permit a univocal interpretation of motion parameters. Motion parameters are estimated locally in image regions, without assuming uniform blur on image so that the algorithm works also with blur produced by camera rotation and, more in general, with space variant blur.	algorithm;box blur;gaussian blur;pixel	Giacomo Boracchi;Vincenzo Caglioti	2007			computer science;motion estimation	Vision	52.32663591517861	-54.22766372128759	81936
996aefa45cd41faeee48fef77aa1d31f36cb5e74	binary edge based adaptive motion correction for accurate and robust digital image stabilization	consumidor;nivel ruido;correlacion;metodo adaptativo;image numerique;estimation mouvement;filtro kalman;image processing;algoritmo adaptativo;surveillance;edge detection;consommateur;real time;zoom;estimacion movimiento;stabilization;filtre kalman;procesamiento imagen;niveau bruit;digital camera;kalman filter;motion estimation;methode adaptative;proceso adquisicion;acquisition process;traitement image;deteccion contorno;detection contour;adaptive algorithm;vigilancia;noise level;algorithme adaptatif;monitoring;estabilizacion;image stabilization;video cameras;consumer;motion correction;temps reel;adaptive method;image sequence;imagen numerica;camera video;filtro adaptable;tiempo real;real time implementation;secuencia imagen;digital image stabilization;stabilisation;digital image;monitorage;motion discrimination;correlation;filtre adaptatif;monitoreo;binary edge transform;adaptive filter;processus acquisition;phase correlation;sequence image	Digital image stabilization (DIS) becomes one of the most important features in consumer cameras. The image sequence is easily interfered by hand-shaking during acquisition process especially in zoom-in highly. Many of the state-of-the-art algorithms for image stabilization perform well for high patterned and clear images. However, for high noise or low pattern level images, the algorithm performance degrades seriously. In this paper, we propose a novel digital image stabilization algorithm for removal of unwanted motion in high noise or low pattern level images. The proposed algorithm consists of an adaptive Kalman filter for motion prediction and a binary edge transform (BET) based phase correlation (PC) for motion estimation. Since the proposed algorithm is designed for real-time implementation, it can be used as an algorithm for a DIS to preserve a good environment that the photograph has been taken of many commercial applications such as low cost camcorders, digital cameras, CCTV, and surveillance video systems.		Ohyun Kwon;Byungdeok Nam;Joonki Paik	2006		10.1007/11949534_115	adaptive filter;kalman filter;computer vision;simulation;edge detection;consumer;binary image;image processing;computer science;digital image processing;motion estimation;zoom;phase correlation;correlation;digital image;image stabilization;computer graphics (images)	Vision	53.590884870068926	-60.061357722342905	82230
b2c3cb46a0134191f1b7fd5b9658429bdbee5842	3d shape initialization of objects in multiview image sequences	image tridimensionnelle;eye;image processing;ajustamiento curva;computer graphics;generation maille;procesamiento imagen;traitement image;computer graphic;reconstruction image;codificacion;reconstruccion imagen;image reconstruction;clouds;information exchange;image sequence;coding;superficie;tridimensional image;ajustement courbe;computing systems;surface;image analysis;video;curve fitting;video communication;mesh generation;grafico computadora;infographie;imagen tridimensional;codage;telecommunications	The ultimate goal for future telecommunication is highly effective inter-personal information exchange. The effectiveness of telecommunication is greatly enhanced by 3-D telepresence. This requires that visual information is presented in such a way that the viewer is under the impression of actually being physically close to the party with whom the communication takes place. One way to achieve a natural 3-D impression is to encode image sequences using 3-D model objects and animate them again by computer graphic means regarding the observers eye positions. This concept will use a parametric 3-D scene description in order to model a scene. The parameters of the model objects will be estimated from trinocular input image sequences by means of image analysis. This paper starts with an overview on the European ACTS project PANORAMA, in which the above mentioned concept will be realized and evaluated. In the main part the shape initialization of physical objects from a multiview image sequence will be discussed. For this the range information given by three disparity maps from different stereo views is backprojected into 3-D space. The resulting cloud of 3-D points is then approximated by a flexible triangular net by using a technique named discrete smooth interpolation. The discrete smooth interpolation is a particular surface interpolation technique, which is solved by an iterative approach. It allows to generate a surface, defined as a wireframe mesh, that fits (or interpolates) a given set of 3D points by observing, at the same time, some given constraints about the surface characteristics, like roughness, behavior at the boundaries, etc. The finally presented results show the capabilities of this approach in video communication.© (1998) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Thomas B. Riegel;Federico Pedersini;Roberto Manzotti	1998		10.1117/12.302454	iterative reconstruction;mesh generation;computer vision;image analysis;simulation;video;information exchange;telecommunications;image processing;computer science;coding;optics;computer graphics;surface;curve fitting;computer graphics (images)	Vision	51.96422782578176	-57.48173451042929	82385
0cc3c753247105ca0516017564f794843a63418b	determination of road traffic flow based on 3d daubechies wavelet transform of an image sequence		Daubechies wavelet transform is proposed to represent the contents of the image sequence. In order to account for temporal changes of the contents a 3D transform is used. 3D DWT, Daubechies based, is chosen for calculations to determine the coefficients. A method of mapping road traffic flow is developed. The method uses a linear function of the wavelet coefficients for describing the changes in detection fields, which is in turn is converted to traffic flow. The parameters of the linear function are determined by minimizing the MSE of fitting this function to corresponding traffic flow values. The method is validated using a set of video sequences.	daubechies wavelet;wavelet transform	Marcin Jacek Klos	2016		10.1007/978-3-319-46418-3_51	wavelet;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;wavelet transform	Vision	52.80703639628044	-63.856063689212625	82482
2a00c424d4659ddbd94ffd7703a1bcbb9d63ada1	geometric robot mapping	control estadistico proceso;image processing;procesamiento imagen;statistical process control;perceptual grouping;maitrise statistique processus;robotics;geometria discreta;traitement image;robot mapping;captador medida;measurement sensor;capteur mesure;polygon merging;geometrie discrete;discrete geometry;segment droite;pattern recognition;robotica;segmento recta;line segment;robotique;reconnaissance forme;reconocimiento patron;polygon simplification	The purpose of this paper is to present a technique to create a global map of a robot’s surrounding by converting the raw data acquired from a scanning sensor to a compact map composed of just a few generalized polylines (polygonal curves). To merge a new scan with a previously computed map of the surrounding we use an approach that is composed of a local geometric process of merging similar line segments (termed Discrete Segment Evolution) of map and scan with a global statistical control process. The merging process is applied to a dataset gained from a real robot to show its ability to incrementally build a map showing the environment the robot has traveled through.	edge detection;experiment;iterative method;level of detail;robot	Rolf Lakämper;Longin Jan Latecki;Xinyu Sun;Diedrich Wolter	2005		10.1007/978-3-540-31965-8_2	discrete geometry;computer vision;line segment;image processing;computer science;mathematics;geometry;robotics;statistical process control	Robotics	49.500780495312334	-58.5659595294859	82918
0f7b50f5b77b1db762242ad56c084d02dd4b5432	object tracking in low-frame-rate video	evaluation performance;change detection;deteccion blanco;performance evaluation;evaluacion prestacion;simulation;mean shift;simulacion;detection cible;algorithme;algorithm;detection objet;deteccion cambio;object tracking;poursuite cible;detection changement;video;target tracking;target detection;object detection;algoritmo	In this paper, we present an object detection and tracking algorithm for low-frame-rate applications. We extend the standard mean-shift technique such that is is not limited within a single kernel but uses multiple kernels centered around high motion areas obtained by change detection. We also improve the convergence properties of the mean-shift by integrating two additional likelihood terms using object templates. Our simulations prove the effectiveness of the proposed method both under heavy occlusions and low frame rates down to 1-fps. SPIE Image and Video Communications and Processing This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c ©Mitsubishi Electric Research Laboratories, Inc., 2005 201 Broadway, Cambridge, Massachusetts 02139	acknowledgment index;algorithm;broadway (microprocessor);mean shift;object detection;simulation	Fatih Murat Porikli;Oncel Tuzel	2005		10.1117/12.587907	computer vision;simulation;geography;video tracking;cartography	Vision	47.901124197310345	-56.71789686137809	83141
ae31f03b65c86b64c8c43a636c4e827454afa8cc	attractor-guided particle filtering for lip contour tracking	attracteur;filtering;vision ordenador;filtrage;pistage;piel;image processing;recherche image;peau;skin;lip;filtrado;rastreo;procesamiento imagen;blind;attractor;segmentation;separability;traitement image;computer vision;atractor;separabilidad;levre;particle filter;labio;separabilite;vision ordinateur;feature selection;shape priors;ciego;segmentacion;tracking;aveugle;image retrieval	We present a lip contour tracking algorithm using attractorguided particle filtering. Usually it is difficult to robustly track the lip contour because the lip contour is highly deformable and the contrast between skin and lip colors is very low. It makes the traditional blind segmentation-based algorithms often fail to have robust and realistic results. But in fact, the lip contour is constrained by the facial muscles, the tracking configuration space can then be represented by a lower dimensional manifold. With this observation, we take some representative lip shapes as the attractors in the lower dimensional manifold. To resolve the low contrast problem, we adopt a color feature selection algorithm to maximize the separability between skin and lip colors. Then we integrate the shape priors and the discriminative feature into the attractor-guided particle filtering framework to track the lip contour. The experimental result shows that we can track the lip contour robustly and efficiently.	color;contour line;feature model;feature selection;linear separability;national supercomputer centre in sweden;particle filter;robustness (computer science);selection algorithm	Yong-Dian Jian;Wen-Yan Chang;Chu-Song Chen	2006		10.1007/11612032_66	filter;computer vision;speech recognition;particle filter;image processing;image retrieval;computer science;pattern recognition;mathematics;tracking;skin;feature selection;segmentation;attractor	Vision	46.19725485924175	-58.83320303663161	83258
fc0a2e5f5d6e8135b37b8f13244ca2506e16d9f2	action recognition using motion primitives and probabilistic edit distance	modelizacion;dato observacion;trajectoire;estimation mouvement;reconnaissance geste;image processing;cuerpo deformable;estimacion movimiento;edit distance;procesamiento imagen;chaine caractere;motion estimation;probabilistic approach;classification;traitement image;modelisation;trajectory;enfoque probabilista;approche probabiliste;action recognition;deformable body;cadena caracter;image sequence;corps deformable;distancia;secuencia imagen;trayectoria;appariement chaine;donnee observation;double difference;string matching;modeling;clasificacion;gesture recognition;observation data;distance;sequence image;character string	In this paper we describe a recognition approach based on the notion of primitives. As opposed to recognizing actions based on temporal trajectories or temporal volumes, primitive-based recognition is based on representing a temporal sequence containing an action by only a few characteristic time instances. The human whereabouts at these instances are extracted by double difference images and represented by four features. In each frame the primitive, if any, that best explains the observed data is identified. This leads to a discrete recognition problem since a video sequence will be converted into a string containing a sequence of symbols, each representing a primitives. After pruning the string a probabilistic Edit Distance classifier is applied to identify which action best describes the pruned string. The approach is evaluated on five one-arm gestures and the recognition rate is 91.3%. This is concluded to be a promising result but also leaves room for further improvements.	background subtraction;edit distance;string (computer science)	Preben Fihl;Michael B. Holte;Thomas B. Moeslund;Lars Reng	2006		10.1007/11789239_39	computer vision;speech recognition;systems modeling;edit distance;string;image processing;biological classification;computer science;artificial intelligence;trajectory;motion estimation;gesture recognition;mathematics;distance;string searching algorithm	Vision	46.35218628984143	-57.38839498572801	83432
69e986fd1ed751f8426cb6f953bd91a1553723ba	two-dimensional pca combined with pca for neural network based image registration	analisis imagen;feedforward neural network;analisis componente principal;analisis bidimensional;image processing;transformation cosinus discrete;extraction forme;procesamiento imagen;effet dimensionnel;traitement image;discrete cosine transform;calcul analogique;registro imagen;analyse bidimensionnelle;extraccion forma;recalage image;discrete cosine transforms;size effect;principal component analysis;image registration;zernike moment;analyse composante principale;two dimensional analysis;image analysis;efecto dimensional;reseau neuronal;analyse image;pattern extraction;red neuronal;neural network;analog calculus;calculo analogico	A novel image registration scheme is proposed. In the proposed scheme, two-dimensional principal component analysis (2DPCA) combined with principal component analysis (PCA) is used to extract features from the image sets and these features are fed into feedforward neural networks to provide translation, rotation and scaling parameters. Comparison experiments between 2DPCA combined with PCA based method and the other two former methods: discrete cosine transform (DCT) and Zernike moment, are performed. The results indicate that the proposed scheme is both accurate and remarkably robust to noise.	artificial neural network;discrete cosine transform;experiment;feature extraction;feedforward neural network;image noise;image registration;image scaling;principal component analysis;signal-to-noise ratio	Anbang Xu;Xin Jin;Ping Guo	2006		10.1007/11881223_87	computer vision;feedforward neural network;image analysis;image processing;computer science;image registration;machine learning;discrete cosine transform;mathematics;artificial neural network;statistics;principal component analysis	ML	44.69211976483213	-60.51199705332567	83483
693e92d0feffd969ce195114ee8a96de74e9efd2	merging multi-view feature models by local rules	frequency modulation;multiple views feature models;lattices;multiview feature models merging normative procedure local rules cross tree relationships sibling features;software reusability feature extraction merging;multiple views;feature models;frequency modulation merging computational modeling lattices scalability feature extraction security;computational modeling;feature extraction;software reusability;merging;scalability;security	In this paper we consider merging of feature models arising from different viewpoints. We propose a normative procedure to merge basic feature models by applying local rules. Our procedure can merge basic feature models and feature models with cross-tree relationships between sibling features.	feature model	Elcin Atilgan Aydin;Halit Oguztüzün;Ali H. Dogru;Ahmet Serkan Karatas	2011	2011 Ninth International Conference on Software Engineering Research, Management and Applications	10.1109/SERA.2011.34	frequency modulation;scalability;feature extraction;computer science;information security;machine learning;pattern recognition;lattice;data mining;computational model;feature;feature model	SE	41.302670221115925	-62.951496558205015	83685
5ac53038faf545c1e8ec915d60da3e843aeffd70	localized registration of point clouds of botanic trees	geophysical image processing;lasers;remote sensing by laser beam;measurement by laser beam;forestry;skeleton vegetation remote sensing clouds octrees estimation lasers;skeleton;vegetation;least squares;estimation;clouds;remote sensing;image registration;vegetation forestry geophysical image processing geophysical techniques image registration measurement by laser beam remote sensing by laser beam;skeletonization automation forestry image registration laser scanning least squares parameter estimation;laser scanning;skeletonization;point cloud;parameter estimation;fine branch registration localized point cloud registration botanic tree point clouds global registration tree dendrometric characteristics roughly registered point clouds skeletonization method branch segments local transformation parameters;octrees;geophysical techniques;automation	A global registration is often insufficient for estimating dendrometric characteristics of trees because individual branches of the same tree may exhibit different positions between two scanning procedures. Therefore, we introduce a localized approach to register point clouds of botanic trees. Given two roughly registered point clouds PC1 and PC2 of a tree, we apply a skeletonization method to both point clouds. Based on these two skeletons, initial correspondences between branch segments of both point clouds are established to estimate local transformation parameters. The transformation estimation relies on minimizing the distance between the points in PC1 and the skeleton of PC2. The performance of the method is demonstrated on two example trees. It is shown that significant improvements can be achieved for the registration of fine branches. These improvements are quantified as the residual point-to-line distances before and after the localized fine registration. In our experiment, the residual error after the local registration is on an average of 5 mm over 90 skeleton segments, which is about three times smaller than the average residual error of the initial rough registration.	pc²;point cloud;rough set;shanks transformation;straight skeleton;tree (data structure)	Alexander Bucksch;Kourosh Khoshelham	2013	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2012.2216251	laser scanning;skeletonization;computer vision;estimation;laser;computer science;image registration;automation;point cloud;mathematics;optics;estimation theory;least squares;skeleton;physics;vegetation;statistics;remote sensing	Vision	51.29893008475724	-53.25992112652856	83930
719da2a0ddd38e78151e1cb2db31703ea8b2e490	the representation and matching of pictorial structures	dynamic programming;representation;picture processing;dynamic program;picture matching;dynamic programming heuristic optimization picture description picture matching picture processing representation;heuristic optimization;picture description	"""The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of """"goodness"""" of matching or detection."""	image	Martin A. Fischler;Robert A. Elschlager	1973	IEEE Transactions on Computers	10.1109/T-C.1973.223602	combinatorics;discrete mathematics;theoretical computer science;dynamic programming;mathematics;representation	Vision	48.22032210849743	-61.351429423383976	84001
f4a58ef1e6ebf734487acd3c8b3abace0395983b	human pose regression through multiview visual fusion	gaussian processes regression;spacing;multiple linear regression;espacement;image features;traitement signal;processus gauss;modelo cuerpo homano;image motion analysis;learning algorithm;image feature;regression analysis computer vision feature extraction gaussian processes image fusion image motion analysis pose estimation;invariance echelle;image processing;combinaison d informations;humaneva database human pose regression multiview visual fusion 3d human motion feature extraction learning algorithm camera utilization scale invariant feature transform sift like descriptor gaussian process multiple linear regression;observacion visual;multi view technology;image databases;multiple views gaussian processes regression human pose estimation image feature;espaciamiento;gaussian processes;fusion d images;signal visuel;gaussian process regression;interest points;humaneva database;image fusion;multiview visual fusion;database;mesure position;procesamiento imagen;image multiple;linear regression;base dato;planar technology;technologie planaire;senal visual;regression model;imagen multiple;algorithme apprentissage;data fusion;invarianza escala;carta de datos;traitement image;medicion posicion;sift like descriptor;multiple views;multiple image;computer vision;3d human motion;human body model;observation visuelle;discriminant analysis;analyse discriminante;analisis discriminante;modelo regresion;research and development;local structure;tecnologia planar;analisis regresion;scale invariant feature transform;video cameras;regresion multiple;feature extraction;mappage;signal processing;human motion;fusion donnee;human body;modele regression;spatial databases;position measurement;regresion lineal;camera video;base de donnees;visual signal;analyse regression;robustness;information combining;human pose regression;life estimation;regression analysis;mapping;humans;fusion de imagen;modele corps humain;gaussian process;extraction caracteristique;camera utilization;fusion datos	We consider the problem of estimating 3-D human body pose from visual signals within a discriminative framework. It is challenging because there is a wide gap between complex 3-D human motion and planar visual observation, which makes this a severely ill-conditioned problem. In this paper, we focus on three critical factors to tackle human body pose estimation, namely, feature extraction, learning algorithm, and camera utilization. On the feature level, we describe images using the salient interest points represented by scale-invariant feature transform (SIFT)-like descriptors, in which the position, appearance, and local structural information are encoded simultaneously. On the learning algorithm level, we propose to use Gaussian processes and multiple linear (ML) regression to model the mapping between poses and features. Fusing image information from multiple cameras in different views is of great interest to us on the camera level. We make a comprehensive evaluation on the HumanEva database and get two meaningful insights into the three crucial aspects for human pose estimation: 1) although the choice of feature is very important to the problem, once the learning algorithm becomes efficient, the choice of feature is no longer critical, and 2) the impact of information combination from multiple cameras on pose estimation is closely related to not only the quantity of image information, but also its quality. In most cases, it is true that the more information is involved, the better results can be achieved. But when the information quantity is the same, the differences in quality will lead to totally different performance. Furthermore, dense evaluations demonstrate that our approach is an accurate and robust solution to the human body pose estimation problem.	3d pose estimation;algorithm;condition number;estimation theory;feature extraction;gaussian process;kinesiology;scale-invariant feature transform;sparse approximation;sparse matrix	Xu Zhao;Yun Fu;Huazhong Ning;Yuncai Liu;Thomas S. Huang	2010	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2010.2045916	computer vision;3d pose estimation;image processing;computer science;linear regression;machine learning;signal processing;pattern recognition;articulated body pose estimation;statistics	Vision	46.81303257053921	-57.32331064943789	84151
3e1d41e5abb5bf49c30646ec0f0eb7a94f6d7aba	shading into texture	estimacion;analyse surface;analisis textura;three dimensional shape;intelligence artificielle;forma tridimensional;texture analysis;forme tridimensionnelle;estimation;analisis superficie;pattern recognition;artificial intelligence;inteligencia artificial;reconnaissance forme;reconocimiento patron;analyse texture;modele fractal;surface analysis	Shape-from-shading and shape-from-texture methods have the serious drawback that they are applicable only to smooth surfaces, while real surfaces are often rough and crumpled. TO extend such methods to real surfaces we must have a model that also applies to rough surfaces. The fractal surface model [Pentland 831 provides a formalism that is competent to describe such natural 3-D surfaces and, in addition, is able to predict human perceptual judgments of smoothness versus roughness thus allowing the reliable application of shape estimation techniques that assume smoothness. Thia model of surface shape has been used to derive a technique for 3-D shape estimation that treats shading and texture in a uni6ed manner.	fractal landscape;photometric stereo;rough set;semantics (computer science);shading	Alex Pentland	1984		10.1016/0004-3702(86)90017-2	computer vision;estimation;computer science;artificial intelligence;surface weather analysis	Vision	47.961314851584056	-58.80973723228532	84158
76b39ce25471d18f32b5b016833f6cb88915c844	a 3d scene analysis framework and descriptors for risk evaluation	machine learning scene analysis risk evaluation;risk evaluation;thermal stability;physics;estimation;machine learning;three dimensional displays;solid modeling;three dimensional displays stability analysis thermal stability solid modeling estimation physics image analysis;stability analysis;image analysis;computer science and informatics;scene analysis	In this paper we evaluate the notion of scene analysis with regard to risk. We consider the problem of evaluating risk and potential hazards in an environment and providing a quantified risk score. A definition of risk is given incorporating two elements, Firstly scene stability, where Newtonian Physics are introduced into the scene analysis process, evaluating object stability within a scene. The effectiveness of which is demonstrated by conducting experiments on several scenes including a variety of stability levels. Secondly the analysis of the intrinsic risk related properties of an object, which is estimated using learning techniques and the utilisation of the 3D Voxel HOG descriptor, analysed against the state-of-the-art descriptors. Finally a new dataset is provided that is designed for scene analysis focusing on risk evaluation.		Rob Dupre;Vasileios Argyriou;Darrel Greenhill;Georgios Tzimiropoulos	2015	2015 International Conference on 3D Vision	10.1109/3DV.2015.19	computer vision;simulation;scene statistics;computer science;data mining	Vision	44.62839564529546	-54.95694838215573	84658
e75591754df7bff70f1c464b1ba37d225c6da9f0	registration and interactive planar segmentation for stereo images of polyhedral scenes	sistema interactivo;iterative method;vision ordenador;image segmentation;image processing;modelo markov;color;image matching;bayes methods;methode bayes;procesamiento imagen;stereoscopy;segmentation;probabilistic approach;coplanarity;traitement image;interactive computer vision;computer vision;systeme conversationnel;metodo iterativo;registro imagen;markov model;color segmentation;recalage image;interactive system;methode iterative;enfoque probabilista;approche probabiliste;image registration;homographie;homography;segmentation image;registration;stereo;stereoscopie;color appearance;vision ordinateur;estereoscopia;modele markov;imagen color;image couleur;appariement image;color image	We introduce a two-step iterative segmentation and registration method to find coplanar surfaces among stereo images of a polyhedral environment. The novelties of this paper are: (i) to propose a user-defined initialization easing the image matching and segmentation, (ii) to incorporate color appearance and planar projection information into a Bayesian segmentation scheme, and (iii) to add consistency to the projective transformations related to the polyhedral structure of the scenes. The method utilizes an assisted Bayesian color segmentation scheme. The initial user-assisted segmentation is used to define search regions for planar homography image registration. The two reliable methods cooperate to obtain probabilities for coplanar regions with similar color information that are used to get a new segmentation by means of Quadratic Markov Measure Fields (QMMF). We search for the best regions by iterating both steps: registration and segmentation.	bayesian network;image registration;image segmentation;iteration;iterative method;markov chain;planar projection;polyhedron;subshift of finite type	Javier-Flavio Vigueras;Mariano Rivera	2010	Pattern Recognition	10.1016/j.patcog.2009.03.012	stereoscopy;computer vision;coplanarity;homography;color image;image processing;computer science;image registration;segmentation-based object categorization;mathematics;iterative method;image segmentation;markov model;scale-space segmentation;stereophonic sound;segmentation;computer graphics (images)	Vision	49.19859064052616	-58.264858307240424	84759
c1497fea1fbe72750280f305bf4ef949b9cbdf9e	video objects segmentation based on spatio-temporal information and its realization in cnnum	power series;extraction information;moving object;analisis contenido;traitement signal;video object;estimation mouvement;algorithm performance;image segmentation;multimedia;image processing;neural networks;information extraction;video signal processing;series expansion;estimacion movimiento;cellular neural network;compresion senal;procesamiento imagen;motion estimation;blanco movil;cellular neural nets;serie entiere;traitement image;gray scale;compression signal;simulator;temporal information;reseau neuronal cellulaire;content analysis;video object segmentation;simulador;senal video;signal video;serie potencias;desarrollo serie;object oriented;resultado algoritmo;signal processing;signal compression;image sequence;multimedia communication;segmentation image;object extraction;performance algorithme;simulateur;traitement signal video;video signal;cible mobile;oriente objet;secuencia imagen;extraccion objeto;analyse contenu;video;communication multimedia;echelle gris;procesamiento senal;orientado objeto;extraccion informacion;escala gris;moving target;spatial information;extraction objet;sequence image;developpement serie	In this paper, we propose a new segmentation method aimed at separating the moving objects from the background in a generic video sequence using Cellular Neural Networks (CNN). This task may be accomplished to support the functionalities foreseen by new multimedia scenarios, and in particular the content-based functionalities focused by the MPEG-4 activity. Extraction of motion information from video series is very power consuming, the proposed scheme extracts moving objects based on both motion and spatial information. Initially, a symmetrical inter-frame difference is performed on a group of gray image, so the approximate area of the video object was presented, then this area can be divided into some flat zones with uninterrupted grey scale information. Finally some zones are merged and forming the object according to a certain rule, others are discarded. It is the case of stationary background hereinbefore, in the case of moving, we will do some motion estimation at first. For the good of laborsaving, some work will be realized by CNN,. At the end of this paper, some typical results obtained on MPEG-4 sequences are here shown, in order to illustrate the segmentation algorithm performance using Aladdin V1.3 simulator system.		Qingli Chang;Yulong Mo;Xiaomei Lin	2004		10.1117/12.525009	computer vision;geography;video tracking;cartography;computer graphics (images)	Vision	45.53424759131355	-57.21735963599803	85148
2f5c27f7a56517b0a193322af559ed0db7d65326	learning methods in segmentation of cardiac tagged mri	myocardium;shape variations;rotation distortions;shape constraints;dynamic prediction learning methods image segmentation cardiac mri tagged mri image tracking mri sequences magnetic resonance imaging transformed component analysis shape variations rotation distortions training shapes motion integration static local appearance features boundary criteria boosting approach adaboost classifier posterior probability form particle filter shape tracking framework shape dynamic models systole diastole shape evolution static appearance motion appearance shape constraints;image motion analysis;shape evolution;heart;probability;image segmentation;cardiology;dynamic model;image classification;posterior probability form;posterior probability;shape measurement;shape tracking framework;static appearance;learning systems;tracking biomedical mri cardiology image classification image motion analysis image segmentation image sequences learning artificial intelligence medical image processing probability shape measurement;shape representation;boosting;learning methods;diastole;cardiac mri;transformed component analysis;particle filter;medical image processing;principal component analysis;dynamic prediction;magnetic resonance imaging;boosting approach;systole;component analysis;motion appearance;motion integration;learning systems magnetic resonance imaging myocardium image segmentation robustness boosting heart image motion analysis active shape model principal component analysis;boundary criteria;robustness;image tracking;learning artificial intelligence;mri sequences;training shapes;adaboost classifier;tagged mri;active shape model;static local appearance features;shape dynamic models;tracking;biomedical mri;image sequences	In this paper we present a learning framework for segmentation and tracking in 2D cardiac tagged MRI sequences. We employ a transformed component analysis (TCA) algorithm to estimate the shape variations, and at the same time, eliminate the rotation distortions of the training shapes. This method also integrates the motion and the static local appearance features and generates accurate boundary criteria via a boosting approach. We extend the conventional Adaboost classifier into a posterior probability form, which can be embedded in a particle filter based shape tracking framework. The TCA shape representation is used to constrain the shape variations and lower the dimensionality, so that it makes the tracking process more robust and faster. We also learn two shape dynamic models for systole and diastole separately to predict the shape evolution. Our segmentation and tracking method incorporates the static appearance, the motion appearance, the shape constraints, and the dynamic prediction in a unified way. The proposed method has been applied to 50 tagged MRI sequences. The experimental results show the accuracy and robustness of our approach	adaboost;advanced telecommunications computing architecture;algorithm;boosting (machine learning);distortion;embedded system;particle filter	Zhen Qian;Dimitris N. Metaxas;Leon Axel	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356945	active shape model;computer vision;contextual image classification;systole;particle filter;computer science;magnetic resonance imaging;machine learning;pattern recognition;probability;mathematics;tracking;image segmentation;posterior probability;diastole;boosting;heart;statistics;robustness;principal component analysis	Vision	41.64467731036163	-53.75041069974588	85288
9b9afb7a7f8cc6e2bf14f8d040acfed7450474ed	decoupling fourir components of dynamic image sequences: a theory of signal separation, image segmentation, and optical flow estimation	traitement signal;vision ordenador;closed form solution;image segmentation;image processing;analyse fourier;procesamiento imagen;optical flow estimation;traitement image;computer vision;flow field;signal processing;image sequence;segmentation image;fourier analysis;analisis fourier;vision ordinateur;secuencia imagen;ground truth;optical flow;procesamiento senal;sequence image	Abs t r ac t . This paper presents a new Fourier-based approach to the separation or decoupling of m additive images from a time-sequence of the sum of these images where at least m 1 images are translating with distinct and unique velocity. A closed-form solution is presented for the case where m = 2. A generalization is then presented which extends the theory to embrace situations where the images are not additive but are, instead, formed by the superposition of an occluding object or objects on an occluded background. That is, the approach is generalized to effect a model-free segmentation of objects undergoing translatory fronto-parallel motion in dynamic image sequences. Object velocities of one pixel per frame are sufficient to guarantee segmentation. We also show how the technique can be applied on a local basis to compute a dense instantaneous optical flow field for the image sequence, even in relatively featureless regions. The technique is evaluated using Otte's and Nagel's benchmark image sequence, for which ground-truth data is available, and results comparable with the ground-truth flow field are achieved. RMS errors of velocity magnitude and direction are computed and reported.	benchmark (computing);coupling (computer programming);ground truth;image segmentation;optical flow;pixel;utility functions on indivisible goods;velocity (software development)	David Vernon	1998		10.1007/BFb0054734	computer vision;closed-form expression;image processing;ground truth;computer science;signal processing;optical flow;mathematics;image segmentation;fourier analysis;computer graphics (images)	Vision	52.50523949630805	-56.451143306797626	85441
3c4eb26602f612469dc9d37bb825633de92f9c85	a comparative analysis of depth-discontinuity and mixed-pixel detection algorithms	image recognition;optical variables measurement;comparative analysis;image segmentation;image resolution;optical scanners;depth discontinuity;laser scanner;surface reconstruction;laser scanner noise models comparative analysis depth discontinuity mixed pixel detection algorithms laser scanner measurements;data analysis;specular reflection;optical variables measurement data analysis image recognition image reconstruction image registration image resolution image segmentation optical scanners;image reconstruction;image registration;mixed pixel detection algorithms;detection algorithm;laser scanner noise models;laser scanner measurements;algorithm design and analysis detection algorithms laser modes laser noise noise measurement surface reconstruction surface emitting lasers colored noise optical reflection acoustic reflection	Laser scanner measurements are corrupted by noise and artifacts that can undermine the performance of registration, segmentation, surface reconstruction, recognition, and other algorithms operating on the data. While much research has addressed laser scanner noise models, comparatively little is known about other artifacts, such as the mixed pixel effect, color-dependent range biases, and specular reflection effects. This paper focuses on the mixed pixel effect and the related challenge of detecting depth discontinuities in 3D data. While a number of algorithms have been proposed for detecting mixed pixels and depth discontinuities, there is no consensus on how well such algorithms perform or which algorithm performs best. This paper presents a comparative analysis of five mixed-pixel/discontinuity detection algorithms on real data sets. We find that an algorithm based on the surface normal angle has the best overall performance, but that no algorithm performs exceptionally well. Factors influencing algorithm performance are also discussed.	3d reconstruction;domain-specific language;genetic algorithm;normal (geometry);pixel;qualitative comparative analysis;reflections of signals on conducting lines;sensor;testbed	Pingbo Tang;Daniel Huber;Burcu Akinci	2007	Sixth International Conference on 3-D Digital Imaging and Modeling (3DIM 2007)	10.1109/3DIM.2007.5	laser scanning;iterative reconstruction;qualitative comparative analysis;computer vision;specular reflection;image resolution;surface reconstruction;computer science;image registration;image segmentation;data analysis;computer graphics (images)	Vision	53.758784040147425	-57.67765040499195	85495
01396e9300c66dc7eb12333efd63d617fb1dc900	mutual hypothesis verification for 6d pose estimation of natural objects		Estimating the 6D pose of natural objects, such as vegetables and fruit, is a challenging problem due to the high variability of their shape. The shape variation limits the accuracy of previous pose estimation approaches because they assume that the training model and the object in the target scene have the exact same shape. To overcome this issue, we propose a novel framework that consists of a local and a global hypothesis generation pipeline with a mutual verification step. The new local descriptor is proposed to find critical parts of the natural object while the global estimator calculates object pose directly. To determine the best pose estimation result, a novel hypothesis verification step, Mutual Hypothesis Verification, is proposed. It interactively uses information from the local and the global pipelines. New hypotheses are generated by setting the initial pose using the global estimation and guiding an iterative closest point refinement using local shape correspondences. The confidence of a pose candidate is calculated by comparing with estimation results from both pipelines. We evaluate our framework with real fruit randomly piled in a box. The potential for estimating the pose of any natural object is proved by the experimental results that outperform global feature based approaches.	3d pose estimation;heart rate variability;interactivity;iterative closest point;iterative method;loss function;pipeline (computing);randomness;refinement (computing)	Kiru Park;Johann Prankl;Markus Vincze	2017	2017 IEEE International Conference on Computer Vision Workshops (ICCVW)	10.1109/ICCVW.2017.256	estimator;artificial intelligence;pose;iterative closest point;pattern recognition;solid modeling;computer science	Vision	45.83491158687506	-52.169890007084945	85802
468c53c9aab6584746fb626ad69fa4df7c80ff8c	optimal separable algorithms to compute the reverse euclidean distance transformation and discrete medial axis in arbitrary dimension	filtering;reversible medial axis extraction reverse euclidean distance transformation discrete medial axis arbitrary dimension binary images geometrical skeleton extraction;vision ordenador;filtrage;algorithms artificial intelligence image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval numerical analysis computer assisted pattern recognition automated signal processing computer assisted;geometric transformation;image processing;esqueleto;binary image;distance transformation;morfoscopia;analisis forma;filtrado;geometry;shape analysis;procesamiento imagen;transformation distance;temps minimal;d dimensional shapes shape representation distance transformation reverse euclidean distance transformation medial axis extraction;intelligence artificielle;euclidean distance;forma geometrica;indexing terms;geometria discreta;traitement image;skeleton;computer vision;dimensional shapes;shape representation;analisis morfologico;feature extraction;morphoscopie;geometrie discrete;timing optimization;transformacion geometrica;discrete geometry;geometrical shape;d dimensional shapes;image binaire;morphological analysis;transformation geometrique;minimum time;controle qualite;squelette;imagen binaria;analyse morphologique;artificial intelligence;reverse euclidean distance transformation;vision ordinateur;geometry feature extraction;forme geometrique;pattern analysis;inteligencia artificial;distance transform;algoritmo optimo;quality control;algorithme optimal;optimal algorithm;tiempo minimo;medial axis extraction;transformacion distancia;medial axis;analyse forme;euclidean distance skeleton image analysis shape control approximation algorithms fires solid modeling filtering image reconstruction labeling;control calidad	In binary images, the distance transformation (DT) and the geometrical skeleton extraction are classic tools for shape analysis. In this paper, we present time optimal algorithms to solve the reverse Euclidean distance transformation and the reversible medial axis extraction problems for d-dimensional images. We also present a d-dimensional medial axis filtering process that allows us to control the quality of the reconstructed shape	algorithm;apache axis;axis vertebra;binary image;c++;computation (action);computational geometry;euclidean distance;high- and low-level;macroscopic findings domain;mathematical optimization;maximal pair;maximal set;medial graph;optic axis of a crystal;paper;physical object;remote direct memory access;shape analysis (digital geometry);subgroup	David Coeurjolly;Annick Montanvert	2007	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2007.54	filter;discrete geometry;computer vision;quality control;topology;index term;medial axis;binary image;geometric transformation;image processing;feature extraction;morphological analysis;computer science;euclidean distance;shape analysis;mathematics;geometry;topological skeleton;distance transform;skeleton	Vision	48.784098924845125	-61.16761144299751	85827
688aedd34c8f2f52026a42c3b194e8d9da15f89a	thresholding of digital images using two-dimensional entropies	optimisation;entropia;image processing;optimizacion;sistema informatico;procesamiento imagen;computer system;segmentation;imagen nivel gris;fonction seuil;traitement image;histogram;histogramme;funcion umbral;entropie;image niveau gris;optimization;systeme informatique;entropy;threshold function;digital image;histograma;grey level image;segmentacion	"""Abstraet--Thresholding is an important form of image segmentation and is a first step in the processing of images for many applications. The selection of suitable thresholds is ideally an automatic process, requiring the use of some criterion on which to base the selection. One such criterion is the maximization of the information theoretic entropy of the resulting background and object probability distributions. Most processes using this concept have made use of the one-dimensional (1D) grey-level histogram of the image. In an effort to use more of the information available in the image, the present approach evaluates two-dimensional (2D) entropies based on the 2D (grey-level/local average grey-level) """"histogram"""" or scatterplot. The 2D threshold vector that maximizes both background and object class entropies is selected."""	digital image;eisenstein's criterion;entropy (information theory);entropy maximization;image segmentation;information theory;thresholding (image processing)	A. D. Brink	1992	Pattern Recognition	10.1016/0031-3203(92)90034-G	computer vision;entropy;image processing;computer science;artificial intelligence;balanced histogram thresholding;mathematics;thresholding;statistics	Vision	46.38381011137639	-63.84654474133407	85894
0b8b39158dc948627dbfb000e16e51e677af08ad	coarse visual registration from closed-contour neighborhood descriptor	complex objects;learning view sphere;local shape descriptor;shape descriptor;image classification;metallic complex objects;closed contour neighborhood descriptor;metal product industries;coarse visual registration;affine transform;affine invariance;affine transformation;image registration;affine transforms;pose hypothesis classification coarse visual registration closed contour neighborhood descriptor visual coarse registration process textureless objects metallic complex objects repetitive patterns local shape descriptor affine transform affine invariance automobile cylinder head learning view sphere pose estimation;metal product industries affine transforms image classification image registration;textureless objects;repetitive patterns;pose hypothesis classification;automobile cylinder head;visual coarse registration process;pose estimation;head shape metals industry boring robustness automotive engineering optical reflection process design automobiles layout	This article introduces an innovative visual coarse-registration process suitable for textureless objects. Because our framework is industrial, the process is designed for metallic, complex objects containing multiple bores and repetitive patterns. This technique is based on a local shape descriptor, invariant under affine transform, which characterizes the neighborhood of a closed contour. The affine invariance is exploited in the learning stage to produce a lightweight model: for an automobile cylinder head, a learning view-sphere with twelve viewpoints is sufficient. Moreover, during the learning stage, this descriptor is combined to a 2D/3D pattern, concept likewise presented in this article. Once associated, the 2D/3D information wealth of this descriptor allows a pose estimation from a single match between two descriptors. This ability is exploited to obtain efficiently a great number of coarse pose hypothesis. A pose hypothesis classification method is proposed to select the best-ones. An evaluation on a cylinder head and a binding beam confirms both the robustness and the precision of the process	computation;contour line;cylinder seal;cylinder-head-sector	Steve Bourgeois;Sylvie Naudet-Collette;Michel Dhome	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.376	computer vision;computer science;affine transformation;mathematics;geometry	Vision	41.61030023462248	-56.50912969997632	85959
db8d9108d5f319cbda3c80d5a9dbc0fe8688e532	efficient contour shape description by using fractal interpolation functions	representation method;fractals;interpolation;image processing;edge detection;signal analysis;fractal interpolation functions;fractals interpolation signal processing inverse problems shape measurement image analysis signal analysis image processing lagrangian functions polynomials;contour shape;complexity;shape measurement;polynomials;fractal dimension;complexity representation method contour shape fractal interpolation functions multiple valued signal extended fif fractal dimension;image representation;signal processing;pattern recognition;image analysis;value function;image representation interpolation fractals edge detection pattern recognition signal processing computer animation;shape description;computer animation;multiple valued;lagrangian functions;extended fif;inverse problems;multiple valued signal	This paper presents a novel representation method for contour shape using Fractal Interpolation Functions (FIF). In the traditional idea of the FIF, the scope of its application has been limited to the case where the signal is represented by a single-valued function. Therefore, the traditional FIF cannot be applicable to multiple-valued signals. The proposed method can model a multiple-valued signal with an extended FIF derived by introducing new parameters to the traditional one. Furthermore, the proposed method utilizes the fractal dimension known as a measure of complexity to determine the parameters in the FIF and thereby can model the signal based on its complexity. Experimental results show the validity of the proposed method.	blum axioms;fractal compression;fractal dimension;interpolation	Satoshi Uemura;Miki Haseyama;Hideo Kitajima	2002		10.1109/ICIP.2002.1038066	computer vision;combinatorics;mathematical analysis;discrete mathematics;complexity;edge detection;fractal;interpolation;computer science;inverse problem;signal processing;mathematics;computer animation;bellman equation;fractal dimension;polynomial	Robotics	51.30589734100442	-63.71518429323052	86205
912c48d5e77ded869d760ff5391f32aa50fe9497	adaptive resolution refinement of ndt map based on localization error modeled by map factors		One of the prominent methods for accurate self-localization for autonomous vehicles is map-matching with light detection and ranging (LiDAR) based on Normal distribution transform (NDT). In NDT, map space is divided into the grids, and for each grid, normal distribution (ND) of the points are calculated, and LiDAR scan is matched to these NDs. Bigger grid sizes (lower resolution) are more favorable because it can abstract more points in each grid and reduce map size. However, if the resolution is low, many details of the environment are ignored, and the localization accuracy degrades. This information loss and localization error is different from place to place on the map and can be evaluated beforehand for each resolution. In this work, ten map factors are used to evaluate the localization ability of the map in a specific position for each resolution. Using the evaluation result, for each position of the map, a lower resolution that can preserve the required localization accuracy are determined. In this method, NDT map is generated by adaptively selecting the resolution for each position of the map. Experimental results in Shinjuku, Tokyo, show that by using this strategy, map size can be reduced by up to 32% of the original size while the mean localization error remains less than 0.141m.		Ehsan Javanmardi;Mahdi Javanmardi;Yanlei Gu;Shunsuke Kamijo	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569236		Robotics	52.523157857033766	-55.29688473224292	86239
7ffed7d584c30c454223d57f104152af96df5a96	efficient approximate scaling of spherical functions in the fourier domain with generalization to hyperspheres	transformation ondelette;operador lineal;traitement signal;fonction echelle;hyperspherical harmonics;scaling function;filter bank;image processing;fourier transform;illumination;spherical harmonics;banc filtre;computer graphics;spherical harmonic;procesamiento imagen;n sphere;harmonique spherique;traitement image;computer graphic;funcion escala;continuous spectrum;algorithme;sphere;algorithm;scaling;2 sphere;wavelet transform;linear operator;fourier transformation;signal processing;banco filtro;fourier transforms;transformation fourier;armonica esferica;transformacion ondita;spectral analysis;spherical function;procesamiento senal;eclairement;grafico computadora;operateur lineaire;infographie;wavelet transformation;alumbrado;transformacion fourier;algoritmo	We propose a simple model for approximate scaling of spherical functions in the Fourier domain. The proposed scaling model is analogous to the scaling property of the classical Euclidean Fourier transform. Spherical scaling is used for example in spherical wavelet transform and filter banks or illumination in computer graphics. Since the function that requires scaling is often represented in the Fourier domain, our method is of significant interest. Furthermore, we extend the result to higher-dimensional spheres. We show how this model follows naturally from consideration of a hypothetical continuous spectrum. Experiments confirm the applicability of the proposed method for several signal classes. The proposed algorithm is compared to an existing linear operator formulation.	approximate computing;approximation algorithm;computer graphics;filter bank;image scaling;resampling (statistics);wavelet transform	Ivan Dokmanic;Davor Petrinovic	2010	IEEE Trans. Signal Processing	10.1109/TSP.2010.2063427	fourier transform;discrete-time fourier transform;mathematical analysis;image processing;fractional fourier transform;calculus;signal processing;fourier inversion theorem;mathematics;geometry	EDA	51.611538156045114	-62.53382474159212	86360
6478eb6552488d1c0058a1654d54b41ebefd45c3	a truncation method for computing walsh transforms with applications to image processing	walsh transformation;image processing;transformacion walsh;walsh transform;procesamiento imagen;traitement image;experimental result;arbol binario;arbre binaire;resultado experimental;resultat experimental;transformation walsh;binary tree	Abstract   We present a method called the  Truncation  method for computing Walsh-Hadamard transforms of one- and two-dimensional data. In one dimension, the method uses binary trees as a basis for representing the data and computing the transform. In two dimensions, the method uses quadtrees (pyramids), adaptive quad-trees, or binary trees as a basis. We analyze the storage and time complexity of this method in worst and general cases. The results show that the Truncation method degenerates to the Fast Walsh Transform (FWT) in the worst case, while the Truncation method is faster than the Fast Walsh Transform when there is coherence in the input data, as will typically be the case for image data. In one dimension, the performance of the Truncation method for  N  data samples is between  O ( N ) and  O ( N  log 2  N ), and it is between  O ( N  2 ) and  O ( N  2  log 2  N ) in two dimensions. Practical results on several images are presented to show that both the expected and actual  overall  times taken to compute Walsh transforms using the Truncation method are less than those required by a similar implementation of the FWT method.	hadamard transform;image processing;truncation	Maurence M. Anguh;Ralph R. Martin	1993	CVGIP: Graphical Model and Image Processing	10.1006/cgip.1993.1036	computer vision;combinatorics;discrete mathematics;hadamard transform;binary tree;image processing;computer science;mathematics;walsh matrix;algorithm	Graphics	51.58201885922861	-62.54800332574046	86399
0bfff6eeb5df046cb680cc314d180d94611bb458	fast content-based image retrieval based on equal-average k-nearest-neighbor search schemes	analisis imagen;texture;raisonnement base sur cas;razonamiento fundado sobre caso;euclidean theory;algoritmo busqueda;multimedia;image processing;recherche image;image databank;base donnee tres grande;approximation plus proche voisin;algorithme recherche;extraction forme;search algorithm;interrogation base donnee;database;procesamiento imagen;interrogacion base datos;base dato;search method;effet dimensionnel;traitement image;feature vector;extraccion forma;busqueda por contenido;size effect;banco imagen;banque image;textura;base de donnees;theorie euclidienne;retroaction pertinence;k nearest neighbor;image analysis;fast k nearest neighbor search;efecto dimensional;very large databases;case based reasoning;content based image retrieval;imagen color;analyse image;relevance feedback;content based retrieval;pattern extraction;database query;recherche par contenu;image couleur;nearest neighbor approximation;color image;teoria euclidiana;variance;variancia;image retrieval;image similarity	The four most important issues in content-based image retrieval (CBIR) are how to extract features from an image, how to represent these features, how to search the images similar to the query image based on these features as fast as we can and how to perform relevance feedback. This paper mainly concerns the third problem. The traditional features such as color, shape and texture are extracted offline from all images in the database to compose a feature database, each element being a feature vector. The “linear scaling to unit variance” normalization method is used to equalize each dimension of the feature vector. A fast search method named equal-average K nearest neighbor search (EKNNS) is then used to find the first K nearest neighbors of the query feature vector as soon as possible based on the squared Euclidean distortion measure. Experimental results show that the proposed retrieval method can largely speed up the retrieval process, especially for large database and high feature vector dimension.	content-based image retrieval;database;distortion;feature vector;image scaling;k-nearest neighbors algorithm;nearest neighbor search;online and offline;performance;precision and recall;relevance feedback;speedup	Zhe-Ming Lu;Hans Burkhardt;Sebastian Boehmer	2006		10.1007/11922162_20	case-based reasoning;computer vision;visual word;image analysis;feature vector;color image;image processing;image retrieval;computer science;pattern recognition;data mining;mathematics;variance;texture;k-nearest neighbors algorithm;feature;search algorithm	Vision	43.0491466100034	-60.93280432161935	86472
ecb7fe54115a768fa321aad4799e2e1059770e3d	structure extraction from decorated characters by graph spectral decomposition and component selection criterion	graph spectral decomposition;spectral decomposition;decorated character;character recognition	For recognition of decorated characters through existing optical character recognition system (OCR), structure extraction of the decorated characters is required. Omachi et al. proposed a structure extraction method for these characters. However, characters including both thin lines and thick lines simultaneously tend to fail the extraction of structure. To overcome the performance in Omachi's method, we have proposed another method based on graph spectral decomposition. In the previous work, we showed applicability of the proposed method to wider range of decorated characters. However, selection criterion among decomposed components for obtaining good results have not been clarified. In this paper, we propose a new criterion to select components in the graph spectral decomposition framework for structure extraction. Experimental results show the validity of the criterion.	contour line;optical character recognition	Hideaki Kawano;Akito Shimamura;Hiroshi Maeda;Hideaki Orii;Norikazu Ikoma	2009	2009 ICCAS-SICE	10.20965/jaciii.2010.p0179	machine learning;pattern recognition;matrix decomposition	AI	43.60056415102789	-64.18902883017363	86491
7f861518def1cb423638ac40a76a4a1f629b069e	uncertain region identification for stereoscopic foreground cutout		This paper presents a method that automatically segments the foreground objects for stereoscopic images. Given a stereo pair, a disparity map can be estimated, which encodes the depth information. Objects that stay close to the camera are considered as foreground while regions with larger depths are deemed as background. Although the raw disparity map is usually noisy, incomplete, and inaccurate, it facilitates an automatic generation of trimaps for both views, where the images are partitioned into three regions: definite foreground, definite background, and uncertain region. Our job is now reduced to labelling of pixels in the uncertain region, in which the number of unknown pixels has been decreased largely. We propose to use an MRF based energy minimization for labelling the unknown pixels, which involves both local and global color probabilities within and across views. Results are evaluated by objective metrics on a ground truth stereo segmentation dataset, which validates the effectiveness of our proposed method.	dvd region code;stereoscopy	Taotao Yang;Shuaicheng Liu;Chao Sun;Zhengning Wang;Bing Zeng	2017		10.1007/978-3-319-71598-8_35	computer vision;artificial intelligence;pattern recognition;stereoscopy;labelling;pixel;computer science;image segmentation;ground truth	Crypto	47.42985802984665	-52.4973626886008	86499
b697d482605449fac67398c4aa44fe2347d71947	an adaptive approach for affine-invariant 2d shape description	affine transformation;shape description	In this paper, a new algorithm for 2D shape characterization is proposed. This method characterizes a planar object using a triangle-area representation obtained from its closed contour. As main novelty with respect to previous approaches, in our approach the triangle side lengths at each contour point are adapted to the local variations of the shape, removing noise from the contour without missing relevant points. This representation is invariant to affine transformations, and robust against noise. The performance of our proposal is demonstrated using a standard test on the well-known MPEG-7 CE-shape-1 data set.		Antonio Bandera;Esther Antúnez;Rebeca Marfil	2009		10.1007/978-3-642-02172-5_54	active shape model;computer vision;topology;computer science;affine transformation;mathematics;geometry;affine shape adaptation	Vision	41.83595365560573	-57.49498936201509	86506
5ae147253df6974cfb409bd18b7c11ecc88d964b	a two-stage multimodal speaker location-aware approach in pervasive computing	sensibilidad contexto;informatica movil;modelo markov oculto;vision ordenador;intelligent video surveillance;context aware;estimation mouvement;informatique mobile;modelo markov;multimodal speaker;modele markov cache;surveillance;etude experimentale;hidden markov model;color;pervasive computing;arrival time;localization;estimacion movimiento;continuous mouth motion;hmm;hombre;location aware computing;motion estimation;localizacion;orientation;voice;colour features;voz;repere visuel;computer vision;informatica difusa;active speakers;stimulus visuel;vigilancia;markov model;localisation;hidden markov models;informatique diffuse;time delays of arrival;tiempo llegada;visual stimulus;human;human voice;orientacion;multimodal;couleur;vision ordinateur;location awareness;temps retard;estimulo visual;delay time;sensibilite contexte;modele markov;speaker;temps arrivee;locutor;mobile computing;speaker orientation;indoor installation;security;instalacion interior;tiempo retardo;installation interieure;estudio experimental;locuteur;speaking recognition;location aware;homme;tdoa;voix;visual cue;marca visual	Location-aware computing is important in pervasive computing and intelligent video surveillance. We propose a two-stage multimodal approach to locate the active speaker in intelligent environments. Firstly, human voice is captured as audio cue to find the approximate orientation of current speaker. Secondly, the colour feature of mouth region is extracted as visual cue to detect continuous mouth motion that identifies the active speaker. The speaking recognition is conducted by a well-trained Hidden Markov Model based on colour feature of mouth region during continuous motion. Experiments show that the proposed multimodal approach is effective for speaker localisation in intelligent indoor environments.	location awareness;multimodal interaction;pc speaker;ubiquitous computing	Ruo-gui Xiao;Tongqiang Guo	2010	IJCAT	10.1504/IJCAT.2010.034147	loudspeaker;speaker recognition;speaker diarisation;simulation;speech recognition;human voice;internationalization and localization;computer science;multilateration;machine learning;multimodal interaction;motion estimation;orientation;markov model;voice;hidden markov model	HCI	45.45128329856864	-58.07715028204606	86516
bfb5b3a56fae726aeb17289614b655b2d323fd1f	ordinal-based shape retrieval with relevance feedback	ordinal correlation scheme ordinal based shape retrieval statistics retrieval iterations weights estimation;correlation methods content based retrieval image retrieval higher order statistics;shape image retrieval information retrieval content based retrieval pixel signal processing laboratories feedback loop statistics humans;retrieval iterations;information retrieval;correlation methods;higher order statistics;ordinal correlation scheme;weights estimation;shape;feedback loop;signal processing;pixel;statistics;humans;shape based image retrieval;shape retrieval;similarity measure;relevance feedback;content based retrieval;ordinal based shape retrieval;image retrieval	In this paper we propose to incorporate a feedback loop, into the ordinal correlation framework and apply it to shapebased image retrieval. The user’s feedback on the relevance of the retrieval results is used to tune the weights of the similarity measure. Statistics from the features of both relevant and irrelevant items are used to estimate the weights. Moreover, the information accumulated from previous retrieval iterations is used in the weights estimation. A simple measure of the discrimination power is proposed and used to show that the relevance feedback increases the capability of the ordinal correlation scheme to discriminate between relevant and irrelevant objects.	image retrieval;iteration;linear discriminant analysis;ordinal data;relevance feedback;similarity measure	Faouzi Alaya Cheikh;Bogdan Cramariuc;Moncef Gabbouj	2003		10.1109/ISSPA.2003.1224672	computer vision;image retrieval;shape;computer science;signal processing;pattern recognition;feedback loop;mathematics;information retrieval;pixel;statistics	Vision	40.3222036932571	-61.69481357174743	86546
3c99a41c8d7a9f42b2c06f764ab1fd936df4cbc4	robust voronoi-based curvature and feature estimation	piecewise smooth;shape analysis;covariance matrices;feature extraction;robust method;hausdorff distance;point cloud;error bound	Many algorithms for shape analysis and shape processing rely on accurate estimates of differential information such as normals and curvature. In most settings, however, care must be taken around non-smooth areas of the shape where these quantities are not easily defined. This problem is particularly prominent with point-cloud data, which are discontinuous everywhere. In this paper we present an efficient and robust method for extracting principal curvatures, sharp features and normal directions of a piecewise smooth surface from its point cloud sampling, with theoretical guarantees. Our method is integral in nature and uses convolved covariance matrices of Voronoi cells of the point cloud which makes it provably robust in the presence of noise. We show analytically that our method recovers correct principal curvatures and principal curvature directions in smooth parts of the shape, and correct feature directions and feature angles at the sharp edges of a piecewise smooth surface, with the error bounded by the Hausdorff distance between the point cloud and the underlying surface. Using the same analysis we provide theoretical guarantees for a modification of a previously proposed normal estimation technique. We illustrate the correctness of both principal curvature information and feature extraction in the presence of varying levels of noise and sampling density on a variety of models.	algorithm;convolution;correctness (computer science);feature extraction;feature vector;hausdorff dimension;point cloud;sampling (signal processing);shape analysis (digital geometry);voronoi diagram	Quentin Mérigot;Maks Ovsjanikov;Leonidas J. Guibas	2009		10.1145/1629255.1629257	hausdorff distance;mathematical optimization;topology;principal curvature;feature extraction;shape analysis;point cloud;mathematics;geometry;statistics	Vision	50.34744980861762	-64.29482290263587	86548
43e55b183ca480987e619bdf8bf9dd99fdf5b6bc	hand-drawn symbol spotting using semi-definite programming based sub-graph matching	sub graph matching;sub graph isomorphism;image segmentation;sub graph matching symbol recognition symbol spotting sub graph isomorphism;graph formation hand drawn symbol spotting semi definite programming based sub graph matching document image stochastic graphical model image segmentation;image matching;training;graph matching;image segmentation document image processing handwritten character recognition image matching;graph isomorphism;accuracy;stochastic graphical model;hand drawn symbol spotting;semi definite program;stochastic processes;feature extraction;pixel;symbol spotting;document image processing;graphical model;semi definite programming based sub graph matching;graph formation;document image;programming;image segmentation pixel training stochastic processes programming accuracy feature extraction;handwritten character recognition;symbol recognition	In this paper we address the problem of hand-drawn symbol spotting in document images. We use stochastic graphical models (SGMs) to represent the structure and variations of hand-drawn symbols. We use a framework which first carries out segmentation and graph formation of the input image, followed by sub-graph matching for spotting of hand-drawn symbols. We used SGMs in place of sub-graphs in a semi-definite programming based sub-graph matching to do the spotting. The experimental results validate our framework. We were able to spot hand-drawn symbols from 10 classes with 78.89% accuracy in a database of 76 document images and also were able to deal with confusingly similar symbol classes.	algorithm;class diagram;experiment;graphical model;matching (graph theory);open-source software;semiconductor industry;semidefinite programming;sockets direct protocol	Kiran Bhuvanagiri;Aditya Vikram Daga;Ramachandrula Sitaram;Suryaprakash Kompalli	2010	2010 12th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2010.51	stochastic process;computer vision;programming;feature extraction;computer science;machine learning;pattern recognition;accuracy and precision;graphical model;graph isomorphism;image segmentation;pixel;matching	Vision	43.398100036753455	-56.67867258368098	86563
bc8b700e34d3f34c7ceaa6d44e0730697e53f856	track matching over disjoint camera views based on an incremental major color spectrum histogram	moving object;video surveillance;single frame matching track matching disjoint camera incremental major color spectrum histogram major color spectrum histogram representation;major color spectrum histogram representation;image matching;disjoint camera;spectrum;track matching;tracking image matching cameras image colour analysis;image colour analysis;incremental major color spectrum histogram;camera network;similarity measure;cameras histograms robustness tracking shape frequency information technology australia video surveillance computerized monitoring;single frame matching;cameras;tracking;conference proceeding	Matching tracks from a single individual across disjoint camera views is a challenging task in video surveillance. In this paper, a major color spectrum histogram representation (MCSHR) is introduced to represent a moving object by using a normalized distance between two points in the RGB space. Then, an incremental MCSHR is proposed to cope with small pose changes and segmentation errors occurring along the track. Finally, a similarity measurement algorithm is proposed based on the incremental MCSHR to measure the similarity of any two tracked moving objects. The proposed similarity measurement algorithm proved capable of measuring the similarity of the two moving objects accurately. Experimental results show that with three to five frames integration, the proposed incremental MCSHR algorithm can make matching more robust and reliable than single-frame matching, especially for small pose changes. The matching performance is not obviously improved instead when the number of integration is more than five. The similarity of a same moving object in two different tracks has been improved from 92% to 95% with the integration number increased from three to five, while two different moving objects have been easily discriminated. The proposed algorithm can be used to match tracks from single individuals in camera networks, which do not provide full coverage of the monitored space.	algorithm;closed-circuit television	Massimo Piccardi;Eric Dahai Cheng	2005	IEEE Conference on Advanced Video and Signal Based Surveillance, 2005.	10.1109/AVSS.2005.1577258	spectrum;computer vision;pattern recognition;mathematics;tracking;computer graphics (images)	Vision	43.50986026483395	-53.63871847844345	86667
a3160d7354aa088cf42992265698838c02081364	kernel biased discriminant analysis using histogram intersection kernel for content-based image retrieval	estimacion sesgada;contenu image;sample size;image content;raisonnement base sur cas;razonamiento fundado sobre caso;decomposition valeur singuliere;small sample size;incertidumbre;uncertainty;tamano muestra;extraction forme;singular value decomposition;taille echantillon;intelligence artificielle;generalized singular value decomposition;discriminant analysis;analyse discriminante;analisis discriminante;histogram;histogramme;machine learning;extraccion forma;feature extraction;pattern recognition;retroaction pertinence;artificial intelligence;decomposicion valor singular;incertitude;inteligencia artificial;reconnaissance forme;extraction caracteristique;case based reasoning;reconocimiento patron;content based image retrieval;contenido imagen;histograma;biased estimation;relevance feedback;content based retrieval;pattern extraction;estimation biaisee;recherche par contenu	It is known that no single descriptor is powerful enough to encompass all aspects of image content, i.e. each feature extraction method has its own view of the image content. A possible approach to cope with that fact is to get a whole view of the image(object). Then using machine learning approach from user’s Relevance feedback to obtain a reduced feature. In this paper, we concentrate on some points about Biased Discriminant Analysis / Kernel Biased Discriminant Analysis (BDA/KBDA) based machine learning approach for CBIR. The contributions of this paper are: 1. using generalized singular value decomposition (GSVD) based approach solve the small sample size problem in BDA/KBDA and 2. using histogram intersection as a kernel for KBDA. Experiments show that this kind of kernel gets improvement compare to other common kernels.	broadcast driver architecture;content-based image retrieval;feature extraction;kernel (operating system);linear discriminant analysis;machine learning;relevance feedback;singular value decomposition	Lin Mei;Gerd Brunner;Lokesh Setia;Hans Burkhardt	2005		10.1007/11508069_9	sample size determination;case-based reasoning;kernel method;kernel fisher discriminant analysis;string kernel;kernel embedding of distributions;radial basis function kernel;uncertainty;feature extraction;kernel principal component analysis;computer science;artificial intelligence;machine learning;pattern recognition;histogram;mathematics;linear discriminant analysis;tree kernel;singular value decomposition;variable kernel density estimation;polynomial kernel;statistics	AI	43.90007077826301	-60.31530094374637	86748
a3eda6ee6d32306ed5d4ec7fc26128317a89263d	using binary pyramids to create multi-resolution shape descriptors	analisis imagen;image processing;shape descriptor;analisis forma;multiscale representation;procesamiento imagen;analyse multiresolution;traitement image;pattern recognition;image analysis;pattern analysis;reconnaissance forme;reconocimiento patron;multi resolution;multiresolution analysis;analyse image;analyse forme;analisis multiresolucion	The analysis of a 2D graphical document can be accomplished by using a suitable linear representation, e.g. the skeleton, of the pattern included in the document. Multiresolution representation and description are desirable for pattern recognition applications, as it reduces the complexity of the matching phase. In this paper, multiresolution shape descriptors of 2D graphical documents are obtained by using binary AND-pyramids. A multiscale representation is first obtained by simply extracting the skeleton of the pattern at all resolution levels of the pyramid. The so obtained skeletons are then transformed into multiresolution structures by suitably ranking skeleton subsets, based on their permanence at the various scales. The two different types of hierarchy built in this way both contribute to facilitate recognition. In fact, the skeleton is available at various scales, so one could initially match roughly using only skeletons at lower scales, where only the most significant parts of the pattern are represented. In turn, at each scale, skeleton subsets are furthermore ranked according to their permanence along the pyramid levels, thus reducing the number of prototypes for which a more detailed comparison is necessary.	document;multiresolution analysis;pattern recognition;shape analysis (digital geometry)	Gunilla Borgefors;Giuliana Ramella;Gabriella Sanniti di Baja	1997		10.1007/3-540-63791-5_9	multiresolution analysis;computer vision;image analysis;image processing;computer science;geometry;topological skeleton	Vision	43.57455878145405	-61.640043047432584	86907
d65cde8a0574a885e2d455101501a58b1245dc24	the geometry of view space of opaque objects bounded by smooth surfaces	deteccion borde;vision ordenador;geometrie algorithmique;edge detection;espacio 3 dimensiones;computational geometry;intelligence artificielle;surface lisse;computer vision;smooth surface;deteccion contorno;detection contour;espace 3 dimensions;three dimensional space;geometria algoritmica;pattern recognition;artificial intelligence;vision ordinateur;inteligencia artificial;reconnaissance forme;superficie lisa;reconocimiento patron;detection bord	A view of a smooth, opaque object is a line drawing consisting of contour fragments which form closed loops, terminate, or form T-junctions. Given a compact object we have a global decomposition of the space of camera positions into cells from which topologically equivalent views are obtained. To apply certain image-based object recognition techniques based on characteristic views of an object one needs to know this cellular decomposition of view space. The boundaries of such cells of stable views are formed by the view bifurcation set from which transitional (degenerate) views are seen. We derive a finite list of geometrical models of the view bifurcation set—the view bifurcation set of any particular object is a combination of such model surfaces from this list. To match a characteristic view with an image one has to find the visible fragments of the apparent contour in the image, and we briefly describe an observation which might lead to an algorithm for finding such contour fragments.		J. H. Rieger	1990	Artif. Intell.	10.1016/0004-3702(90)90097-J	three-dimensional space;computer vision;edge detection;computational geometry;computer science;artificial intelligence;mathematics;geometry	Vision	50.31342734449317	-59.75275803849237	86911
aa01c6401b21a616c81382bfbda62aa15745d878	a top-down quadtree traversal algorithm	connected component labeling;perimeter;bottom up;image coding;image processing;application software;computer graphics;top down;tree graphs;distance measurement;image representation;quadtrees connected component labeling image processing image representation perimeter;transforms;pattern recognition;computer science;connected component;information analysis;quadtrees;image processing labeling tree graphs algorithm design and analysis image representation application software computer graphics pattern recognition computer science costs;algorithm design and analysis;labeling	Many standard image processing operations can be implemented using quadtrees as a simple tree traversal where, at each terminal node, a computation is performed involving some of that node's neighbors. Most of this work has involved the use of bottom-up neighbor-finding techniques which search for a nearest common ancestor. Recently, top-down techniques have been proposed which make use of a neighbor vector as the tree is traversed. A simplified version of the top-down method for a quadtree in the context of a general-purpose tree traversal algorithm is presented. It differs, in part, from prior work in its ability to compute diagonally adjacent neighbors rather than just horizontally and vertically adjacent neighbors. It builds a neighbor vector for each node using a minimal amount of information. Analysis of the algorithm shows that its execution time is directly proportional to the number of nodes in the tree. However, it does require some extra storage. Use of the algorithm leads to lower execution time bounds for some common quadtree image processing operations such as connected component labeling.	algorithm;bottom-up parsing;computation;connected component (graph theory);connected-component labeling;general-purpose modeling;hl7publishingsubsection <operations>;image processing;lowest common ancestor;node - plant part;quadtree;run time (program lifecycle phase);top-down and bottom-up design;tree traversal	Hanan Samet	1985	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1985.4767622	nearest-neighbor chain algorithm;computer vision;discrete mathematics;image processing;computer science;theoretical computer science;machine learning;graph traversal;quadtree;top-down and bottom-up design;tree traversal	Visualization	43.02185760367338	-65.7614783779571	86977
425897dd1a27ff079c15a38e7fadb841bea82235	automatic wavelet base selection and its application to contrast enhancement	transformation ondelette;traitement signal;image recognition;contrast enhanced;reconocimiento imagen;vision ordenador;image processing;accentuation image;implementation;wavelet base;base ondita;procesamiento imagen;qualite image;traitement image;computer vision;over enhancement;algorithme;selection automatique;algorithm;image enhancement;wavelet basis;wavelet transform;seleccion automatica;signal processing;image quality;reconnaissance image;pattern recognition;vision ordinateur;calidad imagen;transformacion ondita;reconnaissance forme;under enhancement;reconocimiento patron;implementacion;base ondelette;procesamiento senal;wavelet transformation;automatic selection;algoritmo	In this paper, we propose a novel approach to automatic selecting wavelet bases and parameters which is an important and essential issue for implementing wavelet algorithms. The proposed approach is applied to contrast enhancement which is one of the fundamental topics in image processing, pattern recognition and computer vision. Our method utilizes wavelet transform to decompose the image, and then modifies the coefficients by employing the proposed method to perform contrast enhancement. Experimental results demonstrate that the proposed method is very efficient in contrast enhancement without under-enhancement and over-enhancement, and it is superior to some other existing methods.	wavelet	Heng-Da Cheng;Rui Min;Ming Zhang	2010	Signal Processing	10.1016/j.sigpro.2009.10.013	image quality;computer vision;speech recognition;second-generation wavelet transform;image processing;computer science;artificial intelligence;signal processing;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;implementation;wavelet transform	ML	45.27177584440323	-61.159105009053675	87106
693b54320062df758c908ad56867bca1660f322e	automatic photo indexing based on person identity	reconnaissance visage;modelizacion;analyse amas;confiance;multimedia;facies;indexation automatique;interrogation base donnee;interrogacion base datos;classification;personal identity;indexing method;modelisation;feature vector;confidence;cluster analysis;face recognition;confianza;indexation;automatic indexing;analisis cluster;modeling;article;database query;clasificacion;indizacion automatica	In this paper, we propose a novel approach to automatically index digital home photos based on person identity. A person is identified by his/her face and clothes. The proposed method consists of two parts: clustering and indexing. In the clustering, a series of unlabeled photos is aligned in taken-time order, and is divided into several sub-groups by situation. The situation groups are decided by time and visual differences. In the indexing, SVMs are trained with features of pre-indexed faces to model target persons. The representative feature vector of the person group from the clustering is queried to the trained SVMs. Each SVM outputs a numeric confidence value about the query person group. The query person group is determined to the target person by the most confident SVM. The experimental results showed that the proposed method outperformed traditional person indexing method using only face feature and its performance increased to 93.56% from 72.31%.		Seungji Yang;Kyong Sok Seo;Sang Kim;Yong Man Ro;Ji-Yeon Kim;Yang Suk Seo	2005		10.1007/11582267_76	personal identity;facial recognition system;computer vision;speech recognition;systems modeling;feature vector;facies;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;data mining;database;confidence;cluster analysis	Vision	44.78736128217956	-58.98680902234855	87214
0ef1c57bee49909e26971f4dbf11191965aad0ee	a new edge-grouping algorithm for multiple complex objects localization	feature extraction;extended kalman filter;kalman filter	We present a new algorithm that provides an efficient localization method of elliptic industrial objects. Our proposed feature extraction inherits edge grouping approaches. But instead of utilizing edge linkage to restore incomplete contours, we introduce criteria of feature's parameters and optimize the criteria using an extended Kalman filter. Through a new parameter estimation under a proper ellipse representation, our system successfully generates ellipse hypotheses by grouping the fragmental edges in the scene. An important advantage of using our Kalman filter approach is that a desired feature can be robustly extracted regardless of ill-condition of partial edges and outlier noises. The experiment results demonstrate a robust localization performance.	algorithm;estimation theory;experiment;extended kalman filter;feature extraction;internationalization and localization;linkage (software);xslt/muenchian grouping	Yuichi Motai	2004		10.1007/978-3-540-24677-0_122	kalman filter;computer vision;outlier;edge detection;system identification;image processing;feature extraction;computer science;artificial intelligence;machine learning;elliptic function;mathematics;extended kalman filter;estimation theory;statistics	Robotics	52.57198960146792	-58.249287011714934	87306
fdd61193950063e0059621c9f3b1cf7293e467e0	genetic algorithms to automatic weld bead detection in double wall double image digital radiographs	weld bead detection;welds flaw detection genetic algorithms image matching inspection mechanical engineering computing object detection pipes radiography;mechanical engineering computing;phenotype and heuristic functions;image matching;welds;welding;joints;inspection genetic algorithm automatic weld bead detection double wall double image digital radiograph radiographic image double wall double image technique dwdi technique fully automatic flaw identification welded joints pipe model image matching genotype linear combination heuristic function phenotype evolutionary process object position object orientation object dimension object detection;inspection;radiography;welding genetic algorithms radiography equations mathematical model biological cells joints;biological cells;flaw detection;mathematical model;phenotype and heuristic functions dwdi radiographic images weld bead detection genetic algorithms;genetic algorithms;dwdi radiographic images;pipes;object detection	This paper presents a pioneering approach for weld bead detection in radiographic images obtained by the Double Wall Double Image (DWDI) technique. Such task constitutes an essential step for several high level processes, such as fully automatic flaw identification on welded joints. Sets of sample pixels, corresponding to candidate solutions provided by a genetic algorithm (GA), are compared to pre-defined synthetic weld bead and pipe models in an image matching procedure. The fitness of each set (individual) is evaluated based on a linear combination of its genotype (evaluated by a heuristic function) and phenotype. The evolutionary process automatically selects the best individual in the population and, thus, provides information such as position, orientation and dimension of the detected object. The proposed approach successfully detects pipes and weld beads in radiographic images of different complexities, encouraging future works.	double image backup;experiment;flaw hypothesis methodology;genetic algorithm;heuristic (computer science);high-level programming language;image processing;image registration;mathematical optimization;particle swarm optimization;pixel;radiography;sampling (signal processing);software release life cycle;synthetic intelligence;testbed	Marcel Kroetz;Tania Mezzadri Centeno;Myriam Regattieri Delgado;Marcelo Kleber Felisberto;Luís A. Lucas;Leyza B. Dorini;Vitor Fylyk;Allan Vieira	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256505	computer vision;genetic algorithm;radiography;inspection;computer science;mathematical model;welding	Vision	46.636111597728515	-54.19395981057235	87472
c9ce6736ff1e858d91a13fa4e8cd7d7e53e1f88e	texture class assignment in texscale: an evaluation study	image sampling;texture samples texture class assignment texture analysis hierarchical approach group method texture super class mask tuning feature extraction classification rule construction texture energy texture classification confusion matrix;image segmentation;image sampling image texture feature extraction image classification;texture energy;group method;information science;convolution;feature extraction image segmentation convolution information science computer science layout shape visual system image texture analysis performance analysis;texture classification;mask tuning;image classification;layout;texture features;image texture;texture analysis;shape;feature extraction;classification rules;confusion matrix;performance analysis;image texture analysis;texture samples;computer science;texture class assignment;classification rule construction;visual system;evaluation studies;texture super class;hierarchical approach	This paper describes a methodology termed texscale for texture analysis. This hierarchical approach is based on the group method which aims to group different textures into super-classes and determine whether a texture belongs in a particular texture super-class in conjunction with a mask tuning scheme to characterize texture features. Unlike the traditional two-step classification operation involving feature extraction followed by classification rule construction, our aim has been to introduce the texture energy computed using texture 'tuned' masks to directly function as a classifier in a single stage. An evaluation study of texscale classification scheme has been taken via the confusion matrix, which examines the extent to which arbitrary texture samples drawn from the total set of sample textures in two separate studies can be correctly assigned to the classes (15 in the study). One involves 360 samples, the other involves 1440 samples. >		Jane You;Harvey A. Cohen	1994		10.1109/ICASSP.1994.389405	image texture;layout;computer vision;contextual image classification;confusion matrix;visual system;feature extraction;information science;shape;computer science;machine learning;pattern recognition;image segmentation;convolution	NLP	40.13927429608263	-63.34932790262251	87521
1f7d0b6adffd7f3ec64f89bc7be2ccba738484d3	exploiting depth discontinuities for vision-based fingerspelling recognition	shape fingers layout image edge detection hidden markov models cameras handicapped aids deafness nails vocabulary;shape descriptor;edge detection;vocabulary;layout;handicapped aids;hidden markov models;shape;image edge detection;deafness;fingers;scale invariance;cameras;nails	We present a novel method for automatic fingerspelling recognition which is able to discriminate complex hand configurations with high amounts of finger occlusions. Such a scenario, while common in most fingerspelling alphabets, presents a challenge for vision methods due to the low intensity variation along important shape edges in the hand image. Our approach is based on a simple and cheap modification of the capture setup: a multi-flash camera is used with flashes strategically positioned to cast shadows along depth discontinuities in the scene, allowing efficient and accurate hand shape extraction. We then use a shift and scale invariant shape descriptor for fingerspelling recognition, demonstrating great improvement over methods that rely on features acquired by traditional edge detection and segmentation algorithms.	algorithm;edge detection	Rogério Schmidt Feris;Matthew Turk;Ramesh Raskar;Kar-Han Tan;Gosuke Ohashi	2004	2004 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPR.2004.336	layout;computer vision;speech recognition;edge detection;shape;computer science;scale invariance;geometry;hidden markov model	Vision	42.961716646996216	-53.060936800250104	87537
16856165843c711e74d67bf5780e77032a7925fa	a robust iris localization model based on phase congruency and least trimmed squares estimation	least trimmed squares estimation;iris recognition;phase congruency;iris segmentation;position estimation;robust regression;least trimmed squares	Iris localization is a crucial step in iris recognition. The previous proposed algorithms perform unsatisfactorily due to the disturbing of eyelash and variation of image brightness. To solve these problems, we proposed a robust iris position estimation algorithm based on phase congruency analysis and LTSE (Least Trimmed Squares Estimation). Through using the robust regression method to fit iris edge points we can solve the eyelash occlusion problem at a certain extent. The experimental results demonstrate the validity of this algorithm.	phase congruency	Lili Pan;Mei Xie;Tao Zheng;Jianli Ren	2009		10.1007/978-3-642-04146-4_73	computer vision;least trimmed squares;computer science;pattern recognition;iris recognition;mathematics;robust regression;statistics	Vision	48.386576790209574	-54.760640518631895	87555
824f5919985777279794bb5fc0b3b6a303e6d3b8	trifocal transfer based novel view synthesis for micromanipulation	modelizacion;vision ordenador;micromanipulation;image processing;procesamiento imagen;traitement image;computer vision;modelisation;reconstruction image;virtual view;view synthesis;reconstruccion imagen;vue virtuelle;image reconstruction;micromanipulacion;vision ordinateur;vista virtual;modeling	In trifocal transfer based novel view synthesis, matched pixels of both input views are projected in the novel view. The angle of view of this latest is usually narrow, i.e. the novel view is very close to input ones. In this paper we improve the method to get a large angle of view. A simplex approach is used to compute the model of the virtual views pose. This model allows the computation of the novel view at any desired angle of view. We also show that those results are very useful in micromanipulation tasks where transfer of edges is enough instead of the entire pixels of input views.	computation;dummy variable (statistics);nelder–mead method;pixel;simplex algorithm;trifocal tensor;view synthesis	Julien Bert;Sounkalo Dembélé;Nadine Le Fort-Piat	2006		10.1007/11919476_42	iterative reconstruction;computer vision;simulation;systems modeling;image processing;computer science;computer graphics (images)	Visualization	50.625001676296485	-56.90326966821823	87777
451f94c9754035c1ec77a3602ec1f1907d4a2f0f	optical wear assessment system for grinding tools	image processing;image fusion;inspection;wavelet transforms;wavelet transform;high performance;wavelets	The inspection and monitoring of the wear of grinding tools is essential to ensure the quality of the grinding tool surface and the finished product. Most of the current methods for examining a grinding tool surface rely on dismounting the grinding tool. Often, the state of the grinding tool surface is checked indirectly by evaluating the quality of the workpiece. We describe the application of image processing, which offers an effective means for in situ inspection and monitoring. It yields more detailed information about the surface and the kind of wear observed than the common methods. By using multidirectional illumination and image fusion, an image with a high degree of relevant information is generated that is then segmented using the wavelet transform (multiscale analysis) and classified to distinguish grains and cavities on the surface. Results of the application of the algorithms for a high-performance grinding tool with CBN grains embedded in a resin base are presented. © 2004 SPIE and IS&T. [DOI: 10.1117/1.1760757]	algorithm;embedded system;image fusion;image processing;resin;wavelet transform	Thomas Heger;Madhukar Pandit	2004	J. Electronic Imaging	10.1117/1.1760757	computer vision;image processing;wavelet transform	EDA	47.16990964450545	-65.6384626403113	87812
38b9850d396eb935231e4907f041d1c3fb897e80	an approach to the recognition of contours and line-shaped objects	printed circuit;pattern recognition;controle qualite;reconnaissance forme;quality control;circuit imprime	Some methods implemented for printed circuit (PC) board inspection have been developed and applied to line analysis. The idea of calculation of the number of objects within a circular operator field, developed by Danielsson and Kruse (Computer Graphics and Image Processing 4, 1979) for distance-checking algorithms, has been elaborated for line recognition. An edgepreserving technique with a rotating neighborhood has been implemented for texture recognition. The local properties of the operator field with the rotating neighborhood have led to formulating and proving a basic condition on representing images. This condition relates conformity of recognition results with group theory. The results of line inspection by means of a circular operator following the line are represented as graphs. The nodes of these graphs are labeled with names of features of the image (e.g., of the line followed) and the arcs of these graphs are labelled with the names of relations on these features. As soon as the names of these features and relations have been expressed, usually through words and phrases, a description of the image can be made with the aid of expressions of natural language, and then converted to graph form.	arcs (computing);algorithm;computer graphics;computer vision;conformity;contour line;image processing;natural language;printed circuit board	Zbigniew M. Wójcik	1984	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(84)90102-6	computer vision;quality control;computer science;artificial intelligence;geometry;printed circuit board;algorithm	Vision	47.99400846721352	-61.214824029787536	87839
18f70d8e1697bc0b85753db2d4d64aeb696b052a	evolutionary discriminant feature extraction with application to face recognition	reconnaissance visage;dimensionalidad;signal image and speech processing;traitement signal;complejidad espacio;evaluation performance;metodo estadistico;analisis componente principal;evolutionary computation;performance evaluation;image processing;computation theory;biometrie;evaluacion prestacion;biometrics;database;biometria;procesamiento imagen;base dato;dimensionality;calcul evolutionniste;statistical method;metodo subespacio;traitement image;methode sous espace;discriminant analysis;analyse discriminante;etat actuel;analisis discriminante;automatic recognition;face recognition;quantum information technology spintronics;methode statistique;dimensionnalite;discriminative feature extraction;feature extraction;signal processing;principal component analysis;state of the art;base de donnees;analyse composante principale;space complexity;pattern recognition;subspace method;algorithme evolutionniste;estado actual;algoritmo evolucionista;reconnaissance forme;extraction caracteristique;evolutionary algorithm;complexite espace;reconocimiento patron;computational efficiency;procesamiento senal;journal magazine article;reconocimiento automatico;reconnaissance automatique	Evolutionary computation algorithms have recently been explored to extract features and applied to face recognition. However these methods have high space complexity and thus are not efficient or even impossible to be directly applied to real world applications such as face recognition where the data have very high dimensionality or very large scale. In this paper, we propose a new evolutionary approach to extracting discriminant features with low space complexity and high search efficiency. The proposed approach is further improved by using the bagging technique. Compared with the conventional subspace analysis methods such as PCA and LDA, the proposed methods can automatically select the dimensionality of feature space from the classification viewpoint. We have evaluated the proposed methods in comparison with some state-of-the-art methods using the ORL and AR face databases. The experimental results demonstrated that the proposed approach can successfully reduce the space complexity and enhance the recognition performance. In addition, the proposed approach provides an effective way to investigate the discriminative power of different feature subspaces.	bootstrap aggregating;dspace;database;evolutionary computation;facial recognition system;feature extraction;feature vector;genetic algorithm;iterative and incremental development;linear discriminant analysis;machine learning;nonlinear dimensionality reduction;nonlinear system;picture transfer protocol;principal component analysis;rm-odp;return loss;software release life cycle	Qijun Zhao;David Zhang;Lei Zhang;Hongtao Lu	2009	EURASIP J. Adv. Sig. Proc.	10.1155/2009/465193	speech recognition;curse of dimensionality;image processing;feature extraction;computer science;artificial intelligence;machine learning;evolutionary algorithm;signal processing;dspace;algorithm;biometrics;evolutionary computation;principal component analysis	AI	44.4238718364349	-60.093000619103165	87907
d55086a138911e6be0d9fb8fe631a3bd6e9697de	improving efficiency of fingerprint matching by minutiae indexing	databases;minutiae indexing score method;minutiae search space;image sequences feature extraction fingerprint identification image matching;search space;image matching;fingerprint matching;minutiae structure based verification;fingerprint identification fingerprint matching minutiae indexing score method minutiae search space feature extraction image sequence minutiae candidate selection minutiae structure based verification;indexing method;accuracy;indexing;fingerprint recognition;feature extraction;indexation;image sequence;fingers;fingerprint recognition indexing feature extraction spatial databases automation nonlinear distortion skin computational complexity degradation robustness;coherence;minutiae candidate selection;fingerprint identification;image sequences	This paper proposes a novel minutiae indexing method to speed up fingerprint matching, which narrows down the searching space of minutiae to reduce the expense of computation. An orderly sequence of features are extracted to describe each minutia and the indexing score is defined to select minutiae candidates from the query fingerprint for each minutia in the input fingerprint. The proposed method can be applied in both minutiae structure-based verification and fingerprint identification. Experiments are performed on a large-distorted fingerprint database (FVC2004 DB1) to approve the validity of the proposed method.	computation;experiment;fingerprint;minutiae;triplet state	Yangyang Zhang;Jie Tian;Kai Cao;Peng Li;Xin Yang	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761855	fingerprint;computer vision;search engine indexing;coherence;feature extraction;computer science;pattern recognition;data mining;accuracy and precision;fingerprint recognition	Vision	39.857998584425836	-58.93272823584742	87993
186e0ddf93fb12fbe8e7f15ef1d7d228d9cfe0b6	filter-based models for pattern classification	filtering;vision ordenador;filtrage;image processing;performance indicator;learning;cross correlation;estudio comparativo;filtrado;human behaviour;procesamiento imagen;intelligence artificielle;classification;traitement image;computer vision;aprendizaje;etude comparative;apprentissage;scale space;comparative study;pattern classification;pattern recognition;artificial intelligence;vision ordinateur;inteligencia artificial;reconnaissance forme;reconocimiento patron;clasificacion	"""-In this paper we consider a technique for pattern classification based upon the development of prototypes which capture the distinguishing features (""""disjunctive prototypes"""") of each pattern class and, via cross-correlation with incoming test images, enable efficient pattern classification. We evaluate such a classification procedure with prototypes based on the images per se (direct code), Gabor scheme (multiple fixed filter representation) and an edge (scale space-based) coding scheme. Our analyses, and comparisons with human pattern classification performance, indicate that the edge-only disjunctive prototypes provide the most discriminating classification performance and are the more representative of human behaviour. Pattern classification Filters Scale space Edges Cross correlation Disjunctive prototypes"""	cross-correlation;disjunctive normal form;gabor filter;scale space;statistical classification	Terry Caelli;Walter F. Bischof;Zhi-Qiang Liu	1988	Pattern Recognition	10.1016/0031-3203(88)90036-2	filter;computer vision;scale space;image processing;biological classification;computer science;artificial intelligence;performance indicator;cross-correlation;machine learning;comparative research	ML	44.34572146691153	-60.7652055746012	88065
e473456063cf96539b2347fd37dfe4122c40ce91	face alignment based on the multi-scale local features	databases;detectors;image recognition;multi scale local features;eye detection;training;face recognition face alignment multi scale local features eye detection;semantics;face alignment;drntu engineering electrical and electronic engineering;conference paper;face recognition;face;face face recognition databases semantics training detectors image recognition;unaligned face image face alignment multiscale local features face recognition algorithms face image position eye location detection automatic transformation mechanism	Many face recognition algorithms depend on careful positioning of face images into the same canonical pose. Currently, this positioning is usually done by detecting the locations of eyes. And the face images are transformed to the same positions according to the eye coordinates detected. In this paper, we describe a method based on multi-scale local features to achieve face alignment automatically not just dependent on the localizations of two eyes. Given an unaligned face image resulting from a face detector and a set of aligned face images in the data set, we build an automatic transformation mechanism, under which the unaligned face image can be precisely aligned for the following recognition process. Our alignment method improves performance on face recognition tasks, over images aligned by many other algorithms.	algorithm;facial recognition system;sensor	Cong Geng;Xudong Jiang	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288179	face;computer vision;detector;face detection;speech recognition;object-class detection;computer science;pattern recognition;three-dimensional face recognition;semantics	Vision	40.274906563626416	-55.16548016538483	88161
1865654908b6b1423b8a944b83537e36d989f8cb	a two-step area based method for automatic tight segmentation of zona pellucida in hmc images of human embryos	artefacto;mascara;modelizacion;calculo de variaciones;topology;parametric model;vision ordenador;in vitro fertilization;image processing;probabilistic method;automatic segmentation;topologie;procesamiento imagen;hombre;segmentation;probabilistic approach;traitement image;embryos;artefact;topologia;computer vision;modelisation;calcul variationnel;enfoque probabilista;approche probabiliste;human;zona pellucida;vision ordinateur;masque;matematik;modeling;image modeling;mask;segmentacion;variational calculus;in vitro;homme	An important prognostic parameter for assessing the success of an in vitro fertilization treatment is the variation in thickness of the zona pellucida. Zona pellucida, the envelope of the human embryo, is usually visualized using Hoffman modulation contrast microscopy (HMC). This paper considers automatic segmentation of zona pellucida in HMC images of human embryos. There are two subproblems: (a) the embryo should be separated from the background and (b) the zona should be separated from the rest of the embryo. (a) is solved using a robust formulation of a classical area based method and (b) is solved using a probabilistic method. Both solutions are set in a variational framework using a novel image model for the zona. This variational framework is adapted to handle images in which large artefacts are covered with masks. Since the zona has a simple topology we focus on parametric models and a representation by trigonometric sums is considered.	calculus of variations;emoticon;hybrid memory cube;image quality;modulation;robustness (computer science);thickness (graph theory);variable shadowing;variational principle	Adam Karlsson;Niels Chr. Overgaard;Anders Heyden	2005		10.1007/11408031_43	embryo;computer vision;parametric model;systems modeling;image processing;computer science;probabilistic method;in vitro;mask;segmentation;calculus of variations	Vision	51.754155123007465	-56.93148677292811	88182
1bdacce5bcd13d5a1592de438da7a0056e81a8f3	a fast rule-based parameter free discrete hough transform	discrete information;image numerique;transformacion discreta;binary image;deteccion;informacion discreta;rule based;information discrete;parametrization;detection;line detection;image bruitee;transformacion hough;parametrizacion;imagen sonora;ligne geometrique;noisy image;imagen numerica;image binaire;discrete transformation;imagen binaria;hough transformation;hough transform;transformation hough;digital image;transformation discrete;parametrisation;line geometry;linea geometrica	This paper introduces a new discrete Hough transform, DHT, that pre-computes discrete line information (rules) and uses this information to detect line segments in the image. Pre-computing line information removes the need for run-time line calculations and the associated parameters. The proposed approach does not depend on the parameterization of a straight line and is formulated based on the discrete domain. This new DHT is compared with selected existing techniques to demonstrate the large reduction in computation time achieved by this new approach, while not sacrificing accuracy.	computation;distributed hash table;hough transform;time complexity;timeline	Bernie M. A. Genswein;Yee-Hong Yang	1999	IJPRAI	10.1142/S0218001499000379	rule-based system;parametrization;hough transform;computer vision;computer science;mathematics;geometry	Vision	48.74508029693711	-62.3080219768604	88226
fa502a2cf2f2c01fa3c3b266049ddc4ec7589e33	robust methods and representations for soccer player tracking and collision resolution	busqueda informacion;extraction information;model based reasoning;homograph;raisonnement base sur modele;pistage;sistema experto;filtro kalman;image processing;occlusion;information extraction;homografo;soccer;information retrieval;zoom;rule based;occultation;filtre kalman;hausdorff dimension;rastreo;procesamiento imagen;base connaissance;oclusion;kalman filter;traitement image;homographe;senal video;signal video;space use;recherche information;football;robust method;collision resolution;hausdorff distance;video signal;base conocimiento;ambiguity;dimension hausdorff;systeme expert;ocultacion;ambiguedad;extraccion informacion;tracking;image mosaicing;ambiguite;futbol;knowledge base;expert system	We present a method of tracking multiple players in a soccer match using video taken from a single fixed camera with pan, tilt and zoom. We extract a single mosaic of the playing field and robustly derive its homography to a playing field model, based on color information, line extraction, and a Hausdorff distance measure. Players are identified by color and shape, and tracked in the image mosaic space using a Kalman filter. The frequent occlusions of multiple players are resolved using a novel representation acted on by a rule-based method, which recognizes differences between removable and intrinsic ambiguities. We test the methods with synthetic and real data.	hash table	Lluis Barceló;Xavier Binefa;John R. Kender	2005		10.1007/11526346_27	kalman filter;hausdorff distance;computer vision;knowledge base;simulation;occultation;image processing;computer science;hausdorff dimension;artificial intelligence;model-based reasoning;tracking;zoom;expert system;information extraction	Robotics	48.63703132667802	-57.615181712479	88233
79d2c4097fe883dcdb6cb026720a512d72e31c00	multivariate relevance vector machines for tracking	hand;bayes estimation;analisis imagen;modelizacion;image features;object recognition;vision ordenador;clutter;pistage;estimation mouvement;image processing;cuerpo;methode noyau;image matching;body;estimacion movimiento;hausdorff dimension;rastreo;procesamiento imagen;sparse set;motion estimation;reconnaissance objet;aprendizaje probabilidades;probabilistic approach;traitement image;temporal information;computer vision;modelisation;classification a vaste marge;posture;estimacion bayes;histogram;fouillis echo;estimation erreur;analisis regresion;histogramme;state space method;methode espace etat;error estimation;erreur estimation;pattern matching;enfoque probabilista;approche probabiliste;human body;confusion eco;state space;metodo nucleo;relevance vector machine;estimacion error;postura;hand tracking;corps;mano;error estimacion;analyse regression;apprentissage probabilites;ambiguity;kernel method;image analysis;vision ordinateur;regression analysis;ensemble epars;concordance forme;dimension hausdorff;estimation error;maquina ejemplo soporte;vector support machine;main;histograma;ambiguedad;modeling;analyse image;appariement image;probability learning;tracking;ambiguite;metodo espacio estado;estimation bayes	This paper presents a learning based approach to tracking articulated human body motion from a single camera. In order to address the problem of pose ambiguity, a one-to-many mapping from image features to state space is learned using a set of relevance vector machines, extended to handle multivariate outputs. The image features are Hausdorff matching scores obtained by matching different shape templates to the image, where the multivariate relevance vector machines (MVRVM) select a sparse set of these templates. We demonstrate that these Hausdorff features reduce the estimation error in clutter compared to shape-context histograms. The method is applied to the pose estimation problem from a single input frame, and is embedded within a probabilistic tracking framework to include temporal information. We apply the algorithm to 3D hand tracking and full human body tracking.	3d pose estimation;clutter;embedded system;hausdorff dimension;kalman filter;one-to-many (data model);relevance;shape context;sparse language;sparse matrix;state space;viterbi algorithm	Arasanathan Thayananthan;Ramanan Navaratnam;Björn Stenger;Philip H. S. Torr;Roberto Cipolla	2006		10.1007/11744078_10	computer vision;kernel method;human body;image analysis;systems modeling;image processing;computer science;state space;hausdorff dimension;artificial intelligence;cognitive neuroscience of visual object recognition;pattern matching;motion estimation;histogram;mathematics;clutter;tracking;relevance vector machine;feature;regression analysis	Vision	46.69551241285505	-57.23560294723649	88396
0c72a5c7cef39017aa4c2bb7df5d52c3495d8772	a new approach of gray level corner detection	corner detection		corner detection	Zhiqiang Zheng;Han Wang;Eam Khwang Teoh;Kap Luk Chan	1998			artificial intelligence;computer vision;corner detection;pattern recognition;computer science	Vision	41.93916024291226	-65.7830076881413	88736
39394f61ed30d171bfd0d35d573b01251c4828a1	recovering 3d human pose from monocular images	image sequences computer vision learning artificial intelligence regression analysis support vector machines image motion analysis;monocular vision;vision ordenador;regression non lineaire;mouvement corporel;image motion analysis;ridge regression;metodo vectorial;vision monoculaire;image segmentation;image processing;support vector machines;regresion ridge;shape descriptor;analisis forma;non linear regression;humans image sequences labeling shape support vector machines kernel learning systems biological system modeling robustness image segmentation;procesamiento imagen;similar test;regression multivariable;regresion no lineal;cuerpo humano;indexing terms;state estimation;traitement image;corps humain;apprentissage machine;index terms computer vision;computer vision;regression pseudo orthogonale;analisis regresion;machine learning;human motion;human body;vector method;machine exemple support;image sequence;relevance vector machine;segmentation image;algorithms artificial intelligence humans image interpretation computer assisted imaging three dimensional joints pattern recognition automated photography posture reproducibility of results sensitivity and specificity subtraction technique;vision monocular;multivariate regression index terms computer vision human motion estimation machine learning;analyse regression;methode vectorielle;vision ordinateur;regression analysis;secuencia imagen;pattern analysis;support vector machine;human motion estimation monocular image sequences 3d human pose learning based method nonlinear regression shape descriptor vectors image silhouettes silhouette shape histogram of shape contexts descriptors ridge regression relevance vector machine regression support vector machine regression;maquina ejemplo soporte;vector support machine;learning artificial intelligence;movimiento corporal;content based retrieval;multivariate regression;recherche par contenu;body movement;human motion estimation;analyse forme;sequence image	We describe a learning-based method for recovering 3D human body pose from single images and monocular image sequences. Our approach requires neither an explicit body model nor prior labeling of body parts in the image. Instead, it recovers pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes. For robustness against local silhouette segmentation errors, silhouette shape is encoded by histogram-of-shape-contexts descriptors. We evaluate several different regression methods: ridge regression, relevance vector machine (RVM) regression, and support vector machine (SVM) regression over both linear and kernel bases. The RVMs provide much sparser regressors without compromising performance, and kernel bases give a small but worthwhile improvement in performance. The loss of depth and limb labeling information often makes the recovery of 3D pose from single silhouettes ambiguous. To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose. We show that the resulting system tracks long sequences stably. For realism and good generalization over a wide range of viewpoints, we train the regressors on images resynthesized from real human motion capture data. The method is demonstrated for several representations of full body pose, both quantitatively on independent but similar test data and qualitatively on real image sequences. Mean angular errors of 4-6/spl deg/ are obtained for a variety of walking motions.	angularjs;autostereogram;base;body part;embedded system;embedding;extraction;generalization (psychology);histogram;image segmentation;kernel (operating system);kinesiology;motion capture;nonlinear system;published comment;relevance vector machine;shape context;support vector machine;test data;biologic segmentation	Ankur Agarwal;Bill Triggs	2006	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2006.21	support vector machine;computer vision;image processing;computer science;machine learning;pattern recognition;mathematics;nonlinear regression	Vision	47.14231400663324	-56.571583745182586	88833
450a2025057104dbf91060a0dba2ef6024a90186	corner-guided image registration by using edges	similarity metric;image segmentation;edge detection;image matching;indexing terms;image registration;edges image registration corner guided;image segmentation edge detection image matching image registration;corner mapping corner guided image registration edge detection matching segment;corner guided;image registration image edge detection image segmentation extraterrestrial measurements mutual information infrared detectors resonance light scattering robustness computer vision data mining;edges	This paper proposes an image registration method. Edges are detected from images and partitioned into segments as matching primitives. Then, corners on the edges are detected to guide registration. A similarity metric is proposed based on the number of pairs of matching segments. Corner mappings are sequentially tried along a segment, from which a transformation is obtained. The corner mappings are evaluated by the similarity metric under their resulting transformation. By this means, corner mappings are established by utilizing whole images. Since the sensitivity of transformation parameters to the accuracy of corner mappings, as many corner mappings as possible are used. Experimental results show that the proposed method is robust, especially when there is no integral corresponding edges between two images.	corner case;image registration;matching (graph theory);robustness (computer science)	Yong Li;Robert L. Stevenson;Jiading Gai	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379840	corner detection;edge;computer vision;feature detection;template matching;edge detection;topology;index term;computer science;image registration;pattern recognition;mathematics;image segmentation	Robotics	42.64184048336657	-58.064219775110814	89009
8828ac679ea5ac6cbd9423f4a673e0069785f6fd	car model recognition by utilizing symmetric property to overcome severe pose variation	mirror morphing;template matching;article;car model recognition;active shape model;pose estimation	This paper presents a mirror morphing scheme to deal with the challenging pose variation problem in car model recognition. Conventionally, researchers adopt pose estimation techniques to overcome the pose problem, whereas it is difficult to obtain very accurate pose estimation. Moreover, slight deviation in pose estimation degrades the recognition performance dramatically. The mirror morphing technique utilizes the symmetric property of cars to normalize car images of any orientation into a typical view. Therefore, the pose error and center bias can be eliminated and satisfactory recognition performance can be obtained. To support mirror morphing, active shape model (ASM) is used to acquire car shape information. An effective pose and center estimation approach is also proposed to provide a good initialization for ASM. In experiments, our proposed car model recognition system can achieve very high recognition rate (>95%) with very low probability of false alarm even when it is dealing with the severe pose problem in the cases of cars with similar shape and color.	3d pose estimation;active shape model;experiment;morphing	Hui-Zhen Gu;Suh-Yin Lee	2012	Machine Vision and Applications	10.1007/s00138-012-0414-8	active shape model;computer vision;simulation;template matching;pose;3d pose estimation;computer science;articulated body pose estimation	Vision	42.961471934441505	-53.06557317302435	89032
3ceeb05f143e90b53728b00c227fc38832b1d426	computing occluding and transparent motions	motion analysis;analisis imagen;moving object;vision ordenador;occlusion;oclusion;analyse mouvement;segmentation;computer vision;image sequence;image analysis;vision ordinateur;analyse image;segmentacion	Computing the motions of several moving objects in image sequences involves simultaneous motion analysis and segmentation. This task can become complicated when image motion changes significantly between frames, as with camera vibrations. Such vibrations make tracking in longer sequences harder, as temporal motion constancy cannot be assumed. The problem becomes even more difficult in the case of transparent motions. A method is presented for detecting and tracking occluding and transparent moving objects, which uses temporal integration without assuming motion constancy. Each new frame in the sequence is compared to a dynamic internal representation image of the tracked object. The internal representation image is constructed by temporally integrating frames after registration based on the motion computation. The temporal integration maintains sharpness of the tracked object, while blurring objects that have other motions. Comparing new frames to the internal representation image causes the motion analysis algorithm to continue tracking the same object in subsequent frames, and to improve the segmentation.	algorithm;computation;sensor	Michal Irani;Benny Rousso;Shmuel Peleg	1994	International Journal of Computer Vision	10.1007/BF01420982	computer vision;structure from motion;image analysis;computer science;motion field;segmentation;computer graphics (images)	Vision	49.28539789880661	-57.04112102422925	89060
27a73ad1ed2a299b56f29f1a05eb22a736160c38	scalable reduced dimension object segmentation based on wavelet	object segmentation;reduced dimension;scalable reduced dimension object segmentation (srdos);wavelet transform;wavelets;video;image compression;wavelet transforms	Scalable reduced dimension object segmentation (SRDOS) based on wavelet is presented in this paper. SRDOS algorithm is taken advantage of the characteristic of wavelet coefficients multiresolution in the same direction, which makes SRDOS be applied to detect the video object of a reduced dimension image with much lower complexity and more sufficient accuracy. The spatial size at the lowest frequency subband is about one of (2 level ) 2 to that of the original image so that the detection complexity at the lowest frequency subband may reduce greatly. It is important that SRDOS may be a multiresolution object segmentation algorithm based on wavelet transform. So SRDOS is a fast and efficient object segmentation algorithm. The proposed algorithm has been successfully integrated with our video object based wavelet color image coding algorithm.	wavelet	Guo-Fang Tu	2003			wavelet;computer vision;speech recognition;computer science;segmentation-based object categorization;signal processing;cascade algorithm;mathematics;accuracy and precision;wavelet packet decomposition;stationary wavelet transform;image segmentation;scale-space segmentation;algorithm;wavelet transform;computer graphics (images)	Vision	52.68688805948248	-65.46816738964174	89217
9a6f60d6ca16d2af4902b0e21db3fea49b2b778a	multi-scale shaft parts image edge detection and measurement based on wavelet transform	shafts;edge detection;filtering scale;measurement system;satisfiability;multi scale;image measurement multiscale shaft parts image edge detection wavelet transform filtering scale;wavelet transforms;shafts image edge detection wavelet transforms filtering algorithms smoothing methods image color analysis image texture analysis conferences computational intelligence computer industry;smoothing methods;wavelet transform;wavelet transform multi scale shaft parts edge detection and measurement;image edge detection;pixel;edge detection and measurement;transforms;multiscale shaft parts image edge detection;image measurement;wavelet transforms edge detection filtering theory;shaft parts;filtering theory;noise	Multi-scale edge detection method was demonstrated, also detailed algorithms, flow chart were put forward, shaft partspsila image as an example in this article. The algorithms resolve two problems existing in the first generation multi-scale edge detection, the demerits were edge defined only considering its irregularity and difficult selection of filtering scale. More satisfied edge detection results can be got applying wavelet transformationspsila regularity under different scales or the same scale. To realize image measurement, system calibration is the key factor, which ascertains the detection accuracy. Detection experiments are carried out to compare between the traditional operators and proposed algorithm, real dimension lengths of the shaft parts are calculated with the calibrated coefficient.	edge detection;wavelet transform	Ji Ge;Yaonan Wang;Bowen Zhou;Hui Zhang	2008		10.1109/PACIIA.2008.69	computer vision;mathematical optimization;edge detection;computer science;pattern recognition;mathematics;wavelet transform	Vision	51.23679336144307	-65.56716698723513	89259
522096b0b64a3825bde7995ef5658f415047258d	a camera calibration technique using three sets of parallel lines	teoria imagen;contraste;focusing;vision ordenador;modele geometrique;image theory;perspective projection;camera model;theorie image;virtual line;parametre;translation parameters;parallel lines;robotics;calibration lenses digital cameras tv optical imaging optical arrays laboratories image analysis image reconstruction focusing;three dimensional camera calibration;point evanescent;methode algebrique;three dimensional;experimental result;computer vision;digital cameras;computerised picture processing computer vision;parametro;parameter;camara;optical imaging;optical arrays;rotation parameters;vanishing point;three dimensional system;image center;image reconstruction;algebraic method;lenses;resultado experimental;robotica;systeme 3 dimensions;computerised picture processing;image analysis;vision ordinateur;etalonnage;sistema 3 dimensiones;rotacion;image plane;robotique;lens;metodo algebraico;tv;camera calibration;resultat experimental;rotation;imaging distance;calibration;camera;geometrical model;modelo geometrico;camera model parallel lines three dimensional camera calibration rotation parameters translation parameters imaging distance lens image plane virtual line image center perspective projection	This paper presents a new method for three-dimensional camera calibration in which the rotation parameters are decoupled from the translation parameters. First, the rotation parameters are obtained by projecting three sets of parallel lines independently of the translation parameters and the imaging distance from the lens to the image plane. The virtual line passing through the image center, which is calculated by perspective projection of a set of parallel lines, depends only on the rotation parameters. Next, the translation parameters and the imaging distance are analytically obtained. Experimental results are used to show how the camera model can be accurately reconstructed in an easily prepared environment.	3d projection;camera resectioning;image plane	Tomio Echigo	1990	Machine Vision and Applications	10.1007/BF01214428	computer vision;camera auto-calibration;image analysis;camera resectioning;computer science;lens;mathematics;robotics;parameter;computer graphics (images)	Vision	50.84115445070175	-57.35781708867836	89359
d983dda8b03ed60fa3afafe5c50f1d9a495f260b	face recognition using elastic local reconstruction based on a single face image	reconnaissance visage;evaluation performance;base donnee;performance evaluation;image processing;elastic local reconstruction elr;biometrie;evaluacion prestacion;biometrics;database;biometria;procesamiento imagen;base dato;traitement image;similitude;algorithme;illumination variations;expression variations;algorithm;reconstruction image;automatic recognition;face recognition;reconstruccion imagen;image reconstruction;similarity;pattern recognition;reconnaissance forme;similitud;face manifold structure;reconocimiento patron;reconocimiento automatico;reconnaissance automatique;algoritmo	In this paper, we propose a new face recognition algorithm based on a single frontal-view image for each face subject, which considers the effect of the face manifold structure. To compare two near-frontal face images, each face is considered a combination of a sequence of local image blocks. Each of the image blocks of one image can be reconstructed according to the corresponding local image block of the other face image. Then an elastic local reconstruction (ELR) method is proposed to measure the similarities between the image block pairs in order to measure the difference between the two face images. Our algorithm not only benefits from the face manifold structure, in terms of being robust to various image variations, but also is computationally simple because there is no need to build the face manifold. We evaluate the performance of our proposed face recognition algorithm with the use of different databases, which are produced under various conditions, e.g. lightings, expressions, perspectives, with/without glasses and occlusions. Consistent and promising experimental results were obtained, which show that our algorithm can greatly improve the recognition rates under all the different conditions. 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	approximation algorithm;database;expression (computer science);facial recognition system;image warping;normal (geometry);pattern recognition;performance;side effect (computer science)	Xudong Xie;Kin-Man Lam	2008	Pattern Recognition	10.1016/j.patcog.2007.03.020	iterative reconstruction;computer vision;speech recognition;object-class detection;similarity;image processing;computer science;artificial intelligence;similitude;pattern recognition;biometrics	Vision	44.8407737009423	-59.37347627203097	89546
ba1f71e3ff143c707412882e100ff8e91e3c9a3b	efficient scrolling videotext detection with adaptive temporal differential approach	background information;adaptive temporal differentiation;spatial computation;video signal processing quantisation signal text detection;quantised measurements;quantised measurements videotext detection adaptive temporal differentiation scrolling text detection spatial computation temporal computation background information;temporal computation;videotext detection;scrolling text detection	This study presents an efficient algorithm for the detection of scrolling text on continuous frames. The proposed scheme adopts both spatial and temporal computation as well as pre-processing to differentiate among noise, text and background information. Scrolling text is detected using temporal differentiation among inter-frames and then the region in which the scrolling text appears is identified as a rectangle. Simulation results demonstrate that the proposed algorithm is capable of precisely differentiating scrolling text in any direction, along any of the frame boundaries without false detection or missed text. In a comparison using quantised measurements, the proposed method outperforms all competing algorithms.	scrolling;teletext	Shih-Chang Hsia;Nan-Tsai Chang-Jian	2014	IET Image Processing	10.1049/iet-ipr.2013.0448	computer vision;speech recognition;computer science;theoretical computer science	Vision	39.647114209681526	-52.82087147397503	89606
84b56d69c0b6e3889f10c76cc831ffefec93b960	increasing illumination invariance of surf feature detector through color constancy		Most of the original image feature detectors are not able to cope with large photometric variations, and their extensions that should improve detection eventually increase the computational cost and introduce more noise to the system. Here we extend the original SURF algorithm increasing its invariance to illumination changes. Our approach uses the local space average color descriptor as working space to detect invariant features. A theoretical analysis demonstrates the impact of distinct photometric variations on the response of blob-like features detected with the SURF algorithm. Experimental results demonstrate the effectiveness of the approach in several illumination conditions including the presence of two or more distinct light sources, variations in color, in offset and scale.	speeded up robust features	Marcelo Petry;António Paulo Moreira;Luís Paulo Reis	2013		10.1007/978-3-642-40669-0_23	computer vision;pattern recognition	Vision	40.82173027581437	-55.10464310201254	89613
198c7d66b5405104c8ac6d864c1769833d146709	progressive probabilistic hough transform	line detection;a priori knowledge;hough transform;real time application	In the paper we present the Progressive Probabilistic Hough Transform (PPHT). Unlike the Probabilistic Hough Transform [4] where Standard Hough Transform is performed on a pre-selected fraction of input points, PPHT minimises the amount of computation needed to detect lines by exploiting the difference in the fraction of votes needed to reliably detect lines with different numbers of supporting points . The fraction of points used for voting need not be specifiedad hocor using a priori knowledge, as in the Probabilistic Hough Transform; it is a function of the inherent complexity of data. The algorithm is ideally suited for real-time applications with a fixed amount of available processing time, since voting and line detection is interleaved. The most salient features are likely to be detected first. Experiments show PPHT has, in many circumstances, advantages over the Standard Hough Transform.	accumulator (computing);algorithm;clutter;computation;edge detection;experiment;gradient descent;hough transform;pixel;real-time clock;real-time computing;video post-processing	Jiri Matas;Charles Galambos;Josef Kittler	1998		10.5244/C.12.26	hough transform;computer vision;a priori and a posteriori;speech recognition;computer science;machine learning;scale-invariant feature transform;mathematics	Vision	45.88756613655181	-54.68994104355362	89839
88d0c14e080a7ab89ebe5a5ef857e8a404dca96d	simultaneous registration of multiple range views for use in reverse engineering of cad models	modelizacion;image tridimensionnelle;concepcion asistida;computer aided design;optimisation;vision ordenador;estimation mouvement;algorithm performance;image processing;optimizacion;etude experimentale;estimacion movimiento;procesamiento imagen;reference frame;motion estimation;traitement image;computer vision;algorithme;modelisation;algorithm;resultado algoritmo;performance algorithme;conception assistee;tridimensional image;global optimization;vision ordinateur;optimization;iterative closest point algorithm;modeling;estudio experimental;imagen tridimensional;reverse engineering;algoritmo	When reverse engineering a CAD model, it is necessary to integrate information from several views of an object into a common reference frame. Given a rough initial alignment of local 3-D shape data in several images, further refinement is achieved using an improved version of the recently popular Iterative Closest Point algorithm. Improved data correspondence is determined by considering the merging data sets as a whole. A potentially incorrect distance threshold for removing outlier correspondences is not needed as in previous efforts. Incremental pose adjustments are computed simultaneously for all data sets, resulting in a more globally optimal set of transformations. Individual motion updates are computed using force-based optimization, by considering the data sets as implicitly connected by groups of springs. Experiments on both 2-D and 3-D data sets show that convergence is possible even for very rough initial positionings, and that the final registration accuracy typically approaches less than one quarter of the interpoint sampling resolution of the images. c © 1998 Academic Press	algorithm;computer-aided design;experiment;iterative closest point;iterative method;mathematical optimization;maxima and minima;reference frame (video);refinement (computing);reverse engineering;sampling (signal processing)	David W. Eggert;Andrew W. Fitzgibbon;Robert B. Fisher	1998	Computer Vision and Image Understanding	10.1006/cviu.1998.0667	reference frame;computer vision;systems modeling;image processing;computer science;artificial intelligence;motion estimation;mathematics;algorithm;reverse engineering;global optimization	Vision	50.39481085628456	-56.15533209810618	89981
13bd80113d79991faece245f974988953f11e3c1	ipsilon: incremental parsing for semantic indexing of latent concepts	busqueda informacion;escena natural;multidimensional incremental parsing algorithm;lempel ziv;traitement signal;query by semantic example;evaluation performance;image distortion robustness ipsilon semantic indexing parsing content based image retrieval source characterization property universal source coding scheme multidimensional incremental parsing algorithm lempel ziv incremental parsing code linguistic processing technique latent semantic analysis intelligent visual information analysis lsa paradigm vector quantization image segmentation image matching query by semantic example query by visual example;indexing image retrieval information analysis vector quantization testing content based retrieval source coding multidimensional systems image coding information retrieval;semantic indexing;image coding;lempel ziv incremental parsing code;image segmentation;performance evaluation;image processing;data compression;recherche image;query by visual example;information retrieval;information visuelle;image matching;implementation;evaluacion prestacion;source characterization property;universal coding;codage source;procesamiento imagen;pregunta documental;algorithme de lempel ziv;incremental parsing;image distortion robustness;testing;algoritmo de lempel ziv;intelligent visual information analysis;traitement image;vector quantisation image matching image representation image retrieval image segmentation indexing source coding;linguistic processing technique;universal source coding scheme;informacion visual;analyse syntaxique;cuantificacion vectorial;natural scene;vector quantization;indexing;analisis sintaxico;recherche information;busqueda por contenido;visual information;image representation;feature extraction;syntactic analysis;signal processing;codage universel;robustesse;indexation;lsa paradigm;segmentation image;codificacion universal;indizacion;scene naturelle;query;robustness;analyse information;source code;vector quantizer;compresion dato	A new framework for content-based image retrieval, which takes advantage of the source characterization property of a universal source coding scheme, is investigated. Based upon a new class of multidimensional incremental parsing algorithm, extended from the Lempel-Ziv incremental parsing code, the proposed method captures the occurrence pattern of visual elements from a given image. A linguistic processing technique, namely the latent semantic analysis (LSA) method, is then employed to identify associative ensembles of visual elements, which lay the foundation for intelligent visual information analysis. In 2-D applications, incremental parsing decomposes an image into elementary patches that are different from the conventional fixed square-block type patches. When used in compressive representations, it is amenable in schemes that do not rely on average distortion criteria, a methodology that is a departure from the conventional vector quantization. We call this methodology a parsed representation. In this article, we present our implementations of an image retrieval system, called IPSILON, with parsed representations induced by different perceptual distortion thresholds. We evaluate the effectiveness of the use of the parsed representations by comparing their performance with that of four image retrieval systems, one using the conventional vector quantization for visual information analysis under the same LSA paradigm, another using a method called SIMPLIcity which is based upon an image segmentation and integrated region matching, and the other two based upon query-by-semantic-example and query-by-visual-example. The first two of them were tested with 20 000 images of natural scenes, and the others were tested with a portion of the images. The experimental results show that the proposed parsed representation efficiently captures the salient features in visual images and the IPSILON systems outperform other systems in terms of retrieval precision and distortion robustness.	algorithm;auditory perceptual disorders;benchmark (computing);body dysmorphic disorders;body of uterus;calculus of variations;color;computational complexity theory;content-based image retrieval;data compression;data dictionary;dictionaries as topic;dictionary [publication type];distortion;embedded system;embedding;genetic heterogeneity;image segmentation;increment;indexes;keyword;latent semantic analysis;lempel–ziv–stac;lempel–ziv–welch;lexicon;lichen sclerosus et atrophicus;linguistics;norm (social);numerical analysis;organizing (structure);parsing expression grammar;pattern matching;performance evaluation;pixel;programming paradigm;query by example;question (inquiry);segmentation action;text corpus;vector quantization	Soo Hyun Bae;Biing-Hwang Juang	2010	IEEE Transactions on Image Processing	10.1109/TIP.2010.2045019	computer vision;image processing;image retrieval;computer science;theoretical computer science;signal processing;pattern recognition;information retrieval;source code	Vision	42.50820255563146	-61.58466926283671	90154
e61a17bf8ea7ccd5732a58e7bfb1142437c2504b	practical background estimation for mosaic blending with patch-based markov random fields	analisis imagen;moving object;mosaicism;image processing;modelo markov;mosaicisme;coupe graphe;zoom;procesamiento imagen;mosaic;arriere plan;blending;probabilistic approach;blanco movil;estimation algorithm;traitement image;markov random field;algorithme;algorithm;corte grafo;background;markov model;campo aleatorio;foreground;enfoque probabilista;approche probabiliste;graph cut;pattern recognition;avant plan;cible mobile;image analysis;mosaicismo;reconnaissance forme;modele markov;reconocimiento patron;analyse image;moving target;champ aleatoire;algoritmo;random field	In this paper, we present a new background estimation algorithm which effectively represents both background and foreground. The problem is formulated with a labeling problem over a patch-based Markov random field (MRF) and solved with a graph-cuts algorithm. Our method is applied to the problem of mosaic blending considering the moving objects and exposure variations of rotating and zooming camera. Also, to reduce seams in the estimated boundaries, we propose a simple exposure correction algorithm using intensities near the estimated boundaries. 2008 Published by Elsevier Ltd.	algorithm;alpha compositing;cut (graph theory);markov chain;markov random field;patch (computing);sequence labeling	Dae Woong Kim;Ki-Sang Hong	2008	Pattern Recognition	10.1016/j.patcog.2008.01.015	computer vision;mosaic;random field;image analysis;simulation;cut;image processing;computer science;foreground-background;markov model;zoom;statistics	Vision	48.915348904102665	-58.487642056695954	90165
1a30cda00137bdc6d5cf38eb0d773d7624d1ddc8	gray-level grouping (glg): an automatic method for optimized image contrast enhancement-part i: the basic method	background noise;histogram components;contrast enhancement;traitement signal;evaluation performance;contrast enhanced;gray level grouping;image segmentation;performance evaluation;image processing;accentuation image;automatic contrast enhancement technique;grayscale segments;evaluacion prestacion;noise reduction contrast enhancement gray level grouping histogram;metodo imagen;procesamiento imagen;color images gray level grouping automatic contrast enhancement technique optimized image contrast enhancement low contrast images histogram components selective glg background noise elimination;imagen nivel gris;low contrast images;indexing terms;qualite image;image bruitee;traitement image;gray scale;reduccion ruido;image contrast;algorithme;imagen sonora;algorithm;optimization methods histograms background noise image segmentation gray scale noise level x ray imaging color noise reduction us department of energy;histogram;image enhancement;algorithms artificial intelligence colorimetry computer simulation image enhancement image interpretation computer assisted information storage and retrieval models statistical pattern recognition automated quality control;histogramme;color images;background noise elimination;image color analysis;contraste image;image colour analysis;signal processing;noise reduction;quality measure contrast enhancement gray level grouping histogram;noisy image;image quality;image niveau gris;image method;segmentation image;reduction bruit;optimized image contrast enhancement;controle qualite;ruido fondo;calidad imagen;image denoising;selective glg;quality measures;image colour analysis image enhancement image denoising image segmentation;quality measure;selective gray level grouping;quality control;bruit fond;imagen color;optimization methods histograms gray scale background noise image processing image segmentation color piecewise linear techniques us department of energy;histograma;methode image;echelle gris;imagen contraste;procesamiento senal	Contrast enhancement has an important role in image processing applications. Conventional contrast enhancement techniques either often fail to produce satisfactory results for a broad variety of low-contrast images, or cannot be automatically applied to different images, because their parameters must be specified manually to produce a satisfactory result for a given image. This paper describes a new automatic method for contrast enhancement. The basic procedure is to first group the histogram components of a low-contrast image into a proper number of bins according to a selected criterion, then redistribute these bins uniformly over the grayscale, and finally ungroup the previously grouped gray-levels. Accordingly, this new technique is named gray-level grouping (GLG). GLG not only produces results superior to conventional contrast enhancement techniques, but is also fully automatic in most circumstances, and is applicable to a broad variety of images. An extension of GLG, selective GLG (SGLG), and its variations will be discussed in Part II of this paper. SGLG selectively groups and ungroups histogram components to achieve specific application purposes, such as eliminating background noise, enhancing a specific segment of the histogram, and so on. The extension of GLG to color images will also be discussed in Part II.	akaike information criterion;algorithm;benchmark (computing);grayscale color map;histogram;image processing;image quality;name;personal computers;personal computer;preprocessor;selective repeat arq	ZhiYu Chen;Besma Roui-Abidi;David L. Page;Mongi A. Abidi	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.875204	image quality;computer vision;quality control;index term;color image;image processing;computer science;signal processing;noise reduction;histogram;background noise;image segmentation;grayscale;image histogram;computer graphics (images)	Vision	46.31669055755566	-64.33022926720666	90235
3953642f3791f6311d1fb42fcc96acbcb1a97db1	object detection and localization in clutter range images using edge features	model generation;multiple objectives;range image;scale invariance;object detection	We present an object detection technique that uses local edgels and their geometry to locate multiple objects in a range image in the presence of partial occlusion, background clutter, and depth changes. The fragmented local edgels (key-edgels) are efficiently extracted from a 3D edge map by separating them at their corner points. Each key-edgel is described using our scale invariant descriptor that encodes local geometric configuration by joining the edgel at their start and end points adjacent edgels. Using key-edgels and their descriptors, our model generates promising hypothetical locations in the image. These hypotheses are then verified using more discriminative features. The approach is evaluated on ten diverse object categories in a real-world environment.	clutter;object detection	Dipankar Das;Yoshinori Kobayashi;Yoshinori Kuno	2009		10.1007/978-3-642-10520-3_16	computer vision;scale invariance;pattern recognition;mathematics;geometry;statistics	Robotics	42.39976099337961	-55.071294445348634	90540
0ae1e56f63e1600cc90a5ba7555d1447037c6a82	multi-view face image synthesis using factorization model	reconnaissance visage;interfase usuario;global solution;base donnee;human computer interaction;realite virtuelle;realidad virtual;facies;user interface;database;virtual reality;image multiple;base dato;hombre;optimum global;non linear model;imagen multiple;modele non lineaire;global optimum;multiple image;sintesis imagen;image synthesis;metodo factorizacion;modelo no lineal;face recognition;factor model;realite terrain;factorization method;human;pattern recognition;synthese image;realidad terreno;interface utilisateur;ground truth;solution globale;reconnaissance forme;reconocimiento patron;methode factorisation;optimo global;solucion global;homme	We present a sample-based method for synthesizing face images in a wide range of view. Here the human identity and head pose are regarded as two influence factors of face appearance and a factorization model is used to learn their interaction with a face database. Our method extends original bilinear factorization model to nonlinear case so that global optimum solution can be found in solving translation task. Thus, some view of a new person's face image is able to be translated into other views. Experimental results show that the synthesized faces are quite similar to the ground-truth. The proposed method can be applied to a broad area of human computer interaction, such as face recognition across view or face synthesis in virtual reality.		Yangzhou Du;Xueyin Lin	2004		10.1007/978-3-540-24837-8_19	simulation;facies;ground truth;computer science;artificial intelligence;database;virtual reality;global optimum;factor analysis;user interface	Vision	46.00188499413466	-56.97962749967279	90737
c112c28d0a19461fe86d0f251a77ff1a91485860	a robust 3d shape descriptor based on the electrical charge distribution		Defining a robust shape descriptor is an enormous challenge in the 3D model retrieval domain. Therefore, great deals of research have been conducted to propose new shape descriptors which meet the retrieving criteria. This paper proposes a new shape descriptor based on the distribution of electrical charge which holds valuable characteristics such as insensitivity to translation, sale and rotation, robustness to noise as well as simplification operation. After extracting the canonical form representation of the models, they are treated as surfaces placed in a free space and charge Q is distributed over them. Following to calculating the amount of charge on each face of the model, a set of concentric spheres enclose the model and the total amount of distributed charge between the adjacent spheres on the model’s surface generates the Charge Distribution Descriptor (CDD). A beneficial two-phase description using the number of Charged-Dense Patches for each model is utilized to boost the discrimination power of the system. The strength of our approach is verified using experiments on the McGill dataset. The results demonstrate higher ability of our system compared to other well-known approaches.	3d modeling;cdd;dolphin;emoticon;experiment;linear discriminant analysis;shape analysis (digital geometry);shape context;text simplification;two-phase commit protocol	Fattah Alizadeh;Alistair Sutherland	2013			artificial intelligence;electric charge;computer vision;computer science	Vision	39.82145766871719	-57.71234006013175	90741
34c13dff01cd24914ac9d6e8c1ce15fd7eaa49e0	multivariate mathematical morphology based on fuzzy extremum estimation	marginal components;fuzzy extremum estimation algorithm;multivariate ordering;multivariate mathematical morphological operators;mathematical morphology fuzzy set theory image colour analysis image representation;multivariate image filtering;colour image representations;fuzzy lexicographical ordering approach;期刊论文;fuzzy extremum estimation;total ordering property;quaternion decomposition;feea;fuzzy extremum estimation multivariate image filtering multivariate mathematical morphological operators feea fuzzy extremum estimation algorithm fuzzy lexicographical ordering approach quaternion decomposition colour image representations marginal components multivariate ordering total ordering property	The existing lexicographical ordering approaches respect the total ordering properties, thus making this approach a very robust solution for multivariate ordering. However, different marginal components derived from various representations of a colour image will lead to different results of multivariate ordering. Moreover, the output of lexicographical ordering only depends on the first component leading to the followed components taking no effect. To address these issues, three new marginal components are obtained by means of quaternion decomposition, and they are employed by fuzzy lexicographical ordering, and thus a new fuzzy extremum estimation algorithm (FEEA) based on quaternion decomposition is proposed in this study. The novel multivariate mathematical morphological operators are also defined according to FEEA. Comparing with the existing solutions, experimental results show that the proposed FEEA performs better results on multivariate extremum estimation, and the presented multivariate mathematical operators can be easily handled and can provide better results on multivariate image filtering.	mathematical morphology;maxima and minima	Tao Lei;Yi Wang;Guohua Wang;Yangyu Fan	2014	IET Image Processing	10.1049/iet-ipr.2013.0510	mathematical optimization;combinatorics;discrete mathematics;mathematics	Vision	51.756331472175084	-65.08562051052724	90862
59f4aefc6ce28998c3dc1d5b1a473b95f76c7e8c	gaussian pyramid wavelet transform for multiresolution analysis of images	transformation ondelette;moving image;two dimensional shape;forme bidimensionnelle;analisis bidimensional;formation image tridimensionnelle;image coding;image processing;progressive image transmission;3d imaging;senal gaussiana;procesamiento imagen;analyse multiresolution;imagen movil;traitement image;image mobile;forma bidimensional;analyse bidimensionnelle;wavelet transform;decomposition algorithm;gaussian signal;two dimensional analysis;signal gaussien;transformacion ondita;formacion imagen tridimensional;multiresolution analysis;perfect reconstruction;data structure;wavelet transformation;analisis multiresolucion	Multiresolution analysis of images using pyramid data structures has become as an important tool in many areas of image processing. In this work we introduce a Gaussian pyramid wavelet transform for multiresolution analysis of images. We show that with a slight modification of the original Gaussian pyramid a decomposition algorithm is yielded, which has Gaussian pyramid reduce and expand operations with a perfect reconstruction property. The method can be applied to multiresolution representation of 2D and 3D images and moving 2D objects for, e.g., image coding and compression, progressive image transmission, and interpolation.	gaussian blur;multiresolution analysis;wavelet transform	Hannu Olkkonen;Peitsa Pesola	1996	CVGIP: Graphical Model and Image Processing	10.1006/gmip.1996.0032	multiresolution analysis;stereoscopy;computer vision;pyramid;contourlet;data structure;image processing;computer science;mathematics;geometry;algorithm;wavelet transform;computer graphics (images)	Vision	51.41334517614506	-62.41256123417315	91013
25f2fcba5d8bdc7533def739ba17a073f0aad3be	estimation of feret's diameter from pixel coverage representation of a shape	computer vision and robotics autonomous systems;coverage representation;datorseende och robotik autonoma system;shape analysis;accuracy and precision;computerized image processing;datoriserad bildbehandling;feret s diameter	We propose a method for Feret's diameter estimation from digital images.We derive a correction term for improving accuracy of the coverage based estimator.We give the upper bound of the absolute error for the proposed method.We evaluate the proposed method on synthetic and real images.The proposed method provides significant improvement over existing methods. Feret's diameter of a shape is a commonly used measure in shape analysis. Traditional methods for estimation of Feret's diameter are performed on binary images and are of poor precision and accuracy. We analyze and further develop a method for estimation of Feret's diameter that utilizes pixel coverage. We improve the accuracy of the method by proposing a correction term. We provide an expression for the upper bound of the absolute error of the estimation. We evaluate the improved method and compare with existing methods for Feret's diameter estimation, based on both binary and coverage representations of image objects. Tests confirm increased precision and accuracy of the new method, on synthetic as well as on real images.	pixel	Slobodan Drazic;Natasa Sladoje;Joakim Lindblad	2016	Pattern Recognition Letters	10.1016/j.patrec.2016.04.021	computer vision;computer science;data mining;shape analysis;mathematics;accuracy and precision;statistics	Vision	42.752406689442545	-58.24353571240877	91050
215405afa06015e1d1f5743bf1a170287886dfa8	compensation of partly photographed page-images using 3-d shape information	3d coordinate partly photographed page image compensation 3d shape information page image contortion compensation book page surface geometrical adjustment image resolution stereo method;shape books image resolution costs character recognition digital cameras computer performance magnetic recording software libraries optical character recognition software;image resolution;stereo image processing image resolution;stereo image processing	We propose a method in order to compensate contortion of page-image which is caused by photographing a book opened and placed face-up (two pages opposite each other state) on the stage just above. For compensating contortion 3-D shape information of the page surface is necessary to apply some geometrical adjustment. To obtain much higher resolution image a page needs to be photographed partly, in this situation each neighboring image necessarily has overlap area for the purpose of joining together. We put characters existing in an overlap area to good use for seeking of corresponding points in the stereo method by which 3-D shape information (3-D coordinate of corresponding points) of book surface can be obtained. If the assumption that no change of the shape of page cross section along the binding are satisfied, satisfactory compensated images were obtained and joining them together was well performed.		Toshifumi Nakajima;Masaaki Kashimura;Shinji Ozawa	1999		10.1109/ICASSP.1999.757586	computer vision;image resolution;computer science;multimedia;computer graphics (images)	Vision	52.86624553344289	-54.81926336435187	91108
36fd858b848dd8f2fbd48bbc1f16103c4769eec2	relationships-based recognition of structural industrial parts stacked in a bin		This paper describes an algorithm which recognizes the position and the orientation of a structural industrial part, such as a crankshaft, utilizing the relationships between its elementary blobs. Crankshafts are arranged tightly and piled up in multiple layers and their image from above includes regions (i.e. pictures) of crankshafts not only of the current top layer but also of the lower ones; it thus becomes complicated. First, the algorithm carries out the connectivity analysis for an input binary image, and then extracts elementary blobs by applying a line fitting procedure on every sequence of boundary pixels of connected regions. Next, each blob is judged to determine to which component of a part it corresponds, using the size model. Then the relationships (distances and orientations) between blobs are examined, using their relational models, and a group of blobs of one part is recognized. Its position and orientation are calculated simultaneously. This model matching algorithm is implicitly included in the procedures.	algorithm;binary image;line fitting;pixel;pose (computer vision)	Youji Fukada;Hiroshi Doi;Keiji Nagemine;Takahiko Inari	1984	Robotica	10.1017/S0263574700000849	control theory;binary image;bin;pixel;engineering;blossom algorithm;line fitting;algorithm;crankshaft	Robotics	45.760699334976806	-55.87661353659129	91220
4920bb4a81385c910fa59831ae4847608da35a5b	a multi-attribute shot segmentation algorithm for video programs	detection algorithm	This paper describes a new algorithm for detecting cuts, thereby segmenting a video into shots. Our Web?based video library contains a large volume of news and documentary material; most of the transitions between shots in that type of programming are cuts, rather than dissolves or other complex transitions. We have developed an accurate multi?attribute algorithm for detecting cuts in video programs. The algorithm uses a motion metric to identify a set of cuts, then uses luminance histograms to eliminate false cuts. Our experimental results show that this algorithm is more accurate than previous motion?based transition detection algorithms.	algorithm	Michael Philips;Wayne H. Wolf	1998	Telecommunication Systems	10.1023/A:1019164327291	computer vision;computer science;theoretical computer science;machine learning	Robotics	39.728364216034	-52.66586940441577	91231
0cd23b85ccb27d07770c87e84418fd09ce82ebd9	rectified surface mosaics	alignement;optimisation;movilidad;pistage;endoscopia;aplicacion medical;image processing;optimizacion;mobility;gauchissement;etat surface;endoscopy;rastreo;procesamiento imagen;mobilite;computer imaging vision pattern recognition and graphics;traitement image;surface conditions;surface geometry;registro imagen;camera motion;posture;recalage image;video cameras;estado superficie;image registration;postura;torcimiento;alineamiento;camera video;artificial intelligence incl robotics;pattern recognition;image processing and computer vision;global optimization;optimization;medical application;endoscopie;computer science;image registration and mosaicing;camara de video;alignment;warping;tracking;application medicale;pose estimation	We approach mosaicing as a camera tracking problem within a known parameterized surface. From a video of a camera moving within a surface, we compute a mosaic representing the texture of that surface, flattened onto a planar image. Our approach works by defining a warp between images as a function of surface geometry and camera pose. Globally optimizing this warp to maximize alignment across all frames determines the camera trajectory, and the corresponding flattened mosaic image. In contrast to previous mosaicing methods which assume planar or distant scenes, or controlled camera motion, our approach enables mosaicing in cases where the camera moves unpredictably through proximal surfaces, such as in medical endoscopy applications.	apache axis;cylinder seal;distortion;emoticon;ibm notes;image rectification;lucas–kanade method;match moving;mathematical optimization;quadratic function;eric	Robert E. Carroll;Steven M. Seitz	2007	2007 IEEE 11th International Conference on Computer Vision	10.1007/s11263-009-0264-7	image warping;computer vision;camera auto-calibration;camera resectioning;simulation;pose;image processing;computer science;image registration;tracking;pinhole camera model;global optimization;computer graphics (images)	Vision	50.69775039742866	-56.44594394580631	91257
e0d823763fa05573f983290b36d42515aa198fdd	intrinsic parameter calibration procedure for a (high-distortion) fish-eye lens camera with distortion model and accuracy estimation	intrinsic camera parameter;lens distortion;contraste;optimisation;vision ordenador;optimizacion;point location;geometry;geometrie;image;movie camera;correction;computer vision;corrections;distortion;camara;imagen;distorsion;pattern recognition;correccion;vision ordinateur;etalonnage;optimization;geometria;camera calibration;calibration;fish eye lens;camera;coordinate system	-This paper presents a calibration procedure for a fish-eye lens (a high-distortion lens) mounted on a CCD TV camera. The method is designed to account for the differences in images acquired via a distortion-free lens camera setup and the images obtained by a fish-eye lens camera. The calibration procedure essentially defines a mapping between points in the world coordinate system and their corresponding point locations in the image plane. This step is important for applications in computer vision which involve quantitative measurements. The objective of this mapping is to estimate the internal parameters of the camera, including the effective focal length, one-pixel width on the image plane, image distortion center, and distortion coefficients. The number of parameters to be calibrated is reduced by using a calibration pattern with equally spaced dots and assuming a pin-hole model camera behavior for the image center, thus assuming negligible distortion at the image distortion center. Our method employs a non-finear transformation between points in the world coordinate system and their corresponding location on the image plane. A Lagrangian minimization method is used to determine the coefficients of the transformation. The validity and effectiveness of our calibration and distortion correction procedure are confirmed by application of this procedure on real images. Copyright © 1996 Pattern Recognition Society. Published by Elsevier Science Ltd. Camera calibration Lens distortion Intrinsic camera parameters Fish-eye lens Optimization	augmented lagrangian method;camera resectioning;charge-coupled device;coefficient;computer vision;distortion;focal (programming language);image plane;lagrange multiplier;pattern recognition;pixel;program optimization	Shishir Shah;Jake K. Aggarwal	1996	Pattern Recognition	10.1016/0031-3203(96)00038-6	computer vision;camera auto-calibration;camera resectioning;distortion;computer science;mathematics;geometry;pinhole camera model;computer graphics (images)	Vision	50.935903037052064	-57.229401130980506	91306
364bf8d3a9652e79c67e6bc908d72fafb46c1957	shape characterization via boundary distortion		In this paper, we derive new shape descriptors based on a directional characterization. The main idea is to study the behavior of the shape neighborhood under family of transformations. We obtain a description invariant with respect to rotation, reflection, translation and scaling. A well-defined metric is then proposed on the associated feature space. We show the continuity of this metric. Some results on shape retrieval are provided on two databases to show the accuracy of the proposed shape metric.	algorithm;database;distortion;feature vector;image scaling;relevance;scott continuity;shape analysis (digital geometry);statistical classification	Xavier Descombes;Sergey A. Komech	2013	CoRR		active shape model;image retrieval;computer vision;distortion;scaling;computer science;invariant (mathematics);artificial intelligence	Vision	41.001471763740206	-58.67197335630239	91578
d5c8e6b40526aa06bc99066070dc46c78e74dcde	gait recognition using view distance vectors	analisis imagen;image features;correlacion;time varying;analisis componente principal;base donnee;euclidean theory;walking;caminata;legged locomotion;securite;classification supervisee;biometrie;locomotion avec jambes;reconocimiento;gait;supervised classification;biometrics;database;biometria;base dato;marcha;gait recognition;intelligence artificielle;time varying system;jeu 2 personnes;posture;recognition;marche a pied;juego 2 personas;principal component analysis;systeme parametre variable;safety;two person game;postura;theorie euclidienne;pattern classification;analyse composante principale;clasificacion supervisada;human identification;artificial intelligence;image analysis;inteligencia artificial;sistema parametro variable;correlation;reconnaissance;seguridad;allure;analyse image;teoria euclidiana;classification forme	This paper presents a new approach for human identification at a distance using gait recognition. Binarized silhouette of a motion object is represented by 1-D signals which are the basic image features called the distance vectors. The distance vectors are differences between the bounding box and silhouette, and extracted using four view directions to silhouette. Based on normalized correlation on the distance vectors, gait cycle estimation is first performed to extract the gait cycle. Second, eigenspace transformation based on PCA is applied to time-varying distance vectors and then Mahalanobis and normalized Euclidean distances based supervised pattern classification is finally performed in the lower-dimensional eigenspace for human identification. Experimental results on two main database demonstrate that the right person in top two matches 100% of the times for the cases where training and testing sets corresponds to the walking styles for data set of 25 people, and other data set of 22 people.	database;gait analysis;hamming distance;minimum bounding box;the times	Murat Ekinci;Eyüp Gedikli	2005		10.1007/11596448_144	computer vision;image analysis;computer science;artificial intelligence;mahalanobis distance;gait;correlation;feature;biometrics;principal component analysis	Vision	45.65424019333876	-58.77470462792501	91652
9f5bb2ea64e01eba03a2dd98d12574b940552638	gender identification on the teeth based on principal component analysis representation	dentistry;analisis componente principal;estimation mouvement;hospital;sex;aplicacion medical;image processing;cuerpo deformable;biometrie;data collection;estimacion movimiento;biometrics;biometria;procesamiento imagen;sexe;motion estimation;odontologia;automatic evaluation;classification;geometric feature;traitement image;identificacion sistema;hopital;vecino mas cercano;system identification;principal component analysis;forth;deformable body;dentisterie;nearest neighbor;analyse composante principale;corps deformable;plus proche voisin;nearest neighbour;medical application;sexo;clasificacion;identification systeme;application medicale;principal component	We present a new approach method for gender identification on the teeth based on PCA (principal component analysis) representation using geometric features of teeth such as the size and shape of the jaws, size of the teeth and teeth structure. In this paper we try to set forth the foundations of a biometric system for automatic evaluation of gender identification using dental geometric features. To create a gender identification system, a template based on PCA is created from dental data collected the plaster figures of teeth which were done at dental hospital, department of oral medicine. Templates of dental images based on PCA representation include the 18 principal components as the features for gender identification. The PCA basis vectors reflects well the features for gender identification in the whole of teeth. The classification for gender identification is generated based on the nearest neighbor (NN) algorithm. The gender identification performance in dental images of 50 person was 76%. The identified values in females and males were 79.3% and 71.4%, respectively	principal component analysis	Young-suk Shin	2006		10.1007/11789239_31	computer vision;speech recognition;image processing;computer science;artificial intelligence;machine learning;principal component analysis	Vision	44.947599294879076	-59.414157761544864	91717
dd7faa9ebacb64bcf4210c3be76202c592e3d637	comparison of visible, thermal infra-red and range images for face recognition	infra red;face recognition;range image;human identification	Existing literature compares various biometric modalities of the face for human identification. The common criterion used for comparison is the recognition rate of different face modalities using the same recognition algorithms. Such comparisons are not completely unbiased as the same recognition algorithm or features may not be suitable for every modality of the face. Moreover, an important aspect which is overlooked in these comparisons is the amount of variation present in each modality which will ultimately effect the database size each modality can handle. This paper presents such a comparison between the most common biometric modalities of the face namely visible, thermal infrared and range images. Experiments are performed on the Equinox and the FRGC databases with results indicating that visible images capture more interpersonal variations of the human face compared to thermal IR and range images. We conclude that under controlled conditions, visible face images have a greater potential of accommodating large databases compared to long-wave IR and range images.	algorithm;biometrics;database;equinox;experiment;facial recognition system;image;modality (human–computer interaction);photometric stereo;range imaging;shading	Ajmal S. Mian	2009		10.1007/978-3-540-92957-4_70	facial recognition system;computer vision;speech recognition;infrared;computer science;three-dimensional face recognition	Vision	44.04591981861651	-56.95444216488595	91877
26240e1add470d011c8758f751eec8099041b21c	fuzzy histograms for efficient visual content representation: application to content-based image retrieval	histograms;application software;histograms image retrieval content based retrieval data mining application software humans shape information retrieval indexing noise reduction;information retrieval;image database;data mining;shape;indexing;noise reduction;humans;content based image retrieval;content based retrieval;image retrieval	The efficiency of a content-based image retrieval (CBIR) system depends on the efficiency of the image visual content representation Usually, the extracted descriptors are organized in a binary framework, which, apart from the fact that it is sensitive to noise, it cannot also provide a physical interpretation of the image content. This problem is faced in this paper by introducing fuzzy histograms In particular, in the proposed scheme each image descriptor is allowed to belong to s everal (or all) classes but with a different degree of membership. Such a scheme removes possible noise existing in the extracted descriptors and simultaneously provides a physical interpretation of the image visual content. Experimental results are also presented, which explain the theoretical developments and illustrate the good performance of the proposed scheme to real-life image databases.	content-based image retrieval;database;real life;visual descriptor	Anastasios D. Doulamis;Nikolaos D. Doulamis	2001	IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.	10.1109/ICME.2001.1237866	image texture;computer vision;search engine indexing;application software;visual word;image retrieval;shape;computer science;noise reduction;data mining;histogram;automatic image annotation;information retrieval;statistics	Vision	39.20923631284577	-60.94302116749869	91958
51b978608c67ab815730a4edd31dd52bb3280514	a new interactive segmentation scheme based on fuzzy affinity and live-wire	medical imagery;fiabilidad;reliability;image segmentation;proceso difusion;image processing;algoritmo borroso;logique floue;processus diffusion;procesamiento imagen;diffusion anisotrope;tomographie numerique;logica difusa;anisotropic diffusion;traitement image;fuzzy logic;mr imaging;difusion anisotropica;filter;scheme based on fuzzy affnity;fiabilite;fuzzy algorithm;segmentation image;computerized tomography;imagineria medica;imagerie medicale;algorithme flou;filtre;diffusion process;anisotropic scattering;medical image segmentation;region growing;filtro;interactive segmentation	In this paper we report the combination of the Live-Wire method with the region growing algorithm based on fuzzy affinity. First, we employed anisotropic diffusion filter to process the images which smoothed the images while keeping the edge, and then we confined the possible boundary in applying the Live-Wire method to the over-segmentation found by the region growing algorithm. The speed and the reliability of the segmentation of the Live-Wire method are greatly improved by such combination. This method has been used for CT and MR image segmentation. The results confirmed that our method is practical and accurate in the medical image segmentation.	processor affinity	Huiguang He;Jie Tian;Yao Lin;Ke Lu	2005		10.1007/11539506_56	fuzzy logic;computer vision;image processing;filter;computer science;artificial intelligence;diffusion process;machine learning;segmentation-based object categorization;reliability;mathematics;region growing;image segmentation;scale-space segmentation;anisotropic diffusion	NLP	46.77261847286741	-64.4945892840765	91965
cd274063de8c041ed15f935ed97a96db96bfb426	detection of soldering defects in printed circuit boards with hierarchical marked point processes	qa75 electronic computers computer science szamitastechnika;szamitogeptudomany;pcb;prior knowledge;parent child relationship;probabilistic approach;marked point process;global optimization;printed circuit board;scooping	In this paper we introduce a probabilistic approach for optical quality checking of Solder Pastes (SP) in Printed Circuit Boards (PCB). Dealing with unregistered image inputs, our task is to address at the same time SP identification, and detection of special soldering errors, called scooping. For this reason we introduce a novel Hierarchical Marked Point Process (HMPP) framework, which is able to handle the paste and scooping extraction problems simultaneously, so that the SPs and included scoops have a parent-child relationship. A global optimization process attempts to find the optimal configuration of entities, considering the observed data, prior knowledge, and interactions between the neighboring circuit elements. The proposed method is evaluated on a real PCB image set containing more than 3000 SPs and 600 scooping artifacts. A morphology-based baseline method is also introduced for the problem and used as reference for qualitative and quantitative comparison against the proposed model.		Csaba Benedek	2011	Pattern Recognition Letters	10.1016/j.patrec.2011.06.006	computer science;printed circuit board;global optimization	ML	46.50228867652434	-53.65436854745776	92022
69888565e3334c9341fa524915cb1a0f65123401	traffic flow matching with clique and triplet cues	pattern matching cost function correlation topology image color analysis layout;topology;cost function;cost function optimization problem traffic flow pattern matching clique cue triplet cue matching cost function optimal flow pattern matching traffic flow distributions random walk based graph matching method;layout;traffic engineering computing image matching optimisation;image color analysis;pattern matching;correlation	This paper addresses a new problem of matching traffic-flow patterns from different scenes. We firstly introduce cliques to measure the topology similarity between traffic flow patterns. Based on the clique information, a matching cost function is formulated to find the optimal flow-pattern matching. In order to avoid wrong matches due to large variations in traffic flow distributions, we further introduce triplets to measure the flow-wise correlation in a scene and include them into the matching cost function. Thus, constraints of traffic flows' relative position can be suitably considered during the flow-pattern matching process. Finally, a random-walk-based graph matching method is also utilized to efficiently solve the matching cost function optimization problem. Experimental results on both simulated flow data and real flow data demonstrate the effectiveness of our approach.	clique (graph theory);experiment;loss function;mathematical optimization;optimization problem;pattern matching;simulation;triplet state	Lihang Liu;Weiyao Lin;Youping Zhong	2015	2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)	10.1109/MMSP.2015.7340792	layout;mathematical optimization;combinatorics;template matching;computer science;3-dimensional matching;machine learning;pattern matching;optimal matching;mathematics;correlation	Vision	46.8782214519038	-54.606008335596776	92099
4323efacb543635b394b17c577fb653bad9f4575	automatic gait recognition based on statistical shape analysis	evaluation performance;metodo estadistico;image recognition;vision ordenador;surveillance image sequences pattern classification computer vision gait analysis biometrics access control image recognition statistical analysis feature extraction;base donnee;performance evaluation;distance measure;biometrics access control;surveillance;classification supervisee;biometrie;analisis forma;evaluacion prestacion;shape legged locomotion image sequence analysis computer vision surveillance computerized monitoring application software algorithm design and analysis image sequences pattern classification;supervised classification;biometrics;angle observation;shape analysis;database;biometria;base dato;viewing angle;technique video;body biometrics automatic gait recognition statistical analysis statistical shape analysis computer vision person identification visual surveillance visual monitoring image sequence background subtraction procedure moving silhouette extraction walking figure procrustes shape analysis method pattern classification;statistical method;gait recognition;statistical shape analysis;indexing terms;tecnica video;computer vision;algorithme;identificacion sistema;algorithm;visual surveillance;distance measurement;remote supervision;automatic recognition;installation exterieure;statistical analysis;analisis morfologico;instalacion exterior;monitoring;system identification;outdoor installation;methode statistique;telesurveillance;medicion distancia;feature extraction;image sequence;background subtraction;morphological analysis;pattern classification;clasificacion supervisada;gait analysis;pattern recognition;analyse morphologique;video technique;vision ordinateur;secuencia imagen;angulo observacion;pattern analysis;monitorage;reconnaissance forme;extraction caracteristique;point of view;reconocimiento patron;monitoreo;identification systeme;analyse forme;sequence image;vigilancia a distancia;reconocimiento automatico;mesure de distance;reconnaissance automatique	Gait recognition has recently gained significant attention from computer vision researchers. This interest is strongly motivated by the need for automated person identification systems at a distance in visual surveillance and monitoring applications. The paper proposes a simple and efficient automatic gait recognition algorithm using statistical shape analysis. For each image sequence, an improved background subtraction procedure is used to extract moving silhouettes of a walking figure from the background. Temporal changes of the detected silhouettes are then represented as an associated sequence of complex vector configurations in a common coordinate frame, and are further analyzed using the Procrustes shape analysis method to obtain mean shape as gait signature. Supervised pattern classification techniques, based on the full Procrustes distance measure, are adopted for recognition. This method does not directly analyze the dynamics of gait, but implicitly uses the action of walking to capture the structural characteristics of gait, especially the shape cues of body biometrics. The algorithm is tested on a database consisting of 240 sequences from 20 different subjects walking at 3 viewing angles in an outdoor environment. Experimental results are included to demonstrate the encouraging performance of the proposed algorithm.	algorithm;background subtraction;biometrics;computer vision;database;entity name part qualifier - adopted;gain;gait analysis;procrustes analysis;shape analysis (digital geometry);statistical shape analysis	Liang Wang;Tieniu Tan;Weiming Hu;Huazhong Ning	2003	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.2003.815251	computer vision;speech recognition;gait analysis;index term;background subtraction;system identification;feature extraction;morphological analysis;computer science;pattern recognition;shape analysis;biometrics	Vision	45.979329335785614	-58.52862845525559	92167
ec629a24ba1d473d2f6223c76b29e318e76a9d4e	a designed edge marking fill algorithm for elongated polygon	databases;elongated polygon;oceans;emfa edge marking fill algorithm design 3d elongated polygon pixel value scan conversion seed fill;marine technology;computer graphics;computational geometry;3d elongated polygon pixel value;doubling time;filling;edge marking fill algorithm design;data mining;computer graphics computational geometry;seed fill;scanning line;emfa;shape;heuristic algorithms;pixel;algorithm design and analysis filling educational institutions oceans databases marine technology shape design methodology;local point elongated polygon scanning line boundary value emfa;boundary value;local point;scan conversion;algorithm design and analysis;design methodology	To fill an elongated polygon, traditional Edge Marking Fill Algorithm can not deal properly. Basing on it, this paper especially presents a designed Edge Marking Fill algorithm aiming at elongated polygon. The idea is to design an algorithm, which signs out the pixel activated double times, then bounce out the function of edge marking fill algorithm and fill it with polygon pixel value. It solves the shortage that Edge Marking Fill Algorithm can not pick up the couple pixels for single point in the case of elongated polygon. The experimental results show that the new designed algorithm can be carried out easily and efficiently.	algorithm;item unique identification;pixel	Guodong Ye;Gui Lin;Changqing Zhu	2009	2009 First International Workshop on Database Technology and Applications	10.1109/DBTA.2009.13	algorithm design;computer vision;boundary-value analysis;design methods;simple polygon;computational geometry;shape;computer science;doubling time;marine technology;computer graphics;pixel;computer graphics (images)	Graphics	44.968128424876404	-66.06687391718324	92317
caaaea0c6b6d9fedc790b71fd734a4544201aed5	moving cast shadows detection based on ratio edge	lighting image edge detection pixel layout testing vehicles light sources image communication information processing performance evaluation;ratio edge distribution;foreground object;moving cast shadow detection;shadow detection;illumination invariant;image classification;object detection image classification;image pixel classification;foreground object moving cast shadow detection ratio edge distribution illumination invariant image pixel classification;physical model;illumination invariance;object detection	In this paper we propose a novel method for moving cast shadows detection. Based on the analysis to the physical model of moving shadows, we prove that the ratio edge is illumination invariant. The distribution of the ratio edge is discussed and a significance test is performed to classify each image pixel into foreground object or moving shadow. Experimental results on typical scenes show that the proposed method can detect moving shadows robustly	pixel	Wei Zhang;Xiangzhong Fang;Xiaokang Yang	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.818	computer vision;contextual image classification;physical model;computer graphics (images)	Vision	44.25140032081656	-52.25758669583644	92365
80b53836b9a5aa8971c1a3bb2ed1ad93e56bfd6f	modeling spatial relationships for remote sensing image processing based on fuzzy set theory	remote sensing image;degree of inclusion image processing spatial relationships fuzzy set theory equality index degree of intersection;image recognition;object recognition;image retrieval remote sensing image processing fuzzy set theory spatial information computer vision structural recognition decision making spatial fuzzy relationships fuzzy set operators structural object recognition;fuzzy set;image segmentation;image processing;fuzzy set operators;degree of inclusion;object recognition fuzzy set theory image recognition image retrieval;fuzzy set theory;fuzzy sets;remote sensing image processing fuzzy set theory fuzzy sets computer vision image recognition context modeling spatial resolution image resolution uncertainty;computer vision;indexes;remote sensing image processing;structural object recognition;pixel;indexation;equality index;spatial relationships;degree of intersection;spatial fuzzy relationships;structural recognition;spatial information;image retrieval	Spatial information is a crucial aspect of image processing, computer vision and structural recognition for modeling context as well as resolving the uncertainties caused by the ambiguities in low-level features. This calls for the framework of fuzzy sets, which exhibits nice features to represent spatial imprecision, and which provides powerful tools for fusion, decision-making and reasoning. In this paper, we present that several spatial fuzzy relationships constructed from fuzzy set operators and norms, and suggest some potential applications in structural object recognition and image retrieval based on fuzzy spatial relationships.	fuzzy set;image processing;set theory	Zhige Jia;Xiaoli Liu	2008		10.1109/CSSE.2008.1446	computer vision;image processing;image retrieval;computer science;neuro-fuzzy;machine learning;pattern recognition;mathematics;fuzzy set	Arch	41.36872355593355	-63.06953410837576	92375
8ab123d639958601920238b92ee3d425d8528830	maximum likelihood parametric blur identification based on a continuous spatial domain model	domain model;parametric model;2 d truncated gaussian blur mle parameter estimation image restoration maximum likelihood estimation blur identification continuous spatial domain model arbitrary point spread functions 1 d uniform motion blur 2 d out of focus blur;convergence;restauration image;image processing;parameter estimation image processing image reconstruction maximum likelihood estimation;maximum likelihood;1 d uniform motion blur;2 d truncated gaussian blur;maximum vraisemblance;procesamiento imagen;maximum likelihood estimation image restoration signal to noise ratio signal restoration inspection cepstrum frequency response convergence parameter estimation;image restoration;mle;maximum likelihood estimation;inspection;traitement image;algorithme;frequency response;algorithm;restauracion imagen;motion blur;blur identification;imagen borrosa;2 d out of focus blur;cepstrum;point spread function;blurred image;image reconstruction;identification;identificacion;signal restoration;image floue;parameter estimation;signal to noise ratio;maxima verosimilitud;continuous spatial domain model;algoritmo;arbitrary point spread functions	A formulation for maximum-likelihood (ML) blur identification based on parametric modeling of the blur in the continuous spatial coordinates is proposed. Unlike previous ML blur identification methods based on discrete spatial domain blur models, this formulation makes it possible to find the ML estimate of the extent, as well as other parameters, of arbitrary point spread functions that admit a closed-form parametric description in the continuous coordinates. Experimental results are presented for the cases of 1-D uniform motion blur, 2-D out-of-focus blur, and 2-D truncated Gaussian blur at different signal-to-noise ratios.		Gordana Pavlovic;A. Murat Tekalp	1992	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.199919	computer vision;image processing;computer science;gaussian blur;pattern recognition;mathematics;maximum likelihood;statistics	Vision	53.591702691190235	-66.09135425512818	92601
cb98c6985beb09d38a94608b0d3b48a1261e9550	computational geometry of contour extraction	image processing;computational geometry;natural images;prior knowledge;compact representation;hough transform;digital image	We present a method for extracting contours from digital images using techniques from computational geometry. Our approach is different from traditional pixelbased methods in image processing. Instead of working directly with pixels, we extract a set of oriented feature points from the input digital images, then apply classical geometric techniques such as clustering, linking, and simplification to find contours among these points. Experiments on synthetic and natural images show that our method can effectively extract contours even from images with considerable noise; moreover the extracted contours have a very compact representation.	cluster analysis;computation;computational geometry;contour line;digital image;experiment;hausdorff dimension;image processing;level of detail;linker (computing);pixel;synthetic intelligence	Pedro J. Tejada;Xiaojun Qi;Minghui Jiang	2009			hough transform;computer vision;image processing;computational geometry;machine learning;digital image processing;pattern recognition;mathematics;digital image	Vision	48.401346877837526	-61.96973739816003	92748
c896a70a418fb1dbc769c5f6acf5301be7797fd8	motion blur removal based on restoration error analysis	restauration image;image processing;fonction etalement point;mouvement relatif;point spread functions;procesamiento imagen;inmunidad ruido;image restoration;traitement image;filtre wiener;algorithme;algorithm;restauracion imagen;error analysis;motion blur;estimation erreur;noise immunity;imagen borrosa;error estimation;movimiento relativo;point spread function;blurred image;estimacion error;funcion distribucion punto;relative motion;wiener filter;image floue;immunite bruit;filtro wiener;radiometric corrections;cameras;algoritmo	A new technique for motion blur removal is proposed in this paper. Motion blur occurs when there is relative motion between the camera and the object of interest. To remove the blur, it is first necessary to identify the point spread function(PSF). We study the characteristics of restoration errors due to some elaborately selected PSFs. The direction and extent of the PSF can be determined after some intentional restorations. Wiener filter is then incorporated to restore the blurred image. The algorithm is effective and robust to noise. We apply it to the restoration of motion blurred license plates images. The results are fairly satisfactory.	circuit restoration;error analysis (mathematics);gaussian blur	Jin Zhang;Huirong Chen;Gang Rong	2006		10.1117/12.584988	image restoration;computer vision;geography;optics;cartography	Vision	53.36537211052131	-60.979282968275626	92760
a5276d0ed193aa923fb6dc2e91975c8570a2275d	finding the motion, position and orientation of a planar patch in 3d space from scaled-orthographic projection	espacio;proyeccion;movimiento;position;image processing;normalisation;procesamiento imagen;transformacion;posicion;espace;orientation;motion;traitement image;projection;mouvement;normalizacion;pattern recognition;orientacion;space;reconnaissance forme;transformation;reconocimiento patron;standardization	Abstract   For the time being, many methods about how to solve the motion and structure of a rigid object in 3D space by using point or line correspondences have been widely researched. In this paper, the projected 2D image shapes of planar patches in 3D space are used as our basic image features. We try to determine the motion parameters and plane equations of planar patches in 3D space from the relationships among their observed image shapes. Besides, scaled-orthographic projection is used instead of the original perspective projection because of its simpler and tractable mathematical formulas. Not only a closely-approximate model to perspective projection, it further solves the inherent depth indeterminacy which exists in orthographic projection. Moreover, after applying a pre-processing of rotation correction to the original image data, our estimation result can achieve a better numerical solution than that without this pre-processing. Simulation experiments show the excellence of our algorithms in estimating the motion parameters. Ambiguities, indeterminacy, and data degeneracy are also carefully discussed in this paper, which provides some important insights to the problems.	orthographic projection	Soo-Chang Pei;Lin-Gwo Liou	1994	Pattern Recognition	10.1016/0031-3203(94)90014-0	transformation;computer vision;oblique projection;projection plane;topology;projection;projection;image processing;computer science;position;motion;space;mathematics;3d projection;geometry;orientation;orthographic projection;motion field;planar projection;standardization;graphical projection;projection	Vision	50.3425499152474	-57.817875492595675	92852
8614052d6d5b92b9662e3d0fdeca63b824b704c5	basic and fine structure of pairwise interactions in gibbs texture models	characteristic minor detail;multiple pairwise pixel interaction;basic structure;stochastic texture;gibbs texture models;pairwise interactions;fine structure;fine interaction structure;basic interaction structure;characteristic interaction structure;regular texture;primary interaction	Gibbs models with multiple pairwise pixel interactions permit us to estimate characteristic interaction structures of spatially homogeneous image textures. Interactions with partial energies over a particular threshold form a basic structure that is sufficient to model a specific group of stochastic textures. Another group, referred here to as regular textures, permits us to reduce the basic structure in size, providing only a few primary interactions are responsible for this structure. If the primary interactions can be considered as statistically independent, a sequential learning scheme reduces the basic structure and complements it with a fine structure describing characteristic minor details of a texture. Whereas the regular textures are described more precisely by the basic and fine interaction structures, the sequential search may deteriorate the basic interaction structure of the stochastic textures.	interaction	Georgy L. Gimel'farb	2000		10.1007/3-540-44522-6_77	econometrics;machine learning;pattern recognition	Vision	40.91110518012989	-63.345698114280665	92928
fa2c6072d5408b078f9020bd79eaa6a5091c1d20	sequential decomposition of 2d apparent motion fields based on low-rank and sparse approximation		Estimation of camera egomotion and detection/tracking of moving objects in video captured by moving camera are challenging tasks in many applications such as autonomous vehicle control, medical image analysis, video surveillance, compression, stabilization, etc. Camera egomotion and object motion in a scene both induce temporal variation of image intensity, which is represented as a vector field of the so-called optical flow. An egomotional optical-flow field at any moment is composed of a few common linear basis vector fields related to camera's translation and rotation, while the moving objects superpose spatio-temporally local and sparse optical flows. We present an online algorithm of stable principal component pursuit that decomposes frame by frame the apparent motion fields into linearly dependent optical-flow fields and sparse optical flows for a given sequence of images. We experimentally show that the former captures the egomotion, and the latter detects the moving objects.	autonomous robot;basis (linear algebra);closed-circuit television;computation;experiment;ip camera;image analysis;medical image computing;medical imaging;online algorithm;optical flow;principal component analysis;sparse approximation;sparse matrix;superposition principle;ti advanced scientific computer;video content analysis;visual odometry	Tomoya Sakai;Shun Ogawa;Hiroki Kuhara	2017	2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)	10.1109/APSIPA.2017.8281998	vector field;basis (linear algebra);computer vision;principal component analysis;sparse matrix;linear independence;approximation error;sparse approximation;artificial intelligence;optical flow;mathematics	Vision	50.20607285371616	-55.36635630156014	93047
c0f6f402a6d070ad1656cd7e8dcf81a8a9741685	estimation of depth and 3d motion parameter of moving object with multiple stereo images	moving image;moving object;optimisation;motion study;rigid body;optimizacion;cost function;redundancia;algoritmo recursivo;simulation;estudio movimiento;simulacion;motion estimation;stereoscopy;segmentation;imagen movil;funcion coste;three dimensional;stereovision;image mobile;algorithme recursif;redundancy;image sequence;etude mouvement;least square;stereo vision;multiple stereo images;stereoscopie;fonction cout;optimization;recursive algorithm;estereoscopia;sum of squared difference;segmentacion;redondance	In this paper a use of stereo motion sequences is considered to estimate both three-dimensional (3D) motion and depth of 3D moving points. The problem is formulated as optimization of a cost function, accumulated sum of squared differences (SSD) computed from stereo motion sequences. It is assumed that the 3D motion is purely translational within any image window in which the SSD is computed. This method does not make any assumptions about stereo correspondences or spatial segmentation into a rigid body. We derive the unique condition under which 3D motion and depth ambiguities can be resolved. Once the ambiguities have been resolved, the 3D motion parameters and depth are estimated by a least squares technique. By analyzing the statistical characteristics of the cost function, it is shown that the precision of the estimates can be improved from data redundancy. A recursive algorithm is presented to reduce memory overload and to sequentially update the estimates. Simulation with synthetic images and experimentation with a real image sequence are presented to show the effectiveness of this method.		Jae-Woong Yi;Jun-Ho Oh	1996	Image Vision Comput.	10.1016/0262-8856(95)01073-4	computer vision;structure from motion;simulation;quarter-pixel motion;computer science;stereopsis;motion estimation;mathematics;geometry;motion field	Vision	50.09728866052451	-56.750159814556206	93065
293544450c487a4628773ea2d443c8440233f395	fast dual decomposition based mesh-graph clustering for point clouds		Robust object detection is one of the key tasks for autonomous vehicles. Clustering is the fundamental step for extracting objects from 3D point clouds. We propose a fast and efficient algorithm to cluster 3D point clouds provided by modern LiDAR sensors. The clustering is based on graph theory and local contextual information. Our method encodes weights of graph edges by adopting perceptual laws based on the intrinsic sensor beam pattern. This significantly increases the robustness of the segmentation process. It allows a point-wise clustering even at challenging distances and viewing angles as well as occlusions. For the sake of speed, the clustering pipeline is separated into vertical and horizontal clustering. Therefore, we split the graph into multiple vertical and horizontal line graphs which are processed in parallel. Finally, the partitioned results are merged into coherent objects using a breadth-first search algorithm. Experiments in different suburban datasets have demonstrated that our proposed method outperforms other state of the art methods, especially in complex scenes. A quantitative comparison between our method and other representative clustering methods proves the efficiency and the effectiveness of our work.		Patrick Burger;Benjamin Naujoks;Hans-Joachim Wünsche	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569999		Robotics	44.76756885708015	-55.8557373821936	93208
810f622b586a0282c3405dd84a0cd9d79b795582	rotation moment invariants for recognition of symmetric objects	method of moments;evaluation performance;object recognition;deteccion blanco;performance evaluation;rotational invariance;symmetric objects;moment invariants;evaluacion prestacion;reconnaissance objet;detection cible;detection objet;complex moments;pattern recognition;reconnaissance forme;invariance rotationnelle;reconocimiento patron;target detection;object detection;n fold rotation symmetry;moment invariant	In this paper, a new set of moment invariants with respect to rotation, translation, and scaling suitable for recognition of objects having N-fold rotation symmetry are presented. Moment invariants described earlier cannot be used for this purpose because most moments of symmetric objects vanish. The invariants proposed here are based on complex moments. Their independence and completeness are proven theoretically and their performance is demonstrated by experiments	experiment;invariant (computer science);physical object;test scaling	Jan Flusser;Tomás Suk	2006	IEEE Transactions on Image Processing	10.1109/TIP.2006.884913	computer vision;method of moments;rotational invariance;computer science;cognitive neuroscience of visual object recognition;mathematics;geometry;statistics	Vision	46.84930577217552	-59.1891166620183	93327
9274648c3c52ea8cf4e82e0c832c45f6d98058c7	cooperative fusion of stereo and motion	motion analysis;moving image;motion study;stereo correspondance;vision estereoscopica;vision stereoscopique;estudio movimiento;correspondence problem;imagen movil;integration;image mobile;cue integration;integracion;pattern matching;etude mouvement;optical flow;concordance forme;stereopsis	Abstract   This paper presents a new cooperative matching algorithm based on the integration of stereo and motion cues. In this algorithm, stereo disparity and image flow values are recovered from two successive pairs of stereo images by solving the stereo and motion correspondence problems. Feature points are extracted from the images as matching objects. The entire matching process composes of a network of four subprocesses (two for stereo and two for motion). Each of the subprocesses can access information from connected nodes to perform the disambiguation. The “best” matches are obtained in a relaxation manner using the 3-D continuity constraint. Experimental results are presented to illustrate the performances of the proposed method.		Anthony Yuk-Kwan Ho;Ting-Chuen Pong	1996	Pattern Recognition	10.1016/0031-3203(95)00068-2	computer stereo vision;computer vision;simulation;computer science;stereopsis;pattern matching;optical flow;correspondence problem;computer graphics (images)	Vision	49.0847416511594	-57.80659038285201	93577
88ceea7b9db7a318c63908ff61f4e02a6aaabda7	implementation and advanced results on the non-interrupted skeletonization algorithm	image processing;data compression;procesamiento imagen;traitement image;squelettisation;pattern recognition;skeletonization;reconnaissance forme;reconocimiento patron	This paper is a continuation to the work in [1], in which a new algorithm for skeletonization is introduced. The algorithm given there and implemented for script and text is applied here on images like pictures, medical organs and signatures. This is very important for a lot of applications in pattern recognition, like, for example, data compression, transmission or saving. Some interesting results have been obtained and presented in this article. Comparing our results with others we can conclude that if it comes to thinning of scripts, words or sentences our method is as good as some of the latest approaches, when considering cursive script. However, when it comes to pictures, signatures or other more complicated images, our algorithm showed better and more precise results [6].	algorithm;continuation;data compression;electronic signature;interrupt;pattern recognition;thinning;topological skeleton;type signature	Khalid Saeed;Mariusz Rybnik;Marek Tabedzki	2001		10.1007/3-540-44692-3_72	data compression;skeletonization;computer vision;image processing;computer science;artificial intelligence;computer graphics (images)	Vision	45.707453604325245	-64.25638318684733	93654
dd5edf76cfe0fd4a425e38d39a740978d401dd0e	three-dimensional face recognition using shapes of facial curves	reconnaissance visage;image tridimensionnelle;3d face recognition;modele geometrique;image databases;face recognition image analysis image texture analysis robustness lighting humans shape measurement face detection geophysics computing image databases;range images facial curves shape analysis geodesic paths 3d face recognition;facies;image databank;morfoscopia;analisis forma;facial curves;depth function;geodesic paths;algorithms artificial intelligence biometry face humans image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval pattern recognition automated subtraction technique;computational geometry;shape analysis;shape measurement;three dimensional;geometric approach;geodesique;face recognition;geophysics computing;geodesic;range image;morphoscopie;differential geometric approach;banco imagen;geodesico;banque image;range images;tridimensional image;robustness;image analysis;pattern analysis;humans;image texture analysis;lighting;three dimensional face recognition;face detection;nearest neighbor classifier;nearest neighbor classifier facial curves three dimensional face recognition depth function differential geometric approach;analyse forme;face recognition computational geometry;imagen tridimensional;geometrical model;modelo geometrico	We study shapes of facial surfaces for the purpose of face recognition. The main idea is to 1) represent surfaces by unions of level curves, called facial curves, of the depth function and 2) compare shapes of surfaces implicitly using shapes of facial curves. The latter is performed using a differential geometric approach that computes geodesic lengths between closed curves on a shape manifold. These ideas are demonstrated using a nearest-neighbor classifier on two 3D face databases: Florida State University and Notre Dame, highlighting a good recognition performance	alignment;curve fitting;database;distance;facial recognition system;image analysis;nearest neighbour algorithm;three-dimensional face recognition;manifold	Chafik Samir;Anuj Srivastava;Mohamed Daoudi	2006	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2006.235	three-dimensional space;computer vision;face detection;geodesic;image analysis;geometric design;facies;computational geometry;computer science;machine learning;pattern recognition;shape analysis;three-dimensional face recognition;lighting;mathematics;robustness	Vision	41.42004347656806	-58.33461223587736	93656
9bd2ca40988fa4883a95ec5a0a4643c96cbae513	separating reflection components based on chromaticity and noise analysis	surface roughness reflection components separation chromaticity noise analysis dielectric inhomogeneous objects;surface roughness;acoustic reflection optical reflection computer vision dielectrics lighting colored noise image analysis noise robustness rough surfaces surface roughness;indexing terms;diffuse reflection;specular to diffuse mechanism;computer vision;separation;dichromatic reflection model;chromaticity;index terms reflection components separation;specular reflection;image colour analysis;reflection model;diffuse reflectance;specular to diffuse mechanism index terms reflection components separation specular reflection diffuse reflection dichromatic reflection model noise analysis chromaticity;light reflection;algorithms artificial intelligence color colorimetry computer graphics computer simulation image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval light lighting models biological models statistical numerical analysis computer assisted pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted stochastic processes subtraction technique;image denoising;image denoising light reflection separation image colour analysis;noise analysis	Many algorithms in computer vision assume diffuse only reflections and deem specular reflections to be outliers. However, in the real world, the presence of specular reflections is inevitable since there are many dielectric inhomogeneous objects which have both diffuse and specular reflections. To resolve this problem, we present a method to separate the two reflection components. The method is principally based on the distribution of specular and diffuse points in a two-dimensional maximum chromaticity-intensity space. We found that, by utilizing the space and known illumination color, the problem of reflection component separation can be simplified into the problem of identifying diffuse maximum chromaticity. To be able to identity the diffuse maximum chromaticity correctly, an analysis of the noise is required since most real images suffer from it. Unlike existing methods, the proposed method can separate the reflection components robustly for any kind of surface roughness and light direction.	algorithm;amiga reflections;computer vision;diffuse reflection;non-contact specular microscopy;physical object;pixel;reflection (computer graphics);specular highlight	Robby T. Tan;Ko Nishino;Katsushi Ikeuchi	2004	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2004.90	computer vision;computer science;diffuse reflection;computer graphics (images)	Vision	53.7193841644715	-56.29174531530209	93692
3cfb503c4ff38eb6d4b01416f8cca45c1e6bc35d	parametric active contour model using gabor balloon energy for texture segmentation		Active contour models (ACM) as deformable shape models are one of the popular methods in object detection and image segmentation. This article presents a robust texture-based segmentation method using parametric ACM. In the proposed method, the energy function of the parametric ACM is modified by adding texture-based balloon energy, so the accurate detection and segmentation of textured object in textured background would be achieved. In this study, texture features of contour, object, and background points are calculated by Gabor filter bank. Then, comparing the calculated texture features of contour points and target object obtains movement direction of the balloon, whereupon active contour curves are shrunk or expanded to make the contour fit to object boundaries. The comparison between our proposed segmentation method and the ACM based on the directional Walsh– Hadamard features, fast adaptive color snake model, and parametric texture model based on joint statistics of complex Wavelet coefficients, indicates that our method is more effective, accurate, and faster for texture image segmentation especially when the textures are irregular or texture direction of object and background is similar. P. Moallem (B) Department of Electrical Engineering, University of Isfahan, Isfahan, Iran e-mail: p_moallem@eng.ui.ac.ir H. Tahvilian Department of Electrical Engineering, Najafabad Branch, Islamic Azad University, Isfahan, Iran e-mail: h_tahviliyan@sel.iaun.ac.ir S. A. Monadjemi Department of Computer Engineering, University of Isfahan, Isfahan, Iran e-mail: monadjemi@eng.ui.ac.ir	active contour model;coefficient;computer engineering;contour line;electrical engineering;email;filter bank;gabor filter;hadamard transform;image segmentation;matlab;mathematical optimization;object detection;run time (program lifecycle phase);wavelet	Payman Moallem;Homa Tahvilian;S. Amirhassan Monadjemi	2016	Signal, Image and Video Processing	10.1007/s11760-015-0748-6	image texture;computer vision;computer science;pattern recognition;scale-space segmentation;texture filtering;computer graphics (images)	Vision	44.13246152277415	-65.5992213607699	93980
ba3b6c4696074a894089a574d6b8bc7441d109de	affine moment invariants of vector fields		Vector field (VF) is a special kind of multidimensional data. In each pixel, VF contains information about the direction and the magnitude of the measured quantity. To detect the patterns of interest in the field, special matching methods must be developed. We propose a method for the description and matching of VF patterns under an unknown affine transformation of the field. Unlike digital images, transformations of VFs act not only on the spatial coordinates but also on the field values, which makes the detection different. To measure the similarity between the template and the field patch, we propose original invariants with respect to affine transformation designed from moments. Their performance is demonstrated by experiments on real data from fluid mechanics.		Jitka Kostková;Tomás Suk;Jan Flusser	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451371	measured quantity;vector field;digital image;computer vision;magnitude (mathematics);artificial intelligence;pattern matching;pixel;affine transformation;computer science;invariant (mathematics)	Visualization	50.14145675284849	-62.046341510743915	94193
00c2e50c79984a76a8868c6f53c1b511392d2477	using line correspondences in invariant signatures for curve recognition	vision ordenador;curve recognition;computer vision;invariante;reconnaissance courbe;vision ordinateur;correspondance ligne;invariant;line correspondence	Plane curves and space curves distorted by an affine or projective transformation may be recognized if invariant descriptions of them are available. Recent research in this area has shown that it is possible to identify transformed curves through the use of various combinations of differential invariants and point correspondences. Purely differential invariants usually require very high order derivatives of the space curves, though taking advantage of point correspondences sharpLy reduces the order of derivatives necessary. In cases where point correspondences are not available but line correspondences are, it is still possible to construct invariant signatures of the curves without increasing the order of derivatives necessary. Using just first order derivatives, invariant signature functions can be established for plane curves using one line correspondence for curves subjected to affine transformations and using two line correspondences for curves subjected to projective transformations. Still with only first order derivatives, invariant signatures can be found for space curves using two Iine correspondences for curves subjected to af~ne transformations, and using three line corre,~pondence.~ for curves subjected to projective transformations. In each of the four cases, these invariant signatures are graphs of one invariant quantity versus another. Determining the equivalence of objects then requires identification of a pair of two-dimensional graphs. Planar objects and surfaces in space may be recognized by matching their boundaries using these variants. Furthermore, a group of partially occluded curves may be resolved into its individual components.	antivirus software;correspondence problem;electronic signature;freddy ii;graph (discrete mathematics);invariant (computer science);richardson number;turing completeness;type signature	Robert J. Holt;Arun N. Netravali	1993	Image Vision Comput.	10.1016/0262-8856(93)90047-K	computer vision;discrete mathematics;topology;computer science;invariant;affine geometry of curves;mathematics;geometry;family of curves	Vision	49.32979478007953	-60.15287425109559	94194
100f9f221430eb21b7dea6edc85d99782c2919d4	description of local singularities for image registration	foveal wavelet theory;fractals;minimal regularity;interest points;holder exponent;local image singularity;salient points;wavelet transforms;bidimensional signal singularity;wavelet transforms fractals image registration;region of interest;image registration;image registration local image singularity digital image salient points holder exponent minimal regularity bidimensional signal singularity foveal wavelet theory;image registration hafnium research and development iris computer integrated manufacturing digital images detectors robustness transform coding photometry;digital image	Recently, it has been shown that gradient-based methods are the most powerful approaches for describing the local content of digital images in the neighborhood of salient points. In practice, salient points are always located on image singularities whatever the detector used. In this paper, we show that a more efficient mathematical notion can be used to describe singularities: the Holder exponent. We propose here to conjointly use the Holder exponents and the direction of minimal regularity of the bidimensional signal singularities to compute a signature describing precisely a region of interest centered on an interest point. Holder exponents are estimated thanks to the foveal wavelets theory and the resulting descriptor is shown to be more efficient than classical SIFT and PCA-SIFT descriptors in the case of an image registration application	algorithm;digital image;experiment;gloh;gradient;harris affine region detector;image registration;performance;principal component analysis;region of interest;scale-invariant feature transform;wavelet	Julien Ros;Christophe Laurent	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.430	computer vision;mathematical optimization;fractal;computer science;image registration;mathematics;geometry;digital image;wavelet transform;region of interest	Vision	50.47245129743497	-64.71319957565643	94206
06dfc1c6f62bffd5f8b8619d8c51db1ec4d25f3f	fusing local patterns of gabor magnitude and phase for face recognition	reconnaissance visage;databases;dimensionalidad;fisher s linear discriminant fld;algorithms biometry face image enhancement image interpretation computer assisted pattern recognition automated reproducibility of results sensitivity and specificity subtraction technique;block based fisher linear discriminant local pattern fusion gabor magnitude face recognition local gabor xor patterns;evaluation performance;local gabor xor patterns;performance evaluation;image processing;fusion;fuses;biometrie;estudio comparativo;signal design;evaluacion prestacion;block based fisher linear discriminant;image fusion;biometrics;database;biometria;procesamiento imagen;base dato;dimensionality;gabor filters;gabor magnitude;indexing terms;filtro gabor;traitement image;discriminant analysis;analyse discriminante;etude comparative;etat actuel;analisis discriminante;local gabor xor patterns lgxp;gabor filter;histogram;automatic recognition;face recognition;histogramme;face representation;dimensionnalite;feature extraction;principal component analysis;state of the art;comparative study;filtre gabor;base de donnees;pattern recognition;estado actual;local gabor xor patterns lgxp face representation fisher s linear discriminant fld fusion histogram;image fusion face recognition feature extraction gabor filters;reconnaissance forme;reconocimiento patron;face detection;local pattern fusion;content addressable storage;discrete fourier transforms;histograma;linear discriminant analysis;reconocimiento automatico;reconnaissance automatique;face recognition face detection content addressable storage feature extraction signal design discrete fourier transforms principal component analysis linear discriminant analysis fuses databases	Gabor features have been known to be effective for face recognition. However, only a few approaches utilize phase feature and they usually perform worse than those using magnitude feature. To investigate the potential of Gabor phase and its fusion with magnitude for face recognition, in this paper, we first propose local Gabor XOR patterns (LGXP), which encodes the Gabor phase by using the local XOR pattern (LXP) operator. Then, we introduce block-based Fisher's linear discriminant (BFLD) to reduce the dimensionality of the proposed descriptor and at the same time enhance its discriminative power. Finally, by using BFLD, we fuse local patterns of Gabor magnitude and phase for face recognition. We evaluate our approach on FERET and FRGC 2.0 databases. In particular, we perform comparative experimental studies of different local Gabor patterns. We also make a detailed comparison of their combinations with BFLD, as well as the fusion of different descriptors by using BFLD. Extensive experimental results verify the effectiveness of our LGXP descriptor and also show that our fusion approach outperforms most of the state-of-the-art approaches.	authorization;database;encode;exclusive or;experiment;feret (facial recognition technology);facial recognition system;fuse device component;gabor filter;generalization (psychology);ieee xplore;linear discriminant analysis;machine learning;norm (social);sum rule in quantum mechanics;test set	Shufu Xie;Shiguang Shan;Xilin Chen;Jie Chen	2010	IEEE Transactions on Image Processing	10.1109/TIP.2010.2041397	fuse;computer vision;face detection;speech recognition;curse of dimensionality;index term;fusion;feature extraction;computer science;machine learning;comparative research;pattern recognition;histogram;mathematics;linear discriminant analysis;image fusion;biometrics;principal component analysis	Vision	43.39099395486295	-60.1982746182119	94251
045c4e110157b5abf1c13ffca4bbf248a4816d58	a new recognition model for electronic architectural drawings	tecnologia electronica telecomunicaciones;computacion informatica;electronic architectural drawing;grupo de excelencia;recognition;sinehir model;ciencias basicas y experimentales;interpretation;tecnologias;coordinate system	Current methods for recognition and interpretation of architectural drawings are limited to either low-level analysis of paper drawings or interpretation of electronic drawings that depicts only high-level design entities. In this paper, we propose a Self-Incremental Axis-Net-based Hierarchical Recognition (SINEHIR) model for automatic recognition and interpretation of real-life complex electronic construction structural drawings. We design and implement a series of integrated algorithms for recognizing dimensions, coordinate systems and structural components. We tested our approach on more than 200 real-life drawings. The results show that the average recognition rate of structural components is about 90%, and the computation time is significantly shorter than manual estimation time. q 2004 Elsevier Ltd. All rights reserved.	4d bim;algorithm;apache axis;bottom-up parsing;computation;distortion;entity;expect;graphical user interface;high- and low-level;integrated circuit;level design;real life;slab allocation;thickness (graph theory);time complexity;top-down and bottom-up design;usb decoration	Tong Lu;Chiew-Lan Tai;Feng Su;Shijie Cai	2005	Computer-Aided Design	10.1016/j.cad.2004.11.004	interpretation;computer science;artificial intelligence;coordinate system;mathematics;geometry;engineering drawing	AI	48.27013709599474	-60.285229891067544	94257
b46234b464245fe65e0eb75ff21f8ef58de698de	a stable voronoi-based algorithm for medial axis extraction through labeling sample points	delaunay triangulation;irrelevant branches stable voronoi based algorithm medial axis extraction sample points labeling small perturbations geometrical structure;skeleton shape labeling filtering image edge detection complexity theory noise;sample points;computational geometry;delaunay triangulation sample points medial axis extraction pruning voronoi diagram;pruning;medial axis extraction;voronoi diagram	This paper presents a Voronoi-based algorithm to extract the medial axis through labeling sample points. A major issue of the medial axis is its inherent instability under small perturbations. The medial axis is very sensitive to small changes of the boundary, which produce many irrelevant branches in the medial axis. Filtering extraneous branches is a common solution to handle this issue, It may be applied as a pre-processing step through simplifying (smoothing) the boundary, or as a post-processing step through pruning, which eliminates the irrelevant branches of the extracted medial axis. However, filtering may alter the topological or geometrical structure of the medial axis. This paper proposes a modification to a Voronoi-based medial axis extraction algorithm to automatically avoid appearing irrelevant branches through labeling the sample points. The experimental results indicate that our method is stable, even in the presence of significant noises and perturbations.	algorithm;apache axis;instability;medial graph;optic axis of a crystal;perturbation theory;preprocessor;relevance;skeleton (computer programming);smoothing;text simplification;video post-processing;voronoi diagram	Farid Karimipour;Mehran Ghandehari	2012	2012 Ninth International Symposium on Voronoi Diagrams in Science and Engineering	10.1109/ISVD.2012.20	combinatorics;topology;voronoi diagram;medial axis;straight skeleton;mathematics;geometry;bowyer–watson algorithm	Robotics	48.93742359750697	-64.91406525358597	94524
4be6aad9ca039bc6f9626dad9306991a94db7f51	implementing continuous-scale morphology via curve evolution	equation derivee partielle;numerical algorithmics;partial differential equation;mathematical morphology;vision ordenador;ecuacion derivada parcial;morfologia matematica;curve evolution;cuve evolution;digital implementation;computer vision;fuzzy clustering;scale space;algorithmique numerique;evolution courbe;groupage flou;vision ordinateur;implantation numerique;algoritmico numerico;espace echelle;morphologie mathematique	Abstraet--A new approach to digital implementation of continuous-scale mathematical morphology is presented. The approach is based on discretization of evolution equations associated with continuous multiscale morphological operations. Those equations, and their corresponding numerical implementation, can be derived either directly from mathematical morphology definitions or from curve evolution theory. The advantages of the proposed approach over the classical discrete morphology are demonstrated.	discretization;evolution;galaxy morphological classification;mathematical morphology;numerical analysis	Guillermo Sapiro;Ron Kimmel;Doron Shaked;Benjamin B. Kimia;Alfred M. Bruckstein	1993	Pattern Recognition	10.1016/0031-3203(93)90142-J	computer vision;scale space;mathematical morphology;fuzzy clustering;computer science;calculus;mathematics;geometry;partial differential equation;algorithm	Vision	49.35719494299575	-63.76387559741403	94563
c6eb51ca82a4f0997d3e8378ed7c8a6382a1ed5c	an approach to image retrieval based on shape	image recognition;reconocimiento imagen;forma;metodologia;chain code;information retrieval;information technology;interrogation base donnee;image database;interrogacion base datos;systeme recherche;technologie information;indexing and retrieval;methodologie;search system;codificacion;shape;indexing;sistema investigacion;recherche information;value chain;indexation;coding;reconnaissance image;indizacion;recuperacion informacion;shape description;methodology;content based image retrieval;tecnologia informacion;forme;similarity measure;database query;codage;image retrieval	In a content-based image retrieval system, it is necessary to find a metric to index shapes of objects in the images. The metric should be unique to each shape, regardless of size and orientation. A similarity measure is also needed which should reflect the perceptual similarity, i.e. the perceptual similar shapes should have high similarity values. Chain codes have been used for shape description in previous works, but chain codes are non-invariant to shape size and orientation. In this paper, a method is introduced to eliminate the inherent non-invariance of chain codes to obtain unique chain codes for shapes. The shape index is derived from this unique chain code representation. The shape distance and similarity measures based on the shape indexes are then discussed. The indexing and retrieval procedures discussed in this paper should be applicable to large image databases.	image retrieval	Guojun Lu	1997	J. Information Science	10.1177/016555159702300203	active shape model;computer vision;search engine indexing;value chain;image retrieval;shape;computer science;methodology;data mining;shape analysis;chain code;coding;law;information technology;information retrieval	Vision	43.192619749368774	-61.242749828408705	94666
728515432f9910f49bbf738291543ce0888a2782	fusion of range and intensity images on a connection machine (cm-2)	bayesian framework;image processing;bayesian approach;fusion;implementation;procesamiento imagen;melting;calculateur simd;minimizacion funcion;traitement image;markov random field;energy function;algorithme;algorithm;ejecucion;function minimization;simd computer;range image;energy minimization;sensor fusion;density functional;minimisation fonction;algoritmo	Abstract   A new algorithm for fusion of range and intensity images in a Bayesian framework is presented. This framework allows the fusion problem to be posed in terms of maximization of a posteriori density function or, equibalently, minimization of an energy function. Experimental results of the fusion algorithm on registered range and intensity images indicate that the detected and labeled edges match the physical edges in the scene. To alleviate the heavy computational demands of our fusion algorithm, two energy a minimization algorithms have been implemented on a CM-2 Connection Machine, an SIMD type parallel hardware. It is demonstrated that a straightforward conversion of sequential code to parallel code results in poor computational performance. Experimental results show that computations in the fusion energy minimization operation can be carried out significantly faster (speedup > 50) on the CM-2 than on a Sun Sparcstation-2.	connection machine	Sateesha G. Nadabar;Anil K. Jain	1995	Pattern Recognition	10.1016/0031-3203(93)E0027-5	melting;computer vision;fusion;image processing;bayesian probability;computer science;theoretical computer science;machine learning;sensor fusion;implementation;energy minimization;algorithm	Vision	50.92258035730855	-55.33724988827347	94737
6387df7c69433aa9213d9f9a0cbe024a43793dcd	automatic graph extraction from color images	graph theory;detectors;corner detection;object recognition;local contour maxima detection;symbiosis;edge detection;color;susan detector;image enhancement;color images;image edge detection;symbolic contour extraction;algorithm theory;image colour analysis;image representation;greedy contour following algorithm;feature extraction;feature enhancement;monkey cortical endstopped cells;automatic graph extraction;joining processes;color image edge detection object detection object recognition symbiosis joining processes neurons fires detectors humans;visual perception;humans;neurons;canny css detector;monkey cortical complex cells;canny css detector automatic graph extraction color images symbolic contour extraction feature enhancement greedy contour following algorithm monkey cortical complex cells monkey cortical endstopped cells corner detection local contour maxima detection symbolic image representation susan detector;fires;object detection;color image;image representation graph theory image colour analysis image enhancement edge detection feature extraction visual perception algorithm theory;symbolic image representation;symbolic representation	An approach to symbolic contour extraction will be described that consists of three stages: enhancement, detection, and extraction of contours and corners. Contours and corners are enhanced by models of monkey cortical complex and endstopped cells. Detection of corners and local contour maxima is performed by selection of local maxima in both contour and corner enhanced images. These maxima form the anchor points of a greedy contour following algorithm that extracts the contours. This algorithm is based on an idea of spatially linking neurons along a contour that will fire in synchrony to indicate an extracted contour. The extracted contours and detected corners represent the symbolic representation of the image. The advantage of the proposed model over other models is that the same low constant thresholds for corner and local contour maxima detection are used for different images. Closed contours are guaranteed by the contour following algorithm to yield a fully symbolic representation which is more suitable for reasoning and recognition. In this respect our methodology is unique, and clearly different from the standard (edge) contour detection methods. The results of the extracted contours (when displayed as being detected) show similar or better results compared to the SUSAN and Canny-CSS detectors.	canny edge detector;cascading style sheets;contour line;greedy algorithm;maxima and minima;sensor	Tino Lourens;Hiroshi G. Okuno;Hiroaki Kitano	2001		10.1109/ICIAP.2001.957026	corner detection;computer vision;detector;edge detection;color image;visual perception;feature extraction;computer science;graph theory;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;symbiosis	Vision	43.47069072789129	-56.27869969040539	94794
0b3f88ddffb2d9f0db57f731a38b73a7a3bdfd18	robust point matching method for multimodal retinal image registration	surf;multimodal retinal image;piifd;image registration;robust point matching	In this paper, motivated by the problem of multimodal retinal image registration, we introduce and improve the robust registration framework based on partial intensity invariant feature descriptor (PIIFD), then present a registration framework based on speed up robust feature (SURF) detector, PIIFD and robust point matching, called SURF–PIIFD–RPM. Existing retinal image registration algorithms are unadaptable to any case, such as complex multimodal images, poor quality, and nonvascular images. Harris-PIIFD framework usually fails in correctly aligning color retinal images with other modalities when faced large content changes. Our proposed registration framework mainly solves the problem robustly. Firstly, SURF detector is useful to extract more repeatable and scale-invariant interest points than Harris. Secondly, a single Gaussian robust point matching model is based on the kernel method of reproducing kernel Hilbert space to estimate mapping function in the presence of outliers. Most importantly, our improved registration framework performs well even when confronted a large number of outliers in the initial correspondence set. Finally, multiple experiments on our 142 multimodal retinal image pairs demonstrate that our SURF–PIIFD–RPM outperforms existing algorithms, and it is quite robust to outliers.	image registration;multimodal interaction	Gang Wang;Zhicheng Wang;Yufei Chen;Weidong Zhao	2015	Biomed. Signal Proc. and Control	10.1016/j.bspc.2015.03.004	computer vision;surf;computer science;image registration;pattern recognition;mathematics;computer graphics (images)	Vision	43.30575606179265	-53.432074096240385	94810
84ed1d1fe3157eaa4a3e005521a9a926c303a563	the generalized-line-based iterative transformation model for imagery registration and rectification	geophysical image processing;photogrammetry;posterior variance estimation generalized line based iterative transformation model glbitm ground control lines gcls imagery registration iterative method with variable weights polynomial model;estimation theory;image segmentation mathematical model polynomials remote sensing image registration vectors accuracy;image resolution;image sensors;generalized line based iterative transformation model affine transformation sensor high resolution satellite imagery processing quality control posterior variance estimation scale recalculation coefficient rotation recalculation coefficient translation amount elimination iteratively solve transformation coefficient quadratic polynomial model linear feature adjustment model ground control point gcl ground control line gpp generalized point photogrammetry lbtm line based transformation model glbitm coordinate system data transformation imagery rectification imagery registration;quality control affine transforms estimation theory geophysical image processing image registration image resolution image sensors iterative methods photogrammetry polynomials;polynomials;iterative methods;image registration;affine transforms;quality control	Imagery registration and rectification is a process of transforming different sets of data into one coordinate system. A new model, i.e., the generalized-line-based iterative transformation model (GLBITM), is proposed by integrating the line-based transformation model (LBTM) and generalized point photogrammetry (GPP). First, the initial value of an affine transformation is acquired by LBTM. Then, on the basis of ground control lines (GCLs), not ground control points, the linear feature adjustment model with GPP is extended to a quadratic polynomial model and utilized to iteratively solve transformation coefficients. This process eliminates the translation amount and recalculates the scale and rotation coefficients. The authors suggest an iterative method with variable weights that is based on posterior variance estimation to improve quality control. A significant characteristic of the GLBITM is that the two endpoints of the corresponding GCLs are not necessarily conjugate points. The GLBITM integrates the advantages of the LBTM and GPP and avoids their respective shortfalls. Finally, this experiment verifies that the GLBITM gives correct, robust, and effective results that can be applied in high-resolution satellite imagery processing of multiple sensors, angles, and resolutions.	coefficient;control flow;graph partition;image rectification;image registration;image resolution;iterative method;photogrammetry;polynomial;quadratic function;sensor	Chang Li;Wenzhong Shi	2014	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2013.2293844	computer vision;mathematical optimization;quality control;image resolution;image registration;image sensor;mathematics;iterative method;estimation theory;photogrammetry;statistics;polynomial;remote sensing	Vision	52.066641869918286	-52.95832752120695	94902
4fb8497496ab2e06815489624834ef2a71a900e9	virtual view synthesis of people from multiple view video sequences	contraste;free viewpoint video;rendu image;occlusion;restitucion imagen;computer graphics;virtual view rendering;occultation;cible multiple;image multiple;oclusion;imagen multiple;blanco multiple;surface reconstruction;visual quality;multiple views;multiple image;multiple view;reconstruction surface;virtual view;distance focale;focal length;view synthesis;senal video;signal video;vue virtuelle;distancia focal;image sequence;image rendering;video signal;vue multiple;view dependent reconstruction;ambiguity;etalonnage;secuencia imagen;multiple target;vista virtual;experimental evaluation;reconstruccion superficie;camera calibration;image based rendering;ocultacion;ambiguedad;grafico computadora;infographie;calibration;view dependent reconstructions;sequence image;vista multiple;ambiguite;visual reconstruction	This paper addresses the synthesis of novel views of people from multiple view video. We consider the target area of the multiple camera 3D Virtual Studio for broadcast production with the requirement for free-viewpoint video synthesis for a virtual camera with the same quality as captured video. A framework is introduced for view-dependent optimisation of reconstructed surface shape to align multiple captured images with sub-pixel accuracy for rendering novel views. View-dependent shape optimisation combines multiple view stereo and silhouette constraints to robustly estimate correspondence between images in the presence of visual ambiguities such as uniform surface regions, self-occlusion, and camera calibration error. Free-viewpoint rendering of video sequences of people achieves a visual quality comparable to the captured video images. Experimental evaluation demonstrates that this approach overcomes limitations of previous stereoand silhouette-based approaches to rendering novel views of moving people. 2005 Elsevier Inc. All rights reserved.	3d construction kit;align (company);approximation algorithm;flicker (screen);mathematical optimization;pixel;refinement (computing);rendering (computer graphics);reprojection error;scott continuity;synthetic intelligence;view synthesis;virtual artifact;virtual camera system;virtual reality headset;virtual studio;visual hull	Jonathan Starck;Adrian Hilton	2005	Graphical Models	10.1016/j.gmod.2005.01.008	focal length;computer vision;calibration;camera resectioning;simulation;image-based modeling and rendering;surface reconstruction;occultation;computer science;computer graphics;computer graphics (images)	Vision	51.37278394008652	-56.663699827367644	94967
284f196fd155b3f0e9cec272d65a715f27230c74	robust matching area selection for terrain matching using level set method	analisis imagen;modelizacion;navegacion;fiabilidad;reliability;image segmentation;guidage;path planning;unmanned aerial vehicle;localization;level set;localizacion;guiado;probabilistic approach;engin volant autonome;planification trajectoire;modelisation;navigation;localisation;unmanned aerial vehicle uav;maquina autonoma voleando;enfoque probabilista;approche probabiliste;fiabilite;segmentation image;courbe niveau;pattern recognition;correlation matching;navigation reference image;guidance;image analysis;reconnaissance forme;curva nivel;reconocimiento patron;level set method;modeling;analyse image;dct;contour line	To enhance the reliability of path planning in scenery guidance system, it's very important to select reliable or high matching probability areas from the navigation reference images for performing unmanned aerial vehicles localization. This paper applies three measures and proposes a new selection scheme base on a simplified Mumford-Shah model. The proposed method artfully avoids selecting thresholds to separate the feature images and optimally selects robust-matching areas by evolving the level set function. Experiments of the selection show that the proposed method is efficient.		Guo Cao;Xin Yang;Shoushui Chen	2005		10.1007/11559573_53	computer vision;navigation;image analysis;simulation;systems modeling;internationalization and localization;computer science;level set;discrete cosine transform;reliability;motion planning;image segmentation;level set method;contour line	Vision	48.93287933572875	-58.469183264319796	94987
8dd0455d88dcf4c5e8b3c6b0fc84bab6ed9f3e60	real-time texture synthesis with patch jump maps	analisis componente principal;analisis textura;texture synthesis;real time;texture image;pattern synthesis;synthese texture;image texture;synthese forme;texture analysis;cuantificacion vectorial;vector quantization;principal component analysis;temps reel;analyse composante principale;patch jump map;tiempo real;sintesis forma;analyse texture;quantification vectorielle	This paper presents a real-time method for synthesizing texture. The algorithm consists of two stages: a preprocess stage and a real-time synthesis stage. In the preprocess stage, jump lists are built for each texture patch in the input sample texture and all the jump lists are stored in patch jump maps. In the synthesis stage, we synthesize the output texture with the aid of stored patch jump maps. Experiments show 200-500 frames of 256 × 256 high quality textures can be produced within a second.		Bin Wang;Jun-Hai Yong;Jia-Guang Sun	2004		10.1007/978-3-540-30497-5_177	image texture;computer vision;computer science;machine learning;texture synthesis;vector quantization;principal component analysis;computer graphics (images)	Logic	46.62379815178989	-61.319126849711886	95101
2b72644bef1d272d1b750cb783a2d5644fa1ee76	blurred image recognition based on complex moment invariants	image recognition	An important class of radiometric degradations we are faced with often in practice is image blurring. Special attention is paid to the recognition of the blurred image by moment invariant approach. Some important rules of complex moments for the blurred image are presented. Based on these rules, a useful subset of moment invariants is introduced, that are not affected by the blur, rotation, scale, and translation of the images. The experiments have shown that these invariants can be successfully used in recognition of the blurred image.	computer vision	Tianxu Zhang;Jin Liu	2004			image quality;image warping;image texture;image restoration;computer vision;feature detection;speech recognition;binary image;image processing;computer science;gaussian blur;digital image processing;pattern recognition;image moment;gaussian process;mathematics	Vision	44.723822176476354	-60.35657212801201	95107
d3cef2eafa2f660b2bfa057246ab01b8f2cae97a	graph-based image segmentation with bag-of-pixels	bag of pixels image segmentation image content graph based;public image database graph based image segmentation bag of pixels image content image processing image retrieval object recognition image compression;visual databases graph theory image retrieval image segmentation object recognition;image edge detection image segmentation abstracts streaming media	Image segmentation can help us with a better understanding of the image content, and thus plays an important role in many fields of image processing including image retrieval, object recognition and image compression. We propose a novel method based on an efficient Graph-Based segmentation after analyzing its irrationalities. The proposed method with bag-of-pixels is simple and effective. In the evaluation using a large public image database that contains a lot of natural images, our method out-performs the efficient graph-based segmentation method, yields better segmentation results and shortens the running time.	image compression;image processing;image retrieval;image segmentation;outline of object recognition;pixel;time complexity	Zhihua Chen;Xiao-Long Xiao;Yi Liu;Jing Zhang;Yubo Yuan	2013	2013 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2013.6890849	image warping;image texture;computer vision;feature detection;range segmentation;visual word;color image;image gradient;binary image;image processing;segmentation-based object categorization;digital image processing;pattern recognition;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;automatic image annotation;information retrieval;digital image;image histogram	Vision	40.12350674561311	-65.24853716859589	95162
f53f6ceb26f649a8dff3da246c82fb2c4f951f45	image indexing and retrieval techniques: past, present, and next	databases;texture;forma;multimedia;articulo sintesis;image processing;article synthese;information retrieval;color;image database;procesamiento imagen;image indexing;methode;traitement image;histogram;shape;histogramme;indexing;recherche information;pixel;indexation;textura;indizacion;couleur;recuperacion informacion;review;histograma;forme;metodo;method;image retrieval	This paper investigates retrieval and indexing schemes in pixel domain, and points to the future work on image retrieval schemes. Image retrieval schemes generate indices for images in pixel or compressed domain based on their features in the corresponding domain. These indices are used to retrieve images from a database. The features in pixel domain are extracted from the color, shape or texture characteristics of images. The application of these three methods depends on the characteristic of the image database, and the query image. In the near future the image databases contains the compressed version of images, therefore there will be a high demand for the image retrieval techniques in compressed domain.© (1999) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Jamshid Shanbehzadeh;Amir-Masoud Eftekhari-Moghadam;Fariborz Mahmoudi	2000		10.1117/12.373578	image texture;computer vision;feature detection;visual word;image processing;image retrieval;computer science;automatic image annotation;information retrieval;computer graphics (images)	NLP	43.06476701124796	-61.423907240876574	95200
3f0e956a33e272fa59cc6d751db4b54e48e61fcb	gaussian affine feature detector	optimal solution;feature modeling;pattern recognition;aspect ratio	A new method is proposed to get image features’ geometric information. Using Gaussian as an input signal, a theoretical optimal solution to calculate feature’s affine shape is proposed. Based on analytic result of a feature model, the method is different from conventional iterative approaches. From the model, feature’s parameters such as position, orientation, background luminance, contrast, area and aspect ratio can be extracted. Tested with synthesized and benchmark data, the method achieves or outperforms existing approaches in term of accuracy, speed and stability. The method can detect small, long or thin objects precisely, and works well under general conditions, such as for low contrast, blurred or noisy images.	benchmark (computing);feature model;iterative method	Xiaopeng Xu;Xiaochun Zhang	2011	CoRR		computer vision;aspect ratio;computer science;machine learning;pattern recognition;harris affine region detector;mathematics;feature	Vision	41.80228999060959	-57.20261440233003	95262
037c33d2e7a9ab3ffe664c749fa285e14270d26e	genetic stereo matching algorithm with fuzzy fitness	stereo image processing genetic algorithms image matching image sensors;genetics;biological cells;stereo vision;statistics;disparity map dense stereo matching fuzzy fitness genetic algorithm;genetic algorithms;genetics stereo vision biological cells genetic algorithms sociology statistics encoding;encoding;sociology;evolutionary operators genetic stereo matching algorithm fuzzy evaluation function disparity matrix fuzzy fitness function uncertain camera measurements noise camera measurements	This paper presents a genetic stereo matching algorithm with fuzzy evaluation function. The proposed algorithm presents a new encoding scheme in which a chromosome is represented by a disparity matrix. Evolution is controlled by a fuzzy fitness function able to deal with noise and uncertain camera measurements, and uses classical evolutionary operators. The result of the algorithm is accurate dense disparity maps obtained in a reasonable computational time suitable for real-time applications as shown in experimental results.	binocular disparity;computation;computer stereo vision;evaluation function;fitness function;genetic algorithm;genetic operator;line code;map;real-time clock;time complexity	Haythem Ghazouani	2014	2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SOCPAR.2014.7007972	computer vision;genetic algorithm;computer science;stereopsis;artificial intelligence;machine learning;mathematics;encoding;statistics	Robotics	52.86469727492266	-58.745289840938746	95422
21031ea3bcb2f3132603e85ef7254d3c5ccdcbae	the grammar of dimensions in machine drawings	grammar;graphe non oriente;analisis escena;analyse scene;non directed graph;image processing;grafico no orientado;dimension;procesamiento imagen;intelligence artificielle;grafico etiquetado;traitement image;graphe etiquete;dimensions;grammaire;labelled graph;artificial intelligence;inteligencia artificial;gramatica;scene analysis	Dimensioning is an important constituent in machine drawings. Recognition of dimensions in machine drawings is a prerequisite for the development of a machine drawing understanding system (MDUS), which is a special class of image understanding systems (IUSs). The approach proposed in this work is a syntactic analysis of the dimensions, which are represented by undirected, labeled graphs called “webs.” Utilizing the conventions of web grammar, a set of web rewriting rules is established, which specify how all the possible dimension-sets can be generated and detected. The recognition process starts by detecting arrows using statistical methods. The location and orientation of the arrows together with rewriting rules of the dimensioning grammar are used to detect the rest of the components and the tree structure of the corresponding dimension set.	computer vision;graph (discrete mathematics);parsing;rewriting;sensor;technical drawing;tree structure	Dov Dori;Amir Pnueli	1988	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(88)90139-9	computer vision;technical drawing;image processing;computer science;artificial intelligence;machine learning;mathematics;geometry;dimension;algorithm	AI	48.17407184113974	-60.25455799405609	95497
ce15fe5e6506436ffb366f6da3bd40ca9045d756	autonomous sub-image matching for two-dimensional electrophoresis gels using maxrst algorithm	image features;features extraction;large dataset;image matching;gaussian similarity measure;shape deformation;feature extraction;two dimensional electrophoresis;relative neighborhood graph;spanning tree;similarity measure;maximum relation spanning tree;sub image matching;matching method;gabriel graph	0262-8856/$ see front matter 2010 Elsevier B.V. A doi:10.1016/j.imavis.2010.01.004 * Tel.: +886 913 061723; fax: +886 226 744448. E-mail address: dalton@mail.ntpu.edu.tw Matching two-dimensional electrophoresis (2-DE) gel images typically generates a bottleneck in the automated protein analysis, and image distortion and experimental variation, which reduce the matching accuracy. However, conventional matching schemes only compare two complete images, and landmark selection and registration procedures are rather time-consuming. This work presents a novel and robust Maximum Relation Spanning Tree (MaxRST) algorithm, in which an autonomous sub-image matching method does not require registering or manual selection of landmarks. The 2D gel images are represented graphically. Image features are then quantitatively extracted regardless of image size. Similarity between a sub-image and large image is then determined based on Gaussian similarity measurement inspired by fuzzy method, thereby increasing the accuracy of fractional matching. The proposed autonomous matching algorithm achieves an accuracy of up to 97.29% when matching 627 2-DE gel test images. In addition to accommodating image rotation, reversals, shape deformation and intensity changes, the proposed algorithm effectively addresses the sub-image mapping problem and was analyzed thoroughly using a large dataset containing 4629 images. The contributions of this work are twofold. First, this work presents a novel MaxRST strategy and autonomous matching method that does not require manual landmark selection. Second, the proposed method, which extends 2-DE gel matching to query sub-image and a database containing large sets of images, can be adopted for mapping and locating, and to compare small gel images with large gel images with robustness and efficiency. 2010 Elsevier B.V. All rights reserved.	algorithm;autonomous robot;computation;computational intelligence;cross-reference;delaunay triangulation;distortion;experiment;fax;federated database system;gadu-gadu;gaussian blur;image registration;image resolution;machine learning;mathematical optimization;proteomics;similarity learning;spanning tree;usability;user interface;whole earth 'lectronic link	Daw-Tung Lin	2010	Image Vision Comput.	10.1016/j.imavis.2010.01.004	computer vision;combinatorics;template matching;spanning tree;feature extraction;computer science;machine learning;optimal matching;pattern recognition;mathematics;feature	Vision	40.50539372252943	-57.63745000654823	95787
96c7e524c2a05b47bef6a3831037a67e74768f83	panter - knowledge-based image analysis system for workpiece recognition	hierarchical structure;semantic network;image analysis;invariant feature;knowledge base	This article describes a knowledge based image analysis system that uses the Hierarchical Structure Code (HSC) for the initial segmentation of the image data. The generation of this code is domain independent and allows for an elegant coupling with a knowledge base. The system was successfully tested in the field of workpiece recognition. In the first section of the article, a short introduction of the image transformation is presented, a presentation of methods to extract the size and position invariant features follows. The main emphasis of the article is on the description of a semantic network language for a knowledge based image analysis system using the Hierarchical Structure Code.	image analysis	Bärbel Mertsching	1992		10.1007/BFb0024972	computer vision;knowledge base;image analysis;computer science;artificial intelligence;machine learning;pattern recognition;semantic network	Vision	47.97715859550446	-61.508921999114065	95874
1012e928c0208ef8804c8e653cf5346f9161c564	an unbiased implementation of regularization mechanisms	symbolic computation;partial differential equation;regularization method;visual motion;diffusion operator;integral operator;unbiased implementation;diffusion process;image denoising;regularization methods	Perceptual processes, in computer or biological vision, require the computation of “maps” of quantitative values. The image itself is a “retinotopic map”: for each pixel of the image there is a value corresponding to the image intensity at this location. This is a vectorial value for color images. A step further, in early-vision, the retinal image contrast is computed at each location, allowing to detect image edges related to boundaries between image areas. Such maps encode not only the contrast magnitude, but several other cues: contrast orientation related to edge orientation, shape curvature, binocular disparity related to the visual depth, color cues, temporal disparity between two consecutive images in relation with visual motion detection, etc.. There are such detectors in both artificial and biological visual systems (see e.g. [12] for a general introduction and e.g. [17] for an overview about biological vision). Such maps are not only parametrized by retinotopic locations, but also using 3D locations, or other parameters.	binocular disparity;binocular vision;color;computation;computer;encode;map;pixel;sensor	Thierry Viéville	2005	Image Vision Comput.	10.1016/j.imavis.2005.07.002	computer vision;mathematical optimization;mathematical analysis;discrete mathematics;symbolic computation;diffusion process;machine learning;mathematics;partial differential equation;statistics	Vision	49.6656254824091	-64.0864252242248	95905
7cd40d9b2c58030f41604210a12c40d0c7402949	contour based shape matching for object recognition		To improve computational efficiency and solve the problem of low accuracy caused by geometric transformations and nonlinear deformations in the shape-based object recognition, a novel contour signature is proposed. This signature includes five types of invariants in different scales to obtain representative local and semi-global shape features. Then the Dynamic Programming algorithm is applied to shape matching to find the best correspondence between two shape contours. The experimental results validate that our methods is robust to rotation, scaling, occlusion, intra-class variations and articulated variations. Moreover, the superior shape matching and retrieval accuracy on benchmark datasets verifies the effectiveness of our method.	contour line;outline of object recognition	Haoran Xu;Jianyu Yang;Zhanpeng Shao;Yazhe Tang;Youfu Li	2016		10.1007/978-3-319-43506-0_25	active shape model;shape analysis;active contour model;3d single-object recognition	Vision	40.914458169331205	-56.942915223015234	95992
98f35b8f99a20f1ead3cebedfe4d82a55c2ea958	a contour characterization for multiply connected figures	digital geometry;contour characterization;multiply connected figures;multiple pixels;simple contours	""".,tb.~l/wc/."""" lhe characterization of a digital figure in terms of the multiple pixels, i.e., the pixcb, placed ~hcrc thc COnlOur sdlinteracls, can provide useful shape cues. These pixels call satisfaclorily be detected it"""" a siiilable dclinition of COiltOtlt simplicity isa\ailable. Such adel'inition isgiven in this paper, for Ihcca~,eol'muliipl\ connected figulcs. Ihc multiple pixcls LIIC those \~here the coiitOUl"""" fails to be simple, and they can bc identif ied by tlSJllg 3 X 3 local operatic)ns"""	pixel	Carlo Arcelli;Gabriella Sanniti di Baja	1987	Pattern Recognition Letters	10.1016/0167-8655(87)90084-5	arithmetic;computer vision;mathematics;computer graphics (images)	Vision	48.73713971190507	-62.36471566625846	96280
72e673c7e596312275412237daf8ce850e89077d	image similarity in gaussian mixture model based image retrieval		As color is a useful characteristic of our surrounding world, it gives clue for the recognition, indexing and retrieval of the images presenting the visual similarity. Thus, this paper focuses on the proper choice of the similarity measure applied to compare features evaluated in process the modeling of lossy coded color image information, based on the mixture approximation of chromaticity histogram. The analyzed similarity measure are those based on (Kullback-Leibler) Diverence, as Goldberger approximation and Variational approximation. Signature-based distance function as Hausdorff Distance, Perceptually Modified Hausdorff Distance and Earth (Moveru0027s) Distance were also investigated. Retrieval results were obtained for RGB, I1I2I3, YUV, CIE XYZ, CIE (L^*a^*b^*), HSx, LSLM and TSL color spaces.	image retrieval;mixture model	Maria Luszczkiewicz-Piatek	2016		10.1007/978-3-319-47274-4_10	image texture;gaussian blur;pattern recognition;information retrieval	Vision	40.62038262125875	-62.59104036462295	96418
ef26b463cda8d003d882745b3bb29f5d3278d5b8	direct computation of qualitative 3-d shape and motion invariants	analisis imagen;foyer;vision ordenador;planar;movimiento;3d motion invariants;shape navigation motion analysis image segmentation optical devices optical recording optical sensors image motion analysis focusing optical computing;espacio 3 dimensiones;picture processing;motion;classification;computer vision;matched images;focus of expansion picture processing pattern recognition structure from motion 3d shape invariants 3d motion invariants depth map matched images local surface patches convex concave cylindrical hyperbolic saddle point planar optical flow;3d shape invariants;cylindrical;espace 3 dimensions;mouvement;focus of expansion;three dimensional space;convex;pattern recognition;invariante;local surface patches;image analysis;vision ordinateur;optical flow;three dimensional structure;depth map;hyperbolic;picture processing pattern recognition;analyse image;structure from motion;clasificacion;concave;invariant;saddle point	Structure from motion often refers to the computation of three-dimensional structure from a matched sequence of images. However, a depth map of a surface is difficult to compute and may not be a good representation for storage and recognition. Given matched images it is shown that the sign of the normal curvature in a given direction at a given point in the image can be computed from a simple difference of slopes of line segments in one image. Using this result, local surface patches can be classified as convex, concave, cylindrical, hyperbolic (saddle point), or planar. At the same time, the translational component of the optical flow, from which the focus of expansion can be computed, is obtained. >	computation	Daphna Weinshall	1991	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.106997	three-dimensional space;computer vision;structure from motion;image analysis;topology;planar;biological classification;computer science;motion;invariant;optical flow;mathematics;geometry;saddle point;cylinder;foyer;depth map	Vision	49.56732067223226	-59.705714578366376	96648
412fece9affd9e5656b484dd31e7af53ab2037c0	ir and visible light face recognition	reconnaissance visage;interfaz multimodal;imageria termica;image recognition;reconocimiento imagen;analisis componente principal;multimodal interface;infrared thermography;biometrie;biometrics;biometria;multi modal;spectrum;infra red;thermographie ir;large scale;face recognition;thermal imaging;principal components analysis;infrared imaging;principal component analysis;reconnaissance image;analyse composante principale;pattern recognition;termografia ir;imagerie thermique;reconnaissance forme;reconocimiento patron;visible light;interface multimodale	This paper presents the results of several large-scale studies of face recognition employing visible light and infra-red (IR) imagery in the context of principal component analysis. We find that in a scenario involving time lapse between gallery and probe, and relatively controlled lighting, (1) PCA-based recognition using visible light images outperforms PCA-based recognition using infra-red images, (2) the combination of PCA-based recognition using visible light and infra-red imagery substantially outperforms either one individually. In a same session scenario (i.e. nearsimultaneous acquisition of gallery and probe images) neither modality is significantly better than the other. These experimental results reinforce prior research that employed a smaller data set, presenting a convincing argument that, even across a broad experimental spectrum, the behaviors enumerated above are valid and consistent.	algorithm;design of experiments;eigenface;emoticon;experiment;face recognition vendor test;facial recognition system;heart rate variability;image resolution;internationalization and localization;modality (human–computer interaction);principal component analysis;vagueness	Xin Chen;Patrick J. Flynn;Kevin W. Bowyer	2005	Computer Vision and Image Understanding	10.1016/j.cviu.2005.03.001	facial recognition system;computer vision;computer science;machine learning;principal component analysis	Vision	44.19185363013795	-57.131143663065124	96906
e26b08488c0860c1a0753e7ad15673b4f95d1f58	joint segmentation and b-spline object contour modelling for object tracking and motion compensation in image sequences	moving object;fast gradient based b spline contour matching algorithm;object recognition;spline;merging thresholds;tool movements;image segmentation;publikationer;motion compensation;image databases;video signal processing;edge detection;local image property;motion estimation;konferensbidrag;screwdriver;segmentation;splines mathematics;motion compensated;hand movements;motion parameters;spline tracking motion compensation image segmentation motion estimation image sequences merging robustness parameter estimation image databases;deformation;multi stage algorithm;robust knot re assignment method;affine transformation;object tracking;image sequence;artiklar;rapporter;merging;screwdriver segmentation b spline object contour modelling object tracking motion compensation image sequences video frames motion parameters affine transformations deformation multi stage algorithm moving objects merging thresholds local image property fast gradient based b spline contour matching algorithm robust knot re assignment method mage frames hand movements tool movements image sequence;mage frames;property a;video frames;moving objects;robustness;object recognition motion compensation parameter estimation image segmentation splines mathematics edge detection tracking image sequences video signal processing;affine transformations;parameter estimation;b spline object contour modelling;tracking;image sequences	One problem in tracking an object through video frames and estimating the associated motion parameters is that the object of interest may undergo various affine transformations and a small deformation. This paper presents a multi-stage algorithm for tracking moving objects using joint segmentation and B-spline contour modelling and motion parameters estimation. The segmentation algorithm uses merging thresholds which are based on the local image property. A fast gradient-based B-spline contour matching algorithm and a robust knot re-assignment method are proposed for tracking moving objects through image frames and estimating their motion parameters. The application of the scheme on images of hand and tool movements, and an image sequence containing a screwdriver with affine transformations shows that the estimated parameters are in very close agreement with the actual parameters.	b-spline;motion compensation	Irene Y. H. Gu;Vasile Gui;Tardi Tjahjadi	1997		10.1109/ICIP.1997.632165	computer vision;mathematical optimization;computer science;segmentation-based object categorization;video tracking;pattern recognition;affine transformation;mathematics	Vision	48.26366533091967	-53.24619078127296	96933
e2be075c14fc30b2c357f978c00f8b7c940817cf	wavelet transform for partial shape recognition using sub-matrix matching.	discrete wavelet transform;shape recognition;wavelet transform;affine transformation;stationary wavelet transform;distance matrix;partial shape matching;invariant feature	In this paper, we propose a method for 2D partial shape recogn iti n under affine transform using the discrete dyadic wavelet transform invariant to translation well kno w asStationary Wavelet Transform or SWT . he method we propose here is about partial shape matching and is based firstly on contour representation using the wavelet transform. A technique of sub matrix matching is the n used to match partial shapes. The representation is based on three steps, the contour is first parameterized by nclosed area, the affine invariant feature is then calculated to finally determine the natural axis which enabl e to fix the starting point. The knowledge of the orientation of the natural axis enables to adjust the sta rting point on the contour between the query and the models in a given database. Furthermore, the method can s elects a subset of useful invariant features for the matching step. A sub-matrix matching algorithm deve lop d by (Saber et al., 2005)is then used to determine correspondences for evaluation of partial simil arity between an example template and a candidate object region. The method is tested on a database of 5000 fish s pecie , and the results are very satisfactory.	algorithm;apache axis;computer vision;distortion;dyadic transformation;standard widget toolkit;stationary wavelet transform	El-hadi Zahzah	2008			multiresolution analysis;wavelet;constant q transform;s transform;harmonic wavelet transform;distance matrix;second-generation wavelet transform;short-time fourier transform;continuous wavelet transform;fractional fourier transform;discrete sine transform;discrete fourier transform;pattern recognition;cascade algorithm;affine transformation;geometry;wavelet packet decomposition;stationary wavelet transform;discrete fourier transform;discrete wavelet transform;fast wavelet transform;lifting scheme;wavelet transform	Vision	41.758736617659395	-59.23309422930082	96987
cb150440f3f0a78c1dad7173a58365806cf769f6	layered mean shift methods		Segmentation is one of the most discussed problems in image processing. Many various methods for image segmentation exist. The mean-shift method is one of them and it was widely developed in recent years and it is still being developed. In this paper, we propose a new method called Layered Mean Shift that uses multiple mean-shift segmentations with different bandwidths stacked for elimination of the over-segmentation problem and finding the most appropriate segment boundaries. This method effectively reduces the need for the use of large kernels in the mean-shift method. Therefore, it also significantly reduces the computational complexity.	bandwidth (signal processing);computational complexity theory;embedded system;image processing;image segmentation;mean shift;pixel;texture mapping	Milan Surkala;Karel Mozdren;Radovan Fusek;Eduard Sojka	2013		10.1007/978-3-642-38267-3_39	computer science;theoretical computer science;data mining;engineering drawing	Vision	52.79983407465326	-65.39203200555508	97166
e42a13d86f79168946ddde0fac221f87c4a95b85	finding image features associated with high aesthetic value by machine learning	evolutionary art;genetic art;feature extraction;feature selection	A major goal of evolutionary art is to get images of high aesthetic value. We assume that some features of images are associated with high aesthetic value and want to find them. We have taken two image databases that have been rated by humans, a photographic database and one of abstract images generated by evolutionary art software. We have computed 55 features for each database. We have extracted two categories of rankings, the lowest and the highest. Using feature extraction methods from machine learning we have identified the features most associated with differences. For the photographic images the key features are wavelet and texture features. For the abstract images the features are colour based features.	database;evolutionary art;feature extraction;graphic art software;machine learning;wavelet	Victor Ciesielski;Perry Barile;Karen Trist	2013		10.1007/978-3-642-36955-1_5	computer vision;computer science;machine learning;pattern recognition	AI	39.5812764570251	-62.224803292816986	97408
39098c6c2b365605b16ca9d5f67fc0df2c4fe8c4	spotting the details: the various facets of facial expressions		3D Morphable Models (MM) are a popular tool for analysis and synthesis of facial expressions. They represent plausible variations in facial shape and appearance within a low-dimensional parameter space. Fitted to a face scan, the model's parameters compactly encode its expression patterns. This expression code can be used, for instance, as a feature in automatic facial expression recognition. For accurate classification, an MM that can adequately represent the various characteristic facets and variants of each expression is necessary. Currently available MMs are limited in the diversity of expression patterns. We present a novel high-quality 3D Facial Expression Morphable Model built from a large-scale face database as a tool for expression analysis and synthesis. Establishment of accurate dense correspondence, up to finest skin features, enables a detailed statistical analysis of facial expressions. Various characteristic shape patterns are identified for each expression. The results of our analysis give rise to a new facial expression code. We demonstrate the advantages of such a code for the automatic recognition of expressions, and compare the accuracy of our classifier to state-of-the-art.	encode;parsing expression grammar	Carl Martin Grewe;Gabriel Le Roux;Sven-Kristofer Pilz;Stefan Zachow	2018	2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)	10.1109/FG.2018.00049	parameter space;spotting;expression (mathematics);facial expression;artificial intelligence;pattern recognition;computer science	Vision	41.1678167891373	-53.05520663160377	97434
2b4e778eeeb73574f747446236c8ecb5a887d9df	free-shaped object recognition method from partial views using weighted cone curvatures	modelizacion;object recognition;vision ordenador;base donnee;range data;image processing;operating conditions;extraction forme;database;object database;procesamiento imagen;base dato;courbure;reconnaissance objet;traitement image;computer vision;modelisation;condition operatoire;extraccion forma;cone;success rate;base donnee orientee objet;pattern recognition;curvatura;curvature;vision ordinateur;object oriented databases;reconnaissance forme;reconocimiento patron;condicion operatoria;modeling;pattern extraction;cono	This work presents a method for free-shaped object recognition from its partial views. Consecutive database reductions are achieved in three stages by using effective discriminant features. These features are extracted from the spherical mesh representation used to modeling the partial view and from the view range data itself. The used characteristics are global, which means that they can not represent the views univocally. However, their staged application allows the initial object database to be reduced to selecting just one candidate in the final stage with a high success rate. Yet, the most powerful search reduction is achieved in the first stage where the new Weighted Cone Curvature (WCC) parameter is processed. The work is devoted to describe the overall method making especial emphasis in the WCC feature and its application to partial views recognition. Results with real objects range data are also presented in the paper.	3d scanner;cone;discriminant;outline of object recognition;portal	Santiago Salamanca;Carlos Cerrada;Antonio Adán;José Antonio Cerrada;Miguel Adán	2005		10.1007/11578079_24	computer vision;systems modeling;cone;image processing;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;curvature	Vision	47.989676583902884	-59.635719746182176	97462
de895d3faf663adee7151fd4818ef7972a193087	an efficient fingerprint ridge distance estimation using typical image blocks		The average ridge distance of fingerprint images is a very important parameter for fingerprint image enhancement, which will greatly affect the performance of fingerprint recognition. A method of efficient ridge distance estimation based on typical image blocks is proposed. First, we obtain some typical candidate image blocks through the initial selection according to the orientation curvature of each block; Then better quality blocks from these candidate blocks are selected by taking quality strategy into account, while the remaining blocks are used to compute ridge distance using statistical window method; Finally, the average ridge distance is estimated through averaging several ridge distances in the remaining blocks. The experimental results show that our method is fast enough for real applications and is robust and reliable in estimating average fingerprint ridge distance.	fingerprint recognition;image editing;online and offline;principle of good enough;spectral density estimation;window function	Xuzhou Li;Dong Yang;Yilong Yin	2012		10.1007/978-3-642-33506-8_39	machine learning;pattern recognition;mathematics;statistics	Vision	46.62910687316334	-63.33981357942565	97479
af06c0bb64f7fddcba896619ec943cde561ba1fb	object-based sar image compression using vector quantization	image coding;neural nets;radar computing;variable rate;radar computing synthetic aperture radar radar imaging image coding vector quantisation radar target recognition neural nets;image coding vector quantization synthetic aperture radar object detection laboratories target recognition bandwidth satellite ground stations pulse modulation powders;target recognition;radar imaging;sar image;radar target recognition;vector quantizer;vector quantisation;backpropagation object based sar image compression vector quantization object plane based encoding method variable rate residual vq algorithm background information target recognition target classification lossy compression multiple object planes nonlinear neural network predictor layer segmentation software simulation;synthetic aperture radar	A simple and elegant algorithm is presented to encode images with rich content, which allows easy access to various objects. An object-plane-based encoding method for compression of synthetic aperture radar (SAR) imagery is developed, with different object planes for target classes and background. A variable-rate residual vector quantization (VQ) algorithm is developed to encode the background information. This algorithm is very powerful as indicated by the experimental results. The proposed coding scheme allows compression matched to the final application of the images, which in this case is target recognition and classification.	image compression;object-based language;vector quantization	Mahesh Venkatraman;Heesung Kwon;Nasser M. Nasrabadi	2000	IEEE Trans. Aerospace and Electronic Systems	10.1109/7.892656	computer vision;synthetic aperture radar;pattern recognition;mathematics;radar imaging;inverse synthetic aperture radar;vector quantization;artificial neural network;remote sensing	EDA	44.36745305601876	-63.31418716698932	97644
97857865e3d9c7e105682d3172a3729b453b03f1	new results on the theory of morphological filters by reconstruction	analisis imagen;filtering;mathematical morphology;filtrage;estimator robustness;morfologia matematica;image processing;funcion logica;filtrado;procesamiento imagen;traitement image;logical function;fonction logique;upper bound;reconstruction image;robustez estimador;reconstruccion imagen;image reconstruction;borne inferieure;image analysis;upper and lower bounds;borne superieure;analyse image;lower bound;cota superior;cota inferior;morphologie mathematique;robustesse estimateur	This paper treats the problem of establishing bounds for the morphological filter by reconstruction class. Morphological filters by reconstruction, which are composed of openings and closings by reconstruction, are useful filters for image processing because they do not introduce discontinuities. The main contributions of this paper are: (a) To establish when the combination of openings by reconstruction (or, respectively, of closings by reconstruction) is an opening by reconstruction (respectively a closing by reconstruction). (b) To establish, for any filter by reconstruction, upper and lower bounds that are, respectively, a closing by reconstruction and an opening by reconstruction. In addition, the paper investigates certain aspects of filters by reconstruction that possess a robustness property called strong property. Some dual and equivalent forms are introduced for a family of multi-level filters recently introduced. A significant side-result is to determine some instances of connected openings composed by openings and closings by reconstruction that are not openings by reconstruction (similarly for closings).		José Crespo;Victor Maojo	1998	Pattern Recognition	10.1016/S0031-3203(97)00062-9	computer vision;image analysis;image processing;computer science;artificial intelligence;mathematics;upper and lower bounds;algorithm	Vision	48.12372801481832	-64.15634202670667	97883
d4936b4068cdef94d9ab46dfdfeac04c79335fe7	registration of 3-d partial surface models using luminance and depth information	camera based depth information;textured surface models;3d euclidian distances;three dimensional objects;convergence;surface texture surface reconstruction cameras image reconstruction optical sensors stereo image processing computer graphics application software lapping merging;application software;computer graphics;degree of freedom;motion estimation;surface texture;indexing terms;surface reconstruction;three dimensional;computer graphic;degrees of freedom;image texture;luminance information;brightness;image reconstruction;image registration;surface model;stereo image processing;merging;overlapping partial models;depth information;optical flow;optical sensors;convergence image registration computer graphics motion estimation image texture merging brightness image sequences;motion estimation 3d partial surface model registration luminance information depth information textured surface models three dimensional objects computer graphics overlapping partial models merging camera based depth information stereo image processing optical flow quaternions 3d euclidian distances convergence degrees of freedom;3d partial surface model registration;cameras;quaternions;image sequences;lapping	Textured surface models of three-dimensional objects are gaining importance in computer graphics applications. These models often have to be merged from several overlapping partial models which have to be registered (i.e. the relative transformation between the partial models has to be determined) prior to the merging process. In this paper a method is presented that makes use of both camera-based depth information (e.g. from stereo) and the luminance image. The luminance information is exploited to determine corresponding point sets on the partial surfaces using an optical flow approach. Quaternions are then employed to determine the transformation between the partial models which minimizes the sum of the 3-D Euclidian distances between the corresponding point sets. In order to find corresponding points on the partial surfaces luminance information is linearized. The procedure is iterated until convergence is reached. In contrast to only using depth information, employing luminance speeds up convergence and reduces remaining degrees of freedom (e.g. when registering sphere-like shapes). Index Terms motion estimation, image registration, range, intensity, 3D	computer graphics;image registration;iteration;motion estimation;optical flow;texture filtering	Sebastian Weik	1997		10.1109/IM.1997.603853	computer vision;computer science;mathematics;degrees of freedom;computer graphics (images)	Vision	52.98383464241376	-54.60080479899941	97958
53b3aab9b300ea708212271b214bd3d094d7806b	collaborative visual tracking of multiple identical targets	networks;metodo monte carlo;high dimensionality;modelo markov;video signal processing;simulacion numerica;cible multiple;aproximacion campo medio;methode monte carlo;blanco multiple;probabilistic approach;state estimation;linear complexity;multiple target tracking;markov model;optical tracking;enfoque probabilista;approche probabiliste;monte carlo method;variational analysis;simulation numerique;poursuite cible;combinatorial complexity;traitement signal video;markov network;multiple target;approximation champ moyen;state space representation;modele markov;video;target tracking;mean field approximation;visual tracking;theoretical foundation;acquisition tracking and pointing;numerical simulation	Multiple target tracking in video is an important problem in many emerging applications. It is also a challenging problem, where the coalescence phenomenon often happens, meaning the tracker associates more than one trajectories to some targets while loses track for others. This coalescence may result in the failure of tracker, especially when similar targets move close or present partial or complete occlusions. Existing approaches are mainly based on joint state space representation of the multiple targets being tracked, therefore confronted by the combinatorial complexity due to the nature of the intrinsic high dimensionality. In this paper, we propose a novel distributed framework with linear complexity to this problem. The basic idea is a collaborative inference mechanism, where the estimate of each individual target state is not only determined by its own observation and dynamics, but also through the interaction and collaboration with the state estimates of other targets, which finally leads to a competition mechanism that enables different but spatial adjacent targets to compete for the common image observations. The theoretical foundation of the new approach is based on a well designed Markov network, where the structure configuration in this network can change with time. In order to inference from such a Markov network, a probabilistic variational analysis of this Markov network is conducted and reveals a mean field approximation to the posterior density of each target, therefore provides a computationally efficient way for such a difficult inference problem. Compared with the existing solutions, the proposed new approach stands out by its linear computational cost and excellent performance achieved to deal with the coalescence problem, as pronounced in the extensive experiments.	algorithmic efficiency;approximation;bittorrent tracker;coalescing (computer science);computation;experiment;markov chain;markov random field;state-space representation;variational analysis;video tracking	Ting Yu;Ying Wu	2005		10.1117/12.586914	econometrics;simulation;artificial intelligence;mathematics	AI	47.755435052719314	-56.35916101375007	98030
38b25ca3dee931c19f4d11146a3687ae69fbd68d	quadric surface extraction by variational shape approximation	quadric surface fitting;calculo de variaciones;vision ordenador;image processing;conference_paper;graph method;shape approximation;surface fitting;procesamiento imagen;quadrico;metric;segmentation;metodo grafo;traitement image;methode graphe;quadrique;computer vision;sphere;calcul variationnel;quadrics;graph cut;variational surface approximation;pattern recognition;metrico;vision ordinateur;cylindre circulaire;esfera;reconnaissance forme;variational method;reconocimiento patron;circular cylinder;cilindro circular;variational calculus;metrique;surface approximation	Based on Lloyd iteration, we present a variational method for extracting general quadric surfaces from a 3D mesh surface. This work extends the previous variational methods that extract only planes or special types of quadrics, i.e., spheres and circular cylinders. Instead of using the exact L error metric, we use a new approximate L error metric to make our method more efficient for computing with general quadrics. Furthermore, a method based on graph cut is proposed to smooth irregular boundary curves between segmented regions, which greatly improves the final results.	approximation algorithm;calculus of variations;cut (graph theory);graph cuts in computer vision;iteration;variational principle	Dong-Ming Yan;Yang Liu;Wenping Wang	2006		10.1007/11802914_6	computer vision;mathematical optimization;quadric;topology;cut;metric;image processing;variational method;mathematics;geometry;segmentation;sphere;calculus of variations	Graphics	50.06325797584897	-60.797276642847706	98527
91f296a41738bdffca34ba475b5874a5c6f13af5	graph-based global optimization for the registration of a set of images	graph theory;teoria grafo;image processing;camino grafo;graph path;procesamiento imagen;image multiple;optimum global;imagen multiple;global optimum;theorie graphe;traitement image;multiple image;registro imagen;recalage image;panoramic imaging;image registration;chemin graphe;global registration;global optimization;panoramic image;image mosaics;optimo global;image mosaicing	In this paper, we introduce a fast and efficient global registration technique in photo-stitching, in which, the layout of the set of images has multiple rows and columns. The proposed algorithm uses a graph based model to deal with the problem of global registration. By using alternative path from the graph containing the image layout, it is possible to align the images against the reference image when pair-wise registration fails.	global optimization	Hui Zhou	2006		10.1007/11949534_122	computer vision;topology;image processing;image registration;graph theory;mathematics;geometry;global optimum;global optimization	Vision	50.315802148049585	-55.52144865249161	98676
f40767ee174caa01eb0fd09bfcbf703f7ab50dd5	automatic computation of histogram threshold for lip segmentation using feedback of shape information		Threshold-based segmentation methods provide a simple and efficient way to implement lip segmentation. However, automatic computation of robust thresholds presents a major challenge. This research proposes an adaptive method for selecting the histogram threshold, based on feedback of shape information. The proposed method reduces unnecessary overhead by first comparing the initial segmentation to a reference lip shape model to decide if optimisation is required. In cases where optimisation is required, the algorithm adjusts the threshold until the segmentation is sufficiently similar to a reference shape model. The algorithm is tested on the AR Face Database by comparing the segmentation accuracy before and after optimisation. The proposedmethod increases the number of segmentations classified as ‘good’ (overlap above 90%) by 7.1% absolute, and significantly improves the segmentation in challenging cases containing facial hair.	adaptive filter;algorithm;computation;ground truth;mathematical optimization;overhead (computing);reference model	Ashley D. Gritzman;Vered Aharonson;David M. Rubin;Adam Pantanowitz	2016	Signal, Image and Video Processing	10.1007/s11760-015-0834-9	computer vision;computer science;machine learning;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation	Vision	44.25754557279387	-65.165793964245	98783
85e53b496b0bd2968622e8f6b1337a581d0aeb5a	mesh segmentation via spectral embedding and contour analysis	solid;and object representations;surface;mesh segmentation;i 3 5 computational geometry and object modeling curve	We propose a mesh segmentation algorithm via recursive bisection where at each step, a sub-mesh embedded in 3D is first spectrally projected into the plane and then a contour is extracted from the planar embedding. We rely on two operators to compute the projection: the well-known graph Laplacian and a geometric operator designed to emphasize concavity. The two embeddings reveal distinctive shape semantics of the 3D model and complement each other in capturing the structural or geometrical aspect of a segmentation. Transforming the shape analysis problem to the 2D domain also facilitates our segmentability analysis and sampling tasks. We propose a novel measure of the segmentability of a shape, which is used as the stopping criterion for our segmentation. The measure is derived from simple areaand perimeter-based convexity measures. We achieve invariance to shape bending through multi-dimensional scaling (MDS) based on the notion of inner distance. We also utilize inner distances to develop a novel sampling scheme to extract two samples along a contour which correspond to two vertices residing on different parts of the sub-mesh. The two samples are used to derive a spectral linear ordering of the mesh faces. We obtain a final cut via a linear search over the face sequence based on part salience, where a choice of weights for different factors of part salience is guided by the result from segmentability analysis.	approximation algorithm;benchmark (computing);concave function;contour line;convex function;embedded system;image scaling;laplacian matrix;linear search;multidimensional scaling;norm (social);perimeter;planar graph;recursion;sampling (signal processing);shape analysis (digital geometry);turing test;whole earth 'lectronic link	Rong Liu;Hao Zhang	2007	Comput. Graph. Forum	10.1111/j.1467-8659.2007.01061.x	computer vision;mathematical optimization;topology;mathematics;geometry;solid;scale-space segmentation;surface	Vision	50.05608246763852	-62.76575931634475	98954
65cd50ede1528e8fefee2929f628387ea96e2e0a	automatic street graph construction in sketch maps	graph matching;ground truth	In this paper we present an algorithm for automatic street graph construction of hand-drawn sketch maps. This detection is important for a subsequent graph matching in order to align the sketch map with another map. Our algorithm detects a number of street candidates and selects street lines by rating the candidates and their neighbors in the street candidate graph. To evaluate this approach, we manually generated a ground truth for some maps and conducted a preliminary quantitative performance study.	map	Klaus Broelemann;Xiaoyi Jiang;Angela Schwering	2011		10.1007/978-3-642-20844-7_28	computer vision;computer science;machine learning;cartography	Crypto	44.21331710930031	-56.274344384717345	98991
96cf843ba6a3e1e7d0cf63ed84111ebf50c7786a	robust lip contour extraction using separability of multi-dimensional distributions	mouth;feature extraction edge detection;robustness image edge detection skin active contours face detection research and development shape mouth man machine systems image analysis;edge detection;skin;active contours;active contour model robust lip contour extraction multidimensional distributions separability color intensity distributions outer lip contour gray scale intensity edge detection method;robust lip contour extraction;multi dimensional;color intensity distributions;research and development;shape;image edge detection;feature extraction;edge detection method;gray scale intensity;robustness;image analysis;outer lip contour;multidimensional distributions separability;face detection;man machine systems;extraction method;active contour model	We present a lip contour extraction method using separability of color intensity distributions. Usually it is difficult to robustly extract the outer lip contour mainly because of the following two problems. First, the outer lip contour is often blurred. Secondly, the contrast between the skin and the lip region is often reduced by transformation from the color intensity to the gray scale intensity. To overcome these two problems we propose an edge detection method in which edge strength is defined as separability of two color intensity distributions. We apply the proposed method to lip contour extraction using an active contour model. We present several experimental results demonstrating the effectiveness of the proposed method.	active contour model;color;contour line;edge detection;grayscale;linear discriminant analysis;linear separability;regular expression	Tomokazu Wakasugi;Masahide Nishiura;Kazuhiro Fukui	2004	Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.	10.1109/AFGR.2004.1301568	computer vision;face detection;image analysis;speech recognition;edge detection;feature extraction;shape;computer science;pattern recognition;active contour model;skin;robustness	Vision	39.812358930404365	-63.23043416483658	99057
7bffc3deb6dd712701dadae19ef4653632fa11ca	mirror symmetry histograms for capturing geometric properties in images	histograms mirrors embryo shape accuracy motion pictures equations;biology histogram mirror symmetry geometric representation cell circle fitting hough transform;geometric representation;circle fitting;cell;object detection image classification;biology;mirror symmetry;histogram;supervised classification mirror symmetry coefficient histograms data structure global geometric properties 6 dimensional histogram hmsc nearly circular cell detection reflection symmetry cell division detection worm tips detection histogram related methods;hough transform	We propose a data structure that captures global geometric properties in images: Histogram of Mirror Symmetry Coefficients. We compute such a coefficient for every pair of pixels, and group them in a 6-dimensional histogram. By marginalizing the HMSC in various ways, we develop algorithms for a range of applications: detection of nearly-circular cells, location of the main axis of reflection symmetry, detection of cell-division in movies of developing embryos, detection of worm-tips and indirect cell-counting via supervised classification. Our approach generalizes a series of histogram-related methods, and the proposed algorithms perform with state-of-the-art accuracy.	algorithm;apache axis;coefficient;data structure;histogram equalization;machine learning;pixel;supervised learning	Marcelo Cicconet;Davi Geiger;Kristin C. Gunsalus;Michael Werman	2014	2014 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2014.381	hough transform;cell;computer vision;combinatorics;histogram matching;histogram;mathematics;geometry;statistics;image histogram;mirror symmetry	Vision	45.57851611783856	-55.04065095521348	99135
f6899aa29a3273a1376ffabd0c2f12f2bf331f28	multi-focus image fusion by local optimization over sliding windows		This article presents a technique to solve the problem of multi-focus image fusion. This technique is based on the maximization of a linear function with spatial coherence constraints. The final fused image is computed as the sum of the source images using a segmentation map. We can compute the segmentation map using the Simplex method, where the objective function includes one variable associated with each pixel. The Simplex method requires a huge amount of memory resources to produce it. We present an algorithm called CPW-S, which uses some strategies to solve the problem in a context with fewer variables; images are split into regions, thus reducing the computational effort. We present results for two pairs of synthetic images in order to quantify the results, obtaining more than (98%) of pixel accuracy for the segmentation map. We also present results for several pairs of real images (widely used in the literature) and a triad of multi-focus images. The resulting fused images are qualitatively good for all the real images included in the experiments.	image fusion;local search (optimization);mathematical optimization;microsoft windows	Adan Garnica-Carrillo;Félix Calderón;Juan J. Flores	2018	Signal, Image and Video Processing	10.1007/s11760-017-1229-x	computer vision;pixel;image segmentation;artificial intelligence;linear function;local search (optimization);linear programming;pattern recognition;mathematics;real image;image fusion;simplex algorithm	EDA	53.33613218223323	-59.30314692933656	99408
2fdb27b6f61077cb99764268fe6c4e9df2689783	a short- time beltrami kernel for smoothing images and manifolds	bilateral filtering;traitement signal;image manifold smoothing;kernel;image processing;methode noyau;ecuacion calor;data smoothing;convolution;implementation;regular 2d image smoothing;tensors convolution image denoising image enhancement smoothing methods;denoising properties;procesamiento imagen;image enhancing flow;indexing terms;metric tensor;traitement image;reduccion ruido;convolution equation;image enhancement;smoothing methods;numerical scheme;heat equation;smoothing;signal processing;noise reduction;methode lissage;metodo nucleo;reduction bruit;gaussian kernel;lissage donnees;equation convolution;kernel smoothing methods space heating filters noise reduction equations convolution geometry tensile stress image processing;kernel method;image denoising;bilateral filter;smoothing beltrami diffusion images kernel manifold;short time beltrami kernel;euclidean approximation;implementacion;ecuacion convolucion;procesamiento senal;alisadura datos;diffusion;images;beltrami;metric tensor short time beltrami kernel regular 2d image smoothing image enhancing flow space dependent kernel image manifold smoothing bilateral filter euclidean approximation denoising properties;space dependent kernel;equation chaleur;manifold;algorithms artificial intelligence image enhancement image interpretation computer assisted numerical analysis computer assisted pattern recognition automated;tensors	"""We introduce a short-time kernel for the Beltrami image enhancing flow. The flow is implemented by """"convolving"""" the image with a space dependent kernel in a similar fashion to the solution of the heat equation by a convolution with a Gaussian kernel. The kernel is appropriate for smoothing regular (flat) 2-D images, for smoothing images painted on manifolds, and for simultaneously smoothing images and the manifolds they are painted on. The kernel combines the geometry of the image and that of the manifold into one metric tensor, thus enabling a natural unified approach for the manipulation of both. Additionally, the derivation of the kernel gives a better geometrical understanding of the Beltrami flow and shows that the bilateral filter is a Euclidean approximation of it. On a practical level, the use of the kernel allows arbitrarily large time steps as opposed to the existing explicit numerical schemes for the Beltrami flow. In addition, the kernel works with equal ease on regular 2-D images and on images painted on parametric or triangulated manifolds. We demonstrate the denoising properties of the kernel by applying it to various types of images and manifolds"""	approximation;apricot kernel oil;bilateral filter;convolution;derivation procedure;kernel (operating system);noise reduction;normal statistical distribution;numerical analysis;smoothing (statistical technique);manifold	Alon Spira;Ron Kimmel;Nir A. Sochen	2007	IEEE Transactions on Image Processing	10.1109/TIP.2007.894253	poisson kernel;computer vision;mathematical optimization;kernel embedding of distributions;topology;radial basis function kernel;image processing;kernel principal component analysis;computer science;signal processing;free boundary condition;mathematics;geometry;bilateral filter;kernel;variable kernel density estimation;polynomial kernel;smoothing;kernel smoother	Vision	52.0663972515711	-62.71968086511452	99489
7bf528c69ca0938d063d1bf91b30c26ad54d3718	mrf-based motion segmentation exploiting a 2d motion model robust estimation	affine one;true motion field;image segmentation;robust estimator;image resolution;image sequences mrf based motion segmentation 2d motion model robust estimation image regions homogeneous motion 2d polynomial model affine one true motion field motion models multiresolution robust estimator statistical regularization boundaries multiscale markov random field mrf modeling detection step estimated models;mrf based motion segmentation;markov random fields;motion estimation;detection step;polynomials;multiresolution robust estimator;markov random field;computer vision;statistical regularization;boundaries;motion segmentation;statistical analysis;estimated models;mrf modeling;homogeneous motion;image sequence;random processes;multiscale markov random field;2d polynomial model;time of arrival estimation;image regions;motion models;robustness;markov processes;statistical analysis markov processes random processes image sequences image segmentation motion estimation image resolution;2d motion model robust estimation;motion detection;motion segmentation computer vision robustness motion estimation time of arrival estimation polynomials markov random fields object detection motion detection image segmentation;object detection;image sequences	"""This paper is dealing with motion-segmentation, that is, with the partitioning of the image into regions of homogeneous motion. Here, homogeneous means that in each region a 2D polynomial model (e.g. an aane one) is able to describe at each location the underlying \true"""" motion with a predeened precision. However, no estimation of this true motion eld is required. The motion models are computed using a multiresolution robust estimator 1]. Therefore, as opposed to almost all other motion-segmentation scheme (for instance 2, 3]), the motion model of a given region only needs to be estimated once at a given time instant. Moreover, the determination of the boundaries between the diierent regions, which is stated as a statistical regulariza-tion based on a multiscale Markov Random Field (MRF) modeling, only requires one pass. Finally, thanks to the deenition of an explicit detection step of areas where the error between the underlying motion and the one given by the estimated models is not whithin the precision , we are able to get a good segmentation from the very beginning of the sequence, and to manage the appearance of new objects in the scene, as well as the momentary increase in complexity of motion in already existing regions. Results obtained on many real image sequences have validated our approach."""	markov chain;markov random field;multiresolution analysis;polynomial	Jean-Marc Odobez;Patrick Bouthemy	1995		10.1109/ICIP.1995.537713	stochastic process;robust statistics;computer vision;mathematical optimization;structure from motion;image resolution;quarter-pixel motion;computer science;pattern recognition;motion estimation;mathematics;image segmentation;markov process;motion field;personal boundaries;statistics;robustness;polynomial	Vision	49.260497631142925	-52.465856206577705	99562
cd1568abc35f8bf6a38a4bd92029b63c98cfbcae	groupwise construction of appearance models using piece-wise affine deformations	group wise registration	We describe an algorithm for obtaining correspondences across a group of images of deformable objects. The approach is to construct a statistical model of appearance which can encode the training images as compactly as possible (a Minimum Description Length framework). Correspondences are defined by piece-wise linear interpolation between a set of control points defined on each image. Given such points a model can be constructed, which can approximate every image in the set. The description length encodes the cost of the model, the parameters and most importantly, the residuals not explained by the model. By modifying the positions of the control points we can optimise the description length, leading to good correspondence. We describe the algorithm in detail and give examples of its application to MR brain images and to faces. We also describe experiments which use a recently-introduced specificity measure to evaluate the performance of different components of the algorithm.	approximation algorithm;control point (mathematics);encode;experiment;linear interpolation;minimum description length;sensitivity and specificity;statistical model	Timothy F. Cootes;Carole J. Twining;Vladimir S. Petrovic;Roy Schestowitz;Christopher J. Taylor	2005		10.5244/C.19.88	computer vision;discrete mathematics;computer science;mathematics;geometry	Vision	47.2855483284422	-52.81697478513553	99700
8eecd57bd2e9b4408e8c8ec90b25af99378d1b87	a probabilistic neural networks system to recognize 3d face of people	reconnaissance visage;3d face recognition;settore inf 01 informatica;image processing;modelo 3 dimensiones;facies;systeme aide decision;modele 3 dimensions;procesamiento imagen;three dimensional model;posterior probability;sistema ayuda decision;prise decision;probabilistic approach;traitement image;decision support system;face recognition;enfoque probabilista;approche probabiliste;probabilite a posteriori;probabilidad a posteriori;pattern recognition;graphical model;arquitectura modular;reconnaissance forme;reseau neuronal;reconocimiento patron;toma decision;probabilistic neural network;modular architecture;red neuronal;architecture modulaire;neural network	In this paper we describe a 3d face recognition system based on neural networks. The system consists of a modular architecture in which a set of probabilistic neural networks cooperate with the associated graphical models in recognising target people. The logic of this cooperation is quite simple: each network is able to discriminate between its target and all other samples of the training set. This is done by using only one characteristic piece of information among the available sets of L, U, V colours and Z coordinate. Every network provides its associated graph with estimates obtained during the training phase, while graphical models coordinate the answers of all the associated networks giving the posterior probability that the target corresponds to the person to be recognised. Then a decision-making criterium based on the maximum posterior probability is established to identify the recognised face.	artificial neural network	Giancarlo Mauri;Italo Zoppis	2003		10.1007/978-3-540-45216-4_17	probabilistic neural network;facies;decision support system;image processing;computer science;artificial intelligence;machine learning;graphical model;posterior probability;artificial neural network	HCI	47.064106811739144	-58.99053822044382	99701
75652f16969eb0a6f86e0401582e109e49c161e3	relevance feedback in content-based image retrieval system by selective region growing in the feature space	evaluation performance;performance evaluation;image processing;content based image retrieval cbir;recherche image;query image;evaluacion prestacion;procesamiento imagen;feature space;traitement image;algorithme;feature vector;algorithm;retroaccion;retroaction;feature extraction;feedback regulation;extraction caracteristique;content based image retrieval;region growing;data structure;relevance feedback;content based retrieval;recherche par contenu;algoritmo;image retrieval	This paper proposes a relevance feedback algorithm for the content-based image retrieval system. In the conventional algorithms, the weights of feature vectors are adjusted based on the user’s feedback, which warps the match region from the hyper-sphere to hyper-ellipsoidal shape. That is, the axis grows into the direction that covers more relevant images in the feature space. The proposed algorithm is not based on the adjustment of the weights, but on the generation of new match region based on the user’s feedback. Specifically, new spheres centered at the relevant images are generated, the radius of which are determined by the number of neighboring relevant and irrelevant images. The overall match region is the union of all the spheres generated and modified at each iteration of feedback process. As a result, the match region grows in a bubble shape into the direction where there are more relevant images. The resulting match region can cover arbitrarily shaped clusters whereas the weight updating approach can cover only hyper-ellipsoidal region. We also propose a data structure that keeps the history of past searches, for more rapid expansion of match region. r 2003 Elsevier B.V. All rights reserved.	algorithm;bonsai;content-based image retrieval;dvd region code;data structure;emoticon;feature vector;iteration;optic axis of a crystal;pebble smartwatch;region growing;relevance feedback	Jung Won Kwak;Nam Ik Cho	2003	Sig. Proc.: Image Comm.	10.1016/S0923-5965(03)00067-5	computer vision;feature vector;data structure;image processing;image retrieval;computer science;machine learning;pattern recognition;information retrieval	Vision	43.53051191831431	-62.056755577334954	99745
18e20ed8803be27684c700fb5383a0958eb3c2e3	fast curvilinear structure extraction and delineation using density estimation	algorithme rapide;analisis imagen;vision ordenador;adaptability;adaptabilite;lwf;medicion densidad;estimacion densidad;density measurement;binary image;methode noyau;edge detection;small object detector;estimation densite;real time;real time processing;line detection;adaptabilidad;processing time;computer vision;deteccion contorno;detection contour;density estimation;senal video;signal video;object oriented;fast algorithm;temps reel;metodo nucleo;image binaire;imagen binaria;video signal;tiempo real;temps traitement;oriente objet;mesure densite;kernel method;image analysis;vision ordinateur;analyse image;orientado objeto;tiempo proceso;algoritmo rapido;centerline detector	Detection and delineation of lines is important for many applications. However, most of the existing algorithms have the shortcoming of high computational cost and can not meet the on-board real-time processing requirement. This paper presents a novel method for curvilinear structure extraction and delineation by using kernel-based density estimation. The method is based on efficient calculation of pixel-wise density estimation for an input feature image, which is termed as local weighted features (LWF). For gray and binary images, the LWF can be efficiently calculated by integral image and accumulated image, respectively. Detectors for small objects and centerlines based on LWF are developed and the selection of density estimation kernels is also illustrated. The algorithm is very fast and achieves 50 fps on a PIV2.4G processor. Evaluation results on a number of images and videos are given to demonstrate the satisfactory performances of the proposed method with its high stability and adaptability. 2009 Elsevier Inc. All rights reserved.	algorithm;algorithmic efficiency;background subtraction;binary image;circular analysis;coalition for patent fairness;computation;edge detection;emoticon;feature detection (computer vision);feature detection (web development);general protection fault;geographic information system;image processing;line fitting;on-board data handling;performance;pixel;real-time transcription;unmanned aerial vehicle	Shuxiao Li;Hongxing Chang;Cheng-Fei Zhu	2009	Computer Vision and Image Understanding	10.1016/j.cviu.2009.01.003	computer vision;kernel method;adaptability;image analysis;density estimation;edge detection;binary image;computer science;object-oriented programming;computer graphics (images)	Vision	47.93978697372588	-57.464490423425886	99807
f6771214a27cc61f3e882c6241cb4d59811be268	the effect of noise on edge orientation computations	edge orientation computation;generalised hough transform;edge detection;‘circular’ operators;impulse noise;object location;edge orientation;industrial automation;gaussian noise	This paper studies the effect of image noise on edge orientation computations. It is found that noise affects estimation of edge orientation in a complex way, but this is simplified for those ‘circular’ operators which act in a strictly vectorial manner. In that case the distribution of edge orientations is closely gaussian for gaussian image noise. These results have important consequences for object location schemes based on the generalised Hough transform - especially when noise is high or contrast is low. Suprisingly, the consequences are much less serious with impulse noise.	computation	Edward Roy Davies	1987	Pattern Recognition Letters	10.1016/0167-8655(87)90014-6	gradient noise;gaussian noise;additive white gaussian noise;computer vision;mathematical optimization;value noise;mathematics;geometry	Vision	53.447233436122744	-64.89516605384428	99883
f66eda6e85c23815083a991a5e4451422a787758	probability approximation using best-tree distribution for skin detection	modelizacion;bayesian network;skin detection;vision ordenador;base donnee;piel;image processing;best approximation;peau;structure arborescente;loi conjointe;approximation algorithm;skin;database;procesamiento imagen;base dato;intelligence artificielle;probabilistic approach;traitement image;receiver operating characteristic curve;computer vision;modelisation;reseau bayes;receiver operating characteristic curves;red bayes;estructura arborescente;enfoque probabilista;approche probabiliste;tree structure;algoritmo aproximacion;distributed models;bayes network;ley conjunta;human skin;mejor aproximacion;artificial intelligence;vision ordinateur;inteligencia artificial;metodo roc;algorithme approximation;methode roc;modeling;joint distribution;meilleure approximation	Skin detection consists in detecting human skin pixels from an image. In this paper we propose a new skin detection algorithm based on approximation of an image patch joint distribution, called Best-Tree distribution. A tree distribution model is more general than a bayesian network one. It can represent a joint distribution in an intuitive and efficient way. We assess the performance of our method on the Compaq database by measuring the Receiver Operating Characteristic curve and its under area. These measures have proved better performances of our model than the baseline one.	algorithm;approximation;baseline (configuration management);bayesian network;performance;pixel;sensor	Sanaa El Fkihi;Mohamed Daoudi;Driss Aboutajdine	2006		10.1007/11864349_70	computer vision;econometrics;image processing;computer science;artificial intelligence;machine learning;bayesian network;mathematics;approximation algorithm;statistics	Vision	45.1852574898434	-61.80469116935428	100060
5cfe8e631f05453e10e7c01e329159be903837ed	a novel detection method of paper defects based on visual attention mechanism	saliency map;visual attention mechanism;paper defects;watershed segmentation;defect detection	"""In this paper, an improved paper defects detection method based on visual attention mechanism computation model is presented. First, multi-scale feature maps are extracted by linear filtering. Second, the comparative maps are obtained by carrying out center-surround difference operator. Third, the saliency map is obtained by combining conspicuity maps, which is gained by combining the multi-scale comparative maps. Last, the seed point of watershed segmentation is determined by competition among salient points in the saliency map and the defect regions are segmented from the background. Experimental results show the efficiency of the approach for paper defects detection. DOI: 10.4018/japuc.2011070103 International Journal of Advanced Pervasive and Ubiquitous Computing, 3(3), 24-31, July-September 2011 25 Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. cessing technologies, inspection systems can locate the position of paper defect and classify the type of it. The research on defect detection technique is now focused on the intelligent on-line measurement, whose purpose is to develop a machine vision system to realize exact detection and localization of defects with a fast and effective algorithm. Existing methods (Newman, 1995; Sezgin & Sankur, 2004; Iivarinen, Heikkinen, Rauhamaa, Vuorimaa, & Visa, 2000; Iivarinen, 2000; Brzakovic, Vujovic, & Liakopoulos, 1995) mainly fall into three types: thresholding method, morphological method and grey level statistics method. The threshold method sets up different thresholds to different paper defects. Morphological method defects the edge of paper defects with eroded and expanded edge detector. Grey level statistics method detects paper defects with the statistical characteristics of the image of paper defects. From the fewer reports of modern web inspection systems, one can concludes that thresholding method is the main algorithm in paper defect detection system. Thresholding methods, which are mainly associated with uniform web materials, is to separate the defect regions from the uniform background by using the segmentation threshold. The segmentation threshold takes an important role in the process, which is usually selected on the basis of statistics to the background with the application domain. An important assumption in this process is that the statistics of defect-free regions are stationary, and these regions extend over a significant portion of inspection images. In real applications, the paper products usually have different texture structure (Tsai & Huang, 2003) such as uniform structure, random structure and patterned structure. Therefore, the segmentation threshold needs to be re-determined because of the difference of texture structures, which has great limitation to the defect detection system in real applications. Usually, it is the defect regions (e.g., holes, stains) not the texture attracts the attention firstly when we observe it because the defect regions are more conspicuity or saliency than the background. Therefore, how to find these attractive regions and separate them from the defect-free background accurately and rapidly is the key problem for paper manufacturing, which can help to ensure the high quality of paper and improve the producing efficiency of the factories. In this paper, we presented a new segmentation method based on visual attention mechanism (Desimone & Duncan, 1995; Kastner & Ungerleider, 2000) to separate the defect regions from the background. The aim of the study presented in this paper is to achieve robust detection of paper defects by using visual attention mechanism. The emphasis of our work is to make the visual inspection system detect defects rapidly, accurately and robustly. 2. THE PROPOSED METHOD DESCRIPTION Psychophysical and physiological evidence indicates that primates and humans have a remarkable ability to interpret complex scenes in real time, despite the limited speed of the neuronal hardware available for such tasks. A number studies concerning the detection, localization, and recognition of objects in the visual field have suggested a two-stage theory of human visual perception. The first stage is the “preattentive” mode, in which simple features are processed rapidly and in parallel over the entire visual field. In the second mode, “attentive” mode, a specialized processing focus, usually called FOA, is directed to particular locations in the visual field. This processing mechanism of human visual system is called visual attention mechanism (Desimone & Duncan, 1995; Kastner & Ungerleider, 2000). Inspired by the research results on the human visual system, Tsotsos, Culhane, Wai, Lai, Davis, and Nuflo (1995), Niebur and Koch (1998), Koch and Ullman (1995), and Itti, Koch, and Niebur (1998). etc., have proposed some calculation models by simulating the HVS, which are called bottom-up visual attention mechanism (BUVAM) com6 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/novel-detection-method-paperdefects/64315?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Communications and Social Science, InfoSciTechnology Adoption, Ethics, and Human Computer Interaction eJournal Collection, InfoSci-Artificial Intelligence and Smart Computing eJournal Collection, InfoSci-Computer Systems and Software Engineering eJournal Collection, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	finite difference;map;model of computation;software bug;watershed (image processing)	Ping Jiang;Tao Gao	2011	IJAPUC	10.4018/japuc.2011070103	computer vision;watershed;computer science;machine learning	AI	45.79547817541436	-65.82780823403391	100148
a6f25862658c499257d0eb2ae74dc44e9ffec80a	automatic image semantic segmentation by mrf with transformation-invariant shape priors		Shape priors has greatly enhanced low-level driven image segmentations, however existing graph cut based segmentation methods still restrict to pre-aligned shape priors. The major contribution of this paper is to incorporate transformation-invariant shape priors into the graph cut algorithm for automatic image segmentations. The expectation of shape transformation and image knowledge are encoded into energy functions that is optimized in a MRF maximum likelihood framework using the expectation-maximization. The iteratively updated expectation process improves the segmentation robustness. In turn, the maximum likelihood segmentation is realized integrally by casting the lower-bound of energy function in a graph structure that can be effectively optimized by graph-cuts algorithm in order to achieve a global solution and also increase the accuracy of the probabilities measurement. Finally, experimental results demonstrate the potentials of our method under conditions of noises, clutters, and incomplete occlusions.	markov random field	Peng Tang;Weidong Jin	2016		10.1007/978-981-10-2663-8_23	computer vision;scale-space segmentation	Vision	45.05276143357143	-52.39631211204924	100176
274c6ec7831b17d5badbf8e808bd398931f0da24	3d reconstruction of periodic motion from a single view	motion analysis;movimiento periodico;image tridimensionnelle;image recognition;reconocimiento imagen;vision ordenador;mouvement corporel;estimation mouvement;image processing;estimacion movimiento;gait;angle observation;procesamiento imagen;viewing angle;analyse mouvement;motion estimation;marcha;periodicite;traitement image;multiple views;mouvement periodique;computer vision;multiple view;feasibility;periodicity;single view 3d reconstruction;posture;reconstruction image;periodicidad;reconstruccion imagen;image reconstruction;postura;reconnaissance image;gait analysis;human motion analysis;periodic motion;vue multiple;tridimensional image;vision ordinateur;angulo observacion;analisis movimiento;resolubilite;movimiento corporal;allure;solvability;practicabilidad;body movement;faisabilite;3d reconstruction;imagen tridimensional;vista multiple;resolubilidad;activity recognition	Periodicity has been recognized as an important cue for tasks like activity recognition and gait analysis. However, most existing techniques analyze periodic motions only in image coordinates, making them very dependent on the viewing angle. In this paper we show that it is possible to reconstruct a periodic trajectory in 3D given only its appearance in image coordinates from a single camera view. We draw a strong analogy between this problem and that of reconstructing an object from multiple views, which allows us to rely on well-known theoretical results from the multi-view geometry domain and obtain significant guarantees regarding the solvability of the estimation problem. We present two different formulations of the problem, along with techniques for performing the reconstruction in both cases, and an algorithm for estimating the period of motion from its image-coordinate trajectory. Experimental results demonstrate the feasibility of the proposed techniques.	3d reconstruction;activity recognition;algorithm;computer vision;free viewpoint television;gait analysis;kinesiology;programming paradigm;quasiperiodicity;reprojection error;stationary process;viewing angle;virtual reality headset	Evan Ribnick;Nikolaos Papanikolopoulos	2010	International Journal of Computer Vision	10.1007/s11263-010-0334-x	3d reconstruction;iterative reconstruction;periodic function;computer vision;gait analysis;image processing;computer science;motion estimation;gait;computer graphics (images);activity recognition	Vision	49.668672590889635	-56.508451975589935	100185
cd08c99739a180dc49daf206efd521189b239f75	a robust, correspondenceless, translation-determining algorithm	analisis imagen;objet;vision ordenador;center of mass;espacio 3 dimensiones;object;correspondence problem;movie camera;robotics;experimental result;computer vision;algorithme;algorithm;camara;theoretical analysis;espace 3 dimensions;movimiento traslacion;three dimensional space;resultado experimental;robotica;mouvement translation;image analysis;vision ordinateur;robotique;resultat experimental;translation motion;analyse image;objeto;camera;algoritmo	A method is presentedfor the recovery of the three-dimen sional translation of a rigtdly translating object. The novelty of the method consists of the fact that four cameras are used in order to avoid the solution of the correspondence problem. The method is immune to low levels of noise and has good behavior when the noise increases. The noise immunity is so high that even though the algorithm is intended only for translating objects, its accuracy is very high even if the object is also rotating (with a small rotation) around an axis pass ing through its center of mass. We provide a theoretical analysis of the robustness of our algorithm and present ex perimental results from the application of the theory to syn thetic and real images.	algorithm;robustness (computer science)	Anup Basu;Yiannis Aloimonos	1990	I. J. Robotics Res.	10.1177/027836499000900503	center of mass;three-dimensional space;computer vision;image analysis;simulation;computer science;artificial intelligence;object;mathematics;robotics;correspondence problem	Robotics	49.37042954962037	-57.9312329350112	100236
3772d3664c4c21e851b456000ffc59ecc8012ef5	separating rigid motion from linear local deformation models	image motion analysis;convex programming schemes;socp scheme;convex programming;shape deformable models surface reconstruction image reconstruction training three dimensional displays optimization;training;psi_visics;deformable models;socp scheme rigid motion separation linear local deformation models deformable 3d surface recovery image observations convex programming schemes statistical models global rigid transformations systematic reconstruction error;surface reconstruction;statistical models;shape deformation;image observations;statistical model;three dimensional;deformable 3d surface recovery;shape;statistical analysis;deformation;three dimensional displays;image reconstruction;statistical analysis convex programming deformation image motion analysis image reconstruction;systematic reconstruction error;rigid motion separation;optimization;linear local deformation models;deformable model;global rigid transformations	In this paper we deal with the problem of recovering deformable 3D surfaces from image observations, a topic which has received a lot of attention in recent years. As the problem is inherently under-constrained, additional information has to be used to regularize the solution. Linear local deformation models have been presented as a solution that fits into convex programming schemes. In contrast to more complex statistical models, they also offer very good generalizability. However, in existing work, they are used to model not only the local non-rigid deformations, but also the global and local rigid transformations. We show that by not estimating the rigid transformations separately, a systematic reconstruction error that depends on the transformation is introduced. We then propose separating the rigid and non-rigid parts and demonstrate how to fit the resulting problem into the existing SOCP scheme. We finally compare our method to the baseline approach and show that our method outperforms it.	baseline (configuration management);convex optimization;fits;second-order cone programming;statistical model	Markus Moll;Luc Van Gool	2011	CVPR 2011 WORKSHOPS	10.1109/CVPRW.2011.5981733	statistical model;computer vision;mathematical optimization;convex optimization;mathematics;geometry;statistics	Vision	52.82139000050549	-52.55496795140714	100376
a4c8f5f89c26322617f75e800f6e5ad28ccd0676	matching 2d shapes using u descriptors	object recognition;image processing;polinomio ortogonal;computer graphics;morfoscopia;shape analysis;orthogonal polynomial;procesamiento imagen;reconnaissance objet;forma geometrica;traitement image;fourier descriptors;analisis morfologico;pattern matching;morphoscopie;geometrical shape;morphological analysis;analyse morphologique;forme geometrique;concordance forme;polynome orthogonal;information system;grafico computadora;infographie;systeme information;sistema informacion	In this paper, we propose a novel U-System-based approach for representing and matching similar shapes. U-system is a complete orthogonal piecewise k-degree polynomials in L2[0,1]and it has some good properties,such as regeneration,convergence by group. Using U-system with finite items, it can be realized to accurate representation of shapes. This paper make shapes analysis in theory. We experimentally demonstrate that U descriptors are more suitable for representing and matching 2D shapes than Fourier descriptors.		Zhanchuan Cai;Wei Sun;Dongxu Qi	2006		10.1007/11784203_18	computer vision;image processing;morphological analysis;computer science;cognitive neuroscience of visual object recognition;pattern matching;shape analysis;mathematics;geometry;orthogonal polynomials;computer graphics;information system;algorithm	Vision	48.47023327510046	-60.21561280969058	100472
03b7386878ab0ef31cf6a21f5286ccbb6ac9900c	mosaicing of flattened images from straight homogeneous generalized cylinders	monocular vision;vision ordenador;vision monoculaire;image processing;procesamiento imagen;peinture art;traitement image;computer vision;reconstruction image;reconstruccion imagen;pintura arte;image reconstruction;vision monocular;vision ordinateur;coordinate system;painting art	This paper presents a new method for reconstructing paintings from component images. A set of monocular images of a painting from a straight homogeneous generalized cylinder is taken from various viewpoints. After deriving the surface localization in the camera coordinate system, the images are backprojected on the curved surface and attened. We derive the perspective distortion of the scene in the case when it is mapped on a cylindrical surface. Based on the result of this study we derive the necessary number of views in order to represent the entire scene depicted on a cylindrical surface. We propose a matching-based mosaicing algorithm for reconstructing the scene from the curved surface. The proposed algorithm is applyed on paintings.	algorithm;cylinder seal;distortion	Adrian G. Bors;William Puech;Ioannis Pitas;Jean-Marc Chassery	1997		10.1007/3-540-63460-6_108	iterative reconstruction;computer vision;image processing;computer science;monocular vision;coordinate system;computer graphics (images)	Vision	50.92415683287659	-57.44407066457698	100506
d4c23b5fad7e808331d125731ea616cd6650daec	a subspace approach to layer extraction	motion analysis;cluster algorithm;global optimality subspace approach layer extraction images representation video compression motion analysis 3d scene analysis planar patches low dimensional linear subspace mean shift based clustering algorithm;video compression;mean shift;motion estimation;image representation;feature extraction;3d scene analysis;global optimization;subspace constraints tiles motion analysis image analysis layout computer vision motion estimation computer science video compression clustering algorithms;image representation motion estimation feature extraction	Representing images with layers has many important applications, such as video compression, motion analysis, and 3D scene analysis. This paper presents an approach to reliably extracting layers from images by taking advantages of the fact that homographies induced by planar patches in the scene form a low dimensional linear subspace. Layers in the input images will be mapped in the subspace, where it is proven that they form well-defined clusters and can be reliably identified by a simple mean-shift based clustering algorithm. Global optimality is achieved since all valid regions are simultaneously taken into account, and noise can be effectively reduced by enforcing the subspace constraint. Good layer descriptions are shown to be extracted in the experimental results.	algorithm;cluster analysis;coherence (physics);data compression;experiment;feedback;gaussian blur;goto;mean shift;motion estimation;optical flow;pixel;singular value decomposition	Qifa Ke;Takeo Kanade	2001		10.1109/CVPR.2001.990484	data compression;computer vision;mean-shift;feature extraction;quarter-pixel motion;computer science;machine learning;pattern recognition;motion estimation;global optimization	Vision	52.225849181490204	-53.58543002630337	100550
be069e6841fe2de171e460b632b91937c847741a	robust real-time segmentation of images and videos using a smooth-spline snake-based algorithm	moving object;traitement signal;b spline interpolation real time image segmentation video segmentation smooth spline snake based algorithm region based active contour;spline;interpolation;estimation mouvement;detection forme;active contour;b spline interpolation;image segmentation;methode parametrique;image processing;video signal processing;complexite calcul;esplin;edge detection;flexibilidad;metodo parametrico;real time;image segmentation videos active contours computational efficiency interpolation level set spline active noise reduction noise robustness smoothing methods;interpolacion;estimacion movimiento;parametric method;level set;procesamiento imagen;technique video;real time processing;region based active contour;motion estimation;real time image segmentation;video segmentation;active contours;tecnica video;shape detection;noise robustness;traitement image;splines mathematics;reduccion ruido;deteccion contorno;signal processing computer assisted;active noise reduction;detection contour;tratamiento tiempo real;minimizacion costo;deteccion forma;aproximacion esplin;image enhancement;complejidad computacion;traitement temps reel;numerical analysis computer assisted;smoothing methods;minimisation cout;contorno activo;image interpretation computer assisted;cost minimization;computational complexity;spline approximation;approximation spline;feature extraction;signal processing;noise reduction;smooth spline snake based algorithm;segmentation image;video recording;reduction bruit;fast imaging;traitement signal video;video technique;artificial intelligence;algorithms;flexibilite;pattern recognition automated;b spline;algorithms artificial intelligence image enhancement image interpretation computer assisted information storage and retrieval numerical analysis computer assisted pattern recognition automated signal processing computer assisted video recording;contour actif;smoothing methods image segmentation video signal processing splines mathematics interpolation	This paper deals with fast image and video segmentation using active contours. Region-based active contours using level sets are powerful techniques for video segmentation, but they suffer from large computational cost. A parametric active contour method based on B-Spline interpolation has been proposed in to highly reduce the computational cost, but this method is sensitive to noise. Here, we choose to relax the rigid interpolation constraint in order to robustify our method in the presence of noise: by using smoothing splines, we trade a tunable amount of interpolation error for a smoother spline curve. We show by experiments on natural sequences that this new flexibility yields segmentation results of higher quality at no additional computational cost. Hence, real-time processing for moving objects segmentation is preserved.	active contour model;active galactic nucleus;algorithm;algorithmic efficiency;b-spline;biologic preservation;computation;experiment;interpolation imputation technique;muscle rigidity;physical object;real-time clock;robustification;smoothing (statistical technique);smoothing spline;spline (mathematics);spline interpolation;biologic segmentation;videocassette	Frédéric Precioso;Michel Barlaud;Thierry Blu;Michael Unser	2005	IEEE Transactions on Image Processing	10.1109/TIP.2005.849307	computer vision;speech recognition;image processing;interpolation;computer science;segmentation-based object categorization;signal processing;image segmentation;scale-space segmentation;computer graphics (images)	Vision	52.375840659034296	-65.56630351560341	100625
15e7059f4499fc8e584e5bf732498a16cc2f7921	multi-oriented moving text detection	histograms;image edge detection vectors graphics feature extraction estimation dynamics histograms;multi oriented text detection motion vector estimation central geometric moments region growing;vectors;estimation;image edge detection;dynamics;gradient direction multioriented moving text detection video orientations video background motion vectors constant velocity linear velocity k means clustering algorithm;feature extraction;video signal processing gradient methods image resolution text analysis;graphics	Detection of moving text of different orientations in video is challenging because of low resolution and complex background of video. In this paper, we propose a method based on motion vectors to identify the moving blocks which have linear and constant velocity. For each block, we compute moments and use k-means clustering algorithm to extract text candidate. We introduce a new criterion based on gradient direction of pixels in text candidates to remove false text candidates which we outputs potential text candidates. Then the method performs region growing to group the potential text candidates which outputs text lines. The method is tested on both static and moving text video to evaluate the performance in terms of recall, precision, F-measure, misdetection rate and time. The results are compared with the well-known existing methods to show effectiveness of the proposed method.	algorithm;cluster analysis;f1 score;gradient;graphics;image resolution;k-means clustering;pixel;region growing;velocity (software development);whole earth 'lectronic link	Vijeta Khare;Palaiahnakote Shivakumara;Raveendran Paramesran	2014	2014 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)	10.1109/ISPACS.2014.7024481	computer vision;speech recognition;computer science;pattern recognition	Vision	40.88962206917898	-53.74979655876851	100637
55c638f48f7869015584dc1933e279d8fa9b9bff	automatic fingerprint center point determination by using modified directional field and morphology	morphologie;image recognition;reconocimiento imagen;biometrie;biometrics;biometria;morphology;empreinte digitale;rejection;dactyloscopie;reconnaissance image;fingerprint;huella digital;morfologia;rechazo;rejet;fingerprint identification;qa75 5 76 95 electronic computers computer science	Accurate and reliable center point determination of the fingerprint is an essential pre-processing step for the image based fingerprint recognition approach. This step is particularly important since a reference point is required to cancel the variation in position of the reference and testing fingerprint image. This paper illustrated an automatic center point determination algorithm that couples the modified averaged square directional field (MASDF) with morphological operation, in order to pinpoint the center point of the fingerprint efficiently and accurately. The experiment result shows only 3.13% rejection rate for the false center point by using the proposed method.	fingerprint;mathematical morphology	Andrew Beng-Jin Teoh;Thian Song Ong;David Chek Ling Ngo;Y. W. Sek	2003		10.1007/978-3-540-24581-0_54	fingerprint;computer vision;morphology;computer science;artificial intelligence	Vision	42.570027034140715	-63.11164818219771	100659
7ae219f3b2c71c9d9a03f483937fb739043c28f0	matching folded garments to unfolded templates using robust shape analysis techniques		This work presents a novel method performing shape matching of folded garments to unfolded templates, aiming to facilitate unfolding by robotic manipulators. The proposed method incorporates robust shape analysis techniques, estimating point correspondences between contours of folded garments and unfolded templates. The analysis results are also used for estimating the location of the folding axis on the templates and discriminating between different types of garments. The method has been experimentally evaluated using both synthetic and real datasets of folded garments and the produced results indicate the usefulness of the proposed approach.		Ioannis Mariolis;Sotiris Malassiotis	2013		10.1007/978-3-642-40246-3_24	combinatorics;theoretical computer science	Vision	41.73201255272898	-56.98194769868804	100719
6409e4e1d4a091f0c376db2f4213b5c91d927c2e	in-pixel edge detection circuit without non-uniformity correction for an infrared focal plane array (irfpa)	tratamiento paralelo;non uniformity correction;imageria termica;tecnologia electronica telecomunicaciones;traitement parallele;taux erreur;edge detection;real time;readout electronics;photodetecteur;real time processing;inmunidad ruido;fotodetector;matrice plan focal;readout circuit;deteccion contorno;detection contour;tratamiento tiempo real;traitement temps reel;optoelectronic device;noise immunity;thermal imaging;detecteur ir;error rate;focal plane arrays;imagerie thermique;dispositif optoelectronique;electronique de mesure;immunite bruit;tecnologias;infrared;0757k;grupo a;infrared detector;real time image processing;indice error;detector rayos infrarrojos;focal plane array;parallel processing;dispositivo optoelectronico;photodetector	For real time image processing, a readout circuit for an infrared focal plane array (IRFPA) involving a new edge detection technique has been proposed in this letter. A non-uniformity correction unit (NUC), essential in an IRFPA because of bad non-uniformity characteristics of IR sensors is eliminated in this circuit by using a noise tolerant edge detection technique. In addition, real time edge detection can be possible, because of pixel-level integration and parallel processing. The proposed readout circuit shows an approximately three to nine times better edge error rate than other available methods using pixel-level parallel processing.	circuit complexity;edge detection;focal (programming language);pixel;staring array	Chul Bum Kim;Doo Hyung Woo;Yong Soo Lee;Hee Chul Lee	2008	IEICE Transactions	10.1093/ietele/e91-c.2.235	parallel processing;electronic engineering;edge detection;infrared;telecommunications;word error rate;computer science;optics;photodetector;physics	Vision	47.58306527963628	-63.93096297605075	100861
48a379a4b8703de0b06c64956c612a47de0f9a36	incremental learning of statistical motion patterns with growing hidden markov models	modelizacion;pattern learning hidden markov models hmms motion prediction;modelo markov oculto;learning algorithm;estimation mouvement;pedestrian safety;analisis estadistico;modelo markov;poison control;modele markov cache;hidden markov model;laser;injury prevention;intelligent transportation systems;estimacion movimiento;pattern learning;laser scanner;scanneur;motion estimation;safety literature;intelligence artificielle;aprendizaje probabilidades;algorithme apprentissage;statistical motion patterns;probabilistic approach;escaner;traffic safety;injury control;scanner;statistical model;pattern recognition hidden markov models;home safety;modelisation;captador medida;injury research;safety abstracts;measurement sensor;markov model;capteur mesure;hidden markov models;trajectory;human factors;incremental learning;statistical analysis;machine learning;enfoque probabilista;approche probabiliste;occupational safety;safety;analyse statistique;hidden markov models hmms;offline learning algorithms;pattern recognition;clustering algorithms;safety research;apprentissage probabilites;artificial intelligence;accident prevention;predictive models;violence prevention;humans;vehicles;bicycle safety;inteligencia artificial;modele markov;poisoning prevention;algoritmo aprendizaje;modeling;falls;ergonomics;laser modes;suicide prevention;cameras;probability learning;growing hidden markov models;hidden markov models predictive models humans clustering algorithms intelligent transportation systems vehicles machine learning trajectory cameras laser modes;offline learning algorithms statistical motion patterns growing hidden markov models machine learning;motion prediction	Modeling and predicting human and vehicle motion is an active research domain. Due to the difficulty of modeling the various factors that determine motion (e.g., internal state and perception), this is often tackled by applying machine learning techniques to build a statistical model, using as input a collection of trajectories gathered through a sensor (e.g., camera and laser scanner), and then using that model to predict further motion. Unfortunately, most current techniques use offline learning algorithms, meaning that they are not able to learn new motion patterns once the learning stage has finished. In this paper, we present an approach where motion patterns can be learned incrementally and in parallel with prediction. Our work is based on a novel extension to hidden Markov models (HMMs) - called growing hidden Markov models - which gives us the ability to incrementally learn both the parameters and the structure of the model.	algorithm;hidden markov model;machine learning;markov chain;offline learning;online and offline;real-time clock;statistical model;synthetic data	Dizan Vasquez;Thierry Fraichard;Christian Laugier	2009	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2009.2020208	laser scanning;statistical model;intelligent transportation system;simulation;systems modeling;laser;computer science;engineering;suicide prevention;artificial intelligence;human factors and ergonomics;trajectory;injury prevention;machine learning;hidden semi-markov model;motion estimation;predictive modelling;markov model;cluster analysis;hidden markov model	ML	46.42521040756376	-57.087309310811506	100874
8b827a4618271d6b92ecb2b78640d2785d1b755b	a 3d model retrieval approach using the interior and exterior 3d shape information	shell grid descriptor;art based elevation descriptor;3d model retrieval;3d model	In this paper, we will propose a new exterior shape feature, ART-based elevation descriptor (ART-ED), and a new interior shape feature, shell grid descriptor (SGD), for 3D model retrieval. ART-ED describes the elevation information of a 3D model from six different angles. Since ART-ED represents only the exterior contour of a 3D model, SGD is proposed for extracting the interior shape information. Finally, these two proposed features as well as other features are combined in an attempt to improve retrieval. Experimental results show that the proposed methods are superior to other descriptors.	3d modeling;data descriptor;feature extraction;polygonal modeling	Jau-Ling Shih;Hong-Yu Chen	2008	Multimedia Tools and Applications	10.1007/s11042-008-0256-6	computer vision;simulation	Vision	39.3290780890097	-58.03437019071265	101033
b7a0568fb9e1381a9b48e8bb1847c4a72e3f83a5	structure feature extraction for finger-vein recognition	vein recognition curve fitting feature extraction image matching;modified included angle chain;image matching;vein recognition;structure feature extraction dynamic scheme modified included angle chain curve segment extraction curve tracing scheme vein skeleton finger vein image matching finger vein recognition;finger vein recognition;modified included angle chain finger vein recognition structure feature;feature extraction;structure feature;junctions veins feature extraction skeleton encoding image segmentation pattern recognition;curve fitting	A new finger-vein image matching method based on structure feature is proposed in this paper. To describe the finger-vein structures conveniently, the vein skeletons are firstly extracted and used as the primitive information. Based on the skeletons, a curve tracing scheme depended on junction points is proposed for curve segment extraction. Next, the curve segments are encoded piecewise using a modified included angle chain, and the structure feature code of a vein network are generated sequentially. Finally, a dynamic scheme is adopted for structure feature matching. Experimental results show that the proposed method perform well in improving finger-vein matching accuracy.	feature extraction;finger vein recognition;image registration;vein matching	Di Cao;Jinfeng Yang;Yihua Shi;Chenghua Xu	2013	2013 2nd IAPR Asian Conference on Pattern Recognition	10.1109/ACPR.2013.113	computer vision;pattern recognition;mathematics;engineering drawing	Robotics	42.131184211009476	-57.901733091441805	101039
5d4a793c4cc85b4a41db8e2a097a409f7037fb18	nonlinear enhancement of extremely high contrast images for visibility improvement	metodo adaptativo;visibilite;rendu image;contrast enhanced;vision ordenador;visibilidad;restauration image;image processing;accentuation image;funcion no lineal;restitucion imagen;inversion;luminance;procesamiento imagen;non linear function;image restoration;methode adaptative;high contrast imaging;traitement image;computer vision;image contrast;restauracion imagen;image enhancement;visibility;transfer function;contraste image;eclairage;medio contraste;adaptive method;produit contraste;image rendering;fonction non lineaire;contrast media;vision ordinateur;spectral band;lighting;banda espectral;bande spectrale;imagen color;imagen contraste;image couleur;color image;alumbrado;luminancia	This paper presents a novel image enhancement algorithm using a multilevel windowed inverse sigmoid (MWIS) function for rendering images captured under extremely non uniform lighting conditions. MWIS based image enhancement is a combination of three processes viz. adaptive intensity enhancement, contrast enhancement and color restoration. Adaptive intensity enhancement uses the non linear transfer function to pull up the intensity of underexposed pixels and to pull down the intensity of overexposed pixels of the input image. Contrast enhancement tunes the intensity of each pixel’s magnitude with respect to its surrounding pixels. A color restoration process based on relationship between spectral bands and the luminance of the original image is applied to convert the enhanced intensity image back to a color image.	adaptive filter;adaptive grammar;algorithm;circuit restoration;color image;earthbound;image analysis;image editing;pattern recognition;pixel;sigmoid function;transfer function;viz: the computer game;window function	Vijayan K. Asari;Ender Oguslu;Saibabu Arigela	2006		10.1007/11949619_22	computer vision;geography;optics;computer graphics (images)	Vision	53.68636711976206	-63.19731201155832	101096
4e55295a58ee6736e7a79a899ec16a961502d39f	an efficient approach to iris detection for iris biometric processing	iris detection;interfase usuario;image segmentation;image processing;occlusion;biometric authentication;image databank;user interface;biometrie;occultation;biometrics;biometria;procesamiento imagen;oclusion;iris recognition;biometric;qualite image;traitement image;automated identification;iris ojo;image quality;banco imagen;banque image;segmentation image;interface utilisateur;calidad imagen;iris oeil;ocultacion;iris eye	Detection of iris in an eye image poses a number of challenges, such as inferior image quality, occlusion of eyelids, eyelashes etc. Owing to these problems, it is not possible to achieve 100% accuracy in any iris-based biometric authentication system. In this paper, we have proposed an approach to detect the iris boundary in an efficient and accurate way. Experimental results show that our approach is approximately 75% faster than the existing approaches. With our approach it is possible to detect the iris part 98% accurately as substantiated by our experiments on Bath, MMU and UBIRIS iris image databases.	biometrics	Somnath Dey;Debasis Samanta	2009	IJCAT	10.1504/IJCAT.2009.024616	computer vision;image processing;computer science;iris recognition;computer security;biometrics;computer graphics (images)	AI	45.599528881216514	-60.04627095699531	101153
f06a7d24df343b9eb27f4a626a0af96e37f471d1	shape-based retrieval of 3d mesh models	shape mpeg 7 standard computational complexity design automation information retrieval gravity spatial databases multimedia databases indexing content based retrieval;mpeg 7 3d model database;design automation;3d mesh models;shape descriptor;information retrieval;3d polygonal mesh models shape based retrieval 3d mesh models 3d mesh indexation geometric invariance topological invariance canonical 3d hough transform descriptor geometric transformations computational complexity spatial alignment procedure geometric invariant behavior mpeg 7 3d model database shape representation similarity retrieval;canonical 3d hough transform descriptor;gravity;geometric transformations;similarity retrieval;shape based retrieval;shape representation;3d model;image representation image retrieval hough transforms;shape;topological invariant;indexing;computational complexity;image representation;indexation;spatial databases;multimedia databases;spatial alignment procedure;topological invariance;3d polygonal mesh models;hough transforms;hough transform;mpeg 7 standard;content based retrieval;geometric invariant behavior;3d mesh indexation;geometric invariance;image retrieval	This paper addresses the issue of 3D mesh indexation by using shape descriptors (SDs) under constraints of geometric and topological invariance. A new shape descriptor, the Canonical 3D Hough Transform Descriptor (C3DHTD) is here proposed. Intrinsically topologically stable, the C3DHTD is not invariant to geometric transformations. Nevertheless, we show mathematically how the C3DHTD can be optimally associated (in terms of compactness of representation and computational complexity) with a spatial alignment procedure which leads to a geometric invariant behavior. Experiments carried out upon the categorized MPEG-7 3D model database objectively show that the C3DHTD outperforms both the MPEG-7 3D SD and classic EGIs descriptor.	categorization;computational complexity theory;hough transform;mpeg-7;shape analysis (digital geometry)	Titus B. Zaharia;Françoise J. Prêteux	2002		10.1109/ICME.2002.1035812	hough transform;computer vision;search engine indexing;discrete mathematics;gravity;transformation geometry;image retrieval;shape;computer science;theoretical computer science;mathematics;computational complexity theory	Vision	40.81840597581804	-59.48183029446552	101340
f4f73ddab21e7bf461631d39c0718744c1a967e4	independent components analysis for representation interest point descriptors	transformation ondelette;modelizacion;funcion haar;fonction haar;low frequency;interest points;localization;haar function;laplacian;gradiente;vector space;intelligence artificielle;localizacion;gradient;independent component analysis;modelisation;feature vector;captador medida;laplacien;laplaciano;measurement sensor;capteur mesure;localisation;robustesse;basse frequence;analyse composante independante;artificial intelligence;robustness;baja frecuencia;inteligencia artificial;transformacion ondita;espace vectoriel;analisis componente independiente;haar wavelet transform;modeling;espacio vectorial;wavelet transformation;robustez	This paper presents a new interest point descriptors representation method based on independent components analysis (ICA). The aim of this algorithm is to find a meaningful image subspace and more compact descriptors. Combination the descriptors with an effective interest point detector, the proposed algorithm has a more accurate matching rate besides the robustness towards image deformations. The proposed algorithm first finds the characteristic scale and the location for the interest points using Harris-Laplacian interest point detector. We use Haar wavelet transform on the neighborhood of the interest points and get low frequency gradient feature vectors. Then ICA is used to model the subspace and reduces the dimension of the feature vectors. The experiments show the efficiency of the proposed algorithm.	independent component analysis	Dongfeng Han;Wenhui Li;Tianzhu Wang;Lingling Liu;Yi Wang	2006		10.1007/11816157_152	independent component analysis;laplace operator;systems modeling;internationalization and localization;feature vector;vector space;computer science;artificial intelligence;machine learning;calculus;mathematics;geometry;low frequency;programming language;gradient;robustness	Vision	45.837039552992046	-59.788473454989834	101396
07a1aabf83a48768945cee1be7dd7695515517db	robust error metric analysis for noise estimation in image indexing	gaussian noise;noise estimation;maximum likelihood;noise robustness error analysis image analysis indexing maximum likelihood estimation computer errors computer vision additive noise gaussian noise guidelines;additive noise;image database;image indexing;maximum likelihood estimation;noise robustness;computer vision;error analysis;indexing;guidelines;nonlinear estimation;image analysis;computer errors	In many computer vision algorithms, the well known Euclidean or SSD (sum of the squared differences) metric is prevalent and justified from a maximum likelihood perspective when the additive noise is Gaussian. However, Gaussian noise distribution assumption is often invalid. Previous research has found that other metrics such as double exponential metric or Cauchy metric provide better results, in accordance with the maximum likelihood approach. In this paper, we examine different error metrics and provide a general guideline to derive a rich set of nonlinear estimations. Our results on image databases show more robust results are obtained for noise estimation based on the proposed error metric analysis.	additive white gaussian noise;algorithm;computer stereo vision;computer vision;database;nonlinear system;solid-state drive;time complexity;utility functions on indivisible goods;whole earth 'lectronic link	Qi Tian;Jie Yu;Qing Xue;Nicu Sebe;Thomas S. Huang	2004	2004 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPR.2004.432	gaussian noise;computer vision;image analysis;computer science;machine learning;stein's method;pattern recognition;mathematics;maximum likelihood;statistics	Vision	50.403262919134505	-65.50277913878283	101399
eeed60b185c8502acba6949266f7d7731797460e	recognition of occluded objects: a cluster structure paradigm	image segmentation;occlusion;shape matching clustering occlusion recognition segment matching sequencing;image sequence analysis;defense industry;indexing terms;sequencing;image segmentation shape computer science cities and towns pattern recognition image sequence analysis clustering methods clustering algorithms defense industry machine vision;recognition;shape;clustering;shape matching;machine vision;clustering method;pattern recognition;clustering algorithms;segment matching;cities and towns;image analysis;polygonal approximation;computer science;clustering methods	Clustering techniques have been used to perform image segmentation, to detect lines and curves in the images and to solve several other problems in pattern recognition and image analysis. In this paper we apply clustering methods to a new problem domain and present a new method based on a cluster-structure paradigm for the recognition of 2-D partially occluded objects. The cluster-structure paradigm entails the application of clustering concepts in a hierarchical manner. The amount of computational effort decreases as the recognition algorithm progresses. As com ared to some of the earlier methods, which identify an olject based on only one sequence of matched segments, the new technique allows the identification of all parts of the model which match with the apparent object. Also the method is able to tolerate a moderate change in scale and a significant amount of shape distortion arising as a result of segmentation and/or the polygonal approximation of the boundary of the object. The method has been evaluated with respect to a large number of examples where several objects partially occlude one another. A summary of the results is presented.	algorithm;apple a9;approximation;binocular disparity;cluster analysis;computation;computer cluster;diagram;distortion;emoticon;hidden surface determination;image analysis;image segmentation;k-means clustering;pattern recognition;problem domain;programming paradigm;xfig	Bir Bhanu;John C. Ming	1986		10.1109/ROBOT.1986.1087422	computer vision;image analysis;machine vision;computer science;machine learning;pattern recognition;mathematics;cluster analysis	Robotics	45.949423681063784	-54.03462924539865	101600
82e55e809b78cb7da0dec3ff910da4fb4c2f21e4	line-drawing interpretation: straight lines and conic sections	proyeccion;vision ordenador;layout face detection lighting reflectivity humans robots computer vision stability tiles;reflectivity;geometrie algorithmique;perspective projection;degree of freedom;line drawing interpretation;hyperbolas;computational geometry;picture processing;layout;conic sections;computer vision;stability;line drawings;straight lines;projection;ellipses;robots;quadric surfaces;geometria algoritmica;pattern recognition;vision ordinateur;humans;tiles;developable surface;lighting;parabolas;reconnaissance forme;perturbation;reconocimiento patron;face detection;picture processing pattern recognition;scene edges;quadric surfaces line drawing interpretation picture processing pattern recognition straight lines conic sections ellipses parabolas hyperbolas perturbation line drawings scene edges	Line drawings of man-made scenes often exhibit instances of straight lines and conic sections, i.e. ellipses, parabolas, and hyperbolas. Constraints imposed on the scene by such instances are investigated, under the assumption of general viewpoint, i.e. the mapping of the viewed surface onto the line drawing is stable under perturbation of the viewpoint within some open set. Both orthographic and perspective projection are considered. The viewed surfaces are assumed to be piecewise C/sup 3/. It is shown that straight lines and conic sections in line drawings are projections of scene edges which are also straight lines and conic sections, respectively. It is also shown that scene events which project onto straight lines or conic sections cannot be combinations of view-point-independent and viewpoint-dependent edges. Further, continuous-surface-normal depth discontinuities which project onto straight lines can be locally described by developable surfaces, and those which project onto conic sections can be locally described by nondevelopable quadric surfaces. Each of these quadric surfaces is determined up to four degrees-of-freedom by its projection. >		Vishvjit S. Nalwa	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.3914	robot;layout;computer vision;face detection;perspective;quadric;developable surface;perturbation;stability;projection;computational geometry;parabola;lighting;mathematics;geometry;reflectivity;conic section;degrees of freedom;ellipse;hyperbola	Vision	51.59407345928521	-55.00036505351595	101660
069fddd37fddd64797bcfe09ca9920038c0b0d72	image correspondences by warping functions and its applications	image morphing;minimization;warping functions;image synthesis;variational principle	Abstract#R##N##R##N#In various fields such as movement detection, stereo matching, image morphing, image synthesis, and image recognition, automatic determination of the image correspondence is a very basic problem. In this paper, the relation establishing correspondence between a prototype and the images (i.e., warping function) is treated and the method of determination of such function is proposed. The proposed method is based on the variational principle. The warping function is determined as the solution which minimizes the brightness differences between the pixels under smoothness constraints. Examples on applications of the proposed procedure of determination of warping functions are presented which indicate the effectiveness of the method. ©2002 Scripta Technica, Syst Comp Jpn, 33(2): 22–30, 2002		Zdenek Procházka;Takayuki Ito;Toshio Okamoto	2002	Systems and Computers in Japan	10.1002/scj.1103	image warping;computer vision;mathematical optimization;variational principle;mathematics;geometry	Crypto	52.48184136261082	-54.829147714656365	101765
fa36baa14c22c29562799590ef2c9b4656dc8874	a simple contour matching algorithm	filtering;performance evaluation;probability density function;shape analysis;speech;shape measurement;data mining;shape;digital filters;similarity measure contour matching shape analysis;approximation methods;shape measurement performance evaluation encoding;encoding;contour matching;similarity measure	Two similarity measures between strings are proposed. This correspondence also describes an experiment performed to illustrate the inadequacy of a commonly used measure.	algorithm;contour line	T. W. Sze;Y. H. Yang	1981	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1981.4767169	active shape model;filter;computer vision;probability density function;digital filter;shape;computer science;speech;machine learning;pattern recognition;shape analysis;mathematics;encoding	Vision	41.43164591074886	-58.94445101963522	101821
1b99d195fa112a16d66caed5d19cee93ab18040d	topographic cellular active contour techniques: theory, implementations and comparisons	software;non linear circuit;analogic;evaluation performance;medical imagery;arquitectura circuito;active contour;articulo sintesis;performance evaluation;image processing;cellular activation;contour;etude theorique;logiciel;topographie;complexite calcul;article synthese;edge detection;implementation;estudio comparativo;evaluacion prestacion;circuit non lineaire;procesamiento imagen;circuit architecture;boundary tracking;electrocardiographie;comparison;topography;traitement image;parallel computation;paralelismo masivo;deteccion contorno;etude comparative;detection contour;complejidad computacion;electrocardiography;calculo paralelo;electrocardiografia;active;contorno activo;red celular;computational complexity;cell network;reseau cellulaire;comparative study;architecture circuit;estudio teorico;imagineria medica;imagerie medicale;pattern recognition;echocardiography;logicial;contour actif;reconnaissance forme;theoretical study;reconocimiento patron;implementacion;review;calcul parallele;topographic;circuito no lineal;parallelisme massif;massive parallelism;topografia;cellular;cnn	Abstract#R##N##R##N#This paper overviews some massively parallel topographic cellular computational approaches proposed for contour localization and tracking. When implemented on a focal plane cellular array microprocessor, these algorithms offer real-time object contour localization and tracking—even at very high frame rates. Three specific methods (Constrained Wave Computing, Pixel Level Snakes and Moving Patch Method) will be described and compared along with their associated hardware–software architectures. Computational complexity, implementation, and performance related issues are discussed on a common platform (ACE-BOX with the ACEx CNN-UM chips). In conclusion, a novel architecture is proposed incorporating the best solutions learned from this comparative study. Copyright © 2006 John Wiley & Sons, Ltd.	active contour model;topography	Dániel Hillier;Viktor Binzberger;David López Vilariño;Csaba Rekeczky	2006	I. J. Circuit Theory and Applications	10.1002/cta.337	computer vision;topographic map;edge detection;image processing;computer science;artificial intelligence;topography;comparative research;active contour model;computational complexity theory;implementation;algorithm	Theory	47.299873964262204	-62.64354603572169	101916
79a157bf600902258b420ab69ab82aee8d3a13d1	moving-edge detection via heat flow analogy	moving image;traitement signal;vision ordenador;moving edges;detection forme;medicion automatica;image processing;threshold detection;edge detection;procesamiento imagen;diffusion anisotrope;reference frame;arriere plan;automatic measurement;mesure automatique;shape detection;imagen movil;traitement image;image mobile;computer vision;transfert chaleur;deteccion contorno;algorithme;algorithm;detection contour;heat flow;detection seuil;deteccion forma;background;deteccion umbral;difusion anisotropica;feature extraction;signal processing;heat transfer;image sequence;transferencia termica;methode moyenne;vision ordinateur;secuencia imagen;extraction caracteristique;anisotropic scattering;procesamiento senal;averaging method;metodo medio;sequence image;algoritmo	0167-8655/$ see front matter 2010 Elsevier B.V. A doi:10.1016/j.patrec.2010.08.012 ⇑ Corresponding author. Address: School of Electr University of Southampton, SO17 1BJ, UK. Tel.: +4 (0)2380594498. E-mail address: cdirekoglu@googlemail.com (C. Di In this paper, a new and automatic moving-edge detection algorithm is proposed, based on using the heat flow analogy. This algorithm starts with anisotropic heat diffusion in the spatial domain, to remove noise and sharpen region boundaries for the purpose of obtaining high quality edge data. Then, isotropic and linear heat diffusion is applied in the temporal domain to calculate the total amount of heat flow. The moving-edges are represented as the total amount of heat flow out from the reference frame. The overall process is completed by non-maxima suppression and hysteresis thresholding to obtain binary movingedges. Evaluation, on a variety of data, indicates that this approach can handle noise in the temporal domain because of the averaging inherent of isotropic heat flow. Results also show that this technique can detect moving-edges in image sequences, without background image subtraction. 2010 Elsevier B.V. All rights reserved.	algorithm;canny edge detector;display resolution;edge detection;feature extraction;hysteresis;image subtraction;mail (macos);map;maxima;reference frame (video);sobel operator;thresholding (image processing);time complexity;zero suppression	Cem Direkoglu;Mark S. Nixon	2011	Pattern Recognition Letters	10.1016/j.patrec.2010.08.012	computer vision;image processing;computer science;artificial intelligence;signal processing;heat transfer	Vision	47.10864302382027	-64.12536242454834	102016
5aae79dbb2ae58aade554c83af29a110fc9097f2	moving shadow detection with multifeature joint histogram	image segmentation;detection and tracking algorithms;algorithms;video;image retrieval	This paper describes a method for moving shadow detection using the joint histogram of multifeatures. In our method, we ﬁrst obtain the moving region by background subtraction. Then, based on the intensity feature, candidate shadow regions are extracted. Moreover, the joint histogram of intensity, color, and gradient features is constructed in candidate background and foreground regions. Furthermore, the joint histogram is backprojected to the foreground regions to yield the moving shadow likelihood image. In the end, the adaptive threshold is derived by the joint histogram of the foreground and background, and accurate shadow regions are extracted by segmenting the shadow likelihood image with this threshold. The main contribution of this paper is twofold. First, multifeatures are fused together by the joint histogram, which is a unified and simple description method for shadow detection. Second, the histogram of background and foreground was compared with backprojection. Moreover, the final result only depends on a few parameters. Unlike other approaches, our method does not make any assumption and moving shadow regions can be detected fast and accurately. Experimental results show that the proposed method is efficient and robust over a broad range of shadow types and challenging video conditions.		Yanzhao Su;Aihua Li;Yanping Cai;Guoyan Feng;Guangzhi Jin	2014	J. Electronic Imaging	10.1117/1.JEI.23.5.053015	image texture;computer vision;video;image retrieval;computer science;histogram matching;machine learning;pattern recognition;image segmentation;image histogram	Vision	40.722060480487166	-54.575408918954764	102115
fc56b811e692a60093432ed5daa92b9134e221f9	edge detection using holladay's principle	edge detection;image edge detection testing brightness moon geometry gabor filters performance analysis differential equations resumes performance evaluation;visual perception edge detection edge detection;human visual system;detection algorithm;image analysis edge detection holladay s principle contour detection algorithm human visual system threshold value background intensity surround intensity;visual perception	We propose herein a new contour detection algorithm based on the human visual system. Using the proposed method, one can automatically select the thresholds that define the significant edges, such as perceived by the human eye. The threshold value is adapted to the background and surround intensities, according to criteria involved by Holladay’s principle. THEORY OF THE APPROACH The basic idea of the proposed method is to adapt to actual digital images some known laws governing the human visual perception. An important work has been devoted to the modeling of relevant data from psychovisual experiments. The intensity discrimination experiment explaining the ability of the eye to discriminate between changes in brightness is governed by the law of Fechner-Weber [1]. If B is the background intensity and B+ AB, the object intensity, AB being as small as possible and yet visible, then Af3, the just noticeable intensity difference, is such that ~=cW is constant over a large range of intensities or Iuminances (CW is the Weber’s constant). Experiments show that this constancy is somewhat effective for high Iuminances, but that unfortunately, as B decreases, ~ slowly increases. Unfortunately, these results are obtained from a simple and unusual situation in practice. Indeed, an actual image may be composed of objects of different brightness on a nonuniform background. Thus, it becomes necessary to perform local analysis where such inhomogeneity in brightness should be taken into account. The original work of Moon and Spencer [2] fills this gap. It would be too lengthy to detail this work and we shall content ourselves with the essential results recalled in [3]. Using previous results, Moon and Spencer [4] have proposed a new expression for the just noticeable contrast c~,~, represented by : ~ (B-Bo)th,e.ho,d c — mln— =&( A+B’’2)2 (1) B where the constant A is equal to 0.8, and B. is the object intensity. Figure 1 adapted from reference [3] describes the observation field, the limited luminance test, its short range background area and its long range surround area. Equation (1) corresponds to the case of a uniform surround Bs (B,(8,4) = B). The perception of differential thresholds is also much influenced by the surround intensity, which is often different from the background intensity. The effect of a nonuniform surround has been studied by many researchers and an overview is presented in [2-4]. A nonuniform surround	algorithm;digital image;edge detection;experiment;surround sound	Kamel Belkacem-Boussaid;Azeddine Beghdadi;H. Depoisot	1996		10.1109/ICIP.1996.559628	computer vision;speech recognition;edge detection;visual perception;computer science;deriche edge detector;mathematics;canny edge detector;human visual system model	Vision	46.71527010541498	-65.91704357296717	102398
5065c0aa581b18a6a7075b185ea9051c4bb69560	motion detection and tracking based on level set algorithm	partial differential equation;distance function;image motion analysis;curve evolution;level set;set theory;motion detection tracking level set active contours narrowband power engineering and energy lighting partial differential equations solid modeling object detection;stopping criterion;partial differential equations;object tracking;energy minimization;motion detection;partial differential equations image motion analysis set theory object detection;object detection;logarithmic image motion detection level set algorithm object tracking curve evolution equation partial differential equations	A novel energy-minimizing model is proposed in this paper for motion detection and object tracking. In our model, the logarithmic image is employed to compensate for illumination change. Another feature of our approach is that the boundary force is no longer necessary. For solving the corresponding curve evolution equation efficiently, a local level set algorithm is adopted. When constructing the narrow band and resetting the level set function to the signed distance function, it is not needed to explicitly label the contour points during the evolution of contours. The local level set algorithm is based on partial differential equations (PDEs), which leads to a simple, flexible and stable scheme. This paper also proposes an appropriate stopping criterion for the level set algorithm without a need of explicitly extracting the locations of the evolving curve.	algorithm;motion detector;numerical partial differential equations	Bo Ma;Zheru Chi;Tianwen Zhang	2004	ICARCV 2004 8th Control, Automation, Robotics and Vision Conference, 2004.	10.1109/ICARCV.2004.1468905	computer vision;mathematical optimization;scale space;mathematics;geometry;partial differential equation;level set method	Robotics	49.52333573300213	-52.99047379719854	102403
ee79f82218514013105d95e40c32edd71a64bd35	query oriented subspace shifting for near-duplicate image detection	histograms;filtering;query processing;near duplicate image detection;copy protection;search algorithm;indexing terms;similarity search subspace shifting near duplicate detection image copyright protection;copyright protection;image copyright protection;distance measurement;internet;subspace shifting;indexing;histograms principal component analysis heuristic algorithms filtering distance measurement indexing internet;heuristic algorithms;principal component analysis;search algorithm query oriented subspace shifting near duplicate image detection copyright protection internet;near duplicate detection;query processing copy protection filtering theory internet object detection;similarity search;query oriented subspace shifting;filtering theory;object detection	Near-duplicate image detection is a critical task in copyright protection. More challenging than the common similarity search, this task requires not only the retrieval of the top similar images but also the detection of the entire near-duplicates collection from the Internet. The common similarity search algorithms are not capable to undertake the latter demand. This paper proposes the query oriented subspace shifting algorithm. The algorithm measures the similarity in various subspaces, which are dynamically generated based on the correlation between samples and the query image. An adaptive threshold is generated automatically to filter the near-duplicates in each subspace. As these subspaces are query oriented, the near-duplicates are less likely to be missed. Experiments shows that this method can effectively improve the detection recall while keeps the similar precision, comparing with the common similarity search algorithm.	experiment;internet;search algorithm;similarity search	Lei Wu;Nenghai Yu;Mingjing Li	2008	2008 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2008.4607521	filter;search engine indexing;query expansion;the internet;index term;computer science;theoretical computer science;data mining;histogram;world wide web;information retrieval;statistics;search algorithm;principal component analysis	Vision	39.996290988805434	-59.67621056475775	102435
412432e6281c74020282f610e1caac7de839d974	robust real-time pupil tracking in highly off-axis images	nmr;random sampling;real time;k means;infra red;scanpath;chemistry;detection rate;eye tracking;ellipse fitting;permutation test	Robust, accurate, real-time pupil tracking is a key component for online gaze estimation. On head-mounted eye trackers, existing algorithms that rely on circular pupils or contiguous pupil regions fail to detect or accurately track the pupil. This is because the pupil ellipse is often highly eccentric and partially occluded by eyelashes. We present a novel, real-time dark-pupil tracking algorithm that is robust under such conditions. Our approach uses a Haar-like feature detector to roughly estimate the pupil location, performs a k-means segmentation on the surrounding region to refine the pupil centre, and fits an ellipse to the pupil using a novel image-aware Random Sample Concensus (RANSAC) ellipse fitting. We compare our approach against existing real-time pupil tracking implementations, using a set of manually labelled infra-red dark-pupil eye images. We show that our technique has a higher pupil detection rate and greater pupil tracking accuracy.	algorithm;apache axis;curve fitting;eye tracking;fits;haar wavelet;k-means clustering;random sample consensus;real-time clock;real-time computing;robustness (computer science)	Lech Swirski;Andreas Bulling;Neil A. Dodgson	2012		10.1145/2168556.2168585	computer vision;mathematics;optics;computer graphics (images)	Vision	48.58603069977553	-52.69831502080735	102901
1bf04fb06486b099bdb6f16546e5fb9aa1ae6040	incremental online pca for automatic motion learning of eigen behaviour	motion analysis;analisis componente principal;teleenseignement;estimation mouvement;eigen behaviour;supervised learning;real time;estimacion movimiento;no x;learning by imitation;analyse mouvement;motion estimation;intelligence artificielle;online learning;feasibility;incremental learning;automatic learning;senal video;signal video;space use;principal component analysis;temps reel;intelligent system;analyse composante principale;behaviour editor;video signal;tiempo real;artificial intelligence;teleensenanza;inteligencia artificial;apprentissage supervise;analisis movimiento;remote teaching;aprendizaje supervisado;pca;practicabilidad;faisabilite	This paper presents an online learning framework for the behavior of an articulated body by capturing its motion using real-time video. In our proposed framework, supervised learning is first utilised during an offline learning phase for small instances using principal component analysis (PCA); then we apply a new incremental PCA technique during an online learning phase. Rather than storing all the previous instances, our online method just keeps the eigenspace and reconstructs the space using only the new instance. We can add numerical new training instances while maintaining the reasonable dimensions. The experimental results demonstrate the feasibility and merits.	eigen (c++ library);humanoid robot;numerical analysis;offline learning;online and offline;principal component analysis;real-time locating system;supervised learning	Xianhua Jiang;Yuichi Motai	2007	IJISTA	10.1504/IJISTA.2007.012490	instance-based learning;simulation;computer science;artificial intelligence;machine learning;supervised learning;principal component analysis	AI	46.546095511745584	-56.64600682207802	102961
d4a65b35f0fc87dc1cfd330dfd5dc96a2255da52	a two-step circle detection algorithm from the intersecting chords	intersecting chord;chord;circle detection;radius histogram;hough transform;two-step circle detection algorithm	This paper proposes a two-step circle detection algorithm using pairs of chords. It is shown how a pair of two intersecting chords locates the center of the circle. Based on this idea, in the ®rst step, a 2D Hough transform (HT) method is employed to ®nd the centers of the circles in the image. In the second step, a 1D radius histogram is used to compute the radii. The experimental results demonstrate that the proposed method can detect the circles eectively.	algorithm;hough transform;robustness (computer science);sensor;synthetic intelligence;the circle (file system);thresholding (image processing)	Heung-Soo Kim;Jong-Hwan Kim	2001	Pattern Recognition Letters		hough transform;computer vision;combinatorics;arc;topology;computer science;midpoint circle algorithm;mathematics;geometry;chord	Vision	45.07541700491642	-64.83959414044041	103066
348bb04b6c5ef0d949c23dcbbcc76d84b0d80e6b	free-view watermarking for free-view television	watermarking;embedded watermarking video watermarking method free view television human visual system hvs imagery camera position image based rendering operation homography estimation method;new technology;estimation method;copy protection;free view television;indexing terms;multiple views;data encapsulation;television cameras;watermarking tv cameras rendering computer graphics image analysis protection humans visual system image generation pattern analysis;watermarking data encapsulation rendering computer graphics television cameras video coding;video coding;human visual system;light field rendering;image based rendering watermarking free view television light field rendering;image based rendering;rendering computer graphics	The recent advances in image based rendering (IBR) has pioneered a new technology, free-view television, in which TV-viewers select freely the viewing position and angle by the application of IBR on the transmitted multi-view video. Noting that the TV-viewer might also record a personal video for this arbitrarily selected view and misuse this content, it is apparent that copyright and copy protection problems also exist and should be solved for free-view TV. In this paper, we focus on this problem by proposing a watermarking method for free-view video. The watermark is embedded into every frame of multiple views by exploiting the spatial masking properties of the human visual system (HVS). Assuming that the position and rotation for the imagery view is known, the proposed method extracts the watermark successfully from an arbitrarily generated image. In order to extend the method for the case of an unknown imagery camera position and rotation, the modifications on the watermark pattern due to image based rendering operations are also analyzed. Based on this analysis, a camera position and homography estimation method is proposed considering the operations in image based rendering. The results show that the watermark detection is achieved successfully for the cases in which the imagery camera is arbitrarily located on the camera plane.	copy protection;digital watermarking;embedded system;homography (computer vision);human visual system model;image-based modeling and rendering;requirement	Alper Koz;Cevahir Çigla;A. Aydin Alatan	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312689	computer vision;image-based modeling and rendering;index term;digital watermarking;computer science;professional video camera;multimedia;human visual system model;computer graphics (images)	Robotics	52.83572200971702	-57.395791289243725	103116
037c7043a399b0a02aff4b0481ab383f05fa8634	a unified approach for image segmentation using exact statistics	deteccion borde;vision ordenador;test statistique;image segmentation;image processing;edge detection;digitizing;test estadistico;statistical test;procesamiento imagen;segmentation;imagen nivel gris;numerisation;image bruitee;traitement image;computer vision;imagen sonora;noisy image;image niveau gris;numerizacion;vision ordinateur;grey level image;detection bord;segmentacion	The concept of segmentation of a noisy digitized image is developed. The problem is treated as a problem of classification into classes comprising different types of edges and regions. A framework to represent these classes is established so that a unified approach for edge detection and region growing can be considered simultaneously. A two-stage algorithm is developed in this framework	image segmentation	B. Kartikeyan;Anjan Sarkar	1989	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(89)80038-6	computer vision;statistical hypothesis testing;edge detection;image processing;computer science;segmentation-based object categorization;image segmentation;scale-space segmentation;segmentation;computer graphics (images)	Vision	46.772544140112714	-63.39274969715067	103298
011698384fc20be9e7b50f0ef72e055ba4165ede	expression transfer between photographs through multilinear aam's	facial expression recognition;image colour analysis digital photography face recognition;facial expression transfer;active appearance model;computer vision;facial expression analysis;digital photography;face recognition;image colour analysis;photographed expression mapping;active appearance model tensile stress facial animation image databases image analysis image color analysis performance analysis visual databases face detection computer vision;photographed expression mapping facial expression transfer multilinear analysis color image computer vision facial expression analysis facial expression recognition active appearance model;facial expression;color image;multilinear analysis	Expression transfer is a method for mapping a photographed expression performed by a given subject onto the photograph of another person's face. Building on well succeeded previous works by the vision researchers (facial expression decomposition, active appearance models and multilinear analysis, we propose a novel approach for expression transfer based on color images. We attack this problem with methods developed by the computer vision community for facial expression analysis and recognition. Combining active appearance models and multilinear analysis, it's possible to suitably represent and analyze expressive facial images, while separating both style (subject's identity) and content (expressive flavor) from the captured performance	active appearance model;automatic acoustic management;computer vision;multilinear subspace learning	Ives Macedo;Emilio Vital Brazil;Luiz Velho	2006	2006 19th Brazilian Symposium on Computer Graphics and Image Processing	10.1109/SIBGRAPI.2006.18	psychology;computer vision;multimedia;face hallucination;computer graphics (images)	Vision	41.43757502707634	-53.04592989519407	103566
202e3618297fbd25a1b452f2881385f20512c575	the multiple window parameter transform	disjoint support;filtering;vision ordenador;filtrage;analyse amas;parameter estimation image segmentation image edge detection image reconstruction data mining feature extraction surface reconstruction computational complexity polynomials shape;image segmentation;iterative relaxation phase;high dimensionality;systeme multivariable;image processing;feature dimensionality;parameter spaces;estudio comparativo;sistema informatico;extraction forme;filtrado;procesamiento imagen;computer system;transforms computational complexity feature extraction image processing image segmentation;noisy feature hypothesis suppression;nonexistent feature hypotheses;long range correlation;constraint satisfaction;transformacion hough;traitement image;correlated information;windows;computer vision;etude comparative;image size;multiple window parameter transform;cluster analysis;extraccion forma;computational complexity;evidence integration techniques;fenetre;feature extraction;sistema multivariable;comparative study;transforms;parameter space;space requirements;multivariable system;ventana;analisis cluster;vision ordinateur;hough transformation;systeme informatique;transformation hough;disjoint support computational requirements feature dimensionality feature extraction parameter spaces noisy feature hypothesis suppression image segmentation multiple window parameter transform high dimensional features space requirements image size correlated information evidence integration techniques nonexistent feature hypotheses constraint satisfaction networks iterative relaxation phase;high dimensional features;constraint satisfaction networks;pattern extraction;computational requirements	The multiwindow transform, an extension of parameter transform techniques that increase performance and scope by exploiting the long-range correlated information contained in multiple portions of an image, is presented. Multiple-window transforms allow the extraction of high-dimensional features with improvement in accuracy over conventional techniques while keeping linear to low-order-polynomial computational and space requirements with respect to image size and dimensionality of the features. Using correlated information provides a direct link between extracted features and supporting regions in the image. This, coupled with evidence integration techniques, is used to suppress noisy or nonexistent feature hypotheses. Parameter spaces are implemented as constraint satisfaction networks, where feature hypotheses with overlapping support in the image compete. After an iterative relaxation phase, surviving hypotheses have disjoint support, forming a segmentation of the image. Examples show the performance and provide insight about the behavior. >		Andrea Califano;Ruud M. Bolle	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.177381	filter;hough transform;computer vision;image resolution;constraint satisfaction;image processing;feature extraction;computer science;machine learning;comparative research;pattern recognition;mathematics;image segmentation;cluster analysis;parameter space;computational complexity theory;top-hat transform	Vision	47.38641105426415	-60.967598680002396	103583
694faa8a72bcd23e85d69a63326ca799ff9fb4f3	a probability weighted hough transform technique for shape retrieval from noisy imagery	image processing;edge detection;procesamiento imagen;image bruitee;transformacion hough;traitement image;deteccion contorno;imagen sonora;detection contour;noisy image;hough transformation;hough transform;transformation hough;shape retrieval	The detection of straight edges is an important first stage in many recognition tasks. One of the main methods for achieving this objective is the Hough transform (HT) . The Hough transform is a method, first suggested by Hough ( 19 9 2 ) (see also Duda and Hart, 19 7 2 or Illingworth and Kittler, 19 8 7 ), by which analytical curves may be found in images. The detection of straight edges is discussed in this paper although the analysis is equally valid for any parameterization. The HT is an integrating technique in that it sums all features along a line; this has the effect of making it fairly robust when working on imagery where noise is present. However, when very large amounts of noise are present, or in cases where true straight lines need to be distinguished from clutter in the presence of noise, the transform is found to fail dramatically. In this paper a probability weighted Hough transform (PWHT) technique is proposed in which each detected edge pixel increments all corresponding Hough space elements by a weight proportional to the likelihood that, if no noise were present, the edge would be detected with an orientation corresponding to that element. This weight function is derived assuming Gaussian noise as a function of the magnitude and orientation responses of the edge operators and a variant on this function is suggested. The performance of the PWHT is assessed against two conventional types of HT.	clutter;friedrich kittler;hough transform;image noise;pixel;straight skeleton;weight function	M. A. Cooper	1994	Pattern Recognition Letters	10.1016/0167-8655(94)90023-X	hough transform;computer vision;speech recognition;image processing;computer science;pattern recognition;scale-invariant feature transform;mathematics	Vision	47.31105292865668	-62.90885372824222	103678
66bce5cb36545aed8ca0b14dadb19c4c7dcccd55	feature extraction by best anisotropic haar bases in an ocr system	databases;baja resolucion;television;traitement signal;funcion haar;base donnee;algoritmo busqueda;haar wavelet;image resolution;fonction haar;algorithme recherche;optical character recognition;haar function;search algorithm;low resolution;database;basse resolution;base dato;qualite image;image bruitee;imagen sonora;reconnaissance caractere;feature extraction;signal processing;noisy image;image quality;wavelet packet decomposition;reconocimento optico de caracteres;pattern recognition;calidad imagen;reconnaissance forme;extraction caracteristique;reconocimiento patron;procesamiento senal;character recognition;resolution image;reconocimiento caracter;reconnaissance optique caractere	In this contribution, we explore the best basis paradigm for in feature extraction. According to this paradigm, a library of bases is built and the best basis is found for a given signal class with respect to some cost measure. We aim at constructing a library of anisotropic bases that are suitable for the class of 2-D binarized character images. We consider two, a dyadic and a non-dyadic generalization scheme of the Haar wavelet packets that lead to anisotropic bases. For the non-dyadic case, generalized Fibonacci p-trees are used to derive the space division structure of the transform. Both schemes allow for an efficient O(N log N) best basis search algorithm. The so built extended library of anisotropic Haar bases is used in the problem of optical character recognition. A special case, namely recognition of characters from very low resolution, noisy TV images is investigated. The best Haar basis found is then used in the feature extraction stage of a standard OCR system. We achieve very promising recognition rates for experimental databases of syntheti c and real images separated into 59 classes.	artificial neural network;database;dyadic transformation;feature extraction;haar wavelet;image resolution;optical character recognition;programming paradigm;real-time clock;search algorithm;wavelet packet decomposition	Atanas P. Gotchev;Dmytro Rusanovskyy;Roumen Popov;Karen O. Egiazarian;Jaakko Astola	2004		10.1117/12.527065	computer vision;speech recognition;geography;cartography	DB	51.20324957529912	-62.52560414816519	103681
c3b520f915eee6c21659ff9b80ab810a8833f26d	improving image segmentation by gradient vector flow and mean shift	evaluation performance;gradient vector flow;metodo vectorial;image segmentation;performance evaluation;image processing;fonction energie;evaluacion prestacion;procesamiento imagen;mean shift;snake;segmentation;traitement image;energy function;algorithme;algorithm;vector method;segmentation image;funcion energia;methode vectorielle;algoritmo	The classical gradient vector flow (GVF) method suffers from deficiency in the presence of other significant edges adjacent to the real boundary. In this paper, we propose an improved energy function to challenge this problem by consistently reducing the Euclidean distance between the inspected centroid of the real boundary and the estimated one of the snake. Experimental work shows the proposed framework outperforms the classical GVF algorithm in different circumstances.	gradient;image segmentation;mean shift	Tangwei Liu;Huiyu Zhou;Faquan Lin;Yusheng Pang;Ji Wu	2008	Pattern Recognition Letters	10.1016/j.patrec.2007.08.015	computer vision;mean-shift;image processing;computer science;mathematics;geometry;image segmentation;segmentation;algorithm	Vision	46.47308408077538	-63.85281723265089	103729
565e5093a49d150e2633734f9ff56027dab558c4	a shape-based object class detection model using local scale-invariant fragment feature	scale invariant fragments;shape object detection image segmentation image edge detection vectors computational modeling clutter;conjunctive lines shape matching object detection scale invariant fragments;conjunctive lines;weizmann horse dataset shape based object class detection model local scale invariant fragment feature strong clutter background conjunctive short straight segmentation shape descriptor bypassing object scale estimation object deformation textureless image dataset inria horse dataset;shape matching;object detection estimation theory image segmentation;object detection	Detecting object in unseen images is an challenging task because of the strong clutter background, various scale of object and the deformation of class. In this paper, we present a shape-based object detection model using scale-invariant fragment feature which is approximated by conjunctive short straight segments. This is a novel shape descriptor for object detection by bypassing estimation of scale of object in natural scene. Utilizing those local and consistent segments, we improve the robustness of model to natural background and deformation of object. We experiment our model on two texture-less image datasets, INRIA horses dataset and Weizmann horses dataset. The results demonstrate our model outperform those state-of-the-art methods.	approximation algorithm;clutter;object detection;sensor;shape context	Hui Wei;Jinwen Xiao	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7026199	active shape model;computer vision;object-class detection;viola–jones object detection framework;machine learning;pattern recognition;mathematics	Vision	44.70190773811644	-52.86629111704116	103843
a522d98356e34f725c8e77115f1f167e245098e3	fourier domain representation of planar curves for recognition in multiple views	planar shape recognition;fourier transform;projective geometry;shape recognition;satisfiability;multiple views;computer vision;affine homography;matrix computation	Recognition of planar shapes is an important problem in computer vision and pattern recognition. The same planar object contour imaged from di1erent cameras or from di1erent viewpoints looks di1erent and their recognition is non-trivial. Traditional shape recognition deals with views of the shapes that di1er only by simple rotations, translations, and scaling. However, shapes su1er more serious deformation between two general views and hence recognition approaches designed to handle translations, rotations, and/or scaling would prove to be insu5cient. Many algebraic relations between matching primitives in multiple views have been identi7ed recently. In this paper, we explore how shape properties and multiview relations can be combined to recognize planar shapes across multiple views. We propose novel recognition constraints that a planar shape boundary must satisfy in multiple views. The constraints are on the rank of a Fourier-domain measurement matrix computed from the points on the shape boundary. Our method can additionally compute the correspondence between the curve points after a match is established. We demonstrate the applications of these constraints experimentally on a number of synthetic and real images. ? 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	algorithm;computer vision;experiment;fibre channel point-to-point;image scaling;linear algebra;outline of object recognition;pattern recognition;real life;synthetic intelligence	Sujit Kuthirummal;C. V. Jawahar;P. J. Narayanan	2004	Pattern Recognition	10.1016/j.patcog.2003.06.002	fourier transform;computer vision;projective geometry;topology;shape analysis;mathematics;geometry;numerical linear algebra;satisfiability	Vision	50.624113065234006	-53.64285970168222	104034
5a29f3ef8264c219066741e214b20b7a71ea6f89	an evaluation of shape descriptors for image retrieval in human pose estimation	shape descriptor;discrete cosine transform;shape representation;linear transformation;pose estimation	This paper presents an empirical comparison of several shape representations in order to search a database of training examples (silhouettes) for the task of human pose estimation. In particular, we compare the Discrete Cosine Transform (DCT), Lipschitz embeddings and the Histogram of Shape Contexts that has previously demonstrated some success in this task. Our results suggest that a simple linear transformation of the image (such as the DCT) is as effective as the more complex, non-linear methods.	3d pose estimation;computational complexity theory;discrete cosine transform;image retrieval;nonlinear system;shape analysis (digital geometry);shape context	Philip A. Tresadern;Ian D. Reid	2007		10.5244/C.21.65	active shape model;computer vision;pose;3d pose estimation;computer science;heat kernel signature;discrete cosine transform;pattern recognition;linear map	Vision	40.33097518452397	-57.09715804570925	104165
f652cb159a2cf2745aabcbf6a7beed4415e79e34	an efficient image normalization method for face recognition under varying illuminations	image segmentation;image processing;illumination;region segmentation;image enhancement;face recognition;computational complexity	While much progress has been made in face recognition over the last decades, changes in illumination directions still remain as a difficult problem. In this paper, we propose an efficient image normalization method which can overcome illumination effects effectively. The proposed method is based on intensity distribution transformation. However, instead of applying it globally, transformation in intensity distribution is performed for each column independently using one frontal mean face as a reference image. Since it does not require image processing such as image segmentation, the computational complexity is very low and it can circumvent boundary discontinuity caused by region segmentation. Extensive experimental results using Feret database and extended Yale B database demonstrate the competence of the proposed method.	computational complexity theory;feret (facial recognition technology);feret database;facial recognition system;illumination (image);image processing;image segmentation;reflections of signals on conducting lines	Moonhwi Lee;Cheong Hee Park	2008		10.1145/1460096.1460119	image texture;image restoration;computer vision;speech recognition;image processing;computer science;segmentation-based object categorization;pattern recognition;region growing;image segmentation;scale-space segmentation;computational complexity theory	Vision	43.180248263510514	-58.48055062477706	104419
c64130cd6c0531ba8f5aa9759defeabf9b22ad16	recursive x-y cut using bounding boxes of connected components	rectangular blocks;sparc 10 workstations;connected components;image segmentation;letter sized document images;top down;page segmentation;recursive x y cut;image segmentation text analysis pixel image analysis graphics computer science workstations image resolution layout tree graphs;document image processing image segmentation;bounding boxes;letter sized document images recursive x y cut bounding boxes connected components top down page segmentation technique document image rectangular blocks image pixels sparc 10 workstations;document image processing;top down page segmentation technique;image pixels;document image;connected component	A top-down page segmentation technique known as the recursive X-Y cut decomposes a document image recursively into a set of rectanguzar blocks. This paper proposes that the recursive X-Y cut be implemented using bounding bozes of connected components of black pixels instead of using image pizels. The advantage is that great improvement can be achieved in computation. In fact, once bounding boxes of connected components are obtained, the recursive X-Y cut is completed within an order of a second on Spare-10 workutations for letter-sized document images scanned at 300 dpi resolution. keywords: page segmentation, recursive X-Y cut, projection profile, connected components	collision detection;computation;connected component (graph theory);pixel;recursion (computer science);top-down and bottom-up design	Jaekyu Ha;Robert M. Haralick;Ihsin T. Phillips	1995		10.1109/ICDAR.1995.602059	computer vision;connected component;computer science;theoretical computer science;bounding volume hierarchy;computer graphics (images)	Vision	42.91824652717679	-65.76818447039784	104509
2d2b0d1665c0c6dd71d6e89d0378dcd8bae02c8a	noise and intensity invariant moments	simulation ordinateur;image processing;moment invariants;procesamiento imagen;noisy images;image bruitee;traitement image;algorithme;imagen sonora;algorithm;noisy image;invariante;simulacion computadora;computer simulation;invariant;moment invariant;algoritmo	Moments and moment invariants can be normalized such that they become completely insensitive to the absolute intensity of the studied image. When this normalization is applied, moments as well as moment invariants become highly insensitive to noise. This will be shown by computer simulations of noisy bi-level images. Up to high levels of noise the normalized invariants of noisy silhouettes hardly differ from those of perfect silhouettes. The distribution of invariants for a given noise level can be calculated by computer simulations and can be used to further improve the recognition algorithm.	algorithm;black and burst;computer simulation;image moment;invariant (computer science);noise (electronics)	Th. M. Hupkens;J. de Clippeleir	1995	Pattern Recognition Letters	10.1016/0167-8655(94)00110-O	computer simulation;computer vision;discrete mathematics;image processing;computer science;invariant;mathematics;geometry;algorithm	Vision	47.36639704121937	-62.51530317053598	104535
a769845501eae827d1fa6d5234671c452587e23f	implementation and performance study of a generalized iterative algorithm for image reconstruction from the hartley transform intensity	transformation hartley;image processing;transformacion hartley;procesamiento imagen;iterative algorithm;traitement image;reconstruction image;reconstruccion imagen;image reconstruction;hartley transformation;algorithme iteratif sous contrainte;constrained iterative algorithm	Abstract   In many imaging applications only the intensity of the image transform can be observed, and the phase information of the transform is lost. Because the Fourier transform of a real function is complex in general, the phase is needed to reconstruct the real image. On the other hand, the Hartley transform of a real image is always real, and only the sign is lost when the Hartley intensity is recorded. The sign ambiguity is a much less serious defect than the absence of phase knowledge when one is recording the intensity of the Fourier transform of a real image. In this paper, we implement a generalized interative algorithm for reconstructing an image from its Hartley transform intensity. The generalized algorithm is based on the error-reduction and input-output concepts. Programs were developed to implement the algorithm. Results show reconstructed images from their Hartley transform intensity. Also, the performance of the implemented algorithm is monitored during the image reconstruction process.	algorithm;fast fourier transform;hartley (unit);iterative method;iterative reconstruction	E. A. Korany	1993	Pattern Recognition Letters	10.1016/0167-8655(93)90059-M	iterative reconstruction;discrete hartley transform;computer vision;image processing;computer science;mathematics;iterative method;top-hat transform;computer graphics (images)	Vision	52.97921949767953	-61.25169257741619	104551
7e87271b2b5bb9fec223b3271171f64ed04eccc2	3d scene retrieval and recognition with depth gradient images	object representation;experimental tests;3d object representation models;3d computer vision;object retrieval;range image processing;range image;3d recognition and pose;image modeling	The intention of the strategy proposed in this paper is to solve the object retrieval problem in highly complex scenes using 3D information. In the worst case scenario the complexity of the scene includes several objects with irregular or free-form shapes, viewed from any direction, which are self-occluded or partially occluded by other objects with which they are in contact and whose appearance is uniform in intensity/color. This paper introduces and analyzes a new 3D recognition/pose strategy based on DGI (Depth Gradient Images) models. After comparing it with current representative techniques, we can affirm that DGI has very interesting prospects.The DGI representation synthesizes both surface and contour information, thus avoiding restrictions concerning the layout and visibility of the objects in the scene. This paper first explains the key concepts of the DGI representation and shows the main properties of this method in comparison to a set of known techniques. The performance of this strategy in real scenes is then reported. Details are also presented of a wide set of experimental tests, including results under occlusion, performance with injected noise and experiments with cluttered scenes of a high level of complexity.	best, worst and average case;complexity;experiment;gradient;hidden surface determination;high-level programming language;worst-case scenario	Antonio Adán;Pilar Merchán;Santiago Salamanca	2011	Pattern Recognition Letters	10.1016/j.patrec.2011.03.016	computer vision;computer science;machine learning;pattern recognition	Vision	45.28046121982671	-52.47959700228842	104571
67fcd86614aca8e59c43ec1ed4d562a9ac1c561d	segmentation of fingerprint images - a composite method	background noise;doigt;image processing;seuil;estudio comparativo;empreinte;procesamiento imagen;threshold;huella;segmentation;traitement image;etude comparative;comparative study;pattern recognition;finger;ruido fondo;print;umbral;reconnaissance forme;reconocimiento patron;bruit fond;dedo;segmentacion	Abstract   In this paper the limitations of the segmentation of FP images using the directional criterion as suggested in Ref. (1) are pointed out. The equation used for the direction computation becomes undefined when the input image has perfectly uniform regions. To overcome this difficulty a composite method of segmentation is suggested which uses the variance criterion wherever the directional method fails. The failure of the directional method is detected by the low gray variance property of the uniform regions. The composite method takes advantage of both the directional and variance methods. This composite method is tested for a large number of FP images from different sources, and is found to be effective and robust. The results of segmentation of FP images using the composite method and the two methods separately are presented. The desirable features of a segmentation method are also given.	fingerprint	Babu M. Mehtre;B. Chatterjee	1989	Pattern Recognition	10.1016/0031-3203(89)90047-2	computer vision;image processing;computer science;artificial intelligence;comparative research;segmentation-based object categorization;pattern recognition;background noise;scale-space segmentation;segmentation	Vision	46.35052516879976	-63.41552739118879	104649
e2d0f72f30bc0ada6d7b0178a836a25f5785d37f	watermarking of 3d objects based on 2d apparent contours	digital watermarking;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;video	In this paper we describe a novel framework for watermarking 3-D objects via contour information. Instead of classical existing watermarking technologies dealing with 3-D objects that operate on the object itself to insert and extract the mark (3-D/3-D approach), the goal of our work is to retrieve information originally hidden in the apparent contour of the object from resulting 2D images or videos having used the 3D synthetic object (3-D/2-D approach). In this paper we also propose an extension of 2-D polygonal line watermarking algorithm to 3-D silhouette.© (2006) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Jihane Bennour;Jean-Luc Dugelay	2006		10.1117/12.647752	computer vision;simulation;computer science;multimedia	Robotics	52.47952348369447	-57.57523156006901	104675
14e013ca6a01c63e4fa4b4339d00463d0d11a617	statistical models of face images - improving specificity	modelizacion;image tridimensionnelle;image recognition;reconocimiento imagen;arquitectura red;learning algorithm;image processing;procesamiento imagen;model based approach;algorithme apprentissage;architecture reseau;traitement image;gray scale;statistical model;journal;modelisation;image interpretation;interpretacion imagen;reconnaissance image;tridimensional image;face;network architecture;interpretation image;perceptron;reseau neuronal;echelle gris;algoritmo aprendizaje;modeling;red neuronal;escala gris;face image interpretation;imagen tridimensional;neural network;cara	Model based approaches to the interpretation of face images have proved very successful. We have previously described statistically based models of face shape and grey-level appearance and shown how they can be used to perform various coding and interpretation tasks. In the paper we describe improved methods of modelling which couple shape and greylevel information more directly than our existing methods, isolate the changes in appearance due to different sources of variability (person, expression, pose, lighting), and deal with non-linear shape variation. We show that the new methods are better suited to interpretation and tracking tasks.	interpretation (logic);nonlinear system;sensitivity and specificity;spatial variability;statistical model	Gareth J. Edwards;Andreas Lanitis;Christopher J. Taylor;Timothy F. Cootes	1998	Image Vision Comput.	10.1016/S0262-8856(97)00069-3	face;statistical model;computer vision;systems modeling;network architecture;image processing;computer science;artificial intelligence;perceptron;machine learning;grayscale	Vision	46.91404644651163	-58.22817029288296	104763
3e97de8df078ab8b50a005889f602f5dd36d603f	face recognition using gabor features and support vector machines	reconnaissance visage;analisis estadistico;image processing;facies;extraction forme;procesamiento imagen;facial feature extraction;filtro gabor;classification;traitement image;gabor filter;face recognition;statistical analysis;extraccion forma;feature extraction;machine exemple support;analyse statistique;filtre gabor;pattern recognition;facial features;reconnaissance forme;support vector machine;extraction caracteristique;maquina ejemplo soporte;vector support machine;reconocimiento patron;gabor wavelets;pattern extraction;clasificacion	This paper presents a face recognition algorithm by using Gabor wavelet transform for facial features extraction and Support Vector Machines (SVM) for face recognition, Gabor wavelets coefficients are used to represent local facial features. The implementations of our algorithm are as follows: Firstly, facial feature points are located roughly by using a set of node templates. Secondly, Gabor wavelet coefficients are extracted at every facial feature point, and all the Gabor wavelet coefficients are catenated to represent a face image. Lastly, SVM classifiers are used for face recognition. The experimental results demonstrate the effectiveness of our face recognition algorithm.	facial recognition system;support vector machine	Yunfeng Li;Zongying Ou;Guoqiang Wang	2005		10.1007/11539117_20	support vector machine;computer vision;speech recognition;facies;image processing;feature extraction;biological classification;computer science;machine learning;pattern recognition;gabor wavelet;face hallucination	Vision	44.50558629240499	-60.141949538108626	104908
c047c4bf6e18ad29a5eb796ef4447644aee61302	commute times for graph spectral clustering	analisis imagen;modelizacion;fonction green;random graph;metodo espectral;analyse amas;funcion discreta;eigenvalue problem;image segmentation;image processing;funcion green;laplacian spectrum;graph method;analisis forma;grafo aleatorio;laplacian;procesamiento imagen;probleme valeur propre;graphe aleatoire;spectrum;metodo grafo;classification;traitement image;methode graphe;spectral clustering;modelisation;laplacien;discrete function;laplaciano;fonction discrete;cluster analysis;random walk;segmentation image;spectral method;heat kernel;image analysis;analisis cluster;methode spectrale;pattern analysis;marcha aleatoria;graph laplacian;modeling;analyse image;clasificacion;marche aleatoire;green function;analyse forme;eigenvectors;problema valor propio	This paper exploits the properties of the commute time to develop a graph-spectral method for image segmentation. Our starting point is the lazy random walk on the graph, which is determined by the heat-kernel of the graph and can be computed from the spectrum of the graph Laplacian. We characterise the random walk using the commute time between nodes, and show how this quantity may be computed from the Laplacian spectrum using the discrete Green's function. We explore the application of the commute time for image segmentation using the eigenvector corresponding to the smallest eigenvalue of the commute time matrix.	computer cluster;spectral clustering	Huaijun Qiu;Edwin R. Hancock	2005		10.1007/11556121_17	algebraic connectivity;random graph;spectrum;computer vision;combinatorics;laplace operator;image analysis;systems modeling;topology;laplacian matrix;image processing;biological classification;eigenvalues and eigenvectors;computer science;machine learning;mathematics;geometry;heat kernel;green's function;image segmentation;cluster analysis;random walk;spectral clustering;spectral method	AI	46.977721688387774	-62.03323519346215	105081
fbc642de6de156870278f4546c6316507c5fd77e	an object indexing methodology as support to object recognition	vision system;object recognition;traffic signs;systeme intelligent;architecture systeme;systeme vision;autonomous vehicle;autonomous system;sistema inteligente;reconnaissance objet;conceptual clustering;multiple criteria;advanced vehicle control systems;sistema autonomo;computer vision;indexation;systeme autonome;intelligent system;pattern recognition;artificial intelligence;arquitectura sistema;reconnaissance forme;reconocimiento patron;system architecture;pattern recognition systems	This paper describes an object recognition process that uses a step- by-step discrimination approach. The approach combines numerical vision, or object recognition, with conceptual clustering. The application domain is the recognition of road signs which must support semi-autonomous vehicles in their navigational task. The approach features a multiple criteria adaptation criteria.	outline of object recognition	Guy W. Mineau;Mounsif Lahboub;Jean-Marie Beaulieu	1998		10.1007/3-540-64575-6_41	computer vision;method;simulation;object model;computer science;autonomous system;artificial intelligence;cognitive neuroscience of visual object recognition;3d single-object recognition;conceptual clustering	Vision	46.97030289134157	-59.191749568944864	105136
6017b19c4c0e6c0e5b32e54efda6eff78b69d1dd	an efficient 3d geometrical consistency criterion for detection of a set of facial feature points	reconnaissance visage;mimica;iterative method;evaluation performance;tecnologia electronica telecomunicaciones;performance evaluation;image processing;modelo 3 dimensiones;learning;alignment defect;modele 3 dimensions;biometrie;mimique;evaluacion prestacion;localization;biometrics;biometria;procesamiento imagen;three dimensional model;localizacion;traitement image;three dimensional;metodo iterativo;aprendizaje;accuracy;apprentissage;automatic recognition;defaut alignement;precision;face recognition;localisation;defecto alineacion;methode iterative;3d generic face model;facial feature point;face modeling;race images facial feature point;pattern recognition;geometrical consistency criterion;facial features;3 dimensional;reconnaissance forme;facial expression;tecnologias;reconocimiento patron;grupo a;reconocimiento automatico;reconnaissance automatique	We propose a novel efficient 3-dimensional geometrical consistency criterion for detection of a set of facial feature points. Many face recognition methods employing a single image require localization of particular facial feature points and their performance is highly dependent on localization accuracy in detecting these feature points. The proposed method is able to calculate alignment error of a point set rapidly because calculation is not iterative. Also the method does not depend on the type of point detection method used and no learning is needed. Independently detected point sets are evaluated through matching to a 3-dimensional generic face model. Correspondence error is defined by the distance between the feature points defined in the model and those detected. The proposed criterion is evaluated through experiment using various facial feature point sets on face images.	autostereogram;experiment;facial recognition system;image plane;iterative method;sensor	Mayumi Yuasa;Tatsuo Kozakaya;Osamu Yamaguchi	2007		10.1093/ietisy/e91-d.7.1871	three-dimensional space;computer vision;speech recognition;image processing;computer science;artificial intelligence;mathematics;accuracy and precision;feature;statistics	Vision	45.936780203979914	-59.133929478464054	105540
4f894283fda0e2dd1124e242dcc06ad8db5cb9c4	linear and incremental acquisition of invariant shape models from image sequences	shape image sequences image recognition acoustic noise noise shaping cameras computer science image storage rivers libraries;computer vision image sequences;computational techniques;computer vision;shape representation;image sequence;computational techniques linear acquisition incremental acquisition invariant shape models image sequences shape representations of objects storage intensive batch methods affine invariant basis preprocessing state noise;shape modeling;image sequences	We show how to automatically acquire similarity-invariant shape representations of objects from noisy image sequences under weak perspective. The proposed method is linear and incremental, requiring no more than pseudo-inverse. It is based on the observation that the trajectories that points on the object form in weak-perspective image sequences are linear combinations of three of the trajectories themselves, and that the coe cients of the linear combinations represent shape in an a ne-invariant basis. A nonlinear but numerically sound preprocessing stage is added to improve the accuracy of the results even further. Experiments show that attention to noise and computational techniques improve the shape results substantially with respect to previous methods proposed for ideal images.	3d projection;computation;experiment;image noise;ne (complexity);nonlinear system;numerical analysis;preprocessor	Daphna Weinshall;Carlo Tomasi	1993		10.1109/ICCV.1993.378147	active shape model;computer vision;feature detection;computer science;machine learning;pattern recognition;mathematics	Vision	52.75478043897256	-52.71007239986633	105665
9c5e3501a3bf30917863cbc862358002c599ae5f	an extension to hough transform based on gradient orientation		The Hough transform is one of the most common methods for line detection. In this paper we propose a novel extension of the regular Hough transform. The proposed extension combines the extension of the accumulator space and the local gradient orientation resulting in clutter reduction and yielding more prominent peaks, thus enabling better line identification. We demonstrate benefits in applications such as visual quality inspection and rectangle detection.		Tomislav Petkovic;Sven Loncaric	2015	CoRR		hough transform;computer vision;mathematics;geometry;computer graphics (images)	Vision	51.61867395575221	-61.728438939583704	105886
8ce77196ebf908422e4455d1cd1e2717b4a3663e	constraint networks in vision	coupling;vision ordenador;multiple sensors;regularisation;neural networks;neural nets computer vision finite element analysis;neural nets;reconstruction;multiple sensors neural networks machine vision constraint networks augmented lagrangian formulation harris coupled depth slope analog model visual reconstruction finite element theory associated mathematical theory data fusion;coaccion;circuito analogico;contrainte;data fusion;couplage;mixed finite element;regularization;computer vision;constraint networks;analog circuit;constraint;acoplamiento;methode lagrange;machine vision;intelligent networks lagrangian functions application software neural networks computer vision finite element methods surface reconstruction layout analog computers computer networks;metodo lagrange;lagrangian method;vision ordinateur;augmented lagrangian formulation;regularizacion;finite element analysis;reseau neuronal;finite element theory;associated mathematical theory;augmented lagrangian;red neuronal;circuit analogique;harris coupled depth slope analog model;reconstruccion;neural network;visual reconstruction	The author has found many applications in machine vision of Constraint Networks based upon an Augmented Lagrangian formulation. This paper discusses two of the more fundamental applications: to provide a generalization of the Harris Coupled Depth-Slope analog network, and as a method of implementing data fusion (such as between two visual modules). Index Tenns-Computer vision, data fusion, neural networks, regularization, visual reconstruction.	artificial neural network;augmented lagrangian method;computer vision;harris affine region detector;machine vision	David Suter	1991	IEEE Trans. Computers	10.1109/12.106221	regularization;mathematical optimization;augmented lagrangian method;analogue electronics;computer science;artificial intelligence;machine learning;finite element method;mathematics;sensor fusion;coupling;constraint;artificial neural network;algorithm	Vision	52.7277648525431	-57.492513677703776	106392
f0eacc810a1e646824fc86c809a630527d4df854	intrinsic dimensionality estimation with optimally topology preserving maps	eigenvalues and eigenfunctions;topology;estimation theory;fractals;high dimensionality;neural networks;time complexity;topology principal component analysis data visualization image sequences vector quantization fractals system identification monitoring nonlinear distortion neural networks;intrinsic dimensionality estimation;eigenvalues intrinsic dimensionality time complexity image sequence topology preservation principal component analysis vector quantization pattern classification;feature space;eigenvalues;nonlinear distortion;vector quantization;monitoring;system identification;computational complexity;principal component analysis;image sequence;data visualization;pattern classification;synthetic data;intrinsic dimensionality;topology preservation;vector quantisation;eigenvalues and eigenfunctions pattern classification image sequences topology computational complexity vector quantisation estimation theory;image sequences	A new method for analyzing the intrinsic dimensionality (ID) of low dimensional manifolds in high dimensional feature spaces is presented. The basic idea is to rst extract a low-dimensional representation that captures the intrinsic topological structure of the input data and then to analyze this representation, i.e. estimate the intrinsic dimensionality. More speciically, the representation we extract is an optimally topology preserving feature map (OTPM) which is an undirected parametrized graph with a pointer in the input space associated with each node. Estimation of the intrinsic dimensionality is based on local PCA of the pointers of the nodes in the OTPM and their direct neighbors. The method has a number of important advantages compared with previous approaches: First, it can be shown to have only linear time complexity w.r.t. the dimensionality of the input space, in contrast to conventional PCA based approaches which have cubic complexity and hence become computational impracticable for high dimensional input spaces. Second, it is less sensitive to noise than former approaches, and, nally, the extracted representation can be directly used for further data processing tasks including auto-association and classiication. Experiments include ID estimation of synthetic data for illustration as well as ID estimation of a sequence of full scale images. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible	computation;cubic function;estimation theory;full scale;graph (discrete mathematics);pointer (computer programming);synthetic data;time complexity	Jörg Bruske;Gerald Sommer	1998	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.682189	time complexity;nonlinear distortion;discrete mathematics;feature vector;fractal;system identification;eigenvalues and eigenvectors;computer science;machine learning;pattern recognition;mathematics;estimation theory;computational complexity theory;vector quantization;data visualization;statistics;synthetic data;principal component analysis	Vision	50.333786514070205	-63.88559253904557	106458
3ccff30141372019a09c85a1e86474364c81685b	efficient segmentation and plane modeling of point-cloud for structured environment by normal clustering and tensor voting	tensile stress clustering algorithms estimation entropy information theory image segmentation robots;image segmentation;tensile stress;estimation;robots;clustering algorithms;tensors pattern clustering;entropy;information theory point cloud plane modeling structured environment normal clustering tensor voting efficient point cloud segmentation algorithm parameterised normal words distance measures surface normal clustering sparse tensor voting framework adaptive structural extraction labeled point representations;information theory	In this paper, we introduce an efficient point-cloud segmentation algorithm, inspired by efficient segmentation (also named as super-pixel extraction). It uses parameterised “normal words” as distance measures, which are obtained by clustering of surface normals. We estimate the surface normals by the sparse tensor voting framework, which enables adaptive structural extraction, even for the case of missing points. The output result is consist of labeled point representations regarding plane assumptions, which is validated by metrics based on information theory. We show the quality of the segmentation results by experiments on real datasets, and demonstrate its potentials in aiding 2.5D topological navigation for structured environments.	2.5d;algorithm;cluster analysis;experiment;information theory;mobile robot;normal (geometry);pixel;point cloud;sparse matrix	Ming Liu	2014	2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)	10.1109/ROBIO.2014.7090597	robot;computer vision;entropy;estimation;fuzzy clustering;information theory;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;image segmentation;cluster analysis;stress;scale-space segmentation;statistics	Robotics	45.585632390680075	-53.37742060795453	106554
a85ccce202a9fa5994150cfc75ac149a249b1178	a curve evolution approach to object-based tomographic reconstruction	parametric model;evaluation performance;radon transforms;transformacion radon;performance evaluation;image processing;radon transform;analisis textura;curve evolution;efficient algorithm;evaluacion prestacion;regularization method;level set;radon transformation;procesamiento imagen;regularized inversion methods object based tomographic reconstruction texture coefficients background inhomogeneities object inhomogeneities multiple connected objects unconnected objects image reconstruction geometric curve evolution tomographic flow efficient algorithm level set techniques noisy limited view radon transformed data noisy ground penetrating radar data computational cost pixel based regularization methods shape reconstruction;methode contour frontiere;image bruitee;traitement image;image texture;tomographic reconstruction;imagen sonora;radar penetration sol;detection objet;reconstruction image;texture analysis;ground penetrating radar;underground radar imaging;reconstruccion imagen;boundary contour method;inverse method;image reconstruction;shape reconstruction;noisy image;radar imaging;tomographie;radar penetracion suelo;pattern recognition;transformation radon;imagerie radar;reconnaissance forme;reconocimiento patron;tomografia;analyse texture;radiolocalizacion;tomography;radiolocalisation;tomography image reconstruction shape inverse problems data mining level set noise shaping ground penetrating radar pixel focusing;metodo contorno frontera;object detection;ground penetrating radar image reconstruction image texture radon transforms noise radar imaging tomography;noise	"""In this paper, we develop a new approach to tomographic reconstruction problems based on geometric curve evolution techniques. We use a small set of texture coefficients to represent the object and background inhomogeneities and a contour to represent the boundary of multiple connected or unconnected objects. Instead of reconstructing pixel values on a fixed rectangular grid, we then find a reconstruction by jointly estimating these unknown contours and texture coefficients of the object and background. By designing a new """"tomographic flow"""", the resulting problem is recast into a curve evolution problem and an efficient algorithm based on level set techniques is developed. The performance of the curve evolution method is demonstrated using examples with noisy limited-view Radon transformed data and noisy ground-penetrating radar data. The reconstruction results and computational cost are compared with those of conventional, pixel-based regularization methods. The results indicate that the curve evolution methods achieve improved shape reconstruction and have potential computation and memory advantages over conventional regularized inversion methods."""	algorithm;algorithmic efficiency;coefficient;computation;estimated;evolution;object-based language;physical object;pixel;radon;regular grid;tomographic reconstruction	Haihua Feng;W. Clem Karl;David A. Castañón	2003	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.2002.806253	iterative reconstruction;image texture;computer vision;radon transform;parametric model;ground-penetrating radar;computer science;noise;level set;mathematics;tomography;radar imaging;tomographic reconstruction	Vision	53.51342903694658	-65.625486500594	106788
9b6ab9d4de12a1dae899e886780d838a809bec63	human face profile recognition by computer	curva;vision ordenador;learning;perfil;hombre;courbe;profile;curve;computer vision;aprendizaje;apprentissage;automatic recognition;human;pattern recognition;vision ordinateur;face;esplin cubico;spline cubique;reconnaissance forme;reconocimiento patron;profil;reconocimiento automatico;reconnaissance automatique;homme;cubic spline;cara	A human face profile recognition system with learning capability is developed. One key point of the imaging system is the use of back-lighting so that the outline curve can be extracted easily. Cubic B-splines are used to extract the interesting points (turning points) and a total of six interesting points are extracted. From the five curve segments determined by these interesting points 24 features are extracted and used for the recognition. Eighteen people, typically representing most faces here, were tried for the learning and the recognition test. After complete learning the recognition tests were all successful. Human face profile Back-lighting Cubic B-splines Pattern recognition Learning Curvature analysis I. I N T R O D U C T I O N Human face recognition has practical importance in many applications, such as criminal identification and security checks. The recognition process involves highly complex human psychological phenomena and the exact computational procedures are still unknown. However, we did try to develop computational procedures ~t~ for face recognition but the result was not successful. One reason for failure is that the face image can be changed completely in intensity if the face is modified, for instance by cosmetics, oil, dirt, or hair covering. For successful recognition by computer the task must be under rigid constraint. Thus if we ask each person to comb their hair back, open their eyes widely and close their lips tightly, we may be able to train the computer to recognize their face to some degree. We attempted to extract the outline of a face, which provides significant information for recognition, but were unable to develop a stable noise invariant algorithm. Harmon and coworkers 2-6 have studied the automatic identification of human faces either from a psychological point of view or from profile analysis. As it is too difficult to extract the front face features automatically, these authors paid more attention to profile analysis. First, they asked an artist to reduce the profiles to outline curves and they then took nine automatically (later 11) fiducial marks (or interesting points, which are significant in characterization of the outline curves). (See Fig. 1, where the length of line 1-3 is equal to the length of line 1-2.) They then used these nine fiducial marks to generate six feature characteristics (later 11 feature characteristics): * To whom correspondence should be addressed. (1) Protrusion of nose: the distance of point 1 from baseline 2-3. (2) Area right of base line: the absolute magnitude of the areas framed by the profile trace and line 2-3. (3) Base angle of profile triangle: measured between lines 1--2 and 2-3 (angle 123). (4) Wiggle (Hi and Lo): Hi corresponded to the average of the inverse radius of curvature at each sample point between fiducial marks 1 and 3, and Lo corresponded to that of 1 and 2. (5) Distance between fiducials: R12, the length of the line 1-2, etc. (6) Angles between fiducials: angle 341, etc. Finally they used a minimum weighted distance criterion to classify each person's face. In this paper we try to develop face recognition procedures by profile analysis. One of our points of distinction from Harmon's method is that we take a profile image by direct photography with back-lighting and obtain the outline curves automatically, not by an artist's drawing. Another difference is that the subjects we encounter are oriental faces, whose profile outlines are not as significantly curved as European faces (for example, many noses are not high and the protrusions of many chins are not significantly sharp). The other difference is that some of the features extracted by computer are different from those in Harmon's papers. We use a B-spline to extract some interesting points (or turning points) on the outline curve and then from these interesting points obtain six interesting points. From these six interesting points we obtain 24 features. For each person, we take three face images and calculate each feature's mean and standard deviation. This is the learning mode. In the recognition mode, we match the input feature vector to the library files established during the learning process. We reject the match of a person if most of	algorithm;automatic identification and data capture;b-spline;baseline (configuration management);computation;cubic function;facial recognition system;feature vector;fiducial marker;pattern recognition;point of view (computer hardware company);requirements analysis;wiggle stereoscopy;xfig	Chyuan Jy Wu;Jun S. Huang	1990	Pattern Recognition	10.1016/0031-3203(90)90013-B	face;spline;computer vision;computer science;artificial intelligence;mathematics;geometry;curve	Vision	46.452181017597105	-60.05544393980097	106825
03161081b47eba967fd3e663c57ec2f99f66eebd	face and facial feature localization	reconnaissance visage;busqueda informacion;settore inf 01 informatica;face and feature localization;illumination;occlusion;facies;componente logicial;image databank;information retrieval;support vector machine svm;localization;occultation;luminance;oclusion;composant logiciel;localizacion;general techniques;classification;support vector;skin color;face recognition;localisation;skin color model;recherche information;banco imagen;banque image;software component;facial features;ocultacion;imagen color;eclairement;clasificacion;image couleur;color image;alumbrado;luminancia	In this paper we present a general technique for face and facial features localization in 2D color images with arbitrary background. In a previous work we studied an eye localization module, here we focus on mouth localization. Given in input an image that depicts a sole person, first we exploit the color information to limit the search area to candidate mouth regions, then we determine the exact mouth position by means of a SVM trained for the purpose. In this way we achieve both the localization of the face and of its mouth, so exploiting the advantages of component based approaches, like the treatment of partial occlusions and pose independence. The algorithm is also robust to scale and illumination variations. We report the results of the separate modules of the single feature classifiers and their combination on images of several public databases.	algorithm;color;database;display resolution;feature model;internationalization and localization;performance	Paola Campadelli;Raffaella Lanzarotti;Giuseppe Lipori;Eleonora Salvi	2005		10.1007/11553595_123	facial recognition system;support vector machine;computer vision;internationalization and localization;color image;facies;occultation;biological classification;computer science;artificial intelligence;component-based software engineering;luminance;programming language	Vision	45.297682203394146	-59.50287366173848	106851
22436872922033dc2c36808efc286e015f53bc05	efficient color image retrieval using hue distribution similarity	databases;distribution;analisis contenido;filtracion;information retrieval;edit distance;algorithme;algorithm;histogram;content analysis;histogramme;indexing;recherche information;indexation;similarity;indizacion;hue;similarite;recuperacion informacion;analyse contenu;filtration;imagen color;histograma;distribucion;image couleur;color image;algoritmo;image retrieval	In content-based image indexing and retrieval (IIR), hue component histograms of images are widely used for indexing the images in an image database. It is to retrieve all color images whose distance between hue distributions are within some threshold distance of the query image. Edit distance has been successfully used as a similarity measure. Our earlier O(b 2 ) algorithm computing the edit distance between two angular histograms, where b is the number of bins in the hue histogram, tends to be too slow for users to wait for the outputs when applied to every image in the database. For this reason, we design two filtration functions that eliminate most color images from consideration as possible outputs quickly and exact edit distances are only computed for those remaining images. We are still guaranteed to find all similar hue distributions and the filtration technique gives significant speeds-ups.	color image;image retrieval	Sung-Hyuk Cha	2003		10.1117/12.476313	computer vision;pattern recognition;mathematics;information retrieval	Vision	42.89332026236168	-60.853963036885844	106870
4d4be112c180d5a4484fe6e17e506ad6e1853f08	improving long range and high magnification face recognition: database acquisition, evaluation, and enhancement	reconnaissance visage;video databases;vision ordenador;high resolution;image processing;facies;algoritmo adaptativo;image databank;surveillance;aumento;biometrie;face database;authentication;biometrics;database;biometria;procesamiento imagen;base dato;base donnee video;image restoration;traitement image;grossissement;computer vision;authentification;reduccion ruido;long range surveillance;adaptive algorithm;image enhancement;haute resolution;magnification;vigilancia;autenticacion;installation exterieure;face recognition;algorithme adaptatif;instalacion exterior;long distance;monitoring;imagen borrosa;outdoor installation;blurred image;noise reduction;image quality;banco imagen;banque image;alta resolucion;reduction bruit;base de donnees;pattern recognition;human identification;super resolution;vision ordinateur;rapport signal bruit;long range;relacion senal ruido;monitorage;reconnaissance forme;image floue;reconocimiento patron;signal to noise ratio;monitoreo;video database;indoor installation;instalacion interior;installation interieure	In this paper, we describe a face video database, UTK-LRHM, acquired from long distances and with high magnifications. Both indoor and outdoor sequences are collected under uncontrolled surveillance conditions. To our knowledge, it is the first database to provide face images from long distances (indoor: 10–16 m and outdoor: 50–300 m). The corresponding system magnifications range from 3· to 20· for indoor and up to 284· for outdoor. This database has applications in experimentations with human identification and authentication in long range surveillance and wide area monitoring. Deteriorations unique to long range and high magnification face images are investigated in terms of face recognition rates based on the UTK-LRHM database. Magnification blur is shown to be a major degradation source, the effect of which is quantified using a novel blur assessment measure and alleviated via adaptive deblurring algorithms. A comprehensive processing algorithm, including frame selection, enhancement, and super-resolution is introduced for long range and high magnification face images with a large variety of resolutions. Experimental results using face images of the UTK-LRHM database demonstrate a significant improvement in recognition rates after assessment and enhancement of degradations. 2007 Elsevier Inc. All rights reserved.	adaptive filter;algorithm;authentication;database;deblurring;elegant degradation;facial recognition system;gaussian blur;lasso;pixel;super-resolution imaging;uncontrolled format string;wavelet	Yi Yao;Besma Roui-Abidi;Nathan D. Kalka;Natalia A. Schmid;Mongi A. Abidi	2008	Computer Vision and Image Understanding	10.1016/j.cviu.2007.09.004	computer vision;image processing;computer science;authentication;computer graphics (images)	Vision	45.39005010031659	-60.41929041376499	106897
bc8221265579032dde52f46b5adca39072755841	object evidence extraction using simple gabor features and statistical ranking	modelizacion;object recognition;vision ordenador;fiabilidad;reliability;analisis estadistico;image processing;extraction forme;procesamiento imagen;reconnaissance objet;probabilistic approach;filtro gabor;traitement image;computer vision;modelisation;detection objet;detector proximidad;gabor filter;hierarchical classification;statistical analysis;extraccion forma;object oriented;enfoque probabilista;approche probabiliste;feature extraction;fiabilite;analyse statistique;filtre gabor;pattern recognition;classification hierarchique;invariante;oriente objet;vision ordinateur;reconnaissance forme;extraction caracteristique;reconocimiento patron;modeling;orientado objeto;clasificacion jerarquizada;pattern extraction;invariant;proximity detector;object detection;detecteur proximite	Several novel methods based on locally extracted object features and spatial constellation models have recently been introduced for invariant object detection and recognition. The accuracy and reliability of the methods depend on the success of both tasks: evidence extraction and spatial constellation model search. In this study an accurate and efficient method for evidence extraction is introduced. The proposed method is based on simple Gabor features and their statistical ranking.	algorithm;constellation model;experiment;gabor filter;object detection;supervised learning	Joni-Kristian Kämäräinen;Jarmo Ilonen;Pekka Paalanen;Miroslav Hamouz;Heikki Kälviäinen;Josef Kittler	2005		10.1007/11499145_14	computer vision;speech recognition;systems modeling;image processing;feature extraction;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;invariant;reliability;object-oriented programming	Vision	46.22662851926161	-59.37765461371862	107050
75a3bb729f8d7bb1ca7bafae91abc9d252440d8f	monocular template-based 3d reconstruction of extensible surfaces with local linear elasticity	elasticity;solid modelling elasticity image reconstruction poisson ratio;surface reconstruction three dimensional displays materials shape image reconstruction cameras deformable models;conference paper;image reconstruction;geometrical constraints monocular template based 3d reconstruction local linear elasticity template based extensible surface reconstruction isometric surface reconstruction conformal surface reconstruction stretching energy poisson ratio parameter patch based formulation mechanical constraints;poisson ratio;solid modelling	We propose a new approach for template-based extensible surface reconstruction from a single view. We extend the method of isometric surface reconstruction and more recent work on conformal surface reconstruction. Our approach relies on the minimization of a proposed stretching energy formalized with respect to the Poisson ratio parameter of the surface. We derive a patch-based formulation of this stretching energy by assuming local linear elasticity. This formulation unifies geometrical and mechanical constraints in a single energy term. We prevent local scale ambiguities by imposing a set of fixed boundary 3D points. We experimentally prove the sufficiency of this set of boundary points and demonstrate the effectiveness of our approach on different developable and non-developable surfaces with a wide range of extensibility.	3d reconstruction;elasticity (data store);experiment;extensibility;isometric projection;misiurewicz point;patch (computing);surface-mount technology;synthetic intelligence	Abed Malti;Richard I. Hartley;Adrien Bartoli;Jae-Hak Kim	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2013.200	iterative reconstruction;poisson's ratio;mathematical optimization;mathematics;geometry;elasticity	Vision	53.59542445150317	-52.711221770386835	107219
48cebbda0997d6587580083e4424d2cef592672b	invariance of stereo images via the theory of complex moments	stereotypie;translation invariant;image recognition;reconocimiento imagen;transformation affine;numero complejo;moment;algorithm performance;image processing;momento;geometrie algorithmique;etude experimentale;edge detection;extraction forme;computational geometry;procesamiento imagen;corners;traitement image;transformacion fourier rapida;deteccion contorno;algorithme;algorithm;detection contour;estereotipia;rotation invariance;extraccion forma;stereotypy;resultado algoritmo;affine transformation;reconnaissance image;performance algorithme;invariante;geometria computacional;complex number;transformation fourier rapide;estudio experimental;pattern extraction;invariant;nombre complexe;transformacion afin;fast fourier transformation;moment invariant;algoritmo	For an approximate epipolar registration of stereo images the transformation between the images can be approximated from an affine one to a rotational and translational one. This property can be used to find the point of correspondences of stereo images in conjunction with complex moments which are themselves rotational invariant. Corners are chosen as features and around them an intensity kernel is defined and complex moments are calculated. Then the correspondences are found from similar corners by finding the L2 norm of the invariances between the two images. From the matched points the respective affine models of the images are also created.		Debashis Bhattacharya;Satyabroto Sinha	1997	Pattern Recognition	10.1016/S0031-3203(96)00177-X	computer vision;fast fourier transform;edge detection;topology;image processing;computational geometry;computer science;invariant;affine transformation;mathematics;geometry;moment;fundamental matrix;complex number;stereotypy	Vision	49.31099719663137	-60.35102696336336	107259
a73f71ecb1039b1d27ac7dabbbed12b77f6b9d02	photon detection and color perception at low light levels	poisson distribution computer vision image colour analysis image sensors night vision object detection;low light levels;photonics;colored noise;color;chromaticity diagram;photon detection;macadam ellipses;power distribution;low light levels photon detection chromaticity diagram macadam ellipses;image color analysis;photoreceptors;low light levels photon detection color perception uncertainty macadam ellipses human cone spectral sensitivity functions poisson distribution ellipse orientation ellipse size chromaticity diagram elliptic shape uncertain color measurements color patch normalized spectral power distribution color vision photon emission surveillance cameras photography low light imaging tone mapping techniques night vision machine vision application;light sources;photonics power distribution image color analysis color photoreceptors colored noise light sources	Working under low light conditions is of particular interest in machine vision applications such as night vision, tone-mapping techniques, low-light imaging, photography, and surveillance cameras. This work aims at investigating the perception of color at low light situations imposed by physical principles governing photon emission. The impact of the probabilistic nature of photon emission on our color perception becomes more significant at low light levels. In this regard, physical principles are leveraged to develop a framework to take into account the effects of low light level on color vision. Results of this study shows that the normalized spectral power distribution of light changes with light intensity and becomes more uncertain at low light situation as a result of which the uncertainty of color perception increases. Furthermore, a color patch at low light levels give rise to uncertain color measurements whose chromaticities form an elliptic shape inside the chromaticity diagram around the high intensity chromaticity of the color patch. The size of these ellipses is a function of the light intensity and the chromaticity of color patches however the orientation of the ellipses depends only on the patch chromaticity and not on the light level. Moreover, the results of this work indicate that the spectral composition of light is a determining factor in the size and orientation of the ellipses. The elliptic shape of measured samples is a result of the Poisson distribution governing photon emission together with the form of human cone spectral sensitivity functions and can partly explain the elliptic shape of MacAdam ellipses.	closed-circuit television;color vision;diagram;machine vision;tone mapping	Mehdi Rezagholizadeh;James J. Clark	2014	2014 Canadian Conference on Computer and Robot Vision	10.1109/CRV.2014.45	color histogram;color temperature;computer vision;color model;colors of noise;photonics;lightness;color normalization;colorimetry;chromaticity;dominant wavelength;spectral color	Vision	53.7340762397048	-56.267579135846475	107498
ca26e9329459c6bd0122da7dc6339301952c1a3f	gabor-based texture representation in aams	texture representation aams gabor;computer science and information systems;generic model;image texture computational complexity gabor filters image matching image representation;image matching;conference;real property;gabor filters;active appearance model;active appearance model gabor filters active shape model deformable models image storage image coding active contours iterative algorithms biometrics image matching;image texture;gst;deformable objects;commercial;gabor filter;local structure;computational complexity;image representation;active appearance models;residential;excessive storage active appearance model image texture gabor filter image representation image matching deformable object computational complexity;conference proceeding	Active Appearance Models (AAMs) are generative models which can describe deformable objects. However, the texture in basic AAMs is represented using intensity values. Despite its simplicity, this representation does not contain enough information for image matching. In this paper, we firstly propose to utilize Gabor filters to represent the image texture. The benefit of Gabor-based representation is that it can express local structures of an image. As a result, this representation can lead to more accurate matching when condition changes. Given the problem of the excessive storage and computational complexity of the Gabor, three different Gabor-based image representations are used in AAMs: (1) GaborD is the sum of Gabor filter responses over directions, (2) GaborS is the sum of Gabor filter responses over scales, and (3) GaborSD is the sum of Gabor filter responses over scales and directions. Through a large number of experiments, we show that the proposed Gabor representations lead to more accurate and reliable matching between model and images.	active appearance model;computational complexity theory;experiment;gabor atom;gabor filter;generative model;image registration;image texture	Ya Su;Xinbo Gao;Dacheng Tao;Xuelong Li	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811625	computer vision;active appearance model;computer science;machine learning;pattern recognition;mathematics;gabor wavelet	Vision	39.20304883232638	-58.43506991816566	107601
85b621ab12d30529fcd1aa7658986afc707c161c	searching parameter spaces with noisy linear constraints	theoretical framework;probability;high dimensionality;parameter estimation extraterrestrial phenomena equations transforms computer science noise robustness application software computer vision pattern recognition costs;linear constraint;satisfiability;heuristic estimate parameter spaces searching parameter estimation pattern recognition hough transforms noisy linear constraints course to fine search paradigm ellipsoidal cells constraint surfaces;transforms parameter estimation pattern recognition probability;affine transformation;transforms;parameter space;pattern recognition;cell division;parameter estimation	Hough transform can be viewed as exhaustive search of parameter spaces. The exceptional noise robustness of the technique makes it attractive for many applications in computer vision and pattern recognition. However, for parameter estimation problems in high dimensional spaces a severe penalty in time arid storage niust be paid. This paper develops a theoretical framework to facilitate rapid search of such spaces. The bmic method is predicated upon some invariant properties of affine transformations and on the coarse to fine search paradigm. The parameter space is divitled into oirerlapping ellipsoidal cells. The gooclncw or va1idit.y of a. cell is measured by the number of constraint sivfaces passing through the cell and a heuristic est,irnat.e of the probability that t,he cell coiit,ains ii soliitioti point satisfying most of t h c x constrailits. T h e iiat.iira1 advantages of the ellipsoidal cell tlivisioirs are tlisciissrd. Experimental resi i l ts show that, tlie met hod Iixs i-a\t,l!superior search eficieiicy compared t o c i n ~ c ~ n t l \ Ikiioicii algorithms.	algorithm;brute-force search;computer vision;estimation theory;heuristic;hough transform;pattern recognition;programming paradigm	Amit Bandapadhay;Jung Liang Fu	1988		10.1109/CVPR.1988.196289	mathematical optimization;machine learning;probability;affine transformation;mathematics;geometry;parameter space;estimation theory;cell division;statistics;satisfiability	Vision	46.28439655584989	-53.23931820316229	107674
b33f73f5caf810f40261ef7cb4bc678b626115f4	image retrieval based on texture and color method in btc-vq compressed domain	databases;histograms;image coding;block truncation coding image retrieval texture method color method btc vq compressed domain graphic information compressed images image compression;color method;transform coding;image texture;texture method;image compression;image color analysis;image colour analysis;feature extraction;block truncation coding;compressed images;image retrieval image coding information retrieval histograms graphics transform coding image storage image databases digital images vector quantization;image texture block codes image coding image colour analysis image retrieval;btc vq compressed domain;graphic information;block codes;image retrieval	Because of high volume of graphic information, the retrieval of compressed images is one of the needs of information era. One of the rapid methods for image compression which has the capability to maintain important information of images for retrieval is Block Truncation Coding (BTC). In this article a new method for retrieval of images compressed by BTC has been provided. This method has been examined on a database consisting of 9983 images with different contents and its results have been compared with similar methods.	block truncation coding;color histogram;database;image compression;image retrieval;iterative method;sensitivity and specificity;vector quantization	Mahdi Rezaei;Mohammad Reza Sarshar	2007	2007 9th International Symposium on Signal Processing and Its Applications	10.1109/ISSPA.2007.4555277	block code;image texture;computer vision;visual word;transform coding;block truncation coding;feature extraction;image retrieval;image compression;computer science;pattern recognition;histogram;mathematics;statistics;computer graphics (images)	Vision	39.194013172174614	-62.10932164982822	107715
11df9e9c7020f9df38e03bca2b3bddfa6c8e0ada	direct passive navigation	eigenvalues and eigenfunctions;erbium;metodo cuadrado menor;surface structure;methode moindre carre;vision ordenador;nonlinear optics;image motion analysis;movimiento;least squares method;metodo descomposicion;methode decomposition;optical computing;structure and motion eigenvalue decomposition least squares optical flow planar surfaces;motion;eigenvalue decomposition;iterative program;computer vision;navigation brightness matrix decomposition symmetric matrices transmission line matrix methods optical computing nonlinear optics image motion analysis nonlinear equations eigenvalues and eigenfunctions;eigenvalue;programa iterativo;symmetric matrices;mechanical engineering;brightness;planar surfaces;decomposition method;reconstruction image;navigation;least squares;surface plane;optical imaging;matrix equation;brillance;thesis;matrix decomposition;image reconstruction;mouvement;valor propio;image sequence;least square;nonlinear equation;nonlinear equations;vision ordinateur;valeur propre;secuencia imagen;reconstruccion de imagen;optical flow;transmission line matrix methods;linear equations;plane surface;structure and motion;brillantez;programme iteratif;sequence image;superficie plana	In this correspondence, we show how to recover the motion of an observer relative to a planar surface from image brightness derivatives. We do not compute the optical flow as an intermediate step, only the spatial and temporal brightness gradients (at a minimum of eight points). We first present two iterative schemes for solving nine nonlinear equations in terms of the motion and surface parameters that are derived from a least-squares fomulation. An initial pass over the relevant image region is used to accumulate a number of moments of the image brightness derivatives. All of the quantities used in the iteration are efficiently computed from these totals without the need to refer back to the image. We then show that either of two possible solutions can be obtained in closed form. We first solve a linear matrix equation for the elements of a 3 × 3 matrix. The eigenvalue decomposition of the symmetric part of the matrix is then used to compute the motion parameters and the plane orientation. A new compact notation allows us to show easily that there are at most two planar solutions.	density matrix;eigenvalue;gradient;iteration;least squares;nonlinear system;optical flow;quantity;solutions;the matrix;brightness;notation	Shahriar Negahdaripour;Berthold K. P. Horn	1987	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1987.4767884	mathematical optimization;nonlinear system;calculus;mathematics;geometry;least squares	Vision	50.894491996508485	-56.729493521808934	107828
75b9e767626f89b0aee07bd5c586f5752505a06e	zero crossings of a non-orthogonal wavelet transform for object location	hypothesis generation;human faces;image matching wavelet transforms feature extraction image segmentation object detection face recognition;image segmentation;cost function;venus;image matching;object location;matching algorithm;text analysis;newspaper photographs zero crossings nonorthogonal wavelet transform object location object segmentation photographs feature extraction basis functions gaussian function multilevel hypothesis matching algorithm wavelet coefficients model matching stage human faces;multilevel hypothesis;wavelet transforms;object segmentation;springs;photographs;wavelet transform;face recognition;newspaper photographs;feature extraction;model matching;basis functions;face;low pass filters;model matching stage;humans;zero crossings;nonorthogonal wavelet transform;wavelet coefficients;object detection;gaussian function;wavelet transforms feature extraction image segmentation springs humans face cost function low pass filters venus text analysis	In this paper we address the task of segmentation of objects from photographs. A method of extraction of features based on the zero-crossings of a wavelet transform is described. The wavelet transform basis functions are derived from the second derivative of a Gaussian function. The extracted features are then used in a multilevel hypothesis generate and test algorithm to locate the objects of interest. The matching algorithm is based on the springs and templates framework of Fischler and Eschlanger (1973). The zero-crossings of the wavelet coefficients at different scales are combined in the model-matching stage to generate possible candidates. We apply this method to segment human faces from newspaper photographs.		Mahesh Venkatraman;Venu Govindaraju	1995		10.1109/ICIP.1995.537579	facial recognition system;wavelet;computer vision;text mining;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;computer science;machine learning;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;fast wavelet transform;lifting scheme;wavelet transform	HCI	39.47274586829656	-63.53139350918809	108004
c9cef8f4ae12ca8b3baacb70acb28dbc9078281e	an image content description technique for the inspection of specular objects	busqueda informacion;signal image and speech processing;traitement signal;forma cilindrica;surface inspection;image segmentation;image processing;recherche image;information retrieval;metodo imagen;procesamiento imagen;traitement image;cylindrical shape;quantum information technology spintronics;recherche information;control superficie;feature extraction;signal processing;metrologia superficie;image method;segmentation image;metrologie surface;pattern recognition;reconnaissance forme;extraction caracteristique;reconocimiento patron;forme cylindrique;surface metrology;methode image;controle surface;procesamiento senal;image retrieval	This paper proposed an image content description method within the context of specular surface inspection. Such a method is based on a preliminary research concerning the generation of specific stripe patterns for the visual enhancement of defective surface parts of cylindrical specular objects. The goal of this paper is to address the stripe pattern interpretation within a general approach. For this purpose, different pattern recognition processes, consisting not only of the combination of different image segmentation, feature retrieval, and classification, but also of feature combination and selection, will be considered. Three top-down and one bottom-up approaches are evaluated for retrieving the most appropriate feature sets in terms of highest classification rates. It will be demonstrated that following a combination and appropriate selection of these feature sets, even better rates can be reached. With only half of the initial features, an increase of more than 2% is observable.	bottom-up proteomics;box counting;feature extraction;feature model;feature selection;flying-spot scanner;grayscale;image segmentation;mathematical optimization;maxima and minima;os-tan;observable;pattern recognition;relevance;stepwise regression;stripes;top-down and bottom-up design	Yannick Caulier;Salah Bourennane	2008	EURASIP J. Adv. Sig. Proc.	10.1155/2008/195263	computer vision;image processing;feature extraction;image retrieval;computer science;artificial intelligence;signal processing;image segmentation;feature	Vision	44.6847167332172	-61.76826946699213	108175
13e835ca293610e517059b0f3629438920288334	q-pso: fast quaternion-based pose estimation from rgb-d images		We present a pipeline for fast object pose estimation using RGB-D images, which does not rely on image features or machine learning. We are interested in segmenting objects with large variety in app.earance, from lack of texture to presence of strong textures, with a focus on the task of robotic grasping. The proposed pipeline is divided into an object segmentation part and a pose estimation part. We first find candidate object clusters using a graph-based image segmentation technique. A modified Canny edge detector is introduced for extracting robust graph edges by fusing RGB and depth information. A suitable cost function is used for building the graph, which is then partitioned using the concept of internal and external differences between graph regions. The extracted object regions are then used to initialize the 3D position of a quaternion-based Particle Swarm Optimization algorithm (Q-PSO), that fits a 3D model of the object to the depth image. The fitness function is based on depth information only and the quaternion formulation avoids singularities and the need for conversions between rotation representations. In this work we focus on the details of the GPU implementation of Q-PSO, in order to fully exploit the highly parallelizable nature of the particular implementation of the particle swarm algorithm, and discuss critic implementation details. We then test the app.roach on different publicly available RGB-D object datasets, and provide numeric comparisons with other state-of-the-art methods, as well as a discussion on robustness and an extension to the case of articulated objects. We show how Q-PSO offers comparable performances to current learning-based app.roaches, while not suffering from the problems of lack of features in objects or issues related to training, such as the need for a large training set and long training times.	3d pose estimation;phase-shift oscillator	Stefano Rosa;Giorgio Toscana;Basilio Bona	2018	Journal of Intelligent and Robotic Systems	10.1007/s10846-017-0714-3	canny edge detector;robustness (computer science);feature (computer vision);pose;3d pose estimation;computer vision;artificial intelligence;image segmentation;particle swarm optimization;mathematics;fitness function	Robotics	40.61598777149412	-56.02772674938535	108223
17b18235b31a95bc42d7ce598eb592b9ba9a389e	detecting facial features on image sequences using cross-verification mechanism	reconnaissance visage;image features;detection forme;illumination;extraction forme;shape detection;deteccion forma;face recognition;extraccion forma;image sequence;facial features;secuencia imagen;eclairement;pattern extraction;sequence image;alumbrado	An approach is presented to detect facial features on image sequences. Face regions are first detected across the sequence, then a PCA-based feature detector for still images is used to detect facial features on each single frame until the resulted features of three adjacent frames don't change significantly. Given a frame with correct features, the features of its neighbor frames are first detected by the still-image feature detector, then verified and corrected by using the smoothness constraint and the planar surface motion constraint. Experiments have been performed on image sequences taken under different environments, and prove the presented method to be quite robust and efficient over variable poses, ages and illumination conditions.	sensor	Zhenyun Peng;Wei Hong;Luhong Liang;Guangyou Xu;HongJiang Zhang	2001		10.1007/3-540-45453-5_144	facial recognition system;computer vision;computer science;pattern recognition;feature;computer graphics (images)	Vision	45.84724055421195	-58.094939689483816	108315
417f8e41732cb7ade6de1e107eb156edde765b91	template matching: matched spatial filters and beyond	eficacia sistema;correlacion;filtering;filtrage;base donnee;sistema experto;algoritmo busqueda;image processing;least squares method;learning;cross correlation;etude experimentale;algorithme recherche;aproximacion;filtrado;search algorithm;performance systeme;database;calcul erreur;procesamiento imagen;base dato;mathematical filters;data bases;discriminant function;system performance;traitement image;approximation;computer vision;aprendizaje;error analysis;filter design;reconstruction image;apprentissage;nonlinear systems;reconstruccion imagen;image reconstruction;matching;least square;target discrimination;pattern recognition;spatial filtering;calculo error;matched filters;optimization;systeme expert;correlation;reseau neuronal;signal to noise ratio;template matching;estudio experimental;red neuronal;eigenvectors;neural network;hyperbf networks;principal component;expert system	-Template matching by means of cross-correlation is common practice in pattern recognition in spite of its drawbacks. This paper reviews some results on how these shortcomings can be removed. Several techniques (Matched Spatial Filters, Synthetic Discriminant Functions, Principal Components Projections and Reconstruction Residuals) are reviewed and compared on a common task: locating eyes in a database of faces. New variants are also proposed and compared: least squares Discriminant Functions and the combined use of projections on eigenfunctions and the corresponding reconstruction residuals. Finally, approximation networks are introduced in an attempt to improve filter design by the introduction of nonlinearity. © 1997 Pattern Recognition Society. Published by Elsevier Science Ltd. Template matching Correlation Neural networks Learning HyperBF networks Principal components	approximation;cross-correlation;discriminant;feature vector;filter design;least squares;neural networks;nonlinear system;pattern recognition;synthetic intelligence;template matching	Roberto Brunelli;Tomaso A. Poggio	1997	Pattern Recognition	10.1016/S0031-3203(96)00104-5	computer vision;image processing;computer science;artificial intelligence;mathematics;least squares;expert system;algorithm;statistics	Vision	44.12135645902547	-59.512434638252444	108501
19fcb95815e4c225b250f7deed9be3e90963933d	evaluación de la calidad de las imágenes de rostros utilizadas para la identificación de las personas	image processing	Automatic evaluation of face image quality is an important topic in the development of face recognition systems. This paper describes a framework for assessing the conformity of face images with the parameter set in the standard ISO/IEC 19794-5 that determines if given images possess an identification value and can be used in personal identification documents. New algorithms for image analysis and image classification with respect to parameters evaluated in the proposed framework are presented. The proposal is implemented as a dynamic link library (DLL), offering many advantages for the use in different applications. Good and bad quality images are evaluated, and the feasibility of the use of this framework is shown experimentally.	algorithm;computer vision;conformity;dynamic-link library;experiment;facial recognition system;image analysis;image quality;linear algebra	Heydi Mendez Vazquez;Leonardo Chang;Dayron Rizo-Rodriguez;Annette Morales-González	2012	Computación y Sistemas		art;performance art;cartography	Vision	42.38680609487902	-61.0243557123479	108536
cc89b8dc481ae2d1fb8757df8ede9c83799feac0	a condition number for point matching with application to registration and postregistration error estimation	image matching;motion;conditioning;objective function;feature extraction;affine transformation;image registration;image points correspondence image analysis feature representation error estimation image registration;image matching image sequences image registration feature extraction;registration;condition number;image analysis;feature representation;error estimate;error analysis image motion analysis image registration videos eigenvalues and eigenfunctions detectors testing satellites remote sensing infrared imaging;matching method;image sequences	Selecting salient points from two or more images for computing correspondence is a well studied problem in image analysis. This paper describes a new and effective technique for selecting these tiepoints using condition numbers, with application to image registration and mosaicking. Condition numbers are derived for point-matching methods based on minimizing windowed objective functions for 1) translation, 2) rotation-scaling-translation (RST) and 3) affine transformations. Our principal result is that the condition numbers satisfy KTrans ≤ KRST ≤ KAffine. That is, if a point is ill-conditioned with respect to point-matching via translation then it is also unsuited for matching with respect to RST and affine transforms. This is fortunate since KTrans is easily computed whereas KRST and KAffine are not. The second half of the paper applies the condition estimation results to the problem of identifying tiepoints in pairs of images for the purpose of registration. Once these points have been matched (after culling outliers using a RANSAC-like procedure) the registration parameters are computed. The postregistration error between the reference image and the stabilized image is then estimated by evaluating the translation between these images at points exhibiting good conditioning with respect to translation. The proposed method of tiepoint selection and matching using condition number provides a reliable basis for registration. The method has been tested on a large number of diverse collection of images–multi-date Landsat images, aerial images, aerial videos, and infra-red images. A web site where the users can try our registration software is available and is being actively used by researchers around the world. Index Words: Registration, Conditioning, Feature representation, Motion This research was supported by the Office of Naval Research under ONR Grant Number N00014-02-1-0318. January 7, 2004 Submitted to PAMI	aerial photography;condition number;image analysis;image registration;image scaling;image stitching;intel matrix raid;random sample consensus;reverse semantic traceability;window function	Charles S. Kenney;B. S. Manjunath;Marco Zuliani;Gary A. Hewer;Alan Van Nevel	2003	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2003.1240118	computer vision;mathematical optimization;image analysis;feature extraction;computer science;image registration;motion;conditioning;condition number;pattern recognition;affine transformation;mathematics	Vision	51.34755132140768	-52.777881623632126	108564
6f7ae416d5b86d51334e760aadcf39f1038addae	a framework for efficient correspondence using feature interrelations	polynomials noise robustness deformable models colored noise computer vision stability explosions computational complexity labeling eigenvalues and eigenfunctions;complexity theory;image segmentation;image transformation invariant;image matching;statistical framework;correspondence problem;intuitive voting scheme;computer vision;accuracy;computational modeling;point set matching point pattern correspondence problem feature interrelation image transformation invariant image thresholding computer vision statistical framework intuitive voting scheme;statistical analysis;statistical analysis computer vision image matching image segmentation;feature extraction;pattern recognition;image thresholding;point set matching;robustness;point pattern correspondence problem;noise;feature interrelation	We propose a formulation for solving the point pattern correspondence problem, relying on transformation invariants. Our approach can accommodate any degree of descriptors thus modeling any kind of potential deformation according to the needs of each specific problem. Other potential descriptors such as color or local appearance can also be incorporated. A brief study on the complexity of the methodology is made which proves to be inherently polynomial while allowing for further adjustments via thresholding. Initial experiments on both synthetic and real data demonstrate its potentials in terms of accuracy and robustness to noise and outliers.	color;correspondence problem;experiment;polynomial;synthetic intelligence;thresholding (image processing)	Angelos-Georgios Tsolakis;Manolis Falelakis;Anastasios Delopoulos	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4761227	computer vision;feature extraction;computer science;noise;machine learning;pattern recognition;mathematics;accuracy and precision;image segmentation;correspondence problem;computational model;statistics;robustness	Vision	44.72841704498365	-53.18990786219999	108591
41239210ffcd9c055085d8a642810a169414105c	model-based classification methods of global patterns in dermoscopic images	skin cancer feature extraction gaussian distribution image classification image colour analysis image retrieval markov processes medical image processing;image retrieval model based classification methods dermoscopic images global patterns identification pattern analysis melanoma diagnosis method finite symmetric conditional markov model gaussian model gaussian mixture model bag of features histogram model;cancer;skin;image classification;markov random field mrf bag of features classification distance metrics between models gaussian mixture model global pattern;image colour analysis;feature extraction;medical image processing;markov processes;classification image color analysis gaussian processes markov processes feature extraction level set image segmentation;gaussian distribution;image retrieval	In this paper different model-based methods of classification of global patterns in dermoscopic images are proposed. Global patterns identification is included in the pattern analysis framework, the melanoma diagnosis method most used among dermatologists. The modeling is performed in two senses: first a dermoscopic image is modeled by a finite symmetric conditional Markov model applied to L*a*b* color space and the estimated parameters of this model are treated as features. In turn, the distribution of these features are supposed that follow different models along a lesion: a Gaussian model, a Gaussian mixture model, and a bag-of-features histogram model. For each case, the classification is carried out by an image retrieval approach with different distance metrics. The main objective is to classify a whole pigmented lesion into three possible patterns: globular, homogeneous, and reticular. An extensive evaluation of the performance of each method has been carried out on an image database extracted from a public Atlas of Dermoscopy. The best classification success rate is achieved by the Gaussian mixture model-based method with a 78.44% success rate in average. In a further evaluation the multicomponent pattern is analyzed obtaining a 72.91% success rate.	classification;color space;dermoscopy;esthesia;extraction;histogram;image retrieval;markov chain;maximum-entropy markov model;mixture model;normal statistical distribution;pattern recognition	Aurora Sáez;Carmen Serrano;Begoña Acha	2014	IEEE Transactions on Medical Imaging	10.1109/TMI.2014.2305769	normal distribution;computer vision;contextual image classification;feature detection;feature extraction;image retrieval;computer science;machine learning;pattern recognition;mathematics;skin;markov process;hidden markov model;statistics;cancer	Vision	40.61124046303584	-63.95187200554306	108754
4cb616d32410269e3d69874833bb729f1599c286	comments on fingerprints of two-dimensional edge models	deteccion borde;edge detection;detection bord	Shah, Sood, and Jain ( Comput. Vision Graphics Image Process  34 , 1986, 321–343) have recently published an interesting scale-space analysis of pulse and staircase edge models, both one- and two-dimensional. In this note we comment upon Shah, Sood, and Jain's analysis of the two-dimensional step edge, pulse edge, and staircase edge models. Their derivation of the scale-space images and fingerprints can be simplified by taking advantage of a key geometric feature of Gaussian filters, namely, rotational invariance. The fingerprints of these three models can easily and directly be geometrically deduced from the fingerprints of the one-dimensional models. The fingerprints should be viewed as cylinders over a base curve which is precisely the fingerprint of the corresponding one-dimensional edge model. In this way fingerprints of the two-dimensional models can be immediately visualized from their one-dimensional counterparts. We also demonstrate that the range of influence of one edge upon another edge located a distance  d away begins at a scale of  d /3.	fingerprint	M. Ann Piech	1988	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(88)80046-X	computer vision;combinatorics;edge detection;computer science;mathematics;geometry	Vision	49.213347747073094	-65.50723302084688	108814
fa2837e28b6953317cbdb64c72b66929e574fdd3	joint segmentation and registration through the duality of congealing and maximum likelihood estimate		In this paper we consider the task of joint registration and segmentation. A popular method which aligns images and simultaneously estimates a simple statistical shape model was proposed by E. Learned-Miller and is known as.congealing. It considers the entropy of a simple, pixel-wise independent distribution as the objective function for searching the unknown transformations. Besides being intuitive and appealing, this idea raises several theoretical and practical questions, which we try to answer in this paper. First, we analyse the approach theoretically and show that the original congealing is in fact the DC-dual task (difference of convex functions) for a properly formulated Maximum Likelihood estimation task. This interpretation immediately leads to a different choice for the algorithm which is substantially simpler than the known congealing algorithm. The second contribution is to show, how to generalise the task for models in which the shape prior is formulated in terms of segmentation labellings and is related to the signal domain via a parametric appearance model. We call this generalisation unsupervised congealing. The new approach is applied to the task of aligning and segmenting imaginal discs of Drosophila melanogaster larvae.	alignment;convex function;dual;estimated;experiment;imaginal discs;larva;loss function;markov chain;markov random field;microscope device component;optimization problem;pixel;segmentation action;statistical shape analysis;total disc replacement;unsupervised learning;algorithm;biologic segmentation;cell transformation;registration - actclass	Boris Flach;Archibald Pontier	2015	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-319-19992-4_27	mathematical optimization;pattern recognition;statistics	Vision	49.376325794305245	-52.237841588410355	108824
0f41a537205a20e2efea2d259f60341a2433e33b	morphological corner detection	corner detection;detectors image edge detection calibration gray scale morphology information technology probes brightness computational efficiency computer vision;edge detection;computational cost morphological corner detection morphological closing operator asymmetrical closing morphological transformations structuring elements orientation brightness comparisons	This paper presents a new operator for corner detection. This operator uses a variant of the morphological closing operator, which we have called asymmetrical closing. It consists of the successive application of different morphological tranformations using different structuring elements. Each of these structuring elements used to probe the image under study is tuned to affect corners of different orientation and brightness. We found that this kind of approach, based on brightness comparisons, leads to better quality results than others and is achieved at a lower computational cost.	algorithmic efficiency;closing (morphology);computation;corner detection;mathematical morphology;morphological parsing;motion estimation;point of interest	Robert Laganière	1998		10.1109/ICCV.1998.710731	corner detection;computer vision;edge detection;computer science;mathematics	Vision	45.49078758992126	-65.28081048774901	108925
14df251338201ff4bdccedfbc6dfc3aeef70ad47	saliency-based notabilia re-detection via as-is primary transfer	over the horizon cooperation saliency based notabilia redetection as is primary transfer robust color matching scheme landmark sign redetection landmark design redetection probe vehicles inherent susceptivity indexing chromatic diversity nondeterministic saliency pattern restoration ambient light;image matching;image restoration;mobile robots;robot vision;image colour analysis;image color analysis complexity theory probes robustness vehicles indexing fractals;robot vision image colour analysis image matching image restoration mobile robots object detection;object detection	A robust color matching scheme is presented for future re-detection of landmark sign/design annotated by probe vehicles. By indexing inherent susceptivity to chromatic diversity in terms of the as-is primary, the re-detection process nondeterministically restore the saliency patterns spanning significant discrepancy of ambient light. Annotated and re-detected saliency patterns maintain various types of notabilia to be identified for facilitating over-the-horizon cooperation.	discrepancy function;file spanning	Kohji Kamejima	2012	2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2012.6343733	mobile robot;image restoration;computer vision;computer science;machine learning	Arch	39.686516545386986	-54.49588208030627	109052
fb76d9181214a31b9e658a2647eafd4d2cdb3099	affine-invariant correlation of gray-scale characters using gat iteration	gaussian noise;image degradation;q measurement;degradation;affine invariant correlation;convergence;random gaussian noise affine invariant correlation gray scale characters gat iteration correlation based matching reinforcement normalized cross correlation matching measure definite canonicalization image degradation robustness iterative global affine transformation numerals;image matching;optical character recognition;geometry;image degradation robustness;global affine transformation;correlation methods;correlation based matching reinforcement;noise robustness;gray scale;gat iteration;acceleration;invariance;iterative methods;definite canonicalization;numerals;successive iteration method ntt cyber space laboratories;gray scale degradation equations convergence acceleration gaussian noise laboratories noise robustness q measurement;random gaussian noise;gray scale character recognition;affine transformation;matching measure;gaussian noise geometry invariance correlation methods optical character recognition image matching iterative methods;iterative global affine transformation;normalized cross correlation;gray scale characters	Introduces a new technique of affine-invariant correlation of gray-scale characters by reinforcing correlation-based matching in two ways. The first method is the use of normalized cross-correlation as a matching measure based on definite canonicalization in order to realize robustness against image degradation. The second method is the application of an iterative global affine transformation (GAT) to the input image, so as to realize the maximal affine-invariant correlation with the target image. The advantages and effectiveness of the proposed method are both shown theoretically and demonstrated through preliminary experiments using gray-scale images of numerals subject to a wide range of affine transformations and random Gaussian noise.	iteration	Toru Wakahara;Yoshimasa Kimura	1999		10.1109/ICDAR.1999.791862	acceleration;gaussian noise;mathematical optimization;degradation;convergence;computer science;invariant;cross-correlation;affine transformation;iterative method;optical character recognition;grayscale;statistics;numeral system	NLP	43.57487138082289	-57.71806342733406	109165
84f9f2e4bb9317669182e33d7a9053a015207dd5	the response of texture features to illuminant rotation	texture classification;texture features;image texture;illuminant tilt angle texture features illuminant rotation texture classification linear texture filters;feature extraction;pattern classification;nonlinear filters surface topography surface texture gabor filters image texture cameras transfer functions frequency domain analysis geometry testing;lighting;pattern classification image texture feature extraction lighting	Rotation of the illuminant source about a subject textured surface can cause catastrophic failure of texture classification schemes. This is due to the variation of texture feature output that can occur when the illuminant direction is varied. This paper uses theory and experiment to show that the outputs of linear texture filters, and their features, are sinusoidal functions of the illuminant’s tilt angle.		Mike J. Chantler;Ged McGunnigle	2000		10.1109/ICPR.2000.903700	bidirectional texture function;image texture;computer vision;feature extraction;computer science;pattern recognition;lighting;texture compression;texture filtering;projective texture mapping	Vision	41.02031791361825	-61.0870343353994	109364
1344c189aa2ca5b25d85ba12e0238c1e6f156688	invariants of a pair of conics revisited	vision ordenador;modele geometrique;cross ratio;forme quadratique;geometrie solide;quadratic form;geometria solidos;forma cuadratica;computer vision;cone;pattern recognition;invariante;vision ordinateur;reconnaissance forme;reconocimiento patron;solid geometry;conic;invariant;geometrical model;modelo geometrico	The invariants of a pair of quadratic forms and a pair of coplanar conies are revisited following [1, 5, 2]. For a given pair of conies, with their associated matrices Ci and C2, we show that Trace(Cj1Ci), Trac^C^1 C2) and |Ci |/|C21 are only invariants of associated quadratic forms, but not invariants of the conies. Two of true invariants of the conies are Trace(C~1Ci) |C->I . Trace  |C,| ants of the conies are geometrically interpreted, in terms of cross ratios, through the common self-polar triangle of the two conies.		Long Quan;Patrick Gros;Roger Mohr	1992	Image Vision Comput.	10.1016/0262-8856(92)90049-9	topology;cone;quadratic form;invariant;solid geometry;pure mathematics;mathematics;geometry;conic section;cross-ratio	Vision	49.39836857234095	-60.163330116844605	109394
8cebad693659cbc95cc1fa4123349e1a50ba2e66	improving difference operators by local feature detection	processus gauss;laplacian of gaussian;flatness;difference operator;operateur differentiel;image processing;recherche image;best approximation;shape descriptor;edge detection;derivatives;laplacian;procesamiento imagen;differential operators;courbure;geometria discreta;traitement image;deteccion contorno;busca local;local adaptation;detection contour;laplacien;laplaciano;discrete approximation;technology and engineering;local features;geometrie discrete;differential operator;discrete geometry;mejor aproximacion;curvatura;curvature;digital image;gaussian process;planeite;proceso gauss;local search;content based retrieval;recherche par contenu;recherche locale;operador diferencial;planeidad;fitness function;meilleure approximation;image retrieval	Differential operators are required to compute several characteristics for continuous surfaces, as e.g tangents, curvature, flatness, shape descriptors We propose to replace differential operators by the combined action of sets of feature detectors and locally adapted difference operators A set of simple local feature detectors is used to find the fitting function which locally yields the best approximation for the digitized image surface For each class of fitting functions, we determine which difference operator locally yields the best result in comparison to the differential operator Both the set of feature detectors and the difference operator for a function class have a rigid mathematical structure, which can be described by Groebner bases In this paper we describe how to obtain discrete approximates for the Laplacian differential operator and how these difference operators improve the performance of the Laplacian of Gaussian edge detector.	feature detection (computer vision)	Kristof Teelen;Peter Veelaert	2006		10.1007/11907350_33	discrete geometry;differential operator;constant coefficients;computer vision;operator theory;mathematical analysis;topology;semi-elliptic operator;image processing;operator norm;image retrieval;computer science;mathematics;geometry;fourier integral operator	Vision	49.855804930386	-64.04645448169575	109615
c8d84fc463d76653494382273577e0fc3b856591	a discrete labelling approach to attributed graph matching using sift features	graph theory;structure methods;image features;clutter;image video registration structural methods for pattern recognition;image processing;discrete labelling approach;image matching;set theory feature extraction graph theory image matching;comunicacion de congreso;geometrical information discrete labelling approach attributed graph matching sift features local invariant feature extraction methods image features matching;deformable models;joints;set theory;local invariant feature extraction methods;feature matching;graph matching;attributed graph matching;image video registration;robot vision;geometrical information;feature extraction;image features matching;conference report;sift features;automation robots robot vision;pattern recognition image recognition;mathematical model;pattern recognition;noise clutter mathematical model contamination labeling deformable models joints;structural methods for pattern recognition;contamination;pattern recognition systems;image recognition pattern recognitionrobot vision;extraction method;labeling;invariant feature;noise	Local invariant feature extraction methods are widely used for image-features matching. There exist a number of approaches aimed at the refinement of the matches between image-features. It is a common strategy among these approaches to use geometrical criteria to reject a subset of outliers. One limitation of the outlier rejection design is that it is unable to add new useful matches. We present a new model that integrates the local information of the SIFT descriptors along with global geometrical information to estimate a new robust set of feature-matches. Our approach encodes the geometrical information by means of graph structures while posing the estimation of the feature-matches as a graph matching problem. Some comparative experimental results are presented.	feature extraction;graph (discrete mathematics);matching (graph theory);refinement (computing);rejection sampling;scale-invariant feature transform	Gerard Sanroma;René Alquézar;Francesc Serratosa	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.239	computer vision;labeling theory;image processing;feature extraction;computer science;noise;graph theory;machine learning;pattern recognition;mathematical model;mathematics;clutter;contamination;feature;matching;set theory	Robotics	44.73444497417618	-53.211911836565804	110082
e9bbbd67407dc6d23b10502129af12a6e6c1ccdd	are multifractal multipermuted multinomial measures good enough for unsupervised image segmentation?	cluster algorithm;aerial images image segmentation multinomial measures multifractal measures texture representation;image segmentation;image texture image segmentation;image texture;aerial image;rotation invariance;fractals image segmentation image analysis clustering algorithms filtering us department of transportation geometry satellites information analysis image texture analysis	By extending multinomial measures, a new class of self-similar multifractal measures is developed for texture representation. Two multifractal features have been shown to be suitable for texture discrimination and classification. Their use within a supervised segmentation framework provides us with satisfactory results. In this paper we complete the survey on these features by showing their rotation invariant property and their scaling behaviour. Both properties are particularly important for analyzing aerial images because the geographical elements can appear in different orientations and scales. Then, an automatic clustering algorithm based on a watershed technique is used for the segmentation of real world images. The experimental results are encouraging.	image segmentation;multifractal system;multinomial logistic regression	Lui Kam;Jacques Blanc-Talon	2000		10.1109/CVPR.2000.855799	image texture;computer vision;range segmentation;computer science;machine learning;segmentation-based object categorization;pattern recognition;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	42.40577602134477	-64.18752545527599	110197
c4b02b2e97b19c0ce0df2c781e82bdb5593fc4ad	efficient fingerprint search based on database clustering	fingerprint search;evaluation performance;image recognition;reconocimiento imagen;base donnee;algoritmo busqueda;algorithm performance;performance evaluation;query processing;algorithme k moyenne;methode echelle multiple;search space;algorithme recherche;biometrie;traitement requete;evaluacion prestacion;orientation field;search algorithm;fingerprint classification;biometrics;database;biometria;base dato;metodo escala multiple;feature space;accuracy;hierarchical classification;automatic recognition;precision;resultado algoritmo;dactyloscopie;signal classification;reconnaissance image;performance algorithme;pattern recognition;classification hierarchique;classification signal;algoritmo k media;k means algorithm;multiscale method;tratamiento pregunta;reconnaissance forme;classification automatique;reconocimiento patron;automatic classification;clasificacion automatica;clasificacion jerarquizada;k means clustering;fingerprint identification;reconocimiento automatico;reconnaissance automatique	Fingerprint identification has been a great challenge due to its complex search of database. This paper proposes an efficient fingerprint search algorithm based on database clustering, which narrows down the search space of fine matching. Fingerprint is non-uniformly partitioned by a circular tessellation to compute a multi-scale orientation field as the main search feature. The average ridge distance is employed as an auxiliary feature. A modified K-means clustering technique is proposed to partition the orientation feature space into clusters. Based on the database clustering, a hierarchical query processing is proposed to facilitate an efficient fingerprint search, which not only greatly speeds up the search process but also improves the retrieval accuracy. The experimental results show the effectiveness and superiority of the proposed fingerprint search algorithm. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	cluster analysis;database;feature vector;fingerprint;hierarchical and recursive queries in sql;k-means clustering;online and offline;pattern recognition;search algorithm;web search engine	Manhua Liu;Xudong Jiang;Alex ChiChung Kot	2007	Pattern Recognition	10.1016/j.patcog.2006.11.007	beam search;computer science;artificial intelligence;machine learning;accuracy and precision;best-first search;algorithm;k-means clustering	Vision	43.592504512924926	-60.9752037113773	110473
87b54761e5fbf8a2197091aa966a152c74883734	computational strategies for object recognition	two dimensional images;image recognition;object recognition;reconocimiento imagen;vision ordenador;image numerique;analisis escena;analyse scene;articulo sintesis;image processing;article synthese;noisy data;image understanding;procesamiento imagen;3 d objects;model based vision;psi_mic;segmentation;traitement image;computer vision;feature vector;knowledge;rule based interpretation;system;theory;estructura datos;imagen numerica;reconnaissance image;pattern recognition;algorithms;relaxation;design;vision ordinateur;optimization;structure donnee;hough transform;digital image;reconnaissance forme;reconocimiento patron;experimentation;review;data structure;matching model;scene analysis	This article reviews the available methods for automated identification of objects in digital images. The techniques are classified into groups according to the nature of the computational strategy used. Four classes are proposed: (1) the simplest strategies, which work on data appropriate for feature vector classification, (2) methods that match models to symbolic data structures for situations involving reliable data and complex models, (3) approaches that fit models to the photometry and are appropriate for noisy data and simple models, and (4) combinations of these strategies, which must be adopted in complex situations. Representative examples of various methods are summarized, and the classes of strategies with respect to their appropriateness for particular applications.	computation;data structure;digital image;feature vector;norm (social);outline of object recognition;signal-to-noise ratio	Paul Suetens;Pascal Fua;Andrew J. Hanson	1992	ACM Comput. Surv.	10.1145/128762.128763	hough transform;computer vision;design;feature vector;data structure;image processing;computer science;artificial intelligence;relaxation;system;knowledge;segmentation;theory;digital image;computer graphics (images)	Graphics	46.97376838617852	-60.92110498722932	110644
15f98108487c3cf7d85555c2dc74977873b96026	breakpoint skeletal representation and compression of document images	piecewise linear;interpolation;image coding;data compression;interpolation image representation image reconstruction image coding data compression document image processing feature extraction;lossy compression;document images;euclidean distance;linear interpolation;image representation;feature extraction;image reconstruction;skeletal breakpoint;lossless image reconstruction breakpoint skeletal representation breakpoint skeletal compression skeletal medial axis extraction lossy compression bitonal document images true euclidean distance map piecewise linear breakpoints binary object linear interpolation fractional dilation antialiasing pruning radius;document image processing;image coding image reconstruction skeleton image segmentation computer science euclidean distance piecewise linear techniques interpolation 1f noise sampling methods;medial axis	Summary form only given. We present a new method for representation and (lossy) compression of bitonal document images. The technique extracts a skeletal medial axis from each object using a true Euclidean distance map of the image and then finds piecewise linear breakpoints in the skeleton to create a breakpoint skeletal representation, b.p.s. The b.p.s. is encoded for each object as a set of triples. The original binary object is reconstructed by first reconstructing the skeleton using linear interpolation between breakpoints and then fractionally dilating each point on the skeleton with the (linearly interpolated) radius, r/sub i/. For noninteger r/sub i/ fractional dilation provides a natural antialiasing in the reconstructed image. Breakpoints can be extracted to preserve fine detail or a more coarse representation by tightening or relaxing the pruning radius respectively. If, in extracting breakpoints, the pruning radius is set to zero, the reconstruction is almost lossless, but the compression is worse.	breakpoint	David Tam;William A. Barrett;Bryan S. Morse;Eric N. Mortensen	1998		10.1109/DCC.1998.672317	data compression;iterative reconstruction;lossy compression;computer vision;mathematical optimization;medial axis;piecewise linear function;feature extraction;interpolation;pattern recognition;euclidean distance;mathematics;linear interpolation;statistics	Vision	50.38062992641834	-63.84686419602905	110667
73b6a8677a04ecd458151960723de742dbd984ac	low-cost laser range scanner and fast surface registration approach	image tridimensionnelle;vision ordenador;image processing;componente logicial;laser;sistema adquisicion dato;procesamiento imagen;software systems;telemetro laser;scanneur;composant logiciel;escaner;data acquisition system;scanner;traitement image;gray scale;computer vision;reconstruction image;laser range finder;reconstruccion imagen;image reconstruction;software component;pattern recognition;telemetre laser;tridimensional image;object reconstruction;vision ordinateur;reconnaissance forme;reconocimiento patron;echelle gris;systeme acquisition donnee;measurement technique;data acquisition;escala gris;laser range scanner;imagen tridimensional	In the last twenty years many approaches for contact-free measurement techniques for object surfaces and approaches for 3d object reconstruction have been proposed; but often they still require complex and expensive equipment. Not least due to the rapidly increasing number of efficient 3d hardand software system components, alternative lowcost solutions are in great demand. We propose such a low-cost system for 3d data acquisition and fast pairwise surface registration. The only hardware requirements are a simple commercial hand-held laser and a standard grayscale camera.	data acquisition;grayscale;iterative closest point;mobile device;requirement;software system	Simon Winkelbach;Sven Molkenstruck;Friedrich M. Wahl	2006		10.1007/11861898_72	computer vision;image processing;computer science;data acquisition;computer graphics (images)	Vision	49.38441053745506	-56.52649351338901	110825
805d54dc4e5699a7c9848c044fddd2044091c697	synthesizing for face recognition	image recognition;spline;least squares approximations;image synthesizing;minimum bending;splines mathematics face recognition least squares approximations rendering computer graphics;landmark locating;probes;splines mathematics;face recognition;shape;2d bending deformation methods 2d face recognition face synthesizing strategy nonfrontal view input images performance improvement pose variance image synthesizing minimum bending synthesizing strategy thin plate splines moving least squares;face face recognition shape probes spline image recognition;pose variance;landmark locating image synthesizing face recognition pose variance minimum bending;face;rendering computer graphics	Pose variance is one of the most challenging problem to 2D face recognition. In this paper, a novel frontal view face synthesizing strategy is introduced to improve the performance of traditional face recognition methods on non-frontal view input images. Given several non-frontal input faces, our minimum bending synthesizing strategy automatically picks up and merges information, to realize most natural frontal view face synthesizing. It is shown by experiments that our strategy could effectively reduce the influence of pose variance to face recognition, and rather than traditional landmark based approaches, our strategy does not require perfect landmark locating results.	experiment;facial recognition system	Yuelong Li;Jufu Feng	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6115619	facial recognition system;face;spline;computer vision;face detection;shape;computer science;machine learning;pattern recognition;three-dimensional face recognition;mathematics	Vision	41.84058506892184	-56.54958182065991	110952
78ce94c60fb6cc1c80f4b916ade882cf6bcaf30e	a line segment based approach for 3d motion estimation and tracking of multiple objects	image tridimensionnelle;eficacia sistema;line segment matching;architecture systeme;estimation mouvement;filtro kalman;image processing;etude experimentale;edge detection;estimacion movimiento;filtre kalman;performance systeme;procesamiento imagen;outdoor scenes;kalman filter;motion estimation;pairing;system performance;traitement image;tracking movable target;deteccion contorno;algorithme;algorithm;detection contour;multiple objectives;line segment detection;object tracking;image sequence;pattern recognition;tridimensional image;arquitectura sistema;secuencia imagen;poursuite;reconnaissance forme;emparejamiento;reconocimiento patron;system architecture;extended kalman filter;appariement;estudio experimental;sequence image;imagen tridimensional;persecucion y continuacion;algoritmo	A line segment based approach for 3D motion estimation and tracking of multiple objects from a monocular image sequence is presented. Objects are described by means of 3D line segments, and their presence in the scene is associated with the detection of 2D line segments on the image plane. A change detection algorithm is applied to detect moving objects on the image plane and a Hough-based algorithm is used to individuate 2D line segments. 3D parameters of each line segment are estimated, at each time instant, by means of an extended Kalman filter (EKF), whose observations are the displacements of 2D line segment endpoints on the image plane. Results on both synthetic and real scenes are presented.	algorithm;extended kalman filter;hough transform;image plane;motion estimation;synthetic intelligence	Gian Luca Foresti	1998	IJPRAI	10.1142/S0218001498000488	kalman filter;computer vision;edge detection;image processing;computer science;video tracking;motion estimation;pairing;extended kalman filter;line segment intersection;computer graphics (images)	Vision	48.78909995746385	-57.23551109594378	111108
1772f47feaa2cb1ec0c820816151adf2bccd92f1	planar shape classification using hidden markov model	markov processes computer vision computerised pattern recognition computerised picture processing;hidden markov model;shape recognition;computerised pattern recognition;shape hidden markov models helium computer vision curve fitting fourier transforms predictive models pattern recognition speech recognition handwriting recognition;computer vision;shape classification;computerised picture processing;markov processes;occlusion planar shape classification segmentation planar shape recognition hidden markov models autoregressive parameters shape contour perturbation	In this paper, we present a planar shape recognition approach based on hidden Markov model and autoregressive parameters. This approach segments closed shapes into segments and explores the characteristic relations between consecutive segments to make classification a t finer level. The algorithm can tolerate a lot of shape contour perturbation and moderate amount of occlusion. Also, the overall classification scheme is independent of shape orientation. Excellent recognition result has been reported. A distinct advantage of the approach is that the classifier does not have to be trained all over again when a new class of shapes is added.	algorithm;autoregressive model;cellular automaton;hidden markov model;hidden surface determination;markov chain;shape context	Yang He;Amlan Kundu	1991		10.1109/CVPR.1991.139653	active shape model;computer vision;computer science;machine learning;pattern recognition;mathematics;markov process;markov model;hidden markov model;signature recognition	Vision	41.090662991117625	-55.99936835111302	111211
465ba2ea96cfc2956d498c9cd50fd606b6cb585c	wide baseline stereo matching based on scale invariant feature transformation with hybrid geometric constraints	wide baseline stereo matching;local homography constraints;feature based methods;sift ncc;stereo image processing geometry image matching;epipolar constraint;2d projective transformation;scale invariant feature transformation algorithm;hybrid matching scheme;lsm method;3d space;epipolar geometry;hybrid geometric constraints;sift algorithm;sift based robust weighted least squares matching;area based methods;adaptive scale;sift features;robust matching propagation;bidirectional selection strategy;geometric deformations;error matches;feature based sift matching method;error matches wide baseline stereo matching hybrid geometric constraints geometric deformations illumination changes scale invariant feature transformation algorithm sift algorithm hybrid matching scheme feature based methods area based methods sift based robust weighted least squares matching lsm method 2d projective transformation normalised cross correlation metric adaptive scale sift features sift ncc sift lsm robust matching propagation epipolar geometry local homography constraints geometrical consistency checking feature based sift matching method 3d space epipolar constraint bidirectional selection strategy;sift lsm;geometrical consistency checking;normalised cross correlation metric;illumination changes	Wide baseline stereo matching is a challenging task because of the presence of significant geometric deformations and illumination changes within the images. Based on the scale invariant feature transformation (SIFT) algorithm, this study proposes a new hybrid matching scheme that uses both the feature-based and the area-based methods to find reliable matches from sparse to dense under different geometric constraints. Firstly, the authors propose a SIFT-based robust weighted least squares matching (LSM) method modelled by a two-dimensional (2D) projective transformation to establish the initial correspondences and their local homographies. In this method, a normalised cross correlation metric modified with an adaptive scale and an orientation of the SIFT features (SIFT-NCC) is proposed to find a good initial alignment for the SIFT-LSM. Secondly, a robust matching propagation using the SIFT-NCC starts from the initial matches under an epipolar geometry and the local homography constraints; geometrical consistency checking is used simultaneously to identify the false matches. Thirdly, they use an improved, feature-based SIFT matching method to find the correspondences from the points that are not coplanar in the 3D space under an epipolar constraint only. A bidirectional selection strategy is used to remove the error matches.	baseline (configuration management);computer stereo vision	Huachao Yang;Mei Yu;Shubi Zhang	2014	IET Computer Vision	10.1049/iet-cvi.2013.0265	computer vision;computer science;machine learning;pattern recognition;scale-invariant feature transform;mathematics;epipolar geometry	Vision	44.71056208615349	-52.68108609039029	111289
e8cfbae2c911da336c600c8cfb0dd532403fbbfa	material classification using morphological pattern spectrum for extracting textural features from material micrographs	granularite;grain size;vision ordenador;grain size distribution;distribution dimension particule;image processing;analisis textura;texture image;extraction forme;particle size distribution;procesamiento imagen;morphological operation;spectrum;imagen nivel gris;texture features;traitement image;gray scale;granulometria;image texture;computer vision;morphological classification;texture analysis;analisis morfologico;extraccion forma;grosor grano;image niveau gris;clasificacion morfologica;morphological analysis;classification morphologique;pattern classification;analyse morphologique;industrial application;vision ordinateur;classification automatique;classification accuracy;automatic classification;echelle gris;grey level image;clasificacion automatica;distribucion dimension particula;analyse texture;pattern extraction;escala gris;grosseur grain;classification forme	In this paper, we address one very important industrial application of computer vision – automatic classification of materials. In our work, we have considered materials that are mixtures of two or more elements. Such materials are called alloys. It is observed at the microscopic level that an alloy is composed of small randomly distributed crystals of varying shapes and sizes called grains. Also, the color and hence the intensity of the grains vary in alloys. Generally, this shape-size-intensity distribution of the grains is different for different materials. This means micrographs obtained from different materials form texture-like images that differ from one material to another in appearance. Therefore, in principle, any texture analysis method may be used for material classification. In our method, we propose to extract textural features corresponding to grain geometry and intensity and use them for analysis and classification of alloys. These features are extracted via gray-scale morphological operations and are measured in terms of Size-Intensity-Diagram (SID) and Tri-variate Pattern Spectrum (TPS) coefficients. In our experiments, we achieved 83.43% and 89.43% classification accuracies in cases of SID and TPS, respectively. This demonstrates the effectiveness of the proposed method for material classification which in turn confirms that our choice of features is indeed appropriate for the purpose.	morphological pattern;statistical classification	D. Ghosh;David C. Tou Wei	2006		10.1007/11612704_62	computer vision;particle-size distribution;image processing;computer science	Vision	44.69120239480055	-62.16134489584287	111368
a57cb0e6d7b07971c6ca948e451f441bbd07edbc	fundamental geodesic deformations in spaces of treelike shapes	planar treelike shapes;shape morphology fundamental geodesic deformations planar treelike shapes geometric framework shape matching shape recognition;electric shock;treelike shapes;building block;geometry;computational geometry;shape analysis;vector space;shape recognition;tree metric;euclidean distance;trees mathematics;binary trees;shape;image edge detection;shape matching;shape electric shock binary trees euclidean distance geometry image edge detection;shape morphology;geometric framework;fundamental geodesic deformations shape analysis shape matching treelike shapes tree metric tree geodesics;tree geodesics;fundamental geodesic deformations;trees mathematics computational geometry	This paper presents a new geometric framework for analysis of planar treelike shapes for applications such as shape matching, recognition and morphology, using the geometry of the space of treelike shapes. Mathematically, the shape space is given the structure of a stratified set which is a quotient of a normed vector space with a metric inherited from the vector space norm. We give examples of geodesic paths in tree-space corresponding to fundamental deformations of small trees, and discuss how these deformations are key building blocks for understanding deformations between larger trees.	algorithm;analysis of algorithms;communication endpoint;image noise;mathematical morphology;medical imaging;shape context;spaces	Aasa Feragen;François Lauze;Mads Nielsen	2010	2010 20th International Conference on Pattern Recognition	10.1109/ICPR.2010.513	combinatorics;topology;binary tree;vector space;computational geometry;shape;euclidean distance;shape analysis;mathematics;geometry	Vision	49.48371098173786	-62.391816043833245	111747
6bc8abd67f44d8a55b0eab334d9e15e7b76bacd7	in the saddle: chasing fast and repeatable features	detectors;dogs;surface treatment;shape;image edge detection;three dimensional displays;feature extraction	A novel similarity-covariant feature detector that extracts points whose neighborhoods, when treated as a 3D intensity surface, have a saddle-like intensity profile. The saddle condition is verified efficiently by intensity comparisons on two concentric rings that must have exactly two dark-to-bright and two bright-to-dark transitions satisfying certain geometric constraints. Experiments show that the Saddle features are general, evenly spread and appearing in high density in a range of images. The Saddle detector is among the fastest proposed. In comparison with detector with similar speed, the Saddle features show superior matching performance on number of challenging datasets.	experiment;fastest;image resolution;point process;random sample consensus	Javier Aldana-Iuit;Dmytro Mishkin;Ondrej Chum;Jiri Matas	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7899712	computer vision;mathematical optimization;detector;feature extraction;shape;computer science;machine learning;mathematics;geometry	Robotics	49.08475799701474	-54.26113146396512	111764
2458c5c19cbced693422886e9bdbd7d491cde755	performance evaluation and analysis of vanishing point detection techniques	photogrammetry;object recognition;performance evaluation;edge detection;performance analysis object detection image edge detection layout image segmentation image converters acoustic noise detection algorithms computer vision noise robustness;vanishing points;computer vision;complex aerial imagery performance evaluation performance analysis vanishing point detection techniques gaussian sphere representation computer vision systems 3d line orientation extraction object detection perspective robust vanishing point detection gaussian sphere primitive based vanishing point analysis interpretation plane error modeling;shape representation;aerial imagery;vanishing point;remote sensing;detection algorithm;cartographic feature extraction;remote sensing computer vision edge detection;building detection;quantitative evaluation;object detection	Vanishing point detection algorithms based on a Gaussian sphere representation have been employed in a variety of computer vision systems, for extracting 3D line orientations as a first step towards object detection. Typically, these algorithms have been applied to imagery with strong perspective effects and with little noise or texture, resulting in good solutions for line orientations. However, these algorithms can fail if perspective effects are weak, or if texture edges are predominant; they also fail to take advantage of knowledge about the objects to be detected. In this paper, two new techniques for robust vanishing point detection on the Gaussian sphere are presented; primitive-based vanishing point analysis and interpretation plane error modeling. The performance of these methods, along with two other existing methods from the literature, are quantitatively evaluated and compared for the task of building detection in complex aerial imagery.	performance evaluation;vanishing point	Jefferey A. Shufelt	1999	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.754631	computer vision;vanishing point;computer science;machine learning;mathematics	Vision	53.39413766046412	-57.62094149763461	111788
38a73d2abe0201230bdb11884247d955cc344716	a constraint network for symbol detection in architectural drawings	acoplamiento grafo;vision ordenador;analisis espacial;graph matching;computer vision;couplage graphe;reseau messmer;compact representation;reconocimiento grafico;traitement document;dessin architecture;plano arquitectura;vision ordinateur;reconnaissance graphique;document processing;spatial analysis;architectural drawing;analyse spatiale;graphical recognition;tratamiento documento	A network used to detect and recognize several diierent symbols (doors, windows...) in scanned architectural drawings is presented. This network, based on Messmer's network for exact and inexact graph matching, presents a compact representation of all the symbols, which allows a one-pass search. Some modiications to this method for our speciic document analysis problem are outlined: the symbols are represented as sets of constraints on the segments and arcs of the symbol; a description language has been written in order to describe these constraints. Symbol detection is performed by propagating the segments and the arcs in the network and retrieving the recognized symbols. The construction of this network is an iterative incremental process.	iteration;matching (graph theory);microsoft windows	Christian Ah-Soon	1997		10.1007/3-540-64381-8_41	computer vision;architectural drawing;document processing;computer science;artificial intelligence;spatial analysis;algorithm;matching	AI	48.33285022129437	-60.03156861747312	111835
93685cd90b7f128c5807542f2d1584d8e571cef8	parametric gaussianization procedure of wavelet coefficients for texture retrieval	statistical approach;gaussianization procedure image texture analysis information retrieval steerable pyramid generalized gaussian distribution;gaussian processes;wavelet transforms content based retrieval feature extraction gaussian processes image retrieval image texture;information retrieval;texture retrieval;image database;parametric density assumptions;texture features;statistical model;image database parametric gaussianization procedure wavelet coefficients texture retrieval feature extraction content based image retrieval statistical approach parametric density assumptions pyramid coefficients image textures;image texture;image textures;parametric gaussianization procedure;wavelet transforms;steerable pyramid;feature extraction;generalized gaussian distribution;gaussianization procedure;gaussian processes wavelet coefficients feature extraction image retrieval content based retrieval image texture data analysis image analysis image texture analysis performance analysis;image texture analysis;pyramid coefficients;content based image retrieval;content based retrieval;wavelet coefficients;extraction method;image retrieval	In this paper, we deal with the problem of feature extraction in content-based image retrieval (CBIR) using statistical approach. A Gaussianization procedure based on parametric density assumptions of steerable pyramid coefficients is proposed. The extraction method of features including the Gaussianization step allows us to limit the order of the statistical model used to characterize the image textures. The performances of the proposed method are analyzed on a database of texture images and compared with the performances of other texture features proposed in previous works.	coefficient;content-based image retrieval;database;feature extraction;performance;pyramid (image processing);statistical model;wavelet	Noureddine Lasmar;Youssef Stitou;Soufiane Jouini;Yannick Berthoumieu;Mohamed Najim	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517718	image texture;statistical model;computer vision;steerable pyramid;feature extraction;image retrieval;computer science;machine learning;pattern recognition;gaussian process;mathematics;generalized normal distribution;statistics;wavelet transform	Vision	40.033431714810966	-62.23863665199005	111848
0f453074b457ad22d9c02ba033a8fd7a0ddbda92	histogram of gabor phase patterns (hgpp): a novel object representation approach for face recognition	reconnaissance visage;object representation;traitement signal;phase measurement;evaluation performance;global gabor phase pattern;base donnee;image coding;local xor pattern operator object representation face recognition histogram of gabor phase pattern quadrant bit codes nonoverlapping rectangular regions spatial histograms fisher separation criterion local gabor phase pattern global gabor phase pattern gabor wavelet;quadrant bit codes;performance evaluation;image processing;nonoverlapping rectangular regions;learning;phase pattern;gabor transform;fisher separation criterion;biometrie;evaluacion prestacion;biometrics;algorithms artificial intelligence biometry cluster analysis face humans image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated;database;biometria;procesamiento imagen;base dato;gabor transformation;informacion fisher;histograms face recognition frequency feature extraction robustness image databases pattern recognition computers concatenated codes performance evaluation;traitement image;medida fase;similitude;algorithme;aprendizaje;discriminant analysis;analyse discriminante;wavelet transforms;algorithm;vecino mas cercano;large scale;analisis discriminante;histogram;apprentissage;automatic recognition;gabor wavelet;face recognition;mesure phase;histogramme;object oriented;local xor pattern operator;image representation;feature extraction;signal processing;signal classification;phase pattern face recognition feature extraction gabor histogram local pattern;similarity;pattern recognition;transformation gabor;gabor;classification signal;local gabor phase pattern;oriente objet;plus proche voisin;spatial histograms;nearest neighbour;reconnaissance forme;similitud;extraction caracteristique;classification automatique;reconocimiento patron;nearest neighbor classifier;automatic classification;histograma;procesamiento senal;clasificacion automatica;orientado objeto;gabor wavelets	A novel object descriptor, histogram of Gabor phase pattern (HGPP), is proposed for robust face recognition. In HGPP, the quadrant-bit codes are first extracted from faces based on the Gabor transformation. Global Gabor phase pattern (GGPP) and local Gabor phase pattern (LGPP) are then proposed to encode the phase variations. GGPP captures the variations derived from the orientation changing of Gabor wavelet at a given scale (frequency), while LGPP encodes the local neighborhood variations by using a novel local XOR pattern (LXP) operator. They are both divided into the nonoverlapping rectangular regions, from which spatial histograms are extracted and concatenated into an extended histogram feature to represent the original image. Finally, the recognition is performed by using the nearest-neighbor classifier with histogram intersection as the similarity measurement. The features of HGPP lie in two aspects: 1) HGPP can describe the general face images robustly without the training procedure; 2) HGPP encodes the Gabor phase information, while most previous face recognition methods exploit the Gabor magnitude information. In addition, Fisher separation criterion is further used to improve the performance of HGPP by weighing the subregions of the image according to their discriminative powers. The proposed methods are successfully applied to face recognition, and the experiment results on the large-scale FERET and CAS-PEAL databases show that the proposed algorithms significantly outperform other well-known systems in terms of recognition rate	behavior;code;concatenation;encode;electroencephalography phase desynchronization;exclusive or;experiment;extraction;feret (facial recognition technology);feret database;face;facial recognition system;feature selection;frequency band;gabor filter;gabor wavelet;histogram;image resolution;information theory;intersection of set of elements;linear discriminant analysis;name;nearest neighbour algorithm;outline of object recognition;power (psychology);product binning;scientific publication;solutions;spatial network;negative regulation of trichome patterning	Baochang Zhang;Shiguang Shan;Xilin Chen;Wen Gao	2007	IEEE Transactions on Image Processing	10.1109/TIP.2006.884956	computer vision;image processing;computer science;machine learning;signal processing;pattern recognition;mathematics;gabor wavelet;statistics	Vision	43.24339796860927	-60.3350778509231	111875
47be43efe6150efcdc87cc8b5e8d53c31250bad1	motion compensation for face recognition based on active differential imaging	motion compensated;face recognition	Active differential imaging has been proved to be an effective approach to remove ambient illumination for face recognition. In this paper we address the problem caused by motion for a face recognition system based on active differential imaging. A moving face will appear at two different locations in the ambient illumination frame and combined illumination frame and as result artifacts are introduced to the difference face image. An approach based on motion compensation is proposed to deal with this problem. Experiments on moving faces demonstrate that the proposed approach leads to significant improvements in face identification and verification results.	facial recognition system;motion compensation	Xuan Zou;Josef Kittler;Kieron Messer	2007		10.1007/978-3-540-74549-5_5	facial recognition system;computer vision;speech recognition;computer science	Vision	42.17789915568741	-52.3653922814846	111992
b52c2c5ab44724497f56ca1ba39fb82748e4efc6	grey-scale image colorization by local correlation based optimization algorithm	minimisation;metodo correlacion;correlacion;minimization;optimisation;vision ordenador;quadratic function;boundary extraction;funcion cuadratica;fonction quadratique;multimedia;coloration;optimizacion;cost function;correlation method;connectivity detection;least square solver;minimizacion;imagen nivel gris;computer vision;local correlation;colorization;coloracion;mathematical programming;image niveau gris;vision ordinateur;optimization;correlation;subsample;optimal algorithm;grey level image;programmation mathematique;programacion matematica;methode correlation	In this paper, we present a grey-scale image colorization technique by using local correlation based optimization algorithm. The core of our colorization method is to formalize the colorization problem as minimizing a quadratic cost function under some assumptions that are mainly based on the local image characters. It can be successfully applied in colorization a variety of grey-scale images. In our colorization method, users only need to freely scribble the desired color in the input grey-scale image, which is a great improvement upon the traditional manual colorization techniques. By introducing new local connectivity factor and distance factor, our approach can effectively alleviate the color diffuseness in different regions, which is one of main problem in previous colorization methods. Additionally, by exploiting subsampling in YUV space, we accelerate the colorization process with nearly the same good results. Experiments show that better colorization results can be obtained faster with our method.	algorithm	Dongdong Nie;Lizhuang Ma;Shuangjiu Xiao;XueZhong Xiao	2005		10.1007/11590064_2	computer vision;minimisation;quadratic function;computer science;artificial intelligence;mathematics;geometry;correlation	Vision	53.231659158389384	-59.39170499169936	112485
c7804b09bc0ddaac25e28a79e8fb4c292e02df4f	a rotation invariant pattern signature	kernel laboratories information science image analysis gray scale optical character recognition software character recognition image segmentation pattern matching optimal matching;image classification;invariance;rotation invariance;vectors;algebra;image representation;local image symmetry rotation invariant pattern signature rotation invariant representation local image structure complex valued vector oriented basis kernels algebraic invariants grayscale imagery junction classification junction representation;algebra image representation image classification invariance vectors	We propose a “signature” for rotation-invariant representation of local image structure. The signature is a complex-valued vector constructed analytically from the projections of the image onto a set of oriented basis kernels. The components of the signature form an overcomplete set of algebraic invariants, but are chosen to avoid instabilities associated with previously developed algebraic invariants. We demonstrate the use of this signature for representing and classifying junctions in grayscale imagery.	basis function;grayscale;linear algebra;vector graphics	Eero P. Simoncelli	1996		10.1109/ICIP.1996.560415	computer vision;contextual image classification;discrete mathematics;topology;u-matrix;invariant;mathematics	Vision	41.200545002108925	-59.87451120127684	112512
b12565b22fef78fd25776b9cc16477b6df0acfa7	a new fingerprint indexing algorithm for latent and non-latent impressions identification		In this work, a new fingerprint identification algorithm for latent and non-latent impressions based on indexing techniques is presented. This proposal uses a minutia triplet state-of-the-art representation, which has proven to be very tolerant to distortions. Also, a novel strategy to partition the indexes is implemented, in the retrieving stage. This strategy allows to use the algorithm in both contexts, criminal and non-criminal. The experimental results show that in latent identification this approach has a 91.08% of hit rate at penetration rate of 20%, on NIST27 database using a large background of 267000 rolled impressions. Meanwhile in non-latent identification at the same penetration rate, the algorithm reaches a hit rate of 97.8% on NIST4 database and a 100% of hit rate on FVC2004 DB1A database. These accuracy values were reached with a high efficiency.	algorithm;fingerprint;search engine indexing	José Hernández Palancar;Alfredo Muñoz-Briseño	2015		10.1007/978-3-319-25751-8_16	computer vision;pattern recognition;information retrieval	Vision	39.444291792037816	-58.88868078245456	112618
3a0a79918f4c9182dfbe1cf38c582d62c2ad0363	multiscale branch-and-bound image database search	databases;distance function;search algorithm;image database;multiscale representation;color histogram;spatial distribution;convex function;parameter space;algorithms;global optimization;branch and bound;content based retrieval;image similarity	This paper presents a formal framework for designing search algorithms which can identify target images by the spatial distribution of color, edge and texture attributes. The framework is based on a multiscale representation of both the image data, and the associated parameter space that must be searched. We define a general form for the distance function which insures that branch and bound search can be used to find the globally optimal match. Our distance function depends on the choice of a convex measure of feature distance. For this purpose, we propose the L1 norm and some other alternative choices such as the Kullback-Liebler and divergence distances. Experimental results indicate that the multiscale approach can improve search performance with minimal computational cost. Keyword: multiscale search, image similarity, content-based retrieval, color histogram, convex function	algorithmic efficiency;branch and bound;color histogram;convex function;kullback–leibler divergence;maxima and minima;search algorithm;t-norm;taxicab geometry	Jau-Yuen Chen;Charles A. Bouman;Jan P. Allebach	1997		10.1117/12.263402	computer vision;machine learning;pattern recognition;mathematics	Vision	42.69797007938806	-60.98132166793688	112931
847069ddae835da0bed93fb20a7121eebee7a7cc	three-dimensional shape knowledge for joint image segmentation and pose estimation	top down method;methode descendante;forma libre;modelizacion;calculo de variaciones;image tridimensionnelle;pistage;image segmentation;analisis estadistico;image processing;image databank;racinisation;top down;espectro visible;three dimensional shape;free form;level set;rastreo;procesamiento imagen;probabilistic approach;traitement image;three dimensional;forma tridimensional;energy function;visible spectrum;modelisation;posture;forme libre;calcul variationnel;statistical analysis;forme tridimensionnelle;metodo descendente;enfoque probabilista;approche probabiliste;surface model;banco imagen;banque image;analyse statistique;segmentation image;postura;courbe niveau;pattern recognition;architecture basee modele;tridimensional image;model management;reconnaissance forme;curva nivel;reconocimiento patron;spectre visible;modeling;stemming;model driven architecture;variational calculus;tracking;imagen tridimensional;contour line;object model;arquitectura basada modelo;pose estimation	This paper presents the integration of 3D shape knowledge into a variational model for level set based image segmentation and tracking. Having a 3D surface model of an object that is visible in the image of a calibrated camera, the object contour stemming from the segmentation is applied to estimate the 3D pose parameters, whereas the object model projected to the image plane helps in a top-down manner to improve the extraction of the contour and the region statistics. The present approach clearly states all model assumptions in a single energy functional. This keeps the model manageable and allows further extensions for the future. While common alternative segmentation approaches that integrate 2D shape knowledge face the problem that an object can look very different from various viewpoints, a 3D free form model ensures that for each view the model can perfectly fit the data in the image. Moreover, one solves the higher level problem of determining the object pose including its distance to the camera. Experiments demonstrate the performance of the method. In Pattern Recognition, Springer LNCS 3663, W. Kropatsch, R. Sablatnig, and A. Hanbury (Eds.), pp. 109-116, Vienna, Austria, Aug. 2005c © Springer-Verlag Berlin Heidelberg 2005	3d pose estimation;image plane;image segmentation;lecture notes in computer science;pattern recognition;springer (tank);stemming;top-down and bottom-up design;variational principle	Thomas Brox;Bodo Rosenhahn;Joachim Weickert	2005		10.1007/11550518_14	active shape model;three-dimensional space;computer vision;systems modeling;pose;object model;3d pose estimation;image processing;computer science;artificial intelligence;level set;segmentation-based object categorization;top-down and bottom-up design;active contour model;stemming;visible spectrum;tracking;image segmentation;scale-space segmentation;contour line;calculus of variations	Vision	48.55714126350596	-58.80618108267046	113035
4bb2c8c2749d773cd4ed33c3c725393751f18fa8	volume image processing (vip'93)	image processing		image processing	Max A. Viergever	1994	Pattern Recognition Letters	10.1016/0167-8655(94)90133-3	image texture;computer vision;color image;image gradient;binary image;image processing;computer science;digital image processing;normalization	Vision	41.64143197130363	-65.72730407178202	113163
ae0c82a357d992a73f0b7ac231730d4ff28e401e	a highly repeatable feature detector: improved harris–laplace	remote sensing image;grouping;local structure;scale space;scale invariant feature transform;image registration;feature detector;redundant points;repeatability	A feature detector named improved Harris–Laplace is proposed to obtain higher repeatability than that of original Harris–Laplace. In this novel method, all points detected at each scale are tracked and grouped beginning with the largest scale in the scale-space to make each group represent one local structure firstly. Then the point in each group which simultaneously leads to the maxima of corner points measuring and scale normalization Laplace function is selected. Finally, these points are described and matched by scale invariant feature transform (SIFT) descriptor successfully. Experimental results indicate that the proposed method has higher repeatability than original Harris–Laplace. Meanwhile, the new method was evaluated with image registration. Compared with SIFT, more accurate registration precision of multi-sensor remote sensing images was obtained by the advanced method.	computation;harris affine region detector;image registration;mark harris (programmer);maxima;repeatability;scale space;scale-invariant feature transform	Jieyu Zhang;Qiang Chen;Quan-Sen Sun;Huaijiang Sun;De-Shen Xia	2010	Multimedia Tools and Applications	10.1007/s11042-010-0471-9	computer vision;repeatability;scale space;computer science;image registration;pattern recognition;feature detection;scale-invariant feature transform;data mining	Vision	41.56601107076328	-56.20364928714144	113225
3e80edfbc578652b7a62a44dda4b611170d741c9	single-image shadow detection and removal using paired regions	graph theory;image recognition;image segmentation;hidden feature removal;shadow detection;edge information;image classification;image matting;region segmentation;single image shadow detection;natural scene;lighting materials image color analysis image edge detection histograms light sources robustness;graph cut;shadow free ground truth image single image shadow detection single images removal natural scene edge information region segmentation pairwise classification graph cut image matting image recovery;single images removal;image recovery;ground truth;natural scenes graph theory hidden feature removal image classification image recognition image segmentation;pairwise classification;natural scenes;shadow free ground truth image	In this paper, we address the problem of shadow detection and removal from single images of natural scenes. Different from traditional methods that explore pixel or edge information, we employ a region based approach. In addition to considering individual regions separately, we predict relative illumination conditions between segmented regions from their appearances and perform pairwise classification based on such information. Classification results are used to build a graph of segments, and graph-cut is used to solve the labeling of shadow and non-shadow regions. Detection results are later refined by image matting, and the shadow free image is recovered by relighting each pixel based on our lighting model. We evaluate our method on the shadow detection dataset in [19]. In addition, we created a new dataset with shadow-free ground truth images, which provides a quantitative basis for evaluating shadow removal.	autostereogram;cut (graph theory);experiment;ground truth;pixel;shading	Ruiqi Guo;Qieyun Dai;Derek Hoiem	2011	CVPR 2011	10.1109/CVPR.2011.5995725	computer vision;contextual image classification;cut;ground truth;computer science;graph theory;machine learning;pattern recognition;mathematics;image segmentation	Vision	44.58394419388013	-52.608547309298345	113277
104039369ea685e166ef6887adebc75d33d93047	high-speed template matching algorithm using information of contour points	semiconducteur;image processing;contour;edge detection;procesamiento imagen;semiconductor material;inspection;traitement image;deteccion contorno;algorithme;algorithm;detection contour;semiconductor materials;wafer;pattern recognition;pastilla electronica;reconnaissance forme;pastille electronique;reconocimiento patron;high speed algorithm;template matching;high speed;semiconductor;algoritmo	Abstract#R##N##R##N#Template matching is a useful technique for matching images. This paper proposes a high-speed template matching technique which is effective for images that have sharp contours. The method uses only the image contour parts as one-dimensional templates. Although it can retain fine patterns, the data compression ratio and speed are very high. To improve reliability of matching, gray gradient information and intensity of contour points are used. Also, dilation of contours can reduce several errors due to disturbance of the contour or scaling. The algorithm herein can indicate differences between the template and the target image automatically after the alignment of images.#R##N##R##N##R##N##R##N#The expanded algorithm applying the sequential similarity detection algorithm (SSDA) method also is discussed. Software simulation proved that the algorithm is 10 or 200 times faster than the conventional template matching technique which uses the cross-correlation estimation between two-dimensional (2-D) template and the target image. This algorithm was applied to special hardware. It can align two 512 × 512 pixels images in 40 ms when the size of the search area is 64 × 64.	algorithm;template matching	Manabu Hashimoto;Kazuhiko Sumi;Yoshikazu Sakaue;Shinjiro Kawato	1992	Systems and Computers in Japan	10.1002/scj.4690230908	computer vision;template matching;edge detection;inspection;image processing;computer science;semiconductor;wafer;computer graphics (images)	Robotics	47.22618223267587	-63.970182234970565	113509
d9529dbcc49b67e0443e6f00cd1ab51a51a84260	progressive coding scheme delaying a background display for image retrieval	image retrieval		image retrieval	Shun Ido;Masanori Izumida;Kenji Murakami;Makoto Sato	1999			coding (social sciences);visual word;information retrieval;image retrieval;computer vision;artificial intelligence;computer science	Vision	39.20489468022165	-63.1115342735284	113514
f9a7cc761acb1362dfdb68ac35cb4c997794e861	using multi-instance enrollment to improve performance of 3d face recognition	reconnaissance visage;conjunto independiente;mimica;image tridimensionnelle;3d face recognition;vision ordenador;image processing;facies;componente logicial;independent set;perforation;biometrie;mimique;depth of field;biometrics;biometria;procesamiento imagen;composant logiciel;biometric;profondeur champ;traitement image;computer vision;expression variation;ensemble independant;face recognition;range image;component based recognition;software component;pattern recognition;profundidad campo;tridimensional image;vision ordinateur;multi instance;reconnaissance forme;facial expression;reconocimiento patron;imagen tridimensional	This paper explores the use of multi-instance enrollment as a means to improve the performance of 3D face recognition. Experiments are performed using the ND-2006 3D face data set which contains 13,450 scans of 888 subjects. This is the largest 3D face data set currently available and contains a substantial amount of varied facial expression. Results indicate that the multi-instance enrollment approach outperforms a state-of-the-art component-based recognition approach, in which the face to be recognized is considered as an independent set of regions. ! 2008 Elsevier Inc. All rights reserved.	component-based software engineering;experiment;facial recognition system;independent set (graph theory);three-dimensional face recognition	Timothy C. Faltemier;Kevin W. Bowyer;Patrick J. Flynn	2008	Computer Vision and Image Understanding	10.1016/j.cviu.2008.01.004	computer vision;image processing;computer science;artificial intelligence;biometrics	Vision	45.455135408696094	-59.60014131262292	113760
57e48e7607a6c92abd79aa559ceff90bd958bb98	research of shoeprint image matching based on sift algorithm		It researches on shoeprint image positioning and matching. Firstly, this paper introduces the algorithm of Scale- invariant feature transform (SIFT) into shoeprint matching. Then it proposes an improved matching algorithm of SIFT. Because of its good scale and illumination invariant, the algorithm can be used to go on the shoeprint matching. The secondary posi- tioning on the image will be used before the feature points are created. It makes shoeprint image in the same vertical position. After that, use the minimum Euclidean distance as the standard of shoeprint matching. According to the ratio of the minimum Euclidean distance to the second minimum Euclidean distance, the invalid points are removed. That can improve the matching efficiency. The results of experiment show that the algorithm can not only shorten the matching time, but also improve the matching accuracy with high robust.	algorithm;image registration;scale-invariant feature transform	Hongxing Wang;Jihui Fan;Yan Li	2016	J. Comput. Meth. in Science and Engineering	10.3233/JCM-160622	computer vision;mathematical optimization;pattern recognition;mathematics	Logic	40.9589850443706	-57.260974200387444	114150
792ec0f58c66c982311070dda6bfb195fbb9b502	incremental discovery of object parts in video sequences	motion based layer segmentation;image motion analysis;monocular video sequence;image segmentation;image sequences image motion analysis image segmentation;video sequences humans tracking shape computer vision biological system modeling image segmentation motion analysis laboratories motion measurement;motion based layer segmentation incremental object part discovery deformable moving object monocular video sequence;image sequence analysis;human tracking;deformable moving object;temporal scale;incremental object part discovery;base layer;image sequences	This paper addresses the fundamental problem of automatically discovering an unknown moving deformable object in a monocular video sequence. No prior model of the object is used; it is only assumed that the object is composed of a set of apparently rigid parts that are not necessarily visible simultaneously, making it possible to circumvent the typical constraint of model initialization. A set of rigid parts describing the object is incrementally extracted in a modeling-tracking loop with reinforced memory. In this framework, low-level segmentation is considered as a necessary but non reliable process that helps initiating hypotheses. Motion-based layer segmentation from feature points and edges is applied only when and where no modeled parts can be tracked. Using the quantity of motion measure, it is further shown how to deal with temporal scale. The interest for this approach in applications such as human tracking is demonstrated for a set of various sequences including a rapidly evolving shape	high- and low-level;key frame	Stéphane Drouin;Patrick Hébert;Marc Parizeau	2005	Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1	10.1109/ICCV.2005.121	computer vision;computer science;segmentation-based object categorization;video tracking;pattern recognition;motion estimation;image segmentation;motion field;scale-space segmentation;computer graphics (images)	Vision	47.40594015147501	-52.76561118477721	114212
95da703908869732603868a1c03345e6fb446e93	rotation invariant distance measures for trajectories	time warp;handwriting recognition;distance measure;standard deviation;time warping;video tracking;motion capture data;time series;trajectories;motion capture;rotation invariance;positional information;lower bound;elastic matching	For the discovery of similar patterns in 1D time-series, it is very typical to perform a normalization of the data (for example a transformation so that the data follow a zero mean and unit standard deviation). Such transformations can reveal latent patterns and are very commonly used in datamining applications. However, when dealing with multidimensional time-series, which appear naturally in applications such as video-tracking, motion-capture etc, similar motion patterns can also be expressed at different orientations. It is therefore imperative to provide support for additional transformations, such as rotation. In this work, we transform the positional information of moving data, into a space that is translation, scale and rotation invariant. Our distance measure in the new space is able to detect elastic matches and can be efficiently lower bounded, thus being computationally tractable. The proposed methods are easy to implement, fast to compute and can have many applications for real world problems, in areas such as handwriting recognition and posture estimation in motion-capture data. Finally, we empirically demonstrate the accuracy and the efficiency of the technique, using real and synthetic handwriting data.	cobham's thesis;data mining;handwriting recognition;imperative programming;motion capture;poor posture;synthetic data;time series;video tracking	Michail Vlachos;Dimitrios Gunopulos;Gautam Das	2004		10.1145/1014052.1014144	computer vision;motion capture;simulation;computer science;trajectory;machine learning;dynamic time warping;time series;video tracking;mathematics;handwriting recognition;upper and lower bounds;standard deviation;statistics	ML	47.1399232097721	-54.19696055415434	114295
b7a4218dc507d30dd082292bc9908ad8c0280231	an algorithm for vein matching based on log-polar transform	image matching;finger vein;log polar transform	This article discusses a new algorithm for vein matching based on log-polar transform to address problems that occur with the changing of finger position and from differences between imaging devices for current vein matching algorithms. The new algorithm first extracts the feature area, which contains enough characteristics for image matching, depending on the structure of the finger vein ridge alignment. It then calculates the degree of similarity between the log-polar transform results of the model image feature areas and the sample image, and finally analyzes the result by the degree of similarity and the relationship of relative positions between feature areas. Experiments show that the algorithm is robust for rotating and zooming images of the finger vein.	algorithm;vein matching	Wei Yan;Jianbin Xie;Peiqin Li;Xiaoguang Guo	2013	Smart CR	10.6029/smartcr.2013.05.004	computer vision;speech recognition;geography;engineering drawing	EDA	41.91391622154534	-58.476633536338404	114444
2c132470a48e5d68b226ae53cc88236cf6411e22	the gvf snake with a minimal path approach	image segmentation;edge detection contour extraction gvf snake method minimal path method image segmentation object boundary detection;edge detection;active contours image edge detection object detection sun signal processing data mining robustness signal processing algorithms deformable models digital images;active contours;deformable models;data mining;object detection edge detection feature extraction image segmentation;image edge detection;feature extraction;signal processing;contour extraction;sun;gvf snake method;robustness;signal processing algorithms;minimal path method;digital images;object boundary detection;extraction method;active contour model;object detection	In this paper we propose a contour extraction method based on the active contour model, which uses the GVF snake to obtain the initial segments for a contour; and then a minimal path method for the refinement stage, to obtain an accurate and more robust result. By employing the minimal path method to find missing segments between pairs of nodes defined on the contour obtained by the GVF snake, our algorithm is able to detect deep concave parts of object boundary, and works well even when the snake initialization is not very good.	active contour model;algorithm;computer vision;concave function;contour line;extensibility;foobar;icis;image processing;image segmentation;information and computer science;information science;maxima and minima;refinement (computing)	Chensheng Sun;Kin-Man Lam	2007	6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)	10.1109/ICIS.2007.178	computer vision;computer science;machine learning;pattern recognition	Vision	44.32295092343244	-65.83282065566206	114567
66e9cb57da9e628150473057e43226472fea3a15	integration of strategies based on relevance feedback into a tool for the retrieval of mammographic images	busqueda informacion;analisis imagen;analisis contenido;kernels;contenu image;image content;raisonnement base sur cas;razonamiento fundado sobre caso;cluster;incidence;analisis estadistico;image processing;case base reasoning;tumor maligno;traitement image stereoscopique;recherche image;amas;information retrieval;self organization map;procesamiento imagen;hombre;knowledge discovery retrieval data;intelligence artificielle;interpretacion abstracta;percepcion;probabilistic approach;traitement image;systeme asservi;content analysis;statistical analysis;recherche information;noyau mathematiques;enfoque probabilista;approche probabiliste;stereo image processing;analyse statistique;human;retroaction pertinence;autoorganizacion;servomecanismo;artificial intelligence;self organization;image analysis;self organized map;tumeur maligne;monton;inteligencia artificial;analyse contenu;perception;feedback system;interpretation abstraite;case based reasoning;abstract interpretation;contenido imagen;analyse image;relevance feedback;content based retrieval;bioinformatics tools;breast cancer;recherche par contenu;autoorganisation;incidencia;malignant tumor;homme;knowledge discovery;image retrieval	The incidence of breast cancer varies greatly among countries, but statistics show that every year 720,000 new cases will be diagnosed world-wide. However, a high percentage of these cases can be 100% healed if they are detected in early stages. Because symptoms are not visible as far as advanced stages, it makes the treatments more aggressive and also less efficient. Therefore, it is necessary to develop new strategies to detect the formation in early stages.#R##N##R##N#We have developed a tool based on a Case-Based Reasoning kernel for retrieving mammographic images by content analysis. One of the main difficulties is the introduction of knowledge and abstract concepts from domain into the retrieval process. For this reason, the article proposes integrate the human experts perceptions into it by means of an interaction between human and system using a Relevance Feedback strategy. Furthermore, the strategy uses a Self-Organization Map to cluster the memory and improve the time interaction.		Albert Fornells;Elisabet Golobardes;X. Vilasís;Joan Martí	2006		10.1007/11875581_14	case-based reasoning;computer vision;incidence;image analysis;content analysis;image processing;image retrieval;computer science;artificial intelligence;breast cancer;perception;cluster	Vision	43.60626121703624	-61.78524868612772	114669
254cc57d47f8be869c08ed49930b88277804011a	morphological shape decomposition interframe interpolation method	mathematical morphology;computer simulations;image interpolation;image compression;interpolation method;pattern recognition	One of the main image representations in mathematical morphology is the shape decomposition representation, useful for image compression and pattern recognition. The morphological shape decomposition representation can be generalized to extend the scope of its algebraic characteristics as much as possible. With these generalizations, the morphological shape decomposition (MSD) role to serve as an efficient image decomposition tool is ex- tended to interpolation of images. We address the binary and gray- scale interframe interpolation by means of generalized morphologi- cal shape decomposition. Computer simulations illustrate the results. © 2008 SPIE and IS&T. DOI: 10.1117/1.2885243	interpolation	Nicolae Vizireanu	2008	J. Electronic Imaging	10.1117/1.2885243	computer vision;mathematical morphology;bilinear interpolation;image compression;computer science;theoretical computer science;stairstep interpolation;pattern recognition;mathematics;nearest-neighbor interpolation;multivariate interpolation;image scaling	Theory	51.98375074794175	-64.28084302057465	114688
a58623c54d63dccc2c905f1276dbd500164ace7a	wear particle texture classification using artificial neural networks	tribologia;vision ordenador;image processing;neural networks;analisis textura;texture classification;procesamiento imagen;tribology;optical microscope;traitement image;particula desgaste;computer vision;texture analysis;tribologie;wear particle;wear particles;identification;identificacion;microscopio optico;vision ordinateur;particule usure;reseau neuronal;analyse texture;red neuronal;microscope optique;artificial neural network;neural network	Analysis of wear debris carried by a lubricant in an oil-wetted system provides important information about the condition of a machine. This paper describes the analysis of microscopic metal particles generated by wear using computer vision and image processing. The aim is to classify these particles according to their morphology and surface texture and by using the information obtained, to predict wear failure modes in engines and other machinery. This approach obviates the need for specialists and reliance on human visual inspection techniques. The procedure reported in this paper, is used to classify surface features of the wear particles by using artificial neural networks. A visual comparison between cooccurrence matrices representing five different texture classes is described. Based on these comparisons, matrices of reduced sizes are utilized to train a feed-forward neural classifier in order to distinguish between the various texture classes.	artificial neural network;neural networks	Mohammad Shakeel Laghari;A. S. Boujarwah	1999	IJPRAI	10.1142/S0218001499000240	identification;computer vision;computer science;artificial intelligence;machine learning;optical microscope;artificial neural network	ML	46.15288007869762	-61.50005297376259	114698
954eff2f83444ea6ab9a46d212d520dea9d99fbb	occlusions and binocular stereo	bayes estimation;dynamic programming;discontinuity;discontinuite;programacion dinamica;bayesian approach;vision estereoscopica;coaccion;vision stereoscopique;contrainte;estimacion bayes;constraint;binocular vision;programmation dynamique;discontinuidad;vision binocular;deteccion bayes;bayes detection;algoritmo optimo;stereopsis;algorithme optimal;optimal algorithm;vision binoculaire;detection bayes;estimation bayes	Binocular stereo is the process of obtaining depth information from a pair of cameras. In the past, stereo algorithms have had problems at occlusions and have tended to fail there (though sometimes post-processing has been added to mitigate the worst effects). We show that, on the contrary, occlusions can help stereo computation by providing cues for depth discontinuities. We describe a theory for stereo based on the Bayesian approach, using adaptive windows and a prior weak smoothness constraint, which incorporates occlusion. Our model assumes that a disparity discontinuity, along the epipolar line, in one eyealways corresponds to an occluded region in the other eye thus, leading to anocclusion constraint. This constraint restricts the space of possible disparity values, thereby simplifying the computations. An estimation of the disparity at occluded features is also discussed in light of psychophysical experiments. Using dynamic programming we can find the optimal solution to our system and the experimental results are good and support the assumptions made by the model.	algorithm;binocular disparity;binocular vision;computation;dynamic programming;epipolar geometry;experiment;hidden surface determination;microsoft windows;reflections of signals on conducting lines;video post-processing	Davi Geiger;Bruce Ladendorf;Alan L. Yuille	1995	International Journal of Computer Vision	10.1007/BF01679683	computer stereo vision;binocular vision;computer vision;simulation;bayesian probability;computer science;stereopsis;discontinuity;dynamic programming;mathematics;constraint	Vision	48.85825094530611	-56.85071754147099	114753
bf23de0c2b478114cc5c4733e4e701a1d4662cc0	deformations, patches, and discriminative models for automatic annotation of medical radiographs	busqueda informacion;anotacion;image features;medical imagery;image databank;information retrieval;image deformation model;interrogation base donnee;interrogacion base datos;annotation;medical image annotation;non linear model;radiografia;modele non lineaire;image annotation;radiography;discriminant analysis;analyse discriminante;regle decision;vecino mas cercano;analisis discriminante;modelo no lineal;medical image;bag of features;recherche information;local features;automatic annotation;banco imagen;banque image;signal classification;imagineria medica;imagerie medicale;classification signal;plus proche voisin;nearest neighbour;regla decision;classification automatique;automatic classification;clasificacion automatica;deformable model;database query;discriminative model;radiographie;decision rule	In this paper, we describe three different methods for the classification and annotation of medical radiographs. The methods were applied in the medical image annotation tasks of ImageCLEF in 2005, 2006, and 2007. Image annotation can be used to access and find images in a database using textual queries when no textual image description is available. One of the methods is a non-linear model taking into account local image deformations to compare images which are then classified using the nearest neighbour decision rule. The other two methods use local image descriptors for a bag-of-features approach. The bags of local image features are classified using discriminative classifiers. Our methods performed best in the 2005 and 2006 evaluations and second best in 2007.	automatic image annotation;discriminative model;linear model;medical imaging;nonlinear system;patch (computing);radiography;visual descriptor	Thomas Deselaers;Hermann Ney	2008	Pattern Recognition Letters	10.1016/j.patrec.2008.03.013	computer vision;radiography;image retrieval;computer science;machine learning;pattern recognition;data mining;decision rule;linear discriminant analysis;automatic image annotation;feature;discriminative model	Vision	43.14535881421743	-62.023121021175754	114767
067141abbcd1c1b45bd35244090757cf64edf64e	using the dual-tree complex wavelet transform for improved fabric defect detection		The dual-tree complex wavelet transform (DTCWT) solves the problems of shift variance and low directional selectivity in two and higher dimensions found with the commonly used discrete wavelet transform (DWT). It has been proposed for applications such as texture classification and content-based image retrieval. In this paper, the performance of the dual-tree complex wavelet transform for fabric defect detection is evaluated. As experimental samples, the fabric images from TILDA, a textile texture database from the Workgroup on Texture Analysis of the German Research Council (DFG), are used. The mean energies of real and imaginary parts of complex wavelet coefficients taken separately are identified as effective features for the purpose of fabric defect detection. Then it is shown that the use of the dual-tree complex wavelet transform yields greater performance as compared to the undecimated wavelet transform (UDWT) with a detection rate of 4.5% to 15.8% higher depending on the fabric type.	complex wavelet transform;software bug	Hermanus Vermaak;Philibert Nsengiyumva;Nicolaas Luwes	2016	J. Sensors	10.1155/2016/9794723	wavelet;computer vision;constant q transform;speech recognition;s transform;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;engineering;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;fast wavelet transform;lifting scheme;wavelet transform;computer graphics (images)	SE	40.859292793894696	-65.19019607803413	114774
be6022201c87e1136cf15207428079db0094d560	a fuzzy spatial coherence-based approach to background/foreground separation for moving object detection	moving object;calcul neuronal;neural computation;estimator robustness;background modeling;aplicacion;maintenance;spatial coherence;color;decision borrosa;decision floue;experimental result;decision problem;detection objet;robustez estimador;background subtraction;moving object detection;resultado experimental;mantenimiento;autoorganizacion;coherence;self organization;couleur;coherencia;reseau neuronal;resultat experimental;application;red neuronal;computacion neuronal;multivalued background modeling;autoorganisation;reseau neuronal artificiel;object detection;fuzzy decision;fuzzy model;artificial neural network;neural network;robustesse estimateur	The detection of moving objects from stationary cameras is usually approached by background subtraction, i.e. by constructing and maintaining an up-to-date model of the background and detecting moving objects as those that deviate from such a model. We adopt a previously proposed approach to background subtraction based on self-organization through artificial neural networks, that has been shown to well cope with several of the well known issues for background maintenance. Here, we propose a spatial coherence variant to such approach to enhance robustness against false detections and formulate a fuzzy model to deal with decision problems typically arising when crisp settings are involved. We show through experimental results and comparisons that higher accuracy values can be reached for color video sequences that represent typical situations critical for moving object detection.	artificial neural network;background subtraction;coherence (physics);color depth;data dependency;decision problem;emoticon;fuzzy logic;object detection;pixel;self-organization;sensor;stationary process;whole earth 'lectronic link	Lucia Maddalena;Alfredo Petrosino	2009	Neural Computing and Applications	10.1007/s00521-009-0285-8	computer vision;self-organization;coherence;background subtraction;computer science;artificial intelligence;machine learning;decision problem;mathematics;artificial neural network;models of neural computation	Vision	47.49368205179286	-57.72483454333336	114829
e62f90e2ec720498ec48d804e10127a945d01a1b	crop classification in satellite images through probabilistic segmentation based on multiple sources †	histogram;likelihood;probabilistic segmentation;remote sensing;vegetation indices	Classification methods based on Gaussian Markov Measure Field Models and other probabilistic approaches have to face the problem of construction of the likelihood. Typically, in these methods, the likelihood is computed from 1D or 3D histograms. However, when the number of information sources grows, as in the case of satellite images, the histogram construction becomes more difficult due to the high dimensionality of the feature space. In this work, we propose a generalization of Gaussian Markov Measure Field Models and provide a probabilistic segmentation scheme, which fuses multiple information sources for image segmentation. In particular, we apply the general model to classify types of crops in satellite images. The proposed method allows us to combine several feature spaces. For this purpose, the method requires prior information for building a 3D histogram for each considered feature space. Based on previous histograms, we can compute the likelihood of each site of the image to belong to a class. The computed likelihoods are the main input of the proposed algorithm and are combined in the proposed model using a contrast criteria. Different feature spaces are analyzed, among them are 6 spectral bands from LANDSAT 5 TM, 3 principal components from PCA on 6 spectral bands and 3 principal components from PCA applied on 10 vegetation indices. The proposed algorithm was applied to a real image and obtained excellent results in comparison to different classification algorithms used in crop classification.	3d computer graphics;algorithm;avian crop;bands;class;classification;common criteria;computer vision;entropy (information theory);experiment;feature vector;gauss;generalization (psychology);histogram;image segmentation;markov chain;matthews correlation coefficient;normal statistical distribution;probability;subshift of finite type;weight function;algorithm;biologic segmentation	Oscar Dalmau Cedeño;Teresa E. Alarcón;Francisco E. Oliva	2017		10.3390/s17061373		ML	40.71026478258308	-63.89859792441242	114998
6679f5b597801f7869fd4dd23600b85035fee27b	functional vanishing point estimation via a filtered-radon operator	edge texture information functional vanishing point estimation filtered radon operator camera orientation subtle line textures occluded segments video sequences;transforms joints estimation image edge detection optimization feature extraction robustness;edge texture information;radon transforms;radon transform;hidden feature removal;video signal processing;vanishing points;video sequences;joints;camera orientation;image texture;filtered radon operator;video signal processing hidden feature removal image sequences image texture radon transforms;estimation;vanishing point;image edge detection;subtle line textures;feature extraction;transforms;absolute orientation;robustness;optimization;occluded segments;absolute orientation vanishing points radon transform;structure from motion;functional vanishing point estimation;image sequences	When available, vanishing points in a scene are a key factor in effectively recovering absolute camera orientation, thus simplifying the structure-from-motion problem. We present a novel method for estimating vanishing points without explicitly detecting line features. This approach first maps images into line-space with a filtered- Radon operator, allowing subtle line textures to contribute, and improving the angular resolution of broken or occluded segments of the same line. Then, we use a robust coarse-to-fine method to jointly estimate the three vanishing points. We evaluate our method on video sequences, demonstrating robustness to clutter lines as well as the ability to effectively utilize subtle edge-texture information.	angularjs;clutter;map;sensor;structure from motion;vanishing point	William Mantzel;Justin K. Romberg	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5651773	computer vision;mathematical optimization;vanishing point;computer science;mathematics;geometry	Vision	51.76288094403794	-54.07939802984984	115032
9dae6577e505c3ad3a0e96d45a5583f425a89cb2	a reliable fingerprint orientation estimation algorithm	algoritmo busqueda;image processing;algorithme recherche;search algorithm;gradiente;database;procesamiento imagen;hexagonal restoration;base dato;gradient;orientation;classification;traitement image;empreinte digitale;base de donnees;punto singular;fingerprint;orientacion;huella digital;orientation estimation;fingerprint enhancement;article;clasificacion;point singulier;orientation restoration;singular point	Correctly estimating fingerprint ridge orientation is an important task in fingerprint image processing. A successful orientation estimation algorithm can drastically improve the performance of tasks such as fingerprint enhancement, classification, and singular points extraction. Gradient-based orientation estimation algorithms are widely adopted in academic literature, but they cannot guarantee the correctness of ridge orientations. Even worse, they assign orientations to blocks with singular points. A novel and reliable orientation estimation algorithm is proposed in this paper. This algorithm runs in two phases. The first phase assigns reliable orientations to blocks with parallel structures and marks other blocks with noise, singular points, and minutiae as uncertain. Since most uncertain blocks marked in the first phase do have unique ridge orientations, the second phase of our algorithm restores the orientations of these uncertain blocks from their neighbor blocks orientations. Different from other orientation estimation algorithms, our algorithm leaves the blocks containing singular points and assigns reliable orientations to the other blocks. Detailed examples are given in this paper to show how our algorithm works. We use NIST-4 fingerprint database in our experiment to verify the superiority of our algorithm.	algorithm;correctness (computer science);fingerprint;gradient;image processing;minutiae;type signature	Li-min Liu;Tian-Shyr Dai	2011	J. Inf. Sci. Eng.		fingerprint;singular point of a curve;image processing;biological classification;computer science;artificial intelligence;machine learning;database;mathematics;orientation;gradient;algorithm;search algorithm	EDA	46.10154849781836	-59.68851792160397	115419
2bab6c0c9ed2154bf84c5f19fa515e136f805748	image annotation using high order statistics in non-euclidean spaces	image annotation;non euclidean space;dissimilarity diffusion distribution;gaussian mixture model;corel database;maximum a posteriori;high order statistics;experimentation	Automatic image annotation is a promising way to achieve more effective image retrieval and image analysis by using keywords associated to the image content. Due to the semantic gap between low-level visual features and high-level semantic concepts of an image, however, the performances of many existing algorithms are not so satisfactory. In this paper, a novel image classification scheme, named high order statistics based maximum a posterior (HOS-MAP), is proposed to deal with the issue of image annotation. To bridge the gap between human judgment and machine intelligence, the proposed scheme first constructs a dissimilarity representation for each image in a non-Euclidean space; then, the information of dissimilarity diffusion distribution for each image is achieved with respect to the high-order statistics of a triplet of nearest neighbor images; finally, a maximum a posteriori algorithm with the information of Gaussian Mixture Model and dissimilarity diffusion distribution is adopted to estimate the relevance between each annotation and an input un-annotated image. Experimental results on a general-purpose image database demonstrate the effectiveness and efficiency of the proposed automatic image annotation scheme. 2013 Elsevier Inc. All rights reserved.	algorithm;artificial intelligence;automatic image annotation;categorization;cognitive science;comparison and contrast of classification schemes in linguistics and metadata;computer vision;euler–bernoulli beam theory;experiment;flickr;general-purpose modeling;high- and low-level;image analysis;image retrieval;mixture model;performance;relevance;triplet state	Songhao Zhu;Juanjuan Hu;Wang Baoyun;Shuhan Shen	2013	J. Visual Communication and Image Representation	10.1016/j.jvcir.2013.09.004	image texture;computer vision;feature detection;u-matrix;computer science;maximum a posteriori estimation;machine learning;pattern recognition;mixture model;data mining;mathematics;automatic image annotation	Vision	40.55717849903643	-62.63800632617295	115549
47516d9237c7e2a71a4f82d4b92fd4d30b708aff	a metric and multiscale color segmentation using the color monogenic signal	fourier transform;differential geometry;color image processing;color segmentation;clifford algebra;signal processing;monogenic signal;geometric structure;clifford algebras;color image	In this paper, we use the formalism of Clifford algebras to extend the so-called Monogenic Signal to color images. This extension consists in a function with values in the Clifford algebra ?5,0 that encodes color as well as geometric structure information. Using geometric calculus, such a mathematical object can be used to extend classical concepts of signal processing (filtering, Fourier Transform...) to color images in a consistent manner. Regarding this paper, a local color phase is introduced, which generalizes the one for grayscale image. As an example of application, we provide a new method for color segmentation. Based on our phase definition and the multiscale aspect of the Color Monogenic Signal, we provide a metric approach using differential geometry which reveals relevant on the Berkeley Image Dataset.	image segmentation;metric	Guillaume Demarcq;Laurent Mascarilla;Pierre Courtellemont	2009		10.1007/978-3-642-03767-2_110	color histogram;computer vision;color quantization;hsl and hsv;color normalization;signal processing;pure mathematics;mathematics;geometry;clifford algebra	Vision	51.86516327533783	-63.94616434423418	115823
03228c23b39286429da34f8a5df91fcc2af63279	comparison of feature extraction techniques for watermark synchronization	transformation ondelette;filigranage numerique;digital watermarking;traitement signal;triangulacion delaunay;delaunay triangulation;steganographie;geometric transformation;robust watermarking;securite;geometrie algorithmique;triangulation delaunay;signal distortion;localization;extraction forme;computational geometry;tiling;interactive method;intelligence artificielle;localizacion;distorsion signal;synchronisation;steganography;esteganografia;localisation;extraccion forma;synchronization;delaunay tessellation;feature extraction;signal processing;filigrana digital;transformacion geometrica;safety;pavage;transformation geometrique;pattern recognition;invariante;artificial intelligence;geometria computacional;sincronizacion;inteligencia artificial;transformacion ondita;reconnaissance forme;extraction caracteristique;reconocimiento patron;seguridad;procesamiento senal;pattern extraction;invariant;scale invariance;wavelet transformation;distorsion senal	This paper evaluates feature extraction techniques in aspect of watermark synchronization. Most watermarking algorithms suffer from geometric distortion attacks that desynchronize the location of the inserted watermark. The process of synchronizing the location for watermark insertion and detection is crucial to design robust watermarking. One solution for watermark synchronization is to use features. This paper reviews feature extraction techniques in feature-based watermarking: the Harris corner detector and the Mexican Hat wavelet scale interaction method. We evaluate the scale-invariant keypoint extractor in comparison with others. After feature extraction, the set of triangles is generated by Delaunay tessellation. These triangles are the location for watermarking. Redetection ratio of triangles is measured against geometric distortion attacks and signal processing attacks. Experimental results show that the scale invariant keypoint extractor is appropriate for robust watermarking.	algorithm;corner detection;delaunay triangulation;digital watermarking;distortion;feature extraction;harris affine region detector;image scaling;mexican hat wavelet;randomness extractor;robustness (computer science);signal processing;watermark (data file)	Hae-Yeoun Lee;Heung-Kyu Lee;Junseok Lee	2005		10.1007/11554028_43	synchronization;computer vision;computational geometry;computer science;theoretical computer science;signal processing;mathematics;watermark	EDA	45.51166279540036	-60.22871537931084	115919
86a21d44afd21561be778b303fc502c767d7481f	a statistical measure for evaluating regions-of-interest based attention algorithms	modelizacion;bottom up method;bottom up;metodo ascendente;analisis estadistico;incertidumbre;uncertainty;intelligence artificielle;probabilistic approach;region interes;methode ascendante;modelisation;statistical analysis;enfoque probabilista;approche probabiliste;region of interest;analyse statistique;pattern recognition;artificial intelligence;incertitude;inteligencia artificial;reconnaissance forme;region interet;reconocimiento patron;modeling;interest region	We present a new measure for evaluation of algorithms for the detection of regions of interest (ROI) in, e.g., attention mechanisms. In contrast to existing measures, the present approach handles situations of order uncertainties, where the order for some ROIs is crucial, while for others it is not. We compare the results of several measures in some theoretical cases as well as some real applications. We further demonstrate how our measure can be used to evaluate algorithms for ROI detection, particularly the model of Itti and Koch for bottom-up data-driven attention.	algorithm;bottom-up parsing;koch snowflake;region of interest	Martin Clauss;Pierre Bayerl;Heiko Neumann	2004		10.1007/978-3-540-28649-3_47	systems modeling;uncertainty;computer science;artificial intelligence;top-down and bottom-up design;operations research;statistics;region of interest	ML	45.45415754798185	-61.80306076457814	115926
4e2bd956ebc8fe1d10da6b0b4f6e4d3efceb8631	the connected-component labeling problem: a review of state-of-the-art algorithms		Abstract This article addresses the connected-component labeling problem which consists in assigning a unique label to all pixels of each connected component (i.e., each object) in a binary image. Connected-component labeling is indispensable for distinguishing different objects in a binary image, and prerequisite for image analysis and object recognition in the image. Therefore, connected-component labeling is one of the most important processes for image analysis, image understanding, pattern recognition, and computer vision. In this article, we review state-of-the-art connected-component labeling algorithms presented in the last decade, explain the main strategies and algorithms, present their pseudo codes, and give experimental results in order to bring order of the algorithms. Moreover, we will also discuss parallel implementation and hardware implementation of connected-component labeling algorithms, extension for n -D images, and try to indicate future work on the connected component labeling problem.	algorithm;connected-component labeling	Lifeng He;Xiwei Ren;Qihang Gao;Xiao Zhao;Bin Yao;Yuyan Chao	2017	Pattern Recognition	10.1016/j.patcog.2017.04.018	theoretical computer science;pixel;sequence labeling;connected-component labeling;machine learning;binary image;feature detection (computer vision);artificial intelligence;labeling problem;cognitive neuroscience of visual object recognition;algorithm;connected component;pattern recognition;computer science	Vision	40.12647170624742	-65.31275003476453	115945
f8c76e2d27f5cf11633bc1cd64c765f5c3f2bf1f	segmentation of mr images of the human brain using fuzzy adaptive radial basis function neural network	cluster algorithm;fuzzy c mean;fuzzy membership function;image segmentation;magnetic field;image processing;algorithme k moyenne;fonction base radiale;logique floue;procesamiento imagen;logica difusa;resonancia magnetica;qualite image;traitement image;fuzzy logic;mr imaging;radial basis function;magnetic resonance;rbf neural network;fonction appartenance;image quality;radial basis function neural network;segmentation image;membership function;brain imaging;algoritmo k media;k means algorithm;calidad imagen;funcion pertenencia;reseau neuronal;funcion radial base;resonance magnetique;red neuronal;k means clustering;human brain;neural network	A method for segmentation of magnetic resonance (MR) images of the human brain using a fuzzy adaptive radial basis function neural network (FARBF-NN) has been proposed. Since the quality of MR images always gets affected by intensity in-homogeneities (artifacts or noises), generated due to the non-uniformity of magnetic fields during the acquisition process, thereby making segmentation task more difficult. The outputs of the hidden layer neurons of the FARBF-NN have been modified using a fuzzy membership function to eliminate the effect of noises present in the input image. The proposed method has been tested both on simulated and real patient MR brain images for segmentation and found to be better than the k-means clustering algorithm, the fuzzy c-means (FCM) clustering algorithm, and the RBF neural network that uses k-means clustering algorithm to select the centers of the RBFs in the hidden layer, in most of the cases.	artificial neural network;brain implant;radial (radio);radial basis function	Jamuna Kanta Sing;Dipak Kumar Basu;Mita Nasipuri;Mahantapas Kundu	2005		10.1007/11590316_55	computer vision;image processing;computer science;artificial intelligence;machine learning;mathematics;artificial neural network;k-means clustering	ML	45.61918270608978	-63.83687889312895	116016
ef37654beca9aecf6e5e3b7305d4c0fdd76a774a	a method for deforming-driven exaggerated facial animation generation	exaggerated facial animation facial image facial diversity facial identity deforming parameters central point feature vector exaggerated facial features;facial animation facial features humans signal generators artificial intelligence intelligent robots robotics and automation centralized control robustness shape;automatic generation;feature vector;vectors;exaggeration deforming parameter feature vector facial animation;animation;facial animation;deforming parameter;transforms;facial features;face;vectors computer animation;computer animation;exaggeration;nose	This paper proposes a method for automatically generating facial animation with exaggerated features from a facial image. According to facial diversity and identity, an exaggerated face can be determined by the neutral face and the exaggeration effect difference that is represented with the deforming parameters. The proposed method utilizes the central point and the feature vector to represent a facial component and then transforms these feature vectors under the control of deforming parameters to generate the exaggerated facial features. The exaggerated facial animation can be driven to generate by the sequence of the deforming parameters. Experimental results prove that the proposed method has the advantages of simplicity, flexibility and directness, and the generated facial animations are expressive.	computer animation;facial recognition system;feature vector;image warping;real-time transcription	Ping Wei;Yuehu Liu;Yuanqi Su	2008	2008 International Conference on Cyberworlds	10.1109/CW.2008.105	face;anime;computer vision;computer facial animation;feature vector;computer science;geometry;computer animation;face hallucination;computer graphics (images)	Robotics	41.893552935188765	-56.40261278920565	116033
eecdef45ace4ce3f496abd94449ffe09f2e78b85	statistical models of shape and texture for face recognition	reconnaissance visage;modelizacion;relative position;texture;ajustamiento modelo;analisis estadistico;image processing;generic model;facies;gauchissement;localization;procesamiento imagen;image multiple;reference frame;imagen multiple;localizacion;probabilistic approach;traitement image;statistical model;form defect;multiple image;ajustement modele;modelisation;image interpretation;face recognition;localisation;interpretacion imagen;statistical analysis;enfoque probabilista;approche probabiliste;model matching;analyse statistique;textura;torcimiento;pattern recognition;interpretation image;reconnaissance forme;defaut forme;defecto forma;reconocimiento patron;modeling;warping	Human faces are an example of a class of objects in which each example exhibits significant variation in shape and appearance, but which is composed of a fixed number of sub-parts which have a similar configuration in every case. For such objects we can define landmark points on each example which imply a correspondence between different examples. We can then build statistical models of the shape by consid- ering the relative positions of landmarks, and can model the pattern of intensities across the object by warping them into a common reference frame. Such combined models of shape and appearance have been found to be powerful tools for image interpretation. They are generative mod- els, capable of synthesizing new examples similar to those in the training set. The formulation of such models is described, and their application to face location and recognition investigated. Particular attention is paid to methods of matching such models to new images in a multi-stage process.	facial recognition system;statistical model	Timothy F. Cootes;David Cristinacce;Vladimir S. Petrovic	2006		10.1007/11957959_27	active shape model;reference frame;image warping;statistical model;computer vision;active appearance model;systems modeling;internationalization and localization;facies;image processing;computer science;artificial intelligence;texture;statistics	Vision	47.19661344829126	-58.18393242330602	116317
5e81a56e8a0db48350cc349a38f099b57cb06c0e	feature matching and deformation for texture synthesis	texture warping;construccion arquitectura tecnologia ambiental;computacion informatica;conference_paper;texture synthesis;texture mapping;grupo de excelencia;feature matching;ciencias basicas y experimentales;image registration;distance transforms;oriented features;tecnologias;distance transform;neighborhood search;similarity measure;structural similarity	One significant problem in patch-based texture synthesis is the presence of broken features at the boundary of adjacent patches. The reason is that optimization schemes for patch merging may fail when neighborhood search cannot find satisfactory candidates in the sample texture because of an inaccurate similarity measure. In this paper, we consider both curvilinear features and their deformation. We develop a novel algorithm to perform feature matching and alignment by measuring structural similarity. Our technique extracts a feature map from the sample texture, and produces both a new feature map and texture map. Texture synthesis guided by feature maps can significantly reduce the number of feature discontinuities and related artifacts, and gives rise to satisfactory results.	texture synthesis	Qing Wu;Yizhou Yu	2004	ACM Trans. Graph.	10.1145/1015706.1015730	image texture;texture mapping;computer vision;computer science;image registration;structural similarity;machine learning;pattern recognition;distance transform;texture compression;texture synthesis;texture filtering;feature	Graphics	47.46732965719872	-62.110177833920275	116385
d2fdb36cfa5930a39eb231b46236421c5f288b5e	iris image capture system design for personal identification	evaluation performance;performance evaluation;technology;biometrie;computer science artificial intelligence;evaluacion prestacion;biometrics;biometria;iris recognition;qualite image;identificacion sistema;captador medida;measurement sensor;capteur mesure;science technology;system identification;image acquisition;system design;image quality;calidad imagen;computer science;computer science theory methods;identification systeme	Iris image acquisition is a key issue in iris recognition, as the quality of the captured image greatly affects the performance of the overall system This paper first discusses the current status of iris capture devices and then describes the design of a new iris sensor Experimental results with the iris images captured using the new iris image acquisition device are also presented in this paper.		Yuqing He;Yangsheng Wang;Tieniu Tan	2004		10.1007/978-3-540-30548-4_61	image quality;computer vision;system identification;computer science;artificial intelligence;iris recognition;biometrics;technology	EDA	45.29843896051383	-60.51540372654101	116590
93e3a8b3a2e947b74e78790e750937312fcd97fa	a robot vision system for recognizing 3d objects in low-order polynomial time	objet;reconocimiento;object;robotics;computerised pattern recognition;recognition;robot vision;computational complexity;data structures;robots;polynomial time;hypothesis generation computerised picture processing pattern recognition computer vision 3d object recognition efficient constant time algorithms robot vision system low order polynomial time 3d poly occlusion cluttered backgrounds time complexity data structure feature sphere;robotica;computerised picture processing;robotique;robots computational complexity computerised pattern recognition computerised picture processing data structures;reconnaissance;vision;objeto;robot vision systems polynomials layout object recognition data mining data structures streaming media feature extraction shape	Ahsrrucr -The two factors that determine the time complexity associated with model-driven interpretation of range maps are: 1) the particular strategy used for the generation of object hypotheses; and 2) the manner in which both the model and the sensed data are organized, data organization being a primary determinant of the efficiency of verification of a given hypothesis. 3D-POLY, a working system for recognizing objects in the presence of occlusion and against cluttered backgrounds is presented. The time complexity of this system is only O( n * ) for single object recognition, where 17 is the number of features on the object. The most novel aspect of this system is the manner in which the feature data are organized for the models; we use a data structure called the feature sphere for the purpose. Efficient constant time algorithms for assigning a feature to its proper place on a feature sphere and for extracting the neighbors of a given feature from the feature sphere representation are present. For hypothesis generation, we use local feature sets, a notion similar to those used before us by Rolles, Shirai and others. The combination of the feature sphere idea for streamlining verification and the local feature sets for hypothesis generation results in a system whose time complexity has a low-order polynomial bound.	3d film;algorithm;data structure;feature data;map;model-driven integration;outline of object recognition;polynomial;robot;time complexity	Chien-Hue Chen;Avinash C. Kak	1989	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.44070	robot;feature recognition;time complexity;vision;computer vision;feature vector;feature;computer science;local feature size;artificial intelligence;object;machine learning;kanade–lucas–tomasi feature tracker;robotics;computational complexity theory;k-nearest neighbors algorithm;feature;feature model	Robotics	41.1875587107765	-53.8899650041519	116613
be4e505d65a214ba4b130778621fa41fce8fff67	performance driven facial animation by appearance based tracking	analisis imagen;modelizacion;animacion por computador;pistage;contraction musculaire;image processing;facies;movimiento ocular;real time;lip;rastreo;procesamiento imagen;traitement image;marqueur;modelisation;marcador;levre;contraccion muscular;muscle contraction;eye movement;temps reel;image sequence;ceja;facial animation;face modeling;pattern recognition;tiempo real;labio;image analysis;secuencia imagen;reconnaissance forme;marker;sourcil;eyebrow;reconocimiento patron;computer animation;mouvement oculaire;modeling;analyse image;tracking;sequence image;animation par ordinateur	We present a method that estimates high level animation parameters (muscle contractions, eye movements, eye lids opening, jaw motion and lips contractions) from a marker-less face image sequence. We use an efficient appearance-based tracker to stabilise images of upper (eyes and eyebrows) and lower (mouth) face. By using a set of stabilised images with known animation parameters, we can learn a re-animation matrix that allows us to estimate the parameters of a new image. The system is able to re-animate a 32 DOF 3D face model in real-time.	3d modeling;feedback;floating-point unit;grayscale;high-level programming language;polygonal modeling;real-time clock	José Miguel Buenaposada;Enrique Muñoz;Luis Baumela	2005		10.1007/11492429_58	computer vision;image analysis;systems modeling;computer facial animation;facies;image processing;computer science;computer animation;tracking;eye movement;computer graphics (images)	Graphics	47.71455869623809	-56.55653626412919	116673
082ca9368abb8953521c8972b9b77809ff9fbad3	robotic intelligence for industrial automation: object flaw auto detection and pattern recognition by object location searching, object alignment, and geometry comparison	geometry matching;image inspection;image movement;pattern recognition;image subtraction;industrial automation	This research investigates the techniques using image subtraction to find flaws in the cosmetic products. The technique developed in this research moves the perfect image to overlap with the flawed image. Then, the perfect and the flawed images are aligned in the same orientation. After the perfect image has overlapped with the flawed image, the flawed image is subtracted from the perfect image. If there are flaws in the flawed image, after the image subtraction, the flaws will remain in the subtracted result. From beginning to end the inspection is done by machine automatically. There is no further human effort involved. The technique developed in this research can find the flaws in two-dimensional images very accurately. This paper explains the method using the second moment to find the orientations of cosmetic products. By the orientations of the cosmetic products, the perfect cosmetic product and the flawed cosmetic product can be aligned in the same orientation. A detailed process of image rotation is addressed in this paper.	automation;flaw hypothesis methodology;pattern recognition;robot	Ching-Liang Su	2002	Journal of Intelligent and Robotic Systems	10.1023/A:1015544400326	image restoration;computer vision;feature detection;computer science;artificial intelligence;automation;image subtraction;mathematics;engineering drawing	Robotics	50.270493383095705	-54.67290274057495	116767
51f89fc199564626d5b3f3c3ba5e012a743ec39f	fusion of complementary detectors for improving blotch detection in digitized films	spatio temporal filtering;evaluation performance;spatiotemporal filter;belief function;procesamiento informacion;restauration image;performance evaluation;image processing;belief function theory;07 05 mh;evaluacion prestacion;procesamiento imagen;digital film restoration;image restoration;07 05 pj;theorie conflit;data fusion;teoria conflicto;archive;traitement image;digital archive;filtre spatio temporel;temporal filtering;restauracion imagen;dempster shafer data fusion;teoria dempster shafer;archivo;fusion donnee;dempster shafer theory;information processing;dempster shafer;ground truth;filtro espacio tiempo;traitement information;fusion datos;conflict theory;fonction de croyance;quantitative evaluation;theorie dempster shafer	This paper proposes a novel method based on Dempster–Shafer (belief function) theory for the detection of blotches in digitized archive film sequences. The detection scheme relies on the fusion of two uncorrelated blotch detectors, one working in the spatial domain and the other one in the temporal domain. The imprecision and uncertainty of both detectors have been modeled using belief function theory, and their combination improves the decision, by taking into account the ignorance and the conflict between detectors. Quantitative evaluation using real blotches ground truth shows that this combination scheme improves the global performance, and compares favorably with two classical blotch detectors. 2007 Elsevier B.V. All rights reserved. PACS: 07.05.Mh; 07.05.Pj	archive;complementarity theory;ground truth;performance evaluation;physics and astronomy classification scheme;sensor;thresholding (image processing)	Sorin Tilie;Isabelle Bloch;Louis Laborelli	2007	Pattern Recognition Letters	10.1016/j.patrec.2007.05.005	computer vision;dempster–shafer theory;information processing;image processing;computer science;artificial intelligence;mathematics	Vision	45.906419903636206	-62.64787695500036	116896
d71d742d5bb7018fa81aa86f4e9b342e12b6e326	improvements to uncalibrated feature-based stereo matching for document images by using text-line segmentation	fractals;image segmentation;search space;image matching;image restoration;document capturing;set theory;feature grouping;divide and conquer methods;3d model;stereo matching;feature extraction;text detection divide and conquer methods document image processing feature extraction fractals image matching image restoration image segmentation set theory stereo image processing;stereo image processing;stereo image pairs text line segmentation uncalibrated feature based stereo document image matching standard stereo correspondence approaches global optimization scheme layout information 3d model document restoration systems divide and conquer approach search space grouping entity text line extraction character blobs;stereo correspondence;document image processing;text detection;global optimization;experimental evaluation;divide and conquer;3d reconstruction;feature extraction robustness three dimensional displays image segmentation cameras solid modeling stereo vision;feature grouping stereo matching stereo correspondence 3d reconstruction document capturing	Document images prove to be a difficult case for standard stereo correspondence approaches. One of the major problem is that document images are highly self-similar. Most algorithms try to tackle this problem by incorporating a global optimization scheme, which tends to be computationally expensive. In this paper, we show that incorporation of layout information into the matching paradigm, as a grouping entity for features, leads to better results in terms of robustness, efficiency, and ultimately in a better 3D model of the captured document, that can be used in various document restoration systems. This can be seen as a divide and conquer approach that partitions the search space into portions given by each grouping entity and then solves each of them independently. As a grouping entity text-lines are preferred over individual character blobs because it is easier to establish correspondences. Text-line extraction works reasonably well on stereo image pairs in the presence of perspective distortions. The proposed approach is highly efficient and matches obtained are more reliable. The claims are backed up by showing their practical applicability through experimental evaluations.	3d reconstruction;algorithm;analysis of algorithms;backup;binary image;binocular disparity;circuit restoration;computer stereo vision;distortion;feature model;global optimization;graphics processing unit;mathematical optimization;preprocessor;programming paradigm;robustness (computer science);self-similarity	Muhammad Zeshan Afzal;Martin Krämer;Syed Saqib Bukhari;Faisal Shafait;Thomas M. Breuel	2012	2012 10th IAPR International Workshop on Document Analysis Systems	10.1109/DAS.2012.44	3d reconstruction;image restoration;computer vision;divide and conquer algorithms;fractal;feature extraction;computer science;machine learning;pattern recognition;image segmentation;global optimization;set theory	Vision	44.18236928761307	-53.796410646099005	116984
afb1fe0b05b61e9c83ba070f8e69aa3841181df3	underwater image descattering and quality assessment	intelligent transportation systems;manganese;indexes;optical imaging;decision support systems;pattern analysis;integrated circuits	Vision-based underwater navigation and object detection requires robust computer vision algorithms to operate in turbid water. Many conventional methods aimed at improving visibility in low turbid water. In this paper, we propose a novel contrast enhancement to enhance high turbid underwater images using descattering and color correction. The proposed enhancement method removes the scatter and preserves colors. In addition, as a rule to compare the performance of different image enhancement algorithms, a more comprehensive image quality assessment index Qu is proposed. The index combines the benefits of SSIM index and color distance index. Experimental results show that the proposed approach statistically outperforms state-of-the-art general purpose underwater image contrast enhancement algorithms. The experiment also demonstrated that the proposed method performs well for image classification.	algorithm;color;computer vision;image editing;image quality;inverted index;object detection;structural similarity	Huimin Lu;Yujie Li;Xing Xu;Li He;Yun Li;Donald G. Dansereau;Seiichi Serikawa	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532708	computer vision;simulation;decision support system;computer science;artificial intelligence;manganese;optical imaging	Vision	39.57120399142977	-56.30289017858236	116988
d035cd4af4c77f46e4c29901a54acce30227e0e0	implementation of a fast reassembly methodology for polygon fragment	corner detection;image segmentation;edge detection;gray correlation fast reassembly methodology polygon image fragment straight line segment corner detection;robotics and automation image segmentation transforms image reconstruction asia informatics automatic control robot control power engineering and energy shape;data mining;gray correlation;feature extraction;pixel;transforms;hough transform;correlation;image segmentation edge detection;gray correlation fragment reassembly corner detection hough transform;algorithm design and analysis;fragment reassembly;noise	The polygon image fragment is a special fragment type, whose sides is composed of straight line segment, and it has seldom been researched. In this paper, a new image fragment reassembly methodology based on corner detection and gray correlation is proposed for polygon fragments. The experimentation indicates the reassembly methodology based on corner detection and gray correlation can get good result, although there are rotation, translation and noise between image fragments.	corner detection;experiment;segmentation and reassembly	Gang Xu;Yi Xian	2009	2009 International Asia Conference on Informatics in Control, Automation and Robotics	10.1109/CAR.2009.61	corner detection;hough transform;algorithm design;computer vision;edge detection;feature extraction;computer science;noise;image segmentation;engineering drawing;correlation;pixel;computer graphics (images)	Robotics	44.48537431003029	-65.88806197953024	116996
158b521d720318696ae28ae7dc68465b104e6254	non-local characterization of scenery images: statistics, 3d reasoning, and a generative model	image processing;generic model;statistical properties;graphical model	This work focuses on characterizing scenery images. We semantically divide the objects in natural landscape scenes into background and foreground and show that the shapes of the regions associated with these two types are statistically different. We then focus on the background regions. We study statistical properties such as size and shape, location and relative location, the characteristics of the boundary curves and the correlation of the properties to the region’s semantic identity. Then we discuss the imaging process of a simplified 3D scene model and show how it explains the empirical observations. We further show that the observed properties suffice to characterize the gist of scenery images, propose a generative parametric graphical model, and use it to learn and generate semantic sketches of new images, which indeed look like those associated with natural scenery.	generative model;gist;graphical model	Tamar Avraham;Michael Lindenbaum	2010		10.1007/978-3-642-15555-0_8	computer vision;image processing;computer science;machine learning;pattern recognition;mathematics;graphical model	Vision	44.79133976501535	-52.243274506724276	117047
d12a94e06b804739b10a6e9b94ca21ec9e967c9c	recognition of trademarks during sport television broadcasts	polar shape descriptors;sport television broadcast;trademark recognition;partial point matching algorithm	In the paper the problem of the recognition of trademarks placed on banners which are visible during a sport television broadcast is described and experimentally investigated. It constitutes the second stage of the process of the analysis of the banners, e.g. in order to estimate the time that a particular banner is visible and can exert influence on the customers’ behaviour. Banners placed near a play field during football matches were analysed. For this task four algorithms were selected and tested, namely the UNL shape descriptor combined with the Partial Point Matching Algorithm, the Contour Sequence Moments, the UNLFourier descriptor and the Point Distance Histogram. Amongst them the best result was obtained when using the UNL + PPMA approach. The average efficiency of this method was equal to 84%.	algorithm;circular shift;community climate system model;contour line;euclidean distance;experiment;television;universal networking language	Dariusz Frejlichowski	2011		10.1007/978-3-642-21596-4_38	simulation;multimedia	Vision	39.2729410907678	-56.9558553979248	117060
a65c77e030173b984ced2c9a73d2434fc214c10a	3-d-skeleton-based head detection and tracking using range images	reconnaissance visage;baja resolucion;dispositif securite;3d skeletal model;automotive engineering;safety device;tracking systems;head position;teledetection;image tridimensionnelle;topology;passive safety system;routing protocols;systeme passif;distance function;voxel neighborhood connectivity;protective device;estimacion robusta;video surveillance;robust detection;position tete;topology based framework;tracking system;low resolution range image data;protocole transmission;filtro kalman;modelo 3 dimensiones;damage prevention;nearest neighbor data association;image resolution;vision based 3d head detection;televigilancia;esqueleto;vehiculo caminero;vehicule routier;dispositivo seguridad;multiple hypothesis tracker;3 d skeleton;estimation robuste;modele 3 dimensions;biometrie;estudio comparativo;head detection;filtre kalman;kalman filters;biometrics;signalbehandling;low resolution;biometria;basse resolution;head face detection topology layout machine vision lighting video surveillance robustness vehicle safety automotive engineering;safety systems;airbags;invarianza;technique video;real time processing;three dimensional model;kalman filter;layout;graph invariance;tecnica video;occupant posture analysis;robust estimation;automotive safety;data association;voxel;skeleton;dispositivo proteccion;multiple hypothesis tracking;multiple hypothesis tracking mht;computer vision;invariance;etude comparative;vecino mas cercano;protocolo transmision;remote supervision	Vision-based 3-D head detection and tracking systems have been studied in several applications like video surveillance, face-detection systems, and occupant posture analysis. In this paper, we present the development of a topology-based framework using a 3-D skeletal model for the robust detection and tracking of a vehicle occupant's head position from low-resolution range image data for a passive safety system. Unlike previous approaches to head detection, the proposed approach explores the topology information of a scene to detect the position of the head. Among the different available topology representations, the Reeb graph technique is chosen and is adapted to low-resolution 3-D range images. Invariance of the graph under rotations is achieved by using a Morse radial distance function. To cope with the particular challenges such as the noise and the large variations in the density of the data, a voxel neighborhood connectivity notion is proposed. A multiple-hypothesis tracker (MHT) with nearest-neighbor data association and Kalman filter prediction is applied on the endpoints of the Reeb graph to select and filter the correct head candidate out of Reeb graph endpoints. A systematic evaluation of the head detection framework is carried out on full-scale experimental 3-D range images and compared with the ground truth. It is shown that the Reeb graph topology algorithm developed herein allows the correct detection of the head of the occupant with only two head candidates as input to the MHT. Results of the experiments demonstrate that the proposed framework is robust under the large variations of the scene. The processing requirements of the proposed approach are discussed. It is shown that the number of operations is rather low and that real-time processing requirements can be met with the proposed method.	algorithm;closed-circuit television;correspondence problem;experiment;face detection;full scale;ground truth;kalman filter;mhtml;poor posture;radial (radio);range imaging;real-time clock;real-time operating system;requirement;topological graph theory;tracking system;voxel	Pandu Ranga Rao Devarakota;Marta Castillo-Franco;Romuald Ginhoux;Bruno Mirbach;Serge Kater;Björn E. Ottersten	2009	IEEE Transactions on Vehicular Technology	10.1109/TVT.2009.2020595	kalman filter;computer vision;simulation;image resolution;machine vision;tracking system;computer science;signal processing	Robotics	48.44407653504837	-56.889714010739766	117124
4cbf873d3d359200267a3bc33d45c442061f6989	robust fft-based scale-invariant image registration with image gradients	reconnaissance visage;analisis imagen;image features;metodo correlacion;correlacion;ley uniforme;g740 computer vision;interpolation;estimation mouvement;heart;coordenada polar;invariance echelle;complex function;scaling phenomena;image processing;spatial domain;correlation method;aliasing;analisis forma;interpolacion;estimacion movimiento;video compression;low pass;image interpolation;procesamiento imagen;outlier;motion estimation;fft;intelligence artificielle;imagen nivel gris;invarianza escala;layout;correlation methods;effet dimensionnel;traitement image;transformacion fourier rapida;residual translation;registro imagen;observacion aberrante;frontal view face registration global motion estimation correlation methods fft scale invariant image registration;scale factors;face recognition;recalage image;image functions;complex gray level edge maps;translations;size effect;scale factor;robustesse;image registration;image niveau gris;scaling phenomena correlation methods fast fourier transforms gradient methods image registration interpolation;border effects;log polar fourier domain;robust performance;gradient methods;fast fourier transforms;arbitrary rotations;observation aberrante;artificial intelligence;image gradients;funcion compleja;image nature;robustness;fonction complexe;fft based correlation;image analysis;polar coordinate;pattern analysis;frontal;computer science and informatics;inteligencia artificial;border effect;efecto dimensional;correlation;interpolation errors;coordonnee polaire;transformation fourier rapide;fourier based correlation techniques;grey level image;analyse image;loi uniforme;facteur echelle;global motion estimation;factor escala;scale invariance;cameras;scale invariant image registration;analyse forme;object detection	We present a robust FFT-based approach to scale-invariant image registration. Our method relies on FFT-based correlation twice: once in the log-polar Fourier domain to estimate the scaling and rotation and once in the spatial domain to recover the residual translation. Previous methods based on the same principles are not robust. To equip our scheme with robustness and accuracy, we introduce modifications which tailor the method to the nature of images. First, we derive efficient log-polar Fourier representations by replacing image functions with complex gray-level edge maps. We show that this representation both captures the structure of salient image features and circumvents problems related to the low-pass nature of images, interpolation errors, border effects, and aliasing. Second, to recover the unknown parameters, we introduce the normalized gradient correlation. We show that, using image gradients to perform correlation, the errors induced by outliers are mapped to a uniform distribution for which our normalized gradient correlation features robust performance. Exhaustive experimentation with real images showed that, unlike any other Fourier-based correlation techniques, the proposed method was able to estimate translations, arbitrary rotations, and scale factors up to 6.	alias;aliasing;fast fourier transform;image gradient;image registration;image scaling;interpolation imputation technique;language translations;low-pass filter;map;robustness (computer science);test scaling;registration - actclass	Georgios Tzimiropoulos;Vasileios Argyriou;Stefanos P. Zafeiriou;Tania Stathaki	2010	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2010.107	scale factor;computer vision;fast fourier transform;image analysis;image processing;interpolation;computer science;mathematics;geometry;statistics;computer graphics (images)	Vision	50.78019942511775	-60.89395859127361	117134
cabaa60a565b9d1a4923391600797f8c7c9a8f2e	multi contrast based texture model for understanding human subjectivity	printing;filtering;filter bank;image resolution;color property;gabor filters;layout;psychology;correlation methods;texture features;orientation interaction;image texture;computer vision;human subjects;multiple contrast texture model;humans psychology layout image retrieval filter bank signal processing power system modeling gabor filters filtering printing;statistical analysis;image colour analysis;feature extraction;signal processing;psychology computer vision image texture image colour analysis feature extraction image retrieval statistical analysis correlation methods;human subjectivity understanding;humans;subjective interpretation;statistical textured images;correlation;power system modeling;canonical correlation;image retrieval multiple contrast texture model human subjectivity understanding subjective interpretation statistical textured images orientation interaction color property image resolution psychological responses correlation;psychological responses;image retrieval	We have researched subjective interpretation for statistical texture images in order to clarify human subjective intelpretation mechanism for images. We have focused on orientation interaction and color property, and unified those features by calculating the contrast over the entire image resolution. Next, we have measured psychological responses and corresponded them to our texture feature based on the canonical correlation statistics. We developed an image retrieval system for texture images based on our model. The results show that our model can retrieve images which give a similar impression, and can also predict images from some descriptive adjectives.	image resolution;image retrieval	Yuichi Kobayashi;Toshikazu Kato	2000		10.1109/ICPR.2000.903694	filter;image texture;layout;computer vision;canonical correlation;image resolution;feature extraction;image retrieval;computer science;machine learning;signal processing;pattern recognition;filter bank;correlation	Vision	40.99328743257549	-62.245469837240066	117188
685a21e49158ccf939c1cda92fc1c2397cfba410	use of gray value distribution of run lengths for texture analysis	analisis imagen;run length;analisis textura;tissue characterization;texture measure;texture analysis;image analysis;analyse image;analyse texture	Abstract   Most of the texture measures based on run lengths use only the lengths of the runs and their distribution. We propose to use the gray value distribution of the runs to define two new features, viz., low gray level run emphasis ( LGRE ) and high gray level run emphasis ( HGRE ).		A. Chu;C. M. Sehgal;James F. Greenleaf	1990	Pattern Recognition Letters	10.1016/0167-8655(90)90112-F	computer vision;image analysis;computer science;computer graphics (images)	Vision	45.32923289400409	-63.55450476384208	117247
69fa9356526da8e43c9972bb04a6832ad3963210	face detection using simplified gabor features and hierarchical regions in a cascade of classifiers	reconnaissance visage;funcion haar;evaluation performance;learning algorithm;context information;performance evaluation;learning;fonction haar;taux erreur;implementation;biometrie;evaluacion prestacion;haar function;biometrics;biometria;algorithme apprentissage;filtro gabor;aprendizaje;gabor filter;apprentissage;automatic recognition;face recognition;human visual system;signal classification;adaboost;filtre gabor;autogeneration mutuelle;pattern recognition;classification signal;robust performance;error rate;simplified gabor features;bootstrapping;reconnaissance forme;classification automatique;reconocimiento patron;face detection;implementacion;automatic classification;indice error;algoritmo aprendizaje;clasificacion automatica;reconocimiento automatico;reconnaissance automatique	0167-8655/$ see front matter 2009 Elsevier B.V. A doi:10.1016/j.patrec.2009.03.006 * Corresponding author. Tel.: +852 2766 6207; fax: E-mail address: enkmlam@polyu.edu.hk (K.-M. Lam Face-detection methods based on cascade architecture have demonstrated a fast and robust performance. In most of these methods, each node of the cascade employs the simple Haar-like features from the central eye–nose–mouth region using the boosting method. However, it can be empirically observed that, in the deeper nodes of the boosting process, the non-face examples collected by bootstrapping are in fact very similar to the face examples, and the error rate of those feature-based weak classifiers is very close to 50%. Consequently, the performance of the face detector is hardly further improved. In this paper, we propose a novel and simple solution to this problem by imitating the characteristics of the human visual system. The main idea of our solution is to boost the cascade based on a hierarchical strategy, which employs the information from the central and surrounding parts of the face regions step by step. We argue that the context information about a face can be advantageously used in the deeper nodes of the boosting process when the features derived from the central region of the face do not provide any further benefit. Furthermore, we also propose a simplified Gabor feature to extend the feature set for the training of deeper nodes. Experiments show that our proposed method can improve not only the detection performance, but also the detection speed, by about 10% when compared to the original AdaBoost face-detection method for our implementation. 2009 Elsevier B.V. All rights reserved.	adaboost;algorithm;boosting (machine learning);experiment;face detection;fax;gabor filter;haar wavelet;lam/mpi	Xiaohua Li;Kin-Man Lam;Lansun Shen;Jiliu Zhou	2009	Pattern Recognition Letters	10.1016/j.patrec.2009.03.006	adaboost;facial recognition system;computer vision;face detection;speech recognition;word error rate;computer science;artificial intelligence;pattern recognition;human visual system model;implementation;bootstrapping;biometrics	Vision	44.19396051308788	-59.0131127646036	117306
556a9a8bf8aeb0ba1860cdc5042c602a8f245702	adaptive multiple sets of css features for hand posture recognition	curvature scale space;hand posture recognition;feature matching;rotation invariance;feature extraction;nearest neighbor;gesture recognition	In this paper, an adaptive feature extraction approach based on curvature scale space (CSS) is presented for translation, scale, and rotation invariant recognition of hand postures. First, hands are segmented from hand posture images into binary silhouettes and then binary hand contours are computed. CSS images are then used to represent the contours of hand postures. In particular, adaptive multiple sets of CSS features are extracted to address the problem of deep concavities in the contours of hand postures. Finally, 1-nearest neighbor techniques are used to perform adaptive multiple sets of CSS feature matching for hand posture identification. Results indicate that the proposed approach performs well in the recognition of hand postures. And, the proposed approach is more accurate than previous methods which were based on conventional features. The proposed technique could be useful in improving the recognition of hand postures.	cascading style sheets;poor posture	Chin-Chen Chang	2006	Neurocomputing	10.1016/j.neucom.2005.11.002	computer vision;speech recognition;feature extraction;computer science;machine learning;pattern recognition;gesture recognition;mathematics;k-nearest neighbors algorithm	Vision	40.66401777305345	-57.138600283447914	117373
161058642d9e3d1230fd512908731a6bca656432	exact compensation of color-weakness with discrimination threshold matching	engineering and technology;teknik och teknologier	In this paper we describe a novel compensation algorithm for color-weakness based on a new, objective criterion to compare normal observers and color-weak observers, using Riemann geometric properties of color spaces. The criterion is to match the color discrimination thresholds of average, normal observers and a colorweak observer. The method uses local and global isometry theory and provides the two groups of observers with the same color-difference experience. A one-dimensional compensation and simulation of color-weakness is shown as an application of the general approach to the Brettel color-blind model. The 2D and 3D compensations and simulations are illustrated in chromaticity planes and full color spaces.		Rika Mochizuki;Satoshi Oshima;Reiner Lenz;Jinhui Chao	2011		10.1007/978-3-642-21657-2_17	computer vision;mathematical optimization;control theory;mathematics	Vision	51.40852809522715	-61.477734215081696	117379
111973239adc2cfdf3b493a50c350b4aee6466c1	flow-based local optimization for image-to-geometry projection	optimisation;computer graphics;image color analysis computer graphics;image color analysis cameras three dimensional displays optical imaging solid modeling adaptive optics geometry;geometry;photography;three dimensional;computer graphic;scaling up;3d model;optical imaging;three dimensional displays;image color analysis;image colour analysis;feature extraction;image registration;solid modeling;solid modelling cameras feature extraction image colour analysis image registration image sequences optimisation photography;global optimization;optical flow;per vertex attribute encoding flow based local optimization image to geometry projection photographic data set 3d model object information pipeline reconstruction camera calibration multiple camera image object surface optical flow overlapping image low level geometric detail global optimization manual method mapping strategy;camera calibration;cameras;solid modelling;adaptive optics;image sequences	The projection of a photographic data set on a 3D model is a robust and widely applicable way to acquire appearance information of an object. The first step of this procedure is the alignment of the images on the 3D model. While any reconstruction pipeline aims at avoiding misregistration by improving camera calibrations and geometry, in practice a perfect alignment cannot always be reached. Depending on the way multiple camera images are fused on the object surface, remaining misregistrations show up either as ghosting or as discontinuities at transitions from one camera view to another. In this paper we propose a method, based on the computation of Optical Flow between overlapping images, to correct the local misalignment by determining the necessary displacement. The goal is to correct the symptoms of misregistration, instead of searching for a globally consistent mapping, which might not exist. The method scales up well with the size of the data set (both photographic and geometric) and is quite independent of the characteristics of the 3D model (topology cleanliness, parametrization, density). The method is robust and can handle real world cases that have different characteristics: low level geometric details and images that lack enough features for global optimization or manual methods. It can be applied to different mapping strategies, such as texture or per-vertex attribute encoding.	3d modeling;3d reconstruction;alignment;alpha compositing;anatomy, regional;attribute grammar;basis function;calibration;circuit restoration;computation;displacement mapping;global optimization;image resolution;local search (optimization);mathematical optimization;morphologic artifacts;optical flow;psychologic displacement;registration;robustness (computer science);rollover (key);texture mapping;vertex (computer graphics)	Matteo Dellepiane;Ricardo Marroquim;Marco Callieri;Paolo Cignoni;Roberto Scopigno	2012	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2011.75	three-dimensional space;computer vision;camera resectioning;feature extraction;computer science;image registration;photography;optical imaging;optical flow;solid modeling;computer graphics;adaptive optics;global optimization;computer graphics (images)	Visualization	52.65932332434268	-53.26649566482268	117491
2838470b5090b53545d777fc6e1e474895bddce0	a new efficient svm-based edge detection method	edge detection;gradient and zero crossing operators;gaussian radial basis function kernel;radial basis function;computer experiment;least squares support vector machine	An innovative edge detection algorithm, using both the gradients and the zero crossings to locate the edge positions, is presented in this paper. Based on the least squares support vector machine (LS-SVM) with Gaussian radial basis function kernel, a set of the new gradient operators and the corresponding second derivative operators are obtained. Computer experiments are carried out for extracting edge information from real images and sharp image edges are obtained from a variety of sample images. Some of the best results are attained from a number of standard test problems. The performance of the proposed algorithm is compared with many other existing methods, including Sobel and Canny detectors. The experimental results indicate that the proposed edge detector is near equal to the Canny in the performance and is fast in the speed. 2004 Elsevier B.V. All rights reserved.	algorithm;canny edge detector;computer experiment;deriche edge detector;edge detection;gradient;least squares support vector machine;radial (radio);radial basis function kernel;sensor;sobel operator;turing test	Sheng Zheng;Jian Liu;Jin-Wen Tian	2004	Pattern Recognition Letters	10.1016/j.patrec.2004.03.009	least squares support vector machine;computer vision;mathematical optimization;radial basis function;computer experiment;edge detection;radial basis function kernel;image gradient;computer science;machine learning;deriche edge detector;pattern recognition;mathematics;canny edge detector;marr–hildreth algorithm	Vision	46.37891383501149	-65.3362958960827	117580
3975de8f8bd1d33522d74fe24f9c8bb680caae7f	automatic image segmentation by wave propagation	velocidad propagacion;iterative method;esquema euler;evaluation performance;approximation eikonale;wavefront;duracion trayecto;image segmentation;wavefronts;performance evaluation;travel time;image processing;multiple wave;euler scheme;color space;propagation onde;automatic segmentation;arrival time;evaluacion prestacion;fast marching method;level set;schema euler;procesamiento imagen;eikonal approximation;propagation onde electromagnetique;propagation velocity;electromagnetic wave propagation;guia onda biselado;estimacion a priori;traitement image;similitude;metodo iterativo;a priori estimation;accuracy;stopping criterion;eikonal equation;tapered waveguide;precision;varying speed;propagacion onda;methode iterative;tiempo llegada;smoothing;onde multiple;robustesse;velocidad variable;segmentation image;similarity;estimation a priori;a priori information;robustness;mixture of gaussians;vitesse variable;espace chromatique;frente onda;similitud;espacio cromatico;temps arrivee;wave propagation;imagen color;region growing;vitesse propagation;image couleur;front onde;onda multiple;color image;robustez;guide onde biseaute;duree trajet	We develop a level set based region growing method for automatic partitioning of color images into segments. Previous attempts at image segmentation either suffer fromrequiring a priori information to initialize regions, being computationally complex, or fail to establish the color consistency and spatial connectivity at the same time. Here, we represent the segmentation problem as monotonic wave propagation in an absorbing medium with varying front speeds. We iteratively emit waves from the selected base points. At a base point, the local variance of the data reaches a minimum, which indicates the base point is a suitable representative of its local neighborhood. We determine local variance by applying a hierarchical gradient operator. The speed of the wave is determined by the color similarity of the point on the front to the current coverage of the wave, and by edge information. Thus, the wave advances in an anisotropic spatial-color space. The absorbing function acts as a stopping criterion of the wave front. We take advantage of fast marching methods to solve the Eikonal equation for finding the travel times of the waves. Our method is superior to the linkage-based region growing techniques since it prevents leakage and imposes compactness on the region without over-smoothing its boundary. Furthermore, we can deal with sharp corners and changes in topology. The automatic segmentation method is Eulerian, thus it is computationally efficient. We compare our results with a non-Eulerian approach that evaluates the arrival times of multiple waves as well. Our experiments illustrate the robustness, accuracy, and effectiveness of the proposed method. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c ©Mitsubishi Electric Research Laboratories, Inc., 2004 201 Broadway, Cambridge, Massachusetts 02139	acknowledgment index;algorithmic efficiency;broadway (microprocessor);color space;eulerian path;experiment;fast marching method;gradient;image segmentation;lagrangian and eulerian specification of the flow field;linkage (software);region growing;smoothing;software propagation;spectral leakage	Fatih Murat Porikli	2004		10.1117/12.527193	mathematical optimization;mathematics;geometry;optics	Vision	46.92095850518168	-64.48757972289918	117601
62df24c9cf4dfebb8717e28ca3d40374c1864399	texture descriptors using neighborhood information		"""The use of point neighborhood information and dependence in the analysis of visual scenes is not new. One of its earlier uses, in analog form, was in the analysis of T.V. pictures [1]. Here the grey levels at two neighboring points on alternate scan lines were monitored in a voltage form and fed to an X Y deflection plate arrangement. The change in grey levels could be observed directly on a C.R.T. as the picture was scanned. Neighborhood information has also been used extensively in character recognition applications, where the information at a given picture point on the digitized character was considered as a statistical function of the grey levels at neighboring points [2]. In the majority of cases only binarized situations were considered. The application to be discussed here is in the area of texture description. The types of textures to be considered are the kind in which an observer can readily identify edges, edge direction, blobs and blob size. The observer is also to determine the color of the items within the texture as well as the grey level of what he would call the background. The measurements to be described for obtaining such descriptions are based upon direct rather than statistical neighborhood dependence and will hopefully yield a quantitative assessment of the texture, in that they will indicate features like """"the texture contains blobs which are elongated in the horizontal direction"""" or """"the blobs are of grey level 27 and are on a background of grey level 49."""" These measurements can be used to classify textures, especially in the case when a decision as to whether a given texture belongs to a given category has to be made."""	color;grayscale;image;optical character recognition;scan line;television;texture mapping	Edward S. Deutsch;N. J. Belknap	1972	Computer Graphics and Image Processing	10.1016/S0146-664X(72)80012-1	computer vision;machine learning;pattern recognition	Vision	43.06768947702188	-65.18248959163483	117718
4f9a8d232491f34f5efdc8cc91d5027594334949	postmatch pruning of sift pairs for iris recognition	local feature matching;iris matching;sift;pruning of impairments;scale invariant feature transform	This article looks into pros and cons of the conventional global and local feature matching techniques for iris. The review of related research works on matching techniques leads to the observation that local features like scale invariant feature transform SIFT gives satisfactory recognition accuracy for good quality images. However the performance degrades when the images are occluded or taken non-cooperatively. As SIFT matches keypoints on the basis of 128-D local descriptors, hence it sometimes falsely pairs two keypoints which are from different portions of two iris images. Subsequently the need for filtering or pruning of faulty SIFT pairs is felt. The paper proposes two methods of filtering impairments faulty pairs based on the knowledge of spatial information of the keypoints. The two proposed pruning algorithms angular filtering and scale filtering are applied separately and applied in union to have a complete comparative analysis of the result of matching. The pruning approaches has given better recognition accuracy than conventional SIFT when experimented on two publicly available BATH and CASIAv3 iris databases.	alpha–beta pruning;iris recognition;scale-invariant feature transform	Sambit Bakshi;Hunny Mehrotra;Banshidhar Majhi	2013	IJBM	10.1504/IJBM.2013.052965	computer vision;computer science;machine learning;pattern recognition;scale-invariant feature transform	Vision	39.26084047452704	-58.398591649123546	117761
257f3df085093e0708a2583c6a921bd2e3a67f71	finding edges by a contrario detection of periodic subsequences		A new method to detect salient pieces of boundaries in an image is presented. After detecting perceptually meaningful level lines, periodic binary sequences are built by labeling each point in close curves as salient or non-salient. We propose a general and automatic method to detect meaningful subsequences within these binary sequences. Experimental results show its good performance.	sensor	Mariano Tepper;Pablo Musé;Andrés Almansa;Marta Mejail	2012		10.1007/978-3-642-33275-3_95	pattern recognition;computer vision;periodic graph (geometry);salient;artificial intelligence;computer science;binary number;edge detection	Vision	39.71509729748307	-52.53389870675963	117806
6496a1a9d96dcca186ff6bef41c65d9a5d5079f3	human posture recognition using curved segments for image retrieval	analisis imagen;extraction information;image recognition;reconocimiento imagen;reliability;cuerpo;information extraction;body;skin;methode;membre;human body model;algorithme;algorithm;posture;data storage;human body;postura;reconnaissance image;corps;pattern recognition;image analysis;reconnaissance forme;facial recognition systems;video;reconocimiento patron;face detection;miembro;metodo;analyse image;method;limb;algoritmo;extraction informacion;image retrieval	This paper presents a human posture recognition method from a single image. We rst segment an image into homogeneous regions and extract curve segments corresponding to human body parts. Each body part is considered as a 2D ribbon. From the smooth curve segments in skin regions, 2D ribbons are extracted and a human body model is constructed. We assign a predeened posture type to the image according to the constructed body model. For the user input query to retrieve images containing human of speciic posture, the system convert the query to a body model. The body model is compared to other body models saved in the local storage of target images and images of good matches are retrieved. When a face detection result is available for the given image, it is also used to increase the reliability of body model. For the query human posture, our system retrieves images of the corresponding posture. As another application, the proposed method provides an initial location of a human body to track in a video sequence.	autostereogram;face detection;image retrieval;poor posture;thread-local storage	JongSeung Park;Hwang-Seok Oh;DukHo Chang;EeTack Lee	2000		10.1117/12.373539	computer vision;geography;artificial intelligence;cartography	Vision	48.474081841609845	-58.97179821834641	118036
8330ce7da943011c6a69a45ba61aa415fc85feca	high-speed action recognition and localization in compressed domain videos	databases;motion analysis;traitement signal;teledetection;mesure deplacement;video databases;front end;video encoding;object recognition;video surveillance;image motion analysis;compressed domain video;image coding;performance evaluation;image processing;data compression;televigilancia;video signal processing;motion similarity;real time video surveillance;real time;localization;stabilization;procesamiento imagen;technique video;analyse mouvement;pregunta documental;low complexity;video sequences;base donnee video;testing;localizacion;segmentation;space time;tecnica video;espacio tiempo;traitement image;similitude;video signal processing action recognition compressed domain processing real time video surveillance video coding;codage image;video coding;accuracy;remote supervision;compression image;precision;localisation;displacement measurement;senal video;signal video;image compression;codage video;estabilizacion;telesurveillance;motion correlation measure;signal processing;action recognition;remote sensing;video coding gesture recognition image motion analysis object recognition;image sequence;teledeteccion;similarity;query;traitement signal video;video signal;video technique;secuencia imagen;medicion desplazamiento;stabilisation;compresion dato;similitud;compressed domain processing;analisis movimiento;classification accuracy;motion measurement;video database;encoding;video encoding action recognition compressed domain video motion similarity motion correlation measure;procesamiento senal;high speed;gesture recognition;segmentacion;cameras;cameras testing performance evaluation video sequences encoding motion measurement databases video surveillance video coding video signal processing;espace temps;sequence image;compression donnee;requete;compresion imagen	We present a compressed domain scheme that is able to recognize and localize actions at high speeds. The recognition problem is posed as performing an action video query on a test video sequence. Our method is based on computing motion similarity using compressed domain features which can be extracted with low complexity. We introduce a novel motion correlation measure that takes into account differences in motion directions and magnitudes. Our method is appearance-invariant, requires no prior segmentation, alignment or stabilization, and is able to localize actions in both space and time. We evaluated our method on a benchmark action video database consisting of six actions performed by 25 people under three different scenarios. Our proposed method achieved a classification accuracy of 90%, comparing favorably with existing methods in action classification accuracy, and is able to localize a template video of 80 x 64 pixels with 23 frames in a test video of 368 x 184 pixels with 835 frames in just 11 s, easily outperforming other methods in localization speed. We also perform a systematic investigation of the effects of various encoding options on our proposed approach. In particular, we present results on the compression-classification tradeoff, which would provide valuable insight into jointly designing a system that performs video encoding at the camera front-end and action classification at the processing back-end.	benchmark (computing);data compression;pixel	Chuohao Yeo;Parvez Ahammad;Kannan Ramchandran;S. Shankar Sastry	2008	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2008.927112	computer vision;image processing;computer science;signal processing;video tracking;gesture recognition;accuracy and precision;multimedia;motion compensation;statistics;computer graphics (images)	Vision	47.79115839474111	-55.659999019231805	118039
a3d9778db49081d3ba402bc2734f3ee3bd7dfab9	detection and estimation translations of large images using random projections	estimation theory;optimisation;optimisation estimation theory image processing iterative methods;image processing;iterative methods;vertical translation estimation translations detection translations random projections image frames image stabilization euclidean norm optimization problems squared norms iterative procedure horizontal translation;vectors;estimation;image color analysis;vectors estimation digital images image color analysis correlation sparse matrices;correlation;digital images;sparse matrices	This paper describes a technique of fast detection and estimation of translations in large image frames for image stabilization. Our approach is based on random projection methodology for reduction of image dimension which retain with prescribed accuracy and probability the squared Euclidean norm of projected vectors (image's rows and columns). We formulate simple optimization problems for estimation of vertical and horizontal motions of the frame. The first one tries to find the best match between energies (squared norms) of rows (columns) of the actual projected image and the projected reference frame. The second one uses the squared Euclidean distance between the same objects. An iterative procedure based on the successive, alternate estimation of a vertical and a horizontal translation is proposed.	column (database);computation;dimensionality reduction;euclidean distance;image processing;iterative method;locality-sensitive hashing;mathematical optimization;random projection;reference frame (video);vii	Ewa Skubalska-Rafajlowicz	2011	The 2011 International Workshop on Multidimensional (nD) Systems	10.1109/nDS.2011.6076838	mathematical optimization;combinatorics;feature detection;u-matrix;mathematics;geometry	Vision	51.108328405538394	-53.53909599846183	118068
22bcd17277e43181a940e0e9f3e83ff5d135164f	a graph matching approach to symmetry detection and analysis		Spectral relaxation was shown to provide an efficient approach for solving a gamut of computational problems, ranging from data mining to image registration. In this chapter we show that in the context of graph matching, spectral relaxation can be applied to the detection and analysis of symmetries in n-dimensions. First, we cast symmetry detection of a set of points in Rn as the self-alignment of the set to itself. Thus, by representing an object by a set of points S ∈Rn, symmetry is manifested by multiple self-alignments. Secondly, we formulate the alignment problem as a quadratic binary optimization problem, solved efficiently via spectral relaxation. Thus, each eigenvalue corresponds to a potential self-alignment, and eigenvalues with multiplicity greater than one correspond to symmetric self-alignments. The corresponding eigenvectors reveal the point alignment and pave the way for further analysis of the recovered symmetry. We apply our approach to image analysis, by using local features to represent each image as a set of points. Last, we improve the scheme’s robustness by inducing geometrical constraints on the spectral analysis results. Our approach is verified by extensive experiments and was applied to two and three dimensional synthetic and real life images.	apache axis;clutter;computational problem;data mining;embedded system;experiment;fixed points of isometry groups in euclidean space;image analysis;image registration;linear programming relaxation;link rot;matching (graph theory);mathematical optimization;optic axis of a crystal;optimization problem;real life;shiira;software rot;synthetic intelligence	Michael Chertok;Yosi Keller	2012		10.1007/978-3-642-24049-2_7	folded cube graph;factor-critical graph;combinatorics;graph bandwidth;3-dimensional matching;voltage graph;quartic graph;strength of a graph	Vision	50.68325140719053	-53.87378524458191	118176
ce3596e3a71a4792f6792d68f07f8c89155f6dbc	object classification using half-contour features	edge boundary;mathematical morphology;morfologia matematica;decision tree;image processing;contour;procesamiento imagen;arbol decision;classification;traitement image;experimental result;morphological operations;resultado experimental;pattern recognition;contorno;object classification;reconnaissance forme;reconocimiento patron;resultat experimental;arbre decision;clasificacion;morphologie mathematique	We address the problem of classifying objects based upon shape using features of an object's half-contours . Objects belonging to the same category arc envisioned to share several shape characteristics, but they may have other dissimilarities in shape, size, color, and orientation . By identifying essential shape features for each category. objects satisfying these shape constraints Lire classified without the use of statistical and/or syntactical methods . A fast outer contour tracer and interior pixel labeler for extracting object contours are described .	color;contour line;label printer applicator;pixel;shape context	Thomas J. Hebert;Seenwei Chen	1993	Pattern Recognition Letters	10.1016/0167-8655(93)90031-8	computer vision;mathematical morphology;image processing;biological classification;computer science;artificial intelligence;decision tree;pattern recognition;mathematics	Vision	46.07127518354948	-61.65864864551672	118404
8e3b750f2336e1c6965850e84e3ff9566ff6e4ee	smoothness constraints in recursive search motion estimation for picture rate conversion	moving image;smoothing methods correlation methods image texture motion compensation motion estimation recursive estimation;traitement signal;methode recursive;recursive estimation;texture;motion compensation mc;block correlation;estimation mouvement;detection forme;estimation recursive;image processing;motion estimation me;motion compensation;recursive search rs;systeme embarque;edge detection;implementation;piecewise smooth;real time;estimacion movimiento;recursive search motion estimation;metodo recursivo;procesamiento imagen;recursive method;consumer market embedded devices smoothness constraint recursive search motion estimation picture rate conversion motion compensation algorithms block matching block correlation brightness constancy assumption translational motion;motion estimation;motion compensation algorithms;correlation methods;shape detection;imagen movil;traitement image;image mobile;motion compensated;image texture;motion estimation motion compensation equations optimization methods flat panel displays image motion analysis vectors optical materials permission inference algorithms;deteccion contorno;algorithme;brightness;algorithm;detection contour;compensation mouvement;embedded systems;consumer market embedded devices;deteccion forma;smoothing methods;brillance;vectors;deformation;recursive search rs block matching motion compensation mc motion estimation me;signal processing;movimiento traslacion;pixel;textura;picture rate conversion;mathematical model;correspondencia bloque;block matching;mouvement translation;optimization;correlation;correspondance bloc;implementacion;translation motion;procesamiento senal;brillantez;translational motion;brightness constancy assumption;deformacion;smoothness constraint;embedded device;algoritmo	Many motion compensation algorithms are based on block matching. The quality of the block correlation depends on the validity of the brightness constancy assumption and the assumption of fixed translational motion within a block. These assumptions are invalid in areas with texture changes, noise, lighting changes, and rapid deformations. Smoothness priors should enforce stable estimates in these regions by propagating neighboring estimates, while preserving hard object boundaries (piecewise smoothness). Most motion estimation algorithms that successfully implement these constraints are computationally complex. In this paper, we show an intuitive and computationally efficient way to implement them within the framework of (real-time) recursive search, targeting consumer-market embedded devices with limited resources.	algorithmic efficiency;approximation algorithm;bandwidth (signal processing);embedded system;gradient;modulus of smoothness;motion compensation;motion estimation;real-time clock;real-time computing;recursion (computer science);reed–solomon error correction	Chris Bartels;Gerard de Haan	2010	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2010.2058474	image texture;computer vision;mathematical optimization;edge detection;image processing;computer science;signal processing;motion estimation;mathematical model;mathematics;geometry;texture;implementation;motion compensation;correlation;deformation;brightness;pixel	Vision	53.14690525700775	-58.28603712962053	118676
0361bb05785f18d877ef3e3cec375869dff8d24b	computing regions of interest for geometric features in digital images	optimisation;transformation affine;image numerique;combinatorics;uncertainty modeling;geometric primitives;optimizacion;incertidumbre;uncertainty;combinatoria;combinatoire;transformation polytopes;calculo automatico;geometric feature;computing;primitivo;calcul automatique;52bxx;politope;technology and engineering;informatique theorique;region of interest;affine transformation;region;imagen numerica;primitif;optimization;incertitude;digital image;polytopes;primitive;transformacion afin;computer theory;polytope;informatica teorica	We present an uncertainty model for geometric transformations based on polygonal uncertainty regions and transformation polytopes. The main contribution of this paper is a systematic approach for the computation of regions of interest for features by using the uncertainty model for affine and projective transformations. The focus is on the solution of transformation problems for geometric primitives, especially lines, so that regions of interest can be computed for corresponding geometric features in distinct images.	digital image;region of interest	Kristof Teelen;Peter Veelaert	2009	Discrete Applied Mathematics	10.1016/j.dam.2009.02.002	polytope;combinatorics;topology;geometric transformation;mathematics;geometry	Graphics	48.96205497799038	-61.236166996181964	119092
00b6b5795ff5b7a39b7bf3c48a94b6057d6085ee	best-buddies similarity for robust template matching	statistical analysis image matching;statistical analysis best buddies similarity bbs robust template matching parameter free similarity measure best buddies pairs bbps complex geometric deformations;robustness clutter numerical models visualization image color analysis extraterrestrial measurements q measurement	We propose a novel method for template matching in unconstrained environments. Its essence is the Best-Buddies Similarity (BBS), a useful, robust, and parameter-free similarity measure between two sets of points. BBS is based on counting the number of Best-Buddies Pairs (BBPs)-pairs of points in source and target sets, where each point is the nearest neighbor of the other. BBS has several key features that make it robust against complex geometric deformations and high levels of outliers, such as those arising from background clutter and occlusions. We study these properties, provide a statistical analysis that justifies them, and demonstrate the consistent success of BBS on a challenging real-world dataset.	clutter;similarity measure;template matching	Tali Dekel;Shaul Oron;Michael Rubinstein;Shai Avidan;William T. Freeman	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7298813	computer vision;machine learning;pattern recognition;mathematics	Vision	44.61945262959836	-53.300850524969476	119211
25fb6b096d720e84f73702db6f7bac8a2b2c6658	a minimum-entropy procedure for robust motion estimation	image processing;motion compensation;image matching;minimum entropy methods;motion estimation;indexing terms;robustness motion estimation entropy image processing video sequences design for disassembly image matching motion compensation adaptive estimation signal processing;entropy estimation;motion compensated;robustness image matching minimum entropy methods motion compensation adaptive estimation image processing;motion estimation image matching minimum entropy methods;motion vector;block matching;robustness;efficient estimation;entropy method;kernel based method minimum entropy procedure robust motion estimation block matching approach parzen windowing;adaptive estimation	We focus on motion estimation using a block matching approach and suggest using a minimum-entropy criterion. Many entropy-based estimation procedures exist, such as plug-in estimators based on Parzen windowing. We consider here an alternative that is applicable to data of any dimension and that circumvents the critical issues raised by kernel-based methods. To the best of our knowledge, this criterion has not yet been considered for image processing problems. The inherent robustness property of entropy is expected to provide a robust and efficient estimation of the motion vector of a block of a video sequence. In particular, the minimum-entropy estimator should be robust to occlusions and variations of luminance, for which standard approaches like SSD usually meet their limitations.	entropy (information theory);image processing;kernel density estimation;motion estimation;plug-in (computing);solid-state drive;window function	Sylvain Boltz;Eric Wolsztynski;Eric Debreuve;Eric Thierry;Michel Barlaud;Luc Pronzato	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312552	computer vision;mathematical optimization;index term;entropy estimation;image processing;computer science;pattern recognition;motion estimation;mathematics;motion compensation;robustness	Robotics	50.55306933099054	-65.47825275340138	119231
d1e425b9e049ab9bdc6a3edaa8ca2bb46ffa4009	determining pose of a human face from a single monocular image		A new approach for estimating 3D head pose form a monocular image is proposed. Our approach employs general prior knowledge of face structure and the corresponding geometrical constraints provided by the location of vanishing point to determine pose of human faces. Eye-lines and mouth-line are assumed parallel in 3D space, and the vanishing point formed by the intersection of the eyeline and mouth-line in the image can be used to infer 3D orientation and location of human face. Perspective invariance of cross ratio and harmonic range is used to locate the vanishing point stably. The robustness analysis of the algorithm with synthesis data and real face images are enclosed.	algorithm;computation;line level;vanishing point	Jian-Gang Wang;Eric Sung;Ronda Venkateswarlu	2003		10.5244/C.17.11	computer vision;mathematics;geometry	Vision	47.22531379210473	-53.53843989305063	119264
3e63e93b46a403f4bdbf3f7e497dc53c23b6824c	elastic appearance models		This paper presents a fusion of the active appearance model (AAM) and the Riemannian elasticity framework which yields a non-linear shape model and a linear texture model – the active elastic appearance model (EAM). The non-linear elasticity shape model is more flexible than the usual linear subspace model, and it is therefore able to capture more complex shape variations. Local rotation and translation invariance are the primary explanation for the additional flexibility. In addition, we introduce global scale invariance into the Riemannian elasticity framework which together with the local translation and rotation invariances eliminate the need for separate pose estimation. The new approach was tested against AAM in three experiments; face labeling, face labeling with poor initialization and corpus callosum segmentation. In all the examples the EAM performed significantly better than AAM. Our Matlab implementation can be downloaded through svn from https://svn.imm.dtu.dk/AAMLab/svn/AAMLab/trunk/ .	active appearance model;automatic acoustic management;elasticity (data store);embedded atom model;experiment;matlab;nonlinear system	Mads Fogtmann Hansen;Jens Fagertun;Rasmus Larsen	2011		10.5244/C.25.91	computer vision;simulation;mathematics	Vision	42.688683955120176	-56.21074474913149	119383
09ee4985f2772facc37b47162978f05167e5f9af	unsupervised texture segmentation based on histogram of encoded gabor features and mrf model	unsupervised learning;self organising feature maps image texture image segmentation unsupervised learning;histograms;image segmentation;application software;gabor transform;biomedical imaging;gabor filters;texture segmentation;unsupervised;texture features;encoded gabor features;computer applications;image texture;feature vector;mrf model;gabor filter;self organising feature maps;space use;feature extraction;kohnen s sofm texture segmentation encoded gabor features mrf model unsupervised;clustering algorithms;computer science;frequency;histograms gabor filters image segmentation frequency feature extraction clustering algorithms computer science application software computer applications biomedical imaging;kohnen s sofm	In this paper, we propose an unsupervised texture segmentation scheme in which Gabor transforms and GMRF model are integrated. The Gabor filters are used to extract low-level textural features. The Gabor feature vectors are mapped to an 1-D space using the Kohnen's SOFM algorithm, and then encoded by the feature map indices. The histogram of encoded features over a small window are used to determine the regions of homogeneous textures. From these regions, class-specific parameters for GMRF model are estimated and used to detect exact boundaries of different textures.		Gouchol Pok;Jyh-Charn Liu	1999		10.1109/ICIP.1999.817102	unsupervised learning;image texture;gabor transform;computer vision;application software;feature vector;feature extraction;computer science;machine learning;frequency;pattern recognition;histogram;image segmentation;cluster analysis;computer applications	Vision	39.824355165960384	-62.748848721011534	119396
5f6b7e86fea6ea9d488071501d4dc59244426b3e	indexing using a spectral encoding of topological structure	database indexing;eigenvalues and eigenfunctions;image features;object recognition;topological subspaces;occlusion;computer graphics;information retrieval;local evidence;vector space;index structure;topological structure;encoding object recognition computer vision database indexing;2d object recognition;indexing encoding tree graphs object recognition feature extraction computer vision computer graphics computational biology eigenvalues and eigenfunctions information retrieval;local deformation;eigenvalues;computer vision;tree graphs;indexing;feature extraction;indexation;spectral encoding;computational biology;encoding;2d object recognition indexing spectral encoding topological structure object recognition image features computer vision occlusion local deformation local evidence topological subspaces	In an object recognition system, if the extracted image features are multilevel or multiscale, the indexing structure may take the form of a tree. Such structures are not only common in computer vision, but also appear in linguistics, graphics, computational biology , and a wide range of other domains. In this paper , we develop an indexing mechanism that maps the topological structure of a tree into a low-dimensional vector space. Based on a novel eigenvalue characterization of a tree, this topological signature allows us to eeciently retrieve a small set of candidates from a database of models. To accommodate occlusion and local deformation, local evidence is accumulated in each of the tree's topological subspaces. We demonstrate the approach with a series of indexing experiments in the domain of 2-D object recognition.	computational biology;computer vision;experiment;graphics;outline of object recognition	Ali Shokoufandeh;Sven J. Dickinson;Kaleem Siddiqi;Steven W. Zucker	1999		10.1109/CVPR.1999.784726	database index;computer vision;search engine indexing;vector space;feature extraction;eigenvalues and eigenvectors;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;pattern recognition;mathematics;computer graphics;feature;tree;encoding	Vision	40.891142751039986	-59.332882024904485	119428
f393d1162b50ce9f60d843eada98f6fcee40e7c9	robust detection of degenerate configurations while estimating the fundamental matrix	motion analysis;modelizacion;image features;model selection;estimator robustness;matrice fondamentale;degeneracy;estimation mouvement;algorithm performance;image processing;degeneracion;geometrie algorithmique;etude experimentale;echantillonnage;estimacion movimiento;extraction forme;multiple solution;computational geometry;procesamiento imagen;fundamental matrix;motion estimation;image bruitee;traitement image;sampling;algorithme;modelisation;imagen sonora;epipolar geometry;algorithm;camera motion;robustez estimador;estimation erreur;degeneration;extraccion forma;error estimation;resultado algoritmo;noisy image;estimacion error;performance algorithme;estimacion parametro;geometria computacional;parameter estimation;estimation parametre;muestreo;modeling;estudio experimental;structure from motion;pattern extraction;degenerescence;robust methods;algoritmo;robustesse estimateur;mdl	We present a new method for the detection of multiple solutions or degeneracy when estimating thefundamental matrix, with specific emphasis on robustness to data contamination (mismatches). The fundamental matrix encapsulates all the information on camera motion and internal parameters available from image feature correspondences between two views. It is often used as a first step in structure from motion algorithms. If the set of correspondences is degenerate, then this structure cannot be accurately recovered and many solutions explain the data equally well. It is essential that we are alerted to such eventualities. As current feature matchers are very prone to mismatching the degeneracy detection method must also be robust to outliers.In this paper a definition of degeneracy is given and all two-view nondegenerate and degenerate cases are catalogued in a logical way by introducing the language of varieties from algebraic geometry. It is then shown how each of the cases can be robustly determined from image correspondences via a scoring function we develop. These ideas define a methodology which allows the simultaneous detection of degeneracy and outliers. The method is called PLUNDER-DL and is a generalization of the robust estimator RANSAC.The method is evaluated on many differing pairs of real images. In particular it is demonstrated that proper modeling of degeneracy in the presence of outliers enables the detection of mismatches which would otherwise be missed. All processing including point matching, degeneracy detection, and outlier detection is automatic.	fundamental matrix (computer vision)	Philip H. S. Torr;Andrew Zisserman;Stephen J. Maybank	1998	Computer Vision and Image Understanding	10.1006/cviu.1997.0559	sampling;computer vision;mathematical optimization;structure from motion;systems modeling;image processing;computational geometry;computer science;motion estimation;mathematics;geometry;fundamental matrix;estimation theory;feature;degeneracy;model selection;statistics;epipolar geometry	Vision	50.19313466511109	-57.12781044183087	119432
0701a3fc8824613db0d02e6489c27ff6c69c92a2	motion editing for time-varying mesh	signal image and speech processing;analisis imagen;time varying;analisis escena;analyse scene;hierarchized structure;exigence usager;time variation;exigencia usuario;database;base dato;structure hierarchisee;variation temporelle;qualite service;algorithme;algorithm;quantum information technology spintronics;video cameras;motion editing;user requirement;methode maille;mesh method;camera video;base de donnees;metodo malla;image analysis;analyse image;variacion temporal;estructura jerarquizada;service quality;scene analysis;calidad servicio;algoritmo	Recently, time-varying mesh (TVM), which is composed of a sequence of mesh models, has received considerable interest due to its new and attractive functions such as free viewpoint and interactivity. TVM captures the dynamic scene of the real world from multiple synchronized cameras. However, it is expensive and time consuming to generate a TVM sequence. In this paper, an editing system is presented to reuse the original data, which reorganizes the motions to obtain a new sequence based on the user requirements. Hierarchical motion structure is observed and parsed in TVM sequences. Then, the representative motions are chosen into a motion database, where a motion graph is constructed to connect those motions with smooth transitions. After the user selects some desired motions from the motion database, the best paths are searched by a modified Dijkstra algorithm to achieve a new sequence. Our experimental results demonstrate that the edited sequences are natural and smooth.	alpha compositing;dijkstra's algorithm;error detection and correction;graphical user interface;interactivity;parsing;requirement;smoothing;texton;time-varying mesh;user requirements document	Jianfeng Xu;Toshihiko Yamasaki;Kiyoharu Aizawa	2009	EURASIP J. Adv. Sig. Proc.	10.1155/2009/592812	computer vision;image analysis;simulation;telecommunications;computer science;user requirements document;service quality;algorithm;computer graphics (images)	Graphics	48.60140272036167	-55.68368435682423	119452
db8f9e35fee4db71ccb438cec1aa592ddca51278	the affine transforms for image enhancement in the context of logarithmic models		The logarithmic model offers new tools for image processing. An efficient method for image enhancement is to use an affine transformation with the logarithmic operations: addition and scalar multiplication. We define some criteria for automatically determining the parameters of the processing and this is done via mean and variance computed by logarithmic operations. keywords : logarithmic image processing, image enhancement, affine transforms.	image editing;image processing	Vasile Patrascu;Vasile Buzuloiu	2014	CoRR		combinatorics;discrete mathematics;mathematics	ML	51.64256475061574	-64.89333822787283	119556
d215a1577d84ea791aafdd5f0939b80c7042c85c	real-time motion segmentation from moving cameras	moving object;frames per second;optimisation;estimation mouvement;modelo markov;optimizacion;video signal processing;real time;estimacion movimiento;real time processing;motion estimation;segmentation;blanco movil;markov random field;tratamiento tiempo real;detection objet;camera motion;detection mouvement;motion segmentation;traitement temps reel;markov model;color segmentation;campo aleatorio;camera mobile;analyse performance;performance analysis;pattern recognition;traitement signal video;cible mobile;optimization;modele markov;optimal algorithm;content based retrieval;recherche par contenu;segmentacion;region merging;moving target;object detection;champ aleatoire;analisis eficacia;random field	This paper describes our approach to real-time detection of camera motion and moving object segmentation in videos acquired from moving cameras. As far as we know, none of the proposals reported in the literature are able to meet real-time requirements. In this work, we present an approach based on a color segmentation followed by a region-merging on motion through Markov Random Fields (MRFs). The technique we propose is inspired to a work of Gelgon and Bouthemy (Pattern Recognition 33 (2000) 725–40), that has been modified to reduce computational cost in order to achieve a fast segmentation (about 10 frame per second). To this aim a modified region matching algorithm (namely Partitioned Region Matching) and an innovative arc-based MRF optimization algorithm with a suitable definition of the motion reliability are proposed. Results on both synthetic and real sequences are reported to confirm validity of our solution. r 2004 Elsevier Ltd. All rights reserved.	algorithm;algorithmic efficiency;computation;image segmentation;markov chain;markov random field;mathematical optimization;pattern recognition;real-time clock;requirement;synthetic intelligence	Rita Cucchiara;Andrea Prati;Roberto Vezzani	2004	Real-Time Imaging	10.1016/j.rti.2004.03.002	computer vision;random field;real-time computing;simulation;computer science;motion estimation;markov model;scale-space segmentation;segmentation;frame rate;statistics	Vision	48.074848190401724	-56.815884483634825	120027
2994c262f2b41c4d87397fe346b47a1ec32f8871	a mathematical model for shape description using minkowski operators	operateur minkowski;mathematical morphology;vision ordenador;morfologia matematica;modele mathematique;image processing;procesamiento imagen;intelligence artificielle;modelo matematico;traitement image;computer vision;descripcion;mathematical model;artificial intelligence;vision ordinateur;inteligencia artificial;shape description;description;morphologie mathematique	Abstract   Using two new shape operators called Minkowski addition and decomposition operators, a simple shape model is presented. Mathematical characteristics of these operators are explored in some detail, with the aim of eventually arriving at a formal theory of shape description. A few application areas of the shape model, particularly some important uses of the shape operators are briefly mentioned.	mathematical model;minkowski addition	Pijush K. Ghosh	1988	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(88)90123-5	microlocal analysis;computer vision;mathematical morphology;image processing;computer science;artificial intelligence;mathematical model;mathematics;geometry;fourier integral operator	Vision	49.24515491811063	-63.2617574904877	120253
6f4952a76d6e9eab9a046a1cc7df09903c406c8d	fast weighted histograms for bilateral filtering and nearest neighbor searching	histograms;kernel;pattern classification filtering theory image colour analysis;joints;edge preserving smoothing locality sensitive histograms bilateral weighted histograms bilateral filtering nearest neighbor searching;image edge detection;computational complexity;image color analysis;image reconstruction;color information fast weighted histograms bilateral filtering nearest neighbor searching locality sensitive histogram lsh spatial information visual tracking edge preserving nearest neighbor fields nnf grayscale image processing box spatial filter kernels computational complexity bilateral weighted histogram bwh patch size;histograms kernel joints image edge detection computational complexity image color analysis image reconstruction	The locality sensitive histogram (LSH) injects spatial information into the local histogram in an efficient manner, and has been demonstrated to be very effective for visual tracking. In this paper, we explore the application of this efficient histogram in two important problems. We first extend the LSH to linear time bilateral filtering, and then propose a new type of histogram for efficiently computing edge-preserving nearest neighbor fields (NNFs). While the existing histogram-based bilateral filtering methods are the state of the art for efficient grayscale image processing, they are limited to box spatial filter kernels only. In our first application, we address this limitation by expressing the bilateral filter as a simple ratio of linear functions of the LSH, which is able to extend the box spatial kernel to an exponential kernel. The computational complexity of the proposed bilateral filter is linear in the number of image pixels. In our second application, we derive a new bilateral weighted histogram (BWH) for NNF. The new histogram maintains the efficiency of LSH, which allows approximate NNF to be computed independent of patch size. In addition, BWH takes both spatial and color information into account, and thus provides higher accuracy for histogram-based matching, especially around color edges.	approximation algorithm;bilateral filter;computational complexity theory;grayscale;image processing;image registration;kernel (operating system);linear function;locality of reference;locality-sensitive hashing;negation normal form;patchmatch;pixel;thinking outside the box;time complexity;video tracking;lsh	Shengfeng He;Qingxiong Yang;Rynson W. H. Lau;Ming-Hsuan Yang	2016	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2015.2430671	iterative reconstruction;color histogram;computer vision;kernel;histogram matching;machine learning;pattern recognition;histogram;mathematics;adaptive histogram equalization;computational complexity theory;histogram equalization;algorithm;statistics;image histogram	Vision	53.42616529889522	-64.15444663369912	120369
0b12243e6230084c1cdb5fd1612b2ccebc016d07	non-rigid visible and infrared face registration via regularized gaussian fields criterion	image fusion;gaussian fields;face recognition;registration;non rigid;infrared	Registration of multi-sensor data (particularly visible color sensors and infrared sensors) is a prerequisite for multimodal image analysis such as image fusion. Typically, the relationships between image pairs are modeled by rigid or affine transformations. However, this cannot produce accurate alignments when the scenes are not planar, for example, face images. In this paper, we propose a regularized Gaussian fields criterion for non-rigid registration of visible and infrared face images. The key idea is to represent an image by its edge map and align the edge maps by a robust criterion with a non-rigid model. We model the transformation between images in a reproducing kernel Hilbert space and a sparse approximation is applied to the transformation to avoid high computational complexity. Moreover, a coarse-to-fine strategy by applying deterministic annealing is used to overcome local convergence problems. The qualitative and quantitative comparisons on two publicly available databases demonstrate that our method significantly outperforms the state-of-the-art method with an affine model. As a result, our method will be beneficial for fusion-based face recognition. & 2014 Elsevier Ltd. All rights reserved.	align (company);computational complexity theory;database;digital image processing;eisenstein's criterion;facial recognition system;gaussian blur;hilbert space;image analysis;image fusion;local convergence;map;multimodal interaction;planar (computer graphics);sensor;simulated annealing;sparse approximation;sparse matrix	Jiayi Ma;Ji Zhao;Yong Ma;Jinwen Tian	2015	Pattern Recognition	10.1016/j.patcog.2014.09.005	facial recognition system;point set registration;computer vision;infrared;computer science;machine learning;pattern recognition;mathematics;image fusion	Vision	43.443311475342696	-53.60609421703289	120622
0a9a94e7dc9ceb2320767a7946b6389a46c01d56	asset-2: real-time motion segmentation and object tracking	moving object;image features;detection forme;tracking system;image processing;flux optique;real time;corps mobile;procesamiento imagen;movie camera;segmentation;shape detection;traitement image;tracking movable target;deteccion forma;motion segmentation;camara;first order;senal video;signal video;flujo optico;flow field;temps reel;cuerpo movil;object tracking;image sequence;video signal;tiempo real;asset 2;secuencia imagen;optical flow;poursuite;moving body;camera calibration;segmentacion;sequence image;persecucion y continuacion;camera	This paper describes how image sequences taken by a moving video camera may be processed to detect and track moving objects against a moving background in real-time. The motion segmentation and shape tracking system is known as a scene segmenter establishing tracking, version 2 (ASSET-2). Motion is found by tracking image features, and segmentation is based on first-order (i.e. six-parameter) flow fields. Shape tracking is performed using two-dimensional radial map representations. The system runs in real-time, and is accurate and reliable. It requires no camera calibration and no knowledge of the camera's motion.	real-time transcription	Stephen M. Smith	1998	Real-Time Imaging	10.1006/rtim.1996.0061	computer vision;camera auto-calibration;match moving;camera resectioning;tracking system;image processing;computer science;video tracking;first-order logic;optical flow;motion field;segmentation;feature;computer graphics (images)	Robotics	48.53024080563	-57.00078882835774	120781
5a2d63d2ec3f0c983e68f0d54b88de6a4fefa341	variance reduction techniques in particle-based visual contour tracking	filtre particule;rao blackwellized particle filter;methode globale locale;evaluation performance;performance evaluation;filtro kalman;estudio comparativo;evaluacion prestacion;filtre kalman;kalman filter;filtro particulas;unscented particle filter;etude comparative;rao blackwellization;sampling technique;variance reduction techniques;active shape models;particle filter;contour tracking;echantillonnage importance;poursuite cible;comparative study;partitioned sampling;global local method;target tracking;importance sampling;metodo global local;active shape model	This paper presents a comparative study of three different strategies to improve the performance of particle filters, in the context of visual contour tracking: the unscented particle filter, the Rao-Blackwellized particle filter, and the partitioned sampling technique. The tracking problem analyzed is the joint estimation of the global and local transformation of the outline of a given target, represented following the active shape model approach. The main contributions of the paper are the novel adaptations of the considered techniques on this generic problem, and the quantitative assessment of their performance in extensive experimental work done.	variance reduction	Daniel Ponsa;Antonio M. López	2009	Pattern Recognition	10.1016/j.patcog.2009.04.007	active shape model;kalman filter;sampling;econometrics;particle filter;importance sampling;computer science;comparative research;control theory;mathematics;statistics	Vision	52.277915405379225	-59.86886232142169	120836
59ccd8704fd6a6e9203000955658367289b0b757	feature matching for illumination variation images	enhancement;illumination variation;sensors;image matching;oxygen;shape analysis;overlapping area;期刊论文	Illumination variability is one of the most important issues affecting imagery matching performances and still remains a critical problem in the literature, although different levels of improvement have been reported in recent years. This study proposes an illumination robust image matching method. There are three steps in the proposed method: first, local regions are extracted and matched from the input images by using a multiresolution region detector and an illumination robust shape descriptor; second, an algorithm is proposed to estimate the overlapping areas of images and enhance them based on the region matches; finally, general feature detectors and descriptors are combined to process the previous results for illumination robust matching. Experimental results demonstrate that the proposed matching method provides significant improvement in robustness for illu- mination change images compared with traditional methods. © 2015 SPIE and IS&T (DOI: 10.1117/1.JEI.24.3.033011)		Zhenfeng Shao;Min Chen;Chong Liu	2015	J. Electronic Imaging	10.1117/1.JEI.24.3.033011	computer vision;computer science;sensor;machine learning;pattern recognition;shape analysis;oxygen	Vision	39.24633660100741	-56.47048464614499	120842
448879914009933373687b7d5e13398ec1fe934a	computing stochastic completion fields in linear-time using a resolution pyramid	analisis imagen;vision ordenador;image processing;time complexity;analisis forma;linear time algorithm;procesamiento imagen;traitement image;computer vision;algorithme;algorithm;complexite temps;linear time;diffusion equation;image analysis;vision ordinateur;pattern analysis;complejidad tiempo;analyse image;analyse forme;algoritmo	We describe a linear-time algorithm for computing the likelihood that a completion joining two contour fragments passes through any given position and orientation in the image plane. Our algorithm is a resolution-pyramid-based method for solving a partial differential equation (PDE) characterizing a distribution of short, smooth completion shapes. The PDE consists of a set of independent advection equations in (x, y) coupled in the θ dimension by the diffusion equation. A previously described algorithm used a first-order, explicit finite difference scheme implemented on a rectangular grid. This algorithm required O(n3m) time for a grid of size n× n with m discrete orientations. Unfortunately, systematic error in solving the advection equations produced unwanted anisotropic smoothing in the (x, y) dimension. This resulted in visible artifacts in the completion fields. The amount of error and its dependence on θ have been previously characterized. We observe that by careful addition of extra spatial smoothing, the error can be made totally isotropic. The combined effect of this error and of intrinsic smoothness due to diffusion in the θ dimension is that the solution becomes smoother with increasing time, i.e., the high spatial frequencies drop out. By increasing ∆x and ∆t on a regular schedule, and using a secondorder, implicit scheme for the diffusion term, it is possible to solve the modified PDE in O(n2m) time, i.e., time linear in the problem size. Using current hardware and for problems of typical size, this means that a solution which previously took 1 h to compute can now be computed in about 2 min. c © 1999 Academic Press	algorithm;analysis of algorithms;anisotropic diffusion;finite difference method;first-order logic;first-order predicate;image plane;intrinsic dimension;maxima and minima;regular grid;smoothing;time complexity	Lance R. Williams;Tairan Wang;Karvel K. Thornber	1997		10.1007/3-540-63460-6_137	time complexity;computer vision;image analysis;image processing;computer science;calculus;mathematics;geometry;algorithm	Theory	51.43318953757477	-59.6932815654515	120936
fd396ab59dfc28ab40529d98ee9570dbc7a8b669	the multiscale line segment detector		We propose a multiscale extension of a well-known line segment detector, LSD. We show that its multiscale nature makes it much less susceptible to over-segmentation and more robust to low contrast and less sensitive to noise, while keeping the parameter-less advantage of LSD and still being fast. We also present here a dense gradient filter that disregards regions in which lines are likely to be irrelevant. As it reduces line mismatches, this filter improves the robustness of the application to structure-from-motion. It also yields a faster detection.	computation;edge detection;gradient;human-readable medium;relevance;structure from motion	Yohann Salaün;Renaud Marlet;Pascal Monasse	2016		10.1007/978-3-319-56414-2_12	robustness (computer science);structure from motion;line segment;detector;computer vision;electronic engineering;artificial intelligence;computer science	Vision	49.1353181464086	-64.98184738089601	121152
2a3fb5ef9662238ff4be0b5b9893efebe2cd55a7	scale-based approach to hierarchical fuzzy clustering	hierarchical fuzzy clustering;hierarchical clustering;minimax strategy;traitement signal;cluster algorithm;sistema experto;critere stabilite;effet echelle;fuzzy set;management system;scale effect;image processing;logique floue;procesamiento imagen;logica difusa;criterio estabilidad;strategie minimax;traitement image;fuzzy logic;fuzzy clustering;hierarchical classification;senal video;signal video;signal processing;efecto escala;classification hierarchique;video signal;scene change detection;stability criterion;systeme gestion base donnee;systeme expert;video database;procesamiento senal;sistema gestion base datos;database management system;clasificacion jerarquizada;scale based approach;estrategia minimax;expert system;stability evaluation	"""Sensorial signals are processed by brain by relying on their signi""""cant aspects. Fuzzy and scale-based approaches try to imitate this mechanism. In the paper, a new clustering algorithm is proposed which makes use of both approaches. It is characterised by a hierarchical splitting process guided by the scale-based approach and based on the repetitive application of an improved version of the Min}Max fuzzy algorithm. In each iteration of the algorithm at least one cluster is split and a scale parameter is determined. The optimal partition is decided based on a stability criterion de""""ned as a function of the scale. Several tests illustrate the performance of the algorithm, also in the framework of video databases management systems. In fact, hierarchical clusters of video frames seem to be very appropriate for browsing a video sequence, especially if they are determined by a scale-based criterion simulating di!erent resolution levels of the human observation. Moreover, fuzzy sets play a fundamental role because of the resulting soft decision criteria in the critical task of the scene change detection. ( 2000 Elsevier Science B.V. All rights reserved."""	algorithm;cloud computing;cluster analysis;database;fuzzy clustering;fuzzy set;iteration;routh–hurwitz stability criterion;simulation	Fabio Massimo Frattale Mascioli;Antonello Rizzi;Massimo Panella;Giuseppe Martinelli	2000	Signal Processing	10.1016/S0165-1684(00)00016-5	fuzzy logic;fuzzy clustering;image processing;computer science;artificial intelligence;machine learning;signal processing;data mining;management system;mathematics;hierarchical clustering;fuzzy set;expert system	AI	45.72575192404341	-62.91156032952353	121182
2fe14852435b69e7889523184a2f604995597977	edge-based image restoration	traitement signal;interpolation;detection forme;restauration image;image processing;esqueleto;edge detection;interpolacion;image restoration image reconstruction mathematics computer science data mining skeleton interpolation filling cultural differences biomedical imaging;procesamiento imagen;edge structure reconstruction;image restoration;indexing terms;shape detection;traitement image;skeleton;deteccion contorno;algorithme;algorithm;detection contour;restauracion imagen;deteccion forma;inpainting;image restoration image inpainting algorithm edge information skeleton image structure reconstruction spatial order numerical interpretation pixel filling method t junctions;t junctions edge structure reconstruction image restoration inpainting sequentiality;feature extraction;image reconstruction;signal processing;sequentiality;squelette;image inpainting;extraction caracteristique;image thinning;procesamiento senal;t junctions;image restoration image thinning image reconstruction interpolation edge detection;algorithms artifacts artificial intelligence image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated;algoritmo	In this paper, we propose a new image inpainting algorithm that relies on explicit edge information. The edge information is used both for the reconstruction of a skeleton image structure in the missing areas, as well as for guiding the interpolation that follows. The structure reconstruction part exploits different properties of the edges, such as the colors of the objects they separate, an estimate of how well one edge continues into another one, and the spatial order of the edges with respect to each other. In order to preserve both sharp and smooth edges, the areas delimited by the recovered structure are interpolated independently, and the process is guided by the direction of the nearby edges. The novelty of our approach lies primarily in exploiting explicitly the constraint enforced by the numerical interpretation of the sequential order of edges, as well as in the pixel filling method which takes into account the proximity and direction of edges. Extensive experiments are carried out in order to validate and compare the algorithm both quantitatively and qualitatively. They show the advantages of our algorithm and its readily application to real world cases.	algorithm;circuit restoration;color;continuation;delimiter;electron hole;experiment;exploit (computer security);extraction;fill;frame (physical object);image restoration;information theory;inpainting;interpolation imputation technique;masks;missing data;morphologic artifacts;motion estimation;numerical analysis;obstruction;paste;performance;physical object;pixel;user-generated content;visual artifact;whittaker–shannon interpolation formula;biologic segmentation	Andrei Rares;Marcel J. T. Reinders;Jan Biemond	2005	IEEE Transactions on Image Processing	10.1109/TIP.2005.854466	computer vision;image processing;interpolation;computer science;signal processing;mathematics;geometry;computer graphics (images)	Vision	51.701430470961135	-59.341476272587464	121218
1ef29da518e6025292fe5ba41986184796e1df71	fast 3d medial axis transformation to reduce computation and complexity in radiosurgery treatment planning	treatment planning;medial axis transform;three dimensions;transform theory;medial axis	The medial axis analysis of an object can be used to effectively guide and optimize radiosurgery treatment planning. In this paper, a fast Euclidean medial axis transformation in three dimensions based on dynamic grassfire simulation and ridge extraction is presented. A ridge occurs when fire fronts collapse during grassfire propagation. Iso-contours (2D) or iso- surfaces (3D) can be obtained from dynamic grassfire transforms. They are locally smooth everywhere except at ridge locations. Ridges are detected by measuring local curvature at each point. This process is invariant under spatial translations and rotations. The algorithm yields the true Euclidean skeleton of the objects and is several orders of magnitude faster than other thinning methods. In radiosurgery treatment planning, optimal shots are only placed on the medial axis of the 3D target, which reduces optimization time and complexity. An example of a treatment planning process is presented and the relationship between skeleton disks and the dose distributions which they predict are discussed.© (1996) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	apache axis;computation;medial graph	Qingrong Jackie Wu;J. Daniel Bourland;Richard A. Robb	1996		10.1117/12.237959	computer vision;medial axis;mathematics;geometry;engineering drawing	Robotics	48.43787783365702	-62.70633953278341	121257
386dc0445ba9991e6f981ad407bc45f17900daf5	background removal in image indexing and retrieval	database indexing;image features;color clusters;image databases;content based indexing and retrieval;information retrieval;color features;image indexing;indexing and retrieval;feature extraction database indexing content based retrieval visual databases image colour analysis;fuzzy clustering;indexing;image color analysis;image colour analysis;feature extraction;image background analysis background removal image indexing image retrieval content based retrieval digital image libraries image features color features color clusters;spatial databases;image analysis;humans;image background analysis;digital image libraries;digital image;indexing image retrieval content based retrieval humans digital images image color analysis image analysis image databases spatial databases information retrieval;content based retrieval;digital images;background removal;color image segmentation;visual databases;image retrieval	This paper presents our research in image content based indexing and retrieval, a key technology in digital image libraries. In most of the existing image content-based techniques, image features used for indexing and retrieval are global, features are computed over the entire image. The major problem with the global image feature based retrieval methods is that background features can be easily mistakenly taken as object features. When a user attempts to retrieve images using color features, he/she usually means the color feature of an object or objects of interests contained in the image. The approach we describe in this paper utilizes color clusters for image background analysis. Once the background regions are identified, they are removed from the image indexing procedure; therefore, no longer interfering with the meaningful image content during the retrieval process. The algorithm consists of three major steps of computation, fuzzy clustering, color image segmentation, and background analysis.	algorithm;cluster analysis;color image;computation;digital image;feature (computer vision);fuzzy clustering;image segmentation;library (computing)	Yi Lu;Hong Guo	1999		10.1109/ICIAP.1999.797715	image warping;image texture;computer vision;feature detection;visual word;image analysis;binary image;image processing;image retrieval;computer science;digital image processing;multimedia;automatic image annotation;feature;information retrieval;digital image	Vision	39.33596457618882	-61.07202487287435	121270
39b0b65f0474da167babf747d3a4c050dcba80fa	automated recognition of sunspots on the soho/mdi white light solar images	edge detection;morphological operation;statistical properties;white light;weather condition	A new technique is presented for automatic identification of sunspots on the full disk solar images allowing robust detection of sunspots on images obtained from space and ground observations, which may be distorted by weather conditions and instrumental artefacts. The technique applies image cleaning procedures for elimination of limb darkening, intensity noise and noncircular image shape. Sobel edge-detection is applied to find sunspot candidates. Morphological operations are then used to filter out noise and define a local neighbourhood background via thresholding, with threshold levels defined as a function of the quiet sun intensity and local statistical properties. The technique was tested on one year (2002) of full disk SOHO/MDI white light (WL) images. The detection results are in very good agreement with the Meudon manual synoptic maps as well as with the Locarno Observatory Sunspot manual drawings. The detection results from WL observations are cross-referenced with the SOHO/MDI magnetogram data for verification purposes.	astrophysical virtual observatory;automatic identification and data capture;edge detection;hydrogen darkening;map;medium-dependent interface;multiple document interface;plasma cleaning;small office/home office;sobel operator;thresholding (image processing)	Sergei I. Zharkov;Valentina V. Zharkova;Stanley S. Ipson;Ali Benkhalil	2004		10.1007/978-3-540-30134-9_60	optics;physics;cartography;remote sensing	Vision	52.86997516602729	-55.98050804551496	121310
bc30d2a0b533a575a48c8f45f71fc9120fcc83a4	measuring rectilinearity	shape descriptor;object classification;perceptually meaningful result;aerial photograph;shape measure;polygon;canonical orientation;shape retrieval;rectilinear;human subject;new method;curve simplification;image segmentation	Two new methods for computing the rectilinearity of polygons are presented. They provide shape measures and estimates of canonical orientations which can be used in applications such as shape retrieval, object classification, image segmentation, etc. Examples are presented demonstrating their use in skew correction of scanned documents, deprojection of aerial photographs of buildings, and scale selection for curve simplification. Furthermore, testing has been carried out on synthetic data and with human subjects to verify that the measures do indeed produce perceptually meaningful results.	aerial photography;algorithm;computer performance;image segmentation;perimeter;quantization (physics);synthetic data;text simplification;utility	Paul L. Rosin;Jovisa D. Zunic	2005	Computer Vision and Image Understanding	10.1016/j.cviu.2005.01.003	computer vision;pattern recognition;mathematics	Vision	52.50863624134837	-57.12198270129724	121451
b51ebf46cf2ff1d054917cb37816c983072c35d5	detection of partially visible objects		An ‘elephant in the room’ for most current object detection and localization methods is the lack of explicit modelling of partial visibility due to occlusion by other objects or truncation by the image boundary. Based on a sliding window approach, we propose a detection method which explicitly models partial visibility by treating it as a latent variable. A novel non-maximum suppression scheme is proposed which takes into account the inferred partial visibility of objects while providing a globally optimal solution. The method gives more detailed scene interpretations than conventional detectors in that we are able to identify the visible parts of an object. We report improved average precision on the PASCAL VOC 2010 dataset compared to a baseline detector.	baseline (configuration management);information retrieval;latent variable;maxima and minima;no man's sky;object detection;part-based models;sensor;truncation;window function;zero suppression	Patrick Ott;Mark Everingham;Jiri Matas	2013	CoRR		computer vision;simulation;mathematics	Vision	51.208843699999335	-54.55071996130404	121484
9e26da7003a1c59df42a688c1065ea680f92234c	non-additive approach for omnidirectional image gradient estimation	optimisation;omnidirectional vision;omnidirectional image gradient estimation;image segmentation;radial distortion;catadioptric images;maximization;edge detection;omnidirectional image;image edge detection mirrors kernel interpolation geometry image resolution image processing pixel robot vision systems cameras;nonadditive kernels;computer vision;optimisation computer vision edge detection gradient methods image segmentation;gradient estimate;gradient methods;omnidirectional vision omnidirectional image gradient estimation catadioptric images edge detection radial resolution changes nonadditive kernels thresholding step maximization;radial resolution changes;thresholding step	The way catadioptric images are acquired implies that they present radial distortions. Therefore, classical processing may not be suitable. This statement will be illustrated by considering edge detection matter. Classical edge detectors usually consist in three steps : gradient computation, maximization and thresholding. The two lasts steps use pixels neighborhood concept. On the opposite of perspective images where pixel neighborhood is intuitive, catadioptric images present radial resolution changes. Then, the size and shape of pixel neighborhood have to be depending on pixel location. This article presents a new gradient estimation approach based on non-additive kernels. This technique is adapted to catadioptric images and also provides a natural threshold discarding the arbitrary thresholding step.	computation;distortion;edge detection;expectation–maximization algorithm;image gradient;pixel;radial (radio);sensor;thresholding (image processing);utility functions on indivisible goods	Florence Jacquey;Frédéric Comby;Olivier Strauss	2007	2007 IEEE 11th International Conference on Computer Vision	10.1109/ICCV.2007.4409193	distortion;computer vision;mathematical optimization;edge detection;computer science;morphological gradient;mathematics;image segmentation;pixel connectivity	Vision	53.029056137698106	-64.79996265026895	121620
a8ca61e73684af4c1f9a4d7af3b469828de37af3	3d facial image recognition using a nose volume and curvature based eigenface	reconnaissance visage;image tridimensionnelle;image recognition;reconocimiento imagen;vision ordenador;analisis componente principal;arquitectura red;fuzzy neural network;fuzzy neural nets;control difusa;image processing;3d imaging;facies;etude experimentale;fuzzy control;procesamiento imagen;base connaissance;reseau neuronal flou;courbure;architecture reseau;traitement image;computer vision;qa75 electronic computers computer science;face recognition;principal component analysis;reconnaissance image;analyse composante principale;pattern recognition;curvatura;tridimensional image;base conocimiento;curvature;vision ordinateur;network architecture;reconnaissance forme;reseau neuronal;reconocimiento patron;estudio experimental;red neuronal;imagen tridimensional;commande floue;neural network;knowledge base	The depth information in the face represents personal features in detail. In this study, the important personal facial information was presented by the surface curvatures and the features of vertical and horizontal of nose volume extracted from the face. The approach works by the depth of nose, the area of nose and the volume of nose based both on a vertical and horizontal are calculated. And the principal components analysis (PCA), which is calculated using the curvature data, was presented different features for each person. To classify the faces, the cascade architectures of fuzzy neural networks (CAFNNs), which can guarantee a high recognition rate as well as parsimonious knowledge base, are considered. In the experimental results, 3D images demonstrate the effectiveness of the proposed methods.	computer vision;eigenface	Yeung-hak Lee;Ik-Dong Kim;Jae-Chang Shim;David Marshall	2006		10.1007/11802914_48	stereoscopy;computer vision;network architecture;facies;image processing;computer science;artificial intelligence;curvature;artificial neural network;principal component analysis	Vision	44.413317645040514	-59.31634600581519	121729
f1c342a5f2960723513c4552d9be9a8ea5922cdd	a novel approach for computing partial similarity between 3d models	modelizacion;early experience;algorithme k moyenne;logique floue;polygone;database;base dato;logica difusa;classification;effet dimensionnel;similitude;fuzzy logic;polygon;modelisation;similarity transformation;3d model;computational complexity;size effect;decouverte connaissance;similarity;base de donnees;poligono;descubrimiento conocimiento;algoritmo k media;k means algorithm;similitud;efecto dimensional;modeling;clasificacion;knowledge discovery	In this paper, we present our initial solution to partial similarity computation between arbitrary 3D polygon models. The task is considered as the estimation of similarity transformations between the query pattern and target object. Two steps accounting for the scaling and rotation/translation parts are carried out, facilitated by applying EMD (earth mover's distance) to search the correspondence between focused point sets. In order to reduce the computation complexity involved in the second step, we use K-means algorithm to cluster the vertices of each model. We report our early experiments testing the efficiency of the proposed method on a small database as well as detailed discussions and the outline for the future work.	3d modeling	Wei Chen	2006		10.1007/11881599_51	computer science;artificial intelligence;polygon;mathematics;knowledge extraction;algorithm	HPC	43.62563477686845	-60.812376437431155	121949
5954860ac0f4a34ccb4e462fc7335119216aab47	a class of algorithms for fast digital image registration	sequential similarity detection algorithms;spatial registration of digital images;image processing;cross correlation;probability density function;spatial registration of digital images registration efficiency sequential similarity detection algorithms spatial cross correlation;data mining;manganese;correlation noise manganese data mining algorithm design and analysis probability density function image processing;image registration;detection algorithm;pattern recognition;digital image;correlation;spatial cross correlation;algorithm design and analysis;noise;structured data;registration efficiency	The automatic determination of local similarity between two structured data sets is fundamental to the disciplines of pattern recognition and image processing. A class of algorithms, which may be used to determine similarity in a far more efficient manner than methods currently in use, is introduced in this paper. There may be a saving of computation time of two orders of magnitude or more by adopting this new approach. The problem of translational image registration, used for an example throughout, is discussed and the problems with the most widely used method-correlation explained. Simple implementations of the new algorithms are introduced to motivate the basic idea of their structure. Real data from ITOS-1 satellites are presented to give meaningful empirical justification for theoretical predictions.	algorithm;computation;digital image;image processing;image registration;pattern recognition;time complexity	Daniel I. Barnea;Harvey F. Silverman	1972	IEEE Transactions on Computers	10.1109/TC.1972.5008923	computer vision;probability density function;image processing;computer science;noise;image registration;manganese;pattern recognition;data mining;correlation;digital image;statistics	Vision	43.149470439719956	-57.62468093328777	122022
9a3dfbb8b061f6c29d13b2875ecbadba54b1a5a8	a novel stability quantification of detected interest points in scale-space	databases;feature extraction edge detection;interest point detection;edge detection;interest points;stability quantification;scale space representation;noise effect;noise measurement;scale space;noise level;feature extraction;stability analysis;local invariant feature;robustness;noise effect stability quantification scale space representation local invariant feature interest point detection;robust stability noise robustness detectors computer vision feature extraction stability criteria noise measurement laboratories stability analysis numerical stability;invariant feature;noise	In local invariant features, the detected interest points using scale-space representations are considered the most robust to many variations in the imaging conditions. The existing approaches extract interest points at scale-space differential singularities. In these approaches, all detected interest points are considered equally robust without taking in consideration the variable sensitivities of these interest points with respect to noise effects. In this paper, we analyze the robustness of detected interest points at scale-space singularities against noise effects. Also, we propose a novel quantitative stability measure of these interest points. The evaluation results show the effectiveness of the proposed stability measure in estimating the robustness of the detected interest points to noise effects.	interest point detection;scale space	Alaa E. Abdel-Hakim;Aly A. Farag	2008	2008 19th International Conference on Pattern Recognition	10.1109/ICPR.2008.4760978	computer vision;mathematical optimization;von neumann stability analysis;scale space;edge detection;feature extraction;computer science;noise measurement;noise;mathematics;interest point detection;statistics;robustness	Vision	49.99425285714853	-65.25030053543371	122232
11e91d98e814f26d5b9c40dee8749ae6be407d8f	a threshold algorithm based on the local information	histograms;image segmentation;engineering drawings;engineering computing;manufacturing automation;thresholding algorithm;pixel engineering drawings histograms image analysis image segmentation manufacturing automation robotics and automation eyes frequency conversion production facilities;engineering drawing processing;eyes;drawing vectorization;engineering drawing processing drawing vectorization multiple gray level images thresholding algorithm local information;pixel;production facilities;document image processing;image analysis;engineering computing document image processing;robotics and automation;frequency conversion;local information;multiple gray level images	A novel method of threshold selecting is proposed. I t i s based on the local information of the image in the engineering drawing processing and vectorization system. The method is effective for images of multiple gray levels, especially the engineering drawing image. The properties of the algorithm ? experimentally verified on computer, are discussed. 1: Analysis In order to find a simple, quick and valid way of selecting threshold for an engineering drawing image, we have found the following facts : (1) in an image. (2) The pixels’ gray levels of most thin lines in the engineering drawing are high (bright to one’s eyes) and always very near the background pixels’. ( 3 ) Most of line drawings have a small pixel’s proportion in the image and have a limited line width. The background pixels have a large proportion According to the analysis above about the engineering drawing image, we can find that the crux of segmenting the line and background is to segment the thin line drawing from the whole image. A local area including the line drawing and the background pixels could be chosen to reduce the sample data of the image which are used to form the histogram. We can get several histogram models of the ideal Pixel’s frequency Gray level (P G ) distributing curve in the local image. 2: Algirithm The algorithm is divided into two parts as preprocessing and postprocessing. In the preprocessing, a local area of image should be defined first, and the line drawing should be included. Form the histogram with the data in the local image. Match the P-G curve with the ideal one and select the gray level corresponding to the valley which is nearer to the background in the curve as the threshold. Operate on the whole frame image as following: Change the current pixel’s gray level into the background’s (255) if this pixel’s gray level is greater than the threshold; If the level is less than the threshold, no change. In the postprocessing, a local area of the image with the line drawing should be chosen first. Form the histogram with the data except the background pixels’ in the local image. Match the P G curve with the ideal one and select the gray level corresponding to the valley in the curve as the threshold. This threshold is just what we need and it is a satisfactory one proved by experiments. 1050-4729l93 $3.00	automatic vectorization;engineering drawing;experiment;grayscale;line drawing algorithm;pixel;preprocessor	Minglun Fang;Limin Li;Tao Yu	1993		10.1109/ROBOT.1993.291815	computer vision;image analysis;computer science;histogram;image segmentation;engineering drawing;pixel;computer graphics (images)	Vision	44.83181344808231	-65.98944238847547	122250
ee68c312fa94d40c3fa76af91b8e2e78a0540206	robust computation of optical flow under non-uniform illumination variations	minimisation;motion analysis;image motion analysis;nonuniform illumination variations;pixel to pixel variation minimization;data constraint energy;optical computing robustness image motion analysis lighting image sequences brightness equations minimization methods geometrical optics motion analysis;optical computing;dynamic weighting scheme;minimization methods;robust optical flow computation;linear system;energy function;statistical properties;brightness;estimated optical flow;statistical analysis;energy function minimization;statistical analysis image sequences minimisation conjugate gradient methods;image sequence;robustness;optical flow;energy minimization;lighting;incomplete cholesky preconditioned conjugate gradient algorithm;image sequences robust optical flow computation nonuniform illumination variations image sequence data constraint energy smoothness constraint pixel to pixel variation minimization energy function minimization linear system incomplete cholesky preconditioned conjugate gradient algorithm dynamic weighting scheme statistical properties estimated optical flow robustness;conjugate gradient methods;preconditioned conjugate gradient;smoothness constraint;geometrical optics;image sequences	In this paper, an energy minimization method is proposed to estimate the optical flow of an image sequence in the presence of non-uniform illumination variations. The energy function is formulated by combining a data constraint energy that considers the illumination variations and a smoothness constraint, which minimizes the pixel-to-pixel variation of the velocity and illumination fields. Minimization of this energy function is equivalent to solving a linear system, which is accomplished by using an incomplete Cholesky preconditioned conjugate gradient algorithm. A dynamic weighting scheme, which considers the statistical properties of estimated optical flow, is also combined with this algorithm to improve the robustness of our algorithm. This algorithm has been successfully applied to synthetic and real image sequences and some experimental results demonstrate that this algorithm can estimate the optical flow under non-uniform illumination variations accurately.	computation;optical flow	Chin-Hung Teng;Shang-Hong Lai;Yung-Sheng Chen;Wen-Hsing Hsu	2002		10.1109/ICPR.2002.1044707	geometrical optics;minimisation;mathematical optimization;computer science;theoretical computer science;optical flow;lighting;mathematics;geometry;linear system;optical computing;energy minimization;brightness;robustness	Theory	53.09206343161248	-52.729951276948405	122834
a67dee08d90e7733060d25ed111402ea8c8e725b	image analysis by tchebichef moments	analisis imagen;fonction orthogonale;funcion discreta;coordinate space transformation tchebichef moments 2d image analysis orthogonal moment functions discrete tchebichef polynomials pattern features two dimensional images orthogonal basis set discrete domain image coordinate space orthogonal moments legendre moments zernike moments information redundancy feature representation image reconstruction;polinomio tchebychev;representation image;method of image;polynomials;polynome tchebychev;discrete function;fonction discrete;image representation;feature extraction;image reconstruction;zernike moment;transforms;transforms image reconstruction polynomials feature extraction image representation;orthogonal function;image analysis;numerical approximation;tchebychev polynomial;image analysis polynomials kernel image edge detection dynamic range shape integral equations pattern analysis information analysis image reconstruction;funcion ortogonal;analyse image;qa75 5 76 95 electronic computers computer science	This paper introduces a new set of orthogonal moment functions based on the discrete Tchebichef polynomials. The Tchebichef moments can be effectively used as pattern features in the analysis of two-dimensional images. The implementation of moments proposed in this paper does not involve any numerical approximation, since the basis set is orthogonal in the discrete domain of the image coordinate space. This property makes Tchebichef moments superior to the conventional orthogonal moments such as Legendre moments and Zernike moments, in terms of preserving the analytical properties needed to ensure information redundancy in a moment set. The paper also details the various computational aspects of Tchebichef moments and demonstrates their feature representation capability using the method of image reconstruction.	approximation;basis set (chemistry);discrete chebyshev polynomials;image analysis;iterative reconstruction;numerical analysis;polynomial;redundancy (information theory)	Ramakrishnan Mukundan;Sim Heng Ong;Poh Aun Lee	2001	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.941859	iterative reconstruction;velocity moments;computer vision;combinatorics;discrete mathematics;image analysis;feature extraction;computer science;orthogonal functions;mathematics;geometry;polynomial	Visualization	50.385774096831504	-62.44882844563656	123508
b2d15fdf04a85d761e7d04d02c13943fb6d4f5c3	the complex representation of algebraic curves and its simple exploitation for pose estimation and invariant recognition	database indexing;image recognition;visual databases computer vision image recognition polynomials database indexing;shape based indexing complex representation pose estimation invariant recognition 2d algebraic curves implicit polynomial curves pose independent shape recognition euclidean transformations rotation estimation polynomial coefficient space orthogonal subspaces two dimensional subspaces;curve centers;implicit polynomial curves;complex polynomials;shape recognition;polynomials;pose independent curve recognition;computer vision;euclidean invariants;polynomials shape computer vision application software extraterrestrial measurements databases noise shaping geometry rotation measurement indexing;shape representation;complete sets of rotation invariants;algebraic curves;algebraic curve;pose estimation;visual databases	New representations are introduced for handling 2D algebraic curves (implicit polynomial curves) of arbitrary degree in the scope of computer vision applications. These representations permit fast accurate pose-independent shape recognition under Eu-clidean transformations with a complete set of invariants, and fast accurate pose-estimation based on all the polynomial coeecients. The latter is accomplished by a new centering of a polynomial based on its coeecients, followed by rotation estimation by decomposing polynomial coeecient space into a union of orthogonal subspaces for which rotations within two dimensional subspaces or identity transformations within one dimensional subspaces result from rotations in x; y measured-data space. Angles of these rotations in the two dimensional coeecient subspaces are proportional to each other and are integer multiples of the rotation angle in the x; y data space. By recasting this approach in terms of a complex variable, i.e, x + iy = z and complex polynomial-coeecients, further conceptual and computational simpliication results. Application to shape-based indexing into databases is presented to illustrate the usefulness and the 1 robustness of the complex representation of algebraic curves.	3d pose estimation;computer vision;cross-validation (statistics);database;dataspaces;linear algebra;polynomial	Jean-Philippe Tarel;David B. Cooper	2000	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.865183	computer vision;discrete mathematics;topology;computer science;mathematics;geometry;algebraic curve	Vision	41.76459557662707	-59.394987026321374	123705
1c03f1da235291d75471db6c9597f46f39acd6da	face and palmprint pixel level fusion and kernel dcv-rbf classifier for small sample biometric recognition	evaluation performance;multi modal biometric;base donnee;metodo vectorial;procesamiento informacion;performance evaluation;image processing;methode noyau;gabor transform;biometrie;evaluacion prestacion;small sample biometric recognition;fonction base radiale;biometrics;database;biometria;procesamiento imagen;base dato;gabor transformation;data fusion;small samples;traitement image;journal;radial base function rbf network;discriminant analysis;analyse discriminante;analisis discriminante;automatic recognition;real world application;radial basis function;fusion donnee;pixel level fusion;vector method;metodo nucleo;information processing;signal classification;kernel discriminative common vectors kdcv;analyse correlation;radial base function;pattern recognition;transformation gabor;classification signal;kernel method;methode vectorielle;face and palmprint;reconnaissance forme;classification automatique;reconocimiento patron;traitement information;fusion datos;automatic classification;funcion radial base;clasificacion automatica;rbf network;transformacion gabor;analisis correlacion;reconocimiento automatico;kdcv rbf classifier;reconnaissance automatique;correlation analysis	Recently, multi-modal biometric fusion techniques have attracted increasing atove the recognition performance in some difficult biometric problems. The small sample biometric recognition problem is such a research difficulty in real-world applications. So far, most research work on fusion techniques has been done at the highest fusion level, i.e. the decision level. In this paper, we propose a novel fusion approach at the lowest level, i.e. the image pixel level. We first combine two kinds of biometrics: the face feature, which is a representative of contactless biometric, and the palmprint feature, which is a typical contacting biometric. We perform the Gabor transform on face and palmprint images and combine them at the pixel level. The correlation analysis shows that there is very small correlation between their normalized Gabor-transformed images. This paper also presents a novel classifier, KDCV-RBF, to classify the fused biometric images. It extracts the image discriminative features using a Kernel discriminative common vectors (KDCV) approach and classifies the features by using the radial base function (RBF) network. As the test data, we take two largest public face databases (AR and FERET) and a large palmprint database. The experimental results demonstrate that the proposed biometric fusion recognition approach is a rather effective solution for the small sample recognition problem.	biometrics;fingerprint;kernel (operating system);pixel;radial basis function network	Xiao-Yuan Jing;Yong-Fang Yao;David Zhang;Jingyu Yang;Miao Li	2007	Pattern Recognition	10.1016/j.patcog.2007.01.034	gabor transform;computer vision;kernel method;radial basis function;speech recognition;information processing;image processing;computer science;machine learning;pattern recognition;sensor fusion;biometrics;signature recognition	Vision	44.508098880374725	-60.19583735375266	123708
de462b378edfb541ae17ce24ed6fed18d79e9411	view synthesis under perspective projection	linear combination;modelo 3 dimensiones;perspective projection;modele 3 dimensions;three dimensional shape;three dimensional model;3d objection;forma tridimensional;experimental result;sintesis imagen;image synthesis;reconstruction image;human face;view synthesis;forme tridimensionnelle;reconstruccion imagen;combinacion lineal;image reconstruction;resultado experimental;projection perspective;synthese image;face;frontal;facial image;resultat experimental;visage humain;proyeccion perspectiva;image faciale;combinaison lineaire;frontal view face image construction;cara	This paper addresses the issue of generating a 2D view of a 3D object from its other 2D views. Linear Combination method is the typical approach to this problem. However, a 2D view cannot be represented by a linear combination of other 2D views under perspective projection. Instead, we have presented a solution under perspective projection. The proposed method also applies to the construction of virtual frontal view face image and the results are encouraging.	oblique projection;view synthesis	Guo-Can Feng;Jianhuang Lai;Pong C. Yuen	2000	IJPRAI	10.1142/S0218001400000428	iterative reconstruction;face;computer vision;oblique projection;perspective;linear combination;mathematics;geometry;projection	Vision	50.44785069064208	-57.038655161304284	123947
b70633ca237395130552dfef32b99e888efab009	forensic classification of imaging sensor types	image numerique;metodo vectorial;aspect medicolegal;authentication;maquina vector soporte;digital camera;prior knowledge;digital imaging;authentification;feature vector;digital cameras;accuracy;machine vecteur support;scanners;image generation;autenticacion;precision;vector method;imaging;signal classification;imagen numerica;classification signal;formation image;methode vectorielle;optical sensors;formacion imagen;digital image;support vector machine;classification automatique;aspecto forense;classification accuracy;automatic classification;clasificacion automatica;image sensor;cameras;forensic aspect	Digital images can be captured or generated by a variety of sources including digital cameras and scanners. In many cases it is important to be able to determine the source of a digital image. Methods exist to authenticate images generated by digital cameras or scanners, however they rely on prior knowledge of the image source (camera or scanner). This paper presents methods for determining the class of the image source (camera or scanner). The method is based on using the differences in pattern noise correlations that exist between digital cameras and scanners. To improve the classification accuracy a feature vector based approach using an SVM classifier is used to classify the pattern noise.	authentication;digital camera;digital image;elegant degradation;feature vector;image noise;image scanner;image sensor;normalization (image processing);resampling (statistics);sampling (signal processing)	Nitin Khanna;Aravind K. Mikkilineni;George T.-C. Chiu;Jan P. Allebach;Edward J. Delp	2007		10.1117/12.705849	medical imaging;computer vision;digital image processing;image sensor;authentication;digital imaging;accuracy and precision;digital image;computer graphics (images)	Vision	45.31354593405093	-61.26125696008605	124051
275b002d108bda5f5d61fd9afe0b232579ddc4f1	active/space-variant object recognition	objet;image recognition;object recognition;reconocimiento imagen;vision ordenador;base donnee;space variant sensing;database;base dato;object;contextual information;computer vision;face recognition;reconnaissance image;acquisition;pattern recognition;vision ordinateur;selective attention;reconnaissance forme;reconocimiento patron;objeto;adquisicion;active vision	The problem of object recognition is addressed. In the literature this task has been generally considered in a passive perspective, where everything is static and there is no definite relation between the object and its environment. In this paper, several aspects related to the application of active vision techniques to object recognition are discussed. The capability of the observer to move is very important to give a better description of the object during acquisition of the model database, and also for recognition. The recognition task can be simplified considerably by defining classes of expected objects based on contextual information. Moreover, a selective attentional mechanism allows us to reduce the amount of information needed to describe a database of objects. This is accomplished both at the task level, by performing planned fixations, and at the sensor level, by adopting a space-variant sampling of the image. The face recognition problem based on the face-space approach is considered to demonstrate the advantage of adopting an active retina in recognition tasks. By using an active space-variant retina, the size of the database is considerably reduced and, consequently, so too is the processing time for recognition.	outline of object recognition;variant object	Massimo Tistarelli	1995	Image Vision Comput.	10.1016/0262-8856(95)90841-U	facial recognition system;computer vision;active vision;attention;form perception;computer science;artificial intelligence;object;cognitive neuroscience of visual object recognition;3d single-object recognition	Vision	46.84680046419028	-58.563060388959016	124258
54dcfd42e6531100d9a6d4056dbcc71faa8e9f48	boundary element deformable object tracking with equilibrium constraints	minimisation;boundary element method;boundary element;image matching;grippers bem boundary element method deformable object tracking equilibrium constraints fem finite element method computer vision problems deformable template matching energy minimization bem tracking algorithm static equilibrium robustness linear elastic properties nonlinear elastic properties cell deformation;finite element method;satisfiability;computer vision;deformable objects;deformable models boundary element methods robustness integral equations robot vision systems intelligent robots elasticity stress poisson equations mechanical engineering;robot vision;deformation;linear elasticity;grippers;finite element analysis;energy minimization;deformable template;robot vision boundary elements methods finite element analysis object detection deformation minimisation grippers image matching tracking;boundary elements methods;equilibrium constraint;tracking;object detection	This paper presents a deformable object tracking algorithm based on the boundary element method (BEM). BEM differs from the finite element method (FEM) in that only the boundary of the object needs to be meshed for BEM. FEM requires that the interior of the object is meshed in addition to its boundary. This feature of BEM makes it attractive for computer vision problems. We present a deformable template that uses BEM to model deformations. This deformable template is registered to an image using an energy minimization approach. The BEM tracking algorithm presented in this paper constraints the tracking results to satisfy the condition of static equilibrium. This increases the robustness of the tracking results and enhances the usefulness of the forces obtained from the tracking procedure. We demonstrate the tracking performance of this algorithm for objects with linear and non-linear elastic properties. In addition, the results of tracking the deformations of a cell are presented.	algorithm;boundary element method;computer vision;energy minimization;finite element method;integral theory (ken wilber);nonlinear system;numerical stability;traction teampage	Michael A. Greminger;Yu Sun;Bradley J. Nelson	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308875	control engineering;computer vision;mathematical optimization;boundary element method;finite element method;mathematics;geometry;statistics	Robotics	50.146897920918974	-52.66931186149431	124296
a1b6aed0b998f0e6e049fcc209287c8b2801d054	an expression deformation approach to non-rigid 3d face recognition	reconnaissance visage;mimica;image tridimensionnelle;3d face recognition;analisis componente principal;image processing;facies;mimique;procesamiento imagen;disparity;invarianza;metric;traitement image;disparidad;similitude;invariance;automatic recognition;face recognition;principal component analysis;similarity;analyse composante principale;pattern recognition;non rigid matching;tridimensional image;metrico;reconnaissance forme;similitud;facial expression;reconocimiento patron;similarity measure;disparite;metrique;imagen tridimensional;expression invariance;reconocimiento automatico;eigenvectors;reconnaissance automatique	The accuracy of non-rigid 3D face recognition approaches is highly influenced by their capacity to differentiate between the deformations caused by facial expressions from the distinctive geometric attributes that uniquely characterize a 3D face, interpersonal disparities. We present an automatic 3D face recognition approach which can accurately differentiate between expression deformations and interpersonal disparities and hence recognize faces under any facial expression. The patterns of expression deformations are first learnt from training data in PCA eigenvectors. These patterns are then used to morph out the expression deformations. Similarity measures are extracted by matching the morphed 3D faces. PCA is performed in such a way it models only the facial expressions leaving out the interpersonal disparities. The approach was applied on the FRGC v2.0 dataset and superior recognition performance was achieved. The verification rates at 0.001 FAR were 98.35% and 97.73% for scans under neutral and non-neutral expressions, respectively.	data acquisition;experiment;facial recognition system;morphing;parsing expression grammar;software deployment;three-dimensional face recognition	Faisal R. Al-Osaimi;Mohammed Bennamoun;Ajmal S. Mian	2008	International Journal of Computer Vision	10.1007/s11263-008-0174-0	computer vision;similarity;facies;metric;image processing;eigenvalues and eigenvectors;computer science;artificial intelligence;similitude;invariant;mathematics;facial expression;principal component analysis	Vision	45.398575265504185	-59.254351131804114	124302
65d7c27dcdcafabfafeb542eb2b68865a49a35db	the infection algorithm: an artificial epidemic approach for dense stereo correspondence	artificial epidemics;image matching;computer vision;epipolar geometry;infection algorithm image matching epipolar geometry stereo vision artificial epidemics;view synthesis;stereo vision;3d scene reconstruction;infection algorithm	We present a new bio-inspired approach applied to a problem of stereo image matching. This approach is based on an artificial epidemic process, which we call the infection algorithm. The problem at hand is a basic one in computer vision for 3D scene reconstruction. It has many complex aspects and is known as an extremely difficult one. The aim is to match the contents of two images in order to obtain 3D information that allows the generation of simulated projections from a viewpoint that is different from the ones of the initial photographs. This process is known as view synthesis. The algorithm we propose exploits the image contents in order to produce only the necessary 3D depth information, while saving computational time. It is based on a set of distributed rules, which propagate like an artificial epidemic over the images. Experiments on a pair of real images are presented, and realistic reprojected images have been generated.	british informatics olympiad;computer vision;experiment;image registration;infection;inspiration function;projections and predictions;published comment;rule (guideline);time complexity;view synthesis;algorithm;contents - htmllinktype;photograph	Gustavo Olague;Francisco Fernández;Cynthia B. Pérez;Evelyne Lutton	2006	Artificial Life	10.1162/artl.2006.12.4.593	computer stereo vision;stereo cameras;computer vision;simulation;computer science;stereopsis;machine learning;fundamental matrix;epipolar geometry	Vision	51.78838943738536	-52.579003849680134	124435
319bad64f7c8f9339203311aa741cfb415d0552d	silhouette extraction with random pattern backgrounds for the volume intersection method	object colors;volume intersection method;shape image reconstruction cameras laser theory laser modes informatics production calibration stereo vision surface reconstruction;image colour analysis;feature extraction;image reconstruction;shape reconstruction;random pattern backgrounds;image reconstruction feature extraction image colour analysis;object colors silhouette extraction random pattern backgrounds volume intersection method shape reconstruction;silhouette extraction	In this paper, we present a novel approach for extracting silhouettes by using a particular pattern that we call the random pattern. The volume intersection method reconstructs the shapes of 3D objects from their silhouettes obtained with multiple cameras. With the method, if some parts of the silhouettes are missed, the corresponding parts of the reconstructed shapes are also missed. When colors of the objects and the backgrounds are similar, many parts of the silhouettes are missed. We adopt random pattern backgrounds to extract correct silhouettes. The random pattern has many small regions with randomly-selected colors. By using the random pattern backgrounds, we can keep the rate of missing parts below a specified percentage, even for objects of unknown color. To refine the silhouettes, we detect and fill in the missing parts by integrating multiple images. From the images captured by multiple cameras used to observe the object, the object's colors can be estimated. The missing parts can be detected by comparing the object's color with its corresponding background's color. In our experiments, we confirmed that this method effectively extracts silhouettes and reconstructs 3D shapes.	color;experiment;randomness	Masahiro Toyoura;Masaaki Iiyama;Koh Kakusho;Michihiko Minoh	2007	Sixth International Conference on 3-D Digital Imaging and Modeling (3DIM 2007)	10.1109/3DIM.2007.48	iterative reconstruction;computer vision;radiology;feature extraction;computer science;pattern recognition;mathematics	Vision	49.60286852256217	-52.5359268330696	124476
ba62b4af023d8abf778d244124bed12a1408e538	an image representation based on planar patches and the local adjustment technique		An efficient technique for representing a grey-scale image with a collection of connected triangular planar patches is investigated. The patches are planar in the three-dimensional space described by the plane of the image and using the intensity as the third dimension. In this way, the image can be thought of geometrically as a surface. The patches are fitted to this surface by application of the local adjustment technique. u003e		Jeffrey A. Bloom;Todd R. Reed;Chang Y. Choo	1993			image warping;image texture;layout;three-dimensional space;computer vision;national electrical code;pyramid;feature detection;scale space;color image;visual system;image gradient;binary image;u-matrix;image processing;computer science;electrical engineering;cognitive neuroscience of visual object recognition;machine learning;digital image processing;free boundary condition;pattern recognition;mathematics;image segmentation;tree;distance transform;image histogram	Robotics	48.803301478561586	-62.11022682499815	124754
bfd397339a9fcb0a6baae5ce0263457baf6b5420	fundamentals of texture flow equations in vision calculus	analisis imagen;movimiento;flux texture;analisis textura;motion;orientation spatiale;texture analysis;mouvement;image sequence;superficie;surface;image analysis;secuencia imagen;orientacion espacial;analyse image;analyse texture;sequence image;spatial orientation	Abstract   The question of texture flow equations for a textured surface moving relatively to a perspective camera is considered. Motion constraint equations involving projected image texture density and optic flow are derived and briefly compared with the classic motion constraint equation involving photometric image irradiance and optic flow. It is pointed out that these flow equations are significantly different by nature and by content.		Jens Arnspang	1991	Pattern Recognition Letters	10.1016/0167-8655(91)90034-J	computer vision;image analysis;spatial disorientation;computer science;motion;mathematics;geometry;surface	Vision	50.857702002332246	-58.49914277529651	124985
306957285fea4ce11a14641c3497d01b46095989	face recognition under varying lighting based on derivates of log image	reconnaissance visage;cmu;base donnee;analisis estadistico;facies;biometrie;biometrics;database;biometria;base dato;probabilistic approach;irradiance;aclaramiento energetico;face recognition;statistical analysis;eclairage;enfoque probabilista;approche probabiliste;analyse statistique;pattern recognition;lighting;reconnaissance forme;reconocimiento patron;similarity measure;eclairement energetique;alumbrado	This paper considers the problem of recognizing faces under varying illuminations. First, we investigate the statistics of the derivative of the irradiance images (log) of human face and find that the distribution is very sparse. Based on this observation, we propose an illumination insensitive similarity measure based on the min operator of the derivatives of two images. Our experiments on the CMU-PIE database have shown that the proposed method improves the performance of a face recognition system when the probes are collected under varying lighting conditions.	experiment;facial recognition system;maxima and minima;similarity measure;sparse matrix	Laiyun Qing;Shiguang Shan;Wen Gao	2004		10.1007/978-3-540-30548-4_23	facial recognition system;computer vision;facies;computer science;artificial intelligence;lighting;database;irradiance;biometrics	Vision	44.90446421390146	-60.43289667100558	125076
30b8fd8617a19aed25777ea45ae3538953ef57fa	automatic scene activity modeling for improving object classification	systeme temps reel;evaluation performance;urban environment;video techniques;long period;video surveillance;procesamiento informacion;performance evaluation;image processing;0705p;televigilancia;0130c;technique video;statistical models;traitement image;statistical model;algorithme;modelisation;semantic model;remote supervision;redundancy;automatic detection;telesurveillance;dempster shafer theory;information processing;modele statistique;algorithms;object classification;analisis semantico;scene understanding;traitement information;analyse semantique;4230v;modeling;cameras;buildings;redondance;semantic analysis;real time systems	In video surveillance, automatic methods for scene understanding and activity modeling can exploit the high redundancy of object trajectories observed over a long period of time. The goal of scene understanding is to generate a semantic model of the scene describing the patterns of normal activities. We are proposing to boost the performances of a real time object tracker in terms of object classification based on the accumulation of statistics over time. Based on the object shape, an initial three class object classification (Vehicle, Pedestrian and Other) is performed by the tracker. This initial labeling is usually very noisy because of object occlusions/merging and the eventual presence of shadows. The proposed scene activity modeling approach is derived from Makris and Ellis algorithm where the scene is described in terms of clusters of similar trajectories (called routes). The original envelope based model is replaced by a simpler statistical model around each route's node. The resulting scene activity model is then used to improve object classification based on the statistics observed within the node population of each route. Finally, the Dempster-Shafer theory is used to fuse multiple evidence sources and compute an improved object classification map. In addition, we investigate the automatic detection of problematic image areas that are the source of poor quality trajectories (object reflections in buildings, trees, flags, etc.). The algorithm was extensively tested using a live camera in a urban environment.	algorithm;bruce ellis;closed-circuit television;function model;instance (computer science);performance;reflection (computer graphics);statistical model;tree accumulation	Samuel Foucher;Marc Lalonde;Langis Gagnon	2010		10.1117/12.850273	statistical model;computer vision;method;simulation;object model;information processing;image processing;computer science;artificial intelligence	Vision	47.24647670242948	-56.758038501553926	125123
c342eddb5148eb096108e4403df5205ea49b7580	application of genetic algorithms to stereo matching of images	image processing;cross correlation;vision estereoscopica;cross correlation measurement;vision stereoscopique;procesamiento imagen;algoritmo genetico;traitement image;stereo matching;algorithme genetique;genetic algorithm;stereopsis;disparity map;image correspondence	A method is proposed that employs genetic algorithms (GAs) to determine a disparity map optimizing both the compatibility between corresponding points and the map continuity. This method is applied to analyze both computer synthesized and CCD stereo images. It is confirmed that use of GAs is effective when applied to stereo matching problems.	binocular disparity;charge-coupled device;computer stereo vision;genetic algorithm;scott continuity	Hideo Saito;Masayuki Mori	1995	Pattern Recognition Letters	10.1016/0167-8655(95)00048-L	computer stereo vision;computer vision;genetic algorithm;image processing;computer science;stereopsis;cross-correlation;computer graphics (images)	Vision	52.69033175546622	-58.78849692787664	125261
93674832ef7e240d5ab8bd9ab2626880cb940fcd	a similarity measure for image and volumetric data based on hermann weyl's discrepancy	lp norm;image segmentation;image processing;fluctuations;partial sums;distance measure;cross correlation;application software;image matching;positive definite;frequency measurement;indexing terms;upper bound;volume measurement mutual information measurement standards image segmentation autocorrelation upper bound frequency measurement image texture analysis fluctuations application software;registration;tracking image matching image segmentation;similarity measure similarity of images normalized cross correlation autocorrelation mutual information discrepancy norm registration tracking image processing;mutual information;image segmentation similarity measure volumetric data image data hermann weyl discrepancy l p norm homogenously linear upper bound monotonicity property similarity based registration;volume measurement;image texture analysis;measurement standards;similarity measure;tracking;autocorrelation;normalized cross correlation;discrepancy norm;similarity of images	The paper focuses on similarity measures for translationally misaligned image and volumetric patterns. For measures based on standard concepts such as cross-correlation, L_p-norm, and mutual information, monotonicity with respect to the extent of misalignment cannot be guaranteed. In this paper, we introduce a novel distance measure based on Hermann Weyl's discrepancy concept that relies on the evaluation of partial sums. In contrast to standard concepts, in this case, monotonicity, positive-definiteness, and a homogenously linear upper bound with respect to the extent of misalignment can be proven. We show that this monotonicity property is not influenced by the image's frequencies or other characteristics, which makes this new similarity measure useful for similarity-based registration, tracking, and segmentation.	cross-correlation;discrepancy function;mutual information;similarity measure	Bernhard Moser	2011	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2009.50	mathematical analysis;discrete mathematics;image processing;cross-correlation;pattern recognition;mathematics;statistics	Vision	49.83658729601148	-66.13157323860163	125524
1cb4f969564c56d4817bb88fc45cc364d9e68204	a computationally efficient 3d shape rejection algorithm	histograms;image recognition;art;technological innovation;haar wavelet;shape computational complexity art histograms testing feature extraction technological innovation real time systems image recognition earth;image resolution;image matching;multiresolution shape representation;earth;image classification;testing;real world pose classification;image matching image representation image classification computational complexity image resolution haar transforms wavelet transforms real time systems;wavelet transforms;shape representation;3d shape rejection algorithm;shape;computational complexity;shape matching;image representation;baseline shape matching algorithm 3d shape rejection algorithm unlabeled 3d marker multiresolution shape representation haar wavelet real world pose classification computational complexity;feature extraction;baseline shape matching algorithm;performing art;multi resolution;classification accuracy;haar transforms;real time systems;unlabeled 3d marker	In this paper, we present an efficient 3D shape rejection algorithm for unlabeled 3D markers. The problem is important in domains such as rehabilitation and the performing arts. There are three key innovations in our approach-(a) a multi-resolution shape representation using Haar wavelets for unlabeled markers, (b) a multi-resolution shape metric and (c) a shape rejection algorithm that is predicated on the simple idea that we do not need to compute the entire distance to conclude that two shapes are dissimilar. We tested the approach on a real-world pose classification problem with excellent results. We achieved a classification accuracy of 98% with an order of magnitude improvement in terms of computational complexity over a baseline shape matching algorithm.	algorithm;algorithmic efficiency;baseline (configuration management);computational complexity theory;emoticon;haar wavelet;rejection sampling	Yinpeng Chen;Hari Sundaram	2005	2005 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2005.1521643	active shape model;computer vision;contextual image classification;image resolution;feature extraction;shape;computer science;machine learning;pattern recognition;histogram;mathematics;earth;software testing;computational complexity theory;wavelet transform	Vision	39.92133417362042	-54.76489467811959	125629
3635ff96e776054af7ff95b782afb15f2a110f58	analyzing oriented patterns	deteccion borde;analisis imagen;anisotropie;anisotropia;edge detection;anisotropy;orientation;campo flujo;flow field;pattern recognition;champ ecoulement;orientacion;image analysis;reconnaissance forme;reconocimiento patron;analyse image;detection bord	"""Oriented patterns, such as those produced by propagation, accretion, <>r deformation, ore common in nature and therefore an important class for visual analysis. Our approach to understanding such patterns is to decompose them into two parts: a flow field, describing the direction of anisotropy, and the residual pattern obtained by describing the image in a coordinate system built, from the flow field. We develop a method for the local estimation of anisotropy and a method for combining the estimates to construct a flow coordinate system. Several examples of the use of these methods are presented. These included the use of the (low coordinates to provide preferred directions for edge detection, detection of anomalies, fitting simple models to the straightened pattern, and detecting singularities in the flow field. I I n t r o d u c t i o n A central focus in recent computational vision has been the decomposition of the original intensity image into intrinsic images (Horn 1977, Barrow & Tenenbaum, 1978; Marr, 1982), representing such properties as depth, reflectance, and illuminance. These intrinsic properties are believed to be more meaningful than image intensity because they describe basic independent constituents of the image formation process. Thus, for example, in separating shape from illumination, we can recognize an invaxiance of shape regardless of changing illumination. The advantages of decomposing what we see into its more-orless independent parts extends beyond the image formation process to the shapes and patterns on which that process operates. For instance, decomposing a bent rod into a straight rod and a bending transformation reveals the similarity between a bent rod and one that hasn't been bent, or some other solid that's been bent the same way (Barr, 1984). Just as we need to understand the image-forming process to decompose an image into intrinsic images, we need to understand the processes that generate patterns to decompose them into their intrinsic parts. But, whde there is only one imageforming process, a staggering variety of processes shape and color the world around us. Our only hope of dealing with this complexity is to begin with some basic pattern classes that recur in nature, and understand how to decompose and describe them. One such class are oriented patterns, notably those produced by propagation, accretion, or deformation. To understand an oriented pattern we must be able to say (l) what is propagating, accreting, or deforming, and (2) which way and how much. More precisely, we must estimate everywhere the direction and magnitude of anistropy (which we will call the flow field,) and describe the residual pattern, independent of that field. Why this decomposition leads to simpler, more regular descriptions is best illustrated by example: • A typical oriented pattern created by propagation is the streaked trail left by a paint brush dipped in variegated paint. The flow field describes the trajectory of the brush, the residual pattern depending only on the distribution of paint on the brush. • Accretion typically results in laminar structures, such as wood grain. Here, the flow field gives isochrones (the moving accretion boundary,) and the residual pattern describes the change in color or brightness of the accreting material over time. • If an isotropic body is deformed, the flow field principally describes the bending and stretching it has undergone, while the residual pattern describes the undeformed body. In all these cases, separate descriptions of the flow field and the residual pattern are appropriate because they describe different processes. The path of propagation for many physical processes is controlled by very different mechanisms than control the coloration of the trail left behind. Similarly, the mechanisms which control the shape of an accretion boundary are frequently unrelated to the processes controlling the color of the accreted material. Finally, the forces which deform a piece of material are often completely unrelated to the process which created the piece of material in the first place By separately describing these processes, we can create descriptions of the whole which are often simpler than is possible without the separation because each of the pieces may have different regularities. Orientation selective mechanisms have been extensively stud ied by physiologists since Ilubel and Wiesel's (1962) discovery of orientation selective cells in mammalian visual cortex (see Schiller et. al. (1976) for a comprehensive example). There has also been considerable interest among psychologists in the perception of oriented patterns, particularly dot patterns (Glass, 1969). Only recently have the computational issues involved received attention. Stevens (1978) examined the groupmg of tokens in Glass patterns based on orientation. While successful with Glass patterns, his methods were never extended to natural imagery. Zucker (1983) investigated the estimation of orientation by combining the outputs of linear operators. Zucker's estimation method for what he calls """"Type II"""" patterns, while differing in many respects, is quite close in spirit to our own. Little progress has been made in using local orientation estimates to interpret patterns, perhaps because reliable estimates have proved difficult to obtain. The key difference between our work and earlier efforts lies in our use of the flow field to build a natural coordinate system for analyzing the pattern. The remainder of the paper covers the computation of the flow field by local estimation of orientation, the construction of a coordinate system using the flow field, and some examples of analysis and description using flow coordinates. In Section 2 we develop an estimator for the local flow direction, that direction in which intensity tends to vary most slowly M. Kass and A. Witkin 945 due to an underlying anisotropic process. The estimator, based on the direction of least spatial variance in the output of an ori­ ented filter, is computed as follows: After initial filtering, the intensity gradient is measured at each point in the image. The gradient angle, 0, is then doubled (by treating the gradient vec­ tors as complex numbers and squaring them) to map directions differing by π into a single direction. The transformed vectors are then summed over a weighted neighborhood around the point of interest. The angle of the summed vector is halved, undoing the previous transformation. This gives an estimate for the direction of greatest variance, which is then rotated by π/2 to yield the flow direction. In section 3, we describe the construction and use of coordi­ nate systems based on the result of local estimation. Integral curves in the flow field are computed numerically, by following the estimated vectors from point to point. A coordinate system is constructed in which the integral curves are parameter lines. Transforming the image into these """"flow coordinates"""" straight­ ens the pattern, removing the effects of changing orientation. We present several examples of analysis and description of the flow field and the straightened pattern. I I F l o w C o m p u t a t i o n For intensity patterns created by anisotropic processes such as propagation, accretion, or deformation, variation in the flow direction is much slower than variation in the perpendicular di­ rection. Anisotropy in such patterns will be evident in the local power spectrum. The high frequency energy will tend to cluster along the line in the Fourier domain perpendicular to the flow orientation. A simple way to detect this clustering is to sum the energy in an appropriate region of the power spectrum and examine how the sum is affected by rotations. This can be done by examining the energy in the output of an appropriate orientation-selective linear filter. The orientation at which the energy is maximal can be expected to be perpendicular to the flow orientation. Selection of the filter involves a number of tradeoffs. Very low spatial frequencies are affected more strongly by illumina­ tion effects than surface coloration, so they are inappropriate for measuring textural anisotropy. Very high spatial frequencies are sensitive to noise and aliasing effects so they too are inappropri­ ate. Hence some type of roughly bandpass filtering is required. The orientation specificity of the filter is also quite important If the filter is too orientation-specific then a large spatial neighbor­ hood will be required in order to make a reliable measurement of the energy. Conversely, if the filter responds over a wide range of orientations then it will be difficult to localize the orientation very accurately. Thus there is a trade-off between angularand spatialresolution. The filter is bandpass with passband determined by and a2In our experience, ratios of the sigmas in the range of 2.0 to 10.0 work well. The orientation specificity or tuning curve is provided by the cosine dependence of the filter on 0. This appears to strike a reasonable balance between angularand spatialresolutions for the range of patterns we have examined. The filter's power spectrum is shown in figure 1 The cosine orientation tuning-curve of the filter has some un­ usually good properties for computing the filter output at dif­ ferent orientations. The impulse response S(xyy) of the filter 946 M. Kass and A. Witkin One might be tempted to believe that smoothing the gradient vectors G(x,y) would be nearly as good a measure of anisotropy as smoothing the rotated squared gradient vectors J(x,y). This is emphatically not the case Consider an intensity ridge such as /(x,y) = exp(x). The gradient vectors on the left halfplane all point to the right and the gradient vectors on the right half-plane all point to the left. Adding them together results in cancellation. By contrast, if they are first rotated to form the J vectors, they reinforce. The types of oriented patterns we are concerned with of"""	aliasing;cluster analysis;computation;computer vision;edge detection;gradient;hood method;image formation;line level;loss of significance;maximal set;newton's method;numerical analysis;numerical integration;pattern language;point of interest;poptropica;sensitivity and specificity;sensor;service-oriented architecture;smoothing;software propagation;spectral density	Michael Kass;Andrew P. Witkin	1985		10.1016/0734-189X(87)90043-0	computer vision;image analysis;computer science;anisotropy	Vision	51.73400755592974	-60.915776218436946	125643
625043a6da69e2e9b12b6339eac8a01eb4a594cf	identity verification through palm vein and crease texture	imageria termica;texture;pliegue;biometrie;biometrics;biometria;useful information;informacion util;near infra red;infra red;multimodal biometrics;thermal imaging;crease;pli;textura;pattern classification;imagerie thermique;palm vein recognition;palm print recognition;information utile	In this paper, an identity verification framework which combines pattern information from the palm-vein and the palm-crease texture is proposed. Main feature of this system is the use of a low cost Near-Infra-Red (NIR) camera instead of the more expensive infra-red thermal camera for palm image capture. Our preliminary experiments show that useful information from palm-vein and palm-crease texture can be effectively extracted for identity verification using a simple setup to contain the camera.		Kar-Ann Toh;How-Lung Eng;Yuen-Siong Choo;Yoon-Leon Cha;Wei-Yun Yau;Kay Soon Low	2006		10.1007/11608288_73	computer vision;infrared;archaeology;texture;biometrics	Logic	44.99032335972479	-60.73409920491587	125754
ea49a51cb1272d33e9b0a97fa8098c493c9130e3	planar object detection under scaled orthographic projection	object recognition;vision ordenador;projection orthographique;generalized hough transform;proyeccion imagen;reconnaissance objet;transformacion hough;computer vision;detection objet;image projection;projection image;vision ordinateur;hough transformation;transformation hough;object detection	In this work a new method to detect objects under scaled orthographic projections is shown. It also calculates the parameters of the transformations the object has suffered. The method is based on the use of the Generalized Hough Transform (GHT) that compares a template with a projected image. The computational requirements of the algorithm are reduced by restricting the transformation to the template edge points and using invariant information during the comparison process. This information is obtained from a precomputed table of the template that is directly transformed and compared with the image table. Moreover, a multiresolution design of the algorithm speeds-up the parameters calculation.	object detection;orthographic projection	Julián Ramos Cózar;Nicolás Guil Mata;Emilio L. Zapata	2000		10.1007/3-540-44438-6_39	hough transform;computer vision;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;mathematics;orthographic projection;graphical projection;computer graphics (images)	Vision	48.90596973699632	-59.09589964270058	125975
b60c5732cebc20f975148109617d1cf531741523	realistic animation using extended adaptive mesh for model based coding	animacion por computador;metodo adaptativo;estimation mouvement;adaptive mesh;movimiento ocular;estimacion movimiento;motion estimation;methode adaptative;sintesis imagen;image synthesis;mesh adaptation;eye movement;methode maille;mesh method;adaptive method;facial feature detection;synthese image;facial features;metodo malla;computer animation;quality model;mouvement oculaire;animation techniques;animation par ordinateur	Accurate localization and tracking of facial features are crucial for developing high quality model-based coding (MPEG-4) systems. For teleconferencing applications at very low bit rates, it is necessary to track eye and lip movements accurately over time. These movements can be coded and transmitted to a remote site, where animation techniques can be used to synthesize facial movements on a model of a face. In this paper we describe the integration of simple heuristics which are effective in improving the results of well-known facial feature detection with robust techniques for adapting a dynamic mesh for animation. A new method of generating a self-adaptive mesh using an extended dynamic mesh (EDM) is proposed to overcome the convergence problem of the dynamic-motion-equation method (DMM). The new method consisting of two-step mesh adaptation (called coarse-to-fine adaptation) can enhance the stability of the DMM and improve the performance of the adaptive process. The accuracy of the proposed approach is demonstrated by experiments on eye model animation. In this paper, we focus our discussion only on the detection, tracking, modeling and animation of eye movements.	digital molecular matter (dmm);display resolution;experiment;feature detection (computer vision);feature detection (web development);heuristic (computer science)	Lijun Yin;Anup Basu	1999		10.1007/3-540-48432-9_19	computer vision;simulation;computer science;motion estimation;computer animation;eye movement;computer graphics (images)	Graphics	47.78527689477484	-56.74792342742674	126007
ad88dbad3c24533879c43b0bc7db01e918529062	quasi-circular rotation invariance in image denoising	image sampling;translation invariant;interpolation;lattices;rotation invariant ri;geometry;image restoration;translation invariant ti;image denoising noise reduction lattices interpolation shape geometry image representation image sampling pixel white noise;wavelet based;wavelet based image denoising;wavelet transforms;rotation invariance;shape;image representation;noise reduction;pixel;image denoising;image rotation;image modeling;likelihood function;white noise;image rotation image denoising translation invariant wavelet based image modeling;wavelet transforms image restoration	This paper studies a new method for wavelet-based image denoising which is translation invariant (TI) and rotation invariant (RI). These invariances are crucial in image denoising and, more generally, may play important roles in image modeling. In contrast to other approximately RI methods, like the steerable pyramid, our new method employs standard separable wavelet bases in conjunction with a pseudo-circular image rotation. This scheme does not involve interpolation and hence the observation model (likelihood function) is invariant under this rotation. The superiority of our new method with respect to existing TI (non-RI) techniques is supported by experiments. 1 Introduction A major diiculty in wavelet-based image denoising (and wavelet-based image modeling in general) is the lack of translation invariance (TI) and rotation invari-ance (RI) associated with separable wavelet bases. TI can be obtained fairly easily using the frame formed by all possible translations of the wavelet basis, but RI is more diicult to achieve simply because images are usually sampled on a rectangular lattice. It is well-known that TI denoising methods reduce blocky artifacts and in general produce better image denois-ing results than non-TI methods 1, 2]. However, TI methods still tend to favor certain features that align well with the wavelet basis functions. In the case of Haar wavelets, for example, these features are approximately vertical or horizontal edges. For a slant edge with slope of, say, 30 degrees, or a circular disk, it is easy to see that their shape and orientation will remain unchanged for any translation operation. Hence, TI methods are not well-matched to the above mentioned situations which are very common in natural images. The geometry of natural images can be dealt with more eeectively by designing more complex, often redundant, image representations. The shiftable multiscale transform developed in 3, 4] represents one eeort in this direction. The shiftable multiscale transform (here shiftable refers to both translation and rotation) essentially involves a standard image rotation. Unfortunately, standard rotation is not compatible with rectilinear image sampling schemes, and involves pixel interpolation. Here we propose a new rotation scheme that is better suited to square image lattices and ooers certain advantages. In this paper we develop a new translation and rotation invariant (TRI) denoising method which uses a quasi-circular image rotation scheme. It makes use of the l 1 distance norm, rather than the Euclidean norm underlying standard image rotation, and hence we call this an l 1-rotation. …	align (company);basis function;experiment;haar wavelet;interpolation;noise reduction;pixel;pyramid (image processing);rs-232;regular grid;rotation system;sampling (signal processing)	Yi Wan;Robert D. Nowak	1999		10.1109/ICIP.1999.821703	image restoration;computer vision;topology;interpolation;shape;lattice;noise reduction;mathematics;geometry;white noise;likelihood function;non-local means;pixel;statistics;wavelet transform	Vision	52.540886007104504	-64.04679270430687	126056
0486214fb58ee9a04edfe7d6a74c6d0f661a7668	patch-based probabilistic image quality assessment for face selection and improved video-based face recognition	portals;face localisation;video surveillance;probability;illumination;video signal processing;face selection;video based face recognition;patch based probabilistic image quality assessment;pie datasets;face cameras lighting portals quality assessment light sources face recognition;sharpness;quality assessment;chokepoint;motion blur;face recognition;shadowing;image quality assessment;face modeling;video signal processing face recognition probability;face;lighting;feret;chokepoint patch based probabilistic image quality assessment face selection video based face recognition head pose illumination shadowing motion blur face localisation alignment variations geometric alignment sharpness cast shadows pie datasets feret;head pose;cast shadows;cameras;alignment variations;light sources;geometric alignment	In video based face recognition, face images are typically captured over multiple frames in uncontrolled conditions, where head pose, illumination, shadowing, motion blur and focus change over the sequence. Additionally, inaccuracies in face localisation can also introduce scale and alignment variations. Using all face images, including images of poor quality, can actually degrade face recognition performance. While one solution it to use only the ‘best’ of images, current face selection techniques are incapable of simultaneously handling all of the abovementioned issues. We propose an efficient patch-based face image quality assessment algorithm which quantifies the similarity of a face image to a probabilistic face model, representing an ‘ideal’ face. Image characteristics that affect recognition are taken into account, including variations in geometric alignment (shift, rotation and scale), sharpness, head pose and cast shadows. Experiments on FERET and PIE datasets show that the proposed algorithm is able to identify images which are simultaneously the most frontal, aligned, sharp and well illuminated. Further experiments on a new video surveillance dataset (termed ChokePoint) show that the proposed method provides better face subsets than existing face selection techniques, leading to significant improvements in recognition accuracy.	algorithm;closed-circuit television;experiment;feret (facial recognition technology);facial recognition system;gaussian blur;image quality;patch (computing);uncontrolled format string	Yongkang Wong;Shaokang Chen;Sandra Mau;Conrad Sanderson;Brian C. Lovell	2011	CVPR 2011 WORKSHOPS	10.1109/CVPRW.2011.5981881	facial recognition system;computer vision;face detection;object-class detection;three-dimensional face recognition;lighting;mathematics;geometry;multimedia;statistics;computer graphics (images)	Vision	42.701192524857454	-52.7611407865135	126077
8c22dc1b494c4612c4ebc61b22a480666cd841d5	towards practical facial feature detection	feature detection;machine vision;image registration;facial feature detection	Localizing facial features is a critical component in computer vision applications such as person identification and expression recognition. Practical applications require detectors that operate reliably under a wide range of conditions, including variations in illumination, ethnicity, gender, age, and imaging hardware. One challenge for the development of such detectors is the inherent tradeoff between robustness and precision. Robust detectors provide poor localization and detectors sensitive to small shifts, which are needed for precise localization, generate a large number of false alarms. Here we present an approach to this tradeoff based on context dependent inference. First robust detectors are used to detect contexts in which target features occur, then precise detectors are trained to localize the features given the context. This paper describes the approach and presents a thorough empirical examination of the parameters needed to achieve practical levels of performance, including the size of the training database, size of the detector’s receptive fields, and methods for information integration. The approach operates in real time and achieves, to our knowledge, the best performance to-date reported in the literature.	approximation algorithm;computer vision;database;emoticon;experiment;feature detection (computer vision);feature detection (web development);internationalization and localization;machine perception;real-time computing;region of interest;robustness (computer science);sensor;world wide web	Micah Eckhardt;Ian R. Fasel;Javier R. Movellan	2009	IJPRAI	10.1142/S0218001409007247	computer vision;machine vision;computer science;image registration;machine learning;pattern recognition;feature detection	Vision	42.46879525069968	-54.44856850350448	126201
1779e903a58c44b3412f55c69e4f67ad50d5d456	multivariate entropy detector based hybrid image registration	image matching image registration entropy;image matching;entropy detectors image registration color layout application software computational efficiency biomedical imaging remote sensing computer vision;image registration;computational cost multivariate entropy based detector hybrid image registration spatial alignment intensity alignment color images transformation parameters salient descriptors;entropy;color image	Image registration is used to match two images for spatial alignment and intensity alignment. One of the possible applications of image registration is for the evaluation of a printed image with respect to a given reference image. We propose a new hybrid image registration algorithm to identify the spatial or intensity variations between two color images. The proposed approach extracts salient descriptors from the two images using a multivariate entropy-based detector. The transformation parameters are obtained after establishing the correspondence between the salient descriptors of the two images, which yields better accuracy and lesser computational cost compared to the approaches present in the literature.	algorithm;computation;computational complexity theory;image registration;mike lesser;printing	S. Pavan;G. Sridhar;V. Sridhar	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1415544	homography;computer vision;entropy;feature detection;template matching;image resolution;color image;image gradient;binary image;image processing;computer science;image registration;machine learning;pattern recognition;mathematics	Vision	42.916527916777056	-57.94075816324959	126281
6621c274677dadd21f1e97cd0d37738a1daf0984	a nonlinear laplace operator as edge detector in noisy images	deteccion borde;image numerique;non linear filtering;image processing;laplace operator;edge detection;estudio comparativo;operateur laplace;filtrado no lineal;procesamiento imagen;intelligence artificielle;image bruitee;traitement image;imagen sonora;etude comparative;operador laplace;noisy image;imagen numerica;comparative study;artificial intelligence;digital image;inteligencia artificial;detection bord;filtrage non lineaire	An edge detection scheme is developed robust enough to perform well over a wide range of signal-to-noise ratios. It is based upon the detection of zero crossings in the output image of a nonlinear Laplace filter. Specific characterizations of the nonlinear Laplacian are its adaptive orientation to the direction of the gradient and its inherent masks which permit the develop ment of approximately circular (isotropic) filters. We have investigated the relation between the locally optimal filter parameters, smoothing size, and filter size, and the SNR of the image to be processed. A quantitative evaluation shows that our edge detector performs at least as well-and in most cases much better-than other edge detectors. At very low signal-to-noise ratios, our edge detector is superior to all others tested. Q 1989 Academic press, I D C .	discrete laplace operator;edge detection;gradient;local optimum;nonlinear system;sensor;signal-to-noise ratio;smoothing	Lucas J. van Vliet;Ian T. Young;Guus L. Beckers	1989	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(89)90131-X	computer vision;laplace operator;edge detection;image processing;computer science;comparative research;calculus;mathematics;geometry;canny edge detector;digital image	Vision	47.93426086138018	-64.19002266757597	126624
8d4fd3e9fe17f4ad5efe56e80b0982ce5702114b	motion normalization	retargeting problem;simpler solution;constraint condition;motion data;previous step;footskate cleanup algorithm;previous motion;single frame;input motion stream;efficient algorithm;motion normalization	This paper presents a very simple but efficient algorithm to normalize all motion data in database with same skeleton length. The input motion stream is processed sequentially while the computation for a single frame at each step requires only the results from the previous step over a neighborhood of nearby backward frames. In contrast to previous motion retargeting approaches, we simplify the constraint condition of retargeting problem, which leads to the simpler solutions. Moreover, we improve Shin et al.’s algorithm [10], which is adopted by a widely used Kovar’s footskate cleanup algorithm [6] through adding one case missed by it.	computation;constraint algorithm;database normalization;retargeting	Yan Gao;Lizhuang Ma;Zhihua Chen;Xiaomao Wu	2005		10.1007/11573548_13	mathematical optimization;algorithm	Vision	48.80537019591159	-53.56477054187992	126719
02252287943499a5e8cdadccdc63f0cb5217383d	hexagonal parallel thinning algorithms based on sufficient conditions for topology preservation		"""Description: Thinning is a widely used pre–processing step in digital image processing and pattern recognition. It is an iterative layer by layer erosion until only the """"skeletons"""" of the objects are left. Thinning algorithms are generally constructed in the following way: first the thinning strategy and the deletion rules are figured out, then the topological correctness is proved. In the case of the proposed algorithms we used the converse way: first we considered some sufficient conditions for parallel reduction operators to preserve topology, then the deletion rules were accommodated to them. In our algorithms, the correctness is predestinated, hence no complex proof–part is needed. In 2D, we applied Ronse's sufficient conditions for topology preservation (C. Ronse: Minimal test patterns for connectivity preservation in parallel thinning algorithms for binary digital images. Discrete Applied Mathematics 21, 67-79, 1988); our 3D thinning algorithms are based on conditions proposed by Palágyi and Kuba (K. Palágyi, A. Kuba: A parallel 3D 12-subiteration thinning algorithm. Graphical Models and Image Processing 61, 1999, 199–221)."""	algorithm;correctness (computer science);digital image processing;erosion (morphology);graphical model;iterative method;pattern recognition;test card;thinning	Péter Kardos;Kálmán Palágyi	2012		10.1201/b12753-12	mathematical optimization;combinatorics;distributed computing	AI	48.929897139858944	-64.50658566741393	127002
ebf2d514c30a6254c222a708049d0929cc8700c8	camera calibration using one-dimensional information and its applications in both controlled and uncontrolled environments	contraste;analisis imagen;auto calibracion;modelo 3 dimensiones;selfcalibration;autoetalonnage;modele 3 dimensions;angulo rotacion;three dimensional model;metric;multipoint method;one dimensional calibration object;journal article;three dimensional;methode multipoint;metodo multipunto;object oriented;video cameras;modelo 2 dimensiones;rotation angle;camera video;modele 2 dimensions;oriente objet;metrico;image analysis;angle rotation;etalonnage;camera calibration;analyse image;orientado objeto;calibration;metrique;two dimensional model;pin hole camera model	Camera model and its calibration are required in many applications for coordinate conversions between the two-dimensional image and the real three-dimensional world. Self-calibration method is usually chosen for camera calibration in uncontrolled environments because the scene geometry could be unknown. However when no reliable feature correspondences can be established or when the camera is static in relation to the majority of the scene, self-calibration method fails to work. On the other hand, object-based calibration methods are more reliable than self-calibration methods due to the existence of the object with known geometry. However, most object-based calibration methods are unable to work in uncontrolled environments because they require the geometric knowledge on calibration objects. Though in the past few years the simplest geometry required for a calibration object has been reduced to a 1D object with at least three points, it is still not easy to find such an object in an uncontrolled environment, not to mention the additional metric/motion requirement in the existing methods. Meanwhile, it is very easy to find a 1D object with two end points in most scenes. Thus, it would be very worthwhile to investigate an object-based method based on such a simple object so that it would still be possible to calibrate a camera when both self-calibration and existing object-based calibration fail to work. We propose a new camera calibration method which requires only an object with two end points, the simplest geometry that can be extracted from many real-life objects. Through observations of such a 1D object at different positions/orientations on a plane which is fixed in relation to the camera, both intrinsic (focal length) and extrinsic (rotation angles and translations) camera parameters can be calibrated using the proposed method. The proposed method has been tested on simulated data and real data from both controlled and uncontrolled environments, including situations where no explicit 1D calibration objects are available, e.g. from a human walking sequence. Very accurate camera calibration results have been achieved using the proposed method.	camera resectioning;uncontrolled format string	En Peng	2010	Pattern Recognition	10.1016/j.patcog.2009.08.003	three-dimensional space;computer vision;camera auto-calibration;calibration;image analysis;camera resectioning;simulation;metric;computer science;mathematics;object-oriented programming	Vision	49.99741088812778	-56.994161232921016	127042
e5fd4c7c2badb7a63dc8dff90b9ad0e2018fdbf5	symmetry detection in 3d scenes	image features;man;evaluation performance;medical imagery;ophtalmoscopie;performance evaluation;asymmetry;0130c;computer model;asymetrie;human subjects;computational modeling;imagineria medica;imagerie medicale;ophthalmoscopy;axis of rotation;retinal imaging;oftalmoscopia;homme	Retinal image of a symmetric object is itself symmetric only for a small set of viewing directions. Interestingly, human subjects have little difficulty in determining whether a given retinal image was produced by a symmetric object, regardless of the viewing direction. We tested perception of planar (2D) symmetric figures (dotted patterns and polygons) when the figures were slanted in depth. We found that symmetry could be detected reliably with polygons, but not with dotted patterns. Next, we tested the role image features representing the symmetry of the pattern itself (orientation of projected symmetry axis and symmetry lines) vs. those representing the 3D viewing direction (orientation of the axis of rotation). We found that symmetry detection is improved when the projected symmetry axis or lines are known to the subject, but not when the axis of rotation is known. Finally, we showed that performance with orthographic images is higher than that with perspective images. A computational model, which measures the asymmetry of the presented polygon based on its single orthographic or perspective image, is presented. Performance of the model is similar to the performance of human subjects.	apache axis;computational model;optic axis of a crystal;orthographic projection;simulation;terms of service;viewing cone	Tadamasa Sawada;Zygmunt Pizlo	2007		10.1117/12.715160	computer simulation;computer vision;rotational symmetry;rotation;optics;computational model;feature;physics;quantum mechanics;asymmetry;computer graphics (images)	Vision	51.669888729060006	-58.174150896191215	127187
0ce73241c828f0f30e0906b4ecf9d675dc9ca915	affine morphological shape stable boundary regions (ssbr) for image representation	detectors;object recognition;stable regions;detectors shape vectors feature extraction stability analysis skeleton equations;feature matching affine morphological shape stable boundary regions structure based interest region detector object class recognition multiscale morphological image representation multiscale analysis anisotropic diffusion operators affine transformations transition boundary extraction diffusivity velocity map minimization process;object recognition affine transforms feature extraction image matching image representation;image matching;feature matching;anisotropic diffusion;skeleton;scale space;shape;vectors;image representation;feature extraction;morphological scale space;affine transformation;affine transforms;stability analysis;multi scale analysis;affine invariant;affine invariant stable regions morphological scale space	This paper presents a new structure-based interest region detector called Shape-Stable Region Boundaries (SSRB) which we use for object class recognition. The SSRB interest operator detects stable boundary regions within the multi-scale morphological image representation [1]. To detect robust boundary regions, we perform multi-scale analysis via anisotropic diffusion operators to preserve boundaries and guarantee invariance to affine transformations. We extract the transition boundaries of the diffusivity velocity map and track their evolution at each level of the scale-space. The stability of the boundary shape is subsequently estimated through a minimization process over different scales. Unlike most state of the art detectors which use the Gaussian scale space for multi-scale image representation, our approach is intrinsically affine invariant [1]. Experiments on different benchmark datasets show that SSRB is comparable or superior to state-of the art detectors for both feature matching and object recognition.	algorithm;anisotropic diffusion;benchmark (computing);experiment;outline of object recognition;region of interest;repeatability;scale space;sensor;shape context;velocity (software development)	Petros Kapsalas;Stefanos D. Kollias	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116435	computer vision;detector;von neumann stability analysis;scale space;topology;feature extraction;shape;computer science;cognitive neuroscience of visual object recognition;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;skeleton;anisotropic diffusion	Vision	42.131032282378925	-57.221164025319396	127218
7d760cb2b25b384f7a31cade0e702906a464f56e	texture analysis with a texture matched m-channel wavelet approach	wavelet analysis;brodatz textures;filtering;2d fir filters;decomposition;filter bank;biorthogonal wavelets;degree of freedom;signal design;performance;brodatz textures 2d fir filters texture analysis wavelet transform decomposition filter coefficients finite impulse response texture feature dependent pyramid structures performance;wavelet transforms image texture iterative methods transient response two dimensional digital filters;wavelet analysis wavelet transforms filter bank image texture analysis image analysis spatial resolution signal resolution filtering design optimization signal design;texture features;design optimization;texture feature dependent pyramid structures;image texture;two dimensional digital filters;wavelet transforms;iterative methods;texture analysis;transient response;finite impulse response;wavelet transform;signal resolution;image analysis;image texture analysis;filter coefficients;spatial resolution	A novel method of texture analysis based on the wavelet transform is described. An M-channel extension of the existing two-channel biorthogonal wavelets is proposed. The extension offers a compact and efficient decomposition, a higher degree of freedom in the design of the filter coefficients, and the facility of an iterative linear solution. In contra-distinction to the classical, purely mathematical design procedures of wavelet filters, the proposed design takes into account texture-relevant features. Texture-matched, asymmetric separable 2-D FIR (finite impulse response) filters are obtained which permit the decomposition of the image into texture-feature-dependent pyramid structures downsampled by a factor of M for each direction. The performance of the new filters is tested with the Brodatz textures and compared with the results of other wavelet approaches. >		Thomas Greiner;J. P. Casel;Madhukar Pandit	1993		10.1109/ICASSP.1993.319764	wavelet;computer vision;image analysis;speech recognition;second-generation wavelet transform;continuous wavelet transform;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Vision	51.97514258806158	-65.76391879672148	127485
c08a5df71af016e85bad419d5a8f4d0cae1d6e8a	segmentation of fingerprint images using the directional image	algorithm complexity;image processing;complejidad algoritmo;direccion;procesamiento imagen;segmentation;traitement image;histogram;empreinte digitale;histogramme;complexite algorithme;direction;pattern recognition;reconnaissance forme;reconocimiento patron;histograma;segmentacion	Abstract   In this paper the concept of the directional image is introduced and its application for segmentation is presented. The directional image can be thought of as an image transform, where each pixel of the image represents direction of the local grey level uniformity.  The statistics derived from the directional image are used for the segmentation of the original image. It has been found to work better than the segmentation based on grey level statistics and other methods. This method is suited for simple images like Fingerprint and other images that consist of only background and foreground, but whose histogram may not necessarily be bimodal. The results of segmentation with the new and other methods are presented.	fingerprint	Babu M. Mehtre;Nikhil Murthy;Surendra Kapoor;B. Chatterjee	1987	Pattern Recognition	10.1016/0031-3203(87)90069-0	image texture;computer vision;feature detection;range segmentation;binary image;image processing;computer science;artificial intelligence;morphological gradient;segmentation-based object categorization;pattern recognition;histogram;mathematics;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation;segmentation;statistics	Vision	46.34229964892336	-63.49188425171122	127496
161ea58468cc2820a9d1ee76009bdae218466c1e	a study on vision-based robust hand-posture recognition by learning similarity between hand-posture and structure	hand;vision ordenador;occlusion;degree of freedom;occultation;oclusion;calcul analogique;similitude;computer vision;posture;performance improvement;estructura datos;similarity;postura;mano;vision ordinateur;structure donnee;similitud;main;ocultacion;data structure;analog calculus;calculo analogico	This paper proposes a robust hand-posture recognition method by learning similarity between hand-posture and structure for the performance improvement of vision-based hand-posture recognition. The difficulties in vision-based hand-posture recognition lie in viewing direction dependency and self-occlusion problem due to the high degree-of-freedom of human hand. General approaches to deal with these problems include multiple camera approach and methods of limiting the relative angle between cameras and the user's hand. In the case of using multiple cameras, however, fusion techniques to induce the final decision should be considered. Limiting the angle of user's hand restricts the user's freedom. The proposed method combines angular features and appearance features to describe hand-postures by a two-layered data structure and includes learning the similarity between the two types of features. The validity of the proposed method is evaluated by applying it to the hand-posture recognition system using three cameras.	poor posture	Hyoyoung Jang;Jin-Woo Jung;Z. Zenn Bien	2006		10.1007/11881223_68	computer vision;simulation;similarity;data structure;occultation;computer science;artificial intelligence;similitude;machine learning;mathematics;degrees of freedom;programming language;computer security	Vision	46.86644651532168	-58.909976444874935	127628
76475193e1921ceab3d644065d00b0d1aef00d34	real time object tracking based on local texture feature with correlation filter	correlation filter;haar like feature;dense sampling;discrete fourier transform	Object tracking is a fundamental problem in computer vision, therefore attracts many researchers and there has been many influential algorithms in the list few years. A good feature descriptor is half of the success. In this paper, we propose an effective tracking algorithm based on texture feature with correlation filter. We improve the tracking precision by Haar-like feature and speed it up via discrete Fourier transform. The feature which is a good representation of the target can be obtained via dense sampling. What is more important is that the feature containing a great deal of information of the target appears only in the form of low-dimension. With the property of circluant matrix, we can translate the processes of training and testing into Fourier domain, which can cut the computation and reduce the time complexity. Our algorithm is proved to have better performance especially in deformation and rotation in the benchmark datasets.	algorithm;benchmark (computing);computation;computer vision;discrete fourier transform;haar wavelet;robustness (computer science);sampling (signal processing);time complexity;visual descriptor	Meina Qiao;Tian J. Wang;Yuan Dong;Jingang Shi;Jing Teng;Hichem Snoussi	2016	2016 IEEE International Conference on Digital Signal Processing (DSP)	10.1109/ICDSP.2016.7868604	computer vision;machine learning;pattern recognition;mathematics;feature	Robotics	39.74080332628198	-54.892098549085084	128014
30f09f263c506a669b1b0af29239cff59797f1ad	error analysis of 3d shape construction from structured lighting	modelizacion;vision ordenador;formation image tridimensionnelle;image processing;system configuration;3d imaging;system modeling;modeling error;calcul erreur;procesamiento imagen;structured light;courbure;orientation;traitement image;three dimensional;computer vision;surface properties;modelisation;error analysis;relative error;orientacion;calculo error;curvatura;curvature;vision ordinateur;experimental error;formacion imagen tridimensional;modeling;quantization error;modeling and analysis	In this paper, we present a detailed model and analysis of several error sources and thier effects on measuring three-dimensional (3D) surface properties using the structured lighting technique. The analysis is based on a general system configuration and identifies three types of error surces--system modeling error, image processing error and experimental error. Absolute and relative error bounds in obtaining 3D surface orientation and curvature measurements using structured lighting are derived in terms of the system parameters and likely error sources. In addition to the quantization error, other likely error sources in system modeling and experimental setup are also considered. Even though our analysis is on structured lighting, the results are readily applicable to other triangulation-based techniques such as stereopsis. Finally, our analysis focuses on error in inferring surface orientation and principal surface curvature. Such analyses, to our knowledge, have never been attempted before. Image processing Structured light Orientation Curvature Error analysis 1. I N T R O D U C T I O N The problem of reconstructing 3D surface structures from their 2D projections is an important research topic in computer vision. Over the past two decades, a variety of techniques have been developed to infer 3D surface structures from 2D images using different imaging devices, shape cues and heuristics. (1-3) These techniques can rely on ambient light reflection (passive sensing) or can employ a light source to actively probe the environment (active sensing). They have also relied on many image shape cues such as stereo disparity, image brightness and surface pattern to recover the depth, orientation and curvature of an imaged surface. To study the feasibility of these 3D shape reconstruction techniques in industrial applications, it is imperative that their accuracy be understood. That is, for each technique, rigid modeling and analysis of the inherent error sources and their effects on 3D shape inference are needed. However, error analysis of all types of sensors used in machine vision is beyond the scope of this paper. Our discussion will be limited to the structured light-sensing technique, which we have some experience with. Thus, the goal of this paper is to identify likely error sources and investigate their effects on computing surface properties using the structured light sensing technique. More precisely, errors in using strucfured lighting to infer surface orientation and principal surface curvatures are analysed. Error * This research was supported in part by a grant from the National Science Foundation, IRI-8908627. ~ Author for correspondence. bounds are derived in terms of various system parameters and error sources. Simulation was conducted to verify the correctness of the analysis. Structured lighting is an active sensing technique which projects a spatially modulated pattern to encode the image object for analysis. ~4-15) Tradit ional structured light techniques use a grid pattern and rely on the triangulation principle in the analysis, i.e. the observed pattern is matched with the projected one, and the 3D position of the pa t t e rn -hence that o f the encoded surface-is recovered through triangulation. More recently, it was shown that it is possible to analyse the orientation and curvature of the projected pattern to infer the orientation and curvature of the encoded surfaces.(lo,11.13,14) Although many image analysis techniques have been developed using structured lighting, no formal modeling and analysis of errors in structured lighting have been attempted, except, maybe, for references (16, 17). Frobin (16'1v) considered the image processifig error in his reconstruction equat ion and modeled such an error as uncorrelated Gaussian noise at each pixel location. He then computed the 3D surface position using the least-squares minimization, with sensor data weighted by the inverse of the observation error. However, Frobin 's analysis was on computing 3D surface position using structured lighting and the analysis results are not applicable to the surface orientation and curvature computations. Other researches on error analysis in computer vision were mainly concerned with the analysis of the stereopsis technique and considered only the quantization error318 22) Duda and Hart ~23) gave a brief treat-	approximation error;binocular disparity;computation;computer vision;correctness (computer science);encode;error analysis (mathematics);heuristic (computer science);image analysis;image processing;imperative programming;least squares;machine vision;modulation;pixel;quantization (signal processing);sensor;shape context;simulation;stereopsis;structured light;system configuration;systems modeling	Zaiming Yang;Yuan-Fang Wang	1996	Pattern Recognition	10.1016/0031-3203(95)00076-3	human error assessment and reduction technique;discretization error;computer vision;systems modeling;image processing;computer science;error bar;mathematics	Vision	51.18123183763835	-57.85937847221793	128024
4c91ca56283200e150c1d5a71dc73234904d56ba	a survey of advances in vision-based human motion capture and analysis	motion analysis;vision ordenador;human movement;mouvement corporel;analisis escena;pistage;analyse scene;estimation mouvement;image understanding;estimacion movimiento;rastreo;analyse mouvement;motion estimation;inicializacion;analisis automatico;computer vision;image interpretation;posture;automatic analysis;recognition;interpretacion imagen;senal video;signal video;human motion;visual analysis;postura;scene naturelle;analyse automatique;video signal;vision ordinateur;interpretation image;analisis movimiento;review;movimiento corporal;initialization;body movement;natural scenes;initialisation;tracking;scene analysis;pose estimation	This technical report summarizes the research efforts undertaken within the first report period of PACO. The key points of investigation included representation of action in the space of human joint settings and how to recognize actions. For action recognition, two subproblems have been investigated: 1) Given a set of example actions, how can novel actions be recognized that are of the same type as the example actions. 2) Given a set of example actions, how can actions be reocognized that are a composition of novel actions of the example action type. The questions we wanted to answer were: 1) What are useful modelling strategies for action representation and recognoition. 2) Is it possible to distinguish between very similar actions such as pick up or push. 3) What role does an object play that is involved in an action ? The representations we have investigated are HMMs, PCA and spatiotemporal isomap. For our experiments, we have recorded three different action databases. The actions we have considered in our work are single arm actions of humans, partially including the hand and objects. The actions were performed by different individuals with several repetitions. The field of action and activity representation for synthesis and recognition is relatively old, yet still immature. This area is presently subject to intense investigation which is also reflected by the large number of different ideas and approaches. The approaches depend on the goal of the researcher and applications for activity recognition are interesting for surveillance, medical studies and rehabilitation, robotics, video indexing and animation for film and games, see [6] for an extensive review. For example, in applications for scene interpretation the data is often represented statistically and is meant to distinguish “regular” from “irregular” activities. In scene interpretation, the representations should be independent from the objects causing the activity and thus are usually not meant to distinguish explicitly, e.g, cars from humans. On the other hand, some surveillance applications focus explicitly on human activities and the interactions between humans. Here, one finds both, holistic approaches, that take into account the entire human body without considering particular body parts, and local approaches. Most holistic approaches attempt to identify “holistic” information such as gender, identity or simple actions like walking or running. Researchers using local approaches appear often to be interested in more subtle actions or attempt to model actions by looking for action primitives with which the complex actions can be modeled. In PACO, we are particularly interested in understanding and representing action for both, recognition and synthesis. There is strong neurobiological evidence that human actions and activities are directly connected to the motor control of the human body [2; 7; 8]. When viewing other agents performing an action, the human visual system seems to relate the visual input to a sequence of motor primitives. The neurobiological representation for visually perceived, learned and recognized actions appears to be the same as the one used to drive the motor control of	action potential;activity recognition;database;experiment;holism;human visual system model;interaction;isomap;kinesiology;motion capture;principal component analysis;push technology;rehabilitation robotics;spatiotemporal pattern	Thomas B. Moeslund;Adrian Hilton;Volker Krüger	2006	Computer Vision and Image Understanding	10.1016/j.cviu.2006.08.002	computer vision;initialization;visual analytics;pose;computer science;motion estimation;tracking;computer graphics (images)	Vision	46.30478147347542	-56.82282078960021	128039
6c00472372f3dcc299e71acdbcd3d5a2ad1cfa5c	enhancing the mst-css representation using robust geometric features, for efficient content based video retrieval (cbvr)	matching method mst css representation robust geometric features content based video retrieval cbvr multispectro temporal curvature scale space video content descriptor saddle points feature points salient features mst css surface enhanced mst css feature representation;precision recall emst css cbvr curvature peak ridge stv vob matching;ridge;video signal processing;video retrieval;precision recall;video signal processing content based retrieval feature extraction pattern matching video retrieval;pattern matching;feature extraction;matching;vob;stv;peak;emst css;curvature;cbvr;feature extraction shape trajectory surface treatment cameras robustness humans;content based retrieval	Multi-Spectro-Temporal Curvature Scale Space (MST-CSS) had been proposed as a video content descriptor in an earlier work, where the peak and saddle points were used for feature points. But these are inadequate to capture the salient features of the MST-CSS surface, producing poor retrieval results. To overcome these, we propose EMST-CSS (Enhanced MST-CSS) as a better feature representation with an improved matching method for CBVR (Content Based Video Retrieval). Comparative study with the existing MST-CSS representation and two state-of-the-art methods for CBVR shows enhanced performance on one synthetic and two real-world datasets.	cascading style sheets;digital video;experiment;list of sega arcade system boards;synth;scale space;synthetic intelligence;vp/css	Chiranjoy Chattopadhyay;Sukhendu Das	2012	2012 IEEE International Symposium on Multimedia	10.1109/ISM.2012.71	matching;computer vision;ridge;feature extraction;computer science;machine learning;pattern matching;pattern recognition;curvature;precision and recall;information retrieval	Vision	39.55650796832094	-58.345603494298345	128054
84cb46ba1742ddaf79f9d04f75aa15b97257a07e	invariant representation in image processing	object recognition;image processing;scene accidental conditions;optical reflection;intersymbol interference;feeds;color features;object intrinsic characteristics;layout;texture features invariant representation image processing invariance object intrinsic characteristics scene accidental conditions image retrieval object recognition content based retrieval color features;texture features;universiteitsbibliotheek;image texture;computer vision;invariance;invariant representation;image colour analysis;image representation;image processing layout image retrieval cameras intersymbol interference object recognition computer vision feeds optical reflection;content based retrieval image colour analysis image retrieval image representation image texture;content based retrieval;cameras;image retrieval	The paper discusses the role of invariance in image processing, specifically the desire to discriminate against unwant ed variations in the scene while maintaining the power to tell the difference between object-intrinsic characteristics and scene-accidental conditions. It provides an analysis and r eferences of what are directly observables in a general scene.	error-tolerant design;image processing;observable	Arnold W. M. Smeulders;Jan-Mark Geusebroek;Theo Gevers	2001		10.1109/ICIP.2001.958040	image texture;layout;computer vision;image processing;image retrieval;computer science;invariant;cognitive neuroscience of visual object recognition;pattern recognition;multimedia;intersymbol interference	Vision	41.019134443955885	-61.208390028508504	128127
1c638e32dac608e60c5c2a11d4632a3497561623	extremal edges: evidence in natural images	image patches;statistical testing edge detection feature extraction principal component analysis statistical distributions;bayesian t test;luminance gradient;edge detection;figure ground assignment prediction;bayesian methods;extremal edges;natural images;object occlusion;bayesian method;statistical distribution analysis;statistical distributions;image edge detection;background distributions;feature extraction;image edge detection bayesian methods;principal component analysis;luminance gradient extremal edges figure ground assignment prediction image patches natural images principal component analysis t junction object occlusion statistical distribution analysis bayesian t test background distributions;t junction;statistical testing	In complex natural scenes, information about figure ground organization is obtained from a combination of global and local features. In this study, we searched for local features that predict figure-ground assignment in natural images. A large number of image patches were extracted from natural images along the boundary of perceptual objects and Principal Component (PC) Analysis was applied to these patches. Two sets of experiments were carried out. In the first (E1), only patches were included that did not contain any occlusion features (T-junctions) in the background. In the second (E2), both patches with and without occlusions in the background were included. As expected, the first principal component in both datasets is a step edge, and the second PC in E2 is a T-junction in the background. The next principal component (PC2 in E1 and PC3 in E2) in both datasets has uniform intensity on the background side, and a large contrast gradient on the figure side. This is the signature of an extremal edge [1]; the gradient is a local feature indicative of an object occluding a background. To test if these components are predictive of figure-ground segregation, statistical analyses of distributions obtained by the projection of patches on the respective PCs were performed. Both datasets, E1 and E2, show significant differences on Students t-test (p ≤ 10−22) and the Bayesian t-test (JZSbƒ ≤ 10−19) between figure and background distributions. We conclude that: (1) next to the T-junction the second strongest local feature in natural images predictive of figure ground organization is a luminance gradient of the figure side; (2) figure-side gradients are prevalent irrespective of the presence or absence of occlusion features.	electrical junction;experiment;gradient;pc²;principal component analysis	Sudarshan Ramenahalli;Stefan Mihalas;Ernst Niebur	2011	2011 45th Annual Conference on Information Sciences and Systems	10.1109/CISS.2011.5766185	computer vision;bayesian probability;computer science;machine learning;pattern recognition;mathematics;statistics	Vision	39.50480383873381	-54.485383475078955	128315
c4cbb1c0606ac37d33bb6542359c98d7bb1b94f7	quasi-invariant properties and 3-d shape recovery of non-straight, non-constant generalized cylinders	application software;intelligent robots;computational geometry;shape recovery;contracts;2 d contours nonstraight nonconstant cylinders 3 d shape recovery geometric protective properties contours right generalized cylinders rigourous quasi invariant properties 2 d descriptions 3 d object centered descriptions;psychology;computer vision;protection;shape;monitoring;image reconstruction;image reconstruction computational geometry computer vision;intelligent systems;shape intelligent robots humans intelligent systems application software computer vision psychology monitoring contracts us government;cross section;humans;us government	We address geometric projective properties of the contours of Right generalized cylinders with a Planar, but not necessarily straight, axis and Circular, but possibly varying size, cross-sections (called Circular PRGCs). Previous work has addressed primitives with either a straight axis, such as SHGCs, or a constant size cross-section such as PRCGCs. in this work, we derive important rigorous quasiinvariant properties of Circular PRGCs, invariant properties firr their subclasses and show their application for 2 0 descriptions and for recovery of complete 3 0 object centered descriptions from the 20 contours. We demonstrate our claims on some examples.	apache axis	Mourad Zerroug;Ramakant Nevatia	1993		10.1109/CVPR.1993.340973	iterative reconstruction;computer vision;application software;simulation;computational geometry;shape;computer science;mathematics;cross section;geometry	Vision	51.6639113111749	-54.41002745562623	128408
0ede9ab18ab60007769b024c559eaf21dcde3c2b	generation of 3d building model using 3d line detection scheme based on line fitting of elevation data	analisis imagen;modelizacion;ajustamiento modelo;fiabilidad;reliability;multimedia;image processing;grouping;ajustamiento curva;edge detection;analisis cuantitativo;procesamiento imagen;line detection;fotografia aerea;traitement image;self consistent;deteccion contorno;ajustement modele;modelisation;aerial image;detection contour;self consistency;image generation;photographie aerienne;autocoherencia;analyse quantitative;fiabilite;model matching;3d building model;segment droite;quantitative analysis;autocoherence;ajustement courbe;segmento recta;image analysis;accuracy analysis;line segment;agrupamiento;curve fitting;modeling;analyse image;extraction method;aerial photography;groupage	This paper presents a new 3D line segment extraction method, which can be used in generating 3D rooftop model. The core of our method is that 3D line segment is extracted by using line fitting of elevation data on 2D line coordinates of ortho-image. In order to use elevation in line fitting, the elevation itself should be reliable. To measure the reliability of elevation, in this paper, we employ the concept of self-consistency. We test the effectiveness of the proposed method with a quantitative accuracy analysis using synthetic images generated from Avenches data set of Ascona aerial images. Experimental results indicate that our method generates 3D line segments almost 10 times more accurate than raw elevations obtained by area-based method. Also, our proposed method shows much improved accuracy over the cooperative hybrid stereo method. Using a simple 3D line grouping scheme, 3D line segments are shown to generate a precise 3D building model effectively.	edge detection;line fitting	Dong-Min Woo;Seung Soo Han;Young-Kee Jung;Kyu-Won Lee	2005		10.1007/11581772_49	novikov self-consistency principle;computer vision;image analysis;systems modeling;edge detection;line segment;image processing;computer science;quantitative analysis;reliability;aerial photography;curve fitting	Vision	49.29492917731331	-58.24840902009563	128432
68a2257ad4987071f9f2a2f3a22d57bcd9f6b12f	walrus: a similarity retrieval algorithm for image databases	dynamic programming;pattern clustering;clustering walrus similarity retrieval algorithm image databases content based image querying texture features shape features user specified scenes object translation image matching regions region extraction sliding windows dynamic programming algorithm wavelet based signature retrieval real life data sets;image matching;dynamic programming algorithm;image database;image colour analysis image matching visual databases content based retrieval image retrieval feature extraction dynamic programming image texture pattern clustering natural scenes;similarity retrieval;image texture;clustering;image colour analysis;feature extraction;region matching;information retrieval image retrieval image databases layout shape robustness area measurement data mining dynamic programming clustering algorithms;similarity measure;content based retrieval;wavelets;natural scenes;sliding window;visual databases;image retrieval	Approaches for content-based image querying typically extract a single signature from each image based on color, texture, or shape features. The images returned as the query result are then the ones whose signatures are closest to the signature of the query image. While efficient for simple images, such methods do not work well for complex scenes since they fail to retrieve images that match the query only partially, that is, only certain regions of the image match. This inefficiency leads to the discarding of images that may be semantically very similar to the query image since they may contain the same objects. The problem becomes even more apparent when we consider scaled or translated versions of the similar objects. We propose WALRUS (wavelet-based retrieval of user-specified scenes), a novel similarity retrieval algorithm that is robust to scaling and translation of objects within an image. WALRUS employs a novel similarity model in which each image is first decomposed into its regions and the similarity measure between a pair of images is then defined to be the fraction of the area of the two images covered by matching regions from the images. In order to extract regions for an image, WALRUS considers sliding windows of varying sizes and then clusters them based on the proximity of their signatures. An efficient dynamic programming algorithm is used to compute wavelet-based signatures for the sliding windows. Experimental results on real-life data sets corroborate the effectiveness of WALRUS'S similarity model.	algorithm	Apostol Natsev;Rajeev Rastogi;Kyuseok Shim	2004	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2003.1262183	computer vision;image retrieval;computer science;machine learning;dynamic programming;pattern recognition;information retrieval	DB	39.87263191810899	-60.32444864679955	128434
8fa36e8998a0178c412f2a2ed25407f79a52f50b	a new method for recognition partially occluded curved objects under affine transformation	robust hausdorff distance partially occluded curved object recognition affine transformation affine distorted object recognition;partially occluded;recognition;object recognition affine transforms;affine transformation;transforms shape robustness pattern recognition image recognition mathematical model distortion;hausdorff distance;hausdorff distance recognition partially occluded affine transformation	A new method dealing with recognition of partially occluded and affine distortion objects is presented. The method is designed for objects with smooth curved boundary. It divides an object into affine-invariant parts based on the feature point. And a new approach for matching each part is presented in this paper. Robust Hausdorff distance (RHD) is introduced to measure the similarity between feature points set of model and that of target. In terms of the new RHD, the optimal affine transform can be estimated. And then the sub-curve match pairs are calculated based on the optimal affine transformation. The experimental results show proposed algorithm are capable of coping with partial occlusion and affine transformation.	algorithm;distortion;feature model;hausdorff dimension	Gui-mei Zhang;Jiyuan Xu;Jianxin Liu	2015	2015 10th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)	10.1109/ISKE.2015.52	affine space;computer vision;complex space;topology;affine coordinate system;affine involution;affine plane;affine geometry of curves;affine hull;affine transformation;harris affine region detector;mathematics;geometry;3d single-object recognition;affine shape adaptation;affine combination;hessian affine region detector	Robotics	41.38572748489044	-57.27269179152675	128497
1daa4bac01ed36834c0b80d494105821545f0489	neighborhood decomposition of 3d convex structuring elements for morphological operations	analisis imagen;image tridimensionnelle;mathematical morphology;optimisation;decomposition;image processing;optimizacion;cost function;3d imaging;analisis forma;procesamiento imagen;morphological operation;traitement image;voxel;structuring element;optimization problem;erosion;programacion lineal;mathematical programming;convex polyhedron;linear programming;programmation lineaire;tridimensional image;image analysis;optimization;pattern analysis;dilation;analyse image;programmation mathematique;programacion matematica;analyse forme;imagen tridimensional	Morphological operations with 3D images require a huge amount of computation. The decomposition of structuring elements used in the morphological operations such as dilation and erosion greatly reduces the amount of computation. This paper presents a new method for the decomposition of a 3D convex structuring element into a set of neighborhood structuring elements. A neighborhood structuring element is a convex structuring element consisting of a subset of a set consisting of the origin voxel and its 26 neighborhood voxels. First, we derive the set of decomposition conditions on the lengths of the original and the basis convex structuring elements, and then the decomposition problem is converted to linear integer optimization problem. The objective of the optimization is to minimize a cost function representing the optimal criterion for the implementation of morphological operations. Thus, our method can be used to obtain the different optimal decompositions minimizing the amount of computation in different cases.		Syng-Yup Ohn	2005		10.1007/11556121_79	stereoscopy;optimization problem;computer vision;mathematical optimization;image analysis;convex polytope;mathematical morphology;erosion;image processing;computer science;linear programming;mathematics;dilation;decomposition;voxel;structuring element;algorithm	Vision	48.922874713186296	-62.760781003119206	128549
3b6bfcc6b97e9ce4a3041adbf083264de374ebe2	probabilistic tensor voting for robust perceptual grouping	tensile stress vectors standards noise manifolds probabilistic logic noise reduction;image segmentation;tensile stress;standards;manifolds;vectors bayes methods image segmentation tensors;probabilistic meaning;bayes methods;unsupervised segmentation;2nd order symmetric tensor;nonparametric outlier filtering;3d space;2d space;vectors;probabilistic tensor voting;polarity vector;noise reduction;robust perceptual grouping;nonparametric algorithm;standard tensor voting bayesian extension;inlier denoising;probabilistic logic;outlier noise;polarity vector probabilistic tensor voting robust perceptual grouping unsupervised segmentation 2d space 3d space nonparametric outlier filtering inlier denoising nonparametric algorithm local data geometric structure standard tensor voting bayesian extension probabilistic meaning geometric meaning outlier noise 2nd order symmetric tensor;geometric meaning;local data geometric structure;noise;tensors	We address the problem of unsupervised segmentation and grouping in 2D and 3D space, where samples are corrupted by noise, and in the presence of outliers. The problem has attracted attention in previous research work, but non-parametric outlier filtering and inlier denoising are still challenging. Tensor voting is a non-parametric algorithm that can infer local data geometric structure. Standard tensor voting considers outlier noise explicitly, but may suffer from serious problems if the inlier data is also noisy. In this paper, we propose probabilistic Tensor Voting, a Bayesian extension of standard tensor voting, taking into consideration both probabilistic and geometric meaning. Probabilistic tensor voting explicitly considers both outlier and inlier noise, and can handle them simultaneously. In the new framework, the representation consists of a 2nd order symmetric tensor, a polarity vector, and a new type 2 polarity vector orthogonal to the first one. We give a theoretical interpretation of our framework. Experimental results show that our approach outperforms other methods, including standard tensor voting.	algorithm;algorithmic efficiency;basis pursuit denoising;computation;list of sega arcade system boards;nsa product types;noise reduction;unsupervised learning	Dian Gong;Gérard G. Medioni	2012	2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2012.6238926	computer vision;tensor;manifold;computer science;noise;machine learning;pattern recognition;noise reduction;mathematics;image segmentation;probabilistic logic;stress;statistics	Vision	45.372967893344835	-52.62022298052342	128670
992b11129239f2fc7ccaaf114e9e1686a90d2e08	retrieving geometric distortion properties from image moments	image moments;pattern recognition;geometric distortion	This paper presents a novel technique to determine image distortion properties, such as translation, scale, rotation and skew properties, by only using its moments. The properties are retrieved by solving the algebraic relationships between moment functions of original and geometrically distorted images. These properties, to the best of our knowledge, have yet to be presented in any papers. The derived distortion properties are experimentally validated using randomly scaled, rotated and skewed images. Promising results are produced from these experiments.	distortion;image moment	Hock-Ann Goh;Rosli Besar;Fazly Salleh Abas;Lee-Yeng Ong	2009	IEICE Electronic Express	10.1587/elex.6.774	velocity moments;combinatorics;discrete mathematics;computer science;image moment;mathematics;geometry	Theory	50.65289802261124	-61.57333145601	128713
7694aaa97f1ac4f95a7eab8b347194b00f2b801c	touchless-to-touch fingerprint systems compatibility method		Touchless multiview fingerprinting technology has been proposed as an alternative to overcome intrinsic problems of traditional touchbased systems. However, if one wants to benefit from the advantages presented by touchless scanners, the captured images must be processed in order to become compatible to touchbased systems. This paper proposes a two-step solution to the touchless-to-touch compatibility problem. First, it reproduces the texture of touchbased acquisition; and second, it performs a geometric transformation in order to approximate the nail-to-nail touchbased enrollment process. Two experiments were proposed, one to evaluate the quality of the processed images, another one to estimate the EER (equal error rate) for a set of 200 fingerprints (100 fingers, 2 images per finger). Results show that 90% of the images presented good, very good or excellent scores according to NFIQ. In addition, the observed EER was approximately 4%, demonstrating the viability of the proposed method.	approximation algorithm;enhanced entity–relationship model;experiment;fingerprint (computing);multiview video coding	P. Salum;D. Sandoval;Alexandre Zaghetto;Bruno Macchiavello;Caue Zaghetto	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296943	computer vision;geometric transformation;pattern recognition;software;artificial intelligence;word error rate;interoperability;nist;fingerprint recognition;computer science;compatibility (mechanics)	Robotics	42.42939590227304	-52.43894652349465	128855
9ea5b077fd994cab539c2ea95f9f0829bc02a39e	blobworld: a system for region-based image indexing and retrieval	analisis imagen;image recognition;object recognition;reconocimiento imagen;high dimensionality;image processing;automatic segmentation;texture image;procesamiento imagen;image indexing;reconnaissance objet;feature space;traitement image;image texture;large scale;region of interest;indexation;reconnaissance image;pattern recognition;image analysis;reconnaissance forme;reconocimiento patron;analyse image;image retrieval	Blobworld is a system for image retrieval based on finding coherent image regions which roughly correspond to objects. Each image is automatically segmented into regions (“blobs”) with associated color and texture descriptors. Querying is based on the attributes of one or two regions of interest, rather than a description of the entire image. In order to make large-scale retrieval feasible, we index the blob descriptions using a tree. Because indexing in the high-dimensional feature space is computationally prohibitive, we use a lower-rank approximation to the high-dimensional distance. Experiments show encouraging results for both querying and indexing.	approximation;coherence (physics);feature vector;image retrieval;region of interest	Chad Carson;Megan Thomas;Serge J. Belongie;Joseph M. Hellerstein;Jitendra Malik	1999		10.1007/3-540-48762-X_63	image texture;computer vision;feature detection;visual word;image analysis;feature vector;image processing;image retrieval;computer science;cognitive neuroscience of visual object recognition;pattern recognition;automatic image annotation;information retrieval;region of interest	Vision	42.89925339077892	-60.79873573513198	128927
3b7ef315f1dae0501857cdfeea7d869ef456502b	intelligent acquisition and learning of fluorescence microscope data models	modelizacion;filtre particule;fotoblanqueo;algorithms artificial intelligence microscopy fluorescence models theoretical photobleaching reproducibility of results;evaluation performance;systeme intelligent;microscopie;fluorescence;performance evaluation;photoblanchiment;learning;debit information;information transmission;evaluacion prestacion;active learning;sistema inteligente;biological system modeling;microscopy;filtro particulas;time series;indice informacion;inspection;microscopio;microscope;data model;algorithme;aprendizaje;modelisation;algorithm;apprentissage;intelligent acquisition;model building;fluorescence microscopy;particle filter;visual inspection;fluorescence microscope;particle filter active learning fluorescence microscopy image modeling intelligent acquisition;serie temporelle;intelligent systems;intelligent system;serie temporal;phototoxicity fluorescence microscope intelligent acquisition active learning photobleaching;mathematical model;visual control;information rate;photobleaching;controle visuel;fluorescence microscopy data models biological system modeling mathematical model intelligent systems photobleaching algorithm design and analysis buildings inspection;transmision informacion;phototoxicity;transmission information;time series data acquisition fluorescence optical microscopes optical microscopy;high throughput;modeling;image modeling;data acquisition;algorithm design and analysis;optical microscopy;microscopia;buildings;control visual;data models;algoritmo;optical microscopes	We propose a mathematical framework and algorithms both to build accurate models of fluorescence microscope time series, as well as to design intelligent acquisition systems based on these models. Model building allows the information contained in the 2-D and 3-D time series to be presented in a more useful and concise form than the raw image data. This is particularly relevant as the trend in biology tends more and more towards high-throughput applications, and the resulting increase in the amount of acquired image data makes visual inspection impractical. The intelligent acquisition system uses an active learning approach to choose the acquisition regions that let us build our model most efficiently, resulting in a shorter acquisition time, as well as a reduction of the amount of photobleaching and phototoxicity incurred during acquisition. We validate our methodology by modeling object motion within a cell. For intelligent acquisition, we propose a set of algorithms to evaluate the information contained in a given acquisition region, as well as the costs associated with acquiring this region in terms of the resulting photobleaching and phototoxicity and the amount of time taken for acquisition. We use these algorithms to determine an acquisition strategy: where and when to acquire, as well as when to stop acquiring. Results, both on synthetic as well as real data, demonstrate accurate model building and large efficiency gains during acquisition.	acquired image;algorithm;contain (action);fluorescence;high-throughput computing;mathematics;microscope device component;raw image format;synthetic data;throughput;time series;visual inspection	Charles Jackson;Robert F. Murphy;Jelena Kovacevic	2009	IEEE Transactions on Image Processing	10.1109/TIP.2009.2024580	fluorescence microscope;computer vision;simulation;computer science;microscopy;statistics	Vision	46.697862785717426	-57.027640706941696	128951
51a9de3b6ffd4b87f024cbde2157d03412b1384f	recognizing occluded 3d faces using an efficient icp variant	databases;3d face recognition;occlusion;probes;visual databases face recognition iterative methods;iterative methods;accuracy;shape representation;face recognition;surface registration;shape;bosphorus database occluded 3d face recognition efficient icp variant iterative closest point computational efficiency spherical depth map sdm facial surface rejection strategy face outliers;iterative closest point;iterative closest point algorithm face recognition shape databases accuracy probes robustness;robustness;iterative closest point algorithm;visual databases;occlusion 3d face recognition surface registration shape representation iterative closest point	This paper proposes an efficient variant of the Iterative Closest Point (ICP) algorithm for 3D face recognition in the presence of occlusion. The new ICP variant improves the original one in two aspects: the computational efficiency and the robustness to occlusion changes. For the former one, a facial surface is firstly described as a Spherical Depth Map (SDM), based on which uniform down-sampling can be conveniently applied to remove redundant vertices, aiming to decrease the consumed time of ICP. For the latter one, since occlusions can be considered as face outliers, a rejection strategy is embedded into ICP to eliminate their impacts. The proposed method is validated in face verification and identification scenarios on the Bosphorus database, and the experimental results clearly demonstrate its effectiveness and efficiency.	algorithm;computation;depth map;embedded system;facial recognition system;iterative closest point;iterative method;rejection sampling;sampling (signal processing);three-dimensional face recognition	Peijiang Liu;Yunhong Wang;Di Huang;Zhaoxiang Zhang	2012	2012 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2012.158	facial recognition system;computer vision;shape;computer science;machine learning;pattern recognition;mathematics;accuracy and precision;iterative method;iterative closest point;robustness	Robotics	41.58686775250968	-57.00834321707776	129126
3173313860a3f4dd6ac32ddc44bd6c6690ce0c63	ε-isometryε-isometry based shape approximation for image content representation	e isometry;multi scale;dominant point detection;polygonal approximation;planar shape representation	Shape approximation is usually a prerequisite step to image content analysis and understanding and has been well studied in the passed decades. However, those approaches show their deficiencies while facing the factors such as the representation efficiency, the variation of image scale and the initial estimation. To alleviate these issues, we propose a novel method for e-isometrye-isometry based shape approximation. We first analyze the descending property on approximating error and its relation with salient geometric features. After that, we approximate the polygonal shape and detect the feature point based on the e-isometrice-isometric construction. In the experiments, we employ traditional shape benchmarks, MPEG7 shape dataset, SQUID dataset and other real contours to evaluate the visual effects and quantitative performances of the proposed method. Experimental results demonstrate that our method is not only robust to the initial estimation, but also outperforms the state-of-the-art methods with respect to the compactness and scale variability.	approximation	Shijie Hao;Jianguo Jiang;Yanrong Guo;Shu Zhan	2013	Signal Processing	10.1016/j.sigpro.2012.04.011	active shape model;computer vision;mathematical optimization;combinatorics;shape analysis;mathematics;geometry	Vision	41.79060678850062	-57.315113754746875	129312
f2c22eb5e7762370595559938b952e0df50dd026	an approach fractal and analysis of variogram for edge detection of biomedical images	local fractal dimension;medical imagery;detecteur image;aplicacion medical;edge detection;biomedical imaging;dimension fractal;deteccion contorno;fractal dimension;image biomedicale;detection contour;variogram;gabor filter;variogramme;filtre gabor;imagerie medicale;medical application;detector imagen;imageneria medical;dimension fractale;gabor filtering;biomedical images;image sensor;application medicale	In this work, we study a fractal approach of edge detection. This approach is based on the evaluation of the local fractal dimension (in every pixel of the image) by using Gabor filtering. Gabor Filters use several parameters, as: radial frequency p and angular frequency θ. As we will see the choice of these parameters influence directly on the edge detection. Our contribution is using a mathematical tool said variogram that is going to guide us in the selection of the angular frequency θ. The method is based on exploitation of local indications that permits to affirm the existence of edge in an image on a direction θ. Results of edge detection are better since there is extraction in privileged directions of the image.	edge detection;fractal	Latifa Hamami;Nadia Lassouaoui	2001		10.1007/3-540-45723-2_40	medical imaging;computer vision;edge detection;fractal analysis;computer science;variogram;pattern recognition;image sensor;mathematics;geometry;fractal dimension;statistics	Vision	46.50838812150521	-63.433094928742555	129507
112f8a7567b5ba80336a38cd63d331e05951a9a4	medical image classification using birth-and-death mcmc	analytical models;rigid gaussian distributions birth and death mcmc breast cancer diagnosis american women screening mammography medical mammogram image classification generalized beta mixture model texture extraction mammographic images earth mover distance metric gaussian texture characteristics;bayesian methods breast cancer analytical models data models markov processes medical diagnostic imaging;cancer;bayes methods;bayesian methods;image classification;medical image processing bayes methods cancer feature extraction gaussian distribution gynaecology image classification image texture mammography;gynaecology;image texture;mixture modeling;feature extraction;medical image processing;beta distribution;mcmc;markov processes;mammography;bayesian analysis;breast cancer;gaussian distribution;mammograph;medical diagnostic imaging;data models;mcmc image classification mammograph beta distribution mixture modeling bayesian analysis	Breast cancer is one of the main causes of death among American women. The use of screening mammography is widely recommended for early diagnosis of breast cancer. In this paper, we propose a highly efficient algorithm for medical mammogram image classification, based on the generalized Beta mixture model. The proposed method, first extracts texture information from mammographic images then model it using the generalized Beta mixture models. For classification, we use the Earth Mover Distance (EMD) metric. Our work is motivated by the fact that mammographic images contain non-Gaussian texture characteristics, impossible to model using rigid distributions like the Gaussian. Experimental results are provided to show the merits of the proposed approach.	algorithm;computer vision;estimation theory;markov chain monte carlo;medical imaging;mixture model;model selection;overfitting;virtual screening	Tarek Elguebaly;Nizar Bouguila	2012	2012 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2012.6271691	computer vision;bayesian probability;computer science;pattern recognition;mathematics;statistics	Vision	40.66210060910756	-63.81267557707924	129541
5b6099da1ce03b13d2970b2efe6cad213d86b7d3	unsupervised feature reduction in image segmentation by local transforms	dimensionalidad;texture;karhunen loeve transformation;image segmentation;image processing;karhunen loe grave;ve transform;procesamiento imagen;dimensionality;segmentation;traitement image;feature vector;feature reduction;dimensionality reduction;dimensionnalite;composante principale;segmentation image;textura;vecteur caracteristique;principal components;lkl transform;transformation karhunen loeve;lts1;reduction dimensionnalite;transformacion karhunen loeve;segmentacion;principal component	The automatic segmentation of an image into regions that are homogeneous according to certain properties, such as gray level, texture or color, is an important step in machine vision, and has consequently been the topic of an intensive research . In the general case the segmentation chain includes three steps : Feature extraction, Feature selection, and Segmentation/Classification . The choice for the feature extraction techniques is quite large . Without being complete we refer to [16,21,2] for an extensive exposure of this step . Likewise, several segmentation algorithms have been developed . These can segment images successfully based on multi-dimensional feature spaces in an unsuper-	algorithm;feature extraction;feature selection;grayscale;image segmentation;machine vision;unsupervised learning	Josef Bigün	1993	Pattern Recognition Letters	10.1016/0167-8655(93)90108-P	computer vision;speech recognition;image processing;computer science;machine learning;pattern recognition;mathematics;principal component analysis	Vision	44.67164556306461	-61.7349138426311	129624
8566cdbf0cbfd880077b2b0cb2c79ee36094e051	an improved method of angle detection on digital curves	angle detection;picture processing;digital curves;pattern recognition;curvature;angle detection curvature digital curves pattern recognition picture processing	"""This correspondence describes an improved method of detecting """"angles""""—i.e., maxima of the difference between successive nonoverlapping average slopes—on a digital curve. The method is similar to, but gives better results than, a method described in an earlier paper."""	maxima;sensor	Azriel Rosenfeld;Joan S. Weszka	1975	IEEE Transactions on Computers	10.1109/T-C.1975.224342	computer vision;computer science;mathematics;geometry;curvature	Visualization	48.218389770154474	-62.617651636687306	129666
f35143088dce9b715271469a9bd114df578cd448	locating ceramics system based on computer vision	null	In this paper, a locating ceramics system based on computer vision is introduced. The system is used to indirectly measure the ceramics' poses on the automatic product line of the robot spraying unburned ceramics. The structure, locating principle and method of the system are described and some application results are given. The locating principle of the system adopts the camera calibration, image segmentation through finding the valley at an image saturation histogram, and the image morphological operation. The locating ceramics system based on computer vision has been applied in practice.	camera resectioning;computer vision;heap spraying;image histogram;image segmentation;real-time locating system;robot;veracity	Haifeng Wang;Wenjuan Lu;Feng Chuan	2004	IEEE Conference on Robotics, Automation and Mechatronics, 2004.		computer vision;camera resectioning;simulation;machine vision;computer science;engineering;image segmentation;computer graphics (images)	Robotics	43.49269242823374	-65.5102208432083	129752
e7eba07baba2a57943e608e1579b51ffaa466534	classification of mpeg video content using divergence measure with data covariance	medida informacion;analisis contenido;cluster algorithm;fuzzy c mean;centro gravitacional;analyse amas;covariancia;multimedia;centre gravite;distance measure;mesure information;mpeg video;deporte;center of mass;logique floue;gradiente;false alarm rate;logica difusa;covariance;gradient;classification;fuzzy logic;content analysis;cluster analysis;senal video;signal video;information measure;video signal;analisis cluster;sport;analyse contenu;reseau neuronal;taux fausse alarme;data classification;porcentaje falsa alarma;clasificacion;red neuronal;neural network	This paper describes how the covariance information in MPEG video data can be incorporated into a distance measure and applies the resulting divergence measure to video content classification problems. The divergence measure is adopted into two different clustering algorithms, the Centroid Neural Network (CNN) and the Gradient Based Fuzzy c-Means (GBFCM) for MPEG video data classification problems, movie or sports. Experiments on 16 MPEG video traces show that the divergence measure with covariance information can decrease the False Alarm Rate (FAR) in classification as much as 46.6% on average.		Dong-Chul Park;Chung-Nguyen Tran;Yunsik Lee	2005		10.1007/11581772_85	fuzzy logic;center of mass;content analysis;computer science;artificial intelligence;video quality;covariance;sport;machine learning;data mining;mathematics;cluster analysis;gradient	Vision	44.60569592949072	-62.41142690245283	129907
78ddad6e373b228219a197ccb491a53a9fbf05bb	computing the eccentricity transform of a polygonal shape	eccentricity transform;polygon;distance transform;pepper	The eccentricity transform associates to each point of a shape the distance to the point farthest away from it. The transform is defined in any dimension, for open and closed manyfolds, is robust to Salt & Pepper noise, and is quasi-invariant to articulated motion. This paper presents and algorithm to efficiently compute the eccentricity transform of a polygonal shape with or without holes. In particular, based on existing and new properties, we provide an algorithm to decompose a polygon using parallel steps, and use the result to derive the eccentricity value of any point. keywords: eccentricity transform, distance transform, polygon.	algorithm;distance (graph theory);distance transform;salt-and-pepper noise;shortest path problem	Walter G. Kropatsch;Adrian Ion;Samuel Peltier	2007		10.1007/978-3-540-76725-1_31	computer vision;mathematical optimization;computer science;polygon;mathematics;geometry;distance transform	Vision	49.90466531847432	-62.883547682535145	129928
b913e014fb47e44bf40ee77243a2d21ef321408d	multiscale image segmentation using wavelets and watersheds	image segmentation;image resolution;wavelet decomposition;wavelet transforms;wavelet transforms image segmentation image resolution image denoising pattern recognition;wavelet transform;watershed segmentation;pattern recognition;noisy image multiscale image segmentation wavelet transform watershed segmentation image resolution inverse wavelet transform;image segmentation image resolution wavelet transforms frequency image edge detection shape measurement filters energy resolution position measurement size measurement;image denoising	This paper proposes a new multiscale segmentation technique based on wavelet decompositions and watersheds. The wavelet transform is applied to the image, producing detail and approximation coefficients. The watershed is applied to the approximation image at a certain resolution 2 , and projected up to higher resolutions using the inverse wavelet transform. At lower resolutions, the segmentation captures large relevant objects, while at higher resolution more details are obtained. Since downsizing is inherent to the wavelet transform, watershed segmentation is applied to a smaller image, demanding less computational time. The proposed technique appears to be robust for noisy images, even when the amount of noise is very large.	approximation;coefficient;color image;computation;computer graphics;image processing;image segmentation;multiresolution analysis;time complexity;watershed (image processing);wavelet transform	Cláudio Rosito Jung	2003		10.1109/SIBGRA.2003.1241020	image texture;wavelet;image restoration;computer vision;feature detection;second-generation wavelet transform;binary image;continuous wavelet transform;segmentation-based object categorization;pattern recognition;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;image segmentation;image fusion;scale-space segmentation;discrete wavelet transform;lifting scheme;top-hat transform;wavelet transform;computer graphics (images)	Vision	52.31970774083071	-65.46419431325913	129936
6080cc739c78807388e66161bb1775216905f7bb	a fuzzy mapping from image texture to affective thesaurus	texture features;image texture;indexation;image analysis	Most of the image analysis methods focus on affective information by using color. In this paper a new indexing scheme, called FRD (Fuzzy Recognize Degree)-Clustering is proposed for affection-assisted semantic image analysis on the basis of the texture feature. A set of perceptual relevant features, used for indexing is hence introduced: directionality, contrast and coarseness. This FRD scheme allows us to retrieve images based on high-level affective concepts. Experiments with images of the nature and landscape domain demonstrate the performance of the proposed approach.	image texture;thesaurus	Haifang Li;Jin Li;Jiancheng Song;Junjie Chen	2007		10.1007/978-3-540-74769-7_39	image texture;computer vision;pattern recognition;mathematics;information retrieval	Vision	39.820827686684325	-61.49230696559499	129965
2627a04fb2b015baa1e7af2b5f86792a6c260c69	geometric analysis of continuous, planar shapes	analyse amas;geodesic structure;numerical method;longitud;morfoscopia;differential geometry;shape analysis;estructura geodesica;courbure;forma geometrica;classification;length;connecting;geodesique;cluster analysis;analisis morfologico;longueur;metodo numerico;geodesic;morphoscopie;structure geodesique;geodesico;geometrical shape;morphological analysis;geometrie differentielle;analyse morphologique;curvatura;curvature;analisis cluster;forme geometrique;geometria diferencial;acometida;branchement;clasificacion;methode numerique	We propose two differential geometric representations of planar shapes using: (i) direction functions and (ii) curvature functions, of their boundaries. Under either representation, planar shapes are treated as elements of infinite-dimensional shape spaces. Pairwise differences between the shapes are quantified using the lengths of geodesics connecting them on the shape spaces. We specify the geometry of the two shape spaces and utilize numerical methods for finding geodesics on them. Some applications of this shape analysis are illustrated including: (i) interpolation between shapes, (ii) clustering of objects according to their shapes, and (iii) computation of intrinsic mean shapes.	british machine vision conference;cluster analysis;computable function;computation;david g. kirkpatrick;extrapolation;friedrich kittler;geometric analysis;image analysis;international journal of computer vision;interpolation;matching (graph theory);numerical method;optimal matching;pattern matching;planar (computer graphics);planar graph;scale space;shape context;springer (tank)	Anuj Srivastava;Washington Mio;Eric Klassen;Shantanu H. Joshi	2003		10.1007/978-3-540-45063-4_22	differential geometry;combinatorics;geodesic;topology;biological classification;numerical analysis;morphological analysis;computer science;length;shape analysis;mathematics;geometry;curvature;cluster analysis	Graphics	49.46415394874057	-61.00407693520507	129975
8e078e1fc0462187f64274b16edad66cc2d2c562	a fuzzy segmentation of salient region of interest in low depth of field image	transformation ondelette;contenu image;fuzzy theory;image content;deteccion blanco;fuzzy set;image segmentation;multimedia;edge detection;depth of field;logique floue;conjunto difuso;mean shift;logica difusa;image indexing;ensemble flou;unsupervised segmentation;segmentation;region interes;profondeur champ;deteccion contorno;detection cible;fuzzy logic;detection contour;indexing;target recognition;busqueda por contenido;wavelet modulus maxima;region of interest;indexation;indizacion;pattern recognition;profundidad campo;transformacion ondita;reconnaissance forme;region interet;reconocimiento patron;contenido imagen;target detection;content based retrieval;fuzzy segmentation;recherche par contenu;segmentacion;wavelet transformation;interest region	Unsupervised segmenting region of interest in images is very useful in content-based application such as image indexing for content-based retrieval and target recognition. The proposed method applies fuzzy theory to separate the salient region of interest from background in low depth of field (DOF) images automatically. First the image is divided into regions based on mean shift method and the regions are characterized by color features and wavelet modulus maxima edge point densities. And then the regions are described as fuzzy sets by fuzzification. The salient region interest and background are separated by defuzzification on fuzzy sets finally. The segmentation method is full automatic and without empirical parameters.	region of interest	KeDai Zhang;Hanqing Lu;Zhenyu Wang;Qi Zhao;MiYi Duan	2007		10.1007/978-3-540-69423-6_76	fuzzy logic;computer vision;search engine indexing;range segmentation;edge detection;mean-shift;computer science;pattern recognition;depth of field;fuzzy set;image segmentation;segmentation;region of interest	Vision	44.14521634457897	-61.70634758032243	129980
c8b988ed419757efd22adac7f3df954c39879fcb	automated registration of dissimilar images: application to medical imagery	optimisation;medical imagery;analisis escena;analyse scene;metodo simplejo;image processing;optimizacion;deteccion;procesamiento imagen;simplex method;detection;traitement image;image sequence;modificacion;estimacion parametro;imagerie medicale;secuencia imagen;optimization;imageneria medical;parameter estimation;estimation parametre;methode simplexe;sequence image;scene analysis;modification	Abstract   A modeling approach for the registration of dissimilar images is presented. Registration is viewed as the estimation of the parameters of a mathematical model in the presence of outliers (i.e., the changes to be detected). Thus the methodology of modeling can be directly transposed in the field of image registration and permits the use of complex registration models. A 6-parameters registration model consisting of a bidimensional translation, a rotation, a magnification, and a linear transformation of the gray levels is developed. The estimation of the registration parameters is performed by optimizing recently developed robust similarity measures. This optimization can be carried out by using either an adaptive random search strategy or an adaptation of the simplex procedure. Examples of application are given at each step for the registration of digitized video images. They evidence the properties of robustness of the approach proposed in this paper.	medical imaging	Michel Herbin;Alain Venot;J. Y. Devaux;Eric Walter;J. F. Lebruchec;Louis Dubertret;J. C. Roucayrol	1989	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(89)90055-8	computer vision;image processing;computer science;image registration;artificial intelligence;mathematics;estimation theory;simplex algorithm	Vision	50.050091071091565	-58.18401313574951	130129
dfaa0448784778cae77ea4f66b46320672005811	an improved object detection and contour tracking algorithm based on local curvature	gradient vector flow;active contour model;object detection	  Using the classical snake algorithm it is difficult to detect the contour of an object with complex concavities. Whereas the  GVF (Gradient Vector Flow) method successfully detects the concavity of a contour, but consumes lots of time to compute the  energy map. In this paper, we propose a fast snake algorithm to reduce computation time and to improve the performance of  detecting and tracking the contour. In order to represent the object’s contour accurately, a snake point inserting and deleting  strategy is also proposed. Simulation results from a sequence of images show that our method performs well in detecting and  tracking the object’s contour.    	algorithm;contour line;object detection	Jung-Ho Lee;Fang Hua;Jong-Whan Jang	2009		10.1007/978-3-642-10546-3_4	computer vision;pattern recognition;active contour model	Vision	44.96644387778455	-65.6015376928317	130168
0aee8df95e5831cbf17b62a8bd50107e8f7209c9	on automatic selection of temporal scales in time-causal scale-space	computer vision and robotics autonomous systems;mesure deplacement;medida velocidad;vision ordenador;estimation mouvement;image processing;estimacion movimiento;datorseende och robotik autonoma system;procesamiento imagen;motion estimation;mesure vitesse;robotics;traitement image;computer vision;speed measurement;scale space;displacement measurement;temporal scale;datavetenskap datalogi;robotica;vision ordinateur;medicion desplazamiento;robotique;computer science;motion detection	This paper outlines a general framework for automatic selection in temporal scale-space representations, and shows how the suggested theory applies to motion detection and motion estimation.	causal filter;scale space	Tony Lindeberg	1997		10.1007/BFb0017862	computer vision;scale space;simulation;image processing;computer science;motion estimation;robotics	Vision	49.15456017869826	-57.693390099015055	130260
c29e33fbd078d9a8ab7adbc74b03d4f830714cd0	3d shape constraint for facial feature localization using probabilistic-like output	mouth;shape constraints;3d shape constraint;probability;support vector machines;gaussian processes;application software;facial feature localization;active shape model 3d shape constraint facial feature localization probabilistic like output gaussian mixture model facial feature points;gaussian mixture model;3d model;shape;probability object detection feature extraction gaussian processes;feature extraction;shape facial features face detection facial animation mouth nose application software support vector machines support vector machine classification asia;facial animation;support vector machine classification;facial feature points;facial features;facial expression;face detection;active shape model;object detection;nose;asia;probabilistic like output	This work presents a method to automatically locate facial feature points under large variations in pose, illumination and facial expressions. First we propose a method to calculate probabilistic-like output for each pixel of image. This probabilistic-like output describes the possibility of the pixel to be the center of specified object. A Gaussian mixture model is used to approximate the distribution of probabilistic-like output. The centers of these Gaussians are assigned with a probabilistic-like measure and they are considered as candidate feature points. There might be one or more candidate feature points in each facial region. A 3D model of facial feature points is built to enforce constraints on the localization results of feature points. Compared with active shape model (ASM) and its variant methods, our method could accommodate larger variations in pose, lighting and face expressions. Moreover, it is less sensitive to initialization errors, accurate, and fast. It takes a computer with P4 CPU about 10 ms to locate the five feature points (two eye centers, two mouth corners and nose tip). The feature localization accuracy is comparable with the accuracy of manually labeled features and it is robust to noise (glasses, beards). Experiments on FERET gallery and PIE are reported in this paper as well.	active shape model;approximation algorithm;central processing unit;experiment;feret (facial recognition technology);feature recognition;mixture model;pixel	Longbin Chen;Lei Zhang;HongJiang Zhang;Mohamed Abdel-Mottaleb	2004	Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.	10.1109/AFGR.2004.1301548	active shape model;support vector machine;computer vision;face detection;application software;computer facial animation;feature extraction;shape;computer science;machine learning;pattern recognition;probability;mixture model;gaussian process;facial expression;feature;statistics	Vision	46.03835323125587	-53.00225063756725	130340
15b79c6733f3e42de776d6f35be99a8ad0ff8a48	projection distortion analysis for flattened image mosaicing from straight uniform generalized cylinders	monocular vision;perspective projection;localization;straight uniform generalized cylinder;upper bound;visualization;image representation;pattern recognition;cross section;cross sections;image mosaicing;coordinate system	eprints@whiterose.ac.uk https://eprints.whiterose.ac.uk/ Reuse Items deposited in White Rose Research Online are protected by copyright, with all rights reserved unless indicated otherwise. They may be downloaded and/or printed for private study, or other acts as permitted by national copyright laws. The publisher or other rights holders may allow further reproduction and re-use of the full text version. This is indicated by the licence information on the White Rose Research Online record for the item.	3d projection;algorithm;apache axis;circuit restoration;column (database);displacement mapping;distortion;document mosaicing;image plane;pattern recognition;scientific visualization;synthetic data	William Puech;Adrian G. Bors;Ioannis Pitas;Jean-Marc Chassery	2001	Pattern Recognition	10.1016/S0031-3203(00)00056-X	computer vision;perspective;visualization;internationalization and localization;computer science;monocular vision;coordinate system;mathematics;cross section;geometry;upper and lower bounds	AI	52.089863453813194	-57.60992181029375	130368
5b532f6a700e28cd0b98f98d8b5f6b2782e98efa	human body analysis with biomechanics criteria	animacion por computador;robot humanoide;morphologie;humanoid robot;vision ordenador;human movement;representation graphique;mouvement corporel;image processing;modelo 3 dimensiones;computer graphics;modele 3 dimensions;procesamiento imagen;virtual human;biomechanics;three dimensional model;cuerpo humano;biomecanique;traitement image;corps humain;computer vision;morphology;human motion;human body;image sequence;three dimensional reconstruction;graphical model;grafo curva;vision ordinateur;secuencia imagen;biomecanica;computer animation;morfologia;movimiento corporal;grafico computadora;infographie;body movement;graphics;sequence image;animation par ordinateur	Today in many applications the study of human movement using a computer vision and graphics techniques is very useful. One of these applications is the three-dimensional reconstruction of the structure of the human body and its movement using sequences of images and biomechanical graphics models. In this paper we present a whole and general system to study the human motion without markers but, in this case, we apply it to high-level competition. This kind of study needs special procedures to do the analysis and reconstruction of the person’s body, therefore the virtual human (avatar) must have similar anthropometrical characteristics than the person who is doing the movement. We define a process to adjust the humanoid to the morphology of the person. It could be very laborious and subjective if done manually or by selection of points, but in this article we present a global human motion system capturing, modeling and matching a semiautomatic process between the real person and the modeled humanoid or synthetic avatar. Semiautomatic means that the computers propose the best matching from previous frames and the user can accept it or not.	anthropometry;computer vision;galaxy morphological classification;graphics;high- and low-level;kinesiology;motion system;synthetic intelligence;virtual actor	Jose Maria Buades Rubio;Francisco J. Perales López;Manuel González Hidalgo;A. Aguiló;P. Martinez	2004		10.1007/978-3-540-30074-8_23	computer vision;human body;simulation;morphology;image processing;computer science;humanoid robot;graphics;artificial intelligence;biomechanics;computer animation;graphical model;computer graphics;computer graphics (images)	Vision	49.50750051882873	-55.66105598778371	130387
6b72b5f9d396fff2f1d88a0586e0e24976207c78	face learning using a sequence of images	ojo;acoplamiento grafo;variabilidad;probabilistic relaxation;graphe biparti;eye;presentation face;pistage;learning algorithm;position;grafo bipartido;localization;rastreo;posicion;localizacion;algorithme apprentissage;probabilistic approach;graph matching;face tracking;relajacion;face presentation;couplage graphe;human face;localisation;face representation;enfoque probabilista;approche probabiliste;presentacion cara;image sequence;invariante;relaxation;secuencia imagen;face;rotacion;variability;visage humain;rotation;variabilite;algoritmo aprendizaje;bipartite graph;oeil;invariant;tracking;sequence image;bipartite graph matching;cara	We present a face matching algorithm used in the face learning stage. For this, several images of the same person are acquired under head movement constraints, the user rotating his head from left to right. After a precise eyes location, the normalization of the face under rotation and scale is achieved, setting the right and the left eyes at a fixed position. For the recognition, we represent a face as a set of weighted salient points attributed with a local feature vector, giving an invariant description of the image (signal) around each point. In order to compute the variability of the component of the feature vector, as well as the weight associated to each point, denoting its relative importance in the face representation, we have developed a matching algorithm throughout the same sequence. It is formalized as a maximal matching in a bipartite graph and is approximated, due to a planarity constraint, by a probabilistic relaxation scheme.	3d reconstruction;approximation algorithm;computation;corner detection;feature vector;harris affine region detector;linear programming relaxation;matching (graph theory);maximal set;nl (complexity);numerical aperture;pattern matching;planar graph;probabilistic automaton;semantics (computer science);spatial variability;structure from motion	Robert Mariani	2000	IJPRAI	10.1142/S0218001400000416	face;computer vision;facial motion capture;internationalization and localization;bipartite graph;rotation;position;machine learning;invariant;relaxation;mathematics;tracking;algorithm;matching	Vision	48.0712585988349	-57.96011665896973	130757
d20029afad83c2aa928769e2d811737bc1c77586	a snake algorithm for automatically tracking multiple objects	silicon;topology;active contour;topology changes snake detection tracking multiple objects;level set;snake;active contours;detection;multiple objectives;vectors;object tracking;topology changes;weak topology;joining processes;joining processes topology silicon tracking active contours vectors level set;object tracking snake algorithm object contours initialized snake contours risk image sequence snake contour rapid splitting weak topology;topology image sequences object tracking;tracking;multiple objects;image sequences	Snake is an active contour for representing object contours. Traditional snake algorithms are often used to represent the contour of a single object. However, if there is more than one object in the image, the snake model must be adaptive to determine the corresponding contour of each object. Also, the previous initialized snake contours risk in getting wrong results when tracking multiple objects in successive frames due to the weak topology changes. To overcome this problem, in this paper, we present a new snake method for efficiently tracking contours of multiple objects. Our proposed algorithm can provide a straightforward approach for snake contour rapid splitting and connection, which usually cannot be gracefully handled by traditional snakes. Experimental results of various test sequence images with multiple objects show good performance which proves that the proposed method is both effective and accurate.	active contour model;algorithm	Hua Fang;Shin-Hyoung Kim;Jong-Whan Jang	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116553	computer vision;level set;video tracking;active contour model;mathematics;geometry;weak topology;tracking;silicon	Vision	47.84726635698731	-52.88329905013941	130815
facef167572324c80ae2d71c95115ba5d825c523	a rule-based interpretation system for segmentation of seismic images	sistema experto;analisis textura;systeme modulaire;rule based;base regle;sistema modular;seismic signal;segmentation;classification;senal sismica;texture analysis;interpreteur;modular system;pattern recognition;signal sismique;reconnaissance forme;systeme expert;interpreter;reconocimiento patron;interprete;analyse texture;rule base;clasificacion;segmentacion;expert system	Abstract   A rule-based interpretation system for segmenting seismic images based on signal character is presented in this paper. The system consists of two substructures: a texture analyzer and an intelligent interpreter.  The texture analyzer adapts the “texture energy measurement” method developed by Laws to extract discriminant features from the texture-like signal image. The major function of the analyzer is to assign a vector of initial certainty factors (CFs) to each texel in the image based on the extracted feature measures. The elements of the CF vector essentially correspond to the degree of membership of the texel to each of the texture regions in the image.  The intelligent interpreter, which is the rule-based system, is made up of a knowledge database, a reasoning engine and a parallel region growing controller. Whenever a growing region requests to classify one of its boundary texels, a fact list is formed carrying information about the texel and its neighborhood. The interpreter takes the fact list and searches in the knowledge database to determine if any rules can be exercised. After a sequence of executions of rules and manipulations of CF numbers, a final CF vector emerges. If this vector favors the requesting region by having its corresponding component element exceed a preset threshold, the texel is classified to this texture class and merged into the requesting region.  A test run of the system on a piece of a seismic section shows that it can very successfully segment it into regions of common signal character. A noticeable advantage of the intelligent interpreter over other conventional classification techniques is its capability of patching small areas in the image for which the original data apparently do not provide enough discriminant information. An example illustrating these results on real seismic data from the Gulf of Mexico is presented.	logic programming	Zhen Zhang;Marwan A. Simaan	1987	Pattern Recognition	10.1016/0031-3203(87)90016-1	computer vision;speech recognition;interpreter;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;segmentation;expert system;algorithm	Vision	44.781148203915805	-63.84072566909569	131080
4454c8d19be76c853201cb8ae705fb09601e80e1	a novel pattern matching approach on the use of multi-variant local descriptor		The objective of pattern matching problem is to find the most similar image pattern in a scene image by matching to an instance of the given pattern. For pattern matching, most distinctive features are computed from a pattern that is to be searched in the scene image. Scene image is logically divided into sliding windows of pattern size, and all the sliding windows are to be checked with the pattern for matching. Due to constant matching between the pattern and the sliding window, the matching process should be very efficient in terms of space, time and impacts due to orientation, illumination and occlusion must be minimized to obtain better matching accuracy. This paper presents a novel local feature descriptor called Multi-variant Local Binary Pattern (MVLBP) for pattern matching process while LBP is considered as base-line technique. The efficacy of the proposed pattern matching algorithm is tested on two databases and proved to be a computationally efficient one.	pattern matching	Deep Suman Dev;Dakshina Ranjan Kisku	2017		10.1007/978-981-10-7895-8_4	sliding window protocol;local binary patterns;pattern matching;string searching algorithm;mathematics;pattern recognition;artificial intelligence	Vision	39.98008402768847	-53.3680443404028	131114
9b05a87f459571adfa2c17e49b5c3054d6660808	3-d hand posture recognition by training contour variation	shape feature extraction humans robustness principal component analysis image databases fingers mechanical systems character generation image generation;image matching;feature space;image generation;image matching 3d hand posture recognition training contour variation 3d hand posture estimation locally compressed feature manifold;image sequences image matching;image sequences	This paper proposes a 2-D appearance-based method of estimating 3-D hand posture. The conventional methods are essentially weak in appearance changes due to the changes of 3-D postures and viewpoint. This weakness can be overcome by registering all the possible appearances but it is not suitable because of the high DOF of human hand. In the novel method, the variations of possible shape appearances (hand contour) around the registered typical appearances are trained from a number of CG images generated from 3-D hand model. The possible variations are efficiently represented as the locally-compressed feature manifold (LCFM) in an appearance feature space. The posture estimation for the sequential images is done by tracking the posture in the LCFM. Finally the experimental results show the effectiveness of the method.	feature model;feature vector;poor posture	Akihiro Imai;Nobutaka Shimada;Yoshiaki Shirai	2004	Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings.	10.1109/AFGR.2004.1301647	computer vision;feature detection;speech recognition;feature vector;computer science;machine learning;pattern recognition	Vision	41.10042220638337	-56.61289136960734	131196
67273fc4a3106bfb3916a8b25976ba7e0f24870e	visual quasi-periodicity	detectors;image recognition;object recognition;probability;probabilistic principal component analysis;performance evaluation;turning;frequency measurement;universiteitsbibliotheek;spinning turning conductors brushes performance evaluation principal component analysis spectral analysis object detection frequency measurement assembly;assembly;visualization;internet;shape;estimation;visual quasi periodicity;principal component analysis;action recognition;pixel;object tracking;cnn news visual quasi periodicity action recognition periodicity classification object tracking probabilistic principal component analysis spectral analysis frequency measurement internet;cnn news;conceptual frame work;spectral analysis;periodicity classification;tracking;tracking frequency measurement image recognition object recognition principal component analysis probability spectral analysis;object detection;noise;spinning;brushes;conductors	Periodicity is at the core of the recognition of many actions. This paper takes the following steps to detect and measure periodicity. 1) We establish a conceptual framework of classifying periodicity in 10 essential cases, the most important of which are flashing (of a traffic light), pulsing (of an anemone), swinging (of wings), spinning (of a swimmer), turning (of a conductor), shuttling (of a brush), drifting (of an escalator) and thrusting (of a kangaroo). 2) We present an algorithm to detect all cases by the one and the same algorithm. It tracks the object independent of the objectpsilas appearance, then performs probabilistic PCA and spectral analysis followed by detection and frequency measurement. The method shows good performance with fixed parameters for examples of all above cases assembled from the Internet. 3) Application of the method, completely unaltered, to a random half hour of CNN news has led to an 80% score.	algorithm;authorization;categorization;coherence (physics);firmware;ieee xplore;internet;lorenz cipher;principal component analysis;quasi-quotation;quasiperiodicity;spectral density estimation;spectrum analyzer	Erik Pogalin;Arnold W. M. Smeulders;Andrew H. C. Thean	2008	2008 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2008.4587509	computer vision;estimation;detector;the internet;speech recognition;visualization;shape;spinning;computer science;noise;cognitive neuroscience of visual object recognition;machine learning;electrical conductor;video tracking;probability;mathematics;assembly;tracking;pixel;statistics;principal component analysis	Vision	40.6063917345028	-55.59190718284542	131198
16826a6277fd5e9287b69320b7fc894d7f1705ed	mosaic-based global vision system for small size robot league	vision system;vision ordenador;multiagent system;sistema experto;soccer;rule based;image multiple;base connaissance;imagen multiple;robotics;multiple image;computer vision;football;robotica;base conocimiento;vision ordinateur;robotique;high resolution imager;systeme expert;sistema multiagente;systeme multiagent;futbol;knowledge base;expert system	In the RoboCup F180 Small Size League, a global vision system using multiple cameras has been used to capture the whole field view. In the overlapping area of two cameras' views, a process to merge information from both cameras is needed. To avoid this complex process and rule-based approach, we propose a mosaic-based global vision system which produces high resolution images from multiple cameras. Three mosaic images, which take into account the height of each object such as our robots, opponent robots, and the ball on the field, are generated by pseudo corresponding points. Our system archives a position accuracy of better than 14.2 mm(mean: 4 mm) over a 4 × 5.5 m field.	robot	Yuji Hayashi;Seiji Tohyama;Hironobu Fujiyoshi	2005		10.1007/11780519_58	stereo cameras;computer vision;knowledge base;simulation;computer science;artificial intelligence;robotics;expert system	Robotics	48.997517955699884	-58.16234592848675	131260
f0abc3821bdf32fa52355567be1ccc708114b4bb	binocular image sequence analysis: integration of stereo disparity and optic flow for improved obstacle detection and tracking	motion analysis;vision system;signal image and speech processing;analisis imagen;traitement signal;image tridimensionnelle;mesure deplacement;vision ordenador;obstacle detection;deteccion blanco;filtro kalman;image processing;modelo 3 dimensiones;systeme vision;image matching;modele 3 dimensions;image sequence analysis;filtre kalman;procesamiento imagen;disparity;three dimensional model;analyse mouvement;kalman filter;melangeur;stereoscopy;traitement image;disparidad;computer vision;detection cible;algorithme;qa76 electronic computers computer science computer software;algorithm;detection objet;distance measurement;quantum information technology spintronics;displacement measurement;binocular vision;medicion distancia;mixer;signal processing;image sequence;poursuite cible;stereoscopie;tridimensional image;image analysis;vision ordinateur;secuencia imagen;optical flow;medicion desplazamiento;estereoscopia;mezclador;vision binocular;analisis movimiento;target tracking;procesamiento senal;target detection;analyse image;disparite;vision binoculaire;sistema vision;appariement image;sequence image;object detection;imagen tridimensional;mesure de distance;algoritmo	Binocular vision systems have been widely used for detecting obstacles in advanced driver assistant systems (ADASs). These systems normally utilise disparity information extracted from left and right image pairs, but ignore the optic flows able to be extracted from the two image sequences. In fact, integration of these two methods may generate some distinct benefits. This paper proposes two algorithms for integrating stereovision and motion analysis for improving object detection and tracking. The basic idea is to fully make use of information extracted from stereo image sequence pairs captured from a stereovision rig. The first algorithm is to impose the optic flows as extra constraints for stereo matching. The second algorithm is to use a Kalman filter as a mixer to combine the distance measurement and the motion displacement measurement for object tracking. The experimental results demonstrate that the proposed methods are effective for improving the quality of stereo matching and three-dimensional object tracking.	algorithm;binocular disparity;binocular vision;coefficient;computation;computer stereo vision;converge;coupling (computer programming);cross-correlation;displacement mapping;kalman filter;object detection;optical flow;sensor;sequence analysis;stereopsis;weight function	Yingping Huang;Ken Young	2008	EURASIP J. Adv. Sig. Proc.	10.1155/2008/843232	computer stereo vision;kalman filter;binocular vision;stereoscopy;computer vision;image analysis;image processing;computer science;signal processing;optical flow;computer graphics (images)	Robotics	48.851769187518215	-57.31122270108832	131356
1e6bc9d9fd8e834af92eb4b635491a8b3cb51be6	iterative colour correction of multicamera systems using corresponding feature points	dynamic programming;gaussian kernel density function;average colour intensities;kernel density;dynamic program;suppressing outliers;colour correction;sift;nonlinear weighting;scale invariant feature transform;gaussian kernel;density functional;corresponding intensities	 Color distortion in multicamera – Proposing novel color correction method • Advantage of proposed method − Both working for dense and sparse multicamera − Obtaining average color pattern among all cameras • Starting from any camera on array sequentially − Following certain path until reaching starting point and trigger iterations • Color correction transformation based on energy minimisation − Using dynamic programming » By nonlinearly weighted Gaussian-based kernel density function » From geometrically corresponding feature points • Guarantee convergence of iteration procedure − Without any visible color distortion	distortion;dynamic programming;iteration;nonlinear system;sparse matrix	Mehrdad Panahpour Tehrani;Akio Ishikawa;Shigeyuki Sakazawa;Atsushi Koike	2010	J. Visual Communication and Image Representation	10.1016/j.jvcir.2010.03.007	computer vision;mathematical optimization;computer science;machine learning;scale-invariant feature transform;mathematics;statistics	Robotics	53.51536061481447	-58.949613015501775	131542
aa792e1a05acccb8811f04adf540835237fb5ffe	automatic detection of clustered microcalcifications in digital mammograms using mathematical morphology and neural networks	morphological filter;filtro morfologico;faux positif;traitement signal;evaluation performance;mathematical morphology;medical imagery;medicion automatica;morfologia matematica;performance evaluation;neural networks;mastografia;binary image;multilayer perceptrons;evaluacion prestacion;fonction base radiale;automatic measurement;neural network classifier;filtre morphologique;mesure automatique;falso positivo;algorithme;perceptron multicouche;radial basis function networks;algorithm;microcalcifications;radial basis function;mammographie;automatic detection;radial basis function network;dynamics;feature extraction;signal processing;radial basis function neural network;signal classification;image binaire;detection rate;imagineria medica;imagerie medicale;true positive;classification signal;imagen binaria;dynamic neural network;multi layer perceptron;elevation;extraction caracteristique;mammography;classification automatique;reseau neuronal;false positive;automatic classification;funcion radial base;procesamiento senal;clasificacion automatica;red neuronal;artificial neural network;neural network;morphologie mathematique;algoritmo	In this paper we propose a new algorithm for the detection of clustered microcalcifications using mathematical morphology and artificial neural networks. Considering each mammogram as a topographic representation, each microcalcification appears as elevation constituting a regional maxima. Morphological filters are applied, in order to remove noise and regional maxima that doesn't correspond to calcifications. Each suspicious object is marked using a binary image and finally a feed forward neural network classifies every object achieving a rate of 90% true positive detections with 0.11 false positives per image.	algorithm;artificial neural network;binary image;breast microcalcification;mammography;mathematical morphology;mathematics;maxima;particle filter;physiologic calcification;sensor;topography	Stelios Halkiotis;Taxiarchis Botsis;Maria Rangoussi	2002	Studies in health technology and informatics	10.1016/j.sigpro.2007.01.004	dynamics;radial basis function;mathematical morphology;type i and type ii errors;binary image;elevation;feature extraction;computer science;artificial intelligence;machine learning;pattern recognition;multilayer perceptron;radial basis function network;artificial neural network	Vision	45.39681760780782	-63.36078999472026	131588
c19301e348189b3ea061f3cac81a466f2f287afd	evolution of vehicle detectors for infrared line scan imagery	analisis imagen;imagerie ir;object recognition;genetic program;feature detection;image segmentation;image processing;procesamiento imagen;reconnaissance objet;algoritmo genetico;traitement image;rotation invariance;infrared imaging;vehicle identification;segmentation image;identificacion vehiculo;algorithme genetique;genetic algorithm;image analysis;infrared;analyse image;identification vehicule	The paper addresses an important and difficult problem of object recognition in poorly constrained environments and with objects having large variability. This research uses genetic programming (GP) to develop automatic object detectors. The task is to detect vehicles in infrared line scan (IRLS) images gathered by low flying aircraft. This is a difficult task due to the diversity of vehicles and the environments in which they can occur, and because images vary with numerous factors including fly-over, temporal and weather characteristics. A novel multistage approach is presented which addresses automatic feature detection, automatic object segregation, rotation invariance and generalisation across diverse objects whilst discriminating from a myriad of potential non-objects. The approach does not require imagery to be pre-processed.	sensor	Simon C. Roberts;Daniel Howard	1999		10.1007/10704703_9	computer vision;image analysis;simulation;genetic algorithm;infrared;image processing;computer science;cognitive neuroscience of visual object recognition;feature detection;image segmentation	Vision	47.120807768284344	-60.00431316319493	131657
769ea4385f3a0957968aa27dce79292002c4e13e	real-time body pose recognition using 2d or 3d haarlets	transformation ondelette;funcion haar;vision ordenador;silhouette;anmm;haar wavelet;image processing;fonction haar;haarlets;real time;haar function;procesamiento imagen;psi_visics;3d hulls;classification;traitement image;computer vision;posture;features;rotation invariance;lda;human motion;temps reel;silhouettes;postura;delai d execution;visual hull;tiempo real;invariante;plazo ejecucion;vision ordinateur;transformacion ondita;pose recognition;clasificacion;silueta;invariant;wavelet transformation;time allowed;pose estimation	This article presents a novel approach to markerless real-time pose recognition in a multicamera setup. Body pose is retrieved using example-based classification based on Haar wavelet-like features to allow for real-time pose recognition. Average Neighborhood Margin Maximization (ANMM) is introduced as a powerful new technique to train Haar-like features. The rotation invariant approach is implemented for both 2D classification based on silhouettes, and 3D classification based on visual hulls.	adaboost;approximation algorithm;expectation–maximization algorithm;face detection;gesture recognition;haar wavelet;hash function;jones calculus;object detection;omnidirectional treadmill;real-time clock;real-time transcription;switzerland;visual basic[.net];voxel	Michael Van den Bergh;Esther Koller-Meier;Luc Van Gool	2009	International Journal of Computer Vision	10.1007/s11263-009-0218-0	computer vision;speech recognition;pose;3d pose estimation;image processing;biological classification;computer science;invariant;articulated body pose estimation;mathematics;silhouette;computer graphics (images)	Vision	45.993523626063755	-58.5120200805259	131816
6c9a6864155f7975168d582d0feb169af9439124	efficient object matching using affine-invariant deformable contour	bayesian framework;efficient object matching;object recognition;parametric statistics;image matching;asm;insensitivity;bayes methods;prototypes;ai snake model efficient object matching affine invariant deformable contour affine invariant eigensnake ai es bayesian framework object shape distribution prototype contour affine invariant internal energy global shape deformation local shape deformation real object matching robustness insensitivity active shape model asm;deformable models bayesian methods parametric statistics prototypes robustness active shape model shearing artificial intelligence principal component analysis;object shape distribution;bayesian methods;prior distribution;deformable models;shape deformation;local shape deformation;principal component analysis;affine invariant internal energy;affine invariant eigensnake;shearing;global shape deformation;prototype contour;artificial intelligence;robustness;affine invariant deformable contour;bayes methods object recognition image matching;real object matching;ai es;large deformation;active shape model;ai snake model	An affine-invariant deformable contour model for object matching, called affine-invariant eigensnake (AI-ES), is presented in the Bayesian framework. In AI-ES, the prior distribution of object shapes is estimated and utilized to constrain the prototype contour, which is dynamically adjustable in the matching process. Also, an affine-invariant internal energy is presented to define the global and local shape deformation of the contours between the shape domain and the image domain. Experiments on real object matching show that the proposed method is more robust and insensitive to the positions, viewpoints, and large deformations of object shapes, than the active shape model (ASM) and the AI-snake model.	contour line	Zhong Xue;Stan Z. Li;Eam Khwang Teoh	2000		10.1109/ICPR.2000.905477	active shape model;computer vision;prior probability;bayesian probability;computer science;cognitive neuroscience of visual object recognition;pattern recognition;shape analysis;active contour model;mathematics;geometry;prototype;shearing;parametric statistics;statistics;robustness;principal component analysis	Vision	42.829301895081215	-56.463177086922435	131923
2da351674cdc9caa9e0272b39870eddde5adaa55	coarse registration of 3d surface triangulations based on moment invariants with applications to object alignment and identification	object recognition;3d surface triangulation coarse registration;local surface moments;surface roughness;surface reconstruction;three dimensional;rough surfaces;similarity transformation;iterative closest point algorithm 3d surface triangulation coarse registration 3d moment invariants object alignment object identification three dimensional surface registration local surface moments local surface descriptors hungarian method minimum cost assignment;object alignment;three dimensional displays;image registration;minimum cost assignment;3d moment invariants;hungarian method;iterative closest point;iterative closest point algorithm object recognition surface fitting application software computer vision noise robustness iterative algorithms databases registers costs;face;local surface descriptors;object recognition image registration mesh generation;iterative closest point algorithm;mesh generation;object identification;noise;moment invariant;three dimensional surface registration	We present a new, direct way to register three-dimensional (3D) surfaces given the respective 3D points and surface triangulations. Our method is non-iterative and does not require any initial solution. The idea is to compute 3D invariants based on local surface moments. The resulting local surface descriptors are invariant with respect to Euclidean or to similarity transformations, by choice. In the final step we use the Hungarian method to find a minimum cost assignment of the computed descriptors. The method is robust against different point densities, noise and partial overlap. Our experiments with real data also show that the method can serve as automatic initialization of the iterative-closest-point (ICP) algorithm and, hence, extends the field of applications for this standard registration method.	experiment;global positioning system;hungarian algorithm;iterative closest point;iterative method;optimization problem;overlap–add method;pattern matching;preprocessor;sampling (signal processing);surface triangulation	Michael Trummer;Herbert Süße;Joachim Denzler	2009	2009 IEEE 12th International Conference on Computer Vision	10.1109/ICCV.2009.5459321	face;three-dimensional space;matrix similarity;mesh generation;computer vision;mathematical optimization;surface reconstruction;surface roughness;computer science;noise;image registration;cognitive neuroscience of visual object recognition;hungarian algorithm;mathematics;geometry;iterative closest point	Vision	50.50869760191963	-52.29636231786394	132186
b25ee75e4597d1d5a4d2ab0afc08278b98a76d63	robust motion segmentation using rank ordering estimatiors	estimation mouvement;image processing;robust estimator;flux optique;estimacion movimiento;procesamiento imagen;motion estimation;segmentation;traitement image;computer vision;motion segmentation;flujo optico;image sequence;secuencia imagen;optical flow;segmentacion;sequence image;structured data	Robust estimators have become popular tools for sol ving a wide range of problems in computer vision. Despite many successes in this fie ld, there is still a need for estimators, which are suited to specific problems such as recovering structures from multi-structural data. This paper offers an alternative approach to, and some p ractical insights into, the implementation of well-known rank ordering based robust estimators. T he approach has been tested on synthetic and real image data for motion segmentation purpose s.	computer vision;synthetic intelligence	Alireza Bab-Hadiashar;David Suter	1998		10.1007/3-540-63931-4_267	robust statistics;computer vision;image processing;data model;computer science;motion estimation;optical flow;segmentation;computer graphics (images)	Vision	50.74669870534459	-55.03286629449296	132201
b1e527f19ddc0343fc7f3a76d97025bfab15d4f4	the nist humanid evaluation framework	reconnaissance visage;marco;standards;facies;securite;biometrie;xml language;biometrics;biometria;standard;system evaluation;face recognition;senal video;signal video;documentacion;safety;norma;pattern recognition;video signal;number;reconnaissance forme;reconocimiento patron;nombre;etalon;seguridad;norme;langage xml;lenguaje xml;numero;documentation;evaluation framework	The NIST HumanID Evaluation Framework, or HEF, is an effort to design, implement, and deploy standards for the robust and complete documentation of the biometric system evaluation process. The HEF is leverages contemporary technologies, specifically XML, for the formal description of biometric tests. The HEF was used to facilitate the administration of the Face Recognition Vendor Test (FRVT) 2002. Unlike FRVT 2000 or the FERET 1996 evaluations, FRVT 2002 used a large number (over 100,000) of both still and video facial imagery, warranting the development of a more sophisticated and regular means of describing data presented to the participants. The HEF is one component in NIST’s ongoing effort to address the need in the biometrics community for a common evaluation framework.	antivirus software;biometrics;database;documentation;email;emoticon;feret (facial recognition technology);face recognition vendor test;information and computer science;lazy evaluation;machine learning;primer;r language;s-plus;xml;xml schema	Ross J. Micheals;Patrick Grother;P. Jonathon Phillips	2003		10.1007/3-540-44887-X_48	facial recognition system;simulation;facies;documentation;computer science;operating system;database;programming language;world wide web;computer security;biometrics	Web+IR	45.18929399710716	-59.798674787679865	132226
3ef92ca006511ebdf87238c5442ee23f0d4ea824	context-based adaptive filtering of interest points in image retrieval	detectors;object recognition;interest points detection image retrieval;context based adaptive filtering;adaptive filters image retrieval application software computer vision feature extraction detectors intelligent systems videoconference object recognition runtime;probability density function;interest points;interest points detection;video retrieval;object recognition context based adaptive filtering image retrieval computer vision applications image video retrieval;set theory;data mining;feature space;set theory adaptive filters feature extraction filtering theory image retrieval;computer vision;adaptive filters;computer vision applications;local features;feature extraction;pixel;image video retrieval;processing speed;adaptive filter;context;filtering theory;buildings;image retrieval	Interest points have been used as local features with success in many computer vision applications such as image/video retrieval and object recognition. However, a major issue when using this approach is a large number of interest points detected from each image and created a dense feature space. This influences the processing speed in any runtime application. Selecting the most important features to reduce the size of the feature space will solve this problem. Thereby this raises a question of what makes a feature more important than the others? In this paper, we present a new technique to choose a subset of features. Our approach differs from others in a fact that selected feature is based on the context of the given image. Our experimental results show a significant reduction rate of features while preserving the retrieval performance.	adaptive filter;computer vision;database;experiment;feature vector;filter (signal processing);image retrieval;information;interest point detection;outline of object recognition	Giang P. Nguyen;Hans Jørgen Andersen	2009	2009 Ninth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2009.25	adaptive filter;feature recognition;computer vision;feature detection;visual word;image retrieval;computer science;machine learning;pattern recognition;feature;information retrieval	Vision	39.69698228164128	-60.335582949280905	132260
ddb7cf8de309064be253304da3dd6b6784decae3	neural net based division of an image blob of people into parts of constituting individuals	baja resolucion;modelizacion;vision ordenador;peaton;pistage;image processing;image resolution;occlusion;televigilancia;surveillance;occultation;low resolution;basse resolution;rastreo;procesamiento imagen;hombre;oclusion;intelligence artificielle;probabilistic approach;traitement image;observador;computer vision;identificacion sistema;modelisation;remote supervision;resolucion imagen;observateur;vigilancia;neural net;monitoring;system identification;video cameras;telesurveillance;enfoque probabilista;approche probabiliste;pedestrian;human;camera video;pattern classification;division image;artificial intelligence;image division;vision ordinateur;division imagen;people tracking;inteligencia artificial;monitorage;reseau neuronal;ocultacion;monitoreo;probabilistic neural network;modeling;observer;resolution image;red neuronal;identification systeme;tracking;homme;neural network;pieton;classification forme	This paper presents an example-based learning approach to divide a foreground blob of people into its constituents on a surveillance video camera image. As people tend to walk and interact in groups with other people, occlusions frequently happen in camera images. They are detected in the same foreground image blob and dividing it into image parts of constituting individuals is a prerequisite for high-level vision processing like people tracking and activity understanding. The division is easy for a human observer but difficult in computer vision especially when the image resolution is low. We treat this task as a pattern classification problem by identifying partial outline shape patterns of a foreground blob, which can characterize the position where the blob can be well divided. When a probabilistic neural network was employed to identify the pattern, the network showed over 80% correct recognition rates in experiments.	artificial neural network	Yongtae Do	2006		10.1007/11941439_53	computer vision;image resolution;blob detection;computer science;artificial intelligence;machine learning;artificial neural network	Vision	46.413370225360104	-57.94105264032061	132316
ff1f4eebc0041273dfd0e2638616f9ccf9f6e997	3d object pose estimation using viewpoint generative learning	stable keypoint;generative learning;pose estimation	Conventional local features such as SIFT or SURF are robust to scale and rotation changes but sensitive to large perspective change. Because perspective change always occurs when 3D object moves, using these features to estimate the pose of a 3D object is a challenging task. In this paper, we extend one of our previous works on viewpoint generative learning to 3D objects. Given a model of a textured object, we virtually generate several patterns of the model from different viewpoints and select stable keypoints from those patterns. Then our system learns a collection of feature descriptors from the stable keypoints. Finally, we are able to estimate the pose of a 3D object by using these robust features. In our experimental results, we demonstrate that our system is robust against large viewpoint change and even under partial occlusion.	3d pose estimation;computation;feature vector;graphics processing unit;parallel computing;scale-invariant feature transform;speeded up robust features;time complexity;viewpoint	Dissaphong Thachasongtham;Takumi Yoshida;François de Sorbier;Hideo Saito	2013		10.1007/978-3-642-38886-6_48	computer vision;pose;3d pose estimation;computer science;machine learning;pattern recognition;generative model	Vision	41.90427836180598	-52.3593056923424	132365
d5d3a51d7b65b03febb060724828d06214c1bfca	determining angular frequency from images of rotating objects via a generalized fast fourier transform	fast fourier transform;rate of rotation;angular frequency	In certain real-world applications, one needs to estimate the angular frequency of a spinning object. We consider the image processing problem of estimating this rate of rotation from a video of the object taken by a camera aligned with the axis of rotation. For many types of spinning objects, this problem can be addressed with existing techniques: simply register two consecutive video frames. We focus, however, on objects whose shape and intensity changes greatly from frame to frame, such as spinning plumes of plasma that emerge from a certain type of spacecraft thruster. To estimate the angular frequency of such objects, we introduce the Geometric Sum Transform (GST), a new rotation-based generalization of the discrete Fourier transform (DFT). Taking the GST of a given video produces a new sequence of images, the most coherent of which corresponds to the object's true rate of rotation. After formally demonstrating this fact, we provide a fast algorithm for computing the GST which generalizes the decimation-in-frequency approach for performing a Fast Fourier Transform (FFT). We further show that computing a GST is, in fact, mathematically equivalent to computing a system of DFTs, provided one can decompose each video frame in terms of an eigenbasis of a rotation operator. We conclude with numerical experimentation.	angularjs;fast fourier transform	Lindsay N. Smith;Matthew C. Fickus	2014	Adv. Comput. Math.	10.1007/s10444-013-9296-1	angular frequency;computer vision;fast fourier transform;short-time fourier transform;discrete fourier transform;mathematics;geometry;discrete fourier transform;non-uniform discrete fourier transform;algorithm;quantum mechanics	Vision	52.476295414119484	-54.33592731186498	132609
1a526f4d175d70e8e938fc34eb6682032b8420bc	an image retrieval method on color primitive co-occurrence matrix	analisis coocurrencia;busqueda informacion;texture;analyse cooccurrence;recherche image;information retrieval;texture features;cooccurrence analysis;calcul analogique;recherche information;textura;imagen color;similarity function;image couleur;co occurrence matrix;color image;analog calculus;calculo analogico;image retrieval	The paper presents and realizes a new image retrieval method based on the combination of the color connected area information with the texture features. The image is firstly divided into several parts and the color connected areas in the image is computed, then, the primitive co-occurrence matrix of the four color components corresponded with the connected area of each color is extracted. Lastly the image retrieval on the basis of the content is realized by using of the feature similar function which is designed according to these features.	co-occurrence matrix;document-term matrix;image retrieval	HengBo Zhang;ZongYing Ou;Guanhua Li	2006		10.1007/11881223_65	color histogram;image texture;computer vision;feature detection;visual word;color quantization;hsl and hsv;color depth;color image;binary image;image retrieval;computer science;high color;mathematics;texture;co-occurrence matrix;computer graphics (images)	Vision	43.56431471680535	-61.514442276249284	132720
4179727fc511715252202c06334d392913db8273	function from visual analysis and physical interaction: a methodology for recognition of generic classes of objects	modelizacion;image tridimensionnelle;eficacia sistema;object recognition;vision ordenador;architecture systeme;image processing;etude experimentale;performance systeme;procesamiento imagen;intelligence artificielle;robotics;raisonnement;system performance;traitement image;three dimensional;computer vision;modelisation;3d model;interactive system;range image;visual analysis;razonamiento;pattern recognition;robotica;tridimensional image;artificial intelligence;arquitectura sistema;vision ordinateur;robotique;inteligencia artificial;reconnaissance forme;reasoning;reconocimiento patron;system architecture;potential function;modeling;estudio experimental;imagen tridimensional;physical interaction	This paper presents an overview of the GRUFF-I (Generic Recognition Using Form, Function and Interaction) system, a nonpart-based approach to generic object recognition which reasons about and generates plans for interaction with three-dimensional (3D) shapes from the categories furniture and dishes. The system operates as follows. A researcher selects an object and places it in an observation area. An initial intensity and range image are acquired. These are input to a three-stage recognition system. The first stage builds a 3D model. The second stage receives as input a 3D model and considers the shape-suggested functionality of this shape by applying concepts of physics and causation (e.g. to infer stability) to label the object’s potential functionality. The third stage uses this labeling to instantiate a plan for interaction to confirm the object’s functional use in a task by incorporating feedback from both visual and robotic sensors. Results of this work are presented for eighteen chair-like and cup-like objects. Major conclusions from this work include: (1) metrically accurate representations of the world can be built and used for higher level reasoning; (2) shape-based reasoning prior to interaction-based reasoning provides an efficient methodology for object recognition, in terms of the judicious use of system resources; and (3) interaction-based reasoning can be used to confirm the functionality of a categorized object without explicitly determining the object’s material composition.	3d modeling;categorization;causality;fundamental interaction;generic programming;outline of object recognition;range imaging;robot;robotic sensors;sensor	Melanie A. Sutton;Louise Stark;Kevin W. Bowyer	1998	Image Vision Comput.	10.1016/S0262-8856(98)00069-9	three-dimensional space;computer vision;method;simulation;systems modeling;object model;image processing;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;3d single-object recognition;robotics;reason	Vision	47.92629918512214	-59.098982456318346	132739
cc2ec1863f7b7ce16b78bfdd8b5c7bd0f056c99e	object detection using gabor filters	modelizacion;agregacion;filtering;filtrage;base donnee;algorithm performance;modele mathematique;image processing;analisis textura;etude experimentale;filtrado;interrogation base donnee;database;procesamiento imagen;interrogacion base datos;base dato;modelo matematico;segmentation;aggregation;traitement image;even symetric gabor filters;algorithme;modelisation;algorithm;gabor filter;texture analysis;texture based segmentation;target recognition;resultado algoritmo;performance algorithme;mathematical model;pattern recognition;agregation;fingerprint;reconnaissance forme;reconocimiento patron;modeling;analyse texture;estudio experimental;database query;segmentacion;object detection;spatial orientation;even symmetric gabor filters;algoritmo	"""This paper pertains to the detection of objects located in complex backgrounds. A feature-based segmentation approach to the object detection problem is pursued, where the features are computed over multiple spatial orientations and frequencies. The method proceeds as follows: A given image is passed through a bank of even-symmetric Gabor lters. A selection of these ltered images is made and each (selected) ltered image is subjected to a nonlinear (sigmoidal like) transformation. Then, a measure of texture energy is computed in a window around each transformed image pixel. The texture energy (\Gabor features""""), and their spatial locations, are inputted to a squared-error clustering algorithm. This clustering algorithm yields a segmentation of the original image { it assigns to each pixel in the image a cluster label that identiies the amount of mean local energy the pixel possesses across diierent spatial orientations and frequencies. The method is applied to a number of visual and infrared images, each one of which contains one or more objects. The region corresponding to the object is usually segmented correctly, and a unique signature of \Ga-bor features"""" is typically associated with the segment containing the object(s) of interest. Experimental results are provided to illustrate the usefulness of this object detection method in a number of problem domains. These problems arise in IVHS, military reconnaissance, ngerprint analysis, and image database query."""	algorithm;cluster analysis;database;gabor filter;image;nonlinear system;object detection;pixel;problem domain;sigmoid function	Anil K. Jain;Nalini K. Ratha;Sridhar Lakshmanan	1997	Pattern Recognition	10.1016/S0031-3203(96)00068-4	filter;gabor transform;fingerprint;computer vision;speech recognition;systems modeling;spatial disorientation;image processing;computer science;artificial intelligence;mathematical model;segmentation	Vision	44.20708819709441	-61.386747025832356	132831
a8f9596513ec8cdbb11a7fb4db3e0984aff7438e	curve representing and matching based on feature points and minimal area threshold	silicon;curve representation feature points recognition vector recognition vector matrix;object recognition;feature points;sample points recognition vector;dissimilarity measure;edge detection;curve representation;image matching;object recognition edge detection image matching matrix algebra;probability density function;matrix algebra;recognition vector;data mining;recognition vector matrix;feature extraction;recognition vector matrix curve representation curve matching contour curve recognition sample points recognition vector;area measurement;curve matching;text recognition;feature extraction binary trees feathers circuit noise data mining object recognition shape clocks;contour curve recognition;data models	A new method for representing and recognizing the contour curve is presented in this paper. First, feature points are employed to describe contour curve preliminarily; Then the sample points of the sub-curve are introduced to describe contour more, they are obtained based on the precision requirement using the given minimal area threshold. A new recognition vector of sample points is defined, and a novel recognition vector matrix is constructed based on the recognition vector of sample points; Last the dissimilarity measure of the corresponding sub-curves is calculated by compared the recognition vector matrix. The curves are recognized by recognizing their each sub-curve. The method match object and model from simple to complex, thus many redundancies calculation are avoided. The experiment results show the algorithm is efficient and feasible.	algorithm	Gui-mei Zhang;Wei Ren;Jun Miao	2009	2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics	10.1109/CADCG.2009.5246830	data modeling;computer vision;probability density function;edge detection;feature extraction;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;silicon;statistics	Robotics	41.47929844559397	-58.45453835428008	132934
1d3b21e75f89283d0e095b1d517a6d9992e2bd28	quaternion polar harmonic transforms for color images	quaternions transforms color kernel harmonic analysis image color analysis image reconstruction;interchannel redundancy quaternion polar harmonic transform content representation color image processing complex field hypercomplex field quaternion algebra qpht quaternion computation quaternion kernel orthogonality rotation invariance color image representation chromatic feature;wavelet transforms;quaternion polar harmonic transforms color image processing image description orthogonal transforms;wavelet transforms algebra feature extraction harmonic analysis image colour analysis image representation redundancy;redundancy;algebra;image colour analysis;image representation;feature extraction;harmonic analysis	Robust and compact content representation is a fundamental problem in image processing. The recently proposed polar harmonic transforms (PHTs) have provided a set of powerful tools for image representation. However, two-dimensional transforms cannot handle color image in a holistic manner. To extend the nice properties of PHTs to color image processing, we generalize PHTs from the complex field to hypercomplex field in this letter, and quaternion polar harmonic transforms (QPHTs) are developed based on quaternion algebra. Furthermore, the properties of QPHTs are studied via quaternion computation, including the orthogonality of quaternion kernels, the relationships between different transforms and their rotation invariance. Experimental results reveal that compared with complex PHTs, the quaternion transforms can make a more compact and discriminative representation of color image. Moreover, QPHTs can well capture the chromatic features and exploit the inter-channel redundancies of color image.	color image;computation;discriminative model;holism;image processing;kinetic data structure;numerical stability;resonance	Yue-Nan Li	2013	IEEE Signal Processing Letters	10.1109/LSP.2013.2267775	computer vision;topology;feature extraction;harmonic analysis;mathematics;geometry;redundancy;wavelet transform	Vision	41.1774272582428	-59.854292421984304	133445
acfcc2796757673fb2c083301ff1e6ccfec5041d	a method of motion segmentation based on region shrinking	moving object;continuous function;vision ordenador;gradient vector flow;estimation mouvement;active contour;image segmentation;geometrie solide;edge detection;estimacion movimiento;corps mobile;gradiente;geometria solidos;motion estimation;fonction continue;intelligence artificielle;posterior probability;gradient;probabilistic approach;computer vision;deteccion contorno;detection contour;motion segmentation;funcion continua;enfoque probabilista;approche probabiliste;pixel;cuerpo movil;probabilite a posteriori;segmentation image;probabilidad a posteriori;artificial intelligence;vision ordinateur;moving body;inteligencia artificial;mpm map;region shrinking;solid geometry	Motion segmentation needs to estimate the parameters of motion and its supporting region. The usual problem in determining the supporting region is how to obtain a complete spatial consistence. On the basis of maximum posterior marginal probability (MPM-MAP) algorithm this paper presents a new algorithm based on region shrinking to locate the supporting area. First the motion parameters are estimated by MPM-MAP algorithm. In this algorithm pixels of maximum probabilities belonging to a motion are considered to be preselected pixels for supporting area. Then the region shrinking algorithm is used to determine the region of maximum density of the preselected pixels to be the range of supporting area. Finally the active contour based on gradient vector flow (GVF) is adopted to obtain the accurate shape of supporting region. This method obtains a solid region to be supporting area of a motion and extracts the accurate shape of moving objects, so it offers a better way in motion segmentation to solve the problem of spatial continuity.		Zhihui Li;Fenggang Huang;Yongmei Liu	2006		10.1007/11875581_33	continuous function;computer vision;edge detection;computer science;solid geometry;motion estimation;active contour model;geometry;image segmentation;posterior probability;gradient;pixel	Vision	48.91617592869269	-58.432152611744556	133450
a0ef5c73906996ba23002e85f32e8da600a342b5	predicting disparity windows for real-time stereo	processor architecture;image tridimensionnelle;algorithm performance;image segmentation;vision estereoscopica;real time;representation image;vision stereoscopique;virtual reality;optical flow estimation;reconstruction image;reconstruccion imagen;resultado algoritmo;image representation;image reconstruction;image sequence;segmentation image;performance algorithme;time use;tridimensional image;optical flow;temporal coherence;stereopsis;imagen tridimensional	New applications in elds such as augmented or virtualized reality have created a demand for dense, accurate real-time stereo reconstruction. Our goal is to reconstruct a user and her ooce environment for networked tele-immersion, which requires accurate depth values in a relatively large workspace. In order to cope with the combinatorics of stereo correspondence we can exploit the temporal coherence of image sequences by using coarse optical ow estimates to bound disparity search ranges at the next iteration. We use a simple ood ll segmenta-tion method to cluster similar disparity values into overlapping windows and predict their motion over time using a single optical ow calculation per window. We assume that a contiguous region of disparity represents a single smooth surface which allows us to restrict our search to a narrow disparity range. The values in the range may vary over time as objects move nearer or farther away in Z, but we can limit the number of disparities to a feasible search size per window. Further, the disparity search and optical ow calculation are independent for each window, and allow natural distribution over a multi-processor architecture. We have examined the relative complexity of stereo correspondence on full images versus our proposed window system and found that, depending on the number of frames in time used to estimate optical ow, the window-based system requires about half the time of standard correlation stereo. Experimental comparison to full image correspondence search shows our window-based reconstructions compare favourably to those generated by the full algorithm, even after several frames of propagation via estimated optical ow. The result is a system twice as fast as conventional dense correspondence without signiicant degradation of extracted depth values.	algorithm;binocular disparity;coherence (physics);correspondence problem;elegant degradation;glossary of computer graphics;immersion (virtual reality);iteration;microsoft windows;multiprocessing;real-time locating system;real-time transcription;software propagation;television;workspace	Jane Mulligan;Kostas Daniilidis	2000		10.1007/3-540-45054-8_15	iterative reconstruction;computer vision;simulation;microarchitecture;computer science;stereopsis;optical flow;virtual reality;image segmentation;computer graphics (images)	Vision	51.74552753877252	-55.81503865625095	133562
08e243f7e50461ab26c9c0e3ebf22a106eb5a1b2	new applications for object recognition and affine motion estimation by independent component analysis	mesure deplacement;object recognition;vision ordenador;transformation affine;estimation mouvement;analisis datos;estimacion movimiento;motion estimation;reconnaissance objet;intelligence artificielle;independent component analysis;computer vision;data analysis;displacement measurement;senal video;signal video;affine transformation;pattern recognition;analyse composante independante;video signal;invariante;artificial intelligence;analyse donnee;vision ordinateur;medicion desplazamiento;inteligencia artificial;reconnaissance forme;reconocimiento patron;analisis componente independiente;invariant;transformacion afin	This paper proposes a new scheme based on independent component analysis(ICA) for object recognition with affine transformation and for affine motion estimation between video frames. For different skewed shapes of recognized object, an invariant descriptor can be extracted by ICA, and it can solve some skewed object recognition problems. This method also can be used to estimate the affine motion between two frames, which is important in high compression rate coding such as MPEG4 or MPEG7 standard. Simulation results show that the proposed method has a better performance than other traditional methods in pattern recognition and affine motion estimation.	independent component analysis;motion estimation;outline of object recognition	Liming Zhang;Xuming Huang	2004		10.1007/978-3-540-28651-6_88	independent component analysis;computer vision;speech recognition;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;invariant;motion estimation;affine arithmetic;affine transformation;harris affine region detector;3d single-object recognition;affine shape adaptation;data analysis;affine combination;motion compensation	Vision	45.788405785684475	-58.793545190001225	133650
e3d092eb962e31fe2af6999f0578a17c61a42128	detection of occluded circular objects by morphological operators	mathematical morphology;image numerique;morfologia matematica;forme circulaire;image processing;occlusion;binary image;edge detection;procesamiento imagen;oclusion;morphological operation;circular shape;traitement image;deteccion contorno;detection contour;forma circular;imagen numerica;image binaire;pattern recognition;imagen binaria;parallel machines;digital image;reconnaissance forme;reconocimiento patron;object detection;morphologie mathematique	In this article we propose a simple and fast method to locate circular objects from binary images even if they are highly occluded by one another. The algorithm is based on basic morphological transforms and thus can be implemented on parallel machines. Some examples are presented to illustrate the efficiency of the approach.	algorithm;binary image;mathematical morphology	Adrish Ray Chaudhuri;Bhabatosh Chanda;Bidyut Baran Chaudhuri	1995	Signal Processing	10.1016/0165-1684(95)00085-R	computer vision;mathematical morphology;edge detection;binary image;image processing;computer science;mathematics;digital image	Vision	47.47202053755685	-63.05130746701214	133729
cdb40bed9e06fd5642b2beb82fabac89889b534d	a comparative study of texture coarseness measures	image features;fineness image features textural features human perception visual coarseness;visual coarseness;textural features;size measurement;texture features;noise measurement;image texture;brightness;image texture feature extraction;humans noise robustness brightness image color analysis image texture analysis image retrieval noise measurement size measurement computer science artificial intelligence;feature extraction;robustness;humans;correlation;human coarseness perception texture coarseness measures image features image brightness image contrast image noise image size;human perception;fineness;noise	There are a wide variety of measures in the literature that capture the ¿coarseness¿ texture property. Some of them have better ability to represent coarseness than the others. Furthermore, some of them are more robust against the variation of other image features, like brightness, contrast, noise and size of the image. In this paper, we propose to study the robustness and the relationship with human coarseness perception of 17 classical measures of coarseness, in order to obtain a ranking of measures. This ranking can be used to identify those measures that have the highest relationship degree with perception and the least variation with the other image features.	image noise	Jesús Chamorro-Martínez;Pedro Martínez-Jiménez	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5413579	image texture;computer vision;feature extraction;computer science;noise measurement;noise;machine learning;pattern recognition;perception;correlation;feature;brightness;robustness	Vision	41.05628998151481	-62.34154816422208	133739
1c0f7854c14debcc34368e210568696a01c40573	using vanishing points for camera calibration	vision system;contraste;punto de fuga;vision ordenador;localizacion objeto;vision estereoscopica;object location;optimal estimation;vision stereoscopique;point de fuite;computer vision;algorithme;algorithm;camara;vanishing point;machine vision;image sequence;vision ordinateur;etalonnage;camera calibration;stereopsis;localisation objet;calibration;camera;coordinate system;algoritmo	In this article a new method for the calibration of a vision system which consists of two (or more) cameras is presented. The proposed method, which uses simple properties of vanishing points, is divided into two steps. In the first step, the intrinsic parameters of each camera, that is, the focal length and the location of the intersection between the optical axis and the image plane, are recovered from a single image of a cube. In the second step, the extrinsic parameters of a pair of cameras, that is, the rotation matrix and the translation vector which describe the rigid motion between the coordinate systems fixed in the two cameras are estimated from an image stereo pair of a suitable planar pattern. Firstly, by matching the corresponding vanishing points in the two images the rotation matrix can be computed, then the translation vector is estimated by means of a simple triangulation. The robustness of the method against noise is discussed, and the conditions for optimal estimation of the rotation matrix are derived. Extensive experimentation shows that the precision that can be achieved with the proposed method is sufficient to efficiently perform machine vision tasks that require camera calibration, like depth from stereo and motion from image sequence.	apache axis;autostereogram;camera resectioning;experiment;focal (programming language);image plane;machine vision	Bruno Caprile;Vincent Torre	1990	International Journal of Computer Vision	10.1007/BF00127813	optimal estimation;computer vision;camera matrix;calibration;camera resectioning;vanishing point;machine vision;computer science;stereopsis;coordinate system;geometry;fundamental matrix;essential matrix;motion field;epipolar geometry	Vision	49.91858110182668	-57.15788197828014	133755
2911af62d3a05210689706f82c26205476c6b6c2	interpretation of motion trajectories using focus of expansion	motion analysis;focusing;approaching motion;vision ordenador;analisis escena;analyse scene;movimiento;trajectoire;metodologia;focusing image analysis computer vision motion analysis h infinity control government computer science smart cameras machine intelligence;single point;perspective projection;receding motion motion trajectory interpretation approaching motion direction change focus of expansion single point straight line;sistema informatico;government;receding motion;motion estimation;computer system;motion;methodologie;computer vision;interpretacion;focus;trajectory;machine intelligence;mouvement;focus of expansion;smart cameras;motion estimation image sequences;foyer optique;projection perspective;interpretation;image analysis;vision ordinateur;trayectoria;systeme informatique;computer science;methodology;h infinity control;proyeccion perspectiva;motion trajectory interpretation;foco optico;straight line;direction change;scene analysis;image sequences;expansion	The focus of expansion (FOE) of a group of motion trajectories is defined to be a point in the image plane at which the trajectories intersect when they are extended. The FOE observed over a time sequence defines the locus of the FOE. The authors present an analytical approach for the study of dynamic events as they project on the image plane by analyzing the locus of the FOE. They find that the locus of the FOE can be used to make qualitative assertions regarding the type of motion. Interesting behavior of the locus of the FOE for various types of motion is observed. The cases include a single point and a horizontal, a vertical, and a sloped straight line. It was also possible to determine whether the object has approaching or receding motion or when the object changes its direction of motion. This inference can be used in qualitative computer vision. >		Krishnan Rangarajan;Mubarak Shah	1992	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.177386	computer vision;image analysis;simulation;interpretation;computer science;trajectory;motion;motion estimation;methodology;geometry;motion field;government;focus	Vision	50.5050238904399	-58.1629590366293	133925
3ddf73a87aa06c2f9b0d862d978e0e1fa362c1f5	video segmentation using active contours on a group of pictures	background mosaic;active contour;image segmentation;group of pictures;colored noise;parametric statistics;motion compensation;edge detection;region based segmentation;motion estimation;video segmentation;active contours;noise robustness;group of picture;video coding;active contours cameras noise robustness motion estimation image segmentation parametric statistics colored noise object detection motion compensation computational efficiency;motion compensation video coding edge detection image sequences image colour analysis image segmentation;image colour analysis;motion camera;video segmentation active contours region based segmentation video background sequence color region video frame background mosaic group of pictures motion camera;color region;computational efficiency;video frame;cameras;object detection;video background sequence;image sequences	In this paper we address a new method for motion camera video segmentation. Most of video segmentation methods use temporal gradient between two consecutive frames and therefore are not robust to light variations and noise. Thus we present a new region based active contour segmentation on a group of pictures. This new segmentation proceeds in two steps: first a mosaic is computed to generate the background sequence of the video. then color region based active contour segmentation is applied on each video frame, related to its background. Finally, we show experimental results obtained on real sequences after each step of the algorithm i.e. the background mosaic and the final segmented objects.	active contour model;active galactic nucleus;algorithm;gradient;group of pictures	Muriel Gastaud;Michel Barlaud	2002		10.1109/ICIP.2002.1039892	group of pictures;computer vision;colors of noise;edge detection;computer science;segmentation-based object categorization;motion estimation;active contour model;multimedia;image segmentation;scale-space segmentation;motion compensation;parametric statistics;computer graphics (images)	Vision	48.245178737782396	-53.71119654267763	133933
1c83eb5bc894b650942f0035c8ee93a1dba78032	neural network based 3d model reconstruction with highly distorted stereoscopic sensors	contraste;modelizacion;image tridimensionnelle;model based reasoning;vision ordenador;raisonnement base sur modele;image processing;traitement image stereoscopique;oeil de poisson;procesamiento imagen;hombre;stereoscopy;intelligence artificielle;traitement image;stereoscopic vision;computer vision;modelisation;captador medida;reconstruction image;measurement sensor;3d model;capteur mesure;depth perception;reconstruccion imagen;biomimetique;oclusion hidrogeno;machine vision;image reconstruction;stereo image processing;human;fish eye;stereoscopie;tridimensional image;artificial intelligence;vision ordinateur;etalonnage;estereoscopia;vision artificielle;inteligencia artificial;camera calibration;reseau neuronal;artificial vision;modeling;calibration;red neuronal;3d reconstruction;imagen tridimensional;homme;biomimetics;neural network;vision artificial	In stereoscopic vision, there are two artificial eyes implemented so that it can obtain two separate views of the scene and simulate the binocular depth perception of human beings. Traditionally, camera calibration and 3D reconstruction of such a vision sensor are performed by geometrical solutions. However, the traditional camera model is very complicated since nonlinear factors in it and needs to approximate the light projection scheme by a number of parameters. It is even very difficult to model some highly distorted vision sensors, such as fish-eye lens. In order to simplify both the camera calibration and 3D reconstruction procedures, this work presents a method based on neural networks which is brought forward according to the characteristics of neural network and stereoscopic vision. The relation between spatial points and image points is established by training the network without the parameters of the cameras, such as focus, distortions besides the geometry of the system. The training set for our neural network consists of a variety of stereo-pair images and corresponding 3D world coordinates. Then the 3D reconstruction of a new s cene is simply using the trained network. Such a method is more similar to how human's eyes work. Simulations and real data are used to demonstrate and evaluate the procedure. We observe that the errors obtained our experimentation are accurate enough for most machine-vision applications.	3d modeling;artificial neural network;sensor;stereoscopic video game;stereoscopy	Wanliang Wang;Bing-bing Xia;Qiu Guan;Shengyong Chen	2005		10.1007/11494669_81	3d reconstruction;iterative reconstruction;biomimetics;stereoscopy;computer vision;calibration;camera resectioning;systems modeling;machine vision;image processing;depth perception;computer science;stereopsis;artificial intelligence;model-based reasoning;artificial neural network	Vision	47.45452508606807	-58.032009864339905	134093
064ba712aee13cc0f809972589e86915363d2eec	evaluating color difference formulae by riemannian metric		For precision color matching, visual sensitivity to small color difference is an essential factor. Small color differences can be measured by the just noticeable difference (JND) ellipses. The points on the ellipse represent colours that are just noticably different from the colour of the centre point. Mathematically, such an ellipse can be described by a positive definite quadratic differential form, which is also known as the Riemannian metric. In this paper, we propose a method which makes use of the Riemannian metric and Jacobean transformations to transform JND ellipses between different colour spaces. As an example, we compute the JND ellipses of the CIELAB and CIELUV color difference formulae in the xy chromaticity diagram. We also propose a measure for comparing the similarity of a pair of ellipses and use that measure to compare the CIELAB and CIELUV ellipses to two previously established experimental sets of ellipses. The proposed measure takes into account the size, shape and orientation. The technique works by calculating the ratio of the area of the intersection and the area of the union of a pair of ellipses. The method developed can in principle be applied for comparing the performance of any color difference formula and experimentally obtained sets of colour discrimination ellipses.	color space;diagram;experiment	Dibakar R. Pant;Ivar Farup	2010			mathematical analysis;topology;color difference;mathematics;geometry	Vision	50.72304543269198	-61.562630372709904	134209
9cbf81992e9167a4ff3d9337fc3c301e02eec086	cut digits classification with k-nn multi-specialist	document structure;euclidean theory;document analysis;image processing;estructura documental;caracter manuscrito;structure document;manuscript character;database;procesamiento imagen;base dato;classification;traitement image;analyse documentaire;base de donnees;theorie euclidienne;pattern recognition;analisis documental;reconnaissance forme;information system;reconocimiento patron;caractere manuscrit;clasificacion;systeme information;teoria euclidiana;sistema informacion	A multi-classifier formed by specialised classifiers for noise produced by an image is shown in this work. A study has been carried out in the case of cut images, where tree cases of specialization are considered. Classifiers based on neighbourhood criteria are used, the zoning global feature and the Euclidean distance too. Furthermore, the paper explains a modification of the Euclidean distance for classifying cut digits. The experiments have been carried out with images of typewritten digits, taken from real forms. Trying to obtain a strong database to support the experiments, we have cut images deliberately. The recognition rate improves from 84.6% to 97.70%, but whether the system provides information about the disturbance of the image, it can achieve a 98.45%.	euclidean distance;experiment;image noise;k-nearest neighbors algorithm;optical character recognition;partial template specialization;pattern recognition	Fernando Boto;Andoni Cortés Vidal;Clemente Rodríguez Lafuente	2006		10.1007/11669487_44	image processing;biological classification;computer science;artificial intelligence;document structure description;database;mathematics;information system;algorithm	Vision	44.024329268260644	-61.259896598846936	134291
811d3412187390591eaac9ae595579b885f4c97f	content-based image retrieval by dictionary of local feature descriptors	computers;scrap images content based image retrieval local feature descriptor dictionary image keypoint descriptor indexing dictionary based representation image descriptor sets descriptor representation dictionary creation ordered descriptor dictionary structure standard deviation similarity estimation panoramic photography;standards;panoramic photography;image matching;standard deviation;scrap images;indexing content based retrieval dictionaries image matching image representation image retrieval;dictionary creation;accuracy;local feature descriptor dictionary;dictionaries standards image color analysis image retrieval computers indexing accuracy;indexing;similarity estimation;image color analysis;image representation;dictionaries;ordered descriptor dictionary structure;content based image retrieval;content based retrieval;descriptor representation;dictionary based representation;image descriptor sets;image keypoint descriptor indexing;image retrieval	This paper describes a novel method of image key-point descriptor indexing and comparison used to speed up the process of content-based image retrieval as the main advantage of the dictionary-based representation is faster comparison of image descriptors sets in contrast to the standard list representation. The proposed method of descriptor representation allows to avoid initial learning process, and can be adjusted taking into consideration new examples. The presented method sorts and groups components of descriptors in the process of the dictionary creation. The ordered structure of the descriptors dictionary is well suited for quick comparison of images by comparing their dictionaries of descriptors or by comparing individual descriptors with the dictionary. This allows to skip a large part of operations during descriptors comparison between two images. In contrast to the standard dictionary, our method takes into account the standard deviation between the image descriptors. This is due to the fact that almost all descriptors generated for the points indicating the same areas of the image have different descriptors. Estimation of the similarity is based on the determined value of the standard deviation between descriptors. We assume that proposed method can speed up the process of descriptor comparison. It can be used with many solutions which require high-speed operations on the image e.g. robotics, or in software which computes panoramic photography from scrap images and in many others.	brute-force search;computer science;content-based image retrieval;data dictionary;experiment;group of pictures;kilobyte;lexicography;robotics;speedup;visual descriptor;xfig	Patryk Najgebauer;Tomasz Nowak;Jakub Romanowski;Marcin Gabryel;Marcin Korytkowski;Rafal Scherer	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889815	computer vision;search engine indexing;image retrieval;computer science;pattern recognition;accuracy and precision;standard deviation;information retrieval;statistics	Vision	41.25280073603332	-55.054887690547176	134319
8a74835c9690a651c4a1207e505795551c73ff7b	a new approach to vector median filtering based on space filling curves	filling multidimensional systems information filtering information filters sorting color cameras remote sensing image processing computational efficiency;vector median filtering;evaluation performance;information sources;non linear filtering;performance evaluation;image processing;median filter;filtering performance vector median filtering vectorial data multidimensional information sources color cameras multispectral remote sensing imagery devices image processing research scalar nonlinear filtering multidimensional data filtering multidimensional median filtering absolute sorting vectorial space peano space filling curves scalar median filtering 1d space computational efficiency image sequences;sorting;color;evaluacion prestacion;information filtering;filtrado no lineal;procesamiento imagen;1d space;vectorial data;nonlinear filter;multidimensional data;filling;traitement image;image processing research;filtering performance;multidimensional information sources;algorithme;color cameras;algorithm;remote sensing imagery;scalar median filtering;absolute sorting;multidimensional data filtering;filtro mediano;remote sensing;image sequence;scalar nonlinear filtering;vectorial space;space filling curve;multidimensional median filtering;computational efficiency;imagen color;information filters;multidimensional digital filters;filtre median;peano space filling curves;filtering theory median filters multidimensional digital filters image processing;image couleur;filtering theory;cameras;multidimensional systems;median filters;filtrage non lineaire;color image;image sequences;algoritmo;multispectral remote sensing imagery devices	The availability of a wide set of multidimensional information sources in different application fields (e.g., color cameras, multispectral remote sensing imagery devices, etc.) is the basis for the interest of image processing research on extensions of scalar nonlinear filtering approaches to multidimensional data filtering. A new approach to multidimensional median filtering is presented. The method is structured into two steps. Absolute sorting of the vectorial space based on Peano space filling curves is proposed as a preliminary step in order to map vectorial data onto an appropriate one-dimensional (1-D) space. Then, a scalar median filtering operation is applied. The main advantage of the proposed approach is the computational efficiency of the absolute sorting step, which makes the method globally faster than existing median filtering techniques. This is particularly important when dealing with a large amount of data (e.g., image sequences). Presented results also show that the filtering performances of the proposed approach are comparable with those of vector median filters presented in the literature.	appendix;authorization;basis function;best, worst and average case;color image;computation;filter (signal processing);graphical user interface;guided imagery;higher-order function;ieee xplore;image processing;mathematical morphology;mathematics;median filter;multispectral image;nonlinear system;performance;quantum superposition;sorting;space-filling curve;the filter;vector processor	Carlo S. Regazzoni;Andrea Teschioni	1997	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.597277	nonlinear filter;median filter;computer vision;mathematical optimization;color image;multidimensional systems;image processing;computer science;sorting;theoretical computer science;mathematics	Visualization	52.36514984886157	-64.86413776559925	134471
23dbae7ac6c75fcd29d1606645496af20e5e2b32	automatic aerial image registrationwithout correspondence	histograms;human computer interaction;image matching;layout;image sensors;satisfiability;image registration computer vision layout image edge detection histograms human computer interaction image matching shape voting image sensors;computer vision;aerial image;shape;image edge detection;voting;image registration	This paper presents an approach for registering aerial images taken at different time, viewpoints, or heights. Different from conventional image registration algorithms, our approach does not need image matching or correspondence. In this approach, we extract a number of corner features as the basis for registration and create a number of image patches with the corner points as centers on both reference and observed images. In order to let the corresponding patches cover same scene, we use a circle which the radius can be changed as the shape of the image patches. In this way, the image patches can handle the case in which there are rotation and scaling at the same time between reference and observed images. With the orientation differences of patches between these two images, we create an angle histogram with a voting procedure. The rotation angle between the two images can be determined by seeking the orientation difference that corresponds to the maximum peak in the histogram. Once we get the rotation angle, we seek back for the two corresponding patches which the value of orientation difference is the same as the rotation angle. The ratio of radii of these two patches is the value of the scaling. The proposed approach can handle the situation of large rotation and scaling between reference and observed images. It is applied to real aerial images and the results are very satisfying.	aerial photography;algorithm;image registration;image scaling	Yingen Xiong;Francis K. H. Quek	2006	Fourth IEEE International Conference on Computer Vision Systems (ICVS'06)	10.1109/ICVS.2006.15	homography;layout;image restoration;computer vision;feature detection;orientation;voting;image processing;shape;computer science;image registration;pattern recognition;image sensor;histogram;image formation;satisfiability;computer graphics (images)	Vision	52.66133309539281	-55.393361584560374	134791
909182a5f22d17f4b4ccae7826ab1f8ce72fae03	phase congruence measurement for image similarity assessment	analisis imagen;traitement signal;phase measurement;evaluation performance;evaluation image;performance evaluation;image processing;evaluacion prestacion;erreur quadratique moyenne;procesamiento imagen;image comparison;qualite image;traitement image;medida fase;similitude;image quality evaluation;algorithme;algorithm;mesure phase;mean square error;feature extraction;signal processing;image quality;indexation;similarity;controle qualite;evaluacion imagen;image analysis;calidad imagen;image evaluation;similitud;extraction caracteristique;error medio cuadratico;phase congruence;quality control;procesamiento senal;analyse image;performance assessment;control calidad;algoritmo;image similarity	In the performance assessment of an image processing algorithm, an image is often compared with an available reference. Measuring image similarity can be achieved in many ways; comparison algorithm varies from pixel-based mean square error method to structure-based image quality index. In this paper, we present a new feature-based approach that utilizes image phase congruency measurement to quantify the assessment of the similarities or differences between two images. Test results with standard images and industrial inspection images are presented.	congruence of squares	Zheng Liu;Robert Laganière	2007	Pattern Recognition Letters	10.1016/j.patrec.2006.06.019	image quality;image texture;computer vision;quality control;feature detection;image analysis;similarity;binary image;image processing;feature extraction;computer science;artificial intelligence;similitude;signal processing;mathematics;mean squared error;standard test image	Vision	45.08362580277601	-61.59482608313271	134861
12532f9333d19478bb53be2ca412baeec5cb03d9	on the reliability degree of hue and saturation values of a pixel for color image classification	pixel saturation value;reliability;image segmentation;illumination;reliability degree;illumination reliability degree pixel hue value pixel saturation value color image classification color image segmentation hsi space;pixel hue value;image classification;reliability computer vision fuzzy set theory image classification image colour analysis image representation image segmentation;fuzzy set theory;computer vision;color segmentation;image colour analysis;image representation;pixel color lighting colored noise computer vision image segmentation application software humans shadow mapping reliability engineering;hsi space;color image classification;color image;color image segmentation	Variability of hue and saturation components is an important drawback for developing accurate color image segmentation algorithms based on HSI spaces: different colors can return similar color components because of the different illumination levels, and the components of a color change accordingly to the illumination level. To avoid these problems within color segmentation algorithms, we propose a method that, based on predicted hue and saturation deviations, provides the reliability degree of the H-S color components based obtained HIS values. The reliability degree has been used for improving color classification results	algorithm;color image;heart rate variability;horizontal situation indicator;image segmentation;pixel	Santiago Romaní;Pilar Sobrevilla;Eduard Montseny	2005	The 14th IEEE International Conference on Fuzzy Systems, 2005. FUZZ '05.	10.1109/FUZZY.2005.1452411	color histogram;computer vision;contextual image classification;icc profile;color quantization;hsl and hsv;lightness;color normalization;color depth;color image;chromaticity;computer science;pattern recognition;reliability;color balance;fuzzy set;image segmentation;color space;computer graphics (images)	Robotics	42.5365697179458	-63.84677239142642	135026
5317354e5f78fe19e929217fc1160575a92f5b68	on aligning shapes	global shape properties shape matching shape retrieval method rigid transformation shape deformation query shape database shapes minimum bounding box similarity measure;image processing;shape recognition image matching image retrieval query processing;query processing;image matching;center of mass;shape recognition;shape measurement;shape;shape shape measurement image processing conferences area measurement context noise;shape matching;area measurement;similarity measure;context;conferences;noise;image retrieval	In this paper, we exploit some global shape properties in an efficient shape matching and retrieval method, which is robust with respect to rigid transformations (translation, rotation, scaling) and some deformations. The retrieval of similar shapes is obtained by normalizing the query shape and the database shapes using the area, the center of mass and the minimum bounding box. Then, an alignment is achieved by overlapping the shape areas. The retrieval of similar shapes is based on a similarity measure defined by the symmetric difference. The experimental results validate the proposed approach.	database normalization;image scaling;minimum bounding box;shape context;similarity measure	Saliha Bouagar;Slimane Larabi;Nabil Djellouli	2011	2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)	10.1109/ICSIPA.2011.6144131	center of mass;computer vision;image processing;image retrieval;shape;computer science;noise;pattern recognition;shape analysis;mathematics;geometry	Vision	41.44944376665775	-58.45090097553324	135049
d1252ca09115983818be56aaa5227a90b2cb8287	a segmentation algorithm for rock fracture detection	tratamiento automatico;image segmentation;image processing;methode echelle multiple;edge detection;procesamiento imagen;metodo escala multiple;data mining;traitement image;deteccion contorno;multiple scales;detection contour;automatic processing;fouille donnee;segmentation image;pattern recognition;image processing techniques;multiscale method;reconnaissance forme;reconocimiento patron;traitement automatique;busca dato	The recognition of rock fractures is very important in many real rock engineering applications. To apply im2 age processing technique into rock fracture recognition , the key and hardest task is to auto tracing fractures on the rock fracture images , and the newly developed ridge detection algorithm is very powerful for tracing rock fractures , it has been tested in a laboratory and works satisfactorily.	algorithm;ridge detection	Weixing Wang;Eva Hakami	2005		10.1007/11552499_64	computer vision;edge detection;image processing;computer science;image segmentation;scale-space segmentation;computer graphics (images)	ML	45.62776978598589	-62.86595459547673	135481
1454ab06efffc1254a9ad1578fa9f7669a454f23	real-time classification of traffic signs	size specification;teletrafic;navegacion;clutter;image processing;signalling;automovil;etude experimentale;multilayer perceptrons;real time;procesamiento imagen;technique video;real time processing;signalisation;analyse multiresolution;tecnica video;classification;traitement image;fast fourier transform;perceptron multicouche;tratamiento tiempo real;navigation;teletrafico;traitement temps reel;fouillis echo;red multinivel;neural net;senal video;signal video;automobile;filter;pattern matching;confusion eco;motor car;materiau stratifie;statistical pattern recognition;stratified material;teletraffic;pattern recognition;filtre;video signal;video technique;multi layer perceptron;rotation scaling and translation;concordance forme;reconnaissance forme;multilayer network;reseau multicouche;galibo;reseau neuronal;reconocimiento patron;multi resolution;multiresolution analysis;gabor wavelets;template matching;estudio experimental;filtro;clasificacion;gabarit;red neuronal;material estratificado;analisis multiresolucion;senalizacion;neural network	A challenging real-time imaging problem is classifying video traffic signs in background clutter under rotation, scale, and translation invariant conditions. Normalized Gabor Wavelet Transform features from multi-resolution filters were originally biologically-based; however, optimized features proved more effective. Two whole image template matching techniques were unsuccessful. A statistical pattern recognition system recognized approximately 30% of the images for the original features and 50% for the optimized features; however, a multi-layer perceptron (mlp) detected over 70% of the images with the optimized features. The research demonstrated the possibility of a future automotive navigation aid which robustly collects sign images and classifies these images in real-time with a single Fast Fourier Transform (FFT), a bank of filters and a trained neural net.		Phil Douville	2000	Real-Time Imaging	10.1006/rtim.1998.0142	multiresolution analysis;signalling;computer vision;fast fourier transform;navigation;speech recognition;template matching;biological classification;filter;computer science;pattern matching;clutter;multilayer perceptron;artificial neural network	Vision	46.45506555338942	-60.79062960402534	135564
0419e551a81343c339e5c41af815d55d39687f46	the automatic generation of 3d object model from range image	gaussian curvature;character generation shape petroleum testing graphics object recognition data mining gaussian noise tin;computational geometry;mean square;automatic generation;computational geometry solid modelling;range image;mean curvature;computer graphics automatic generation 3d object model range image algorithmic procedure 3d wireframe model shape attributes dominant points 3d invariant characteristics mean square curvature;solid modelling;object model	This paper presents an algorithmic procedure for the generation of a 3D wireframe model from range image. The basic idea is to represent a surface by dominant points which have important shape attributes. To determine dominant points, we propose a criterion based on 3D invariant characteristics of surfaces, which we call mean-square curvature. This quantity has some desirable properties and, compared to conventional Gaussian curvature or mean curvature, is more suitable for dominant point selection. It also allows a physical explanation. The 3D wireframe model is constructed by detecting dominant points followed by triangulating them in 3D space. The algorithms are tested on a real range image and the results are shown. >	range imaging	Wentao Zheng;Hiroshi Harashima	1994		10.1109/ICASSP.1994.389459	gaussian curvature;computer vision;object model;computational geometry;machine learning;mean curvature;mathematics;geometry	Robotics	52.11644149538634	-56.952934108818745	135576
a08e7450a694f5ed9a689227b3afc05866936057	on the human left ventricular shape	computerized axial tomography;tomodensitometria;radiodiagnostic;electron beam tomography;medical imagery;representation tridimensionnelle;propiedad geometrica;heart;shape descriptor;analisis forma;analyse fonctionnelle;cardiac function;propriete geometrique;geometrical cardiogram;geometry;end diastole;hombre;healthy volunteer;left ventricular;anatomia;geometric feature;effet dimensionnel;discrete cosine transform;left ventricle;three dimensional;radiodiagnostico;tomodensitometrie;circulatory system;functional analysis;ventricule gauche;size effect;geometrical properties;human;imagerie medicale;three dimensional representation;pattern analysis;imageneria medical;radiodiagnosis;efecto dimensional;appareil circulatoire;anatomie;cine ct;aparato circulatorio;anatomy;representacion tridimensional;ventriculo izquierdo;analyse forme;end systole;homme;aspect ratio;analisis funcional	"""The geometry of the heart plays a major role in cardiac function. The purpose of this study was to characterize analytically the geometric properties of the left ventricular (LV) three-dimensional (3D) shape, while excluding the effects of aspect ratio and size. Two groups of human hearts were studied by Cine-CT. The first group was composed of 10 healthy volunteers and the second of 9 pathological hearts. The hearts were scanned from apex to base. The endocardial borders of each LV scan were traced and used to reconstruct the 3D LV at end-diastole (ED) and end-systole (ES). Using a special normalized helical shape descriptor, denoted """"geometrical cardiogram"""" (GCG), the typical 3D normal ED and ES shapes were determined. These typical shapes were then analytically approximated via a discrete cosine transform (DCT). The shape of each LV was then investigated for its correspondence to five analytically defined shapes: (i) a cone, (ii) a sphere, including all ellipsoidal shapes, (iii) a cylinder, (iv) a truncated ellipsoid, and (v) the DCT approximation of the normal LV shape. The results indicate that the normal LV shape can be well approximated by using only seven coefficients of the DCT. Conicity was the only geometrical feature which did not change from ED to ES in the normal group of hearts. The most prominent shape difference between normal and abnormal hearts was the significantly reduced conicity of the latter. Conicity is an important feature of LV geometry. The possible contribution of the conical shape to LV ejection efficiency is also discussed."""		Haim Azhari;Rafael Beyar;Samuel Sideman	1999	Computers and biomedical research, an international journal	10.1006/cbmr.1999.1513	functional analysis;three-dimensional space;aspect ratio;topology;cardiac function curve;calculus;circulatory system;discrete cosine transform;mathematics;geometry;heart	Vision	48.885792807240556	-60.82090691088422	135580
7edcc547f43558874fb46cd34d988959ed5e5f52	matching trajectories between video sequences by exploiting a sparse projective invariant representation	software;representacion proyectiva;alignement;spatial alignment;temporal window;nonsynchronized cameras;image motion analysis;cross ratio;video signal processing;view invariant representation;surveillance;temporal alignment;recubrimiento;geometry;trajectory segments;exhaustive testing;sparse set;overlay;metric;motion estimation;video sequences;representation projective;indice aptitud;testing;temporal shifts video sequences sparse projective invariant representation trajectory segments nonsynchronized cameras complete trajectory motion data spatial alignment temporal alignment exhaustive testing temporal window view invariant representation;layout;blanco movil;recouvrement;sparse projective invariant representation;similitude;computer vision;invariants;registro imagen;video sequences cameras trajectory layout geometry motion estimation testing surveillance computer vision software;indice aptitude;trajectory;recalage image;capability index;image representation;projective representation;image registration;image sequence;similarity;registration;alineamiento;complete trajectory;similarity measures;representacion parsimoniosa;invariante;cible mobile;motion data;metrico;secuencia imagen;ensemble epars;video signal processing image motion analysis image representation;similitud;temporal shifts;sparse representation;cross ratio registration invariants similarity measures;similarity measure;alignment;invariant;cameras;moving target;metrique;sequence image;representation parcimonieuse	Identifying correspondences between trajectory segments observed from nonsynchronized cameras is important for reconstruction of the complete trajectory of moving targets in a large scene. Such a reconstruction can be obtained from motion data by comparing the trajectory segments and estimating both the spatial and temporal alignments. Exhaustive testing of all possible correspondences of trajectories over a temporal window is only viable in the cases with a limited number of moving targets and large view overlaps. Therefore, alternative solutions are required for situations with several trajectories that are only partially visible in each view. In this paper, we propose a new method that is based on view-invariant representation of trajectories, which is used to produce a sparse set of salient points for trajectory segments observed in each view. Only the neighborhoods at these salient points in the view-invariant representation are then used to estimate the spatial and temporal alignment of trajectory pairs in different views. It is demonstrated that, for planar scenes, the method is able to recover with good precision and efficiency both spatial and temporal alignments, even given relatively small overlap between views and arbitrary (unknown) temporal shifts of the cameras. The method also provides the same capabilities in the case of trajectories that are only locally planar, but exhibit some nonplanarity at a global level.	alignment;appendix;checking (action);cluster analysis;computation (action);concave function;convex hull;denominator;dropping;dynamic time warping;emoticon;estimated;experiment;frame (physical object);limnobacter sp. u24;matching;numerical analysis;pentium 4;planar (computer graphics);planar graph;similarity measure;sparse approximation;sparse language;sparse matrix;streaming media;statistical cluster	Walter Nunziati;Stan Sclaroff;Alberto Del Bimbo	2010	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2009.35	computer vision;topology;computer science;invariant;mathematics;geometry	Vision	50.30002750539874	-55.695967947794934	135758
b15b21abeb03454fffcac1680374d3628939c708	an initial assessment of discriminant surface complexity for power law features	power law	The detection of man-made objects in natural terrain is important in both the targeting and terminal homing phase of modern warfare. The presence of man-made objects in gray-scale images has been successfully detected using a new class of density estimation neural networks to analyze power law signatures. The complex nature of the discriminant surface relating these features has been elucidated using these adaptive mixture networks.	artificial neural network;computation;discriminant;grayscale;multiple homing;pixel;type signature	Jeffrey L. Solka;Carey E. Priebe;George W. Rogers	1992	Simulation	10.1177/003754979205800503	econometrics;mathematical optimization;power law;computer science;mathematics;statistics	Vision	40.91269096525906	-64.61526860156766	135763
12f8819be8421e5c70d682e4e28b77fe641728fa	adaptive real-time image smoothing using local binary patterns and gaussian filters	lbps image denoising image enhancement locally adaptive variable kernel size texture analysis;gaussian processes;image texture;image enhancement;smoothing methods;time 2 6 ms adaptive real time image smoothing gaussian filters gpu graphical processing unit gaussian smoothing kernel lbp local binary patterns local texture real time computing;smoothing methods kernel psnr image edge detection graphics processing units speckle;image denoising;smoothing methods gaussian processes image denoising image enhancement image texture	Image smoothing is widely used for enhancing the quality of single images or videos. There is a large amount of application areas such as machine vision, entertainment industry with smart TVs or consumer cameras, or surveillance and reconnaissance with different imaging sensors. In many cases it is not easy to find the trade-off between high smoothing quality and fast processing time. However, this is necessary for the mentioned applications as they are dependent on real-time computing. In this paper, we aim to find a good trade-off. Local texture is analyzed with Local Binary Patterns (LBPs) which are used to adapt the size of a Gaussian smoothing kernel for each pixel. Real-time requirements are met by the implementation on a Graphical Processing Unit (GPU). An image of 512 × 512 pixels is processed in 2.6 ms.	autostereogram;gaussian blur;graphics processing unit;image editing;local binary patterns;machine vision;pixel;real-time clock;real-time computing;real-time transcription;requirement;sensor;smart tv;smoothing;video	Michael Teutsch;Patrick Trantelle;Jürgen Beyerer	2013	2013 IEEE International Conference on Image Processing	10.1109/ICIP.2013.6738231	image texture;edge-preserving smoothing;computer vision;pyramid;feature detection;binary image;image processing;computer science;machine learning;gaussian blur;free boundary condition;pattern recognition;gaussian process;mathematics;non-local means;statistics;smoothing	Vision	52.86329370795512	-65.19041771603571	135886
2f7bc6714c31355e85394d8bbf02ce2d3ee3a6eb	improving color constancy using indoor–outdoor image classification	extraction information;evaluation performance;procesamiento informacion;performance evaluation;image processing;illumination;algorithm parameter tuning;information extraction;color constancy;color constancy improvement;color;evaluacion prestacion;illuminant estimation techniques;algorithms artificial intelligence color colorimetry image enhancement image interpretation computer assisted pattern recognition automated reproducibility of results sensitivity and specificity;decision forests;image classification layout image color analysis clustering algorithms image analysis vegetation mapping data mining lighting algorithm design and analysis uncertainty;procesamiento imagen;indoor and outdoor image classification color constancy decision forests;image classification;indexing terms;estimation algorithm;image colour analysis feature extraction image classification;traitement image;algorithme;algorithm;general purpose algorithms color constancy improvement indoor outdoor image classification illuminant estimation techniques information extraction algorithm parameter tuning;adaptive algorithm;installation exterieure;instalacion exterior;estimation;outdoor installation;image colour analysis;feature extraction;information processing;signal classification;classification image;general purpose algorithms;indoor environments;classification signal;theorie information;classification automatique;indoor outdoor classification;traitement information;automatic classification;indoor installation;instalacion interior;clasificacion automatica;installation interieure;indoor outdoor image classification;extraccion informacion;information theory;indoor and outdoor image classification;algoritmo;teoria informacion	In this work, we investigate how illuminant estimation techniques can be improved, taking into account automatically extracted information about the content of the images. We considered indoor/outdoor classification because the images of these classes present different content and are usually taken under different illumination conditions. We have designed different strategies for the selection and the tuning of the most appropriate algorithm (or combination of algorithms) for each class. We also considered the adoption of an uncertainty class which corresponds to the images where the indoor/outdoor classifier is not confident enough. The illuminant estimation algorithms considered here are derived from the framework recently proposed by Van de Weijer and Gevers. We present a procedure to automatically tune the algorithms' parameters. We have tested the proposed strategies on a suitable subset of the widely used Funt and Ciurea dataset. Experimental results clearly demonstrate that classification based strategies outperform general purpose algorithms.	class;extraction;silo (dataset);subgroup;algorithm	Simone Bianco;Gianluigi Ciocca;Claudio Cusano;Raimondo Schettini	2008	IEEE Transactions on Image Processing	10.1109/TIP.2008.2006661	computer vision;estimation;contextual image classification;index term;information processing;image processing;information theory;feature extraction;computer science;machine learning;pattern recognition;color constancy;information extraction;statistics	Vision	44.759086475892964	-62.46771085723941	136075
a094e850c469bd72284bd3e08041bd56db8f3edb	real time contour tracking with a new edge detector	systeme temps reel;digital signal processing;interfase usuario;interfaz grafica;medical imagery;computadora personal;ordinateur personnel;senal analogica;image processing;video signal processing;personal computer;graphical interface;user interface;edge detection;thoracic aorta;implementation;real time;procesamiento imagen;analog signal;echocardiographie;traitement image;deteccion contorno;algorithme;algorithm;detection contour;first order;feature extraction;robustesse;tratamiento digital;poursuite cible;data visualization;imagineria medica;imagerie medicale;traitement signal video;echocardiography;graphic user interface;cross sectional area;robustness;interface utilisateur;visualisation donnee;real time system;digital processing;sistema tiempo real;ecocardiografia;signal analogique;extraction caracteristique;target tracking;implementacion;interface graphique;traitement numerique;robustez;algoritmo	In this paper, a new system for real time contour tracking is presented. If a rough contour of the desired structure is available on the first image of a sequence, the system can automatically outline the contours on the subsequent images at video rate. The method we used is based on a new edge detector which was obtained by the generalization of the first order absolute central moment operator. The new algorithm proved to be very robust to noise and fast enough to be implemented in real time. The contour tracking procedure was implemented on an integrated software/hardware platform composed of a personal computer equipped with a digital signal processing board. The system can capture an analog video signal with a resolution of 512×512 pixels, 25 frames/s, process the data and display the results in real time. A graphical user interface is also available to interact with the system. Tests on images of the descending thoracic aorta and of a carotid, recorded by echocardiography, are reported. The cross-sectional area of the aorta and the diameter of the carotid were computed in real time and plotted on the user interface. The system proved to be a useful tool for the investigation of vascular mechanisms.	edge detection	Vincenzo Gemignani;Marco Paterni;Antonio Benassi;Marcello Demi	2004	Real-Time Imaging	10.1016/j.rti.2004.02.005	computer vision;simulation;image processing;computer science;graphical user interface;data visualization;computer graphics (images)	Robotics	48.11152406338219	-63.710598947995116	136233
749df6a6469a0277cde29cad00a8dbacea1813ec	a novel synthetic dataset for research in overlapped fingerprint separation		This paper presents a new image dataset for evaluating approaches for overlapped fingerprint separation. The VLATACOM dataset consists of 120,000 synthetically overlapped test images (and the associated masks), with and without noise, processed with three different rotation angles, and in two variations of overall brightness. Each image in the dataset also contains information about the number of the singular points within its overlapped region, which is a distinctly unique feature of the proposed dataset. The paper also reports early experimental results which demonstrate the suitability of the VLATACOM dataset for overlapped fingerprint separation research. The dataset, along with testing results, is freely and publicly available.	archive;email;fingerprint;readme;synthetic data	Branka Stojanovic;Oge Marques;Aleksandar Neskovic	2017	2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2017.8310137	grayscale;computer vision;brightness;artificial intelligence;fingerprint;computer science;fingerprint recognition;pattern recognition	Vision	39.3994350533598	-64.52351176525617	136381
86731c0b8dbcd8ca3c30e2e59d1a9b20d79dc4a6	a dynamic combinatorial hough transform for straight lines and circles		A new algorithm for the Hough transform is presented. It uses information available in the distribution of image points to calculate the parameters associated with combinations of the minimum number of points necessary to define an instance of the shape under detection. The method requires only one dimensional accumulation of evidence to determine the parameters associated with a given shape. Using the algorithm, the Hough transform of sparse images is more efficiently calculated. Dense images may be segmented and similarly processed. The method also provides a feedback mechanism between image and transform space whereby contiguity of feature points and endpoints of curves may be determined.	accumulator (computing);algorithm;computation;emoticon;feedback;hough transform;image resolution;sparse matrix;tree accumulation	Violet F. Leavers;D. Ben-Tzvi;Mark B. Sandler	1989		10.5244/C.3.28	hough transform	Vision	49.67066775570839	-54.132159501720764	136457
d325359db6fb81ccdb0a449da3a00336c53ba3f8	collection, analysis and representation of memory color information		Memory color plays an important role in the perceptual process. The aim of this research is to collect, analyze and represent memory color data for certain natural scenes objects: sky, grass and tree leaves. To emphasize reliable data collection, we consider several sources: (a) psychophysical experiment; (b) multispectral image; (c) standard image database and (d) random image collection. Moreover, we consider different daylight conditions and locations. We perform an in-depth analysis of the collected information in the CIE-xy chromaticity space and present the natural scene objects as a memory color ellipse or polygon. Finally, we demonstrate a potential use of the collected information for natural image segmentation and enhancement.		G. M. Atiqur Rahaman;Md. Abul Hasnat;Rahul Mourya	2015		10.1007/978-3-319-15979-9_9	computer vision;information retrieval	Vision	44.58454009293295	-56.0429262348554	136644
43e737d8d91ddeda5cce9f6b28aa95a15f229318	automatic correspondence finding for chinese characters using graph matching	graph theory;histograms;automatic stroke extraction chinese character skeleton extraction chinese character skeleton pruning connectivity relations key point similarity local features edge set k nearest neighbor algorithm k nn algorithm guided graph matching algorithm printing styles handwritten styles;image matching;set theory feature extraction graph theory handwritten character recognition image matching natural language processing;correspondence finding;set theory;graph matching;skeleton;graph matching local features chinese characters correspondence finding;skeleton shape feature extraction histograms matrices accuracy optimization;accuracy;matrices;shape;local features;feature extraction;chinese characters;optimization;natural language processing;handwritten character recognition	Automatically establishing correspondence between Chinese characters is a challenging task. In this paper, we propose a novel method to solve this problem. Given two Chinese characters, we first extract and properly prune the skeleton of each character to get the key points and the connectivity relations of these points. Then, the similarity between each pair of key points is calculated via the comparison of their local features. Afterwards, a set of edges are constructed by considering both the connectivity relations and k nearest neighbors (k-nn) of each point. Finally, correspondence between two characters is established by applying a guided graph matching algorithm. Experimental results demonstrate the effectiveness of our method for the correspondence problem of Chinese characters in both printing and handwritten styles. Moreover, we also show that our method can be utilized to automatically extract strokes from Chinese characters.	correspondence problem;k-nearest neighbors algorithm;matching (graph theory);printing	Chenxi Wang;Zhouhui Lian;Yingmin Tang;Jianguo Xiao	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.115	arithmetic;feature extraction;shape;graph theory;machine learning;pattern recognition;histogram;mathematics;accuracy and precision;skeleton;matrix;statistics;matching;set theory	Vision	40.915355631728026	-58.116345557594435	136667
843144829c8b678a3511038dfb2d706c283addb0	seal object detection in document images using ght of local component shapes	generalized hough transform;rotation invariance;automatic detection;support vector machine;graphical symbol spotting;connected component;character recognition;object detection	Due to noise, overlapped text/signature and multi-oriented nature, seal (stamp) object detection involves a difficult challenge. This paper deals with automatic detection of seal from documents with cluttered background. Here, a seal object is characterized by scale and rotation invariant spatial feature descriptors (distance and angular position) computed from recognition result of individual connected components (characters). Recognition of multi-scale and multi-oriented component is done using Support Vector Machine classifier. Generalized Hough Transform (GHT) is used to detect the seal and a voting is casted for finding possible location of the seal object in a document based on these spatial feature descriptor of components pairs. The peak of votes in GHT accumulator validates the hypothesis to locate the seal object in a document. Experimental results show that, the method is efficient to locate seal instance of arbitrary shape and orientation in documents.	accumulator (computing);angularjs;basic stamp;connected component (graph theory);feature vector;generalised hough transform;object detection;support vector machine;visual descriptor	Partha Pratim Roy;Umapada Pal;Josep Lladós	2010		10.1145/1774088.1774094	support vector machine;computer vision;speech recognition;connected component;computer science;machine learning;pattern recognition	Vision	40.10374961488827	-56.73006626356387	136680
e62eaafad7f7b53606ade3e3a446136d005a82a6	construction of wavelets for width-invariant characterization of curves	image processing;edge detection;general solution;wavelet transform;pattern recognition;width invariance;construction of wavelets;wavelet	This paper studies the construction of a special kind of wavelets which are used for width-invariant characterization of curves in an image. The general solutions of such wavelets are obtained. At last, two examples are given and an experiment to support the construction is conducted.	wavelet	Lihua Yang;Zhihua Yang;Xingming Sun	2003	Pattern Recognition Letters	10.1016/S0167-8655(03)00118-1	wavelet;computer vision;mathematical analysis;edge detection;continuous wavelet transform;image processing;computer science;legendre wavelet;mathematics;geometry;discrete wavelet transform;fast wavelet transform;lifting scheme;gabor wavelet;wavelet transform	Vision	50.46477280613717	-62.857445248905904	136906
49db059ed7a2ed6ef0f50632b7be576eabc18dc1	surface approximation from industrial sem images	surface approximation	We are currently involved in an industrial project to recover depth information from stereo image pairs retrieved using a scanning electron microscope, (SEM). Feature based approaches to stereo provide accurate disparity estimations, however the quantity of estimates recovered is small (typically 1-2% of the image). If a continuous approximation to the surface is to be reconstructed, as requested by potential customers, more data has to be recovered. Our approach involves using the disparity estimates from a feature based stereo algorithm to constrain a function tting process. Assuming the image may be represented by an iterated facet model, the algorithm attempts to t piecewise polynomials between the feature disparity estimates, which describe the mapping of grey-levels from the left to right image along epi-polars. The problems of illumination variation between the left and right images have been addressed using a modiication to rank-order ltering which we calìsoft' ranking. The tted functions are then used to calculate intermediate disparities.	algorithm;approximation;binocular disparity;electron;grayscale;image scanner;iteration;polynomial	A. J. Lacey;Neil A. Thacker;R. B. Yates	1996		10.5244/C.10.28	computer science	Vision	53.341944453091074	-55.11917450179125	137015
fe3724914588f4c1b8b9420c53900d1aad1d47e9	applying the multi-category learning to multiple video object extraction	traitement signal;video object;evaluation performance;deteccion blanco;performance evaluation;learning;evaluacion prestacion;maquina vector soporte;journal;ψ learning;detection cible;aprendizaje;etat actuel;learning support;detection objet;accuracy;machine vecteur support;apprentissage;multiple objectives;precision;machine learning;multi class classification;feature extraction;signal processing;state of the art;multimedia communication;signal classification;object extraction;poursuite cible;psi learning;support vector machines svm;classification signal;estado actual;category learning;extraccion objeto;support vector machine;vo extraction;extraction caracteristique;classification automatique;target tracking;multiple object tracking;communication multimedia;automatic classification;procesamiento senal;target detection;clasificacion automatica;ψ;extraction objet;object detection	Video object (VO) extraction is of great importance in multimedia processing. In recent years approaches have been proposed to deal with VO extraction as a classification problem. This type of methods calls for state-of-the-art classifiers because the performance is directly related to the accuracy of classification. Promising results have been reported for single object extraction using support vector machines (SVM) and its extensions. Multiple object extraction, on the other hand, still imposes great difficulty as multi-category classification is an ongoing research topic in machine learning. This paper introduces a new scheme of multi-category learning for multiple VO extraction, and demonstrates its effectiveness and advantages by experiments. 2008 Elsevier Ltd. All rights reserved.	algorithm;computational complexity theory;concept learning;digital video;euro-vo;experiment;information extraction;machine learning;multiclass classification;performance;statistical classification;support vector machine;video content analysis	Yi Liu;Yuan F. Zheng;Xiaotong Shen	2008	Pattern Recognition	10.1016/j.patcog.2008.02.007	computer vision;computer science;machine learning;signal processing;pattern recognition;accuracy and precision	AI	44.45473161726198	-59.596915566355136	137378
669b41b1337cf1383a4f368d5a0dc7e07bec5977	vehicle tracking and traffic parameter extraction based on discrete wavelet transform	transformation ondelette;vision ordenador;trajectoire;dwt;transformacion discreta;discrete wavelet transform;image processing;formacion;occlusion;road traffic;real time;occultation;trafic urbain;real time traffic;procesamiento imagen;arteria;oclusion;ondita discreta;discrete time;urban traffic;intelligence artificielle;traitement image;extraccion parametro;parameter extraction;formation;computer vision;trafico urbano;circulatory system;its;extraction parametre;trajectory;trafic routier;monitoring;machine vision;temps reel;traffic parameter extraction;discrete wavelet;poursuite cible;discrete transformation;ondelette discrete;tiempo real;artificial intelligence;trafico carretera;vision ordinateur;trayectoria;vision artificielle;inteligencia artificial;monitorage;transformacion ondita;vehicle tracking;target tracking;tiempo discreto;ocultacion;temps discret;appareil circulatoire;monitoreo;artificial vision;aparato circulatorio;transformation discrete;artery;artere;wavelet transformation;vision artificial	Real time traffic monitoring is one of the most challenging problems in machine vision. In this paper, we describe a method for multiple vehicles tracking and traffic parameters extraction based on Discrete Wavelet Transform. Occlusion is effectively resolved by our method. In order to describe the traffic characteristics, some important traffic parameters are extracted, such as vehicle trajectory, vehicle speed and vehicle count. Discrete wavelet transform is used to prevent the disturbance of fake motions. Experimental results are presented to demonstrate the effective tracking of vehicles on an urban artery.	discrete wavelet transform;vehicle tracking system	Jun Kong;Huijie Xin;Yinghua Lu;Bingbing Li;Yanwen Li	2006		10.1007/11941439_52	computer vision;discrete time and continuous time;simulation;machine vision;occultation;image processing;computer science;trajectory;circulatory system;cascade algorithm;discrete wavelet transform;lifting scheme	EDA	48.301185056890844	-57.13391317999009	137466
b6cb8c9711cbf50cd53b27ce48a94ecd3b5e6ffb	some segmentation processes for application with a spoke filter	texture;image processing;decision bayes;gradiente;procesamiento imagen;segmentation;imagen nivel gris;gradient;bayes decision;traitement image;algorithme;algorithm;algorritmo;pixel;image niveau gris;textura;grey level image;segmentacion	Abstract   Two methods of segmentation are examined. Each uses a spoke filter to localise these processes to small windows within the image. The two techniques each use gradient and texture information.		K. C. Markham	1987	Pattern Recognition Letters	10.1016/0167-8655(87)90074-2	computer vision;image processing;computer science;texture;scale-space segmentation;gradient;segmentation;algorithm;pixel;computer graphics (images)	Vision	46.9654433318725	-63.72656576026988	137533
fe910399235285238a0a415dddb3cb7f3766dec8	combining singular points and orientation image information for fingerprint classification	sistema interactivo;evaluation performance;image recognition;reconocimiento imagen;base donnee;singularite;fingerprints classification;performance evaluation;biometrie;evaluacion prestacion;maquina vector soporte;biometrics;database;biometria;base dato;non linear model;modele non lineaire;singular points;orientation model;processing time;systeme conversationnel;algorithme;feature vector;algorithm;machine vecteur support;large scale;modelo no lineal;automatic recognition;interactive system;dactyloscopie;signal classification;reconnaissance image;punto singular;singularidad;pattern recognition;classification signal;temps traitement;reconnaissance forme;support vector machine;classification automatique;reconocimiento patron;automatic classification;clasificacion automatica;tiempo proceso;point singulier;fingerprint identification;reconocimiento automatico;reconnaissance automatique;singularity;algoritmo;singular point	Fingerprint classification is crucial to reduce the processing time in a large-scale database. Two popular features used are the singularities and orientation information and they are complementary. Therefore, an algorithm based on the interactive validation of singular points and the constrained nonlinear orientation model is proposed. The final features used for classification comprises the coefficients of the orientation model and the singularity information. This resulted in very compact feature vector which is used as input to an SVM classifier to perform the classification. The experiments conducted on the NIST database 4 show the effectiveness of the proposed method in producing good classification result. 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	algorithm;coefficient;computation;experiment;feature vector;fingerprint;interdependence;nonlinear system;pattern recognition;statistical classification;technological singularity	Jun Li;Wei-Yun Yau;Han Wang	2008	Pattern Recognition	10.1016/j.patcog.2007.03.015	singularity;support vector machine;fingerprint;computer vision;singular point of a curve;feature vector;computer science;artificial intelligence;machine learning;mathematics;algorithm;biometrics	Vision	44.934869878692574	-60.20678909242054	137623
886ad5658bc004b14281803b4adc486b174cf344	new panoramic image generation based on modeling of vignetting and illumination effects	lens distortion;modelizacion;multimedia;image processing;image formation;illumination;generic algorithm;panoramic photography;perspective projection;luminance;procesamiento imagen;photographie panoramique;traitement image;fotografia panoramica;identificacion sistema;modelisation;reconstruction image;system identification;reconstruccion imagen;image realiste;image reconstruction;image sequence;estimacion parametro;projection perspective;realistic images;secuencia imagen;panoramic image;parameter estimation;estimation parametre;proyeccion perspectiva;modeling;eclairement;identification systeme;sequence image;alumbrado;luminancia	In this paper, a new panoramic image generation algorithm is proposed based on more realistic image formation processes. Perspective projection, lens distortion, vignetting and illumination effects are incorporated into the proposed panoramic modeling. Intrinsic and extrinsic camera parameters are estimated by the proposed stable camera parameter estimation algorithm derived from panning camera constraints. This paper shows that accurate panoramic images can be reconstructed based on the proposed camera modeling and parameters estimation. The effectiveness of the proposed algorithm is also shown with several image sequences in terms of reconstruction error from the generated panoramic image.		Dong-Gyu Sim	2005		10.1007/11581772_1	distortion;iterative reconstruction;computer vision;perspective;systems modeling;genetic algorithm;system identification;image processing;computer science;luminance;estimation theory;image formation;computer graphics (images)	Vision	51.44305535924697	-56.92032225285889	137636
d2743517226fa476975d94e5035c0f6d617460e6	statistical image modeling in the contourlet domain using contextual hidden markov models	modelizacion;traitement signal;hidden markov tree;evaluation performance;performance evaluation;ligne de base;hidden markov model;evaluacion prestacion;modele markov variable cachee;informacion mutual;probabilistic approach;reduccion ruido;modelisation;etat actuel;information mutuelle;hidden markov models;enfoque probabilista;approche probabiliste;signal processing;noise reduction;state of the art;contourlet;reduction bruit;baseline;linea de base;mutual information;estado actual;procesamiento senal;modeling;image modeling;context design	In this paper, a contourlet contextual hidden Markov model (C-CHMM) is established for modeling contourlet images by adapting a previous CHMM for wavelet images (W-CHMM). A mutual information based context design procedure is presented, through which a new context has been constructed. The C-CHMM is tested in a denoising application with promising results, which verifies its effectiveness. This new model is demonstrated to be a better model for contourlet images than the state of the art contourlet hidden Markov tree model. As a general image model, it also shows more potential than the baseline W-CHMM. & 2008 Elsevier B.V. All rights reserved.	baseline (configuration management);contourlet;hidden markov model;image processing;markov chain;mutual information;noise reduction;wavelet;wavelet transform	Zhiling Long;Nicolas H. Younan	2009	Signal Processing	10.1016/j.sigpro.2008.11.011	computer vision;contourlet;speech recognition;systems modeling;computer science;pattern recognition;noise reduction;mutual information;baseline;hidden markov model	Vision	45.20666991887934	-61.340229829070765	137683
fe314dd21c3f04c966874774c0afecf608848c02	extraction of shape features for syntactic recognition of mechanical parts	componente mecanico;plane shape shape feature extraction pattern recognition syntactic recognition mechanical parts boundary representation contour descriptors global features;lenguaje de programacion;fabricacion asistida por computador;programming language;mechanical component;composant mecanique;fabrication assistee;feature extraction shape switches cybernetics syntactics machining correlation;rainure;computer aided manufacturing;groove;pattern recognition;langage programmation;reconnaissance forme;reconocimiento patron;ranura	A language for describing the shape of those mechanical parts modeled by the rotational or translational sweeping (based on boundary representation) is presented. Each boundary is represented by a contour composed of primitives from the specified set. A work (in the mentioned language) is the description of a given contour and constitutes an input to the detector (transducer). Its output is a compact representation of the contour (i.e. mechanical part). This output is a sequence of descriptors, each consisting of two characters, and their meaning allows regions (features) to be extracted and exactly characterized. These regions are arranged to form global features such as grooves, flanks, complex grooves, and cascades. The global features, which have the important technology meaning, are extracted by means of very simple algorithms. These algorithms may be applied for extracting features of an arbitrary plane shape described in the language developed.	algorithm;boundary representation;data descriptor;transducer	Ryszard Jakubowski	1985	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1985.6313442	groove;computer vision;computer science;computer-aided manufacturing	Vision	47.984885773148264	-61.37335149626332	137733
824e10aad785cabe7b9957d3bcec167c5d6e5f9e	grid-based multi-scale pca method for face recognition in the large face database	reconnaissance visage;distributed system;analisis componente principal;haute performance;systeme reparti;image processing;facies;image databank;base donnee tres grande;multigrille;service web;procesamiento imagen;web service;traitement image;grid;sistema repartido;face recognition;rejilla;principal component analysis;banco imagen;multigrid;banque image;multigrilla;analyse composante principale;pattern recognition;component analysis;alto rendimiento;grille;reconnaissance forme;very large databases;reconocimiento patron;high performance;multimedia services;servicio web;variance;variancia	In this paper, we propose an efficient grid-based multi-scale PCA method in the large face database. This method divides the large face database into some small sub-face databases by maximizing the variance in the face sub-database and minimizing the variance between the face sub-databases, then it segments the recognition process into the local coarse profile recognition process and accurate detailed geometric sub-component analysis process, and assigns the local coarse profile recognition process to the nodes of the multimedia service grid to reduce the recognition time. Our experimental results show that with the increase of the face database, this method not only reduces the recognition time, but also remarkably increases the recognition precision, compared with other PCA methods.	facial recognition system	Haiyang Zhang;Huadong Ma;Anlong Ming	2006		10.1007/11610496_144	web service;simulation;facies;image processing;computer science;artificial intelligence;variance;grid;multigrid method;statistics;principal component analysis	Vision	44.14759270690558	-60.824597902093096	137789
087a3f3d09b55c54fd0b0ed57a9d358a7b9876b3	texture classification and segmentation using wavelet packet frame and gaussian mixture model	transformation ondelette;analisis contenido;traitement signal;processus gauss;mosaicism;gaussian mixture;image segmentation;image processing;analisis textura;classification non supervisee;mosaicisme;texture classification;kullback leibler divergence;texture image;procesamiento imagen;texture segmentation;texture features;high precision;wavelet packet;traitement image;fabric defect detection;wavelet packet frame;image texture;content analysis;texture analysis;gaussian mixture model;detection defaut;feature extraction;signal processing;precision elevee;clasificacion no supervisada;segmentation image;signal classification;precision elevada;classification signal;unsupervised classification;teoria mezcla;mosaicismo;transformacion ondita;gaussian process;extraction caracteristique;analyse contenu;classification automatique;proceso gauss;automatic classification;mixture theory;procesamiento senal;clasificacion automatica;theorie melange;analyse texture;deteccion imperfeccion;wavelet transformation;defect detection	In this paper, we propose a scheme for texture classification and segmentation. The methodology involves an extraction of texture features using the wavelet packet frame decomposition. This is followed by a Gaussian-mixture-based classifier which assigns each pixel to the class. Each subnet of the classifier is modeled by a Gaussian mixture model and each texture image is assigned to the class to which pixels of the image most belong. This scheme shows high recognition accuracy in the classification of Brodatz texture images. It can also be expanded to an unsupervised texture segmentation using a Kullback–Leibler divergence between two Gaussian mixtures. The proposed method was successfully applied to Brodatz mosaic image segmentation and fabric defect detection. 2006 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	feature extraction;google map maker;image segmentation;kullback–leibler divergence;mixture model;pattern recognition;pixel;software bug;subnetwork;wavelet	Soo Chang Kim;Tae Jin Kang	2007	Pattern Recognition	10.1016/j.patcog.2006.09.012	image texture;computer vision;speech recognition;content analysis;image processing;feature extraction;computer science;signal processing;pattern recognition;mixture model;gaussian process;mathematics;image segmentation;kullback–leibler divergence;scale-space segmentation;texture compression;texture filtering	Vision	44.883000677195	-61.26981896601742	137793
1c3e54befd18a7498ae3a3196c3ede4f585d7682	view-invariant human action recognition based on factorization and hmms	low dimensional system;motion analysis;modelo dinamico;traitement signal;linear combination;evaluation performance;modelo cuerpo homano;matrix factorization;tecnologia electronica telecomunicaciones;performance evaluation;systeme basse dimensionnalite;view invariant;hidden markov model;evaluacion prestacion;dynamic model;modele markov variable cachee;analyse mouvement;shape measurement;probabilistic approach;factorisation matricielle;human body model;discriminant analysis;analyse discriminante;descomposicion matricial;analisis discriminante;markov model;hidden markov models;decomposition matricielle;combinacion lineal;matrix decomposition;enfoque probabilista;approche probabiliste;signal processing;action recognition;modele dynamique;pattern recognition;modele corps humain;reconnaissance forme;analisis movimiento;tecnologias;reconocimiento patron;grupo a;procesamiento senal;factorizacion matricial;mesure forme;combinaison lineaire	One of the fundamental challenges of human action recognition is accounting for the variability that arises during video capturing. For a specific action class, the 2D observations of different instances might be extremely different due to varying viewpoint when the sequences are captured by moving cameras. The situation is even worse if the actions are executed at different rates. In this paper, a novel view-invariant human action recognition method is proposed based on non-rigid factorization and Hidden Markov Models (HMMs). By assuming that the execution of an action can be approximated by dynamic linear combination of a set of basis shapes, we show that the weight coefficients of basis shapes by measurement matrix non-rigid factorization contain crucial information for action recognition regardless of the viewpoint. Based on the extracted discriminative features, the HMMs is used for action modeling and classification. The performance of the proposed method has been successfully demonstrated experimentally using real sequences.	approximation algorithm;coefficient;experiment;hidden markov model;markov chain;spatial variability;statistical classification	Xi Li;Kazuhiro Fukui	2007		10.1093/ietisy/e91-d.7.1848	computer science;artificial intelligence;machine learning;mathematics;matrix decomposition;algorithm;hidden markov model	Vision	46.50613873390766	-57.43823452248524	137854
a8935eb1d4b442b63084317bf1dab9104df0ddae	centerline detection on partial mesh scans by confidence vote in accumulation map	data mining;vegetation;casting;shape;three dimensional displays;image reconstruction;robustness	This paper proposes an original method for extracting the centerline of 3D objects given only partial mesh scans as input data. Its principle relies on the construction of a normal vector accumulation map build by casting digital rays from input vertices. This map is then pruned according to a confidence voting rule: confidence in a point increases if this point has maximal votes along a ray. Points with high confidence accurately delineate the centerline of the object. The resulting centerline is robust enough to allow the reconstruction of the associated graph by a simple morphological processing of the confidence and a geodesic tracking. The overall process is unsupervised and only depends on a user-chosen maximal object radius. Experiments show a good behavior on standard mesh scans. Moreover, the proposed method is not only competitive with state-of-the-art methods on perfect data, but appears to be much more reliable on imperfect or damaged data, like holes, partial scans, noise, and scans from only one direction.	algorithm;ct scan;connected component (graph theory);connected-component labeling;experiment;maximal set;normal (geometry);tree accumulation;unsupervised learning	Bertrand Kerautret;Adrien Krähenbühl;Isabelle Debled-Rennesson;Jacques-Olivier Lachaud	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7899829	iterative reconstruction;computer vision;casting;shape;computer science;machine learning;data mining;geometry;vegetation;robustness	Vision	48.702749457029	-52.989005533579764	137872
1a1f5896e2b411fdb2852494b0618a35aafa2730	joint detection, interpolation, motion and parameter estimation for image sequences with missing data	analisis imagen;image processing;motion pictures;dato que falta;procesamiento imagen;prior knowledge;traitement image;statistical model;donnee manquante;reconstruction image;reconstruccion imagen;image reconstruction;image sequence;modele statistique;image analysis;modelo estadistico;3 dimensional;digital video;missing data;parameter estimation;analyse image	This paper presents methods for detection and reconstruction of ‘missing’ data in image sequences which can be modelled using 3-dimensional autoregressive (3DAR) models. The interpolation of missing data i s i m portant in m a n y areas of image processing, including the restoration of degraded motion pictures, reconstruction of drop-outs in digital video and automat ic ‘re-touching ’ of old photographs. Here a probabilistic Bayesian framework i s adopted. T h e method assumes n o pr ior knowledge of the motion field or 3DAR model parameters as these are estimated jointly with the missing image pixels. Incorporating a degradation model in to the framework allows detection t o proceed jointly with interpolation.	autoregressive model;bayesian network;circuit restoration;digital video;elegant degradation;estimation theory;image processing;interpolation;missing data;motion field;pixel	Anil C. Kokaram;Simon J. Godsill	1997		10.1007/3-540-63508-4_188	iterative reconstruction;statistical model;three-dimensional space;computer vision;image analysis;missing data;image processing;pattern recognition;estimation theory;statistics	Vision	51.79005628230275	-57.02292495748223	137893
f41049fb175fdb02951b9f7a6892c77aee305ecb	a new color constancy algorithm based on the histogram of feasible mappings	analisis imagen;vision ordenador;image processing;illumination;image databank;color constancy;color;comunicacion de congreso;luminance;procesamiento imagen;color histogram;traitement image;computer vision;histogram;histogramme;machine vision;banco imagen;banque image;color mappings;pattern recognition;color histograms;image analysis;vision ordinateur;reconnaissance forme;reconocimiento patron;imagen color;histograma;pattern recognition computer vision;eclairement;analyse image;image couleur;color image;alumbrado;luminancia	Color is an important cue both in machine vision and image processing applications, despite its dependence upon illumination changes. We propose a color constancy algorithm that estimates both the set and the likelihood of feasible color mappings in respect to their frequency and effectiveness. The best among this set is selected to rendered back image colors as seen under a canonical light. Experiments were done to evaluate its performance compared to Finlayson’s 2D gamut–mapping algorithm, outperforming it. Our approach is a helpful alternative wherever illumination is poorly known since it employs only image data.	algorithm;color management;computation;image processing;machine vision;map	Jaume Vergés-Llahí;Alberto Sanfeliu	2005		10.1007/11559573_88	color histogram;computer vision;image analysis;color normalization;color image;machine vision;image processing;computer science;histogram;mathematics;luminance;color balance;color constancy;computer graphics (images)	Vision	45.75906842503309	-60.08281792089456	137918
26bbad5071c1a9a7bb01f7f240a19336e009a3c7	the iterative object symmetry transform	iterative methods;fourier transforms;face recognition	This paper introduces a new operator named the Iterated Object Transform that is computed by combining the Object Symmetry Transform with the morphological operator erosion. This new operator has been applied on both binary and gray levels images showing the ability to grasp the internal structure of a digital object. We present some experiments on real images in face analysis.	bitwise operation;experiment;grayscale;iterated function;iterative method;virtual artifact	Bertrand Zavidovique;Vito Di Gesù	2004	2004 International Conference on Image Processing, 2004. ICIP '04.		facial recognition system;fourier transform;computer vision;object-class detection;computer science;viola–jones object detection framework;machine learning;pattern recognition;mathematics;iterative method	Robotics	42.225933503016165	-64.4851969876695	137992
9373cdb27aebf39fea893bf36f21f592ccdca8a2	fast distance computation with a stereo head-eye system	geometria euclidiana;image recognition;comprension imagen;reconocimiento imagen;vision ordenador;video signal processing;geometrie euclidienne;representation image;prior knowledge;euclidean distance;computer vision;human visual system;image representation;reconnaissance image;pattern recognition;traitement signal video;comprehension image;euclidean geometry;vision ordinateur;reconnaissance forme;camera calibration;reconocimiento patron;image comprehension	In this paper, a fast method is presented for computing the 3D Euclidean distance with a stereo head-eye system using a disparity map, a vergence angle, and a relative disparity. Our approach is to use the dense disparity for an initial vergence angle and a fixation point for its distance from a center point of two cameras. Neither camera calibration nor prior knowledge is required. The principle of the human visual system is applied to a stereo head-eye system with reasonable assumptions. Experimental results show that the 3D Euclidean distance can be easily estimated from the relative disparity and the vergence angle. The comparison of the estimated distance of objects with their real distance is given to evaluate the performance of the proposed method.	computation	Sang-Cheol Park;Seong-Whan Lee	2000		10.1007/3-540-45482-9_44	euclidean geometry;computer vision;camera resectioning;simulation;computer science;euclidean distance;mathematics;human visual system model;computer graphics (images)	Robotics	49.96337701719299	-57.11028411097651	138179
901205214f7883d20611ec86bad30a8fdf679dec	partially occluded leaf recognition via beta-spline curve matching and energy minimization		We present an approach to classify partially occluded plant leaves. Although contour based 2D shape matching has been studied extensively in the last couple of decades, handling occlusion is still a challenging task. Classifying plant leaves is even more challenging due to the large intra class variations and complex leaf structures. Matching an occluded contour with all the full contours in the database is an NP-hard problem. To the best of our knowledge, classifying occluded plant leaves has not been studied before. We propose a suboptimal solution to match an occluded leaf (tested on leaves with up to 50 percent occlusion of its contour) and classify the species from the database. #R##N#First, we represent the 2D contour points as a Beta-Spline curve. After smoothing the spline, we extract interest points on the contour via Discrete Contour Evolution (DCE). To find the best match of the occluded curve with the full leaves in the database, we formulate our solution as a subgraph matching algorithm using the feature points as graph nodes. After undoing the affine transform (rotation, translation, scaling and shear) of the occluded curve, we keep the first five best matched curves based on the Frechet distance measure. Then we formulate an objective function involving local and global curvature, angular information and local geometric features and then minimize this energy using the well known convex-concave relaxation technique. The curve section having the minimum energy is considered to be the best match with the occluded leaf. Experiments on 3 publicly available leaf image database shows that our method outperforms state of the art.	energy minimization;spline (mathematics)	Ayan Chaudhury;John L. Barron	2017	CoRR		computer vision;pattern recognition;mathematics;geometry	Vision	41.133959279068755	-57.25259001330902	138234
b8d90a0140c4778454a2de6299bba5dac33518c6	a note on the iterative object symmetry transform	mathematical morphology;image classification;morphological operation;internal structure;feature extraction;symmetry transforms	This paper introduces a new operator named the iterated object transform that is computed by combining the object symmetry transform with the morphological operator erosion. This new operator has been applied on both binary and gray levels images showing the ability to grasp the internal structure of a digital object. We present also some experiments on artificial and real images and potential applications. 2004 Elsevier B.V. All rights reserved.	bitwise operation;experiment;grayscale;iteration;iterative method;virtual artifact	Vito Di Gesù;Bertrand Zavidovique	2004	Pattern Recognition Letters	10.1016/j.patrec.2004.03.017	computer vision;contextual image classification;mathematical morphology;feature extraction;computer science;machine learning;pure mathematics;mathematics;geometry;top-hat transform	Vision	42.29494207302168	-64.60524031616916	138245
8a8fa2f5572011e9a861682f061e16afe1ddf74b	contour-detection using the shape of the nearest neighbors set (nn-set)	image segmentation;nearest neighbor;digital image	In this paper, we present an algorithm for detecting the contour-points of digital images. The proposed method is mainly based on the shape of the pixels set that are the nearest neighbors (NN-set) of the actual pixel. Several algorithms of image segmentation use this concept of nearest neighbors, but using the shape of this set seems to be a new approach.	contour line	Jean Pierre Asselin de Beauville;M. C. Mraghni	1993		10.1007/3-540-57233-3_22	nearest-neighbor chain algorithm;r-tree;computer vision;nearest neighbor graph;best bin first;computer science;image segmentation;nearest neighbor search;k-nearest neighbors algorithm;digital image	Vision	42.15254095185962	-65.58748953307749	138273
fd7444b7c36b45b8e15f0f62f51c12128f200672	a novel description of handwritten characters for use with generalised fourier descriptors	fourier descriptors	A new description is developed for handwritten character recognition for Western style characters. Character recognition here is based on Generalised Fourier Descriptors (GFDs). The characters are described by sections which are either straight line pieces or arcs of circles. Analytical expressions exist for the GFDs of these two types of curves. In order to apply these expressions on handwritten characters, these characters are first curve-fitted into straight linepieces and arcs of circles. After this description the GFDs can easily be calculated. Experiments were performed and preliminary, qualitative remarks on these are made.	curve fitting;experiment;handwriting recognition;optical character recognition	Leon-Paul W. Niemel;Ramjee Prasad	1992	European Transactions on Telecommunications	10.1002/ett.4460030506	arithmetic;computer science;artificial intelligence;mathematics;algorithm	Vision	49.89135209421236	-61.432432916505796	138371
2bd8b60c85316bad8eed3e1e0c00865fb78ca234	3-d surface reconstruction using spatial frequency based approaches under influence of perspective distortion		The use of local spatial frequency provides a powerful analytical tool for image analysis. This dissertation provides an improved solution to long-standing problems in stereo vision; foreshortening, ambiguous matches, detecting and handling discontinuities and occlusion, and quantitative evaluation of stereo results. Challenges arise from the fact that stereo images are acquired from slightly different views. Therefore, the projection of the surface in the image plane is more compressed and occupied a smaller area in one view than the other. This effect makes the matching of its two images very difficult and leads to confusing results. That is because, while corresponding two images N pixels on a scanline in one image may correspond to a different number of M pixels in the other image. In this research, a new approach called local-spatial-frequency approach is proposed to combine the localizability of the spatial approach and the analytical benefits of the frequency approach. To simplify the matching process the prescribed system consists of a combination of stereo vision concept and the structured light concept. We also provide a solution for the long-standing problems in stereovision in two suggested algorithms: The first algorithm is based on the output of linear spatial filters tuned to a range of orientations and scales that make the correspondence analysis more reliable and robust. The responses of these filters at a given pixel constitute a vector called filter response vector (FRV). This vector is correlated instead of correlating area in the two images. The correspondence problem can be solved by seeking points in the other view where this vector is maximally similar. In addition, an automatic procedure is used to evaluate and optimize the filters set by using the Steering theorem and the singular value decomposition (SVD). The projective distortion regions are detected to improve the quality of the disparity estimation by adapting to the size of filter kernel. One of the major contributions of this algorithm appears while detecting and handling the depth discontinuities in order to improve the quality of the initial estimate disparity map. The algorithm maintains a current best estimate of the viewing parameters (to constrain vertical disparity to be consistent with epipolar geometry), a visibility map (to record whether a point is binocularly visible or occluded) and a	algorithm;binocular disparity;correspondence analysis;correspondence problem;data compression;distortion;epipolar geometry;image analysis;image plane;internationalization and localization;pixel;scan line;sensor;singular value decomposition;stereopsis;structured light	Sherif Said Aly el-Etriby	2008			computer vision;perspective distortion;surface reconstruction;spatial frequency;artificial intelligence;mathematics	Vision	52.53953487775655	-55.74943781854279	138377
4d5b8fcc927413a7a47028d4cc7ed6cb7b058f93	collision and event detection using geometric features in spatio-temporal volumes	ridge;video signal processing;spatio temporal volume;edge detection;computational geometry;event detection;geometric feature;collision detection;occlusion edge;event detection computer vision image edge detection object detection optical computing image sequences image motion analysis video sequences geometrical optics layout;image sequence;spatiotemporal phenomena;curvature;curvature event detection collision detection occlusion edge spatio temporal volume ridge;optical flow;collision avoidance;image sequences event detection collision detection occlusion edge spatiotemporal volume geometric features temporal collision maximum principal curvature principal curvature direction overlapping object events optical flow;spatiotemporal phenomena video signal processing edge detection image sequences computational geometry collision avoidance;image sequences	In video sequences, edges in 2D images (frames) produces 3D surface in the spatio-temporal volume, in this paper, we propose to consider temporal collisions between edges, and thus objects, as 3D ridges in the spatio-temporal volume. Collisions (i.e. ridge points) can be located using the maximum principal curvature and the principal curvature direction. Using the detected collisions, we then propose a technique to detect overlapping objects events in an image sequence, by neither computing depth or optical flow. We present successful experiments on real image sequences.	computation;contour line;experiment;linear algebra;optical flow;signal-to-noise ratio	Mathieu Marquis Bolduc;François Deschênes	2005	The 2nd Canadian Conference on Computer and Robot Vision (CRV'05)	10.1109/CRV.2005.26	computer vision;ridge;edge detection;computational geometry;computer science;optical flow;mathematics;geometry;curvature;collision detection	Vision	49.35879060616676	-54.568070255045626	138448
e41a81f7abe0965a29973fd9e39e5daf3b3bcee4	using the local phase of the magnitude of the local structure tensor for image registration	engineering and technology;local structure;teknik och teknologier;medical image;non rigid registration;image registration	The need of image registration is increasing, especially in the medical image domain. The simplest kind of image registration is to match two images that have similar intensity. More advanced cases include the problem of registering images of different intensity, for which phase based algorithms have proven to be superior. In some cases the phase based registration will fail as well, for instance when the images to be registered do not only differ in intensity but also in local phase. This is the case if a dark circle in the reference image is a bright circle in the source image. While rigid registration algorithms can use other parts of the image to calculate the global transformation, this problem is harder to solve for non-rigid registration. The solution that we propose in this work is to use the local phase of the magnitude of the local structure tensor, instead of the local phase of the image intensity. By doing this, we achieve invariance both to the image intensity and to the local phase and thereby only use the structural information, i.e. the shapes of the objects, for registration.	algorithm;image registration;structure tensor	Anders Eklund;Daniel Forsberg;Mats T. Andersson;Hans Knutsson	2011		10.1007/978-3-642-21227-7_39	homography;image restoration;computer vision;feature detection;computer science;image registration;geometry	Vision	52.19773499536407	-54.07620306655689	138475
55b62d9f9c3d15814a2775376a0e5048111208d8	optimal discretization for stereo reconstruction	methode discretisation;image tridimensionnelle;ccd camera;vision ordenador;vision estereoscopica;teoria shannon;sistema informatico;optimal estimation;analisis correspondencia;vision stereoscopique;computer system;computer vision;metodo discretizacion;reconstruction image;reconstruccion imagen;structure resolution;image reconstruction;correspondence analysis;shannon theory;pixel;theorie shannon;resolucion estructural;analyse correspondance;camara ccd;tridimensional image;camera ccd;discretization method;vision ordinateur;systeme informatique;estimation optimale;stereopsis;resolution structurale;imagen tridimensional;estimacion optima	Basu, A., Optimal discretization for stereo reconstruction, Pattern Recognition Letters 13 (1992) 813-820. A significant amount of research has been done on designing sensors for digitizing visual images. Over the years vidicon and CCD technologies have been developed to improve sensor performance. However the problem of how the sensors should be distributed over a two-dimensional array has been largely overlooked. Sensor resolution is often determind by industry and international standards, and has little to do with the problem for which it is being used. In this work we investigate the optimal horizontal and vertical resolution (given the total resolution) for solving the problem of stereo-reconstruction. We show that the best arrangement of sensor elements depends on both the parameters of a stereo system and the assumptions on the 3-D scene,	array data structure;charge-coupled device;correspondence problem;discretization;nyquist–shannon sampling theorem;pattern recognition letters;pixel;sampling (signal processing);sensor;shannon (unit);video camera tube	Anup Basu	1992	Pattern Recognition Letters	10.1016/0167-8655(92)90132-J	iterative reconstruction;optimal estimation;computer vision;information theory;computer science;stereopsis;charge-coupled device;correspondence analysis;pixel;computer graphics (images)	Vision	51.3306945258476	-58.41639014335967	138678
b056f6f92ae7b4dc4974654f4f4d55ad687c2066	shape matching of 3d topologically segmented objects		Shape matching of 3D digital objects is an important domain of study from topological as well as geometric point of view. Shape matching of two or more digital objects by an efficient segmentation-based method is reported in this paper. The method receives input objects after segmentation of their articulated components and exploits the topological relation between the articulated components and the central section of the objects for shape matching. The method involves simple calculations and is primarily based on the extent of articulations in the objects. The accuracy of shape matching is dependent on the object size and segmentation of the object and is invariant to rotation. Experimental results are provided to demonstrate the structural similarity in various digital objects.		Nilanjana Karmakar;Arindam Biswas	2016		10.1007/978-3-319-39441-1_16	computer vision;topology;mathematics;geometry	Vision	49.07712155108856	-61.467285353218024	138812
87c66c06d727cb3d8fb234febc4ecf54986c58ef	glcm-based chi-square histogram distance for automatic detection of defects on patterned textures	cluster;defects;fabric images;periodicity;wallpaper;chi square histogram;machine vision;dissimilarity;computer science;grey level co occurrence matrix;patterned textures;defect detection	Chi-square histogram distance is one of the dista nce measures that can be used to find dissimilarity bet ween two histograms. Motivated by the fact that texture discrimination by human vision system is based on second-order sta tistics, we make use of histogram of gray-level co-occurrence m atrix (GLCM) that is based on second-order statistics and propose a new machine vision algorithm for automatic defect detection on patterned textures. Input defective images are s plit into several periodic blocks and GLCMs are computed afte r quantizing the gray levels from 0-255 to 0-63 to ke ep the size of GLCM compact and to reduce computation time. Dissimilarity matrix derived from chi-square distances of the GLCMs is subjected to hierarchical clustering to automatical ly identify defective and defect-free blocks. Effectiveness of the proposed method is demonstrated through experiments on defec tive real-fabric images of 2 major wallpaper groups (pmm and p4m groups). KeywordsChi-square histogram; Cluster; Co-occurrence matrix; Defect; Periodicity	algorithm;chi;cluster analysis;co-occurrence matrix;computation;distance matrix;document-term matrix;experiment;grayscale;hierarchical clustering;machine vision;pentium 4;quasiperiodicity;software bug;time complexity	V. Asha;Nagappa U. Bhajantri;P. Nagabhushan	2011	IJCVR	10.1504/IJCVR.2011.045267	computer vision;wallpaper;machine vision;computer science;cluster;computer graphics (images)	Vision	43.18037822971105	-63.54209579954313	138927
735a29f134445bdcade343ebbb3d3c9f20b61f64	multi-scale gesture recognition from time-varying contours	time varying;time scale;image matching;nonparametric kernel density estimation multiscale gesture recognition time varying contour time varying human gesture dynamic time warping mutual information similarity measure;density estimation;humans hidden markov models shape speech recognition mutual information system testing performance evaluation density measurement kernel robustness;image matching gesture recognition;cumulant;dynamic time warping;gesture recognition	A novel method is introduced to recognize and estimate the scale of time-varying human gestures. It exploits the changes in contours along spatiotemporal directions. Each contour is first parameterized as a 2D function of radius vs. cumulative contour length, and a 3D surface is composed from a sequence of such functions. In a two-phase recognition process, dynamic time warping is employed to rule out significantly different gesture models, and then mutual information (MI) is applied for matching the remaining models. The system has been tested on 8 gestures performed by 5 subjects with varied time scales. The two-phase process is compared against exhaustively testing three similarity measures based upon MI, correlation, and nonparametric kernel density estimation. Experimental results demonstrate that the exhaustive application of MI is the most robust with a recognition rate of 90.6%, however, the two-phase approach is much more computationally efficient with a comparable recognition rate of 90.0%.	algorithmic efficiency;dynamic time warping;gesture recognition;kernel density estimation;mutual information;two-phase commit protocol;two-phase locking	Hong Li;Michael A. Greenspan	2005	Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1	10.1109/ICCV.2005.156	computer vision;speech recognition;density estimation;computer science;dynamic time warping;pattern recognition;gesture recognition;statistics;cumulant	Vision	39.94189946699999	-53.736665166040034	138974
3ca070cac3d573f758d19ab4e3e376d40dfa786c	fast 3d face alignment and improved recognition through pyramidal normal map metric	pyramidal normal map metric;image processing;image resolution;image processing face recognition;iterative closest point method 3d face alignment pyramidal normal map metric biometric identifier face recognition approach 3d face mesh angular distance measurement gallery database;3d face mesh;indexing terms;gallery database;face alignment;biometric identifier;iterative closest point method;iterative methods;face recognition;visual databases face recognition image registration image representation image resolution iterative methods;image representation;image registration;face recognition approach;iterative closest point;face recognition shape biometrics iterative methods iterative closest point algorithm principal component analysis image recognition rough surfaces surface roughness databases;3d face alignment;angular distance measurement;visual databases	Face's tri-dimensional shape represents a highly discriminating yet challenging biometric identifier due to different issues, some of which related to capture, alignment and normalization. This paper presents an improved normal map based face recognition approach, which relies on a novel method to automatically align a captured 3D face mesh to a reference template, allowing a more precise face comparison. The alignment algorithm exploits pyramidal-normal-map metric, a coarse to finer measurement of angular distance between two surfaces computed through normal maps with progressively increasing resolution. After the registration has been performed, the normalized face can be rapidly compared to any other template in the gallery database for authentication or identification purposes using standard normal map metric. The alignment approach avoids the need for a rough or manual face pre-alignment and maximizes recognition precision, requiring a fraction of the time needed by the iterative closest point (ICP) method to operate. We show preliminary experimental results on a 3D dataset featuring 235 different subjects.	algorithm;align (company);angularjs;authentication;biometrics;facial recognition system;identifier;image resolution;iterative closest point;iterative method;map;normal mapping;triangular function	Andrea F. Abate;Michele Nappi;Stefano Ricciardi;Gabriele Sabatino	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4378915	computer vision;index term;image resolution;image processing;computer science;image registration;machine learning;pattern recognition;iterative method;iterative closest point	Vision	42.4186697455046	-58.09847262539483	138979
13b2c020223f637e22c73f8751ae933d25ebb41d	fuzzy clustering with partial supervision in organization and classification of digital images	databases;pattern clustering;fuzzy c mean;columbia object image library fuzzy clustering digital image organization digital image classification web oriented society digital image retrieval fuzzy c means fuzzy sets image clustering;fuzzy set;image databases;separability index angular spectrum signature fuzzy c means fcm fuzzy clustering human centric systems image classification partial supervision relevance feedback;separability index;pattern clustering fuzzy set theory image classification image retrieval;image classification;spectrum;digital images fuzzy sets feedback image retrieval fuzzy systems image classification humans road vehicles societies image analysis;image clustering;fuzzy set theory;fuzzy sets;objective function;digital image classification;distance measurement;fuzzy clustering;visualization;shape;image color analysis;indexation;fuzzy c means;angular spectrum signature;columbia object image library;digital image;organizations;fuzzy c means fcm;digital image organization;partial supervision;relevance feedback;digital image retrieval;web oriented society;human centric systems;image retrieval	In a Web-oriented society, organization, retrieval, and classification of digital images have become one of the major endeavors. In this paper, we study the mechanisms of fuzzy clustering and fuzzy clustering with partial supervision in the analysis and classification of images. It is demonstrated that the main features of fuzzy clustering become essential in revealing the structure in a collection of images and supporting their classification. The discussed operational framework of fuzzy clustering is realized by means of fuzzy c-means (FCM). When dealing with the mode of partial supervision, we augment an original objective function guiding the clustering process by an additional component expressing a level of coincidence between the membership degrees produced by the FCM and class allocation supplied by the user(s). The study also contrasts the use of the technology of fuzzy sets in image clustering with other approaches studied in this area. A suite of experiments deals with two collections of images, namely, Columbia object image library (COIL-20) and a database composed of 2000 outdoor images.	angularjs;cluster analysis;database;digital image;experiment;fuzzy clustering;fuzzy cognitive map;fuzzy set;loss function;mathematical optimization;matthews correlation coefficient;mixed-signal integrated circuit;optimization problem;relevance feedback;visual descriptor	Witold Pedrycz;Alberto Amato;Vincenzo Di Lecce;Vincenzo Piuri	2008	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2008.917287	correlation clustering;computer vision;data stream clustering;defuzzification;fuzzy clustering;image retrieval;flame clustering;fuzzy classification;computer science;artificial intelligence;canopy clustering algorithm;machine learning;pattern recognition;data mining;mathematics;fuzzy set;cluster analysis;fuzzy set operations	Vision	39.68420782473073	-62.53083775002632	139019
75125c95ae89f4e2e6db088124b484e72e50a14c	locating facial features using an anthropometric face model for determining the gaze of faces in image sequences	model based approach;automatic detection;image sequence;face modeling;image processing techniques;facial features;direct detection;aspect ratio	This paper presents a framework that combines a robust facial features location with an elliptical face modelling to measure user’s intention and point of attention. The most important facial feature points are automatically detected using a statistically anthropometric face model. After observing the structural symmetry of the human face and performing some anthropometric measurements, the system is able to build a model that can be used in isolating the most important facial feature areas: mouth, eyes and eyebrows. Combination of different image processing techniques are applied within the selected regions for detecting the most important facial feature points. A model based approach is used to estimate the 3D orientation of the human face. The shape of the face is modelled as an ellipse assuming that the human face aspect ratio (ratio of the major to minor axes of the 3D face ellipse) is known. The elliptical fitting of the face at the image level is constrained by the location of the eyes which considerable increase the performance of the system. The system is fully automatic and classifies rotation in all-view direction, detects eye blinking and eye closure and recovers the principal facial features points over a wide range of human head rotations. Experimental results using real images sequences demonstrates the accuracy and robustness of the proposed solution.	anthropometry;feature recognition;image processing;internationalization and localization;iterative method;sensor;time complexity;yaws	Jorge P. Batista	2007		10.1007/978-3-540-74260-9_75	computer vision;face detection;aspect ratio;speech recognition;object-class detection;computer science;pattern recognition;three-dimensional face recognition;face hallucination	Vision	43.73815947380243	-57.10567217345753	139336
bce7dc93c83f38965eaf4811bc7fa22ce86b8541	a lens collar auto-inspection system	discrete wavelet transforms;optical surface waves;image restoration;light emitting diodes automatic optical inspection ccd image sensors discrete cosine transforms image restoration lenses;inspection;charge coupled devices;discrete cosine transforms;gray levels lens collar auto inspection system surface quality quality assurance nondestructive inspection system ccd system white led coaxial light statistical texture discrete cosine transformation dct image restoration sub function;lenses;lenses image restoration inspection discrete cosine transforms optical surface waves charge coupled devices discrete wavelet transforms	Surface quality of lens collar arouses customers' highly concern. Manual inspection has been a way for quality assurance, but it might cause employees injuries and strenuosity. So it is worthy to introduce a nondestructive inspection system. The proposed system is composed of a CCD, a white LED coaxial light and a motor. The region of interesting (ROI) of lens collar is extracted firstly where is filled with statistical texture. The discrete cosine transformation (DCT) image restoration sub-function reflects textures into high energy components which are then be oppressed by filters. We finally attempt to highlight the defects by defect detection sub-function because of gray levels of textures within a range of limit while defects not.	charge-coupled device;circuit restoration;discrete cosine transform;grayscale;image restoration;region of interest;software bug	Chien-Chih Wang;Ssu-Han Chen	2015	2015 14th IAPR International Conference on Machine Vision Applications (MVA)	10.1109/MVA.2015.7153162	image restoration;computer vision;inspection;computer science;lens	Robotics	53.58665998291051	-61.83082799464405	139388
24a59d4de52dfb1b148fab07beb76b584e4dedf3	convex layers: a new tool for recognition of projectively deformed point sets	proyeccion;image recognition;triangular shape;reconocimiento imagen;vision ordenador;image processing;efficient algorithm;procesamiento imagen;transformacion;forme triangulaire;traitement image;symetrie;symmetry;computer vision;projection;projectively deformed point set;reconnaissance image;forma triangular;vision ordinateur;convex layer;transformation;simetria	A new more efficient algorithm for recognition of projectively deformed point sets is presented. It supposes the type of projective transformation, where the orientation of a triangle is preserved. First, convex layers of two compared sets are computed and left-tangents are found. If their structures are different, then an advanced algorithm is used. It creates the new structure of one set according to the other set. If the numbers of the points in the convex layers differ from each other, then the suitable points are moved to other layers, and if the left-tangents do not link the corresponding points, then their structure is corrected. The suitable combination of optimal structure correction criteria was investigated by a numerical experiment, the angle criteria were found as the best. Finally, five-point cross ratios of sequences of the points from both sets are computed and compared.		Tomás Suk;Jan Flusser	1999		10.1007/3-540-48375-6_55	transformation;computer vision;topology;convex combination;projection;image processing;computer science;mathematics;geometry;symmetry	Vision	49.384431399087475	-60.13170029238621	139407
68cf173fb48d2dc89e1ce9776c13d54bc4d1968e	nonlinear neurons and higher-order statistics: new approaches to human vision and digital image processing	engineering;metodo estadistico;neurone;metodo matematico;image numerique;human vision;mathematical method;digital image processing;image processing;electronique;nerve;differential geometry;procesamiento imagen;statistical method;non linear model;modele non lineaire;traitement image;linear filtering;higher order statistics;mode ordre eleve;neurona;modelo no lineal;human vision and color perception;electronica;methode statistique;natural environment;imagen numerica;electronics;methode mathematique;biological systems;orientation selectivity;digital image;cumulant;modeling;visual system;vision;neuron;gain control;complex cell;modo orden elevado;high order mode	The classical approach in vision research the derivation of basically linear filter models from experiments with simple artificial test stimuli is currently undergoing a major revision. Instead of trying to keep the dirty environment out of our clean labs we put it now right into the focus of scientific exploration. The new approach has a close relation to basic engineering strategies for electronic image processing since its major concept is the exploitation of the statistical redundancies of the environment by appropriate neural transformations. The standard engineering methods are not sufficient, however. Even a basic biological feature like orientation selectivity requires the consideration of higher-order statistics, like cumulants or polyspectra. Furthermore, there exists an abundance of nonlinear phenomena in biological vision, for example the phase-invariance of complex cells, cortical gain control, or end-stopping, which make it necessary to consider unconventional modeling approaches like differential geometry or Volterra-Wiener systems. By use of such methods we cannot only gain a deeper understanding of the adaptation of the visual system to the complex natural environment, but we can also make the biological system an inspiring source for the design of novel strategies in electronic image processing.	biological system;digital image processing;experiment;nonlinear system;selectivity (electronic)	Christoph Zetzsche;Gerhard Krieger	1999		10.1117/12.348430	computer vision;engineering;artificial intelligence;cartography	ML	46.53521310955681	-62.48213803315879	139736
8d54c0121bebcdf30162b9c59f83580d883e05ac	region filtering using color and texture features for image retrieval	busqueda informacion;analisis imagen;filtering;texture;mathematical morphology;filtrage;morfologia matematica;image processing;bassin versant;recherche image;dissimilarity measure;information retrieval;extraction forme;filtrado;interrogation base donnee;procesamiento imagen;interrogacion base datos;filtro gabor;texture features;traitement image;region based image retrieval;gabor filter;histogram;senal video;histogramme;signal video;extraccion forma;recherche information;cuenca;comportement utilisateur;watershed segmentation;textura;filtre gabor;retroaction pertinence;video signal;image analysis;user behavior;watershed;imagen color;histograma;analyse image;relevance feedback;content based retrieval;pattern extraction;database query;recherche par contenu;image couleur;comportamiento usuario;color image;morphologie mathematique;image retrieval	This paper presents a region-based image retrieval (RBIR) system in which users can choose specific regions as the query. Our goal is to assist the user to formulate more precise queries with which the retrieval system can focus on the user’s interested part. In this work, images are partitioned into a set of regions by using the watershed segmentation. Color-size histogram and Gabor texture features are extracted from each watershed region. We propose a scheme of region filtering based on individual features, rather than integrating different features, to reduce the computational load of the image retrieval. This paper also defines the dissimilarity measure of images, and therefore relevance feedback is used for improving our retrieval. Finally we describe some experimental results of our RBIR system.	gabor filter;image retrieval;relevance feedback;watershed (image processing)	Cheng-Chieh Chiang;Ming-Han Hsieh;Yi-Ping Hung;Greg C. Lee	2005		10.1007/11526346_52	image texture;computer vision;visual word;image analysis;watershed;image processing;image retrieval;computer science;computer graphics (images)	Vision	43.37533710657607	-61.53097352732021	139754
1f5b2476faa1dfe36f7903bd2f7b79a5557420f3	precision registration and mosaicking of multicamera images	teledetection;multicamera images registration;airborne methods;mosaico;projective constraint;mosaics;image segmentation;image resolution;six camera system multicamera images registration multicamera images mosaicking control points projective transformation overlapping images seamless mosaics;image segmentation geophysics computing image registration;six camera system;image fusion;transformations;mosaique;transformacion;imagerie;analyse moindres carres;layout;satisfiability;deteccion a distancia;digital cameras;aerial image;accuracy;least squares;imagery;overlapping images;projective constraint aerial image image mosaicking image registration multicamera images;precision;geophysics computing;recalage image;remote sensing;image registration;least square;control points;image mosaicking;multicamera images;imagineria;layout image registration remote sensing least squares methods image fusion image resolution digital images computer science digital cameras aircraft;transformation;computer science;projective transformation;seamless mosaics;metodo aerotransportado;digital images;least squares methods;methode aeroportee;aircraft;multicamera images mosaicking	A method for registering and mosaicking multicamera images is described. Registration is achieved using control points and projective transformation, paying special attention to factors that contribute to the precision registration of images. Among the corresponding control points found in overlapping images, those that best satisfy the projective constraint are used to register the images. Experimental results show that a small number of correspondences that satisfy the projective constraint produce a more accurate registration than a large number of correspondences in least squares fashion. To achieve seamless mosaics, the intensities of all images captured by the cameras are transformed to the intensities of one of the images to minimize the intensity difference between the registered images. Mosaicking results on 4096 image sets acquired by a six-camera system are presented and discussed.	control point (mathematics);image stitching;least squares;seamless3d	David J. Holtkamp;A. Ardeshir Goshtasby	2009	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2009.2023114	computer vision;mathematics;accuracy and precision;least squares;statistics;remote sensing;computer graphics (images)	Vision	51.53916388909857	-55.49830575520171	140169
7efdbc68dcabbdcee5b192593a57cbbc1b646edf	recognizing objects using color-annotated adjacency graphs	approximate matching	We introduce a new algorithm for identifying objects in cluttered images, based on approximate subgraph matching. This algorithm is robust under moderate variations in the camera viewpoints. In other words, it is expected to recognize an object (whose model is derived from a template image) in a search image, even when the cameras of the template and search images are substantially different. The algorithm represents the objects in the template and search images by weighted adjacency graphs. Then the problem of recognizing the template object in the search image is reduced to the problem of approximately matching the template graph as a subgraph of the search image graph. The matching procedure is somewhat insensitive to minor graph variations, thus leading to a recognition algorithm which is robust with respect to camera variations.	approximation algorithm;subgraph isomorphism problem	Peter H. Tu;Tushar Saxena;Richard I. Hartley	1999		10.1007/3-540-46805-6_15	adjacency list;combinatorics;template matching;machine learning;pattern recognition;mathematics	Vision	43.8651316321123	-54.81826639745756	140391
5821c485247506a2642bf2b3415d6def82a69628	style similarity measure for video documents comparison	busqueda informacion;dynamic programming;television;programacion dinamica;image processing;information retrieval;extraction forme;procesamiento imagen;metric;morphological operation;dynamic program;traitement image;similitude;senal video;signal video;extraccion forma;recherche information;feature extraction;similarity;programmation dynamique;video signal;metrico;document localization;similitud;similarity measure;pattern extraction;localizacion documento;metrique;localisation document	We define a style similarity measure for video documents based on the localization of common elements and on the temporal order in which they appear in each document. Common elements for a couple of compared videos are segments presenting similar behaviors on a subset of low or mid level features extracted for the comparison process. We propose a method to compare two video documents and to extract those similar elements using dynamic programming and one-dimensional morphological operations. The similarity measure is applied on TV-news broadcast to illustrate its behavior.	similarity measure	Siba Haidar;Philippe Joly;Bilal Chebaro	2005		10.1007/11526346_34	computer vision;speech recognition;similarity;metric;image processing;feature extraction;computer science;similitude;machine learning;dynamic programming;multimedia;television;information retrieval	Vision	45.073943494784864	-57.65497852102316	140438
886ea42c420b6a841e1e7687dc708c0471988197	finding human faces with a gaussian mixture distribution-based face model	gaussian mixture;distance measure;face modeling	We present a distribution-based modeling scheme for representing and detecting human faces in cluttered scenes. A 2-Value metric is proposed for computing distance features between test patterns and the distribution-based model during classiication. We present performance statistics of our overall system, and empirical results comparing the discriminative power of feature sets based on our 2-Value metric , versus similar feature sets based on other classical distribution dependent distance measures .	sensor;test card	Tomaso A. Poggio;Kah Kay Sung	1995		10.1007/3-540-60793-5_97	machine learning;pattern recognition;statistics	Vision	43.53171034262967	-55.52641544841819	140449
4a91e7de7ee254f1097fe3d8a7af8026dc878d89	on the set of images modulo viewpoint and contrast changes	image recognition;image reconstruction;image representation;contrast change;illumination effect;image recognition;image reconstruction;image representation;images modulo viewpoint;viewpoint effect	"""We consider regions of images that exhibit smooth statistics, and pose the question of characterizing the """"essence"""" of these regions that matters for recognition. Ideally, this would be a statistic (a function of the image) that does not depend on viewpoint and illumination, and yet is sufficient for the task. In this manuscript, we show that such statistics exist. That is, one can compute deterministic functions of the image that contain all the """"information"""" present in the original image, except for the effects of viewpoint and illumination. We also show that such statistics are supported on a """"thin"""" (zero-measure) subset of the image domain, and thus the """"information"""" in an image that is relevant for recognition is sparse. Yet, from this thin set one can reconstruct an image that is equivalent to the original up to a change of viewpoint and local illumination (contrast). Finally, we formalize the notion of """"information"""" an image contains for the purpose of viewpoint- and illumination- invariant tasks, which we call """"actionable information"""" following ideas of J. J. Gibson."""	list of common shading algorithms;modulo operation;sparse matrix	Ganesh Sundaramoorthi;Peter Petersen;V. S. Varadarajan;Stefano Soatto	2009	2009 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPRW.2009.5206704	iterative reconstruction;computer vision;computer science;level set;pattern recognition;lighting;mathematics;geometry	Vision	51.78401730495586	-60.84126197449037	140473
e02d66d2e6b89328b5bcf6fe007de4eac0e8e3f7	correspondence with cumulative similiarity transforms	image matching transforms;image matching;motion;contour tracking;least square;transforms;stereo;robust correspondence matching cumulative similarity transforms local image transform cumulative similarity measures efficient correspondence efficient tracking occluding boundaries contrast local image homogeneity region shape least squares matching;cumulant;similarity measure;robustness image color analysis image motion analysis image texture analysis shape measurement image edge detection image sequence analysis smoothing methods higher order statistics particle measurements;image correspondence	ÐA local image transform based on cumulative similarity measures is defined and is shown to enable efficient correspondence and tracking near occluding boundaries. Unlike traditional methods, this transform allows correspondences to be found when the only contrast present is the occluding boundary itself and when the sign of contrast along the boundary is possibly reversed. The transform is based on the idea of a cumulative similarity measure which characterizes the shape of local image homogeneity; both the value of an image at a particular point and the shape of the region with locally similar and connected values is captured. This representation is insensitive to structure beyond an occluding boundary but is sensitive to the shape of the boundary itself, which is often an important cue. We show results comparing this method to traditional least-squares and robust correspondence matching. Index TermsÐImage correspondence, stereo, motion, contour tracking.	algorithm;alpha compositing;anisotropic diffusion;contour line;displacement mapping;hood method;least squares;propagation of uncertainty;radial (radio);radial basis function;similarity measure;smoothing;tracking system	Trevor Darrell;Michele Covell	2001	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.908973	computer vision;feature detection;topology;motion;pattern recognition;mathematics;stereophonic sound;least squares;statistics;cumulant	Vision	50.37542389851257	-53.89082316175137	140789
f5f00e54d9309dd44bf731782197af91ef3ec3d8	on the detection and matching of structures on less-textured scenes		Due to the lack of non-zero gradients around the structures in the less textured scenes, current local feature can hardly be applied in less textured object detection. To deal with this issue, two types of local structures, namely, corner and closed region are proposed in this paper. They are based on purely object contours, which are easier to obtain in less textured scenes. Compare to existing detectors, these features describe objects’ local structures in a better way. In addition, these new type of local structures also bring the advantage that allows us to have different level of abstraction on the object structures. Its effectiveness has been evaluated under various transformations.	feature extraction;gradient;instability;object detection;object type (object-oriented programming);performance;principle of abstraction;sensor	Wan-Lei Zhao;Wonmin Byeon;Thomas M. Breuel	2013			computer vision	Vision	39.63958032756871	-55.61566336165889	141287
fb49792d59c74f3bf1066a1e0592cd50b13da28c	image database indexing using jpeg coefficients	image database;image database systems;indexing;indexation;content based image retrieval	In this paper, we describe an image database system that can retrieve images that are similar to a query image. The query image is processed to extract information that is matched against an index to provide pointers to similar images. The salient feature of the system is that the index is developed from the jpeg-compressed images without rst having to uncompress them. We use a similarity measure to determine the diierence between the jpeg coee-cients of the query image to those of the images in the database index. The index itself is developed by partitioning the jpeg-compressed image into a quad-tree structure and computing certain characteristics for each quad at each level in the tree. Each quad representation is stored in tables corresponding to the quad size in a relational database that can be queried by conventional means. Given a query image, or image segment, the corresponding quad tree-based representation is computed. Then, each of the quad representations in the query is used to search the index for the matching quads in the database. Initial experiments with the index have provided encouraging results. The system outputs a set of ranked images in the database with respect to the query using the similarity measure, and can be limited to output a speciied number by changing the threshold match.	coefficient;database index;experiment;image segmentation;jpeg;quadtree;relational database;similarity measure;tree structure	Sharlee Climer;Sanjiv K. Bhatia	2002	Pattern Recognition	10.1016/S0031-3203(01)00182-0	search engine indexing;image retrieval;computer science;data mining;database;view;automatic image annotation;information retrieval	Vision	39.23391256961959	-60.55635307054871	141305
ec2d1fc940fbfa1ec1d9f000a119be6c39f15fe2	a method for sonar based recognition of walking people	transformation ondelette;experimental tests;tratamiento datos;moving object;reseau capteur;time varying;deteccion blanco;target strength;linear array;data processing;hombre;traitement donnee;analyse multiresolution;detection cible;red sensores;human body;information processing;human;sensor array;pattern recognition;transformacion ondita;reconnaissance forme;reconocimiento patron;signal to noise ratio;multiresolution analysis;target detection;wavelet transformation;analisis multiresolucion;homme;sonar	In this paper we investigate the problem of recognising a person based on the rhythmic features of human walking. The perceptual task is perfonned using in-air sonar sensors. A linear array sensing head with limited complexity is developed to achieve the stated goal; the method of sensory information processing implemented in the device is a blend of grid based mapping and wavelet based multiresolution analysis. Grid based mapping allows to perform detection and tracking of a moving object at the highest signal-to-noise ratios; wavelet based multiresolution analysis allows us to detect the features that are peculiar to walking people in the range measurement sequence extracted from a single sonar sensor of the sensing head. Experimental tests on a number of moving objects with highly time-varying target strengths are carded out; the results prove the feasibility of the approach in terms of recognition rate and acquisition time. The present study contributes to understanding how in-air sonar sensors behave and interact with complex scatterers such as the human body; also, it offers promise for novel applications of sonar technologies in the field of advanced robotics, where the close interaction between human users and robotic systems is on stage. © 1998 Elsevier Science B.V. All rights reserved.	charge-coupled device;information processing;multiresolution analysis;robot;robotics;sonar (symantec);sensor;signal-to-noise ratio;wavelet	Angelo M. Sabatini;Valentina Colla	1998	Robotics and Autonomous Systems	10.1016/S0921-8890(98)00006-2	multiresolution analysis;computer vision;human body;data processing;information processing;computer science;signal-to-noise ratio;sensor array;sonar	Robotics	46.971122107164526	-60.11670116518104	141378
748940e5a865af4e0f663b4861bde573af69f374	a new morphological 3d shape decomposition: grayscale interframe interpolation method		"""One of the main image representations in Mathematical Morphology is the 3D Shape Decomposition Representation, useful for Image Compression, and Pattern Recognition. The 3D Morphological Shape Decomposition representation can be generalized a number of times, to extend the scope of its algebraic characteristics as much as possible. With these generalizations, the Morphological Shape Decomposition 's role to serve as an efficient image decomposition tool was extended to discrete images and grayscale images. This work follows the above line, and further develops it. A new evolutionary branch is added to the 3D Morphological Shape Decomposition's development, by the introduction of a 3D Multi Structuring Element Morphological Shape Decomposition, which permits 3D Morphological Shape Decomposition of 3D binary images (grayscale iamges) into """"multiparameter"""" families of elements. At the beginning, 3D Morphological Shape Decomposition representations are based only on """"1 parameter"""" families of elements for image decomposition. This paper addresses the gray scale interframe interpolation by means of mathematical morphology. The new interframe interpolation method, called 3D Shape Decomposition interpolation is based on morphological 3D Shape Decomposition. This article will present the theoretical background of the morphological interframe interpolation, deduce the new representation and show some application examples. Computer simulations could illustrate results."""	binary image;frame language;grayscale;image compression;linear algebra;mathematical morphology;motion interpolation;pattern recognition;simulation;structuring element;whittaker–shannon interpolation formula	Nicolae Vizireanu;Radu Mihnea Udrea	2004			computer vision;interpolation;pattern recognition;computer science;grayscale;artificial intelligence;demosaicing;multivariate interpolation;nearest-neighbor interpolation;stairstep interpolation;bicubic interpolation;bilinear interpolation	Vision	51.905193484410304	-64.18860424170289	141401
13dfc1d4c413a692a62c065993f47c5db8812eda	three-dimensional object recognition: statistical approach	statistical approach;object recognition;distance measure;three dimensional;computer vision;statistical analysis;human vision system;artificial vision;dimensional reduction;eigenvectors	The design of a general purpose artificial vision system capable of recognizing arbitrarily complex threedimensional objects without human intervention is still a challenging task in computer vision. Experiments have been conducted to test the ability of incorporating the knowledge of how human vision system works in a threedimensional object recognition system. Firstly, the process of shape outline detection and secondly, the use of multiple viewpoints of object. Shape outline readings are put through normalization and dimensionality reduction process using an eigenvector based method to produce a new set of readings. Through statistical analysis, these readings together with other key measures, namely peak measures and distance measures, a robust classification and recognition process is achieved. Tests show that the suggested methods are able to automatically recognize three-dimensional objects from multiple viewpoints. Finally, experiments also demonstrate the system invariance to rotation, translation, scale, reflection and to a small degree of distortion.	computer vision;dimensionality reduction;distortion;experiment;outline of object recognition;statistical classification	R. Abdul Salam;Maria Andréia F. Rodrigues	2003			three-dimensional space;computer vision;eigenvalues and eigenvectors;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;3d single-object recognition;computer graphics (images)	Vision	43.08541117666267	-56.17490665731635	141432
684f9584f742fec19a175e1cba60b5659df5300e	combining features and intensity for wide-baseline non-rigid surface registration		Non rigid surface registration consists in estimating the deformation of a known surface between two images, usually by fitting a warp such as a Thin-Plate Spline or a Free-Form Deformation. Common techniques are split in two categories: feature-based surface detection i.e. estimation of a potentially important deformation from an image and a flat source template, and pixel-based surface tracking where important deformations can be estimated over a video sequence as long as the frame to frame steps are small. Our contribution consists in bridging the two worlds by introducing a new data term robustly merging feature and pixel-based costs in a pyramidal variational approach. By using a robust estimator we achieve an implicit optimal filtering of features and automatic balancing between the two terms. Our goal is to directly estimate a deformation between an image I and a given flat template I0. This deformation is parametrized by the displacements u of the control points of a Free-Form Deformation warp [4]. The image in I of the point q from I0 is W(q,u). For the sake of clarity and to allow easier comparison with feature-based methods, we adopt a feature-filtering model for our cost function:	baseline (configuration management);bridging (networking);free-form deformation;image registration;iterative closest point;loss function;pixel;thin plate spline;variational principle	Jim Braux-Zin;Romain Dupont;Adrien Bartoli	2013		10.5244/C.27.125	computer vision;merge (version control);deformation (mechanics);artificial intelligence;computer science;filter (signal processing);parametrization;bridging (networking);spline (mathematics);robust statistics	Vision	52.8905735957887	-52.9872830648323	141546
b8c702c3a0dd54e976445e027a589247773736e7	finding motion primitives in human body gestures	phoneme;phonetique;interfase usuario;human interaction;mouvement corporel;trajectoire;speech synthesis;cuerpo;user interface;body;gesture;speech processing;tratamiento palabra;traitement parole;fonema;man machine system;trajectory;human body;state space;corps;fonetica;speech recognition;invariante;sistema hombre maquina;interface utilisateur;trayectoria;phonetics;movimiento corporal;geste;body movement;invariant;gesto;systeme homme machine	In the last decade speech processing has been applied in commercially available products. One of the key reasons for its success is the identification and use of an underlying set of generic symbols (phonemes) constituting all speech. In this work we follow the same approach, but for the problem of human body gestures. That is, the topic of this paper is how to define a framework for automatically finding primitives for human body gestures. This is done by considering a gesture as a trajectory and then searching for points where the density of the training data is high. The trajectories are re-sampled to enable a direct comparison between the samples of each trajectory, and enable time invariant comparisons. This work demonstrates and tests the primitive’s ability to reconstruct sampled trajectories. Promising test results are shown for samples from different test persons performing gestures from a small one armed gesture set.	cubic hermite spline;cubic function;euler;gesture recognition;interpolation;motion capture;speech processing;spline (mathematics);time-invariant system	Lars Reng;Thomas B. Moeslund;Erik Granum	2005		10.1007/11678816_16	phonetics;computer vision;interpersonal relationship;human body;speech recognition;computer science;state space;artificial intelligence;trajectory;invariant;speech processing;user interface;gesture;speech synthesis;algorithm	Graphics	48.97956806124045	-56.31698899733496	141616
ad5db62a5a92662b746611c50e71a12c3111af0e	analysis of feature detector and descriptor combinations with a localization experiment for various performance metrics	object matching;performance evaluation;localization;feature detectors and descriptors;performance metrics	The purpose of this study is to give a detailed performance comparison about the feature detector and descriptor methods, particularly when their various combinations are used for image matching. As the case study, the localization experiments of a mobile robot in an indoor environment are given. In these experiments, 3090 query images and 127 dataset images are used. This study includes five methods for feature detectors such as features from accelerated segment test (FAST), oriented FAST and rotated binary robust independent elementary features (BRIEF) (ORB), speeded-up robust features (SURF), scale invariant feature transform (SIFT), binary robust invariant scalable keypoints (BRISK), and five other methods for feature descriptors which are BRIEF, BRISK, SIFT, SURF, and ORB. These methods are used in 23 different combinations and it was possible to obtain meaningful and consistent comparison results using some performance criteria defined in this study. All of these methods are used independently and separately from each other as being feature detector or descriptor. The performance analysis shows the discriminative power of various combinations of detector and descriptor methods. The analysis is completed using five parameters such as (i) accuracy, (ii) time, (iii) angle difference between keypoints, (iv) number of correct matches, and (v) distance between correctly matched keypoints. In a range of 60°, covering five rotational pose points for our system, “FAST-SURF” combination gave the best results with the lowest distance and angle difference values and highest number of matched keypoints. The combination “SIFT-SURF” is obtained as the most accurate combination with 98.41% of correct classification rate. The fastest algorithm is achieved with “ORB-BRIEF” combination with a total running time 21303.30 seconds in order to match 560 images captured during the motion with 127 dataset images.	algorithm;emoticon;experiment;fastest;features from accelerated segment test;image registration;internationalization and localization;matched filter;mobile robot;scalability;scale-invariant feature transform;sensor;software performance testing;speeded up robust features;time complexity	Ertugrul Bayraktar;Pinar Boyraz	2016	CoRR	10.3906/elk-1602-225	computer vision;internationalization and localization;computer science;machine learning;pattern recognition	Robotics	41.493769755573	-55.29231840964811	141662
98647dfe66228ce905db97c01a5a2770584dac39	color-wise: a system for image similarity retrieval using color	base donnee;image databank;information retrieval;information visuelle;color;database;base dato;image;color histogram;similarity retrieval;histogram;informacion visual;histogramme;compact representation;imagen;recherche information;visual information;banco imagen;banque image;similarity;similarite;couleur;recuperacion informacion;imagen color;histograma;image couleur;color image;image similarity	Color is one of the most widely used features for image similarity retrieval. Most of the existing image similarity retrieval schemes employ either global or local color histogramming. In this paper, we explore the use of localized dominant hue and saturation values for color-based image similarity retrieval. This scheme results in a relatively compact representation of color images for similarity retrieval. Experimental results comparing the proposed representation with global and local color histogramming are presented to show the efficacy of the suggested scheme.© (1997) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.		Ishwar K. Sethi;Ioana Coman;B. Day;F. Jiang;Dongge Li;Jose L. Segovia-Juarez;Gang Wei;B. You	1998		10.1117/12.298438	color histogram;computer vision;visual word;similarity;color image;image;histogram;information retrieval;computer graphics (images)	Vision	42.906836033672214	-61.45558203191384	141755
8b987174a30ba92de37e20e22502815fef14fdbf	physics-based extraction of intrinsic images from a single image	kubelka-munk color theory;intrinsic image extraction;intrinsic images;proposed technique;illumination image;chromatic characteristic;real image;input image;feature extraction;physics-based extraction;single image;derivative filter;photometric reflectance model;filtering theory;single color image;filtered image;intrinsic image;image colour analysis;reflectance image;color image	A technique for extracting intrinsic images, including the reflectance and illumination images, from a single color image is presented. The technique first convolves the input image with a prescribed set of derivative filters. The pixels of filtered images are then classified into reflectance-related or illumination-related based on a set of chromatic characteristics of pixels calculated from the input image. Chromatic characteristics of pixels are defined by a photometric reflectance model based on the Kubelka-Munk color theory. From the classification results of the filtered images, the intrinsic images of the input image can be computed. Real images have been utilized in our experiments. The results have indicated that the proposed technique can effectively extract the intrinsic images from a single image.	autostereogram;color image;convolution;experiment;pixel	Yun-Chung Chung;Jung Ming Wang;Robert R. Bailey;Sei-Wang Chen;Shyang-Lih Chang;Shen Cherng	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333867	color histogram;image texture;computer vision;feature detection;image resolution;color image;image gradient;binary image;image processing;feature extraction;computer science;machine learning;mathematics;color balance;image formation;top-hat transform;computer graphics (images)	Vision	53.005278018124024	-63.14835934989325	141777
0b37d81e84385d0753d1181670cf0eddca17ce53	research on a novel medical image non-rigid registration method based on improved sift algorithm	corner detection;wmi;global context vector;improved sift;pso;feature matching;scale space;particle swarm optimizer;medical image;non rigid registration;scale invariant feature transform;feature extraction;affine transformation;harris corner detection;mutual information;invariant feature	In allusion to non-rigid registration of medical images, the paper gives a novel algorithm based on improved Scale Invariant Features Transform (SIFT) feature matching algorithm. First, Harris corner detection algorithm is used in the process of scale invariant feature extraction, so the number of right matching points is increased; with regard to the feature points detected in the scale space, an improved SIFT feature extraction algorithm with global context vector is presented to solve the problem that SIFT descriptors result in a lot of mismatches when an image has many similar regions. On this basis, affine transformation is chosen to implement the non-rigid registration, and weighted mutual information (WMI) measure and Particle Swarm Optimization (PSO) algorithm are also chosen to optimize the registration process. The experimental results show that the method can achieve better registration results than the method based on mutual information.	algorithm;scale-invariant feature transform	Anna Wang;Dan Lv;Zhe Wang;Shiyao Li	2010		10.1007/978-3-642-15615-1_12	corner detection;computer vision;scale space;feature extraction;computer science;machine learning;pattern recognition;scale-invariant feature transform;affine transformation;mathematics;mutual information	Vision	40.65583111450629	-57.45087411830141	141812
a6f5301a7ee0da50178b53cdef360324777bf1a1	a novel unsupervised approach for multilevel image clustering from unordered image collection	lai kang lingda wu yee hong yang 图像采集 图像聚类 无序 多级 监督 图像特征 国际空间站 二进制序列 a novel unsupervised approach for multilevel image clustering from unordered image collection;unordered image collection;multilevel image clustering imaging sample space iss unordered image collection;multilevel image clustering;imaging sample space iss	A novel unsupervised approach to automatically constructing multilevel image clusters from unordered images is proposed in this paper. The whole input image collection is represented as an imaging sample space (ISS) consisting of globally indexed image features extracted by a new efficient multi-view image feature matching method. By making an analogy between image capturing and observation of ISS, each image is represented as a binary sequence, in which each bit indicates the visibility of a corresponding feature. Based on information theory-inspired image popularity and dissimilarity measures, we show that the image content and distance can be quantitatively described, guided by which an input image collection is organized into multilevel clusters automatically. The effectiveness and the efficiency of the proposed approach are demonstrated using three real image collections and promising results were obtained from both qualitative and quantitative evaluation.	3d reconstruction;algorithm;bitstream;cluster analysis;feature (computer vision);indexed color;information theory;unsupervised learning	Lai Kang;Lingda Wu;Yee-Hong Yang	2013	Frontiers of Computer Science	10.1007/s11704-013-1266-8	image texture;computer vision;feature detection;pattern recognition;data mining;automatic image annotation	Vision	42.20156933808154	-63.68963215062501	141854
380cc017badfb9eaed34a223b037760f2bdc44f8	range facial recognition with the aid of eigenface and morphological neural networks	3d face recognition;3d imaging;max plus algebra;hybrid genetic algorithm;neural network;principal component	The depth information in the face represents personal features in detail. In particular, the surface curvatures extracted from the face contain the most important personal facial information. These surface curvature and eigenface, which reduce the data dimensions with less degradation of original information, are collaborated into the proposed 3D face recognition algorithm. The principal components represent the local facial characteristics without loss for the information. Recognition for the eigenface referred from the maximum and minimum curvatures is performed. To classify the faces, the max plus algebra based neural networks (morphological neural networks) optimized by hybrid genetic algorithm are considered. Experimental results on a 46 person data set of 3D images demonstrate the effectiveness of the proposed method.	eigenface;facial recognition system;neural networks	Chang-Wook Han	2008		10.1007/978-3-540-88906-9_28	stereoscopy;computer vision;computer science;machine learning;pattern recognition;eigenface;artificial neural network;principal component analysis	Vision	43.6861470637807	-59.147945344110745	141942
4335971af0a97c429d76439b702b18ee9029a228	a fast globally optimal algorithm for template matching using low-resolution pruning	baja resolucion;algorithme rapide;signal processing algorithms pattern matching pattern recognition video compression image processing motion estimation filtering pixel video signal processing uninterruptible power systems;optimisation;estimation mouvement;full search;image processing;image resolution;methode echelle multiple;pruning tree;image matching;estimacion movimiento;low resolution;video compression;basse resolution;procesamiento imagen;motion estimation;noise image matching optimisation image resolution search problems;metodo escala multiple;indexing terms;poda;traitement image;experimental result;low noise;signal processing;fast algorithm;image search;resultado experimental;pattern recognition;correspondencia bloque;block matching;global optimization;multiscale method;search problems;reconnaissance forme;2d template matching fast globally optimal algorithm exact best match low resolution pruning signal processing image processing pattern recognition video compression coarse to fine template matching algorithm full search low noise;correspondance bloc;reconocimiento patron;resultat experimental;elagage;template matching;algoritmo rapido;noise;exhaustive search	Template matching has many applications in signal processing, image processing, pattern recognition, and video compression. This paper proposes a fast coarse-to-fine template matching algorithm for finding the exact best match, i.e., the match that may be found by a full search. This is obtained by pruning the number of candidates in the full search using the results of a coarse search. Experimental results show that speed ups of a couple of orders of magnitude can easily be achieved using this method for typical low-noise cases of two-dimensional (2-D) template matching.		Mohammad Gharavi-Alkhansari	2001	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.913587	computer vision;template matching;image resolution;image processing;computer science;machine learning;signal processing;pattern recognition;mathematics;global optimization	Vision	51.93134585531011	-60.34102650198933	141944
1bef0185b8c8313b2d1c8462ceefa1881cf073fb	spatial color image processing using clifford algebras: application to color active contour		In the literature, the color information of the pixels of an image has been represented by different structures. Recently, algebraic entities such as quaternions or Clifford algebras have been used to perform image processing for example. This paper presents the embedding of color information into the vectorial parts of a multivector. This multivector is an element of the geometric or Clifford algebra constructed from a three-dimensional vector space. This formalism presents the advantage of algebraically separating colors which are handled entities from the geometric operations done to them. We propose to introduce several contributions for color image processing by using this Clifford algebra. First, as colors are represented by 1-vectors, we point out that a color pixel given in the RGB color space can be expressed algebraically by its hue saturation and value using the geometry. Then, we illustrate how this formalism can be used to define color alterations with algebraic operations. We generalize linear filtering algorithms already defined with quaternions and define a new color edge detector. Finally, the application of the new color gradient is illustrated by a new color formulation of snakes. Thus, we propose in this paper the definition and exploitation of a formalism in which we geometrically handle colors with algebraic entities and expressions.	active contour model;color image;image processing	Philippe Carré;Patrice Denis;Christine Fernandez-Maloigne	2014	Signal, Image and Video Processing	10.1007/s11760-012-0366-5	color gradient;computer vision;color quantization;pure mathematics;mathematics;geometry;algorithm	Robotics	51.88527970650891	-63.94936827566636	141983
9d7b96145be7544b54cc22a6c6c9bdd22cd02f73	edge detection in dynamic vision		Using a model of an edge's motion through a sequence of images, the problem of its recognition can be formulated as a stochastic filtering problem. The Extended Kalman Filter for such a system is considered in detail and is shown to be interpretable as a sequence of oriented spatial convolutions. Preliminary results show that the edge localization obtained using this filter is substatinally better than that obtained using the Sobel operator on each image individually. time varying imagery, such as obtained from AGVs or motion'''', there is a temporal coherency in the sequence of images that can be exploited in the design of filters with a temporal as well as spatial basis. By capturing this temporal coherency with a dynamical model, it is possible to obtain an Extended Kalman Filter which localizes edges. This is the purpose of the work reported in this paper. Related work is reported in >>) where Extended Kalman Filters are used to combine multiple pieces of data about higher order entities such as three dimensional points, lines and planes.	convolution;edge detection;entity;extended kalman filter;sobel operator;stochastic control	Alan M. McIvor	1988		10.5244/C.2.22	edge detection;interest point detection	Vision	47.571290035458425	-52.52605058203481	142052
29282c6dcbb7341e44b171469c7e6ef130afbc01	geodesic active contours	minimisation;interior boundaries;metrique riemann;dynamic contour;geometric active contours;topology;active contours object detection solid modeling geophysics computing topology stability level measurement object segmentation gas detectors image analysis;image content;variational problems;geodesic active contour;curve evolution geodesic active contours object boundary detection active contour deformation intrinsic geometric measures image evolving contours object detection exterior boundaries interior boundaries geodesics minimal distance curves riemannian space metric image content object segmentation classical snakes energy minimization geometric active contours;active contour;image segmentation;image processing;curve evolution;free boundary;geometrie algorithmique;etude experimentale;edge detection;minimal distance curves;efficient algorithm;extraction forme;differential geometry;computational geometry;intrinsic geometric measures;procesamiento imagen;metric;image;active contours;variational problem;traitement image;topology free boundary detection;classical snakes;computer vision;deteccion contorno;stability;exterior boundaries;algorithme;geodesique;algorithm;detection contour;object segmentation;riemannian space;geophysics computing;dynamic contours;extraccion forma;geodesic;geodesics;solid modeling;geodesico;level measurement;geometrie differentielle;image analysis;geodesic active contours;geometria computacional;energy minimization;gas detectors;geometria diferencial;riemann metric;boundary detection;riemannian geometry;estudio experimental;object boundary detection;pattern extraction;computer vision geodesy object detection image segmentation minimisation active vision;metrico riemann;object detection;active contour deformation;active vision;algoritmo;geodesy;evolving contours	A novel scheme for the detection of object boundaries is presented. The technique is based on active contours evolving in time according to intrinsic geometric measures of the image. The evolving contours naturally split and merge, allowing the simultaneous detection of several objects and both interior and exterior boundaries. The proposed approach is based on the relation between active contours and the computation of geodesics or minimal distance curves. The minimal distance curve lays in a Riemannian space whose metric is defined by the image content. This geodesic approach for object segmentation allows to connect classical “snakes” based on energy minimization and geometric active contours based on the theory of curve evolution. Previous models of geometric active contours are improved, allowing stable boundary detection when their gradients suffer from large variations, including gaps. Formal results concerning existence, uniqueness, stability, and correctness of the evolution are presented as well. The scheme was implemented using an efficient algorithm for curve evolution. Experimental results of applying the scheme to real images including objects with holes and medical data imagery demonstrate its power. The results may be extended to 3D object segmentation as well.	algorithm;computation;correctness (computer science);energy minimization;gradient;numerical stability	Vicent Caselles;Ron Kimmel;Guillermo Sapiro	1997	International Journal of Computer Vision	10.1023/A:1007979827043	computer vision;geodesic;image analysis;topology;image processing;computational geometry;computer science;mathematics;geometry	Vision	48.52948916522786	-65.26407530758912	142108
bb1cb67543440cfb519ed6506a47f6c79253e562	on the computation of the affine skeletons of planar curves and the detection of skew symmetry	curve evolution;symmetry;shape;efficient implementation;affine invariant;planar skeleton;medial axis	In this paper we discuss a new approach to compute discrete skeletons of planar shapes which is based on a$ne distances, being therefore a$ne invariant. The method works with generic curves that may contain concave sections. A dynamical interpretation of the a$ne skeleton construction, based on curve evolution, is discussed as well. We propose an e$cient implementation of the method and give examples. We also demonstrate how to use this method to detect a$ne skew symmetry in real images. ( 2001 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	computation;concave function;dynamical system;pattern recognition;straight skeleton	Santiago Betelú;Guillermo Sapiro;Allen R. Tannenbaum;Peter J. Giblin	2001	Pattern Recognition	10.1016/S0031-3203(00)00045-5	affine geometry;affine space;complex space;combinatorics;topology;affine coordinate system;medial axis;affine involution;shape;affine plane;affine geometry of curves;affine hull;affine arithmetic;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;symmetry;affine combination;affine group	Vision	49.658692447273644	-61.002239240649146	142238
be365c989e1eb1cf2b73a1b42a171ac1b87c363a	an improved fingerprint matching algorithm using low discriminative region		In our previous work, we introduced a hybrid fingerprint matcher which consists of two stages: local minutiae matching stage and consolidation stage. To improve the accuracy of the former stage, in this paper we suggest characterizing each minutia by an additional feature representing the ability to distinguish it from other minutiae in the fingerprint. By utilizing the discriminability of each minutia in the calculation of the local similarity score between two minutiae, the performance of the local matching stage is improved significantly. Thereby, an increase in the accuracy of the whole matching algorithm of 0.33% in EER and 0.51% in FMR1000 over thepreviousworknow makesour matcherrank2nd in FVC2002-DB2A leaderboard.		Nghia Duong;M. Nguyen;H. Le Quang;Hoang Manh Cuong	2018		10.1145/3287921.3287986	discriminative model;fingerprint;minutiae;blossom algorithm;pattern recognition;computer science;artificial intelligence	Vision	39.27022122328227	-57.30457125719933	142314
71ba63a2081827cc497dac7f38ff4a1f92aa474e	continuous collision detection for two moving elliptic disks	robots object detection vehicles charge coupled devices equations robustness interference computer science shape performance analysis;methode domaine temps;esquiva colision;racine equation;disque compact;planar rational motions;compact shape representation;planar cycloidal motions;algebraic conditions;analytic representation;robotics;elliptic disks;metodo dominio tiempo;colision;representation analytique;polynome caracteristique;shape representation;cillision detection;collision detection;algebra;interference analysis;robustesse;compact disk;ellipses;robots;robotica;rational motion;time domain;robustness;continuous collision detection;time domain method;representacion analitica;collision avoidance;robotique;rational motion collision detection ellipses elliptic disks interference analysis;collision;equation root;esquive collision;planar rational motions continuous collision detection moving elliptic disks collision detection collision avoidance robotics compact shape representation algebraic conditions univariate equation planar cycloidal motions;raiz ecuacion;characteristic polynomial;robots algebra collision avoidance;article;moving elliptic disks;disco compacto;polinomio caracteristico;robustez;univariate equation	Collision detection and avoidance are important in robotics. Compared with commonly used circular disks, elliptic disks provide a more compact shape representation for robots or other vehicles confined to move in the plane. Furthermore, elliptic disks allow a simpler analytic representation than rectangular boxes, which makes it easier to perform continuous collision detection (CCD). We shall present a fast and accurate method for CCD between two moving elliptic disks, which avoids any need to sample the time domain of the motion, thus avoiding the possibility of missing collisions between time samples. Based on some new algebraic conditions on the separation of two ellipses, we reduce collision detection for two moving ellipses to the problem of detecting real roots of a univariate equation, which is the discriminant of the characteristic polynomial of the two ellipses. Several techniques are investigated for robust and accurate processing of this univariate equation for two classes, of commonly used motions: planar cycloidal motions and planar rational motions. Experimental results demonstrate the efficiency, accuracy, and robustness of our method	algorithm;analytic signal;approximation;bivariate data;cd-rom;characteristic polynomial;charge-coupled device;collision detection;discriminant;experiment;floppy disk;linear algebra;motion planning;numerical analysis;numerical stability;parsing;phil bernstein;robot;robotics;robustness (computer science);sampling (signal processing);sensor;solver	Yi-King Choi;Wenping Wang;Yang Liu;Myung-Soo Kim	2006	IEEE Transactions on Robotics	10.1109/TRO.2005.862479	robot;mathematical optimization;topology;time domain;computer science;artificial intelligence;rational motion;mathematics;geometry;robotics;characteristic polynomial;collision detection;ellipse;robustness;collision	Robotics	49.58030987632019	-59.406724460387345	142384
0cf7ea4ac16db69056449e61f3d2d13c8d7de6fd	stereo matching of curves by least deformation	piecewise linear approximation;image segmentation;mobile robots;shape measurement;information geometry;epipolar geometry;image segmentation calibration shape measurement information geometry piecewise linear approximation pixel stereo vision mobile robots cameras;stereo matching;pixel;stereo vision;large deformation;calibration;cameras	A stereo algorithm developed for the Oxford AGV is described which matches connected chains of edgels (curves) between images. It is based on representing the curves as elastic strings and measuring tlie amount of deformation the strings have to undergo to transform between corresponding curves, and incorporates the ideas of the disparity gradient and tlle fact that matching sections of curve have to l ie of a similar sliape. This explicit, use of shape information means that a precisely known epipolar geometry is no longer crucial. Pairs of potentially corresponding cnrves wllicli lead to a large deformation energy, are eliminated and the greatly reduced number of potentially matching pairs are passed on to a tree search stage. A typical result of running tlie algorithm on a stereo triple is presented.	algorithm;binocular disparity;computer stereo vision;epipolar geometry;gradient	Andrew T. Brint;Michael Brady	1989		10.1109/IROS.1989.637902	computer stereo vision;mobile robot;computer vision;calibration;topology;computer science;stereopsis;mathematics;geometry;fundamental matrix;image segmentation;information geometry;pixel;epipolar geometry	Vision	49.72740642204617	-53.81247916584271	142505
af16a1279e888b4118c98ece7e1a61044b2f8232	analysis of multiple orientations	veronese map additive superposition eigensystem analysis local orientation mixed orientation parameters multiply oriented patterns occluding superposition structure tensor tensor decomposition texture analysis;eigenvalues and eigenfunctions;modelizacion;analisis contenido;traitement signal;local orientation estimation;evaluation performance;vision ordenador;veronese map local orientation estimation image processing computer vision optical flow estimation color image sequences additive superposition eigensystem analysis occluding superposition texture analysis;algorithms computer simulation image processing computer assisted models theoretical multivariate analysis signal processing computer assisted software;image motion analysis;estimation mouvement;tensile stress;performance evaluation;modele mathematique;image processing;analisis textura;flux optique;color;evaluacion prestacion;signal analysis;structure tensor;estimacion movimiento;volume;mesure position;procesamiento imagen;local orientation;veronese map;optical flow estimation;multiply oriented patterns;motion estimation;modelo matematico;space time;espacio tiempo;traitement image;medicion posicion;image texture;computer vision;modelisation;content analysis;tensor decomposition;texture analysis;volumen;flujo optico;occluding superposition;image colour analysis;signal processing;additive superposition;image sequence;color image sequences;position measurement;mathematical model;vision ordinateur;secuencia imagen;optical flow;pattern analysis;image texture analysis;image texture computer vision eigenvalues and eigenfunctions image colour analysis image sequences;analyse contenu;orientation estimation;imagen color;procesamiento senal;modeling;analyse texture;eigensystem analysis;image couleur;mixed orientation parameters;espace temps;computer vision signal analysis image texture analysis pattern analysis tensile stress signal processing image processing image motion analysis mathematical model color;sequence image	Estimation of local orientations in multivariate signals is an important problem in image processing and computer vision. This general problem formulation also covers optical flow estimation, which can be regarded as orientation estimation in space-time-volumes. Modelling a signal using only a single orientation, however, is often too restrictive, since occlusions and transparencies occur frequently, thus necessitating the modelling and analysis of multiple orientations. We, therefore, develop a unifying mathematical model for multiple orientations: Beyond describing an arbitrary number of orientations in scalar- and vector-valued image data such as color image sequences, it allows the unified treatment of additively and occludingly superimposed oriented structures as well as of combinations of these. Based on this model, we describe estimation schemes for an arbitrary number of additively or occludingly superimposed orientations in images. We confirm the performance of our framework on both synthetic and real image data.	algorithm;application program interface;assumed;automatic vectorization;color image;computation (action);computer vision;description;download;eigenvalue;entity;estimated;forty nine;generalization (psychology);gradient;image processing;matlab;map;markov chain;markov random field;mathematical model;mathematics;mental orientation;obstruction;optical flow;quantum superposition;solutions;statistical classification;statistical model;structure tensor;synthetic data;transparency (projection);user interface device component;utility functions on indivisible goods;whole earth 'lectronic link;biologic segmentation	Matthias Mühlich;Til Aach	2009	IEEE Transactions on Image Processing	10.1109/TIP.2009.2019307	image texture;computer vision;systems modeling;color image;computer science;space time;signal processing;motion estimation;mathematical model;optical flow;mathematics;geometry;stress;volume;structure tensor	Vision	51.02904429974733	-58.99746822676188	142561
358acab1709c5270b02c2d8295f44ce6380dbfc5	causal video object segmentation from persistence of occlusions	experimental design;gaussian noise;target classification;probability;image processing;kernel functions;image segmentation video object segmentation occlusion persistence convex optimization framework;computer vision;performance engineering;visual surveillance;numerical analysis;moving targets;feature extraction;video signal processing convex programming image segmentation object tracking;pattern recognition;algorithms;optimization;network architecture;image segmentation reflection tv image edge detection;video signals;target detection;layers	Occlusion relations inform the partition of the image domain into “objects” but are difficult to determine from a single image or short-baseline video. We show how long-term occlusion relations can be robustly inferred from video, and used within a convex optimization framework to segment the image domain into regions. We highlight the challenges in determining these occluder/occluded relations and ensuring regions remain temporally consistent, propose strategies to overcome them, and introduce an efficient numerical scheme to perform the partition directly on the pixel grid, without the need for superpixelization or other preprocessing steps.	autostereogram;baseline (configuration management);causal filter;convex optimization;mathematical optimization;numerical analysis;persistence (computer science);pixel;preprocessor	Brian Taylor;Vasiliy Karasev;Stefano Soatto	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7299055	kernel;gaussian noise;computer vision;network architecture;performance engineering;layers;image processing;feature extraction;numerical analysis;computer science;machine learning;pattern recognition;probability;design of experiments	Vision	51.32970607743155	-54.710338510475765	142710
d7562bef618b44bba8d1294aa827bce3c0a48b7f	practical gaze detection by auto pan/tilt vision system	baja resolucion;ojo;vision system;gaze;systeme temps reel;angulo inclinacion;eye;ophthalmology;modelo 3 dimensiones;image resolution;aumento;modele 3 dimensions;movimiento ocular;low resolution;angle inclinaison;basse resolution;three dimensional model;hombre;mirada;grossissement;regard;magnification;eye movement;human;tilt angle;facial features;real time system;functionality;sistema tiempo real;maquina fotografica;fonctionnalite;mouvement oculaire;resolution image;oeil;funcionalidad;eye gaze;appareil photographique;oftalmologia;camera;homme;ophtalmologie	This paper presents a practical method for detecting the point in the monitor where a user gazes by moving his face and eyes. Previous gaze detection system uses a wide view camera, which can capture the whole face of user. In such case, the image resolution is so low that the fine movements of user's eye cannot be exactly detected and the accurate eye gaze position cannot be located consequently. So, we implement the gaze detection system with a wide view camera and a narrow view camera. Because the narrow view camera captures the eye image with high magnification, the eye position easily escapes from the narrow view camera by user's facial movements. For these reasons, we adopt the functionalities of auto focusing and auto panning/tilting into the narrow view camera and those are performed based on the information of the detected 3D facial feature positions by the wide view camera. As experimental results, our gaze detection system operates in real-time and the gaze detection accuracy between the computed positions and the real ones is about 3.57 cm of RMS error.		Kang Ryoung Park	2003		10.1007/978-3-540-39737-3_47	computer vision;camera auto-calibration;real-time operating system;image resolution;machine vision;computer science;computer graphics (images)	Vision	48.52405363138833	-56.293499010505286	142947
45d353aec60b2ce725761e8847b81222633da6c9	toward a symbolic representation of intensity changes in images	contour points;contraste;deteccion borde;vision ordenador;convolution kernel;image processing;edge detection;procesamiento imagen;picture processing;intelligence artificielle;segmentation;imagen nivel gris;indexing terms;traitement image;computer vision;contrast;image generation;image function;convolution kernel picture processing symbolic representation gray value variations image function image generation contour points gradient filters;image edge detection gaussian processes layout image segmentation filters kernel image reconstruction computer vision physics convolution;image niveau gris;pattern recognition;artificial intelligence;vision ordinateur;inteligencia artificial;reconnaissance forme;reconocimiento patron;grey level image;gradient filters;detection bord;gray value variations;adaptive filter;segmentacion;symbolic representation	The problem of symbolic representation of gray value variations is studied, especially with respect to the gradient of the image function. The goal is to relate the results of this analysis to the structure of the picture, which is determined by the physics of the image generat ion process. The operators for the detection of gray value transitions are the first derivatives of two-dimensional Gaussians with different widths whose positive and negative parts are separately normalized to + 1 and I, respectively. Candidates for contour points are the maximal magni tudes of the gray value gradient for different scales in the direction of the gradient. Rased on the output of such a bank of gradient filters, a procedure is proposed in order to select automatically a suitable scale and with that the size of the right convolution kernel. In this way, the application of poorly adapted filters, which make the exact localization of gray value corners or T-, X-, and Y-junctions more difficult, can be avoided. For images of real scenes, possible gaps at such junctions are discussed, and possibilities for the closure of some of these gaps are demonstrated if the extrema of the magni tude of the gray value gradient are used. Closed chains of contour points define regions whose gray values can be reconstructed approximately from the attributes of contour points. Results of the segmentat ion are shown for various pictures of real	convolution;gradient;maximal set	Axel Korn	1988	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.6770	adaptive filter;computer vision;edge detection;index term;image processing;contrast;computer science;artificial intelligence;mathematics;segmentation;kernel;computer graphics (images)	Vision	47.89535223769285	-63.15305906537591	143004
0939dcc2006eb7d196b63106ef1fcd54a514e4a8	focusing in thermal imagery using morphological gradient operator	morphological gradient;focus;face recognition;focus measure;thermal imagery	This paper presents focusing on an object of interest in thermal infrared (IR) imagery using the morphological gradient operator. Most existing focus metrics measure the degree of sharpness on the edge of an object in the field of view, often based on the local gradient operators of pixel brightness intensity. However, such focus measures may fail to find the optimal focusing distance to the object in thermal IR images, where strong edge components of an object do not exist. In particular, when the end goal of image acquisition is object recognition, focusing on an object must retain prominent features of the object for recognition. In this paper, the performances of various focus measures are evaluated in terms of sharpness as well as recognition accuracies for face recognition in thermal IR images. Experiment results show that the morphological gradient operator outperforms conventional gradient operators in terms of autofocusing resolution metric as well as face recognition accuracy. Crown Copyright 2013 Published by Elsevier B.V. All rights reserved.	crown group;facial recognition system;morphological gradient;nonlinear system;outline of object recognition;performance;pixel;requirement	Myung-Geun Chun;Seong G. Kong	2014	Pattern Recognition Letters	10.1016/j.patrec.2013.10.023	facial recognition system;computer vision;computer science;morphological gradient;pattern recognition;mathematics;3d single-object recognition;focus	Vision	40.45349964251029	-55.46000594875255	143203
a3a67df3f9d8834f200fa35b9807e71e107ede69	scatter search for point pattern matching: a comparative study	object recognition;scatter search;evolutionary computation;optimal affine transformation;image alignment;dissimilarity measure;testing;simulated annealing;pixel arrays;search problems affine transforms pattern matching;scatter search genetic algorithm simulated annealing point pattern matching;local features;dissimilarity measure scatter search point pattern matching image alignment object recognition pattern retrieval pixel arrays optimal affine transformation;pattern matching;affine transformation;classification algorithms;affine transforms;comparative study;genetic algorithm;genetic algorithms pattern matching testing simulated annealing evolutionary computation classification algorithms;genetic algorithms;search problems;pattern retrieval;point pattern matching	Matching of point patterns is a fundamental process prior to many applications such as image alignment, object recognition, and pattern retrieval. When two images are aligned, people prefer to deal with sets of local features instead of pixel arrays to increase the accuracy and save the computational time. Given two point patterns, the aim of point pattern matching (PPM) problem is to find an optimal affine transformation which transforms one point pattern by reference to the other such that a dissimilarity measure between them is minimized. This paper investigates the strengths and weaknesses of applying scatter search to cope with the PPM problem. The performance of the proposed algorithm is evaluated by competing with existing algorithms on synthetic datasets. The experimental results manifest that the proposed algorithm is superior and malleable against varying scenarios.	computation;evolutionary algorithm;genetic algorithm;outline of object recognition;pattern matching;perturbation theory;pixel;positive feedback;simulated annealing;synthetic intelligence;time complexity	Peng-Yeng Yin	2012	2012 8th International Conference on Natural Computation	10.1109/ICNC.2012.6234542	mathematical optimization;machine learning;pattern recognition;mathematics	Vision	39.83419176217581	-55.804867668806004	143225
cc8061dce72421e3a7b3a59470063227bdc76749	an integrated color-spatial approach to content-based image retrieval	image segmentation;color retrieval;content based image retrieval;content based retrieval;spatial retrieval	The use of color information for image retrieval has been used widely in many content-based retrieval system with some success. However, histogram-based color retrieval techniques su er from a lack of important spatial knowledge. We discuss a technique of integrating color information with spatial knowledge to obtain an overall impression of the image. The technique involves three steps: the selection of a set of representative colors, the analysis of spatial information of the selected colors, and the retrieval process based on the integrated color-spatial information. Two color histograms are used to aid in the process of color selection. After deriving the set of representative colors, spatial knowledge of the selected colors is obtained using a maximum entropy discretization with event covering method. A retrieval process is formulated to make use of the spatial knowledge to retrieve relevant images. A prototype image retrieval system has been implemented on the Unix system. It is tested on an image database consisting of 260 images. The result shows substantial improvement over the histogram-based color retrieval methods.	color depth;color histogram;content-based image retrieval;discretization;information retrieval;prototype;unix	Wynne Hsu;Tat-Seng Chua;Hung Keng Pung	1995		10.1145/217279.215284	image texture;computer vision;visual word;image retrieval;computer science;image segmentation;automatic image annotation	AI	39.45799981620283	-61.36113177759948	143634
cc5eed6a51e38882b12e92cf4e67ea25fbd1fd00	theoretical foundation of the intersecting cortical model and its use for change detection of aircraft, cars, and nuclear explosion tests	satellite images;moving object;change detection;deteccion blanco;image processing;procesamiento imagen;physical sciences;pne;traitement image;photographie par satellite;corteza visual;detection cible;detection objet;detection mouvement;deteccion movimiento;level set methods;satellite image;autowaves;curvature flow;detection changement;reseau neuronal;fotografia por satelite;theoretical foundation;level set method;satellite photography;icm;target detection;diffusion;cortex visuel;motion detection;visual cortex;red neuronal;pulse coupled neural network;object detection;neural network;fysik	The intersecting cortical model (ICM) is a model based on neural network techniques especially designed for image processing. It was derived from several visual cortex models and is basically the intersection of these models, i.e. the common elements amongst these models. The theoretical foundation of the ICM is given and it is shown how the ICM can be derived as a reduced set of equations of the pulse-coupled neural network based upon models proposed by Eckhorn and Reitboeck.Tests of the ICM are presented: one on a series of images of an aircraft moving in the sky; two on car detection; and one on preparations of underground nuclear explosions.The ICM is shown here, in a few examples, to be useful in imagery change detection: aircraft moving against a homogeneous background without precise geometric matching; car on a road; two cars moving in an urban setting without precise geometric matching; and for a linear structure in a complex background. The ICM can be used when the moving objects are not too small and the background is not too difficult. Changes involving larger linear structures can be detected even if the background is not homogeneous.		Ulf Ekblad;Jason M. Kinser	2004	Signal Processing	10.1016/j.sigpro.2004.03.012	computer vision;image processing;computer science;physical science;mathematics;diffusion;change detection;level set method;statistics	Logic	48.71719992222135	-57.77251411845478	143785
052d664a38a6113675f4de55374a0b49939c05ed	hierarchical depth mapping from multiple cameras	analisis imagen;vision ordenador;image processing;procesamiento imagen;traitement image;computer vision;reconstruction image;stereo matching;reconstruccion imagen;image reconstruction;image analysis;vision ordinateur;depth map;analyse image	We present a method to estimate a dense and sharp depth map using multiple cameras. A key issue in obtaining sharp depth map is how to overcome the harmful in uence of occlusion. Thus, we rst propose an occlusion-overcoming strategy which selectively use the depth information from multiple cameras. With a simple sort and discard technique, we resolve the occlusion problem considerably at a slight sacri ce of noise tolerance. Another key issue in area-based stereo matching is the size of matching window. We propose a hierarchical scheme that attempts to acquire a sharp depth map such that edges of the depth map coincide with object boundaries on the one hand, reduce noisy estimates due to insu cient size of matching window on the other hand. We show the hierarchical method can produce a sharp and correct depth map.	computer stereo vision;depth map	Jong-Il Park;Seiki Inoue	1997		10.1007/3-540-63507-6_261	iterative reconstruction;stereo cameras;computer vision;image analysis;image processing;computer science;depth map;computer graphics (images)	Vision	49.66062460804128	-57.4719551745044	143858
cf99d26417ce412e563e516d797a46440433f8f6	a neural-network-based approach to optical symbol recognition	base donnee;reseau communication;neural networks;fuzzy rules;optical character recognition;musica;database;handwritten digit recognition;base dato;resolucion problema;musique;telecomunicacion optica;telecommunication optique;reconnaissance caractere;reconocimento optico de caracteres;pattern recognition;optical telecommunication;sistema difuso;reconnaissance forme;systeme flou;reseau neuronal;reconocimiento patron;red de comunicacion;character recognition;music;communication network;red neuronal;fuzzy systems;fuzzy system;reconocimiento caracter;problem solving;resolution probleme;reconnaissance optique caractere;neural network;optical music recognition;symbol recognition	In this paper we propose a neural-network-based approach to solving optical symbol recognition problems, from node head recognition to handwritten digit recognition. We demonstrated that node heads could be easily recognized by using a set of fuzzy rules extracted from the parameters of trained neural networks. For handwritten digit recognition we demonstrated that only 12 features are sufficient to achieve a high recognition rate. Several databases were tested to demonstrate the effectiveness and efficiency of the proposed recognition method.	artificial neural network;automated planning and scheduling;database;experiment;fuzzy rule;national supercomputer centre in sweden;optical character recognition;radial basis function network;rule-based system	Mu-Chun Su;Hsin-Hua Chen;Wan-Chi Cheng	2002	Neural Processing Letters	10.1023/A:1015288717988	feature;intelligent character recognition;computer science;artificial intelligence;intelligent word recognition;machine learning;music;3d single-object recognition;optical character recognition;artificial neural network;fuzzy control system;signature recognition	ML	44.07430956361952	-58.9270160046233	143873
c75493c155fe716274918e978d4418053ed859ce	prominent symmetry points as landmarks in finger print images for alignment	experimental results prominent symmetry points landmarks fingerprint images image alignment complex orientation field multiple resolution scales;naturvetenskap;image matching;natural sciences;feature extraction;feature extraction fingerprint identification image matching;fingerprint identification;fingerprint recognition image matching filters testing filtering theory tensile stress information science robustness automatic control humans	For the alignment of two fingerprints the position of certain landmarks are needed. These should be automatically extracted with a low misidentification rate. As landmarks we suggest the prominent symmetry points (core-points) in the fingerprint. They are extracted from the complex orientation field estimated from the global structure of the fingerprint, i.e. the overall pattern of the ridges and valleys. Complex filters, applied to the orientation field in multiple resolution scales, are used to detect the symmetry and the type of symmetry. Experimental results are reported.	fingerprint	Kenneth Nilsson;Josef Bigün	2002		10.1109/ICPR.2002.1047929	fingerprint;computer vision;feature extraction;computer science;machine learning;pattern recognition;mathematics	Vision	41.444671422994574	-58.013019617713304	144075
2a2996a7fe25b354304f8586ae48954421d01ee4	a fast correlation method for scale-and translation-invariant pattern recognition	translation invariant;logarithmic mapping;image processing;fourier transform;cross correlation;image converters;probability density function;auditory system;spectrum;euclidean distance;data mining;scale invariant pattern recognition;correlation pattern recognition fourier transforms discrete fourier transforms image converters discrete transforms visual system auditory system fast fourier transforms image processing;moments;discrete transforms;fourier transforms;discrete fourier transform;transforms;pattern recognition;fast fourier transforms;border effect;correlation;discrete fourier transforms;visual system;scale invariance;scale invariant pattern recognition cross correlation fourier transform logarithmic mapping mellin transform moments pattern recognition;mellin transform	A size- and position-invariant description of an image function can be obtained via the absolute value of the Mellin transform of its Fourier amplitude spectrum. If the transform is implemented on a digital computer via a discrete Fourier-Mellin transform, these exact invariances are not preserved due to sampling-and border-effects. In this paper these effects are discussed, and an alternative correlation method is proposed. The method consists of calculating the normalized absolute magnitude of the discrete Fourier transform (DFT) of the image function (which gives invariance to translation and multiplicative amplitude changes) and a subsequent logarithmic distortion in x- and y- direction, which converts scaling to translation. Two such transforms are compared by calculating the normalized Euclidean distances between both for all possible relative shifts along the main diagonal. If, for some shift, the distance has a minimum below a similarity threshold, the underlying image functions will probably differ only by translation and scaling. The magnitude of this shift is related to the scale factor between the objects. Good separation between similar and nonsimilar objects is possible if two size criteria imposed by the DFT are met: the total object size must not exceed N/4 (N is the number of image points in each dimension), and object details have to be larger than about 4 image points. As a consequence, N increases with object complexity and desired scale range.	algorithm;biologic preservation;central processing unit;computation (action);computer;discrete fourier transform;distortion;euclidean distance;fast fourier transform;genetic translation process;image scaling;interpolation imputation technique;large;parallel computing;pattern recognition;physical object;quartic function;real-time transcription;sampling (signal processing);spectral density;test scaling;time complexity	Jürgen Altmann;Herbert J. Reitböck	1984	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1984.4767474	fourier transform;mathematical analysis;discrete mathematics;image processing;mathematics;geometry	Vision	51.57895824247884	-63.097085852530434	144161
8fd20f35cfc5fb8d61ae9e85b2112b947097ce6d	automatic object-based video segmentation using distributed genetic algorithms	moving object;video object;change detection;automatic segmentation;video segmentation;markov random field;energy function;multiple objectives;object tracking;object extraction;distributed genetic algorithm	This paper presents a segmentation method that can automatically segment a scene into its constitute objects. The proposed method is consists of four major modules: spatial segmentation, temporal segmentation, object extraction and tracking. For the spatial segmentation, a video sequence is modeled using Markov random fields (MRFs), and the energy function of each MRF is minimized by chromosomes that evolve using distributed genetic algorithms (DGAs). Then, to improve the performance, chromosomes of the subsequent frame are started with the segmentation result of the previous frame, thereafter only unstable chromosomes corresponding to the actually moving objects parts are evolved by mating. The change detection masks are produces by the temporal segmentation, and video objects are extracted by combining two segmentation results. Finally, the extracted objects are tracked using the proposed tracking algorithm. Here, the proposed object tracking method need not to compute the motion field or motion parameters. It can deal with scenes including multiple objects, plus keep track of objects even when they stop moving for an arbitrarily long time. The results tested with several real video sequences show the effectiveness of the proposed method.	genetic algorithm;object-based language	Eun Yi Kim;Se Hyun Park	2003		10.1007/3-540-44839-X_34	computer vision;simulation;computer science;machine learning;segmentation-based object categorization;video tracking;image segmentation;scale-space segmentation;change detection;statistics	Robotics	48.230252721242145	-53.42743907254328	144193
d008ed7efb09b6759bd38748ce64f2fe77684f09	segmentation and 3-d recovery of curved-axis generalized cylinders from an intensity image	complex objects;image segmentation;image segmentation intelligent robots shape terminology intelligent systems noise shaping us government geometry joining processes;occlusion 3 d recovery curved axis generalized cylinders intensity image segmentation 3 d object centered descriptions 3 d primitives geometric projective properties structural properties noise contour breaks markings shadows;structural properties	Addresses the problem of segmentation and recovery of 3-D object-centered descriptions of two large sub-classes of curved axis generalized cylinders, PRCGCs and circular PRGCs, from a single real intensity image. The purpose of this work is to augment the set of 3-D primitives which can be recovered, beyond previous work which has addressed mainly straight axis ones, so that more complex objects can be handled. The authors' approach is based on the exploitation of geometric projective properties as well as structural properties of the contours of circular PRGCs. The implemented method works in the presence of noise, contour breaks, markings, shadows and occlusion. The authors demonstrate their method on real images.	apache axis	Mourad Zerroug;Ramakant Nevatia	1994		10.1109/ICPR.1994.576399	computer vision;computer science;mathematics;image segmentation;scale-space segmentation;computer graphics (images)	Vision	51.54651047318508	-54.381528726293965	144337
6f7c08559d2f99e78734e4f9746130c1247e5e29	directional relations composition by orientation histogram fusion	histograms;topology;degradation;spatial reasoning;distance relations;histogram fusion;layout;spatial reasoning model;spatial relation;spatial scene histogram fusion topological relation distance relations spatial reasoning model orientation histogram;histograms industrial relations layout degradation us department of transportation;relational model;spatial scene;pattern recognition;industrial relations;us department of transportation;orientation histogram;sensor fusion;topological relation;sensor fusion pattern recognition spatial reasoning topology	Orientation relations represent a significant component of spatial relations, complementing topological and distance relations, for the description of a spatial scene. The most important operator, in a spatial reasoning model is an operator of composition defining the behavior of the combination of two relations. This paper focuses on the composition of orientation relations modeling by orientation histogram. Composition can be seen as fusion of orientation information derived from the orientation histograms and spatial objects information, represented mainly by vectorial data.		Jamal Malki;Laurent Mascarilla;El-hadi Zahzah;Patrice Boursier	2000		10.1109/ICPR.2000.903655	spatial relation;layout;computer vision;relational model;degradation;computer science;machine learning;pattern recognition;histogram;mathematics;sensor fusion;industrial relations;spatial intelligence	NLP	41.34187565357853	-62.930213835708926	144369
8cae9bfd310f5b2d9c79bd24a5cf60fd25048474	fast algorithms for ridge detection	analytic surfaces;principal curvature;fast algorithms;image analysis shape measurement cities and towns geometry humans skeleton topology design automation computer aided manufacturing cadcam;surface fitting feature extraction computational geometry;view independent ridges;computational geometry;surface fitting;principal direction;characteristic feature;ridge detection;real data;feature extraction;fast algorithm;real data fast algorithms ridge detection view independent ridges graphs of functions principal curvature principal direction characteristic feature analytic surfaces;graphs of functions	We propose fast algorithms for the detection of viewindependent ridges on surfaces given by graphs of functions. The ridges are dejined via exifrema of the principal curvatures along the associated principal direction. These algorithms have the advantage to be jhst and it appears that the so-deJined ridges deserve as a characteristic feature of the shape of the surface. Results on analytic surfaces and on real data are shown and discussed.	algorithm;fast fourier transform;graph of a function;ridge detection;time complexity	V. Lang;Alexander G. Belyaev;I. A. Bogaevsici;Tosiyasu L. Kunii	1997		10.1109/SMA.1997.634896	computer vision;principal curvature;feature extraction;computational geometry;mathematics;geometry;graph of a function;ridge detection	Vision	49.319168925913154	-62.68141322183981	144431
5c6c1c927704effe7f707903043c2c2e7b8b5c9d	bezier curve-based character descriptor considering shape information	automatic control;image coding;image segmentation;shape descriptor;bezier curves;edge detection;shape segmentation;control points bezier curves shape descriptor curvature corner points;information technology;cp encoding bezier curves shape information bc based character descriptor control points curvature properties cornerity properties shape segmentation;cornerity properties;image segmentation character recognition curve fitting edge detection feature extraction image coding;corner points;shape information;feature extraction;curvature properties;multimedia communication;mobile communication;performance analysis;control points;cp encoding;curvature;shape control;curve fitting;communication system control;shape control algorithm design and analysis mobile communication performance analysis multimedia communication information technology australia automatic control communication system control encoding;encoding;character recognition;algorithm design and analysis;australia;bc based character descriptor;bezier curve	While a Bezier curve (BC)-based character descriptor calculates the control points (CPs), it does not consider the shape characteristics for a prescribed distortion. This paper presents a novel Bezier Curve-based character descriptor considering shape information (BCDSI) which automatically divides a shape into segments based on the curvature and cornerity properties. Each segment is then defined by either a BC or straight line, depending on the distortion criteria in terms of a set of CPs. Quantitative and qualitative performances of the algorithm have been rigorously analysed upon both English and Bangla alphabetic characters, with the results confirming that the new BCDSI algorithm exhibits superior performance over other currently available shape descriptor algorithms employing the BC.	algorithm;bézier curve;control point (mathematics);distortion;performance	Ferdous Ahmed Sohel;Gour C. Karmakar;Laurence Dooley	2007	6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)	10.1109/ICIS.2007.69	computer vision;mathematics;geometry;engineering drawing	Vision	43.41480446429545	-64.68407956115205	144535
9b7d2ff16cfcb5ab9624e0cdd24a31941c536bb8	retrieving landscape images using scene structural matrix	scene structural matrix;paysage;recherche image;paisaje;histogram;histogramme;indexing;description contenu image;indexation;indizacion;landscape;histograma;content based retrieval;recherche par contenu;image retrieval	In this paper, we present Scene Structural Matrix (SSM) and apply it to the retrieval of landscape images. The SSM captures the overall structural characteristics of the scene by indexing the geometric features of the image. A binary image tree (bintree) is used to partition the image and from which we derive multi-resolution geometric structural descriptors of the image. It is shown that SSM is particularly effective in retrieving images with strong structural features, such as landscape photographs. We show that SSM is robust against spatial and spectral distortions thus making it superior to current state of the art techniques such as color correlogram in certain applications. We will also show that images retrieved by the SSM are more relevant than those returned by color correlogram and color histogram.	binary image;color histogram;distortion;log-spectral distance	Guoping Qiu;S. Sudirman	2001		10.1007/3-540-45453-5_122	computer vision;search engine indexing;image retrieval;computer science;histogram;landscape;statistics	Vision	40.17544248265546	-59.94775868086981	144576
04553d8cf358ce19079ba86a46d037b8aecb5f61	determining straight line correspondences from intensity images	edge boundary;pretraitement image;analisis escena;analyse scene;image processing;contour;pretratamiento imagen;extraction forme;procesamiento imagen;traitement image;extraccion forma;pattern matching;feature extraction;segment droite;segmento recta;contorno;line segment;concordance forme;pattern extraction;scene analysis	Abstract   This paper presents an algorithm for straight edge extraction from intensity images and an algorithm for straight line matching. In the first part of the paper, straight edge extraction is described. Image data are first processed by the operation of edge support focusing to remove unnecessary image details. An edge support is formed in this process. Then, straight edges are extracted from line support regions, which are segmented from the edge support. In the second part of this paper, we describe straight line matching using a matching function, which characterizes the similarity of edge lines of two images and is based on not only the geometrical relations of the lines but also the information from the intensity images. A technique of two-step matching is applied to reduce the cost of computation.  The motivation behind this paper is our work on motion estimation from line correspondences of sequential images where straight edge extraction and matching is an essential first step. The output data of the algorithm can also be used for calibration of stereo camera setups. The results of experiments using indoor and outdoor scene images are shown.		Yuncai Liu;Thomas S. Huang	1991	Pattern Recognition	10.1016/0031-3203(91)90016-X	computer vision;line segment;image processing;feature extraction;computer science;machine learning;pattern matching;geometry;computer graphics (images)	Vision	49.12833249821527	-58.15838038156928	144755
be6cc1695d8cf28b051534879b6dcde32b5ef6ed	detection and segmentation of generic shapes based on affine modeling of energy in eigenspace	eigenvalues and eigenfunctions;background noise;object recognition;transformation affine;edge map representation;clutter;detection forme;probability;algoritmo busqueda;image segmentation;image processing;affine parameters;circles;edge detection;shape segmentation;algorithme recherche;energy probability based detection;vectorial eigen space;search algorithm;distributed computing;procesamiento imagen;vectorial boundary noise shape detection shape segmentation man made generic shapes cluttered images affine transformed geometric shapes rectangles circles shape representation vectorial edge map affine parameters eigenvectors a posteriori probability map energy distribution edge map representation vectorial eigen space energy probability based detection hypertoroid verification stage fast search algorithm angle space pose information karhunen loeve transform angular representation euclidean distance representation;man made generic shapes;reconnaissance objet;posterior probability;euclidean distance;layout;indexing terms;shape detection;vectorial edge map;noise robustness;traitement image;eigenvector;experimental result;vectorial boundary noise;vector propio;shape image edge detection object detection image segmentation noise robustness background noise noise shaping distributed computing euclidean distance layout;vecino mas cercano;deteccion forma;shape representation;verification stage;karhunen loeve transforms;karhunen loeve transforms edge detection image segmentation eigenvalues and eigenfunctions clutter probability search problems image representation;shape;image edge detection;affine transformed geometric shapes;angular representation;image representation;energy distribution;affine transformation;segmentation image;fast search algorithm;resultado experimental;angle space;plus proche voisin;noise shaping;nearest neighbour;search problems;a posteriori probability map;resultat experimental;pose information;karhunen loeve transform;vecteur propre;transformacion afin	This paper presents a novel approach for detection and segmentation of man made generic shapes in cluttered images. The set of shapes to be detected are members of affine transformed versions of basic geometric shapes such as rectangles, circles etc. The shape set is represented by its vectorial edge map transformed over a wide range of affine parameters. We use vectorial boundary instead of regular boundary to improve the robustness to noise, background clutter and partial occlusion. Our approach consists of a detection stage and a verification stage. In the detection stage, we first derive the energy from the principal eigenvectors of the set. Next, an a posteriori probability map of energy distribution is computed from the projection of the edge map representation in a vectorial eigen-space. Local peaks of the posterior probability map are located and indicate candidate detections. We use energy/probability based detection since we find that the underlying distribution is not Gaussian and resembles a hypertoroid. In the verification stage, each candidate is verified using a fast search algorithm based on a novel representation in angle space and the corresponding pose information of the detected shape is obtained. The angular representation used in the verification stage yields better results than a Euclidean distance representation. Experiments are performed in various interfering distortions, and robust detection and segmentation are achieved.	angularjs;clutter;distortion;eigen (c++ library);euclidean distance;experiment;generic drugs;mandelbrot set;normal statistical distribution;search algorithm;segmentation action;sensor;verification of theories;version	Zhiqian Wang;Jezekiel Ben-Arie	2001	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.967390	computer vision;combinatorics;image processing;eigenvalues and eigenvectors;computer science;mathematics;geometry;statistics	Vision	42.18421654884986	-59.61614060430569	144837
10f1647e2b2eabc54d10e513583caf2966266a7d	fast iris detection for personal verification using modular neural nets	reconnaissance visage;learning process;image recognition;reconocimiento imagen;image segmentation;cross correlation;biometrie;biometrics;biometria;face recognition;neural net;image simulation;computational complexity;iris ojo;segmentation image;reconnaissance image;detection iris humain;iris oeil;reseau neuronal;image decomposition;frequency domain;red neuronal;neural network;iris eye	In this paper, a combination of fast and cooperative modular neural nets to enhance the performance of the detection process is introduced. I have applied such approach successfully to detect human faces in cluttered scenes [10]. Here, this technique is used to identify human irises automatically in a given image. In the detection phase, neural nets are used to test whether a window of 20×20 pixels contains an iris or not. The major difficulty in the learning process comes from the large database required for iris / noniris images. A simple design for cooperative modular neural nets is presented to solve this problem by dividing these data into three groups. Such division results in reduction of computational complexity and thus decreasing the time and memory needed during the test of an image. Simulation results for the proposed algorithm show a good performance. Furthermore, faster iris detection is obtained through image decomposition into many sub-images and applying cross correlation in frequency domain between each sub-image and the weights of the hidden layer.	artificial neural network	Hazem M. El-Bakry	2001		10.1007/3-540-45493-4_31	computer vision;computer science;artificial intelligence;cross-correlation;machine learning;image segmentation;computational complexity theory;frequency domain;artificial neural network;biometrics	NLP	44.23425445165406	-58.99728390772647	144885
16b73ddb6c1370b37e0e96b4bded3ab3ae392426	an ensemble approach to image matching using contextual features	detectors;histograms;image segmentation;visualization;scale invariant feature transform contextual features 2d image matching image registration image pairs linear features corner keypoints pseudo corners homography refinement methods edge information gradient information;feature extraction;pipelines;lighting;feature extraction visualization lighting image segmentation histograms pipelines detectors;histogram of gradients keypoint matching 2d registration contextual features ensemble features linear features;image registration feature extraction gradient methods image matching	We propose a contextual framework for 2D image matching and registration using an ensemble feature. Our system is beneficial for registering image pairs that have captured the same scene but have large visual discrepancies between them. It is common to encounter challenging visual variations in image sets with artistic rendering differences or in those collected over a period of time during which the lighting conditions and scene content may have changed. Differences between images may also be caused using a variety of cameras with different sensors, focal lengths, and exposure values. Local feature matching techniques cannot always handle these difficulties, so we have developed an approach that builds on traditional methods to consider linear and histogram of gradient information over a larger, more stable region. We also present a technique for using linear features to estimate corner keypoints, or pseudo corners, that can be used for matching. Our pipeline follows this unique matching stage with homography refinement methods using edge and gradient information. Our goal is to increase the size of accurate keypoint match sets and align photographs containing a combination of man-made and natural imagery. We show that incorporating contextual information can provide complimentary information for scale invariant feature transform and boost local keypoint matching performance, as well as be used to describe corner feature points.	align (company);alignment;artistic rendering;clutter;complement system proteins;data descriptor;focal (programming language);feature extraction;feature model;gradient descent;guided imagery;harris affine region detector;homography (computer vision);image registration;large;matching;pseudo brand of pseudoephedrine;refinement (computing);scale-invariant feature transform;security descriptor;sensor;subgroup;photograph;registration - actclass	Brittany Morago;Giang Bui;Ye Duan	2015	IEEE Transactions on Image Processing	10.1109/TIP.2015.2456498	computer vision;detector;feature detection;template matching;visualization;feature extraction;computer science;machine learning;pattern recognition;lighting;histogram;mathematics;pipeline transport;image segmentation;feature;statistics	Vision	45.464557193431176	-54.59868033948454	144969
45cf2f6fe83915f41300858e6bb91d456127cef4	discrete wavelet descriptor for 2d shape	object representation;discrete wavelet transforms;image recognition;shape recognition;discrete wavelet transforms shape databases object recognition computer vision mpeg 7 standard fourier transforms covariance matrix;null;wavelet transform;image representation;object extraction;decomposition level discrete wavelet descriptor 2d shape recognition method discrete dyadic wavelet transform object representation objects retrieval system contour signature;image retrieval image recognition discrete wavelet transforms image representation;image retrieval	The aim of this paper is to propose a 2D shape recognition method under similitude transforms using the discrete dyadic wavelet transform with decimation (DWT). We propose four technics to fix the starting point necessary to obtain the same object representation in the framework of objects retrieval system. These representations are obtained by applying the DWT on the contour signature. We also propose a method to select a decomposition level of the DWT. These different solutions are assessed and compared using 1400 2D objects extracted from the MPEG7 database.	decimation (signal processing);discrete wavelet transform;dyadic transformation;mpeg-7	Kimcheng Kith;El-hadi Zahzah	2004	Third International Conference on Image and Graphics (ICIG'04)	10.1109/ICIG.2004.56	multiresolution analysis;wavelet;computer vision;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;image retrieval;computer science;theoretical computer science;curvelet;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Vision	41.39395925901944	-59.746924137978596	144985
65d9bc8931b3435eb605c71180550675aa2d065e	the 2.1-d sketch	minimisation;human visual system edge junctions image segmentation depth reconstruction human vision edge terminations disrupted edges crack tips corners cusps occluding regions 2 1 d sketch minimization problem optimal contours nonlinear splines square of curvature optical illusions;human vision;minimisation computer vision computerised picture processing;image segmentation;image segmentation blades humans lenses motion estimation electronic mail visual system military computing information resources layout;computer vision;monograph or book;human visual system;computerised picture processing	A model is described for image segmentation that tries to capture the low-level depth reconstruction exhibited in early human vision, giving an important role to edge terminations. The problem is to find a decomposition of the domain D of an image that has a minimum of disrupted edges-junctions of edges, crack tips, corners, and cusps-by creating suitable continuations for the disrupted edges behind occluding regions. The result is a decomposition of D into overlapping regions R/sub 1/ union . . . union R/sub n/ ordered by occlusion, which is called the 2.1-D sketch. Expressed as a minimization problem, the model gives rise to a family of optimal contours, called nonlinear splines, that minimize length and the square of curvature. These are essential in the construction of the 2.1-D sketch of an image, as the continuations of disrupted edges. An algorithm is described that constructs the 2.1-D sketch of an image, and gives results for several example images. The algorithm yields the same interpretations of optical illusions as the human visual system. u003e		Mark Nitzberg;David Mumford	1990		10.1109/ICCV.1990.139511	computer vision;minimisation;computer science;machine learning;geometry;image segmentation;human visual system model;computer graphics (images)	Theory	50.63016712727109	-59.82771820420512	145029
6025e0f2f977ace671f9be84246a8287450ce43d	fast detection and segmentation of partial image blur based on discrete walsh-hadamard transform		Abstract Image signals can be blurred due to defocus or motion. Blur may be undesirable for image sensing, but may also contain useful information. Therefore, detecting the blurriness of each pixel and segmenting the partial blur regions in natural images are important and yet challenging in the field of machine vision. A concise no-reference method based on discrete Walsh–Hadamard transform is proposed to detect and segment partial blur in this paper. First, a re-blurring strategy is performed over multiple overlapping image patches extracted from the test image. Then, for both test image and re-blurred image, discrete Walsh–Hadamard transforms are utilized in each image patches to obtain the blur map. This blur map can characterize the blurriness of each pixel in test image. Based on it, combined with K-Means clustering and region-growing, the test image can be segmented into blurry/non-blurry regions. The experiments, performed on a public dataset, demonstrate the capability of the proposed metric in the detection and segmentation of the blur region. Comparative results with the state-of-the-art show the superiority of the proposed approach in image segmentation for both defocus and motion blur images. The proposed approach is compendious without data training and possesses a high time efficiency because of the fast sequency transform.		Xuewei Wang;Xiao Liang;Jinjin Zheng;Hongjun Zhou	2019	Sig. Proc.: Image Comm.	10.1016/j.image.2018.09.007	motion blur;computer vision;market segmentation;machine vision;artificial intelligence;image segmentation;cluster analysis;pixel;hadamard transform;computer science;standard test image	Vision	44.301194840848176	-55.47781294894881	145066
2c2a4fdb4263573818655f84cea91a98189da493	estimating printer misregistration from color shifts: a new paradigm	baja resolucion;printing;4230;halftones;reflectivity;printers;methode mesure;etude experimentale;facteur reflexion;0130c;low resolution;basse resolution;methode geometrique;geometrical method;etat actuel;accuracy;scanners;precision;robustesse;state of the art;pixel;measuring methods;imprimante;impression;robustness;estado actual;metodo geometrico;imagen color;image couleur;color image;color printing;robustez	Inherent to most multi-color printing systems is the inability to achieve perfect registration between the primary separations. Because of this, dot-on-dot or dot-off-dot halftone screen sets are generally not used, due to the significant color shift observed in the presence of even the slightest misregistration. Much previous work has focused on characterizing these effects, and it is well known that dot-off-dot printed patterns result in a higher chroma (C*) relative to dot-on-dot. Rotated dot sets are used instead for these systems, as they exhibit a much greater robustness against misregistration. In this paper, we make the crucial observation that while previous work has used color shifts caused by misregistration to design robust screens, we can infact exploit these color shifts to obtain estimates of misregistration. In particular, we go on to demonstrate that even low resolution macroscopic color measurements of a carefully designed test patch can yield misregistration estimates that are accurate up-to the sub-pixel level. The contributions of our work are as follows: 1.) a simple methodology to construct test patches that may be measured to obtain misregistration estimates, 2.) derivation of a reflectance printer model for the test patch so that color deviations in the spectral or reflectance space can be mapped to misregistration estimates, and 3.) a practical method to estimate misregistration via scanner RGB measurements. Experimental results show that our method achieves accuracy comparable to the state-of-the art but expensive geometric methods that are currently used by high-end color printing devices to estimate misregistration.© (2008) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	printer (computing);programming paradigm	Jon S. McElvain;Vishal Monga;Charles M. Hains;Manu Parmar	2008		10.1117/12.766539	computer science;accuracy and precision;optics;statistics;computer graphics (images)	Crypto	52.191215439200604	-58.49558089591398	145120
98e04badbe671bbbb38a987576e2ad091cc66899	a projection-based extension to phase correlation image alignment	robust alignment;alignement sequence;image processing;image alignment;image matching;procesamiento imagen;alineacion secuencia;image bruitee;traitement image;registro imagen;imagen sonora;accuracy;masquage;precision;recalage image;enmascaramiento;robustesse;image registration;fonction correlation;noisy image;correlation function;fourier based;masking;funcion correlacion;robustness;sequence alignment;appariement image;phase correlation;robustez	Phase-correlation (PC) is a computationally efficient scheme for estimating 2-D and 3-D translations. We present a masking operator that significantly improves the accuracy and robustness of the PC scheme. The masking projects the estimated correlation function on the space of correlation functions that result from a certain range of translations, while rejecting components that are unrelated to the estimated motion. Thus, the registration accuracy is improved by an order of magnitude, especially when registering noisy images and volumes. The scheme is also shown to improve the registration of rotated images in the Fourier domain. r 2006 Elsevier B.V. All rights reserved.	additive white gaussian noise;algorithmic efficiency;aliasing;image registration;phase correlation;pixel;signal processing;signal-to-noise ratio	Yosi Keller;Amir Averbuch	2007	Signal Processing	10.1016/j.sigpro.2006.04.013	computer vision;image processing;computer science;mathematics;geometry;accuracy and precision;statistics	Vision	52.08813056790484	-58.66200686433669	145134
022af111eb44f4b7a64d5f142eb030ce9c2fb3cd	localisation of image features using measures of rank distribution	grey scale images local rank distribution image structure image feature localisation image enhancement diversity pixel precision;image features;edge detection;pixel physics electronic mail filters morphology particle measurements statistics;computer vision;image enhancement;feature extraction;computer vision image enhancement feature extraction	Measures which characterise local rank distribution can be used to enhance and localise image structure. The diversity and local rank of pixels provide results which are invariant to any strictly order-preserving transformations previously applied to the image data. Localisation of image features to pixel precision is possible through the rank distribution, even with the use of relatively large window sizes. To help detect variations in rank distributions over lengths smaller than the window size, we present methods to sharpen the response of local diversity to image structure. The aim is to enhance image features based directly on rank, rather than using conventional linear edge detection. The methods outlined in this paper may be applied to single or multi-band image data.	edge detection;pixel	Imants D. Svalbe;Carolyn J. Evans	1998		10.1109/ICPR.1998.711112	image quality;image texture;image restoration;computer vision;feature detection;edge detection;image gradient;binary image;image processing;feature extraction;computer science;machine learning;free boundary condition;pattern recognition;image moment;mathematics;pixel connectivity;non-local means;feature	Vision	40.84871076750054	-61.84151859417216	145166
61191412d1811aaa2a75c90890ca23a67da5eecc	pairwise matching of 3d fragments using cluster trees	artefacto;hierarchical clustering;alignement;arbre recherche;image tridimensionnelle;hierarchical system;paroi mince;thin wall;image processing;contact area;structure arborescente;metodo arborescente;systeme hierarchise;procesamiento imagen;search strategy;fragment alignment;contact surface;traitement image;artefact;surface contact;registro imagen;sistema jerarquizado;pared delgada;cluster tree;surface registration;superficie contacto;surface matching;arbol investigacion;recalage image;estructura arborescente;arbol binario;image registration;tree structure;arbre binaire;alineamiento;strategie recherche;tâche appariement;tarea apareamiento;tridimensional image;tree structured method;methode arborescente;fracture matching;broken objects;search tree;matching task;alignment;surface registration 3d puzzle;imagen tridimensional;3d puzzle;estrategia investigacion;binary tree	We propose a novel and efficient surface matching approach for reassembling broken solids as well as for matching assembly components using cluster trees of oriented points. The method rapidly scans through the space of all possible contact poses of the fragments to be (re)assembled using a tree search strategy, which neither relies on any surface features nor requires an initial solution. The new method first decomposes each point set into a binary tree structure using a hierarchical clustering algorithm. Subsequently the fragments are matched pairwise by descending the cluster trees simultaneously in a depth-first fashion. In contrast to the reassemblage of pottery and thin walled artifacts, this paper addresses the problem of matching broken 3D solids on the basis of their 2.5D fracture surfaces, which are assumed to be reasonable large. Our proposed contact area maximization is a powerful common basis for most surface matching tasks, which can be adapted to numerous special applications. The suggested approach is very robust and offers an outstanding efficiency.	2.5d;binary tree;cluster analysis;computer cluster;depth-first search;expectation–maximization algorithm;hierarchical clustering;tree structure	Simon Winkelbach;Friedrich M. Wahl	2007	International Journal of Computer Vision	10.1007/s11263-007-0121-5	computer vision;combinatorics;binary tree;image processing;computer science;image registration;contact area;mathematics;geometry;hierarchical clustering;hierarchical control system;tree structure;search tree;algorithm	Vision	50.655394153290956	-60.154746200176504	145173
8ee09584bd6261b09f61e714bf88ddfb70dd512f	from local descriptors to holistic models: a general framework embedding video processing and object representation	video signal processing computational geometry computer vision feature extraction hough transforms image denoising image representation image restoration image sequences image texture object tracking statistical analysis;image processing;geometry;computer vision;computational modeling;abstracts;dense hough transforms local descriptors video processing object representation feature space based image processing model feature space based image representation model local geometry description local categorisation similarity based metrics nonlocal denoising inpainting optical flow background estimation background tracking global geometrical measures global statistical measures computer vision statistical salient structures;image processing mathematical model geometry computer vision computational modeling computer science abstracts;mathematical model;computer science	Summary form only given. We present in this talk recent and ongoing works on feature space based image processing and representation models. We choose the multiscale partial derivatives (the local jet) as a basic description of the local geometry. The local jet feature space allows local categorisation and provides a similarity based metrics which can be used in many image processing and vision tasks, including: non local denoising, inpainting, optical flow, background estimation and tracking. Furthermore, global geometrical or statistical measures in the feature space provide relevant descriptors of objects, textures, scenes or activities, that revisit from a new perspective several classic themes of computer vision, amongst which: statistical salient structures, dense Hough transforms. Finally, we consider the active vision point of view, assuming that the scene is partially and progressively acquired by a moving sensor, and investigate the model associated to this sparse and dynamic representation.	active vision;categorization;computer vision;feature vector;holism;hough transform;image processing;inpainting;noise reduction;optical flow;sparse matrix;video processing	Antoine Manzanera	2014	2014 4th International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2014.7001918	hough transform;computer vision;pyramid;feature detection;scale space;edge detection;image processing;computer science;local feature size;machine learning;digital image processing;pattern recognition;mathematical model;mathematics;bag-of-words model in computer vision;multi-scale approaches;computational model;feature;scale-space axioms	Vision	39.93859362654755	-54.292946367577265	145178
9bcb685e180af66bf52e76932dc5b1a3a273f9af	colour invariants under a non-linear photometric camera model and their application to face recognition from video	recognition;face;video;invariant;colour	Illumination invariance remains one of the most researched, yet the most challenging aspect of automatic face recognition. In this paper the discriminative power of colour-based invariants is investigated in the presence of large illumination changes between training and query data, when appearance changes due to cast shadows and non-Lambertian effects are significant. Specifically, there are three main contributions: (i) a general photometric model of the camera is described and it is shown how its parameters can be estimated from realistic video input of pseudo-random head motion, (ii) several novel colour-based face invariants are derived for different special instances of the camera model, and (iii) the performance of the largest number of colour-based representations in the literature is evaluated and analysed on a database of 700 video sequences. The reported results suggest that: (i) colour invariants do have a substantial discriminative power which may increase the robustness and accuracy of recognition from low resolution images in extreme illuminations, and (ii) that the nonlinearities of the general photometric camera model have a significant effect on recognition performance. This highlights the limitations of previous work and emphasizes the need to assess face recognition performance using training and query data which had been captured by different acquisition equipment. & 2012 Elsevier Ltd. All rights reserved.	facial recognition system;image resolution;lambertian reflectance;nonlinear system;pseudorandomness	Ognjen Arandjelovic	2012	Pattern Recognition	10.1016/j.patcog.2012.01.013	face;computer vision;video;invariant;three-dimensional face recognition;mathematics;geometry;multimedia;computer graphics (images)	Vision	42.19605914146984	-52.87344352878179	145276
2bcd1f4de0408313b6f8960b22ec4bfd0b386f09	automatic registration of tree point clouds from terrestrial lidar scanning for reconstructing the ground scene of vegetated surfaces	skeleton vegetation remote sensing vectors cost function lasers estimation;lasers;vegetation geophysical image processing image registration remote sensing by laser beam solid modelling;cost function;skeleton;vegetation;tree skeleton point cloud registration terrestrial lidar;vectors;estimation;field scanning efficiency tree point cloud automatic registration terrestrial lidar scanning vegetated surfaces botanical trees fully reconstruct 3 d models terrestrial laser scanners skeleton segments cost function mapping coarse registration gauss newton method populus euphratica tree heihe river basin;remote sensing	Multiple scans are generally required to fully reconstruct 3-D models of botanical trees. An algorithm for the automatic registration of tree point clouds scanned from terrestrial laser scanners is proposed in this letter. The method extracts skeletons from the point cloud and conducts coarse registration automatically. It defines a distance measure between two skeleton segments and a mapping cost function between two skeletons. The coarse registration is refined using the Gauss-Newton method. Three example trees, including a Populus euphratica tree scanned in the lower reaches of the Heihe River basin, are registered using the proposed algorithm. The algorithm does not require a perfect skeleton to be extracted. No manual coarse registration is needed. The algorithm contributes to the automatic marker-free tree point cloud registration and improves field scanning efficiency by making the placement of markers unnecessary.	gauss–newton algorithm;loss function;newton's method;point cloud;point set registration;terrestrial television	Guiyun Zhou;Bin Wang;Ji Zhou	2014	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2014.2314179	computer vision;estimation;laser;hydrology;computer science;mathematics;skeleton;physics;vegetation;statistics;remote sensing	Vision	51.405934148678455	-53.269566661364564	145350
c1ec45df6a3d1202d0876ce5ca62b9d41c34cab6	recovery of upper body poses in static images based on joints detection	processus gauss;mcmc algorithm;fonction vraisemblance;continuous function;mcmc methods;image processing;imagen fija;articulation;heuristic method;mesure position;procesamiento imagen;metodo heuristico;fonction continue;arriere plan;prior knowledge;traitement image;medicion posicion;funcion verosimilitud;articulacion;torso detection;background;gaussian mixture model;fixed image;funcion continua;markov chain monte carlo;human body;position measurement;algoritmo mcmc;pattern recognition;image fixe;clothing;teoria mezcla;vestidura;methode heuristique;reconnaissance forme;gaussian process;algorithme mcmc;joint;reconocimiento patron;proceso gauss;mixture theory;theorie melange;likelihood function;vetement;pose estimation	Recovering human body poses from static images is challenging without prior knowledge of pose, appearance, background and clothing. In this paper, we propose a novel model-based upper poses recovery method via effective joints detection. In our research, three observables are firstly detected: face, skin, and torso. Then the joints are properly initialized according to the observables and some heuristic configuration constraints. Finally the sample-based Markov chain Monte Carlo (MCMC) method is employed to determine the final pose. The main contributions of this paper include a robust torso detector through maximizing a posterior estimation, effective joints initialization, and two continuous likelihood functions developed for effective pose inference. Experiments on 250 real world images show that our method can accurately recover upper body poses from images with a variety of individuals, poses, backgrounds and clothing.		Zhilan Hu;Guijin Wang;Xinggang Lin;Hong Yan	2009	Pattern Recognition Letters	10.1016/j.patrec.2008.12.005	continuous function;joint;computer vision;human body;simulation;pose;markov chain monte carlo;image processing;computer science;artificial intelligence;clothing;mixture model;gaussian process;mathematics;likelihood function;statistics	Vision	47.29437188038738	-56.83419914498837	145394
3804f5ea33210bef13e1795e5c75e8fd1e76e274	accurate object localization in gray level images using the center of gravity measure: accuracy versus precision	maximum likelihood estimation image processing approximation theory error analysis gaussian distribution gaussian noise;gaussian noise;object recognition;centro gravitacional;centre gravite;image processing;centroid;maximum likelihood;localizacion objeto;subpixel precision;object position;center of mass;object location;maximum vraisemblance;ruido gaussiano;additive noise;ruido aditivo;procesamiento imagen;bruit additif;reconnaissance objet;imagen nivel gris;gravity additive noise noise generators object detection two dimensional displays gaussian noise object recognition biomedical imaging stochastic resonance maximum likelihood detection;indexing terms;maximum likelihood estimation;traitement image;approximation theory;error analysis;object localization;maximum likelihood estimate;ordered by external client;image niveau gris;bruit gaussien;center of gravity;measurement noise object localization gray level images subpixel precision estimate weighted center of gravity maximum likelihood estimators two dimensional center of gravity image noise gaussian distribution pixels 2d bell shaped markers gaussian noise approximations approximation variance estimate error signal to noise ratio object recognition subpixel precision;variance estimation;signal to noise ratio;grey level image;localisation objet;gaussian distribution;maxima verosimilitud;measurement noise;wiskunde en informatica wiin;object detection;variance;variancia	A widely used subpixel precision estimate of an object center is the weighted center of gravity (COG). We derive three maximum-likelihood estimators for the variance of the two-dimensional (2-D) COG as a function of the noise in the image. We assume that the noise is additive, Gaussian distributed and independent between neighboring pixels. Repeated experiments using 2500 generated 2-D bell-shaped markers superimposed with an increasing amount of Gaussian noise were performed, to compare the three approximations. The error of the most exact approximative variance estimate with respect to true variance was always less than 5% of the latter. This deviation decreases with increasing signal-to-noise ratio. Our second approximation to the variance estimate performed better than the third approximation, which was originally presented by Oron et al. by up to a factor approximately 10. The difference in performance between these two approximations increased with an increasing misplacement of the window in which the COG was calculated with respect to the real COG.	approximation;experiment;grayscale;normal statistical distribution;pixel;precision and recall;sample variance;signal-to-noise ratio;utility functions on indivisible goods	Hans C. van Assen;Michael Egmont-Petersen;Johan H. C. Reiber	2002	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/TIP.2002.806250	computer vision;image processing;pattern recognition;mathematics;maximum likelihood;statistics	Robotics	48.641296292729265	-65.29038968261769	145643
0461e78b53c5c2c78d31ecd96d811c8ac86af390	a natural norm for color processing	analisis imagen;modele geometrique;image processing;edge detection;analisis forma;procesamiento imagen;traitement image;deteccion contorno;detection contour;natural selection;image analysis;pattern analysis;imagen color;analyse image;image couleur;analyse forme;color image;steepest descent;geometrical model;modelo geometrico	"""Abs t r ac t . We show that the geometrical framework, in which color images are considered as surfaces, results in a meaningful operator for enhancing color images. The area functional, or """"norm '~, captures the way we would like the smoothing process to act on the different color channels while exploring the coupling between them. Next, the steepest descent flow associated with the first variation of this functional is shown to be a natural selective smoothing filter for the color case. Here we justify the usage of the area norm and the Beltrami steepest descent flow in the color case. We list the requirements, compare to other recent norms, relate to line element methods in color, and conclude with simulation results."""	color;first variation;glossary of computer graphics;gradient descent;requirement;simulation;smoothing	Ron Kimmel	1998		10.1007/3-540-63930-6_108	gradient descent;computer vision;natural selection;image analysis;edge detection;color image;image processing;computer science;artificial intelligence;mathematics	Vision	51.3965908553545	-59.77001291533259	145725
3e2ac0cb5911a1d64694a3b48bf97b624c75ee18	point landmarks for registration of ct and mr images	nuclear magnetic resonance imaging;forme concave;representacion proyectiva;marking;computerized axial tomography;tomodensitometria;transformation affine;informatica biomedical;biomedical data processing;affine projection;recording;etude experimentale;forma concava;point landmarks;informatique biomedicale;conjunto canonico;biomedical imaging;image;representation projective;concavities;imageria rmn;tomodensitometrie;mr imaging;enregistrement;canonical ensemble;indexing;imagen;marcacion;affine and projective transformations;projective representation;affine transformation;indexation;canonical frame;registration;indizacion;reperage;imagerie rmn;concave shape;convex hull;frame of reference;ensemble canonique;estudio experimental;measure of mismatch;registro;transformacion afin	We propose here a point landmark based registration method utilizing geometric invariance properties of biomedical images. These point landmarks constitute entrance and exit points of concavities of individual structures and points of inflexion of curves, derived from the convex hull. Registration is performed in a canonical frame of reference. This technique is fast, semi-automatic and computationally inexpensive.	convex hull;semiconductor industry	Sreeparna Banerjee;Dipti Prasad Mukherjee;D. Dutta Majumder	1995	Pattern Recognition Letters	10.1016/0167-8655(95)00058-O	medical imaging;frame of reference;recording;computer vision;search engine indexing;canonical ensemble;topology;projective representation;convex hull;image;affine transformation;mathematics;geometry	Vision	48.77058338186083	-60.357035147724254	145736
c266a11ea7dcb7134cac03d19ce68216272cd975	a robust boundary-based object recognition in occlusion environment by hybrid hopfield neural networks	calcul matriciel;object recognition;occluded object;boundary representation;algoritmo busqueda;image processing;fault tolerant;hopfield network;algorithme recherche;transformacion fourier discreta;extraction forme;logique floue;search algorithm;discrete fourier transformation;procesamiento imagen;logica difusa;traitement image;hopfield neural network;fuzzy logic;transformation fourier discrete;extraccion forma;smoothing;methode lagrange;machine vision;metodo lagrange;alisamiento;pattern recognition;lagrangian method;matrix calculus;reseau neuronal;pattern extraction;lissage;red neuronal;calculo de matrices;neural network	This paper presents a new method of occluded object matching for machine vision applications. The current methods for occluded object matching lack robustness and require high computational effort. In this paper, a new Hybrid Hopfield Neural Network (HHN) algorithm, which combines the advantages of both a Continuous Hopfield Network (CHN) and a Discrete Hopfield Network (DHN), will be described and applied for partially occluded object recognition in a multi-context scenery. The HHN proposed as a new approach provides great fault tolerance and robustness and requires less computation time. Also, advantages of HHN such as reliability and speed will be discussed.	artificial neural network;hopfield network;outline of object recognition	Jung H. Kim;Sung H. Yoon;Kwang H. Sohn	1996	Pattern Recognition	10.1016/S0031-3203(96)00043-X	fuzzy logic;computer vision;fault tolerance;machine vision;image processing;matrix calculus;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;mathematics;hopfield network;boundary representation;algorithm;smoothing;search algorithm	Vision	46.295858827879606	-60.615769034774296	145754
0959fc9f6c86ef2f93f2ca70b78491880a70738e	dews: a live visual surveillance system for early drowning detection at pool	noyade;extraction information;systeme temps reel;modelizacion;traitement signal;early warning system;teledetection;distress visual indicators;image recognition;sistema alarma;video surveillance;procesamiento informacion;performance evaluation;real time vision system;televigilancia;information extraction;concepcion sistema;dynamic aquatic background;ahogamiento;surveillance;hidden markov model;real time;image fusion;modele markov variable cachee;technique video;foreground silhouette extraction;behavior recognition;arriere plan;real time video surveillance system crowded scenario dynamic aquatic background foreground silhouette extraction modeling of water crisis behaviors;data fusion;probabilistic approach;early drowning detection;tecnica video;alarm system;proof of concept;crowded scenario;computer vision;real time video surveillance system;reduccion ruido;modelisation;dews;prototipo;drowning;visual surveillance;remote supervision;background;installation exterieure;face recognition;hidden markov models;foreground;noise level;instalacion exterior;outdoor installation;real time vision;surveillance hidden markov models face detection real time systems machine vision alarm systems noise level face recognition noise reduction performance evaluation;telesurveillance;system design;enfoque probabilista;approche probabiliste;machine vision;signal processing;noise reduction;fusion donnee;foreground detection;remote sensing;information processing;background subtraction;teledeteccion;reduction bruit;live visual surveillance system;modeling of water crisis behaviors;avant plan;video technique;video surveillance computer vision hidden markov models image denoising image fusion image recognition object detection;real time system;sistema tiempo real;image denoising;denoising;systeme alarme;hidden markov modeling;face detection;outdoor swimming pool;traitement information;alarm systems;fusion datos;blob splitting;procesamiento senal;modeling	A real-time vision system operating at an outdoor swimming pool is presented in this paper. The system is designed to automatically recognize different swimming activities and to detect occurrence of early drowning incidents. We have named this system the Drowning Early Warning System (DEWS). One key challenge we faced in the problem is the relatively high level of noise in the steps of foreground detection and behavior recognition. Therefore, a set of methods in the fields of background subtraction, denoising, data fusion and blob splitting are proposed, which have been motivated by characteristics of aquatic background and crowded scenario at the pool. In the step to detect an early drowning incident, visual indicators of distress and drowning are incorporated through a set of foreground descriptors. A module comprising data fusion and hidden Markov modeling is developed to learn unique traits of different swimming behaviors, in particular, those early drowning events. The experiment of this work reports realistic on-site evaluations performed. Examples of interesting behaviors, i.e., distress, drowning, treading and numerous swimming styles, are simulated and collected. Experimental results show that we have established a prototype system which is robust and beyond the stage of proof-of-concept.	aquatic ecosystem;background subtraction;binary large object;distress (novel);experiment;hidden markov model;high-level programming language;markov chain;noise reduction;prototype;real-time transcription;simulation	How-Lung Eng;Kar-Ann Toh;Wei-Yun Yau;Junxian Wang	2008	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2007.913960	computer vision;simulation;computer science;noise reduction;hidden markov model	Vision	46.766119627675515	-56.653997490036204	145758
6db047ff4020b2e6077ccd3043a1a0626cf09398	gabor-based kernel fisher discriminant analysis for pose discrimination	base donnee;puissance fractionnaire;facies;biometrie;biometrics;database;biometria;fractional power;base dato;hombre;non linear model;modele non lineaire;filtro gabor;classification;discriminant analysis;analyse discriminante;analisis discriminante;gabor filter;modelo no lineal;kernel fisher discriminant analysis;poder fraccionario;human;filtre gabor;discriminacion;clasificacion;discrimination;homme	This paper presents a novel Gabor-based Kernel Fisher Discriminant Analysis (KFDA) method to determine human pose under depth rotation (out of the image plane) Specially, the capability of different orientation and size of Gabor Filter is discussed and the optimal one is selected for feature representation Then KFDA with fractional power polynomial models leads to a non-linear projection to meet the non-linear depth rotation of human face In the experiment section, we can see that, the correct classification rate of 93.5% is achieved in MIT database.	linear discriminant analysis	Jiada Chen;Jianhuang Lai;Guo-Can Feng	2004		10.1007/978-3-540-30548-4_18	kernel fisher discriminant analysis;discrimination;speech recognition;facies;biological classification;computer science;machine learning;pattern recognition;database;mathematics;linear discriminant analysis;fisher kernel;biometrics;statistics	ML	45.071110446204486	-59.409803783790935	145791
9b92fca169c9b496fc030476dfb7330a950cedf9	textonboost: joint appearance, shape and context modeling for multi-class object recognition and segmentation	texturation;modelizacion;texture;image recognition;object recognition;reconocimiento imagen;vision ordenador;image segmentation;image processing;modele agrege;supervised learning;probabilidad condicional;large dataset;learning model;base donnee tres grande;probabilite conditionnelle;competitive algorithms;database;procesamiento imagen;base dato;semantics;modelo agregado;reconnaissance objet;probabilistic approach;high precision;semantica;semantique;classification;traitement image;computer vision;context model;discriminant analysis;analyse discriminante;modelisation;algorithme competitif;analisis discriminante;automatic recognition;machine learning;enfoque probabilista;approche probabiliste;contexto;precision elevee;general lighting;segmentation image;textura;reconnaissance image;base de donnees;precision elevada;pattern recognition;contexte;aggregate model;texturacion;vision ordinateur;feature selection;random fleld;reconnaissance forme;apprentissage supervise;very large databases;reconocimiento patron;aprendizaje supervisado;modeling;conditional probability;eclairage general;clasificacion;context;reconocimiento automatico;reconnaissance automatique;alumbrado general;approaches to learning	"""The paper investigates the problem of achieving automatic detection, recognition and segmentation of object classes in photographs. Namely, given an image the system is expected to automatically partition the image into semantically meaningful areas each labeled with a specific object class. Figure: Image partitioning into semantically meaningful object classes This problem is far from being an easy task. Just think on a local level a window can be part of a car, a building or an aeroplane. Hence; there are ambiguities which the system must overcome. It is important to this problem was avoided by almost all researchers in the field mainly due to the fact that object recognition and segmentation are considered as separate tasks. The project provides a MATLAB limited but working implementation to the massive problem raised by the paper and achieves several goals such as: Tackling (""""playing"""") with real research data Developing sophisticated feature extraction (Texton based shape filters) Developing auxiliary machine learning classification algorithm (fast K-means) Multi-class boosting algorithm implementation for recognition and segmentation (AdaBoost.Mh multiclass reduction to binary variation) And more... Note that although the paper goal is to efficiently detect the object classes and give segmentation of an image into these classes, in practice the paper (and the limited MATLAB implementation) shows that it is a massive computational task. This being said to note that the more """"classical"""" machine learning analysis based on training set size and common bag of algorithms is replaced in this paper (and project) to the novelty of the algorithms and accuracy level."""	adaboost;algorithm;boosting (machine learning);feature extraction;k-means clustering;matlab;machine learning;outline of object recognition;test set;texton	Jamie Shotton;John M. Winn;Carsten Rother;Antonio Criminisi	2006		10.1007/11744023_1	computer vision;systems modeling;conditional probability;image processing;biological classification;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;semantics;context model;image segmentation;texture;supervised learning;feature selection	Vision	46.36207739385001	-59.95807013652441	146185
52bf97858e4fa67f9abeaeb1ebb208d20f28175d	a mpeg video structure analysis scheme and its application to hierarchical video browser	hierarchical structure;fuzzy reasoning;mpeg video;detection rate;high speed;structure analysis	"""This paper presents a novel scheme that automatically extracts out the hierarchical structure of MPEG video by detecting cuts and scenes, and a very user?friendly hierarchical video browser. The proposed scheme first conducts a fast, robust cut detection, chooses the representative frames of shots through clustering, calculates the connectivity between shots based on the similarities of the shots including a certain number of neighbors by using fuzzy reasoning, and extracts scenes by examining the connectivity change. The scheme is overall robust against threshold setting, cut miss?detection and over?detection. We applied our scheme to parts of movies, the cut and scene detection rates are respectively higher than 95% and 75%. Considering the scheme is of high speed and in no need of knowledge on specific kinds of videos, these detection rates are quite satisfactory. The scheme is also feasible for other kinds of videos if they possess the feature that """"scene consists of a group of similar shots""""."""	moving picture experts group	Jiying Zhao;Rina Hayasaka;Ryoji Muranoi;Yutaka Matsushita	1998	Telecommunication Systems	10.1023/A:1019116511362	computer vision;computer science;theoretical computer science;structural analysis;multimedia	Vision	39.32613741087393	-52.46685191170095	146193
4abc78ae1b040da85e2858f90019b73af5541a37	histogram preserving image transformations	perspective projection;weak perspective projection;histogram based recognition;fixed point;hamiltonian transformation;indexation;histogram preservation;local transformation;paraperspective projection;vector field	Histograms are used to analyze and index images. They have been found experimentally to have low sensitivity to certain types of image morphisms, for example, viewpoint changes and object deformations. The precise effect of these image morphisms on the histogram, however, has not been studied. In this work we derive the complete class of local transformations that preserve or scale the magnitude of the histogram of all images. We also derive a more general class of local transformations that preserve the histogram relative to a particular image. To achieve this, the transformations are represented as solutions to families of vector fields acting on the image. The local effect of fixed points of the fields on the histograms is also analyzed. The analytical results are verified with several examples. We also discuss several applications and the significance of these transformations for histogram indexing.	3d projection;elastic net regularization;experiment;fixed point (mathematics)	Efstathios Hadjidemetriou;Michael D. Grossberg;Shree K. Nayar	2001	International Journal of Computer Vision	10.1023/A:1012356022268	mathematical analysis;discrete mathematics;vector field;perspective;topology;histogram matching;balanced histogram thresholding;mathematics;fixed point;adaptive histogram equalization;image histogram	Vision	50.66038784937853	-61.69253203762387	146279
b15e2f5ce73a0ea8194d1596589588e24e23a429	3d face reconstruction based on progressive cascade regression		In order to better learn the distributions of 2D and 3D faces and the mapping between them with limited training samples, a new 3D face reconstruction method based on progressive cascade regression is proposed. Firstly, it learns the mapping between 2D and 3D facial landmarks to estimate the initial 3D facial landmarks with a coupled space learning method. Secondly, a deformed space is constructed with the difference between the estimated initial landmarks and the ground truth of training samples; and more accurate 3D facial landmarks are reconstructed by modifying the initial 3D ones with shape compensations which are calculated by minimizing an objective function. Finally, the realistic 3D faces are reconstructed by a method that is based on a simple sparse regulation and shape deformation. The results on BJUT 3D face database demonstrate the effectiveness of the proposed method. In addition, compared with some typical methods, the method can get better subjective and objective results, especially in details.	3d printing;facial recognition system;ground truth;loss function;optimization problem;progressive meshes;progressive scan;sparse matrix	Lihua Han;Quan Xiao;Xianyang Liang	2017	2017 International Conference on Computer, Information and Telecommunication Systems (CITS)	10.1109/CITS.2017.8035340	iterative reconstruction;cascade;ground truth;computer vision;solid modeling;artificial intelligence;computer science	Vision	51.80807570976685	-53.3177094921095	146330
ba0fb692f44f40234baf98eeabf5edb770aa0507	a novel feature-based tracking approach to the detection, localization, and 3-d reconstruction of internal defects in hardwood logs using computer tomography	image tridimensionnelle;oak;image segmentation;filtro kalman;computed tomography;edge detection;filtre kalman;defaut interne;analisis correspondencia;tomographie numerique;computer tomography;kalman filter;feature based tracking;computer tomography internal defect detection kalman filter feature based tracking;nondestructive evaluation;deteccion contorno;detection contour;bois de construction;aproximacion esplin;building timber;automated lumber production;detection defaut;evaluation non destructive;madera de construccion;spline approximation;approximation spline;correspondence analysis;segmentation image;poursuite cible;computerized tomography;defecto interno;analyse correspondance;nondestructive evaluation automated lumber production;tridimensional image;internal defect detection;cross section;target tracking;deteccion imperfeccion;internal defect;imagen tridimensional;defect detection	A novel feature-based tracking approach based on the Kalman filter is proposed for the detection, localization, and 3-D reconstruction of internal defects in hardwood logs from cross-sectional computer tomography (CT) images. The defects are simultaneously detected, classified, localized, and reconstructed in 3-D space, making the proposed scheme computationally much more efficient than existing methods where the defects are detected and localized independently in individual CT image slices and the 3-D reconstruction of the defects accomplished via correspondence analysis across the various CT image slices. Robust techniques for defect detection and classification are proposed. Defect class-specific tracking schemes based on the Kalman filter, B-spline contour approximation, and Snakes contour fitting are designed which use the geometric parameters of the defect contours as the tracking variables. Experimental results on cross-sectional CT images of hardwood logs from select species such as white ash, hard maple, and red oak are presented.	angular defect;approximation;b-spline;ct scan;contour line;correspondence analysis;cross-sectional data;graphical user interface;internationalization and localization;kalman filter;maple;motion estimation;robustness (computer science);software bug;statistical classification;tomography	Suchendra M. Bhandarkar;Xingzhi Luo;Richard F. Daniels;Ernest William Tollner	2006	Pattern Analysis and Applications	10.1007/s10044-006-0035-9	kalman filter;computer vision;simulation;edge detection;nondestructive testing;computer science;machine learning;cross section;image segmentation;computed tomography;correspondence analysis	Vision	46.55565975378558	-62.10714182904498	146377
281e1000e0f9873f217a1d5895036ee72a54bf7a	image-based human age estimation by manifold learning and locally adjusted robust regression	vision system;analisis imagen;age difference;evaluation performance;vision ordenador;regression non lineaire;metodo vectorial;human computer interaction;performance evaluation;envejecimiento;support vector regression svr;learning;systeme vision;image databases;image based human age estimation;application software;support vector machine svm;evaluacion prestacion;facial image analysis;localization;relacion hombre maquina;non linear regression;maquina vector soporte;database;support vector regression;base dato;man machine relation;aging;regresion no lineal;localizacion;manifold learning;fechado;datation;computer vision;aprendizaje;accuracy;machine vecteur support;apprentissage;support vector regression svr age manifold human age estimation locally adjusted robust regression manifold learning nonlinear regression support vector machine svm;real world application;precision;face recognition;localisation;analisis regresion;fenomeno meteorologico;feature extraction;aging process;robustness aging image databases image analysis application software human computer interaction multimedia communication computer vision face feature extraction;vector method;internal age database image based human age estimation manifold learning locally adjusted robust regression facial image analysis human computer interaction multimedia communication computer vision systems aging process fg net database;multimedia communication;signal classification;fg net database;age estimation;phenomene meteorologique;ageing;base de donnees;weather condition;classification signal;robust regression;vieillissement;analyse regression;computer vision systems;methode vectorielle;age manifold;robustness;regression analysis computer vision face recognition;image analysis;vision ordinateur;regression analysis;face;relation homme machine;support vector machine;classification automatique;communication multimedia;automatic classification;internal age database;clasificacion automatica;analyse image	Estimating human age automatically via facial image analysis has lots of potential real-world applications, such as human computer interaction and multimedia communication. However, it is still a challenging problem for the existing computer vision systems to automatically and effectively estimate human ages. The aging process is determined by not only the person's gene, but also many external factors, such as health, living style, living location, and weather conditions. Males and females may also age differently. The current age estimation performance is still not good enough for practical use and more effort has to be put into this research direction. In this paper, we introduce the age manifold learning scheme for extracting face aging features and design a locally adjusted robust regressor for learning and prediction of human ages. The novel approach improves the age estimation accuracy significantly over all previous methods. The merit of the proposed approaches for image-based age estimation is shown by extensive experiments on a large internal age database and the public available FG-NET database.	aging-related process;computer vision;estimated;evaluation;experiment;human computer;human–computer interaction;image analysis;intermediate filament proteins;job control (unix);learning disorders;multimedia;nonlinear dimensionality reduction;principle of good enough;support vector machine;total peripheral resistance;manifold	Guodong Guo;Yun Fu;Charles R. Dyer;Thomas S. Huang	2008	IEEE Transactions on Image Processing	10.1109/TIP.2008.924280	ageing;support vector machine;computer vision;image analysis;computer science;artificial intelligence;machine learning;accuracy and precision;nonlinear regression;statistics	Vision	44.69207234391806	-58.84536115697507	146411
a60ee0616c626a2a3f8edf9197bba81c3b9dfeb8	feature extraction and matching as signal detection	image recognition;reconocimiento imagen;algorithm performance;detection signal;automatic system;implementation;signal detection;extraction forme;formulacion;disparity constraint;detection;integration;ejecucion;deteccion senal;sistema automatico;extraccion forma;resultado algoritmo;geometric constraint;integracion;feature extraction;robustesse;matching;rigidity constraint;reconnaissance image;feature;performance algorithme;systeme automatique;pattern recognition;robustness;reconnaissance forme;reconocimiento patron;pattern extraction;formulation;extraction;robustez	This paper discusses detection and matching of arbitrary image features or patterns. The common characteristics of feature extraction and matching are summarized which show that they can be considered as special cases of a more general problem—signal detection. However, the existing signal detection theories do not solve feature extraction and matching problems readily. Therefore, a general formulation of feature extraction and matching as a problem of signal detection is presented. This formulation unifies feature extraction and matching into a more general framework so that the two can be better integrated to form an automatic system for image matching or object recognition. Following this formulation, guidelines for designing algorithms for detection or matching of arbitrary image features or patterns which can be easily implemented or reconfigurated for many practical applications are derived. Sample algorithms resulting from this formulation and the associated experimental results with real image data are provided which demonstrate the performance and robustness of the methods.	feature extraction	Xiaoping Hu;Narendra Ahuja	1994	IJPRAI	10.1142/S021800149400067X	matching;computer vision;feature detection;extraction;template matching;feature;feature extraction;computer science;machine learning;pattern recognition;formulation;implementation;feature;algorithm;robustness;detection theory	EDA	46.94471575895054	-60.670843839999684	146503
a8dff9f4130f920ed2469f5866d47155a8624632	multiresolution image motion detection and displacement estimation	vision system;deteccion borde;moving object;correlacion;estimacion;movimiento;image multiresolution;image processing;deteccion;edge detection;deplacement;procesamiento imagen;detection;motion;desplazamiento;traitement image;dynamic threshold;forme pyramidale;estimation;forma piramidal;mouvement;pyramidal shape;displacement;correlation;region growing;detection bord;motion detection;object detection	A motion vision system is developed in which a moving object can be detected and image displacement can be estimated based on human visual characteristics and use of a multiresolution image. The system consists of four parts: (1) Temporal gradient, logic AND, and dynamic thresholding operations are used to obtain the primary mask. (2) A region growing algorithm is applied. (3) A hierarchical object detection algorithm is used to identify image patterns. (4) Displacement of the image is estimated by breaking each frame of the motion sequence into local regions (edges). A search is undertaken to discover how the image pattern within a given region appears displaced. This search takes the form of motion channels, the output of which are used to obtain the estimation of displacement. A correlative measure is proposed to match the patterns.	algorithm;computer vision;displacement mapping;gradient;multiresolution analysis;object detection;region growing;thresholding (image processing)	Shuwu Song;Mengyang Liao;Jiamei Qin	1988	Machine Vision and Applications	10.1007/BF01211449	computer vision;estimation;feature detection;edge detection;machine vision;displacement;image processing;computer science;motion;motion estimation;geometry;region growing;motion field;correlation	Vision	48.8115919964953	-57.84137910014109	146603
5627586b0941744257bde873f2439d731beb1d52	mathematical morphology for vector images using statistical depth	vector images;hyperspectral images;depth function;image representations;multidimensional data;multivariate morphology;open problems;hyper spectral images;morphological operator;data driven approach	"""The open problem of the generalization of mathematical morphology to vector images is handled in this paper using the paradigm of depth functions. Statistical depth functions provide from the """"deepest"""" point a """"center-outward ordering"""" of a multidimensional data distribution and they can be therefore used to construct morphological operators. The fundamental assumption of this data-driven approach is the existence of """"background/foreground"""" image representation. Examples in real color and hyperspectral images illustrate the results."""	mathematical morphology;vector graphics	Santiago Velasco-Forero;Jesús Angulo	2011		10.1007/978-3-642-21569-8_31	computer vision;vector graphics;computer science;machine learning;pattern recognition	Vision	51.080345985939076	-63.68804312453965	146849
da5b0631b9426df9ceb995e0781d06c425d23c3c	the weight-shape decomposition of density estimates: a framework for clustering and image analysis algorithms		Abstract We propose an analysis scheme which addresses the Parzen-window and mixture model methods for estimating the probability density function of data points in feature space. Both methods construct the estimate as a sum of kernel functions (usually Gaussians). By adding an entropy-like function we prove that the probability distribution is a product of a weight function and a shape distribution. This Weight-Shape decomposition leads to new interpretations of established clustering algorithms. Furthermore, it suggests the construction of three different clustering schemes, which are based on gradient-ascent flow of replica points in feature space. Two of these are Quantum Clustering and the Mean-Shift algorithm. The third algorithm is based on maximal-entropy. In our terminology they become Maximal Shape Clustering, Maximal Probability Clustering and Maximal Weight Clustering, correspondingly. We demonstrate the different methods and compare them to each other on one artificial example and two natural data sets. We also apply the Weight-Shape decomposition to image analysis. The shape distribution acts as an edge detector. It serves to generate contours, as demonstrated on face images. Furthermore, it allows for defining a convolutional Shape Filter.	algorithm;cluster analysis;image analysis	Lior Deutsch;David Horn	2018	Pattern Recognition	10.1016/j.patcog.2018.03.034	kernel (statistics);mixture model;probability density function;probability distribution;feature vector;cluster analysis;artificial intelligence;data point;algorithm;pattern recognition;mathematics;weight function	Vision	40.56381200818051	-63.94812476214092	147134
f043763eabdc2c3d2a3df716b7b09645920fb70d	motion direction detection from segmentation by liac, and tracking by centroid trajectory calculation	moving object;lateral interaction;direct detection	Motion information can form the basis of predictions about time-toimpact and the trajectories of objects moving through a scene. Firstly, a model that incorporates accumulative computation and lateral interaction is presented. By means of the lateral interaction in accumulative computation (LIAC) of each element with its neighbours, the model is able to segment moving objects present in an indefinite sequence of images. In a further step, moving objects are tracked using a centroid-based trajectory calculation. 1 Motion Direction Detection Motion plays an important role in our visual understanding of the surrounding environment [1]. Visual motion can aid in the detection of shape [2], provide information as to the relative depth of moving objects [3], and give clues about the material properties of moving objects, such as the rigidity and transparency [4]. Motion information can also form the basis of predictions about time-to-impact and the trajectories of objects moving through a scene [5]. This paper introduces a novel method for motion direction detection based on segmentation by lateral interaction in accumulative computation (LIAC) and tracking by centroid trajectory calculation. 1.1 Segmentation from LIAC The aim of segmentation step is firstly to determine in what grey level stripe a given element (x,y) falls. Let GLS (x,y,t) be the grey level stripe of image pixel (x,y) at time t and n the total number of grey level stripes. [ ] 256 , 1 , 256 ) , , ( ∈ = n n t y x GLS (1) Lateral interaction in accumulative computation is capable of modelling the motion on the image, starting from the pixel grey level stripe and the element state or permanence value. There are as many permanence values for a given element as grey level stripes. At each time instant t, the permanence value is obtained in two steps. (1) A charge or discharge due to the motion detection, that's to say, due to a change in the grey level stripe, and, (2) a re-charge due to the lateral interaction on the partially Fernández-Caballero A. (2005). Motion Direction Detection from Segmentation by LIAC, and Tracking by Centroid Trajectory Calculation. In Proceedings of the 5th International Workshop on Pattern Recognition in Information Systems, pages 213-218 Copyright c © SciTePress charged elements that are directly or indirectly connected to maximally charged elements. The charge or discharge behaviour of the permanence memory is explained next. (a) All permanence values not associated to grey level stripe k are completely discharged down to value vdis. (b) If the pixel associated to the element is enclosed in grey level stripe k, we are in front of two different possibilities. (b.1) If the pixel was not enclosed in grey level stripe k in time t-1, permanence memory is completely charged up to the maximum value vsat, or, (b.2) if the pixel was previously enclosed in grey level stripe k in time t-1, permanence memory is applied a decrement of value vdm (discharge value due to motion detection), down to a minimum of vdis.	c date and time functions;computation;data striping;discharger;emoticon;generalized least squares;grayscale;increment and decrement operators;lateral thinking;magnetic stripe card;pattern recognition;pixel;stripes	Antonio Fernández-Caballero	2005			computer vision	Vision	40.981000244278654	-52.349879814969796	147177
13464907eedc437fd7a80726c2e16ea59558b990	color constancy using ridge regression	illuminant estimation;ridge regression;analisis estadistico;image processing;regresion ridge;psicofisica;competitividad;color constancy;base donnee tres grande;vision color;procesamiento imagen;intelligence artificielle;probabilistic approach;ley weibull;traitement image;vision couleur;weibull distribution;regression pseudo orthogonale;light source;analisis regresion;statistical analysis;enfoque probabilista;approche probabiliste;analyse statistique;competitiveness;source lumineuse;psychophysique;fuente luminosa;analyse regression;artificial intelligence;regression analysis;inteligencia artificial;source lumiere;very large databases;competitivite;loi weibull;light sources;color vision;psychophysics	Although there exist a number of single color constancy algorithms, none of them can be considered universal. Consequently, how to select and combine existing single algorithms are two important research directions in the field of color constancy. In this paper we use ridge regression, a simple yet effective machine learning approach, to select and combine existing color constancy algorithms. Two algorithms are proposed using ridge regression in this paper. In the first method (combination of existing color constancy algorithms), the color of the light source is estimated based on the results of existing single color constancy algorithms using ridge regression. In the second method (selection of existing color constancy algorithms), the proper algorithm for a given image is selected by ridge regression based on natural image statistics. Then it is used to estimate the color of the light source. The proposed two algorithms are verified on a large data set with more than 11,000 images. The experimental results demonstrate that the proposed methods are competitive with the state-of-the-art methods.	algorithm;color;existential quantification;machine learning;regular expression;scene statistics	Rui Lu;De Xu;Bing Li	2010	J. Inf. Sci. Eng.		weibull distribution;computer vision;color normalization;image processing;computer science;artificial intelligence;color vision;tikhonov regularization;psychophysics;color constancy;regression analysis;statistics	Vision	45.761506469967024	-60.38117354885298	147336
aac1e2bb66b716228b5239f5e2f2a8b929c4cd5e	post-processing on lda's discriminant vectors for facial feature extraction	reconnaissance visage;filtrage gauss;image processing;facies;extraction forme;procesamiento imagen;gaussian filtering;linear discriminate analysis;facial feature extraction;filtrado gaussiano;traitement image;feasibility;discriminant analysis;analyse discriminante;analisis discriminante;face recognition;extraccion forma;feature extraction;pattern recognition;reconnaissance forme;extraction caracteristique;reconocimiento patron;pattern extraction;practicabilidad;faisabilite	Linear discriminant analysis (LDA) based methods have been very successful in face recognition. Recently, pre-processing approaches have been used to further improve recognition performance but few investigations have been made into the use of post-processing techniques. This paper intends to explore the feasibility and efficiency of the post-processing technique on LDA's discriminant vectors. In this paper we propose a Gaussian filtering approach to post-process the discriminant vectors. The results of our experiments demonstrate that, post-processing technique can be used to improve recognition performance.	discriminant;feature extraction;video post-processing	Kuanquan Wang;Wangmeng Zuo;David Zhang	2005		10.1007/11527923_36	computer vision;speech recognition;facies;image processing;feature extraction;computer science;machine learning;pattern recognition;multiple discriminant analysis	AI	44.60161812858181	-60.2621797483423	147452
22f1864528b3758efb7024e4feb4b3083c6a759b	ovocyte texture analysis through almost shift-invariant decimated wavelet transform	medical image processing image texture wavelet transforms splines mathematics image classification;signal analysis;image classification;splines mathematics;image texture;wavelet transforms;wavelet analysis wavelet transforms signal resolution filters signal analysis approximation algorithms spline information analysis energy resolution wavelet coefficients;texture analysis;wavelet transform;medical image processing;image texture ovocyte texture analysis shift invariant decimated wavelet transform signal analysis multiscale parameter ovocyte cell evolution high order orthogonal b spline wavelet basis quincunx schemes;shift invariant	Wavelet transforms are superior tools for signal analysis. They are used in this paper in order to perform a texture study of the evolution state of ovocyte cells. The analysis is based on a multiscale parameter. High order orthogonal B-spline wavelet basis are used to obtain significant parameters. Separable and quincunx schemes are studied and compared.	wavelet transform	Frédéric Morain-Nicolier;Anne-Claire Legrand;Olivier Laligant;Sophie Kohler;Frédéric Truchetet	2000		10.1109/KES.2000.885837	multiresolution analysis;image texture;wavelet;computer vision;mathematical optimization;harmonic wavelet transform;second-generation wavelet transform;continuous wavelet transform;pattern recognition;cascade algorithm;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;lifting scheme;wavelet transform	Vision	52.343465506172116	-65.75434877854686	147465
70be8f9a4bde9452cab3be2e983c3082ff86f19b	perceptual dominant color extraction by multidimensional particle swarm optimization	busqueda informacion;signal image and speech processing;analisis imagen;evaluation performance;performance evaluation;optimizacion pso;color space;information retrieval;evaluacion prestacion;compresion senal;artikkeli article;metric;compression signal;similitude;quantum information technology spintronics;particle swarm optimizer;recherche information;biomimetique;busqueda por contenido;particle swarm optimization;signal compression;signal classification;similarity;classification signal;optimisation pso;metrico;image analysis;espace chromatique;similitud;espacio cromatico;classification automatique;automatic classification;discriminacion;clasificacion automatica;analyse image;content based retrieval;recherche par contenu;metrique;discrimination;biomimetics	Color is the major source of information widely used in image analysis and content-based retrieval. Extracting dominant colors that are prominent in a visual scenery is of utmost importance since the human visual system primarily uses them for perception and similarity judgment. In this paper, we address dominant color extraction as a dynamic clustering problem and use techniques based on Particle Swarm Optimization (PSO) for finding optimal (number of) dominant colors in a given color space, distance metric and a proper validity index function. The first technique, so-called Multi-Dimensional (MD) PSO, re-forms the native structure of swarm particles in such a way that they can make inter-dimensional passes with a dedicated dimensional PSO process. Therefore, in a multidimensional search space where the optimum dimension is unknown, swarm particles can seek both positional and dimensional optima. Nevertheless, MD PSO is still susceptible to premature convergence due to lack of divergence. To address this problem we then present Fractional Global Best Formation (FGBF) technique, which basically collects all promising dimensional components and fractionally creates an artificial global-best particle (aGB) that has the potential to be a better “guide” than the PSO’s native gbest particle. In order to extract perceptually important colors and to further improve the discrimination factor for a better clustering performance, an efficient color distance metric, which uses a fuzzy model for computing color (dis-) similarities over HSV (or HSL) color space is proposed. The comparative evaluations against MPEG-7 dominant color descriptor show the superiority of the proposed technique.	cluster analysis;color space;image analysis;information source;mpeg-7;particle swarm optimization;premature convergence;telecommunications link	Serkan Kiranyaz;Stefan Uhlmann;Turker Ince;Moncef Gabbouj	2009	EURASIP J. Adv. Sig. Proc.	10.1155/2009/451638	biomimetics;computer vision;discrimination;image analysis;color quantization;speech recognition;similarity;metric;computer science;artificial intelligence;similitude;color space;particle swarm optimization	AI	41.992133940557224	-62.20777268618195	147492
004d652a1102cd6e3119b316cb1cbd978cb6f2be	shape and view independent reflectance map from multiple views	shape estimation;modelizacion;image tridimensionnelle;vision ordenador;shape from shading;image processing;illumination;cost function;fonction repartition;facteur reflexion;image matching;reconstitution forme;luminance;procesamiento imagen;modelo reflectividad bidireccional;bidirectional reflectance model;illumination model;triangular mesh;global constraint;traitement image;multiple views;computer vision;multiple view;modelisation;posture;reconstruction image;funcion distribucion;distribution function;specular reflection;light source;bidirectional reflectance distribution function;reflectance;reconstruccion imagen;reconstitucion forma;image reconstruction;postura;source lumineuse;fuente luminosa;vue multiple;tridimensional image;vision ordinateur;source lumiere;brdf;modele reflectance bidirectionnelle;pattern recovery;modeling;eclairement;reflectance model;3d reconstruction;appariement image;imagen tridimensional;vista multiple;light sources;alumbrado;coeficiente reflexion;luminancia	We consider the problem of estimating the 3D shape and reflectance properties of an object made of a single material from a set of calibrated views. To model the reflectance, we propose to use the View Independent Reflectance Map (VIRM), which is a representation of the joint effect of the diffuse+specular Bidirectional Reflectance Distribution Function (BRDF) and the environment illumination. The object shape is parameterized using a triangular mesh. We pose the estimation problem as minimizing the cost of matching input images, and the images synthesized using the shape and VIRM estimates. We show that by enforcing a constant value of VIRM as a global constraint, we can minimize the cost function by iterating between the VIRM and shape estimation. Experimental results on both synthetic and real objects show that our algorithm can recover both the 3D shape and the diffuse/specular reflectance information. Our algorithm does not require the light sources to be known or calibrated. The estimated VIRM can be used to predict the appearances of objects with the same material from novel viewpoints and under transformed illumination.	algorithm;approximation;background subtraction;bidirectional reflectance distribution function;estimation theory;experiment;iterative method;normal (geometry);oblique projection;polygon mesh;reflection (computer graphics);self-shadowing;specular highlight;synthetic intelligence;vertex normal	Tianli Yu;Ning Xu;Narendra Ahuja	2006	International Journal of Computer Vision	10.1007/s11263-006-9373-8	computer vision;image processing;computer science;bidirectional reflectance distribution function;computer graphics (images)	Vision	51.721573852572774	-56.59175657734204	147508
15ec23ae3007c8474149777e6f3d9974dd392fb5	novel line verification for multiple instance focused retrieval in document collections	complexity theory yttrium estimation manuals	Spatial verification is typically employed to check the spatial consistency among matched local features and to remove outliers. However, when looking for multiple instances of the query within a target image, RANSAC algorithms which are widely applied in many one-to-one matching applications might fail due to the large proportion of “outliers” - correct matches corresponding to other instances. On the other hand, geometrical verification methods are more robust to outliers but usually suffer from high computational costs. In this paper, we introduce a novel two-step line verification method which is more flexible than existing methods and leads to lower computational complexity especially when multiple instances of a query are sought. We study this approach within an information extraction scenario, where the objective is to locate document structures indicative of certain type of information (e.g. different records on invoices).	algorithm;algorithmic efficiency;computational complexity theory;information extraction;minimum bounding box;one-to-one (data model);random sample consensus;spatial verification	Hongxing Gao;Marçal Rusiñol;Dimosthenis Karatzas;Josep Lladós;Rajiv Jain;David S. Doermann	2015	2015 13th International Conference on Document Analysis and Recognition (ICDAR)	10.1109/ICDAR.2015.7333808	computer vision;speech recognition;computer science;machine learning;pattern recognition;data mining;statistics	AI	43.81900058382851	-53.58334899181547	147757
e72f5d45d1607e0714e196aa9ab312361f659852	a three-dimensional muscle-based facial expression synthesizer for model-based image coding	point estimation;image coding;real time;virtual human;three dimensional;muscle contraction;near real time;facial expression	A three-dimensional muscle-based facial expression synthesizer is proposed. The proposed synthesizer will compute the contraction of 19 muscles and rotation of the jaw from 22 feature points estimated by the analyzer, then apply the muscle contraction model to modify the 3D head model. The head motion, including translation and orientation, is also derived from a set of three feature points. Currently the analyzer is implemented on a PC with a camcorder with near real-time performance, and the synthesizer receives the feature points from the analyzer and synthesizes facial expressions on an SGI Indigo in real time.	real-time clock;real-time computing	Yuong-Wei Lei;Ja-Ling Wu;Ming Ouhyoung	1996	Sig. Proc.: Image Comm.	10.1016/0923-5965(95)00057-7	three-dimensional space;simulation;speech recognition;computer science;point estimation;mathematics;facial expression;computer graphics (images)	Vision	47.766623694391946	-56.13659497547425	148023
cefee6ab43e895057916f7baeed28c3a2d236a26	fuzzy modelling of local linearity in contours		Shape analysis, and particulary the contour study, is a fundamental task for object recognition in images. In this paper, a fuzzy approach for representing the linearity property of a contour segment is proposed. Linearity is a key property related to which degree a contour segment is a curve or a straight line; in addition, it is the basis for modelling other properties like curvature, salience or concavity/convexity. In this framework, firstly, the idea of linearity vs non-linearity, and the meaning of its fulfilment, will be analyzed. Secondly, the definition of a membership function according to that meaning will be proposed on the basis of the coefficient of determination. Finally, we will show the goodness of our proposal by analyzing linearity in a set of shapes with different characteristics.	coefficient of determination;concave function;fuzzy logic;nonlinear system;outline of object recognition;shape analysis (digital geometry)	Jesús Chamorro-Martínez;Pedro Martínez-Jiménez;A. Garrido;Jose Manuel Soto-Hidalgo	2018	2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2018.8491659	fuzzy logic;line (geometry);linearity;control theory;shape analysis (digital geometry);curvature;image segmentation;mathematical optimization;computer science;membership function;convexity	Vision	42.06074864862092	-59.344635007707254	148315
e1a500636e0566f08214b104ab5e5fd451dc90a3	fingerprint indexing with pose constraint	fingerprint indexing;locality sensitive hashing;pose estimation	Fingerprint indexing is critical for identifying fingerprints efficiently in large-scaled fingerprint databases. The state-of-the-art indexing accuracies are achieved by minutiae-based indexing approaches. A major difference of these approaches is how they deal with fingerprint registration problem. Some of the approaches do not use registration, while others perform relative/pairwise registration (e.g., based on mated minutiae between two fingerprints). However, the former approach is not accurate, since without geometric constraints, many false matches can be found even for non-mated fingerprints. The latter is not efficient for large databases since the relative registration step has to be performed for each pair of fingerprints. It is desirable to develop an absolute registration approach, which can register any single fingerprint into a common coordinate system, and therefore can address efficiency and accuracy problems simultaneously. In this paper, we proposed a fingerprint pose estimation algorithm which can register fingerprints into a common finger coordinate system. Fingerprint pose estimation problem is viewed as a two-class classification problem and approached by sliding window classifiers trained on labeled data. Ridge orientation information is used as features instead of singularities which are often affected by noise. With the pose estimation, we are able to refine the matched minutiae with global spatial constraint. By combining the proposed pose estimation algorithm with an improved Locality Sensitive Hashing algorithm for MCC descriptor, our indexing system outperformed previous state-ofthe-art on widely used databases and its scalability was tested on a large database with one million fingerprints. & 2016 Elsevier Ltd. All rights reserved.	3d pose estimation;algorithm;cryptographic hash function;database;fingerprint;locality of reference;locality-sensitive hashing;minutiae;point set registration;scalability	Yijing Su;Jianjiang Feng;Jie Zhou	2016	Pattern Recognition	10.1016/j.patcog.2016.01.006	computer vision;pose;computer science;machine learning;pattern recognition;data mining;locality-sensitive hashing	Vision	42.237506955463274	-55.037811112689084	148349
8d7b091541290a9f64388e6f0926b0d7bcc696cd	iterative methods in image analysis	image analysis;iteration method	This paper reviews recent developments in the use of iterative (or “relaxation”) methods in image analysis. Applications of these methods include histogram modification, noise cleaning, edge and curve detection, thinning, angle detection, template matching, and region labelling. These applications are briefly described, and references are given to papers and reports in which more detailed discussions and examples can be found.	image analysis;iterative method	Azriel Rosenfeld	1978	Pattern Recognition	10.1016/0031-3203(78)90026-2	computer vision;mathematical optimization;image analysis;computer science;theoretical computer science;iterative method	Vision	45.62394864418853	-65.67659418742228	148379
60699ae80aee6d06cf2638a097bdc83902aae8a1	local-to-global signature descriptor for 3d object recognition		In this paper, we present a novel 3D descriptor that bridges the gap between global and local approaches. While local descriptors proved to be a more attractive choice for object recognition within cluttered scenes, they remain less discriminating exactly due to the limited scope of the local neighborhood. On the other hand, global descriptors can better capture relationships between distant points, but are generally affected by occlusions and clutter. So, we propose the Local-to-Global Signature (LGS) descriptor, which relies on surface point classification together with signature-based features to overcome the drawbacks of both local and global approaches. As our tests demonstrate, the proposed LGS can capture more robustly the exact structure of the objects while remaining robust to clutter and occlusion and avoiding sensitive, low-level features, such as point normals. The tests performed on four different datasets demonstrate the robustness of the proposed LGS descriptor when compared to three of the SOTA descriptors today: SHOT, Spin Images and FPFH. In general, LGS outperformed all three descriptors and for some datasets with a 50-70% increase in Recall.	3d single-object recognition;antivirus software;cellular automaton;clutter;data acquisition;high- and low-level;image noise;outline of object recognition;relevance;type signature	Isma Hadji;Guilherme N. DeSouza	2014		10.1007/978-3-319-16628-5_41	gloh;3d single-object recognition;signature recognition	Vision	40.80640110897837	-55.28293339128383	148605
3bf2f4b5c0feab7f83b5f3971f2b748fe6992b42	blur identification in image processing	image processing;supervised learning;automatic segmentation;image classification;image processing focusing cameras layout image segmentation lenses supervised learning photography pixel image restoration;image classifier blur identification image processing still images photographic camera optical lenses automatic image segmentation supervised learning	"""The aim of this study is to achieve a blur identification task in still images. In fact, in photographic camera, the optical lenses may be set in a way to clearly distinct two areas in the image: the blurry one and the non blurry one. An automatic segmentation coupled to specific descriptors allow first to describe any region of the image. Then, a supervised learning processes permits to build a classifier able to decide for each unknown region the label """"blurry"""" or """"sharp"""". We discuss here precisely the overall process, from the objective choice of the segmentation algorithm to the presentation of the different introduced descriptors. Finally, some results are presented validating such an approach."""	algorithm;artificial neural network;box blur;experiment;gaussian blur;high- and low-level;image processing;numerical analysis;signal processing;supervised learning	Jérôme Da Rugna;Hubert Konik	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247106	image texture;image restoration;computer vision;contextual image classification;feature detection;binary image;image processing;computer science;machine learning;segmentation-based object categorization;digital image processing;pattern recognition;image segmentation;supervised learning;scale-space segmentation;automatic image annotation;computer graphics (images)	Vision	41.31436458937252	-65.8915107744201	148629
d2898f3334cbb0184bf284dd8251c7d46c504691	practical medial axis filtering for occlusion-aware contours		We propose a filtering system for occlusion-aware contours. Given a point of view, we use the silhouette of a 3D shape from that point of view, its medial axis and a map of the occluded areas. Our filter is able to select the points of the medial axis which are projections of the curve-skeleton of the 3D shape, discarding all the points affected by occlusions. Our algorithm is easy to implement and works in real time. It can be plugged as is into existing methods for curve-skeleton extraction from 2D images; it can be used to robustly rank silhouettes according to how much they are representative of the 3D shape that generated them and can also be used for shape recognition from images or video sequences.	algorithm;apache axis;medial graph;optic axis of a crystal;point of view (computer hardware company);real-time computing	Marco Livesu;Riccardo Scateni	2015		10.2312/stag.20151302	computer vision;filter (signal processing);medial axis;artificial intelligence;mathematics;occlusion	Vision	44.969139103418165	-55.74212485127383	148744
0a2603603f3210dad6c577470d1c95b9e0160aa9	computation of discontinuous optical flow by domain decomposition and shape optimization	campo desplazamiento;discontinuity;vision ordenador;discontinuite;analisis escena;analyse scene;displacement field;domain decomposition;image processing;hypothese;sistema informatico;procesamiento imagen;computer system;image bruitee;traitement image;computer vision;imagen sonora;reconstruction image;hipotesis;shape optimization;reconstruccion imagen;flow field;image reconstruction;noisy image;champ deplacement;vision ordinateur;optical flow;systeme informatique;discontinuidad;hypothesis;scene analysis	A well-known method for the reconstruction of motion fields from noisy image data is to determine flow fields by the minimization of a quadratic functional. The first approach of this class has been proposed by Horn and Schunck (1981). A drawback of such approaches is that an explicit representation of the discontinuities of the motion field is lacking and that, in general, the resulting flow fields approximate the motion fields only badly at the corresponding locations in the image plane. In this article, we discuss the possibility to improve the results by hypothesizing the qualitative structure of the motion field in terms of certain parameters. We decompose the image plane into disjoint sets, restrict the domain of definition of the functionals to these sets, and use the hypotheses to deform and to move the boundaries of the sets within the image plane. We discuss the range of applicability of this new technique and illustrate the algorithm by numerical examples. This article is a revised and extended version of Schnörr (1990).	approximation algorithm;computation;domain decomposition methods;image plane;mathematical optimization;motion field;numerical analysis;optical flow;shape optimization	Christoph Schnörr	1992	International Journal of Computer Vision	10.1007/BF00127172	iterative reconstruction;computer vision;hypothesis;image processing;computer science;discontinuity;shape optimization;displacement field;optical flow;mathematics;geometry;domain decomposition methods;motion field;algorithm	Vision	50.80912933637101	-58.25567779797028	149153
331e02f38fc25bc0f29da9ef13d15467e586f679	matching 2d image segments with genetic algorithms and approximation spaces	filtering;2d matching;filtrage;image segmentation;image segment;image databank;image matching;approximation algorithm;rough set theory;filtrado;approximation space;image;codigo bloque;high precision;algoritmo genetico;theorie ensemble approximatif;precision elevee;banco imagen;banque image;algoritmo aproximacion;precision elevada;algorithme genetique;rough sets;algorithme evolutionniste;genetic algorithm;code bloc;algoritmo evolucionista;coverage;evolutionary algorithm;algorithme approximation;rough set;block code;appariement image	1 This article introduces an approach to matching 2D image segments using approximation spaces. The rough set approach introduced by Zdzis law Pawlak provides a ground for concluding to what degree a particular set of similar image segments is a part of a set of image segments representing a norm or standard. The number of features (color difference and overlap between segments) typically used to solve the image segment matching problem is small. This means that there is not enough information to permit image segment matching with high accuracy. By contrast, many more features can be used in solving the image segment matching problem using a combination of evolutionary and rough set methods. Several different uses of a Darwinian form of a genetic algorithm (GA) are introduced as a means to partition large collections of image segments into blocks of similar image segments. After filtering, the output of a GA provides a basis for finding matching segments in the context of an approximation space. A coverage form of approximation space is presented in this article. Such an approximation space makes it possible to measure the the extent that a set of image segments representing a standard covers GA-produced blocks. The contribution of this article is the introduction of an approach to matching image segments in the context of an approximation space.	approximation;computer vision;genetic algorithm;image segmentation;overlap–add method;rough set;software release life cycle;spaces	Maciej Borkowski;James F. Peters	2006		10.1007/11847465_4	mathematical optimization;combinatorics;range segmentation;discrete mathematics;template matching;rough set;computer science;machine learning;evolutionary algorithm;mathematics;approximation algorithm;algorithm	AI	47.24525977516565	-63.48867718539242	149394
a63bb2962fc96f7d970954d271b78d93bc249d7c	feature point tracking for incomplete trajectories	analisis imagen;evaluation performance;feature points;analisis escena;analyse scene;algorithm complexity;performance evaluation;complexite calcul;complejidad algoritmo;evaluacion prestacion;motion tracking;complejidad computacion;key words motion tracking;complexite algorithme;computational complexity;image sequence;poursuite cible;feature point tracking;pattern recognition;algorithms;validation;image analysis;secuencia imagen;reconnaissance forme;target tracking;reconocimiento patron;analyse image;sequence image;scene analysis;dynamic scenes	A new algorithm is presented for feature point based motion tracking in long image sequences. Dynamic scenes with multiple, independently moving objects are considered in which feature points may temporarily disappear, enter and leave the view field. This situation is typical for surveillance and scene monitoring applications. Most of the existing approaches to feature point tracking have limited capabilities in handling incomplete trajectories, especially when the number of points and their speeds are large, and trajectory ambiguities are frequent. The proposed algorithm was designed to efficiently resolve these ambiguities. Correspondences between moving points are established in a competitive linking process that develops as the trajectories grow. Appearing and disappearing points are treated in a natural way as the points that do not link. The proposed algorithm compares favorably to efficient alternative algorithms selected and tested in a performance evaluation study.	activity tracker;algorithm;experiment;fits;feature vector;laser tracker;performance evaluation;synthetic intelligence	Dmitry Chetverikov;Judit Verestóy	1999	Computing	10.1007/s006070050027	computer vision;image analysis;simulation;artificial intelligence;computational complexity theory;algorithm	Vision	48.74103315036638	-57.02615162493695	149509
a040f2c262861653a7bbae7f6b475d56b1fa0002	an adaptive video shot segmentation scheme based on dual-detection model	journal;dual detection model;scale invariant feature transform;video shot segmentation;adaptive binary search	Efficient segmentation of the video shots is the important and foundational work for the research of video content retrieval and analysis. A video shot segmentation scheme based on a dual-detection model is proposed, which includes the pre-detection and re-detection processes. The concepts of uneven blocked color histogram difference and uneven blocked pixel value difference based on human visual features are introduced, which are used as the main descriptors of the pre-detection process to enlarge the importance of central areas and to reduce the noises of background movements and logos. And the adaptive binary search method is introduced to fast detect boundaries with a time complexity of O(log(2)n). In the re-detection round, the scale invariant feature transform is applied to re-detect boundaries so as to improve the detection precision rate. Experiments show that this algorithm can improve both the recall rate and the precision rate of video shot boundary detection, especially for gradual shot boundaries. (C) 2012 Elsevier B.V. All rights reserved.		Xinghao Jiang;Tanfeng Sun;Jin Liu;Juan Chao;Wensheng Zhang	2013	Neurocomputing	10.1016/j.neucom.2011.11.037	computer vision;speech recognition;computer science;machine learning;scale-invariant feature transform	Vision	39.52866590740924	-52.96405005531327	149569
282b65848455e3a83a9fa16c0d4581939929ce6e	a taxonomy and analysis of camera calibration methods for traffic monitoring applications	surveillance systeme;simulation ordinateur;video based sensing;contraste;error medida;vision ordenador;video based sensing camera calibration traffic monitoring vehicle tracking;length based classifications;measurement error;pedestrian safety;image processing;automatic monitoring;poison control;injury prevention;taxonomy cameras calibration monitoring roads vehicles costs pixel image edge detection intelligent transportation systems;road traffic;intelligent transportation systems;gestion trafic;sistema adquisicion dato;metodo imagen;system monitoring;technique video;safety literature;systematique;traffic management;data acquisition system;image sensors;traffic safety;tecnica video;injury control;roadside camera calibration;computer vision;erreur mesure;home safety;traffic monitoring applications;two vanishing point solutions taxonomy camera calibration analysis traffic monitoring applications vision based automatic traffic monitoring systems length based classifications vehicle tracking roadside camera calibration single vanishing point solutions oft neglected ambiguity;injury research;safety abstracts;single vanishing point solutions;trafic routier;human factors;senal video;signal video;sistematica;monitoring;route;vanishing point;image edge detection;roads;video cameras;pixel;controle automatique;occupational safety;image method;safety;poursuite cible;taxonomy;oft neglected ambiguity;traffic engineering computing calibration cameras image processing image sensors monitoring road traffic road vehicles taxation;vision based automatic traffic monitoring systems;camera video;taxation;gestion trafico;seguimiento de blanco;carretera;video signal;safety research;video technique;ambiguity;traffic engineering computing;accident prevention;trafico carretera;vision ordinateur;etalonnage;violence prevention;control automatico;highway;vehicles;bicycle safety;simulacion computadora;monitorage;vehicle tracking;camera calibration;traffic monitoring;target tracking;monitoreo	Many vision-based automatic traffic-monitoring systems require a calibrated camera to compute the speeds and length-based classifications of tracked vehicles. A number of techniques, both manual and automatic, have been proposed for performing such calibration, but no study has yet focused on evaluating the relative strengths of these different alternatives. We present a taxonomy for roadside camera calibration that not only encompasses the existing methods (VVW, VWH, and VWL) but also includes several novel methods (VVH, VVL, VLH, VVD, VWD, and VHD). We also introduce an overconstrained (OC) approach that takes into account all the available measurements, resulting in reduced error and overcoming the inherent ambiguity in single-vanishing-point solutions. This important but oft-neglected ambiguity has not received the attention that it deserves; we analyze it and propose several ways of overcoming it. Our analysis includes the relative tradeoffs between two-vanishing-point solutions, single-vanishing-point solutions, and solutions that require the distance to the road to be known. The various methods are compared using simulations and experiments with real images, showing that methods that use a known length generally outperform the others in terms of error and that the OC method reduces errors even further.	algorithm;camera resectioning;experiment;image processing;numerical taxonomy;simulation;taxonomy (general);volumetric haptic display	Neeraj K. Kanhere;Stanley T. Birchfield	2010	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2010.2045500	route;system monitoring;computer vision;intelligent transportation system;active traffic management;calibration;camera resectioning;simulation;vanishing point;computer science;suicide prevention;human factors and ergonomics;injury prevention;image sensor;data acquisition;computer security;pixel;observational error	Visualization	49.006338760842375	-56.37604153488652	149635
5e4e0413ee2cf229b8dba19022fcf5132d379cc1	image alignment using pyramid structure with harris corner detection	corner based image alignment;pyramid image;corner detection;inspection;gradient vector;vectors;estimation;image edge detection;gradient vector corner based image alignment corner detection pyramid image;robustness;lighting;algorithm design and analysis;image edge detection robustness algorithm design and analysis vectors inspection estimation lighting	A corner-based image alignment algorithm based on the procedures of corner-based template matching is presented in this study. This algorithm consists of two stages: training and matching. In the matching phase, the corners are obtained using Harris corner detection algorithm. These corners are then used to build the pyramid images. In the matching phase, the corners are obtained using the same corner detection algorithm. The similarity measure is then determined by the differences of gradient vector between the corners obtained in the template image and the inspection image, respectively. Furthermore, it further applied the refined function to evaluate the geometric relationship between the template and the inspection images. Results show that the corner-based template matching outperforms the original edge-based template matching in efficiency, and both of them are robust against lighting changes.	algorithm;corner detection;gradient;harris affine region detector;matching (graph theory);pyramid (geometry);similarity measure;template matching	Chin-Sheng Chen;Shun-Hung Tsai;Kang-Yi Peng;Chorng-Tyan Lin;Chih-Chin Wen	2013	2013 Second International Conference on Robot, Vision and Signal Processing	10.1109/RVSP.2013.53	corner detection;computer vision;feature detection;template matching;pattern recognition;mathematics;engineering drawing;structure tensor	Vision	42.354287504923185	-57.815575344225735	149832
cde7fd31a79fb167bde8cc639b6b08d554ee5c1e	supervised colour image segmentation using granular reflex fuzzy min-max neural network	man;image numerique;brain;image segmentation;image processing;neural networks;0705p;learning;0705m;metodo minimax;0130c;minimax method;4230s;colour image segmentation;traitement image;apprentissage;encephale;pixel;segmentation image;imagen numerica;methode minimax;pattern recognition;digital image;reconnaissance forme;classification automatique;video;reseau neuronal;automatic classification;imagen color;4230v;data classification;clasificacion automatica;human brain;image couleur;color image;homme;neural network	Granular data classification and clustering is an upcoming and important issue in the field of pattern recognition. This paper proposes a Supervised Colour Image Segmentation technique based on Granular Reflex Fuzzy Min-Max Neural Network (GrRFMN). GrRFMN architecture consists of a reflex mechanism inspired from human brain to handle class overlaps. It has been observed that most of the image segmentation techniques are pixel based. It means that segmentation is done on pixel-by-pixel basis. In this paper, a novel granule based approached for colour image segmentation is proposed. In the proposed technique granules of an image are processed. This results into a fast segmentation process. The image segmentation discussed here is a supervised. In training phase, GrRFMN learns different classes in the image using class granules. A trained GrRFMN is then used to segment the image. As GrRMN is trainable on-line in a single pass through data, the proposed method is easily extended for video sequence segmentation. Results on various standard images are presented.© (2010) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	artificial neural network;color image;image segmentation;maxima and minima	Abhijeet V. Nandedkar	2010		10.1117/12.856289	image texture;computer vision;computer science;artificial intelligence;machine learning;segmentation-based object categorization;region growing;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Robotics	45.42551704630487	-63.47902631876587	149948
29da60eb3c16c4736b9d99efb60b8f8fa403a69f	common visual pattern discovery via nonlinear mean shift clustering	quadratic programming graph theory image matching image retrieval lie algebras lie groups matrix algebra pattern clustering;near duplicate image retrieval common pattern discovery local affine region mean shift clustering;detectors;manifolds;manifolds algebra clustering algorithms feature extraction detectors visualization noise;visualization;algebra;feature extraction;near duplicate image retrieval common visual pattern discovery nonlinear mean shift clustering geometric deformation photometric deformation graph based quadratic optimization approache cvp matrix lie group structure non euclidean nature lie algebra vector space;clustering algorithms;noise	Discovering common visual patterns (CVPs) from two images is a challenging task due to the geometric and photometric deformations as well as noises and clutters. The problem is generally boiled down to recovering correspondences of local invariant features, and the conventionally addressed by graph-based quadratic optimization approaches, which often suffer from high computational cost. In this paper, we propose an efficient approach by viewing the problem from a novel perspective. In particular, we consider each CVP as a common object in two images with a group of coherently deformed local regions. A geometric space with matrix Lie group structure is constructed by stacking up transformations estimated from initially appearance-matched local interest region pairs. This is followed by a mean shift clustering stage to group together those close transformations in the space. Joining regions associated with transformations of the same group together within each input image forms two large regions sharing similar geometric configuration, which naturally leads to a CVP. To account for the non-Euclidean nature of the matrix Lie group, mean shift vectors are derived in the corresponding Lie algebra vector space with a newly provided effective distance measure. Extensive experiments on single and multiple common object discovery tasks as well as near-duplicate image retrieval verify the robustness and efficiency of the proposed approach.	algorithm;algorithmic efficiency;cluster analysis;common variable immunodeficiency;experiment;focus stacking;graph - visual representation;image retrieval;mathematical optimization;mean shift;nonlinear system;photometry;the matrix;transformation matrix;cell transformation;statistical cluster	Linbo Wang;Dong Tang;Yanwen Guo;Minh N. Do	2015	IEEE Transactions on Image Processing	10.1109/TIP.2015.2481701	computer vision;detector;combinatorics;discrete mathematics;visualization;topology;manifold;feature extraction;computer science;noise;machine learning;mathematics;cluster analysis	Vision	44.876738839731004	-53.39057006623319	150039
5d6f6c0044d8c8238860f1856bbab7bc5b0f8c3c	precise sensor orientation of high-resolution satellite imagery with the strip constraint		To achieve precise sensor orientation of high- resolution satellite imagery (HRSI), ground control points (GCPs) or height models are necessary to remove biases in orientation parameters. However, measuring GCPs is costly, laborious, and time consuming. We cannot even acquire well-defined GCPs in some areas. In this paper, a strip constraint model is established according to the geometric invariance that the biases of image points remain the same in dividing a strip image into standard images. Based on the rational function model and the strip constraint model, a feasible sensor orientation approach for HRSI with the strip constraint is presented. Through the use of the strip constraint, the bias compensation parameters of each standard image in the strip can be solved simultaneously with sparse GCPs. This approach remains effective even when the intermediate standard images in the strip are unavailable. Experimental results of the three ZiYuan-3 data sets show that two GCPs in the first image and two GCPs in the last image are sufficient for the sensor orientation of all the standard images in the strip. An orientation accuracy that is better than 1.1 pixels can be achieved in each standard image. Moreover, the inconsistent errors of tie points between adjacent standard images can also be reduced to less than 0.1 pixel. This result can guarantee that the generated complete digital orthophoto map of the whole strip is geometrically seamless.	document object model;function model;orthophoto;pixel;polynomial and rational function modeling;seamless3d;sensor;sparse matrix	Jinshan Cao;Xiuxiao Yuan;Jianhong Fu;Jianya Gong	2017	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2017.2705242	invariant (physics);artificial intelligence;pixel;computer vision;mathematics;satellite;satellite imagery;division (mathematics);data set;strips;orthophoto	Vision	51.90351389795192	-55.14572109883893	150076
911a8052ab4f2c4eeb747aab2322ca763bd3dead	gait recognition using hidden markov model	analisis imagen;image features;modelo markov oculto;cmu;silhouette;analisis estadistico;modelo markov;modele markov cache;binary image;hidden markov model;biometrie;gait;biometrics;database;biometria;base dato;inner product;morphological operation;marcha;gait recognition;probabilistic approach;by product;calcul analogique;similitude;baum welch;feature vector;posture;markov model;statistical analysis;sous produit;viterbi algorithm;enfoque probabilista;approche probabiliste;subproducto;analyse statistique;similarity;image binaire;postura;base de donnees;imagen binaria;human identification;image analysis;similitud;modele markov;allure;analyse image;silueta;analog calculus;calculo analogico	Gait-based human identification is a challenging problem and has gained significant attention. In this paper, a new gait recognition algorithm using Hidden Markov Model (HMM) is proposed. The input binary silhouette images are preprocessed by morphological operations to fill the holes and remove noise regions. The width vector of the outer contour is used as the image feature. A set of initial exemplars is constructed from the feature vectors of a gait cycle. The similarity between the feature vector and the exemplar is measured by the inner product distance. A HMM is trained iteratively using Viterbi algorithm and Baum-Welch algorithm and then used for recognition. The proposed method reduces image feature from the two-dimensional space to a one-dimensional vector in order to best fit the characteristics of one-dimensional HMM. The statistical nature of the HMM makes it robust to gait representation and recognition. The performance of the proposed HMM-based method is evaluated using the CMU MoBo database.	hidden markov model;markov chain	Changhong Chen;Jimin Liang;Heng Zhao;Haihong Hu	2006		10.1007/11881070_56	image analysis;speech recognition;similarity;feature vector;binary image;dot product;viterbi algorithm;computer science;baum–welch algorithm;artificial intelligence;similitude;machine learning;pattern recognition;mathematics;gait;markov model;silhouette;feature;hidden markov model;biometrics	Vision	45.07072394635721	-59.13639960270457	150119
c80119bf54df773848ccf5083652bf4ee06a3f06	orthogonal spline fitting in range data	tls technique;iterative process;spline;least squares approximations;image processing splines mathematics parameter estimation error analysis least squares approximations distance measurement;sensor systems;range data;image processing;range imaging data;orthogonal fitting technique;surface fitting;parameterization;orthogonal spline fitting;image sensors;splines mathematics;adaptive parameterization;input output;error analysis;distance measurement;spline least squares methods shape surface fitting signal processing laboratories parameter estimation image sensors sensor systems image analysis;shape;least squares spline approximation;signal processing;least square;not significant;image analysis;error;parameter estimation;input output relationship;least squares methods;total ls fitting;tls technique orthogonal spline fitting range imaging data orthogonal fitting technique input output relationship least squares spline approximation iterative process parameterization error total ls fitting adaptive parameterization	An orthogonal fitting technique for spline approximation is introduced. The technique takes into account the fact that there is uncertainty in both sides of the input-output relationship. In least squares (LS) spline approximation a computationally costly iterative process is required to refine the parameterization such that the error is orthogonal to the signal. This process may be avoided by using the total LS (TLS) fitting in case the nature of the error in parameterization is random instead of systematic. A lower rank approximation of the signal may be used as an input to the spline fitting process. In particular, if adaptive parameterization based on distances among observations is used a more reliable parameterization can be obtained. The TLS technique yields a lower bias than LS fitting whereas the LS has a lower variance. However, the difference in variance is not significant.	smoothing spline;spline (mathematics)	Visa Koivunen;Pauli Kuosmanen;Jaakko Astola	1996		10.1109/ICIP.1996.560841	parametrization;spline;input/output;computer vision;econometrics;mathematical optimization;image analysis;image processing;shape;computer science;signal processing;iterative and incremental development;image sensor;mathematics;estimation theory;least squares;statistics	Robotics	51.97152805969451	-52.37486011198283	150156
008a9d78a4dcbfffd8c1fed36d74b324f1fd07ad	the role of geometry in age estimation	mouth;face geometry;human face understanding;function estimation problem;manifolds;biometric authentication;geometry solid modeling aging shape facial animation humans face biometrics mouth feature extraction;biometrics;geometry;computational geometry;human face modeling;aging;human face modeling geometry age estimation geometric face attributes grassmann manifold function estimation problem velocity vector human face understanding;geometric face attributes;regression;real world application;shape;estimation;grassmann manifold;feature extraction;solid modeling;facial animation;age estimation;solid modelling computational geometry regression analysis;velocity vector;regression analysis;face;humans;regression face geometry age estimation grassmann manifold;solid modelling	Understanding and modeling of aging in human faces is an important problem in many real-world applications such as biometrics, authentication, and synthesis. In this paper, we consider the role of geometric attributes of faces, as described by a set of landmark points on the face, in age perception. Towards this end, we show that the space of landmarks can be interpreted as a Grassmann manifold. Then the problem of age estimation is posed as a problem of function estimation on the manifold. The warping of an average face to a given face is quantified as a velocity vector that transforms the average to a given face along a smooth geodesic in unit-time. This deformation is then shown to contain important information about the age of the face. We show in experiments that exploiting geometric cues in a principled manner provides comparable performance to several systems that utilize both geometric and textural cues. We show results on age estimation using the standard FG-Net dataset and a passport dataset which illustrate the effectiveness of the approach.	authentication;biometrics;experiment;job control (unix);landmark point;manifold regularization;velocity (software development)	Pavan K. Turaga;Soma Biswas;Rama Chellappa	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5495292	face;computer vision;computational geometry;machine learning;pattern recognition;mathematics;biometrics	Vision	42.052885434980396	-52.99338134084303	150296
09821aaea3078020ae6f2564c1a2b4eee734cbb3	perceptual grouping of 3-d features in aerial image using decision tree classifier	decision tree classifier;structured target model;learned gestalt primitives;object recognition;decision tree learning;convergence;bottom up;gestalt principles;decision tree;radius model board image;hierarchical multilevel grouping strategy;decision trees classification tree analysis feature extraction computer vision layout object recognition robustness parallel processing convergence humans;man made structure extraction;input image;collinearity;reference model;training samples;convergence of numerical methods;image classification;perceptual grouping;layout;collated feature grouping;computer vision;aerial image;parallelism;perceptual grouping algorithm;3d reference model;l typed convergence;2d image;feature extraction;stereo image processing;robustness;humans;decision tree learning technique;man made structure extraction perceptual 3d feature grouping aerial image decision tree classifier perceptual grouping algorithm hierarchical multilevel grouping strategy 2d image gestalt principles collinearity parallelism l typed convergence decision tree learning technique training samples 3d reference model 3d line feature extraction input image learned gestalt primitives multilevel grouping procedure collated feature grouping structured target model radius model board image;classification tree analysis;3d line feature extraction;decision trees;object recognition stereo image processing feature extraction decision trees image classification convergence of numerical methods computer vision;parallel processing;multilevel grouping procedure;perceptual 3d feature grouping	We address a new perceptual grouping algorithm for aerial images, which employs a decision tree classifier and hierarchical multilevel grouping strategy an a bottom-up fashion. In our approach, grouping is performed perceptually on 9-D features extracted from 2D images, in which the Gestalt principles including collinearity, parallelism and L-typed convergence are encoded by the decision tree learning technique. The decision tree is constructed using training samples obtained from the given 9-D reference model. Then, each pair of the extracted 9-D line features of an input image is classified into one of the learned Gestalt primitives. On the other hand, an multilevel grouping procedure, grouping of collated features are performed from lower to higher level, yielding the structured target model. In order to evaluate the proposed algorithm, experiments are carried out on RADIUS model board images. The results show that grouping is performed effectively to extract man-made structures an aerial images.	aerial photography;algorithm;bottom-up parsing;decision tree learning;experiment;gestalt psychology;outline of object recognition;parallel computing;radius;reference model;xslt/muenchian grouping	In Kyu Park;Kyoung Mu Lee;Sang Uk Lee	1999		10.1109/ICIP.1999.821559	parallel processing;computer vision;decision tree learning;computer science;machine learning;decision tree;pattern recognition	Vision	41.488388637125865	-64.08638537720918	150297
2b341b938ea029a63e30f308375a615a8fedd8ed	sparse geometric image representations with bandelets	transformation ondelette;algorithme rapide;traitement signal;optimisation;image coding;image segmentation;non linear filtering;image processing;data compression;imagen fija;wavelets and multiresolution processing 2 wavp nonlinear filtering and enhancement 2 nflt still image coding 1 stil;methode echelle multiple;implementation;aproximacion optima;representation image;subband decomposition;filtrado no lineal;procesamiento imagen;nonlinear filter;metodo escala multiple;still image coding 1 stil;imagen nivel gris;analyse multiresolution;traitement image;algorithms artificial intelligence computer graphics data compression image enhancement image interpretation computer assisted multimedia numerical analysis computer assisted pattern recognition automated reproducibility of results sensitivity and specificity signal processing computer assisted;reduccion ruido;wavelet transforms;filtering theory image coding data compression image representation image denoising optimisation distortion wavelet transforms;codage image;distortion;compression image;optimal approximation;approximation optimale;fixed image;image compression;descomposicion subbanda;representation signal;image representation;signal processing;noise reduction;fast algorithm;nonlinear filtering and enhancement 2 nflt;signal representation;image niveau gris;segmentation image;regular variation;reduction bruit;representacion parsimoniosa;image fixe;multiscale method;image denoising;compresion dato;transformacion ondita;image coding noise reduction rate distortion theory approximation error image decomposition filtering image resolution costs image representation inverse problems;wavelets and multiresolution processing 2 wavp;decomposition sous bande;image decomposition;implementacion;image gray level sparse geometric image representation bandelet bases multiscale vector image decomposition fast subband filtering algorithm optimal approximation wavelet image compression;sparse representation	This paper introduces a new class of bases, called bandelet bases, which decompose the image along multiscale vectors that are elongated in the direction of a geometric flow. This geometric flow indicates directions in which the image gray levels have regular variations. The image decomposition in a bandelet basis is implemented with a fast subband-filtering algorithm. Bandelet bases lead to optimal approximation rates for geometrically regular images. For image compression and noise removal applications, the geometric flow is optimized with fast algorithms so that the resulting bandelet basis produces minimum distortion. Comparisons are made with wavelet image compression and noise-removal algorithms.	approximation;bandelet (computer science);base excess:scnc:pt:blda:qn:calculated;displacement mapping;distortion;grayscale;image compression;image segmentation;psychologic displacement;schiff bases;search algorithm;sparse;time complexity;video coding format;wavelet;biologic segmentation	Erwan Le Pennec;Stéphane Mallat	2005	IEEE Transactions on Image Processing	10.1109/TIP.2005.843753	data compression;multiresolution analysis;nonlinear filter;computer vision;geometric flow;discrete mathematics;distortion;image processing;image compression;computer science;theoretical computer science;signal processing;noise reduction;sparse approximation;mathematics;bandelet;image segmentation;implementation;wavelet transform	Vision	52.341653077920895	-64.82691368574021	150428
b1a1379a81a75c6eb4e023c16b5ed36b6f31e228	phase and magnitude in normalized images	image processing;normalisation;procesamiento imagen;traitement image;distortion;perturbacion;statistical analysis;statistical analysis image representation;image representation;distorsion;image representation image structure image distortion magnitude information phase information energy normalized images statistical assumptions;normalizacion;perturbation;brightness signal processing phase distortion fourier series image coding high performance computing humans visual system nonlinear distortion image representation;standardization	Distortion due to complete loss or perturbation of phase or magnitude information is considered for energy normalized images. With certain statistical assumptions on the image structure, phase information is shown to be more crucial.	distortion	Douglas Cochran	1994	IEEE transactions on image processing : a publication of the IEEE Signal Processing Society	10.1109/83.336255	image quality;image warping;image texture;image restoration;computer vision;pyramid;feature detection;distortion;image processing;computer science;theoretical computer science;pattern recognition;mathematics	Vision	50.741627981259995	-64.5641562800671	150464
a5d292f12cd113ddf686c45bcb6f577a814e2a9d	automatic symmetry determination and normalization for rotationally symmetric 2d shapes and 3d solid objects	image processing;normalisation;principal axis;procesamiento imagen;traitement image;rotational symmetry;fourier transformation;transformation fourier;normalizacion;standardization;transformacion fourier	-Determination of the rotational symmetry of a shape is useful for object recognition and shape analysis in computer vision application. However, the usual normalization methods are inapplicable when the shape is N-fold rotationally-symmetric (N > = 3). In this paper, an efficient and reliable new method using modified Fourier transform is introduced to normalize such a 2D rotationally-symmetric shape. Furthermore, we extend this new method to the normalization of a N-fold axial rotationally-symmetric 3D object. There are two obvious advantages when using this new method: (1) it prevents the high computation load and the difficulty in normalizing the shape's orientation which occurred in the old methods using full matching or correlation functions; and (2) the weakness introduced by the old methods using data reduction (from 2D data to 1D data) is remedied. Experiments will show the validity of our method. Shape normalization Moment Rotational symmetry Principal axis Fourier transform	apache axis;computation;computer vision;experiment;outline of object recognition;shape analysis (digital geometry)	Soo-Chang Pei;Lin-Gwo Liou	1994	Pattern Recognition	10.1016/0031-3203(94)90005-1	principal axis theorem;fourier transform;computer vision;image processing;rotational symmetry;mathematics;geometry;standardization	Vision	42.97664826229041	-62.8218114050087	150595
c69b1a70c811df83ae8471113759582953af8f22	adaptive weighting of local classifiers by particle filters for robust tracking	reconnaissance visage;filtre particule;metodo adaptativo;evaluation performance;adaptability;adaptabilite;ombre;performance evaluation;biometrie;evaluacion prestacion;weighting;biometrics;biometria;methode adaptative;connaissances explicites;posterior probability;filtro particulas;ponderacion;adaptabilidad;explicit knowledge;face tracking;interruption partielle;robust;adaptive;automatic recognition;sombra;face recognition;shadow;particle filter;weighted space;partial occlusion;robustesse;adaptive method;probabilite a posteriori;signal classification;poursuite cible;probabilidad a posteriori;pattern recognition;classification signal;robustness;ponderation;reconnaissance forme;classification automatique;target tracking;reconocimiento patron;interrupcion parcial;automatic classification;clasificacion automatica;combination of local classifiers;tracking;reconocimiento automatico;reconnaissance automatique;robustez	This paper presents an adaptive weighting method for combining local classifiers using a particle filter. Although the effectiveness of weighting methods based on combinations of local classifiers (features) has been reported recently, such methods fail in cases where there is partial occlusion or when shadows appear due to changes in the illumination direction since fixed weights are used for combining the local classifiers. In order to achieve the desired robustness, the weights should be changed adaptively. For this purpose, we use a particle filter, where each particle is assigned to the weight set for combining local classifiers. By estimating the posterior probability in weight space by using a particle filter, the effective weights for current time-step are obtained, and as a result the proposed method can account for dynamic occlusion. As a means of a demonstration, our approach is applied to the face tracking problem. The adaptability and the robustness of the method with respect to partial occlusion are evaluated using test sequences in which the occluded areas are changed dynamically. The weights of the occluded regions decrease automatically without the need for explicit knowledge about the occurrence of occlusion, which makes it possible to track the face under conditions of dynamic occlusion.	particle filter	Kazuhiro Hotta	2009	Pattern Recognition	10.1016/j.patcog.2008.09.026	facial recognition system;computer vision;shadow;facial motion capture;adaptability;speech recognition;particle filter;computer science;explicit knowledge;adaptive behavior;pattern recognition;weighting;tracking;posterior probability;biometrics;statistics;robustness	Vision	45.9310005463673	-58.57099850075099	150872
946f41c78946a203fd9d40f3d36d8cdf6c85ed38	recognition and positioning of partially occluded 3-d objects	vision ordenador;analisis escena;analyse scene;minimal spanning tree;occlusion;localizacion objeto;object location;espacio 3 dimensiones;differential geometry;oclusion;computer vision;espace 3 dimensions;three dimensional space;pattern recognition;geometrie differentielle;vision ordinateur;reconnaissance forme;geometria diferencial;reconocimiento patron;localisation objet;arbre maximal minimal;scene analysis	Abstract Ray, K.S. and D. Dutta Majumder, Recognition and positioning of partially occluded 3-D objects, Pattern Recognition Letters 12 (1991) 93–108. The task of recognizing and positioning the partially occluded three-dimensional (3-D) rigid objects of a given scene is considered. The surfaces of 3-D objects may be planar or curved. The 3-D surface informations are captured through range data (depth map). For recognition we use the principal curvatures, mean curvature and Gaussian curvature as the local descriptions of the surfaces. These curvatures are the local invariant features of the surfaces. A computer vision scheme, based upon the matching between the local features of the 3-D objects in a scene and those of the models which are considered as knowledge data base, is described. Finally, the hypothesis generation and verification scheme is considered for best possible recognition.		Kumar Sankar Ray;D. Dutta Majumder	1991	Pattern Recognition Letters	10.1016/0167-8655(91)90055-Q	three-dimensional space;differential geometry;computer vision;computer science;minimum spanning tree;pattern recognition;mathematics;geometry	Vision	48.59848484180235	-59.03296197529271	151045
f382157787ecb27a080e369b047c096c5cb98732	geometrical image filtering with connected operators and image inpainting	image filtering;filtering;partial differential equation;mathematical morphology;filtrage;image processing;filtrado;procesamiento imagen;traitement image;algorithme;algorithm;image inpainting;4230v;connected operator;algoritmo	This paper deals with the joint use of connected operators and image inpainting for image filtering. Connected operators filter the image by merging its flat zones while preserving contour information. Image inpainting restores the values of an image for a destroyed or consciously masked subregion of the image domain. In the present paper, it will be shown that image inpainting can be combined with connected operators to perform an efficient geometrical filtering technique. First, connected operators are presented and their drawbacks for certain applications are highlighted. Second, image inpainting methodology is introduced and a structural image inpainting algorithm is described. Finally, a general filtering scheme is proposed to show how the drawbacks of connected operators can be efficiently solved by structural image inpainting.	algorithm;experiment;filter (signal processing);inpainting;item unique identification;level of detail;the mask	Mariella Dimiccoli;Philippe Salembier	2007		10.1117/12.704276	filter;image restoration;computer vision;mathematical optimization;feature detection;mathematical morphology;image processing;computer science;partial differential equation	Vision	52.34876967854923	-64.98722346718591	151055
2c2436e9e7eb9aefc41f12a0c32f5dcfe050c713	footwear print retrieval system for real crime scene marks	footwear impression evidence;footwear print distance;attributed relational graph;hough transform;arg;content based image retrieval	Footwear impression evidence has been gaining increasing importance in forensic investigation. The most challenging task for a forensic examiner is to work with highly degraded footwear marks and match them to the most similar footwear print available in the database. Retrieval process from a large database can be made significantly faster if the database footwear prints are clustered beforehand. In this paper we propose a footwear print retrieval system which uses the fundamental shapes in shoes like lines, circles and ellipses as features and retrieves the most similar print from a clustered database. Prints in the database are clustered based on outsole patterns. Each footwear print pattern is characterized by the combination of shape features and represented by an Attributed Relational Graph. Similarity between prints is computed using Footwear Print Distance. The proposed system is invariant to distortions like scale, rotation, translation and works well with the partial prints, color prints and crime scene marks.	database;distortion;flat panel detector;shoes;similarity measure	Yi Tang;Sargur N. Srihari;Harish Kasiviswanathan;Jason J. Corso	2010		10.1007/978-3-642-19376-7_8	hough transform;computer vision;computer science	Vision	39.555223142221365	-59.098192614747944	151345
25fc041bcb4f902552cdbfb0974f8627514b922a	multi-scale phase-based local features	model identification;image features;detectors;phase detection;object recognition;image feature;subpixel translation;differential invariant;illumination change;interest point detection;edge detection;image matching;interest points;image deformation;motion estimation;deformable models;feature matching;data mining;image texture;image point selection;detectors robustness feature extraction object recognition motion estimation data mining principal component analysis computer science deformable models phase detection;semiinvariant representation;phase based local feature;structure estimation;sift;scale invariant feature transform;local features;image representation;2d rotation;feature extraction;principal component analysis;position measurement;feature matching multiscale local feature phase based local feature image feature motion estimation structure estimation interest point detection image point selection image deformation feature extraction image neighborhood representation semiinvariant representation model identification quantitative evaluation differential invariant scale invariant feature transform sift illumination change 2d rotation subpixel translation object recognition system;object recognition system;robustness;computer science;image texture feature extraction edge detection object recognition motion estimation position measurement image matching image representation;quantitative evaluation;multiscale local feature;image neighborhood representation	Local feature methods suitable for image feature based object recognition and for the estimation of motion and structure are composed of two steps, namely the ‘where’ and ‘what’ steps. The ‘where’ step (e.g., interest point detector) must select image points that are robustly localizable under common image deformations and whose neighborhoods are relatively informative. The ‘what’ step (e.g., lo cal feature extractor) then provides a representation of th e image neighborhood that is semi-invariant to image deformations, but distinctive enough to provide model identification. We present a quantitative evaluation of both the ‘where’ and the ‘what’ steps for three recent local feature methods: a) phase-based local features [2], b) differentia l invariants [14], and c) the scale invariant feature transfo rm (SIFT) [9]. Moreover, in order to make the phase-based approach more comparable to the other two approaches, we also introduce a new form of multi-scale interest point detector to be used for its ‘where’ step. The results show that the phase-based local features lead to better performance than the other two approaches when dealing with common illumination changes, 2D rotation, and sub-pixel translation. On the other hand, the phase-based local features are somewhat more sensitive to scale and large shear changes than the other two methods. Finally, we demonstrate the viability of the phase-based local feature in a simple object recognition system.	differentia;emoticon;feature (computer vision);information;outline of object recognition;pixel;randomness extractor;sampling (signal processing);scale space;scale-invariant feature transform;semiconductor industry;system identification	Gustavo Carneiro;Allan D. Jepson	2003		10.1109/CVPR.2003.1211426	computer vision;computer science;machine learning;pattern recognition;scale-invariant feature transform;mathematics;feature	Vision	42.22118255906954	-57.151864526639145	151366
4c55383e88634980363b248ce2a48e7675fbfd9e	g-hdaf multiresolution deformable models	transformation ondelette;scale function;vision ordenador;range data;hermite interpolation;biorthogonal wavelets;computer graphics;cuerpo deformable;interpolation hermite;distributed approximating functional;analyse multiresolution;computer vision;interpolacion hermite;vanishing moment;deformable body;corps deformable;vision ordinateur;transformacion ondita;multiresolution analysis;grafico computadora;deformable model;infographie;wavelet transformation;analisis multiresolucion	In this paper, we construct a new class of deformable models using a new family of biorthogonal wavelets, named generalized Hermite Distributed Approximating Functional (g-HDAF) Wavelets. The scaling functions of this new family are symmetric and the corresponding wavelets optimize their smoothness for a given number of vanishing moments. In addition, we embed these multiresolution deformable models to the physics-based deformable model framework and use them for fitting 3D range data. We have performed a number of experiments with both synthetic and real data with very encouraging results.	experiment;image scaling;synthetic intelligence;wavelet	Ioannis A. Kakadiaris;Emmanuel Papadakis;Lixin Shen;Donald Kouri;David K. Hoffman	2002		10.1007/3-540-36138-3_2	multiresolution analysis;computer vision;mathematical optimization;computer science;hermite interpolation;mathematics;geometry;computer graphics;algorithm	Vision	51.041291555981005	-62.31696616704705	151411
38a514c21f989f59c00b4e69ce7061fe73a9712c	curvature estimation of point-sampled surfaces and its applications	funcion discreta;point estimation;fonction energie;digitizing;extraction forme;courbure;surface simplification;numerisation;energy function;multi dimensional;discrete function;fonction discrete;extraccion forma;estimation ponctuelle;extreme point;feature extraction;pattern recognition;funcion energia;curvatura;numerizacion;curvature;point cloud;reconnaissance forme;extraction caracteristique;reconocimiento patron;estimacion puntual;pattern extraction	In this paper, we propose a new approach to estimate curvature information of point-sampled surfaces. We estimate curvatures in terms of the extremal points of a one-dimensional energy function for discrete surfels (points equipped with normals) and a multi-dimensional energy function for discrete unstructured point clouds. Experimental results indicate that our approaches can estimate curvatures faithfully, and reflect the subtle curvature variations. Some applications for curvature information, such as surface simplification and feature extraction for point-sampled surfaces, are given.	calculus of variations;digital geometry;feature extraction;geometry processing;level of detail;mathematical optimization;point cloud;sampling (signal processing);surfel	Yongwei Miao;Jieqing Feng;Qunsheng Peng	2005		10.1007/11424857_110	extreme point;topology;principal curvature;feature extraction;computer science;point estimation;calculus;mean curvature;point cloud;mathematics;geometry;curvature;constant-mean-curvature surface	Robotics	49.63321060530892	-61.40468107955948	151483
4c5abd626147217a45fbd5db1b774195b73b9529	vanishing point detection in the hough transform space	metodo analitico;image processing;procesamiento imagen;transformacion hough;linear system;traitement image;vanishing point;analytical method;methode analytique;hough transformation;hough transform;transformation hough;depth estimation	Depth estimation from monocular images can be retrieved from the perspective distortion. One major effect of this distortion is that a set of parallel lines in the real world converges into a single point in the image plane. The estimation of the co-ordinates of the vanishing point can be retrieved directly on the Hough Transformation space or polar plane. In fact the vanishing point in the image plane is mapped in the polar plane into a sine curve that can be estimated with a simple linear system.	hough transform;vanishing point	Andrea Matessi;Luca Lombardi	1999		10.1007/3-540-48311-X_137	hough transform;computer vision;topology;image processing;computer science;mathematics;geometry	Vision	50.04573519918604	-58.1057670976241	151628
1650411ffb9922979141adab88047e80b6b5f062	a new curve control function for the detection of the brain ventricle area	nuclear magnetic resonance imaging;brain ventricle;medical imagery;tecnologia electronica telecomunicaciones;geodesic active contour;detection forme;imagineria rmn;active contour;image processing;methode mesure;edge detection;procesamiento imagen;metodo medida;shape detection;traitement image;deteccion contorno;geodesique;brightness;detection contour;deteccion forma;brillance;contorno activo;geodesic;geodesico;imagineria medica;imagerie medicale;imagerie rmn;contour actif;measurement method;tecnologias;grupo a;brillantez;curve control function	This paper proposed a region-based curve control function to detect the brain ventricle area by utilizing a geodesic active contour model. This is based on the average brightness of the brain ventricle area which is brighter in MRI images. Compared numerically by using various types of measurements, the proposed method can detect the brain ventricle area better than the existing methods.		Chul-Ho Won;Dong Hoon Kim;Jyung Hyun Lee;Sang Hyo Woo;Yeon Kwan Moon;Jin-Ho Cho	2007	IEICE Transactions	10.1093/ietisy/e90-d.11.1896	computer vision;geodesic;edge detection;image processing;computer science;active contour model;brightness;computer graphics (images)	Vision	47.00880233933315	-64.03115888951794	151676
6593de27e2da946ae530e358f04da78e6faeb26b	circular spot detection and segmentation with rotating line local binary analysis	circular spot detection;retina object detection biomedical imaging robustness lesions image color analysis gaussian distribution;object detection gaussian distribution image segmentation;local binary analysis;local binary analysis circular spot detection rotating line;round local peaks circular spot detection circular spot segmentation rotating line local binary analysis round local valleys image space omnidirectional symmetry gaussian distribution characteristics rotating line scan operator feature analysis spot object spot appearance variation spot size spot local contrast spot intensity real images;rotating line	The circular spots appear as round local peaks/valleys in image space, and they reflect omnidirectional symmetry and Gaussian distribution characteristics. According to these observations, a novel rotating line scan operator is proposed to achieve feature analysis of the spot object. Experimental tests show that the proposed algorithm is robust to spots' appearance variation (size, local contrast and intensity). The method presents promising performance in various real images.	algorithm	Dongbo Zhang;Xia Liu	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025337	computer vision	Robotics	43.262929097980496	-65.18618621770192	151728
6b08e99e5db3eca2d95d87e4e8e09f50ca80f53d	a motion estimation algorithm under time-varying illumination	analisis imagen;vision ordenador;time varying;movimiento;illumination;motion estimation;motion;computer vision;mouvement;image sequence;estimacion parametro;image analysis;vision ordinateur;secuencia imagen;parameter estimation;estimation parametre;eclairement;analyse image;sequence image;alumbrado	In this paper, a modified motion estimation algorithm via Hadamard transform suitable for time-varying space-invariant (TVSI) illumination is proposed. The amount of computation is much less in comparison with the formula derived by Lai and Chang in the estimation of 3-D motion parameters. Furthermore, the latter is shown to be a special case of our formula in the time-invariant illumination case.	algorithm;computation;hadamard transform;motion estimation;time-invariant system	Chang-Wu Fu;Shyang Chang	1989	Pattern Recognition Letters	10.1016/0167-8655(89)90087-1	computer vision;image analysis;computer science;motion;motion estimation;estimation theory;computer graphics (images)	Vision	50.1371474445423	-57.86067410878335	151955
e8711f37ee8a2f9fbf37d4ee4260b082cd60f5e9	explicit modelling of invariances in bernoulli mixtures for binary images	binary image;probabilistic model;mixture model;natural transformation	Bernoulli mixture models have been recently proposed as simple yet powerful probabilistic models for binary images in which each image pattern is modelled by a different Bernoulli prototype (component). A possible limitation of these models, however, is that usual geometric transformations of image patterns are not explicitly modelled and, therefore, each natural transformation of an image pattern has to be  independently modelled using a different,  rigid prototype. In this work, we propose a simple technique to make these rigid prototypes more flexible by explicit modelling of invariances to translation, scaling and rotation. Results are reported on a task of handwritten Indian digits recognition.	bernoulli polynomials	Verónica Romero;Adrià Giménez;Alfons Juan-Císcar	2007		10.1007/978-3-540-72847-4_69	statistical model;computer vision;combinatorics;binary image;natural transformation;computer science;machine learning;pattern recognition;mixture model;mathematics;statistics	AI	40.833490922827195	-53.219431985048224	151958
78818f700e713f7bfc211067f6a021a0fae348e1	quality inspection of size, shape and arrangement of sweet corn seeds by image processing		This article proposes the techniques for inspecting the quality of sweet corn using image processing. The size, shape and arrangement of sweet corn kernels were considered in quality inspection. The measurement of the size of sweet corn was done by measuring the distance between the two endpoints of the sweet corn image. The shape of the sweet corn was examined by the symmetry of the sweet corn. In order to determine the arrangement of the kernels, the edges of the image were figured out by Laplacian of Gaussian which was then used to calculate the uniformity of the distance between lines. The experimental results showed that, the size of sweet corn, the average error was 0.18 cm and the shape and the symmetry of corn cob and the arrangement of the corn kernels were correct.	blob detection;business continuity planning;circuit complexity;image processing	Monlica Wattana;Thichakorn Phonarin;Ubon Ketnork	2018	2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2018.8466509	image processing;blob detection;computer vision;artificial intelligence;mathematics	Vision	47.15594020840156	-64.79169306783967	151974
957c7cd5be8a1ca647b6cedd9b14c472afbf9fc6	a template matching approach of one-shot-learning gesture recognition	depth image;2d fourier transform;motion history image;gesture recognition	This paper proposes a novel approach for gesture recognition from motion depth images based on template matching. Gestures can be represented with image templates, which in turn can be used to compare and match gestures. The proposed method uses a single example of an action as a query to find similar matches and thus termed one-shot-learning gesture recognition. It does not require prior knowledge about actions, foreground/background segmentation, or any motion estimation or tracking. The proposed method makes a novel approach to separate different gestures from a single video. Moreover, this method is based on the computation of space-time descriptors from the query video which measures the likeness of a gesture in a lexicon. These descriptor extraction methods include the standard deviation of the depth images of a gesture as well as the motion history image. Furthermore, two dimensional discrete Fourier transform is employed to reduce the effect of camera shift. The comparison is done based on correlation coefficient of the image templates and an intelligent classifier is proposed to ensure better recognition accuracy. Extensive experimentation is done on a very complicated and diversified dataset to establish the effectiveness of employing the proposed methods.	gesture recognition;template matching	Upal Mahbub;Hafiz Imtiaz;Tonmoy Roy;Md. Shafiur Rahman;Md. Atiqur Rahman Ahad	2013	Pattern Recognition Letters	10.1016/j.patrec.2012.09.014	fourier transform;computer vision;speech recognition;computer science;pattern recognition;gesture recognition	Vision	39.70733151420287	-53.38794926950326	152000
16f21c05dda83a2d9e88fe2aaef7a228b4c47593	multisensor-based object identification using uncertain geometric models	objet;object recognition;vision ordenador;modele geometrique;information loss;incertidumbre;uncertainty;sensor integration;object;robotics;computer vision;captador medida;measurement sensor;capteur mesure;model uncertainty;pattern recognition;robotica;vision ordinateur;geometric model;robotique;incertitude;reconnaissance forme;reconocimiento patron;objeto;object identification;geometrical model;object model;modelo geometrico	One of the problems in sensor integration is how to design the integration strategy for the given task. In this paper, we deal with model-based object recognition from uncertain geometric observations using uncertain object models. First, we decompose the recognition problem into a hierarchy of statistically well-defined subproblems depending on sensor uncertainties and model uncertainties. A recognition algorithm based on this approach is developed. Second, a method to preserve the consistency under model uncertainties is discussed. It is shown that information loss can be avoided by adding dummy variables to parameters in the integration. Finally, applications of the proposed method to two-dimensional object recognition are demonstrated.		Toshio Kawashima;Yoichi Shirakawa;Yoshinao Aoki	1993	Advanced Robotics	10.1163/156855394X00031	computer vision;object model;uncertainty;computer science;artificial intelligence;object;geometric modeling;cognitive neuroscience of visual object recognition;robotics	Robotics	47.037326709621205	-55.65931076870684	152023
1f062632356e603e199029860702d36860e02cbb	image fusion using weighted multiscale fundamental form	image fusion;wavelet transforms;image fusion wavelet transforms eigenvalues and eigenfunctions image resolution application specific integrated circuits design engineering design automation wavelet coefficients mutual information entropy;image representation;wavelet transforms sensor fusion image representation;conditional entropy;mutual information;sensor fusion;fusion process image fusion weighted multiscale fundamental form multivalued image wavelet representation wavelet coefficients	Several images to be fused can be taken as a multivalued image. From multiscale fundamental form (MFF), a multivalued image wavelet representation can be obtained. In order to avoid the enlargement of the wavelet coefficients, the weighted multiscale fundamental form (WMFF) is exploited in our fusion process. The mutual information and the conditioned entropy are introduced to evaluate the fused result. Compared with the multiscale fundamental form, the weighted one has a better performance on image fusion.	coefficient;image fusion;mutual information;subscriber identity module;wavelet	Tao Chen;Ruosan Guo;Silong Peng	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1421824	computer vision;mathematical optimization;pattern recognition;mathematics;sensor fusion;wavelet packet decomposition;mutual information;image fusion;conditional entropy;statistics;wavelet transform	Robotics	52.07492193176335	-65.76209605901045	152196
6554ca3187b3cbe5d1221592eb546dfc11aac14b	hybrid method based on topography for robust detection of iris center and eye corners	reconnaissance visage;gaze;iris detection;corner detection;vision ordenador;multistage;parpado;mouvement oculaire poursuite;topographie;edge detection;reconocimiento de cara;real time;multietage;mirada;analyse multiresolution;classification;topography;computer vision;deteccion contorno;detection contour;regard;face recognition;eyelid;iris ojo;poliescalonado;temps reel;movimiento ocular seguimiento;tiempo real;algorithms;vision ordinateur;iris oeil;eye tracking;multiresolution analysis;clasificacion;topografia;analisis multiresolucion;pursuit eye movement;paupiere;iris eye	A multistage procedure to detect eye features is presented. Multiresolution and topographic classification are used to detect the iris center. The eye corner is calculated combining valley detection and eyelid curve extraction. The algorithm is tested in the BioID database and in a proprietary database containing more than 1200 images. The results show that the suggested algorithm is robust and accurate. Regarding the iris center our method obtains the best average behavior for the BioID database compared to other available algorithms. Additional contributions are that our algorithm functions in real time and does not require complex post processing stages.	algorithm;multiresolution analysis;multistage amplifier;topography	Arantxa Villanueva;Victoria Ponz;Laura Sesma;Mikel Ariz;Sonia Porta;Rafael Cabeza	2013	TOMCCAP	10.1145/2501643.2501647	multiresolution analysis;corner detection;computer vision;edge detection;eye tracking;biological classification;computer science;topography;computer graphics (images)	ML	46.14203768897014	-60.3423546194308	152292
e9f7303a0f03d60cb7bd02123ea1b14719bb22b3	novel techniques for color texture classification	color image processing;principal components analysis;texture classifi- cation;band ratioing;feature extraction;color image;principal component analysis;ccd camera;computer vision	In the computer vision domain, color has not been a relevant field of study, since grayscale images contained enough information to solve many different tasks. Another reason to avoid color images, was the fact that they require to upgrade the input hardware (mainly CCD cameras) and that the CPU processing power need to be higher to be able to handle the additional color information. In the recent years, many researchers have begun to take color information into consideration. In the texture analysis field, many classical feature extraction algorithms have been enhanced to process color textures and new ones have been researched. In this paper, a new approach to extend grayscale texture analysis methods is presented. By means of the band ratioing technique, we can modify any feature extraction algorithm to take advantage of color information and achieve higher classification rates. To prove this extreme, three standard techniques has been selected: Gabor filters, Wavelets and Cooccurrence Matrices. For testing purposes, 30 color textures have been selected from the Vistex database. We will perform a number of experiments on that texture set, combining different ways of adapting the former algorithms to process color textures and extract features from them.	algorithm;central processing unit;charge-coupled device;computation;computer performance;computer vision;experiment;feature extraction;gabor wavelet;grayscale;input device;monochrome;preprocessor;principal component analysis;spectral method;supercomputer	Rubén Muñiz;José Antonio Corrales	2006			texture filtering;hsl and hsv;demosaicing;color histogram;color image;color normalization;image texture;computer vision;texture compression;artificial intelligence;computer science	Vision	41.10034539292553	-65.48018432493257	152432
752beca6df510a2178fbffbb4fda85360f1cb605	a domain reduction algorithm for incremental projective reconstruction	traitement pipeline;analisis imagen;modelizacion;vision ordenador;movilidad;image processing;diminution cout;batch production;dimension reduction;mobility;real time;three dimensional shape;projection method;procesamiento imagen;procede discontinu;mobilite;traitement image;three dimensional;forma tridimensional;computer vision;reduction dimension;modelisation;metodo factorizacion;reconstruction image;produccion por lote;methode projection;forme tridimensionnelle;reconstruccion imagen;factorization method;image reconstruction;robustesse;temps reel;image sequence;production par lot;metodo proyeccion;batch process;reduccion dimension;tiempo real;procedimiento discontinuo;robustness;image analysis;vision ordinateur;projective reconstruction;methode factorisation;reduccion costes;modeling;analyse image;real time application;cost lowering;pipeline processing;robustez	In this paper we address the problem of recovering the three-dimensional shape of an object and the motion of the camera based on multiple feature correspondences from an image sequence. We present a new incremental projective factorization algorithm using a perspective camera model. The original projective factorization method produces robust results. However, the method can not be applied to real-time applications since it is based on a batch processing pipeline and the size of the data matrix grows with each additional frame. The proposed algorithm obtains an estimate of shape and motion for each additional frame adding a dimension reduction step. A subset of frames is selected analyzing the contribution of frames to the reconstruction quality. The main advantage of the novel algorithm is the reduction of the computational cost while keeping the robustness of the original method. Experiments with synthetic and real images illustrate the accuracy and performance of the new algorithm.	domain reduction algorithm	Rafael Lemuz-López;Miguel Arias-Estrada	2006		10.1007/11919629_57	iterative reconstruction;three-dimensional space;computer vision;image analysis;systems modeling;image processing;computer science;mathematics;projection method;algorithm;robustness;dimensionality reduction;batch processing	EDA	49.54465244328334	-56.69249568479678	152629
7888b53f4a25b5e7d86b41d8dbce18c9a465b4db	compressed quadtree with content-addressable memory	cadcam;resolution;hierarchical data structure;linear quadtree structure;image coding;linear quadtree;image segmentation;coherence image coding quadtrees content addressable storage image representation image segmentation;image resolution;spatial coherence;quad quadtree;homogeneous regions merging content addressable memory compressed quadtree linear quadtree structure image coding linear quadtree leaf nodes locational nodes dont care state spatial coherence hierarchical data structure quad quadtree recursive subdivision sub image resolution rearranged labelling order;image coding associative memory computer aided manufacturing cadcam spatial coherence data structures spatial resolution image resolution labeling merging;recursive subdivision;rearranged labelling order;data structures;image representation;computer aided manufacturing;sub image;locational nodes;merging;homogeneous regions merging;content addressable memory;associative memory;coherence;leaf nodes;compressed quadtree;dont care state;content addressable storage;quadtrees;labeling;spatial resolution	This paper is concerned with the development of linear quadtree structure for image coding with the objective of making it more compact and suitable for CAM implementation. Linear quadtree represents an image by a collection of leaf nodes which are represented by locational nodes. We aim a t reducing the number of locational codes by making use of coherence of regions. The underlying idea is to extend the use of “dont care” s ta te in the CAM-based linear quadtree to exploit more spatial coherence. We propose a new hierarchical da ta structure, named as quad-quadtree, which is based on recursively subdivision of an image into 16 equal-sized sub-image until each is homogeneous or until a sufficiently fine resolution is reached. The quad-quadtree differs from other quadtree structures in that it reduces the number of codes by using rearranged labelling order and merging homogeneous regions. Experimental results obtained on real da ta demonstrate its space efficiency and usefulness.	code;coherence (physics);content-addressable memory;quadtree;recursion;subdivision surface;tree (data structure)	Dekun Yang	1994		10.1109/ICIP.1994.413599	computer vision;image resolution;data structure;computer science;theoretical computer science;quadtree;computer-aided manufacturing;computer graphics (images)	Vision	47.46756510814926	-66.12140299998329	153287
7f644028bacbb359e2eadef13f244b1f86f8e46d	robust optical flow computation based on least-median-of-squares regression	metodo cuadrado menor;methode moindre carre;transformation affine;estimator robustness;estimation mouvement;algorithm performance;motion discontinuity detection;image processing;least squares method;flux optique;image sequence analysis;estimacion movimiento;least median of squares;procesamiento imagen;optical flow estimation;motion estimation;mediane;median;statistical regression;traitement image;algorithme;least median of squares robust regression;algorithm;robustez estimador;estimation erreur;flujo optico;error estimation;resultado algoritmo;regresion estadistica;affine transformation;image sequence;estimacion error;performance algorithme;estimacion parametro;robust regression;secuencia imagen;optical flow;mediana;parameter estimation;estimation parametre;regression statistique;transformacion afin;sequence image;affine motion model;algoritmo;robustesse estimateur	An optical flow estimation technique is presented which is based on the least-median-of-squares (LMedS) robust regression algorithm enabling more accurate flow estimates to be computed in the vicinity of motion discontinuities. The flow is computed in a blockwise fashion using an affine model. Through the use of overlapping blocks coupled with a block shifting strategy, redundancy is introduced into the computation of the flow. This eliminates blocking effects common in most other techniques based on blockwise processing and also allows flow to be accurately computed in regions containing three distinct motions. A multiresolution version of the technique is also presented, again based on LMedS regression, which enables image sequences containing large motions to be effectively handled. An extensive set of quantitative comparisons with a wide range of previously published methods are carried out using synthetic, realistic (computer generated images of natural scenes with known flow) and natural images. Both angular and absolute flow errors are calculated for those sequences with known optical flow. Displaced frame difference error, used extensively in video compression, is used for those natural scenes with unknown flow. In all of the sequences tested, a comparison with those methods that result in a dense flow field (greater than 80% spatial coverage), show that the LMedS technique produces the least error irrespective of the error measure used.	algorithm;algorithmic efficiency;angularjs;blocking (computing);computation;computer;data compression;function model;ibm research;motion estimation;optical flow;parallel computing;pixel;sparse matrix;synthetic intelligence;workstation	Ee Ping Ong;Michael Spann	1999	International Journal of Computer Vision	10.1023/A:1008046826441	computer vision;econometrics;mathematical optimization;image processing;computer science;motion estimation;optical flow;affine transformation;mathematics;estimation theory;least squares;median;robust regression;regression analysis;statistics	Vision	51.73568779608867	-58.9578412001681	153308
13aa92ddc1488964030418c95cb363f10d16ea7a	multiresolution texture analysis of surface reflection images	quality assurance;surface properties;gabor filter;texture analysis	Surface reflection can be used as one quality assurance procedure to inspect the defects, cracking, and other irregularities occurring on a polished surface. In this paper, we present a novel approach to the detection of defects based on analysis of surface reflection images. In this approach, the surface image is analyzed using texture analysis based on Gabor-filtering. Gabor-filters can be used in the inspection of the surface in multiple resolutions, which makes it possible to inspect the defects of different sizes. The orientation of the defects and surface cracking is measured by applying the Gabor-filters in several orientations. A set of experiments were carried out by using surface reflection images of polished rock plates and the orientation of the surface cracking was determined. In addition, the homogeneity of the rock surface was measured based on the Gabor features. The results of the experiments show that Gabor features are effective in the measurement of the surface properties.	experiment;gabor filter;password cracking	Leena Lepistö;Iivari Kunttu;Jorma Autio;Ari Visa	2003		10.1007/3-540-45103-X_2	quality assurance;computer vision	Vision	47.1763883662534	-65.54143725545862	153474
1d1e42cf0aace147e3a41aa6a24a79ef025d2958	intrinsic shape context descriptors for deformable shapes	image sampling;kernel;shape matching intrinsic shape context descriptor deformable shape isc descriptor 3d shape polar sampling image domain geodesic shooting direction geodesic distance orientation ambiguity fourier transform charting method isometric shape transformation meta descriptor photometric property field geometric property field intrinsic shape analysis heat kernel signature;standards;shape recognition differential geometry fourier transforms image matching image sampling photometry;image matching;differential geometry;geometry;shape recognition;heating;surface treatment;shape;photometry;fourier transforms;context;shape context surface treatment geometry heating kernel standards	In this work, we present intrinsic shape context (ISC) descriptors for 3D shapes. We generalize to surfaces the polar sampling of the image domain used in shape contexts: for this purpose, we chart the surface by shooting geodesic outwards from the point being analyzed; `angle' is treated as tantamount to geodesic shooting direction, and radius as geodesic distance. To deal with orientation ambiguity, we exploit properties of the Fourier transform. Our charting method is intrinsic, i.e., invariant to isometric shape transformations. The resulting descriptor is a meta-descriptor that can be applied to any photometric or geometric property field defined on the shape, in particular, we can leverage recent developments in intrinsic shape analysis and construct ISC based on state-of-the-art dense shape descriptors such as heat kernel signatures. Our experiments demonstrate a notable improvement in shape matching on standard benchmarks.	antivirus software;benchmark (computing);distance (graph theory);encode;experiment;image analysis;isometric projection;sampling (signal processing);semiconductor industry;shape analysis (digital geometry);shape context	Iasonas Kokkinos;Michael M. Bronstein;Roee Litman;Alexander M. Bronstein	2012	2012 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2012.6247671	active shape model;fourier transform;differential geometry;computer vision;kernel;topology;photometry;shape;heat kernel signature;principal geodesic analysis;shape analysis;mathematics;geometry	Vision	40.4558999812204	-56.37347368014726	153628
0919b48f0c60cc4c8205da8f0a353e868dd0a42c	dasc: dense adaptive self-correlation descriptor for multi-modal and multi-spectral correspondence	sampling methods computer vision image matching learning artificial intelligence optimisation;robustness correlation measurement benchmark testing visualization pattern matching image edge detection;discriminative learning dasc dense adaptive self correlation descriptor multimodal correspondence multispectral correspondence computer vision computational photography image matching randomized receptive field pooling sampling pattern optimization	Establishing dense visual correspondence between multiple images is a fundamental task in many applications of computer vision and computational photography. Classical approaches, which aim to estimate dense stereo and optical flow fields for images adjacent in viewpoint or in time, have been dramatically advanced in recent studies. However, finding reliable visual correspondence in multi-modal or multi-spectral images still remains unsolved. In this paper, we propose a novel dense matching descriptor, called dense adaptive self-correlation (DASC), to effectively address this kind of matching scenarios. Based on the observation that a self-similarity existing within images is less sensitive to modality variations, we define the descriptor with a series of an adaptive self-correlation similarity for patches within a local support window. To further improve the matching quality and runtime efficiency, we propose a randomized receptive field pooling, in which a sampling pattern is optimized with a discriminative learning. Moreover, the computational redundancy that arises when computing densely sampled descriptor over an entire image is dramatically reduced by applying fast edge-aware filtering. Experiments demonstrate the outstanding performance of the DASC descriptor in many cases of multi-modal and multi-spectral correspondence.	computational photography;computer vision;modal logic;modality (human–computer interaction);optical flow;randomized algorithm;sampling (signal processing);self-similarity	Seungryong Kim;Dongbo Min;Bumsub Ham;Seungchul Ryu;Minh N. Do;Kwanghoon Sohn	2015	2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2015.7298822	computer vision;machine learning;pattern recognition;mathematics	Vision	39.47577995987969	-54.01971911917456	153667
495313075023e3387e8d6937415512f12cefd5c6	evaluation of strategies for segmentation of blue-dyed pores in thin sections of reservoir rocks		Abstract   Petrographic image analysis concerns segmentation and analysis of a rock fabric in the format of a 30 μ thick “thin section.” A major objective of such analysis is to segment pores (voids) from the rock material inasmuch as pore size and geometry control fluid flow. Conventionally, prior to sectioning, the rock is impregnated with blue dyed epoxy. Since few, if any naturally occurring components of reservoir rocks are blue, a segmentation process based upon color is appropriate. Segmentation in this case must accomplish both the correct identification of a pore and the precise definition of its edge. Most of the conventional segmentation techniques, which employ thresholding on histograms, failed in this because of problems associated with high light intensities required for petrographic microscopy and because of gradational boundaries caused by shelving effects. Successful segmentation was accomplished by modeling the digital filters on the human perception of the color of pore pixels. It has been shown that both of the filters developed clearly distinguish pore from nonpore and locate edges with high precision. However, a histogram of hue is still employed to identify the nature of pore boundaries (vertical, shelving, etc.).		Sterling J. Crabtree;Robert Ehrlich;Christopher Prince	1984	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(84)90136-1	computer vision;pixel;petrography;thresholding;hue;histogram;artificial intelligence;mathematics;segmentation	Vision	46.76911983685606	-66.12020869525001	153735
2aa6ee917e2a2874c6e2710976594b708f4ad13a	finite-element methods for active contour models and balloons for 2-d and 3-d images	minimisation;analisis imagen;minimization;partial differential equation;2d planar curves;regularisation;finite element methods active contours image edge detection feature extraction deformable models finite difference methods stability convergence image segmentation magnetic resonance;methode element fini;metodo elemento finito;3d imaging;metodo diferencia finita;magnetic resonance image segmentation active contour models 3d images energy minimizing curves balloon model 3d deformable surface attraction potential minimization 2d planar curves finite element method;edge detection;potentiel attraction;edge elements;magnetic resonance image segmentation;finite difference;segmentation;finite element method;surface reconstruction;satisfiability;balloon model;magnetic resonance image;three dimensional;finite difference method;regularization;difference scheme;methode difference finie;reconstruction surface;3d deformable surface;feature extraction;surface model;modele deformable;active contour models;image analysis;regularizacion;finite element analysis;energy minimization;extraction caracteristique;reconstruccion superficie;3d images;modele contour actif;analyse image;deformable model;segmentacion;minimisation edge detection feature extraction finite element analysis;active contour model;energy minimizing curves;attraction potential	AbsfrucfThe use of energy-minimizing curves, known as “snakes” to extract features of interest in images has been introduced by Kass, Witkin and Tenopoulos [W]. A balloon model was introduced in [12] as a way to generalize and solve some of the problems encountered with the original method. A 3-D generalization of the balloon model as a 3-D deformable surface, which evolves in 3-D images, is presented. It is deformed under the action of internal and external forces attracting the surface toward detected edgels by means of an attraction potential. We also show properties of energy-minimizing surfaces concerning their relationship with 3-D edge points. To solve the minimization problem for a surface, two simplified approaches are shown first, defining a 3-D surface as a series of 2-D planar curves. Then, after comparing finite-element method and finite-difference method in the 2-D problem, we solve the 3-D model using the finite-element method yielding greater stability and faster convergence. This model is applied for segmenting magnetic resonance images.	3d modeling;active contour model;contour line;finite difference method;finite element method;resonance	Laurent D. Cohen;Isaac Cohen	1993	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.244675	computer vision;mathematical optimization;image analysis;computer science;finite element method;mathematics;geometry	Vision	51.96269424382294	-58.28011491480787	154227
a0bde509f2a0f40ce4c38ca934c70a1499f73d2c	a new approach of local feature descriptors using moment invariants	local descriptor;feature matching;geometric moments	Moment invariants have been widely introduced in re cognizing planar objects for a few decades. This is due the robustness of moment function in disting u shing the original identity of object under vario us two Dimensional (2D) transformations. A set of mome nts computed from a planar images, represents the global description of an object’s shape and geo metrical features of an image. Since global descriptor utilizes the information of a whole obje ct or shape to describe the features of an object, it does not tolerate occlusion. If there is a mixture of regions that do not belong to the object of the interest, an additional task of segmentation is req uired to isolate the object for recognition. Hence, moment invariants are proposed to be employed as lo cal descriptors for object recognition since local descriptors do not suffer from the drawbacks caused by image clutter and occlusion. A new approach of local feature descriptors using moment invariant s is presented. The preliminary framework is divided into three different stages. Interest point s are firstly detected in the entire image. The loc a descriptors are then produced by applying moment in var ants on the region around the interest points. Cross-correlation is finally carried out for featur e matching.	clutter;cross-correlation;feature vector;hidden surface determination;image moment;outline of object recognition;variometer	Lee-Yeng Ong;Siong-Hoe Lau;Voon Chet Koo	2014	JCS	10.3844/jcssp.2014.2538.2547	computer vision;pattern recognition	Vision	40.242773305084036	-56.63178404750432	154331
3bddac9394f7b80c4c0a3d00681553d530d54586	recovering ball motion from a single motion-blurred image	ball motion recovery;image tridimensionnelle;medida velocidad;vision ordenador;tennis;estimation mouvement;image processing;edge detection;deporte;localization;estimacion movimiento;single image 3d reconstruction;procesamiento imagen;motion estimation;mesure vitesse;localizacion;contour detection in motion blurred images;image bruitee;traitement image;computer vision;deteccion contorno;imagen sonora;detection contour;reconstruction image;detection mouvement;speed measurement;motion blur;localisation;senal video;signal video;imagen borrosa;reconstruccion imagen;blurred image;image reconstruction;noisy image;ball trajectory from streak;tenis;deteccion movimiento;video signal;tridimensional image;vision ordinateur;image floue;sport;motion detection;3d reconstruction;imagen tridimensional;canal surface	Motion blur often affects the ball image in photographs and video frames in many sports such as tennis, table tennis, squash and golf. In this work we operate on a single calibrated image depicting a moving ball over a known background, and show that motion blurred ball images, usually unwelcome in computer vision, bear more information than a sharp image. We provide techniques for extracting such information ranging from low-level image processing to 3D reconstruction, and present a number of experiments and possible applications, such as ball localization with speed and direction measurement from a single image, and ball trajectory reconstruction from a single long-exposure photograph.	3d reconstruction;autostereogram;color;computer vision;experiment;gaussian blur;high- and low-level;image processing;motion compensation	Vincenzo Caglioti;Alessandro Giusti	2009	Computer Vision and Image Understanding	10.1016/j.cviu.2008.01.008	3d reconstruction;computer vision;edge detection;image processing;computer science;sport;motion estimation;computer graphics (images)	Vision	50.13079169125377	-57.0613578854212	154333
434c29310bb92aa81fd057c7c7e82ccf913ec481	high dynamic range global mosaic	modelizacion;radiance;vision ordenador;image processing;depth of field;procesamiento imagen;image multiple;imagen multiple;profondeur champ;traitement image;luminancia energetica;multiple image;computer vision;modelisation;profundidad campo;vision ordinateur;luminance energetique;high dynamic range;modeling;reduction method	This paper presents a global approach for constructing high dynamic range mosaic from multiple images with large exposure differences. By relating image intensities to scene radiances with a convenient distortion model, we robustly estimated registration parameters for the high dynamic range global mosaic (HDRGM), simultaneously estimating scene radiances and distortion parameters in a single framework. Also, a simple detail-preserving contrast reduction method is introduced.	distortion;high dynamic range;ncsa mosaic	Dae Woong Kim;Ki-Sang Hong	2006		10.1007/11612032_75	radiance;computer vision;systems modeling;image processing;computer science;depth of field	Vision	51.4263776127784	-57.041415222793766	154435
6cbbf498cc2db6a7eb4af2865eb4066355c1064e	distances based on non-rigid alignment for comparison of different object instances		d(F1,F2) = 〈F1,F2〉 ‖F1‖2 · ‖F2‖2 . Table: Comparison of various distances with and without non-rigid alignment in terms of average precision (AP). The left block uses pure energies, the two blocks in the middle use HOG and WHO features, before and after the alignment. Methods with +λEP make use of the deformation cost. The last two blocks use the coarse to fine method, which yields the best results.	histogram of oriented gradients;information retrieval	Benjamin Drayer;Thomas Brox	2013		10.1007/978-3-642-40602-7_22	procrustes;belief propagation;normalization (statistics);k-nearest neighbors algorithm;artificial intelligence;computer science;pattern recognition	NLP	39.65687993815812	-57.22172609648568	154468
765279ee533fc97acc2fff7dcad30cefbb5f1fad	biometric watermarking based on face recognition	reconnaissance visage;databases;filigranage;digital watermarking;watermarking;metodo adaptativo;object recognition;networks;base donnee;karhunen loeve transformation;learning algorithm;facies;filigrana;algoritmo adaptativo;taux erreur;convolution;biometrie;intruso;authentication;biometrics;database;biometria;base dato;methode adaptative;algorithme apprentissage;authentification;adaptive algorithm;autenticacion;face recognition;algorithme adaptatif;adaptive method;pattern recognition;error rate;facial features;intrus;reconnaissance forme;facial recognition systems;transformation karhunen loeve;learning artificial intelligence;reconocimiento patron;face detection;indice error;algoritmo aprendizaje;modeling;intruder;transformacion karhunen loeve;karhunen loeve transform;apprentissage intelligence artificielle	We describe biometric watermarking procedure based on object recognition for accurate facial signature authentication. An adaptive metric learning algorithm incorporating watermark and facial signatures is introduced to separate an arbitrary pattern of unknown intruder classes from that of known true-user ones. The verification rule of multiple signatures is formulated to map a facial signature pattern in the overlapping classes to a separable disjoint one. The watermark signature, which is uniquely assigned to each face image, reduces the uncertainty of modeling missing facial signature patterns of the unknown intruder classes. The adaptive metric learning algorithm proposed improves a recognition error rate from 2.4% to 0.07% using the ORL database, which is better than previously reported numbers using the Karhunen-Loeve transform, convolution network and the hidden Marcov model. The face recognition facilitates generation and distribution of the watermark key. The watermarking approach focuses on using salient facial features to make watermark signatures robust to various attacks and transformation. The coarse-to-fine approach is presented to integrate pyramidal face detection, geometry analysis and face segmentation for watermarking. We conclude with an assessment of the strength and weakness of the chosen approach as well as possible improvements of the biometric watermarking system.© (2002) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	biometrics;facial recognition system	Takami Satonaka	2002		10.1117/12.465325	computer vision;speech recognition;computer science;artificial intelligence;signature recognition	Vision	44.37308671928051	-59.34837459237948	154660
d4537f458a9c4e2346d230eca7d03ca6130fae6d	fast k-nn classification for multichannel image data	algorithme rapide;analisis imagen;empirical study;classification algorithm;aplicacion;k nearest neighbour rule;transformacion;complexity analysis;imagerie;mri segmentation;segmentation;resonancia magnetica;classification;magnetic resonance image;magnetic resonance image mri segmentation;vecino mas cercano;imagery;magnetic resonance;fast algorithm;exact algorithm;pattern classification;distancia;pattern recognition;plus proche voisin;nearest neighbour;image analysis;imagineria;reconnaissance forme;transformation;reconocimiento patron;distance transform;application;resonance magnetique;analyse image;algoritmo rapido;clasificacion;segmentacion;distance	A new fastandexactalgorithmfor determiningthe -NN classificationof multichannelimagedata,anda new distancetransformalgorithm are described. Complexity analysisand empirical studieswith magneticresonance images(MRI) demonstratetheeffectivenessof thenew classificationalgorithm.	fast fourier transform;k-nearest neighbors algorithm	Simon K. Warfield	1996	Pattern Recognition Letters	10.1016/0167-8655(96)00036-0	transformation;computer vision;biological classification;computer science;artificial intelligence;magnetic resonance imaging;mathematics;distance transform;empirical research;distance;segmentation	Vision	46.79434281858938	-62.706981381232744	154801
5d012f15aaf6b644c3ef6567e6ae566cea423864	direct detection of flow discontinuities by 3d curvature operators	discontinuity;discontinuite;hipersuperficie;operator;modelo 3 dimensiones;occlusion;operador;deteccion;modele 3 dimensions;three dimensional model;oclusion;courbure;detection;campo flujo;flow field;operateur;champ ecoulement;curvatura;curvature;direct detection;discontinuidad;optical field;campo optico;champ optique;hypersurface	Zetzsche, C. and E. Barth, Direct detection of flow discontinuities by 3D curvature operators, Pattern Recognition Letters 12 (1991) 771-779. We present an approach for the direct detection of flow discontinuities which avoids explicit computation of a dense optic flow field. It is based on regarding the time varying image as a hypersurface in four-dimensional space and on using the Gaussian curvature properties of this hypersurface as a direct indicator for the presence of motion discontinuities. An easy to implement, nonlinear operator is suggested and possible extensions of the basic scheme are discussed.	computation;nonlinear system;optical flow;pattern recognition letters	Christoph Zetzsche;Erhardt Barth	1991	Pattern Recognition Letters	10.1016/0167-8655(91)90075-W	hypersurface;topology;optical field;operator;discontinuity;calculus;mathematics;geometry;curvature	Vision	50.64642870938103	-58.626466674605666	154881
f9b3c3e03a98ecd662560d5631c48f45d0e7f698	color correction on digital image based on reference color charts surrounding object	color normalization;illuminant correction;automatic detection;chromatic adaptation;color correction	The image color may deviate from the actual colors of the object due to the lighting conditions and different illumination. Therefore, this paper proposes an algorithm for correcting the colors of digital image in various lighting conditions based on matrix calculations from all reference color charts surrounding the object. The six transformation matrix M for color correction have been calculated from six color charts surrounding the object rather than a single color chart. Then the automatic detection and recognition of the target color charts technique has been performed. Next, the image is divided into small grids. The matrix M elements at all grid's corners were calculated based on distance from each color chart position to the considering grid's corner position. Then, the matrix M elements for each pixel in the considering grid were determined by interpolation from the matrix elements of four corners nearby. Finally, the matrix M for each pixel is applied to complete the color correction. This technique has been tested on a table of 132 colors which taken in four different lighting conditions. The results have shown that the color correction technique can be applied for work that requires accurate color matching as a less costly. For our work, this technique will be applied to the teeth photos in order to match the tooth color with the appropriated dental crowns for further development.	algorithm;chart;color;digital image;grid computing;interpolation;pixel;the matrix;transformation matrix	Chanjira Sinthanayothin;Wisarut Bholsithi;Nonlapas Wongwaen	2016	2016 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)	10.1109/ISPACS.2016.7824683	color gradient;color histogram;false color;rgb color model;computer vision;icc profile;color model;color quantization;color normalization;color depth;color image;geography;high color;color balance;optics;color space;computer graphics (images)	Robotics	52.8062496323724	-55.72180744579294	154915
2b43537c5db9cf23a296c9cf2927e2f4c560d5c3	a novel information entropy shift based image retrieval algorithm	histograms;image retrieval content based retrieval entropy image enhancement image matching;spatial information distribution;color;image matching;information entropy heuristic algorithms image color analysis image retrieval histograms algorithm design and analysis signal processing algorithms;image statistical feature;dynamic margin matching algorithm;image translation;image resizing;information entropy shift;image enhancement;image retrieval algorithm;image color analysis;heuristic algorithms;image translation information entropy shift image retrieval algorithm content based image retrieval image statistical feature spatial information distribution dynamic margin matching algorithm template matching algorithm image resizing;color information entropy image retrieval;entropy;information entropy;signal processing algorithms;content based image retrieval;high efficiency;template matching;content based retrieval;algorithm design and analysis;template matching algorithm;spatial information;color image;image retrieval	In order to solve the problem of content-based image retrieval, this paper defines a new concept of information entropy shift, and proposes a novel image retrieval algorithm based on it. The Information Entropy Shift is defined as the changes of Information Entropy in one direction; it not only describes the statistical feature of an image, but also reflects the spatial information distribution. On the basis of this concept, this paper presents a new dynamic margin matching algorithm. In this algorithm, the matching problem of information entropy shift sequence is transformed to the matching of the characteristic curve of a binary function; the trend of curve changes is used as the feature to match. Besides, the template matching algorithm in audio processing is referred to deal with the problem too. Experimental results show that the new algorithm has the advantage of high efficiency and is robust to image resizing and translation.	algorithm;content-based image retrieval;entropy (information theory);image scaling;template matching	Yan Wang;Kebin Jia	2008	2008 International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIH-MSP.2008.148	algorithm design;computer vision;entropy;template matching;color image;image retrieval;computer science;pattern recognition;histogram;spatial analysis;information retrieval;statistics;entropy	Robotics	39.292271450704305	-60.20900018283965	155054
182a572e0c9069b86a5c389aec40cee07a426658	manufacturing primitive-based object identification using recognition-by-components	topology;surface topology analysis;machining;actual object model indexing;object recognition;manufacturing primitive based object identification;design automation;recognition by components;image segmentation;image databases;lead time reduction;geometry;lead time;automatic generation;actual object model indexing manufacturing primitive based object identification recognition by components lead time surface finish accuracy machining operations primitive based cad system object recognition system range images instantiated machining manufacturing primitives surface topology analysis;accuracy;primitive based cad system;design environment;range image;surface finish;cad cam;indexation;spatial databases;manufacturing;range images;object recognition system;machining operations;instantiated machining manufacturing primitives;product design;surface finishing;object identification;manufacturing machining design automation lead time reduction costs product design surface finishing object recognition image databases spatial databases;object model;image segmentation cad cam object recognition visual databases topology geometry;visual databases	It has been recognized that lead time and costs can be reduced by representing product designs in terms of manufacturing features such as surface finish, accuracy, or machining operations. Usually, a design environment supporting such representations is referred to as a primitive-based CAD system. This paper describes an object recognition system for range images which exploits the primitive-based CAD database information to reduce set up time and accelerate object identification. The heart of our work resides in modeling objects as collections of instantiated machining manufacturing primitives. This permits the implementation of a recognition-bycomponents approach using surface topology analysis. Thus, the main recognition task is broken down into the less stringent ones of primitive identijkation and instantiation, followed by the actual object model indexing. The result is faster recognition as well as automatic generation of object models from the CAD’S output databases.	computer-aided design;database;feature recognition;outline of object recognition;universal instantiation;uptime	Leda Villalobos;Francis L. Merat	1997		10.1109/ROBOT.1997.614378	surface finish;computer vision;simulation;object model;machining;computer science;engineering;cognitive neuroscience of visual object recognition;accuracy and precision;3d single-object recognition;image segmentation;manufacturing;product design;engineering drawing;computer-aided technologies	Robotics	41.52019145665895	-58.014621583340386	155074
1788cb9b3289546cb70969f8cba16e677906a43b	image matching optimization based on taguchi method and adaptive spatial clustering with sift features	image matching;sift;spatial clustering;taguchi method	A novel image matching algorithm based on both Taguchi method and spatial clustering is proposed to optimize the Scale Invariant Feature Transform (SIFT) matching results. To improve the matching accuracy, adaptive spatial clustering is used. What is more, in order to get the fitting parameters to balance matching accuracy and quantity, Taguchi method is adopted to optimize the key parameter combination including the ratio threshold of Euclidean distance and the constrain parameters in the process of adaptive spatial clustering. Moreover, signal-to-noise ratio (SNR) results are analyzed by variance to get the effect factor which is taken as the basis for the selection of optimized parameters. The optimum parameters combination is obtained eventually. The final experimental results show that the matching quality based on SIFT feature are improved significantly.	image registration;taguchi methods	Yuan Xu;Hehui Lu;Defu Zhou;Jiongbin Zheng;Jianguo Zhang	2017	IJPRAI	10.1142/S021800141755014X	computer vision;mathematical optimization;taguchi methods;computer science;machine learning;pattern recognition;scale-invariant feature transform;mathematics;statistics	Vision	44.612991395720194	-65.01841058885118	155133
e52793b0d797470e23802053149dc33cc9728517	motion estimation and segmentation	moving image;estimacion;movimiento;line process;modelo markov;markov random fields;motion estimation;motion boundaries;segmentation;motion;imagen movil;approche deterministe;markov random field;image mobile;algorithme;deterministic approach;algorithm;mean field;markov model;estimation;campo flujo;mean field techniques;flow field;mouvement;enfoque determinista;champ ecoulement;optical flow;optical field;modele markov;campo optico;champ optique;segmentacion;algoritmo;timing	In the general structure-from-motion (SFM) problem involving several moving objects in a scene, the essential first step is to segment moving objects independently. We attempt to deal with the problem of optical flow estimation and motion segmentation over a pair of images. We apply a mean field technique to determine optical flow and motion boundaries and present a deterministic algorithm. Since motion discontinuities represented by line process are embedded in the estimation of the optical flow, our algorithm provides accurate estimates of optical flow especially along motion boundaries and handles occlusion and multiple motions. We show that the proposed algorithm outperforms other well-known algorithms in terms of estimation accuracy and timing.	deterministic algorithm;embedded system;motion estimation;optical flow;structure from motion	Tina Yu Tian;Mubarak Shah	1996	Machine Vision and Applications	10.1007/BF01246637	computer vision;estimation;optical field;quarter-pixel motion;computer science;mean field theory;motion;motion estimation;optical flow;geometry;markov model;motion field;deterministic system;segmentation	Vision	48.939927004888375	-57.09880200240252	155220
f801b33fd7be2ca95f9294f2f110806c183f8cc3	registration of multimodality medical images using a region overlap criterion	medical image	Matching images is an important process allowing one to relate pieces of information available in several images of a given scene. It involves two steps: registration, in which image differences induced by scene and detector positions are discarded, and comparison, in which image differences induced by actual scene modifications are estimated. Registration and comparison techniques depend on image content; thus no general methodology for matching images has been proposed. We present a unified description of existing registration methods. A model of image information is proposed and applied to registration, leading to a formulation of the registration problem in agreement with the intuitive view of it. We define a new criterion based on the above formulation, which maximizes the overlap of reglstrable regions in the image pair. Finally, an experimental evaluation of the proposed criterion (for multimodality medical images) is reported. e 1992 Academic press, tnc.		Pascale Gerlot-Chiron;Yves Bizais	1992	CVGIP: Graphical Model and Image Processing	10.1016/1049-9652(92)90024-R	homography;computer vision;computer science;image registration;data mining;multimedia	Vision	53.18711842093168	-54.224533904345385	155332
44ee917bc7f2ed41550bdd6e259fe2f2b1ebd17b	stereokinematic analysis of visual data in active convergent stereoscopy	viewing system;vision ordenador;sistema punteria;modele mathematique;vision estereoscopica;vision stereoscopique;modelo matematico;computer vision;systeme visee;mathematical model;vision ordinateur;stereopsis;kineopsis;active vision	The core contribution of this study is a mathematical model of combination of stereopsis and kineopsis under active viewing, a model to serve as a basis for algorithms implemental of active stereokinematic analysis of visual data. The model is specified by two main groups of equations: (A) The fundamental equations of interpretation: they relate the unknowns of perception (depth and motion in space) to image variables (image positions and optical velocities) and viewing system control variables (angles of stereoscopic convergence and angular velocities of viewing system movement), in a neck-eyes as well as a neck-less mode of active viewing, (B) The equations of control regimes: they specify trategies of control of stereoscopic viewing system movement (neck-eyes and neck-less modes) in the form of expressions integratable with the fundamental equations. The presentation of the model is prefaced by a motivational discussion, and the model's prerequisite background. It is postfaced by an account of some of its algorithmic implications. © 1998 Elsevier Science B.V. All fights reserved.	algorithm;angularjs;mathematical model;stereopsis;stereoscopy	Amar Mitiche;Jean-Michel Létang	1998	Robotics and Autonomous Systems	10.1016/S0921-8890(98)00033-5	computer vision;simulation;active vision;computer science;stereopsis;mathematical model	Robotics	50.84967444887801	-58.382007086195074	155341
017cc34abe8d2184ebfa36f54701c0dfe8dfe236	clipart image retrieval system using shape information	busqueda informacion;recherche image;information retrieval;shape measurement;similitude;recherche information;similarity;similitud;information system;mesure forme;systeme information;sistema informacion;image retrieval	The current paper presents a method of extracting shape information from clipart images and then measuring the similarity between different clipart images using the extracted shape information. Previous methods of extracting shape information can be classified into outline-based methods and region-based methods. Included in the former category, the proposed method expresses the convex and concave aspects of an outline using the ratio of a rectangle. Experimental results demonstrated that the proposed method is superior in expressing shape information than previous outline-based feature methods.	image retrieval	Chang-Gyu Choi;Seongil Cheong;Yongseok Chang;Sung-Ho Kim	2004		10.1007/978-3-540-24655-8_83	computer vision;similarity;image retrieval;computer science;artificial intelligence;similitude;information retrieval;information system	Vision	43.51877641452148	-61.33308289127331	155514
e5e59a16272a994efa5098a09275e0ea97918054	region-based representations of image and video: segmentation tools for multimedia services	video object;partition method;estimation mouvement;image coding;image segmentation;multimedia;articulo sintesis;image processing;data compression;article synthese;indexation automatique;structure arborescente;estimacion movimiento;procesamiento imagen;motion estimation;video segmentation;segmentation;code standards;image segmentation mpeg 4 standard mpeg 7 standard indexing motion estimation video compression pixel layout partitioning algorithms image coding;feature space;traitement image;image coding multimedia communication code standards telecommunication standards image segmentation image representation video coding;video coding;methode partition;senal video;signal video;estructura arborescente;image representation;telecommunication standards;indexation;tree structure;object tracking;multimedia communication;object extraction;automatic indexing;region based retrieval region based representations image video segmentation tools multimedia services mpeg 4 standard mpeg 7 standard processing steps feature spaces decision spaces decision algorithms transition based strategies homogeneity based strategies partition tree representation similarity estimation step partition creation step spatial segmentation motion estimation region based coding semantic object extraction;video signal;metodo particion;compresion dato;review;multimedia services;article;segmentacion;compression donnee;indizacion automatica	This paper discusses region-based representations of image and video that are useful for multimedia services such as those supported by the MPEG-4 and MPEG-7 standards. Classical tools related to the generation of the region-based representations are discussed. After a description of the main processing steps and the corresponding choices in terms of feature spaces, decision spaces, and decision algorithms, the state of the art in segmentation is reviewed. Mainly tools useful in the context of the MPEG-4 and MPEG-7 standard are discussed. The review is structured around the strategies used by the algorithms (transition based or homogeneity based) and the decision spaces (spatial, spatio-temporal, and temporal). The second part of this paper proposes a partition tree representation of images and introduces a processing strategy that involves asimilarity estimationstep followed by apartition creation step. This strategy tries to find a compromise between what can be done in a systematic and universal way and what has to be application dependent. It is shown in particular how a single partition tree created with an extremely simple similarity feature can support a large number of segmentation applications: spatial segmentation, motion estimation, region-based coding, semantic object extraction, and region-based retrieval.	algorithm;image segmentation;mpeg-7;motion estimation;video	Philippe Salembier;Ferran Marqués	1999	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.809153	data compression;computer vision;feature vector;image processing;computer science;theoretical computer science;video tracking;motion estimation;multimedia;image segmentation;tree structure;scale-space segmentation;segmentation	ML	47.59925400055987	-54.62079797430552	155562
3f4671333df2c96104df0e8fd8b2fa304b96b019	a robust shape retrieval method based on hough-radii	centro gravitacional;base donnee;point shape;centre gravite;occlusion;recherche image;shape descriptor;generalized hough transform;competitividad;center of mass;occultation;forme ponctuelle;forma puntual;solution similitude;database;base dato;oclusion;similarity solution;intelligence artificielle;shape measurement;transformacion hough;effet dimensionnel;similitude;reference point;solucion semejanza;shape similarity;size effect;similarity;competitiveness;invariante;artificial intelligence;hough transformation;transformation hough;rotacion;shape retrieval;inteligencia artificial;similitud;efecto dimensional;ocultacion;rotation;competitivite;content based retrieval;mesure forme;recherche par contenu;invariant;image retrieval	A novel shape similarity retrieval algorithm (Hough-Radii) for 2-D objects is presented. The method uses a polar transformation of the contour points to get the shape descriptor that is invariant to translation, rotation and scaling. We take the maximum point in the generalized Hough transform (GHT) mapping array as the reference point for polar transform that is different from the traditional Centroid-Radii method where the geometric centre was taken as the origin. The effectiveness of our algorithm is illustrated in the retrieval of two databases of 99 and 216 shapes provided by Sebastian et al. The experimental results show the competitiveness of our approach to some others especially in the retrieval of partially occluded and missing images.	hough transform	Xu Yang;Xin Yang	2006		10.1007/11941439_70	hough transform;center of mass;computer vision;topology;similarity;occultation;rotation;image retrieval;computer science;similitude;invariant;mathematics;geometry	Vision	43.69483833745132	-60.71928013146155	155833
18dabd13f7017dbb40f50922d67942b3c8435e3a	an efficient video indexing and retrieval algorithm using the luminance field trajectory modeling	content management;busqueda informacion;modelizacion;on line systems;histograms;evaluation performance;video frame luminance field;algoritmo busqueda;performance evaluation;subspace learning;learning;information retrieval;image matching;algorithme recherche;presentation de la ligne apellante;evaluacion prestacion;luminance;simulation;search algorithm;identificacion de llamada entrante;indexing video sequences robustness image retrieval principal component analysis computational modeling content management shape histograms statistics;video retrieval;pregunta documental;simulacion;video sequences;metodo subespacio;video sequence representation;video clip search video trajectory indexing video retrieval algorithm luminance field trajectory modeling personal video repository video search solution video sequence representation lower dimensional representation video frame luminance field video matching scheme;methode sous espace;aprendizaje;modelisation;video indexing;brightness;video retrieval brightness image matching image representation image sequences indexing;accuracy;apprentissage;computational modeling;precision;video retrieval modeling subspace learning video indexing;senal video;shape;signal video;indexing;recherche information;image representation;systeme en ligne;principal component analysis;indexation;image sequence;indizacion;statistics;luminance field trajectory modeling;query;subspace method;video signal;personal video repository;robustness;video trajectory indexing;secuencia imagen;video matching scheme;video search solution;modeling;calling line identification presentation;video clip search;video search;sequence image;requete;video retrieval algorithm;lower dimensional representation;image sequences;image retrieval;luminancia	With the phenomenal growth of the online and personal video repositories, an efficient and robust example-based video search solution is required to support applications like query by clip, query by capture, and repeated clip detection. In this letter, video sequences are represented as temporal trajectories via scaling and lower dimensional representation of the video frame luminance field, and a video trajectory indexing and matching scheme is developed to support video clip search. Simulation results demonstrate that the proposed approach achieves excellent performance in both response speed and precision-recall accuracy.	algorithm;experiment;image formation;image scaling;query by example;simulation;video clip	Li Gao;Zhu Li;Aggelos K. Katsaggelos	2009	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2009.2026813	video compression picture types;computer vision;image retrieval;computer science;video tracking;accuracy and precision;block-matching algorithm;multimedia;smacker video;video post-processing;statistics;multiview video coding;computer graphics (images)	Vision	45.42803937109932	-56.47702253232444	155905
3c28462bd9996c18d6ad54fc6e3780eb7b88fb71	efficient gabor filter design for texture segmentation	filtering;filtrage;image segmentation;image processing;analisis textura;complexite calcul;filtrado;procesamiento imagen;texture segmentation;segmentation;curva gauss;traitement image;algorithme;algorithm;gabor filter;complejidad computacion;texture analysis;fourier transformation;computational complexity;transformation fourier;loi normale;analyse texture;segmentacion;gaussian distribution;transformacion fourier;algoritmo	Gabor filters have been successfully applied to a broad range of image processing tasks. The present paper considers the design of a single filter to segment a two-texture image. A new efficient algorithm for Gabor-filter design is presented, along with methods for estimating filter output statistics. The algorithm draws upon previous results that showed that the output of a Gabor-filtered texture is modeled well by a Rician distribution. A measure of the total output power is used to select the center frequency of the filter and is used to estimate the Rician statistics of the Gabor-filtered image. The method is further generalized to include the statistics of postfiltered outputs that are generated by a Gaussian filtering operation following the Gabor filter. The new method typically requires an order of magnitude less computation to design a filter than a previously proposed method. Experimental results demonstrate the efficacy of the method. Image segmentation Texture Gabor filters Rician statistics Texture segmentation Image statistics Texture analysis	algorithm;algorithmic efficiency;autocorrelation;computation;emoticon;filter (signal processing);filter design;gabor filter;gaussian blur;image processing;image segmentation;kalman filter;kernel (operating system);portable document format;spectral density;statistical model;synthetic intelligence;window function	Thomas P. Weldon;William E. Higgins;Dennis F. Dunn	1996	Pattern Recognition	10.1016/S0031-3203(96)00047-7	normal distribution;filter;adaptive filter;fourier transform;computer vision;mathematical optimization;kernel adaptive filter;image processing;computer science;root-raised-cosine filter;mathematics;image segmentation;filter design;prototype filter;computational complexity theory;segmentation;composite image filter;algorithm;statistics;m-derived filter	Vision	51.7528366791569	-65.90976312383894	156347
b5d79ada702d9a65b155743a3e1f8f5367f6c1d6	locally embedded linear subspaces for efficient video indexing and retrieval	video sequence;high dimensionality;embedded linear subspace;information retrieval;image matching;geometry;video retrieval;video sequences;manifold learning;indexing extraterrestrial measurements video sequences principal component analysis content based retrieval geometry shape pixel information retrieval computer science;video indexing;shape;indexing;principal component analysis;pixel;indexation;geometry matching algorithm embedded linear subspace video indexing content based video retrieval video sequence linear transformation;distance metric;component analysis;linear transformation;video retrieval content based retrieval image matching image sequences indexing;computer science;content based video retrieval;extraterrestrial measurements;manifold learning video retrieval high dimensional indexing component analysis;content based retrieval;high dimensional indexing;geometry matching algorithm;image sequences	Efficient Indexing is a key us content-based video retrieval solutions. In this paper we represent video sequences as traces via scaling and linear transformation of the frame luminance field. Then an appropriate lower dimensional subspace is identified for video trace indexing. We also develop a trace geometry matching algorithm for retrieval based on average projection distance with a locally embedded distance metric. Simulation results demonstrated the high accuracy and very fast retrieval speed for the proposed solution	algorithm;embedded system;graph embedding;image noise;image scaling;information retrieval;simulation;tracing (software)	Zhu Li;Li Gao;Aggelos K. Katsaggelos	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262893	computer vision;search engine indexing;metric;shape;computer science;pattern recognition;mathematics;linear map;nonlinear dimensionality reduction;information retrieval;pixel;principal component analysis	Vision	39.95757120593343	-59.182696576027446	156425
da9ea73fe3fc6d26e0d43f11236c53f062c17598	facial geometry estimation using photometric stereo and profile views	shape estimation;iterative refinement;three dimensional;energy function;image generation;face recognition;photometric stereo;ground truth;high speed	This paper presents a novel method for estimating the three-dimensional shape of faces, facilitating the possibility of enhanced face recognition. The method involves a combined use of photometric stereo and profile view information. It can be divided into three principal stages: (1) An initial estimate of the face is obtained using four-source high-speed photometric stereo. (2) The profile is determined from a side-view camera. (3) The facial shape estimation is iteratively refined using the profile until an energy functional is minimised. This final stage, which is the most important contribution of the paper, works by continually deforming the shape estimate so that its profile is exact. An energy is then calculated based on the difference between the raw images and synthetic images generated using the new shape estimate. The surface normals are then adjusted according to energy until convergence. Several real face reconstructions are presented and compared to ground truth. The results clearly demonstrate a significant improvement in accuracy compared to standard photometric stereo.	facial recognition system;photometric stereo	Gary A. Atkinson;Melvyn L. Smith;Lyndon N. Smith;Abdul R. Farooq	2009		10.1007/978-3-642-01793-3_1	facial recognition system;three-dimensional space;computer vision;photometric stereo;ground truth;computer science;computer graphics (images)	Vision	53.141950422002935	-53.18558610116482	156442
2c273461d4bb15624e25c53a3063eff63e46b1c7	detection of elongated structures by using invertible angular representations of scalar images	image reconstruction;gaussian processes;image segmentation;image analysis;anisotropic diffusion;apertures;scale space;anisotropic magnetoresistance;integral transforms;pixel;feature extraction;kernel;visual system	A unitary approach for locally apertured orientation analysis of 2D and 3D scalar images is proposed. The size of the local aperture (the scale) needed for the orientation representation induces in general a loss of spatial acuity, or blur. Our construction permits a compensation of the blur by a reconstruction procedure. For this purpose, a special scale-dependent orientation bundle (map of the visual space into a function of both position and orientation) is built from the local Gaussian-derivatives jet of a scalar image. In this construction there is an invertible relation between the orientation bundle and the original image in the space domain. This invertible transformation is used to regain the original acuity in the spatial domain after analyzing orientation features at any given scale. This type of orientation encoding might contribute to understand both the role of orientation columns and the hyper-acuity phenomenon in biological visual systems. The approach turns out to be highly effective for the detection of elongated structures and for removal of elongated artifacts in 2D images. The results from the detection task can be enhanced by applying an anisotropic diffusion of the orientation field and thus closing missing contour segments.	scalar processor	Stiliyan Kalitzin;Bart M. ter Haar Romeny;Max A. Viergever	1998			computer vision;scale space;topology;visual system;feature extraction;computer science;mathematics;geometry;anisotropic diffusion;integral transform	Robotics	51.7803568325625	-61.00507465273265	156537
a322c2af33762effdd798ba9c8c6975018f05f64	a novel method for gaze tracking by local pattern model and support vector regressor	gaze;analisis contenido;traitement signal;svr;ppbtf;analisis textura;maquina vector soporte;gaze tracking;lpm;mirada;local binary pattern;texture features;support vector;carta de datos;etat actuel;regard;accuracy;machine vecteur support;content analysis;texture analysis;precision;analisis regresion;binocular vision;feature extraction;mappage;signal processing;state of the art;signal classification;poursuite cible;classification signal;analyse regression;estado actual;regression analysis;mapping;vision binocular;support vector machine;extraction caracteristique;analyse contenu;classification automatique;target tracking;gaze direction;automatic classification;procesamiento senal;clasificacion automatica;analyse texture;vision binoculaire;eye gaze	This paper presents a novel eye gaze tracking method with allowable head movement based on a local pattern model (LPM) and support vector regressor (SVR). The LPM, a combination of improved pixel-pattern-based texture feature (PPBTF) and local-binary-pattern texture feature (LBP), is employed to calculate texture features from the characteristics of the eyes and a new binocular vision scheme is adopted to detect the spatial coordinates of the eyes. The texture features from LPM and the spatial coordinates together are fed into support vector regressor (SVR) to match a gaze mapping function, and subsequently to track gaze direction under allowable head movement. The experimental results show that the proposed approach results in better accuracy in estimating the gaze direction than the state-of-the-art pupil center corneal reflection (PCCR) method.	eye tracking	Huchuan Lu;Guo-Liang Fang;Chao Wang;Yen-Wei Chen	2010	Signal Processing	10.1016/j.sigpro.2009.10.014	support vector machine;computer vision;speech recognition;content analysis;computer science;machine learning;signal processing;accuracy and precision	Vision	45.7777925098672	-58.77185890654499	156607
f31cd51c87e64bfdd5c2c9259ae40b5add8cfcc3	locatization of human eyes based on a series of binary images	eye;human eyes localization;eyeball detection;eye candidates selection;statistical analysis;geometrical constraints;valley map;image segmentation;binary images;binary image sequence;eyes image segmentation;image sequences;object detection;face databases;grayscale face image;statistical method;arithmetical morphology method;statistics;gray scale;binary image;morphology;visual system;face detection	A new method for eyes localization is presented. By incorporating some eye geometrical constraints, our method includes such procedures as eyes image segmentation, eye candidates selection and eyeball detection. In order to locate the eyes more precisely, the valley map transformed from the grayscale face image using an arithmetical morphology method is successively binarized with a series of threshold values determined adaptively, and many possible eyeball candidates are extracted from them. The final position of the two eyes is obtained using a statistical method. Experimental results on AR and Yale face databases show that a locating rate of over 94% and an average locating disparity of below 2 pixels can be achieved	arithmetical hierarchy;binary image;binocular disparity;database;grayscale;image segmentation;mathematical morphology;pixel	Jiatao Song;Jilin Liu;Zheru Chi;Wei Wang	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		computer vision;binary image;computer science;pattern recognition;statistics;computer graphics (images)	Robotics	43.18959328458283	-65.51716642659008	156634
74909b029d71589006bbd9ba12cface2b6c82fe3	an active contour model guided by lbp distributions	modelizacion;vision ordenador;active contour;image segmentation;analisis estadistico;image processing;information extraction;edge detection;texture image;procesamiento imagen;metric;texture segmentation;intelligence artificielle;probabilistic approach;local binary pattern;traitement image;similitude;image texture;computer vision;deteccion contorno;modelisation;detection contour;statistical analysis;enfoque probabilista;approche probabiliste;analyse statistique;segmentation image;similarity;artificial intelligence;metrico;vision ordinateur;inteligencia artificial;similitud;modeling;similarity measure;metrique;active contour model	The use of active contours for texture segmentation seems rather attractive in the recent research, indicating that such methodologies may provide more accurate results. In this paper, a novel model for texture segmentation is presented, combining advantages of the active contour approach with texture information acquired by the Local Binary Pattern (LBP) distribution. The proposed LBP scheme has been formulated in order to capture regional information extracted from distributions of LBP values, characterizing a neighborhood around each pixel, instead of using a single LBP value to characterize each pixel. The log-likelihood statistic is employed as a similarity measure between the LBP distributions, resulting to more detailed and accurate segmentation of texture images.	active contour model;belief propagation;binary pattern (image generation);contour line;display resolution;local binary patterns;pixel;similarity measure	Michalis A. Savelonas;Dimitrios K. Iakovidis;Dimitrios E. Maroulis;Stavros A. Karkanis	2006		10.1007/11864349_18	computer vision;local binary patterns;image processing;computer science;machine learning;pattern recognition;active contour model;mathematics;information extraction	Vision	45.17553317740241	-62.208585991737756	156810
9c99b4e51411a72070e4ab13721e36a6f997b37d	adaptive non-linear intensity mapping based salient region extraction	contextual texture;feature extraction;salient map;salient region;visual attention;bottom up;human perception	Salient Region Extraction provides an alternative methodology to image description in many applications such as adaptive content delivery and image retrieval. In this paper, we propose a robust approach to extracting the salient region based on bottom-up visual attention. The main contributions are twofold: 1) Instead of the feature parallel integration, the proposed saliencies are derived by serial processing between texture and color features. Hence, the proposed approach intrinsically provides an alternative methodology to model attention with low implementation complexity. 2) A constructive approach is proposed for rendering an image by a non-linear intensity mapping, which can efficiently eliminate high contrast noise regions in the image. And then the salient map can be robustly generated for a variety of nature images. Experiments show that the proposed algorithm is effective and can characterize the human perception well.		Congyan Lang;De Xu;Shuoyan Liu;Ning Li	2009	IEICE Transactions		computer vision;content analysis;feature extraction;image retrieval;computer science;artificial intelligence;machine learning;signal processing;top-down and bottom-up design;texture;implementation;perception;algorithm;serial memory processing	Visualization	41.88352524318412	-61.69891514113281	156877
d14d8f8a12eaf6c92848ab7810bbbe10ba7dcf71	fuzzy morphological polynomial image representation	signal image and speech processing;quantum information technology spintronics;image representation	A novel signal representation using fuzzy mathematical morphology is developed. We take advantage of the optimum fuzzy fitting and the efficient implementation of morphological operators to extract geometric information from signals. The new representation provides results analogous to those given by the polynomial transform. Geometrical decomposition of a signal is achieved by windowing and applying sequentially fuzzy morphological opening with structuring functions. The resulting representation is made to resemble an orthogonal expansion by constraining the results of opening to equate adapted structuring functions. Properties of the geometric decomposition are considered and used to calculate the adaptation parameters. Our procedure provides an efficient and flexible representation which can be efficiently implemented in parallel. The application of the representation is illustrated in data compression and fractal dimension estimation temporal signals and images.	data compression;fractal dimension;mathematical morphology;opening (morphology);parallel computing;polynomial	Chin-Pan Huang;Luis F. Chaparro	2010	EURASIP J. Adv. Sig. Proc.	10.1155/2010/914921	computer vision;pyramid;discrete mathematics;theoretical computer science;machine learning;mathematics;algorithm	Vision	51.75880480738216	-63.960344625435646	156895
6008675c17fb6c6b3c05bff7960624a00a6609b2	subtrajectory-based video indexing and retrieval	analyse symbolique;modele geometrique;trajectoire;motion control;multimedia;image processing;recherche image;analisis simbolico;database;procesamiento imagen;base dato;courbure;segmentation;indexing and retrieval;effet dimensionnel;traitement image;commande mouvement;video indexing;control movimiento;analyse syntaxique;trajectory;senal video;signal video;indexing;analisis sintaxico;object oriented;size effect;syntactic analysis;indexation;indizacion;base de donnees;video signal;curvatura;oriente objet;curvature;trayectoria;symbolic analysis;efecto dimensional;orientado objeto;segmentacion;geometrical model;symbolic representation;image retrieval;modelo geometrico	This paper proposes an approach for retrieving videos based on object trajectories and subtrajectories. First, trajectories are segmented into subtrajectories according to the characteristics of the movement. Efficient trajectory segmentation relies on a symbolic representation and uses selected control points along the trajectory. The selected control points with high curvature capture the trajectory various geometrical and syntactic features. This symbolic representation, beyond the initial numeric representation, does not suffer from scaling, translation or rotation. Then, in order to compare trajectories based on their subtrajectories, several matching strategies are possible, according to the retrieval goal from the user. Moreover, trajectories can be represented at the numeric, symbolic or the semantic level, with the possibility to go easily from one representation to another. This approach for indexing and retrieval has been tested with a database containing 2500 trajectories, with promising results.	bluetooth;control point (mathematics);database;image scaling;longest common subsequence problem;matching (graph theory)	Thi-Lan Le;Alain Boucher;Monique Thonnat	2007		10.1007/978-3-540-69423-6_41	motion control;computer vision;search engine indexing;image processing;image retrieval;computer science;trajectory;theoretical computer science;parsing;curvature;symbolic data analysis;programming language;object-oriented programming;segmentation;algorithm	AI	45.08677242918764	-57.70302983532067	157002
3a86f60f361ff1f268bf96c12aa0023428ff476f	object recognition and tracking for remote video surveillance	moving object;nonlinear filters;eficacia sistema;description systeme;object recognition;mathematical morphology;vision ordenador;poursuite optique;system description;video surveillance;feature extraction object recognition video signal processing surveillance computational complexity statistical analysis mathematical morphology image thinning nonlinear filters kalman filters image sequences;filtro kalman;image processing;forme onde;video signal processing;surveillance;real time;filtre kalman;kalman filters;performance systeme;procesamiento imagen;kalman filter;indexing terms;system performance;noise robustness;traitement image;persecucion optica;experimental result;computer vision;remote supervision;forma onda;senal video;statistical analysis;signal video;analisis morfologico;optical tracking;computational complexity;telesurveillance;feature extraction;temps reel;object tracking;object recognition video surveillance skeleton image analysis real time systems computational complexity noise robustness image recognition image databases spatial databases;morphological analysis;resultado experimental;pattern recognition;video signal;analyse morphologique;tiempo real;vision ordinateur;descripcion sistema;waveform;reconnaissance forme;reconocimiento patron;resultat experimental;image thinning;extended kalman filter;feature extraction remote video surveillance statistical morphological skeleton real time object tracking real time object recognition low computational complexity localization accuracy noise robustness analytical approximation skeleton function model objects database extended kalman filter geometric characteristics experiments video based applications image sequences;vigilancia a distancia;image sequences	A system for real-time object recognition and tracking for remote video surveillance is presented. In order to meet real-time requirements, a unique feature, i.e., the statistical morphological skeleton, which achieves low computational complexity, accuracy of localization, and noise robustness has been considered for both object recognition and tracking. Recognition is obtained by comparing an analytical approximation of the skeleton function extracted from the analyzed image with that obtained from model objects stored into a database. Tracking is performed by applying an extended Kalman filter to a set of observable quantities derived from the detected skeleton and other geometric characteristics of the moving object. Several experiments are shown to illustrate the validity of the proposed method and to demonstrate its usefulness in video-based applications.	closed-circuit television;outline of object recognition	Gian Luca Foresti	1999	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.795058	kalman filter;computer vision;simulation;speech recognition;image processing;computer science;video tracking;3d single-object recognition	Vision	47.644096721200384	-57.74405129635744	157100
fa46cc48724c9c7da52c1ebeb9a27f7d172ea106	segmentation of textured images and gestalt organization using spatial/spatial-frequency representations	traitement signal;filtering;vision ordenador;filtrage;early vision;human vision;gestalt organization;image processing;grouping;analisis textura;texture segmentation low level vision early vision preattentive vision pattern recognition textured images gestalt organization spatial frequency representations clustering grouping spectrogram difference of gaussians representation gabor representation wigner distribution joint resolution;difference of gaussians representation;gabor representation;spectrogram;estudio comparativo;filtrado;procesamiento imagen;gestalt;texture segmentation;segmentation;indexing terms;traitement image;distribution wigner;computer vision;etude comparative;representation dog;texture analysis;preattentive vision;clustering;wigner distribution;signal processing;comparative study;textured images;filtre gabor;statistics;pattern recognition;statistics pattern recognition;vision ordinateur;classification automatique;low level vision;automatic classification;procesamiento senal;clasificacion automatica;spatial frequency representations;analyse texture;image segmentation computer vision humans spectrogram taxonomy testing frequency gaussian distribution stochastic processes surface texture;joint resolution;segmentacion;spatial frequency	The generic issue of clustering/grouping is addressed. Recent research, both in computer and human vision, suggests the use of joint spatial/spatial-frequency (s/sf) representations. The spectrogram, the difference of Gaussians representation, the Gabor representation, and the Wigner distribution are discussed and compared. It is noted that the Wigner distribution gives superior joint resolution. Experimental results in the area of texture segmentation and Gestalt grouping using the Wigner distribution are presented, proving the feasibility of using s/sf representations for low-level (early, preattentive) vision. >	gestalt psychology	Todd R. Reed;Harry Wechsler	1990	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.41379	filter;computer vision;speech recognition;index term;image processing;computer science;wigner distribution function;spectrogram;comparative research;signal processing;pattern recognition;mathematics;spatial frequency;cluster analysis;segmentation	Vision	45.971739251976494	-62.44318919062707	157243
7b955d097fcc4e934f6238bcc5452d71679d0d0d	data fusion for photorealistic 3d models	image scanners;qa75 electronic computers computer science szamitastechnika;analisis imagen;modelizacion;image tridimensionnelle;image processing;szamitogeptudomany;analisis forma;etat surface;texture image;texture mapping;procesamiento imagen;image optique;data fusion;traitement image;image texture;surface conditions;registro imagen;modelisation;3d model;optical imaging;flattening;recalage image;estado superficie;aplanamiento;fusion donnee;image registration;surface model;imagen optica;tridimensional image;image analysis;pattern analysis;synthetic data;fusion datos;modeling;analyse image;scanneur image;optical image;analyse forme;imagen tridimensional;aplatissement	This study aims at building photorealistic 3D models of realworld objects. We discuss the problem of combining a 3D textureless model obtained by 3D scanner, with optical images that provide textural information of the object. Recently, we have proposed a novel method to register an uncalibrated image pair to a 3D surface model. After registration, the images are mapped to the surface. However, as the images show different parts of the objects, partial overlapping textures can only be extracted from them. Combining the images into a complete texture map that covers the entire object is not trivial. We present a method to build photorealistic 3D models that includes algorithms for data registration and for merging multiple texture maps using surface flattening. Experimental results on real and synthetic data are shown.	3d modeling;3d scanner;algorithm;display resolution;genetic algorithm;graphics pipeline;image scanner;loss function;map;photo-consistency;polygonal modeling;synthetic data;synthetic intelligence;texture mapping	Zsolt Jankó;Dmitry Chetverikov	2005		10.1007/11556121_30	image texture;texture mapping;computer vision;image analysis;systems modeling;image processing;computer science;image registration;optical imaging;sensor fusion;flattening;synthetic data;computer graphics (images)	Vision	50.83089185066512	-57.33692121308125	157363
1cb150e67c2d2fc01a70a4a84f6f8e2772d3ecaf	a remote diagnosis system for rotating machinery using virtual reality	cyberspace;tecnologia electronica telecomunicaciones;tele robotics;difference operator;realite virtuelle;realidad virtual;2d 3d matching;maintenance;computer graphics;image matching;virtual reality;robotics;classical solution;computer graphic;col;internet;ciberespacio;diagnostic panne;fault diagnostic;diagnostico pana;remote maintenance;mantenimiento;robotica;robotique;tecnologias;grupo a;grafico computadora;cyberespace;infographie;appariement image	It is important to look for alternative forms of physical movement of people and equipment in order to assure diagnosis and maintenance tasks, especially in an environment where workers are subject to danger. An evident and classical solution is the use of tele-operation and tele-robotics. If tele-operation helps to solve real and technical problems, it is still unable to assure appropriate remote diagnosis and maintenance. The use of virtual reality techniques with tele-operation can be the solution for effective remote maintenance and diagnosis. We show that inefficiency occurred with the use of tele-operation only in remote maintenance. We introduce our original new system where we use 2D-3D matching and virtual reality techniques with tele-operation to remotely collect machinery vibration data. We explain its structure, implementation and advantages. We finished by experimenting the system, measuring the different operating times and precision and discussing the results.	experiment;robotics;television;virtual reality	Moez Bellamine;Norihiro Abe;Kazuaki Tanaka;Peng Chen;Hirokazu Taki	2004	IEEE Conference on Robotics, Automation and Mechatronics, 2004.	10.1093/ietisy/e88-d.5.894	embedded system;computer vision;the internet;simulation;computer science;artificial intelligence;operating system;virtual reality;robotics;computer graphics;computer security	Robotics	48.28866674292394	-55.8861359120581	157573
a04dcc15acde21223d06b73608e89c79d77dfa25	a fourier interpretation of the frei-chen edge masks	deteccion borde;vision ordenador;image processing;edge detection;procesamiento imagen;traitement image;masque frei chen;computer vision;detection contour;fourier transformation;transformation fourier;vision ordinateur;detecciοn contorno;detection bord;transformacion fourier	The orthogonal set of 3 × 3 Frei-Chen edge detection makes was proposed based on a vector space approach. The way the masks were chosen was not fully explained. We introduce an interpretation of the Frei-Chen masks in terms of eight-dimensional Fourier transform coefficient vectors. The linear transformation between the nine-dimensional Frei-Chen space and the eight-dimensional Fourier transform space is derived. We also propose a modified set of eight orthogonal masks based on the frequency space analysis.	entity–relationship model	Rae-Hong Park	1990	Pattern Recognition Letters	10.1016/0167-8655(90)90016-U	fourier transform;computer vision;edge detection;image processing;computer science;mathematics;geometry	Vision	50.35807582198333	-62.56312938684658	157607
aeec61ef41d55b5c1becfdc00c2e4dbca0e379c0	automatic recognition by gait	databases;baja resolucion;visual databases biometrics access control gait analysis image processing;evaluation performance;image recognition;base donnee;covariate factors;performance evaluation;aplicacion medical;image processing;learning;biometrics access control;biometrie;evaluacion prestacion;gait;biometrics;biometrics image recognition image databases lighting psychology humans testing clothing footwear biomedical imaging;low resolution;database;biometria;basse resolution;base dato;gait recognition;psychology;aprendizaje;etat actuel;qa75 electronic computers computer science;apprentissage;automatic recognition;installation exterieure;uncontrolled illumination;current measurement;instalacion exterior;outdoor installation;gait recognition biometrics covariate factors gait gait analysis gait database;identification;state of the art;gait analysis;pattern recognition;gait database;identificacion;estado actual;clothing;psychologie;gait recognition automatic recognition biometrics uncontrolled illumination gait analysis gait database;medical application;vestidura;reconnaissance forme;reconocimiento patron;psicologia;reconocimiento automatico;reconnaissance automatique;analyse allure;vetement;application medicale;visual databases	Recognizing people by gait has a unique advantage over other biometrics: it has potential for use at a distance when other biometrics might be at too low a resolution, or might be obscured. The current state of the art can achieve over 90% identification rate under situations where the training and test data are captured under similar conditions, while recognition rates with change of clothing, shoe, surface, illumination, and pose usually decrease performance and are the subject of much of the current study. Recognition can be achieved on outdoor data with uncontrolled illumination and at a distance when other biometrics could not be used. We shall show how this position has been achieved, covering most approaches to recognition by gait and the databases on which performance has been evaluated. We shall describe the context of these approaches, show how recognition by gait can be achieved and how current limits on performance are understood. We shall describe results on the most popular database, showing how recognition can handle some of the covariates that can affect recognition. We shall also investigate the supporting literature for this research, since the notion that people can be recognized by gait has support not only in medicine and biomedicine, and also in literature and psychology and other areas. In this way, we shall show that this new biometric has capability and research and application potential in other domains	biometrics;computer performance;database;test data;uncontrolled format string	Mark S. Nixon;John N. Carter	2006	Proceedings of the IEEE	10.1109/JPROC.2006.886018	identification;computer vision;simulation;gait analysis;image resolution;image processing;computer science;clothing;gait;biometrics	Vision	44.66408669025852	-58.636119668858576	157715
da80b64bdfd95d623e9e302f494570f28d144ae7	detection of intensity changes with subpixel accuracy using laplacian-gaussian masks	deteccion borde;mascara;laplacian of gaussian;subpixel accuracy edge detection;gauss formula;image segmentation;image processing;image resolution;gaussian processes;convolution;edge detection;formule gauss;zero crossings of second derivative;franchissement niveau o;laplacian;procesamiento de imagen;information filtering;filters;segmentation;imagen nivel gris;data mining;traitement image;polynomials;algorithme;algorithm;accuracy;laplacien;algorritmo;laplaciano;image edge detection;gaussian approximation;filter;pixel;image niveau gris;full resolution;filtre;zero crossings of second derivative edge operator image processing image segmentation subpixel accuracy edge detection;formula gauss;masque;information filters;grey level image;detection bord;mask;filtro;segmentacion;edge operator;image edge detection gaussian processes convolution filters image resolution polynomials data mining gaussian approximation pixel image processing	We present a system that takes a gray level image as input, locates edges with subpixel accuracy, and links them into lines. Edges are detected by finding zero-crossings in the convolution of the image with Laplacian-of-Gaussian (LoG) masks. The implementation differs markedly from M.I.T.'s as we decompose our masks exactly into a sum of two separable filters instead of the usual approximation by a difference of two Gaussians (DOG). Subpixel accuracy is obtained through the use of the facet model [1]. We also note that the zero-crossings obtained from the full resolution image using a space constant ¿ for the Gaussian, and those obtained from the 1/n resolution image with 1/n pixel accuracy and a space constant of ¿/n for the Gaussian, are very similar, but the processing times are very different. Finally, these edges are grouped into lines using the technique described in [2].	approximation;arabic numeral 0;blob detection;convolution;grayscale;masks;normal statistical distribution;pixel;subpixel rendering	Andres Huertas;Gérard G. Medioni	1986	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.1986.4767838	computer vision;laplace operator;edge detection;image resolution;image processing;filter;blob detection;computer science;gauss–kronrod quadrature formula;gaussian process;mathematics;geometry;accuracy and precision;image segmentation;mask;convolution;segmentation;pixel;polynomial	Vision	48.29598788207268	-65.16024621845037	158000
a368420c6c2a0381b0507b837f9010d795b25e99	a new methodology of illumination estimation/normalization based on adaptive smoothing for robust face recognition	estimation theory;indexing terms;illumination normalization;adaptive weighting illumination estimation illumination normalization adaptive smoothing face recognition retinex theory iterative convolution discontinuity measures conduction function;iterative methods;smoothing methods;face recognition;retinex adaptive smoothing illumination estimation illumination normalization;retinex;smoothing methods estimation theory face recognition iterative methods;adaptive smoothing;lighting smoothing methods robustness face recognition low pass filters convolution reflectivity layout image databases image recognition;illumination estimation	In this paper, we propose a novel method of illumination estimation/normalization based on adaptive smoothing, which is to be applied to robust face recognition. In order to estimate the illumination in the framework of retinex theory, adaptive smoothing is applied based on both iterative convolution and two discontinuity measures. In addition to that, we also introduce a couple of new concepts, which are designed to be suitable especially for face images. One is the new conduction function for adaptive weighting, and the other is the smoothing constraint for more accurate description of real environments. The evaluations, which are conducted based on the Yale face database B, show that the proposed method achieves high recognition rates even in more challenging environments such as the case of using images with the worst case of illumination as a training set.	best, worst and average case;convolution;facial recognition system;iterative method;reflections of signals on conducting lines;smoothing;test set	Young Kyung Park;Joongkyu Kim	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4378913	facial recognition system;computer vision;index term;computer science;machine learning;pattern recognition;mathematics;iterative method;estimation theory;color constancy;statistics;smoothing	Vision	43.54121616455572	-57.79813917156283	158104
e2b48be0c2c4bea80a358d1e01c88bd397dd69ee	statistical modelling of outliers for fast visual search	keypoint matching;outlier statistical modelling;statistical modelling;statistical analysis image retrieval;statistical analysis;geometric consistency check;visual search;goodness of fit test;geometric consistency check outlier statistical modelling visual search keypoint matching goodness of fit test;image retrieval	The matching of keypoints present in two images is an uncertain process in which many matches may be incorrect. The statistical properties of the log distance ratio for pairs of incorrect matches are distinctly different from the properties of that for correct matches. Based on a statistical model, we propose a goodness-of-fit test in order to establish whether two images contain views of the same object. This technique can be used as a fast geometric consistency check for visual search.	statistical model	Skjalg Lepsøy;Gianluca Francini;Giovanni Cordara;Pedro P. B. de Gusmao	2011	2011 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2011.6012184	statistical model;visual search;image retrieval;machine learning;pattern recognition;mathematics;goodness of fit;statistics	Robotics	43.480028413716745	-54.76792685475427	158111
