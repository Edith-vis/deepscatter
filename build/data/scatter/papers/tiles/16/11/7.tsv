id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
55961012acc1f785434c0ac7ee1df2812f947698	a bit stream scalable speech/audio coder combining enhanced regular pulse excitation and parametric coding	libre mercado;estensibilidad;signal image and speech processing;modelizacion;codage parole;evaluation performance;audio signal processing;performance evaluation;methode parametrique;wide band signal;debit information;information transmission;pricing;metodo parametrico;evaluacion prestacion;speech processing;wide band;parametric method;tratamiento palabra;compresion senal;traitement parole;speech coding;acoustic signal processing;fijacion precios;indice informacion;compression signal;marche concurrentiel;large bande;modelisation;audio coding;quantum information technology spintronics;signal large bande;traitement signal audio;signal compression;information rate;banda ancha;traitement signal acoustique;extensibilite;scalability;transmision informacion;open market;codage audiofrequence;transmission information;modeling;senal banda ancha;fixation prix	This paper introduces a new audio and speech broadband coding technique based on the combination of a pulse excitation coder and a standardized parametric coder, namely, MPEG-4 high-quality parametric coder. After presenting a series of enhancements to regular pulse excitation (RPE) to make it suitable for the modeling of broadband signals, it is shown how pulse and parametric codings complement each other and how they can be merged to yield a layered bit stream scalable coder able to operate at different points in the quality bit rate plane. The performance of the proposed coder is evaluated in a listening test. The major result is that the extra functionality of the bit stream scalability does not come at the price of a reduced performance since the coder is competitive with standardized coders (MP3, AAC, SSC).	advanced audio coding;backward compatibility;bitstream;mp3;parametric stereo;sql server compact;scalability;waveform	Felip Riera-Palou;Albertus C. den Brinker	2007	EURASIP J. Adv. Sig. Proc.	10.1155/2007/74064	pricing;dictionary coder;scalability;speech recognition;systems modeling;open market operation;telecommunications;audio signal processing;computer science;speech coding;speech processing	HPC	47.25203214879759	-8.755652386890363	54216
94e7c62673007a659da63a6bf46b814bd7854673	perceived degradation effects in packet speech systems	loss measurement;digital signal processing;degradation;degradation speech digital signal processing loss measurement delay effects humans length measurement airborne radar propulsion signal processing algorithms;packet loss;delay effects;speech;length measurement;human subjects;propulsion;airborne radar;humans;network delay;signal processing algorithms	A packet speech system's sound quality is degraded when packets do not arrive at their destination in a timely fashion. This can happen when packets are lost in a network or when network delay is excessive. Simulation results are reported which measure the effects of such losses and delays on sound quality and intelligibility. Thirty human subjects were asked to listen to the output of a simulated packet speech system in which some packets are missing. Sound quality and intelligibility were measured as a function of packet loss and packet length.	elegant degradation;network packet	Alan Hills;K. S. Scott	1987	IEEE Trans. Acoustics, Speech, and Signal Processing	10.1109/TASSP.1987.1165187	electronic engineering;speech recognition;propulsion;degradation;telecommunications;length measurement;computer science;engineering;processing delay;speech;digital signal processing;end-to-end delay;transmission delay;packet loss;network delay	Arch	49.85921565993883	-8.306245772793773	54774
4e231ef04748f4925a64e3e3919762d87a42e394	a temporal domain audio watermarking technique	filigranage numerique;protection information;digital watermarking;watermarking;audio signal processing;data compression;signal audio;transparency robustness plane;mask system;acoustic modeling;signal detection;securite informatique;audio signal;human auditory system;indexing terms;removal attacks;computer security;wavelet transforms;audio coding;ear;proteccion informacion;streaming media;watermarking systems;traitement signal audio;criptografia;cryptography;information protection;seguridad informatica;robustesse;filigrana digital;short time envelope;immune system;watermark detector temporal domain audio watermarking audio signals audio stream removal attacks watermarking systems modified audio signal keying mask system short time envelope psycho acoustic model;audio signals;signal resolution;cryptographie;transparency;robustness;humans;modified audio signal keying;psycho acoustic model;watermark detector;audio stream;security of data;audio compression;signal detection audio coding data compression watermarking security of data;temporal domain audio watermarking;senal audio;watermarking robustness humans signal resolution streaming media ear audio compression delay wavelet transforms immune system;robustez;audio watermarking	Audio watermarking techniques can be used to embed extra information into audio signals. The goal is to hide prespecified data carrying some information into the audio stream such that it is not audible to the human ear (i.e., transparent) and is, at the same time, resistant to removal attacks (i.e., robust). In the currently known watermarking systems, the above challenges are not always adequately resolved. We present an alternative audio watermarking technique that mitigates these and other related shortcomings. The system is referred to as modified audio signal keying (MASK). In MASK, the short-time envelope of the audio signal is modified in such a way that the change is imperceptible to the human listener. The MASK system can easily be tailored for a wide range of applications. Moreover, informal experimental results show that it has a good robustness and audibility behavior.	internationalized domain name	Aweke Negash Lemma;Javier Aprea;Werner Oomen;Leon van de Kerkhof	2003	IEEE Trans. Signal Processing	10.1109/TSP.2003.809372	speech recognition;aes11;telecommunications;audio signal processing;digital watermarking;computer science;electrical engineering;audio signal;statistics	EDA	42.6016536467085	-9.071668737698424	54928
17b3558f25ef1f80d2abcb4f9939938b3b21d700	medium-rate speech coding - trial of a review	speech coding	Abstract   Between the end of the chain of waveform coders, which reaches from linear PCM to adaptive predictive coders (APC), and the class of (especially: predictive) vocoders, a “coding gap” of roughly 32-2.4 kbit/s is shown to actually define “medium-rate” speech coding.  The fundamental approaches trying to close the gap are exposed, working either in time or frequency-domain. It is discussed, how their weaknesses may be overcome in advanced predictive or generalized “Filter-Bank” Coding (FBC) systems.  The basic ideas and problems of vector quantization (VQ) are reviewed. Combinations of VQ with other schemes are addressed as well as other composite coding systems.	speech coding	Ulrich Heute	1988	Speech Communication	10.1016/0167-6393(88)90035-0	linear predictive coding;speech recognition;shannon–fano coding;telecommunications;computer science;speech coding;code-excited linear prediction	NLP	47.79795028316112	-8.63836465588291	55270
237e9a313416d1d36b926362d0a8c52c4151aada	bandwidth extension of speech using perceptual criteria	loudness;bandwidth extension;electrical engineering;visar;computer science bandwidth extension of speech using perceptual criteria arizona state university berisha;speech compression;psychoacoustics	Bandwidth extension of speech is used in the International Telecommunication Union G.729.1 standard in which the narrowband bitstream is combined with quantized high-band parameters. Although this system produces high-quality wideband speech, the additional bits used to represent the high band can be further reduced. In addition to the algorithm used in the G.729.1 standard, bandwidth extension methods based on spectrum prediction have also been proposed. Although these algorithms do not require additional bits, they perform poorly when the correlation between the low and the high band is weak. In this book, two wideband speech coding algorithms that rely on bandwidth extension are developed. e algorithms operate as wrappers around existing narrowband compression schemes. More specifically, in these algorithms, the low band is encoded using an existing toll-quality narrowband system, whereas the high band is generated using the proposed extension techniques. e first method relies only on transmitted high-band information to generate the wideband speech.e second algorithm uses a constrained minimum mean square error estimator that combines transmitted high-band envelope information with a predictive scheme driven by narrowband features. Both algorithms make use of novel perceptual models based on loudness that determine optimum quantization strategies for wideband recovery and synthesis. Objective and subjective evaluations reveal that the proposed system performs at a lower average bit rate while improving speech quality when compared to other similar algorithms.	algorithm;bandwidth extension;bitstream;consistency model;extension method;g.729.1;mean squared error;quantization (signal processing);speech coding	Visar Berisha;Steven Sandoval;Julie M. Liss	2013		10.2200/S00535ED1V01Y201309ASE013	voice activity detection;loudness;electronic engineering;speech recognition;acoustics;bandwidth extension;telecommunications;computer science;psychoacoustics	Graphics	48.606980815145015	-8.727596909197553	55986
6ca3cc35c9ee3339d96649ca6f70d4b9c77668f1	design and analysis of a cmos ratio-memory cellular nonlinear network (rmcnn) requiring no elapsed time	ratio memory cellular nonlinear networks rmcnn cellular nonlinear networks cnn cmos elapsed time;size 0 35 mum;image processing;neural nets;very large scale integration;cellular networks;tsmc 2p4m mixed signal technology;no elapsed time;cellular networks cellular neural networks pattern recognition nanoelectronics laboratories signal processing algorithms circuits signal processing very large scale integration image processing;chip;integrated circuit design;cmos ratio memory cellular nonlinear network;cmos memory circuits;signal processing;nanoelectronics;cmos rmcnn chip;pattern recognition;ratio memory cellular nonlinear networks rmcnn;mixed analogue digital integrated circuits;circuits;neural nets cmos memory circuits integrated circuit design mixed analogue digital integrated circuits;cellular neural networks;signal processing algorithms;size 0 35 mum cmos ratio memory cellular nonlinear network no elapsed time elapsed multidividers cmos rmcnn chip tsmc 2p4m mixed signal technology;article;cmos;elapsed time;cellular nonlinear networks cnn;elapsed multidividers	A CMOS ratio-memory cellular nonlinear network (RMCNN) requiring no elapsed time is proposed. The correlations between any two neighboring cells are stored in the memories. The ratio weights of each cell are generated through a comparison of the four correlations around one cell with the mean value of these four correlations. With this method, the elapsed time required by the previously existing RMCNN algorithm is no longer required and, therefore, the ratio weights can be generated individually. Moreover, the use of multi-dividers can be avoided to make the circuit simple. Based on the proposed algorithm, a CMOS RMCNN chip requiring no elapsed time has been designed and fabricated using TSMC 0.35-μm 2P4M mixed-signal technology. In the fabricated chip, three test patterns can be learned and recognized.	algorithm;cmos;mixed-signal integrated circuit;nonlinear system;test card	Chung-Yu Wu;Sheng-Hao Chen;Yu Wu	2010	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2009.2031704	nanoelectronics;chip;embedded system;cellular network;electronic circuit;electronic engineering;cellular neural network;real-time computing;image processing;computer science;electrical engineering;signal processing;very-large-scale integration;cmos;artificial neural network;integrated circuit design	EDA	39.58275935141305	-2.397583106467063	56104
82a0f5949cdf825bcfe24dbb514c60b5f004ae0a	data gathering in a virtual architecture for wireless sensor networks with some empty clusters	wireless sensor network;data gathering	A door mounted in a door frame is held closed by an electromagnet mounted on the door frame which magnet attracts an armature mounted on the door. A switch is mounted adjacent to the electromagnet and is operated by a switch operator mounted on the door. The switch provides a signal indicating that an attempt is being made to open the door, which signal may be used to sound an alarm or start a time delay release. A pair of contacts are also mounted adjacent to the electromagnet and are bridged by the armature to indicate when the armature is properly held by the electromagnet.		Idrissa Sow;Jean Frédéric Myoupo	2008			visual sensor network;wireless sensor network;distributed computing;computer network;computer science;wi-fi array;magnet;electromagnet;key distribution in wireless sensor networks;mobile wireless sensor network;armature (electrical engineering)	Mobile	45.46110542694089	-0.3003838177801755	56214
519f67a34ccbcee19d1eda21439832b75259b883	speech quality improvement of a multi-pulse speech codec with pitch prediction on a single chip signal processor	quality improvement;chip	The multi-pulse speech coding with pitch prediction has been known as an efficient speech coding method. In this paper, a new pulse search method is proposed for improving speech quality with small amount of computation. Characteristics ofthispulse search method are listed below. 1. Modifying pulse amplitude in pulse search loop. 2. Controlling pulse search conditions. 3. Quantization of pulse positions. This pulse search method improves S/Nseg of the multi-pulse speech codec with pitch prediction on a single-chip 32-bit floating-point signal processor, by 1.0 to 1.3 dB.	32-bit;codec;computation;quantization (signal processing);signal processing;speech coding	A. Fukui;K. Shibagaki	1987			speech recognition;digital signal processor;chip;quality management;speech coding;computer science;enhanced variable rate codec;adaptive multi-rate audio codec;pulse (signal processing)	ML	47.751828069384615	-7.928995699401618	57207
735fdffb0886ca7c2e3cafc7bb26d2992962dce1	bearing-only multi-target localization for wireless array networks: a spatial sparse representation approach		Bearing-only multi-target localization (BOMTL) using multiple sensors is generally required to solve the sophisticated data association problem which determines a designated sensor measurement originated from a particular target. In this paper, a novel spatial sparse representation based BOMTL method is proposed by fully utilizing a wireless array network structure. With array spatial features, the BOMTL problem can be formulated as a binary sparse vector recovery problem using the converted “pseudo-measurements” in frequency domain. The proposed method transforms the source location estimation problem into a spatial sparse representation (SSR) framework, which avoids dealing with the conventional data association. With orthogonal matching pursuit (OMP) exploiting the binary property of the sparse vector to be estimated, we develop a BOMTL-OMP algorithm to reconstruct the sparse vector. The numerical simulations demonstrate the performance of the proposed method.	algorithm;correspondence problem;matching pursuit;numerical analysis;openmp;sensor;simulation;source separation;sparse approximation;sparse matrix	Ji-an Luo;Yi Fang Shi;Shen-Tu Han;Taek Lyul Song;Dongliang Peng;Yu Gu	2018	2018 21st International Conference on Information Fusion (FUSION)	10.23919/ICIF.2018.8455672	matching pursuit;frequency domain;artificial intelligence;machine learning;computer science;wireless;sparse approximation;binary number;bearing (mechanical)	Robotics	52.05448790549245	2.7465424602024937	57596
60b296a81f6a43c283b7b0bb23515f68b8424e1b	a pulse-density modulation circuit exhibiting noise shaping with single-electron neurons	bio inspired circuit;neural nets;oscillators;pulse modulation pulse circuits pulse shaping methods noise shaping neurons circuit noise coupling circuits single electron devices tuned circuits circuit optimization;monte carlo based computer simulations;single electron neuronal units;single electron devices monte carlo methods neural nets;capacitive coupling;firing;device fabrication;device fabrication pulse density modulation circuit noise shaping single electron neurons bio inspired circuit single electron devices single electron neuronal units neuronal circuits capacitive coupling monte carlo based computer simulations;threshold voltage;pulse density modulation circuit;noise shaping;single electron devices;neurons;couplings;signal to noise ratio;monte carlo;neuronal circuits;computer simulation;high frequency;monte carlo methods;single electron neurons;noise;tunneling	We propose a bio-inspired circuit performing pulse-density modulation with single-electron devices. The proposed circuit consists of three single-electron neuronal units, receiving the same input and are connected to a common output. The output is inhibitorily fedback to the three neuronal circuits through a capacitive coupling, tuned to obtain a winners-share-all network operation. The circuit performance was evaluated through Monte-Carlo based computer simulations. We demonstrated that the proposed circuit possesses noise-shaping characteristics, where signal and noises are separated into low and high frequency bands respectively. This significantly improved the signal-to-noise ratio (SNR) by 4.34 dB in the coupled network, as compared to the uncoupled one. The noise-shaping properties are as a result of i) the inhibitory feedback between the output and the neuronal circuits, and ii) static noises (originating from device fabrication mismatches) and dynamic noises (as a result of thermally induced random tunneling events) introduced into the network.	british informatics olympiad;computer simulation;electron;frequency band;monte carlo method;noise shaping;one-electron universe;pulse-density modulation;signal-to-noise ratio;tunneling protocol	Andrew Kilinga Kikombo;Tetsuya Asai;Takahide Oya;Alexandre Schmid;Yusuf Leblebici;Yoshihito Amemiya	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178715	equivalent circuit;computer simulation;computer science;artificial neural network;monte carlo method	EDA	40.05258222568848	-0.7954295874446553	58397
89de60ea904dbfc25aef7b8c3278cf2b18469172	underwater acoustic sensor fault detection for passive sonar systems	sonar detection sensor arrays fault detection sonar measurements fault diagnosis underwater acoustics;underwater acoustic communication fault diagnosis hydrophones sonar;sonar detection;crossing rate of rms passive sonar acoustic sensor fault detection root mean square;fault detection;fault sensors underwater acoustic sensor fault detection passive sonar systems multichannel line array hydrophones root mean square value;underwater acoustics;sensor arrays;fault diagnosis;sonar measurements	In this paper, an underwater acoustic sensor fault detection method is proposed that determines whether or not each sensor of multi-channel line array hydrophones malfunctions for passive sonar systems. To this end, the proposed method first measures a short-time root mean square (RMS) value of input signal for each channel. Then, it analyzes the RMS difference between the adjacent channels. In addition, the crossing rate of RMS values (RMSCR) is computed for each channel, and then the average value of RMSCR over all the channels is obtained. Some faulty sensors are identified by comparing the RMS difference with a threshold, and others by comparing the ratio between RMSCR of each of them and the average value of RMSCR with a threshold. In order to evaluate the performance of the proposed method, the precision of detecting fault sensors is measured. Consequently, it is shown that the proposed method works well in underwater environments with average RMS of -18.6 and -9.7 dB.	acoustic cryptanalysis;fault detection and isolation;mean squared error;sonar (symantec);sensor;zero crossing;zero-crossing rate	Yong Guk Kim;YoungShin Kim;Sang Hyuck Lee;Sang-Taeck Moon;Moongu Jeon;Hong Kook Kim	2016	2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE)	10.1109/SPLIM.2016.7528395	underwater acoustic communication;synthetic aperture sonar;electronic engineering;acoustics;telecommunications;engineering;sensor array	Robotics	47.38487476361715	-1.9314077954753373	58432
861ff5d0c5ec846830db3ed03bc552429d370b08	discrete-time minimal control synthesis adaptive algorithm	modele reference;minimal control synthesis;continuous time;continuous control;programme commande;sintesis control;stabilite asymptotique;canonical form;single input single output;reference model;forme canonique;model reference adaptive control;adaptive control;systeme commande adaptative modele reference;variacion lenta;control design;temps continu;robustez mando;discrete time;temps minimal;tiempo continuo;asymptotic stability;control continuo;robustesse commande;hyperstabilite;adaptive algorithm;systeme incertain;model reference adaptive control systems;systeme siso;formal verification;control adaptativo;control program;synthese commande;hyperstabilidad;control robustness;commande adaptative;minimum time;forma canonica;siso system;programa mando;parameter uncertainty;verification formelle;hyperstability;estabilidad asintotica;tiempo discreto;temps discret;sistema incierto;controle continu;tiempo minimo;slow variation;uncertain system;variation lente;control synthesis;discrete time system;sistema siso;modelo referencia	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	adaptive algorithm;benchmark (computing);control engineering;discretization;euler;euler–lagrange equation;francis;lr parser;mcs algorithm;multi categories security;nl (complexity);numerical analysis;picasa web albums;primary source;reference model;serial digital video out;simulation	Mario di Bernardo;F. di Gennaro;Josep M. Olm;Stefania Santini	2010	Int. J. Control	10.1080/00207179.2010.536916	control engineering;canonical form;discrete time and continuous time;reference model;adaptive control;formal verification;control theory;mathematics;algorithm	Robotics	50.976290144442025	-3.431650068515023	58499
1b7876d6274c533a18768a9fbec0e2f167639f17	x-ray laser imaging of biomolecules using multiple gpus	berakningsmatematik;computational mathematics;datavetenskap datalogi;computer science	Extremely bright X-ray lasers are becoming a promising tool for 3D imaging of biomolecules. By hitting a beam of streaming particles with a very short burst of a high energy X-ray and collecting the resulting scattering pattern, the 3D structure of the particles can be deduced. The computational complexity associated with transforming the data thus collected into a 3D intensity map is very high and calls for efficient data-parallel implementations.	graphics processing unit	Stefan Engblom;Jing Liu	2013		10.1007/978-3-642-55224-3_45	computational science;numerical analysis;computer science;theoretical computer science	Robotics	44.33218960873937	1.5604934678031857	58731
4b0d270198f5afcf70cf00c63214df9325ebab8d	packet loss concealment based on vq replicas and mmse estimation applied to distributed speech recognition	quantization;degradation;propagation losses;least mean squares methods;model based mmse estimation;speech recognition forward error correction hidden markov models degradation telecommunication standards quantization mean square error methods estimation error ip networks propagation losses;aurora 2;fec bits;hidden markov models;forward error correction;packet loss concealment;vq replicas;telecommunication standards;distributed speech recognition;mean square error methods;speech recognition;data replicas;ip network;ip networks;estimation error;minimum mean square error estimation;vector quantisation;least mean squares methods forward error correction speech recognition vector quantisation;model based mmse estimation packet loss concealment vq replicas distributed speech recognition fec bits data replicas minimum mean square error estimation aurora 2 ip network;minimum mean square error	This paper proposes a new packet loss concealment technique based on the inclusion in each packet of a few FEC bits, representing data replicas, combined with a minimum mean square error estimation (MMSE). This technique is developed for an Aurora-2 distributed speech recognition system working over an IP network. In addition to the data representing the transmitted speech frames, each packet includes some FEC bits representing a strongly VQ-quantized version (replicas) of previous and subsequent frames. When a loss burst occurs, the lost frames can be reconstructed from the VQ replicas. In order to mitigate the degradation introduced by the coarse VQ quantization of the replicas, a model-based MMSE estimation is applied. The experimental results show that, under a strongly degraded channel, it is possible to obtain up to 83.31 % of word accuracy with only 4 FEC bits or 88.47 % with 8 FEC bits per packet, when the Aurora mitigation algorithm only obtains 76.98 %.	algorithm;aurora;elegant degradation;forward error correction;jumbo frame;mean squared error;network packet;speech recognition;vector quantization	Antonio M. Peinado;Ángel M. Gómez;Victoria E. Sánchez;José L. Pérez-Córdoba;Antonio J. Rubio	2005	Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.	10.1109/ICASSP.2005.1415117	minimum mean square error;speech recognition;degradation;quantization;telecommunications;computer science;theoretical computer science;forward error correction;hidden markov model;statistics	Robotics	49.60003102743308	-9.141229926237726	59451
d81f9ce46039793a8f23e54cd63c381bdddf145b	signal-adaptive transform kernel switching for stereo audio coding	kernel;codecs;decoding;transform coding;transforms;switches;encoding	Modern stereo and multi-channel perceptual audio codecs utilizing the modified discrete cosine transform (MDCT) can achieve very good overall coding quality even at low bit-rates but lack efficiency on some material with inter-channel phase difference (IPD) of about ±90 degrees. To address this issue a generalization of the lapped transform coding scheme is proposed which retains the perfect reconstruction property while allowing the usage of three further transform kernels, one of which is the modified discrete sine transform (MDST). Blind listening tests indicate that by frame-wise adaptation of each channel's transform kernel to the instantaneous IPD characteristics, notable gains in coding quality are possible with only negligible increase in decoder complexity and parameter rate.	codec;discrete sine transform;interpupillary distance;kernel (operating system);lapped transform;modified discrete cosine transform;psychoacoustics;s transform;transform coding	Christian R. Helmrich;Bernd Edler	2015	2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/WASPAA.2015.7336952	sub-band coding;electronic engineering;codec;kernel;transform coding;speech recognition;s transform;lapped transform;telecommunications;network switch;computer science;discrete cosine transform;mathematics;encoding;statistics	Vision	47.6680948717088	-9.089541525671894	59548
9efe2a0717bcaafd1215ccbb7fc7cce5efc016ec	memristor crossbar for adaptive synchronization	memristor resistive switching crossbar adaptive synchronization nonlinear circuits;memristors synchronization adaptation models adaptive systems couplings circuit faults switches	"""Nonlinear circuits may be synchronized with interconnections that evolve in time incorporating mechanisms of adaptation found in many biological systems. Such dynamics in the links is efficiently implemented in electronic devices by using memristors. However, the approach requires a massive amount of interconnections (of the order of <inline-formula> <tex-math notation=""""LaTeX"""">$N^{2}$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=""""LaTeX"""">$N$ </tex-math></inline-formula> is the number of nonlinear circuits to be synchronized). This issue is solved in this paper by adopting a memristor crossbar architecture for adaptive synchronization. The functionality of the structure is demonstrated, with respect to different switching characteristics, via a simulation-based evaluation using a behavioral threshold-type model of voltage-controlled bipolar memristor. In addition, we show that the architecture is robust to device variability and faults: quite surprisingly, when faults are localized, the performance of the approach may also improve as adaptation becomes more significant."""	biological system;crossbar switch;heart rate variability;memristor;nonlinear system;simulation;software bug	Lucia Valentina Gambuzza;Mattia Frasca;Luigi Fortuna;Vasileios G. Ntinas;Ioannis Vourkas;Georgios Ch. Sirakoulis	2017	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2017.2692519	control engineering;electronic engineering;real-time computing;computer science;memistor	EDA	39.54855984982184	-0.5914844568953204	59582
cfec00f48df89a1961ec7cba035fc202e71435c8	ls-decomposition for robust recovery of sensory big data		"""The emerging Internet of Things (IoT) systems are fueling an exponential explosion of sensory data. The major challenge to effective implementation of IoT systems is the presence of <italic>massive missing data entries, measurement noise, and anomaly readings</italic>, which motivates us to investigate the robust recovery of sensory big data. In this paper, we propose an <italic>LS-decomposition</italic> approach that decomposes a sensory reading matrix as the superposition of a <underline>L</underline>ow-rank matrix and a <underline>S</underline>parse anomaly matrix. First, based on data sets from three representative real-world IoT projects, i.e., the IntelLab project (indoor environment), the GreenOrbs project (mountain environment), and the NBDC-CTD project (ocean environment), we observe that anomaly readings are ubiquitous and cannot be ignored. Second, we prove that the convex surrogate of the LS-decomposition problem guarantees bounded recovery error under proper conditions. Third, we propose an accelerated proximal gradient algorithm that converges to the optimal solution at a rate that is inversely proportional to the square of the number of iterations. Evaluations on the above three data sets show that the proposed scheme achieves (relative) recovery error <inline-formula><tex-math notation=""""LaTeX"""">$\leq 0.05$</tex-math><alternatives> <inline-graphic xlink:href=""""wang-ieq1-2763170.gif""""/></alternatives></inline-formula> for missing data rate <inline-formula><tex-math notation=""""LaTeX"""">$\leq 50$</tex-math><alternatives> <inline-graphic xlink:href=""""wang-ieq2-2763170.gif""""/></alternatives></inline-formula> percent and almost exact recovery for missing data rate <inline-formula><tex-math notation=""""LaTeX"""">$\leq 40$</tex-math><alternatives> <inline-graphic xlink:href=""""wang-ieq3-2763170.gif""""/></alternatives></inline-formula> percent, while previous methods have (relative) recovery error <inline-formula><tex-math notation=""""LaTeX"""">$0.04\! \sim\! 0.15$</tex-math><alternatives> <inline-graphic xlink:href=""""wang-ieq4-2763170.gif""""/></alternatives></inline-formula> even at only 10 percent missing data rate."""	algorithm;anomaly detection;big data;code for the japanese graphic character set for information interchange (jis x 0208-1990),;comparative toxicogenomics database (ctd);data rate units;evaluation;internet of things;iteration;least squares;link-state routing protocol;missing data;parsing;proximal gradient methods for learning;time complexity;uncompressed video;xlink	Xiao-Yang Liu;Xiaodong Wang	2018	IEEE Transactions on Big Data	10.1109/TBDATA.2017.2763170	missing data;robustness (computer science);mathematical optimization;machine learning;artificial intelligence;sparse matrix;computer science;big data;data set;bounded function;matrix (mathematics);matrix decomposition	DB	52.11592591569644	0.8085662597339444	59792
76b11e71de2a495fb0e795512be96341de81e78f	vector coding the finite-volume procedure for the cyber 205	finite volume method;computer program;aeronautique;ecoulement;aerodynamics;equation euler;boundary value problem;simulacion numerica;vector space;flujo;vecteur;algorithme;algorithm;transonic flow;codificacion;algorritmo;boundary condition;simulation numerique;ecuacion euler;coding;aeronautica;vector;fortran;aeronautics;finite volume;aerodynamique;aerodinamica;digital simulation;codage;flow fluid;euler equation	The paper reviews a method for the large-scale numerical simulation of fluid flow and discusses fundamental principles of vector programming in FORTRAN in order to set the stage for the main topic, the vector coding and execution of the finite-volume procedure on the CYBER 205. With the proper structure given to the data by the grid transformation each coordinate direction can be differenced throughout the entire grid in one vector operation. Boundary conditions must be interleaved which tends to inhibit the concurrency of the overall scheme, but a stragey of no data motion together with only inner-loop vectorization is judged to be the best compromise. The computed example of transonic vortex flow separating from the sharp leading edge of a delta wing demonstrates the processing performance of the procedure. Vectors over 40000 elements long are obtained, and a rate of over 125 megaflops sustained over the entire computation indicates the high degree of vectorization achieved.	automatic vectorization;cdc cyber;computation;concurrency (computer science);flops;fortran;numerical weather prediction;simulation;vortex	Arthur Rizzi	1985	Parallel Computing	10.1016/0167-8191(85)90029-8	mathematical optimization;parallel computing;simulation;aerodynamics;boundary value problem;theoretical computer science;mathematics;finite volume method;algorithm	HPC	44.98657230873146	4.139680413731091	59903
2c685277bd33c217695ccf8122ca211657f6b7fa	security camera based on a single chip solution using a sharply outlined display algorithm and variable-clock video encoder	cmos integrated circuits;digital camera;indexing terms;ccd image sensors;chip;ccd image sensors video cameras security cmos integrated circuits closed circuit television high definition television video coding;closed circuit television;video coding;video cameras;0 25 micron security camera single chip solution sharply outlined display algorithm variable clock video encoder displays high definition images charge coupled device complementary filter chrominance processes luminance processes composite video baseband signal ccd module cmos process 27 mhz;charged couple device;security;high definition;high definition television;security cameras displays charge coupled devices hardware charge coupled image sensors clocks frequency high definition video filters	In this paper, we have proposed a security camera system that displays high-definition images by using a sharply outlined display algorithm (SODA), which generates less hardware complexity because of a modified video encoder. While the proposed system uses a charge coupled device (CCD) with a complementary filter that may cause some problems in representing vivid color, we have been able to resolve the problem by mixing two signals, such as those generated by chrominance and luminance processes. In doing so, the system requires the use of a video encoder that converts the CCD's output signals into a composite video baseband signal (CVBS). Moreover, although a video encoder generally operates at 27 MHz the CCD module used in the security camera requires a particular clock frequency. Here, we have proposed that the new video encoder uses a clock to equal the CCD module at a given frequency. In doing so, the system using the encoder reduces hardware complexity and noise. The proposed system is fabricated with a test camera chip that has been manufactured by the MagnaChip 0.25 /spl mu/m CMOS process.	algorithm;closed-circuit television;encoder	Joohyun Kim;Jooyoung Ha;Shinki Jeong;Hoongee Yang;Bongsoon Kang	2006	IEEE Trans. Consumer Electronics	10.1109/TCE.2006.1605061	composite video;chip;embedded system;computer vision;encoder;electronic engineering;video;index term;telecommunications;computer science;information security;video capture;video processing;charge-coupled device;cmos;three-ccd camera;s-video	Vision	42.553852671560186	-4.905606198028555	60223
92297433dca8e17882c8c90ea9e4391cbbd75b33	3dann-r: a tera-op convolution engine for image processing	evaluation performance;entrada salida;caracteristica funcionamiento;architecture systeme;performance evaluation;image processing;modelo 3 dimensiones;integrated circuit;sensors;convolution;modele 3 dimensions;evaluacion prestacion;procesamiento imagen;three dimensional model;circuito integrado;convolucion;traitement image;input output;captador medida;artificial neural networks;measurement sensor;capteur mesure;caracteristique fonctionnement;arquitectura sistema;reseau neuronal;system architecture;performance characteristic;red neuronal;circuit integre;artificial neural network;neural network;entree sortie	A commercial version of the 3D Artificial Neural Network has been developed under a collaborative effort between JPL and Irvine Sensors, sponsored by BMDO and the U.S. Air Force. It is capable of continuous trillion eight bit multiply and add operations per second while consuming under ten watts. Its architecture, input-output characteristics, and performance data will be presented.© (2000) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	convolution;image processing	John C. Carson;David E. Ludwig	2000		10.1117/12.390474	telecommunications;engineering;artificial intelligence;cartography	Arch	41.69892358032817	-4.002996852552098	60281
b7987c5fa5ac832e67ed7d35c7ab910d214d736b	on cross-correlation properties of boolean functions	06e30;cross correlation;boolean function;94a60;propagation characteristics;correlation function;global avalanche characteristics;strict avalanche criterion;lower bound	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	autocorrelation;cross-correlation;francis;maximal set;primary source	Zhuo Ze-peng	2011	Int. J. Comput. Math.	10.1080/00207160.2010.539367	combinatorics;boolean model;mathematical analysis;discrete mathematics;boolean network;bent function;maximum satisfiability problem;cross-correlation;mathematics;boolean function;upper and lower bounds;correlation function;algorithm;quantum mechanics;parity function	Robotics	49.49233452993101	-2.694955769361725	60548
ffce59c3c9808223c74a977d98ba955c00e329b0	group consensus of multi-agent systems in directed networks with noises and time delays	multi agent system;directed graph;communication delay;group consensus;noise	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	agent-based model;algebraic graph theory;broadcast delay;complex network;computational fluid dynamics;consensus (computer science);directed graph;francis;multi-agent system;network partition;numerical linear algebra;primary source;random graph;simulation;zentralblatt math	Yilun Shang	2015	Int. J. Systems Science	10.1080/00207721.2013.862582	real-time computing;directed graph;computer science;noise;multi-agent system;control theory;mathematics;distributed computing	Robotics	50.68488588743905	-3.262312957439931	60714
49f0f2c971e677c70ef95bc6667cdf569be6b79d	hierarchical vector quantization: theoriy and application to speech coding			speech coding;vector quantization	Christoph Erdmann	2005				NLP	47.46822276107113	-8.469018765000719	60871
c7ef3814717ee3620c584724bbc9f01dc62c8797	an imager with built-in image-velocity computation capability	cmos integrated circuits;computational techniques;delay lines;si image velocity computation cmos technology imager delay lines computational error delay gates 3 0 micron;image sensors;delay lines image edge detection image segmentation error correction silicon fabrication signal design propagation delay image analysis;image sensors cmos integrated circuits delay lines	An imager with built-in image-velocity computation capability is described. The image-velocity computation technique is based on signals propagating on delay lines. Silicon implementation using ~ F C M O S technology is described. Experimental results show that a computational error of less than 20% can be achieved using currently available fabrication technology. This figure can be reduced by using larger arrays and better implementations of delay gates.	analog delay line;canonical account;computation;contour line;delay line memory;image sensor;ion beam;semiconductor device fabrication;velocity (software development);xfig	Chu Phoon Chong;C. Andre T. Salama;Kenneth C. Smith	1992	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.157162	computer vision;real-time computing;delay calculation;computer science;image sensor;cmos	EDA	42.28573586837727	-3.3857652877467337	61049
156d882dd5293530a8b75eb3e445cf08df593f18	a lossless audio compression scheme with random access property	audio compression phase change materials transform coding audio coding iso standards usa councils laboratories random media sampling methods frequency;pulse code modulation;signal sampling;sampling frequency;32 bit lossless audio compression random access lossless coding algorithm audio encoding pcm format data ieee floating point format data sampling frequencies compression rate 48 khz 96 khz;audio coding;signal reconstruction;floating point;signal reconstruction pulse code modulation audio coding signal sampling;random access	We propose an efficient lossless coding algorithm that not only handles both PCM format data and IEEE floating-point format data, but also provides end users with a random access property. In the worst-case scenario, where the proposed algorithm was applied to artificially generated full 32 bit floating-point sound files with 48 kHz or 96 kHz sampling frequencies, an average compression rate of more than 1.5 and 1.7, respectively, was still achieved, which is much better than the average compression rate of less than 1.1 achieved by the general purpose lossless coding algorithm, gzip. Moreover, input sound files with samples' magnitudes out-of-range can also be perfectly reconstructed by our algorithm.	32-bit;algorithm;data compression;lossless compression;netbsd gzip / freebsd gzip;random access;sampling (signal processing);worst-case scenario	Dai Yang;Takehiro Moriya;Tilman Liebchen	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1326720	pulse-code modulation;data compression;lossy compression;signal reconstruction;sub-band coding;data compression ratio;mpeg-4 part 3;digital audio;telecommunications;audio signal processing;computer science;floating point;theoretical computer science;audio bit depth;speech coding;sound quality;lossless compression;adaptive coding;context-adaptive binary arithmetic coding;audio signal flow;sampling;random access;g.711;golomb coding	Visualization	47.01369876774785	-9.485073367058106	61381
eb40bf312c23613bd7eb39e3b5fac734b21242e2	advanced structural similarity rules for the bga package family	optimisation;microelectronic fabrication;parametre geometrique;fiabilidad;reliability;tecnologia electronica telecomunicaciones;fabricacion microelectrica;developpement industriel;sistema experto;optimizacion;diminution cout;packaging electronico;desarrollo industrial;rule based;manufacturing process;modele lineaire;cost reduction;technologie bga;non linear model;modele non lineaire;modelo lineal;parametro geometrico;microelectronique;body size;conception circuit integre;microelectronica;valeur efficace;packaging electronique;miniaturisation;integrated circuit design;modelo no lineal;integrated circuit bonding;wafer;response function;matriz formadora;procedimiento fabricacion;geometrical parameter;assemblage circuit integre;fiabilite;valor eficaz;electronic packaging;linear model;defaillance;failure mechanism;root mean square value;bga technology;die;pastilla electronica;optimization;miniaturization;prediction model;failures;microelectronics;systeme expert;pastille electronique;miniaturizacion;tecnologias;assemblage brasage tendre;funcion respuesta;procede fabrication;grupo a;reduccion costes;matrice formage;junta soldada;fallo;soldered joint;cost lowering;structural similarity;ball grid array;fonction reponse;fabrication microelectronique;industrial development;expert system;tecnologia bga	To efficiently select qualification and reliability monitoring programs, structural similarity rules for integrated circuit designs, wafer fabrication processes and/or package designs are currently used by the industry. By following the package structural similarity rules, the numbers of reliability qualification tests may be greatly reduced. However, when looking at the present rules it is clear that they are not reliably defined. For instance, geometrical parameters such as die-to-pad ratio are not quantitatively included and it seems that linear relationships are assumed. Besides that, these rules are mainly deducted from experience and industrial trial and error results, not from reliability physics. Driven by the present development trends of microelectronics (miniaturization, integration, cost reduction, etc) it is urgently needed to develop 'advanced based structural similarity rules' based on reliability physics (physics of failures), to meet the industrial development trends. In this study, the authors have used DOE/RMS techniques to deduct advanced structural similarity rules through simulation-based optimisation techniques. Parametric 3D non-linear FE models are used to explore the responses of the complete BGA family for both the thermo-mechanical and moisture-diffusion responses as function of six parameters among which the die-to-pad ratio and the body size. In this way, advanced structural similarity rules are deduced which can be used to shorten design cycles. Even more, by using the accurate 3D nonlinear reliability prediction models an Excel-based tool is created for package designers. By using this tool, the number of reliability qualification tests can be reduced. More importantly, possible failure mechanisms can be (better) understood and predicted.	ball grid array;failure cause;integrated circuit;mathematical optimization;nonlinear system;qualification problem;simulation;structural similarity;wafer fabrication	Willem D. van Driel;A. Mavinkurve;M. A. J. van Gils;G. Q. Zhang	2005	EuroSimE 2005. Proceedings of the 6th International Conference on Thermal, Mechanial and Multi-Physics Simulation and Experiments in Micro-Electronics and Micro-Systems, 2005.	10.1016/j.microrel.2006.09.005	ball grid array;electronic engineering;computer science;engineering;electrical engineering;structural similarity;linear model;reliability;miniaturization;predictive modelling;electronic packaging;engineering drawing;expert system;microelectronics;die;wafer;statistics;integrated circuit design	EDA	52.01263043305254	-1.8665646148821042	61654
aac78feec4a16e7ed9cc20915bfb26d7c122a291	poster abstract: human localization and activity detection using thermopile sensors	thermopile sensor;total darkness;temperature reading;sensor node;sensor reading;human localization;activity detection	We describe a method of using a network of thermopile sensors distributed along the walls of a room to locate a person within the room. At any given time, a person would be in the view of at least one of the sensor nodes. An algorithm is used to calculate the distance of a person from each sensor node based on its temperature reading and locate the person based on a combination of the sensor readings from the distributed nodes. This method is immune to lighting changes and works even in total darkness. Furthermore, this method of sensing can also detect events such as a person walking past the doorway to a room, lingering outside, and entering or leaving the room.	internationalization and localization;sensor	Hock M. Ng	2013		10.1109/IPSN.2013.6917604	embedded system;telecommunications;electro-optical sensor	Robotics	45.28749210763793	-0.4890920597950859	61703
90e9758089255ec38e1644a34e8a37c70ce2deaf	raster simulation using advanced fuzzy cellular non-linear network	raster simulation;fuzzy cellular neural networks;edge detection;cellular nonlinear networks;fuzzy sets;fuzzy logic;type ii fcnn;numerical integration	In this framework, a non-linear network structure known as fuzzy cellular neural network (FCNN) of type II is reported by integrating fuzzy operations with the classical cellular neural network (CNN) structure and it is an extension of the cellular non-linear network from classical to fuzzy sets (FSs). Type II FCNN is implemented to detect the edges of an object through raster scheme efficiently. The functional behaviour of the simulator is to perform raster simulation for any kind as well as any size of input image using the two newly proposed efficient numerical techniques. An efficient pseudo code for exploiting the latency properties of type II FCNN along with well-known RK-fourth-order embedded numerical integration algorithms is presented. Simulation results and comparison have also been presented to show the efficiency of the newly introduced numerical integration algorithm.		Sukumar Senthilkumar	2010	IJAACS	10.1504/IJAACS.2010.035549	fuzzy logic;edge detection;numerical integration;computer science;artificial intelligence;theoretical computer science;neuro-fuzzy;machine learning;fuzzy set	Robotics	40.12523650549966	0.6624774204410877	62594
f9512da5f089dd276c2f17c3e92215822928150b	calibrating nonlinear mobile sensors	chemical and biological sensors;sensor phenomena and characterization;error reduction;mobile sensors;time measurement;sensors;calibration sensor phenomena and characterization chemical and biological sensors biosensors error correction chaos collaboration monitoring time measurement curve fitting;chaos;nullspace based calibration;light field;collaboration;significant error reduction nonlinear mobile sensors in field calibration blind calibration schemes nullspace based calibration moments based calibration;blind calibration schemes;polynomials;noise measurement;moments based calibration;monitoring;nonlinear mobile sensors;significant error reduction;error correction;mobile radio;in field calibration;ground truth;wireless sensor networks calibration mobile radio;curve fitting;calibration;wireless sensor networks;biosensors	In-field calibration of sensor devices is known to be a challenging problem because there is often no access to a controlled signal field and/or a pre-calibrated device to provide the ground truth. Nonlinear characteristics of sensor devices make the calibration problem even harder. In this paper, we describe two blind calibration schemes for nonlinear mobile sensor nodes: nullspace based calibration (NBC) and moments based calibration (MBC). Simulation results are included to demonstrate the effectiveness of the proposed schemes. MBC scheme is also used to calibrate light sensors on MICA2 motes in a light field generated by a light bulb. Results show that significant error reduction can be achieved when nonlinearity is considered.	coefficient;convex function;estimation theory;ground truth;kernel (linear algebra);light field;mbc-55x;mathematical optimization;nonlinear system;sensor;simulation	Chao Wang;Parameswaran Ramanathan;Kewal K. Saluja	2008	2008 5th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks	10.1109/SAHCN.2008.70	calibration;error detection and correction;wireless sensor network;ground truth;computer science;sensor;noise measurement;light field;biosensor;statistics;polynomial;time;curve fitting;collaboration	Mobile	51.97754593878411	4.045375720781677	63402
3f0a4f3e3f97c7e4251da7623b2fbf478d204f61	panphasia: a user guide		We make a very large realisation of a Gaussian white noise field, called panphasia, public by releasing software that computes this field. Panphasia is designed specifically for setting up Gaussian initial conditions for cosmological simulations and resimulations of structure formation. We make available both software to compute the field itself and codes to illustrate applications including a modified version of a public serial initial conditions generator. We document the software and present the results of a few basic tests of the field. The properties and method of construction of Panphasia are described in full in a companion paper – Jenkins 2013.	code;initial condition;jenkins;simulation;white noise	Adrian Jenkins;Stephen Booth	2013	CoRR		statistics	ML	42.07824229304028	2.602794238505863	63650
4d9a5af82cf482342876a4707944775419a1660d	public key steganography using discrete cross-coupled chaotic maps		By cross-coupling two logistic maps a novel metho d is proposed for the public key steganography in JPEG image. Chaotic maps entail high complexity in the used alg orithm for embedding secret data in a medium. In this paper, d iscrete crosscoupled chaotic maps are used to specifying the loc ation of the different parts of the secret data in the image. Mo difying JPEG format during compressing and decompressing, and al so using public key enhanced difficulty of the algorithm. Si mulation results show that in addition to excessive capacity , this method has high robustness and resistance against hackers and can be applicable in secret communication. Also the PSNR v alue is high compared to the other works. Keywords-component; Cross-coupled chaotic maps; Bifurcation; Statistical steganalysis; Least significant bits; Chisquare attack Introduction	algorithm;bifurcation theory;jpeg;list of chaotic maps;map;peak signal-to-noise ratio;public-key cryptography;statistical model;steganalysis;steganography	Sodeif Ahadpour;Mahdiyeh Majidpour;Yaser Sadra	2012	CoRR		theoretical computer science;mathematics;internet privacy;computer security	Crypto	39.873409144427406	-9.714893858706333	63711
55500dd4a68fe42804dd7f5a564df63f989c2e00	watermarking and rank metric codes		This paper presents a different way to improve the resistance of digital watermarking. Using the well known Lattice QIM in the spatial domain, we analyze the interest of using a different kind of error correcting codes: rank metric codes. These codes are already used in communications for network coding but not used in the context of watermarking. In this article, we show how this metric permits to correct errors with a specific structure and is adapted to specific image attacks. We propose a first study to validate the concept of rank metric for watermarking process. For this, we use these codes to obtain invariance against luminance additive constant change.		Pascal Lefèvre;Philippe Carré;Philippe Gaborit	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462647	linear network coding;invariant (physics);decoding methods;lattice (order);digital watermarking;artificial intelligence;pattern recognition;computer science	Visualization	41.065770698990235	-9.404331582701715	63878
738785f412143d1d857cf82c76b27e9648a7423a	a hybrid gmm/smc diffusion bernoulli filter for joint distributed detection and tracking	joints target tracking monte carlo methods surveillance approximation methods trajectory object detection;surveillance;gaussian mixture model hybrid gmm smc diffusion bernoulli filter random exchange diffusion bernoulli filter joint target distributed detection and tracking rndex bf distributed algorithm sensor measurement internode communication cost reduction optimal centralized bernoulli filter sequential monte carlo method;joints;wireless sensor networks gaussian processes mixture models monte carlo methods object detection radiofrequency filters target tracking;joint detection and tracking bernoulli filter sequential monte carlo diffusion rss sensors;trajectory;approximation methods;target tracking;monte carlo methods;object detection	We introduce in this paper the Random Exchange Diffusion Bernoulli Filter (RndEx-BF), which enables joint target detection and tracking by a network of collaborative sensors. RndEx-BF is a fully distributed algorithm that, unlike consensus-based solutions, does not require iterative internode communication between sensor measurements. Internode communication cost is further reduced by a novel hybrid GMM/SMC implementation of the proposed filter. Experimental results show that RndEx-BF approaches the performance of a flooding-based implementation of the optimal centralized Bernoulli filter with much lower bandwidth requirements.	bernoulli polynomials;brainfuck;centralized computing;distributed algorithm;google map maker;iterative method;requirement;sensor	Stiven Schwanz Dias;Marcelo G. S. Bruno	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178726	mathematical optimization;simulation;speech recognition;computer science;trajectory;mathematics;statistics;monte carlo method	Robotics	53.488700174016444	3.3143820004993443	63966
16fd0f282e86f4bc03b724d2c3e1375fbae6be5a	zero-branch tree encoding of speech pitch/voicing signals	linear predictive coding speech processing zero branch encoding speech pitch voicing tree encoding;speech analysis and processing encoding;linear prediction coding;speech analysis and processing;encoding speech jitter linear predictive coding synchronization frequency bit rate delay clocks vocoders;encoding	A computationally efficient, although suboptimal, tree encoding method for the pitch and voicing parameters of an LPC (linear predictive coding) vocoder is presented. It is shown that when pitch and voicing signals are combined, it becomes difficult to take advantage of linear predictors and at the same time avoid any errors in voicing. The modified pitch tree coder presented here solves this problem by incorporating a branch leading to zero pitch value from each node of the tree. Only two bits per analysis frame are used to convey the combined pitch/voicing signal, with 1.585 bits being used to encode nonzero pitch values. >		V. Goncharoff;B. Bukiet;D. Hayner	1989	IEEE Trans. Communications	10.1109/26.46520	linear predictive coding;speech recognition;computer science;encoding;audio time-scale/pitch modification	Mobile	48.846282400849404	-9.072436526297592	64406
deaeb53c2d97e164fbd908f0740c9623c198838c	computing with coupled chaotic neuronal maps		Recently, there has been a growing interest in unconventional computing concepts including chaos computing, quantum computing, natural computing, biologically-inspired computing, DNA computing, etc. In this paper, we focus on the chaotic computing with neuronal systems [1, 2]. Coupled chaotic neuron model maps has been proposed in studies of the squid giant axon and the Hodgkin–Huxley equation [1]. Chaos represent a deterministic dynamical system that is non-linear, sensitive to initial condition and that exhibits sustained irregularity. Chaotic phenomena is found in many systems such as laser, electronic circuit and in chemical and biological systems. The versatility of chaotic functions in general gives us opportunities to exploit many input and output mapping suitable for chaos–based computing, thus forming a strong motivation to use chaos for computing, together with its abundant presence in nature and engineering systems [3]. It is well known that a neuron exhibits chaotic behaviour [1, 4] and we can exploit this characteristic as	bio-inspired computing;biological neuron model;biological system;chaos computing;chaos theory;computation;dna computing;dynamical system;electronic circuit;hodgkin–huxley model;huxley: the dystopia;information processing;initial condition;input/output;mit engineering systems division;map;natural computing;nonlinear system;offset binary;parallel computing;quantum computing;unconventional computing	Pooja Rani Sharma;Manish Dev Shrimali	2011	IJUC		chaotic;mathematics;control theory	HPC	40.94891435699517	-0.7081020998804213	64519
095cb57c425090d857f5e2de93e9541dc2e494a3	efficacy of memristive crossbars for neuromorphic processors	neural network learning algorithm;neuromorphic processors;neural nets;multilayer neural networks;nonlinear separable pattern recognition;memristors;virtual ground approach;training;spice learning artificial intelligence memristors neural nets;crossbar circuits;nonlinearly separable logic functions;memristive crossbars;integrated circuit modeling;mathematical model;memristive crossbars nonlinearly separable logic functions virtual ground approach crossbar circuits spice neural network learning algorithm multilayer neural networks memristor based neuron circuit nonlinear separable pattern recognition memristor based neuromorphic circuits neuromorphic processors;neurons;learning artificial intelligence;memristors neurons training integrated circuit modeling spice mathematical model biological neural networks;memristor based neuromorphic circuits;spice;memristor based neuron circuit;biological neural networks	This paper describes memristor-based neuromorphic circuits for non-linear separable pattern recognition. We initially describe a memristor based neuron circuit and then show how multilayer neural networks can be constructed using this neuron circuit. These neuromorphic circuits are capable of learning both linearly and non-linearly separable logic functions. This paper presents the first study of applying neural network learning algorithms to these circuits in SPICE. Our simulations capture alternate current paths within the memristor crossbars and wire resistances that are essential to properly model in crossbar circuits. Our results show that neural network learning algorithms are able to train around these alternate current paths. Further, it was shown that neural networks can properly train the passive memristor-based crossbars without having to use virtual ground mode operational amplifiers as suggested in previous work. Our circuit requires in-situ training, but reduces the number of transistors required by the circuit by about 3 times and reduced the circuit power consumption almost 2 orders of magnitude compared to a virtual ground approach. The key impact of this study is the demonstration through low level circuit simulations that dense memristor crossbars can be effectively utilized to build neuromorphic processors.	algorithm;artificial neural network;boolean algebra;central processing unit;computer simulation;crossbar switch;linear separability;machine learning;memristor;neuromorphic engineering;neuron;nonlinear system;operational amplifier;pattern recognition;spice;simulation;transistor;virtual ground	Chris Yakopcic;Raqibul Hasan;Tarek M. Taha;Mark R. McLean;Doug Palmer	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889807	memristor;computer science;theoretical computer science;machine learning;mathematical model;neuromorphic engineering;artificial neural network	EDA	39.20873286963025	-1.0819758608301568	64639
8bba19929277e26c6a1165e990358fe1875ef458	2d-spectral estimation based on dct and modified magnitude group delay	discrete cosine transform;hilbert transform;gaussian white noise;communications and radar;discrete fourier transform;spectral estimation;signal to noise ratio	This paper proposes two new 2D-spectral estimation methods. The 2D-modified magnitude group delay (MMGD) is applied to 2D-discrete Fourier transform (2DDFT) for the first and to the analytic 2D-discrete Cosine transform for the second. The analytic 2D-DCT preserves the desirable properties of the DCT (like, improved frequency resolution, leakage and detectability) and is realized by a 2D-discrete cosine transform (2D-DCT) and its Hilbert transform. The 2D-MMGD is an extension from 1D to 2D, and it reduces the variance preserving the original frequency resolution of 2D-DFT or 2D-analytic DCT, depending upon to which is applied. The first and the second methods are referred to as DFT-MMGD and DCT-MMGD, respectively. The proposed methods are applied to 2D sinusoids and 2D AR process, associated with Gaussian white noise. The performance of the DCT-MMGD is found to be superior to that of DFT-MMGD in terms of variance, frequency resolution and detectability. The performance of DFT-MMGD and DCT-MMGD is better than that of 2D-LP method even when the signal to noise ratio is low. S. V. Narasimhan (B) Digital Signal Processing Systems Group, Aerospace Electronics and Systems Division, National Aerospace Laboratories, Bangalore 560 017, India e-mail: narasim@nal.res.in S. V. Narasimhan Council of Scientific and Industrial Research, New Delhi, India P. Sandeep · B. K. Shreyamsha Kumar Department of Electronics and Communication Engineering, National Institute of Technology Karnataka, Srinivasanagar PO, Surathkal 575 025, Karnataka, India		P. Sandeep;B. K. Shreyamsha Kumar;S. V. Narasimhan	2013	Signal, Image and Video Processing	10.1007/s11760-011-0286-9	gabor transform;fourier transform;constant q transform;discrete-time fourier transform;transform coding;speech recognition;hartley transform;s transform;harmonic wavelet transform;modified discrete cosine transform;hilbert transform;short-time fourier transform;continuous wavelet transform;fractional fourier transform;hilbert–huang transform;discrete sine transform;discrete fourier transform;discrete cosine transform;mathematics;spectral density estimation;white noise;discrete fourier transform;signal-to-noise ratio;non-uniform discrete fourier transform;hilbert spectral analysis;statistics	EDA	41.70248739110273	-7.978593012281653	64984
01b4f506d24bfe59f450d17007f883e7165005b7	development of a deeply-coupled gps/ins integration algorithm using quaternions	global positioning system tracking loops clocks receivers quaternions kalman filters;kalman filters;inertial navigation;quaternions deeply coupled gps ins;global positioning system;rf deeply coupled gps ins integration algorithm quaternions global positioning system inertial navigation system extended kalman filter ekf ifen gps radio frequency signal simulator;kalman filters computerised instrumentation global positioning system inertial navigation;computerised instrumentation	A deeply-coupled Global Positioning System (GPS)/ Inertial Navigation System (INS) integration algorithm is proposed in this paper. The mathematical system process and observation models are provided. Due to the nonlinearity of the system models, an Extended Kalman Filter (EKF) is employed, which uses quaternions as the representation of attitude. The integrated algorithm is tested using the IFEN GPS radio frequency (RF) signal simulator. Both static and dynamic scenarios are simulated. Numerical results are compared and analyzed.	algorithm;extended kalman filter;gps signals;global positioning system;inertial navigation system;multiprocessing;nonlinear system;numerical method;observable;radio frequency;simulation	Yuhong Yang;Junchuan Zhou;Holger Nies;Otmar Loffeld;Stefan Knedlik	2013	Proceedings of the 16th International Conference on Information Fusion		control engineering;gps/ins;satellite navigation;geodesy;engineering;control theory	Robotics	51.07599519123747	1.2340805753262176	65347
56538e669707e61a8573257ceda03859fdedd637	the impetus project: using abacus for the high performance computation of radiative tables for accretion onto a galaxy black hole		We present the intensive calculations of digital tables for the radiative terms that appear in the energy and momentum equations used to simulate the accretion onto supermassive black holes (SMBHs) at the centers of galaxies. Cooling and heating rates are presented, calculated with a Spectral Energy Distribution constructed from: an accretion disk plus an X-ray power-law and an accretion disk plus a Corona. The electronic structures of atoms, the photoionization cross-sections, and the recombination rates are treated in great detail. With the recent discovery of outflows originating at sub-parsec scales, these tables may provide a useful tool for modeling gas accretion processes onto a SMBH.	black hole;computation;computer cooling;electronic structure;photoelectrochemical process;simulation	José M. Ramírez-Velasquez;Jaime Klapp;Ruslan F. Gabbasov;Fidel Cruz;Leonardo Di G. Sigalotti	2016		10.1007/978-3-319-57972-6_28	radiative transfer;astrophysics;computer science;corona;parallel computing;supermassive black hole;black hole;spectral energy distribution;accretion (meteorology);photoionization;galaxy	HPC	45.1949556747467	2.136061197131864	65688
3296d4e2c8faee600e0f39070841e4e926544814	parameter driven monitoring for a flip-chip led module under power cycling condition		In this paper, a parameter driven monitoring model is introduced, in which a flip-chip LED module was investigated during a power cycling test. This approach was investigated to develop a monitoring model to describe thermally induced solder fatigue as root cause of flip-chip failure in a power cycling test. As monitoring parameter the thermal resistance of the LED module was used, which was determined by thermal impedance measurements of the whole LED module, as well as for each LED chip itself. Further analyses of the occurring temperature at the LED junction recorded of each chip during the power cycling test were used to generate a prediction model. The evaluation of the temperature change allowed to forecast the number of cycles until failure.	flip chip;power cycling	Julien Magnien;Lisa Mitterhuber;Jördis Rosc;Franz Schrank;Stefan Hörth;Matthias Hutter;Stefan Defregger;Elke Kraker	2018	Microelectronics Reliability	10.1016/j.microrel.2018.01.005	engineering;chip;electronic engineering;root cause;power cycling;flip chip;thermal resistance	Arch	53.43154086172249	-2.465868778813586	66306
0553693b02111771b3c9f5f090cee8a7e9a3758a	optimum detection for spread-spectrum watermarking that employs self-masking	digital watermarking;watermarking;image coding;spread spectrum;watermark detection;neyman pearson criterion;neyman pearson criterion digital watermarking watermark detection spread spectrum human visual system perceptual masking;nonlinear functions;human visual system;watermarking image coding industrial property nonlinear functions;industrial property;perceptual masking;human visual system optimum detection spread spectrum watermarking digital watermarking intellectual property rights digital media image watermarking schemes just noticeable difference nonlinear function nonlinearly embedded watermarks closed form detectors self masking properties;spread spectrum communication watermarking detectors humans visual system protection intellectual property robustness computer science security	Digital watermarking is an efficient and promising approach to protect intellectual property rights of digital media. Spread spectrum (SS) is one of the most widely used image watermarking schemes because of its robustness against attacks and its support for the exploitation of the properties of the human visual system (HVS). To maximize the watermark strength without introducing visual artifacts, in SS watermarking, the watermark signal is usually modulated by the just-noticeable difference (JND) of the host image. In advanced perceptual models, the JND is characterized as a nonlinear function of local image features. The optimum detection scheme for such nonlinearly embedded watermarks, however, has rarely been studied. In this paper, we address this problem and propose a novel approach that transforms the test signal to a perceptually uniform domain and then performs Bayesian hypothesis testing in that domain. Locally optimum detectors for arbitrary host signal distributions and arbitrary JND models that exploit the self-masking property of the HVS are derived in closed forms, in which the test signal is first nonlinearly preprocessed before a linear correlator is applied. The optimality of the proposed detector is justified mathematically according to the Neyman-Pearson criterion. Simulation results demonstrate the superior performances of the proposed detector over the conventional linear correlation detector.	digital media;digital watermarking;embedded system;frequency-hopping spread spectrum;human visual system model;modulation;nonlinear system;performance;preprocessor;receiver operating characteristic;sensor;simulation;unsharp masking;utility functions on indivisible goods;visual artifact	Wei Liu;Lina Dong;Wenjun Zeng	2007	IEEE Transactions on Information Forensics and Security	10.1109/ICIP.2007.4379864	computer vision;speech recognition;digital watermarking;computer science;mathematics;watermark;computer security	Vision	41.65691019042398	-9.683267121631719	66318
d840d270e90be72ae294519c38f21f019af60e5f	evolving wavelets using a coevolutionary genetic algorithm and lifting	biorthogonal wavelets;digital filter;compact representation;genetic algorithm	Finding a good wavelet for a particular application and type of input data is a difficult problem. Traditional methods of wavelet design focus on abstract properties of the wavelet that can be optimized analytically but whose influence on its real-world performance are not entirely understood. In this paper, a coevolutionary genetic algorithm is developed that searches the space of biorthogonal wavelets. The lifting technique, which defines a wavelet as a sequence of digital filters, provides a compact representation and an efficient way of handling necessary constraints. The algorithm is applied to a signal compression task with good results.	cubic hermite spline;cubic function;digital filter;experiment;genetic algorithm;lifting scheme;signal compression;spline (mathematics);wavelet	Uli Grasemann;Risto Miikkulainen	2004		10.1007/978-3-540-24855-2_109	wavelet;mathematical optimization;genetic algorithm;digital filter;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;discrete wavelet transform;lifting scheme;gabor wavelet	AI	43.96890142725983	-6.642255901637952	66350
723210847a4e2319aa0d8e5a2f43f15b45acbb3d	crossnets: neuromorphic networks for nanoelectronic implementation	hopfield model;cmos integrated circuits;circuit integre cmos;modele hopfield;diseno circuito;integrated circuit;modelo hopfield;circuit design;nanotechnology;tecnologia mos complementario;single molecule;sinapsis;nanotecnologia;biomimetique;conception circuit;nanowires;reseau neuronal;nanotechnologie;technologie mos complementaire;red neuronal;complementary mos technology;biomimetics;neural network;synapse	Hybrid “CMOL” integrated circuits, incorporating advanced CMOS devices for neural cell bodies, nanowires as axons and dendrites, and singlemolecule latching switches as synapses, may be used for the hardware implementation of extremely dense (~10 cells and ~10 synapses per cm) neuromorphic networks, operating up to 10 times faster than their biological prototypes. We are exploring several “CrossNet” architectures that accommodate the limitations imposed by CMOL hardware and should allow effective training of the networks without a direct external access to individual synapses. CrossNet training in the Hopfield mode have been confirmed on a software model of the network.	cmos;hopfield network;integrated circuit;network switch;neuromorphic engineering;synapse	Özgür Türel;Konstantin Likharev	2003		10.1007/3-540-44989-2_90	biomimetics;computer science;synapse;integrated circuit;circuit design;cmos;artificial neural network;nanowire	Arch	39.30489867161928	-0.9562905951122609	66531
798a19d2b930f068cb6257f03cc45377d2ac4334	scaled unscented kalman filter for rssi-based indoor positioning and tracking	mobile nodes;ieee 802 11n standard;kalman filters;received signal strength indicator;wireless lan computational complexity indoor navigation kalman filters monte carlo methods rssi;global positioning system;tracking extended kalman filter ieee 802 11 standards received signal strength indicator scaled unscented kalman filter;wireless lan kalman filters mobile nodes global positioning system ieee 802 11n standard received signal strength indicator;wireless lan;monte carlo simulation scaled unscented kalman filter rssi based indoor positioning and tracking indoor location tracking system received signal strength indicator wireless local area network wlan extended kalman filter computational complexity sigma point kalman filters	Global positioning technologies such as the Global Positioning System (GPS) are ubiquitously available for different positioning applications. Within indoor environments, coverage of the explicit sensors based on GPS is limited. Developing an indoor location tracking system based on the Received Signal Strength Indicator (RSSI) of the Wireless Local Area Network (WLAN) is considered cost effective method. The widely used technique for estimating the position out of the RSSI measurements is the Extended Kalman Filter (EKF). However, EKF has high computational complexity due to the calculation of Jacobian matrices and suffers from filer instability. In this paper, we propose the Scaled Unscented Kalman Filter (SUKF), which is one of the Sigma Point Kalman Filters (SPKF) family, to overcome the limitations of the EKF. SUKF shall work over the WLAN IEEE 802.11n networks to exploit the RSSI range measurements for localizing and tracking of a mobile node. For performance evaluation, SUKF is compared with the EKF. Results are illustrated using Monte Carlo simulation in MATLAB.	academy;algorithm;computational complexity theory;effective method;extended kalman filter;fingerprint (computing);global positioning system;instability;jacobian matrix and determinant;matlab;monte carlo method;netapp filer;performance evaluation;sensor;simulation;tracking system	Laith Khalil;Peter Jung	2015	2015 9th International Conference on Next Generation Mobile Applications, Services and Technologies	10.1109/NGMAST.2015.20	kalman filter;embedded system;global positioning system;fast kalman filter;telecommunications;computer science;extended kalman filter;moving horizon estimation	Robotics	50.1599831719673	0.8745828952911697	66963
4ce54f13e9af545d32c985d49644069521d00607	in-vehicle data logging system for fatigue analysis of drive shaft	windows ce 3 0 operating system;torque;fatigue;piecewise linear approximation;shafts;real time data acquisition system;over sampling data acquisition system;vehicles data loggers data acquisition data compression piecewise linear techniques approximation theory huffman codes operating systems computers signal reconstruction;data compression;huffman coding;piecewise linear techniques;piecewise linear approximation method;signal design;invehicle data logging system;signal reconstruction invehicle data logging system fatigue analysis real time data acquisition system windows ce 3 0 operating system over sampling data acquisition system data reduction decimation data compression piecewise linear approximation method run length coding huffman coding;decimation;data acquisition system;real time data;huffman codes;approximation theory;fatigue analysis;first order;operating system;run length coding;bandwidth;cost effectiveness;signal reconstruction;data reduction;vehicles;data loggers;data acquisition;fatigue shafts data compression torque data acquisition bandwidth real time systems signal design operating systems piecewise linear approximation;operating systems computers;operating systems;real time systems	The work presents a cost-effective custom-made data logging system for in-vehicle use. Based on the required bandwidth and accuracy of the torque signal a real-time data acquisition system for long-term data logging of torque signal has been designed and implemented. The system is based on a computer running Windows CE 3.0 operating system. Filtered input signal is sample by over-sampling data acquisition system. Data reduction is achieved by decimation and data compression. Three data compression methods are compared: two methods based on zero-order and first-order predictors and a piecewise linear approximation method followed by run-length and Huffman coding. Several error bands have been investigated in the data compression methods. Test result show that a system with 1 GB flash card can store over 10000 hrs of drive shaft load history data allowing signal reconstruction with satisfactory accuracy.	data acquisition;data compression;data logger;decimation (signal processing);first-order predicate;flash memory;huffman coding;linear approximation;microsoft windows;operating system;oversampling;piecewise linear continuation;real-time clock;real-time data;run-length encoding;sampling (signal processing);signal reconstruction	Slobodan Ilic;Jayantha Katupitiya;Michal J. Tordon	2004	International Workshop on Robot Sensing, 2004. ROSE 2004.	10.1109/ROSE.2004.1317610	embedded system;electronic engineering;real-time computing;computer science	Robotics	45.771399152522626	-4.240339145272167	67000
8e4c7f72f4b2f733b2d308ba7af46e11e5c88b74	complexity of the newton method for set-valued maps	68w40;49j53;complexity analysis;newton s method;set valued maps;93b40	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	complexity;francis;map;newton's method;primary source	Georgi Smirnov	2014	Optimization Methods and Software	10.1080/10556788.2013.779695	local convergence;mathematical optimization;mathematical analysis;newton fractal;calculus;mathematics;newton's method	Robotics	49.550695655579915	-2.9594815787258626	67336
3f2538f21d15c3817d7130e318dace23275b5535	toa-based lateral distance measurement system using uwb impulse radio	relative position;base stations;distance measure;intelligent transport system;collision prediction;ranging error toa based lateral distance measurement system uwb impulse radio intelligent transportation systems collision prediction system time of arrival based bilateration;intelligent transportation systems;lateral distance;low pass filter;collision prediction system;ultra wideband communication distance measurement low pass filters time of arrival estimation;accuracy;distance measurement;toa based lateral distance measurement system;time of arrival based bilateration;ultra wideband;ultra wideband impulse radio;ranging error;time of arrival estimation;ultra wideband communication;time of arrival;low pass filters;transceivers;vehicles;estimation error;target tracking;impulse radio;vehicles target tracking distance measurement base stations accuracy estimation error transceivers;low pass filter lateral distance ultra wideband impulse radio relative position collision prediction;uwb impulse radio	Lateral distance between two traffic participants is an important context for intelligent transportation systems for realizing a collision prediction system. Obtaining lateral distance requires costly hardware, prohibiting traffic participants such as pedestrians and/or bicyclists to receive benefits of lateral distance information for securing their safety. In this paper, a time-of-arrival (TOA) based bilateration is proposed for estimating relative lateral distance using ultra-wideband impulse radio (UWB-IR). Ranging error of UWB-IR systems affecting the estimation accuracy of lateral distance is coped with applying a low pass filter to angular data. Experimental results show that the estimation error is reduced from 8 m to 3 m when the relative distance between a target vehicle and a pedestrian is less than 15 m, using a portable UWB-IR system with 30 cm ranging accuracy.	angularjs;communications protocol;computer simulation;experiment;graphical user interface;lateral computing;lateral thinking;low-pass filter;system of measurement;time of arrival;ultra-wideband	Keiichi Nakamura;S. Kobayashiy;Hisanori Matsumoto;Noboru Koshizuka;Ken Sakamura	2010	2010 IEEE 6th International Conference on Wireless and Mobile Computing, Networking and Communications	10.1109/WIMOB.2010.5645049	embedded system;low-pass filter;telecommunications;computer science	Robotics	50.493766466240544	0.8416232617575319	67381
eec294a695fcfe61ec71fdd375eb56436027bcdc	a programmable controller for spatio-temporal pattern stimulation of cortical visual prosthesis		This paper proposes a programmable stimulation controller for cortical visual prosthesis to configure spatio-temporal parameters of stimulation. Since the relationship between stimulation to the visual cortex and responses in vision has not been clarified enough both flexibility for stimulation strategies and timewise precision of stimulation are required for in-vivo experiments. In the proposed stimulation controller a 16bit microprocessor is utilized for various stimulation strategies and dedicated control signal generator for electrodes runs in parallel with the microprocessor. The proposed stimulation controller generates stimulations in temporal resolution of 1 yus and spatio resolution up to 4 096 stimulation sites. Evaluation with an FPGA demonstrates the programmability of its implementation.	experiment;field-programmable gate array;microprocessor;spatiotemporal pattern;video-in video-out;visual prosthesis	Tomoki Sugiura;Arif Ullah Khan;Jaehoon Yu;Yoshinori Takeuchi;Seiji Kameda;Takatsugu Kamata;Yuki Hayashida;Tetsuya Yagi;Masaharu Imai	2016	2016 IEEE Biomedical Circuits and Systems Conference (BioCAS)	10.1109/BioCAS.2016.7833824	control engineering;electronic engineering;computer hardware;engineering	Robotics	41.2596709113731	-2.2618419900372038	67400
69b2f167e764ba35f6a1a39ab247e155b784626c	live demonstration: tactile events from off-the-shelf sensors in a robotic skin		The demonstration presents a robotic event-based tactile infrastructure for a humanoid robot. It leverages on currently deployed sample-based capacitive sensors to generate tactile events, enabling the investigation and development of event-driven tactile applications, and minimizing communication bandwidth and latency. The modular FPGA-based system samples data from tactile sensors and generates address-events, transmitted through an asynchronous serial address-event representation protocol. To enable performance comparisons of the event-driven approach with respect to standard sample-based solutions, the acquisition modules can directly forward the input samples through the same event-based communication channel. We will show in real time a comparison between the tactile events and the original sampled data generated when the skin patch is touched.		Chiara Bartolozzi;Paolo Motto Ros;Francesco Diotalevi;Marco Crepaldi	2017	2017 IEEE Biomedical Circuits and Systems Conference (BioCAS)	10.1109/BIOCAS.2017.8325104	capacitive sensing;skin patch;humanoid robot;electronic engineering;asynchronous communication;modular design;computer hardware;computer science;tactile sensor;bandwidth (signal processing);communication channel	Robotics	44.17382470443196	-2.351588750713757	67446
f74f52b5a2b6d09048b7d9404fa300bbf006831b	intrinsic activation of iridium electrodes over a wireless link	microelectrodes;eye;iridium;prosthetics;application specific integrated circuits;intracortical visual prosthesis project wireless link iridium electrode intrinsic activation wireless neural stimulator application specific integrated circuit iridium microelectrode activated iridium oxide film microelectrode current controlled driver voltage compliance limit output waveform voltage pulsing waveform ramp activation waveform iridium electrode current driven activation wireless link;iridium microelectrodes visual prosthesis;neuromuscular stimulation;vision application specific integrated circuits biomedical electrodes eye iridium iridium compounds microelectrodes neuromuscular stimulation prosthetics;biomedical electrodes;vision;iridium compounds;wireless communication application specific integrated circuits microelectrodes metals wireless sensor networks current measurement	Activated Iridium Oxide Film (AIROF) microelectrodes are regarded as advantage for stimulation of neural tissue owing to their superior charge injection capabilities, as compared to other noble-metal based electrodes. Including AIROF electrodes within an implantable neural stimulator can be challenging since the stimulator fabrication steps often involve elevated temperatures at which the AIROF can be damaged. In this work, a wireless neural stimulator application-specific-integrated-circuit (ASIC) was used to intrinsically activate iridium microelectrodes. This intrinsic activation allows for the growth of the AIROF as the final assembly step after the entire device is assembled, thus avoiding stress on the AIROF. Since a typical neural stimulator is essentially a current-controlled driver with voltage compliance limits, its output waveform can be tuned to match the traditional voltage pulsing/ramp activation waveform. Here the feasibility of the current driven activation of iridium electrodes, over a wireless link, is demonstrated.	activation action;application-specific integrated circuit;implants;nerve tissue;neural network simulation;prosthesis;ramp simulation software for modelling reliability, availability and maintainability;waveform;electrode;iridium oxide;voltage	Zhe Hu;Philip R. Troyk;Glenn A. DeMichele;Kevin Kayvani;Sungjae Suh	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346543	vision;electronic engineering;neuroscience;microelectrode;computer science;electrical engineering;iridium;biological engineering;application-specific integrated circuit	Robotics	47.00158349907615	0.7979562189077617	67701
73cf89e6d29a92c7eef10a2862648056fa2d8a5d	vlsi implementation of visible watermarking for secure digital still camera design	cmos integrated circuits;watermarking;image numerique;arquitectura circuito;image coding;integrated circuit;systeme multimedia;fotografia digital;implementation;digital watermark;circuit vlsi;photographie numerique;copyright;circuit architecture;circuito integrado;tecnologia mos complementario;image sensors;0768;multimedia systems;conception circuit integre;chip;copyright protection;prototipo;digital photography;integrated circuit design;vlsi circuit;prototype cmos vlsi chip vlsi architecture digital image watermarking digital still camera multimedia object copyright protection decoding mechanism;imagen numerica;architecture circuit;vlsi;on the fly;very large scale integration watermarking digital cameras hardware copyright protection inspection decoding digital images computer architecture circuits;digital image watermarking;maquina fotografica;digital image;circuito vlsi;implementacion;image sensors copyright watermarking image coding vlsi cmos integrated circuits;technologie mos complementaire;prototype;appareil photographique;circuit integre;complementary mos technology;camera;vlsi architecture	Watermarking is the process that embeds data called a watermark into a multimedia object for its copyright protection. The digital watermarks can be visible to a viewer on careful inspection or completely invisible and cannot be easily recovered without an appropriate decoding mechanism. Digital image watermarking is a computationally intensive task and can be speeded up significantly by implementing in hardware. In this work, we describe a new VLSI architecture for implementing two different visible watermarking schemes for images. The proposed hardware can insert on-the-fly either one or both watermarks into an image depending on the application requirement. The proposed circuit can be integrated into any existing digital still camera framework. First, separate architectures are derived for the two watermarking schemes and then integrated into a unified architecture. A prototype CMOS VLSI chip was designed and verified implementing the proposed architecture and reported in this paper. To our knowledge, this is the first VLSI architecture for implementing visible watermarking schemes.	cmos;digital camera;digital image;digital watermarking;prototype;secure digital;very-large-scale integration;watermark (data file)	Saraju P. Mohanty;N. Ranganathan;Ravi Namballa	2004	17th International Conference on VLSI Design. Proceedings.	10.1109/ICVD.2004.1261070	embedded system;computer vision;electronic engineering;digital watermarking;computer science;electrical engineering;computer graphics (images)	EDA	42.50063586176241	-4.937646039849848	67977
d653d3d3a4cbd9cbd6fbb67fb1579c94935dc620	consensus-based sparse signal reconstruction algorithm for wireless sensor networks	compressive sensing;sparse;variational bayesian;consensus filter;wireless sensor networks	This article presents a distributed Bayesian reconstruction algorithm for wireless sensor networks to reconstruct the sparse signals based on variational sparse Bayesian learning and consensus filter. The proposed approach is able to address wireless sensor network applications for a fusion-center-free scenario. In the proposed approach, each node calculates the local information quantities using local measurement matrix and measurements. A consensus filter is then used to diffuse the local information quantities to other nodes and approximate the global information at each node. Then, the signals are reconstructed by variational approximation with resultant global information. Simulation results demonstrate that the proposed distributed approach converges to their centralized counterpart and has good recovery performance.	approximation algorithm;calculus of variations;centralized computing;chandra–toueg consensus algorithm;distributed algorithm;kalman filter;lan manager;resultant;signal reconstruction;simulation;sparse matrix;variational principle	Bao Peng;Zhi Zhao;Guangjie Han;Jian Shen	2016	IJDSN	10.1177/1550147716666290	machine learning;pattern recognition;distributed computing	Mobile	53.46614532087616	3.7094620414516513	68177
08cd1b6c225d77d037e155ef7a13660a98785699	asynchronous self-localization of sensor networks with large clock drift	maximum likelihood estimation;sensor network;synchronisation;mle method asynchronous self localization sensor networks clock offsets differential time difference of arrival method dtdoa localization method two stage clock drift cancellation method maximum likelihood estimation;wireless sensor networks maximum likelihood estimation synchronisation time of arrival estimation;maximum likelihood estimate;time of arrival estimation;time of arrival;clock drift;clocks frequency synchronization wireless sensor networks circuits time difference of arrival delay signal processing maximum likelihood estimation timing radio frequency;wireless sensor networks;time difference of arrival;time constraint	Large clock offsets and drifts impose many difficulties on sensor self-localization. We have proposed a differential time-difference-of-arrival (dTDOA) localization method in [1] to overcome the problem caused by asynchronous clock offsets. In this paper, the dTDOA method is extended to combat clock drifts by a two-stage clock-drift cancellation method. Furthermore, based on the clock-drift cancellation, a maximum likelihood estimation (MLE) method that is theoretically optimal for sensor locations is derived. The method can achieve sensor localization using a single round of time-of-arrival (TOA) measurements, and thus greatly reduces the communications burden and timing constraint.	clock drift;multilateration;sensor;time of arrival	Chunpeng Yan;H. Howard Fan	2007	2007 Fourth Annual International Conference on Mobile and Ubiquitous Systems: Networking & Services (MobiQuitous)	10.1109/MOBIQ.2007.4451038	clock synchronization;embedded system;real-time computing;wireless sensor network;computer science;maximum likelihood;statistics	Robotics	51.27458785435696	3.954877382333864	68492
d88408c84a7a15e47bd1dbba117b35e03290087d	a wearable ecg acquisition system with compact planar-fashionable circuit board-based shirt	long term monitoring;biomedical monitoring;biology computing;planar fashionable circuit board p fcb;dry electrodes;printed circuits;electrocardiogram ecg;ecg monitoring shirt;skin;wires;planar fashionable circuit board p fcb dry electrodes electrocardiogram ecg electrodes holter monitor;electrocardiography biology computing biomedical electrodes;prototype hardware wearable ecg acquisition system compact planar fashionable circuit board based shirt electrocardiogram dry electrodes ecg monitoring shirt monitoring chip;chip;prototype hardware;monitoring system;electrocardiography;electrodes;compact planar fashionable circuit board based shirt;integrated circuit interconnections;monitoring chip;holter monitor;fabrics;production;biomedical electrodes;production cost;electrocardiography printed circuits electrodes biomedical monitoring wires fabrics skin integrated circuit interconnections production costs;clothing electrocardiography ambulatory electrodes equipment design humans signal processing computer assisted;wearable ecg acquisition system;electrocardiogram;screen printing	A wearable electrocardiogram (ECG) acquisition system implemented with planar-fashionable circuit board (P-FCB)-based shirt is presented. The proposed system removes cumbersome wires from conventional Holter monitor system for convenience. Dry electrodes screen-printed directly on fabric enables long-term monitoring without skin irritation. The ECG monitoring shirt exploits a monitoring chip with a group of electrodes around the body, and both the electrodes and the interconnection are implemented using P-FCB to enhance wearability and to lower production cost. The characteristics of P-FCB electrode are shown, and the prototype hardware is implemented to successfully verify the proposed concept.	apnea monitor alarm type:type:point in time:apnea monitor:nominal;dermatologic disorders;electrocardiography;interconnection;ion-selective electrodes;printed circuit board device component;printing;prototype;wearable computer;electrode	Jerald Yoo;Long Yan;Seulki Lee;Hyejung Kim;Hoi-Jun Yoo	2009	IEEE Transactions on Information Technology in Biomedicine	10.1109/TITB.2009.2033053	chip;embedded system;telecommunications;computer science;electrode;skin;printed circuit board	Mobile	46.306193195411396	-2.1939680744700834	68535
5eb481db0e5846dd9b042a17a0002bc92782d963	improving sampling rate with multiplexed ultrasonic emitters	sampling methods ultrasonic devices sensors;sensorized environment sampling rate multiplexed ultrasonic emitters position estimation method theoretical analysis robust estimation;robust estimator;sensors;sampling methods algorithm design and analysis humans crosstalk robustness decoding monitoring frequency synchronization signal detection sensor systems;theoretical analysis;position estimation;sampling methods;ultrasonic devices	This paper presents a position estimation method for multiple ultrasonic emitters which are activated simultaneously. Locations of ultrasonic emitters are generally calculated from distance data obtained at receivers, but the emitters must be activated one after another to avoid crosstalk. Thus, the sampling rate for each emitter decreases as the number of emitters increases. The authors solved this problem by activating multiple emitters simultaneously and applying a newly developed position estimation algorithm. This paper presents the theoretical analysis and the results of simulations and experiments.		Toshio Hori;Yoshifumi Nishida;Takeo Kanade;Kenji Akiyama	2003		10.1109/ICSMC.2003.1245696	robust statistics;sampling;sensor;statistics	PL	50.61018625310724	2.546918581302318	68549
aa4b18853271f23e706efd6ac1f6f1426d4146d6	an advanced emulated digital retina model on fpga to implement a real-time test environment	cellular neural;qa75 electronic computers computer science szamitastechnika;digital signal processors;field programmable gate array;szamitogeptudomany;nonlinear network;real time;automatic testing;fpga;cellular neural nets;real time video;computer architecture;nonhomogeneous media;single channel;nonlinear network emulated digital retina model fpga real time test environment real time video cellular neural;retina;network model;real time test environment;digital signal processing chips;differential equations;neurons;field programmable gate arrays;point of view;cellular neural networks;processing speed;emulated digital retina model;cameras;real time systems cellular neural nets digital signal processing chips field programmable gate arrays;retina field programmable gate arrays cellular neural networks neurons hardware automatic testing differential equations cameras nonhomogeneous media computer architecture;hardware;real time systems	This paper presents an extended emulated digital retina model to compute two different retina channels in video real-time. The proposed emulated digital implementation of the two-channel retina model was compared to the previously developed single channel model from three different points of view: processing speed, number of physical cells and accuracy. A real-time test environment with camera input and display output is going to be set up to analyze the retina model implementation on emulated digital CNN (cellular neural/nonlinear network) model by using a 6M gate equivalent FPGA (field programmable gate array)	channel (communications);deployment environment;emulator;field-programmable gate array;gate equivalent;nonlinear system;real-time clock;real-time transcription	Zoltán Nagy;Zsolt Vörösházi;Péter Szolgay	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692993	embedded system;electronic engineering;real-time computing;computer science;field-programmable gate array	EDA	40.3289697212052	-1.9470910523521576	68920
0d46a1336bb003ca684861418abc7cd05f9268d1	pseudoranges error correction in partial gps outages for a nonlinear tightly coupled integrated system	kalman filtering;nonlinear filters;errors;radio receivers;tightly coupled integration global positioning system gps inertial sensors land vehicle navigation parallel cascade identification pci particle filter pf pseudoranges error modeling;sensors;radio receivers error correction global positioning system kalman filters nonlinear filters particle filtering numerical methods;kalman filters;nonlinear systems;global positioning system;error correction;particle filtering;pseudorange equations;kf pci pseudoranges error correction partial gps outages nonlinear tightly coupled integrated system integrated navigation systems global positioning system gps satellites residual correlated errors parallel cascade identification nonlinear system identification technique nonlinear filter mixture particle filter m pf reduced inertial sensor system pci models m pf pci kalman filter;particle filtering numerical methods	Integrated navigation systems based on a tightly coupled integration scheme utilize pseudoranges and pseudorange rates from Global Positioning System (GPS) satellites measured by the receiver. The positioning accuracy is highly dependent on the accuracy of the pseudoranges whose residual errors can deteriorate the overall positioning accuracy. The integrated system can be improved by the provision of more accurate pseudoranges through modeling the residual correlated errors. This paper utilizes parallel cascade identification (PCI), which is a nonlinear system identification technique, to model these correlated errors. To address the nonlinear error characteristics in the whole integrated navigation system, a nonlinear filter, i.e., mixture particle filter (M-PF), is employed to perform tightly coupled integration of a 3-D reduced inertial sensor system (RISS) with a GPS. The M-PF can accommodate the PCI models of the pseudorange errors in the measurement model. The results demonstrate the advantages of using M-PF-PCI for correcting the pseudoranges and enhancing the positioning solution as compared with M-PF-only, Kalman filter (KF)-PCI, and KF-only solutions.	automotive navigation system;error detection and correction;global positioning system;kalman filter;microelectromechanical systems;nonlinear system identification;pci express;pf (firewall);particle filter;pseudorange	Umar Iqbal;Jacques Georgy;Walid Farid Abdelfatah;Michael J. Korenberg;Aboelmagd Noureldin	2013	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2013.2264474	kalman filter;control engineering;electronic engineering;nonlinear system;computer science;engineering;machine learning;control theory;extended kalman filter;statistics	Visualization	50.68435932317093	0.47204222450449795	70239
a253fbb2e35b648bca1c7b329e98688129a5c544	distributed estimation and equalization of room acoustics in a wireless acoustic sensor network	distributed algorithms;acoustic devices;wireless acoustic sensor networks;distributed consensus averaging;equalization;architectural acoustics;acoustic signal processing;wireless sensor networks acoustic devices acoustic signal processing architectural acoustics distributed algorithms equalisers sensor placement;equalisers;sensor placement;equalization performance distributed estimation wireless acoustic sensor networks room acoustics equalization multiple point equalization problem common acoustical pole room model cap room model autonomous node deployment local sensing communication capabilities cap model estimation problem wasn nodes distributed averaging algorithm;sista;distributed consensus averaging wireless acoustic sensor networks room acoustics equalization;estimation microphones vectors loudspeakers computational modeling wireless sensor networks wireless communication;room acoustics;wireless sensor networks	In this paper, the use of a wireless acoustic sensor network (WASN) for the estimation and equalization of room acoustics is proposed as a flexible and promising alternative to the traditional wired implementations. We consider a multiple-point equalization problem based on a common-acoustical-pole (CAP) room model. Instead of collecting microphone signals in a central processing unit to compute the CAP model estimate in a centralized fashion, we deploy a large number of autonomous nodes with local sensing, processing, and communication capabilities to solve the CAP model estimation problem in a distributed manner. Even though the WASN nodes are restricted to exchange information with neighboring nodes only, the use of a distributed averaging algorithm results in a CAP model estimate with an accuracy and equalization performance comparable to a wired implementation.	acoustic cryptanalysis;algorithm;autonomous robot;central processing unit;centralized computing;microphone	Toon van Waterschoot;Marc Moonen	2012	2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)		electronic engineering;acoustics;telecommunications;engineering	Mobile	50.5731456773044	3.915381833556033	70349
3531e066bc507133246446bedd5ba7d41fb2b667	evolutionary pattern recognition in incomplete nonlinear multithreshold networks	eigenvalues and eigenfunctions;pattern recognition fixed point arithmetic eigenvalues and eigenfunctions error analysis computer errors input variables roundoff errors machinery floating point arithmetic programming profession;input variables;error analysis;programming profession;weighted sums;roundoff errors;pattern recognition;fixed point arithmetic;floating point arithmetic;machinery;computer errors	A pattern recognition network which computes a weighted sum of nonlinear functions of its inputs is considered. An algorithm for training this multithreshold network is presented. The multithreshold device is used for classifying patterns into more than two categories. Experimental results on the recognition of hand-printed characters are shown. In this case, the nonlinear functions consisted of an orthogonal set of property detectors. The network changed its structure by an evolutionary technique which consisted of periodic replacement of the least useful elements by new ones, randomly chosen.	pattern recognition	Anthony N. Mucciardi;Earl E. Gose	1966	IEEE Trans. Electronic Computers	10.1109/PGEC.1966.264313	arithmetic;electronic engineering;machine;discrete mathematics;computer science;floating point;theoretical computer science;operating system;mathematics;fixed-point arithmetic;algorithm;statistics;algebra	Vision	39.19932096313727	-3.9885653548691486	70486
21f07cb4ec058d24b4990d627f644fb0fe5c2d64	optimization of coil element configurations for a matrix gradient coil		Recently, matrix gradient coils (also termed multi-coils or multi-coil arrays) were introduced for imaging and B0 shimming with 24, 48, and even 84 coil elements. However, in imaging applications, providing one amplifier per coil element is not always feasible due to high cost and technical complexity. In this simulation study, we show that an 84-channel matrix gradient coil (head insert for brain imaging) is able to create a wide variety of field shapes even if the number of amplifiers is reduced. An optimization algorithm was implemented that obtains groups of coil elements, such that a desired target field can be created by driving each group with an amplifier. This limits the number of amplifiers to the number of coil element groups. Simulated annealing is used due to the NP-hard combinatorial nature of the given problem. A spherical harmonic basis set up to the full third order within a sphere of 20-cm diameter in the center of the coil was investigated as target fields. We show that the median normalized least squares error for all target fields is below approximately 5% for 12 or more amplifiers. At the same time, the dissipated power stays within reasonable limits. With a relatively small set of amplifiers, switches can be used to sequentially generate spherical harmonics up to third order. The costs associated with a matrix gradient coil can be lowered, which increases the practical utility of matrix gradient coils.	algorithm;amplifier;basis set (chemistry);coil device component;diameter (qualifier value);gradient descent;mathematical optimization;np-hardness;network switch;numerous;ordinary least squares;preparation;simulated annealing;simulation;switch device component	Stefan Kroboth;Kelvin J. Layton;Feng Jia;Sebastian Littin;Huijun Yu;Jürgen Hennig;Maxim Zaitsev	2018	IEEE Transactions on Medical Imaging	10.1109/TMI.2017.2743463	spherical harmonics;mathematics;mathematical optimization;electromagnetic coil;simulated annealing;harmonic analysis;shim (magnetism);amplifier;matrix (mathematics);least squares	Vision	45.90834495837047	-3.301568120265465	70642
6f8d8f95800251771d5d9cb090d87b0d6c26efca	a learning-enabled neuron array ic based upon transistor channel models of biological phenomena	cmos integrated circuits;topology;topology bioelectric phenomena biomedical electronics biomimetics cmos integrated circuits neural nets neurophysiology;neural nets;electrical implementation learning enabled neuron array ic transistor channel models biological phenomena biologically based electronic neuron models cmos ic process dense circuit models synaptic behavior biological computation biological learning address event representation spike communication ic architecture configuration tools testing platform stdp neuron dynamics measurement compiled spiking neuron wta topology;artificial intelligence neural networks computer neurons synapses transistors electronic;biomedical electronics;neurophysiology;bioelectric phenomena;neurons arrays integrated circuit modeling biological system modeling;biomimetics;neuromorphic engineering electrical implementation of neurobiology	We present a single-chip array of 100 biologically-based electronic neuron models interconnected to each other and the outside environment through 30,000 synapses. The chip was fabricated in a standard 350 nm CMOS IC process. Our approach used dense circuit models of synaptic behavior, including biological computation and learning, as well as transistor channel models. We use Address-Event Representation (AER) spike communication for inputs and outputs to this IC. We present the IC architecture and infrastructure, including IC chip, configuration tools, and testing platform. We present measurement of small network of neurons, measurement of STDP neuron dynamics, and measurement from a compiled spiking neuron WTA topology, all compiled into this IC.	anatomic node;anatomy, regional;artificial neuron;biological phenomena;biological computation;cmos;compiler;computation (action);eeprom;hl7 2.5 event type;integrated circuit;neuromorphic engineering;node - plant part;synapse;synapses;synaptic package manager;transistor;weapon target assignment problem	Stephen Brink;Stephen Nease;Paul E. Hasler;Shubha Ramakrishnan;Richard B. Wunderlich;Arindam Basu;Brian P. Degnan	2013	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2012.2197858	biomimetics;electronic engineering;neuroscience;computer science;electrical engineering;cmos;neurophysiology	Metrics	39.98005694586458	-1.098233239766319	70759
884977cc80897e87ab271275a2e9b4868584b45c	distributed sequential monte carlo algorithms for node localization and target tracking in wireless sensor networks	sensors;manganese;signal processing;target tracking;signal processing algorithms;wireless sensor networks;monte carlo methods	We address the problem of tracking a maneuvering target that moves along a region monitored by a wireless sensor network (WSN) whose nodes, including sensors and data fusion centers (DFCs), are located at unknown positions. Therefore, the target trajectory, its velocity and all node locations must be estimated jointly, without assuming the availability of any “beacons” with known location that can be used as a reference. We introduce a new method that comprises: (i) a combination of Monte Carlo optimization and iterated importance sampling to yield and initial population of node locations with high posterior probability (given data collected at the network startup) and (ii) a sequential Monte Carlo (SMC) algorithm for recursively tracking the target position and velocity and sequentially re-generating new populations of node positions as new observations become available. The resulting algorithm is implemented in a distributed fashion. Assuming that the communication capabilities of the DFCs enable them to share some data, each DFC can run an independent SMC algorithm and produce local estimates of the magnitudes of interest. Optimal data fusion is achieved by a linear combination of the local estimates with adequate weights. We illustrate the application of the algorithm in a network of power-aware sensors.	algorithm;computer simulation;importance sampling;iteration;mathematical optimization;monte carlo method;particle filter;population;recursion;sampling (signal processing);sensor;velocity (software development)	Joaquín Míguez;Antonio Artés-Rodríguez	2007	2007 15th European Signal Processing Conference		mathematical optimization;real-time computing;simulation;computer science;brooks–iyengar algorithm	Robotics	53.14106529372809	3.376768326529511	71217
ad84993816dea35e8a6e07bfdbd9e19d60f946bf	joint object detection and tracking in sensor networks	nonlinear filters;kalman filters;signal intensity nonlinear filtering sensor data fusion moving object tracking moving object detection optimal detection algorithm optimal nonlinear filter likelihood ratio test extended kalman filter passive sensor network;object tracking;sensor fusion kalman filters nonlinear filters object detection object tracking;sensor fusion;object detection	A nonlinear filtering based approach that fuses sensor data from the local sensors is proposed to jointly detect and track a moving object in a sensor field. First, the optimal detection algorithm based on the optimal nonlinear filter and the likelihood ratio test is provided. Then, a computationally efficient approach based on the extended Kalman filter is proposed and applied to jointly detect and track an object with very weak signal in a passive sensor network. The signal intensity is assumed to be inversely proportional to a power of the distance from the object. Simulation results show that the proposed detection approach can quickly detect the object after it appears in the sensor field with very high detection performance, even when the object state estimate is not very accurate.	algorithm;algorithmic efficiency;extended kalman filter;nonlinear system;object detection;sensor;simulation	Ruixin Niu	2013	2013 16th International Symposium on Wireless Personal Multimedia Communications (WPMC)		kalman filter;computer vision;computer science;machine learning;video tracking;control theory;sensor fusion	Mobile	53.05362201689083	2.903571199055969	71818
eeb2d833b1c6bc0a0e4ecfadf052857b1d4279ff	an efficient singular value decomposition algorithm for digital audio watermarking	detection probability;dwt;image processing;singular value;singular value decomposition;svd;lexicographic order;time domain;image watermarking;dst;dft;dct;audio watermarking	The singular value decomposition (SVD) mathematical technique is utilized, in this paper, for audio watermarking in time and transform domains. Firstly, the audio signal in time or an appropriate transform domain is transformed to a 2-D format. The SVD algorithm is applied on this 2-D matrix, and an image watermark is added to the matrix of singular values (SVs) with a small weight, to guarantee the possible extraction of the watermark without introducing harmful distortions to the audio signal. The transformation of the audio signal between the 1-D and 2-D formats is performed in the well-known lexicographic ordering method used in image processing. A comparison study is presented in the paper between the time and transform domains as possible hosting media for watermark embedding. Experimental results are in favor of watermark embedding in the time domain if the distortion level in the audio signal is to be kept as low as possible with a high detection probability. The proposed algorithm is utilized also for embedding chaotic encrypted watermarks to increase the level of security. Experimental results show that watermarks embedded with the proposed algorithm can survive several attacks. A segment-by-segment implementation of the proposed SVD audio watermarking algorithm is also presented to enhance the detectability of the watermark in the presence of severe attacks.	algorithm;audio signal processing;baker's map;digital watermarking;distortion;embedded system;encryption;experiment;fast fourier transform;image processing;lexicographical order;lexicography;singular value decomposition;the matrix;watermark (data file);whole earth 'lectronic link	Fathi E. Abd El-Samie	2009	I. J. Speech Technology	10.1007/s10772-009-9056-2	computer vision;speech recognition;image processing;theoretical computer science;watermark;singular value decomposition	EDA	41.103348921435106	-9.48142629517554	71887
fbb2d348cb84d0311117c7b1a56b8f58a10c0870	chip-on board technology for low temperature environment. part ii: thermomechanical stresses in encapsulated ball-wedge bond wires	durcissement;module multipuce;thermomechanical stress;deformacion plastica;continuous function;tecnologia electronica telecomunicaciones;condiciones limites;interconnection;hardening;methode element fini;metodo elemento finito;integrated circuit;condition aux limites;numerical method;thermal expansion;dilatation thermique;fonction polynomiale;wire bonding;modulo multipulga;ordre 1;contrainte thermomecanique;union por hilo;circuito integrado;multi chip module;fonction continue;endommagement;finite element method;chip on board;deterioracion;chip on board packaging;tension termomecanica;interconexion;low temperature;multichip module;thermal cycling;thermal test;integrated circuit bonding;first order;metodo numerico;funcion continua;boundary condition;matriz formadora;cycle thermique;dilatacion termica;assemblage circuit integre;robustesse;interconnexion;defaillance;die;deformation plastique;microcâblage;robustness;ciclo termico;rapid assessment;failures;finite element analysis fea;tecnologias;funcion polinomial;damaging;environmental change;grupo a;thermal cycle;endurecimiento;polynomial function;matrice formage;technologie puce sur carte;orden 1;fallo;plastic deformation;methode numerique;circuit integre;essai thermique;cubic spline;robustez;prueba termica	Wire-bonded chip-on-board (CoB) multi chip modules consist of die and bond wires that are encapsulated to protect them from mechanical and chemical damage. This paper describes a rapid-assessment model for the prediction of thermomechanical strains developed in the encapsulated ball–wedge bond wires due to thermal expansions experienced during curing or subsequent environmental changes. The wire profile is modeled using a piece-wise continuous polynomial function (cubic spline) with appropriate boundary conditions at the two bond sites. Plastic deformation is ignored in the current analysis as a first-order approximation. Then a 2D Raleigh–Ritz (RR) model is developed to estimate the thermomechanical stresses in the bond wire due to temperature cycling in the presence of an encapsulant. The purpose of the model is to provide a rapid ranking of the thermomechanical robustness of different wire-bond design options. Results are validated by detailed 2D finite element analysis (FEA) and are compared to fatigue failure data available from thermal cycling tests.	wire bonding	K. K. Jinka;A. Dasgupta;S. Ganesan;S. Ling	2009	Microelectronics Reliability	10.1016/j.microrel.2009.02.008	continuous function;spline;thermal expansion;temperature cycling;hardening;environmental change;numerical analysis;boundary value problem;computer science;engineering;integrated circuit;interconnection;finite element method;first-order logic;wire bonding;forensic engineering;engineering drawing;die;deformation;robustness;mechanical engineering	EDA	52.03129053974752	-1.8878561195414074	71991
6510f497ad03410cdae03892635965b0c54b8f50	pitch synchronous extended excitation in multimode celp	tabla codificacion;eficacia sistema;bloc diagramme;system structure;mobile radiocommunication;code excited linear prediction;filtrage lineaire;filtrado lineal;speech processing;performance systeme;tratamiento palabra;traitement parole;speech coding;4 kbit s multimode code excited linear prediction celp coder pitch synchronous extended excitation short term excitation algebraic excitation stochastic excitation adaptive codebook long term excitation fs 1016 coder itu t g 723 1 coder speech coding;raya espectral;adaptive codes;system performance;radiocommunication service mobile;linear filtering;raie spectrale;spectral line;codage predictif;linear predictive coding;cuantificacion vectorial;vector quantization;structure systeme;codebook;table codage;prediccion lineal;codificacion predictiva;adaptive codes speech coding linear predictive coding;linear prediction;speech bit rate linear predictive coding signal synthesis stochastic processes code standards nonlinear filters vectors filtering theory laboratories;diagrama conjunto;radiocomunicacion servicio movil;predictive coding;prediction lineaire;estructura sistema;block diagram;quantification vectorielle	This letter proposes a 4-kb/s multimode code-excited linear prediction (CELP) coder with pitch synchronous extended excitation. Three modes are used for the short-term excitation, namely algebraic, extended, or stochastic excitations, together with an adaptive codebook for the long-term excitation. Comparisons with the FS-1016 and ITU-T G.723.1 coders show a performance level between these standards.	code-excited linear prediction;codebook;fs-1016;g.723.1;linear algebra;synchronous circuit	W. S. Tian;W. C. Wong;C. Y. Law;A. P. Tan	1999	IEEE Communications Letters	10.1109/4234.784585	block diagram;spectral line;linear predictive coding;speech recognition;linear prediction;telecommunications;computer science;codebook;speech coding;linear filter;speech processing;vector quantization;code-excited linear prediction	Vision	47.81541047178366	-8.251124279662971	72004
271514ab36a9555f754baf358a522ea635271778	hardware architecture for pattern recognition in gamma-ray experiment	signal image and speech processing;gamma ray;circuits and systems;control structures and microprogramming;electronic circuits and devices;hardware architecture;pattern recognition	The HESS project has been running successfully for seven years. In order to take into account the sensitivity increase of the entire project in its second phase, a new trigger scheme is proposed. This trigger is based on a neural system that extracts the interesting features of the incoming images and rejects the background more efficiently than classical solutions. In this article, we present the basic principles of the algorithms as well as their hardware implementation in FPGAs (Field Programmable Gate Arrays).		Sonia Khatchadourian;Jean-Christophe Prévotet;Lounis Kessal	2009	EURASIP J. Emb. Sys.	10.1155/2009/737689	gamma ray;embedded system;real-time computing;computer hardware;computer science;operating system;hardware architecture	Vision	42.753947619440105	-2.1688257388768184	72817
463c39455f4eeb09f740e72200f81f87c7b58e44	an algorithm to evaluate spectral densities of high-dimensional stationary diffusion stochastic processes with non-linear coefficients: the general scheme and issues on implementation with pvm	algoritmo paralelo;parallel algorithm;metodo monte carlo;stochastic process;high dimensionality;algorithm analysis;physique atomique;simulacion numerica;fisica atomica;methode monte carlo;spectral density;algorithme parallele;monte carlo method;simulation numerique;atomic physics;processus stochastique;message passing;analyse algorithme;proceso estocastico;parallel virtual machine;analisis algoritmo;numerical simulation	The present work deals with spectral-density matrix of the stationary diffusion stochastic process with non-linear coefficients (i.e. drift vector and diffusion matrix) in the case as numbcr of variables of the process is high, i.e. is much greater than a few units. This is an important topic in modern microelectronics and other applied fields associated with non-linear fluctuations in high-dimensional systems. A general scheme for the algorithm to evaluate the above matrix for realistic computing expenses is proposed. This algorithm applies the Monte Carlo method for multifold integrals. An implementation with the Parallel Virtual Machine (PVM) software environment is discussed. To reduce the corresponding message-passing time overheads, the initial-and-final-only-messages (IFOM) technique should be applied. It is shown that the IFOM approach enables to keep the parallelization efficiency at the level of 80-90% even if many tens (or more) processors are involved.	algorithm;parallel virtual machine;stationary process;stochastic process	Yevgeny V. Mamontov;Magnus Willander	1998		10.1007/BFb0095352	stochastic process;message passing;simulation;computer science;theoretical computer science;parallel algorithm;spectral density;algorithm;statistics;monte carlo method	ML	44.339655161146815	2.8599610547301624	74160
a3dd91a8daf035be635fcb4c289ddeff9fad6826	wide band sub-band speech coding using nonlinear prediction	segsnr;quantization;mirrors;sampling rate;wideband;neural networks;data compression;decoding;adaptive modulation;multilayer perceptrons;finite impulse response filter;nonlinear prediction;adpcm;speech coding;differential pulse code modulation;linear predictive;narrowband signal wideband sub band speech coding nonlinear prediction adpcm linear prediction multilayer perceptrons nonlinear neural net prediction sampling rate quantization bits compression standards wide band speech signals wide band audio signals nonlinear speech processing synthetic high frequency band generation synthetic hf band generation qmf filters segsnr synthetic wideband signal;wide band speech signals;qmf filters;frequency response;neural net;prediction theory;multilayer perceptrons data compression speech coding prediction theory adaptive modulation differential pulse code modulation;wideband speech coding finite impulse response filter bandwidth neural networks decoding sampling methods quantization mirrors frequency response;quantization bits;synthetic hf band generation;bandwidth;multi layer perceptron;nonlinear speech processing;linear prediction;nonlinear neural net prediction;sampling methods;synthetic wideband signal;wideband sub band speech coding;wide band audio signals;synthetic high frequency band generation;compression standards;narrowband signal	We compare a wide band sub-band speech coder using ADPCM schemes with linear prediction against the same scheme with nonlinear prediction based on multi-layer perceptrons. Exhaustive results are presented in each band, and the full signal. Our proposed scheme with non-linear neural net prediction outperforms the linear scheme up to 2 dB in SEGSNR. In addition, we propose a simple method based on a non-linearity in order to obtain a synthetic wide band signal from a narrow band signal.	nonlinear system;speech coding	Marcos Faúndez-Zanuy	2003		10.1109/ICASSP.2003.1202324	data compression;sampling;frequency response;speech recognition;quantization;link adaptation;linear prediction;telecommunications;computer science;finite impulse response;speech coding;mathematics;multilayer perceptron;sampling;artificial neural network;bandwidth;statistics	ML	47.75817790907877	-8.292848922323786	74322
97b9a22cca75fb4665520fb0c0b4af9231efab0d	performance evaluation of parallel stripmap cs-sar imaging on nvlink-connected gpus		To develop a real-time CS-SAR (compressive sensing synthetic aperture radar) system, in which signals are randomly truncated and recovered using iterative forward and inverse imagings, we studied its parallel implementation that performs before and after fourier-transforms and is accelerated by the callback-customized cuFFT library on the NVLink-connected GPUs. When observing 8192x32768-signals every 6.0 s, we found that our CS-SAR reconstructions with four GPUs takes 2.1 s, which is 29.5 times faster than 96-threaded CPUs.	central processing unit;compressed sensing;graphics processing unit;iterative method;nvlink;performance evaluation;randomness;real-time clock;synthetic intelligence	Masato Gocho;Takehiro Hoshino	2018	2018 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2018.00027	computer science;iterative reconstruction;radar imaging;parallel computing;compressed sensing;synthetic aperture radar	HPC	44.40285419941339	1.6304477427798005	74820
977f4989f6f743fec861c4ed725d60b35c84a4cf	exergy analysis of a subcritical refrigeration cycle with an improved impulse turbo expander	coefficient of performance cop;exergy efficiency;refrigeration cycle;optimum intermediate pressure;turbo expander	The impulse turbo expander (ITE) is employed to replace the throttling valve in the vapor compression refrigeration cycle to improve the system performance. An improved ITE and the corresponding cycle are presented. In the new cycle, the ITE not only acts as an expansion device with work extraction, but also serves as an economizer with vapor injection. An increase of 20% in the isentropic efficiency can be attained for the improved ITE compared with the conventional ITE owing to the reduction of the friction losses of the rotor. The performance of the novel cycle is investigated based on energy and exergy analysis. A correlation of the optimum intermediate pressure in terms of ITE efficiency is developed. The improved ITE cycle increases the exergy efficiency by 1.4%–6.1% over the conventional ITE cycle, 4.6%–8.3% over the economizer cycle and 7.2%–21.6% over the base cycle. Furthermore, the improved ITE cycle is also preferred due to its lower exergy loss.	r.o.t.o.r.	Zhenying Zhang;Lili Tian	2014	Entropy	10.3390/e16084392	exergy efficiency;turboexpander;thermodynamics;refrigeration;physics	EDA	52.963539356416305	-4.053652472456915	75540
69dd89e66fce380d1f159799433d200d72475467	criteria for the dod 2400 bps vocoder selection	microphones;united states department of defense;degradation;performance evaluation;low bit rate voice coding applications;speech processing;working environment noise;military equipment;speech coding;testing;bit rate;military communication;algorithm;telecommunication equipment testing;us department of defense;telecommunication standards;2400 bit s dod 2400 bps vocoder selection algorithm low bit rate voice coding applications evaluation process 2400 bps standard figure of merit united states department of defense;dod 2400 bps vocoder selection;military equipment vocoders speech coding telecommunication equipment testing telecommunication standards military communication military standards;vocoders;military standards;us department of defense vocoders testing performance evaluation speech processing degradation working environment noise microphones speech recognition bit rate;speech recognition;2400 bit s;evaluation process;2400 bps standard;figure of merit	Use of vocoder competitions remains a prevalent method for selecting a candidate algorithm for low bit rate voice coding applications. Without proper safeguards in the evaluation process, the final selection may be perceived as biased or unfair. This paper describes the evaluation process that was used by DoD for the selection of a new 2400 bps standard. Specific attention was aimed at creating an evaluation environment such that each candidate received equitable treatment. This paper describes the structure of the evaluation team, the roles and responsibilities of its components, the information that was available for evaluation, and the equations and weights that were used to develop an overall figure of merit (FOM) for each candidate.	vocoder	Mary A. Kohler;Philip A. LaFollette;Matthew R. Bielefeld	1996		10.1109/ICASSP.1996.543571	figure of merit;speech recognition;degradation;telecommunications;computer science;speech coding;speech processing;software testing	Crypto	48.42564117486102	-7.6812944416145434	75617
4942c8355bf6969e2fb5ffe4e5d50bdeb91bcd8e	blind robust 3-d mesh watermarking based on oblate spheroidal harmonics	watermarking;spline;telematics;watermarking mesh generation;transform domain oblate spheroidal harmonics blind robust 3d mesh watermarking discrete continuous regions oblate spheroids spheroidal harmonic coefficients;blind detection;surface parameterization;mesh simplification;robustness watermarking copyright protection information processing laboratories informatics telematics spline mesh generation discrete transforms;spheroidal harmonics 3 d watermarking blind detection copyright protection mesh watermarking;spheroidal harmonic coefficients;blind robust 3d mesh watermarking;mesh watermarking;transform domain;copyright protection;similarity transformation;discrete transforms;information processing;oblate spheroidal harmonics;discrete continuous regions;robustness;informatics;is success;mesh generation;oblate spheroids;3 d watermarking;spheroidal harmonics	In this paper, a novel transform-based, blind and robust 3-D mesh watermarking scheme is presented. The 3-D surface of the mesh is firstly divided into a number of discrete continuous regions, each of which is successively sampled and mapped onto oblate spheroids, using a novel surface parameterization scheme. The embedding is performed in the spheroidal harmonic coefficients of the spheroids, using a novel embedding scheme. Changes made to the transform domain are then reversed back to the spatial domain, thus forming the watermarked 3-D mesh. The embedding scheme presented herein resembles, in principal, the ones using the multiplicative embedding rule (inherently providing high imperceptibility). The watermark detection is blind and by far more powerful than the various correlators typically incorporated by multiplicative schemes. Experimental results have shown that the proposed blind watermarking scheme is competitively robust against similarity transformations, connectivity attacks, mesh simplification and refinement, unbalanced resampling, smoothing and noise addition, even when juxtaposed to the informed ones.	blind signature;coefficient;computation;converge;digital watermarking;emoticon;high-water mark (computer security);level of detail;refinement (computing);sensor;smoothing;social inequality;unbalanced circuit;watermark (data file)	John M. Konstantinides;Athanasios Mademlis;Petros Daras;Pericles A. Mitkas;Michael G. Strintzis	2009	IEEE Transactions on Multimedia	10.1109/TMM.2008.2008913	spline;matrix similarity;mesh generation;information processing;telecommunications;digital watermarking;computer science;theoretical computer science;mathematics;telematics;programming language;informatics;robustness	Visualization	40.783542538064374	-8.619726354193853	76022
689e4261220d69b872c23ab37abf4191b07ea142	performance prediction of parallel self consistent field computation	distributed memory;prediction error;parallel algorithm;data representation;computational chemistry;large scale;graphical representation;self consistent field;performance model;parallel computer;performance prediction	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	computation;francis;performance prediction;primary source	Juri Papay;Tim J. Atherton;Mohamed Jamal Zemerly;Graham R. Nudd	1996	Parallel Algorithms Appl.	10.1080/10637199608915612	parallel computing;distributed memory;computer science;theoretical computer science;machine learning;mean squared prediction error;external data representation;parallel algorithm;algorithm	Robotics	48.516606211313615	-2.9499822995027505	76734
15329ce8363b42fb6c08762363328715cd987c83	exploration of spatial-temporal dynamic phenomena in a 32*32-cell stored program two-layer cnn universal machine chip prototype	complex dynamics;temporal dynamics;articulo;mixed signal chip;nonlinear wave;chip;cellular neural networks	This paper describes a full-custom mixed-signal chip that embeds digitally programmable analog parallel processing and distributed image memory on a common silicon substrate. The chip was designed and fabricated in a standard 0.5μm CMOS technology and contains approximately 500,000 transistors. It consists of 1024 processing units arranged into a 32×32 grid. Each processing element contains two coupled CNN cores, thus, constituting two parallel layers of 32×32 nodes. The functional features of the chip are in accordance with the 2nd Order Complex Cell CNN-UM architecture. It is composed of two CNN layers with programmable interand intra-layer connections between cells. Other features are: cellular, spatial-invariant array architecture; randomly selectable memory of instructions; random storage and retrieval of intermediate images. The chip is capable of completing algorithmic image processing tasks controlled by the user-selected stored instructions. The internal analog circuitry is designed to operate with 7-bits equivalent accuracy. The physical implementation of a CNN containing second order cells allows real time experiments of complex dynamics and active wave phenomena. Such well-known phenomena from the reaction-diffusion equations are traveling waves, autowaves, and spiral-waves. All of these active waves are demonstrated on-chip. Moreover this chip was specifically designed to be suitable for the computation of biologically inspired retina models. These computational experiments have been carried out in a development environment designed for testing and programming the analogic (analog-and-logic) programmable array processors.	autowave;cmos;cell (microprocessor);central processing unit;complex dynamics;computation;electronic circuit;experiment;full custom;image processing;mixed-signal integrated circuit;parallel computing;prototype;randomness;spiral wave;stored-program computer;transistor	István Petrás;Csaba Rekeczky;Tamás Roska;Ricardo Carmona-Galán;Francisco Jiménez-Garrido;Ángel Rodríguez-Vázquez	2003	Journal of Circuits, Systems, and Computers	10.1142/S0218126603001112	chip;embedded system;electronic engineering;cellular neural network;complex dynamics;computer hardware;telecommunications;computer science;electrical engineering;operating system	HPC	40.44976304948488	-1.264097713243612	77138
4a32b7526a699feb935be06bd49f117daaee63b9	modelling of temperature dependent impedance in lithium ion polymer batteries and impact analysis on electric vehicles	impedance;heating;propulsion systems temperature dependent impedance modelling lithium ion polymer batteries impact analysis electric vehicles high power lithium ion polymer cells self heating thermal model system simulations highway drive cycles internal resistance ambient temperature load current requirements battery thermal management system btms heating systems;motorcycles;current measurement;system on chip;batteries temperature measurement impedance system on chip current measurement motorcycles heating;batteries;temperature measurement;thermal management packaging battery management systems battery powered vehicles secondary cells	The objective of this work is to demonstrate a temperature-dependent impedance model for high-power lithium-ion polymer cells used in modern Electric Vehicles (EV). The impedance model is combined with a self-heating thermal model for system simulations, in order to predict the impact of different cell types on the overall EV performance, under real-world urban and highway drive-cycles. Measurements show that the internal resistance is almost doubled when the ambient temperature is lowered from 20° C to 5°C. This has a drastic impact on the EV's ability to satisfy the load current requirements without performance lags, and justifies the importance of the modelling approach. When operating in cold climates, it is observed that the Battery Thermal Management System (BTMS) must strike a balance between EV range and performance, as the stored energy should be optimally distributed between the propulsion and heating systems.	characteristic impedance;discharger;extended validation certificate;management system;output impedance;polymer;requirement;simulation;thermal management (electronics);thermal management of high-power leds	Andishe Moshirvaziri;Jacky Liu;Yajneshvar Arumugam;Olivier Trescases	2014	IECON 2014 - 40th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2014.7048960	materials science;electronic engineering;electrical engineering;forensic engineering	Embedded	53.240457932027454	-2.090205408274893	77497
79729a4f5bb95c30fd32c2cf19fd0ea1b107d066	how to transform and filter images using iterated function systems	filter images;fractal transformation;fractals dynamical systems;iterated function system;chaotic dynamics;fractal geometry;digital imaging;novel methods;journal article;fractal transformations;iterated function systems;54h20;68u10;37b10;dynamical systems;digital image;keywords chaotic dynamics;functions	We generalize the mathematics of fractal transformations and illustrate how it leads to a new approach to the representation and processing of digital images, and consequent novel methods for filtering, watermarking, and encryption. This work substantially generalizes earlier work on fractal tops. The approach involves fractal geometry, chaotic dynamics, and an interplay between discrete and continuous representations. The underlying mathematics is established and some applications to digital imaging are described and exemplified.	iterated function system	Michael F. Barnsley;Brendan Harding;Konstantin Igudesman	2011	SIAM J. Imaging Sciences	10.1137/100815293	discrete mathematics;pure mathematics;mathematics;fractal transform;fractal compression;iterated function system	Theory	39.430113012493784	-6.690957762290122	77511
fcc27192605623189fd9244d9a6f4f1e4921cf1b	rarefied gas flow computational with a 3d unstructured mesh on a connection machine (cm2)	metodo monte carlo;rarefied gas flow;aerodynamics;implementation;simulacion numerica;gas enrarecido;methode monte carlo;modele physique;three dimensional;gaz rarefie;paralelismo masivo;algorithme;algorithm;ejecucion;massively parallel computers;connection machine;rarefied gas;massively parallel computer;monte carlo method;simulation numerique;aerodynamic;modelo fisico;communication cost;unstructured mesh;physical model;aerodynamique;parallelisme massif;massive parallelism;aerodinamica;numerical simulation;algoritmo	The implementation on a Connection Machine (CM2) of a Monte Carlo method for rarefied gas flow Isimulation is presented. The physical model and the algorithm are described. Because of the architecture of the1 CM2, the association between processors and data is very important. Two different mappings are used in order tolobtain the best performance for the two different parts of the algorithm. Moreover, the displacement of a p	algorithm;central processing unit;connection machine;displacement mapping;monte carlo method;unstructured grid	François Coron;Philippe Homsi	1995	Future Generation Comp. Syst.	10.1016/0167-739X(94)00042-D	three-dimensional space;parallel computing;simulation;aerodynamics;physical model;computer science;theoretical computer science;implementation;monte carlo method	HPC	44.51737416712265	3.3943555556882656	77938
f6d33e7a3e3193b663b628014d060b0a6f77259c	vhdl-ams based genetic optimization of mixed-physical-domain systems in automotive applications	modelizacion;mixed programming;parallel genetic algorithm;langage description materiel informatique;algoritmo paralelo;vhdl language;evaluation performance;optimisation;senal analogica;sistema activo;active suspension system;parallel algorithm;control difusa;performance evaluation;optimizacion;automovil;modeling and simulation;vhdl ams;optimization technique;active suspension;evaluacion prestacion;fuzzy control;logique floue;hardware description languages;logica difusa;analog signal;fuzzy logic controller;suspension vehicule;programmation mixte;forma geometrica;algoritmo genetico;systeme actif;genetics;algorithme parallele;active system;fuzzy logic;automatisme logique;modelisation;lenguaje vhdl;logic controller;performance improvement;suspension vehiculo;programacion mixta;automobile;senal numerica;fonction appartenance;motor car;geometrical shape;membership function;algorithme genetique;signal numerique;genetic algorithm;optimization;forme geometrique;signal analogique;digital signal;funcion pertenencia;automatismo logico;hardware description language;vehicle suspension;modeling;performance optimization;langage vhdl;commande floue	This paper presents a VHDL-AMS based genetic optimization methodology suitable for performance improvement of hardware systems in automotive applications. Models of such systems are mixedsignal (analog and digital) in which the analog parts cover mixed physical domains. A case study applying this novel method to the fuzzy logic controller (FLC) optimization in an automotive active suspension system (AASS) has been investigated. A new type of fuzzy logic membership functions with variable geometrical shapes has been proposed and optimized. In this optimization technique, VHDL-AMS is used not only for the modeling and simulation of the FLC and its underlying AASS but also for the implementation of a parallel genetic algorithm (GA). This has resulted in an integrated performance optimization system wholly implemented in the hardware description language (HDL). Results show that the proposed FLC has superior performance to that of existing FLCs that use fixed-shape membership functions.	analog signal;fuzzy logic;genetic algorithm;hardware description language;mathematical optimization;simulation;vhdl;vhdl-ams;verilog-ams	Leran Wang;Tom J. Kazmierski	2009	Simulation	10.1177/0037549709106693	control engineering;electronic engineering;computer science;engineering;artificial intelligence;modeling and simulation;hardware description language;algorithm	EDA	52.227169572323675	-6.376101181548691	78291
65cc2ada0935e5369ba25b0a7468e79cd9efe73e	particle filter parallelisation using random network based resampling	systematics synchronization stochastic processes acceleration sensors hardware target tracking;particle filter parallelisation target tracking synchronisation constraints parallel hardware systems posterior density fixed random network random network based resampling;tracking filters particle filtering numerical methods signal sampling synchronisation target tracking	The particle filter approximation to the posterior density converges to the true posterior as the number of particles used increases. The greater the number of particles, the higher the computational load, which can be implemented by operating the particle filter in parallel architectures. However, the resampling stage in the particle filter requires synchronisation, extensive interchange and routing of particle information, and thus impedes the use of parallel hardware systems. This paper presents a novel resampling technique using a fixed random network. This idea relaxes the synchronisation constraints and minimises the particle interaction to a significant level. Using simulations we demonstrate the validity of our technique to track targets in linear and non-linear sensing scenarios.	approximation;computation;deterministic algorithm;field-programmable gate array;nonlinear system;pf (firewall);parallel computing;particle filter;random graph;real-time computing;resampling (statistics);routing;simulation	Praveen B. Choppala;Paul D. Teal;Marcus R. Frean	2014	17th International Conference on Information Fusion (FUSION)		real-time computing;auxiliary particle filter;computer science;theoretical computer science;control theory	HPC	53.34784447219987	1.9863822188752667	78405
4a0ca2595aa318f0426f4d71e775e659a89dcb24	cpa performance comparison based on wavelet transform	private key cryptography;multi resolution analysis;side channel attack;wavelet basis correlation power analysis cpa performance comparison wavelet transform secret keys cryptosystems power consumption signals side channel attack side channel analysis attack performance signal processing decomposition level noise reduction transform domain;wavelet transforms;wavelet transforms private key cryptography signal resolution;wavelet transform;correlation power analysis wavelet transform side channel attack multi resolution analysis;correlation power analysis;signal resolution	Correlation Power Analysis (CPA) is a very effective attack method for finding secret keys using the statistical features of power consumption signals from cryptosystems. However, the power consumption signal of the encryption device is greatly affected or distorted by noise arising from peripheral devices. When a side channel attack is carried out, this distorted signal, which is affected by noise and time inconsistency, is the major factor that reduces the attack performance. A signal processing method based on the Wavelet Transform (WT) has been proposed to enhance the attack performance. Selecting the decomposition level and the wavelet basis is very important because the CPA performance based on the WT depends on these two factors. In this paper, the CPA performance, in terms of noise reduction and the transform domain, is compared and analyzed from the viewpoint of attack time and the minimum number of signals required to find the secret key. In addition, methods for selecting the decomposition level and the wavelet basis using the features of power consumption are proposed, and validated through experiments.	cryptosystem;encryption;experiment;image noise;key (cryptography);noise reduction;peripheral;side-channel attack;signal processing;wavelet transform	Aesun Park;Dong-Guk Han;Jeong Choon Ryoo	2012	2012 IEEE International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2012.6393559	wavelet;speech recognition;second-generation wavelet transform;telecommunications;engineering;cascade algorithm;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;fast wavelet transform;lifting scheme;computer security	EDA	41.650235540216	-9.110245399244901	78464
d433af3fd9350395677c87f3563744c2b8a6e42e	a parallelized artificial immune network for fuzzy clustering	parallel computing;clone selection;ain;artificial immune system;time complexity;fuzzy clustering;parallel computer;68t01;coarse grained;68w10;stochastic search	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithm;central processing unit;cluster analysis;experiment;francis;fuzzy clustering;global optimization;mathematical optimization;nl (complexity);parallel computing;primary source;processor affinity;run time (program lifecycle phase);scalability;speedup;time complexity;zero suppression	Li Liu;Wenbo Xu	2010	Int. J. Comput. Math.	10.1080/00207160802331515	time complexity;fuzzy clustering;computer science;theoretical computer science;machine learning;data mining;artificial immune system;algorithm	Robotics	48.328710509939256	-2.968131612292524	78725
9b399f4f0fe850ff704bc11577ebb507694db1c8	bitrate and tandem detection for the amr-wb codec with application to network testing		In network testing, identifying the cause for an observed speech quality degradation is of special interest. Common speech codec related causes to be identified are the application of a low bitrate or the occurrence of transcoding or self-tandem. This paper presents two comprehensible types of signal features which enable a speech-quality-motivated bitrate detection for the AMR-WB codec. The first type of feature is based on codec linearity, while the second type exploits the different structure of the fixed codebook at each bitrate. With these underlying features, the bitrate detection is performed with high accuracy. Since the one feature gathers information on the last applied bitrate and the other on coding effects accumulated during the entire transmission, this paper, additionally, provides a method to extract information on the occurrence of self-tandem in the network-under-test.		Tobias Hubschen;Gerhard Schmidt	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553360	codec;codebook;feature extraction;speech coding;transcoding;artificial intelligence;pattern recognition;computer science	SE	49.41153266348267	-9.359586677788121	78889
c8ec8035e1373f4fe44f1ba8e0d44742d3211d2b	design and development of fpga-based high-performance radar data stream mining system		Abstract   Radar signal sorting is a key technique in electronic reconnaissance systems and is currently an important research direction in radar signal processing. Clustering, one of data mining techniques, has been adopted to solve radar sorting problem. However, none of the existing clustering-based methods is able to perform real-time analysis on high speed radar stream. Therefore, in this paper, we propose, design and implement a high performance FPGA-based data stream mining system to perform real-time radar signal sorting on continuous data stream. Firstly, a density-based clustering algorithm is proposed for radar signal sorting; secondly, FPGA-based program of the clustering algorithm is designed and implemented; thirdly, the FPGA board is designed and implemented. Experiments are performed on the board we designed. The results show that the proposed system can achieve real-time radar signal sorting on FPGA, and the resource consumption on FPGA is very low. The clustering algorithm is efficient in terms of accuracy.	data stream mining;field-programmable gate array;radar	Ying Liu;Pengshan Ma;Hongyuan Cui	2015		10.1016/j.procs.2015.07.147	embedded system;data stream clustering;real-time computing;computer science	HPC	42.766636008425024	-2.073973552282985	79532
5a65f7a8e4455d91f04060a58ad23baacd62f4af	a new computational paradigm in multiscale simulations: application to brain blood flow	continuum atomistic simulations;partial differential equations brain data visualisation haemodynamics haemorheology medical computing molecular dynamics method navier stokes equations;brain;navier stokes equations;arteries;haemodynamics;navier stokes;cerebrovascular circulation;medical computing;multi scale modeling;molecular dynamics method;dissipative particle dynamics;data visualisation;coupled solvers;computational modeling;atomistic simulation;partial differential equations;computational modeling blood aneurysm arteries couplings mathematical model program processors;blood;mathematical model;biological systems;molecular dynamic;cerebrovascular circulation coupled solvers continuum atomistic simulations multi scale modeling;blood flow;partial differential equations computational paradigm multiscale simulations brain blood flow atomistic based simulation codes continuum based simulation codes multiscale physical system multiscale biological system navier stokes solver stochastic molecular dynamics solver dissipative particle dynamics topology aware communication simdization multiscale visualization patient specific cerebrovasculature brain aneurysm blood cell interaction glycocalyx thrombus formation eventual aneurysm rupture macro scale dynamics neκtαr spectral element solver dpd lammps;couplings;blood cells;coarse grained;aneurysm;program processors;multiscale simulation;haemorheology	Interfacing atomistic-based with continuum-based simulation codes is now required in many multiscale physical and biological systems. We present the computational advances that have enabled the first multiscale simulation on 190,740 processors by coupling a high-order (spectral element) Navier-Stokes solver with a stochastic (coarse-grained) Molecular Dynamics solver based on Dissipative Particle Dynamics (DPD). The key contributions are proper interface conditions for overlapped domains, topology-aware communication, SIMDization, multiscale visualization and a new domain partitioning for atomistic solvers. We study blood flow in a patient-specific cerebrovasculature with a brain aneurysm, and analyze the interaction of blood cells with the arterial walls endowed with a glycocalyx causing thrombus formation and eventual aneurysm rupture. The macro-scale dynamics (about 3 billion unknowns) are resolved by NεκTαr - a spectral element solver; the micro-scale flow and cell dynamics within the aneurysm are resolved by an in-house version of DPD-LAMMPS (for an equivalent of about 100 billions molecules).	apache continuum;biological system;central processing unit;code;dissipative particle dynamics;molecular dynamics;navier–stokes equations;programming paradigm;simulation;solver;steam rupture	Leopold Grinberg;Joseph A. Insley;Vitali A. Morozov;Michael E. Papka;George Em Karniadakis;Dmitry A. Fedosov;Kalyan Kumaran	2011	2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC)	10.1145/2063384.2063390	molecular dynamics;simulation;computer science;blood flow;hemodynamics;mathematical model;dissipative particle dynamics;coupling;computational model;partial differential equation;data visualization	HPC	45.05548387860235	1.9864580966868215	79723
452fdbe8068ce80c3c0619ab64b8b70b8d024cbf	a new light weight encryption approach to secure the contents of image	encryption correlation coefficient entropy genetics genetic algorithms;peak signal to noise ratio light weight encryption digital image knight pawn chess board genetic algorithm crossover operation visual quality correlation coefficient entropy;knight moves digital image security light weight crossover chess board;image coding cryptography genetic algorithms	In this paper, a light weight encryption approach is proposed to secure the contents of digital image at different levels. The proposed approach is based on moves of knight pawn used in chess board and genetic algorithm. The procedure comprises four stages. In first stage, the numbers of initial positions for knight moves are considered. The number of moves required for each knight is chosen in second stage. Two knight move points are selected randomly in third stage. Finally, crossover operation is applied on selected moves to degrade the visual quality of image. The performance analysis of the proposed method is measured in terms of correlation coefficient, entropy and Peak Signal to Noise Ratio. The analysis carried out reveals that the proposed algorithm works successfully to secure the information in an image at different levels.	coefficient;computation;digital image;elegant degradation;encryption;genetic algorithm;peak signal-to-noise ratio;pixel;randomness;signal-to-noise ratio;the pawn;time complexity	Jalesh Kumar;Shivananda Nirmala	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968400	simulation;computer science;artificial intelligence;theoretical computer science	Vision	39.23597489416695	-9.645653734455475	80027
815e38a43b145ca27f74dce4d2f8d2a77f69f6fc	learning method for ex-situ training of memristor crossbar based multi-layer neural network		Memristor is being considered as a game changer for the realization of neuromorphic hardware systems due to its similarity with biological synapse. Recent studies show that memristor crossbar can provide high density and high performance neural network hardware implementation at low power due to its physical layout, nano scale size and low power consumption feature. This paper describes the training method that can be used for the implementation of memristive multi-layer neural network with ex-situ method. We mimic the behavior of memristor crossbar in software training process to achieve more accurate and close computations to hardware. Voltage divider has been used to calculate the dot product in this method. To demonstrate the accuracy and effectiveness of this method, different patterns and non-separable functions using memristor crossbar structures are simulated. The results demonstrate that more accurate computations can be produced using this learning method for ex-situ. It also reduces the learning time of functions.	artificial neural network;c++;computation;crossbar switch;gnu nano;integrated circuit layout;layer (electronics);linear separability;memristor;networking hardware;neuromorphic engineering;spice;simulation;synapse;teaching method;voltage divider	Anu Bala;Adedotun Adeyemo;Xiaohan Yang;Abusaleh M. Jabir	2017	2017 9th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)	10.1109/ICUMT.2017.8255181	memristor;crossbar switch;artificial neural network;dot product;computation;voltage divider;distributed computing;software;computer science;electronic engineering;neuromorphic engineering	EDA	39.219705383201244	-1.0285566533015609	80159
24724672a959c60c5e0de15cc8609def61afc745	an accelerated randomized kaczmarz method via low-rank approximation	kaczmarz method;52c99;low rank approximations of matrices;68q01;randomized kaczmarz method	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;kaczmarz method;linux/rk;low-rank approximation;numerical analysis;precondition;primary source;randomized algorithm;rate of convergence;the matrix	Xu Xiang;Lizhi Cheng	2015	Int. J. Comput. Math.	10.1080/00207160.2014.941827	mathematical optimization;mathematical analysis;calculus;algebraic reconstruction technique;mathematics;kaczmarz method	Robotics	49.43436229833051	-2.949158150258821	80642
379d621f8628168b3ad21d420e65cfa0d478e9d7	cooperative localization based on topology matching	topology matching;multi sensor kalman filter cooperative localization v2v communication topology matching;telecommunication network topology broadcasting cooperative communication global positioning system kalman filters mobile communication position measurement;cooperative localization;multi sensor kalman filter;v2v communication;vehicles sensors global positioning system accuracy position measurement kalman filters topology;multisensor kalman filter cooperative localization topology matching vehicle localization position measurements vehicle to vehicle communication v2v local map matching algorithm	In this paper, we propose a new vehicle localization method based on topology matching in mutli-vehicle enviroment. Each vehicle is assumed to generate a local map which is a set of position measurements of nearby vehicles by using onboard low-cost GPS and ranging sensors, and share it with others by broadcasting via vehicle-to-vehicle(V2V) communication. When a vehicle receives multiple local maps from neighbors, it incorporates and fuses them with its own local map by using a local map matching algorithm. The proposed algorithm is based on the topology matching technique and the multi-sensor Kalman filter. Simulation results show that our method can extend the detection range and improve the position accuracy by 65% compared to conventional localization methods utilizing the Kalman filter with only onboard GPS measurements.	algorithm;global positioning system;internationalization and localization;kalman filter;map matching;sensor;simulation	Seung-Tak Choi;Woo-Sol Hur;Seung-Woo Seo	2014	2014 IEEE 6th International Symposium on Wireless Vehicular Communications (WiVeC 2014)	10.1109/WIVEC.2014.6953218	control engineering;simulation;engineering;control theory;simultaneous localization and mapping	Robotics	51.110549604035874	0.15529557287528056	80770
683838ee370065195b7c92ba66039bd461806cd0	novel maximum likelihood approach for passive detection and localisation of multiple emitters	signal image and speech processing;quantum information technology spintronics	In this paper, a novel target acquisition and localisation algorithm (TALA) is introduced that offers a capability for detecting and localising multiple targets using the intermittent “signals-of-opportunity” (e.g. acoustic impulses or radio frequency transmissions) they generate. The TALA is a batch estimator that addresses the complex multi-sensor/multi-target data association problem in order to estimate the locations of an unknown number of targets. The TALA is unique in that it does not require measurements to be of a specific type, and can be implemented for systems composed of either homogeneous or heterogeneous sensors. The performance of the TALA is demonstrated in simulated scenarios with a network of 20 sensors and up to 10 targets. The sensors generate angle-of-arrival (AOA), time-of-arrival (TOA), or hybrid AOA/TOA measurements. It is shown that the TALA is able to successfully detect 83–99% of the targets, with a negligible number of false targets declared. Furthermore, the localisation errors of the TALA are typically within 10% of the errors generated by a “genie” algorithm that is given the correct measurement-to-target associations. The TALA also performs well in comparison with an optimistic Cramér-Rao lower bound, with typical differences in performance of 10–20%, and differences in performance of 40–50% in the most difficult scenarios considered. The computational expense of the TALA is also controllable, which allows the TALA to maintain computational feasibility even in the most challenging scenarios considered. This allows the approach to be implemented in time-critical scenarios, such as in the localisation of artillery firing events. It is concluded that the TALA provides a powerful situational awareness aid for passive surveillance operations.	acoustic cryptanalysis;algorithm;analysis of algorithms;angle of arrival;computation;correspondence problem;genie;geolocation;language localisation;radio frequency;real-time computing;sensor;time of arrival;window of opportunity	Mariano Hernández	2017	EURASIP J. Adv. Sig. Proc.	10.1186/s13634-017-0473-0	maximum likelihood;artificial intelligence;machine learning;computer science;estimator;target acquisition;epidemiological surveillance;simulation;homogeneous;pattern recognition	Vision	50.81126507217587	3.4514617436553285	81026
79df023d84ca99ea5d6cabed73b60ed5aec16902	"""corrigendum to """"a probabilistic approach for designing nonlinear optimal robust tracking controllers for unmanned aerial vehicles"""" [appl. soft comput. 34 (2015) 26-28]"""			nonlinear system;television antenna;unmanned aerial vehicle	Paulo André Sperandio Giacomin;Elder Moreira Hemerly;Witold Pedrycz	2018	Appl. Soft Comput.	10.1016/j.asoc.2017.12.033		Robotics	51.362863033536875	-3.819499652149506	81079
029577353d88198c029240c92a7002ee90f1d5c8	genesynth: noise band-based genetic algorithm analysis/synthesis framework		Genesynth is an analysis/synthesis framework that uses a genetic algorithm to search for a noise band sound model. The framework is written as an open source C++ tool, which allows for both the modification and resynthesis of found sound models and also genealogical exploration of the generations of sound variations created as a side effect of the genetic algorithm. The genetic algorithm used is specialized for the problem of audio analysis by using variable chromosome length as well as hierarchical chromosome structure. The algorithm’s fitness function compares cached and compressed FFT data against estimated noise band models represented in the chromosomes. The noise band model is synthesized using sinusoids that are stochastically modulated in frequency to achieve a flexible bandwidth.	analysis of algorithms;c++;fast fourier transform;fitness function;genetic algorithm;graphical user interface;modulation;open-source software;sourceforge	Michael Chinen;Naotoshi Osaka	2007			fast fourier transform;cache;genetic algorithm;artificial intelligence;audio analyzer;pattern recognition;fitness function;computer science;bandwidth (signal processing)	Comp.	46.42550721928253	-6.015508875474816	81329
3e415845beb7b7695c43330ec95ee5ae37e209fd	stability by order stars for non-linear theta-methods based on means	non linear one step methods;65l12;stability region;linear multistep method;riemann surface;30f99;65l05;non linear multistep methods;order stars;classical means;stability regions;65l20;65m12;linear stability analysis	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	approximation;diagram;differential algebraic equation;extrapolation;francis;locus;list of code lyoko episodes;method of lines;nl (complexity);non-deterministic turing machine;nonlinear system;numerical aperture;numerical partial differential equations;padé approximant;primary source;stiff equation;test set;time complexity;wolfram mathematica	Francisco R. Villatoro	2010	Int. J. Comput. Math.	10.1080/00207160802036858	mathematical optimization;mathematical analysis;calculus;mathematics;riemann surface;linear multistep method	Robotics	49.70024721555628	-2.9816489757283504	82348
6ccf2d51060eeb5f222db43e5dbc1102f4db5ade	range bias modeling for hyperbolic-frequency-modulated waveforms in target tracking	doppler tolerant waveform;nonlinear filters;wideband;hyperbolic frequency modulation hfm;radar tracking;target tracking doppler radar kalman filters nonlinear filters radar tracking;hyperbolic frequency modulated waveforms;doppler insensitive;kalman filters;wideband transmissions range bias modeling hyperbolic frequency modulated waveforms target tracking doppler insensitive narrowband transmissions;bias compensation;target tracking wideband mathematical model radar tracking doppler effect equations accuracy;extended kalman filter hyperbolic frequency modulation hfm wideband ambiguity function doppler tolerant waveform bias compensation tracking;accuracy;doppler effect;range bias modeling;narrowband transmissions;doppler radar;mathematical model;target tracking;extended kalman filter;ambiguity function;wideband transmissions;tracking	Hyperbolic-frequency-modulated (HFM) waveforms offer detection performance that is “Doppler insensitive”-relatively unaffected by target range rate in matched filtering. They have been applied in radar; but more they are particularly useful in sonar where the wideband Doppler insensitivity is especially prized. However, Doppler insensitivity does come hand in hand with a range bias, which would significantly degrade the tracking performance. In this paper, we model the range bias as a function of range rate and system parameters, and then utilize that to calibrate the measurement equation in very precise target tracking. By doing so, the tracking performance can be improved, particularly for fast maneuvering targets.	approximation;doppler effect;elegant degradation;modulation;propagation delay;radar;sonar (symantec);software propagation;waveform	Xiufeng Song;Peter Willett;Shengli Zhou	2012	2012 IEEE 7th Sensor Array and Multichannel Signal Processing Workshop (SAM)	10.1109/SAM.2012.6250480	kalman filter;radar tracker;doppler effect;telecommunications;computer science;mathematical model;control theory;mathematics;accuracy and precision;tracking;extended kalman filter;statistics;ambiguity function	Robotics	49.778459152759865	1.9500028660678224	82758
3c7feadf18562f681d7f529879a44f5e30d36343	robust control for nonlinear systems with unknown perturbations using simplified robust right coprime factorisation	asymptotic tracking;robust right coprime factorisation;robust control;satisfiability;nonlinear systems;unknown perturbations;feedback system;nonlinear system	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;ibm 1400 series;integrated circuit layout design protection;monoid factorisation;nl (complexity);nos/ve;nonlinear system;primary source;robust control;simulation	Mingcong Deng;Ni Bu	2012	Int. J. Control	10.1080/00207179.2012.667882	robust control;control engineering;mathematical optimization;nonlinear system;control theory;feedback;mathematics;satisfiability	Robotics	50.70135668837556	-3.3452991187887253	82947
0b371275ad0338c2a1124d0a494be80d5928ac75	formulation, analysis, and hardware implementation of chaotic dynamics based algorithm for compression and feature recognition in digital images	simulink;digital imaging;embedded systems;observatories;computer hardware;matlab	In this paper we will discuss the utilization of a set of waveforms derived from chaotic dynamical systems for compression and feature recognition in digital images. We will also describe the design and testing of an embedded systems implementation of the algorithm. We will show that a limited set of combined chaotic oscillations are sufficient to form a basis for the compression of thousands of digital images. We will demonstrate this in the analysis of images extracted from the solar heliospheric observatory (SOHO), showing that we are able to detect coronal mass ejections (CMEs) in quadrants of the image data during a severe solar event. We undertake hardware design in order to optimize the speed of the algorithm, taking advantage of its parallel nature. We compare the calculation speed of the algorithm in compiled C, enhanced Matlab, Simulink, and in hardware.	algorithm;chaos theory;compiler;digital image;dynamical system;embedded system;feature recognition;matlab;neural oscillation;simulink	Chance Glenn;Srikanth Mantha;Sajin George;Deepti Atluri;Antonio F. Mondragón-Torres	2013		10.1117/12.2001152	real-time computing;simulation;telecommunications;computer science;theoretical computer science;digital imaging	Robotics	44.85481482911418	-5.615238664418099	83187
99c3ca98ee3c3b801d57d4ca82c4cc8b31fb24f6	speech authentication by semi-fragile speech watermarking utilizing analysis by synthesis and spectral distortion optimization	analysis by synthesis abs;speech authentication;spectral distortion;fragile watermark;bit allocation	This paper proposes an improved semi-fragile speech watermarking scheme by quantization of linear prediction (LP) parameters, i.e., the inverse sine (IS) parameters. The spectral distortion due to watermark embedding is controlled to meet the ‘transparency’ criterion in speech coding. A modified bit allocation algorithm combined with watermarking is developed to determine the quantization step so that the ‘transparency’ requirement is satisfied. Due to the statistical nature, the LP coefficients estimated from the watermarked speech signal are different from the watermarked LP coefficients even in the absence of attacks. This effect is the cause of increase in decoding error and minimum authentication length. To tackle this problem, an Analysis by Synthesis (AbS) scheme is developed to reduce the difference between the estimated LP coefficients and the watermarked ones. The watermark detection threshold and minimum authentication length are then derived according to the probability of error and the signal to noise ratio (SNR) requirements. Experimental results show that the proposed AbS based method can effectively reduce the difference between the watermarked IS parameter and the extracted IS parameter when there is no attacks. In addition, the modified bit allocation algorithm can automatically find the appropriate quantization step used in the odd-even modulation so that the transparency requirement is satisfied.	algorithm;basic access authentication;coefficient;digital watermarking;distortion;experiment;iteration;lu decomposition;mathematical optimization;modulation;quantization (signal processing);requirement;semiconductor industry;signal-to-noise ratio;speech coding;watermark (data file)	Bin Yan;Yinjing Guo	2011	Multimedia Tools and Applications	10.1007/s11042-011-0861-7	speech recognition;telecommunications;theoretical computer science	AI	41.51921035586437	-9.276323492158824	83228
b40c3bfbad4f350d584bb34150eb69de511f7079	the design and implementation of a mobile rfid tag sorting robot	localization;rfid;multipath propagation;order tracking	Libraries, manufacturing lines, and offices of the future all stand to benefit from knowing the exact spatial order of RFID-tagged books, components, and folders, respectively. To this end, radio-based localization has demonstrated the potential for high accuracy. Key enabling ideas include motion-based synthetic aperture radar, multipath detection, and the use of different frequencies (channels). But indoors in real-world situations, current systems often fall short of the mark, mainly because of the prevalence and strength of multipath reflections of the radio signal off nearby objects. In this paper we describe the design and implementation of MobiTagbot, an autonomous wheeled robot reader that conducts a roving survey of the above such areas to achieve an exact spatial order of RFID-tagged objects in very close (1--6 cm) spacings. Our approach leverages a serendipitous correlation between the changes in multipath reflections that occur with motion and the effect of changing the carrier frequency (channel) of the RFID query. By carefully observing the relationship between channel and phase, MobiTagbot detects if multipath is likely prevalent at a given robot reader location. If so, MobiTagbot excludes phase readings from that reader location, and generates a final location estimate using phase readings from other locations as the robot reader moves in space. Experimentally, we demonstrate that cutting-edge localization algorithms including Tagoram are not accurate enough to exactly order items in very close proximity, but MobiTagbot is, achieving nearly 100% ordering accuracy for items at low (3--6 cm) spacings and 86% accuracy for items at very low (1--3 cm) spacings.	adversary (cryptography);algorithm;amiga reflections;autonomous robot;book;carrier frequency;experiment;library (computing);mobile rfid;multipath propagation;radar;radio wave;radio-frequency identification;reflection (computer graphics);sorting;synthetic intelligence	Longfei Shangguan;Kyle Jamieson	2016		10.1145/2906388.2906417	radio-frequency identification;multipath propagation;simulation;internationalization and localization;telecommunications;computer science;operating system	Mobile	48.87125854614345	-0.5298881853687889	83234
69df7b72868e06d18ab995d23f2967cafd71a991	a ccd chip for parallel pulse-doppler radar processing	digital signal processing;meteorological radar;radar tracking;buffer storage;charge coupled devices;chip;charge coupled devices doppler radar meteorological radar radar signal processing signal processing algorithms signal processing pulse compression methods radar tracking buffer storage digital signal processing;signal processing;doppler radar;signal processing algorithms;radar signal processing;pulse compression methods	The generic signal processing requirements for a pulse-Doppler radar are presented and a CCD device for performing a portion of the signal processing is described.	charge-coupled device;pulse-doppler radar	A. M. Chiang;Gary A. Shaw	1984		10.1109/ICASSP.1984.1172698	chip;computer vision;continuous-wave radar;pulse compression;radar tracker;radar engineering details;radar lock-on;space-time adaptive processing;computer science;fire-control radar;digital signal processing;low probability of intercept radar;signal processing;monopulse radar;pulse-doppler radar;radar imaging;radar display;radar	HPC	43.8227413385494	-3.4222731140869933	83269
23f1d96d37b01050e220f1123da264c9adf9ffa9	an audio watermarking method based on molecular matching pursuit	auditory system audio coding time frequency analysis;watermarking;watermarking matching pursuit algorithms psychoacoustic models pursuit algorithms frequency signal processing algorithms dictionaries electronic mail humans protection;lossy compression audio watermarking watermarking model joint time frequency representation molecular matching pursuit algorithm psychoacoustic model audio signal representation signal attacks;model combination;data compression;lossy compression;molecular matching pursuit algorithm;watermarking audio coding data compression;time frequency;auditory system;human auditory system;indexing terms;audio coding;psychoacoustic model;audio signal representation;signal attacks;matching pursuit;watermarking model;time frequency analysis;joint time frequency representation;audio watermarking	In this paper we introduce a new watermarking model combining a joint time frequency (TF) representation using the molecular matching pursuit (MMP) algorithm and a psychoacoustic model. We take advantage of the notion of structure of the signal introduced by the MMP to get a precise representation of audio signals, and then by using a psychoacoustic model we can embed a watermark efficiently on the signal. By selecting atoms of TF components that are not perceptible by the human ear we ensure the security and imperceptibility of the watermark. Then by judicious selection of the watermark host spots we ensure the robustness of the watermark to main kind of signal attacks, including lossy compression. The robustness of the proposed method proves the potential of joint TF representation techniques as viable watermarking schemes.	algorithm;coefficient;digital watermarking;discrete cosine transform;discrete wavelet transform;lossy compression;mp3;matching pursuit;mathematics-mechanization platform;psychoacoustics	Mathieu Parvaix;Sridhar Krishnan;Cornel Ioana	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4517961	computer vision;speech recognition;time–frequency analysis;computer science;theoretical computer science;mathematics;watermark;statistics	EDA	41.65340907964664	-9.101635273960284	83282
01e6248b9e0c1016540e63dfac65103584643a80	fpga-based front-end electronics for positron emission tomography	verification;digital signal processing;field programmable gate array;biological patents;high resolution;biomedical journals;measurement;text mining;europe pubmed central;real time;localization;pet;citation search;fpga;data acquisition system;citation networks;positron emission tomography;ease of use;research articles;abstracts;signal processing;open access;life sciences;clinical guidelines;next generation;algorithms;design;event;full text;small animal pet;rest apis;orcids;europe pmc;biomedical research;pulse timing;bioinformatics;literature search;front end electronics;timing	Modern Field Programmable Gate Arrays (FPGAs) are capable of performing complex discrete signal processing algorithms with clock rates above 100MHz. This combined with FPGA's low expense, ease of use, and selected dedicated hardware make them an ideal technology for a data acquisition system for positron emission tomography (PET) scanner. Our laboratory is producing a high-resolution, small-animal PET scanner that utilizes FPGAs as the core of the front-end electronics. For this next generation scanner, functions that are typically performed in dedicated circuits, or offline, are being migrated to the FPGA. This will not only simplify the electronics, but the features of modern FPGAs can be utilizes to add significant signal processing power to produce higher resolution images. In this paper two such processes, sub-clock rate pulse timing and event localization, will be discussed in detail. We show that timing performed in the FPGA can achieve a resolution that is suitable for small-animal scanners, and will outperform the analog version given a low enough sampling period for the ADC. We will also show that the position of events in the scanner can be determined in real time using a statistical positioning based algorithm.	algorithm;analog;analog-to-digital converter;clock rate;data table;data acquisition;digital signal processor;discrete-time signal;electron tomography;field-programmable gate array;host (network);ibm notes;image resolution;input/output;microprocessor development board;national institute of biomedical imaging and bioengineering (u.s.);next-generation network;online and offline;polyethylene terephthalate;positron-emission tomography;positrons;printed circuit board device component;printing;real-time computing;reconfigurability;sampling (signal processing);scanner device component;scanning systems;signal processing;tomography, emission-computed, single-photon;united states national institutes of health;usability	Michael Haselman;Robert Miyaoka;Thomas K. Lewellen;Scott Hauck;Wendy McDougald;Don Dewitt	2009	FPGA. ACM International Symposium on Field-Programmable Gate Arrays	10.1145/1508128.1508143	embedded system;text mining;parallel computing;simulation;reconfigurable computing;computer science;operating system;signal processing;field-programmable gate array	EDA	45.14659277222407	-3.1330916775551083	83418
9d30d4295f321ac26aee5fa9fda9c9d8bcf4c185	audio watermarking forensics: detecting malicious re-embedding	filigranage;filigranage numerique;digital watermarking;watermarking;gestion de derechos de autor digitales;4230;audio signal processing;protection copie;calculateur embarque;security technologies;aspect medicolegal;droit auteur;securite;sensors;0130c;digital watermark;copy protection;authentication;imagerie;copyright;digital rights management;authentification;copyright protection;algorithme;imagery;autenticacion;forensic science;gestion des droits numeriques;traitement signal audio;filigrana digital;safety;boarded computer;algorithms;imagineria;aspecto forense;calculador embarque;digital right management;forensic aspect;audio watermarking	Digital watermarking has become a widely used security technology in the domain of Digital Rights Management and copyright protection as well as in other applications. In this work, we investigate a particular attack strategy: Embedding a new message in media content that already carries a watermark. The possibility for such an attack strategy results from the absence of truly asymmetric watermarking schemes, especially if the watermark is to be detected in public. In public detection scenarios, every detector needs the same key the embedder used to watermark the cover. With knowledge of the embedding algorithm, everybody who is able to detect the message can also maliciously embed a new message with the same key over the old one. This scenario is relevant in the case that an attacker intends to counterfeit a copyright notice, transaction ID or to change an embedded authentication code. This work presents experimental results on mechanisms for identifying such multiple embeddings in a spread-spectrum patchwork audio watermarking approach. We demonstrate that under certain circumstances multiple embedding can be detected.	sensor	Sascha Zmudzinski;Martin Steinebach;Stefan Katzenbeisser;Ulrich Rührmair	2010		10.1117/12.838881	telecommunications;digital watermarking;electrical engineering;internet privacy;forensic science;watermark;computer security	Crypto	42.22507212557985	-8.230487085455394	83436
46f1c8d1949b0b1c7e08abbbb0afda1c15dbf58a	backward linear control systems on time scales	observability;time scale;echelle temps;linear time varying control systems;operateur differentiel;filtro kalman;controlabilidad;time scales;observabilidad;controllability;filtre kalman;duality;differential operators;kalman filter;observabilite;control lineal;identificacion sistema;controlabilite;system identification;linear control system;bien condicionado;realisability;differential operator;escala tiempo;well conditioned;commande lineaire;bien conditionne;linear control;identification systeme;operador diferencial	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	backward differentiation formula;control system;dynamical system;euler method;francis;finite difference;international symposium on fundamentals of computation theory;jackson;mathematical optimization;numerical analysis;primary source;systems theory;time-scale calculus	Ewa Pawluszewicz;Delfim F. M. Torres	2010	Int. J. Control	10.1080/00207179.2010.483562	control engineering;differential operator;observability;calculus;control theory;mathematics	Robotics	50.369080343931785	-3.227968190004019	83836
2e92eb0cfe6b411f5d606a37c3a812310b28d28a	computer-aided optimal design via modified adaptive random-search algorithm	concepcion asistida;computer aided design;optimisation;optimizacion;algoritmo adaptativo;recherche aleatoire;gear;helical shape;adaptive algorithm;algorithme adaptatif;conception assistee;optimal design;investigacion aleatoria;optimization;forme helicoidale;engrenage;forma helicoidal;random search;engranaje	A modified adaptive random-search algorithm for the design of helical gears has been developed. The proposed methodology allows for the implementation of nonlinear design functions and constraints without the need for linearization. In addition, the technique has the capability of starting from either feasible regions or infeasible regions of the design domain. Application examples demonstrate the feasibility of the proposed technique as a practical method for design optimization. The viability is further illustrated in a performance test against the conjugategradient search method.	mathematical optimization;multidisciplinary design optimization;nonlinear system;optimal design;search algorithm	H. Zarefar;S. N. Muthukrishnan	1993	Computer-Aided Design	10.1016/0010-4485(93)90055-S	mathematical optimization;simulation;random search;gear;engineering;optimal design;computer aided design;mathematics;engineering drawing	EDA	53.08865131221291	-4.848339123604917	83927
ca87c54f46b610d706254af9e4b77dc06453c70c	video watermarking system for broadcast monitoring	digital watermarking;intellectual property;technology;radiodifusion;filigrane;protection;just another watermarking system jaws;monitoring;propiedad intelectual;technologie;watermark;proteccion;visual identity verification auditor viva;monitorage;broadcasting;video;monitoreo;propriete intellectuelle;surveillance systems;radiodiffusion;tecnologia	This paper presents a video watermarking technology for broadcast monitoring. The technology has been developed at the Philips Research Laboratories in Eindhoven in the context of the European ESPRIT project VIVA (Visual Identity Veri cation Auditor). The aim of the VIVA project is to investigate and demonstrate a professional broadcast surveillance system. The key technology in the VIVA project is a new video watermarking technique by the name of JAWS (Just Another Watermarking System). The JAWS system has been developed such that the embedded watermarks (i) are invisible, (ii) are robust with respect to all common processing steps in the broadcast transmission chain, (iii) have a very low probability of false alarms, (iv) have a large payload at high rate, and (v) allow for a low complexity and a real-time detection. In this paper we present the basic ingredients of the JAWS technology. We also brie y discuss the performance of JAWS with respect to the requirements of broadcast monitoring.	digital watermarking;embedded system;emoticon;image scaling;participatory monitoring;real-time clock;requirement	Ton Kalker;Geert Depovere;Jaap Haitsma;Maurice Maes	1999		10.1117/12.344661	telecommunications;engineering;multimedia;computer security	EDA	42.87314722319033	-7.709049404195824	84577
1f1e222a21d9e3b116ea1c3a024569cbb870c70f	an improved technique for hiding data in audio	encoding frequency domain analysis time domain analysis transforms robustness security noise;hidden bit extraction hiding data amplitude cover audio file secret message security original signal;frequency domain analysis;time domain analysis;security of data audio signal processing data encapsulation;transforms;perceptiveness audio steganography random number amplitude phase coding;robustness;security;encoding;noise	This paper presents an improved technique for hiding data in audio. The proposed method modifies the amplitude of the cover audio file to embed the secret message. To increase the security of the proposed scheme, we use a key to adjust the hiding technique. The suggested scheme does not need the original signal for extracting the hidden bits. Experimental results show that the proposed method is inaudible and suitable for hiding data in audio.	error detection and correction	Huynh Ba Dieu;Nguyen Xuan Huy	2014	2014 Fourth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)	10.1109/DICTAP.2014.6821673	speech recognition;computer science;noise;information security;theoretical computer science;audio bit depth;internet privacy;frequency domain;encoding;robustness	EDA	41.72606592024222	-9.380180083949035	84647
6217ad8d2bb5a89f1258f61bc39bf80c541e6c8f	distributed fault tolerant estimation in wireless sensor network using robust diffusion adaptation	faulty node;robust estimation;wireless sensor network	The problem of robust distributed estimation in wireless sensor network (WSN) when few sensor nodes are faulty is addressed here. In WSN, each sensor node collects scalar measurements of some unknown parameters and then estimates the parameter of interest from the data collected across the network. An iterative distributed linear parameter estimated algorithm is proposed here by using diffusion co-operation. Each node updates its information by using the data collected by it and the information received from the neighbours. The mean square error (MSE) of distributed estimation schemes increases whenever any faulty sensor node in the network fails to transmit correct information, which leads to inaccurate estimation. Hence a robust diffusion linear estimation algorithm using Hubber's cost function is proposed here in order to improve the accuracy of the estimation.		Meenakshi Panda;Pabitra Mohan Khilar	2012		10.1007/978-3-642-28073-3_25	real-time computing;wireless sensor network;computer science;brooks–iyengar algorithm;distributed computing;key distribution in wireless sensor networks;computer network	Mobile	52.911839309867524	3.854010378760518	84650
bd4410b59b38f5a664432dd162ab0d2058aed2f1	a multi-cast communication scheme using weak electrical current for intra-body networks	design;intra-body area networks;intra-body communication;multi-cast communication;multi-hop communication;network communications;network topology;performance;theory;weak electrical current;wireless communication	Implantable medical devices have paved the way for realizing intra-body networks (IBNs) that are capable of communicating information from within the body. Traditional forms of RF-based based communication face drawbacks in terms of high absorption within tissues and can potentially result in security and privacy issues, owing to the omnidirectional radiation. Instead, we propose the use of weak electrical current as a means of intrabody communication for implants within the human body and to a relay and gateway node located on the surface of the skin that facilitates remote patient monitoring. The main contributions of this paper are: (i) signal reflection and refraction analysis of electromagnetic waves through human tissue boundaries, and (ii) the design of a combined multi-hop and multi-cast communication scheme for communication between implants. Our results reveal that a multi-cast communication scheme can be achieved for IBNs with the appropriate selection of transmission parameters.	privacy;propagation constant;radio frequency;relay;signal reflection	William J. Tomlinson;Kaushik R. Chowdhury;Christopher Yu	2014			electronic engineering;telecommunications;engineering;communication	Security	46.120911030158574	0.7164863378163813	84721
52761e48f4e786aa9d98dfaa23bb2dc3c98e37b1	factor graph based simultaneous localization and mapping using multipath channel information		Radio-based localization has the potential to provide centimeter-level position information. In this paper we apply joint probabilistic data association to multipath-assisted simultaneous localization and mapping (SLAM) for this purpose. In multipath-assisted localization, position-related information in multipath components (MPCs) is exploited to increase the accuracy and robustness of indoor tracking. Based on a recently introduced loopy belief propagation multipath-assisted localization scheme that performs probabilistic data association jointly with agent state estimation, we build a method for SLAM without using apriori known environment maps. The proposed method is highly accurate and robust in localizing a mobile agent while building up an environment feature map. It scales well in all relevant systems parameters and has a very low computational complexity.	apriori algorithm;belief propagation;casio loopy;computational complexity theory;correspondence problem;factor graph;internationalization and localization;location-based service;map;mobile agent;multipath propagation;simultaneous localization and mapping;software propagation	Erik Leitinger;Florian Meyer;Fredrik Tufvesson;Klaus Witrisal	2017	2017 IEEE International Conference on Communications Workshops (ICC Workshops)	10.1109/ICCW.2017.7962732	robustness (computer science);multipath propagation;belief propagation;probabilistic logic;mobile agent;factor graph;simultaneous localization and mapping;computer science;machine learning;artificial intelligence;communication channel	Robotics	52.954414350528076	1.9600530919059282	85117
ba84664872530a6056a460b94872cdf51b9af13f	high capacity logarithmic audio watermarking based on the human auditory system	digital right management audio watermarking multimedia security;audio signal processing;hearing audio signal processing audio watermarking;multimedia security;watermarking robustness quantization cepstrum bit error rate digital audio players auditory system;hearing;digital right management;mp3 logarithmic audio watermarking human auditory system high capacity audio watermarking algorithm logarithm domain absolute threshold of hearing ath has selected frequency band remarkable capacity transparency robustness scale factor frame size watermarking property perceptual distortion audio signal processing added noise filtering mpeg compression;audio watermarking	This paper proposes a high capacity audio watermarking algorithm in the logarithm domain based on the absolute threshold of hearing (ATH) of the human auditory system (HAS) which makes this scheme a novel technique. The key idea is to divide the selected frequency band into short frames and quantize the samples based on the HAS. Apart from remarkable capacity, transparency and robustness, this scheme provides three parameters (frequency band, scale factor, and frame size) which facilitate the regulation of the watermarking properties. The experimental results show that the method has a high capacity (800 to 7000 bits per second), without significant perceptual distortion (ODG is greater than - 1) and provides robustness against common audio signal processing such as added noise, filtering and MPEG compression (MP3).	algorithm;audio signal processing;data rate units;digital watermarking;distortion;frequency band;mp3;moving picture experts group;quantization (signal processing)	Mehdi Fallahpour;David Megías	2012	2012 IEEE International Symposium on Multimedia	10.1109/ISM.2012.13	speech recognition;audio signal processing;audio normalization;computer science;audio bit depth;speech coding;multimedia;audio signal flow	Embedded	43.81411207775674	-8.77498494079001	85180
4a0ba690022e8c2cb3e593f047a5d4a1ddb428f7	updates to the opus audio codec		This document addresses minor issues that were found in thenspecification of the Opus audio codec in RFC 6716. It updates thennormative decoder implementation included in Appendix A of RFC 6716.nThe changes fix real and potential security-related issues, as well asnminor quality-related issues.	codec;libopus	Jean-Marc Valin;Koen Vos	2017	RFC	10.17487/RFC8251	the internet;codec;computer architecture;embedded system;opus;celt;computer science;audio codec	HCI	46.21411722454061	-7.839001184389894	85268
892895d161512baec9685560615295d83c66103d	netform and code optimizer manual	code optimization;electrical network;symbolic analysis;linear equations	NETFORM is a very powerful and flexible tool for solving (sparse) systems of linear equations in algebraic form. The system includes convenient facilities to generate (and solve) linear equations for electrical networks.The accompanying Code Optimizer is a general purpose tool to automatically optimize sets of algebraic expressions, with emphasis on those generated by the NETFORM system.Thus the combination of both systems can be used to solve numerous problems of a symbolic and/or numeric nature, taking full advantage of the REDUCE 2 embedding in which it is supported.For instance NETFORM can automatically provide a user with descriptive (tableau) equations of an arbitrary linear electrical network and, as it solves such linear equations too, calculate any transferfunction of that linear electrical network. The NETFORM environment encourages users to think of electrical networks in terms of network elements, one port elements as well as subnetworks, which can be conveniently described and manipulated.Given a complete network description, NETFORM allows different approaches in analyzing it, i.e. a full symbolic analysis, a hybrid analysis, a state analysis or a mixed hybrid and state analysis.	linear algebra;linear equation;long division;mathematical optimization;program optimization;reduce;sparse matrix;system of linear equations	J. Smit;J. A. van Hulzen;Ben J. A. Hulshof	1981	ACM SIGSAM Bulletin	10.1145/1089270.1089275	electrical network;computer science;theoretical computer science;machine learning;program optimization;mathematics;linear equation;symbolic data analysis;programming language;algorithm;algebra	HPC	42.42092635193133	3.9035904304971116	85292
38c881dbf6335e8246ac0c6efc0b8bf0dd632e86	distributed diffusion-based lms for node-specific parameter estimation over adaptive networks	radio spectrum management cognitive radio cooperative communication least mean squares methods parameter estimation;cognitive radio networks distributed diffusion node specific parameter estimation adaptive networks distributed adaptive algorithm diffusion based implementation least mean squares algorithms lms cooperative spectrum sensing;node specific parameter estimation adaptive distributed networks diffusion algorithm cooperation;estimation least squares approximations vectors adaptive systems parameter estimation conferences signal processing algorithms	A distributed adaptive algorithm is proposed to solve a node-specific parameter estimation problem where nodes are interested in estimating parameters of local interest and parameters of global interest to the whole network. To address the different node-specific parameter estimation problems, this novel algorithm relies on a diffusion-based implementation of different Least Mean Squares (LMS) algorithms, each associated with the estimation of a specific set of local or global parameters. Although all the different LMS algorithms are coupled, the diffusion-based implementation of each LMS algorithm is exclusively undertaken by the nodes of the network interested in a specific set of local or global parameters. To illustrate the effectiveness of the proposed technique we provide simulation results in the context of cooperative spectrum sensing in cognitive radio networks.	adaptive algorithm;cognitive radio;estimation theory;least mean squares filter;simulation	Nikola Bogdanovic;Jorge Plata-Chaves;Kostas Berberidis	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6855002	mathematical optimization;computer science;machine learning;statistics	Robotics	53.55836337857515	4.033437843905728	85710
2dd9fcf887a4c643326c19f893c10c86a864409d	a unified approach to generating series for mixed cascades of analytic nonlinear input-output systems	radius of convergence;chen fliess series;input output;nonlinear systems;formal power series;integral operator;real analytic functionals;nonlinear system;generating series;analytic function	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;nl (complexity);nonlinear system;polynomial;primary source;two-port network	W. Steven Gray;Makhin Thitsa	2012	Int. J. Control	10.1080/00207179.2012.703330	non-analytic smooth function;input/output;mathematical optimization;mathematical analysis;discrete mathematics;function series;nonlinear system;global analytic function;analytic function;radius of convergence;mathematics;formal power series	Robotics	50.39669918276754	-3.221766722704608	85832
0fd4b29d8eb4f993a894b0987246708a82534df1	4800 bps relp vocoder using vector quantization for both filter and residual representations	vocoders vector quantization filters autocorrelation linear predictive coding performance analysis equations pattern classification prototypes testing;prototypes;real time;filters;testing;linear predictive;linear predictive coding;scalar quantization;vector quantization;vocoders;performance analysis;pattern classification;time domain;vector quantizer;autocorrelation;binary tree	The paper presents the full description and discusses the performances of a 4800 bit per second residual excited linear prediction vocoder. The LPC analysis is efficiently performed using a type of binary-tree search vector-quantization approach. The technique, which is described in ref (1), uses a set of hyperplane equations to perform a hierarchical pattern classification of the input autocorrelation vector in the autocorrelation space. The end result of the search is the integer i 1 which is the index of the most appropriate (in the Itakura-distance sense) prediction filter out of a set of N preset filters. The search requires only \Log_{2}N dot products. In this case vector quantization presents two advantages over the classical approach of the Durbin algorithm followed by scalar quantization. First, a faster algorithm is obtained. Second, the same accuracy in filter representation is possible with less bits per second and consequently more bits can be allocated for representing the residual and gain. The residual is vector quantized in the time domain by blocks of 16 the samples according to the approach of ref (2). The 16 sample block is essentially encoded using the integer I 2 which is the index of the most appropriate 16-sample waveform out of set of M preset prototype waveforms stored in memory. The paper includes preference testings for comparison with other types of 4800 Kbit/sec vocoders. Some sample recordings will be presented at the conference. Finally, preliminary results in the attempt to implement the vocoder in real time on a MAP 200 array processor are discussed.	residual-excited linear prediction;vector quantization;vocoder	Jean-Pierre Adoul;Philippe Mabilleau	1982		10.1109/ICASSP.1982.1171774	linear predictive coding;speech recognition;autocorrelation;binary tree;time domain;computer science;theoretical computer science;machine learning;mathematics;prototype;software testing;vector quantization;statistics	ML	48.96880597109644	-9.812698564104839	86021
9c358857c02ecf178c54b8e6cc7aa896331f6e5f	a case study of perceived listening quality of temporally interrupted voip service	speech processing internet telephony;dichotomy treatment perceived listening quality study temporally interrupted voip service discontinuity temporary speech interruption communication data transport network quality assessment technique legacy landline telephone system lab based subjective testing perceptual quality variation estimation speech quality assessment itu t rec p 862 signal layer sqa model itu t rec p 563 signal layer sqa model time alignment algorithm speech sequence unpredictable quality rating estimation;service handovers and pervasive connectivity voipow voip over wireless perceptual quality assessment pqa	In modern VoIP services, we often observe temporary speech interruptions during ordinary conversations. This is caused by the mobility facility and the best effort nature of data transport networks. This impairment factor has been classically de-emphasized by existing subjective and objective quality assessment techniques because it is rarely observed over legacy landline telephone systems. This paper explores the perceptual effects of discontinuity in speech communications. A series of lab-based subjective tests has been carried-out in order to understand the perceptual quality variation with respect to diverse patterns of temporal service discontinuity. In parallel, impairment conditions have been evaluated using the standardized active and passive signal-layer SQA (Speech Quality Assessment) models described in ITU-T Rec. P.862 and P.563, respectively. Our exploration indicates that both strategies estimate poorly perceived quality of interrupted speech stimulus on a sample-by-sample basis. We found that the time-alignment algorithm of original and degraded speech sequences embedded in the ITU-T Rec. P.862 SQA model plays an essential role in the observed unpredictable quality rating estimates. Moreover, the dichotomy treatment of discontinuity instances by the ITU-T Rec. P.563 SQA model constitutes a principal source of inaccuracy of estimated perceptual quality. A guideline for proper consideration of discontinuity distribution and context is presented and applied on the ITU-T Rec. P.862 SQA algorithm. This results in an improvement of its estimation performance in the context of interrupted speech sequences.	algorithm;best-effort delivery;codec;embedded system;interrupt;landline;lossy compression;loudspeaker time alignment;pesq;reflections of signals on conducting lines;relevance;software quality assurance;speech synthesis;temporal logic;wideband voice	Sofiene Jelassi;Gerardo Rubino	2012	2012 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2012.6503352	speech recognition;telecommunications;computer science	SE	49.05743012356019	-7.0516741498055815	86389
9a59d8afd01badb2e3f2a239d2e4f98e3d38bb1d	a parallel strongly implicit algorithm for solving of diffusion equations	simulation ordinateur;linear algebra;algoritmo paralelo;partial differential equation;parallel algorithm;programming language;metodo diferencia finita;incomplete lu factorization;simulacion numerica;finite difference method;algorithme parallele;resolucion sistema ecuacion;resolution systeme equation;methode difference finie;message passing interface;simulation numerique;ecuacion difusion;diffusion equation;parallel computer;fortran;equation system solving;diffusion process;simulacion computadora;equation diffusion;computer simulation;numerical simulation	We present a parallel algorithm for the solution of partial differential equations representing a 3-D diffusion process of the underground water by a finite difference method. The algorithm belongs to a class of the incomplete LU factorization methods, where corresponding system of linear algebraic equations is solved by a quasi LU decomposition in every time step. A code realizing the algorithm was written in Fortran 90 programming language using the MPI message passing interface system and was tested on a SGI Origin 2000 parallel computer.	algorithm	Ladislav Halada;Mária Lucká	1999		10.1007/3-540-49164-3_8	computer simulation;diffusion equation;mathematical optimization;parallel computing;stone method;incomplete lu factorization;computer science;finite difference method;message passing interface;theoretical computer science;diffusion process;mathematics;parallel algorithm;partial differential equation;algorithm	ML	44.60404884336053	3.3907808091327607	86654
1f02e0dc3f6f7313e0076ee21ca0312ad0f48161	a linear predictive method for highly compressed presentation of speech spectra	data compression;speech coding;linear predictive;quantisation signal;spectral matching linear predictive method highly compressed presentation speech spectra linear prediction with sample grouping spectral modelling extrapolation all pole models prediction parameters quantisation;speech processing quantization signal processing algorithms speech coding nonlinear filters acoustic signal processing prediction algorithms predictive models equations;prediction theory;linear prediction;quantisation signal prediction theory speech coding data compression	Our study proposes a new linear predictive algorithm, Linear Prediction with Sample Grouping (LPSG), for spectral modelling of speech. This method reformulates computation of linear prediction by grouping and extrapolating samples used in the prediction. In LPSG the number of samples used in the computation of the prediction is larger than the number of parameters to define the optimal predictor. Consequently, the proposed method makes it possible to obtain all-pole models for speech spectra that can be defined with a very compressed set of parameters. Quantisation of the prediction parameters of LPSG was compared in the present study to conventional linear prediction (LP) using a very low order of prediction. It appeared that LPSG yields better spectral matching and smaller residual energies in comparison to LP.		Susanna Varho;Paavo Alku	2000		10.1109/ISCAS.2000.857362	data compression;linear predictive coding;speech recognition;vector sum excited linear prediction;linear prediction;computer science;machine learning;speech coding;pattern recognition;mathematics;algebraic code-excited linear prediction;statistics;code-excited linear prediction	NLP	49.29161125740592	-9.835387239188114	87279
25385d8add504685ae4132428503ab356bd7bcde	voicing-based codebook in low-rate wideband celp coding.	code excited linear prediction;low complexity;speech coding;indexing terms;constrained voicing based vector quantization;low complexity isf quantization;vector quantizer;split vector quantization;wideband speech coding	In this work we propose an efficient technique to quantize the immitance spectral frequency (ISF) in an algebraic code-excited linear prediction (ACELP) wideband codec. The Constrained Voicing-Based Vector Quantization (C-VBVQ) presented in this paper improves substantially the performance of the unconstrained-VBVQ approach for both clean and noisy speech. Both techniques reduce the codebook search time by almost one third. However, in the C-VBVQ training phase, the three codebooks that are individually designed for voiced, unvoiced and transition speech, are jointly reoptimized to impose a structural configuration. The proposed technique reduces the processing delay since it restricts the quantization of an input vector to only one smaller but optimal codebook. For each speech frame, one codebook is selected from the set of three codebooks based on the interframe correlation of the spectral information. The C-VBVQ was successfully implemented in an ACELP wideband coder. The objective and subjective performance are not only superior to that of the combination of the split vector quantization and multistage vector quantization but also to the unconstrained VBVQ.	algebraic code-excited linear prediction;codebook;codec;multistage amplifier;processing delay;quantization (signal processing);vector quantization	Driss Guerchi;Tamer F. Rabie;Abdelrhani Louzi	2007		10.4304/jcm.4.2.71-77	speech recognition;index term;quantization;vector sum excited linear prediction;computer science;speech coding;pattern recognition;mathematics;linde–buzo–gray algorithm;vector quantization;code-excited linear prediction	ML	48.66358156599406	-9.526443997579078	87322
657d4e8abc6f8fb1f4848cc43665b1956ce66ad3	blue matter: strong scaling of molecular dynamics on blue gene/l	estensibilidad;distributed system;systeme reparti;n body system;proteine;collective communication;communicating process;n body simulations;biologia molecular;milisegundo;molecular dynamics;effet dimensionnel;systeme n corps;dynamique moleculaire;dynamical system;proceso comunicante;milliseconde;systeme dynamique;nanosegundo;molecular dynamics method;nanosecond;sistema repartido;size effect;molecular biology;envoi message;processus communicant;nanoseconde;message passing;biological systems;molecular dynamic;sistema n cuerpos;floating point;proteina;coma flotante;methode dynamique moleculaire;extensibilite;scalability;efecto dimensional;sistema dinamico;dinamica molecular;parallel programs;protein;millisecond;metodo dinamico molecular;virgule flottante;biologie moleculaire	This paper presents strong scaling performance data for the Blue Matter molecular dynamics framework using a novel n-body spatial decomposition and a collective communications technique implemented on both MPI and low level hardware interfaces. Using Blue Matter on Blue Gene/L, we have measured scalability through 16,384 nodes with measured time per time-step of under 2.3 milliseconds for a 43,222 atom protein/lipid system. This is equivalent to a simulation rate of over 76 nanoseconds per day and represents an unprecedented timeto-solution for biomolecular simulation as well as continued speed-up to fewer than three atoms per node. On a smaller, solvated lipid system with 13,758 atoms, we have achieved continued speedups through fewer than one atom per node and less than 2 milliseconds/time-step. On a 92,224 atom system, we have achieved floating point performance of over 1.8 TeraFlops/second on 16,384 nodes. Strong scaling of fixed-size classical molecular dynamics of biological systems to large numbers of nodes is necessary to extend the simulation time to the scale required to make contact with experimental data and derive biologically relevant insights.	atom;biological system;blue gene;electrical connector;flops;image scaling;molecular dynamics;scalability;simulation	Blake G. Fitch;Aleksandr Rayshubskiy;Maria Eleftheriou;T. J. Christopher Ward;Mark Giampapa;Yuriy Zhestkov;Michael Pitman;Frank Suits;Alan Grossfield;Jed W. Pitera;William C. Swope;Ruhong Zhou;Scott Feller;Robert S. Germain	2006		10.1007/11758525_113	nanosecond;molecular dynamics;message passing;scalability;simulation;millisecond;computer science;floating point;operating system;dynamical system;algorithm	HPC	43.59291249287443	0.6793024675038235	87554
1b6ee0307d0de39463ea901b21f92b6cbe6d5ef1	mobile robot localization using biased chirp-spread-spectrum ranging	biased chirp spread spectrum ranging;mobile robot localization chirp spread spectrum css ranging extended kalman filter ekf ieee 802 15 4a measurement bias;nonlinear filters;chirp spread spectrum;rf signals;extended kalman filter ekf;time of flight;chirp;trilateration method;mobile robot;path planning;cascading style sheets;ultrasonic variables measurement;kalman filters;mobile robots;frequency measurement;matrix algebra;chirp spread spectrum css ranging;noise measurement;spread spectrum communication;radio frequency;radio frequency signals;measurement bias;mobile radio;scaling factor;ieee 802 15 4a;mobile robot localization;spread spectrum communication kalman filters matrix algebra mobile radio mobile robots nonlinear filters path planning;extended kalman filter;coordinate measuring machines;mobile robots chirp cascading style sheets coordinate measuring machines rf signals radio frequency noise measurement robot kinematics ultrasonic variables measurement frequency measurement;measurement noise;noise measurement mobile robot localization biased chirp spread spectrum ranging radio frequency signals trilateration method extended kalman filter scaling factor;robot kinematics	In this paper, we propose a method of mobile robot localization based on chirp-spread-spectrum (CSS) ranging. By using the CSS system, the distances between a mobile robot and CSS nodes fixed at known coordinates can be measured according to the time of flight of radio frequency signals. Based on the measured distances, the coordinates of a mobile robot can be calculated by the method of trilateration. To deal with measurement noise, an extended Kalman filter (EKF) can be applied to estimate the coordinate of the mobile robot. These measured distances, however, are not only noisy but also biased. Therefore, the estimated coordinates of the mobile robot represent inconsistent values. To solve the problem of bias, we define a scaling factor, which corresponds to the change of the magnitude of a measured distance vector that is due to biases. Based on the scaling factor, we develop a new biased measurement model and apply the EKF to our model for estimating the coordinates of a mobile robot. Through localization experiments, we evaluate the performance of the proposed algorithm.	algorithm;cascading style sheets;chirp;distance-vector routing protocol;experiment;extended kalman filter;frequency-hopping spread spectrum;image scaling;mobile robot;radio frequency;robotic mapping	Hyeonwoo Cho;Sang Woo Kim	2010	IEEE Transactions on Industrial Electronics	10.1109/TIE.2009.2036633	mobile robot;monte carlo localization;electronic engineering;telecommunications;computer science;engineering;artificial intelligence;control theory;radio frequency	Robotics	51.03591778954578	0.533477962369061	87650
4e2cdbffb488dcb18c7dd1db0dca21a32cbf8d90	a chipless rfid method of 2d localization based on phase acquisition		This paper explores the performance of object localization using chipless tags. We show that it is possible to localize a tag (or an object attached to it) by measuring the phase offset between a known position and the position to estimate. This method provides better accuracy compared to classical ones based on received signal strength indicator (RSSI) or round-trip time of flight. We show that submillimeter precision for distance measurement and an error of less than 4 mm for localization can be achieved. These results point the way toward new kinds of sensors and user interfaces using chipless tags which can be contactless and 3D. This new possibility is in addition to the identification functionality which is inherent to the use of chipless tags.	chipless rfid	Nicolas Barbot;Etienne Perret	2018	J. Sensors	10.1155/2018/7484265	electronic engineering;signal strength;computer vision;chipless rfid;artificial intelligence;offset (computer science);time of flight;engineering;user interface	Robotics	48.81201913020501	-0.8101380870268869	88278
25f6ed202c766dbde73cb768bd5c9650ea458f11	stable direct adaptive fuzzy control for a class of mimo non-linear systems	fuzzy neural network;fuzzy controller;lyapunov function;fuzzy control;multi input multi output;upper bound;theoretical analysis;adaptive fuzzy control;non linear system;fuzzy system	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	approximation;emoticon;francis;fuzzy control system;information science;linear system;mimo;nl (complexity);nonlinear system;primary source;simulation;three utilities problem	Tian-Ping Zhang	2003	Int. J. Systems Science	10.1080/00207720310001612873	control engineering;mathematical optimization;defuzzification;adaptive neuro fuzzy inference system;lyapunov function;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;control theory;mathematics;fuzzy associative matrix;upper and lower bounds;fuzzy set operations;fuzzy control system	Robotics	50.86126735527371	-3.385896514931467	88423
5367376d20eaaf3827fde827fcafcad0e7d4234c	a programmable optimization environment using the gamess-us and merlin/mcl packages. applications on intermolecular interaction energies	second order;electron correlation;ab initio potential energy scans;molecular modeling;programming language;restricted hartree fock;quasi newton;gamess us;distributed programs;data exchange;numerical optimization;02 60 pn;31 50 x;program optimization;intermolecular interaction;mcl;van der waals;operating system;basis set superposition error;geometry optimization strategies;31 15 p;test methods;merlin;fortran;potential energy surface;potential energy;intermolecular interaction energies;electronic structure;benzene water dimer;quantum chemistry;ab initio calculation	The Merlin/MCL optimization environment and the GAMESS-US package were combined so as to offer an extended and efficient quantum chemistry optimization system, capable of implementing complex optimization strategies for generic molecular modeling problems. A communication and data exchange interface was established between the two packages exploiting all Merlin features such as multiple optimizers, box constraints, user extensions and a high level programming language. An important feature of the interface is its ability to perform dimer computations by eliminating the basis set superposition error using the counterpoise (CP) method of Boys and Bernardi. Furthermore it offers CP-corrected geometry optimizations using analytic derivatives. The unified optimization environment was applied to construct portions of the intermolecular potential energy surface of the weakly bound H-bonded complex C6H6–H2O by utilizing the high level Merlin Control Language. The H-bonded dimer HF–H2O was also studied by CP-corrected geometry optimization. The ab initio electronic structure energies were calculated using the 6-31G** basis set at the Restricted Hartree–Fock and second-order Moller–Plesset levels, while all geometry optimizations were carried out using a quasi-Newton algorithm provided by Merlin.#R##N#Program summary#R##N#Title of program: MERGAM#R##N##R##N#Catalogue identifier:ADYB_v1_0#R##N##R##N#Program summary URL:http://cpc.cs.qub.ac.uk/summaries/ADYB_v1_0#R##N##R##N#Program obtainable from: CPC Program Library, Queen's University of Belfast, N. Ireland#R##N##R##N#Computer for which the program is designed and others on which it has been tested: The program is designed for machines running the UNIX operating system. It has been tested on the following architectures: IA32 (Linux with gcc/g77 v.3.2.3), AMD64 (Linux with the Portland group compilers v.6.0), SUN64 (SunOS 5.8 with the Sun Workshop compilers v.5.2) and SGI64 (IRIX 6.5 with the MIPSpro compilers v.7.4)#R##N##R##N#Installations: University of Ioannina, Greece#R##N##R##N#Operating systems or monitors under which the program has been tested: UNIX#R##N##R##N#Programming language used: ANSI C, ANSI Fortran-77#R##N##R##N#No. of lines in distributed program, including test data, etc.:11 282#R##N##R##N#No. of bytes in distributed program, including test data, etc.: 49 458#R##N##R##N#Distribution format: tar.gz#R##N##R##N#Memory required to execute with typical data: Memory requirements mainly depend on the selection of a GAMESS-US basis set and the number of atoms#R##N##R##N#No. of bits in a word: 32#R##N##R##N#No. of processors used: 1#R##N##R##N#Has the code been vectorized or parallelized?: no#R##N##R##N#Nature of physical problem: Multidimensional geometry optimization is of great importance in any ab initio calculation since it usually is one of the most CPU-intensive tasks, especially on large molecular systems. For example, the geometric and energetic description of van der Waals and weakly bound H-bonded complexes requires the construction of related important portions of the multidimensional intermolecular potential energy surface (IPES). So the various held views about the nature of these bonds can be quantitatively tested.#R##N##R##N#Method of solution: The Merlin/MCL optimization environment was interconnected with the GAMESS-US package to facilitate geometry optimization in quantum chemistry problems. The important portions of the IPES require the capability to program optimization strategies. The Merlin/MCL environment was used for the implementation of such strategies. In this work, a CP-corrected geometry optimization was performed on the HF–H2O complex and an MCL program was developed to study portions of the potential energy surface of the C6H6–H2O complex.#R##N##R##N#Restrictions on the complexity of the problem: The Merlin optimization environment and the GAMESS-US package must be installed. The MERGAM interface requires GAMESS-US input files that have been constructed in Cartesian coordinates. This restriction occurs from a design-time requirement to not allow reorientation of atomic coordinates; this rule holds always true when applying the COORD = UNIQUE keyword in a GAMESS-US input file.#R##N##R##N#Typical running time: It depends on the size of the molecular system, the size of the basis set and the method of electron correlation. Execution of the test run took approximately 5 min on a 2.8 GHz Intel Pentium CPU.	gamess (us);macintosh common lisp;mathematical optimization	Fanis G. Kalatzis;Dimitris G. Papageorgiou;Ioannis N. Demetropoulos	2006	Computer Physics Communications	10.1016/j.cpc.2006.04.009	data exchange;van der waals force;computer science;basis set superposition error;theoretical computer science;merlin;potential energy;program optimization;molecular model;mathematics;test method;quantum chemistry;second-order logic;physics;potential energy surface;algorithm;electronic structure;quantum mechanics;electronic correlation	HPC	42.36808794017309	3.4940359748850764	88628
5f31b6531a208f6dbe0bf26ff6a1dc511e456a45	a design of lossy and lossless scalable audio coding	data conversion;data compression;lossy compression;signal reconstruction audio coding data conversion data compression;audio coding;bit rate scalability lossless scalable audio coding lossy scalable audio coding high compression lossy coding iso iec mpeg 4 audio standard encoding process lossy compression bit slice lossless data conversion lossless coding reconstructed signal;signal reconstruction;audio coding iec standards data conversion mpeg 4 standard encoding redundancy iso standards transform coding decoding laboratories	"""This paper proposes a lossless audio coding scheme making use of high-compression lossy coding such as the ISO/IEC MPEG-4 audio standard. The encoding process consists of lossy compression, bit slice lossless data conversion, and lossless coding. The lossy compression significantly reduces the amplitude of the error signal between the input signal and the reconstructed signal. In addition, bit slice data conversion makes the lossless coding more efficient. As a result of preliminary experiment, a total file size can be reduced to 70-50% of the original size, which is significantly more efficient than conventional universal lossless coding schemes such as """"gzip"""". The resultant compressed data is useful for various applications, since it has bit rate scalability and can be used as a highly compressed signal as well as a lossless signal."""	lossless compression;lossy compression;scalability	Takehiro Moriya;Naoki Iwakami;Akio Jin;Takeshi Mori	2000		10.1109/ICASSP.2000.859103	data compression;lossy compression;signal reconstruction;sub-band coding;lossless jpeg;real-time computing;transform coding;data conversion;mpeg-4 part 3;image compression;jbig2;computer science;entropy encoding;theoretical computer science;context-adaptive variable-length coding;speech coding;sound quality;jpeg;mathematics;lossless compression;tunstall coding;adaptive coding;context-adaptive binary arithmetic coding;packbits;statistics;golomb coding	ML	47.08351576376815	-9.603472632342445	89062
ae35c8f72a8c89123b3e11ecca5ae180039db0c8	robust optimal control of regular languages	performance measure;modelizacion;politica optima;langage commande;metodo polinomial;control optimo;systeme evenement discret;robustness analysis;supervisory control;programme commande;lenguaje control;sintesis control;complexite calcul;polynomial control;automata estado finito;automate deterministe;model generation;performance index;control polinomio;regular language;robust control;language measure;optimal policy;robust optimization;sistema acontecimiento discreto;lenguaje racional;optimal control;modelisation;systeme incertain;complejidad computacion;discrete event system;parametric uncertainty;deterministic automaton;polynomial method;computational complexity;control program;synthese commande;commande optimale;automata determinista;commande polynomiale;langage rationnel;finite state automaton;control robusta;programa mando;finite automaton;discrete event supervisory control;automate fini;commande robuste;algoritmo optimo;methode polynomiale;monte carlo simulation;sistema incierto;algorithme optimal;politique optimale;optimal algorithm;modeling;control language;supervision;uncertain system;deterministic finite state automata;control synthesis;discrete event;dynamic behavior	7 This paper presents an algorithm for robust optimal control of regular languages under specified uncertainty bounds on the event cost parameters of the language measure that has been recently reported in literature. The performance index for the proposed robust optimal 9 policy is obtained by combining the measure of the supervised plant language with uncertainty. The performance of a controller is represented by the language measure of the supervised plant and is minimized over the given range of event cost uncertainties. Synthesis 11 of the robust optimal supervisory control policy requires at most n iterations, where n is the number of states of the deterministic finitestate automaton (DFSA) model, generated from the regular language of the unsupervised plant behavior. The computational complexity 13 of the control synthesis method is polynomial in n. 2005 Published by Elsevier Ltd. 15	algorithm;best, worst and average case;computational complexity theory;controlled natural language;deterministic finite automaton;formal language;icy;iteration;maximal set;optimal control;polynomial;regular language;round-robin scheduling;terminate (software);unsupervised learning	Constantino M. Lagoa;Jinbo Fu;Asok Ray	2005	Automatica	10.1016/j.automatica.2005.03.016	robust control;control engineering;process performance index;systems modeling;optimal control;regular language;artificial intelligence;deterministic automaton;mathematics;supervisory control;finite-state machine;computational complexity theory;algorithm;monte carlo method	Robotics	39.848519179554046	2.5154599023682613	89874
870b6a852224c7316cfa05a5199f71852a85a522	a partial steganography algorithm for 3d triangle mesh		In this paper, we present a partial steganography algorithm for 3D triangle mesh. Traditional 3D steganography hides information among the whole mesh and our method random picks some vertices for embedding. The random picking processing works with the pseudorandom number generator (PRNG) and a secret seed for the PRNG. The same random sequence can be disinterred with the same seed so that we can extraction the secret message from the stego model. In experiments, our method is effective against the 3D Steganalysis as best 15.2% reduction in classification accuracy of a supervised classification.	algorithm;experiment;machine learning;pseudorandom number generator;random seed;steganalysis;steganography;supervised learning;triangle mesh	Ran Jiao	2017	2017 International Conference on Machine Learning and Cybernetics (ICMLC)	10.1109/ICMLC.2017.8108948	artificial intelligence;triangle mesh;random sequence;steganography;pattern recognition;computer science;feature extraction;steganalysis;pseudorandom number generator;principal component analysis;solid modeling;algorithm	ML	40.30665201504853	-8.197775567319866	90794
11b7d41d100fe913b79b1d00bb8f129ee6eec503	content personalization in organizations via composing a source content model with user model	user model	An automatic centering method for a video camera having a plurality of pick-up tubes and a deflection control circuit for each of the plurality of pick-up tubes is disclosed, which includes the steps of comparing outputs of two pick-up tubes of the plurality of pick-up tubes to thereby generate an error signal, processing the error signal to thereby generate a control signal, supplying the control signal to the deflection control circuit for one of the two pick-up tubes, storing the control signal in a memory, changing the control signal supplied to the deflection control circuit by a predetermined amount, repeating the above-described first to third steps, comparing the control signal generated in the sixth step and the control signal in the memory with each other to thereby generate an error flag signal when the above two control signals do not coincide with each other and indicating the error flag signal.	personalization	Maryam Tayefeh Mahmoudi;Kambiz Badie;Mahmood Kharrat;Sogol Babazadeh Khamaneh;Mahmood Yadollahi Khales	2008			computer hardware;deflection (engineering);personalization;user modeling;content model;multimedia;computer science;video camera	ECom	46.97841693024827	-4.432412362776458	90892
e97bda27801ebaea52fce7cd21b51d68f5dd87c1	recent advances in active noise control inside automobile cabins: toward quieter cars	automotive engineering;control systems;feedforward neural networks;vibrations;acoustics;automotive engineering acoustics noise measurement control systems vibrations feedforward neural networks smart devices intelligent vehicles;smart devices;noise measurement;intelligent vehicles	In this article, a compact tutorial of ANC techniques was presented with a review of their application in reducing undesired noise inside automobiles. Some of the recent advances have demonstrated significant improvements in the noise reduction levels as well as the cost and implementation complexity. While the aforementioned techniques discussed may individually focus on a particular noise field (e.g., road noise only, engine noise only), it is proven through research and commercial products that a combination of these strategies can deliver significant benefits in realistic conditions.	acoustic fingerprint;binaural beats;bluetooth;computer science;electrical engineering;ethernet hub;instant messaging;loudspeaker;microelectromechanical systems;microphone;noise reduction;pixel;requirement;signal processing;sparse matrix;stack machine;supervised learning;surround sound;system requirements;television;the australian;usb hub	Prasanga N. Samarasinghe;Wen Zhang;Thushara Dheemantha Abhayapala	2016	IEEE Signal Processing Magazine	10.1109/MSP.2016.2601942	telecommunications;noise measurement;control system;electrical engineering;vibration;background noise	EDA	45.248308484755384	-2.2342855819252025	91120
9f1e69a008d0fd055f6309c3abc5f2082eb5bb80	decentralized jointly sparse optimization by reweighted $\ell_{q}$ minimization	minimisation;support consensus;minimization;compressed sensing;decentralized jointly sparse optimization;support vector machines;sensors;convex programming;reweighted l q minimization;jointly sparse optimization;decentralized algorithm;joints;data mining;non convex model;vectors;cognitive radio;joint support estimation;optimization;linear measurements;nonconvex minimization model;distributed human action recognition	A set of vectors (or signals) are jointly sparse if all their nonzero entries are found on a small number of rows (or columns). Consider a network of agents {i} that collaboratively recover a set of jointly sparse vectors {x(i)} from their linear measurements {y(i)}. Assume that every agent i collects its own measurement y(i) and aims to recover its own vector x(i) taking advantages of the joint sparsity structure. This paper proposes novel decentralized algorithms to recover these vectors in a way that every agent runs a recovery algorithm and exchanges with its neighbors only the estimated joint support of the vectors. The agents will obtain their solutions through collaboration while keeping their vectors' values and measurements private. As such, the proposed approach finds applications in distributed human action recognition, cooperative spectrum sensing, decentralized event detection, as well as collaborative data mining. We use a non-convex minimization model and propose algorithms that alternate between support consensus and vector update. The latter step is based on reweighted ℓq iterations, where q can be 1 or 2. We numerically compare the proposed decentralized algorithms with existing centralized and decentralized algorithms. Simulation results demonstrate that the proposed decentralized approaches have strong recovery performance and converge reasonably fast.	algorithm;centralized computing;column (database);compressed sensing;computation;consensus (computer science);converge;convex optimization;data mining;detection theory;existential quantification;image processing;iteration;machine learning;mandelbrot set;mathematical optimization;numerical analysis;semi-continuity;semiconductor industry;simulation;single-instance storage;social inequality;sparse approximation;sparse matrix;stationary process;subderivative;subgradient method	Qing Ling;Zaiwen Wen;Wotao Yin	2013	IEEE Transactions on Signal Processing	10.1109/TSP.2012.2236830	support vector machine;minimisation;mathematical optimization;cognitive radio;convex optimization;computer science;sensor;machine learning;data mining;mathematics;compressed sensing	ML	52.10743879894828	1.8709946058664366	91342
1bfb797e39789b2eb682580facd3ad731280b608	an experimental study of sub-band coder design incorporating recursive quadrature filters and optimum adpcm	nonlinear filters;perceptual quality;finite impulse response filter speech analysis mirrors iir filters phase distortion speech coding acoustic distortion transfer functions tree data structures nonlinear filters;mirrors;acoustic distortion;and forward;transfer functions;speech analysis;finite impulse response filter;speech coding;tree data structures;quadrature mirror filter;phase distortion;transfer function;fir filter;iir filters	This paper presents the results of an analytical and experimental study of the use of IIR quadrature mirror filters and forward adapting ADPCM with optimum quantizers for octave band sub-band coders for speech. It is shown that the underlying analysis-synthesis systems can be designed such that there is no inter-band aliasing distortion in the coded speech and such that the analysis-synthesis transfer function has no frequency distortion or no phase distortion, but not both. The experimental study showed that sub-band coders based on a mixture of IIR and FIR filters resulted in higher quality coding systems using fewer multiplies than for systems based on FIR filters alone. It was also found that a SNR gain of about 4 db could be obtained using optimum quantizers for forward adapting ADPCM coders, but no perceptual quality gain was observed.	adaptive differential pulse-code modulation;experiment;recursion;sub-band coding	Thomas P. Barnwell	1981		10.1109/ICASSP.1981.1171207	computer vision;speech recognition;telecommunications;computer science;finite impulse response;mathematics;transfer function	HCI	48.15571124011259	-9.235157051799693	92224
176eb26eee761da113127e193ca6346ec2db5245	practical evaluation of a data compression algorithm	microprocessors;algorithm data compression algorithm prefix code visual imaging system istp polar satellite feasibility splay tree based compression;image coding;data compression;data compression downlink image coding satellites bandwidth read write memory computer science cities and towns physics microprocessors;trees mathematics;prefix code;satellite links;feasibility;physics;algorithm;imaging system;istp polar satellite;splay tree based compression;downlink;satellites;trees mathematics computerised picture processing data compression geophysical techniques satellite links;data compression algorithm;computerised picture processing;cities and towns;bandwidth;computer science;read write memory;visual imaging system;geophysical techniques	The idea of using splay trees as the basis of a prefix code for data compression was introduced in 1988 [4]. At around the same time, the University of Iowa Physics department began development of the Visual Imaging System for the ISTP POLAR satellite, to be launched in July 1993 [6]. What follows is a report on the feasibility of using splay-tree based compression for image data transmitted from this satellite. In short, we concluded that this algorithm is appropriate for use in this and other similar contexts. The on-board processing resources available to satellite-based systems are significantly limited by a number of factors. For example, a microprocessor may be considered obsolete for use on earth by the time it is available in-low-power, radiation hardened, launch certified form. Additionally, high radiation levels limit the use of dynamic memory technology, and power restrictions further limit the available memory resources. Finally, downlink bandwidths are severely restricted for numerous reasons. The ISTP POLAR Visual Imaging System provides an example of these constraints. At the time this work was done, it was expected that this system would be based on a pair of 80C86 processors clocked at 3.5MHz. Each processor was to have only 64K of private RAM, only a fraction of which would be available for compression. Finally, the downlink bandwidth allocated to the Visual Imaging System is only 11 KBaud. The scientific context of this system places a high value on obtaining sequences of images in quick succession. In this context, transmitting each image as it is collected is not adequate because of the limited downlink capacity. For example, a 256x256 image that is collected in 4 seconds would take 48 seconds to transmit over the downlink. This provides ample motivation for the use of data compression. There are a large number of data compression algorithms [l, 5, 71, but most are unsuited to this application. For example, although the widely used LZW algorithm is quite fast, the memory required to hold a dynamically constructed dictionary of	algorithm;central processing unit;clock rate;data compression;dictionary;lempel–ziv–welch;low-power broadcasting;memory management;microprocessor;on-board data handling;prefix code;radiation hardening;random-access memory;splay tree;succession;telecommunications link;transmitter	Douglas W. Jones	1991		10.1109/DCC.1991.213343	data compression;prefix code;feasibility study;simulation;telecommunications link;telecommunications;computer science;theoretical computer science;mathematics;bandwidth;algorithm;satellite;statistics	ML	44.67564031861561	-3.916715885861265	92319
a00833d093df9de5f4f9ec1ae15c8ae50d78c0e6	a new variant of nonparametric belief propagation for self-localization	distributed algorithms;belief networks;estimation theory;state space methods;nonparametric statistics;belief propagation sampling methods state estimation state space methods military computing coordinate measuring machines distributed algorithms graphical models clustering algorithms distance measurement;nonparametric belief propagation;state estimation;relative self localization;discrete states space;monte carlo integration;distance measurement;graphical models;flipping ambiguity;estimation;delimited space region;belief propagation;nonparametric belief propagation algorithm;probability distribution;state space;clustering algorithms;range measurements;approximation methods;flipping ambiguity relative self localization fixed communicating devices range measurements nonparametric belief propagation algorithm belief estimation monte carlo integration rejection sampling delimited space region rejection ratio discrete states space;probabilistic logic;sampling methods;rejection ratio;coordinate measuring machines;rejection sampling;fixed communicating devices;wireless sensor networks;monte carlo methods;wireless sensor networks belief networks estimation theory monte carlo methods nonparametric statistics state space methods;belief estimation;military computing	We consider the problem of relative self-localization of a network of fixed communicating devices that evaluate range measurements between each other. The solution is obtained in two stages: First, a new variant of the Nonparametric Belief Propagation algorithm is used for estimating the beliefs. This variant is based on a Monte-Carlo integration with rejection sampling where a delimited space region is determined for each node in order to reduce the rejection ratio. Then, a new algorithm based on estimation in discrete states space is proposed for solving the flipping ambiguities resulting from the lack of measurements. This solution has the advantage of reducing the amount of communicating particles and the computation cost.		Hadi Noureddine;Nicolas Gresset;Damien Castelain;Ramesh Pyndiah	2010	2010 17th International Conference on Telecommunications	10.1109/ICTEL.2010.5478820	probability distribution;nonparametric statistics;sampling;distributed algorithm;mathematical optimization;estimation;wireless sensor network;computer science;state space;machine learning;mathematics;rejection sampling;graphical model;probabilistic logic;cluster analysis;estimation theory;monte carlo integration;statistics;belief propagation;monte carlo method	Robotics	53.07162796573703	4.158136874222207	92573
c5cf86da342739fab056ffecfa9d3a23a07620a3	junolo - jülich nonlocal code for parallel post-processing evaluation of vdw-df correlation energy	71 15 mb;energy function;charge density;density functional theory;71 45 gm;density function theory;nonlocal correlation;dft calculation;van der waals interaction;71 15 m;electronic structure;process evaluation	Abstract Nowadays the state of the art Density Functional Theory (DFT) codes are based on local (LDA) or semilocal (GGA) energy functionals. Recently the theory of a truly nonlocal energy functional has been developed. It has been used mostly as a post-DFT calculation approach, i.e. by applying the functional to the charge density calculated using any standard DFT code, thus obtaining a new improved value for the total energy of the system. Nonlocal calculation is computationally quite expensive and scales as N 2 where N is the number of points in which the density is defined, and a massively parallel calculation is welcome for a wider applicability of the new approach. In this article we present a code which accomplishes this goal. Program summary Program title: JuNoLo Catalogue identifier: AEFM_v1_0 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEFM_v1_0.html Program obtainable from: CPC Program Library, Queenu0027s University, Belfast, N. Ireland Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html No. of lines in distributed program, including test data, etc.: 176 980 No. of bytes in distributed program, including test data, etc.: 2 126 072 Distribution format: tar.gz Programming language: Fortran 90 Computer: any architecture with a Fortran 90 compiler Operating system: Linux, AIX Has the code been vectorised or parallelized?: Yes, from 1 to 65536 processors may be used. RAM: depends strongly on the problemu0027s size. Classification: 7.3 External routines: • FFTW ( http://www.tw.org/ ) • MPI ( http://www.mcs.anl.gov/research/projects/mpich2/ or http://www.lam-mpi.org/ ) Nature of problem: Obtaining the value of the nonlocal vdW-DF energy based on the charge density distribution obtained from some Density Functional Theory code. Solution method: Numerical calculation of the double sum is implemented in a parallel F90 code. Calculation of this sum yields the required nonlocal vdW-DF energy. Unusual features: Binds to virtually any DFT program. Additional comments: Excellent parallelization features. Running time: Depends strongly on the size of the problem and the number of CPUs used.	direction finding;nonlocal lagrangian;physics and astronomy classification scheme;video post-processing	Predrag Lazic;Nicolae Atodiresei;Mojtaba Alaei;Vasile Caciuc;Stefan Blügel;Radovan Brako	2010	Computer Physics Communications	10.1016/j.cpc.2009.09.016	computer science;theoretical computer science;mathematics;density functional theory;physics;algorithm;quantum mechanics	AI	42.28467237601948	3.2145181792996596	92662
a7b8ac3601270a3bcb7c6b3a9dfe6e2b26b2cfe8	modal fourier wavefront reconstruction using graphics processing units	wavefronts;degree of freedom;real time;wavefront reconstruction;fast fourier transform;shack hartmann;graphics processing units;fourier transforms;spatial filtering;graphic processing unit;reconstruction algorithm;hardware implementation;adaptive optics	Large degree-of-freedom real-time adaptive optics control requires reconstruction algorithms computationally efficient and readily parallelized for hardware implementation. Lysa Poyneer (2002) has shown that the wave- front reconstruction with the use of the fast Fourier transform (FFT) and spatial filtering is computationally tractable and sufficiently accurate for its use in large Shack-Hartmann-based adaptive optics systems (up to 10,000 actuators). We show here that by use of Graphical Processing Units (GPUs), a specialized hardware capable of performing FFTs on big sequences almost 7 times faster than a high-end CPU, a problem of up to 50,000 actuators can be already done within a 6 ms limit. The method to adapt the FFT in an efficient way for the underlying architecture of GPUs is given. State-of-the-art graphics cards provide consumers with the visual quality of photo-realistic 3D image synthesis, adapted to interactive handling. The computational power required demands processing of the order of millions of vertices and hundreds of millions of pixels per second. Latest generation graphics cards have not only increased by one order of magnitude the computational power of the preceding generation, thereby surpassing performance of CPUs, but they also present an increasingly open programming model. The quantitative leap - in terms of computational power - and the qualitative leap - in terms of processing freedom of the graphics hardware resources - are proving to lead to sustained growth in the sector focusing on leisure use of computers which feeds back into the graphics hardware industry, constantly pushing technology to new heights. So the graphics engine used by the nVidia GeForce 7800 GTX card, launched on the market in the summer 2005, reaches 165 Gflop/s, as opposed to the 12 Gflop/s of a 3 GHz Pentium IV. This power, in a low cost broadly used peripheral, has caught the attention of the scientific community, which has managed to perform general computational tasks using a platform originally designed for specific tasks. Current adaptive optics (AO) systems use vector-matrix-multiply (VMM) reconstructors to convert gradient measurements to wavefront phase estimates. As the number of actuators n increases, the time to compute the reconstruction by means of the VMM method scales as O(n 2 ). The number of actuators involved in AO systems is expected to increase dramatically in the future. In astronomical applications, this is due to both increasing telescope diameters and new higher-resolution applications on existing systems. The increase in size, from hundreds up to tens of thousands of actuators, requires faster methods to complete the adaptive optics correction inside the atmospheric characteristic time (longer in infrared than in visible). Next generation of extremely large telescopes (50 up to 100 meter of diameter) will demand big technological advances to maintain aligned the segments of the telescopes (phasing of segmented mirrors) and then to correct from atmospheric aberrations. Adaptive optics include several steps: detection, wavefront phase recovery, information transmission to the actuators and mechanical movements of them. In order to help on this, a quicker wavefront phase reconstruction seems to be really relevant.	computer graphics;graphics processing unit	José Gil Marichal-Hernández;José Manuel Rodríguez-Ramos;Fernando L. Rosa	2007	J. Electronic Imaging	10.1117/1.2732379	fourier transform;computer vision;fast fourier transform;wavefront;simulation;computer hardware;telecommunications;computer science;machine learning;optics;degrees of freedom;adaptive optics;algorithm;spatial filter;computer graphics (images)	Graphics	44.20434280995022	-3.156405730351903	92708
19af06300995ac3c061262c213b2ed4d3fa110cf	a food intake detection method using intra-body communication	sensors;consumer electronics;receivers;electrodes;transmitters;cameras;conferences	A record of food intake contains information that is useful for health care. We propose a new method for obtaining food intake data using intra-body communication. In this system, a transmitter is attached to each dish, and signals are sent to a receiver via dishes, food, and cutlery; the human body is the medium connecting the transmitter and the receiver. A receiver can detect the moment when the user is in contact with the food by receiving a signal. In this paper, a system overview and the experimental results for signal transmission are presented.	information;parabolic antenna;transmitter	Yuichi Mitsudo	2016	2016 IEEE 5th Global Conference on Consumer Electronics	10.1109/GCCE.2016.7800407	electronic engineering;telecommunications;engineering;electrical engineering	Robotics	45.82431956174113	0.06154127772311979	92988
4f22609cddf01f8f6b20b8837f44f384338c4b67	on reducing computational complexity of codebook search in celp coding	nonlinear filters;technological innovation;code excited linear prediction;speech synthesis;etude theorique;helium;improvement;speech processing;speech analysis and processing computational complexity encoding filtering and prediction theory;performance;search methods;search method;synthetic speech;frequency domain search;bit rate;methode calcul;books;filtering and prediction theory;computational complexity search methods adaptive filters vectors technological innovation nonlinear filters speech processing books bit rate;metodo calculo;calculating method;codificacion;adaptive filters;vectors;codebook search;methode domaine frequence;computational complexity;frequency domain method;amelioration;coding;prediccion lineal;estudio teorico;celp coding;speech analysis and processing;mejoria;sintesis palabra;linear prediction;metodo dominio frecuencia;rendimiento;theoretical study;code vector sparsity;frequency domain;encoding;synthese parole;prediction lineaire;code vector sparsity synthetic speech computational complexity codebook search celp coding code excited linear prediction frequency domain search;codage	A computationally efficient codebook search method in code-excited linear prediction is proposed. The method can reduce the computational complexity by almost one half compared to the frequency-domain codebook search method that is currently regarded as the fastest search method, while giving almost the same quality of speech. This reduction is possible as a result of the simultaneous use of frequency-domain search and code vector sparsity. >	code-excited linear prediction;codebook;computational complexity theory	J. I. Lee;C. K. Un	1990	IEEE Trans. Communications	10.1109/26.61473	adaptive filter;speech recognition;linear prediction;performance;computer science;theoretical computer science;speech processing;mathematics;coding;helium;linde–buzo–gray algorithm;computational complexity theory;speech synthesis;frequency domain;algorithm;encoding;statistics;code-excited linear prediction	Vision	48.89164316926768	-9.67774947656648	93054
aa15ea44fbab0042081464d1e4df4e5b7385beab	an embedded vision system based on an analog vlsi vision sensor [robot vision applications]	vision system;analog vlsi vision sensor;robot sensing systems;sensor systems and applications;image motion analysis;digital post processor;gray scale image data;very large scale integration;real time;optical flow estimation;image sensors;gray scale;embedded vision system;robot vision embedded systems vlsi image sensors;robotic science educational projects;computer architecture;embedded systems;robot vision;smooth optical flow estimation;machine vision;robotic platforms;analog computers;vlsi;analog vlsi;optical flow;optical sensors;robot vision systems;robotic science educational projects embedded vision system analog vlsi vision sensor robot vision programmable miniature vision module digital post processor gray scale image data smooth optical flow estimation image high level processing robotic platforms;programmable miniature vision module;image high level processing;machine vision very large scale integration sensor systems and applications robot sensing systems robot vision systems optical sensors image motion analysis image sensors gray scale analog computers	We present a novel programmable miniature vision module. The module combines an analog VLSI (aVLSI) vision sensor with a digital post-processor (MPC555). The aVLSI sensor provides gray-scale image data as well as smooth optical flow estimates. The particular computational architecture (analog and parallel) of the sensor allows efficient real-time estimation of the smooth optical flow field. The MPC555 controls the sensor read-out and, furthermore, allows for additional higher level processing of the image and optical flow data. It also provides the necessary standard interface such that the module can be easily programmed and integrated into different robotic platforms. The vision module seems particularly suited for educational projects in robotic sciences.	algorithm;computation;embedded system;grayscale;khepera mobile robot;mpc5xx;optical flow;real-time clock;sensor;swarm robotics;systems architecture;very-large-scale integration	Vlatko Becanovic;Stefan Kubina;Alan A. Stocker	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1465200	embedded system;computer vision;simulation;machine vision;computer science;electrical engineering;very-large-scale integration	Robotics	42.09415055624169	-3.2348991021826583	93245
cd8347880b4a611f4a1cb9a67662e14e055218ae	gps aided extended kalman filter based localization for unmanned vehicles	nonlinear filters;application software;kalman filters;remotely operated vehicles global positioning system kalman filters nonlinear filters;global position system;positional errors gps aided extended kalman filter based localization unmanned vehicles gps aided localization system outdoor applications global positioning system measurements navigation systems gps receiver gps signals ekf based localization system matlab;kalman filter;remotely operated vehicles;local system;unmanned vehicles;global positioning system;robots;mathematical model;simulation study;global positioning system robots mathematical model kalman filters application software vehicles;navigation system;vehicles;extended kalman filter	This paper presents design considerations of a GPS-aided localization system for unmanned vehicles used in outdoor applications. The system proposed in this paper is based on Extended Kalman Filter (EKF) and also integrates Global Positioning System (GPS) measurements. Localization and navigation systems are base components of all unmanned vehicles since they give unmanned vehicles the ability of perceiving the environment in order to localize themselves and to navigate to a target. The advantage of the proposed system over a GPS based localization system is that the system works even if the GPS receiver does not receive any GPS signals. In this study, firstly proposed EKF-based localization system is explained, and then how to integrate GPS measurements into this localization system is explained. With simulation studies in MATLAB, the effectiveness of the system is shown. The simulations show that the proposed localization system gives accurate results with negligible positional errors.	extended kalman filter;gps signals;global positioning system;matlab;simulation;unmanned aerial vehicle	Gurkan Tuna;Vehbi Cagri Gungor;Kayhan Gulez	2012	2012 20th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2012.6204515	kalman filter;computer vision;gps/ins;computer science;machine learning;assisted gps;control theory;simultaneous localization and mapping	Robotics	50.54363311691478	0.8053601333337642	93481
8c43db7d0284f79e2c1ebe0b7ef60a1f1753e943	postfiltering for suppression of residual echo from vocoder distortion in packet-based telephony	frequency dependence;data compression;acoustic distortion;frequency dependent scaling factor;frequency estimation;psychoacoustic postfilter;speech;speech coding;spectrum;packet switching;psychology;residual echo suppression;power spectrum;internet telephony;telephony;acoustic filters;vocoders acoustic filters data compression distortion echo suppression filtering theory packet switching speech coding telephony;nonlinear distortion;distortion;signal lpc spectrum;vocoders nonlinear distortion echo cancellers speech acoustic distortion psychology psychoacoustic models frequency estimation internet telephony intelligent networks;vocoders;mean opinion score;itu g 729;echo suppression;intelligent networks;psychoacoustic models;psychoacoustic postfilter residual echo suppression speech compression packet based telephony vocoder distortion itu g 729 signal lpc spectrum frequency dependent scaling factor;echo cancellers;speech compression;filtering theory;packet based telephony;vocoder distortion	This paper investigates postfiltering for residual echo suppression in networks employing low-bit-rate speech compression in the echo path. Simulations show that the residual echo from nonlinear vocoder distortion with ITU G.729 is proportional to the input signal LPC spectrum. An algorithm is proposed to estimate the residual echo power spectrum using a frequency-dependent scaling factor. The algorithm is incorporated into a psychoacoustic postfilter for residual echo suppression and compared to an existing estimator with a fixed scaling factor. Experiments with speech input and near-end signals show an average 0.85 dB lower spectral distortion and 0.4 higher estimated mean opinion score	algorithm;distortion;echo suppression and cancellation;experiment;g.729;image scaling;lpc;nonlinear system;psychoacoustics;spectral density;speech coding;vocoder;zero suppression	James D. Gordy;Rafik A. Goubran	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262940	data compression;mean opinion score;spectrum;intelligent network;nonlinear distortion;speech recognition;distortion;telecommunications;computer science;speech;speech coding;telephony;spectral density;packet switching	Robotics	48.79800910501068	-8.019764010686263	94093
ac0fff2466a734ecedccf8d4452cbea8c62756c8	towards a new e-model impairment factor for linear distortion of narrowband and wideband speech transmission	linear systems;narrowband speech transmission;voice communication speech codecs speech coding;e model impairment factor;error reduction;codecs;network planning;error reduction e model impairment factor linear distortion narrowband speech transmission wideband speech transmission network planning channel filtering codecs user interfaces equipment impairment factors transmission systems;user interface;nonlinear distortion modeling speech codecs linear systems nonlinear systems;speech coding;linear system;wideband speech transmission;nonlinear distortion;nonlinear systems;transmission systems;speech codecs;channel filtering;voice communication;linear distortion;nonlinear system;modeling;user interfaces;equipment impairment factors;narrowband wideband speech codecs nonlinear distortion bandwidth nonlinear filters filtering user interfaces instruments delay estimation	The e-model, a tool for network planning recommended by the ITU-T, suffers from the lack of predicting linear distortions as they may occur from channel filtering, codecs, and user interfaces. In order to face this deficiency, a new impairment factor is introduced in this paper which is estimated on the basis of two simple parameters from the linear portion of a system. Therewith, conventional Equipment Impairment Factors of narrowband and wideband speech codecs are decomposed into a linear and a residual part, allowing to quantify both magnitudes separately on the so-called R-scale. By extending the concept of distortion classes in the e-model, the proposed scheme provides a plausible picture of the linear effect of transmission systems. The advantage of wideband causing a 36% quality gain is well reflected. Further, the decomposition leads to a reduction of error when impairment factors are added on the R-scale. Examples for instrumentally estimating the residual impairment are given.	angular defect;codec;distortion;speech coding;user interface	Marcel Wältermann;Alexander Raake	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4518735	speech recognition;telecommunications;nonlinear system;computer science;linear system;user interface	Vision	49.325509431528744	-7.643375743602774	94267
9e02dd11ca92770d1a6143be2a3da7e7679102ee	convolutional filtering for accurate signal timing from noisy streaming data		Our society depends heavily on the electric power infrastructure. To ensure its reliability, key power grid components such as transformers are extensively monitored for signs of failures and errors. This work concentrates on a type of event known as the partial discharge (PD) because it is the symptom of insulation weakness, the most common cause of transformer failures. More specifically, our work is to locate the position of a partial discharge to provide information for preventive maintenance. Our method utilizes the information from a set of ultra-high frequency (UHF) sensors inside the transformer, and proceeds in two steps: first determine the signal arrival time and then locate the position based on time differences. To determine the arrival time, we develop a convolutional filtering method based on the Savitzky-Golay filter. To provide accurate locations, we simulate the electromagnetic wave propagation using finite-difference time-domain (FDTD) to generate a reference table of the travel time from each FDTD mesh point to the sensors. We exercise our method using two sets of UHF measurements with different signal to noise ratios. In both cases, our method provides more accurate locations than other methods. The difference is particularly prominent when the signal is weak. With weak signals, the best existing method, the cumulative energy method, was only able to predict the PD location within 300 mm of the known sources in 13% of the test cases, while our method is correct in 48% of the test cases.	discharger;finite-difference time-domain method;lookup table;multilateration;sensor;signal-to-noise ratio;simulation;software propagation;stream (computing);suicidegirls;test case;time of arrival;transformer;transformers;ultra high frequency	Jonathan Wang;Kesheng Wu;Alex Sim;Seongwook Hwangbo	2017	2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC-PICom-DataCom-CyberSciTec.2017.157	real-time computing;partial discharge;grid;signal timing;filter (signal processing);test case;finite-difference time-domain method;ultra high frequency;signal-to-noise ratio;computer science	EDA	43.853649153167474	-0.8981641486330679	94512
081c5abecec20fa5c7d65594985a01e2ee749423	a quasi-reversibility regularization method for the cauchy problem of the helmholtz equation	convergence estimates;regularization method;exact solution;quasi reversibility regularization method;difference scheme;35r30;ill posed problem;65j22;helmholtz equation;cauchy problem	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.		H. W. Zhang;H. H. Qin;T. Wei	2011	Int. J. Comput. Math.	10.1080/00207160.2010.482986	backus–gilbert method;cauchy problem;mathematical optimization;mathematical analysis;cauchy condensation test;calculus;cauchy's convergence test;mathematics;helmholtz equation;quantum mechanics	Robotics	49.54038730935724	-2.9543452837352953	94846
01af8f1dedf43a35106f23e1c2f3415bb28ab13b	robust estimation fusion in wireless senor networks with outliers and correlated noises		This paper addresses the problem of estimation fusion in a distributed wireless sensor network (WSN) under the following conditions: (i) sensor noises are contaminated by outliers or gross errors; (ii) process noise and sensor noises are correlated; (iii) cross-correlation among local estimates is unknown. First, to attack the correlation and outliers, a correlated robust Kalman filtering (coR2KF) scheme with weighted matrices on innovation sequences is introduced as local estimator. It is shown that the proposed coR2KF takes both conventional Kalman filter and robust Kalman filter as a special case. Then, a novel version of our internal ellipsoid approximation fusion (IEAF) is used in the fusion center to handle the unknown cross-correlation of local estimates. The explicit solution to both fusion estimate and corresponding covariance is given. Finally, to demonstrate robustness of the proposed coR2KF and the effectiveness of IEAF strategy, a simulation example of tracking a target moving on noisy circular trajectories is included.		Yan Zhou;Dongli Wang;Tingrui Pei;Shujuan Tian	2014	IJDSN	10.1155/2014/393802	wireless sensor network;robustness (computer science);estimator;kalman filter;outlier;matrix (mathematics);special case;distributed computing;computer science;artificial intelligence;covariance;pattern recognition	Robotics	53.4979184941246	3.3092175448157493	95206
825dfc55f28c4cb86b459a534a6df59fbdf41382	reversible audio data hiding algorithm using noncausal prediction of alterable orders	signal image and speech processing;acoustics;mathematics in music;engineering acoustics	This paper presents a reversible data hiding scheme for digital audio by using noncausal prediction of alterable orders. Firstly, the samples in a host signal are divided into the cross and the dot sets. Then, each sample in a set is estimated by using the past P samples and the future Q samples as prediction context. The order P + Q and the prediction coefficients are computed by referring to the minimum error power method. With the proposed predictor, the prediction errors can be efficiently reduced for different types of audio files. Comparing with the existing several state-of-the-art schemes, the proposed prediction model with expansion embedding technique introduces less embedding distortion for the same embedding capacity. The experiments on the standard audio files verify the effectiveness of the proposed method.	algorithm;coefficient;distortion;experiment;kerrison predictor;power iteration	Shijun Xiang;Zihao Li	2017	EURASIP J. Audio, Speech and Music Processing	10.1186/s13636-017-0101-9	information hiding;artificial intelligence;theoretical computer science;speech recognition;digital audio;pattern recognition;computer science;distortion;power iteration;embedding;algorithm	AI	45.613558636592764	-9.025140853178113	95477
4943b611dc5ab0caed96158fa9cdaf359b5d9e87	entangled monte carlo		We propose a novel method for scalable parallelization of SMC algorithms, Entangled Monte Carlo simulation (EMC). EMC avoids the transmission of particles between nodes, and instead reconstructs them from the particle genealogy. In particular, we show that we can reduce the communication to the particle weights for each machine while efficiently maintaining implicit global coherence of the parallel simulation. We explain methods to efficiently maintain a genealogy of particles from which any particle can be reconstructed. We demonstrate using examples from Bayesian phylogenetic that the computational gain from parallelization using EMC significantly outweighs the cost of particle reconstruction. The timing experiments show that reconstruction of particles is indeed much more efficient as compared to transmission of particles.	algorithm;bayesian network;experiment;fabian pascal;monte carlo method;parallel computing;phylogenetics;scalability;simulation	Seong-Hwan Jun;Liangliang Wang;Alexandre Bouchard-Côté	2012			simulation;theoretical computer science;distributed computing	ML	42.17398610114498	1.3875689049849926	95604
3c88d9dad08ffe0de5424d530b1b54dbfc54b055	a novel audio watermarking technique based on low frequency components	watermarking;low frequency;watermarking frequency humans robustness distortion computer science signal processing ear internet intellectual property;watermark removal audio watermarking low frequency components audio signal;selective sampling;recovery rate;audio coding;watermarking audio coding;audio watermarking	In this paper, we present a novel audio watermarking technique that utilizes the low frequency components (LFCs) of an audio signal to identify the location of the embedded watermarks. The embedding takes place by modifying the amplitude of selected samples determined by the LFCs of the audio signal. The amount of modification to the amplitude is determined by the amount of distortion detected by the human ear. This technique is blind where the decoder does not need the original audio file to extract the watermarks. In this technique, we use a novel data recovery scheme to recover any watermarks that were lost because of an intentional or unintentional attempt of watermark removal (attack). Experimental results show that this technique is highly robust against single and double attacks with watermark recovery rates greater than 90%.	codec;data recovery;digital watermarking;distortion;embedded system	Hamad Alaryani;Abdou Youssef	2005	Seventh IEEE International Symposium on Multimedia (ISM'05)	10.1109/ISM.2005.16	speech recognition;telecommunications;digital watermarking;computer science;speech coding;multimedia;low frequency;watermark	EDA	42.39171913873958	-9.200485506587544	96884
0726a67943b5638cdfec2514ea7dc7064ebd261a	diffusion-based em algorithm for distributed estimation of gaussian mixtures in wireless sensor networks	consensus;computer communication networks;normal distribution;distributed processing;electromagnetic fields;equipment design;stochastic processes;likelihood functions;reproducibility of results;models statistical;algorithms;wireless technology;em algorithm;diffusion;wireless sensor networks	Distributed estimation of Gaussian mixtures has many applications in wireless sensor network (WSN), and its energy-efficient solution is still challenging. This paper presents a novel diffusion-based EM algorithm for this problem. A diffusion strategy is introduced for acquiring the global statistics in EM algorithm in which each sensor node only needs to communicate its local statistics to its neighboring nodes at each iteration. This improves the existing consensus-based distributed EM algorithm which may need much more communication overhead for consensus, especially in large scale networks. The robustness and scalability of the proposed approach can be achieved by distributed processing in the networks. In addition, we show that the proposed approach can be considered as a stochastic approximation method to find the maximum likelihood estimation for Gaussian mixtures. Simulation results show the efficiency of this approach.	approximation algorithm;connectivity (graph theory);diffusion;expectation–maximization algorithm;frontotemporal dementia, chromosome 3-linked;iteration;maximum likelihood estimation;natural science disciplines;neural network simulation;node - plant part;normal statistical distribution;overhead (computing);population parameter;scalability;sensor node;stochastic approximation;telecommunications network;mixture	Yang Weng;Wendong Xiao;Lihua Xie	2011		10.3390/s110606297	normal distribution;stochastic process;distributed algorithm;mathematical optimization;wireless sensor network;consensus;electromagnetic field;expectation–maximization algorithm;computer science;theoretical computer science;machine learning;brooks–iyengar algorithm;diffusion;key distribution in wireless sensor networks;physics;statistics	ML	53.20761434877094	3.807607148582041	97026
1aa742bab48fe60b70ad489e9c0557ffe37d690e	robust online music identification using spectral entropy in the compressed domain	audio identification;fragment retrieval;会议论文;music audio coding echo entropy equalisers internet of things;internet of things;compressed domain;mdct spectral entropy;fragment retrieval audio identification internet of things compressed domain mdct spectral entropy robustness;proceedings paper;time frequency audio signal distortions robust online music identification spectral entropy compressed domain audio identification audio format compressed format audio mp3 music mdct coefficients audio fingerprinting audio features recompression noise interference echo addition equalization band pass filtering pitch shifting time scale modification internet of things iot;robustness;fingerprint recognition entropy bit error rate robustness digital audio players databases distortion	Audio identification has been an active research field with wide applications for years. However, most of previously reported methods work on the raw audio format in spite of the fact that nowadays compressed format audio, especially MP3 music, has grown into the dominant way to transmit on the Internet. So far, most of the previous methods take advantage of MDCT coefficients or derived energy type of features. As a first attempt, in this paper we propose a novel audio fingerprinting algorithm utilizing compressed-domain spectral entropy as audio features. Such fingerprint exhibits strong robustness against various audio signal distortions such as recompression, noise interference, echo addition, equalization, band-pass filtering, pitch shifting, and moderate time-scale modification etc. In addition, the algorithm for compressed-domain can be applied in Internet of Things (IoT). Experimental results show that in our test database which is composed of 9823 popular songs, a 5s music clip is able to transmit in IoT and identify its original recording, with more than 90% top five precision rate even under the above severe time-frequency audio signal distortions.	acoustic fingerprint;algorithm;coefficient;distortion;fingerprint (computing);interference (communication);internet of things;mp3;modified discrete cosine transform;online music store;pitch shift	Changqing Yin;Wei Li;Yuanqing Luo;Li-Chuan Tseng	2014	2014 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)	10.1109/WCNCW.2014.6934873	speech recognition;digital audio;audio signal processing;computer science;audio bit depth;speech coding;sound quality;multimedia;audio signal flow;internet of things;robustness	Web+IR	43.64398884392571	-8.678640359386323	97042
3a7b69186074a93047ebcb344c55fd0d74d3dba5	ibar: interacting boson model calculations for large system sizes	reduced matrix elements;nuclear structure;interacting boson model;quantum phase transitions	Scaling the system size of the interacting boson model-1 (IBM-1) into the realm of hundreds of bosons has many interesting applications in the field of nuclear structure, most notably quantum phase transitions in nuclei. We introduce IBAR, a new software package for calculating the eigenvalues and eigenvectors of the IBM-1 Hamiltonian, for large numbers of bosons. Energies and wavefunctions of the nuclear states, as well as transition strengths between them, are calculated using these values. Numerical errors in the recursive calculation of reduced matrix elements of the d-boson creation operator are reduced by using an arbitrary precision mathematical library. This software has been tested for up to 1000 bosons using comparisons to analytic expressions. Comparisons have also been made to the code PHINT for smaller system sizes.#R##N#Program summary#R##N#Program title: IBAR#R##N##R##N#Catalogue identifier: AELI_v1_0#R##N##R##N#Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AELI_v1_0.html#R##N##R##N#Program obtainable from: CPC Program Library, Queenʼs University, Belfast, N. Ireland#R##N##R##N#Licensing provisions: GNU General Public License version 3#R##N##R##N#No. of lines in distributed program, including test data, etc.: 28 734#R##N##R##N#No. of bytes in distributed program, including test data, etc.: 4 104 467#R##N##R##N#Distribution format: tar.gz#R##N##R##N#Programming language: C++#R##N##R##N#Computer: Any computer system with a C++ compiler#R##N##R##N#Operating system: Tested under Linux#R##N##R##N#RAM:   150 MB for 1000 boson calculations with angular momenta of up to L=4L=4#R##N##R##N#Classification: 17.18, 17.20#R##N##R##N#External routines: ARPACK (http://www.caam.rice.edu/software/ARPACK/)#R##N##R##N#Nature of problem: Construction and diagonalization of large Hamiltonian matrices, using reduced matrix elements of the d-boson creation operator.#R##N##R##N#Solution method: Reduced matrix elements of the d-boson creation operator have been stored in data files at machine precision, after being recursively calculated with higher than machine precision. The Hamiltonian matrix is calculated and diagonalized, and the requested transition strengths are calculated using the eigenvectors.#R##N##R##N#Restrictions:   The 1000 boson coefficients for L=0L=0 and L=20L=20 have been included in the IBAR distribution and the 7.3 GB of data that make up the remaining coefficients for L=21L=21 to L=2000L=2000 are available upon request.#R##N##R##N#Running time: If the provided example is changed to include 100 bosons, the calculation requires about 1 second of run time. For 1000 bosons, the calculation requires about 9 minutes of run time.		R. J. Casperson	2012	Computer Physics Communications	10.1016/j.cpc.2011.12.024	nuclear structure;quantum phase transition;interacting boson model;computer science;theoretical computer science;mathematics;physics;algorithm;quantum mechanics	ML	42.33941325794764	3.033546380965009	97391
5fe7692204cac5f8071ef51888311e4572d842e2	on in-service perceptual speech quality monitoring in cellular radio systems	universal mobile telecommunication system;speech signal;radio resource management;codecs;decoding;monitoring land mobile radio cellular systems speech codecs speech analysis testing quality of service australia bit error rate psychology quality assessment;bit error rate;cellular radio;root mean square error;speech analysis;quality of service in service perceptual speech quality monitoring cellular radio systems speech signal feedback signal universal mobile telecommunication system speech coding root mean squared error mean opinion score rating scheme;speech;speech coding;perceptual evaluation of speech quality;testing;psychology;satisfiability;speech coding 3g mobile communication cellular radio mean square error methods quality of service;distortion;cellular radio systems;quality assessment;3g mobile communication;monitoring;speech codecs;root mean squared error;mean opinion score;mean square error methods;land mobile radio cellular systems;mean opinion score rating scheme;quality of service;in service perceptual speech quality monitoring;telekommunikation;australia;feedback signal;telecommunications	A method for in-service monitoring of the end-user perceptual speech quality in cellular radio systems is proposed. This method incorporates the perceptual evaluation of speech quality (PESQ) algorithm to monitor the quality experienced by the end-user. Here, the monitoring is carried out at the transmitting side. In this case, the speech signal received by the end-user is estimated at the transmitter in accordance with a feedback signal. The performance of the proposed scheme has been investigated through extensive simulations for the Universal Mobile Telecommunication System (UMTS) using different speech coding rates and channel conditions. The results indicate that the proposed scheme can predict end-user quality with a root-mean-squared error (RMSE) of at most 0.15 using the mean opinion score (MOS) rating scheme. Such accuracy can be beneficial in applications such as radio resource management for satisfying the desired level of quality of service.	algorithm;feedback;mean squared error;mobile phone;pesq;quality of service;radio resource management;simulation;speech coding;transmitter	Behrooz Rohani;Bijan Rohani;Manora Caldera;Hans-Jürgen Zepernick	2009	2009 Wireless Telecommunications Symposium	10.1109/WTS.2009.5068971	voice activity detection;speech recognition;telecommunications;computer science;communication	Mobile	49.02576626124909	-7.281061409508377	97633
7d10ffa86fd939f6e01e3db29ec381cd226c451c	melp: the new federal standard at 2400 bps	band pass filters standards development code standards instruments linear predictive coding testing communication standards military standards signal processing algorithms matched filters;melp coder;instruments;federal standard;band pass filters;lpc model;speech processing;traitement parole;speech coding;testing;code standards;usa department of defense;linear predictive;tratamiento numerico;telecommunication standards linear predictive coding vocoders speech coding code standards;linear predictive coding;standards development;senal voceada;telecommunication standards;vocoders;military standards;communication standards;prediccion lineal;signal voise;2 4 kbit s;matched filters;voiced signal;digital processing;linear prediction;2 4 kbit s speech coder melp coder federal standard usa department of defense mixed excitation linear prediction digital voice processing consortium lpc model;signal processing algorithms;encoding;speech coder;traitement numerique;digital voice processing consortium;mixed excitation linear prediction;prediction lineaire;codage	(75) Inventor: Seishi Sasaki, Yokosuka (JP) “Analog to Digital Conversion of Voice by 2,400 Bit/Second Mixed Excitation Linear Prediction” May 28, 1998 Draft; (73) Assignee: YRPAdvanced Mobile pp., 1-35. Communication Systems Research 66 Laboratories Co., Ltd., Kanagawa-Ken Analog tO Digital Conversion of Voice by 2,400 Bit/Second (JP) Linear Predictive Coding”; Federal Standard 1015; Nov. 28, 1984; pp., 1-8. (*) Notice: Subject to any disclaimer, the term of this patent is extended or adjusted under 35 * cited by examiner U.S.C. 154(b) by 0 days.	8-bit;approximation;bitstream;code word;code-excited linear prediction;codebook;coefficient;error detection and correction;euclidean distance;forward error correction;hash table;lsf;mixed-excitation linear prediction;quantization (signal processing);requirement;sorting;user requirements document	Lynn M. Supplee;Ronald P. Cohn;John S. Collura;Alan McCree	1997		10.1109/ICASSP.1997.596257	linear predictive coding;speech recognition;linear prediction;telecommunications;computer science;speech coding;speech processing;band-pass filter;software testing;matched filter;encoding	Crypto	47.95178718595366	-7.975982571727309	98014
75b1923cbc76362547ec286ea6a845f67ade3b59	audio watermarking by time-scale modification	perceptual quality;time scale;watermarking signal processing algorithms low pass filters quantization spline filtering algorithms robustness signal processing wavelet transforms copyright protection;lossy compression;copy protection;low pass filter;adaptive quantization steps audio watermarking time scale modification data embedding audio processing operations mp3 lossy compression low pass filtering perceptual quality copyright protection signal salient point intervals nonorthogonal wavelet extrema digital media;quantisation signal;audio coding;quantisation signal copy protection audio coding;audio watermarking	A new algorithm for audio watermarking is proposed. The basic idea of the algorithm is to change the length of the intervals between salient points of the audio signal to embed data. We propose several novel ideas for practical implementations that can be used by other watermarking schemes as well. The algorithm is robust to common audio processing operations e.g. mp3 lossy compression, low pass filtering, and time-scale modification. The watermarked signal has very high perceptual quality and is indistinguishable from the original signal.	algorithm;coefficient;digital watermarking;embedded system;image scaling;lossy compression;mp3;quantization (signal processing);thresholding (image processing);vertical blanking interval;wavelet	Mohamed F. Mansour;Ahmed H. Tewfik	2001		10.1109/ICASSP.2001.941179	data compression;lossy compression;computer vision;speech recognition;low-pass filter;audio signal processing;digital watermarking;computer science;theoretical computer science;audio bit depth;digital signal processing;speech coding;sound quality;mathematics;statistics	ML	43.45273065888527	-8.90009034683354	98348
07d51c56e916d0fc26dc7e08f30eb81e71e45389	adaptive step ode algorithms for the 3d simulation of electric heart activity with graphics processing units	gpu computing;articulo;embedded runge kutta methods;cardiac electrophysiology;rush larsen method;adaptive ode solvers	In this paper we studied the implementation and performance of adaptive step methods for large systems of ordinary differential equations systems in graphics processing units, focusing on the simulation of three-dimensional electric cardiac activity. The Rush-Larsen method was applied in all the implemented solvers to improve efficiency. We compared the adaptive methods with the fixed step methods, and we found that the fixed step methods can be faster while the adaptive step methods are better in terms of accuracy and robustness.	algorithm;audio feedback;computer graphics;graphics processing unit;simulation	Víctor M. García;Alejandro Liberos;Antonio M. Vidal;María de la Salud Guillem;José Millet-Roig;Alberto González;Francisco-Jose Martínez-Zaldívar;Andreu M. Climent	2014	Computers in biology and medicine	10.1016/j.compbiomed.2013.10.023	computational science;mathematical optimization;computer science;theoretical computer science;cardiac electrophysiology;general-purpose computing on graphics processing units	Graphics	45.99688051769825	3.877707228164679	99119
8db104aa6259c02f5fec4d49e47e3a51e4d5ad54	a systematic method for configuring vlsi networks of spiking neurons	temporal dynamics;very large scale integrated;chip;spike timing;spiking neurons;general methods;mathematical model;winner take all;neural network	An increasing number of research groups are developing custom hybrid analog/digital very large scale integration (VLSI) chips and systems that implement hundreds to thousands of spiking neurons with biophysically realistic dynamics, with the intention of emulating brainlike real-world behavior in hardware and robotic systems rather than simply simulating their performance on general-purpose digital computers. Although the electronic engineering aspects of these emulation systems is proceeding well, progress toward the actual emulation of brainlike tasks is restricted by the lack of suitable high-level configuration methods of the kind that have already been developed over many decades for simulations on general-purpose computers. The key difficulty is that the dynamics of the CMOS electronic analogs are determined by transistor biases that do not map simply to the parameter types and values used in typical abstract mathematical models of neurons and their networks. Here we provide a general method for resolving this difficulty. We describe a parameter mapping technique that permits an automatic configuration of VLSI neural networks so that their electronic emulation conforms to a higher-level neuronal simulation. We show that the neurons configured by our method exhibit spike timing statistics and temporal dynamics that are the same as those observed in the software simulated neurons and, in particular, that the key parameters of recurrent VLSI neural networks (e.g., implementing soft winner-take-all) can be precisely tuned. The proposed method permits a seamless integration between software simulations with hardware emulations and intertranslatability between the parameters of abstract neuronal models and their emulation counterparts. Most important, our method offers a route toward a high-level task configuration language for neuromorphic VLSI systems.	analog;artificial neural network;cmos;computer;computers;electronic engineering;emulator;general-purpose markup language;general-purpose modeling;high- and low-level;integrated circuit;license;mathematical model;mathematics;neural network simulation;neuromorphic engineering;neuron;population parameter;robot;seamless3d;transistor;very-large-scale integration	Emre Neftci;Elisabetta Chicca;Giacomo Indiveri;Rodney J. Douglas	2011	Neural Computation	10.1162/NECO_a_00182	chip;winner-take-all;simulation;computer science;theoretical computer science;machine learning;mathematical model;mathematics;artificial neural network	ML	40.021551672193226	-1.3880985717345358	99388
c4903cee2e9650cc8b87d3a94f38335f97aaf6a4	histogram based particle filtering with online adaptation for indoor tracking in wlans	indoor tracking;online adaptation;particle filtering;received signal strength (rss);wireless local area network (wlan)	Indoor localization using signal strength in Wireless Local Area Networks is becoming increasingly prevalent in today’s pervasive computing applications. In this paper, we propose an indoor tracking algorithm under the Bayesian filtering and machine learning framework. The main idea is to apply a graph-based particle filter to track a person’s location on an indoor floor map, and to utilize the machine learning method to approximate the likelihood of an observation at various locations based on the calibration data. Histograms are used to approximate the RSS distributions at the survey points, and Nadaraya–Watson kernel regression is adopted to recover the distributions at non-survey points only from the nearby locations. In addition, we also propose a simple algorithm to continuously update the radio map with the online measurements. A series of experiments are carried out in an office environment. Results show that the proposed Histogram Based Particle Filtering (HBPF)/HBPF with Online Adaptation achieves superior performance than other existing algorithms while retaining low computational complexity.	algorithmic efficiency;approximation algorithm;computational complexity theory;experiment;interpolation;kernel method;logical possibility;lookup table;machine learning;markov chain;missing data;nonlinear system;particle filter;rss;scalability;software deployment;testbed;time complexity;ubiquitous computing	Victoria Ying Zhang;Albert Kai-Sun Wong;Kam Tim Woo	2012	IJWIN	10.1007/s10776-012-0173-5	simulation;machine learning;data mining	AI	51.99647398945568	0.7670776980401545	99533
00da5b4ee3a0570d01d872cc7ed9e0c805d20e94	pollutant's dispersion in the atmosphere. parallel models and applications		The following article contains information about modeling of pollutants dispersion systems in the atmosphere. It also describes main types of pollutants, emission points and analysis of typical atmosphere pollutant dispersion models. It shows a way of using computer cluster systems in modeling process and proper programming libraries for parallel computing. Finally it presents a possibility of environment’s protection method during the emission points’ location planning with calculation of minimal destructive influence on a specified area (for example with definite restrictions of air pollution level). Keywords—parallel computing; distributed computing; computer cluster; atmosphere; pollutant dispersion models; infrastructure expansion planning, MPI.	central processing unit;clustered file system;computation;computer cluster;degree of parallelism;distributed computing;lambert's cosine law;library (computing);mathematical optimization;message passing interface;optimization problem;parallel computing;sensitivity and specificity;tree accumulation	Marcin Majer;Michal Podpora	2014		10.15439/2014F247	simulation;atmospheric dispersion modeling	HPC	45.188820038083314	2.1880730803029125	99846
136bb1849cfd4fa2d95d32f818705cedbf006210	localization in wireless sensor networks with range measurement errors	multi lateration;adapted multilateration method;propagation losses;complexity theory;measurement error;wireless sensor networks iterative methods measurement errors radio direction finding;distance measure;time complexity;probability density function;noisy measurements;data collection;localization;working environment noise;radio direction finding;linear least square;aml method;data mining;sensor network;wireless sensor network;iterative methods;distance measurement;iterative localization method wireless sensor network range measurement error aml method adapted multilateration method;range measurement error;estimation;monitoring;global positioning system;sensor networks;wireless sensor networks measurement errors intelligent sensors global positioning system costs working environment noise equations monitoring target tracking propagation losses;mathematical model;noisy measurements localization sensor networks multi lateration;sensor nodes;iterative localization method;target tracking;wireless sensor networks;intelligent sensors;measurement errors;environmental factor	In sensor networks, data collected by sensor nodes needs to be tagged with time and location information. Localization techniques are used to determine the location information by estimating location of a sensor node. It is well known that distance measurement errors affect the accuracy of estimated location. These errors may be due to methodical or environmental factors. In this paper, we propose AML (Adapted Multi-Lateration) by improving the existing multi-lateration technique. It is shown that the AML method is more robust to measurement errors; its mean localization error is lower than the multi-lateration technique for noisy measurements. Besides, the time complexity of the AML method is less than the multi-lateration technique since it does not require to solve the normal equation for the linear least squares problem as in the multi-lateration technique. Additionally, AML is advantageous for iterative localization where localized nodes become reference nodes and employed in the localization process. Incorporating these reference nodes in the AML equations is easier than multi-lateration technique.	iterative method;linear least squares (mathematics);multilateration;ordinary least squares;sensor node;time complexity	Gulnur Selda Kuruoglu;Melike Erol-Kantarci;Sema F. Oktug	2009	2009 Fifth Advanced International Conference on Telecommunications	10.1109/AICT.2009.51	electronic engineering;wireless sensor network;telecommunications;computer science;data mining;statistics	Mobile	52.131742786663764	4.095494226151148	100422
bf6d4867204d589b816a3dd478816fb41a7c814c	an information theoretic approach to digital image watermarking	singular value;digital image;digital watermark;digital watermarking;least square;multimedia;singular value decomposition;algorithms;digital imaging;wireless communications	With the rapid development of wireless communication systems, transmission of digital multimedia has become widely spread. This brings with itself the issue of copyright protection for digital work. Digital watermarking is the process of embedding data inside a host image such that it does not degrade the perceptual quality of the image. In recent years, there have been many approaches to introduce different watermarking algorithms for the purposes of copyright protection, broadcast monitoring and covert communication. In this paper, a new transform based watermarking algorithm for digital images is introduced. This method uses the Singular Value Decomposition to obtain the eigenimages of a given image which are known to be the best orthogonal basis that can express that image in a least squares sense. The watermark is embedded by changing the strength of the singular values. The strength of the watermark is determined based on the entropy of the eigenimages to ensure robustness and imperceptibility at the simultaneously. A corresponding watermark detection and extraction algorithm is proposed. The performance of the algorithm under different types of attacks that a digital image can go through during transmission is illustrated through an example.	digital image;digital watermarking;information theory	Selin Aviyente	2003			data processing;telecommunications;information theory;digital watermarking;computer science;digital image processing;watermark;least squares;computer security;algorithm;statistics	Vision	40.06740308386164	-9.709018137170823	100605
82faa599772da93d7f606f529dade2810fbdf11d	time-frequency characterisation for electric load monitoring	energy consumption;feature extraction;power engineering computing;space heating;time-frequency analysis;unsupervised learning;france;electric load monitoring;energy monitoring;frequent itemsets extraction;global active power;household appliance;pseudo-periodic signals;space-heating schedule;space-heating signature;time-frequency characterisation;time-frequency detector;time-frequency domain;unsupervised algorithm	Electric utilities and consumers are increasingly interested in energy monitoring for economic and environmental reasons. A non-intrusive solution may rely on information extracted from the electric consumption measured at a centralized part of a distribution network. The problem at hands consists in the separation of the electric load into its major components. This problem of source separation from one sensor is quite tractable under certain conditions. In this work, the focus is made on the most consuming household appliance in France: the space-heating. It is a sum of an unknown number of pseudo-periodic signals embedded in the global active power. An unsupervised algorithm to determine the space-heating schedule from the global consumption based on the interpretation of the space-heating signature in the time-frequency domain is proposed. The proposed method conjoins a time-frequency detector and a frequent itemsets extraction. First results on real data are quite satisfying.	algorithm;centralized computing;cobham's thesis;electrical load;embedded system;performance;real life;relevance;software appliance;source separation;spectrogram;stationary process;statistical model;time–frequency analysis;time–frequency representation	Mabrouka El-Guedri;Guy D'Urso;Christian Lajaunie;Gilles Fleury	2009	2009 17th European Signal Processing Conference		real-time computing;engineering;machine learning;data mining	EDA	43.62802690795953	-0.4411264519758362	100609
09aa32a9b1c61db0cf98e415632aa79aa7be5de3	image-adaptive watermarking using 2d chirps	digital watermarking;frequency modulated function;chirp;digital watermark;time frequency;key exchange;frequency modulated;attack;image watermarking;compression	Linear chirps, a special case of polynomial phase exponentials, have recently been proposed for digital watermarking. In this work, we propose a known-host-state methodology for designing image watermarks that are robust to compression. We use a two-dimensional frequencymodulated chirp as a spreading function in a block-based spatial watermarking scheme. In each block, the chirp is used to embed binary phase information. Chirp parameters allow for spectral shaping of the watermark to match host content. Since host state is known to the embedder, it is possible to tune the chirp for optimum performance, particularly against compression. In contrast to existing chirp watermarking where only a single watermark is generally embedded, the proposed block chirp watermarking allows for a much higher payload. Detection is done using chirp transform subject to key exchange for security. We show that the proposed method significantly outperforms non-adaptive watermarking across all compression factors under variety of attacks.	british undergraduate degree classification;chirp;digital watermarking;embedded system;fm broadcasting;frequency allocation;image scaling;key exchange;noise power;noise shaping;polynomial;x.690	Yimin Zhang;Bijan G. Mobasseri;Behzad Mohammadi Dogahe;Moeness G. Amin	2010	Signal, Image and Video Processing	10.1007/s11760-008-0102-3	telecommunications;digital watermarking;computer science;mathematics;computer security	EDA	41.88171005251413	-9.160546561789008	101515
e66452a1d4e797c1890393531eac6c99851684bd	distributed centroid estimation from noisy relative measurements	noisy relative measurements;distributed linear estimation;sensor networks;distributed systems;multi agent localization	We propose an anchorless distributed technique for estimating the centroid of a network of agents from noisy relative measurements. The positions of the agents are then obtained relative to the estimated centroid. The usual approach to multi-agent localization assumes instead that one anchor agent exists in the network, and the other agents positions are estimated with respect to the anchor. We show that our centroid-based algorithm converges to the optimal solution, and that such a centroid-based representation produces results that are more accurate than anchor-based ones, irrespective of the selected anchor.	algorithm;computation;jacobi method;multi-agent system	Rosario Aragues;Luca Carlone;Carlos Sagüés;Giuseppe Carlo Calafiore	2012	Systems & Control Letters	10.1016/j.sysconle.2012.04.008	mathematical optimization;wireless sensor network;mathematics	ML	53.13623817693642	3.3172301482271664	101693
7d2fc0a72148df6294201e7624c2bfe4c072c5ef	pitch-synchronous linear-prediction analysis by synthesis with reduced pulse densities	analysis by synthesis;variable rate;speech coding;adaptive codes;linear predictive;linear predictive coding;speech synthesis signal synthesis linear predictive coding stochastic processes frequency estimation speech codecs quantization adaptive filters estimation error acoustic noise;speech codecs;adaptive codes speech coding linear predictive coding speech codecs signal reconstruction filtering theory signal representation;signal representation;signal reconstruction;estimation error;filtering theory;4 kbit s speech codec stochastic codebook component coding rate reduction low rate quantization residual reconstruction error reconstructed signal pitch synchronous estimation linear prediction filter pitch synchronous updating adaptive codebook coefficient estimation error audible noise reduction pitch synchronous analysis fixed rate representation pulse density signed magnitudes celp coders speech quality linear prediction analysis by synthesis speech coding	An important step toward achieving a high-quality 4 kb/s speech codec is reducing the coding-rate of the stochastic codebook component to near 2 kb/s. The increased reconstruction error in the residual that such low-rate quantization implies motivates the search for techniques that reduce the perceptibility of the errors in the reconstructed signal. Pitch-synchronous estimation of the linear-prediction filter and pitch-synchronous updating of the adaptive codebook reduce the coefficient-estimation error and increase the relative contribution of the adaptive codebook component to the synthesized signal, thereby reducing audible noise. However, pitch synchronous analysis normally results in a variable-rate coder. To obtain a fixed-rate representation, we introduce an efficient representation of the stochastic codebook component using a pulse density of one pulse per 2 ms and signed magnitudes specified by 2 bits per pulse-pair. The resulting reconstructions are evaluated for CELP coders corresponding to classical and generalized-pitch-predictor designs. In both cases speech quality comparable to 8 kb/s G.729 is achieved.	speech coding;synchronous circuit	Driss Guerchi;Yasheng Qian;Paul Mermelstein	2000		10.1109/ICASSP.2000.861917	adaptive multi-rate audio codec;codec2;linear predictive coding;speech recognition;vector sum excited linear prediction;harmonic vector excitation coding;computer science;speech coding;pattern recognition;code-excited linear prediction	Logic	49.035736269906415	-9.328244867055483	101707
6a258f85eb4b902650dbc21493f127b9f04b8c88	xetal: a low-power high-performance smart camera processor	high performance smart camera processor;charge coupled image sensors;digital signal processors;frames per second;30 mw;image processing equipment;concurrent computing;video signal processing;image communication;30 mw xetal chip low power smart camera processor high performance smart camera processor digital signal processor vga format image sensor cmos image sensor ccd image sensor digital video data source fully programmable processor image communication machine vision parallel processor array special purpose controller digital camera cmos dsp chip 0 18 micron;vga format image sensor;digital camera;digital video data source;cmos process;parallel processor array;image sensors;computer vision;chip;cmos image sensors;smart cameras cmos process digital signal processors cmos image sensors charge coupled image sensors signal processing algorithms image communication machine vision communication system control concurrent computing;programmable circuits cmos digital integrated circuits digital signal processing chips low power electronics image processing equipment image sensors parallel architectures computer vision video signal processing;cmos image sensor;low power;parallel architectures;cmos digital integrated circuits;video conferencing;machine vision;programmable circuits;0 18 micron;smart cameras;low power electronics;xetal chip;digital signal processor;cmos dsp chip;digital signal processing chips;digital video;power consumption;communication system control;signal processing algorithms;ccd image sensor;fully programmable processor;high performance;image sensor;special purpose controller;low power smart camera processor	Xetal is a digital signal processor to be combined with a 30 frames per second VGA-format CMOS or CCD image sensor or any other source of digital video data. The processor is fully programmable and therefore able to run a variet?, of algorithms ranging from image communication to machine vision. Xetal comprises a parallel processor array and a special purpose controller to achieve high computational performances (up to 5 GOPS) with a very modest power consumption. This can go down to 30 mWatts for simple applications such as a digital camera for video cor?ferencing. The Xetal chip has been realized in a 0.18 pm CMOS process and takes up an area of 25 iriiri '.	algorithm;array data structure;cmos;charge-coupled device;digital camera;digital signal processor;digital video;image sensor;low-power broadcasting;machine vision;parallel computing;performance;processor array;signal processing;smart camera;video graphics array;xetal	Richard P. Kleihorst;Anteneh A. Abbo;André van der Avoird;M. Op de Beeck;Leo Sevat;Paul Wielage;R. van Veen;H. van Herten	2001		10.1109/ISCAS.2001.922023	embedded system;electronic engineering;concurrent computing;machine vision;computer hardware;computer science;image sensor	Arch	42.425949039404145	-3.375797047633804	102145
e0fd4466b90c3e3b049253858061a3e1ad96fb19	gsm enhanced full rate speech codec	error free channel conditions;background noise;quantization;channel coding;algebraic codes;algoritmo busqueda;error protection;code excited linear prediction;12 2 kbit s;algorithme recherche;cellular radio;speech processing;speech analysis;mobile communication system;search algorithm;quality improvement;traitement parole;speech coding;gsm mobile communication system;wireline quality;speech enhancement;gsm speech codecs background noise mobile communication speech coding speech enhancement telecommunication standards speech analysis quantization telephony;telephony;graphs;speech quality;standardisation;linear predictive coding;10 6 kbit s;speech codecs;telecommunication standards;10 6 kbit s enhanced full rate speech codec gsm mobile communication system gsm efr codec speech quality speech coding error protection acelp algorithm algebraic code excited linear prediction wireline quality error free channel conditions background noise tandem connections 12 2 kbit s;graphe;mobile communication;channel coding cellular radio speech coding speech codecs linear predictive coding algebraic codes source coding;enhanced full rate;gsm;acelp algorithm;bruit fond;encoding;tandem connections;enhanced full rate speech codec;codage;algebraic code excited linear prediction;source coding;gsm efr codec	30 This paper describes the GSM enhanced full rate (EFR) speech codec that has been standardised for the GSM mobile communication system. The GSM EFR coclec has been jointly developed by Nokia and University of Sherbrooke. It provides speech quality at least equivalent to that of a wireline telephony reference (32 kbit/s ADPCM). The EFR coldec uses 12.2 kbit/s for speech coding and 10.6 kbit/s for error protection. Speech coding is based on the ACELP algorithm (Algebraic Code Excited Linear Prediction). The codec provides substantial quality improvement compared to the existing GSM full rate and half rate codecs. The old GSM codecs lack behind wireline quality even in error-free channel conditions, while the EFR codec provides wireline quality not only for terror-free conditions but also for the most typical error conditions. With the EFR codec, wireline quality is also sustained in the presence of background noise and in tandem connections (mobile to mobile calls).	adaptive differential pulse-code modulation;algebraic code-excited linear prediction;algorithm;codec;data rate units;enhanced full rate;half rate;speech coding	Kari Järvinen;Janne Vainio;Pekka Kapanen;Tero Honkanen;Petri Haavisto;Redwan Salami;Claude Laflamme;Jean-Pierre Adoul	1997		10.1109/ICASSP.1997.596038	enhanced variable rate codec;gsm;adaptive multi-rate audio codec;linear predictive coding;speech recognition;full rate;mobile telephony;quantization;channel code;telecommunications;computer science;speech coding;speech processing;background noise;graph;telephony;algebraic code-excited linear prediction;standardization;encoding;half rate;search algorithm;source code;code-excited linear prediction;g.723		48.397223450807104	-8.529144314493358	102834
a85b02822e0c39031aec11b8f95e828e3b9afc70	kalman filter based packet loss replacement in presence of additive noise	reconstructed signal kalman filter packet loss replacement additive noise real time packet based communication systems misrouted packets delayed packets degraded perceived voice quality network terminal receiver lost speech segments high quality communication system speech quality adaptive filter state space method speech signal bandwidth extension algorithm;state space methods;speech mathematical model kalman filters bandwidth prediction algorithms;packet loss;low order linear prediction;speech processing;kalman filters;prediction algorithms;speech;kalman filter;state space methods adaptive filters internet telephony kalman filters signal reconstruction speech processing;bandwidth extension;internet telephony;adaptive filters;mathematical model;bandwidth;signal reconstruction;bandwidth extension low order linear prediction kalman filter packet loss voip;voip	A major problem in real-time packet-based communication systems, is misrouted or delayed packets which results in degraded perceived voice quality. If packets are not available on time, the packets are considered as lost. The easiest solution in a network terminal receiver is to replace silence for the duration of lost speech segments. In a high quality communication system, to avoid degradation in speech quality due to packet loss, a suitable method or algorithm is needed to replace the missing segments of speech. In this paper, we introduce an adaptive filter for replacement of lost speech segment. In this method Kalman filter as a state-space based method will be used to predict the speech signal and a bandwidth extension algorithm is also used as a post processing technique to increase the quality of reconstructed signal.	adaptive filter;additive white gaussian noise;algorithm;bandwidth extension;display resolution;elegant degradation;kalman filter;network packet;real-time clock;speech synthesis;state space;utility functions on indivisible goods	Seyed Reza Miralavi;Seyed Ghorshi;Aidin Tahaei	2012	2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2012.6334829	voice activity detection;kalman filter;electronic engineering;speech recognition;telecommunications;computer science;speech processing;statistics	Visualization	49.706698279962325	-8.579277716534307	102857
43bdbb4c713154147bd0449704f742d90ebd81fc	transcoded speech contemporary objective quality measurements reliability	digital signal processing;degradation;telecommunication network reliability;speech transcoding;voice communication ad hoc networks speech coding telecommunication network reliability;frequency estimation;speech;speech coding;3sqm;testing;distortion measurement;voice transmission quality measurement;p 563 algorithms;speech testing signal processing algorithms distortion measurement transcoding humans frequency estimation gsm degradation digital signal processing;transmission quality degradation;voice communication;itu t p 862;ad hoc networks;itu t p 800;humans;quality measures;gsm;signal processing algorithms;permanently interoperating networks;transcoding;itu t p 800 speech transcoding transmission quality degradation ad hoc networks permanently interoperating networks test methodology voice transmission quality measurement coder tandem arrangement itu t p 862 pesq p 563 algorithms 3sqm;pesq;coder tandem arrangement;test methodology	Speech transcoding (coder tandeming) is unavoidable source of transmission quality degradation for ad-hoc or permanently interoperating networks. Test methodology and results of voice transmission quality measurement for transcoded voice in coder tandem arrangement is described. The objective tests have been performed using ITU-T P.862 (PESQ) and P.563 (3SQM) algorithms. The subjective tests results based on ITU-T P.800 are also presented. The objective results confirm additional degradations caused by above mentioned transcodings, highlighting coder combinations causing extreme impairments. The subjective tests quantify objective measurement accuracy.	algorithm;elegant degradation;hoc (programming language);pesq	Jan Holub;Lubica Blaskova	2008	2008 Wireless Telecommunications Symposium	10.1109/WTS.2008.4547552	speech recognition;telecommunications;computer science;communication	Embedded	48.80854544595272	-7.673933043559015	103037
a1853b49d0fc64101493393aa109c1f6d917c940	hyperfine spin qubits in irradiated malonic acid: heat-bath algorithmic cooling	quantum information;electron spin resonance;algorithmic cooling;electron nuclear double resonance;quantum error correction	The ability to perform quantum error correction is a significant hurdle for scalable quantum information processing. A key requirement formultiple-round quantum error correction is the ability to dynamically extract entropy from ancilla qubits. Heat-bath algorithmic cooling is a method that uses quantum logic operations to move entropy from one subsystem to another and permits cooling of a spin qubit below the closed system (Shannon) bound. Gamma-irradiated, 13C-labeled malonic acid provides up to five spin qubits: one spin-half electron and four spin-half nuclei. The nuclei are strongly hyperfine-coupled to the electron and can be controlled either by exploiting the anisotropic part of the hyperfine interaction or by using pulsed electron nuclear double resonance techniques. The electron connects the nuclei to a heat-bath with a much colder effective temperature determined by the electron’s thermal spin polarization. By accurately determining the full spin Hamiltonian and performing realistic algorithmic simulations, we show that an experimental demonstration of heat-bath algorithmic cooling beyond the Shannon bound is feasible in both three-qubit and five-qubit variants of this spin system. Similar techniques could be useful for polarizing nuclei in molecular or crystalline systems that allow for non-equilibrium optical polarization of the electron spin. B Jonathan Baugh baugh@uwaterloo.ca 1 Institute for Quantum Computing, University of Waterloo, Waterloo, ON N2L 3G1, Canada 2 Department of Physics and Astronomy, University of Waterloo, Waterloo, ON N2L 3G1, Canada 3 Department of Chemistry and Molecular Materials Science, Graduate School of Science, Osaka City University, Sumiyoshi-ku, Osaka 558-8585, Japan 4 Perimeter Institute for Theoretical Physics, Waterloo, ON N2J 2W9, Canada 5 Canadian Institute for Advanced Research, Toronto, ON M5G 1Z8, Canada 6 Department of Chemistry, University of Waterloo, Waterloo, ON N2L 3G1, Canada	algorithm;algorithmic cooling;ancilla bit;closed system;computer cooling;electron nuclear double resonance;error detection and correction;grape;information processing;ku band;linear programming relaxation;loss–divincenzo quantum computer;microwave;perimeter;polarizer;purity (quantum mechanics);quantum computing;quantum error correction;quantum information science;quantum logic;qubit;radio frequency;scalability;shannon (unit);simulation	Daniel K. Park;Guanru Feng;Robabeh Rahimi;Stéphane Labruyère;Taiki Shibata;Shigeaki Nakazawa;Kazunobu Sato;Takeji Takui;Raymond Laflamme;Jonathan Baugh	2015	Quantum Information Processing	10.1007/s11128-015-0985-1	quantum information;spin engineering;electron nuclear double resonance;nuclear magnetic resonance;condensed matter physics;electron paramagnetic resonance;physics;quantum mechanics;quantum error correction	Theory	46.718498238374075	2.701467360353881	103541
aba93492b056acab4c3951fe8016ad0a6ea4dd58	a secure partition-based document image watermarking scheme	filigranage numerique;digital watermarking;modelizacion;document watermarking;watermarking;invertebrata;secure partition;swarm intelligence;ant colony optimisation;steganographie;intelligence en essaim;image processing;arthropoda;securite;insecto social;gollete estrangulamiento;routing;camino hamiltoniano;heuristic method;document images;document security;routage;procesamiento imagen;metodo heuristico;bottleneck hamiltonian path;aco;probabilistic approach;traitement image;modelisation;steganography;goulot etranglement;acs;esteganografia;metamodel;metamodele;ant colony system;metamodelo;aculeata;insecta;enfoque probabilista;approche probabiliste;robustesse;filigrana digital;safety;chemin hamiltonien;invariante;robustness;secure partitioning;hymenoptera;image watermarking;methode heuristique;insecte social;social insect;document image;image security;formicoidea;seguridad;modeling;inteligencia de enjambre;bottleneck;invariant;hamiltonian path;robustez;enrutamiento	In this paper, a new document image watermarking method based on a secure partitioning scheme is proposed and tested. In the method, a document image is securely divided into weight-invariant partitions, followed by selectively modifying characters to embed watermarks. The high security of a watermark results from applying a probabilistic metaheuristic algorithm, namely the Ant Colony System (ACS), to approximate the involved Bottleneck Hamiltonian Path Problem to generate key-dependent image partitions. For better efficiency, the farthest point heuristic and the multi-scale strategy are introduced into the ant colony system. Our experimental results demonstrate that the proposed watermarking scheme is secure, efficient, and robust to common attacks. The proposed secure partition scheme could serve as a general framework to introduce high security to prevailing watermarking techniques.	digital watermarking	Shiyan Hu	2010	IJICS	10.1504/IJICS.2010.031856	image processing;digital watermarking;swarm intelligence;computer science;artificial intelligence;theoretical computer science;computer security;algorithm	Vision	40.17232223288184	-8.566560623668982	103811
7835edf0ffac89bd0e61d74fd14b26b518b465d7	spatial-temporal patterns in hardware oriented oscillatory cnn architectures	chemicals;oscillations;oscillatory networks;oscillator state vector spatial temporal patterns hardware oriented oscillatory cnn architectures biological phenomena vlsi platforms oscillatory networks space invariant interactions linear dynamical interactions;space invariant interactions;ordinary differential equation;oscillators;hardware cellular neural networks oscillators biological information theory differential equations chemicals nonlinear dynamical systems pattern recognition biological system modeling extraterrestrial phenomena;linear dynamical interactions;spatial temporal patterns;biological phenomena;vectors;vlsi platforms;oscillator state vector;temporal pattern;mathematical model;vlsi;differential equations;couplings;hardware oriented oscillatory cnn architectures;vlsi differential equations;hardware;dynamic behavior	The analysis and the detection of spatial-temporal patterns are extremely important to unfold the main features of numerous biological phenomena. It is also essential to conceive hardware oriented architectures in order to realize VLSI platforms that are able to process and recognize spatial-temporal patterns without breaking them into frames. Oscillatory networks, whose dynamical behavior is described by large system of ordinary differential equation, represent a suitable paradigm to describe many spatial-temporal time-periodic patterns. The aim of the manuscript is to show that locally connected oscillatory networks (oscillatory CNNs) with linear memoryless and space-invariant interactions act as globally connected oscillatory networks with linear dynamical interactions under the constraint that the couplings involve at least two components of the oscillator state vector. The space-invariant local connectivity permits to realize simple prototype hardware platforms for processing spatial-temporal patterns.	dynamical system;interaction;programming paradigm;prototype;quantum state;very-large-scale integration	Fernando Corinto;Tamás Roska;Marco Gilli	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5118361	electronic engineering;discrete mathematics;theoretical computer science;control theory;mathematics;oscillation;quantum mechanics	Arch	41.143447583986514	-0.8765964316066088	104059
b5ecbec355b4168430fecc19ba06b7a53390da56	an extension of gauss's principle of least constraint	gauss s principle of least constraint;lagrange multiplier;mechanical systems;constraint forces	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Robert E. Kalaba;Harriet H. Natsuyama;Firdaus E. Udwadia	2004	Int. J. General Systems	10.1080/0308107031000139996	mathematical optimization;mathematical analysis;binary constraint;constraint algebra;calculus;mathematics;lagrange multiplier;mechanical system;d'alembert's principle	Robotics	49.60315807618568	-2.9704664721408935	104137
7e65816864498617b4c384664e627bde017a1c01	direct time-of-flight tcspc analytical modeling including dead-time effects		The optimization of a TCSPC system requires modeling which considers the design specifications and parameters of the target application under different operating scenarios. Since single-photon detection is fundamentally a stochastic process, extensive behavioral Monte Carlo simulations are normally used. Their accuracy depends upon computation time. However, the trend towards larger SPAD arrays and emerging complex TDC sharing architectures requires much faster simulation methods. In this paper, a simple, fast and accurate analytical model is presented to address this need. It accounts for dead time effects which result in missed photon counts through the analysis of inhomogeneous continuous time Markov chain. The effective received power and photon detection rate are determined and the corresponding analytical histogram is created. This histogram is the basis for calculating time of flight and can be used to explore architectural alternatives and accelerate design verification. Outputs of the presented analytical model match those of Monte Carlo simulations, and are produced considerably faster. The computation time improvement grows with array sizes and this enables parametric analysis of TCSPC system.	array data structure;column (database);computation;emergence;image sensor;markov chain;mathematical optimization;monte carlo method;simulation;stochastic process;time complexity	Foad Arvani;Anthony Chan Carusone	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351608	continuous-time markov chain;computer science;monte carlo method;mathematical optimization;electronic engineering;time of flight;histogram;stochastic process;dead time;parametric statistics;markov process	Arch	43.87945612292188	2.219869621164123	104204
f534a3dcceb1d6bbe570040d8cccb229f2839556	avoiding oddification to simplify mpeg-1 decoding with lns	logarithmic number system;ieee standards;decoding;inverse discrete cosine transform;video compression;low power design mpeg 1 decoding lns logarithmic number system power consumption conventional fixed point techniques numeric errors ieee 1180 standard inverse discrete cosine transform idct mismatch portable battery powered devices video compression data fed quantization dequantization factor oddification visual effect computer arithmetic multimedia;code standards;transform coding;fixed point;video coding;computer arithmetic;discrete cosine transforms;decoding transform coding visual effects fixed point arithmetic energy consumption discrete cosine transforms displays mpeg standards video compression quantization;digital arithmetic ieee standards code standards transform coding discrete cosine transforms video coding decoding;discrete cosine trans form;digital arithmetic;low power design	Low-precision Logarithmic Number System (LNS) arithmetic can reduce the power consumption for MPEG decoding compared to conventional fixed-point techniques. Although this introduces small numeric errors which violate the IEEE1180 standard for the Inverse Discrete Cosine Transform (IDCT), the visual effects of such error may be tolerable for portable battery-powered devices, like video phones, that have limited-resolution displays. The MPEG standard achieves video compression by quantization of the data fed to the IDCT. The MPEG decoder must multiply this data by dequantization factors. Such multiplication, by itself, is trivial with LNS since adding logarithms is equivalent to multiplication. The IEEE-1180 standard suggests oddification, where fixed-point data is forced to become odd after dequantization to minimize IDCT mismatch between the encoder and the decoder. Oddification poses an implementation problem for data in LNS format. This paper suggests that the visual effect of LNS without oddification is nearly indistinguishable from LNS with oddification, meaning that the benefits of LNS in MPEG are even greater than previously expected.	data compression;discrete cosine transform;encoder;fixed point (mathematics);fixed-point arithmetic;logarithmic number system;mpeg-1;moving picture experts group;quantization (signal processing);visual effects	Mark G. Arnold	2002		10.1109/MMSP.2002.1203264	data compression;arithmetic;transform coding;computer science;logarithmic number system;theoretical computer science;mathematics;fixed point;statistics	ML	45.35109452104554	-6.8134842426526046	104878
1f3b48ac5505c03d414bbe4740e51c236d1a83ba	audio trick art based on information misreading technique	data encapsulation audio watermarking;computers;watermarking;information misreading technique;art;information misreading technique trick art information hiding technique;trick art;data encapsulation;subspace constraints;visualization;redundancy;art computers watermarking redundancy visualization subspace constraints containers;audio information audio trick art information misreading technique information hiding steganography digital watermarking;containers;information hiding technique;audio watermarking	Information hiding technique is employed for some practical applications such as steganography and digital watermarking. Besides these applications, trick art may also be categorized as an application of information hiding technique. This paper describes some examples of trick art. Also, based on the concept named information misreading technique, this paper newly introduces a methodology of making trick art for audio information.	categorization;digital watermarking;steganography	Naofumi Aoki	2011	2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing	10.1109/IIHMSP.2011.48	visualization;digital watermarking;computer science;multimedia;internet privacy;redundancy;world wide web	EDA	43.421508325757856	-9.059074886846167	106486
4ccf49dfe8cc2c546d4ff76b474543c0d48054be	memristor based neuromorphic circuit for ex-situ training of multi-layer neural network algorithms	irrigation;training;resistance;multilayer perceptrons boltzmann machines character recognition edge detection learning artificial intelligence memristor circuits memristors;training resistance handheld computers irrigation;handheld computers;risc processor neuromorphic circuit ex situ training multilayer neural network algorithm ex situ programming technique dot product conductance summation restricted boltzmann machine rbm character recognition convolutional neural network cnn multilayer perceptron mlp sobel edge detection memristor crossbar circuit	This paper describes a novel memristor-based neuromorphic circuit that can be used for ex-situ training of multi-layer neural network algorithms. The presented ex-situ programming technique can be used to map many key neural algorithms directly onto the grid of resistances in a memristor crossbar. This is possible because the proposed circuit is capable of calculating a true dot product. Existing circuits provide an approximated dot product based on a summation of conductance values, which is inaccurate due to the parallel structure of the crossbar. To show the effectiveness and versatility of this circuit, three different powerful neural networks were simulated. These include a Restricted Boltzmann Machine (RBM) for character recognition, a Convolutional Neural Network (CNN) also for character recognition, and a Multilayer Perceptron (MLP) trained to perform Sobel edge detection. Finally, an architecture analysis was performed showing that neuromorphic processors based on these memristor crossbar circuits can be up to 5 orders of magnitude more power efficient than a RISC processor.	4-bit;amplifier;approximation algorithm;artificial neural network;central processing unit;conductance (graph);convolutional neural network;crossbar switch;edge detection;johnson–nyquist noise;layer (electronics);memory-level parallelism;memristor;multilayer perceptron;neuromorphic engineering;optical character recognition;oral history metadata synchronizer;quad flat no-leads package;restricted boltzmann machine;sobel operator	Chris Yakopcic;Raqibul Hasan;Tarek M. Taha	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280813	computer science;artificial intelligence;theoretical computer science;machine learning;physical neural network;irrigation;resistance	EDA	39.3306333927786	-1.2950306558821534	106589
5fb9820aae3842f51cb1f9605c681a07b8972f92	2-d digital signal processing with an array processor	digital signal processing;image processing;application software;data processing;image restoration;testing;laser fusion;filtering algorithms;computer displays;software package;cost effectiveness;digital signal processing image processing signal processing algorithms image restoration computer displays microcomputers application software filtering algorithms laser fusion testing;signal processing algorithms;logical process;microcomputers	The applicability of array processor (AP) technology to 2-D digital signal processing is investigated in this paper. The AP-based image processing facility at LLL is described, with emphasis on our applications software Package which utilizes the array processor. Implementations of several key image processing algorithms are discussed and compared with other conventional processors, indicating that array processors are extremely cost-effective for image processing applications.	array processing;digital signal processing;vector processor	Richard E. Twogood	1980		10.1109/ICASSP.1980.1170893	multidimensional signal processing;image restoration;computer vision;application software;media processor;cost-effectiveness analysis;analog image processing;data processing;inertial confinement fusion;image processing;audio signal processing;space-time adaptive processing;computer science;theoretical computer science;digital signal processing;digital image processing;microcomputer;software testing;signal	Arch	43.73785749545304	-5.119190143582428	106623
db0cba1d4f1abb0100c291bfff01d9cb9140b321	modeling and simulation of circuit aging in scaled cmos design	cmos integrated circuits;modeling and simulation;semiconductor process modelling ageing cmos integrated circuits integrated circuit design integrated circuit modelling;aging;testing;circuit simulation circuit aging scaled cmos design circuit modeling;circuit modeling;integrated circuit design;circuit simulation;integrated circuit modelling;semiconductor device modeling circuit simulation aging circuit testing;semiconductor device modeling;integrated circuit modeling;circuit aging;ageing;semiconductor process modelling;scaled cmos design	Methods for manufacturing cosmetic and dermatological compositions for coloring the skin; and composition, for example, an emulsion, comprising (1) at least one aqueous phase, (2) at least one fatty phase, (3) at least one flavylium salt which is unsubstituted in position 3; which is substituted with at least one radical chosen from hydroxyl and alkoxy radicals; and which is, for example, obtained at least one of synthetically, from a plant extract, and from an enriched plant extract, in an amount which is effective for artificially coloring the skin, for example, effective for obtaining, 30 minutes after application of the emulsion to a fair skin in an amount of 2 mg/cm2, a darkening of the skin color characterized in the L*a*b* colorimetric measuring system by a DELTAL* ranging from -0.5 to -20, and (4) at least one organomodified silicone, where the emulsion is configured as at least one of a cosmetic and a dermatological emulsion.	cmos;simulation	Yu Kao	2008	2008 14th IEEE International On-Line Testing Symposium	10.1109/IOLTS.2008.65	ageing;electronic engineering;computer science;engineering;electrical engineering;circuit design;modeling and simulation;computer engineering	Embedded	51.74189643507737	-0.9481746625305324	107147
82a204c86ce87c78da689f0d1bc97110c3afcc29	adaptive write strategy selection mechanism for optical recording systems	write once storage;reliability;recording;write once storage digital versatile discs video recording video discs reliability;recording digital versatile discs;digital versatile discs;digital versatile disc;optical recording dvd manufacturing space vector pulse width modulation disk recording writing consumer electronics clocks lead drives;optical recording;video recording;video discs;optical media adaptive write strategy selection mechanism optical recording systems consumer dvd digital versatile disc recorders digital versatile disc;optical recording dvd manufacturing writing flowcharts optical devices magnetic heads optical control power lasers timing;standardized specifications optical recording systems adaptive write strategy selection mechanism smart algorithm consumer dvd recorders optical media	This paper discusses a smart algorithm for setting the write strategy in an optical recording device like consumer DVD (digital versatile disc) recorders. The proposed algorithm improves the quality of recorded optical media, being particularly efficient for recordable and rewritable DVDs. One of the biggest challenges faced by optical recorder manufacturers is the increasing availability of low-cost optical media that obey marginally the standardized specifications causing poor recordability and corrupt discs. As the mass market embraces optical recorders in their homes, this problem aggravates resulting in consumer dissatisfaction. This paper presents a novel, yet not very complex method to improve the compatibility of conventional DVD recorders with widely available media.	algorithm	Vangala Venkata Ramana;Avinash Jayaraman	2006	IEEE Transactions on Consumer Electronics	10.1109/TCE.2006.1605042	recording;embedded system;computer hardware;telecommunications;computer science;reliability	Visualization	51.05731742248753	-5.893992221233561	107508
89536e6d732c68c4cb75497ab3e9caa8ad696977	a frame interpretation of sinusoidal coding and waveform interpolation	sinusoidal coding;speech coding frame interpretation sinusoidal coding waveform interpolation time frequency localization unvoiced speech component frame expansions frame representations modeling errors elimination;interpolation;time frequency;auditory system;unvoiced speech component;speech coding;bit rate;frame interpretation;model error;vector quantization;signal representation;time frequency localization;performance analysis;waveform analysis speech coding interpolation time frequency analysis signal representation;signal resolution;frame representations;humans;modeling errors elimination;interpolation speech coding time frequency analysis signal resolution auditory system performance analysis bit rate humans vector quantization;waveform interpolation;waveform analysis;time frequency analysis;frame expansions	Conventional sinusoidal and waveform interpolation coders have a modeling error that limits performance at high rates. In addition, their time-frequency localization of the unvoiced speech component is often insufficient to characterize the speech signal in a perceptually accurate manner. Both problems can be addressed with frame expansions. The usage of frame representations, that are very similar to conventional implementations of the fore-mentioned coders, eliminates modeling errors. Furthermore, frame representations can be selected so as to preserve the time-frequency location of the unvoiced component even when it is characterized with statistical parameters only.	frame language;interpolation;speech synthesis;waveform	W. Bastiaan Kleijn	2000		10.1109/ICASSP.2000.861906	speech recognition;time–frequency analysis;computer science;machine learning;mathematics;statistics	Networks	48.66020835628847	-8.789080742860474	107797
c2cdbcfe4a8c7a234a44b36f655062e96df91017	gpu accelerated population annealing algorithm	paper;отжиг популяции;cuda;physics;параллельный монте карло;ising model;nvidia;algorithms;monte carlo simulation;графический ускоритель;tesla k80	Abstract Population annealing is a promising recent approach for Monte Carlo simulations in statistical physics, in particular for the simulation of systems with complex free-energy landscapes. It is a hybrid method, combining importance sampling through Markov chains with elements of sequential Monte Carlo in the form of population control. While it appears to provide algorithmic capabilities for the simulation of such systems that are roughly comparable to those of more established approaches such as parallel tempering, it is intrinsically much more suitable for massively parallel computing. Here, we tap into this structural advantage and present a highly optimized implementation of the population annealing algorithm on GPUs that promises speed-ups of several orders of magnitude as compared to a serial implementation on CPUs. While the sample code is for simulations of the 2D ferromagnetic Ising model, it should be easily adapted for simulations of other spin models, including disordered systems. Our code includes implementations of some advanced algorithmic features that have only recently been suggested, namely the automatic adaptation of temperature steps and a multi-histogram analysis of the data at different temperatures. Program summary Program Title: PAIsing Program Files doi: http://dx.doi.org/10.17632/sgzt4b7b3m.1 Licensing provisions: Creative Commons Attribution license (CC BY 4.0) Programming language: C, CUDA External routines/libraries: NVIDIA CUDA Toolkit 6.5 or newer Nature of problem: The program calculates the internal energy, specific heat, several magnetization moments, entropy and free energy of the 2D Ising model on square lattices of edge length L with periodic boundary conditions as a function of inverse temperature β . Solution method: The code uses population annealing, a hybrid method combining Markov chain updates with population control. The code is implemented for NVIDIA GPUs using the CUDA language and employs advanced techniques such as multi-spin coding, adaptive temperature steps and multi-histogram reweighting. Additional comments: Code repository at https://github.com/LevBarash/PAising . The system size and size of the population of replicas are limited depending on the memory of the GPU device used. For the default parameter values used in the sample programs, L = 64 , θ = 100 , β 0 = 0 , β f = 1 , Δ β = 0 . 005 , R = 20 000 , a typical run time on an NVIDIA Tesla K80 GPU is 151 seconds for the single spin coded (SSC) and 17 seconds for the multi-spin coded (MSC) program (see Section 2 for a description of these parameters).		Lev Yu. Barash;Martin Weigel;Michal Borovský;Wolfhard Janke;Lev N. Shchur	2017	Computer Physics Communications	10.1016/j.cpc.2017.06.020	parallel tempering;massively parallel;parallel computing;importance sampling;monte carlo method;computational science;algorithm;cuda;particle filter;population;computer science;markov chain	HPC	42.086508283004704	2.476084109411658	108077
21feaa95feb1e27750bc94235038a33ce20a3f5d	multiple-description coding of speech using forward error correction codes	phase change materials;decoding;packet loss;speech;speech coding;bit rate	A flexible framework is presented which performs multiple-description coding of speech signals with two or more channels. The use of forward error correction codes together with a layered speech codec permits encoding into more than two descriptions without excessive increase in complexity. Results of a formal MOS listening test reveal considerable improvements in robustness as long as base layer quality and the number of descriptions are chosen appropriately. A modification of the original encoding scheme allows trading off bit rate savings against robustness to extreme channel conditions. Different coding schemes can easily be compared using a real-time demonstrator software.	codec;ecc memory;elegant degradation;error detection and correction;experiment;fault tolerance;forward error correction;line code;molecular dynamics;multiple description coding;network packet;norm (social);real-time clock;rendering (computer graphics);speech coding	Kai Clüver;Jan Weil;Thomas Sikora	2007	2007 15th European Signal Processing Conference		voice activity detection;adaptive multi-rate audio codec;codec2;linear predictive coding;speech recognition;full rate;telecommunications;harmonic vector excitation coding;computer science;speech coding;communication	ML	48.17193750593803	-8.957378537082477	108412
bab3fe1ba43a00c07d4725c6aa7d769334df7c45	testing of a microanalysis system	chemical sensors microsensors microfluidics micropumps mixed analogue digital integrated circuits integrated circuit testing chemical analysis;chemical analysis;failure mode;ccd array microsystem testing microanalysis system mixed signal test techniques fluidics system testing analog signal processing digital signal processing portable instant chemical analyzer microfluid channels flow sensor micropump optical absorption sensor known good substrate well known good die functional testing led array activation;system testing actuators built in self test mechanical sensors fluidics analog digital conversion design for testability helium computer aided manufacturing micromechanical devices;microfluidics;integrated circuit testing;mixed analogue digital integrated circuits;micropumps;microsensors;chemical sensors	During the testing of microsystems, one has to cope with many problems resulting from inaccessibility, different technologies, and nonelectrical failure modes. A number of mixed-signal test techniques have been applied to test a new advanced microsystem. The choices on testing are directly dependent on implementation form and application area of the microsystem. Mixed-signal testing approaches are a key factor in this environment.	failure cause;mixed-signal integrated circuit	Hans G. Kerkhoff	2001	IEEE Trans. Instrumentation and Measurement	10.1109/19.982932	embedded system;electronic engineering;microfluidics;engineering;electrical engineering;failure mode and effects analysis	SE	47.598804817283536	-0.7807716719103984	108421
b334fba987f6235cec477a1f879b20db6452d926	time delay estimation: application to flow rate measurement of cooling fluid in nuclear power plants	coolants;nuclear measurements;time measurement;cross correlation;time delay estimation;delay effects;delay effects delay estimation power measurement fluid flow measurement nuclear measurements time measurement cooling power generation coolants fluid flow control;fluid flow measurement;generalized cross correlation;flow rate;power generation;nuclear power plant;velocity profile;fluid flow control;delay estimation;cooling;power measurement	Precise measurement of the coolant flow rate is of utmost importance for the control and safety of PWR nuclear power plants. In this paper several methods based on generalized cross-correlation of γ-radioactivity signals are tested. We examine the influence of hydrodynamical parameters such as velocity profile and turbulence on the measurement. We show that recently proposed sophisticated estimates (PHAT-SCOT) are not efficient for our purpose and that the Hannan-Thomson (HT) estimate is just slightly better than classical cross correlation (CC).		Jean-Melaine Favennec;B. Georgel;J. Masson	1982		10.1109/ICASSP.1982.1171763	electricity generation;coolant;cross-correlation;control theory;volumetric flow rate;statistics;time	EDA	52.543833454388306	-5.483447331907732	108618
d4332764810a2d26cc4560776e9ec15c8a3ccfeb	state-of-the-art image sensors and signal processing in nasa's space telescopes [in the spotlight]	control application;data transmission;space telescope;detectors;integrated circuit;analog to digital conversion;image sensors;telescopes;image sensors signal processing telescopes space technology instruments infrared detectors application specific integrated circuits image converters data communication integrated circuit technology;application specified integrated circuits;near infrared detectors;near infrared;astronomical image processing;application specific integrated circuits;signal processing;analogue digital conversion;pixel;image sensors analogue digital conversion astronomical image processing astronomical instruments;data transmission image sensors signal processing nasa space telescopes near infrared detectors application specified integrated circuits analog to digital conversion;image sensor;nasa space telescopes;astronomical instruments	In this article we will take a closer look at two of the critical instrument components designed for the JWST: the near infrared detectors and their associated control application-specified integrated circuits (ASICs). These devices have been designed to perform precision analog to digital (A/D) conversion and data transmission in the very harsh environment of deep space. We will first present an overview of the technology used in image sensors for astronomy, followed by a description of the processors used to control them and process the signal. We will then explain how this technology is applied to process the imaging data in the HST and the JWST.	analog-to-digital converter;application-specific integrated circuit;central processing unit;dbpedia;image sensor;signal processing	Markus Loose	2010	IEEE Signal Processing Magazine	10.1109/MSP.2009.934924	computer science;signal processing;image sensor	Embedded	42.96188886271711	-3.321957657802619	108757
0ed21e0e4985017d4bab502e341819e79fc66287	an ewma algorithm with a cycled resetting (cr) discount factor for drift and fault of high-mix run-to-run control	statistics quality control manufacturing processes stability analysis of variance performance analysis algorithm design and analysis system performance;oscillations;asymptotic variance control;semiconductor technology;yarn;fault tolerant;high mix run to run control;semiconductor industry;exponential weighted moving average;statistical process control;asymptotic stability;system performance;journal;ewma algorithm;stability;resetting fault tolerant approach;manufacturing processes;statistical process control asymptotic stability control charts fault tolerance mean square error methods moving average processes semiconductor industry semiconductor technology;control charts;chromium;mean square error;fault tolerance;stability condition;performance analysis;statistics;analysis of variance;mean square error methods;moving average processes;simulation study;cycled resetting cr algorithm;run to run;threaded ewma run to run control cycled resetting cr algorithm fault tolerant;stable control scheme;semiconductor manufacturing process steps;threaded ewma run to run control;quality control;large deviation;algorithm design and analysis;asymptotic variance;cycled resetting discount factor;semiconductor manufacturing;quality control ewma algorithm cycled resetting discount factor high mix run to run control exponential weighted moving average semiconductor manufacturing process steps stable control scheme asymptotic variance control resetting fault tolerant approach mean square error;exponentially weighted moving average	Run-to-run controllers based on the exponential weighted moving average (EWMA) statistic are probably the most frequently used for the quality control of certain semiconductor manufacturing process steps. The threaded-EWMA run-to-run control is an important stable control scheme. However, the process outputs will deviate largely in the first few runs of each cycle if the disturbance follows an IMA(1,1) series with deterministic linear drift and the thread has a long break length. In this paper, the output of the threaded-EWMA run-to-run control is derived, stability conditions are given, and the causes of large deviations in the first few runs of each cycle are found. Based on the analysis of system performance, a cycled resetting (CR) algorithm for discount factor is proposed to reduce the large deviations, as well as to achieve the minimum asymptotic variance control. Furthermore, how to deal with step fault is also discussed in this paper. By analyzing the influence of the fault, a discount factor resetting fault-tolerant (RFT) approach is proposed. Simulation study shows both the mean square error (MSE) and variance of the output by the proposed algorithm is about 30% to 50% lower than that of the algorithm with fixed discount factor in the process with and without oscillation. This verifies the effectiveness of the proposed approach.	algorithm;fault tolerance;mean squared error;request for tender;semiconductor device fabrication;simulation;time complexity	Ying Zheng;Bing Ai;David Shan-Hill Wong;Shi-Shang Jang;Jie Zhang;Yanwei Wang	2010	IEEE Transactions on Industrial Informatics	10.1109/TII.2009.2039904	control engineering;fault tolerance;real-time computing;computer science;engineering;control theory;computer performance;statistics	Visualization	52.86706224645774	-3.047355180926026	108867
12affb70880632f8000fcae28445bff0fbac61cc	robust speech decoding: a universal approach to bit error concealment	cordless telephone systems;speech intelligibility;pulse code modulation;error concealment;awgn channel robust speech decoding bit error concealment digital mobile communication systems universal approach residual bit errors channel decoding bit reliability information speech quality speech codec parameters optimum estimation speech codec standard demodulator dect channel decoder soft output viterbi algorithm sova muting mechanism adverse transmission conditions residual source redundancy output speech quality enhancement error free channel bit exactness gsm lpc;robustness decoding speech codecs mobile communication code standards demodulation viterbi algorithm gsm degradation redundancy;cellular radio;speech processing;mobile communication system;code standards;speech enhancement;a priori knowledge;land mobile radio;speech codecs;digital radio;soft output viterbi algorithm;telecommunication standards;graceful degradation;speech intelligibility speech processing land mobile radio cellular radio cordless telephone systems digital radio telecommunication standards code standards speech codecs speech enhancement pulse code modulation gaussian channels viterbi decoding;viterbi decoding;gaussian channels	In digital mobile communication systems there is the need for reducing the subjective e ects of residual bit errors which have not been eliminated by channel decoding by the use of error concealment techniques. Due to the fact that most standards do not specify these algorithms bit exactly, there is room for new solutions to improve the speech quality. This contribution develops a new approach for optimum estimation of speech codec parameters. It can be applied to any speech codec standard if a bit reliability information is provided by the demodulator (e.g. DECT), or by the channel decoder (e.g. soft-output Viterbi algorithm { SOVA [7] in GSM). The proposed method includes an inherent muting mechanism leading to a graceful degradation of speech quality in case of adverse transmission conditions. Particularly the additional exploitation of residual source redundancy, i.e. some a priori knowledge about codec parameters gives a signi cant enhancement of the output speech quality. In the case of an error free channel, bit exactness as required by the standards can be preserved.	bit error rate;codec;digital enhanced cordless telecommunications;elegant degradation;error concealment;fault tolerance;soft output viterbi algorithm;speech coding	Tim Fingscheidt;Peter Vary	1997		10.1109/ICASSP.1997.598832	pulse-code modulation;enhanced variable rate codec;digital radio;fault tolerance;soft output viterbi algorithm;a priori and a posteriori;speech recognition;full rate;telecommunications;computer science;speech processing;intelligibility;viterbi decoder;statistics	Crypto	48.89842532358169	-8.59678826525421	109085
57548d0dda4df02b25952f3b2825160a03f68bcc	energy targeting and minimum energy distillation column sequences	phase equilibrium;energy targeting;distance function;distillation columns;design method;total stripping line distance;column sequences;distillation;design methodology;two level design method	The determination of distillation column configurations that consume the least total energy is studied. The novel contributions of the proposed design methodology for finding global minimum energy column sequences presented in this article include: (1) the definition of a total stripping line distance function for any sequence, (2) a robust energy targeting strategy that provides a continuously differentiable description of column sequences, (3) the flexibility to use any phase equilibrium model, (4) the ability to find column sequences that contain non-pinched, minimum energy columns within a sequence, and (5) the ability to include heat integration. The proposed energy targeting approach, which is used in conjunction with the two-level design methodology of Amale & Lucia (2008b), is shown to be a reliable and effective tool for finding minimum energy distillation column sequences. A number of example problems are presented to show the efficacy of the proposed design methodology. © 2009 Elsevier Ltd. All rights reserved.	c4 engine;column (database);column-oriented dbms;converge;emoticon;iteration;level design;line search;mass effect trilogy;maxima and minima;numerical analysis;rectifier;sonic x;spec#;volatility	Angelo Lucia;Bradley R. McCallum	2010	Computers & Chemical Engineering	10.1016/j.compchemeng.2009.10.006	chromatography;mathematical optimization;design methods;mathematics	EDA	50.19646897402115	-5.365781484094695	109338
9f87153263527ac60bbd523f30768838a49032a3	parallel implementation of the time-evolving block decimation algorithm for the bose-hubbard model	time evolving block decimation;optical lattice;tensor network;bose hubbard model	A system of ultracold atoms in an optical lattice represents a powerful experimental setup for testing the fundamentals of quantum mechanics. While its microscopic interaction mechanisms are well understood, the system behavior for a moderate number of particles is difficult to simulate due to a high dimension of its many-body space. This article presents TEBDOL, a parallel implementation of the time-evolving block decimation (TEBD) algorithm that can efficiently simulate time evolution of a one-dimensional chain of atoms in optical lattices. We investigate the parallelization strategy and the strong and weak scaling with the number of processes.#R##N#Program summary#R##N#Program title: TEBDOL#R##N##R##N#Catalogue identifier: AEYN_v1_0#R##N##R##N#Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEYN_v1_0.html#R##N##R##N#Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland#R##N##R##N#Licensing provisions: GNU General Public License v3.0#R##N##R##N#No. of lines in distributed program, including test data, etc.: 9060#R##N##R##N#No. of bytes in distributed program, including test data, etc.: 54338#R##N##R##N#Distribution format: tar.gz#R##N##R##N#Programming language: Common Lisp.#R##N##R##N#Computer: x86-64.#R##N##R##N#Operating system: Linux.#R##N##R##N#Has the code been vectorized or parallelized?: Parallelized using MPI#R##N##R##N#RAM: 1–64 GB#R##N##R##N#Classification: 7.7.#R##N##R##N#External routines: Basic Linear Algebra Subprograms (BLAS), Linear Algebra Package (LAPACK), Message Passing Interface (MPI)#R##N##R##N#Nature of problem: A system of neutral atoms in an optical lattice is a many-body quantum system that can be described using the Bose–Hubbard model. Hilbert space dimensions of many-body quantum models grow exponentially with the number of particles. Simulating time evolution in the Bose–Hubbard model is therefore a hard problem even in case of a moderate number of particles.#R##N##R##N#Solution method: A system state is represented by a tensor network. Its time evolution is then simulated using the time-evolving block decimation (TEBD) algorithm.#R##N##R##N#Restrictions: TEBDOL is limited to one-dimensional systems. The times accessible in the simulations are restricted by the growth of entanglement in the system.#R##N##R##N#Unusual features: Tensor networks in TEBDOL support a global Abelian symmetry, i.e., the program conserves the total number of particles. Models with multiple particle species are supported as well. TEBDOL is implemented in Common Lisp and can run in parallel on a computer cluster.#R##N##R##N#Running time: Running time depends on the lattice size, on the number of particles, and on the maximal allowed tensor dimensions. Simulations of simple models take a few seconds on a single CPU while simulations of large and complex models can take up to a week on a cluster with hundreds of CPUs.	algorithm;bose–hubbard model;decimation (signal processing);hubbard model;time-evolving block decimation	Miroslav Urbánek;Pavel Soldán	2016	Computer Physics Communications	10.1016/j.cpc.2015.10.016	bose–hubbard model;time-evolving block decimation;computer science;theoretical computer science;pure mathematics;mathematics;optical lattice;physics;algorithm;quantum mechanics	Theory	42.434584602877884	2.921084789948818	109351
fca50079b8d82f921ed0d32e3ddfe73e7e51f5ef	a novel chaotic uniform quantizer for speech coding		Quantization is an essential step in the analog-to-digital conversion process and it is very important in all modern telecommunication systems. In this paper, a novel chaotic uniform quantizer is proposed and its application for speech coding is presented. The proposed system consists of three stages: two PCM coders separated by an XOR operation with a chaotic sequence, where the first step is used for continuous signal sampling and second stage performs data encryption, while the third stage provides additional data compression. The performance of the presented quantizer for Laplacian distributed signals and real speech signals is investigated and compared with that of the well-known uniform and non-uniform quantizers. Simulation results show that the proposed quantizer provides secured data with higher levels of SQNR compared to others.	analog-to-digital converter;continuous signal;data compression;digital signal processing;encryption;exclusive or;quantization (signal processing);sampling (signal processing);signal-to-quantization-noise ratio;simulation;speech coding;whole earth 'lectronic link	Osama A. S. Alkishriwo	2018	CoRR		continuous signal;encryption;data compression;sampling (statistics);quantization (signal processing);bitwise operation;speech coding;computer science;laplace operator;control theory	AI	44.63130978306796	-8.630266781944185	109499
0358e14814e26bbafb6f96bc5125387e0b7bb883	yet another analog 2d gaussian convolver	real time;chip;kernel;heat equation;convolution;real time systems;finite difference;vlsi;image sensors;finite difference methods;capacitors	A compact, discrete, capacitive, 2D Gaussian convolution network is presented by solving the heat equation in implicit finite difference form. A scalable 2D Gaussian convolution can be performed by controlling the iteration number. This capacitive network is especially adapted to real-time analog VLSI vision chips because of its simplicity and compactness. u003e	yet another	Yang Ni;Yiming Zhu;Bogdan Arion;Francis J. Devos	1993			chip;finite difference;electronic engineering;discrete mathematics;kernel;capacitor;finite difference method;theoretical computer science;image sensor;mathematics;heat equation;very-large-scale integration;convolution;gaussian filter;gaussian function	ML	41.71500384389916	-3.0295069095483655	109760
d01a1bb7ff86fd665c0d9c5068751696e40b4273	improvement of gps position estimation using snr and doppler		In this paper, we propose a method to improve the accuracy of GPS positioning in the environment where the satellite signal including error information is excluded and the satellite signal is reflected and distorted like urban area. Factors that degrade GPS positioning accuracy include time error, ionospheric error, tropospheric error, and multipath error. In order to compensate for this, various methods such as RTK-GPS (Real Time Kinematic GPS), D-GPS (Differential GPS) and A-GPS (Assisted GPS) are used. However, these methods have drawbacks that are difficult to use due to additional system configuration and cost. In order to improve the position accuracy of the GPS receiver, the state of the satellite signal is determined by using the SNR and the Doppler shift, and the accuracy of the position estimation of the GPS receiver is improved by excluding the satellite signal including the error. In order to verify the performance of the proposed method, we proceeded with experiments under static conditions rather than dynamic conditions in a dense environment.	assisted gps;differential gps;doppler effect;experiment;global positioning system;multipath propagation;real time kinematic;signal-to-noise ratio;system configuration	Jong-woo An;Jang-Myung Lee	2017	2017 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)	10.1109/AIM.2017.8014254	real time kinematic;gps signals;control theory;error analysis for the global positioning system;global positioning system;geodesy;time to first fix;gps disciplined oscillator;assisted gps;computer science;gps/ins	Robotics	49.444402308124474	1.6505554568041512	110182
637aa441373b2cefc30bfcc4d4b6fd5d63bbf2eb	optimization of mesh locality for transparent vertex caching	triangle strips;geometry compression;indexation;optimal algorithm;triangle strip	Bus traffic between the graphics subsystem and memory can become a bottleneck when rendering geometrically complex meshes. In this paper, we investigate the use of vertex caching to transparently reduce geometry bandwidth. Use of an indexed triangle strip representation permits application programs to animate the meshes at video rates, and provides backward compatibility on legacy hardware. The efficiency of vertex caching is maximized by reordering the faces in the mesh during a preprocess. We present two reordering techniques, a fast greedy strip-growing algorithm and a local optimization algorithm. The strip-growing algorithm performs lookahead simulations of the cache to adapt strip lengths to the cache capacity. The local optimization algorithm improves this initial result by exploring a set of perturbations to the face ordering. The resulting cache miss rates are comparable to the efficiency of the earlier mesh buffer scheme described by Deering and Chow, even though the vertex cache is not actively managed. CR Categories: I.3.1 [Computer Graphics]: Hardware Architecture; I.3.3 [Computer Graphics]: Picture/Image Generation Display algorithms; Additional	backward compatibility;cpu cache;cache (computing);glossary of computer graphics;graphics hardware;greedy algorithm;locality of reference;mathematical optimization;parsing;preprocessor;simulation;triangle strip	Hugues Hoppe	1999		10.1145/311535.311565	mathematical optimization;theoretical computer science;mathematics	Graphics	45.798886155074136	-5.046214489074625	110289
bd9787a89ffd9d6e84e1293bbf6d82c9e14126aa	analysis of accuracy of modified gradient method in indoor radiolocalisation system	distance measurement gradient method indoor radiolocalisation system position calculation;radionavigation distance measurement gradient methods indoor radio;distance measurement gradient methods accuracy indoor environments buildings mean square error methods vectors;accuracy;distance measurement;vectors;indoor environments;mean square error methods;gradient methods;buildings	In this paper a new method, called modified gradient method, has been proposed for position calculation on the basis of distance measurement in indoor environment. It is shown that well known method of position calculation such as Foy is inefficient in indoor environment. In this article is also described the indoor radiolocalisation system which was used for collecting distance measurements which were employed for further comparative analysis of Foy and modified gradient method.	gradient method;horner's method;nonlinear system;qualitative comparative analysis;software propagation	Agnieszka Czapiewska;Jaroslaw Sadowski	2014	2014 IEEE 79th Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2014.7022830	electronic engineering;simulation;environmental engineering;mathematics;accuracy and precision;statistics	Robotics	49.906800096551734	1.6971642173590675	110647
543141a09f61f9a91fe101359a59c38df0fba37f	parallel surface collision detection implementation with openmp	collision detection	In assembly, disassembly and maintenance operations, it is necessary to find intersecting surfaces for the automatic recognition of geometric constraints between virtual prototypes. In this paper, we propose an algorithm to determine intersecting surfaces in virtual prototyping environments and use parallel computing methods to improve performance. The proposed algorithm is based on the Overlapping Axis-Aligned Bounding Box (OAABB), to determine intersecting surfaces efficiently. We use OpenMP, taking advantage of shared memory multiple processors to reduce the overall time complexity of the collision detection algorithm. In this research, we also describe our experiences in parallelizing the code to achieve a better work distribution. Our results show that the proposed collision detection achieves interactive rates in real industrial applications as desired.	algorithm;assembly language;automatic parallelization;central processing unit;collision detection;disassembler;minimum bounding box;openmp;parallel computing;shared memory;time complexity	Mauro Figueiredo;Terrence Fernando	2004			time complexity;parallel computing;virtual prototyping;collision detection;minimum bounding box;shared memory;computer science	HPC	44.90828448669692	-4.841340979308543	110797
8987b691c7d038dbae6ed90b19eb55c2fb9637b9	neuropipe-chip: a digital neuro-processor for spiking neural networks	performance evaluation neural chips neural net architecture;image segmentation;performance evaluation;real time;neural net architecture;indexing terms;neural networks spiking artificial neural networks sanns neuropipe chip neuro processor accelerator board chip level prototype performance system simulation hardware description language image segmentation;chip;neural chips;spiking neural network;computational complexity;hardware description language;real time image processing;system simulation;hardware design languages cmos technology computer networks artificial neural networks neural network hardware prototypes virtual prototyping computational modeling image segmentation workstations;artificial neural network;neural network	Computing complex spiking artificial neural networks (SANNs) on conventional hardware platforms is far from reaching real-time requirements. Therefore we propose a neuro-processor, called NeuroPipe-Chip, as part of an accelerator board. In this paper, we introduce two new concepts on chip-level to speed up the computation of SANNs. These concepts are implemented in a prototype of the NeuroPipe-Chip. We present the hardware structure of the prototype and evaluate its performance in a system simulation based on a hardware description language (HDL). For the computation of a simple SANN for image segmentation, the NeuroPipe-Chip operating at 100 MHz shows an improvement of more than two orders of magnitude compared to an Alpha 500 MHz workstation and approaches real-time requirements for the computation of SANNs in the order of 10(6) neurons. Hence, such an accelerator would allow for applications of complex SANNs to solve real-world tasks like real-time image processing. The NeuroPipe-Chip has been fabricated in an Alcatel 0.35-mum digital CMOS technology.	artificial neural network;cmos;computation (action);greater than;hardware acceleration;hardware description language;image processing;image segmentation;megahertz;prototype;real-time clock;requirement;spiking neural network;workstation;biologic segmentation;orders - hl7publishingdomain	Tim Schönauer;Sahin Atasoy;Nasser Mehrtash;Heinrich Klar	2002	IEEE transactions on neural networks	10.1109/72.977304	chip;embedded system;index term;computer science;theoretical computer science;machine learning;image segmentation;hardware description language;computational complexity theory;artificial neural network	Robotics	39.83752040136136	-2.1458462073353117	110799
97c31b9697417a2133f389160b0087d93ae71f99	an embedded sinusoidal transform codec with measured phases and sampling rate scalability	sampling rate scalability;phase measurement;speech codec;embedded sinusoidal transform codec;measured phases;wideband;decoding;16 khz;signal sampling;speech coding;transform coding;bit rate;scaling up;telephone bandwidth speech;spectral envelope;speech codecs;3 2 kbit s;bandwidth;4 to 8 khz embedded sinusoidal transform codec sampling rate scalability embedded bit stream telephone bandwidth speech synthetic phases measured phases wideband speech speech codec spectral envelope 3 2 kbit s 6 4 kbit s 9 6 kbit s 16 khz;6 4 kbit s;scalability;wideband speech;synthetic phases;transform coding speech codecs signal sampling speech coding;9 6 kbit s;sampling methods;phase measurement sampling methods scalability bit rate decoding speech codecs bandwidth wideband speech coding transform coding;embedded bit stream;4 to 8 khz	This paper describes an embedded sinusoidal transform codec that is scalable not only in bit-rate, but also in sampling ratet. In a representative implementation, the system produces an embedded bit-stream at 3.2 and 6.4 kb/s for telephonebandwidth speech, and scales up to 9.6 kb/s for 16 kHz sampled wideband speech. The 3.2 kb/s codec is a sinusoidal transform codec with synthetic phases. The 6.4 kb/s codec adds resolution to the spectral envelope and transmits measured phases of the eight lowest harmonics. The 9.6 kb/s codec adds information in the 4 to 8 kHz band to provide higher quality wideband speech.	bitstream;codec;data rate units;dhrystone;embedded system;image resolution;kilobyte;sampling (signal processing);scalability	Gerard Aguilar;Juin-Hwey Chen;Robert B. Dunn;Robert J. McAulay;Xiaoqin Sun;Wei Wang;Robert Zopf	2000		10.1109/ICASSP.2000.859166	adaptive multi-rate audio codec;codec2;speech recognition;full rate;telecommunications;computer science;g.726;speech coding;statistics;g.723	Networks	47.584815050826315	-8.623346569951412	110891
f9b5deb545323169c2c0ab2a20e67970242c077a	data recovery in wireless sensor networks with joint matrix completion and sparsity constraints	convergence;data collection;reconstruction algorithms;spatiotemporal sparsity wireless sensor network joint matrix completion sparsity constraints data collection reduction data recovery method undersampled measurement low rank feature temporal sparsity feature;lowrank matrix completion;data recovery;sparsity constraints wireless sensor networks data recovery lowrank matrix completion;energy consumption;期刊论文;spatiotemporal phenomena;wireless sensor networks data handling matrix algebra telecommunication power management;wireless sensor networks reconstruction algorithms energy consumption data collection convergence spatiotemporal phenomena;wireless sensor networks;sparsity con	An effective way to reduce the energy consumption of energy constrained wireless sensor networks is reducing the number of collected data, which causes the recovery problem. In this letter, we propose a new data recovery method with joint matrix completion and sparsity constraints to recover the signal from undersampled measurements. Utilizing both the low-rank and temporal sparsity feature, the proposed method fully exploits spatiotemporal sparsity of the signal in networks. An algorithm is developed to efficiently solve the formulation incorporating the matrix completion and sparsity constraints terms. The results of experiments indicate that the proposed method outperforms the state-of-the-art methods for different types of signal in the network.	algorithm;data recovery;experiment;mathematical optimization;matrix regularization;optimization problem;sparse matrix;the matrix	Jingfei He;Guiling Sun;Zhihong Wang	2015	IEEE Communications Letters	10.1109/LCOMM.2015.2489212	mathematical optimization;wireless sensor network;convergence;computer science;data recovery;machine learning;data mining;statistics;computer network;data collection	AI	51.958081206276624	2.211905246310417	111113
98441f025d47d7bfb3eaaf8eb4be45775b4f08c1	modeling and controlling variation in mechanical assemblies using state transition models	linear systems;control theory;robotic assembly digital to frequency converters fixtures discrete event systems logic tolerance analysis gaussian approximation manufacturing systems robots assembly systems;controllability;matrix algebra;optimal control;stochastic systems assembling optimal control linear systems matrix algebra discrete systems controllability;model building;control variates;assembling;linear dynamical system;and type 2;discrete systems;stochastic systems;optimal control problem mechanical assemblies state transition models variation propagation multi stage linear dynamic system datum flow chain;state transition;optimal control problem	Presents a state transition model of assembly and concepts from control theory to model variation propagation and control during assembly. The assembly process is modeled as a multi-stage linear dynamic system. Two types of assemblies are addressed: Type-1 where the assembly puts together parts at their pre-fabricated mating features, and Type-2 where the assembly process can incorporate in-process adjustments to redistribute variation. The model builds on the concept of the datum flow chain. Algorithms are developed to determine and control variation in final assembly propagated through the combined effect of individual part variations and choice of assembly methods. An optimal control problem is formulated to develop a scientific approach to designing assembly features.		R. Mantripragada;Daniel E. Whitney	1998		10.1109/ROBOT.1998.676376	control engineering;linear dynamical system;mathematical optimization;model building;controllability;optimal control;control theory;mathematics;linear system;control variates	NLP	53.67925785490601	-3.342755900178022	111367
6233157c3eeb33796b3ca8d0f9af2df7ded0429a	a framework for bioacoustical species classification in a versatile service-oriented wireless mesh network	wireless sensor networks monitoring birds wireless communication noise arrays wireless mesh networks;wireless communication;arrays;birds;monitoring;wireless mesh networks;wireless mesh networks acoustic signal processing array signal processing bioacoustics cepstral analysis digital signal processing chips principal component analysis signal classification;veso wmn bioacoustical species classiication sensor array processing digital signal processing sap mel frequency cepstrum coeficients mfcc principal components analysis pca k nearest neighbor k nn method audio vocalization master sensor node msn configuration versatile service oriented wireless mesh network;wireless sensor networks;noise	The decline in amphibian populations worldwide has become a tangible example of a major environmental concern due to the fact that amphibian presence has been interpreted as a good indicator of the health of an ecosystem. Consequently, monitoring is an imperative. In this work, a conceptual framework for bioacoustical species classification is formulated and an instantiation of this framework is presented in the form of a sensor array processing (SAP) system. From a digital signal processing perspective, the main feature implemented in the instantiated SAP is an application capability, based on Mel-frequency cepstrum coefficients (MFCC), principal components analysis (PCA), and k-nearest neighbors (k-NN) methods that allows identifying species from audio vocalizations recorded by array sensors. Finally, the processed information is being delivered, through what has been termed a master sensor node (MSN) configuration, to a versatile service-oriented (VESO) wireless mesh network (WMN) which is currently being implemented as an instrumentation testbed at the National Jobos Bay Estuarine Research Reserve (JBNERR) located on the island of Puerto Rico.	array processing;coefficient;digital signal processing;ecosystem;imperative programming;k-nearest neighbors algorithm;mel-frequency cepstrum;mesh networking;population;principal component analysis;rico;sensor node;service-oriented device architecture;testbed;universal instantiation;wireless mesh network	Gonzalo Vaca-Castano;Domingo Rodríguez;Julio Castillo;Kejie Lu;Alejandro Rios;Fernando Bird	2010	2010 18th European Signal Processing Conference		electronic engineering;speech recognition;telecommunications;engineering;order one network protocol;key distribution in wireless sensor networks;wi-fi array	Robotics	44.99467408333142	-1.5542967998712318	111427
4690e2df35744c863a859d07ce21d7b7fb9b37c2	a rfid-enabled sensor platform for pervasive monitoring	uhf integrated circuits magnetic sensors magnetoresistive devices motion measurement radiofrequency identification radiotelemetry temperature measurement temperature sensors;ic rfid enabled sensor platform pervasive monitoring uhf rfid sensor temperature detection motion detection pallet tracking applications tagged object integrity control dedicated ic sl900a anisotropic magnetoresistive sensor earth magnetic field electromagnetic simulations tag antenna;magneto resistive rfid sensor temperature motion;radiofrequency identification integrated circuits temperature sensors perpendicular magnetic anisotropy antennas	This paper studies the implementation of an UHF RFID sensor combining temperature detection with motion detection to improve pallet tracking applications. The aim is to control the integrity of the tagged object during its complete product life (realization, transportation, end-user). It is based on a dedicated IC SL900A from AMS connected to an anisotropic magneto-resistive sensor. The temperature detection is provided by an internal sensor in the IC. The motion is detected by the external magneto-resistive sensor due to the apparent variation of the earth's magnetic field when it rotates. Electromagnetic simulations of the tag's antenna and practical validations of the motion sensor are presented.	motion detector;near field communication;programming paradigm;radio-frequency identification;roll-to-roll processing;sensor;simulation;software deployment;ultra high frequency;verilog-ams;wireless access point	Arnaud Vena;Brice Sorli;Alain Foucaran;Yassin Belaizi	2014	2014 9th International Symposium on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC)	10.1109/ReCoSoC.2014.6861358	embedded system;electro-optical sensor	Mobile	46.308295533824214	-3.448191684319487	111517
526e1151249664d9ca787f2aa41211f5c43562bf	thick restarting the weighted harmonic arnoldi algorithm for large interior eigenproblems	thick restarting;interior eigenproblems;arnoldi process;weighted arnoldi process;krylov subspace;numerical experiment;65f15;sparse matrices;65f10	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithm;arnoldi iteration;francis;primary source	Hong-Xiu Zhong;Gang Wu	2011	Int. J. Comput. Math.	10.1080/00207160.2010.489639	mathematical optimization;combinatorics;sparse matrix;krylov subspace;calculus;generalized minimal residual method;mathematics;algebra;arnoldi iteration	Robotics	49.42894807563543	-2.9435527457301984	112316
e0297204acb4440e712f6a14d9a7a1347e42e113	techniques for improving sinusoidal transform vocoders	parametric model;vocoders frequency cepstral analysis psychoacoustic models cepstrum convolution interpolation transfer functions power system modeling speech coding;speech coding;spectrum;transform coding;vocoders;proceedings paper;vocoders transform coding speech coding spectral analysis;speech coding sinusoidal transform vocoders quality enhancement sinusoidal transform speech coders parametric models bark spectrum perceptual coding sine wave amplitudes phase representation noncausal all pole modeling vocal system phase accuracy improvement synthetic speech quality;spectral analysis	This paper presents quality enhancement of sinusoidal transform coders (STC) via the development of new parametric models. First explored are the benefits of Bark spectrum for use in the design of perceptual coding of the sine-wave amplitudes. According to our results, the proposed approach provides a uniform perceptual fit across the spectrum. To enhance the accuracy of phase representation, noncausal all-pole modeling of the vocal system is also discussed. Experimental results indicate that the use of new parametric models allows the STC to improve the phase accuracy as well as the synthetic speech quality.	psychoacoustics;synthetic intelligence;vocoder	Wen-Whei Chang;De-Yu Wang	1998		10.1109/ICASSP.1998.674483	spectrum;transform coding;speech recognition;parametric model;computer science;speech coding;mathematics;statistics	AI	48.12692658822679	-8.915031172479967	112413
6e46a0e5b9091add9c63b6ca6c3bfe470f0e80cc	deriving optimal silicon neuron circuit specifications using data assimilation		Mixed signal neuromorphic circuits represent a promising technology for implementing compact and ultra-low power prosthetic devices that can be directly interfaced to living tissue. However, to accurately emulate the dynamical behavior of the biological tissue, it is necessary to determine the optimal set of specifications and bias parameters for these circuits. In this paper we show how this can be done for a silicon neuron design, by applying a statistical Data Assimilation method (DA). We present a conductance-based silicon neuron based on the Mahowald-Douglas (MD) design and use the DA method to estimate its state variables and the ion channels parameters, so that it can accurately emulate the properties of biological neurons involved in the Central Pattern Generators (CPGs) responsible for producing the respiratory and heart-rate rhythms. While previous work has shown how DA well-estimates and predicts parameters from membrane voltage measurements using a semi-empirical Hodgkin-Huxley neural model, here we show how the same method is suitable for simplified Very Large Scale Integration (VLSI) circuit designs and demonstrate how it allows us to reliably predict the response of the MD neuron to different input current profiles.		Elisa Donati;Kamal Abu Hassan;Alain Nogaret;Giacomo Indiveri	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351338	electronic engineering;conductance;central pattern generator;mixed-signal integrated circuit;data assimilation;electronic circuit;computer science;very-large-scale integration;state variable;neuromorphic engineering	EDA	40.11115104567011	-0.9238321006180096	112808
da97243f1fb13c8fdbdfcd3589661bfd34042f72	design of an intelligent ph sensor for aquaculture industry	intelligent sensor;low power;signal processing;high performance;water quality monitoring	Abstract. Automatic monitoring and controlling system is essential for improvement of aquaculture industry. This paper presents an intelligent PH sensor that applied to water quality monitoring. It involved signal processing, self-calibration. Using low power and high performance microcontroller MSP430F149, Smart Transducer Interface Module (STIM) based on IEEE1451standard was embedded. The design of software and hardware was described in detail, and an initial calibration experiment was carried out to establish a calibration parameter. The results indicate that the pH sensor is more accurate, reliable and easy to use, which is suitable to spread the application in aquaculture industry.	automatic control;bus (computing);embedded system;ieee 1451;microcontroller;sensor web;signal processing;smart transducer;system of measurement	Haijiang Tai;Qisheng Ding;Daoliang Li;Yaoguang Wei	2010		10.1007/978-3-642-18369-0_77	control engineering;embedded system;electronic engineering;engineering	Robotics	46.55144172961875	-1.163890200941492	113291
caa20147de37262260ff250ff5e9cdb31b6bbca3	robust speech coding with evs	codecs;enhanced voice services robust speech coding audio quality characteristics voice quality characteristics evs standardized 3gpp codec erasure conditions 3gpp amr codec amr wb codec subjective listening tests noisy speech clean speech speech quality finnish language random frame erasure rates nine scale subjective mean opinion score;speech;speech coding;bit rate;noise measurement;frame erasure speech coding listening testing multi bandwidth testing mean opinion score;safety;robustness;speech coding natural language processing speech codecs;speech codecs safety noise measurement bit rate speech coding robustness	This paper discusses the voice and audio quality characteristics of EVS, the recently standardized 3GPP codec. Especially frame erasure conditions were evaluated. Comparison to industry standard voice codecs: 3GPP AMR and AMR-WB as well as direct signals at varying bandwidths was made. Speech quality was evaluated with two subjective listening tests containing clean and noisy speech in Finnish language. Five different random frame erasure rates were evaluated: 0 %, 3 %, 6 %, 10 % and 15 %. Nine-scale subjective mean opinion score was calculated for all tested conditions.	adaptive multi-rate audio codec;speech coding;technical standard	Anssi Rämö;Adriana Vasilache;Henri Toukomaa	2015	2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2015.7418302	voice activity detection;adaptive multi-rate audio codec;codec2;g.729;linear predictive coding;speech recognition;full rate;acoustics;computer science;speech coding;acoustic model;psqm;communication	Vision	48.34801276766746	-8.120432978063938	113883
4a17ae1cbbb6b4f9a010f7a3e111de8580ec1b75	system-compatible robustness improvement for new generation dect decoders by g.722 soft-decision decoding	telephony decoding reliability speech codecs speech coding;decoding bit error rate codecs speech indexes encoding proposals;error concealment;adpcm;soft decision decoding;ng dect error concealment speech decoding adpcm soft decision decoding;packet loss concealment algorithm system compatible robustness improvement g 722 soft decision decoding itu t recommendation subband adaptive differential pulse code modulation sb adpcm mandatory wideband speech codec new generation digital enhanced cordless telephony ng dect decoder soft decision speech decoding technique channel reliability information speech quality;speech decoding;ng dect	The ITU-T Recommendation G.722 about subband adaptive differential pulse code modulation (SB-ADPCM) is the mandatory wideband speech codec in the new generation digital enhanced cordless telephony (NG-DECT). Although in ADPCM the difference signal instead of the original signal is quantized and adaptive prediction is employed, redundancy is yet observed within the quantized samples. In this paper we apply a soft-decision speech decoding technique which exploits this redundancy in terms of a priori knowledge and the channel reliability information to NG-DECT. In that way, we propose a novel scheme in a standard-compliant fashion which improves the robustness of the decoder. The performance of our proposal is evaluated in terms of speech quality and a noticeable improvement over the standard codec and its own packet loss concealment algorithm is observed.	adaptive differential pulse-code modulation;algorithm;codec;digital enhanced cordless telecommunications;g.722;ng-pon2;network packet;soft-decision decoder;speech coding	Domingo Lopez-Oiler;Sai Han;Ángel M. Gómez;Jose Luis Perez-Cordoba;Tim Fingscheidt	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7472818	speech recognition;telecommunications;computer science;g.726;psqm	Robotics	48.70601410642204	-8.610817172343479	114332
762239206eea078f638204162c9bea54090b056f	new three-term conjugate gradient method with guaranteed global convergence	standard wolfe line search;90c30;global convergence;conjugate gradient method;65k05;期刊论文;unconstrained optimization;algorithms;powell symmetrical technique;descent	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	code;conjugate gradient method;francis;line search;local convergence;mathematical optimization;newton's method;powell's method;primary source	J. K. Liu;Shunfen Li	2014	Int. J. Comput. Math.	10.1080/00207160.2013.862236	gradient descent;mathematical optimization;conjugate residual method;powell's method;wolfe conditions;gradient method;calculus;derivation of the conjugate gradient method;descent direction;newton's method in optimization;mathematics;conjugate gradient method;nonlinear conjugate gradient method;mathematical economics;biconjugate gradient method;line search;algorithm;algebra	Robotics	49.54401992641561	-2.9526027426315355	114511
702ea4cb972aaa3ff3cb5e3ad933f174313fc61a	scanning the strength of a test signal to monitor electrode degradation within bio-fluidic microsystems	microcontrollers;defective sensing electrode monitoring;self test solution;reliability;microsystem reliability;decision support systems testing;online solutions;electrode electrolyte interface;biofluidic microsystems;fault modeling;liquid crystal displays;electrode degradation monitoring;sensing microelectrodes;customised prototype array structure;testing;multiplexing equipment;analogue multiplexer;lcd;reliability analogue integrated circuits biomedical electrodes biomems built in self test condition monitoring electrolytes lab on a chip liquid crystal displays microcontrollers microfluidics multiplexing equipment;impedance analysis;bio fluidic microsystems built in self test microfluidics;analogue integrated circuits;built in self test;condition monitoring;electrolytes;microfluidics;decision support systems;lab on chip devices;lab on a chip;mea;multielectrode array;biomedical electrodes;multiple multidomain interface validation;real time condition monitoring;test signal strength scanning;bio fluidic microsystems;built in self test test signal strength scanning electrode degradation monitoring biofluidic microsystems lab on chip devices complex multifunctional heterogeneous microsystems microsystem reliability multiple multidomain interface validation online solutions fault modeling impedance analysis electrode electrolyte interface customised prototype array structure self test solution sensing microelectrodes multielectrode array mea defective sensing electrode monitoring analogue multiplexer lcd microcontroller real time condition monitoring;biomems;microcontroller;complex multifunctional heterogeneous microsystems	Lab-on-Chip devices are complex multifunctional heterogeneous microsystems that have the potential to strongly influence advances in important areas such as pharmacology, security, and environmental analysis. High reliability requirements in many of these microsystems are crucial which makes test more challenging especially given the need to validate multiple multi-domain interfaces and realise on-line solutions. Based on fault modeling and impedance analysis of the electrode/electrolyte interface and a customised prototype array structure, this paper proposes a self-test solution that targets degraded sensing microelectrodes within Multi Electrode Array's (MEA). The principle of this approach is to scan the strength of a test signal over the whole array to monitor the defective sensing electrodes. The test solution has been applied at the system level where an analogue multiplexer, an LCD, and a microcontroller have been used to achieve a real time condition monitoring technique.	british informatics olympiad;characteristic impedance;elegant degradation;microcontroller;multi-function printer;multiplexer;online and offline;prototype;requirement	Qais Al-Gayem;Hong Liu;Haroon Khan;Andrew Richardson	2013	2013 IEEE 19th International On-Line Testing Symposium (IOLTS)	10.1109/IOLTS.2013.6604064	microcontroller;embedded system;electronic engineering;decision support system;computer science;engineering;electrical engineering;operating system;liquid-crystal display	Embedded	47.45339459832023	-0.7194550678987087	115348
c6c5fd06d2c5374917b100c4392374df69d56633	shape preserving c2 rational quartic interpolation spline with two parameters	65d05;convergence analysis;65d17;65d07;approximation order;shape preserving interpolation;rational quartic interpolation spline	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;interpolation;primary source;quartic function;spline (mathematics)	Yuanpeng Zhu;Xuli Han	2015	Int. J. Comput. Math.	10.1080/00207160.2014.973864	spline interpolation;interpolation;mathematical optimization;mathematical analysis;bilinear interpolation;perfect spline;smoothing spline;monotone cubic interpolation;interpolation;polynomial interpolation;stairstep interpolation;cubic hermite spline;inverse quadratic interpolation;hermite spline;bicubic interpolation;mathematics;geometry;thin plate spline;polyharmonic spline;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;m-spline;trilinear interpolation	Robotics	49.46838417314327	-2.8103853665094665	115684
c5c9e03a1e1087f2b27f4e1d6340f8a728a2601a	real-time fuzzy processor on a dsp	control application;piecewise linear;programmable controllers;real time;fuzzy control;real time systems programmable controllers fuzzy control digital signal processing chips fuzzy logic;real time system fuzzy logic dsp programmable fuzzy processor defuzzification inference engine fuzzy controllers;fuzzy logic;aggregation operator;signal processing;digital signal processing fuzzy systems fuzzy logic signal processing algorithms hardware signal processing interpolation fuzzy sets telecommunication standards telecommunication control;membership function;digital signal processing chips;high speed;real time systems;knowledge base	Fuzzy logic has been successfully introduced in control applications, but usually has the problem of low speed. Fuzzy logic applications can be seen as any other signal processing application, which makes a DSP a good candidate for high speed fuzzy processing, taking also into account that DSPs are classical platforms in industrial environments. This paper presents a real-time full-programmable fuzzy processor using piecewise-linear interpolation techniques and implements it using a DSP. A full-programmable fuzzy processor is defined as a system where the t-norm, t-conorm aggregation operator, propagation operator, rules, membership functions and defuzzification algorithm can be defined by any valid algorithm. Real-Time fuzzy processing is defined as a way of processing the knowledge base in a constant time and with a minimum speed of 1 MFLIPS.	algorithm;defuzzification;digital signal processor;fuzzy logic;knowledge base;linear interpolation;real-time clock;real-time transcription;signal processing;software propagation;t-norm;time complexity	Enrique Frías-Martínez	2001	ETFA 2001. 8th International Conference on Emerging Technologies and Factory Automation. Proceedings (Cat. No.01TH8597)	10.1109/ETFA.2001.996395	fuzzy logic;control engineering;knowledge base;fuzzy electronics;electronic engineering;real-time computing;membership function;piecewise linear function;defuzzification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;programmable logic controller;signal processing;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	53.60724551313353	-6.077059700563979	115789
c12b10fecc69d49b369188ce76d1936a68c7aef2	composite electro-optical testing of surface-mount device boards-one manufacturer's experience	surface mount device boards;reliability;composite testing;surface mount device;maintenance;production efficiency composite testing machine vision fibre optic sensor electro optical testing surface mount device boards switchboards cost quality reliability automatic optical inspection electrical testing medium volume manufacturing;medium volume manufacturing;automatic testing;automatic optical inspection;manufacturing automation;electrooptic devices;fibre optic sensors;inspection;surface mount technology;surface mount technology automatic testing fibre optic sensors inspection printed circuit testing production testing;manufacturing processes;quality;machine vision;displays;electrooptic devices automatic testing manufacturing processes costs maintenance throughput displays automatic optical inspection manufacturing automation production;electro optical testing;fibre optic sensor;production;electrical testing;printed circuit testing;production testing;cost;electro optic;switchboards;production efficiency;throughput	The use of surface-mount devices (SMDs) in the US manufacture of high-quality switchboards presented the need to reduce cost, while maintaining traditional quality and reliability, and without decreasing throughput or adding process steps. Further, the complexity of the display panels demanded a completely automatic test solution without the operator in the loop. The authors describe the use of automatic optical inspection in conjunction with electrical testing for a medium-volume manufacturing situation. The effectiveness of this test solution in meeting the needs of a major change in device technology is quantified from measurement accuracy and consistency viewpoints. Increased production efficiency as compared with previous tests strategies is indicated. >	surface-mount technology	Frank J. Langley;Ronald R. Boatright;Laurence Crosby	1989		10.1109/TEST.1989.82356	embedded system;throughput;electronic engineering;inspection;machine vision;computer science;engineering;productive efficiency;reliability;engineering drawing;statistics	HCI	51.073714018025534	-5.866097483939097	116354
09661ed8b9ee6c079e9723d4245ac264f9e83485	optimization design of biorthogonal filter banks for image compressing	design process;multi agent system;filter bank;agent based;performance metric;multi agent systems;image compression;peak signal to noise ratio;optimal design;compression ratio;nonlinear optimization;generalization	A new kind of 9/7 wavelet basis, the optimum biorthogonal wavelet basis, is establishedd according to the effect of image compression by adopting the SPIHT algorithm based on the idea of biorthogonal wavelet filter bank with the lattice structure in this paper. Lenna and the Goldhill were adopted as the standard training images; and the maximal peak signal-to-noise values were obtained with the compression rate as the parameter. So, the looking for the optimal biorthogonal wavelet basis is simple to the optimization problem. The genetic algorithm was adopted here. It is illustrated compression effect of other standard image by finding optimum biorthogonal wavelet basis, that is, comparing compression result with Antonini's 9/7 wavelet basis. This method is feasible in the experiments, and the inspection is effective.	biorthogonal wavelet;crystal structure;experiment;filter bank;genetic algorithm;image compression;lenna;mathematical optimization;maximal set;optimization problem;set partitioning in hierarchical trees;signal-to-noise ratio	Yi Shang;Longzhuang Li;Benjamin W. Wah	2001	2008 International Symposium on Information Science and Engineering	10.1016/S0020-0255(01)00067-6	adaptive filter;generalization;mathematical optimization;simulation;design process;kernel adaptive filter;peak signal-to-noise ratio;image compression;computer science;artificial intelligence;optimal design;compression ratio;multi-agent system;filter bank;filter design	Graphics	44.02174832257158	-6.797277103167004	116454
1f607aa7056a75c89b1a7c87ecedd3ece0ba9389	design of multirate observers and multirate control systems	hierarchical structure;time scale;state estimation;control problem;control system	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	control system;francis;primary source	Hisashi Kando;Hiroyuki Ukai;Yoshifumi Morita	2000	Int. J. Systems Science	10.1080/002077200412168	control engineering;mathematical optimization;control system;control theory;mathematics	Robotics	50.79643185179533	-3.3960215057827576	116547
138fa976ed2be7be2212f9411c67df516db25dba	output-based method of applying pesq to measure the perceptual quality of framed speech signals	testing monitoring speech analysis in vivo codecs delay quality of service laboratories computational modeling analytical models;perceptual quality;client server architecture;speech coding;internet telephony;input output;speech codecs;voice communication;mean opinion score;speech recognition speech codecs speech coding voice communication hearing internet telephony quality of service;speech recognition;quality measures;quality of service;hearing;quality of service perceptual evaluation speech quality measurement speech signal frame speech signal transmission speech signal reception objective perceptual quality score speech signal coding voice call voice input voice output frame loss codec client server architecture	A well-known objective method of speech quality measurement is the ITU-T P.862 PESQ. This input/output-based method of perceptual quality evaluation operates on a transmitted (input) and received (output) speech signal to compute an objective perceptual quality score for the received signal. In this paper, we present F-PESQ, a novel output-based method of applying PESQ to received speech signals assumed to be coded in a framed format. It enables the application of PESQ to voice calls in networks without requiring knowledge of the transmitted signals. As such, it may be applied in vivo to voice calls at end-devices. The accuracy of F-PESQ is evaluated with analysis and simulations of frame loss with G.711, G.723, and G.729 codecs. A client/server architecture is presented for minimizing the computational requirements that F-PESQ imposes on end-devices. We also show how F-PESQ can be combined with the ITU-T G.I 07 E-model in a MOSC (conversational mean opinion score) measurement method that accounts for additional factors such as round-trip delay.	client–server model;codec;g.711;g.723;g.729;input/output;pesq;requirement;round-trip engineering;server (computing);simulation;video-in video-out	Adrian E. Conway	2004	2004 IEEE Wireless Communications and Networking Conference (IEEE Cat. No.04TH8733)	10.1109/WCNC.2004.1311485	voice activity detection;mean opinion score;input/output;codec2;g.729;linear predictive coding;speech recognition;quality of service;pesq;computer science;speech coding;voice analysis;speech processing;psqm;client–server model	Visualization	48.98473601799125	-7.3581296531371185	116792
278fc596a19db8e38b4d11ed09126bd0068c57c8	a tactile sensor network system using a multiple sensor platform with a dedicated cmos-lsi for robot applications †	multi-kind sensing;multi-point bus connection;next generation robot;sensor platform lsi;single-ended communication;tactile sensor network system	"""Robot tactile sensation can enhance human-robot communication in terms of safety, reliability and accuracy. The final goal of our project is to widely cover a robot body with a large number of tactile sensors, which has significant advantages such as accurate object recognition, high sensitivity and high redundancy. In this study, we developed a multi-sensor system with dedicated Complementary Metal-Oxide-Semiconductor (CMOS) Large-Scale Integration (LSI) circuit chips (referred to as """"sensor platform LSI"""") as a framework of a serial bus-based tactile sensor network system. The sensor platform LSI supports three types of sensors: an on-chip temperature sensor, off-chip capacitive and resistive tactile sensors, and communicates with a relay node via a bus line. The multi-sensor system was first constructed on a printed circuit board to evaluate basic functions of the sensor platform LSI, such as capacitance-to-digital and resistance-to-digital conversion. Then, two kinds of external sensors, nine sensors in total, were connected to two sensor platform LSIs, and temperature, capacitive and resistive sensing data were acquired simultaneously. Moreover, we fabricated flexible printed circuit cables to demonstrate the multi-sensor system with 15 sensor platform LSIs operating simultaneously, which showed a more realistic implementation in robots. In conclusion, the multi-sensor system with up to 15 sensor platform LSIs on a bus line supporting temperature, capacitive and resistive sensing was successfully demonstrated."""	cable;cmos;electric capacitance;flexible circuit;flexible electronics;integrated circuit;node - plant part;numerous;outline of object recognition;printed circuit board device component;printing;relay device component;robot (device);semiconductor;tactile sensor;temperature sensor device component;very-large-scale integration;sensor (device)	Chenzhong Shao;Shuji Tanaka;Takahiro Nakayama;Yoshiyuki Hata;Travis Bartley;Yutaka Nonomura;Masanori Muroyama	2017		10.3390/s17091974		Robotics	47.74604438514952	0.003890669808528085	117234
eff4dd458dc7069a378713eeacd8dbdffea0ee78	fully integrated 3.2 gbps quantum random number generator with real-time extraction	phase measurement;measurement by laser beam;random number generation;field programmable gate arrays;toeplitz matrices	We present a real-time and fully integrated quantum random number generator (QRNG) by measuring laser phase fluctuations. The QRNG scheme based on laser phase fluctuations is featured for its capability of generating ultra-high-speed random numbers. However, the speed bottleneck of a practical QRNG lies on the limited speed of randomness extraction. To close the gap between the fast randomness generation and the slow post-processing, we propose a pipeline extraction algorithm based on Toeplitz matrix hashing and implement it in a high-speed field-programmable gate array. Further, all the QRNG components are integrated into a module, including a compact and actively stabilized interferometer, high-speed data acquisition, and real-time data post-processing and transmission. The final generation rate of the QRNG module with real-time extraction can reach 3.2 Gbps.	data acquisition;data rate units;field-programmability;field-programmable gate array;hardware random number generator;random number generation;randomness;real-time clock;real-time data;real-time transcription;toeplitz hash algorithm;video post-processing	Xiaoguang Zhang;You-Qi Nie;Hongyi Zhou;Hao Liang;Xiongfeng Ma;Jun Zhang;Jian-Wei Pan	2016	The Review of scientific instruments	10.1063/1.4958663	random number generation;field-programmable gate array	Embedded	44.17312574751024	-3.000388427976471	117383
36c04d54eecf0e03a3e8fcd9289d95c7c96ecb90	characterizing and calibrating low-cost wearable ozone sensors in dynamic environments		The increased interest in utilizing wearable technologies for ubiquitous monitoring of human physiological, behavioral, and environmental parameters has come to force, including the rise of cost-effective, low-power gas sensors that enable personalized air quality monitoring in daily life. Despite the advances in system design of wearable gas sensor nodes, the characteristics of these sensors under real-world conditions have not been comprehensively examined, specifically the influences of environmental dynamics on sensor calibration and sensitivity. In this paper, we propose ozone sensor calibration algorithms that exploit dynamic relative humidity (RH) and temperature sensor measurements to enhance the quality of ozone measurement. The contributions of this study are 1) characterization of the influences of RH and temperature dynamics on low-cost metal oxide ozone sensors, and 2) calibration algorithms with considerations of sensor characteristics. Experimental results demonstrate the efficacy of the proposed methods in characterizing and calibrating the low-cost wearable ozone sensors.	algorithm;low-power broadcasting;personalization;sensor;systems design;wearable computer	Dawei Fan;Jiaqi Gong;Benjamin Ghaemmaghami;Anyi Zhang;John Lach;David B. Peden	2017	2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)		calibration;wearable technology;wearable computer;ozone;materials science;electronic engineering	Mobile	47.205371725331055	-0.5585088547965986	118352
be178a0ce5d241e79850e8252b8f0aa220125ad5	collocation solution of the korteweg-de vries equation using septic splines	numerical solution;septic spline;kdv equation;numerical scheme;korteweg de vries equation;collocation method;linear stability analysis;collocation solution	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithm;collocation method;computer simulation;francis;numerical analysis;primary source;septic equation;spline (mathematics);velocity (software development)	A. A. Soliman	2004	Int. J. Comput. Math.	10.1080/00207160410001660817	dispersionless equation;mathematical optimization;orthogonal collocation;mathematical analysis;korteweg–de vries equation;collocation method;calculus;mathematics	Robotics	49.54720984723951	-2.9521628641766897	118440
39e7eb5489c535364e4138c28a4b81ee3b8929cc	an error mitigation technique for erasure channels based on a wavelet representation of the speech excitation signal	codecs;wavelet transforms haar transforms quantisation signal signal representation speech coding;speech;speech coding;quantization signal;internet low bitrate codec error mitigation technique erasure channels wavelet representation speech excitation signal packet based speech transmission concealment techniques quality of service lpc coefficients linear prediction coding replacement technique minimum mean square error estimation speech parameters signal quantization signal representation haar wavelet transform haar transformed domain objective test subjective test adaptive multirate codec;indexes;estimation;transforms;quantization methods speech excitation signal error concealment erasure channels speech coding;speech quantization signal speech coding codecs estimation indexes transforms	The importance of packet-based speech transmissions has grown since it offers cheaper and efficient communications. However, frame erasures are a common hurdle in these networks and concealment techniques are necessary to ensure a minimum quality of service. In this paper, we propose a mitigation technique focused on the reconstruction of the linear prediction coding (LPC) coefficients and the excitation signal of the lost frame by using a replacement technique. These replacements are obtained by means of a minimum mean square error estimation based on a source model of the speech parameters (LPC coefficients and the excitation signal). As this approach critically relies on the quantization and representation of the excitation signal, we explore the Haar wavelet transform as a novel approach to represent the excitation signal for error mitigation. Thus, this paper describes how optimal codebook and estimates can be computed in a Haar transformed domain. As a result, the excitation signal of a frame can be decomposed in several partitions where each one is independently reconstructed. Objective and subjective tests are conducted in order to assess the quality of the concealed speech signal resulting from our proposal. Both evaluations confirm noticeable improvements over the default mitigation method included in the two tested standard codecs, adaptive multirate, and Internet low bitrate codec.	binary erasure channel;codebook;codec;coefficient;haar wavelet;linear predictive coding;mean squared error;network packet;open-source software;quality of service;wavelet transform	Domingo López-Oller;Ángel M. Gómez;José L. Pérez-Córdoba;Victoria W. Sánchez	2016	IEEE Transactions on Multimedia	10.1109/TMM.2016.2561840	voice activity detection;database index;codec2;estimation;codec;linear predictive coding;speech recognition;telecommunications;computer science;speech;speech coding;statistics	Visualization	48.667800317785826	-8.756315903294864	118549
490efd1101b1363e3ec86fa5a5f75ca5d030dfb6	parallel numerical solution for flood modeling systems	equation derivee partielle;simulation ordinateur;partial differential equation;ecuacion derivada parcial;flujo agua;eau surface;flood;numerical solution;agua superficie;model system;numerical method;inundacion;paralelisacion;ecoulement eau;linux cluster;gran sistema;inondation;metodo numerico;surface water;large system;parallelisation;software package;parallelization;simulacion computadora;progiciel;water flow;computer simulation;solution numerique;methode numerique;parallel simulation;grand systeme	Simulation of the water flood problems often leads to solving large sparse systems of partial differential equations. For such systems, numerical methods can be very CPU-time consuming. Therefore, parallel simulation is beneficial for water flood studies, and provides satisfactory accuracy. In this paper, we present an approach to parallelizing water flow modeling systems and some experimental results obtained on Linux clusters.	automatic parallelization;central processing unit;flood fill;linux;numerical method;parallel computing;simulation;sparse matrix;workstation	Ladislav Hluchý;David Froehlich;Viet D. Tran;Ján Astalos;Miroslav Dobrucký;Giang T. Nguyen	2001		10.1007/3-540-48086-2_53	computer simulation;surface water;parallel computing;simulation;numerical analysis;computer cluster;computer science;partial differential equation	HPC	44.703702662890414	3.4965586148364545	118600
a1fa5afcca41a0c3ed4a8b15ce6888aa7fd6152a	smart constellation selection for precise vehicle positioning in urban canyons using a software-defined receiver solution	radio receivers;resource efficiency satellite positioning software defined gnss receiver sdr positioning enhancement;software radio;global positioning system;safety critical software;gnss smart constellation selection precise vehicle positioning urban canyons satellite navigation systems gps receivers multipath effect atmospheric effect satellite based positioning safety critical systems advanced software defined radio receiver asdr global navigation satellite systems direct receiver surrounding pre positioning routine geo referenced gps measurements;multipath channels;global positioning system satellites receivers satellite broadcasting accuracy atmospheric modeling hardware;software radio global positioning system multipath channels radio receivers safety critical software	Positioning techniques based on satellite navigation systems are nowadays standard in most commercial vehicles. But GPS receivers in general are effected by multipath and atmospheric effects and hence their performance may be decreased, especially in challenging environments that directly affects the usage of satellite-based positioning in traffic-relevant and by that safety-critical systems. Therefore, this paper describes, based on an exemplary implementation of an Advanced Software-Defined radio receiver (ASDR) for Global Navigation Satellite Systems, the impact of the direct receiver surrounding. In addition, a so-called Smart Constellation Selection (SCS) as pre-positioning routine will be introduced to increase the accuracy by just using already available data at the receiver side. Next to the implementation of the ASDR itself, the functionality and performance of the SCS will be explained. In addition, this contribution contains the introduction of a freely available database with geo-referenced GPS measurements including web-based analysis functionalities to enable other researches to test and evaluate their ideas for future GNSS enhancements.	global positioning system;multipath propagation;satellite navigation;web application;web service	Brian Niehoefer;Florian Schweikowski;Christian Wietfeld	2013	2013 IEEE 20th Symposium on Communications and Vehicular Technology in the Benelux (SCVT)	10.1109/SCVT.2013.6735995	embedded system;receiver autonomous integrity monitoring;satellite navigation;pseudorange;geography;telecommunications;precise point positioning;hybrid positioning system;remote sensing	Embedded	46.83874731340822	2.0152600113430683	118734
0bac66f08c79049634ee5ef09a313c503284bebc	a low complexity image compression solution for onboard space applications	software tool;data compression;real time;lossless compression;low complexity;image;space applications;image compression;remote sensing;next generation;compression;on board;space application	In this work, a real time hardware data compression solution for raster scan cameras, to be onboard the next generation of Remote Sensing Brazilian satellites, is proposed. The options for image data compression methods are briefly covered to substantiate the choice: a low complexity implementation based on JPEG-LS, near-lossless compression algorithm, which can be synthesized in a single electronic device. JPEG-LS performance in terms of compression rates and loss is evaluated by processing remote sensing rough images through in-house developed software tool. Finally, the description and results of an implementation in FPGA are presented and compared to other works, emphasizing the differences related to application requirements.	algorithm;data compression;field-programmable gate array;image compression;jpeg;least squares;lossless compression;programming tool;raster scan;requirement	Antonio Lopes Filho;Roberto d'Amore	2010		10.1145/1854153.1854197	video compression picture types;data compression;s3 texture compression;lossy compression;computer vision;simulation;image compression;computer science;image;lossless compression;texture compression;compression;algorithm;computer graphics (images)	Robotics	43.74446128868853	-5.314983050114132	118840
a5b3740cd13fa5b04396a3ffcd109b2c059c4067	current state of the art - challenges and future directions for audio watermarking	layer 3;data embedding;copyright;multimedia systems;dolby ac 3 coding audio watermarking transparent data embedding algorithms binary streams host multimedia signals copyright protection low bit rate mpeg layer 3 aac;copyright protection;watermarking signal processing algorithms streaming media copyright protection signal processing robustness history bit rate intellectual property digital audio broadcasting;cryptography copyright multimedia systems encoding audio signals;cryptography;audio signals;encoding;audio watermarking	Transparent data embedding algorithms embed binary streams in host multimedia signals. The embedded data is perceptually inaudible to maintain the quality of the source data. The embedded data can add features to the host multimedia signal or provide copyright protection. We review developments and requirements in transparent data embedding techniques for audio signals. We describe our latest audio embedding algorithm and include experimental results indicating robustness to low bit rate MPEG-Layer 3, AAC, and Dolby AC-3 coding. We conclude with a discussion of future research directions.	advanced audio coding;algorithm;embedded system;monkey's audio;moving picture experts group;requirement;source data	Mitchell D. Swanson;Bin B. Zhu;Ahmed H. Tewfik	1999		10.1109/MMCS.1999.779114	mpeg-4 part 3;digital audio;aes11;computer science;cryptography;theoretical computer science;speech coding;multimedia;internet privacy;encoding;statistics	HCI	43.99310164870972	-8.9505403569034	119057
6ddd3af0871d6692af419b65d778d832da108b82	one-class support vector machines for structural health monitoring on wave energy converters		A wave energy converter (WEC) is a device that generates electricity from the kinetic energy of waves and the Department of Energy estimates that these devices could contribute significantly to energy production. However, WECs are not currently economically feasible due to high costs of repair and maintenance. Structural health monitoring (SHM) could be used to reduce these costs and make WECs efficient and deployable in large scale. This study investigates SHM techniques for the fiber reinforced plastics (FRPs) used to construct WECs. Data is collected using piezoelectric transducers on sample FRP plates. One of the primary hurdles with this problem is that the underlying structure of the FRPs is different for each plate, which results in significant variability in the collected data between plates. To overcome this issue, we propose using one-class support vector machines (OCSVMs) that can be trained solely on baseline examples from each plate. The OCSVM then detects anomalies and classifies them as damage. The numerical experiments demonstrate that the OCSVM can outperform traditional support vector machines (SVMs). Further, the OCSVM is only trained on baseline data from the plate being monitored while the tradition SVM requires data from the plate being monitored and the auxiliary data, both baseline and damage conditions, from other plates.	baseline (configuration management);experiment;functional reactive programming;numerical analysis;optical fiber;piezoelectricity;spatial variability;super high material cd;support vector machine;transducer;wireless experimental centre	Stephen C. Adams;Ryan Meekins;Kevin Farinholt;Nathan Hipwell;Michael Desrosiers;Peter A. Beling	2018	2018 IEEE International Conference on Prognostics and Health Management (ICPHM)	10.1109/ICPHM.2018.8448829	support vector machine;kernel (linear algebra);kinetic energy;prognostics;control engineering;structural health monitoring;computer science;converters;transducer	Robotics	44.83797921973113	-0.8420702874649668	119387
0a229bc5d50898969a99c720808a5fbce015f1e6	research of complete loss of flow accident for ap1000 based on relap5 code		Abstract. AP1000 reactor is the typical “third-generation” nuclear power plant in the world at present. The primary system of AP1000 nuclear power plant was modeled using RELAP5/MOD 3.3 code, and the transient thermal hydraulic characteristics were analyzed under complete loss of flow accident (CLOFA). The calculation results by RELAP5 code were compared with those of the LOFTRAN codes. The research results show that the RELAP5 model can accurately simulate the transient thermal hydraulic characteristics of AP1000 under the accident of complete loss of forced reactor coolant flow. Meanwhile, comparison was made between the results of complete loss of reactor coolant flow initiated by loss of voltage and frequency reduction of offsite power, and the analysis indicates that the results of complete loss of flow initiated by complete loss of voltage bound the complete loss of flow initiated by reduction in the reactor coolant pump motor supply frequency with a frequency decay of up to 5 hertz per second.	relap5-3d	Jianping Jing;Wei Sun;Xuyang Huang;Xue-Dong Qiao	2015	J. Comput. Meth. in Science and Engineering	10.3233/JCM-150536	reliability engineering;forensic engineering;computer security	Logic	53.396958585195364	-2.5444197518161253	119597
2770c1ca168d08aba04fdc94281160a01c1155bc	three-dimensional numerical semiconductor device simulation: algorithms, architectures, results	semiconductor device simulation;iterative method;dispositif semiconducteur;estructura 3 dimensiones;semiconductor device;performance;simulacion numerica;spatial structure;semiconductor devices numerical simulation computational modeling iterative algorithms computer architecture tensile stress linear systems large scale systems equations workstations;three dimensional;structure 3 dimensions;metodo iterativo;algorithme;iterative methods;algorithm;large scale;irregular grid;transient simulations 3d numerical simulation regular grids semiconductor device simulation second three dimensional grids numerical algorithms drift diffusion equations block schemes preconditioned iterative linear solvers distinct ordering coloring techniques irregular grids;methode iterative;semiconductor device models;simulation numerique;numerical algorithm;drift diffusion;arquitectura;electronic engineering computing;semiconductor device models digital simulation electronic engineering computing iterative methods parallel algorithms;rendimiento;architecture;dispositivo semiconductor;digital simulation;numerical simulation;algoritmo;parallel algorithms	We present SECOND, a program for large-scale semiconductor device simulation with truly three-dimensional (3-D) grids. Since 3-D simulations necessitate large computing resources, the choice of algorithms and their implementation becomes of utmost importance. For that reason we have investigated the most popular numerical algorithms commonly used for the solution of the classical drift-diffusion equations. The study includes coupled and noncoupled point and block schemes, direct and preconditioned iterative linear solvers, and several distinct ordering and coloring techniques. Structures with regular and irregular grids have been analyzed. We have compared these algorithms on a variety of machines including workstations, minisupers, and supercomputers. Results of transient simulations are presented to illustrate our approach towards 3-D simulation.	algorithm;graph coloring;iteration;numerical analysis;semiconductor device modeling;simulation;supercomputer;workstation	Gernot Heiser;Claude Pommerell;Jürgen Weis;Wolfgang Fichtner	1991	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.88918	computer simulation;computational science;mathematical optimization;computer science;theoretical computer science;mathematics;iterative method;algorithm	HPC	44.41739637355377	3.8074277192892945	120509
f99480df4c6372de5b1cf4b544cb21030f84d9ef	high resolution smart image sensor with integrated parallel analog processing for multiresolution edge extraction	tratamiento paralelo;vertical science platform;high resolution;detecteur image;image processing;traitement parallele;analog processing;edge detection;procesamiento imagen;edge extraction;traitement image;deteccion contorno;detection contour;haute resolution;research paper;traitement analogique;patents;alta resolucion;tratamiento analogico;research platform;multiresolution;detector imagen;journals;researchers network;image sensor;parallel processing	Abstract   This paper presents a vision sensor which generates a multiresolution edge description using parallel analog processing support. Its multimodule architecture is based on a Multi-port Access of photo-Receptor (MAR) hexagonal sensor coupled to an external but powerful analog processing unit and a microcoded digital interface. The system supports image scanning and edge tracking. Satellite analog processing allows extensive computation using VLSI technology, leaving all the sensor area available for photo-transduction and communication pathways. It is thus possible to design a sensor with up to   500 × 500   pixels on a single CMOS chip using 1.2 μm technology. The goal of the approach described here is to exploit an imbedded edge tracing algorithm in order to generate a scene description as a list of connected edge segments. Experimental results are presented for the current prototype which implements   256×256   pixels with corresponding multiresolution edge maps.	image sensor	Marc Tremblay;Denis Laurendeau;Denis Poussart	1993	Robotics and Autonomous Systems	10.1016/0921-8890(93)90028-B	analog signal processing;parallel processing;computer vision;analog image processing;edge detection;image resolution;image processing;computer science;image sensor;computer graphics (images)	Robotics	41.74859970426204	-3.94334143560251	120653
f8d7cd00022c398933ce817e09980998f1656ce8	subband coding of speech and audio	audio coding;data compression;speech coding;time-frequency analysis;vocoders;audio compression;human auditory system;masking property;multirate filter bank;speech compression;subband audio coding;subband speech coding;time-frequency tradeoff;wideband speech coder;transform coding;speech;time frequency analysis	We discuss here the use of multirate filter banks for perceptually-weighted speech and audio compression. While our primary focus is on audio compression, we also review two recently proposed wideband speech coders that use filter banks to eliminate perceptually redundant information. Our goal is to examine and compare the time-frequency tradeoffs inherent in various coding algorithms as they try to exploit the masking properties of the human auditory system.	acoustic cryptanalysis;advanced audio coding;algorithm;backward masking;data compression;encoder;filter bank;speech coding;stationary process;sub-band coding;unsharp masking	Charles D. Creusere	1998	9th European Signal Processing Conference (EUSIPCO 1998)		data compression;voice activity detection;sub-band coding;adaptive multi-rate audio codec;codec2;g.729;linear predictive coding;speech recognition;acoustics;vector sum excited linear prediction;harmonic vector excitation coding;speech coding;speech processing;acoustic model;context-adaptive binary arithmetic coding;communication;code-excited linear prediction	HCI	47.69214967709402	-8.914094785621966	120838
6e0ae62c976f92152323937cdaaa7bd70e12df03	self-powered wireless urinary-incontinence sensor system detecting urine amount and diaper change timing in under 10 minutes		A self-powered wireless urinary-incontinence sensor system composed of a wireless sensor and a receiver has been developed that detects the amount of urine and the time for a diaper change. The wireless urinary-incontinence sensor, which consists of a urine-activated battery, an intermittent power-supply circuit with a storage capacitor, and a wireless transmitter, makes it possible to detect the number of urinations and the amount of urine from the spacing between the output signals. The urine-activated battery, which consists of two long flexible electrodes embedded in a diaper and placed under a piece of absorbent material with a trench structure, makes fast detection of less than 10 minutes possible. A prototype urinary-incontinence sensor system detected the amount of urine in a diaper from the spacing between the sensing signals with a resolution of 100 em3 and detected the time for a diaper change 7 minutes after urinations.		Hiroya Sakamoto;Ami Tanaka;Ryota Suematsu;Yo Nakajima;Takakuni Douseki	2018	2018 12th International Symposium on Medical Information and Communication Technology (ISMICT)	10.1109/ISMICT.2018.8573727		Mobile	45.17321360230936	-0.637693805108742	121089
d0dc210160230b946828be05078ddbaf6f4badfa	model-based multirate representation of speech signals and its application to recovery of missing speech packets	kalman filtering;multirate system;sequences;interpolation;pulse code modulation;state space methods;losses;filtrage kalman;signal sampling;packet loss;speech processing;kalman filters;tratamiento palabra;traitement parole;speech coding;speech processing kalman filters interpolation testing degradation interleaved codes performance evaluation phase change materials computer simulation signal to noise ratio;systeme multicadence;packet loss rate;autoregressive processes;signal representation;signal reconstruction;state space representation;spectral analysis;signal to noise ratio;sistema cadencia multiple;computer simulation;filtrado kalman;64 kbit s model based multirate representation speech signals missing speech packets recovery critically sampled speech signal aliasing state space representation autoregressive speech process sample speech sequences sample interpolation algorithm multirate kalman reconstruction filter speech quality degradation packet losses packet interleaving configuration subjective tests odd even sample interpolation procedure pcm codes computer simulations snr waveform reconstruction plots error spectral shapes informal listening tests;speech coding signal representation state space methods signal sampling autoregressive processes sequences interpolation kalman filters signal reconstruction losses pulse code modulation spectral analysis	When the samples of a critically sampled speech signal are lost, objectionable aliasing occurs and perfect recovery of the original speech becomes impossible. In this work, a multirate state-space representation of the autoregressive (AR) speech process is derived to describe the generation of regularly missingsample speech sequences. Next, a new sample-interpolation algorithm based on the multirate Kalman reconstruction filter is proposed to reduce speech quality degradation caused by packet losses. This method is used together with packet interleaving configuration, thereby simplifying the recovery of missing packets to the interpolation of missing samples. Subjective tests indicate that the proposed Kalman-based sample-interpolation algorithm performs better than the conventional odd-even sample-interpolation procedure for mitigating the effects of random packet losses in 64 kb/s PCM codes. The tolerable packet loss ratePL, which is strictly input-speech-dependent, can be as high as 10–20% with Kalman interpolation. These observations are based on computer simulations in terms of signal-to-noise ratio (SNR) values, waveform reconstruction plots, error spectral shapes, and summaries of informal listening tests.	algorithm;aliasing;autoregressive model;code;computer simulation;data rate units;elegant degradation;forward error correction;interpolation;kalman filter;network packet;reconstruction filter;signal-to-noise ratio;speech processing;state-space representation;waveform	You-Li Chen;Bor-Sen Chen	1997	IEEE Trans. Speech and Audio Processing	10.1109/89.568729	voice activity detection;computer simulation;kalman filter;speech recognition;computer science;speech processing	Networks	49.79147085297609	-8.39313514331609	121385
34fef5ba06cf420e0d1b8582d6704fb6198f6f23	dsp implementation of a distributed acoustical beamformer on a wireless sensor platform	microphones;digital signal processing;wireless sensor;least squares approximations;enhancement;built in microphone dsp implementation distributed acoustical beamformer wireless sensor platform compaq ipaq 3760s external wireless card acoustic acquisition time synchronization reference broadcast synchronization method time difference of arrivals tdoa least squares estimation maximum likelihood parameter estimation ml parameter estimation source detection enhancement localization delay steered beamforming direction of arrival estimation;reference broadcast synchronization method;digital signal processing wireless sensor networks acoustic sensors array signal processing microphones delay estimation direction of arrival estimation maximum likelihood estimation time difference of arrival maximum likelihood detection;maximum likelihood;reference broadcast synchronization;least squares estimation;localization;wireless network;built in microphone;maximum likelihood parameter estimation;acoustic signal processing;time synchronization;array signal processing;distributed acoustical beamformer;maximum likelihood estimation;wireless sensor platform;synchronisation;compaq ipaq 3760s;dsp implementation;external wireless card;delay steered beamforming;source detection;maximum likelihood detection;least squares estimate;notebook computers;acoustic acquisition;parameter estimation;acoustic sensors;time difference of arrivals;least squares approximations synchronisation notebook computers acoustic signal processing direction of arrival estimation microphones array signal processing maximum likelihood estimation;wireless sensor networks;delay estimation;ml parameter estimation;direction of arrival estimation;tdoa;time difference of arrival	In this paper, we consider the use of Compaq iPAQ 3760s, equipped with a built-in microphone and an external wireless card, for acoustic acquisition and processing to perform a distributed acoustical beamforming. Time synchronization among the microphones is achieved by the ReferenceBroadcast Synchronization method. Two beamforming algorithms, based on the time difference of arrivals (TDOAs) among the microphones followed by a least-squares estimation, and the maximum-likelihood (ML) parameter estimation method, are used to perform source detection, enhancement, localization, delay-steered beamforming, and direction-of-arrival estimation. Experimental beamforming results using the iPAQs and the wireless network are reported.	acoustic cryptanalysis;algorithm;beamforming;canonical account;direction of arrival;estimation theory;ipaq;internationalization and localization;least squares;microphone	Joe C. Chen;Len Yip;Hanbiao Wang;Daniela Maniezzo;Ralph E. Hudson;Jeremy E. Elson;Kung Yao;Deborah Estrin	2003		10.1109/ICASSP.2003.1202437	real-time computing;speech recognition;computer science;multilateration;mathematics;maximum likelihood;statistics	Mobile	50.27673833131512	3.68467800272616	122174
4db77b9815610af2c616b2d83a8734f490053883	low-power analog smart camera sensor for edge detection	clocks;cmos image sensors;computer architecture;image edge detection;grk 1773 smart camera cmos image sensor analog processing circuits analog sobel;smart cameras;algorithm design and analysis;image edge detection cmos image sensors clocks algorithm design and analysis smart cameras computer architecture	This work presents an intelligent analog image sensor system for smart camera applications with the need of edge or marker detection. The system consists of a 3×3 read-out CMOS image sensor, an analog Sobel stage and additional circuitry like operational amplifiers and comparators to compute a 1 bit image with the edges present in the taken photo. This information can then be further processed digitally to detect specific shapes in order to control robot routines, for example. The architecture of the proposed system is highly desirable as dedicated analog hardware has significant advantages in terms of power and speed compared to digital implementations. The overall system is simulated with the help of a 3×3 CMOS image sensor IC as well as Cadence Virtuoso for analog circuit simulation and MATLAB to convert the sequential information back to an image, and compared to other state of the art CMOS image sensors with edge detection capability. The analog Sobel circuit runs with a clock of 10 MHz and consumes less than 0.79 mW average power for the computation of the example image, and the whole 200×200 pixel image sensor consumes only 5.5 mW at a frame rate of 75 fps.	1-bit architecture;analogue electronics;cmos;comparator;computation;edge detection;electronic circuit simulation;image sensor;matlab;operational amplifier;smart camera;sobel operator	Christopher Soell;Lan Shi;Jürgen Röber;Marc Reichenbach;Robert Weigel;Amelie Hagelauer	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7533193	smart camera;embedded system;algorithm design;computer vision;analog image processing;image processing;computer science;digital image processing;image sensor;cmos sensor;visual sensor network	Robotics	40.63333091848359	-3.3165007946172653	122314
31e526b51d853a2d27930d09184c78befb26b8ae	design a current-mode max/min circuit in cmos technology	cmos integrated circuits;size 0 35 mum current mode max min circuit design bidirectional current mode circuit multiple input min max circuit tsmc 2p4m cmos technology vlsi implementation neural network systems single circuit design circuit complexity morphological operations;neural nets;vlsi circuit complexity cmos integrated circuits integrated circuit design neural nets;morphological min max current mode;circuit complexity;integrated circuit design;vlsi;cmos integrated circuits cmos technology	The multiple-Input Min/Max Circuit with bi-directional current-mode circuit is proposed and fabricated. In the circuit design, Max Circuit and Min circuit are all single-circuit design previously. The multiple signals input to the Min and Max Circuit has been processed to produce the Max and Min Current, respectively. The integrated structure of current-mode Min/Max is designed in CMOS circuits to reduce the area of chip that the circuit complexity is improved. The circuit has capability to operate the Min/Max morphological operations. The simulation results show that Min/Max Circuit is successfully verified by the TSMC 0.35μm 2P4M CMOS technology. There have a great potential in the VLSI implementation used in the neural network systems to processing various applications.	artificial neural network;cmos;circuit complexity;circuit design;mathematical morphology;multistage interconnection networks;simulation;very-large-scale integration	Kuo-Hung Liao;Jui-Lin Lai;Wan-Cing Wang;Rong-Jian Chen	2013	2013 6th IEEE/International Conference on Advanced Infocomm Technology (ICAIT)	10.1109/ICAIT.2013.6621491	electronic engineering;real-time computing;computer science;diode-or circuit;discrete circuit;computer engineering	EDA	39.42409051927077	-2.307043828669234	122397
c06156be86bcb475ac2dbd93dabaecd56bd132ec	solving the chemical master equation by aggregation and krylov approximations	chemicals;tensile stress;approximation algorithms;analog digital conversion;error correction;mathematical model;markov processes	The chemical master equation (CME) is often difficult to solve directly due to the curse of dimensionality. Aggregation was among the earliest ideas for addressing this challenge. It consists in coarsening the state space of the CME to make it more tractable. This reduction inevitably introduces a numerical error that is not trivial to account for, consequently only a few implementations deal with the estimation and control of this aggregation error. Here, we implement an error control by using an adaptive aggregation strategy and the concept of defect (or residual) in the numerical solution of ordinary differential equations. We embed the aggregation approach in the step-by-step matrix exponential implementation of Expokit that uses Krylov subspace approximations. We conduct numerical experiments on test problems that model the toggle switch, receptor oligomerization, and repressilator. This work is an important step toward solving problems that arise in the stochastic modeling of larger biological networks.	adaptive filter;analysis of algorithms;approximation;biological network;cobham's thesis;computation;curse of dimensionality;error detection and correction;experiment;gene regulatory network;krylov subspace;krylov–bogolyubov theorem;numerical analysis;numerical error;numerical methods for ordinary differential equations;numerical partial differential equations;refinement (computing);repressilator;software bug;state space;stepping level;stochastic modelling (insurance);switch;time complexity;vii	Huy D. Vo;Roger B. Sidje	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7799362	mathematical optimization;chemical industry;discrete mathematics;error detection and correction;computer science;theoretical computer science;mathematical model;control theory;mathematics;markov process;stress;approximation algorithm;statistics	Robotics	50.21965612028828	-1.0080581229114203	122683
8c369a6bee41c2bfb6724621275a1f8f850e94e0	design of an architecture for real-time 3d pet imaging	tratamiento paralelo;representation tridimensionnelle;architecture systeme;image processing;traitement parallele;integrated circuit;concepcion sistema;implementation;real time;pet imaging;circuit vlsi;procesamiento imagen;circuito integrado;tomocentelleografia;traitement image;three dimensional;positron emission tomography;ejecucion;reconstruction image;vlsi circuit;emisor positron;reconstruccion imagen;system design;image reconstruction;mappage;scanner data;emission tomography;temps reel;tiempo real;arquitectura sistema;three dimensional representation;mapping;circuito vlsi;reconstruction algorithm;system architecture;emetteur positon;conception systeme;representacion tridimensional;parallel processing;tomoscintigraphie;circuit integre;positron emitter	A major obstacle to the three dimensional approach in Positron Emission Tomography is the time required to compute the reconstruction. The bulk of computations for no matter which algorithm is chosen is backprojection. This paper describes a possible architecture capable of supporting the scanner data rate while performing backprojection on an event by event basis. The architecture matches an event by event algorithm that allows to exploit parallelism and pipelining to reduce the computational burden ; it appears extremely suitable for Backprojection Fil tering reconstruction algorithms. To appear on Journal of Real-Time Imaging, 1998. ∗ Work supported in part by the Italian National Research Council (CNR) under grant n.94.00625.CT11	algorithm;computation;parallel computing;pipeline (computing);polyethylene terephthalate;real-time transcription;tomography;uncompressed video	Eugenio Di Sciascio;Anna R. Manni;Riccardo Guzzardi	1998	Real-Time Imaging	10.1006/rtim.1997.0088	iterative reconstruction;three-dimensional space;parallel processing;computer vision;image processing;computer science;electrical engineering;integrated circuit;implementation;systems design;computer graphics (images)	Robotics	41.76683333422401	-3.9379433793675624	122686
17b19e22409b0a0a3b75be29f4c97887f88437c4	mission profile resolution impacts on the thermal stress and reliability of power devices in pv inverters		Abstract The operating conditions and reliability of Photovoltaic (PV) inverters are strongly affected by their mission profile. Since the mission profile of the PV system can vary considerably, the time-resolution of the mission profile becomes an important factor in the reliability prediction. In this paper, the impacts of mission profile resolutions on the reliability of the PV inverters are investigated. The results indicate that the mission profile resolution can deviate the reliability prediction considerably, especially during the fluctuating solar irradiance condition, and care must be taken during the reliability assessment.	inverter (logic gate);power inverter;power semiconductor device	Ariya Sangwongwanich;Dengji Zhou;Elizaveta Liivik;Frede Blaabjerg	2018	Microelectronics Reliability	10.1016/j.microrel.2018.06.094	solar irradiance;electronic engineering;engineering;reliability engineering;power semiconductor device;photovoltaic system	Arch	53.2288157547317	-2.0655926646937406	122762
3bd0399936a4d3062f5c5148cc803c330ca1dd98	observer design for a class of multi-input multi-output nonlinear systems	observer design;lyapunov function;canonical form;state observer;multi input multi output;nonlinear systems;nonlinear system;coordinate change	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;nonlinear system;primary source	YaLi Dong;Yingjuan Yang	2011	Int. J. Systems Science	10.1080/00207720903260143	control engineering;canonical form;mathematical optimization;nonlinear system;lyapunov function;control theory;mathematics;state observer;separation principle;alpha beta filter	Robotics	50.784031640848774	-3.3724895380994075	123361
54922e1a230c3d1b202c7a5f481a7eff267f456c	a smart error protection scheme based on estimation of perceived speech quality for portable digital speech streaming systems	perceived speech quality;portable digital speech streaming systems;redundant speech transmission.;packet loss;error protection	  In this paper, a smart error protection (SEP) scheme is proposed to improve speech quality of a portable digital speech streaming  (PDSS) system via a lossy transmission channel. To this end, the proposed SEP scheme estimates the perceived speech quality  (PSQ) for received speech data, and then transmits redundant speech data (RSD) in order to assist speech decoder to reconstruct  lost speech signals for high packet loss rates. According to the estimated PSQ, the proposed SEP scheme controls the RSD transmission,  and then optimizes a bitrate of speech coding to encode the current speech data (CSD) against the amount of RSD without increasing  transmission bandwidth. The effectiveness of the proposed SEP scheme is finally demonstrated using adaptive multirate-narrowband  (AMR-NB) and ITU-T Recommendation P.563 as a scalable speech codec and a PSQ estimator, respectively. It is shown from experiments  that a PDSS system employing the proposed SEP scheme significantly improves speech quality under packet loss conditions.    		Jin Ah Kang;Hong Kook Kim	2011		10.1007/978-3-642-20998-7_1	voice activity detection;speech recognition;computer science;speech coding;multimedia	EDA	48.60582646875951	-8.627390075266549	123747
a0594a491fb9301014c44a772a672d9343884c90	vlsi bio-inspired microsystem for robust microarrray image analysis and recognition	image recognition;very large scale integration robustness image analysis image recognition artificial neural networks fluorescence transfer functions pattern recognition signal design circuits;learning algorithm;fluorescence;transfer functions;very large scale integration;signal design;real time;chip;artificial neural networks;transfer function;pattern recognition;robustness;image analysis;circuits;artificial neural network	A VLSI bio-inspired microsystem for real-time, on-site, robust image analysis and recognition has been developed. A corresponding novel artificial neural network (ANN) learning algorithm using new sigmoid-logarithmic transfer function is invented. Our results show the trained new ANN can recognize low fluorescence patterns better than the conventional sigmoidal ANN does. A differential logarithmic imaging chip is designed for calculating logarithm of relative intensities of fluorescence signals. The single-rail logarithmic circuit and a prototype ANN chip are designed, fabricated and characterized.	algorithm;artificial neural network;british informatics olympiad;image analysis;prototype;real-time clock;sigmoid function;transfer function;very-large-scale integration	Wai-Chi Fang;Jaw-Chyng L. Lue	2006	2006 International Conference on Intelligent Information Hiding and Multimedia	10.1109/IIH-MSP.2006.171	computer vision;computer science;artificial intelligence;machine learning;transfer function;artificial neural network	Robotics	39.70478479344098	-2.3216779884857766	124542
0fbfb75b45f0ba836459b5d087a3af1941e38b83	a diffraction tomography method for medical imaging implementation on high performance computing environment	analisis imagen;algoritmo paralelo;medical imagery;parallel algorithm;shared memory;image processing;non linear optimization;inverse scattering problem;procesamiento imagen;traitement image;algorithme parallele;reconstruction image;medical image;efficient implementation;reconstruccion imagen;image reconstruction;tomographie;high performance computer;imagerie medicale;image analysis;imageneria medical;tomografia;analyse image;tomography	The efficient implementation of a diffraction tomography method for medical imaging is addressed within the framework of High Performance Computing (HPC) environment. A non-linear optimization method for the solution of the inverse scattering problem is implemented on a shared memory model computer. Linear speed-up and significant reduction in the total execution time is achieved when the program is executed in parallel, enabling the feasibility of the method for realistic medical imaging applications.	medical imaging;tomography	Theofanis A. Maniatis;Konstantina S. Nikita;K. Voliotis	1999		10.1007/BFb0100579	iterative reconstruction;shared memory;computer vision;simulation;computer science;inverse scattering problem;parallel algorithm;tomography;computer graphics (images)	HPC	44.052639108577075	3.285140984411667	124804
7242b87858893f3c326cc64ad92b7b1ba4689c43	a class-oriented replacement technique for lost speech	speech intelligibility;speech signal processing algorithms delay decoding table lookup random number generation permission acoustic signal processing encoding acoustic testing;packet switching;speech analysis and processing;subjective quality lost speech packets replacement packet switching packets classification speech analysis speech processing speech quality class oriented replacement encoding subjective tests;speech intelligibility encoding packet switching speech analysis and processing;encoding	A replacement technique for lost speech packets is presented. This technique is based on the classification of the packets into four distinct classes. Different encoding schemes and lost packet replacement techniques are used for each class. Results of subjective tests indicate that giving preferential delivery treatment to packets based on class can improve subjective quality. >		Luiz A. DaSilva;David W. Petr;Victor S. Frost	1989	IEEE Trans. Acoustics, Speech, and Signal Processing	10.1109/29.35400	voice activity detection;linear predictive coding;speech recognition;acoustics;computer science;speech processing;psqm;intelligibility;packet switching;encoding	Arch	49.24902051229528	-8.758986518458633	124872
43b51cc2afb66cc08fe3917d1227fd1360074003	mesoscopic-level simulation of dynamics and interactions of biological molecules using monte carlo simulation	field programmable gate array;enzyme;signal transduction pathway;fpga;random walk;signal transduction pathways;3 dimensional;monte carlo simulation;high performance;process migration;reconfigurable hardware	A mesoscopic-level method for clarifying living cell dynamics is described that uses Monte Carlo simulation of biological molecule interactions. The molecules are described as particles that take a random walk in 3-dimensional discrete space. Many kinds of molecules (including complex forms) are supported, so complex reactions with enzymes can be simulated. Also described is an field programmable gate array system with reconfigurable hardware that that will support complete modeling of an entire cell. Two-phase processing (migration and reaction) is used to simulate the complex reactions, so the method can be implemented in a limited amount of hardware. The migration and reaction circuits are deeply pipelined, resulting in high performance. Estimated performance is 30 times faster than with a 3.2-GHz Pentium 4 computer. This approach should make it possible to eventually simulate cell interactions involving one billion particles.	interaction;mesoscopic physics;monte carlo method;simulation	Yoshiki Yamaguchi;Tsutomu Maruyama;Ryuzo Azuma;Moritoshi Yasunaga;Akihiko Konagaya	2007	VLSI Signal Processing	10.1007/s11265-007-0072-7	parallel computing;simulation;computer science;theoretical computer science;signal transduction;field-programmable gate array;statistics	HPC	42.85282743439391	1.579703604142939	125462
848e288386248527e25c2370b785355d01682a9f	a 2.4 kbps variable bit rate adp-celp speech coder	adp celp speech coder;background noise;plural subframes;interpolation;code excited linear prediction;speech non speech classification method;speech quality improvement;working environment noise;spectral analysis vocoders linear predictive coding speech coding vector quantisation variable rate codes;pitch lag coding technique;spectrum envelope variation;speech coding;testing;spectrum;code standards;bit rate;consecutive frame pitch lags;variable rate codes;linear predictive coding;variable bit rate speech coder;relative pitch lags;vocoders;variable bit rate;2 4 kbit s;robustness;adaptive density pulse code excited linear prediction;entropy;relative pitch vector quantisation;spectral analysis;subjective testing;vector quantisation;oral communication;bit rate speech coding working environment noise testing linear predictive coding laboratories robustness code standards entropy oral communication;average bit rate reduction;2 4 kbit s variable bit rate speech coder adp celp speech coder adaptive density pulse code excited linear prediction short time speech characteristics speech quality improvement average bit rate reduction speech non speech classification method spectrum envelope variation background noise pitch lag coding technique interpolation consecutive frame pitch lags relative pitch vector quantisation relative pitch lags estimated pitch lag target pitch lag plural subframes subjective testing;estimated pitch lag;target pitch lag;short time speech characteristics	This paper presents a variable bit rate ADP-CELP (Adaptive Density Pulse Code Excited Linear Prediction) coder that selects one of four kinds of coding structure in each frame based on short time speech characteristics. To improve speech quality and reduce the average bit rate, we have developed a speech/non-speech classification method using spectrum envelope variation, which is robust for background noise. In addition, we propose an efficient pitch lag coding technique. The technique interpolates consecutive frame pitch lags and quantizes a vector of relative pitch lags consisting of variation between an estimated pitch lag and a target pitch lag in plural subframes. The average bit rate of the proposed coder was approximately 2.4 kbps for speech sources with activity factor of 60%. Our subjective testing indicates the quality of the propcsed coder exceeds that of the Japanese digital cellular standard with rate of 3.45 kbps.	code-excited linear prediction;data rate units;interpolation;pitch (music);speech coding;usb on-the-go	Masahiro Oshikiri;Masami Akamine	1998		10.1109/ICASSP.1998.674481	spectrum;entropy;linear predictive coding;speech recognition;harmonic vector excitation coding;interpolation;computer science;speech coding;background noise;software testing;variable bitrate;robustness;code-excited linear prediction	ML	48.21152283897435	-8.197839319890127	125706
352c636ba39088cb53364e42ed36d4177f13550c	robust vector quantization for low bit rate speech coding.	speech coding;vector quantizer	Speech coding systems for mobile communication have to cope with noisy channels. In particular, vector quantization as central data reduction scheme is highly sensitive to transmission errors due to the low redundancy in the encoded data. Here we present three methods for the design of a vector quantizer with enhanced robustness against transmission errors. First the optimization of the index assignment of a LBG vector quantizer via simulated annealing is investigated. Second a neighborhood conserving vector quantizer is designed by using a topology conserving feature map. Third we discuss a method in which the error characteristic of the channel is used in the optimization of a vector quantizer as well as in the quantization of a data vector. Simulation experiments and results for a binary symmetric channel with bit error probabilities up to 10% are presented for vector quantization of speech signals and predic-tor parameters.	binary symmetric channel;bit error rate;data point;experiment;mathematical optimization;quantization (signal processing);simulated annealing;simulation;speech coding;tor messenger;vector quantization	Ulrich Balss;Herbert Reininger;Holger Schalk;Dietrich Wolf	1995			codec2;linear predictive coding;shannon–fano coding;quantization;vector sum excited linear prediction;harmonic vector excitation coding;speech coding;vector quantization;code-excited linear prediction	ML	48.27045138554097	-9.849116717856385	126003
ed9b8027f3cf54f6bbd6ddbe0ed09764da5d8020	parameterized modelling and dynamic analyzing for the drive at centre of gravity (dcg) feed drives	dcg;dynamic characteristics;feed drives;parameterized modelling;centre of gravity	A statistical multiplexing apparatus for permanently recording a plurality of video signals on a video generator so that video programs represented by the video signals can be repeatedly broadcast is provided with a video analyzer for analyzing a first video signal and a second video signal and generating a first compression signal and a second compression signal, a first video encoder for encoding the first video signal at a variable rate determined by the first compression signal to form a first encoded video signal, a second video encoder for encoding the second video signal at a variable rate determined by the second compression signal to form a second encoded video signal, and a video generator for permanently recording the first and second encoded video signals so that the first and second encoded video signals can be repeatedly broadcast from the video generator.	definite clause grammar	Fangyu Peng;Yimin Zhou;Bin Li	2009	I. J. Robotics and Automation		center of mass;encoder;statistical time division multiplexing;encoding (memory);spectrum analyzer;control engineering;engineering;parameterized complexity;broadcasting	Robotics	47.35600867552498	-7.452409220264455	126102
f2b6e8fc1f37cc3c63ece410df139bbe0bb40735	optimum decoder for multiplicative spread spectrum image watermarking with laplacian modeling		This paper investigates the multiplicative spread spectrum watermarking method for the image. The information bit is spreaded into middle-frequency Discrete Cosine Transform (DCT) coefficients of each block of an image using a generated pseudo-random sequence. Unlike the conventional signal modeling, we suppose that both signal and noise are distributed with Laplacian distribution because the sample loss of digital media can be better modeled with this distribution than the Gaussian one. We derive the optimum decoder for the proposed embedding method thanks to the maximum likelihood decoding scheme. We also analyze our watermarking system in the presence of noise and provide analytical evaluations and several simulations. The results show that it has the suitable performance and transparency required for watermarking applications.	coefficient;decoding methods;digital media;digital watermarking;discrete cosine transform;pseudorandomness;signal-to-noise ratio;simulation;watermark (data file);x.690	Nematollah Zarmehi;Mohammad Reza Aref	2017	CoRR		mathematical optimization;discrete mathematics;digital watermarking;computer science;theoretical computer science;laplace distribution;mathematics;statistics	ML	41.91974475074105	-9.60704801760462	126190
ef8b63ae7797f14b82e90b5573c97d1848640251	gaussian noise filtering from ecg by wiener filter and ensemble empirical mode decomposition	gaussian noise;ecg;performance indicator;ensemble empirical mode decomposition;gaussian white noise;intrinsic mode function;mean square error;noise reduction;wiener filter;arrhythmia;empirical mode decomposition	Empirical mode decomposition (EMD) is a powerful algorithm that decomposes signals as a set of intrinsic mode function (IMF) based on the signal complexity. In this study, partial reconstruction of IMF acting as a filter was used for noise reduction in ECG. An improved algorithm, ensemble EMD (EEMD), was used for the first time to improve the noise-filtering performance, based on the mode-mixing reduction between near IMF scales. Both standard ECG templates derived from simulator and Arrhythmia ECG database were used as ECG signal, while Gaussian white noise was used as noise source. Mean square error (MSE) between the reconstructed ECG and original ECG was used as the filter performance indicator. FIR Wiener filter was also used to compare the filtering performance with EEMD. Experimental result showed that EEMD had better noise-filtering performance than EMD and FIR Wiener filter. The average MSE ratios of EEMD to EMD and FIR Wiener filter were 0.71 and 0.61, respectively. Thus, this study investigated an ECG noise-filtering procedure based on EEMD. Also, the optimal added noise power and trial number for EEMD was also examined.	algorithm;error detection and correction;finite impulse response;hilbert–huang transform;iteration;mean squared error;multicanonical ensemble;noise generator;noise power;noise reduction;white noise;wiener filter	Kang-Ming Chang;Shing-Hong Liu	2011	Signal Processing Systems	10.1007/s11265-009-0447-z	gaussian noise;computer vision;speech recognition;computer science;hilbert–huang transform;performance indicator;pattern recognition;noise reduction;mean squared error;white noise;wiener filter;statistics	EDA	45.026509387745236	-8.751906317051834	126416
5e0c0e1bb245f2bcf500c21241e7f4562e9576d5	plastic waste cycle biomimicry of natural nutrient cycle — an integrated technology case study		The effective combination of technologies working as a unit to cause the human plastic cycle to mimic the natural nutrient cycle is the research focus of this case study. Many studies in various disciplines have focused on the diverse problems that plastic waste causes to humans and the environment. The existence of an effective combination of technologies working as a unit to produce oil from plastic waste products that does not require grid-based electricity, is transportable and burns clean with near-zero toxic emissions, that enables the Human Plastic Cycle to mimic the Natural Nutrient Cycle is investigated. Proven models were simulated, verified and adapted to a unique set of conditions and interviews were conducted with industrial stakeholders, government agencies and technology developers to strengthen the quantitative and qualitative methods used to analyze this nonlinear challenge. The unique mix of technologies in this proposed system enables itself to be adaptable to various regional environmental conditions and still mimic the natural waste cycle. The key challenges were internal, continuous, stable heat and electricity production as well as biological composting. However, identifying the most appropriate choice of renewable energy sources will be key to optimizing this biomimicry process in diverse conditions.	biomimetics;mathematical model;nonlinear system;nutrient cycle	Keegan G. Clarke;Christiaan Mouton	2016	2016 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2016.7857368	environmental engineering;engineering;operations management;waste management	HCI	52.587244490205336	-8.820514596661257	126629
826276791cc7e528c3312f410fdb9b15842f746f	a field programmable gate array-based reconfigurable smart-sensor network for wireless monitoring of new generation computer numerically controlled machines	software;field programmable gate array;computer communication networks;fpga;smart sensor;wireless sensor network;signal processing computer assisted;monitoring ambulatory;equipment design;cnc monitoring;reproducibility of results;computer numerically controlled;artificial intelligence;wireless technology;smart sensors	Computer numerically controlled (CNC) machines have evolved to adapt to increasing technological and industrial requirements. To cover these needs, new generation machines have to perform monitoring strategies by incorporating multiple sensors. Since in most of applications the online Processing of the variables is essential, the use of smart sensors is necessary. The contribution of this work is the development of a wireless network platform of reconfigurable smart sensors for CNC machine applications complying with the measurement requirements of new generation CNC machines. Four different smart sensors are put under test in the network and their corresponding signal processing techniques are implemented in a Field Programmable Gate Array (FPGA)-based sensor node.	computer peripherals;decision making;field-programmable gate array;node - plant part;numerical analysis;numerical integration;online and offline;protein array analysis;requirement;satisfaction;sensor node;signal processing;smart transducer;symantec endpoint protection;video post-processing;sensor (device)	Sandra V. Moreno-Tapia;Luis A. Vera-Salas;Roque Alfredo Osornio-Rios;Aurelio Dominguez-Gonzalez;Ion Stiharu;René de Jesús Romero-Troncoso	2010		10.3390/s100807263	embedded system;electronic engineering;computer science;engineering;field-programmable gate array;computer engineering	Embedded	46.61483490482593	-1.0477565367991133	127651
8635aa9d7478af57314687bd7f9caed2226d04d5	optimality conditions for discrete optimal control problems	second order;discrete optimization;optimality conditions;control problem;mathematical programming;discrete optimal control;necessary optimality condition;optimality condition;2 regularity	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.		Boban Marinkovic	2007	Optimization Methods and Software	10.1080/10556780701485314	discrete optimization;mathematical optimization;combinatorics;discrete mathematics;mathematics;second-order logic	Robotics	49.66855252840181	-2.9864869526489564	128372
3da42ccd66e0aa9d52508ae5a3cf12b61237579b	quantization of sew and rew magnitude for 2 kb/s waveform interpolation speech coding	interpolation;matrix algebra vector quantisation discrete cosine transforms interpolation speech coding transform coding;interpolation speech coding bit rate discrete cosine transforms speech processing signal processing vector quantization shape decoding low pass filters;speech coding;spectrum;transform coding;matrix algebra;discrete cosine transforms;predictive vector quantization;vector quantisation;2 kbit s predictive vector quantization slowly evolving waveform magnitude spectra rapidly evolving waveform magnitude spectra waveform interpolation speech coding dct matrix quantizer combined dimension conversion method	The paper presents quantization schemes for the magnitude spectra of the slowly evolving waveform (SEW) and rapidly evolving waveform (REW) components in a 2 kb/s waveform interpolation (WI) coder. The SEW magnitude spectrum is quantized using a DCT-based predictive vector quantization approach. The REW magnitude spectrum is quantized using a matrix quantizer based on the combined dimension conversion method. Objective measures and subjective results indicate that the proposed quantization schemes are effective in achieving good quantization accuracy.	data rate units;discrete cosine transform;quantization (signal processing);speech coding;vector quantization;waveform;whittaker–shannon interpolation formula	Jing Li;Changchun Bao	2004	2004 International Symposium on Chinese Spoken Language Processing	10.1109/CHINSL.2004.1409606	spectrum;discrete mathematics;transform coding;speech recognition;quantization;harmonic vector excitation coding;interpolation;computer science;speech coding;mathematics;vector quantization;statistics	Arch	48.02890829352878	-9.146901385989814	128691
4b658e3592834c9b19d6e87f50efcd58e4f17d0b	split-band ld-celp wideband speech coding at 24 kbit/s	wideband speech coding speech noise standards delays;wideband;standards;speech;speech coding;delays;noise	Nowaday 7 Khz wideband speech coding requires at least 48 kbit/s as it still depends on the ITU standard G.722. CELP coders have been developed for wideband systems achieving high quality speech coding at rates from 16 kbit/s to 32 kbit/s as the wideband LD-CELP at 32 kbit/s. In this paper, a new split-band LD-CELP wideband coder at 24 kbit/s is proposed and its performance and complexity are compared with those of the already known wideband LD-CELP.	aac-ld;code-excited linear prediction;data rate units;display resolution;g.722;speech coding	Andrea Santilli;Aurelio Uncini;Francesco Piazza	1996	1996 8th European Signal Processing Conference (EUSIPCO 1996)	10.5281/zenodo.36285	voice activity detection;adaptive multi-rate audio codec;electronic engineering;g.729;speech recognition;full rate;acoustics;harmonic vector excitation coding	HPC	48.04147614702072	-8.359029563474682	128710
f8bd5cb6f676b9b3857151636eb95e641660ee98	a decentralized gauss-seidel approach for in-network sparse signal recovery	regularized least squares;least squares approximations;convergence;sensors;gaussian processes wireless sensor networks sensor phenomena and characterization monitoring large scale systems least squares methods signal processing algorithms signal processing robustness scalability;limiting;structural health monitoring decentralized gauss seidel approach in network sparse signal recovery wireless sensor network robustness l l regularized least squares formulation;sparse signal recovery;decentralized gauss seidel approach;noise measurement;wireless sensor network;iterative methods;large scale;in network sparse signal recovery;monitoring;theoretical analysis;signal processing;in network signal processing;robustness;structural health monitoring;decentralized gauss seidel approach wireless sensor networks sparse signal recovery in network signal processing;gauss seidel;wireless sensor networks iterative methods least squares approximations signal processing;l l regularized least squares formulation;wireless sensor networks;noise;signal recovery	This paper addresses the problem of monitoring and discovering abnormalities in sensing fields with large-scale wireless sensor networks. By exploiting the sparsity of abnormalities, the signal recovery problem is expressed as an l-l regularized least squares formulation with nonnegative constraints. Furthermore, a decentralized Gauss-Seidel approach is proposed for in-network signal processing. Comparing with its centralized counterpart, the decentralized algorithm improves the robustness and scalability of a large-scale network. Parameter settings of the l-l regularized least squares formulation are studied via theoretical analysis and extensive simulations. An illustrative example of structural health monitoring demonstrates the effectiveness of the proposed decentralized sparse signal recovery algorithm in practical applications.	algorithm;centralized computing;column (database);compressed sensing;detection theory;displacement mapping;elegant degradation;gauss–seidel method;image resolution;least squares;non-negative least squares;rate of convergence;sampling (signal processing);scalability;sensor;signal processing;simulation;sparse matrix	Qing Ling;Zhi Tian	2009	2009 12th International Conference on Information Fusion		mathematical optimization;computer science;theoretical computer science;machine learning	Robotics	52.26700926075916	2.5978646386745496	128906
09778ce77a009d3a07d2933be4427b9ce3cedafd	a compact memristor-based dynamic synapse for spiking neural networks	neurons memristors biological neural networks random access memory neuromorphics integrated circuit modeling	Recent advances in memristor technology lead to the feasibility of large-scale neuromorphic systems by leveraging the similarity between memristor devices and synapses. For instance, memristor cross-point arrays can realize dense synapse network among hundreds of neuron circuits, which is not affordable for traditional implementations. However, little progress was made in synapse designs that support both static and dynamic synaptic properties. In addition, many neuron circuits require signals in specific pulse shape, limiting the scale of system implementation. Last but not least, a bottom-up study starting from realistic memristor devices is still missing in the current research of memristor-based neuromorphic systems. Here, we propose a memristor-based dynamic (MD) synapse design with experiment-calibrated memristor models. The structure obtains both static and dynamic synaptic properties by using one memristor for weight storage and the other as a selector. We overcame the device nonlinearities and demonstrated spike-timing-based recall, weight tunability, and spike-timing-based learning functions on MD synapse. Furthermore, a temporal pattern learning application was investigated to evaluate the use of MD synapses in spiking neural networks, under both spike-timing-dependent plasticity and remote supervised method learning rules.	artificial neural network;bottom-up parsing;experiment;gnu nano;learning rule;memristor;molecular dynamics;neuromorphic engineering;neuron;simulation;spiking neural network;synapse	Miao Hu;Yiran Chen;Jianhua Joshua Yang;Yu Wang;Hai Li	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2016.2618866	synapse;electronic engineering;memristor;theoretical computer science;electronic circuit;computer science;memistor;spiking neural network;physical neural network;limiting;machine learning;neuromorphic engineering;artificial intelligence	EDA	39.193909906307674	-0.8046798736093059	129978
15d11121a21b97892af58762d51f24901de74129	hidden markov model-based 3d path-matching using raytracing-generated wi-fi models	probability;indoor communication;hidden markov models;structural engineering;hmm based algorithm hidden markov model based 3d path matching raytracing generated wi fi models probabilistic 3d indoor path matching indoor localization wi fi signal measurements hidden markov model based algorithms hmm algorithms 3d model building high resolution emission probability transition probability wi fi signal propagations generated signal strength values geometric information;ray tracing;hidden markov models computational modeling ieee 802 11 standards solid modeling radio propagation accuracy signal resolution;wireless lan;solid modelling;wireless lan hidden markov models indoor communication probability ray tracing solid modelling structural engineering	We propose an efficient approach to probabilistic 3D indoor path-matching and localization based on Wi-Fi-signal measurements using Hidden Markov Model-based (HMM) algorithms. Given a 3D model of the building, we derive high-resolution emission probabilities and transition probabilities from raytracing-generated Wi-Fi signal propagations. Therefore we use both the generated signal-strength values and the geometric information of the 3D model. Based on the emission and transition probabilities and a sequence of Wi-Fi signal measurements provided by the client, the HMM-based algorithm computes the most probable path through the building.	3d modeling;airplane mode;algorithm;commodity computing;fingerprint (computing);hidden markov model;image resolution;internationalization and localization;level of detail;markov chain;mathematical optimization;online and offline;pf (firewall);ray tracing (graphics);real-time clock;software deployment;software propagation;state space;synthetic data;viterbi decoder	Nicolai Viol;Jó Ágila Bitsch Link;Hanno Wirtz;Dirk Rothe;Klaus Wehrle	2012	2012 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2012.6418873	forward algorithm;maximum-entropy markov model;speech recognition;telecommunications;viterbi algorithm;computer science;machine learning;markov model;hidden markov model;variable-order markov model	Robotics	48.07969400393328	1.1546180978642848	130543
e8a1517cdd746f6178098ff9929c56d846682220	pre-processing and vector quantization based approach for cfa data compression in wireless endoscopy capsule	vector quantisation biomedical optical imaging endoscopes image coding image reconstruction low pass filters medical image processing statistical analysis;image coding;wireless endoscopy capsule;data compression;jpeg ls compression;lossy compression;reconstruction quality;code mapping;reconstruction quality data preprocessing vector quantization data compression color filter array wireless endoscopy capsule low complexity compression bayer cfa data low pass filtering block partition code mapping entropy compression jpeg ls compression near lossless compression lossy compression statistical experiments;low complexity;low pass filter;entropy compression;statistical experiments;vector quantization;statistical analysis;bayer cfa data;block partition;image reconstruction;medical image processing;low pass filtering;human body;vector quantization data compression endoscopes image coding entropy image reconstruction sensor arrays low pass filters encoding wireless sensor networks;color filter array;near lossless compression;endoscopes;low pass filters;vector quantizer;entropy;low power design;quality index;biomedical optical imaging;digestive tract;vector quantisation;encoding;data preprocessing;low complexity compression;wireless sensor networks;image sensor;sensor arrays	In wireless endoscopy capsule, an efficient, low-complexity compression approach for Bayer CFA data is critical for the low power design of the entire system. In this paper, a compression approach based on pre-processing and vector quantization is proposed. The CFA raw data are first low pass filtered during pre-processing. Then, pairs of pixels are vector quantized into macros of 9 bits by applying block partition and code mapping in succession. After rearranging, these macros are entropy compressed by JPEG-LS. By control of the pre-processor, both near-lossless and lossy compression can be realized. The effectiveness of our block partition scheme has been demonstrated by statistical experiments. Simulation results show that the proposed approach has a good performance in compression rate as well as reconstructed quality	bayer filter;data compression;experiment;lossless compression;lossy compression;pixel;preprocessor;quantization (signal processing);simulation;succession;vector quantization	Xiaowen Li;Xinkai Chen;Xiang Xie;Guolin Li;Lei Zhang;Zhihua Wang	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.357066	data compression;color cell compression;computer vision;data compression ratio;low-pass filter;computer science;theoretical computer science;lossless compression;vector quantization;statistics	Embedded	44.6148586083826	-7.48126021494445	130808
ff6b6650bb48189a90cb62b568a1c995be4ced00	audio watermarking: a way to stationnarize audio signals	audio coding;embedded systems;meta data;statistical analysis;time-frequency analysis;watermarking;artificial signal;audio processing system;audio watermarking;embed metadata;multimedia copyright protection;perceptual watermarking;piecewise stationary;stationarity indices;stationnarize audio signal;statistical characteristic;time-frequency representation;time-variant signal statistic;perceptual audio watermarking;stationarity indices;time-frequency representations	Audio watermarking is usually used as a multimedia copyright protection tool or as a system that embed metadata in audio signals. In this paper, watermarking is viewed as a preprocessing step for further audio processing systems: the watermark signal conveys no information, rather it is used to modify the statistical characteristics of an audio signal, in particular its nonstationarity. The embedded watermark is then added in order to stationnarize the host signal. Indeed, the embedded watermark is piecewise stationary, thus it modifies the stationarity of the original audio signal. In some audio processing fields, this fact can be used to improve performances that are very sensitive to time-variant signal statistics. This work presents an analysis of the perceptual watermarking impact on the stationarity of audio signals. The study is based on stationarity indices, which represent a measure of variations in spectral characteristics of signals, using time-frequency representations. Simulation results with two kinds of signals, artificial signals and audio signals (speech and music), are presented. Stationarity indices comparison between watermarked and original audio signals shows a significant stationarity enhancement of the watermarked signal, especially for transient attacks.	audio signal processing;digital watermarking;embedded system;microsoft windows;performance;preprocessor;self-information;simulation;sound card;stationary process	Sonia Djaziri Larbi;Meriem Jaïdane	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2004.839899(410)53	speech recognition;time–frequency analysis;sample rate conversion;aes11;telecommunications;audio signal processing;digital watermarking;computer science;digital signal processing;speech coding;time–frequency representation;sound quality;multimedia;audio signal flow;metadata	EDA	43.58026673485151	-8.727435760504488	131020
369526b80745004aac8b9735192c62176d091413	perceptual audio watermarking by learning in wavelet domain	watermarking;learning;support vector machines;data embedding;wavelet transforms;audio coding;wavelet transforms audio coding learning artificial intelligence support vector machines watermarking;svm based decoding;svm based decoding perceptual audio watermarking learning wavelet domain;learning artificial intelligence;wavelet domain;perceptual audio watermarking;decision rule;watermarking wavelet domain decoding testing robustness correlators data mining supervised learning support vector machines support vector machine classification;audio watermarking	Conventional blind watermark (WM) decoding schemes use correlation-based decision rules because of their simplicity. Drawback of the correlator decoders is their performance relies on the decision threshold. Existence of an undesirable correlation between the WM data embedded through a secret key and the host signal makes the decision threshold specification harder, especially in noisy channels. To overcome this drawback, we propose a SVM-based decoding scheme which is capable of learning the embedded WM data in wavelet domain. It is shown that both decoding and detection performance of the introduced WM extraction technique outperforms state-of-the-art correlation-based schemes. Test results demonstrate that learning in the wavelet domain improves robustness to attacks while reducing complexity	computational complexity theory;cross-correlation;digital watermarking;embedded system;image scaling;key (cryptography);support vector machine;wavelet	Bilge Günsel;Serap Kirbiz	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.924	support vector machine;speech recognition;digital watermarking;computer science;machine learning;pattern recognition;decision rule;mathematics;wavelet transform	EDA	41.88599083919246	-9.876031171320717	131148
abd67d88f84e04403abdf9395d533ebfad326af8	combining normalised voice features for use in efficient template - free biometric security system		An apparatus and method are disclosed which find particular utility as a component of a traffic control system known as a conflict monitor. The apparatus includes a number of solid state switches which are activated to scan inputs from traffic control signals. The inputs are sequentially applied to a A-D converter which samples the voltage and applies it to a microprocessor which is programmed to determine the voltage and analyze the signals for conflicts, or other errors. The input lines are also connected to terminals of a program board whereby the microprocessor can instruct a switch to ground the common pin on the program board to allow program board inputs to be applied to the microprocessor for indicating permissible conflicts. A method includes a technique for determining the voltage of an input analog signal by scanning a plurality of input signals and sampling them in accordance with a relationship which provides minimum error. A display may be operated in one of two modes. In the first mode, a display indicates the signals involved in a conflict, or other error determination. In a second mode, the display may be sequentially stepped through each signal to determine its particular state at the time of a conflict.	biometrics	Joshua Alewo Atah	2008			voltage;solid-state;microprocessor;sampling (statistics);computer hardware;computer vision;biometrics;analog signal;artificial intelligence;control system;computer science	Crypto	46.97353251733325	-4.407586569770599	131691
2e5cdafee0fc0d28d0bfe8f814e63d0514f08a4a	a case study of cross-floor localization system using hybrid wireless sensing		The indoor positioning system based on Micro Electro Mechanical Systems (MEMS) sensors is featured with short-term high accuracy, whose current positioning performance depends on the historical positioning result. Therefore, MEMS positioning has long-time error accumulation. The fingerprint positioning of Bluetooth Low Energy (BLE) is independent of accumulative error, but there is an irregular jump error in the positioning result, which limits the positioning accuracy. Furthermore, the actual commercial positioning systems generally require the consecutive positioning in multi-floor environment. Based on this, this paper proposes a data fusion algorithm based on BLE and MEMS for indoor cross-floor positioning. Firstly, we denoise the fingerprint database by clustering, outlier detection, and filtering algorithms. Then, the extended Kalman filter is employed to complete the optimal estimation of the two-dimensional target position according to the robust M estimation. Finally, the barometer and geographical position information are used to achieve the height estimation of the target. This paper also carries out a large number of engineering verification. The experimental results show that the algorithm can suppress the cumulative error effectively caused by low-cost MEMS sensors, and solve the problem of irregular jump error caused by Received Signal Strength Indicator (RSSI) jitter. In the indoor multi-layer environment, the proposed system achieves the horizontal and vertical positioning Root Mean Square (RMS) errors less than 0.9 m and 0.35 m respectively. In addition, we have verified the stability of the designed system through the long-time test.	algorithm;anomaly detection;bluetooth;cluster analysis;extended kalman filter;fingerprint;indoor positioning system;layer (electronics);methods of computing square roots;microelectromechanical systems;noise reduction;propagation of uncertainty;scott continuity;sensor;tree accumulation	Mu Zhou;Bin Wang;Zengshan Tian;Jiacheng Wang;Qiankun Zhang	2017	GLOBECOM 2017 - 2017 IEEE Global Communications Conference	10.1109/GLOCOM.2017.8254469	real-time computing;cluster analysis;computer science;indoor positioning system;filter (signal processing);sensor fusion;extended kalman filter;root mean square;control theory;jitter;optimal estimation	Mobile	50.02528343583108	0.8290145085304842	132348
cad16f90a0696b33460b7bfafe72460f16612cb9	a comparative study of parallel strategies for the solution of elliptic pde's	parallel computing;numerical method;explicit decoupled group edg methods;explicit group method eg;elliptic p d e;numerical methods;parallel computer;parallel implementation;iteration method	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Abdul Rahman Abdullah;Norhashidah Hj. Mohd. Ali	1996	Parallel Algorithms Appl.	10.1080/10637199608915609	mathematical optimization;parallel computing;numerical analysis;computer science;theoretical computer science;mathematics;distributed computing	Robotics	48.8899319720169	-2.9526443732128986	132797
49f38701cbb09247bd39f22c631291635f33a839	intraframe quantization of speech line spectrum pairs for code-excited linear prediction based coders in packet networks	lsp coefficients;spectral distortion;error propagation;packet loss concealment;intraframe quantization;embsd	ABSTRACT#R##N##R##N#This paper proposes intraframe quantization schemes of line spectrum pair parameters to improve frame erasures for the ITU-T G.723.1 coder. The standard ITU-T G.723.1 coder uses an interframe quantization of the line spectrum pair parameters, which causes error propagation to the next frames. Simulation results show that our intraframe quantization schemes coding is much more robust to frame erasures than the embedded method in ITU-T G.723.1, and a typical improvement of 0.4 dB on average spectral distortion can be obtained with 40% packet loss. Enhanced modified bark spectral distortion tests, under various packet loss conditions, confirm that our proposed method is superior to the interframe algorithm embedded in the ITU-T G.723.1 coder of over 1.6. Copyright © 2012 John Wiley & Sons, Ltd.	code-excited linear prediction;intra-frame coding;network packet;quantization (signal processing)	Fatiha Merazka	2012	Trans. Emerging Telecommunications Technologies	10.1002/ett.2580	electronic engineering;speech recognition;telecommunications;mathematics	Networks	48.188520106060366	-9.483793517254782	133042
4cd26670a43b969c7c83330512534f07b2ccc967	an asymmetric watermarking method	alternative method;filigranage numerique;digital watermarking;watermarking;sequence directe;protection copie;image coding;spread spectrum;systeme protection;watermarking protection robustness art detection algorithms computer hacking spread spectrum communication information security videos rendering computer graphics;data compression;droit auteur;espectro ensanchado;copy protection;securite informatique;copyright;direct sequence;indexing terms;algorithme;computer security;algorithm;secuencia directa;spectre etale;kerckhoff s principle proof asymmetric watermarking method direct sequence spread spectrum costa schemes security level malicious attacks copy protection copyright enforcement;direct sequence spread spectrum;methode alternative;criptografia;cryptography;seguridad informatica;metodo alternativo;filigrana digital;copy protection system;protection system;cryptographie;copyright image coding watermarking data compression;sistema proteccion;security;derecho autor;algoritmo;asymmetric methods	This paper presents an asymmetric watermarking method as an alternative to classical direct sequence spread spectrum and watermarking Costa schemes techniques. This new method provides a higher security level against malicious attacks threatening watermarking techniques used for a copy protection purpose. This application, which is quite different from the classical copyright enforcement issue, is extremely challenging as no public algorithm is yet known to be secure enough, and some proposed proprietary techniques have been already hacked. Our method is thus an attempt toward the proof that the Kerckhoffs principle can be stated in the copy protection framework.	algorithm;copy protection;digital watermarking;kerckhoffs's principle	Teddy Furon;Pierre Duhamel	2003	IEEE Trans. Signal Processing	10.1109/TSP.2003.809376	telecommunications;digital watermarking;computer science;electrical engineering;information security;computer security;statistics	EDA	40.66636820848289	-9.68837762660371	133128
8d410e542ec297a45fd99de5df331b8b4251e634	on full-connectivity properties of locally connected oscillatory networks	microprocessors;oscillations;space invariant local connectivity full connectivity property locally connected oscillatory networks many core chip technology parallel computing systems vlsi platform turing morphogenesis model spatial temporal time periodic pattern processing lcon linear memoryless interactions space invariant interactions linear dynamical interactions oscillator state vector;spatial temporal time periodic pattern processing;linear memoryless interactions;space invariant interactions;oscillators;locally connected oscillatory networks;linear dynamical interactions;cellular nonlinear networks;lcon;vlsi matrix algebra oscillators;many core chip technology;matrix algebra;turing morphogenesis model;chip;network topology;computer architecture;fully connected networks;parallel computing systems;oscillators computer architecture couplings microprocessors equations network topology mesh networks;oscillator state vector;temporal pattern;vlsi platform;parallel computer;vlsi;mesh networks;mesh network;couplings;space invariant local connectivity;full connectivity property;oscillatory patterns;oscillatory patterns cellular nonlinear networks fully connected networks	The latest many-core chip technology advances foster highly parallel computing systems. Consequently, it is crucial to conceive hardware oriented architectures and to realize VLSI platforms, with kilo- or mega-processors, that are able to process and recognize spatial-temporal patterns without breaking them into frames. Oscillatory networks, their archetype being the Turing morphogenesis model, represent a suitable paradigm for processing spatial-temporal time-periodic patterns. In this manuscript we aim at pointing out full-connectivity properties of locally connected oscillatory networks (LCONs) with linear memoryless and space-invariant interactions. In particular, it is analytically shown that LCONs can implement any operators of globally connected networks with linear dynamical interactions, if some suitable components of the oscillator state vector are coupled. The key issue of our results is that the inverse of a banded matrix is almost always full, i.e., almost all of its entries are nonzero. Space-invariant local connectivity allows for hardware realizations with straightforward architectures.	angularjs;approximation algorithm;central processing unit;dynamical system;integrated circuit;interaction;linear algebra;manycore processor;nonlinear system;numerical partial differential equations;parallel computing;programming paradigm;prototype;turing;two-phase commit protocol;very-large-scale integration	Fernando Corinto;Marco Gilli;Tamás Roska	2011	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2010.2092050	discrete mathematics;computer science;theoretical computer science;mesh networking;control theory;mathematics;distributed computing;oscillation	ML	41.17582554965186	-0.858886387301951	133207
f388d07be87a9bd3b2dba02df2aecc9c2f2cb78b	in-service video quality verifying using dct basis for dtv broadcasting	digital broadcasting		discrete cosine transform	Byeong-No Kim;Chan-Ho Han;Kyu-Ik Sohng	2013	IEICE Transactions		embedded system;electronic engineering;real-time computing;computer science;digital broadcasting	Visualization	46.82892136640451	-7.949498564158206	133213
4c97abf365a94f0e70f63d86952ae566db1ff4ec	wi-fi-based positioning in a complex underground environment	ieee 802 11;localization;underground;autocalibration;positioning;mines;self calibration;wi fi	Underground mining tunnels constitute a very particular environment for radio wave propagation – with characteristics of both indoor and outdoor “regular” environments. This paper shows how a general-purpose WiFi-based indoor positioning system, OwlPS (Owl Positioning System) was adapted to work in that particular environment. A series of experiments, conducted in a formerly exploited gold mine at 70 metres below the surface, across about 400 metres of drifts, is then introduced; it primarily aims at determining the positioning accuracy that can be reached in such a context with a Wi-Fi-based positioning system using the signal strength at 2.4 GHz. The results obtained are improved with a filter, and the mean Euclidean distance error is under 10 metres in most cases when the terminal is carried by an operator; this makes OwlPS usable as is for asset management and emergency positioning of workers underground.	euclidean distance;experiment;general-purpose modeling;global positioning system;indoor positioning system;pyrite;radio wave;software propagation;underground	Matteo Cypriani;Gilles Y. Delisle;Nadir Hakem	2015	JNW	10.4304/jnw.10.3.141-151	ieee 802.11;simulation;internationalization and localization;telecommunications;computer science;operating system;computer security;computer network	HCI	48.20958118037586	-5.012083926749666	134295
1f08d645e9c8472049a951e723be5ef65da30ea7	stochastic first passage time accelerated with cuda		Abstract The numerical integration of stochastic trajectories to estimate the time to pass a threshold is an interesting physical quantity, for instance in Josephson junctions and atomic force microscopy, where the full trajectory is not accessible. We propose an algorithm suitable for efficient implementation on graphical processing unit in CUDA environment. The proposed approach for well balanced loads achieves almost perfect scaling with the number of available threads and processors, and allows an acceleration of about 400× with a GPU GTX980 respect to standard multicore CPU. This method allows with off the shell GPU to challenge problems that are otherwise prohibitive, as thermal activation in slowly tilted potentials. In particular, we demonstrate that it is possible to simulate the switching currents distributions of Josephson junctions in the timescale of actual experiments.	cuda;first-hitting-time model	Vincenzo Pierro;Luigi Troiano;Elena Mejuto;Giovanni Filatrella	2018	J. Comput. Physics	10.1016/j.jcp.2018.01.039	parallel computing;mathematics;acceleration;mathematical optimization;scaling;first-hitting-time model;physical quantity;thread (computing);multi-core processor;cuda;josephson effect	Theory	42.93653617523071	1.7103072237651091	134768
a5b1e5044967f20c8c25a9ae344584e1861e5375	hierarchical multiscale model-based design of experiments, catalysts, and reactors for fuel processing	water gas shift;nh3;hydrogen;model based design of experiments;kinetic model;nh 3;information content;process design;multiscale modeling;model reduction;product engineering;process optimization;lab on a chip;power generation;parameter estimation;process engineering;multiscale;model based design;reactor optimization;microreactors;model based parameter estimation;multiscale simulation;reaction mechanism;design of experiment	In this paper a hierarchical multiscale simulation framework is outlined and experimental data injection into this framework is discussed. Specifcally, we discuss multiscale model-based design of experiments to optimize the chemical information content of a detailed reaction mechanism n order to improve the fidelity and accuracy of reaction models. Extension of this framework to product (catalyst) design is briefly touched upon. urthermore, we illustrate the use of such detailed and reduced kinetic models in reactor optimization as an example toward more conventional rocess design. It is proposed that hierarchical multiscale modeling offers a systematic framework for identification of the important scale(s) and odel(s) where one should focus research efforts on. The ammonia decomposition on ruthenium to produce hydrogen and the water–gas shift eactions on platinum for converting syngas to hydrogen serve as illustrative fuel processing examples of various topics. The former is used to llustrate hierarchical multiscale model development and model-based parameter estimation as well as product engineering. The latter is employed o demonstrate model reduction and process optimization. Finally, opportunities for process design and control in portable microchemical devices lab-on-a chip) for power generation are discussed. 2006 Elsevier Ltd. All rights reserved.	cheminformatics;design of experiments;estimation theory;experiment;hydrogen;mathematical optimization;multiscale modeling;process optimization;product engineering;reactor (software);self-information;simulation	Dionisios G Vlachos;A. B. Mhadeshwar;Niket S. Kaisare	2006	Computers & Chemical Engineering	10.1016/j.compchemeng.2006.05.033	control engineering;electricity generation;process design;hydrogen;simulation;self-information;lab-on-a-chip;engineering;process optimization;reaction mechanism;mathematics;microreactor;estimation theory;design of experiments;water-gas shift reaction;multiscale modeling;statistics;product engineering	EDA	51.83056595078627	-5.5376563165832415	135086
fddbe34fdfe4adee01f098f68d642b4a4087ac30	audio restoration by constrained audio texture synthesis	audio self similarity;fractals;degradation;audio signal processing;error concealment;audio texture restoration constrained audio texture synthesis missing parts audio reconstruction error concealment audio music delivery packet loss internet audio medium audio clip;missing parts;constrained audio texture synthesis;texture synthesis;packet loss;fractals audio signal processing signal reconstruction internet;video sequences;audio clip;audio recording;fractals audio signal processing signal restoration signal reconstruction error correction;audio medium;streaming media signal restoration asia signal synthesis internet audio recording algorithm design and analysis video sequences degradation acoustic noise;internet;audio texture restoration;streaming media;error correction;acoustic noise;audio reconstruction;audio music delivery;signal reconstruction;signal restoration;signal synthesis;audio self similarity constrained audio texture synthesis audio stream audio clip audio texture restoration audio reconstruction error concealment internet;audio stream;streaming media signal restoration internet asia signal synthesis audio recording algorithm design and analysis degradation acoustic noise video sequences;algorithm design and analysis;asia	Audio texture, a new audio medium, is used to synthesize long audio stream according to a given short example audio clip. In this paper, we extend this idea to audio texture restoration, or constrained audio texture synthesis for restoring those missing parts in an audio clip. It is useful in many applications such as audio restoration and audio reconstruction. It can also be used in error concealment for audio/music delivery with packet loss on the internet. A novel method is proposed for constrained audio texture synthesis. Preliminary results are provided for evaluation.	audio signal processing;circuit restoration;error concealment;internet;monkey's audio;network packet;smoothing;streaming media;texture synthesis	Lie Lu;Yi Mao;Wenyin Liu;HongJiang Zhang	2003		10.1109/ICME.2003.1221334	signal reconstruction;algorithm design;computer vision;audio mining;the internet;error detection and correction;speech recognition;degradation;digital audio;fractal;audio signal processing;computer science;speech coding;noise;sound quality;multimedia;packet loss;texture synthesis	Graphics	49.598539295544825	-9.803163587932794	135736
8f58d49c0cd49221cb182154111bcaf36d5d940d	optimal traffic sensor location for origin–destination estimation using a compressed sensing framework	estimation sparse matrices compressed sensing coherence optimization transportation minimization;compressed sensing traffic sensor location traffic flow estimation	A series of flow estimation problems, especially origin–destination estimation, involves optimally locating sensors on a transportation network to measure traffic counts. As compressed sensing (CS) provides a new method to solve the estimation problem, its sensor location strategy needs to be researched in order to facilitate the reconstruction. This paper first points out that the accurate flow recovery is difficult by introducing a necessary condition, and then categorizes the location determination into two cases: sensor number with restriction and without restriction. For both cases, we elucidate their theoretical foundations of locating methods and propose an algorithm based on column coherence minimization, which optimally facilitates the reconstruction for CS framework. Numerical experiments indicate that the selected sensor locations fit the flow recovery and the proposed algorithm, compared with other methods, can lead to a slightly better result under certain observations.	algorithm;coefficient;compressed sensing;computation;count data;experiment;jaishankar menon;motion estimation;norm (social);numerical method;penalty method;performance;rush hour (board game);sampling (signal processing);sensor;sparse matrix;theory	Peijun Ye;Ding Wen	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2614828	mathematical optimization;electronic engineering;computer science	Robotics	47.20048326876318	3.9726286455971165	136513
a6a8480ff7f5ad14970fea56cb4e7ce9b57ee779	inverse, forward and other dynamic computations computationally optimized with sparse matrix factorizations		We propose an algorithm to compute the dynamics of articulated rigid-bodies with different sensor distributions. Prior to the on-line computations, the proposed algorithm performs an off-line optimisation step to simplify the computational complexity of the underlying solution. This optimisation step consists in formulating the dynamic computations as a system of linear equations. The computational complexity of computing the associated solution is reduced by performing a permuted LU-factorisation with off-line optimised permutations. We apply our algorithm to solve classical dynamic problems: inverse and forward dynamics. The computational complexity of the proposed solution is compared to ‘gold standard’ algorithms: recursive Newton-Euler and articulated body algorithm. It is shown that our algorithm reduces the number of floating point operations with respect to previous approaches. We also evaluate the numerical complexity of our algorithm by performing tests on dynamic computations for which no gold standard is available.	algorithm;computation;computational complexity theory;euler;lu decomposition;linear equation;mathematical optimization;monoid factorisation;newton;numerical analysis;online and offline;recursion;sparse matrix;system of linear equations	Francesco Nori	2017	2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2017.8311889	mathematical optimization;combinatorics;average-case complexity;theoretical computer science;mathematics	Robotics	40.55878373696713	2.4415502235831195	137350
55dd144fea535a65393adddc5d9b8a083c937dfe	multiplicative watermarking of audio in dft magnitude	watermarking;correlation detector;log likelihood detection;audio;discrete fourier transform	In this paper, watermark is multiplicatively embedded in discrete fourier transform magnitude of audio signal using spread spectrum based technique. A new perceptual model for magnitude of discrete fourier transform coefficients is developed which finds the regions of highest watermark embedding capacity with least perceptual distortion. Theoretical evaluation of detector performance using correlation detector and likelihood ratio detector is undertaken under the assumption that host feature follows Weibull distribution. Also, experimental results are presented in order to show the performance of the proposed scheme under various attacks such as presence of multiple watermarks, additive white gaussian noise and audio compression.	additive white gaussian noise;coefficient;computation;computational complexity theory;data compression;digital watermarking;discrete fourier transform;distortion;embedded system;experiment;high-water mark (computer security);mp3;psychoacoustics;signal processing;utility functions on indivisible goods	Jyotsna Singh;Parul Garg;Alok Nath De	2012	Multimedia Tools and Applications	10.1007/s11042-012-1282-y	speech recognition;short-time fourier transform;digital watermarking;computer science;discrete fourier transform;statistics	Vision	41.92010831856038	-8.972051945853458	138043
ade60946c4d056c8bae243dd2bbfe73e0c2f3e47	an anti-steganographic approach for removing secret information in digital audio data hidden by spread spectrum methods	desynchronization steganography steganalysis audio spread spectrum information hiding;audio streaming;multimedia communication signal processing algorithms robustness multiple signal classification decoding bit error rate signal processing;steganography audio streaming error statistics;steganography;error statistics;antisteganographic approach digital audio data spread spectrum method multimedia steganography removal method multimedia steganography attack method digital audio carriers embedding steganography data hidden information removal limited pseudorandom shuffling audio stream synchronization information spread spectrum steganography information decoding bit error rate audio quality secret information removal	In this paper, we present and investigate a method to multimedia steganography removal methodand remove multimedia steganography in digital audio data. Among the existing steganography methods that can be used to hide secret data in digital audio carriers, the Spread Spectrum methods are among the most effective and robust for embedding steganography data. Though there are currently a few research efforts on removing or destroying steganography in multimedia, there have been very few efforts on removing steganography from audio. In this paper, we have introduced a simple but very effective anti-steganography approach for removing hidden information from digital audio data embedded using Spread Spectrum methods. The main concept in our approach is to leverage limited pseudo-random shuffling of the samples in the audio stream so that the synchronization information necessary for decoding Spread Spectrum steganography information cannot be attained. Our simulation results in this paper have demonstrated great performance in removing audio steganography by achieving a 50% bit error rate after applying our anti-steganography approach to the digital audio data while maintaining the audio quality.	bit error rate;embedded system;pseudorandomness;simulation;sound quality;spatial anti-aliasing;steganography;streaming media	Fahimeh Rezaei;Tao Ma;Michael Hempel;Dongming Peng;Hamid Sharif	2013	2013 IEEE International Conference on Communications (ICC)	10.1109/ICC.2013.6654839	speech recognition;steganography tools;computer science;theoretical computer science;steganography;internet privacy;statistics	EDA	42.398785296920494	-9.466417340437147	138055
3d1d39fd315756223f84229ee38a32f433d1720c	evaluation of the performance of piecewise-linear-prediction coding (plpc) of speech signals	piecewise linear;speech analysis;speech coding;testing;linear predictive coding;speech coding speech analysis linear predictive coding testing;predictive coding			Caldwell P. Smith	1976		10.1109/ICASSP.1976.1170065	linear predictive coding;speech recognition;vector sum excited linear prediction;piecewise linear function;computer science;speech coding;pattern recognition;software testing;code-excited linear prediction	HCI	47.78917428623718	-8.268449934463288	138198
a2756dc1c08e46a865988dec051f3df060998873	a novel localization algorithm based on isomap and partial least squares for wireless sensor networks	wireless sensor networks wsns contribution rate isometric mapping isomap kernel methods node localization partial least squares pls;least squares approximations;matrix algebra;noise sensors wireless sensor networks kernel manifolds euclidean distance level measurement;computational complexity;computational complexity partial least square isometric mapping wireless sensor networks node localization algorithm measurement error information nonlinear positioning data points kernel matrix multidimensional scale method pls isomap algorithm topological stability;wireless sensor networks;wireless sensor networks computational complexity least squares approximations matrix algebra measurement errors;measurement errors	Node localization is a main application of wireless sensor networks. However, the measurement error and noise in a real environment make the positioning of information nonlinear and have a great effect on the performance of localization methods. In this paper, we propose a novel isometric mapping (Isomap) node localization algorithm based on partial least squares (PLS-Isomap). For topological stability, the critical outlier points are eliminated by comparing the contribution rate of all data points. Then, we employ the PLS method to solve the Isomap. The adoption of PLS reduces the noise sensitivity of Isomap, which achieves solution by least squares. Moreover, the proposed approach applies a projection method to construct a new kernel matrix between new and original data points. Compared with Isomap and the multidimensional scale method, experimental and simulation results indicate that the PLS-Isomap algorithm has good topological stability, robustness, positioning accuracy, and lower computational complexity.	algorithm;computational complexity theory;data point;isomap;isometric projection;nonlinear system;partial least squares regression;projection method (fluid dynamics);sensor;simulation;time complexity	Bing Li;Yigang He;Fengming Guo;Lei Zuo	2013	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2012.2216476	mathematical optimization;discrete mathematics;wireless sensor network;non-linear iterative partial least squares;computer science;machine learning;mathematics;computational complexity theory;statistics;observational error	Embedded	52.264604088125715	4.146679779442825	138428
8ca8efe5b316f5d02d2f71150ccb101da96a1440	model-free approach for sensor network localization with noisy distance measurement		A model-free localization method with noisy distance measurement is proposed for estimating a moving robot in 3D space. Considering that the traditional filter-based sensor network localization algorithms can not provide acceptable estimation accuracy in altitude in 3D space, the proposed method utilizes not only current measurements but also previous measurements to localize a robot. This character adds more constraints to localization to avoid local minimum. In addition, different from the traditional filter-based localization methods which need kinetic model for localization, our proposed method is model-free and converts the localization problem to graph optimization problem. The advantage is that we avoid the possible estimation error caused by inaccurate or simplified kinetic model. Considering that the communication limitation in application makes many graph optimization theories such as distributed localization theory and trilateration difficult to be realized, our method proposes to add constrained equation between adjacent positions to solve this problem. Experiments under a variety of scenarios verify the stability of this method and show that the algorithm achieves better localization accuracy than filter-based methods.		Xu Fang;Chen Wang;Thien-Minh Nguyen;Lihua Xie	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581124	wireless sensor network;control theory;computer science;graph;optimization problem;trilateration	Robotics	50.876994070679785	2.5986806041345187	138901
e3398489bcf4a8ff3c92c0d63cbdd06facad8d97	quantum system modelling	quantum system;fourier series;quantum informatics;probabilistic model;quantisation;complex multi models;complementarity;probabilistic multi models;quantum system modelling	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	basis (linear algebra);complementarity (physics);complementarity theory;conformity;decibel;engineering informatics;francis;filter bank;linear system;nl (complexity);nonlinear system;primary source;quantization (image processing);quantum entanglement;quantum information science;quantum mechanics;quantum system;requirement;systems modeling;systems theory;telematics;time series	Miroslav Svitek	2008	Int. J. General Systems	10.1080/03081070701833039	statistical model;mathematical optimization;combinatorics;discrete mathematics;complementarity;mathematics;quantum algorithm;quantum phase estimation algorithm;fourier series;statistics	Robotics	50.16131320412623	-3.1600073500525894	139079
ab2cb49a6d32b55c4363466c6d2773dc99597d5d	rnc: a high-precision network coordinate system	vectors servers robustness principal component analysis linear matrix inequalities niobium quality of service;principal component analysis computational complexity computer networks convergence distance measurement network servers optimisation;computation complexity distributed systems distance prediction service network hosts convergence speed distributed network coordinate system ncs schemes robust principal component analysis rnc distance measurements convergence process robust nonnegative principal component analysis run pace convex optimization	Network Coordinate System (NCS) has drawn much attention over the past years thanks to the increasing number of large-scale distributed systems that require the distance prediction service for each pair of network hosts. The existing schemes suffer seriously from either low prediction precision or unsatisfactory convergence speed. In this paper, we present a novel distributed network coordinate system based on Robust Principal Component Analysis, RNC, that uses a few local distance measurements to calculate high-precision coordinates without convergence process. To guarantee the non-negativity of predicted distances, we propose Robust Nonnegative Principal Component Analysis (RUN-PACE) which only involves convex optimization, consequently resulting in low computation complexity. Our experimental results indicate that RNC outperforms the state-of-the-art NCS schemes.	computation;convex optimization;distance matrix;distributed computing;geographic coordinate system;mathematical optimization;negativity (quantum mechanics);network computing system;randomness;robust principal component analysis;scalability;simulation	Jie Cheng;Xin Guan;Qiang Ye;Hongbo Jiang;Yan Dong	2014	2014 IEEE 22nd International Symposium of Quality of Service (IWQoS)	10.1109/IWQoS.2014.6914323	mathematical optimization;machine learning;distributed computing	Embedded	52.94909113216911	0.5316002419321484	139216
48d3357a783447d393025a7da55c1a7c71cc8ea3	application of taguchi method to robust multi—criteria optimum design for ultra-thin centrifugal fan	optimization taguchi method numerical simulation flow field;pareto optimisation;design engineering;computational fluid dynamics;arrays;taguchi methods computational fluid dynamics design engineering fans pareto optimisation statistical analysis;statistical analysis;flow field;mathematical model;analysis of variance;blades;robustness;optimization;taguchi methods;taguchi method;cooling performance taguchi method robust multicriteria optimum design ultra thin centrifugal fan maximum volume flow rate static pressure minimum noise orthogonal array computational fluid dynamics signal to noise ratio analysis of variance pareto optimal robust design solution;analysis of variance cooling arrays blades mathematical model noise robustness;cooling;noise;numerical simulation;fans	This study paper presents a new robust multi—criteria optimization method that employs the Taguchi method to design and analyze an ultra-thin centrifugal fan. The objective of this study is to obtain the maximum volume flow rate, static pressure, and minimum noise of a fan. The proposed approach utilizes a combined orthogonal array and computational fluid dynamics method to simulate the internal flow field of the ultra-thin centrifugal fan. This study employs signal-to-noise ratio and analysis of variance to determine the Pareto-optimal robust design solution. The operation section of the optimized fan P-Q curve design is almost 30% larger than the original design. This research also identifies the optimal design parameters that affect the cooling performance of the centrifugal fan. The experimental results confirm the effectiveness of this approach.	centrifugal governor;computational fluid dynamics;computer cooling;mathematical optimization;optimal design;pareto efficiency;signal-to-noise ratio;simulation;taguchi methods	Kuang-Hung Hsien;Shyh-Chour Huang	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6083891	computer simulation;mathematical optimization;taguchi methods;statistics	EDA	52.58663320254378	-7.629196339024362	139327
177a723711640f4f0152f10310ca2b4365e738b1	"""rejoinder to the discussion of """"an analysis of global warming in the alpine region based on nonlinear nonstationary time series models"""""""		The paper by Battaglia and Protopapas (Stat Method Appl 2012) is stimulating. It gives an elegant mathematical generalization of autoregressive models (the nine types). It explains state-of-the-art model fitting techniques (genetic algorithm combined with fitness function and least squares). It is written in a fluent and authoritative manner. Important for having a wider impact: it is accessible to non-statisticians. Finally, it has interesting results on the temperature evolution over the instrumental period (roughly the past 200 years). These merits make this paper an important contribution to applied statistics as well as climatology. As a climate researcher, coming from Physics and having had an affiliation with a statistical institute only as postdoc, I re-analyse here three data series with the aim of providing motivation for model selection and interpreting the results from the climatological perspective.	alpine;autoregressive model;curve fitting;fitness function;genetic algorithm;least squares;model selection;nonlinear system;time series	Francesco P. Battaglia;Mattheos K. Protopapas	2012	Statistical Methods and Applications	10.1007/s10260-012-0205-4		ML	52.42804371792826	-0.7141917646216948	139532
6aec3e91d1b91221270b2826f71a71625a2a41dc	bandwidth extension of audio based on partial loudness criteria	loudness;audio quality source filter bandwidth extension algorithm psychoacoustic concept partial loudness criteria signal representation;audio signal processing;system performance;audio quality;bandwidth frequency wideband speech synthesis narrowband psychology mutual information decoding bit rate psychoacoustic models;psychoacoustic concept;signal representation;signal representation audio signal processing filtering theory loudness;partial loudness criteria;high frequency;filtering theory;source filter bandwidth extension algorithm	Most modern speech coders operate on a limited bandwidth. This tends to decrease the naturalness of the synthesized audio and often also affects the intelligibility of certain sounds. While a few wideband speech coders have been standardized, implementing them in existing systems would require significant changes to the infrastructure. One solution is to use bandwidth extension techniques that predict the high-frequency band based on low-band features. Problems arise however when the correlation between the low and the high band is insufficient for an adequate representation of the wideband signal. In this paper, we propose a novel source-filter bandwidth extension algorithm that makes use of psychoacoustic concepts to determine the perceptual benefits that a particular audio frame gains from a more exact representation of the high band. Preliminary results indicate that the proposed system performs at a lower average bit rate when compared to other similar algorithms without compromising the audio quality	algorithm;bandwidth (signal processing);bandwidth extension;frequency band;intelligibility (philosophy);psychoacoustics;relevance;speech synthesis	Visar Berisha;Andreas Spanias	2006	2006 IEEE Workshop on Multimedia Signal Processing	10.1109/MMSP.2006.285286	loudness;alignment level;speech recognition;bandwidth extension;audio signal processing;computer science;high frequency;sound quality;computer performance;audio signal flow;statistics	Security	48.63082951991289	-8.55300227964559	140102
e4e5ad1ea3552c41d7826f57970255ba61017100	silicon primary visual cortex designed with a mixed analog-digital architecture	vision system;logic design;neural nets;real time;vlsi silicon primary visual cortex mixed analog digital architecture mixed analog digital neuromorphic vision system binocular disparity energy maps robotic vision brain neuronal network neural image visualization fpga;mixed analog digital neuromorphic vision system;neural image visualization;fpga;silicon analog digital conversion neuromorphics machine vision layout real time systems hardware power dissipation robot vision systems biological neural networks;vlsi field programmable gate arrays logic design mixed analogue digital integrated circuits neural nets robot vision;silicon primary visual cortex;mixed analog digital architecture;primary visual cortex;low power;robot vision;binocular disparity energy maps;brain neuronal network;robotic vision;vlsi;mixed analogue digital integrated circuits;field programmable gate arrays;binocular disparity;neuronal network;natural scenes;complex cell	We designed a mixed analog-digital neuromorphic vision system that can replicate the response of complex cells in the primary visual cortex (V1). Using the system, the binocular disparity energy maps were calculated in natural scenes in real time. Because of its compact hardware and low power dissipation, the neuromorphic vision system developed in the present study is suitable to robotic vision. More interestingly, it provides insights to explore the visual function of the neuronal network of the brain, visualizing neural images inferred from physiological experiments.	binocular disparity;binocular vision;experiment;map;neuromorphic engineering;robot;self-replication	Tetsuya Yagi;Kazuhiro Shimonomura	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371389	computer vision;biological neural network;simulation;machine vision;computer science;artificial neural network;field-programmable gate array;computer graphics (images)	Robotics	41.08490083716501	-2.3897173542287264	140639
39f7b6aadfe1e1ceed6f8a47cf3080cd15c76df4	spoofing impact on gnss integrity in the transport context: a tool for the performance analysis		The present work shows the results of a performance analysis for evaluating the impact of spoofing on GNSS Integrity for transport applications. Spoofing represents a potential risk to be managed for GNSS safety-related land mobile applications. To this aim a Virtual Test Bed has been generated. A rover receiver has been developed through an SDR, and relevant spoofed signal injected through a hardware simulator. A performance analysis software simulator performed relevant integrity study. Stanford plots have been generated for analyzing integrity performance to guarantee a THR=10-9/h in DGNSS mode.		Roberto Di Capua;Giuseppe Olivieri;L. Gattuso;Marco Giangolini;Cosimo Stallo;Pietro Salvatori;Alessandro Neri;Francesco Rispoli	2018	2018 IEEE 4th International Forum on Research and Technology for Society and Industry (RTSI)	10.1109/RTSI.2018.8548421	embedded system;spoofing attack;software;automotive industry;software-defined radio;gnss applications;computer science	Arch	46.81894132313222	2.0207111511821454	140640
4e765bd7aca75e4a2ad61d3068aa86e2b1f78569	a graphical model based decoder for recognition of loss-concealed voip speech	silicon;protocols;decoding;packet loss;acoustics;speech;speech coding;viterbi decoding loss concealed voip speech recognition voice over internet protocol graphical model based decoder packet loss concealment techniques;viterbi decoding internet telephony protocols speech coding speech recognition;internet telephony;hidden markov models;graphical models decoding speech recognition hidden markov models programmable control viterbi algorithm automatic speech recognition pattern recognition artificial intelligence robots;voice over internet protocol;packet loss concealment;viterbi decoder;speech recognition voip loss concealment graphical model;graphical model;speech recognition;experimental validation;loss concealment;switches;viterbi decoding;voip	In the recognition of Voice Over Internet Protocol(VoIP) speech, packet losses pose a challenge that is generally addressed by packet loss concealment (PLC)techniques. But improper concealment by these PLC techniques result in unreliable observations that contribute adversely to the Viterbi decoding step and result in misrecognitions. We propose a graphical model based decoding architecture that can skip unreliable observations and hence the corresponding states, so that recognition accuracy improves in spite of improper concealment. Experimental validation of the proposed skip decoder is carried out using the loss-concealed speech samples of isolated words. Results indicate the efficacy of the skip decoder in the improvement of the recognition accuracy for different lengths of burst losses and different PLC schemes.	codec;graphical model;markov chain;network packet;skip list;viterbi algorithm	Anupam Mandal;K. R. Prasanna Kumar;G. Athithan;Chellu Chandra Sekhar	2009	2009 Seventh International Conference on Advances in Pattern Recognition	10.1109/ICAPR.2009.71	speech recognition;telecommunications;computer science;communication	Vision	49.840723324436134	-8.75681837159044	140764
f661c00f23b4fa42e983c4ccd0dc3b8e66945c2c	optimal watermarking scheme for breath sound	digital watermarking;watermarking;lwt dct;speech processing;breath sound;singular value decomposition;pso;watermarking robustness quantization signal to noise ratio discrete cosine transforms optimization;breath sound digital watermarking robust lwt dct svd pso;wavelet transforms discrete cosine transforms singular value decomposition speech processing watermarking;wavelet transforms;robust;svd;discrete cosine transforms;pso optimal watermarking scheme breath sound lifting wavelet transform lwt discrete cosine transform dct singular value decomposition svd dither modulation dm source encryption identity information medical conditions biological signals breathing pattern detection lwt dct coefficients particle swarm optimization	In this paper, a new watermarking scheme for breath sound based on lifting wavelet transform (LWT), discrete cosine transform (DCT), singular value decomposition (SVD) and dither modulation (DM) quantization is proposed to embed encrypted source and identity information, and medical conditions, such as cold and flu symptoms in breath sound while preserving important biological signals for detecting breathing patterns and breathing rates. In the proposed scheme, LWT is first carried out to decompose the signal followed by applying DCT on the approximate coefficients. SVD is then performed on the LWT-DCT coefficients to get the singular values. The novelty of our proposed method includes the introduction of the particle swarm optimization (PSO) technique to optimization the quantization steps of the DM approach too. Simulation results show that our watermarking scheme achieves good robustness against common signal processing attacks and maintains the imperceptivity. The comparison results also show good performance of our scheme.	approximation algorithm;coefficient;digital watermarking;discrete cosine transform;dither;encryption;grand challenges;lifting scheme;mathematical optimization;modulation;particle swarm optimization;quantization (signal processing);sensor;signal processing;simulation;singular value decomposition;wavelet transform	Baiying Lei;Insu Song;Shah Atiqur Rahman	2012	The 2012 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2012.6252586	speech recognition;digital watermarking;computer science;theoretical computer science;speech processing;mathematics;singular value decomposition	EDA	41.49754324283912	-9.013981102621054	141275
2d0ce8f340f4b8ef4dae0e7d52643b435310bff2	a field programmable neural array	biology computing;routing structure field programmable neural array analog circuit biologically relevant circuit components;field programmable analog arrays;neural networks;neural nets;application software;routing;programmable logic arrays analogue circuits network routing neural nets;programmable logic arrays;network routing;computer networks;hardware field programmable analog arrays field programmable gate arrays neurons application software analog computers biology computing analog circuits routing computer networks;field programmable neural array;analog circuits;analog circuit;routing structure;biologically relevant circuit components;analog computers;analogue circuits;neurons;field programmable gate arrays;complex cell;hardware	An analog circuit capable of accurately emulating large complex cells, or multiple less complex ones is described. This circuit is termed the FPNA or the field programmable neural array. It is analogous to the more familiar FPGA, but is composed of biologically relevant circuit components including active channels, dendrites, and synapses. Taking each of these circuit models, and adding a routing structure capable of routing outputs from cells (or external inputs) to any individual synapse at any node yields a device which is capable of emulating complex biological circuits. This circuit opens doors to investigating what particular types of computation individual cells are performing, as well as small networks simpler cells	analogue electronics;computation;emulator;field-programmable gate array;routing;synapse;synthetic biological circuit	Ethan Farquhar;Christal Gordon;Paul E. Hasler	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693534	equivalent circuit;routing;electronic engineering;analogue electronics;computer science;theoretical computer science;artificial neural network;computer engineering	Arch	40.12990828799767	-1.3454994209502795	141391
4b05c7dd9126ef6db3d353f01fab267d9f4c8578	data acquisition and signal processing for endless rope continuous tractor monitoring	data acquisition;endless rope continuous tractor;monitoring;signal processing	Through datas acquisition, processing the data and signal, to achieve full, real-time monitoring of running state of endless rope continuous tractor. Research and analysis the software and hardware of the endless rope continuous tractor monitoring, it has the function of the winch position and speed of real-time display, leakage communication, language broadcaster, fault logging, winch driver identification, fault masking, two-speed winch speed selection. It can be com- prehensive protected for emergency stop to lockout, overwinding protection in the head and tail in running, and remote monitoring through the host computer.	data acquisition;signal processing	Wei Chen;Hai-shun Deng	2013		10.1007/978-3-642-37502-6_79	embedded system;simulation;engineering;forensic engineering	ML	45.7724187154858	-4.236783836004873	141629
d4db08df8ceaa6e6e2012accd9c6a3be67618a02	synchronization based on mixture alignment for sound source separation in wireless acoustic sensor networks	speech separation;short term log energy;wireless acoustic sensor network;mixture alignment	Desynchronization degrades the performance of many signal processing algorithms in Wireless Acoustic Sensor Networks. It is mainly caused by the different distances between the source and each node and by the clock phase offset and frequency skew. Classical solutions use clock synchronization protocols and algorithms in the communication layer, but these alternatives do not tackle the lack of synchronization caused by the distances between sources and nodes. In this paper, we present a novel study of the synchronization problem in acoustic sensor networks from a signal processing point of view. First, we propose a theoretical framework that allows us to study the effects of misalignment over any short-time based algorithm, focusing on the requirements of the effective length of the analysis time frame. From this framework, a theoretical synchronization delay is established aimed at reducing the required length of the time frame. Second, two novel alignment methods are developed and are tuned up to reduce the amount of synchronization information required for transmission. The results obtained demonstrate that our proposed methods represent a good solution in terms of performance over the quality of a standard Blind Source Separation algorithm, allowing us to reduce the transmission bandwidth required for synchronization data. & 2015 Elsevier B.V. All rights reserved.	acoustic cryptanalysis;acoustic fingerprint;algorithm;blind signal separation;clock synchronization;covox speech thing;requirement;signal processing;source separation;synchronization (computer science)	Cosme Llerena;Roberto Gil-Pita;Manuel Rosa-Zurera;David Ayllón;Manuel Utrilla-Manso;Francisco Llerena	2016	Signal Processing	10.1016/j.sigpro.2015.06.023	clock synchronization;electronic engineering;real-time computing;telecommunications;computer science;self-clocking signal;data synchronization	Mobile	49.665206432883146	3.386216806644535	141671
b1c47cf4db18babe4a04d06cd53cb1944e707448	a 32 kbit/s wideband speech coder based on transform coding	transform coding		data rate units;speech coding;transform coding	H. Dia;Gang Feng;Yannick Mahieux	1993			speech recognition;artificial intelligence;wideband audio;transform coding;sub-band coding;pattern recognition;speech coding;computer science;harmonic vector excitation coding	NLP	47.743072534856864	-8.587137981454143	142124
d8af64d34d1cd804452fb9ccc057557583e05549	optimal watermark embedding combining spread spectrum and quantization	signal image and speech processing;quantum information technology spintronics	This paper presents an optimal watermark embedding method combining spread spectrum and quantization. In the method, the host signal vector is quantized to embed a multiple-bit watermark, and meanwhile, the quantized signal is made to locate in the detectable region defined in the context of spread spectrum watermarking. Under the two constraints, the optimal watermarked signal is derived in the sense of minimizing the embedding distortion. The proposed method is further implemented in wavelet transform domain, where the insensitive wavelet coefficients are selected according to the modified human visual model for watermark embedding. Simulations on real images by using the wavelet-based implementations demonstrate the proposed method performs very well in both watermark imperceptibility and robustness and is more robust to typical signal processes, e.g., additive noise, JPEG compression, etc., as compared with the state-of-the-art watermarking methods.	additive white gaussian noise;coefficient;computer simulation;digital watermarking;distortion;jpeg;quantization (signal processing);utility functions on indivisible goods;visual modeling;wavelet transform	Xinshan Zhu;Ya Sun;Ming Zeng;Biao Sun;Ping Wang;Ting Yang	2016	EURASIP J. Adv. Sig. Proc.	10.1186/s13634-016-0373-8	computer vision;computer science;theoretical computer science;mathematics;watermark	Vision	41.65558480517421	-9.880473658059435	142256
fd3a67792f1f49ed0893e1f0e3a3283530ae5349	classical monte carlo with a fast high-quality pseudo random number library in java	monte carlo		java;monte carlo method	Muhammad Z. Hydari;David Ceperley;Ashok Srinivasan;Michael Mascagni	1999			dynamic monte carlo method;computational physics;kinetic monte carlo;monte carlo method in statistical physics;monte carlo method;markov chain monte carlo;monte carlo molecular modeling;hybrid monte carlo;monte carlo integration;physics	EDA	41.54699793388947	1.4436754220655408	143136
27a9e1ed575ce24021b66a134e58818e324d9c48	a parallel two-level preconditioner for cosmic microwave background map-making	toeplitz matrices;astronomy computing;conjugate gradient methods;cosmology;iterative methods;least squares approximations;noise measurement;parallel processing;2lvl-pcg;moore rate;toeplitz block;astrohysical observation;blockdiagonal matrix;conjugate gradient method;cosmic microwave background data analysis;cosmic microwave background map-making;cosmological observation;dimensional image;generalized least square problem;generalized least square system;geophysical observation;iterative algorithm;linear system;measurement noise;nondiagonal weights;parallel two-level preconditioner;parallelizable iterative solver;piecewise stationary;scaling behavior;sparse vector	Generalized least square problems with non-diagonal weights arise frequently in an estimation of two dimensional images from data of cosmological as well as astro- or geo- physical observations. As the observational data sets keep growing at Moore's rate, with their volumes exceeding tens and hundreds billions of samples, the need for fast and efficiently parallelizable iterative solvers is generally recognized.  In this work we propose a new iterative algorithm for solving generalized least square systems with weights given by a block-diagonal matrix with Toeplitz blocks. Such cases are physically well motivated and correspond to measurement noise being piece-wise stationary -- a common occurrence in many actual observations. Our iterative algorithm is based on the conjugate gradient method and includes a parallel two-level preconditioner (2lvl-PCG) constructed from a limited number of sparse vectors estimated from the coefficients of the initial linear system.  Our prototypical application is the map-making problem in the Cosmic Microwave Background data analysis. We show experimentally that our parallel implementation of 2lvl-PCG outperforms by a factor of up to 6 the standard one-level PCG in terms of both the convergence rate and the time to solution on up to 12, 228 cores of NERSC's Cray XE6 (Hopper) system displaying nearly perfect strong and weak scaling behavior in this regime.	cosmic;coefficient;conjugate gradient method;cray xe6;experiment;hopper;image scaling;iterative method;linear system;microwave;preconditioner;rate of convergence;scalability;sparse matrix;stationary process;toeplitz hash algorithm	Laura Grigori;Radek Stompor;Mikolaj Szydlarski	2012	2012 International Conference for High Performance Computing, Networking, Storage and Analysis		parallel processing;covariance matrix;mathematical optimization;parallel computing;sparse matrix;computer science;noise measurement;noise;theoretical computer science;parallel algorithm;iterative method;cosmology;matrix decomposition;metadata;statistics;algebra	HPC	45.962474672579546	2.8888048305931284	143189
8e2b30f80330b89253ed9161e75f274f5fff2a69	compression of navigable speech soundfield zones	soundfield;speech time frequency analysis azimuth navigation speech coding microphones bit rate;perceptual quality;navigable;bepress selected works;speech;speech coding;compression navigable speech soundfield zones;compressed signals navigable speech soundfield zones speech coding architecture;zones;compression	This paper presents a new coding architecture for the compression of navigable speech soundfield zones. The proposed coding scheme encodes multiple speech soundfields, each representing different spatial zones, into a mono or stereo sound-field mixture signal that can be compressed with an existing speech or audio coder. The resulting compressed signals can be decoded back to individual soundfield zones. Objective and subjective testing results show that the approach successfully compresses up to 3 speech soundfields (each consisting of 4 individual speakers) at a bit rate of 48 kbps whilst maintaining the perceptual quality of each decoded soundfield zone.	data rate units;database;sparse matrix;while	Xiguang Zheng;Christian Ritz	2011	2011 IEEE 13th International Workshop on Multimedia Signal Processing	10.1109/MMSP.2011.6093795	speech recognition;computer science;speech;speech coding;speech processing;compression	Vision	47.951282013734584	-8.667111670535753	143566
137b564187a63acaf06ea9ebd75fee295187e81e	extending the opengeospatials specification for managing discrete and continuous time dependent data	continuous time;dependent data			Luca Paolino;Monica Sebillo;Genny Tortora;Giuliana Vitiello	2007		10.1007/978-3-540-72385-1_16	real-time computing	DB	39.28363947917279	4.148328679400419	143645
3aae04148b3053e62b0c52f422677862f443837c	companded quantization of speech mdct coefficients	codage parole;psicoacustico;audio signal processing;vector quantization vq;speech psychology discrete cosine transforms vector quantization psychoacoustic models multidimensional systems masking threshold lattices sampling methods frequency;modified discrete cosine transform mdct;computational complexity speech coding voice communication audio coding discrete cosine transforms vector quantisation statistical analysis;transformation cosinus discrete;speech processing;tratamiento palabra;code generation;psychoacoustique;traitement parole;sampling frequency;speech coding;statistical model;vector quantization vq audio coding modified discrete cosine transform mdct psycho acoustics speech coding statistical modeling;audio coding;interframe memory exploitation companded quantization speech mdct coefficient speech coding procedure speech specific processing packet based voice communication generic audio coding modified discrete cosine transform signal representation vector quantization technique weighted quantization multidimensional mdct psychoacoustic analysis;cuantificacion vectorial;vector quantization;statistical analysis;traitement signal audio;computational complexity;voice communication;discrete cosine transforms;analyse performance;performance analysis;psycho acoustics;modele statistique;modelo estadistico;modified discrete cosine transform;vector quantizer;statistical modeling;vector quantisation;psychoacoustics;analisis eficacia;quantification vectorielle	Here, we propose speech-coding procedures achieving high subjective quality, avoiding speech-specific processing and interframe exploitation. Thus, the scheme is tractable for packet-based voice communication, and has the capability of coding generic audio. The architecture is based on an modified discrete cosine transform (MDCT) representation of the signal, and combines efficient vector quantization (VQ) techniques with psychoacoustic principles. Weighted quantization of MDCT coefficients is performed, using a codebook based on a statistical model of the multidimensional MDCT pdf. The weighting and the codebook are adapted for each frame to account for masking thresholds given by a psychoacoustic analysis. Actual quantization is performed using lattices, thereby, achieving close to rate independent complexity. The result is a coding scheme operational at a range of rates. Here, a particular instance at 16 kbits/s, using a sampling frequency of 8 kHz, is shown to perform better than an LD-CELP operating at the same rate, even though no interframe memory is exploited.	aac-ld;cobham's thesis;code-excited linear prediction;codebook;coding theory;coefficient;companding;data rate units;modified discrete cosine transform;network packet;portable document format;psychoacoustics;sampling (signal processing);statistical model;vector quantization	Fredrik Nordén;Per Hedelin	2005	IEEE Transactions on Speech and Audio Processing	10.1109/TSA.2004.838535	statistical model;speech recognition;computer science;psychoacoustics;speech processing;mathematics;linde–buzo–gray algorithm;statistics	Visualization	47.614669961958555	-9.478208912429311	144275
8dd260fa99a91ea5ab4c2b2e47417caab6f2f9eb	ultra-fast carrier transport simulation on the grid. quasi-random approach	quantum effect;stochastic algorithm;computational grid;kinetic equation;electric field;large scale;quantum wire;monte carlo method;quasi monte carlo;monte carlo;random numbers;grid computing;electron phonon interaction	The problem for simulation ultra-fast carrier transport in nano-electronics devices is a large scale computational problem and requires HPC and/or Grid computing resources. The most widely used techniques for modeling this carrier transport are Monte Carlo methods. In this work we consider a set of stochastic algorithms for solving quantum kinetic equations describing quantum effects during the femtosecond relaxation process due to electron-phonon interaction in one-band semiconductors or quantum wires. The algorithms are integrated in a Grid-enabled package named Stochas-tic ALgorithms for Ultra-fast Transport in sEmiconductors (SALUTE). There are two main reasons for running this package on the computational Grid: (i) quantum problems are very computationally intensive; (ii) the inherently parallel nature of Monte Carlo applications makes efficient use of Grid resources. Grid (distributed) Monte Carlo applications require that the underlying random number streams in each subtask are independent in a statistical sense. The efficient application of quasi-Monte Carlo algorithms entails additional difficulties due to the possibility of job failures and the inhomogeneous nature of the Grid resource. In this paper we study the quasi-random approach in SALUTE and the performance of the corresponding algorithms on the grid, using the scrambled Halton, Sobol and Niederreiter sequences. A large number of tests have been performed on the EGEE and SEEGRID grid infrastructures using specially developed grid implementation scheme. Novel results for energy and density distribution, obtained in the inhomogeneous case with applied electric field are presented.	algorithm;computational problem;egi;electron;gnu nano;grid computing;hans moravec;linear programming relaxation;low-discrepancy sequence;monte carlo method;phonon;quantum hall effect;quantum wire;quasi-monte carlo method;random number generation;semiconductor;simulation	Emanouil I. Atanassov;Todor V. Gurov;Aneta Karaivanova	2001	Scalable Computing: Practice and Experience	10.12694/scpe.v11i2.648	statistical physics;quantum monte carlo;monte carlo method in statistical physics;quasi-monte carlo method;mathematical optimization;dynamic monte carlo method;hybrid monte carlo;markov chain monte carlo;computer science;theoretical computer science;monte carlo molecular modeling;kinetic monte carlo;monte carlo integration;monte carlo method	HPC	42.036816348749184	1.2878495885724732	144805
b19b328c6b6baa64470be1c2731c7e7c2651bb06	cuba - a library for multidimensional numerical integration		Program summary Title of program: Cuba Catalogue identifier: ADVH_v1_3 Program summary URL: http://cpc.cs.qub.ac.uk/summaries/ADVH_v1_3 Catalogue identifier of previous version: ADVH_v1_0 Journal Reference of previous version: Comput. Phys. Comm. 168 (2) 78–95, doi:10.1016/j.cpc.2005.01.010 Program obtainable from: CPC Program Library, Queen's University of Belfast, N. Ireland Computer for which the program is designed and others on which is has been tested: Designed for: all platforms with an ISO C99 C compiler Tested on: x86 (Linux/gcc), Alpha (Tru64 Unix/gcc), PowerPC (Mac OS X/gcc) Operating systems or monitors under which the program has been tested: Linux, Tru64 Unix, Mac OS X Programming language used: C Memory required to execute with typical data: 1M words No. of bits in a word: 8 No. of processors used: 1 Has the code been vectorized or parallelized?: No No. of lines in distributed program, including test data, etc.: 14 972 No. of bytes in distributed program, including test data, etc.: 133 344 Distribution format: gzipped tar archive Nature of the physical problem: Multidimensional numerical integrations, e.g., of phase spaces. Method of solution: The Cuba library contains the four algorithms Vegas, Suave, Divonne, and Cuhre with the following characteristics: Routine Basic integration method Algorithm type Variance reduction Vegas Sobol quasi-random sample Monte Carlo importance sampling Suave Sobol quasi-random sample Monte Carlo globally adaptive subdivision Divonne Korobov quasi-random sample Monte Carlo stratified sampling, or Sobol quasi-random sample Monte Carlo  aided by methods from or cubature rules deterministic  numerical optimization Cuhre cubature rules deterministic globally adaptive subdivision Typical running time: Varies greatly depending on the integrand and the chosen accuracy. Can range from seconds to days. Unusual features of the program: Coherent interface in Fortran, C/C++, and Mathematica. Can integrate vector integrands. Does the new version supersede the previous version?: Yes Reasons for the new version: User-requested improvements Summary of revisions: Version 1.3 adds versions of the integration routines where all number-of-points-like quantities are 64-bit integers ( long long int in C, integer*8 in Fortran). This can become necessary in cases of slow convergence. The corresponding routine names are prefixed with “ ll ”. PACS 02.60.Jh Keywords Multidimensional numerical integration Monte Carlo methods Cubature rules Variance reduction	numerical analysis;numerical integration	Thomas Hahn	2007	Computer Physics Communications	10.1016/j.cpc.2007.03.006		HPC	42.236665421376316	3.295345245726521	144832
671b8b59c0758a09bbf837c7ebd3348d07cb58cb	hydrogen production from a large digester gas plant - plant layout, modeling, and evaluation	organic waste;generators;anaerobic digester plant;internal combustion engines biofuel electrolysis fuel cell vehicles hydrogen economy;hydrogen production microorganisms internal combustion engines waste materials biological materials solids carbon dioxide electrochemical processes fuels;fuel cell vehicle;fuel cell vehicles;biological system modeling;hydrogen production;electrolyser hydrogen production digester gas plant anaerobic digester plant biogas engine hydrogen generation water electrolysis internal combustion engine fuel cell vehicles;digester gas plant;biofuel;hydrogen generation;biogas engine;engines;internal combustion engines;electrolyser;internal combustion engine;electrolysis;mathematical model;hydrogen economy;production;anaerobic digestion;hydrogen storage;microorganisms;water electrolysis	The technical features of a large (300 - 500 kW) anaerobic digester (AD) plant operating on recycled organic waste are presented. The plant is located on the remote Hebridean island of Lewis off the west coast of Scotland. Excess electrical production from the AD plant's biogas engine will be used by the Hebridean Hydrogen Park currently under development for the generation of hydrogen through water electrolysis. The hydrogen in turn will be used to provide fuel for a transport fleet of hydrogen internal combustion engine or fuel cell vehicles on the island. Results of modeling carried out on the digester and electrolyser are presented and an up-date on current progress is presented.	hydrogen;offset binary	Sinclair Gair;Neil Finlayson;A. M. de Martini;Ruairi D. MacIver	2008	2008 IEEE Industry Applications Society Annual Meeting	10.1109/08IAS.2008.130	hydrogen economy;environmental engineering;engineering;automotive engineering;waste management	EDA	53.050080289626905	-8.616096493263878	145764
9b72dacb9bcd98dfd73b3beeae3db23e3067ce8e	parallelizing particle simulations based on the boltzmann equation	algoritmo paralelo;boltzmann equation;parallel algorithm;efficiency;simulacion numerica;methode point fini;algorithme parallele;ecuacion boltzmann;eficacia;ecuacion transporte;flujo tridimensional;parallelisation;simulation numerique;analyse performance;performance analysis;equation transport;efficacite;three dimensional flow;transport equation;equation boltzmann;ecoulement tridimensionnel;numerical simulation;analisis eficacia	Schfiller, A., Parallelizing particle simulations based on the Boltzmann equation, Parallel Computing 18 (1992) 269-279. Particle simulations are the most widely used methods for the numerical solution of the Boltzmann equation. Since such applications are very demanding with respect to computing resources, their parallelization is of particular interest. Starting from a sequential algorithm, some parallelization aspects are discussed in this paper. The parallelization strategy of suitably partitioning the domain into subdomains, which in turn are mapped to different processes, proves to be successful. Numerical results demonstrate the efficiency of the parallelization.	numerical method;numerical partial differential equations;parallel computing;restricted boltzmann machine;sequential algorithm;simulation	A. Schuller	1992	Parallel Computing	10.1016/0167-8191(92)90096-P	computer simulation;mathematical optimization;parallel computing;boltzmann equation;computer science;convection–diffusion equation;mathematics;parallel algorithm;efficiency;algorithm	HPC	44.53656835130001	3.206133920677017	145877
113aa28d880674e9b94b5724e9ab185a310ef10b	integrated electronic system design for an implantable wireless batteryless blood pressure sensing microsystem	adaptive rf powering;wireless sensor networks blood pressure radio frequency biomedical monitoring animals sensor systems laboratories capacitance rf signals feedback;wireless data telemetry;biomedical measurements;wireless sensor networks biomedical electronics biomedical telemetry biomems blood pressure measurement power supplies to apparatus prosthetics;real time;wireless blood pressure sensing microsystem;blood pressure;prosthetics;wireless communication;blood pressure sensing capability;system design;biomedical electronics;instrumented circular cuff;power supplies to apparatus;biomedical telemetry;implantable blood pressure sensing microsystem;batteryless blood pressure sensing microsystem;blood pressure measurement;soft cuff elasticity;wireless data;integrated electronic system design;wireless sensor networks;adaptive rf powering integrated electronic system design implantable blood pressure sensing microsystem wireless blood pressure sensing microsystem batteryless blood pressure sensing microsystem instrumented circular cuff soft cuff elasticity blood pressure sensing capability wireless data telemetry;blood vessels;biomems	A wireless, batteryless, less invasive blood pressure sensing microsystem based on an instrumented circular cuff has been developed for advanced biological research. The proposed sensing technique avoids vessel penetration and substantially minimizes vessel restriction due to the soft cuff elasticity. The integrated electronic system design is presented with emphases on the design trade-off and system considerations. The measurement results demonstrate full functionality of the microsystems with real-time high-fidelity blood pressure sensing capability under wireless data telemetry and adaptive RF powering conditions.	elasticity (cloud computing);radio frequency;real-time clock;real-time computing;systems design	Peng Cong;Wen H. Ko;Darrin J. Young	2010	IEEE Communications Magazine	10.1109/MCOM.2010.5439082	computer science;blood pressure	Mobile	47.38418461359489	-0.44533779857563305	147149
f10ff17d6229eaf953069ed65d50cf507826212b	spatiotemporal compression for efficient storage and transmission of high-resolution electrocorticography data	discrete wavelet transforms;video signal processing;correlation image coding electrodes discrete cosine transforms transform coding standards psnr;algorithms brain computer interfaces computer security electrodes implanted electroencephalography epilepsy humans wireless technology;video signal processing biomedical equipment brain computer interfaces data reduction discrete cosine transforms discrete wavelet transforms electroencephalography medical disorders medical signal processing neurophysiology prosthetics spatiotemporal phenomena;prosthetics;medical disorders;discrete cosine transforms;spatiotemporal phenomena;ultralow power implantable devices high resolution electrocorticography data localized neural activity high temporal resolution high spatial resolution brain computer interfaces bci seizure detection epilepsy hr ecog data compression algorithms implantable wireless medical devices hr ecog recordings hr ecog signals video image signals video image compression motion estimation discrete cosine transform discrete wavelet transform low power requirements spatiotemporal compression methods data reduction low hardware complexity dct based methods dct based compression;data reduction;neurophysiology;brain computer interfaces;electroencephalography;medical signal processing;biomedical equipment	High-resolution Electrocorticography (HR-ECoG) has emerged as a key strategic technology for recording localized neural activity with high temporal and spatial resolution with potential applications in brain-computer interfaces (BCI), and seizure detection for epilepsy. However, HR-ECoG has 400 times the resolution of conventional ECoG, making it a challenge to process, transmit and store the HR-ECoG data. Therefore, simple and efficient compression algorithms are vital for the feasibility of implantable wireless medical devices for HR-ECoG recordings. In this paper, following the observation that HR-ECoG signals have both high spatial and temporal correlations similar to video/image signals, various compression methods suitable for video/image- compression based on motion estimation, discrete cosine transform (DCT) and discrete wavelet transform (DWT)- are investigated for compressing HR-ECoG data. We first simplify these methods to satisfy the low-power requirements for implantable devices. Then, we demonstrate that spatiotemporal compression methods produce up to 46% more data reduction on HR-ECoG data than compression methods using only spatial compression do. We further show that this data reduction can be achieved with low hardware complexity. In particular, among the methods investigated, spatiotemporal compression using DCT-based methods provide the best trade-off between hardware complexity and compression performance, and thus we conclude that DCT-based compression is a promising solution for ultralow-power implantable devices for HR-ECoG.	algorithm;brain-computer interfaces;data compression;discrete cosine transform;discrete wavelet transform;electrocorticography;epilepsy;image compression;image resolution;implants;low-power broadcasting;medical devices;motion estimation;requirement;seizures;heart rate	Taehoon Kim;Nabi Sertac Artan;Jonathan Viventi;H. Jonathan Chao	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6346105	data compression;lossy compression;brain–computer interface;computer vision;electronic engineering;data reduction;neuroscience;speech recognition;electroencephalography;image compression;computer science;neurophysiology	EDA	41.19419049421702	-5.496802570570611	147371
6b277b1e3c03285291380c42a666fee4ccb56b2f	experimental study on watermark interference in multiple re-watermarking	filigranage numerique;protection information;digital watermarking;robust watermarking;proteccion informacion;bande frequence;frequency band;information protection;filigrana digital;banda frecuencia	Watermark interference is a threat to reliable detection in multiple re-watermarking scenarios. The impact of using disjoint frequency bands and/or different embedding domains in limiting those interferences is evaluated and compared. Employing disjoint frequency bands for embedding different watermarks turns out to be more effective and is capable of maintaining reasonable detection correlation in multiple embedding applications.	artificial intelligence;digital watermarking;embedded system;frequency band;interference (communication);threat (computer)	Daniel Mark;Andreas Uhl;Hartmut Wernisch	2007		10.1117/12.699167	telecommunications;digital watermarking;electrical engineering;computer security;information protection policy	Metrics	42.07828056355975	-8.39198066262107	147677
b516acd29357967c8dc5c0c053bc3fbec9a1f597	spatial spectrum analyzer (ssa): a tool for calculations of spatial distribution of fast fourier transform spectrum from object oriented micromagnetic framework output data	micromagnetics;local modes;fast fourier transform;spatial distribution;object oriented micromagnetic framework	We present a tool for calculations of Fourier transform spatial distribution taken from magnetization dynamics simulated in Object Oriented Micromagnetic Framework (OOMMF). In OOMMF, as well as in other popular micromagnetic software, output data is organized as magnetization vectors from each simulation cell written down to separate file for each simulation step. Therefore, we use parallel computations to reorganize data in files containing time evolution for each cell. Fast Fourier transform is obtained for selected time period by parallel computations using Matlab. The output is a spatial distribution of the magnitude for the selected frequency in the sample cross-section. It allows for analysis of spin waves localization and therefore helps to understand their origin in investigated sample.#R##N#Program summary#R##N#Program title: Spatial Spectrum Analyzer (SSA)#R##N##R##N#Catalogue identifier: AEUU_v1_0#R##N##R##N#Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEUU_v1_0.html#R##N##R##N#Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland#R##N##R##N#Licensing provisions: Standard CPC licence, http://cpc.cs.qub.ac.uk/licence/licence.html#R##N##R##N#No. of lines in distributed program, including test data, etc.: 6459509#R##N##R##N#No. of bytes in distributed program, including test data, etc.: 134249057#R##N##R##N#Distribution format: tar.gz#R##N##R##N#Programming language: Bourne Again SHell (Bash), MATLAB.#R##N##R##N#Computer: Any computer with MATLAB and Bourne Again SHell (Bash) installed.#R##N##R##N#Operating system: Any system with MATLAB and Bourne Again SHell (Bash) installed.#R##N##R##N#Classification: 9.#R##N##R##N#External routines: MATLAB Parallel Computing Toolbox#R##N##R##N#Nature of problem:#R##N##R##N#Numerous dynamic problems of ferromagnetic structures can be investigated by micromagnetic simulations using The Object Oriented MicroMagnetic Framework (OOMMF). However, large amounts of OOMMF output data (typically magnetization configuration files take up several gigabytes for few nanoseconds simulation, depending on the structure size) are difficult to process because of being stored in separate files for each simulation step. In particular, for the Fourier Transform (FT) purposes data from all time steps in a single point is needed, but instead the standard output provided by OOMMF and other popular micromagnetic software contains data from all points in a single time step. What is more, calculations of FT for each simulation cell are usually a demanding task. The total time for sequential analysis can exceed the simulation time itself up to several times.#R##N##R##N#Solution method:#R##N##R##N#The SSA tool reorganizes the simulation data into separate files, which describe a single simulation point each and contain values from all time steps. Afterwards, reorganized files are used to compute Fast Fourier Transform for a chosen frequency. The final result is a spectral density map of a sample at a given frequency. Both parts of the SSA tool make use of parallel computing, greatly decreasing the total time needed to process the data.#R##N##R##N#Additional comments:#R##N##R##N#The distribution file for this program is over 134 Mbytes and therefore is not delivered directly when Download or E-mail is requested. Instead a html file, giving details of how the program can be obtained, is sent.#R##N##R##N#Running time:#R##N##R##N#Strongly depends on sample size and time span. Time for the example described in this paper varies from single hours to few days depending on the number of involved processes.	fast fourier transform;spectrum analyzer	Marek Frankowski;Jakub Checinski;Maciej Czapkiewicz	2015	Computer Physics Communications	10.1016/j.cpc.2014.10.027	fast fourier transform;simulation;computer hardware;computer science;theoretical computer science;micromagnetics;mathematics;physics	Theory	42.44935818320183	3.1409696147431725	147930
6520970c15145c0d9431261e4d62f25717d9d3d9	employing k-ary n-cubes for parallel lagrange interpolation	lagrange interpolation;parallel algorithm;performance evaluation;interconnection network;k ary n cubus;performance analysis;interconnection networks;speedup;multicomputer;parallel algorithms	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	euler–lagrange equation;francis;interpolation;lagrange polynomial;olap cube;primary source	Hamid Sarbazi-Azad;Mohamed Ould-Khaoua;Lewis M. Mackenzie	2001	Parallel Algorithms Appl.	10.1080/01495730108935275	mathematical optimization;parallel computing;computer science;theoretical computer science;parallel algorithm;algorithm	Robotics	48.56016984914493	-2.9504897787050997	148300
b8da35ea4dfc0ba0ab4b11461ac034b755308d14	simultaneous optimization and heat integration of the coal-to-sng process with a branched heat recovery steam cycle		Abstract The coal-to-SNG process is an energy-intensive process, and optimizing the heat recovery network can improve the economy and energy efficiency. This study proposes a branched, triple pressure level heat recovery steam cycle (HRSC) to recover waste heat, in which one branch is responsible for recovering the waste heat from the water gas shift (WGS) unit, and the other branch is responsible for the methanation (METH) unit. The extended Duran-Grossmann model is used to optimize two heat exchanger networks to match the branched HRSC superstructure. The temperature/pressure/flow rates of the HRSC streams and the operating temperature of the WGS and METH units are optimized. The optimal bypass ratio of the WGS unit as well as the recycle ratio and split ratio of the METH unit, are 0.506, 0.681 and 0.456, respectively. The exergy efficiency of the coal-to-SNG plant is improved by 1.28% compared with the industrial plant, which can reach 54.17%.	mathematical optimization;social network game	Bo Huang;Yang Li;Rui Gao;Yongfei Zuo;Zhenghua Dai;Fuchen Wang	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2018.02.008	control engineering;heat recovery ventilation;heat exchanger;streams;rankine cycle;mathematics;bypass ratio;waste heat;exergy efficiency;methanation;chromatography	DB	53.273771315815395	-5.619956462082223	148743
6e56471a86955d4ea5b6a8098c28658a7c5ee86b	a log-domain implementation of the mihalas-niebur neuron model	first order log domain low pass filters;adaptive thresholding;neural nets;neurons biological system modeling biomembranes brain modeling differential equations circuits threshold voltage neuroscience low pass filters information filtering;building block;biological system modeling;adaptive threshold;leaky integrate and fire;modular neuron;neural nets low pass filters;low pass filter;biomembranes;manganese;biological neurons;biological neurons mihalas niebur neuron model first order log domain low pass filters leaky integrate and fire core adaptive threshold spike induced currents modular neuron;first order;mihalas niebur neuron model;integrated circuit modeling;mathematical model;low pass filters;neurons;spike induced currents;leaky integrate and fire core	We present an electronic neuron that uses first-order log-domain low-pass filters to implement the Mihalas-Niebur model. The neuron consists of a leaky-integrate-and-fire core and building blocks to implement an adaptive threshold and spike induced currents. Simulation results show that this modular neuron can emulate different spiking behaviours observed in biological neurons.	action potential;artificial neuron;biological neuron model;first-order predicate;low-pass filter;simulation	André van Schaik;Craig T. Jin;Alistair Lee McEwan;Tara Julia Hamilton;Stefan Mihalas;Ernst Niebur	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537563	control engineering;computer vision;electronic engineering;low-pass filter;computer science;electrical engineering;machine learning;artificial neural network	Embedded	40.10203763349679	-0.8784426774507529	149251
c8f84c7c3991a4144b32e2ccc5617a315033fb33	performance analysis of compressed-domain automatic speaker recognition as a function of speech coding technique and bit rate	databases;codec speech quality automatic speaker recognition compressed domain speech coding standards voip;speech coding standards;codecs;data compression;decoding;speech coding code standards data compression internet telephony speaker recognition speech codecs;speech analysis;performance analysis speaker recognition speech coding bit rate speech analysis speech recognition decoding automatic speech recognition databases codecs;low complexity;speech coding;code standards;bit rate;internet telephony;speaker recognition;automatic speech recognition;automatic speaker recognition;speech codecs;codec speech quality;compressed domain;performance analysis;speech recognition;voip	Compressed-domain automatic speaker recognition is based on the analysis of the compressed parameters of speech coders. The objective is to perform low-complexity on-line speaker recognition for VoIP in the compressed domain, without the need to decode or resynthesize the speech bitstream. In this paper, we present initial results in determining the recognition accuracy that can be achieved with five widely used speech coding standards. Experiments with a database of 14 speakers obtain a recognition ratio close to 100% after the analysis of 30 seconds of active speech for most of the considered speech coders and rates. In particular, the results show that performance does not strictly depend on coding rate or codec speech quality	bitstream;codec;database;online and offline;profiling (computer programming);speaker recognition;speech coding	Matteo Petracca;Antonio Servetti;Juan Carlos De Martin	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262799	data compression;voice activity detection;natural language processing;adaptive multi-rate audio codec;speaker recognition;codec2;speaker diarisation;audio mining;linear predictive coding;speech recognition;full rate;computer science;speech coding;voice over ip;speech processing;acoustic model	Robotics	47.94165807723262	-8.1479892398935	149272
305f53cca023d2531a29cb49d9a92484451ae895	simultaneous seismic compression and denoising using a lapped transform coder	presses;natural images;lapped transform;noise presses;noise	Compression and denoising are two of the most successful applications of wavelets to signals and natural images. Both techniques have also been successfully applied to seismic signals, but compression is not widely accepted yet, since it is often believed to harm seismic information.	lapped transform;noise reduction;transform coding;wavelet	Laurent Duval	2002	2002 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2002.5744033	speech recognition;lapped transform;noise	Robotics	46.09989891878871	-9.040014214746362	149594
1338e7b9143dbdf4f58710aa11b91966d497bd64	audio signal processing using time-frequency approaches: coding, classification, fingerprinting, and watermarking	signal image and speech processing;audio signal processing;time frequency;quantum information technology spintronics	Audio signals are information rich nonstationary signals that play an important role in our day-to-day communication, perception of environment, and entertainment. Due to its non-stationary nature, timeor frequency-only approaches are inadequate in analyzing these signals. A joint time-frequency (TF) approach would be a better choice to efficiently process these signals. In this digital era, compression, intelligent indexing for content-based retrieval, classification, and protection of digital audio content are few of the areas that encapsulate a majority of the audio signal processing applications. In this paper, we present a comprehensive array of TF methodologies that successfully address applications in all of the above mentioned areas. A TF-based audio coding scheme with novel psychoacoustics model, music classification, audio classification of environmental sounds, audio fingerprinting, and audio watermarking will be presented to demonstrate the advantages of using time-frequency approaches in analyzing and extracting information from audio signals.	acoustic fingerprint;arithmetic coding;audio signal processing;bch code;basic block;chirp;data compression;digital watermarking;embedded system;error detection and correction;feature extraction;fingerprint (computing);forward error correction;linear phase;nonlinear system;psychoacoustics;radio fingerprinting;stationary process;type signature;watermark (data file);x.690	Karthikeyan Umapathy;Behnaz Ghoraani;Sridhar Krishnan	2010	EURASIP J. Adv. Sig. Proc.	10.1155/2010/451695	audio electronics;sub-band coding;audio mining;speech recognition;time–frequency analysis;aes11;audio signal processing;computer science;digital signal processing;speech coding;anti-aliasing;multimedia	HCI	43.721229172984394	-8.672270098744953	149654
4605718a8b4ff737bff5c01e866ebbac5ac4133b	wideband speech coding with hybrid digital-analog transmission	phase change materials;quality saturation effect wideband speech coding hybrid digital analog transmission digital transmission quantization errors decoded speech signal quantization errors hybrid digital analog codes quantization error quasi analog methods hda concept adpcm coding digital transmission systems channel qualities;decoding;speech;speech coding;quantization signal;websearch;speech quantization signal speech coding decoding digital analog conversion phase change materials;speech coding quantisation signal;lattice adpcm speech coding hybrid digital analog hda transmission;digital analog conversion;ikz613310;rwth publications	Efficient digital transmission of speech requires source coding which comes at the price of unavoidable quantization errors. Thus, even in clear channel conditions, the quality of the decoded speech signal is limited due to the quantization errors. Hybrid Digital-Analog (HDA) codes circumvent this limitation by additionally transmitting the quantization error with quasi-analog methods (discrete-time, quasi-continuous-amplitude) with neither increasing the total transmission power, nor the occupied frequency bandwidth on the radio channel. So far, the HDA concept has mainly been applied to random parameters. In this paper, the HDA concept is adapted to the transmission of wideband speech signals using PCM and ADPCM coding. By experimental verification it is shown that the HDA concept may outperform conventional purely digital transmission systems at all channel qualities while additionally eliminating the quality saturation effect.	adaptive differential pulse-code modulation;analog transmission;bandwidth (signal processing);code;data compression;hd radio;quantization (signal processing);speech coding;transmitter	Matthias Rüngeler;Fabian Kleifgen;Peter Vary	2015	2015 23rd European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2015.7362490	voice activity detection;electronic engineering;linear predictive coding;speech recognition;quantization;telecommunications;computer science;speech coding;speech processing	EDA	48.669315757398266	-8.321335901292326	149872
5fd98f407e5728c88d35bb4d1a35acbb694789fa	on implementing two adaptive data-compression schemes	metodo adaptativo;donnee textuelle;codage intervalle;procesamiento informacion;data compression;dato textual;implementation;codage transpose;chaine caractere;stockage donnee;methode adaptative;ejecucion;data storage;codificacion;codage move to frout;cadena caracter;adaptive method;information processing;coding;textual data;almacenamiento datos;compresion dato;traitement information;compression donnee;codage;character string	The invention relates to a fastening element of synthetic material comprising a sleeve-like hollow insert member adapted to be inserted into a prefabricated opening in a carrier plate and engaging beneath the underside of the opening edge by means of an undercut formed integrally therewith, and a head member connected to the insert member for fastening an article at the carrier member, with either the article to be fastened or the head member lying in close engagement with the side of the carrier plate opposite the undercut.	data compression	Erkki Mäkinen	1989	Comput. J.	10.1093/comjnl/32.3.238	data compression;string;information processing;computer science;theoretical computer science;computer data storage;database;coding;programming language;implementation;algorithm;statistics	Theory	43.39137930796552	-5.9706259905076005	149884
55b681227ee85e2cdf3ff7a7ea2816d69413625c	occupancy estimation using ultrasonic chirps	algorithm;machine learning;occupancy detection;ultrasonic sensing	Estimating the number of people within a room is important for a wide variety of applications including: HVAC load management, scheduling room allocations and guiding first responders to areas with trapped people. In this paper, we present an active sensing technique that uses changes in a room's acoustic properties to estimate the number of occupants. Frequency dependent models of reverberation and room capacity are often used when designing auditoriums and concert halls. We leverage this property by using measured changes in the ultrasonic spectrum reflected back from a wide-band transmitter to estimate occupancy. A centrally located beacon transmits an ultrasonic chirp and then records how the signal dissipates over time. By analyzing the frequency response over the chirp's bandwidth at a few known occupancy levels, we are able to extrapolate the response as the number of people in the room changes. We explore the design of an excitation signal that best senses the environment with the fewest number of training samples. Through experimentation, we show that our approach is able to capture the number of people in a wide-variety of room configurations with people counting accuracy below 10% of the maximum room capacity count with as few as two training points. Finally, we provide a simple mechanism that allows our system to recalibrate when we know the room is empty so that it can adapt dynamically over time.	acoustic cryptanalysis;chirp;extrapolation;frequency response;load management;scheduling (computing);transmitter	Oliver Shih;Anthony Rowe	2015		10.1145/2735960.2735969	simulation;speech recognition;telecommunications;computer science;engineering;machine learning;algorithm	HCI	48.034495506484724	2.242109812347077	150060
b9834f06251372cd987a8b76bd4700f064443aac	a novel hierarchical decomposition vector quantization method for high-order lpc parameters	line spectral frequency;vector quantization line spectral frequency linear prediction coding lpc reflection coefficient scalable coding;speech;speech coding;linear prediction coding lpc;indexes;vector quantization;codebook hierarchical decomposition vector quantization method high order lpc parameters vector quantization coding linear prediction coding parameters scalable speech coding framework lpc analysis lpc parameters linear spectral frequency domain high order lpc model reflection coefficients decomposed low order lpc models high order lpc information direct vector quantization;vectors;speech codecs;speech coding linear codes quantisation signal;reflection coefficient;scalable coding;vector quantization speech vectors speech coding indexes speech codecs	The paper investigates vector quantization coding of high-order (e.g., 20th-50th order) linear prediction coding (LPC) parameters, and proposes a novel hierarchical decomposition vector quantization method for a scalable speech coding framework with variable orders of LPC analysis. Instead of vector quantizing the whole group of LPC parameters in the linear spectral frequency (LSF) domain directly, the proposed method decomposes the high-order LPC model into several low-order (e.g., 10th-order) LPC models, and vector quantizes them in the LSF domain separately. For the decomposition, the high-order LPC model is converted into a group of reflection coefficients at first, and then the group is split into several subgroups and converted into multiple low-order LPC models. It is shown that the proposed method is naturally suitable for a scalable coding framework where the information of the decomposed low-order LPC models can be encoded into a multi-layered bitstream and can be combined in a progressive way to recover the high-order LPC information. Experiments in a scalable coding framework with variable LPC analysis orders (10-50) reveal that, compared to a direct vector quantization scheme, the proposed method can reduce the size of the codebook and the number of coding bits significantly, and can also efficiently reduce the computation cost.	bitstream;codebook;coefficient;computation;lsf;linear predictive coding;scalability;speech coding;vector quantization	Lin Wang;Zhe Chen;Fuliang Yin	2015	IEEE/ACM Transactions on Audio, Speech, and Language Processing	10.1109/TASLP.2014.2380352	database index;speech recognition;harmonic vector excitation coding;computer science;speech;machine learning;speech coding;pattern recognition;reflection coefficient;mathematics;linguistics;vector quantization	ML	48.034676588325425	-9.334078923158112	150509
7476530ee9c906c32937409499c299111c976ba3	a bitrate and bandwidth scalable celp coder	bitrate scalable coder;multi stage excitation coding;embedded coding;mpeg 4 celp speech standard;wideband;speech synthesis;decoding;bandwidth scalability;multimedia applications;narrowband speech;multi pulse based celp coding;itu t g 722;signal analysis;base band coder;multimedia communication linear predictive coding speech coding vocoders;mos tests;mean opinion score tests;speech coding;multimedia application;testing;bit rate;speech quality;linear predictive coding;bit rate bandwidth scalability wideband narrowband speech synthesis testing signal synthesis decoding signal analysis;bandwidth extension tool;embedded coding approach;multimedia communication;vocoders;mean opinion score;bandwidth;bandwidth scalable coder;comparison test results;16 kbit s celp speech coder bandwidth scalable coder bitrate scalable coder multimedia applications multi pulse based celp coding base band coder bandwidth extension tool multi stage excitation coding embedded coding approach multi pulse excitation codebook bandwidth scalability bandwidth conversion comparison test results speech quality narrowband speech mos tests itu t g 722 mpeg 4 celp speech standard mean opinion score tests;16 kbit s;celp speech coder;scalability;signal synthesis;bandwidth conversion;multi pulse excitation codebook;narrowband	This paper proposes a flexible CELP speech coder with bitrate and bandwidth scalabilities for multimedia applications. The coder is based on multi-pulse-based CELP coding and consists of a bitrate scalable base-band coder and a bandwidth extension tool. The bitrate scalable base-band CELP coder employs multi-stage excitation coding based on an embedded-coding approach. The multipulse excitation codebook at each stage is adaptively produced depending on the selected excitation signal at the previous stage. The bandwidth scalability is realized by bandwidth-conversion from base-band CELP parameters to those for wideband without a widely used subband structure. The bandwidth-conversion improves base-band coding quality and expands bandwidth, simultaneously. The comparison test results show that the bitrate scalable coder is equivalent in speech quality to the fixed-bitrate CELP coder at the same bitrate for the narrowband speech. In the MOS tests, the proposed 16 kbit/s coder with the bandwidth scalability achieves equivalent coding quality to ITU-T G.722 at 56 kbit/s. The proposed coder is currently evaluated as the MPEG-4 CELP speech standard.	bandwidth extension;baseband;code-excited linear prediction;codebook;data rate units;embedded system;g.722;scalability;speech coding	Toshiyuki Nomura;Masahiro Iwadare;Masahiro Serizawa;Kazunori Ozawa	1998		10.1109/ICASSP.1998.674437	mean opinion score;average bitrate;selectable mode vocoder;scalability;linear predictive coding;speech recognition;telecommunications;computer science;speech coding;signal processing;software testing;variable bitrate;constant bitrate;speech synthesis;bandwidth;code-excited linear prediction	SE	47.711963697286656	-8.42662226658461	150556
24e7ac5c6c37efbf4a389d63602306111c7aabde	robust algorithm for watermark recovery from cropped speech	transform coding copy protection cryptography speech coding;transform encryption coding watermark recovery cropped speech digital watermarking techniques data cropping recovery process desynchronization;digital watermark;copy protection;environmental conditions;speech coding;transform coding;international conference on acoustics speech and signal processing;cryptography;robustness watermarking cryptography speech processing security filters costs energy measurement gain measurement signal processing	Most digital watermarking techniques are susceptible to damage by data cropping. Although the effects of cropping might not be perceptible, watermark recovery may be rendered difficult or impossible due to the desynchronization of the recovery process. The transform encryption coding (TEC) based watermarking algorithm was presented at ICASSP 2000 [2]. The present paper investigates the performance of TEC watermarking in the presence of cropping, and presents an algorithm that identifies cropped samples and recovers watermarks from the damaged record. Implementation details and experimental results under different environmental conditions are presented.	algorithm;digital watermarking;encryption;international conference on acoustics, speech, and signal processing	Aparna Gurijala;John R. Deller	2001		10.1109/ICASSP.2001.941180	transform coding;speech recognition;telecommunications;computer science;cryptography;electrical engineering;speech coding;mathematics;statistics	DB	42.256655320151175	-9.270343436974185	150682
b62a6cf59fd3dc217783f80e7d36ad50992552f2	an accurate clock offset estimation method between two moving objects based on maximum likelihood estimation		We consider a problem of accurate clock offset estimation between two moving objects. To establish clock synchronization between objects, the principle of the Two Way Ranging (TWR) method has been commonly used in the Network Time Protocol (NTP), the IEEE 1588 standard and so on. In this paper, we first reveal that they do not perform accurately at all when two objects are in motion. Next, to solve the problem, we propose an accurate clock offset estimation method. In the proposed method, we utilize the location information on the two objects as well, and taking into consideration that the measured distance between them is not Gaussian-but Rician-distributed, we strictly derive the Maximum Likelihood estimation (ML) on the clock offset. Then, to reduce the computational complexity of the strict ML method, we introduce two approximated ML methods. In computer simulation, we show that the proposed method outperforms conventional methods, achieving the clock offset estimation accuracy of less than several tens of nanoseconds, which is required for current and future wireless communication tools among moving objects.	approximation algorithm;clock synchronization;computational complexity theory;computer simulation;kernel density estimation;newton's method;precision time protocol;stationary process;time of arrival	Kousuke Matsui;Shinsuke Hara	2017	2017 23rd Asia-Pacific Conference on Communications (APCC)	10.23919/APCC.2017.8303959	real-time computing;computer science;clock synchronization;network time protocol;computational complexity theory;maximum likelihood;synchronization;ranging;offset (computer science)	Robotics	50.2010438762786	0.9804550098000353	150985
5e4765d1b957a35b4e38be8dc68cc5ccb1c9f211	acoustic source localization fusing sparse direction of arrival estimates	direction of arrival estimation sensor fusion acoustic sensors wireless sensor networks acoustic signal detection base stations fuses measurement errors sensor systems middleware;wireless sensor networks acoustic signal processing direction of arrival estimation sensor fusion tracking;tracking system;measurement error;error analysis acoustic source localization wireless sensor network tracking system acoustic channel direction of arrival estimation distributed sensing sensor fusion system architecture middleware service;acoustic channel;doa estimation;direction of arrival;acoustic signal processing;wireless sensor network;error analysis;acoustic source localization;base station;sensor nodes;middleware;sensor fusion;system architecture;distributed sensing;middleware service;wireless sensor networks;tracking;direction of arrival estimation	This paper proposes a wireless sensor network based acoustics source localization and tracking system. Each individual node has a special purpose sensor board with four acoustic channels and a digital compass enabling direction of arrival (DOA) estimation of acoustic sources. Upon detecting a source of interest, the sparsely deployed sensor nodes report their DOA estimates to the base station that fuses the data for accurate localization. Due to the widely distributed sensing and the novel sensor fusion technique, the method can handle multiple measurement errors prevalent in reverberant environments. The paper presents the overall architecture of the system, as well as that of the advanced sensor board. Furthermore, it describes the DOA estimation algorithm and the applied middleware services for coordinated sensing and communication, introduces the sensor fusion algorithm and presents a detailed error analysis	acoustic cryptanalysis;algorithm;direction of arrival;error analysis (mathematics);kernel density estimation;middleware;routing;sensor node;sensor web;simulation;software deployment;sparse;tracking system	Ákos Lédeczi;Gergely Kis;Béla Fehér;Péter Völgyesi;György T Balogh	2006	2006 International Workshop on Intelligent Solutions in Embedded Systems	10.1109/WISES.2006.329124	embedded system;wireless sensor network;telecommunications;computer science;operating system;systems architecture	Mobile	50.440500843313835	3.830936826904766	151434
358aa3bb6fd3708575b40eb508a199d00d7d1604	objective performance evaluation of several state-of-the-art audio codecs		Opus, Advanced Audio Coding (AAC), and mp3 are well known audio codecs in the market. The goal of this research is to compare the quality of above three audio codecs at different bitrates and to determine which codec can maintain the best quality overall. An objective evaluation approach is presented and preliminary results are summarized.	advanced audio coding;codec;mp3;performance evaluation	Chiman Kwan;Yvonne Luk	2018	2018 Data Compression Conference	10.1109/DCC.2018.00071	speech recognition;data compression;theoretical computer science;computer science;codec;advanced audio coding;opus	DB	46.984931855852764	-7.960786659029277	151994
d3a630b937eed06002191666ec2bdee69c981d2d	bandwidth extension with hybrid signal extrapolation for audio coding	tecnologia electronica telecomunicaciones;bandwidth extension;audio coding;linear predictive extrapolation;tecnologias;perceptual audio coding;grupo a	In this paper, we propose a blind method using hybrid signal extrapolation at the decoder to regenerate lost high-frequency components which are removed by encoders. At first, a decoded signal spectral resolution is enhanced by time domain linear predictive extrapolation and then the cut off frequency of each frame is estimated to avoid the spectrum gap between the end of original low frequency spectrum and the beginning of reconstructed high frequency spectrum. By utilizing a correlation between the high frequency spectrum and low frequency spectrum, the low frequency spectrum component is employed to reconstruct the high frequency spectrum component by frequency domain linear predictive extrapolation. Experimental results show an effective improvement of the proposed method in terms of SNR and human listening test results. The proposed method can be used to reconstruct the lost high frequency component to improve the perceptual quality of audio independent of the compression method. key words: perceptual audio coding, bandwidth extension, linear predictive extrapolation	bandwidth extension;encoder;extrapolation;linear predictive coding;psychoacoustics;signal-to-noise ratio;spectral density	Chatree Budsabathon;Akinori Nishihara	2007	IEICE Transactions	10.1093/ietfec/e90-a.8.1564	speech recognition;bandwidth extension;telecommunications;computer science;frequency domain	EDA	48.14760922807594	-8.99407715411833	152061
872459f3d36e41da409c6b5828a7c1324365422d	parallelization of seismic wave calculation by impulse response functions	seismic waves;impulse response function		automatic parallelization;parallel computing	Kyoko Fukuda;Toshihiko Hayakawa;Hayaru Shouno;Kazuki Joe	2002			seismic wave;impulse response;computer science;dispersive body waves	EDA	44.83111732331849	3.1138826064791667	152191
c3f726b1eb5148bf81839bbf8060aeed5765039b	distributed kalman filtering with reduced transmission rate		The centralized Kalman filter can be implemented in such a way that the required calculations can be distributed over multiple nodes in a network, each of which processes only the locally acquired sensor data. The main downside of this implementation is that it requires each distributed sensor node to communicate with the fusion center in every time step so as to compute the optimal state estimate. In this paper, two distributed Kalman filtering algorithms are proposed to overcome these limitations. The first algorithm merely requires communication of each local sensor node with the fusion center in every other time step. The second algorithm even allows for a lower communicate rate. Both algorithms apply event-based communication to compute consistent estimates and to reduce the estimation error for a fixed communication rate. Simulations demonstrate that both algorithms perform better in terms of the mean squared estimation error than the centralized Kalman filter.	algorithm;centralized computing;computer simulation;full rate;kalman filter;least mean squares filter;sensor node	Katharina Dormann;Benjamin Noack;Uwe D. Hanebeck	2017	2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2017.8170437	artificial intelligence;kalman filter;real-time computing;machine learning;square (algebra);computer science;sensor node;transmission (mechanics)	Robotics	53.04536680693156	3.7847682418892927	152595
c6ebab60972f760fd57f015ec465df58e7762cab	a real-time wideband celp coder for a videophone application	code excited linear prediction;videotelephony;real time;speech coding;linear predictive coding;7 khz real time wideband celp coder videophone application algorithm coding speech signals code excited linear prediction audio visual coding systems isdn network telecommunication equipment full band approach computational complexity real time implementation single tms320c31 dsp encoder decoder performance ccitt rec g 722 subband coder 16 kbit s 64 kbit s;speech codecs;computational complexity;vocoders;digital signal processing chips;audio visual;real time implementation;subjective evaluation;digital signal processing chips linear predictive coding videotelephony speech coding vocoders computational complexity speech codecs;wideband speech synthesis speech coding signal synthesis filters speech analysis computational complexity digital signal processing testing linear predictive coding	In this paper we present an algorithm for the coding of wideband (7 kHz) speech signals at 16 kbps using code excited linear prediction (CELP), primarily intended for use in audio-visual coding systems (e.g., videotelephony) in the ISDN network, or other telecommunication equipment using loudspeaker sound. The algorithm is a full-band approach and much effort has been put into reducing the computational complexity. This has led to a real-time implementation of the present algorithm on a single TMS320C31 DSP (encoder+decoder). Through a formal subjective evaluation we have demonstrated a performance comparable to the CCITT Rec. G.722 subband coder at 64 kbps. >	code-excited linear prediction;real-time clock	Erik Harborg;Jan E. Knudsen;Arild Fuldseth;Finn Tore Johansen	1994		10.1109/ICASSP.1994.389703	voice activity detection;linear predictive coding;speech recognition;vector sum excited linear prediction;telecommunications;harmonic vector excitation coding;computer science;speech coding;speech processing;videotelephony;computational complexity theory;code-excited linear prediction	Crypto	47.78508537645587	-8.262615020564585	152604
9470040345336a79d27c8a45b13bc8021cdce2c9	memristor plasticity enables emergence of synchronization in neuromorphic networks	memristors mathematical model synchronization manganese neurons couplings equations;oscillatory cells memristor plasticity neuromorphic network synchronization ultrahigh density low power memory nonvolatile memory pattern recognition system oscillatory associative memory dynamic memory nanoscale memristor biological synapse electronic emulator ionic flow memristor based nonlinear circuit;plasticity content addressable storage memristors nanoelectronics neural nets nonlinear network synthesis	Besides being at the core of novel ultra-high density low-power non-volatile memories and innovative pattern recognition systems based upon oscillatory associative and dynamic memories, the nano-scale memristor also has the potential to reproduce the behavior of a biological synapse more efficiently and accurately than any conventional electronic emulator. As in a living being the weight of a synapse is adapted by the ionic flow through it, so the conductance of a memristor is adjusted by the flux across it. This article is organized according to the regulations of the ISCAS2014 special session on the state-of-the-art in memristor-based nonlinear circuits and architectures. In this work we focus on arrays of oscillatory cells locally coupled through memristors. Our investigations shows how the nonlinear dynamics of the memristor plays a key role in the mechanisms underlying the synchronization properties of the networks. This work provides new insights into the nonlinear behavior of the still largely unexplored memristor element, which promises to revolutionize integrated circuit design in the incoming years.	coefficient;complex network;conductance (graph);coupling constant;emergence;emulator;gnu nano;hindmarsh–rose model;integrated circuit design;ionic;low-power broadcasting;memristor;neuromorphic engineering;non-volatile memory;nonlinear system;pattern recognition;simulation;synapse;synapse	Alon Ascoli;Ronald Tetzlaff;Valentina Lanza;Fernando Corinto;Marco Gilli	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865621	control engineering;electronic engineering;computer science;memistor;theoretical computer science	Arch	39.57041944557437	-0.7626581555354622	152692
1012481052726564dedffa4851443c373a8f79c8	circular coding with interleaving phase	data recovery;halftoning;data bearing hardcopy;coding	A general two-dimensional coding method is presented that allows recovery of data based on only a cropped portion of the code, and without knowledge of the carrier image. A description of both an encoding and recovery system is provided. Our solution involves repeating a payload with a fixed number of bits, assigning one bit to every symbol in the image - whether that symbol is data carrying or non-data carrying - with the goal of guaranteeing recovery of all the bits in the payload. Because the technique is applied to images, for aesthetic reasons we do not use fiducials, and do not employ any end-of-payload symbols. The beginning of the payload is determined by a phase code that is interleaved between groups of payload rows. The recovery system finds the phase row by evaluating candidate rows, and ranks confidence based on the sample variance. The target application is data-bearing clustered-dot halftones, so special consideration is given to the resulting checkerboard subsampling. This particular application is examined via exhaustive simulations to quantify the likelihood of unrecoverable bits and bit redundancy as a function of offset, crop window size, and phase code spacing.	chroma subsampling;forward error correction;simulation	Robert Ulichney;Matthew Gaubatz;Steven J. Simske	2014		10.1145/2644866.2644888	simulation;telecommunications;computer science;data recovery;coding	ML	45.036348751400205	-6.559071728633134	153142
100d0a2f32900a3578a6ad2b1af7ef0545f47069	bio-inspired stretchable absolute pressure sensor network	smart skin;mems;absolute pressure sensor;stretchable network	A bio-inspired absolute pressure sensor network has been developed. Absolute pressure sensors, distributed on multiple silicon islands, are connected as a network by stretchable polyimide wires. This sensor network, made on a 4'' wafer, has 77 nodes and can be mounted on various curved surfaces to cover an area up to 0.64 m × 0.64 m, which is 100 times larger than its original size. Due to Micro Electro-Mechanical system (MEMS) surface micromachining technology, ultrathin sensing nodes can be realized with thicknesses of less than 100 µm. Additionally, good linearity and high sensitivity (~14 mV/V/bar) have been achieved. Since the MEMS sensor process has also been well integrated with a flexible polymer substrate process, the entire sensor network can be fabricated in a time-efficient and cost-effective manner. Moreover, an accurate pressure contour can be obtained from the sensor network. Therefore, this absolute pressure sensor network holds significant promise for smart vehicle applications, especially for unmanned aerial vehicles.	aerial photography;autonomous robot;british informatics olympiad;cns disorder;cost effectiveness;drug vehicle;inspiration function;large;less than;medication event monitoring system;microelectromechanical systems;microtechnology;negative-pressure ventilators;polymer;pressure sensor device component;prototype;silicon;skin (computing);unmanned aerial vehicle;benefit;sensor (device)	Yue Guo;Yu-Hung Li;Zhiqiang Guo;Kyunglok Kim;Fu-Kuo Chang;Shan X. Wang	2016		10.3390/s16010055	electronic engineering;electrical engineering;nanotechnology;microelectromechanical systems	Mobile	47.58957065358117	-0.21719597080382833	153709
5daad8d98b1e0b95cf7b5b6c843273a9144e7657	discontinuous galerkin unsteady discrete adjoint method for real-time efficient tsunami simulations	institutional repositories;fedora;vital;discrete adjoint;discontinuous galerkin;optimization;vtls;dynamic adaptation;ils;tsunami simulation	An unsteady discrete adjoint implementation for a discontinuous Galerkin model solving the shallow water wave equations on the sphere is presented. Its use for tsunami simulations is introduced to reconstruct the initial condition automatically from buoy measurements. Based on this feature, a real-time tsunami model is developed, using several numerical tools such as a high-order discretization, hp-refinement, parallel dynamic load balancing and adjoint-based data assimilation. The model is able to reconstruct the tsunami source and accurately forecast its far-field propagation (e.g. from Japan to Chile, at a distance of about 17000 km) in a computational time 20 times faster than the physical propagation time, to which the data collecting time needs to be added. The work presented constitutes a step towards an efficient nonlinear tsunami warning model. Additional features could be added for more complete realistic forecasts.	algorithm;bathymetry;central processing unit;computation;data assimilation;discretization;galerkin method;image resolution;initial condition;load balancing (computing);mainframe computer;mathematical optimization;nonlinear system;numerical analysis;numerical method;on the fly;propagation time;real life;real-time clock;real-time computing;real-time data;real-time transcription;refinement (computing);simulation;software propagation;time complexity	Sébastien Blaise;Amik St.-Cyr;Dimitri J. Mavriplis;Brian Lockwood	2013	J. Comput. Physics	10.1016/j.jcp.2012.08.022	meteorology;mathematical optimization;simulation;discontinuous galerkin method;mathematics;physics	Graphics	45.69356147547302	3.568206727719884	153789
3f2412ab0fbf7473c11b8c07db1026f22a693bf0	digital rights management for paper-based microfluidic biochips		Paper-based digital microfluidic biochips (PB-DMFBs) provide a promising solution for microfluidic bioassays. Due to the low-cost substrate material and low demand for complicated manufacturing equipment, PB-DMFBs can be fabricated without foundry. On the flip side, convenience of fabrication allows PB-DMFBs to be fabricated everywhere, which makes it is difficult to manage production and distribution of IP (bioassays). As a result, PB-DMFBs are vulnerable to security threats. IP and its creator, the biocoders, may suffer from infringement. To ensure IP protection, in this paper, we proposed the first Digital Rights Management (DRM) scheme to protect IPs of PB-DMFBs from security threats. A chip-level synthesis algorithm is also presented to realize not only complex biochemical operations but also the demand of DRM.		J. Jenny Li;Sying-Jyan Wang;Katherine Shu-Min Li;Tsung-Yi Ho	2018	2018 IEEE 27th Asian Test Symposium (ATS)	10.1109/ATS.2018.00042	computer engineering;microfluidics;real-time computing;biochip;computer science;digital rights management	EDA	47.17100388232462	1.3628057296027192	154377
41aa577139ffaac475585772ca9997643cf3661e	improved delay-dependent stability criteria for neutral-type systems with time-varying delays: a delayed decomposition approach	integral inequality approach iia;maximum allowable delay bound madb;linear matrix inequalities lmis;delay decomposition approach;time varying delay	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source;type system	Pin-Lin Liu	2014	Int. J. General Systems	10.1080/03081079.2014.900059	mathematical optimization;mathematical analysis;control theory;mathematics	Robotics	50.59530242685079	-3.290990299038792	155019
07af29a71d612a3efb50f8865f694805302cb667	non-intrusive estimation of packet loss rates in speech communication systems using convolutional neural networks		In this paper, we analyze whether deep convolutional neural networks can be used to detect lost packets in speech communication systems. The speech quality of modern communication networks has significantly improved recently, for example through higher available audio bandwidth. This was, among other reasons, possible through the use of packet-based networks, which allow a fully digital transmission from the sender to the receiver terminal. However, these networks often suffer from frequent interruptions caused by lost packets due to transmission errors. Consequently, the packet loss rate is one of the main indicators for the quality of speech communication services. In spite of that, the information of how many packets are lost in a network is not always available. To estimate the amount of lost packets, we calculate spectrograms of the transmitted speech signals and use them as input of a convolutional neural network. This approach has recently gained popularity in the field of detection and recognition tasks for music and speech. The interruptions caused by lost packets can often clearly be seen in the spectrogram of the degraded signal. Therefore, it seems natural to interpret the spectrograms as images and use deep learning methods that are common for image classification. The proposed model allows for estimating the packet loss rate of a communication system by simply using the recorded speech file from the receiver side, without the need of the reference speech signal that was originally sent through the channel. Our results show that the model reduces the prediction error by more than 75% when compared to a model that is based on MFCC features.		Gabriel Mittag;Sebastian Möller	2018	2018 IEEE International Symposium on Multimedia (ISM)	10.1109/ISM.2018.00026	speech recognition;convolutional neural network;communications system;pattern recognition;computer science;data transmission;packet loss;deep learning;artificial intelligence;network packet;spectrogram;communication channel	Arch	50.066137983279134	-8.717582234666539	155264
08acc1fee40976e811c93c211385b27b8f64de51	an efficient hpc framework for parallel long-time and large-scale simulation of a class of anomalous single-phase models	reservoirs;standards;high performance computing;frequency domain analysis;parallel in time;high performance computing parallel in time parallel in space single phase fluid flow efficient memory usage;computational modeling;single phase fluid flow;mathematical model;parallel in space;adaptation models;load modeling;efficient memory usage;computational modeling reservoirs load modeling mathematical model standards adaptation models frequency domain analysis	Anomalous sub-diffusion models are currently considered to be efficient for characterization of complex single - (and hence multi -) phase fluid flow in reservoir simulations. For simulation of such models in three space dimensions, typically, millions of degree of freedoms (DoF) are required to resolve multiscale features in reservoirs. Further, the key quantity of interest is on long-time behavior of reservoirs. Consequently, standard time-stepping serial algorithms are not practical. In this article, we develop a high performance computing (HPC) framework to efficiently simulate a class of anomalous sub-diffusion models. The framework is based on hybrid parallel-in-time and parallel-in-space multiple message passing interface (MPI) communicators and efficient load balancing techniques, in conjunction with efficient discretization of the continuous local and non-local operators in the sub-diffusion models.	algorithm;computation;computational fluid dynamics;discretization;load balancing (computing);mathematical optimization;message passing interface;simulation;stepping level;supercomputer	Ahmad Alyoubi;Mahadevan Ganesh	2015	2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems	10.1109/HPCC-CSS-ICESS.2015.197	supercomputer;parallel computing;computer science;theoretical computer science;mathematical model;distributed computing;computational model;frequency domain;statistics;reservoir	HPC	45.81342951622329	2.18556202920283	155614
b4736361ef196856189aa048dccb8c3abecc86fd	a simulated annealing approach to switching grey prediction fuzzy control system design	prediccion;switching;fuzzy controller;motion control;control difusa;sintesis control;fuzzy control;simulated annealing;commande mouvement;control movimiento;control system;recuit simule;system design;synthese commande;conmutacion;recocido simulado;inverted pendulum;prediction;commutation;control synthesis;pendule inverse;commande floue;steady state	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;fuzzy control system;primary source;simulated annealing;systems design	Ching-Chang Wong;Chia-Chong Chen	1998	Int. J. Systems Science	10.1080/00207729808929556	control engineering;motion control;inverted pendulum;simulated annealing;prediction;engineering;control system;artificial intelligence;control theory;mathematics;steady state;systems design	Robotics	50.9538252551512	-3.492728442058883	155771
225c3a5f4ad1782f623972743390ed0c7da33745	analysis and design of passive super low frequency detection system	geophysical prospecting geophysical equipment;fat32 fs passive super low frequency detection system electromagnetic prospecting methods geophysical applications natural source electromagnetic signal electromagnetic signal acquisition hardware technology signal to noise ratio arm platform induction magnetic field lcd screen software system ucosii;embedded system electromagnetic arm;remote sensing electromagnetics power harmonic filters geology receivers magnetic separation noise	Natural source Super Low Frequency electromagnetic prospecting methods have seen an increasingly promising potential in geophysical applications. As the natural source electromagnetic signal is weak, the electromagnetic signal acquisition and processing hardware technology aiming at getting electromagnetic signals with high signal to noise ratio and data inversion accuracy is in great need. In this paper, we designeda signal processing and acquisition hardware system based on ARM platform, i.e., an embedded system, which was specific to the output signal from induction magnetic field. The FFT computation is conducted in our processor to convert time domain in to frequency domain. The relevant information is display on a LCD screen and the acquired data can be stored in storage module for further processing. The software system is based on UCOSII, and FAT32 FS, to improve operability of the system.	arm architecture;computation;embedded system;fast fourier transform;file allocation table;microc/os;operability;signal processing;signal-to-noise ratio;software system	Shanshan Zhao;Qiming Qin;Nan Wang;Li Chen;Yan BingBai;Cheng Ye Zhang	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947633	remote sensing	Embedded	46.26331819251893	-2.1895966544454724	156119
463e8a027a2992f7128097efbe488565b1242c01	screening gps telemetry data for locations having unacceptable error		Abstract Technological improvements in battery life and physical dimensions of Global Positioning System (GPS) telemetry have increased the number of locations one can collect, but due to relatively unimproved GPS accuracy this also increases the number of locations with unacceptable measurement error. We propose and show an example of a new method for screening data for locations with unacceptable error. We also propose a new screening metric: estimated elevation error (EEE). EEE identifies unacceptable xy -coordinate error in some cases better than do methods that use horizontal dilution of precision (HDOP) or fix dimension (2-D or 3-D). Our screening method combines test data and a model-averaging information-theoretic framework that uses a priori candidate models of telemetry measurement error. We demonstrate this method using experimental data collected on banded mongooses ( Mungos mungo ). One can adapt this screening method to any GPS data.	global positioning system	Peter N. Laver;Roger A. Powell;Kathleen A. Alexander	2015	Ecological Informatics	10.1016/j.ecoinf.2015.02.001	telecommunications	AI	47.52476393155834	2.9431680123062316	156221
3596fa723baba4b90cd0dc96bf081aed5bd48828	delay-dependent robust h∞ control for uncertain stochastic t-s fuzzy systems with time-varying state and input delays	takagi sugeno t s fuzzy systems;state and input delay;h control;stochastic systems;linear matrix inequalities	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;fuzzy control system;primary source	T. Senthilkumar;P. Balasubramaniam	2011	Int. J. Systems Science	10.1080/00207721.2010.545493	control engineering;mathematical optimization;control theory;mathematics;h-infinity methods in control theory	Robotics	50.793331003962706	-3.3753128175161735	156866
24daa69736b3f8b5086745902d2a23bfa228664b	chip-on-board (cob) technology for low temperature environments. part i: wire profile modeling in unencapsulated chips	encapsulation;modelizacion;thermomechanical stress;deformacion plastica;continuous function;metodo analitico;tecnologia electronica telecomunicaciones;condiciones limites;interconnection;analyse thermomecanique;integrated circuit;packaging electronico;condition aux limites;fonction polynomiale;wire bonding;ordre 1;parametric study;contrainte thermomecanique;thermomechanical analysis;union por hilo;circuito integrado;encapsulacion;fonction continue;chip on board;chip;packaging electronique;chip on board packaging;tension termomecanica;interconexion;low temperature;modelisation;analyse parametrique;analyse contrainte;integrated circuit bonding;first order;analisis tension;stress analysis;funcion continua;boundary condition;assemblage circuit integre;analytical method;electronic packaging;interconnexion;deformation plastique;methode analytique;microcâblage;parametric analysis;sensibilite parametrique;tecnologias;funcion polinomial;parametric sensitivity;grupo a;polynomial function;modeling;technologie puce sur carte;strain energy;orden 1;analisis termomecanico;plastic deformation;circuit integre;sensibilidad parametrica;analytical model;cubic spline	An analytical model based on elastic strain energy minimization is developed for estimating the wire profile in unencapsulated ballwedge wire bond configuration for chip-on-board (CoB) technology. The wire profile is applicable to ball-wedge bonds with a height offset, and is modeled using a piece-wise continuous polynomial function (cubic spline) with appropriate boundary conditions at the two bond sites. Plastic deformation is ignored in the current analysis as a first-order approximation, since the interest is in parametric sensitivity studies. The model is useful for estimating the wire profile for different offset heights and wire spans, and serves as a starting point for subsequent thermomechanical stress analysis after encapsulation. Parametric studies are presented to explore the wire profile for different CoB geometries. 2006 Elsevier Ltd. All rights reserved.	cubic hermite spline;cubic function;encapsulation (networking);energy minimization;first-order predicate;on-board data handling;order of approximation;polynomial;spline (mathematics);stress–strain analysis;wire bonding	K. K. Jinka;S. Ganesan;A. Dasgupta;S. Ling;A. Shapiro;D. Schatzel	2007	Microelectronics Reliability	10.1016/j.microrel.2006.08.019	thermomechanical analysis;chip;continuous function;spline;electronic engineering;systems modeling;encapsulation;telecommunications;boundary value problem;computer science;engineering;electrical engineering;integrated circuit;interconnection;first-order logic;stress–strain analysis;electronic packaging;wire bonding;strain energy;engineering drawing;parametric statistics;deformation	EDA	52.08888805086405	-1.7946609204771848	156968
e7f06fc3c244fd6323ee094ce3d634b85fc61f52	a joint-receipt conjoint structure and its additive representation	additive representation;independence;joint receipt;conjoint structure	Video editing apparatus for use with video playback and recording devices, such as video tape recorders (VTRu0027s) wherein signals are reproduced from a first record medium and recorded on a second record medium. The apparatus is provided with a console having a plurality of display registers for displaying record medium position data representing respective positions of the first and second media. Register selector switches are associated with respective ones of the display registers, each such switch being operable to select its associated display register. The console also is provided with a plurality of signal selector switches, each being operable to select a particular type of signal (such as a video or audio signal) reproduced from the first medium to be recorded on the second medium when a pre-selected one of the media reaches a position represented by the position data displayed in a selected display register. Indicators, such as visual indicator devices, are associated with respective ones of the signal selector switches and are operative to apprise an operator of the relative positions at which the particular types of signals are to be recorded on the second medium. The apparatus also is provided with a central processing unit responsive to the operation of a selected signal selector switch and a selected register selector switch for associating the position data displayed in the display register associated with that register selector switch with the selected signal selector switch, whereby when the pre-selected medium reaches the position represented by the associated position data, the particular type of signal selected by the signal selector switch is recorded on the second medium.		Yutaka Matsushita	2007	JACIII	10.20965/jaciii.2007.p0891	independence	Vision	46.96529166300504	-4.427077797566571	157326
57f56e874e20e7142daa1a732d0490c1161e4719	optimization of a digital neuron design	neural networks;computer networks;transfer functions;neurofeedback;artificial neural network;monte carlo simulation;hardware;artificial neural networks;network reliability;arithmetic logic unit;real estate;design optimization;computational modeling	Artificial neural network models, composed of many non-linear processing elements operating in parallel, have been extensively simulated in software. The real estate required for neurons and their interconnections has been the major hindrance for hardware implementation. Therefore, a reduction in neuron size is highly advantageous. A digital neuron design consisting of an arithmetic logic unit (ALU) has been implemented to conform to the hard-limiting threshold function. Studies on reducing the ALU size, utilizing Monte-Carlo simulations, indicate that its effect on network reliability and efficiency is not detrimental. Neurons with reduced ALU size operate with the same computational abilities as full sized neurons.	arithmetic logic unit;artificial neural network;monte carlo method;neuron;nonlinear system;simulation	F. Kampf;P. Koch;K. Roy;M. Sullivan;Z. Delalic;S. DasGupta	1989	International 1989 Joint Conference on Neural Networks	10.1145/99633.99644	parallel computing;multidisciplinary design optimization;computer science;artificial intelligence;theoretical computer science;machine learning;arithmetic logic unit;neurofeedback;reliability;transfer function;computational model;artificial neural network;real estate;monte carlo method	ML	39.22515728760861	-3.056888408550515	157562
2bf15e4367aa70ed897ad5e03c38df9b55f8d4ae	real-time lossless compression algorithm for ultrasound data using bl universal code	lossless compression;medical ultrasound;run-length encoding;universal code	Software-based ultrasound imaging systems provide high flexibility that allows easy and fast adoption of newly developed algorithms. However, the extremely high data rate required for data transfer from sensors (e.g., transducers) to the ultrasound imaging systems is a major bottleneck in the software-based architecture, especially in the context of real-time imaging. To overcome this limitation, in this paper, we present a Binary cLuster (BL) code, which yields an improved compression ratio compared to the exponential Golomb code. Owing to the real-time encoding/decoding features without overheads, the universal code is a good solution to reduce the data transfer rate for software-based ultrasound imaging. The performance of the proposed method was evaluated using in vitro and in vivo data sets. It was demonstrated that the BL-beta code has a good stable lossless compression performance of 20%~30% while requiring no auxiliary memory or storage.	abbreviations;algorithm;analog-to-digital converter;application-specific integrated circuit;auxiliary memory;bl (logic);bit-length;cluster headache;codes of ethics;conceptualization (information science);conflict (psychology);count of entities;data rate units;encode;echo-planar imaging;exponential-golomb coding;field-programmable gate array;golomb coding;golomb ruler;graphics processing unit;hematological disease;in vitro [publication type];integrated delivery systems;interface device component;lossless compression;manuscripts;medical ultrasound;most significant bit;moving picture experts group;pci express;peripheral;radio frequency;real-time clock;real-time computing;real-time transcription;resonance;transducer;transducers;usb 3.0;ultrasonography;universal code (data compression);video-in video-out;exponential;fmri;sensor (device)	Jung Hoon Kim;Sunmi Yeo;Jong Won Kim;Kyeongsoon Kim;Tai-Kyong Song;Changhan Yoon;Joohon Sung	2018		10.3390/s18103314	engineering;electronic engineering;run-length encoding;ultrasound;universal code;lossless compression	HPC	41.163201757941856	-5.2470540450187935	157749
a9e6be0c17bf270e4bca3cebc1aa38c8893d3d07	tracking with asynchronous binary readings and layout information in rfid systems with sense-a-tags	particle filtering (numerical methods);particle filtering;target tracking;ultra high frequency radiofrequency identification;sense-a-tags;rfid system;real-time indoor tracking;movement direction estimation;asynchronous measurements;layout information;radiofrequency identification;object detection;direction-of-arrival estimation;multihypothesis particle filtering method;radio frequency identification (rfid);uhf radio propagation;asynchronous binary readings;binary detection probability;indoor tracking;dead zone;probability;indoor radio	This paper addresses the problem of real-time indoor tracking of tagged objects in Ultra High Frequency Radio Frequency IDentification (RFID) systems with layout information and asynchronous readings. The method is based on binary detections and the model for the probability of detection is a function of both distance and angle between a tag and a reader and accounts for the possibility of a tag being in a dead-zone. A newly developed RFID component, called sense-a-tag, is used to improve the tracking performance, especially in areas with intersections and at portals, where the estimation of the direction of movement is important. A multi-hypothesis particle filtering method is applied for the tracking and its performance is demonstrated by computer simulations.	computer simulation;particle filter;portals;radio frequency;radio-frequency identification;real-time locating system;sensor;ultra high frequency	Liuming Zhao;Mónica F. Bugallo;Petar M. Djuric	2013	21st European Signal Processing Conference (EUSIPCO 2013)		electronic engineering;real-time computing;tracking system;telecommunications;engineering	EDA	49.63762327656294	-0.23188532093289851	158122
97637ada85f5765af39682781bd362fd6fd65cd9	identification and estimation of harmonic sources based on compressive sensing		Nodes in electric distribution networks are greatly differentiated and are very often nonlinear and/or unbalanced. They can create significant harmonic pollution, with harmonics that inevitably spread along the grid. Monitoring harmonic propagation and correlated power quality phenomena requires specific measurement devices and methodologies. Nevertheless, because of the unavailability of a rapid diffusion of synchronized and dedicated devices (due to technical and economic reasons) on every node and branch of the network, estimating the harmonic status of the entire grid by means of a complete or even redundant monitoring system can be practically unfeasible. A more feasible, though always meaningful, goal can thus be pursued, that is estimating the main harmonic sources in the network, rather than its complete harmonic status. This approach, of course, can be based on a simpler and cheaper upgrade of the distributed monitoring system. Even more, by considering the common scenario where the number of significant harmonic sources is lower than the number of loads connected to the grid, specific estimation procedures can be defined to further reduce the complexity of the monitoring system. In this scenario, this paper presents an efficient compressive sensing harmonics detector (CSHD) for the identification and the estimation of the principal pollution sources. The proposed CSHD method is validated by means of appropriate tests performed on an example of distribution grid.		Daniele Carta;Carlo Muscas;Paolo Attilio Pegoraro;Sara Sulis	2019	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2018.2838738	total harmonic distortion;grid;harmonics;unavailability;smart grid;harmonic analysis;electronic engineering;harmonic;mathematics;nonlinear system	HPC	43.793438593167004	-0.5291517159958942	158177
9f124028f81d790f266e26ddeb9e6c6c2d3535e1	8 kbit/s coding of speech with 6 ms frame-length	transform coded excitation;coding of speech;quantization;speech synthesis;decoding;8 kbit s coding of speech backward adaptation linear prediction forward pitch analysis transform coded excitation speech quality;backward adaptation;frequency domain analysis;signal analysis;speech analysis;speech coding;transform coding;linear predictive;vocoders linear predictive coding speech coding time frequency analysis;speech quality;time domain analysis;forward pitch analysis;linear predictive coding;8 kbit s;vocoders;time domain;linear prediction;speech coding frequency domain analysis speech analysis speech synthesis quantization time domain analysis signal analysis decoding encoding transform coding;frequency domain;encoding;time frequency analysis	The coder utilizes backward adaptation for updating the LP (linear prediction) parameters, and improved forward pitch analysis. A novel frequency domain approach called transform coded excitation is used for efficient quantization and encoding of the innovative excitation signal. The coder uses a combination of time-domain (linear prediction and pitch analysis) and frequency-domain (transform coding) techniques to achieve the best reproduction of the original signal in the perceptual sense. Good speech quality was obtained with this approach. >		Roch Lefebvre;Redwan Salami;Claude Laflamme;Jean-Pierre Adoul	1993		10.1109/ICASSP.1993.319384	speech recognition;harmonic vector excitation coding;computer science;signal processing;speech synthesis;frequency domain	ML	47.87259737204017	-8.873674362596919	159110
1f2d26e12ef47ce43d0adc21b331fa0a4793fc1e	improving the gjk algorithm for faster and more reliable distance queries between convex objects		This article presents a new version of the Gilbert-Johnson-Keerthi (GJK) algorithm that circumvents the shortcomings introduced by degenerate geometries. The original Johnson algorithm and Backup procedure are replaced by a distance subalgorithm that is faster and accurate to machine precision, thus guiding the GJK algorithm toward a shorter search path in less computing time. Numerical tests demonstrate that this effectively is a more robust procedure. In particular, when the objects are found in contact, the newly proposed subalgorithm runs from 15% to 30% times faster than the original one. The improved performance has a significant impact on various applications, such as real-time simulations and collision avoidance systems. Altogether, the main contributions made to the GJK algorithm are faster convergence rate and reduced computational time. These improvements may be easily added into existing implementations; furthermore, engineering applications that require solutions of distance queries to machine precision can now be tackled using the GJK algorithm.	acm transactions on graphics;backup;barycentric subdivision;collision detection;computation;computational science;condition number;embedded system;finite element method;general-purpose modeling;genetic algorithm;geographic coordinate system;gilbert cell;gilbert–johnson–keerthi distance algorithm;in-game advertising;iteration;johnson's algorithm;linear algebra;linear system;machine epsilon;non-uniform rational b-spline;numerical analysis;path (variable);rate of convergence;real-time clock;recursion;round-off error;rounding;simplex algorithm;simulation;steinhaus–johnson–trotter algorithm;time complexity	Mattia Montanari;Nik Petrinic;Ettore Barbieri	2017	ACM Trans. Graph.	10.1145/3083724	gauss–seidel method;rate of convergence;mathematical optimization;collision;collision detection;theoretical computer science;machine epsilon;algorithm;backup;collision response;computer science;gilbert–johnson–keerthi distance algorithm	Graphics	45.963089706970514	3.9538068583669017	159250
33723114c70c105069a864e0a437acc0174e7eb9	globsol user guide	constraint propagation;90c26;nonconvex optimization;90c30;optimization problem;65k05;65g20;globsol;global optimization;non linear system	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	R. Baker Kearfott	2009	Optimization Methods and Software	10.1080/10556780802614051	probabilistic-based design optimization;optimization problem;mathematical optimization;multi-swarm optimization;constrained optimization;combinatorics;derivative-free optimization;theoretical computer science;stochastic optimization;multi-objective optimization;mathematics;continuous optimization;vector optimization;l-reduction;bilevel optimization;local consistency;metaheuristic;global optimization	Robotics	49.47999296304274	-2.958297743951008	159279
e8ab509d9f8b529975f9358c020f46c052fe2077	design-for-testability for paper-based digital microfluidic biochips		Microfluidic biochips have recently emerged as promising solution for biochemical bioassay, which can be classified into two main categories: flow-based microfluidic biochips [1] and digital microfluidic biochips (DMFBs) [2]. However, both of them have to be fabricated in factories with specific equipment, which makes biochips expensive and inflexible. To tackle these problems, paper-based microfluidics essentially combines low-cost paper substrate and sophisticated inkjet printing to realize microfluidics. However, the relative low sensitivity of conventional paper-based microfluidic devices makes it hard to control multi-step assays with high precision. To deal with this problem, the active paper-based digital microfluidic biochips (P-DMFBs) has been developed [3], [4] as a more scalable and cost-effective solution, which is known as “lab-on-paper”.	design for testing;printing;scalability	Jain-De Li;Sying-Jyan Wang;Katherine Shu-Min Li;Tsung-Yi Ho	2017	2017 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)	10.1109/DFT.2017.8244448	microfluidics;electronic engineering;biochip;computer science;design for testing	Arch	47.186180673976736	1.3513478958451834	159372
315c439914947df3b9e3a3469d691e026895024e	uniform embedding for efficient jpeg steganography	statistical detectability secure embedding capacity bossbase database first order statistics second order statistics dct quantized discrete cosine transform coefficients syndrome trellis coding side informed secure jpeg steganography nonside informed secure jpeg steganography ued uniform embedding distortion function distortion functions minimal distortion embedding framework;image coding;trellis codes discrete cosine transforms distortion higher order statistics image coding steganography;higher order statistics;distortion;steganography;discrete cosine transforms;transform coding discrete cosine transforms payloads encoding histograms security additives;trellis codes	Steganography is the science and art of covert communication, which aims to hide the secret messages into a cover medium while achieving the least possible statistical detectability. To this end, the framework of minimal distortion embedding is widely adopted in the development of the steganographic system, in which a well designed distortion function is of vital importance. In this paper, a class of new distortion functions known as uniform embedding distortion function (UED) is presented for both side-informed and non side-informed secure JPEG steganography. By incorporating the syndrome trellis coding, the best codeword with minimal distortion for a given message is determined with UED, which, instead of random modification, tries to spread the embedding modification uniformly to quantized discrete cosine transform (DCT) coefficients of all possible magnitudes. In this way, less statistical detectability is achieved, owing to the reduction of the average changes of the first- and second-order statistics for DCT coefficients as a whole. The effectiveness of the proposed scheme is verified with evidence obtained from exhaustive experiments using popular steganalyzers with various feature sets on the BOSSbase database. Compared with prior arts, the proposed scheme gains favorable performance in terms of secure embedding capacity against steganalysis.	code word;coefficient;discrete cosine transform;distortion;experiment;jpeg;steganalysis;steganography;trellis quantization	Linjie Guo;Jiangqun Ni;Yun Q. Shi	2014	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2014.2312817	combinatorics;discrete mathematics;distortion;telecommunications;computer science;theoretical computer science;mathematics;steganography;statistics	Vision	41.23293994732681	-9.656455261471947	159437
02db467fadcb66e633c54fe967d2fad5a857b2ee	distributed computation in local area networks of workstations	distributed computing;system performance;performance analysis;task graphs;local area network	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	computation;distributed computing;francis;primary source;workstation	Mehmet Celenk;Yang Wang	1995	Parallel Algorithms Appl.	10.1080/10637199508915477	local area network;parallel computing;computer science;theoretical computer science;distributed computing;computer performance;distributed design patterns	Robotics	48.38279627602741	-2.9490386725513633	160009
c4a1d8432bc9ea04b8551db38e8d922bc1806a29	passive online geometry calibration of acoustic sensor networks	microphones;speech based geometry calibration acoustic sensor network geometry calibration microphone array;geometry;speech;estimation;wireless sensor networks acoustic communication telecommunication direction of arrival estimation microphone arrays radio links reverberation chambers speaker recognition time of arrival estimation;reverberant conference room passive online geometry calibration acoustic sensor network mobile device wireless link multiple microphones microphone arrays communication unit processing unit speaker separation speaker localization direction of arrival target function time difference of arrival target function sparse spike representation tdoa estimation cochlear model;acoustic sensors;geometry calibration direction of arrival estimation microphones speech estimation acoustic sensors;calibration;direction of arrival estimation	As we are surrounded by an increased number of mobile devices equipped with wireless links and multiple microphones, e.g., smartphones, tablets, laptops, and hearing aids, using them collaboratively for acoustic processing is a promising platform for emerging applications. These devices make up an acoustic sensor network comprised of nodes, i.e., distributed devices equipped with microphone arrays, communication unit, and processing unit. Algorithms for speaker separation and localization using such a network require a precise knowledge of the nodes’ locations and orientations. To acquire this knowledge, a recently introduced approach proposed a combined direction of arrival and time difference of arrival (TDoA) target function for offline calibration with dedicated recordings. This letter proposes an extension of this approach to a novel online method with two new features: First, by employing an evolutionary algorithm on incremental measurements, it is online and fast enough for real-time application. Second, by using the sparse spike representation computed in a cochlear model for TDoA estimation, the amount of information shared between the nodes by transmission is reduced, while the accuracy is increased. The proposed approach is able to calibrate an acoustic senor network online during a meeting in a reverberant conference room.	acoustic cryptanalysis;cochlear implant;direction of arrival;evolutionary algorithm;laptop;microphone;mobile device;multilateration;online and offline;real-time clock;real-time computing;smartphone;sparse matrix	Axel Plinge;Gernot A. Fink;Sharon Gannot	2017	IEEE Signal Processing Letters	10.1109/LSP.2017.2662065	estimation;calibration;speech recognition;speech;mathematics;statistics	Mobile	50.38956346503294	3.8455505483112065	160152
005a29e6d3930b924f488dd810df2cdea4119447	self-stabilized distributed network distance prediction	ieee transactions;optimization sparse matrices ieee transactions scalability stability analysis games uncertainty;uncertainty;games;stability analysis;optimization;scalability;matrix factorization latency sensitive applications stability network distance network coordinate relative coordinate;sparse matrices	The network distance service obtains the network latency among large-scale nodes. With increasing numbers of participating nodes, the network distance service has to balance the accuracy and the scalability. The network-coordinate methods scale well by embedding the pairwise latency into a low-dimensional coordinate system. The prediction errors are iteratively optimized by adjusting the coordinates with respect to neighbors. Unfortunately, the optimization process is vulnerable to the inaccurate coordinates, leading to destabilized positions. In this paper, we propose RMF, a relative coordinate-based distributed sparse-preserving matrix-factorization method to provide guaranteed stability for the coordinate system. In RMF, each node maintains a low-rank square matrix that is incrementally adjusted with respect to its neighbors’ relative coordinates. The optimization is self-stabilizing, guaranteeing to converge and not interfered by inaccurate coordinates, since the relative coordinates do not have computational errors. By exploiting the sparse structure of the square matrix, the optimization enforces the  $L_{1}$ -norm regularization to preserve the sparseness of the square matrix. Simulation results and a PlanetLab-based experiment confirm that RMF converges to stable positions within 10 to 15 rounds, and decreases the prediction errors by 10% to 20%.	converge;eclipse requirements modeling framework;mathematical optimization;neural coding;planetlab;scalability;self-stabilization;simulation;sparse matrix	Yongquan Fu;Xu Xiaoping	2017	IEEE/ACM Transactions on Networking	10.1109/TNET.2016.2581592	games;mathematical optimization;von neumann stability analysis;scalability;uncertainty;sparse matrix;computer science;theoretical computer science;mathematics;distributed computing;statistics	HPC	52.97040067773589	0.5285391934316993	160897
56273dafc1526346365bd783549bf4c977da4054	bandwidth extension of speech signals: a catalyst for the introduction of wideband speech coding?	broadband networks;speech intelligibility;wideband;narrowband limitation;data compression;bandwidth allocation;niobium;300 hz to 3 4 khz;speech coding;bandwidth extension;wideband telephony;bit rate;telephony;50 hz to 7 khz bandwidth extension speech signals wideband speech coding wideband telephony narrowband limitation 300 hz to 3 4 khz;speech codecs;speech coding bandwidth wideband niobium telephony speech codecs bit rate narrowband frequency land mobile radio cellular systems;speech signals;bandwidth;speech coding bandwidth allocation broadband networks data compression;50 hz to 7 khz;land mobile radio cellular systems;frequency;narrowband;broadband communication;wideband speech coding	The restricted audio quality of today's telephone networks is mainly due to the narrowband (NB) limitation to the frequency range from about 300 Hz to 3.4 kHz. Meanwhile, codecs for wideband (WB) telephony (50 Hz to 7 kHz) exist with significantly improved speech intelligibility and naturalness. However, the broad introduction of wideband speech coding requires strong efforts of both network operators and their customers because many elements of the networks (i.e., terminals and network nodes) have to be modified. An intermediate step to overcome the narrowband limitation can be achieved by applying artificial bandwidth extension (BWE) in the receiver. In this article we review the basic principles of bandwidth extension, and discuss several application scenarios in which both wideband coding and BWE complement each other. The introduction of BWE methods in terminals and networks may help to speed up the introduction of true wideband speech coding in the near future	bandwidth extension;brainwave entrainment;codec;frequency band;intelligibility (philosophy);naive bayes classifier;speech coding	Peter Jax;Peter Vary	2006	IEEE Communications Magazine	10.1109/MCOM.2006.1637954	data compression;niobium;bandwidth extension;telecommunications;computer science;frequency;speech coding;telephony;intelligibility;bandwidth;bandwidth allocation;broadband networks	AI	48.33132688608256	-8.072599758959146	161869
a63422b47a9ae7a52988f10d1316dbdbf5ae4c11	uwb-inertial fusion location algorithm based on kalman filtering		With the development of industry and commerce, the demands for indoor positioning are increasing. Indoor positioning requires higher reliability, speed and accuracy of the positioning system. However, a single positioning system has its own advantages and disadvantages, which makes it difficult to meet the positioning requirements at the same time. Therefore, this paper proposes a fusion positioning technology that combines ultra-wideband UWB (Ultra-wide Bandwidth) positioning technology and inertial navigation technology using Kalman filter in the case of line of sight. Through the simulation experiment on matlab, by comparing fusion positioning technology with the single UWB positioning technology and the single inertial navigation technology, it is found that the fusion positioning technology improves the positioning accuracy, and meanwhile increases the stability of the system.		Simeng Zhong;Kaiming Zhang;Guodong Zhu;Shuang Liu	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581294	control engineering;positioning system;line-of-sight;kalman filter;inertial navigation system;inertial frame of reference;positioning technology;computer science;bandwidth (signal processing)	Robotics	49.979285673897195	0.6158396212051458	162027
c05501c10f75ae0bcdf55621c24338e18a79f639	an attempt to model the human body as a communication channel	communication channel;transmission medium;biomedical measurements;geometrical body variations;galvanic coupling;biomedical monitoring systems;tissue layers;biological system modeling;measurement system;clinical trial;attenuation;medical electrodes;data communication;receivers;monitoring system;wireless intra body communication;human body transmission attenuation signal to noise ratio medical electrodes geometrical body variations tissue layers on body sensors wireless intra body communication galvanic coupling biomedical monitoring systems data communication electrical signals transmission medium communication channel;transmission attenuation;intra body communication;human body;measurement system biomedical sensor body area network body characterization as transmission medium galvanic coupling intra body communication;transmitters;wireless sensor networks bioelectric phenomena biomedical communication biomedical electrodes biomedical measurement data communication patient monitoring;on body sensors;patient monitoring;electrical signals;biomedical electrodes;communication technology;couplings;bioelectric phenomena;signal to noise ratio;communication channels;biomedical measurement;body characterization as transmission medium;wireless sensor networks;biomedical sensor;biological system modeling humans communication channels data communication biomedical monitoring galvanizing couplings wireless sensor networks wireless communication biosensors;biosensors;body area network;numerical simulation;biomedical communication;computer simulation electromagnetic fields humans information storage and retrieval information theory models biological plethysmography impedance radiation dosage radiometry	Using the human body as a transmission medium for electrical signals offers novel data communication in biomedical monitoring systems. In this paper, galvanic coupling is presented as a promising approach for wireless intra-body communication between on-body sensors. The human body is characterized as a transmission medium for electrical current by means of numerical simulations and measurements. Properties of dedicated tissue layers and geometrical body variations are investigated, and different electrodes are compared. The new intra-body communication technology has shown its feasibility in clinical trials. Excellent transmission was achieved between locations on the thorax with a typical signal-to-noise ratio (SNR) of 20 dB while the attenuation increased along the extremities.	channel (communications);chest;communications media;computer simulation;electrical current;galvanic isolation;limb structure;numerical analysis;sensor;signal-to-noise ratio;anatomical layer;electrode	Marc Simon Wegmueller;Andreas Kuhn;Juerg Froehlich;Michael Oberle;Norbert Felber;Niels Kuster;Wolfgang Fichtner	2007	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2007.893498	computer simulation;electronic engineering;telecommunications;computer science;biological engineering;channel	Visualization	46.131170191868044	0.6681697856595774	162226
ba111abf402bf5584022f416fd5273d7b66d76aa	learning in restless multi-armed bandits using adaptive arm sequencing rules		We consider a class of restless multi-armed bandit (RMAB) problems with unknown arm dynamics. At each time, a player chooses an arm out of $N$ arms to play, referred to as an active arm, and receives a random reward from a finite set of reward states. The reward state of the active arm transits according to an unknown Markovian dynamic. The reward state of passive arms (which are not chosen to play at time t) evolves according to an arbitrary unknown random process. The objective is an arm-selection policy that minimizes the regret, defined as the reward loss with respect to a player that always plays the most rewarding arm. This class of RMAB problems has been studied recently in the context of communication networks and financial investment applications. We develop a strategy that selects arms to be played in a consecutive manner in which the selection sequencing rules are adaptively updated controlled by the current sample reward means, referred to as Adaptive Sequencing Rules (ASR) algorithm. By designing judiciously the adaptive sequencing rules of the chosen arms, we show that ASR algorithm achieves a logarithmic regret order with time and a finite-sample bound on the regret is established. Although existing methods have shown a logarithmic regret order with time in this RMAB setting, the theoretical analysis presents significant improvement in the regret scaling with respect to the system parameters under ASR. Extensive simulation results support the theoretical study and demonstrate strong performance of the algorithm as compared to existing methods.	adaptive filter;algorithm;apollo computer;automated system recovery;c date and time functions;closed-loop transfer function;coat of arms;epoch (reference date);multi-armed bandit;numerical analysis;regret (decision theory);selection rule;simulation;stochastic process;telecommunications network	Tomer Gafni;Kobi Cohen	2018	2018 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2018.8437583	discrete mathematics;telecommunications network;mathematical optimization;logarithm;current sample;regret;computer science;finite set;stochastic process;markov process	ML	39.25362747836345	3.4736023480411378	162354
304b07236bd4cd98d5ea0a77f45840a5cf936641	localizing multiple audio sources in a wireless acoustic sensor network	wireless acoustic sensor networks;location estimation;acoustic source localization;microphone arrays;acoustic sensors	In this work, we propose a grid-based method to estimate the location of multiple sources in a wireless acoustic sensor network, where each sensor node contains a microphone array and only transmits direction-of-arrival (DOA) estimates in each time interval, reducing the transmissions to the central processing node. We present new work on modeling the DOA estimation error in such a scenario. Through extensive, realistic simulations, we show that our method outperforms other state-of-the-art methods, in both accuracy and complexity. We also present localization results of real recordings in an outdoor cell of a sensor network. HighlightsWe examine localization in a WASN where each node transmits DOA estimates.We perform DOA estimation error modeling and examine the merging of nearby sources.We present a real-time low-complexity method for localization of multiple sources.Results indicate the advantages of our method in accuracy/computational complexity.We present localization results of real recordings in an outdoor cell of a sensor network.	acoustic fingerprint	Anthony Griffin;Anastasios Alexandridis;Despoina Pavlidi;Yiannis Mastorakis;Athanasios Mouchtaris	2015	Signal Processing	10.1016/j.sigpro.2014.08.013	electronic engineering;telecommunications;engineering;acoustic source localization	Mobile	50.31306120490946	3.776042380451191	162770
d55f851c3f74c67b9b5e1c2f76f28014def87aca	a nonregressor nonlinear disturbance observer-based adaptive control scheme for an underwater manipulator	adaptive control;underwater manipulator;underwater robotics;disturbance observer;tracking control;nonlinear estimation	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	computer simulation;dynamical system;francis;integrated information theory;nonlinear system;numerical analysis;primary source;robot;robotics;salem;steady state	Mohan Santhakumar	2013	Advanced Robotics	10.1080/01691864.2013.819608	control engineering;simulation;adaptive control;engineering;control theory	Robotics	50.886271860598974	-3.457245895900013	163479
b09b2020fe3fe68a119dd98f6bf8667bed862e90	efficient simulation of nested hollow sphere intersections: for dynamically nested compartmental models in cell biology	prefix sum;gpu;cuda;compartmental models;cellular biology;nearest neighbors;smooth particles;nested shells;neighbor lists	In the particle-based simulation of cell-biological systems in continuous space, a key performance bottleneck is the computation of all possible intersections between particles. These typically rely for collision detection on solid sphere approaches. The behavior of cell biological systems is influenced by dynamic hierarchical nesting, such as the forming of, the transport within, and the merging of vesicles. Existing collision detection algorithms are found not to be designed for these types of spatial cell-biological models, because nearly all existing high performance parallel algorithms are focusing on solid sphere interactions. The known algorithms for solid sphere intersections return more intersections than actually occur with nested hollow spheres. Here we define a new problem of computing the intersections among arbitrarily nested hollow spheres of possibly different sizes, thicknesses, positions, and nesting levels. We describe a new algorithm designed to solve this nested hollow sphere intersection problem and implement it for parallel execution on graphical processing units (GPUs). We present first results about the runtime performance and scaling to hundreds of thousands of spheres, and compare the performance with that from a leading solid object intersection package also running on GPUs.	biological system;collision detection;computation;graphics processing unit;image scaling;interaction;multi-compartment model;parallel algorithm;run time (program lifecycle phase);simulation	Till Köster;Kalyan S. Perumalla;Adelinde M. Uhrmacher	2017		10.1145/3064911.3064920	combinatorics;discrete mathematics;computer science;theoretical computer science	HPC	42.912373044998326	1.5771539061275388	163565
c8c0d91987da60f711f78a078d1b4df6255fe12d	advanced noise reduction for mobile telephony	how things work;mobile handsets interference suppression;noise reduction telephony acoustic noise humans working environment noise mobile handsets noise generators microphones signal processing telephone sets;interference suppression;mobile telephony;noise reduction;mobile handsets;human hearing system advanced noise reduction mobile telephony;mobile telephony how things work	Mobile telephones now contain advanced noise reduction based on the operation of the human hearing system.	noise reduction	Lloyd Watts	2008	Computer	10.1109/MC.2008.278	mobile telephony;imt advanced;telecommunications;computer science;noise reduction;mobile station	EDA	48.346586518180075	-6.455294228170088	163597
58234b2e7f5677836397079668fa145b6237037c	real time localization system with extended kalman filter for indoor applications	mobile nodes;base stations;kalman filters;covariance matrices;mathematical model;real time systems	This paper presents the radio based localization system for indoor applications. For position determination radio COTS transceiver chip was used. Localization accuracy was improved by developing Extended Kalman Filter with modified PV model. Mathematical model of the nonlinear filter was presented and implemented. The described model as well as designed localization system was tested in a realistic environment. Presented results show accuracy of the localization system and enable the assessment possibility of using proposed localization system in further navigational investigations.	aerial photography;algorithm;extended kalman filter;html element;internationalization and localization;mathematical model;nonlinear system;randomness;real-time computing;synthetic intelligence;transceiver	Slawomir Romaniuk;Leszek Ambroziak;Zdzislaw Gosiewski;Pekka Isto	2016	2016 21st International Conference on Methods and Models in Automation and Robotics (MMAR)	10.1109/MMAR.2016.7575085	electronic engineering;invariant extended kalman filter;simulation;fast kalman filter;telecommunications;engineering;extended kalman filter;moving horizon estimation;simultaneous localization and mapping	Robotics	50.68436365638771	1.1584362843500369	163882
a6c7954f57c20040d0e9eeffbb63fdf0caea9cbf	energy-efficient data reconstruction algorithm for spatially- and temporally correlated data in wireless sensor networks		This study introduces a novel algorithm for reconstruction of wireless sensor networks data which inherently have spatial and temporal correlations. The authors’ algorithm is based on compressed sensing (CS) and benefits from sliding window processing. This new algorithm rearranges the data in form of a cube and uses this representation to extract more information about the data. There are two optimisation loops which are solved simultaneously and periodically reconstruct one part of the whole signal from measurements that arrive at the sink. In particular, the first reconstruction loop, which uses a modified version of basis pursuit reconstruction algorithm, is meant for reconstruction of a temporal data which is extracted from the data cube, and the second loop which uses a modified version of reweighted l 1 -norm algorithm is for reconstruction of data windows. The authors used a special kind of binary sparse random measurement matrices for sampling which is equipped with a condition to get samples as variously as possible and this, in turn, balances the duty among sensors and provides more information from the field. Simulation results verify that the proposed algorithm achieves better reconstruction accuracy and less energy consumption in comparison with state-of-the-art CS reconstruction methods.	algorithm	Amin Hu;Mohammad Ali Tinati;Ghanbar Azarnia;Tohid Yousefi Rezaii	2018	IET Signal Processing	10.1049/iet-spr.2017.0467	reconstruction algorithm;wireless sensor network;compressed sensing;mathematics;mathematical optimization;spatial correlation;sliding window protocol;algorithm;basis pursuit;temporal database;data cube	Mobile	51.73781105136496	2.159677405736256	164241
582aa54102b4c2574f76bab052106ba457dfebf4	smart sensor for online detection of multiple-combined faults in vsd-fed induction motors	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;multiple combined faults;fpga;smart sensor;induction motors;uk phd theses thesis;vsd;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Induction motors fed through variable speed drives (VSD) are widely used in different industrial processes. Nowadays, the industry demands the integration of smart sensors to improve the fault detection in order to reduce cost, maintenance and power consumption. Induction motors can develop one or more faults at the same time that can be produce severe damages. The combined fault identification in induction motors is a demanding task, but it has been rarely considered in spite of being a common situation, because it is difficult to identify two or more faults simultaneously. This work presents a smart sensor for online detection of simple and multiple-combined faults in induction motors fed through a VSD in a wide frequency range covering low frequencies from 3 Hz and high frequencies up to 60 Hz based on a primary sensor being a commercially available current clamp or a hall-effect sensor. The proposed smart sensor implements a methodology based on the fast Fourier transform (FFT), RMS calculation and artificial neural networks (ANN), which are processed online using digital hardware signal processing based on field programmable gate array (FPGA).	artificial neural network;clamping (graphics);computation;digital electronics;fast fourier transform;fault detection and isolation;field-programmable gate array;frequency band;hall effect sensor;mathematical induction;microsoft visio;signal processing;smart card;smart transducer;software portability	Armando G. Garcia-Ramirez;Roque Alfredo Osornio-Rios;David Granados-Lieberman;Arturo Garcia-Perez;René de Jesús Romero-Troncoso	2012		10.3390/s120911989	embedded system;electronic engineering;telecommunications;computer science;bioinformatics;engineering;electrical engineering;nanotechnology;induction motor;field-programmable gate array	Robotics	46.39880796817918	-2.0455017663265562	164411
ce8dc306231032f207df898f93586e4c017fed03	one more tag enables fine-grained rfid localization and tracking	rfid tags;geometry;calibration;antenna measurements;antenna arrays	Exploiting radio frequency signals is promising for locating and tracking objects. Prior works focus on per-tag localization, in which each object is attached with one tag. In this paper, we propose a comprehensive localization and tracking scheme by attaching two RFID tags to one object. Instead of using per-tag localization pattern, adding one-more RFID tag to the object exhibits several benefits: 1 providing rich freedom in RFID reader’s antenna spacing and placement; 2 supporting accurate calibration of the reader’s antenna location and spacing, and 3 enabling fine-grained calculation on the orientation of the tags. All of these advantages ultimately improve the localization/tracking accuracy. Our extensive experimental results demonstrate that the average errors of localization and orientation of target tags are 6.415 cm and 1.330°, respectively. Our results also verify that the reader’s antenna geometry does have impact on tag positioning performance.	ieee 754-1985;internationalization and localization;multipath propagation;radio frequency;radio-frequency identification;software propagation	Fu Xiao;Zhong-qin Wang;Ning Ye;Ruchuan Wang;Xiang-Yang Li	2018	IEEE/ACM Transactions on Networking	10.1109/TNET.2017.2766526	distributed computing;computer vision;calibration;radio frequency;computer science;artificial intelligence;rfid localization	Mobile	48.874191892681914	-0.5399943866848568	164962
8666e9d6bd63e48cddfc59c73a370d489be7d7e3	informed source separation of linear instantaneous under-determined audio mixtures by source index embedding	mixture signal;watermarking;information sources;watermarking technique;decoding;semiblind reference method;mix signal;stereo music restitution;time frequency;informed source separation;underdetermined source separation;time frequency joint analysis;speech;watermarking audio processing remixing under determined source separation;corresponding sources index code;remixing;singing voice signals;audio processing;audio coding;indexes;time frequency analysis audio coding audio watermarking source coding source separation;multiple signal classification;under determined source separation;tf joint analysis;indexation;source signals;separate manipulation;two channel stereo mixtures;source index embedding;mixing;source separation;watermarking source separation decoding multiple signal classification indexes speech time frequency analysis;time frequency analysis;specific coder decoder configuration;stereo music restitution informed source separation linear instantaneous under determined audio mixtures source index embedding underdetermined source separation nonstationary audio sources j channel linear instantaneous mixture specific coder decoder configuration source signals mixing time frequency joint analysis tf joint analysis mixture signal corresponding sources index code mix signal watermarking technique singing voice signals two channel stereo mixtures semiblind reference method separate manipulation;j channel linear instantaneous mixture;linear instantaneous under determined audio mixtures;source coding;audio watermarking;nonstationary audio sources	In this paper, we address the issue of underdetermined source separation of I nonstationary audio sources from a J -channel linear instantaneous mixture (J <; I). This problem is addressed with a specific coder-decoder configuration. At the coder, source signals are assumed to be available before the mixing is processed. A time-frequency (TF) joint analysis of each source signal and mixture signal enables to select the subset of sources (among I ) leading to the best separation results in each TF region. A corresponding source(s) index code is imperceptibly embedded into the mix signal using a watermarking technique. At the decoder, where the original source signals are unknown, the extraction of the watermark enables to invert the mixture in each TF region to recover the source signals. With such an informed approach, it is shown that five instruments and singing voice signals can be efficiently separated from two-channel stereo mixtures, with a quality that significantly overcomes the quality obtained by a semi-blind reference method and enables separate manipulation of the source signals during stereo music restitution (i.e., remixing).	16-bit;data compression;digital watermarking;elegant degradation;embedded system;modified discrete cosine transform;neural coding;performance;real-time cmix;real-time transcription;semiconductor industry;source separation;sparse matrix	Mathieu Parvaix;Laurent Girin	2011	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2010.2097250	speech recognition;time–frequency analysis;acoustics;computer science;blind signal separation	Visualization	46.78633059872079	-9.2529304039639	165060
cd1d43243f1f42e502a625f32cd4f61c3fceefcc	distributed detection fusion with nonideal channels under monte carlo framework		The distributed detection fusion is investigated for conditionally dependent sensor networks with channel errors. When the joint probability density functions of the sensor observations are dependent and high dimensional, it is known to be a challenging problem. This paper deals with this problem under Monte Carlo framework. The Bayesian cost function is approximated by Monte Carlo importance sampling. Necessary conditions for optimal sensor rules and optimal fusion rule are derived in the sense of minimizing the approximated Bayesian cost function, respectively. A Gauss-Seidel/person-by-person optimization algorithm is developed to search the optimal sensor rules. It is proved that the discretized algorithm is finitely convergent. Since the error rate of Monte Carlo integration is regardless of dimensionality, the complexity of the new algorithm is much less than that of the previous algorithm based on Riemann sum approximation. The proposed method allows us to design the sensor networks with a higher dimensional joint probability density function of the sensor observations. The typical examples with dependent observations and channel errors are examined. The results of numerical examples demonstrate the effectiveness of the new algorithm.	approximation algorithm;computation;converge;discretization;gauss–seidel method;importance sampling;iteration;iterative method;mathematical optimization;monte carlo integration;monte carlo method;network topology;numerical analysis;sampling (signal processing);sensor;simulation;tree network	Yiwei Liao;Xiaojing Shen;Yunmin Zhu	2017	2017 20th International Conference on Information Fusion (Fusion)	10.23919/ICIF.2017.8009867	monte carlo algorithm;artificial intelligence;computer science;machine learning;monte carlo method;monte carlo integration;particle filter;rejection sampling;hybrid monte carlo;quasi-monte carlo method;markov chain monte carlo	Robotics	53.016158759484334	3.823501141134986	165221
5b990b1158445a92557189a3c7bca95e202c1495	parallel pricing algorithms for multi-dimensional bermudan/american options using monte carlo methods	cluster computing;heterogeneous computing;multi dimensional bermudan american option;multi dimensional;monte carlo method;american option;monte carlo;grid computing;parallel distributed monte carlo methods	In this paper we present two parallel Monte Carlo based algorithms for pricing multi–dimensional Bermudan/American options. First approach relies on computation of the optimal exercise boundary while the second relies on classification of continuation and exercise values. We also evaluate the performance of both the algorithms in a desktop grid environment. We show the effectiveness of the proposed approaches in a heterogeneous computing environment, and identify scalability constraints due to the algorithmic structure. Key-words: Multi–dimensional Bermudan/American option, Parallel Distributed Monte Carlo methods, Grid computing. ∗ INRIA, OASIS † INRIA, TOSCA ‡ Dept. Biological Chemistry & Molecular Pharmacology, Harvard Medical School Algorithmes de Pricing parallèles pour des Options Bermudiennes/Américaines multidimensionnelles par une méthode de Monte Carlo Résumé : Dans ce papier, nous présentons deux algorithmes de type Monte Carlo pour le pricing d’options Bermudiennes/Américaines multidimensionnelles. La premiere approche repose sur le calcul de la frontière d’exercice, tandis que la seconde repose sur la classification des valeurs d’exercice et de continuation. Nous évaluons les performances des algorithmes dans un environnement grille. Nous montrons l’efficacité des approches proposées dans un environnement hétérogène. Nous identifions les contraintes d’évolutivité dues à la structure algorithmique. Mots-clés : options Bermudiennes/Américaines multidimensionnelles, Méthodes de Monte Carlo paralléles, Grid computing. Parallel Pricing Algorithms for Multi–Dimensional Bermudan/American Options 3	algorithm;aperture grille;bibliothèque de l'école des chartes;computation;continuation;desktop computer;grid computing;heterogeneous computing;linear algebra;monte carlo method;oasis tosca;performance;scalability	Viet Dung Doan;Abhijeet Gaikwad;Mireille Bossy;Françoise Baude;Ian Stokes-Rees	2010	Mathematics and Computers in Simulation	10.1016/j.matcom.2010.08.005	quasi-monte carlo method;mathematical optimization;simulation;hybrid monte carlo;particle filter;computer science;theoretical computer science;monte carlo molecular modeling;mathematics;monte carlo integration;monte carlo methods for option pricing;statistics;monte carlo method	HPC	41.37944472718256	1.3893225980619128	165454
6a42dfbce1801dcf96f7b6ba826b32b70ab66423	a simple programmable autowave generator network for wave computing applications	computers;chemicals;physiological study;signal generators;generators;relaxation oscillator;computational techniques;oscillators;reaction diffusion;technological development;cellular neural network;wave computing algorithms;active medium;wave computing algorithms programmable autowave generator network wave computing applications spatiotemporal wave based computing active medium wave computing paradigm biological systems physiological study very large scale integration technology 2d reaction diffusion cellular neural network relaxation oscillator;very large scale integrated;cellular neural nets;wave computing;neural chips;programmable autowave generator network;optical information processing;retina;relaxation oscillators;programmable circuits;vlsi cellular neural nets neural chips optical information processing programmable circuits signal generators;network model;robots;spatiotemporal phenomena;vlsi;biological systems;cellular neural networks cnns;computer application;spatiotemporal waves;wave computing cellular neural networks cnns cellular wave computer relaxation oscillators spatiotemporal waves;wave computing applications;cellular wave computer;spatiotemporal wave based computing;computer applications computer networks spatiotemporal phenomena cellular neural networks biology computing retina computer aided instruction image processing information processing equations;wave computing paradigm;very large scale integration technology;2d reaction diffusion cellular neural network	Spatiotemporal-wave-based computing on an active medium, which is known as wave computing paradigm, mimics the way biological systems process information. Recent anatomic and physiological studies and technological developments in very large-scale integration technology have encouraged the engineers to brace up with this new paradigm. In this paper, a simple network model that is essential in order to explore spatiotemporal behavior and to develop new algorithms based on wave computing technique has been presented. The presented network is a 2-D reaction-diffusion cellular neural network consisting of relaxation oscillators. The network can be programmed as an autowave generator and sources of the wave can be placed at any place on the network. The network has the simplest model that exhibits autowaves. Furthermore, the model is suitable for the implementation of a larger network. The propagation of autowaves between the cells whose dynamics is fixed shows that the network can be adapted to already developed wave computing algorithms in literature.	autowave	Mustak E. Yalcuin	2008	IEEE Trans. on Circuits and Systems	10.1109/TCSII.2008.2002569	electronic engineering;computer science;artificial intelligence;theoretical computer science;relaxation oscillator;control theory;network simulation	EDA	40.522953217508466	-1.2549723638079155	165556
29c8da27f8cc889b601e3643ac99d56bff5ee43b	quantization step parity-based steganography for mp3 audio	quantization;huffman coding;steganography;mp3	Petitcolas has proposed a steganographic technique called MP3Stego which can hide secret messages in a MP3 audio. This technique is well-known be cause of its high capacity. However, in rare cases, the normal audio encoding process will be term inated due to the endless loop problem caused by embedding operation. In addition, the statistica l undetectability of MP3Stego can be further improved. Inspired by MP3Stego, a new steganographic m ethod for MP3 audio is proposed in this paper. The parity bit of quantization step rather than t he parity bit of block size in MP3Stego is employed to embed secret messages. Compared with MP3Steg o, th proposed method can avoid the endless loop problem and achieve better imperceptibili ty and higher security.	block size (cryptography);infinite loop;mp3;parity bit;statistica;steganography	Diqun Yan;Rangding Wang;Liguang Zhang	2009	Fundam. Inform.	10.3233/FI-2009-190	quantization;telecommunications;computer science;theoretical computer science;mathematics;steganography;algorithm;statistics;huffman coding	EDA	42.78284893890536	-9.331734803421979	165803
53d8def49058d7622fddfeb73ac43314216fa73c	stego key recovery based on the optimal hypothesis test		At present, research on steganalysis is mainly focused on the existence detection of hidden messages. However, the extraction of hidden messages, i.e., extraction attacks, also plays a decisive role in tasks such as obtaining evidence of covert communication and fighting against criminal activities. For steganography using a stego key, the purpose of an extraction attack is to recover the stego key. This paper mainly studies methods of recovering the stego key for least significant bit (LSB) steganography in the JPEG domain. Firstly, based on the differences in the statistical properties of the discrete cosine transform (DCT) coefficients between the paths generated by the correct and incorrect keys, a stego key recovery model based on the optimal hypothesis test is proposed. Moreover, formulas are given for calculating the desired sample size and threshold in the proposed stego key recovery model. Secondly, based on the difference in the distributions of odd and even coefficients between the correct and incorrect paths, a method of recovering the stego key for OutGuess steganography using this model is proposed. Finally, based on the difference in the distributions of zero and non-zero coefficients between the correct and incorrect paths, a method of recovering the stego key for F5 steganography (modified version) using this model is proposed. Experimental results for OutGuess 0.13b, OutGuess 0.2 and modified F5 steganography show that the proposed method can successfully recover the stego key and that its performance is superior to that of existing methods.	coefficient;discrete cosine transform;existence detection;experiment;jpeg;key escrow;least significant bit;most significant bit;steganalysis;steganography	Che Xu;Jiu-fen Liu;Junjun Gan;Xiangyang Luo	2017	Multimedia Tools and Applications	10.1007/s11042-017-4878-4	computer science;statistical hypothesis testing;artificial intelligence;steganography;pattern recognition;sample size determination;discrete cosine transform;steganography tools;jpeg;steganalysis;least significant bit	AI	40.16362352932713	-9.65435267291302	166070
0ad2730242329b6db8ed0c8132cc349ebf6ce2e1	speedup analysis of hypercube array processor for machine vision applications	binary image;edge detection;concurrent systems;low level vision operators;machine vision;nearest neighbor;taylor and francis;original articles;i4 6;parallel implementation;image to processor mapping;speedup;ring and mesh topologies;c1 2;hypercube processor;i5 4	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;machine vision;primary source;speedup;vector processor	Mehmet Celenk	1993	Parallel Algorithms Appl.	10.1080/10637199308915443	parallel computing;edge detection;machine vision;binary image;speedup;computer science;theoretical computer science;distributed computing;k-nearest neighbors algorithm	Robotics	48.41465818321944	-2.963006504436081	166095
b333bf61b21ca80e8bbd24e55455bbadb29e9e90	electromagnetic scattering with the boundary integral method on mimd systems	simulation ordinateur;distributed memory;algoritmo paralelo;electromagnetic scattering;boundary integral method;distributed memory systems;parallel algorithm;degree of freedom;electromagnetisme;methode integrale frontiere;algorithme parallele;systeme memoire repartie;parallel computer;metodo integral frontera;parallel machines;electromagnetism;simulacion computadora;electromagnetismo;electric conductivity;computer simulation	This paper deals with parallel computation in electromagnetics. The boundary integral method has been developed to solve scattering by a perfect electric conducting or perfect dielectric bodies. Only parallel computation enables to modelize large devices. We present the implementation of the code on a distributed memory parallel machine. We focus in particular on the parallelization of the BiCGStab solver. Parallel performances are presented with a 2000 degrees of freedom problem.	boundary element method;mimd	Thierry Jacques;Laurent Nicolas;Christian Vollaire	1999		10.1007/BFb0100663	computer simulation;parallel computing;distributed memory;electromagnetism;computer science;theoretical computer science;calculus;mathematics;parallel algorithm;degrees of freedom;electrical resistivity and conductivity;algorithm	Robotics	44.572122545669124	3.412007566854163	166342
84ec36b8ab76998bd3d317996f5213b444e202e8	a post-processing of speech for hearing impaired integrate into standard digital audio decoders.	hearing impaired	This paper describes the simple method of post processing for hearing impaired integrate into standard digital audio decoder such as AAC, AC3 or other codecs based on time/frequency transform. The results of evaluation, employing emulated hearing impairment, will be shown.	advanced audio coding;codec;emulator;list of fourier-related transforms;video post-processing	Shinichi Hoshino;Itaru Kaneko;Hideaki Kikuchi;Katsuhiko Shirai	1999			computer science	AI	47.52182299167501	-8.201289320306428	166723
6d1b313abb8a77d218e497d79b9b768dd99e50e3	consensus protocols for distributed tracking in wireless camera networks	protocols cameras covariance matrices distributed algorithms distributed tracking kalman filters nonlinear filters;consensus protocols distributed nonlinear consensus filters covariance information eiwcf extended information weighted consensus filter eicf extended information consensus filter camera measurement model nonlinear systems consensus based distributed algorithms consensus based target tracking wireless camera networks distributed tracking;information filters cameras redundancy kalman filters target tracking filtering algorithms	Consensus-based target tracking in camera networks faces three major problems: non-linearity in the measurement model, temporary lack of measurements (naivety) due to the limited field of view (FOV) and redundancy in the iterative exchange of information. In this paper we propose two consensus-based distributed algorithms for non-linear systems using the Extended Information Filter as underlying filter to handle the non-linearity in the camera measurement model. The first algorithm is an Extended Information Consensus Filter (EICF) that overcomes the effect of naivety and non-linearity without requiring knowledge of other nodes in the network. The second algorithm is an Extended Information Weighted Consensus Filter (EIWCF) that overcomes all the three major problems (naivety, redundancy and non-linearity) but requires knowledge of the number of cameras (Nc) in the network. The basic principle of these algorithms is weighting node estimates based on their covariance information. When Nc is not available, EICF can be used at the cost of not handling the redundancy problem. Simulations with highly maneuvering targets show that the two proposed distributed non-linear consensus filters outperform the related state of the art by achieving higher accuracy and faster convergence to the centralised estimates computed by simultaneously considering the information from all the nodes.	asynchronous i/o;centralisation;computation;computer simulation;converge;distributed algorithm;dynamic-link library;european interoperability framework;exponential integrate-and-fire;extended memory;field of view in video games;iterative method;kalman filter;linear system;naivety;nonlinear system;overhead (computing);particle filter;redundancy (engineering);software release life cycle;windows firewall	Sandeep Katragadda;Juan Carlos SanMiguel;Andrea Cavallaro	2014	17th International Conference on Information Fusion (FUSION)		computer vision;control theory;distributed computing	Robotics	53.596998317999955	2.4466220300831556	166937
15de50d007221e093476d423dac1dd8e2fad146f	cooperative relative positioning for intelligent transportation system	multipath transmission;intelligent transportation systems;crash avoidance systems;collision avoidance systems;urban areas;global positioning system;satellite navigation systems;global navigation satellite system	Global navigation satellite system-based positioning plays an important role in support system for safe driving, where relative positions of vehicles are used to prevent collision accidents from happening. In urban areas, however, multipath errors (MPEs) in pseudo-ranges, caused by obstruction and reflection of roadside buildings, greatly degrade the precision of relative positions. On the other hand, simply removing all reflected signals might lead to a shortage of satellites in fixing positions. This dilemma is solved in this paper by exploiting spatial correlation of MPEs. First, by analysis, ray-tracing simulation and testbed experiments, we show that MPEs in pseudo-ranges are spatially correlated in a small area. Then, we suggest a cooperative relative positioning scheme to exploit correlated signals, including reflected ones, in computing relative positions of nearby vehicles. Efficient transmission of pseudo-ranges is also discussed. The proposed scheme, which can be implemented either in a distributed way or via a cloud of intelligent transportation system, helps to improve the precision of relative positions in urban canyons.	global positioning system	Suhua Tang;Nobuaki Kubo;Nao Kawanishi;Rei Furukawa;Akio Hasegawa;Yoshio Takeuchi	2015	Int. J. Intelligent Transportation Systems Research	10.1007/s13177-014-0091-2	embedded system;intelligent transportation system;simulation;global positioning system;computer science;transport engineering	Robotics	48.79739908654431	1.4784175497737155	167655
09b83a23daf0448cdc24b003e47def259070408b	introducing new localization and positioning system for aerial vehicles	unmanned aerial vehicles uavs localization positioning time difference of arrival tdoa;robot vision autonomous aerial vehicles position control radio transmitters;radio transmitters;robot vision;position control;visual based positioning systems localization system aerial vehicles uav ubiquitous wireless transmitters communication transmitters multilateration time difference of arrival tdoa gps system stationary transmitters;autonomous aerial vehicles;transmitters global positioning system receivers ubiquitous computing time difference of arrival unmanned aerial vehicles	The concept of localization and positioning has received major attention as the use of UAVs is growing by day. Although there is the general method of GPS for positioning, as we will explain later, the need for alternative measures, such as new methods of localization based on visual means are growing. In this letter we present a new system based on common ubiquitous wireless and communication transmitters, presenting a new localization method based on Multilateration through calculations of time difference of arrival (TDOA) of the propagated signals. In this system we will, so to speak, turn the GPS system upside down and instead of using satellites as reference points in our positioning calculations, we will use the common stationary transmitters; making this system a perfect alternative for GPS and other visual based positioning systems.	aerial photography;ccir system a;comparison of raster-to-vector conversion software;global positioning system;internationalization and localization;multilateration;stationary process;transmitter;unmanned aerial vehicle	Ehsan Mazidi	2013	IEEE Embedded Systems Letters	10.1109/LES.2013.2279594	transmitter;telecommunications;time of arrival	Robotics	48.57722243029282	0.4696527740085616	168723
7d92259a24f9c870e15f2cced83223692f59e011	formtracer. a mathematica tracing package using form		We present FormTracer, a high-performance, general purpose, easy-to-use Mathematica tracing package which uses FORM. It supports arbitrary space and spinor dimensions as well as an arbitrary number of simple compact Lie groups. While keeping the usability of the Mathematica interface, it relies on the efficiency of FORM. An additional performance gain is achieved by a decomposition algorithm that avoids redundant traces in the product tensors spaces. FormTracer supports a wide range of syntaxes which endows it with a high flexibility. Mathematica notebooks that automatically install the package and guide the user through performing standard traces in space–time, spinor and gauge-group spaces are provided. Program summary Program Title: FormTracer Program Files doi: http://dx.doi.org/10.17632/7rd29h4p3m.1 Licensing provisions: GPLv3 Programming language: Mathematica and FORM Nature of problem: Efficiently compute traces of large expressions Solutionmethod: The expression to be traced is decomposed into its subspaces by a recursiveMathematica expansion algorithm. The result is subsequently translated to a FORM script that takes the traces. After FORM is executed, the final result is either imported into Mathematica or exported as optimized C/C++/Fortran code. Unusual features: The outstanding features of FormTracer are the simple interface, the capability to efficiently handle an arbitrary number of Lie groups in addition to Dirac and Lorentz tensors, and a customizable input-syntax. © 2017 Elsevier B.V. All rights reserved.	algorithm;computer performance;form;perturbation theory (quantum mechanics);programming language;quantum field theory;spinor;tracing (software);usability;wolfram mathematica	Anton K. Cyrol;Mario Mitter;Nils Strodthoff	2017	Computer Physics Communications	10.1016/j.cpc.2017.05.024	linear subspace;tensor;recursion;theoretical computer science;fortran;expression (mathematics);lie group;spinor;tracing;computer science	PL	42.40824995870506	3.746829119449722	168864
23ac71a2c552a968c55c0f1d067d42a385950df7	investigation on multilayer raster cellular neural network by arithmetic and heronian mean rkahem(4, 4)	edge detection;various embedded means;index terms- cellular neural networks;multilayer raster. i. introduction;numerical integration;arithmetic mean;indexing terms;initial value problem;cellular neural network;harmonic mean	We introduce a new technique for solving Initial Value Problems (IVPs) by formulating an embedded method involving RK methods based on Arithmetic Mean(AM) and Heronian Mean (HeM). The function of the simulator is that it is capable of performing Raster Simulation for any kind as well as any size of input image. It is a powerful tool for researchers to examine the potential applications of CNN. By using the newly proposed embedded method, a versatile algorithm for simulating multilayer CNN arrays is implemented. This article proposes an efficient pseudo code for exploiting the latency properties of CNN along with well known RK-Fourth Order Embedded numerical integration algorithms. Simulation results and comparison have also been presented to show the efficiency of the Numerical integration Algorithms. It is found that the RK-Embedded Heronian Mean outperforms well in comparison with the RK-Embedded Centroidal Mean, Harmonic Mean and Contra-Harmonic Mean.	algorithm;cellular neural network;embedded system;linux/rk;mean squared error;noise (electronics);numerical analysis;numerical integration;numerical linear algebra;pseudocode;raster graphics;relevance;simulation;theory	R. Ponalagusamy;S. Senthilkumar	2007				Embedded	40.16057897691185	0.7323094519971017	168920
f72d9bf6645d37753abab0c5a1cefc5a631abe4e	toa estimation and data association for through-wall tracking of moving targets	signal image and speech processing;information systems applications incl internet;data association;communications engineering networks	Through-wall tracking of moving targets is of great interest for rescue, surveillance, and security operations. For its realization, the handheld ultrawideband radars with small antenna array provide a practical solution. The radar signal processing, which is hidden behind the estimation of the final target tracks, represents a complex process with several processing phases. In this paper, all phases for through wall tracking are outlined whereas the attention is devoted to the estimation of the correct input data for the localization phase. This is done by applying a new approach that combines the time of arrival (TOA) estimation and the dataassociation into a single step. The properties of the proposed algorithm are illustrated by processing of real radar signals. Here, the obtained results confirm that the proposed algorithm has provided good, stable, and robust TOA estimation including deghosting task solution.		Jana Rovnáková;Dusan Kocur	2010	EURASIP J. Wireless Comm. and Networking	10.1155/2010/420767	simulation;speech recognition;telecommunications	Robotics	50.80762935487477	3.385886801813732	168992
cb50aedab291fdece5cf7ae66dab5fd14d8716c3	a versatile and modular capacitive tactile proximity sensor	robot sensing systems electrodes current measurement capacitance voltage measurement wires;spatial resolution versatile capacitive tactile proximity sensor modular capacitive tactile proximity sensor robotics consumer electronics hri self capacitive proximity mode mutual capacitive proximity mode mutual capacitive tactile mode capacitive measurement principle proximity measurements;tactile sensors capacitive sensors consumer electronics human robot interaction	In this work we discuss the design and realization of a novel capacitive tactile proximity sensor (CTPS) with applications in robotics and consumer-electronics. The current concept is an advancement with respect to a previous design developed at our lab. Experience in the development of applications based on the old sensor, such as manipulation and safe HRI, helped determining the requirements. The new sensor is capable of operating in a self- and mutual-capacitive proximity mode and in a mutual-capacitive tactile mode. The issue of having a trade-off between spatial resolution and sensing range in proximity mode due to the capacitive measurement principle is addressed. A circuit is designed to dynamically select or join electrodes involved in the proximity measurements, a technique which at the same time allows the implementation of the spatial resolution in the tactile mode. Also, all signal processing is done on board of the prototype sensor module, thus complete modularity is achieved.	bridge circuit;data rate units;electronic component;human–robot interaction;printed circuit board;prototype;requirement;robotics;sensor;signal processing	Hosam Alagi;Stefan Escaida Navarro;Michael Mende;Björn Hein	2016	2016 IEEE Haptics Symposium (HAPTICS)	10.1109/HAPTICS.2016.7463192	embedded system;electronic engineering;engineering;electrical engineering;proximity sensor;capacitive sensing;tactile sensor	Robotics	47.777928476970075	0.02822289927921222	169026
708de803f225e63083373324d3416fa6f59f133c	the mcb code for numerical modeling of fourth generation nuclear reactors	vhtr;monte carlo;radiation transport;lfr;mcb;nuclear reactors	R&D in the nuclear reactor physics demands state-of-the-art numerical tools that are able to characterize investigated nuclear systems with high accuracy. In this paper, we present the Monte Carlo Continuous Energy Burnup Code (MCB) developed at AGH University’s Department of Nuclear Energy. The code is a versatile numerical tool dedicated to simulations of radiation transport and radiation-induced changes in matter in advanced nuclear systems like Fourth Generation nuclear reactors.We present the general characteristics of the code and its application for modeling of Very-High-Temperature Reactors and Lead-Cooled Fast Rectors. Currently, the code is being implemented on the supercomputers of the Academic Computer Center (CYFRONET) of AGH University and will soon be available to the international scientific community.	monte carlo method;numerical analysis;reactor (software);simulation;supercomputer	Mikolaj Oettingen;Jerzy Cetnar;Tomasz Mirowski	2015	Computer Science (AGH)	10.7494/csci.2015.16.4.392	statistics;monte carlo method	HPC	42.16491629503281	2.895510310311873	169035
0c4a9125cea129c666fb46e9a2d3f7bf8dcfce89	optimum detection of image-adaptive watermarking in the dct domain	digital watermarking;watermarking;image coding;spread spectrum;intellectual property;optimum detection;digital watermark;bayes methods;indexing terms;watermarking discrete cosine transforms detectors spread spectrum communication humans robustness protection intellectual property nonlinear distortion discrete wavelet transforms;bayesian hypothesis testing;spread spectrum communication;discrete cosine transforms;watermarking bayes methods discrete cosine transforms image coding industrial property spread spectrum communication;industrial property;watson s perceptual model;watson s perceptual model digital watermarking spread spectrum optimum detection;bayesian hypothesis testing optimum blind detection image adaptive digital watermarking discrete cosine transform dct domain intellectual property protection spread spectrum watsons nonlinear perceptual model modulation	Digital watermarking is an efficient and promising means to protect intellectual properties. Spread spectrum (SS) is one of the most widely used watermarking schemes, and can be further facilitated by adapting the watermark strength to the host signal. In this paper we address the problem of optimum blind detection of SS watermarks in the DCT domain, where Watson's non-linear perceptual model is used for the modulation of the watermarks. The basic idea is to transform the DCT coefficients to a perceptually uniform domain and perform Bayesian hypothesis testing in that domain. Simulation results show the superior performance of the proposed scheme over the conventional linear correlation detector (LCD).	approximation;coefficient;digital watermarking;discrete cosine transform;frequency-hopping spread spectrum;modulation;nonlinear system;portable document format;simulation;watermark (data file)	Wei Liu;Lina Dong;Wenjun Zeng	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312981	computer vision;speech recognition;digital watermarking;computer science;theoretical computer science;mathematics	EDA	41.684623271934356	-9.66176564319976	169400
1e689887667a32431e06a7abdff881b71abe6e26	a comparative study of lpc parameter representations and quantisation schemes for wideband speech coding	line spectral frequency;distance measure;institute for integrated and intelligent systems;faculty of science environment engineering and technology;speech coding;280204;journal article;gaussian mixture model;vector quantisation;switched split vector quantiser;pre2009 signal processing;lower bound	In this paper, we provide a review of LPC parameter quantisation for wideband speech coding as well as evaluate our contributions, namely the switched split vector quantiser (SSVQ) and multi-frame GMM-based block quantiser. We also compare the performance of various quantisation schemes on the two popular LPC parameter representations: line spectral frequencies (LSFs) and immittance spectral pairs (ISPs). Our experimental results indicate that ISPs are superior to LSFs by 1 bit/frame in independent quantiser schemes, such as scalar quantisers; while LSFs are the superior representation for joint vector quantiser schemes. We also derive informal lower bounds, 35 and 36 bits/frame, for the transparent coding of LSFs and ISPs, respectively, via the extrapolation of the operating distortion-rate curve of the unconstrained vector quantiser. Finally, we report and discuss the results of applying the SSVQ with dynamically-weighted distance measure and the multi-frame GMM-based block quantiser, which achieve transparent coding at 42 and 37 bits/frame, respectively, for LSFs. ISPs were found to be inferior to the LSFs by 1 bit/frame. In our comparative study, other quantisation schemes that were investigated include PDF-optimised scalar quantisers, the memoryless Gaussian mixture model-based block quantiser, the split vector quantiser, and the split-multistage vector quantiser with MA predictor from the AMR-WB (ITU-T G.722.2) speech coder. © 2005 Elsevier Inc. All rights reserved.	1-bit architecture;adaptive multi-rate wideband;adaptive multi-rate audio codec;distortion;extrapolation;google map maker;kerrison predictor;lpc;line spectral pairs;mixture model;multistage interconnection networks;portable document format;quantization (image processing);quantization (physics);quantization (signal processing);speech coding	Stephen So;Kuldip K. Paliwal	2007	Digital Signal Processing	10.1016/j.dsp.2005.10.002	speech recognition;telecommunications;computer science;speech coding;mixture model;mathematics;upper and lower bounds	HCI	48.29894013173827	-9.67594907995977	169775
8c9a70310e62637f67701845edd02e999f3bb311	optimization of a blind speech watermarking technique against amplitude scaling		This paper presents a gain invariant speech watermarking technique based on quantization of the Lp-norm. In this scheme, first, the original speech signal is divided into different frames. Second, each frame is divided into two vectors based on odd and even indices.Third, quantization indexmodulation (QIM) is used to embed thewatermark bits into the ratio of the Lp-normbetween the odd and even indices. Finally, the Lagrange optimization technique is applied to minimize the embedding distortion. By applying a statistical analytical approach, the embedding distortion and error probability are estimated. Experimental results not only confirm the accuracy of the driven statistical analytical approach but also prove the robustness of the proposed technique against common signal processing attacks.		Mohammad Ali Nematollahi;Chalee Vorakulpipat;Hamurabi Gamboa Rosales	2017	Security and Communication Networks	10.1155/2017/5454768	speech recognition;theoretical computer science	ML	41.66256260880396	-9.407398206575357	169984
04c64a2def777ed920d0c023dfc6f66515ecf0c2	steganographic band width extension for the amr codec of low-bit-rate modes		This paper proposes a bandwidth extension (BWE) method for the AMR narrow-band speech codec using steganography, which is called steganographic BWE herein. The highband information is embedded into the pitch delay data of the AMR codec using an extended quantization-based method that achieves increased embedding capacity and higher perceived sound quality than the previous steganographic method. The target bit-rate mode is below 7 kbps, the level below which the previous steganographic BWE method did not maintain adequate sound quality. The sound quality of the steganographic BWE speech signals decoded from the embedded bitstream is comparable to that of the wide-band speech signals of the AMRWB codec at a bit rate of less than 6.7 kbps, with only a slight degradation in the quality relative to speech signals decoded from the same bitstream by the legacy AMR decoder.	adaptive multi-rate audio codec;bandwidth extension;bitstream;brainwave entrainment;code;data rate units;elegant degradation;embedded system;sound quality;speech coding;steganography	Akira Nishimura	2009			parallel computing;steganography;low bit;computer science;adaptive multi-rate audio codec	Graphics	47.81480858728337	-8.717424995671838	170911
2ab29256ad2167f560f9cb203745f670c79451d2	adaptive segmentation methodology for hardware function evaluators		Abstract This paper presents a new adaptive function segmentation methodology to evaluate mathematical functions in hardware systems through piece-wise polynomial approximation methods. In contrast to conventional segmentation techniques, this methodology automatically adjusts the segmentation strategy through a function shape analysis based on the first- and second-order derivatives. Additionally, a particle swarm optimization algorithm is implemented to search for the best segmentation parameters that satisfy the designer-given signal-to-quantization-noise ratio specification and minimize the number of polynomials. The main advantages are a significant lookup table size reduction, increased approximation accuracy of highly nonlinear sections, and the automatic generation of a hierarchy-less segmentation solution. Hence, the proposed methodology enables efficient development of hardware accelerated surrogate models such as wireless channel emulators and other signal processing applications on inexpensive platforms that rely on fixed-point number representation as a compromise between performance, and output accuracy.		J. M. Trejo-Arellano;J. Vazquez Castillo;Omar Humberto Longoria-Gandara;Roberto Carrasco-Alvarez;Carlos A. Gutiérrez;Alejandro Castillo Atoche	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2018.04.024	computer hardware;signal processing;shape analysis (digital geometry);function (mathematics);computer science;nonlinear system;polynomial;particle swarm optimization;lookup table;compromise	Vision	42.56970174531277	-0.2640220203040734	171018
6d2ef012c765cad43407b5f10ed6b07cc01ad5d1	an extended projective formula and its application to semidefinite optimization	semidefinite least squares;quasi newton;symmetric matrix;15a60;upper bound;65k05;15a48;least squares problem;projection;least square;quasi newton method;90c22;47a75;projected quasi newton method;convex set;interior point method	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	admissible rule;francis;mathematical optimization;primary source	Zhilin Kang	2012	Int. J. Comput. Math.	10.1080/00207160.2012.713942	mathematical optimization;conic optimization;combinatorics;mathematical analysis;quasi-newton method;projection;projection;interior point method;dykstra's projection algorithm;mathematics;convex set;upper and lower bounds;least squares;semidefinite programming;symmetric matrix;algebra	Robotics	49.500223922340304	-2.934725650951454	171053
5bad13d490c15a76e1932d9c0dec56dc3cae76f1	a parallel approach for determining confidence intervals of variable statistics in large and sparse linear equations with rhs ranges	parallel computing;90c06;domain decomposition;65f05;right hand side;statistical confidence intervals;15a06;confidence interval;comparative study;parallel computer;linear program;90c05;65f50;linear equations;large and sparse systems;covariance matrix	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	domain decomposition methods;francis;linear equation;linear programming;primary source;sparse matrix;system of linear equations	Peerayuth Charnsethikul	2009	Int. J. Comput. Math.	10.1080/00207160701689534	covariance matrix;mathematical optimization;confidence interval;computer science;linear programming;machine learning;comparative research;mathematics;domain decomposition methods;linear equation;statistics	Robotics	49.1071591390163	-2.963412415013292	171717
0ada3c5641a87d1c13c565cebad8da8f3fdc5b6c	low-cost electrochemical impedance spectroscopy system for corrosion monitoring of metallic antiquities and works of art	data processing;frequency;frequency analysis;electrochemical impedance spectroscopy;power system protection;system testing;digital signal processing;complex data;art;microcomputers;front end;archaeology;digital signal processor;digital signal processors;electrochemistry;cost function;intelligent systems;floating point processor;corrosion	Electrochemical impedance spectroscopy (EIS) is recognized to be a powerful and noninvasive technique to test the integrity of protective coatings on memorials, but commercial EIS systems are rather costly though versatile devices. This paper describes a low cost and portable EIS system that is based on a compact digital signal processor (DSP) board and embeds the potentiostatic function so that it can be used without requiring an external potentiostat. The software that runs on the DSP is designed to analyze the electrochemical impedance only in a reduced frequency range in order to produce a simple corrosion alert result. The device is equipped with a digital interface and can be connected to a personal computer to carry out a complete frequency analysis and perform a more complex data processing.	characteristic impedance;digital signal processor;frequency analysis;frequency band;output impedance;personal computer;potentiostat;signal processing	Alessio Carullo;Franco Ferraris;Marco Parvis;Alberto Vallan;Emma Angelini;Paolo Spinelli	2000	IEEE Trans. Instrumentation and Measurement	10.1109/19.843080	digital signal processor;electronic engineering;computer science;engineering;electrical engineering;electrochemistry;front and back ends;frequency analysis;dielectric spectroscopy;complex data type	EDA	46.29699346365267	-2.158771936288924	172007
84c282cee609f5cda70ea61f157d4304096777b1	accurate tracking in nlos environments using integrated imu and fixed lag smoother	smoothing methods computational complexity indoor navigation inertial navigation kalman filters pedestrians radionavigation radiowave propagation sensor fusion;mobile nodes;time measurement;measurement uncertainty;position measurement measurement uncertainty time measurement mobile nodes real time systems sensor fusion;kalman filter accurate tracking nlos environments inertial measurement units integrated imu fixed lag smoother multisensor data fusion positioning systems semireal time tracking algorithm indoor positioning platform computational complexity nlos propagation non line of sight propagation indoor environments;position measurement;sensor fusion;nlos error indoor localization imu sensor fusion;real time systems	Multi-sensor data fusion using Inertial Measurement Units (IMUs) is a promising technique for improving the performance of positioning systems. However, the performance of conventional sensor fusion algorithms based on the Kalman Filter (KF) is compromised in indoor environments due to non-line-of-sight (NLOS) propagation. In this paper, we propose a semi-real time tracking algorithm which uses a fixed lag smoother for sensor fusion and achieves high accuracy in NLOS environments. The computational complexity of the algorithm is taken into consideration and is reduced by decreasing the operating rate of the smoother. The performance of the proposed algorithm is validated experimentally using a real indoor positioning platform. It is shown that the 90th percentile positioning error for a pedestrian is reduced by 42% using the proposed semi-real time tracking algorithm with 10 s lag, compared with using a KF-based real time tracking algorithm.	algorithm;computational complexity theory;experiment;kalman filter;line-of-sight (missile);positioning system;semiconductor industry;software propagation	Shenghong Li;Mark Hedley;Iain B. Collings;Mark Johnson	2016	2016 19th International Conference on Information Fusion (FUSION)		computer vision;simulation;geography;telecommunications	Robotics	50.19403939219409	1.0198791797448616	172595
7dc9655dd06f179ab227c911072ca4352e8d32da	distributed arithmetic architecture of discrete wavelet transform (dwt) with hybrid method	discrete wavelet transforms;hybrid method distributed arithmetic architecture 3d discrete wavelet transform spartan 3 xc3s2000 single board rio fpga field programmable gate array g code vhdl daubechies transform multidimensional haar transform medical image compression;biomedical imaging;discrete wavelet transforms table lookup biomedical imaging field programmable gate arrays;field programmable gate arrays;table lookup;medical image processing data compression discrete wavelet transforms distributed arithmetic field programmable gate arrays haar transforms hardware description languages image coding	This paper presents the design and implementation of distributed arithmetic (DA) architectures of three-dimensional (3-D) Discrete Wavelet Transform (DWT) with hybrid method for medical image compression. Due to the separability property of the multi-dimensional Haar and Daubechies, the proposed architecture has been implemented using a cascade of three N-point one-dimensional (1-D) Haar/Daubechies and two transpose memories for a 3-D volume of N×N×N, suitable for 3-D medical imaging applications. The architectures were synthesised using VHDL and G-code and implemented on field programmable gate array (FPGA) single board RIO (sbRIO-9632) with Spartan-3 (XC3S2000). Experimental results and an analysis of the area, power consumption, maximum frequency, latency, throughput as well as the subjective test are discussed in this paper.	approximation;computation;discrete wavelet transform;field-programmable gate array;g-code;haar wavelet;image compression;linear separability;medical imaging;symlet;throughput;vhdl	Noor Huda Ja'afar;Afandi Ahmad;Abbes Amira	2013	2013 IEEE 20th International Conference on Electronics, Circuits, and Systems (ICECS)	10.1109/ICECS.2013.6815463	wavelet;embedded system;electronic engineering;second-generation wavelet transform;computer science;theoretical computer science;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform	EDA	45.16752842113775	-9.67477975429698	172724
512399a89884b0afa0fc48e1eeab9eb8a52f3edd	an ultra-low-power micro-optoelectromechanical tilt sensor	ultra low power;rigid body;mems;tilt sensor;vision chip;cmos based optical sensor surface;microsystem tilt sensor inclinometer vision chip mems;microsystem;indexing terms;chip;cmos image sensors;micromechanical devices biosensors optical sensors detectors biomedical optical imaging biomedical engineering educational institutions photodiodes sensor systems wearable sensors;inclinometer;cmos mems tilt sensor;conference paper;photodiodes;mems based semicircular mass;one dimensional photodiode array;ultralow power microoptoelectromechanical tilt sensor;photodiodes cmos image sensors micro optomechanical devices microsensors;optical sensor;microsensors;micro optomechanical devices;one dimensional photodiode array ultralow power microoptoelectromechanical tilt sensor cmos mems tilt sensor mems based semicircular mass cmos based optical sensor surface	This paper presents a novel hybrid CMOS/MEMS tilt sensor with a 5deg resolution over a 330deg range. The device uses a MEMS-based semicircular mass suspended from a rigid body, projecting a shadow onto the CMOS-based optical sensor surface. A one-dimensional photodiode array arranged as a uniformly segmented ring is then used to determine the tilt angle by detecting the position of the semicircular mass. The complete sensor occupies an area of under 2.5 m times 2.5 mm.	cmos;low-power broadcasting;microelectromechanical systems;sensor	Timothy G. Constandinou;Julius Georgiou;Charalambos M. Andreou	2008	2008 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2008.4542128	chip;embedded system;rigid body;photodiode;electronic engineering;inclinometer;index term;tilt sensor;computer science;sensor;electrical engineering;microsystem;microelectromechanical systems	Embedded	51.31832257872935	-1.321120557844861	172844
425e343d0b8a752d33fd94fb526ad5af5c7845a6	on the compression of locational and environmental data in multi-vehicle missions: a control systems approach	coverage control;formation control;data compression;binary consensus	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	computation;consensus dynamics;control system;francis;ibm notes;internet information services;nonlinear system;optimal control;primary source;quantization (image processing);quantization (signal processing);simulation;stationary process	José-Marcio Luna;Rafael Fierro;Chaouki T. Abdallah;Frank L. Lewis	2013	Int. J. Control	10.1080/00207179.2013.800643	data compression;control engineering;simulation;engineering;control theory;mathematics;computer security	Robotics	50.814576709213966	-3.4199038743915566	173139
50001c087888b0a1dc8b48d79aebf04a58228031	smart brief monitoring system for assisted living	temperature sensors;servers;monitoring;moisture;batteries;temperature measurement;conferences	A system for monitoring the moisture level and temperature of an adult disposable brief has been designed and tested. The system uses an inexpensive (<; $0.05) disposable moisture sensor combined with a re-usable temperature sensor and a Bluetooth Low-Energy transceiver module costing less than $15. The battery lifetime using the CR2032 coin cell is greater than 3 years while sampling data at 10s intervals. This sensor data can be used for monitoring, alerting, statistical analysis, and potentially reducing the incidence of infections. The data can be monitored and processed locally or stored on a server to be analyzed remotely. The prototyped devices were tested and shown to detect as little as 10 mL of tap water when poured into the smart brief. The temperature resolution of less than 0.25° F was observed and a wireless range of 20 m indoors and 100 m outdoors was measured.	bluetooth;incidence matrix;sampling (signal processing);server (computing);transceiver	Mohammad Mohebbi;Florian Luaire;Douglas Jackson;John Naber	2016	2016 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2016.7430734	moisture;embedded system;electronic engineering;telecommunications;temperature measurement;computer science;engineering;server	Robotics	45.120456860812354	-0.6470864521178658	173250
0859e6b90fced4e579f1444d73db992fd69cdbd0	telephony speech enhancement by data hiding	data hiding;telephony speech enhancement data encapsulation bandwidth frequency narrowband degradation speech coding humans ear;speech intelligibility;spread spectrum;telephony speech enhancement;speech coding telephony speech enhancement data hiding public switched telephone network pstn narrowband telephone speech speech intelligibility perceived speech quality channel bandwidth perceptual masking principle orthogonal pseudonoise codes hidden channel hidden signal quantization errors channel noises transmission bandwidth auditory spectrum;channel noises;hidden channel;pstn;channel bandwidth;speech coding;spectrum;auditory spectrum;perceived speech quality;speech enhancement;telephony;data encapsulation;transmission bandwidth;pseudo noise;orthogonal pseudonoise codes;public switched telephone network;public switched telephone network pstn;perceptual masking principle;quantization errors;simulation analysis;bandlimited communication;spread spectrum ss auditory spectrum data hiding public switched telephone network pstn speech coding speech enhancement;hidden signal;spread spectrum ss;orthogonal codes;pseudonoise codes;telephony bandlimited communication data encapsulation orthogonal codes pseudonoise codes speech coding speech enhancement speech intelligibility;narrowband telephone speech;quantization error	The current public switched telephone network (PSTN) is only able to deliver analog signals in a relatively narrow frequency band, about 200-3500 Hz. Such a limited bandwidth causes the typical sound of the narrowband telephone speech. In order to improve intelligibility and perceived quality of telephone speech, we propose using data hiding to extend the PSTN channel bandwidth. Based on the perceptual masking principle, the inaudible spectrum components within the telephone bandwidth can be removed without degrading the speech quality, providing a hidden channel to transmit extra information. The audible components outside the PSTN bandwidth, which are spread out by using orthogonal pseudo-noise codes, are embedded into this hidden channel and then transmitted through the PSTN channel. While this hidden signal is not audible to the human ear, it can be extracted at the receiver end. It results in a final speech signal with a wider bandwidth than the normal PSTN channel. Using both theoretical and simulation analysis, it is shown that the proposed approach is robust to quantization errors and channel noises. Although we cannot physically extend the transmission bandwidth of PSTN, the telephony speech quality can be significantly improved by using the proposed data hiding technique	analog signal;brainwave entrainment;channel (communications);code;embedded system;frequency band;intelligibility (philosophy);naive bayes classifier;simulation;speech enhancement	Siyue Chen;Henry Leung;Heping Ding	2007	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2006.887409	spectrum;speech recognition;quantization;telecommunications;computer science;speech coding;telephony;information hiding;spread spectrum;intelligibility;channel capacity	Mobile	48.931682239278416	-8.2130332982912	173569
fe6ffd56a63a2a3a908d9c39a824681509d8cba3	a rotating machine acoustic emission monitoring system powered by multi-source energy harvester	energy harvesting;acoustic emissions;monitoring system;power management;supercapacitor	This working paper introduces a multi-source energy harvesting powered acoustic emissions (AE) monitoring system for the applications of rotating machine fault detections. This wireless sensor prototype records the AE signal at approximately 200KHz frequency. It performs fast Fourier transform (FFT) and compares the results with known fault patterns. An energy harvesting solution utilizes vibrational, thermal and light energy as the power supply for the AE wireless sensor node. The multiple-source energy harvester proposed in this work generates 1.56mW from 25--48mg vibration energy and 3.37mW from thermoelectric energy when deployed on the 62°C metal surface of air compressor. This AE wireless sensor prototype combines with the batteryless energy harvesting power supply in order to provide a self-powered health monitoring solution for wide range of rotating machinery.	acoustic cryptanalysis;bioinformatic harvester;fast fourier transform;multi-source;power supply;prototype;sensor node	Wensi Wang;Alessandro Vinco;Nikolay Pavlov;Ningning Wang;Mike Hayes;Seán Cian O'Mathuna	2013		10.1145/2534208.2534224	embedded system;electronic engineering;engineering;electrical engineering	Mobile	45.138845100581285	-0.7547802879596711	173654
10dd7ef9330ae02b6fd6ff8c4b114e04e9499f35	progressive syntax-rich coding of multichannel audio sources	signal image and speech processing;progressive coding;quantum information technology spintronics;successive quantization;multichannel audio;karhunen loeve transform;psmac	Being able to transmit the audio bitstream progressively is a highly desirable property for network transmission. MPEG-4 version 2 audio supports fine grain bit rate scalability in the generic audio coder (GAC). It has a bit-sliced arithmetic coding (BSAC) tool, which provides scalability in the step of 1 Kbps per audio channel. There are also several other scalable audio coding methods, which have been proposed in recent years. However, these scalable audio tools are only available for mono and stereo audio material. Little work has been done on progressive coding of multichannel audio sources. MPEG advanced audio coding (AAC) is one of the most distinguished multichannel digital audio compression systems. Based on AAC, we develop in this work a progressive syntax-rich multichannel audio codec (PSMAC). It not only supports fine grain bit rate scalability for the multichannel audio bitstream but also provides several other desirable functionalities. A formal subjective listening test shows that the proposed algorithm achieves an excellent performance at several different bit rates when compared with MPEG AAC.	advanced audio coding;algorithm;arithmetic coding;bitstream;codec;coefficient;data compression;data rate units;lossless compression;mega man network transmission;monkey's audio;moving picture experts group;preprocessor;scalability	Dai Yang;Hongmei Ai;Chris Kyriakakis;C.-C. Jay Kuo	2003	EURASIP J. Adv. Sig. Proc.	10.1155/S1110865703304044	sub-band coding;adaptive multi-rate audio codec;joint;speech recognition;mpeg-4 part 3;digital audio;audio signal processing;computer science;audio bit depth;speech coding;sound quality;mathematics;multimedia;karhunen–loève theorem;statistics	HCI	47.302336505321115	-8.968467815253852	173655
5c7d0fa33e975114b7a0f311805577add4c79672	danger of low-dimensional watermarking subspaces	watermarking;optimisation;digital watermark;video coding;parameter estimation watermarking security of data principal component analysis video coding optimisation;expectation maximization;principal component analysis;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;watermarking payloads principal component analysis cryptography robustness data security information security multimedia communication copyright protection large scale systems;parameter estimation;video watermarking;em algorithm;watermarking subspace estimation low dimensional watermarking subspaces security issue digital watermarking video watermarking hidden watermark removal secret key principal component analysis pca expectation maximization algorithm em algorithm;security of data	The security issue has been neglected for a long time in digital watermarking. Recent results for video watermarking have pointed out that existing watermarking schemes are not secure, i.e., a hostile intelligence succeeds in removing the hidden watermarks. In particular, for a given secret key, many watermarking schemes embed watermarks which lie in the same low-dimensional subspace whatever the host data is. We show that this subspace can be quite easily estimated with an efficient principal component analysis (PCA). For storage convenience, an online expectation-maximization (EM) algorithm is considered. Once this watermarking subspace has been estimated, an attacker only has to project incoming data onto the orthogonal of this subspace to remove the watermark.	digital watermarking;expectation–maximization algorithm;key (cryptography);principal component analysis	Gwenaël J. Doërr;Jean-Luc Dugelay	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1326489	watermarking attack;digital watermarking alliance;expectation–maximization algorithm;digital watermarking;computer science;theoretical computer science;machine learning;mathematics;internet privacy;watermark;computer security;statistics	EDA	40.3270171461939	-9.391948286914856	173753
1761e11ad415e225efb0e0131cc9d903c973f91c	an enhanced parallel version of kiva–3v, coupled with a 1d cfd code, and its use in general purpose engine applications	calcul scientifique;modelizacion;algoritmo paralelo;computer program;haute performance;parallel algorithm;detail level;distributed computing;fluid mechanics;mecanique fluide;dinamica fluido;niveau detail;algorithme parallele;grid;programa informatico;modelisation;computacion cientifica;level of detail;rejilla;simulation ecoulement;scientific computing;alto rendimiento;grille;calculo repartido;fluid dynamics;flow simulation;scientific computation;dynamique fluide;modeling;high performance;calcul reparti;mecanica fluido;programme ordinateur;numerical simulation;nivel detalle	Numerical simulations of reactive flows are among the most computational demanding applications in the scientific computing world.#R##N##R##N#KIVA-3V, a widely used computer program for CFD, specifically tailored to engine applications, had been deeply modified in order to improve accuracy and stability, while reducing computational time.#R##N##R##N#The original methods included in KIVA to solve equations of fluid dynamics had been fully replaced by new solvers, with the aim of both improving performance and writing a fully parallel code. Almost every feature of original KIVA-3V has been partially or entirely rewritten, a full 1D code has been included and a strategy to link directly 3D zones with zero dimensional models has been developed.#R##N##R##N#The result is a reliable program, noticeably faster than the original KIVA-3V in serial mode and obviously even more in parallel, capable of treating more complex cases and bigger grids, with the desired level of details where required.		Gino Bella;Fabio Bozza;Alessandro De Maio;Francesco Del Citto;Salvatore Filippone	2006		10.1007/11847366_2	simulation;systems modeling;computer science;level of detail;parallel algorithm;grid;algorithm;fluid mechanics;fluid dynamics	HPC	44.872377330831405	3.7512346143624247	175083
fc5b7c9392d6911b4400e315aa6f63120dfe2161	a labview based time of flight measurements for ultrasonic phased array sensors	digital signal processing;time of flight;distance measure;cross correlation;phased array;ultrasonic phased array;virtual instrument;graphical programming;ranging;wavelet transform;beam steering;detection algorithm;system level design;dsp;labview	Most of the ultrasonic distance measurements are based on the determination of the Time of flight. Digital signal processing techniques for obtaining high accuracy in ultrasonic distance measurements are presented in this paper. The proposed method employs a Wavelet transform to extract the envelope of the reflected pulse echo, together with a cross-correlation pulse detection algorithm for the Time of flight estimation. The simulated system consists of five elements transducer array as both transmitter and receiver. The transducer array is formed by aligning the transducers with minimum spacing between elements of 2 wavelengths. The results show the accuracy with the theoretical value. The simulation for the above said module has been implemented using LabVIEW (Laboratory virtual instrument engineering workbench) developed by National Instrument, is a graphical programming environment suited for high-level and system level design.	algorithm;cross-correlation;digital signal processing;graphical user interface;high- and low-level;integrated development environment;labview;level design;phased array;sensor;simulation;transducer;transmitter;virtual instrumentation;visual programming language;wavelet transform;workbench	Ashwini Naik;M. S. Panse	2011		10.1145/1980022.1980243	embedded system;electronic engineering;engineering;electrical engineering	EDA	46.184692290920474	-2.177128356812841	175324
71362ed6bbb221f1d2209f602d2410da3a72f226	distributed gaussian particle filtering using likelihood consensus	approximate algorithm;complexity theory;approximation algorithms;polynomial complexity;least squares approximation;state estimation;polynomials;noise measurement;wireless sensor network;polynomials complexity theory least squares approximation approximation algorithms noise measurement noise;wireless sensor network gaussian particle filter distributed particle filter likelihood consensus target tracking;local community;likelihood consensus;particle filter;gaussian particle filter;distributed particle filter;target tracking;likelihood function;noise	We propose a distributed implementation of the Gaussian particle filter (GPF) for use in a wireless sensor network. Each sensor runs a local GPF that computes a global state estimate. The updating of the particle weights at each sensor uses the joint likelihood function, which is calculated in a distributed way, using only local communications, via the recently proposed likelihood consensus scheme. A significant reduction of the number of particles can be achieved by means of another consensus algorithm. The performance of the proposed distributed GPF is demonstrated for a target tracking problem.	chandra–toueg consensus algorithm;general protection fault;ibm gpfs;particle filter	Ondrej Hlinka;Ondrej Sluciak;Franz Hlawatsch;Petar M. Djuric;Markus Rupp	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5947168	mathematical optimization;wireless sensor network;particle filter;computer science;noise measurement;noise;machine learning;mathematics;likelihood function;least squares;approximation algorithm;statistics;polynomial	Robotics	53.23815284164049	3.8677794278272843	175483
eeda8efdda59767004744537eb40ea6d97453bdc	new evaluation scheme for software function approximation with non-uniform segmentation	software;memory management;approximation error;approximation algorithms;indexing;hardware	Modern applications embed complex mathematical processing based on composition of elementary functions. A good balance between approximation accuracy, and implementation cost, i.e. memory space requirement and computation time, is needed to design an efficient implementation. From this point of view, approaches working with polynomial approximation obtain results of a monitored accuracy with a moderate implementation cost. For software implementation in fixed-point processors, accurate results can be obtained if the segment on which the function is computed I is segmented accurately enough, to have an approximating polynomial on each segment. Non-uniform segmentation is required to limit the number of segments and then the implementation cost. The proposed recursive scheme exploits the trade-off between memory requirement and evaluation time. The method is illustrated with the function exp(-√(x)) on the segment [2-6; 25] and showed a mean speed-up ratio of 98.7 compared to the mathematical C standard library on the Digital Signal Processor C55x.	approximation algorithm;c standard library;central processing unit;computation;dspace;digital signal processor;elementary function;memory footprint;pareto efficiency;polynomial;recursion (computer science);texas instruments tms320;time complexity	Justine Bonnot;Erwan Nogues;Daniel Ménard	2016	2016 24th European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2016.7760325	mathematical optimization;computer science;theoretical computer science;algorithm	EDA	42.56284875386302	-0.250712841232446	175524
4a3c43c310471ba2a9cde2ec3f07b2c257822017	multi-model rao-blackwellised particle filter for maneuvering target tracking in distributed acoustic sensor networks	stratified particles sampling multi model rao blackwellised particle filter maneuvering target tracking distributed acoustic sensor networks non gaussian estimation problems;signal sampling;acoustics;particle filters target tracking acoustic sensors wireless sensor networks state estimation kalman filters sampling methods nonlinear equations acoustic measurements intelligent networks;acoustic signal processing;matrix algebra;sensor networks particle filter rbpf maneuvering target multi model;distributed sensors;sensor networks;particle filter;multi model;target tracking acoustic signal processing acoustic transducers distributed sensors matrix algebra particle filtering numerical methods signal sampling;rbpf;target tracking;engineering electrical electronic;acoustic transducers;maneuvering target;particle filtering numerical methods	In this paper, a multi-model Rao-Blackwellised particle filter algorithm is presented for tracking high maneuvering target in distributed acoustic sensor networks. It is more efficient for high-dimension nonlinear and non-Gaussian estimation problems than generic particle filter, and by stratified particles sampling from a set of system models, it can tackle the target's maneuver perfectly. In the simulation comparison, a high maneuvering target moves through an acoustic sensor network field. The target is tracked using both the RBPF and the multi-model RBPF algorithms, and a location-central protocol is applied for energy conservation. The results show that our approach has great performance improvements, especially when the target is making maneuver.	acoustic cryptanalysis;acoustic fingerprint;nonlinear system;particle filter;peterson's algorithm;sampling (signal processing);simulation	Zhijun Yu;Guangxin You;Jianming Wei;Haitao Liu	2007	2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07	10.1109/ICASSP.2007.367061	wireless sensor network;particle filter;computer science;control theory	Robotics	53.42223354350392	4.059583128088375	175689
01e1bbd263fbb321bf7bfbbbad01f430b146cfd3	continuous development of schemes for parallel computing of the electrostatics in biological systems: implementation in delphi	parallel computing;software;static electricity;mitochondrial proteins;animals;electrostatics;models molecular;cattle;delphi;algorithms;poisson boltzmann equation	Due to the enormous importance of electrostatics in molecular biology, calculating the electrostatic potential and corresponding energies has become a standard computational approach for the study of biomolecules and nano-objects immersed in water and salt phase or other media. However, the electrostatics of large macromolecules and macromolecular complexes, including nano-objects, may not be obtainable via explicit methods and even the standard continuum electrostatics methods may not be applicable due to high computational time and memory requirements. Here, we report further development of the parallelization scheme reported in our previous work (Li, et al., J. Comput. Chem. 2012, 33, 1960) to include parallelization of the molecular surface and energy calculations components of the algorithm. The parallelization scheme utilizes different approaches such as space domain parallelization, algorithmic parallelization, multithreading, and task scheduling, depending on the quantity being calculated. This allows for efficient use of the computing resources of the corresponding computer cluster. The parallelization scheme is implemented in the popular software DelPhi and results in speedup of several folds. As a demonstration of the efficiency and capability of this methodology, the electrostatic potential, and electric field distributions are calculated for the bovine mitochondrial supercomplex illustrating their complex topology, which cannot be obtained by modeling the supercomplex components alone.	algorithm;anatomy, regional;biological system;bos taurus;bovine metabolome database;computation (action);computer cluster;electrostatics;embarcadero delphi;energy, physics;gnu nano;lithium;molecular biology;multithreading (computer architecture);parallel computing;physical object;requirement;scheduling (computing);scheduling - hl7 publishing domain;speedup;thread (computing);time complexity;triune continuum paradigm;macromolecule	Chuan Li;Marharyta Petukh;Lin Li;Emil Alexov	2013	Journal of computational chemistry	10.1002/jcc.23340	computational science;static electricity;theoretical computer science;computational chemistry;mathematics;physics;quantum mechanics;poisson–boltzmann equation;electrostatics	Comp.	43.328310188128114	1.2163669787630802	175905
eeed95857ff096160c00607addef407712906779	an integrated decomposition and partitioning approach for irregular block-structured applications	structure methods;algoritmo paralelo;integrated approach;cluster algorithm;bin packing;parallel algorithm;descomposicion grafo;algorithm performance;domain decomposition;berakningsmatematik;algoritmo recursivo;simulacion numerica;computational mathematics;data partitioning;algorithme parallele;algorithme recursif;resultado algoritmo;simulation numerique;performance algorithme;scientific computing;datavetenskap datalogi;recursive algorithm;space filling curve;computer science;multilevel method;graph decomposition;numerical simulation;decomposition graphe	We present an integrated domain decomposition and data partitioning approach for irregular block-structured methods in scienti c computing. We have demonstrated the method for an application related to Ocean modeling. Our approach gives better results than other methods that we have found in the literature. We have compared the domain decomposition part with the Berger-Rigoutsos point clustering algorithm and the partitioning part with a multilevel method used in Metis, a bin packing method, and an inverse space lling curve algorithm. The partitions produced with our approach give lower run times, i.e. higher parallel e ciency, for our application than all the other partitions we have tried. Moreover, the integrated approach gives a possibility to further improve the parallel e ciency compared to doing the decomposition and partitioning in two separate steps.	algorithm;bin packing problem;cluster analysis;domain decomposition methods;metis;set packing	Jarmo Rantakokko	2000		10.1007/3-540-45591-4_65	computer simulation;mathematical optimization;bin packing problem;numerical analysis;computer science;theoretical computer science;mathematics;domain decomposition methods;parallel algorithm;algorithm;recursion	EDA	44.49698014706098	3.5327758635655675	176093
5ee34db5ef5284651da46cd7638ea5490ff6e7c9	residential appliance identification based on spectral information of low frequency smart meter measurements	databases;low frequency smart meter measurements nonintrusive load monitoring method nilm method residential appliances uncorrelated spectral components active power consumption signal karhunen loeve expansion subspace components active power measurement signature data base sc level power conditions maximum a posteriori estimation turned on appliance combination energy estimation algorithm energy contribution tracebase reference energy disaggregation data set;home appliances;frequency measurement;smart meters domestic appliances karhunen loeve transforms maximum likelihood estimation;time domain analysis;uncorrelated spectral information appliances identification energy disaggregate nonintrusive load monitoring nilm smart grid smart meter;monitoring;home appliances databases frequency measurement power demand power measurement monitoring time domain analysis;power demand;power measurement;ta engineering general civil engineering general	A nonintrusive load monitoring (NILM) method for residential appliances based on uncorrelated spectral components of an active power consumption signal is presented. This method utilizes the Karhunen Loéve expansion to breakdown the active power signal into subspace components (SCs) so as to construct a unique information rich appliance signature. Unlike existing NILM techniques that rely on multiple measurements at high sampling rates, this method works effectively with a single active power measurement taken at a low sampling rate. After constructing the signature data base, SC level power conditions were introduced to reduce the number of possible appliance combinations prior to applying the maximum a posteriori estimation. Then, an appliances matching algorithm was presented to identify the turned-on appliance combination in a given time window. After identifying the turned-on appliance combination, an energy estimation algorithm was introduced to disaggregate the energy contribution of each individual appliance in that combination. The proposed NILM method was validated by using two public databases: 1) tracebase; and 2) reference energy disaggregation data set. The presented results demonstrate the ability of the proposed method to accurately identify and disaggregate individual energy contributions of turned-on appliance combinations in real households.	algorithm;database;energy level;fast software encryption;feature extraction;iteration;microsoft windows;real-time computing;residential gateway;sampling (signal processing);smart meter	Chinthaka Dinesh;Buddhika W. Nettasinghe;Roshan Indika Godaliyadda;Mervyn Parakrama B. Ekanayake;Janaka Ekanayake;Janaka V. Wijayakulasooriya	2016	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2484258	embedded system;electronic engineering;telecommunications;computer science;engineering	EDA	43.6783031928386	-0.444529467703487	176186
0240c681d68c10797fb3c32edc0d4c6c81b495bb	enhancing stereo signals with high-order ambisonics spatial information		There is a strong push towards the ultra-realistic presentation of multimedia contents made possible by the latest advances in computational and signal processing technologies. Three-dimensional sound presentation is necessary to convey a natural and rich multimedia experience. Promising ways to achieve this include the sound field reproduction technique known as high-order Ambisonics (HOA). While these advanced methods are now within the capabilities of consumer-level processing systems, their adoption is hindered by the lack of contents. Production and coding of the audio components in multimedia focus on traditional formats such as stereophonic sound. Mainstream audio codecs and media such as CDs or DVDs do not support advanced, rich contents such as HOA encodings. To ameliorate this problem and speed up the adoption of spatial sound technologies, this paper proposes a novel way to downmix HOA contents into a stereo signal. The resulting data can be distributed using conventional methods such as audio CDs or as the audio component of an internet video stream. The results can be listened to using legacy stereo reproduction systems. However, they include spatial information encoded as the inter-channel level and phase differences. The proposed method consists of a downmixing filterbank which independently modulate inter-channel differences at each frequency bin. The proposal is evaluated using simple test signals and found to outperform conventional methods such as matrixencoded surround and the Ambisonics UHJ format in terms of spatial resolution. The proposal can be coupled with a previously presented method to recover HOA signals from stereo recordings. The resulting system allows for the preservation of full-surround spatial information in ultra-realistic contents when they are transferred using a stereo stream. Simulation results show that a compatible decoder can accurately recover up to five HOA channels from a stereo signal (2nd order HOA data in the horizontal plane). key words: spatial sound, high-order Ambisonics, spatialization, surround, sound signal encoding	codec;filter bank;signal processing;simulation;streaming media;surround sound	Jorge Trevino;Shuichi Sakamoto;Junfeng Li;Yôiti Suzuki	2016	IEICE Transactions		computer vision	Graphics	46.39781409336149	-8.559325772287044	176358
da8398547600888cc0810ebfc688c4664b3b8a29	new predictor-corrector methods of second-order for solving nonlinear equations	second order;65h05;fuzzy number;regula falsi method;γ fuzzy number;41a25;nonlinear equation;predictor corrector methods;quadratic convergence;nonlinear equations;numerical experiment;iteration method	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;kerrison predictor;nonlinear system;predictor–corrector method;primary source	Kun Wang;Xinlong Feng	2011	Int. J. Comput. Math.	10.1080/00207160903443748	local convergence;mathematical optimization;mathematical analysis;discrete mathematics;nonlinear system;fuzzy number;mathematics;false position method;iterative method;rate of convergence;second-order logic;relaxation;algorithm;algebra	Robotics	49.56404334182353	-2.946661870101537	176434
142bb17bcf1a13903e9643b4fdac0a973f982713	low noise reversible mdct (rmdct) and its application in progressive-to-lossless embedded audio coding	traitement signal;evaluation performance;compresion con perdida;matrix lifting;haute performance;audio signal processing;codecs;performance evaluation;data compression;reversible mdct rmdct;lossy compression;quantization noise;implementation;evaluacion prestacion;transformation cosinus discrete;circuit sans perte;acoustic signal processing;data compression audio coding signal reconstruction codecs quantisation signal discrete cosine transforms matrix algebra fast fourier transforms;low noise reversible transform;matrix algebra;transformacion fourier rapida;reduccion ruido;fast fourier transform;quantisation signal;audio coding;low noise;factorization;reversible fft;integer transform;factorizacion;multiple factorization reversible rotation low noise reversible mdct rmdct progressive to lossless embedded audio coding signal reconstruction audio codec reversible modified discrete cosine transform quantization noise matrix lifting fast fourier transform lossy audio compression integer transform;traitement signal audio;discrete cosine transforms;reversible transform;signal processing;noise reduction;reduction bruit;factorisation;reversible fractional shifted fft;alto rendimiento;lossless circuit;fast fourier transforms;progressive to lossless embedded audio codec;multiple factorization reversible rotation;codec;audio coding codecs quantization discrete transforms discrete cosine transforms performance loss turning noise reduction fast fourier transforms audio compression;signal reconstruction;modified discrete cosine transform;traitement signal acoustique;compresion dato;codage audiofrequence;circuito sin perdida;implementacion;computational efficiency;reversible transform integer transform low noise reversible transform matrix lifting multiple factorization reversible rotation progressive to lossless embedded audio codec reversible fft reversible fractional shifted fft reversible mdct rmdct;transformation fourier rapide;procesamiento senal;high performance	A reversible transform converts an integer input to an integer output, while retaining the ability to reconstruct the exact input from the output sequence. It is one of the key components for lossless and progressive-to-lossless audio codecs. In this work, we investigate the desired characteristics of a high-performance reversible transform. Specifically, we show that the smaller the quantization noise of the reversible modified discrete cosine transform (RMDCT), the better the compression performance of the lossless and progressive-to-lossless codec that utilizes the transform. Armed with this knowledge, we develop a number of RMDCT solutions. The first RMDCT solution is implemented by turning every rotation module of a float MDCT (FMDCT) into a reversible rotation, which uses multiple factorizations to further reduce the quantization noise. The second and third solutions use the matrix lifting to implement a reversible fast Fourier transform (FFT) and a reversible fractional-shifted FFT, respectively, which are further combined with the reversible rotations to form the RMDCT. With the matrix lifting, we can design the RMDCT that has less quantization noise and can still be computed efficiently. A progressive-to-lossless embedded audio codec (PLEAC) employing the RMDCT is implemented with superior results for both lossless and lossy audio compression.	bitstream;codec;data compression;embedded system;fast fourier transform;lifting scheme;lossless compression;lossy compression;modified discrete cosine transform;quantization (signal processing);the matrix	Jin Li	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2005.845480	data compression;arithmetic;computer vision;fast fourier transform;speech recognition;computer science;signal processing;mathematics	Visualization	46.66350984805873	-9.294950367303924	176588
50451ddb5aa62c51827b4cba6964a8d23003902e	spectral methods for mesh processing and analysis		Spectral methods for mesh processing and analysis rely on the eigenvalues, eigenvectors, or eigenspace projections derived from appropriately defined mesh operators to carry out desired tasks. Early works in this area can be traced back to the seminal paper by Taubin in 1995, where spectral analysis of mesh geometry based on a combinatorial Laplacian aids our understanding of the low-pass filtering approach to mesh smoothing. Over the past ten years or so, the list of applications in the area of geometry processing which utilize the eigenstructures of a variety of mesh operators in different manners have been growing steadily. Many works presented so far draw parallels from developments in fields such as graph theory, computer vision, machine learning, graph drawing, numerical linear algebra, and high-performance computing. This state-of-the-art report aims to provide a comprehensive survey on the spectral approach, focusing on its power and versatility in solving geometry processing problems and attempting to bridge the gap between relevant research in computer graphics and other fields. Necessary theoretical background will be provided and existing works will be classified according to different criteria — the operators or eigenstructures employed, application domains, or the dimensionality of the spectral embeddings used — and described in adequate length. Finally, despite much empirical success, there still remain many open questions pertaining to the spectral approach, which we will discuss in the report as well.	application domain;computer graphics;computer vision;geometry processing;graph drawing;graph theory;laplacian matrix;low-pass filter;machine learning;norm (social);numerical analysis;numerical linear algebra;parallels desktop for mac;smoothing;spectral method;supercomputer	Hao Zhang;Oliver van Kaick;Ramsay Dyer	2007		10.2312/egst.20071052	simulation;computer science;theoretical computer science	Graphics	40.17865181371997	1.5803395368475013	176590
27e057e127f20b37b3d60c284096b75deb7d5992	a diffusion-based em algorithm for distributed estimation in unreliable sensor networks	distributed estimation;maximum likelihood;signal to noise ratio signal processing algorithms wireless sensor networks maximum likelihood estimation noise measurement;soft detection;expectation maximization;soft detection consensus averaging diffusion strategies distributed estimation expectation maximization maximum likelihood sensor networks;wireless sensor networks expectation maximisation algorithm numerical analysis telecommunication network reliability;sensor networks;cramer rao lower bound diffusion based em algorithm distributed estimation unreliable sensor networks snr high signal to noise ratio noisy observations best linear unbiased estimator data failure events optimal performance maximum likelihood framework expectation maximization algorithm statistical model iterative nature information propagation diffusion based distributed implementation numerical analysis;consensus averaging;diffusion strategies;article	We address the problem of distributed estimation of a parameter from a set of noisy observations collected by a sensor network, assuming that some sensors may be subject to data failures and report only noise. In such scenario, simple schemes such as the Best Linear Unbiased Estimator result in an error floor in moderate and high signal-to-noise ratio (SNR), whereas previously proposed methods based on hard decisions on data failure events degrade as the SNR decreases. Aiming at optimal performance within the whole range of SNRs, we adopt a Maximum Likelihood framework based on the Expectation-Maximization (EM) algorithm. The statistical model and the iterative nature of the EM method allow for a diffusion-based distributed implementation, whereby the information propagation is embedded in the iterative update of the parameters. Numerical examples show that the proposed algorithm practically attains the Cramer-Rao Lower Bound at all SNR values and compares favorably with other approaches.	data model;decibel;embedded system;error floor;expectation–maximization algorithm;iterative method;numerical method;sensor;signal-to-noise ratio;software propagation;statistical model	Silvana Silva Pereira;Roberto López-Valcarce;Alba Pagès-Zamora	2013	IEEE Signal Processing Letters	10.1109/LSP.2013.2260329	mathematical optimization;wireless sensor network;expectation–maximization algorithm;computer science;machine learning;brooks–iyengar algorithm;mathematics;maximum likelihood;maximum likelihood sequence estimation;estimation theory;statistics	EDA	52.85137449652455	3.991371868230183	176639
24f71e218c7f5a3fc7d8d665f9b35ef0fa977a74	indoor self-localization and orientation estimation of smartphones using acoustic signals		We propose a new acoustic self-localization and orientation estimation algorithm for smartphones networks composed of commercial off-the-shelf devices equipped with two microphones and a speaker. Each smartphone acts as an acoustic transceiver, which emits and receives acoustic signals. Node locations are found by combining estimates of the range and direction of arrival (DoA) between node pairs using a maximum likelihood (ML) estimator. A tailored optimization algorithm is proposed to simultaneously solve the DoA uncertainty problem that arises from the use of only 2 microphones per node and obtain the azimuthal orientation of each node without requiring an electronic compass.		Héctor A. Sánchez-Hevia;David Ayllón;Roberto Gil-Pita;Manuel Rosa-Zurera	2017	Wireless Communications and Mobile Computing	10.1155/2017/3534829	distributed computing;estimator;maximum likelihood;computer science;azimuth;embedded system;transceiver;direction of arrival;electronic engineering;compass	Mobile	50.544098068123006	4.175666890130278	176917
008bd43c98d9712bb5d3d34ca22dae983db010de	estimating the size of peer-to-peer networks using lambert's w function	ing inf 05 sistemi di elaborazione delle informazioni;inf 01 informatica	In this work, we address the problem of locally estimating the size of a Peerto-Peer (P2P) network using local information. We present a novel approach for estimating the size of a peer-to-peer (P2P) network, fitting the sum of new neighbors discovered at each iteration of a breadth-first search (BFS) with a logarithmic function, and then using Lambert’s W function to solve a root of a ln(n)+b−n = 0, where n is the network size. With rather little computation, we reach an estimation error of at most 10 percent, only allowing the BFS to iterate to the third level.	breadth-first search;computation;iteration;peer-to-peer	Javier Bustos-Jiménez;Nicolas Bersano;Satu Elisa Schaeffer;José M. Piquer;Alexandru Iosup;Augusto Ciuffoletti	2008		10.1007/978-0-387-09457-1_6	arithmetic;calculus;mathematics;algorithm	Web+IR	48.21674463898038	3.2453500144548855	177604
0121dafd767b2b8d78e58b297027c8609df8d4f2	robust distributed least-squares estimation in sensor networks with node failures	peer to peer computing convergence estimation limiting vectors ieee communications society nickel;convergence;nickel;limiting;ieee communications society;wireless sensor networks iterative methods telecommunication network topology;sensor network;network topology;iterative methods;vectors;estimation;network topology robust distributed least squares estimation sensor networks scalar target signal observation locality iterative distributed least squares algorithm sensor node failures centralized least squares estimate iterative exchange process limiting agreement value weight compensation step weight compensation procedure;least square;least squares estimate;sensor nodes;peer to peer computing;telecommunication network topology;wireless sensor networks	Algorithms are studied for distributed least-squares (DLS) estimation of a scalar target signal in sensor networks. Due to the observation locality and the limited sensing ability, the individual sensor estimates are far from being reliable. To obtain a more reliable estimate of the target signal, the sensors could collaborate by iteratively exchanging messages with their neighbors, to refine their local estimates over time. Such an iterative DLS algorithm is investigated in this paper with and without the consideration of node failures. In particular, without sensor node failures it is shown that every instantiation of the DLS algorithm converges, i.e., consensus is reached among the sensors, with the limiting agreement value being the centralized least-squares estimate. With node failures during the iterative exchange process, the convergence of the DLS algorithm is still guaranteed; however, an error exists between the limiting agreement value and the centralized least-squares estimate. In order to reduce this error, a modified DLS scheme, the M-DLS, is provided. The M-DLS algorithm involves an additional weight compensation step, in which a sensor performs a one-time weight compensation procedure whenever it detects the failure of a neighbor. Through analytical arguments and simulations, it is shown that the M-DLS algorithm leads to a smaller error than the DLS algorithm, where the magnitude of the improvement dependents on the network topology.	algorithm;centralized computing;converge;dls format;iterative method;least squares;locality of reference;network topology;sensor node;simulation;universal instantiation	Qing Zhou;Soummya Kar;Lauren M. Huie;H. Vincent Poor;Shuguang Cui	2011	2011 IEEE Global Telecommunications Conference - GLOBECOM 2011	10.1109/GLOCOM.2011.6133690	mathematical optimization;wireless sensor network;computer science;theoretical computer science;brooks–iyengar algorithm;distributed computing;computer network	Robotics	52.86485335334876	3.803084702520171	177631
13c97510756542e3d89d84b2c945a914503264ea	wideband powerline positioning for indoor localization	context awareness;context aware;location tracking;localization;fingerprinting	Fingerprinting techniques for indoor localization have been widely explored. A particular approach by Patel et al. suggested leveraging of the residential powerline as the signaling mechanism for a domestic location capability. In this paper, we critically examine that initial work, called powerline positioning (PLP). We find the proposed technique lacking in temporal stability, requiring frequent and undesired recalibration in some environments. We also determine that there is no a priori method to determine a pair of signaling frequencies that will reliably work in any space. We propose a wideband approach to PLP (WPLP) that injects up to 44 different frequencies into the powerline. We show that this WPLP approach improves upon overall positioning accuracy, demonstrates greatly improved temporal stability and has the added advantage of working in commercial indoor spaces.	elegant degradation;heart rate variability;mind;pl/p;radio fingerprinting;radio frequency;software deployment;transmitter;world-system	Erich P. Stuntebeck;Shwetak N. Patel;Thomas Robertson;Matthew S. Reynolds;Gregory D. Abowd	2008		10.1145/1409635.1409649	fingerprint;internationalization and localization;telecommunications;computer science;operating system	HCI	47.9054151008393	2.207355344061791	178158
1b0e9e7e295c63c68f1d37b69ac0c5fdffee192b	variable dimension spectral coding of speech at 2400 bps and below with phonetic classification	speech signal;phonetic classification;spectral quantization;perceptually important features;speech synthesis;local acoustic phonetic character;variable dimension spectral coding;variable rate;log spectrum;speech processing;fixed rate coding;1 44 kbit s;4 8 kbit s;speech coding;acoustic signal processing;spectrum;code standards;speech enhancement;bit rate;speech quality;spectral modeling;inmarsat m standard imbe coder;variable rate codes;speech coding speech enhancement bit rate code standards vector quantization vocoders speech processing space technology speech synthesis adaptation model;adaptation model;vector quantization;signal processing;federal standard 1016 celp coder;spectral analysis speech coding variable rate codes vocoders vector quantisation acoustic signal processing;vocoders;low bit rate enhanced multiband excitation;2400 bit s;noise shaping;4 15 kbit s;space technology;vector quantizer;multiband excitation vocoder;embe speech coder;spectral analysis;vector quantisation;variable rate coding;variable dimension vector quantization;4 15 kbit s variable dimension spectral coding speech coding phonetic classification low bit rate enhanced multiband excitation embe speech coder spectral quantization variable dimension vector quantization multiband excitation vocoder spectral modeling local acoustic phonetic character speech signal log spectrum perceptually important features fixed rate coding variable rate coding federal standard 1016 celp coder speech quality inmarsat m standard imbe coder 2400 bit s 1 44 kbit s 4 8 kbit s	The low bit rate enhanced multiband excitation or EMBE speech coder adds several important new features including phonetic classification and a naval spectral quantization technique called variable dimension vector quantization (VDVQ) to the basic multiband excitation vocoder. Phonetic classification allows the adaptation of spectral modeling and quantization to the local acoustic-phonetic character of the speech signal, enhancing quality and robustness. The VDVQ scheme quantizes the log-spectrum with relatively few bits while preserving perceptually important features. Both the fixed rate (2.4 kb/s) and the variable rate (1.44 kb/s average) implementations of EMBE deliver speech quality comparable to the 4.8 kb/s Federal Standard 1016 CELP coder and the 4.15 kb/s Inmarsat-M standard IMBE coder.		Amitava Das;Allen Gersho	1995		10.1109/ICASSP.1995.479636	spectrum;speech recognition;noise shaping;computer science;speech coding;signal processing;speech processing;space technology;speech synthesis;vector quantization	ML	48.097159107636244	-8.686033546527154	178188
6e94836bb51c0ca76fa96b56f750ab54f0c9f06b	bioem: gpu-accelerated computing of bayesian inference of electron microscopy images	software;paper;heterogeneous systems;bayesian inference;q bio bm;microscopy;gpu;biology;biomolecules;cuda;bayesian;natural sciences;nvidia geforce gtx titan;electron microscopy;heterogeneous;package;nvidia;openmp;physics comp ph;medicine;image analysis;tesla k20;mpi;tomography;dynamic	In cryo-electron microscopy (EM), molecular structures are determined from large numbers of projection images of individual particles. To harness the full power of this single-molecule information, we use the Bayesian inference of EM (BioEM) formalism. By ranking structural models using posterior probabilities calculated for individual images, BioEM in principle addresses the challenge of working with highly dynamic or heterogeneous systems not easily handled in traditional EM reconstruction. However, the calculation of these posteriors for large numbers of particles and models is computationally demanding. Here we present highly parallelized, GPU-accelerated computer software that performs this task efficiently. Our flexible formulation employs CUDA, OpenMP, and MPI parallelization combined with both CPU and GPU computing. The resulting BioEM software scales nearly ideally both on pure CPU and on CPU+GPU architectures, thus enabling Bayesian analysis of tens of thousands of images in a reasonable time. The general mathematical framework and robust algorithms are not limited to cryo-electron microscopy but can be generalized for electron tomography and other imaging experiments. ∗Corresponding author – E-mail address: Gerhard.Hummer@biophys.mpg.de Both authors contributed equally to the work. Preprint submitted to Computer Physics Communications September 22, 2016 ar X iv :1 60 9. 06 63 4v 1 [ qbi o. B M ] 2 1 Se p 20 16	algorithm;cuda;central processing unit;electron tomography;experiment;general-purpose computing on graphics processing units;graphics processing unit;iterative reconstruction;message passing interface;openmp;parallel computing;semantics (computer science)	Pilar Cossio;David Rohr;Fabio Baruffa;Markus Rampp;Volker Lindenstruth;Gerhard Hummer	2017	Computer Physics Communications	10.1016/j.cpc.2016.09.014	computational science;image analysis;bayesian probability;computer science;microscopy;message passing interface;theoretical computer science;tomography;biomolecule;package;bayesian inference;electron microscope;statistics;computer graphics (images)	ML	42.22304009398087	1.940045359030406	178429
4fc0e833cb68ed8bdf884361db96816e3aaa0d9e	a design of a cost-effective look-up table for rgb-to-rgbw conversion	interpolation;zirconium;acoustics;speech processing;speech;decision support systems;hafnium	RGBW domain is widely used to improve the brightness of display panels without their increasing power consumption. RGBW display systems use a look-up table (LUT) for fast RGB-to-RGBW conversion. However, the LUT is implemented by a large size memory and thereby incurring high hardware cost. To reduce the size of the LUT, data mapping in the LUT are sub-sampled, which results in large errors in data conversion. Based on the piecewise-linear characteristic in color change, the sub-sampled data are linearly interpolated. In addition, the interpolation performance is improved by utilizing distribution patterns of color components. Experimental results show that the average of the mean square errors by the proposed method is 21.72 when the size of the LUT decreases to 1/215 of the original LUT size.	linear interpolation;lookup table;mean squared error	Sunwoong Kim;Hyuk-Jae Lee	2016	2016 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2016.7803929	electronic engineering;computer hardware;interpolation;computer science;speech;theoretical computer science;zirconium;speech processing;hafnium	EDA	47.68510825069275	-6.5869551818979115	178964
09156a294c4c5cc4d1677dbb473f4de915170559	a scalable algorithm for radiative heat transfer using reverse monte carlo ray tracing	simulation science;titan;adaptive mesh refinement;radiation modelling;parallel;scalability;uintah	Radiative heat transfer is an important mechanism in a class of challenging engineering and research problems. A direct all-to-all treatment of these problems is prohibitively expensive on large core counts due to pervasive allto-all MPI communication. The massive heat transfer problem arising from the next generation of clean coal boilers being modeled by the Uintah framework has radiation as a dominant heat transfer mode. Reverse Monte Carlo ray tracing (RMCRT) can be used to solve for the radiative-flux divergence while accounting for the effects of participating media. The ray tracing approach used here replicates the geometry of the boiler on a multi-core node and then uses an all-to-all communication phase to distribute the results globally. The cost of this all-to-all is reduced by using an adaptive mesh approach in which a fine mesh is only used locally, and a coarse mesh is used elsewhere. A model for communication and computation complexity is used to predict performance of this new method. We show this model is consistent with observed results and demonstrate excellent strong scaling to 262K cores on the DOE Titan system on problem sizes that were previously computationally intractable.	adaptive multi-rate audio codec;algorithm;analysis of algorithms;broadcasting (networking);computation;computational complexity theory;computational science;graphics processing unit;image scaling;message passing interface;molecular dynamics;monte carlo method;multi-core processor;pervasive informatics;ray tracing (graphics);refinement (computing);reverse monte carlo;scalability;simulation;solver;titan;turbulence	Alan Humphrey;Todd Harman;Martin Berzins;Phillip Smith	2015		10.1007/978-3-319-20119-1_16	mathematical optimization;parallel computing;scalability;simulation;adaptive mesh refinement;computer science;theoretical computer science;parallel;titan	HPC	42.33537771245639	1.5436880034029012	179213
f8352d454d76db36844585b4e59442c40015ff78	impact of high-end receivers in a peer-to-peer cooperative localization system	gnss positioning;radio receivers;sensor fusion cooperative systems kalman filters peer to peer computing radio receivers satellite navigation;localization;kalman filters;data exchange;high end receiver;kalman filter;data fusion;local system;jamming;gnss receiver;cooperative;distance measurement;localization gnss receiver peer to peer kalman filter cooperative network;gnss data;cooperative systems;estimation;satellite navigation;position measurement;robustness;peer to peer cooperative localization system;sensor fusion;peer to peer computing;hybrid data exchange;peer to peer;integrated circuits;global navigation satellite system high end receiver peer to peer cooperative localization system gnss positioning gnss data hybrid data exchange kalman filter data fusion engine;data fusion engine;network;integrated circuits estimation jamming robustness distance measurement position measurement;global navigation satellite system	This paper introduces the concept of peer-to-peer cooperation as an aiding technique in GNSS positioning and addresses the impact of the presence of professional receivers in the network. The impact of their higher accuracy is evaluated for the cases of both GNSS-data only and hybrid data exchange. Kalman Filters are considered as the data fusion engine.	global positioning system;kalman filter;peer-to-peer;satellite navigation	Lina Deambrogio;Claudio Palestini;Francesco Bastia;Giulio Gabelli;Giovanni Emanuele Corazza;Jaron Samson	2010	2010 Ubiquitous Positioning Indoor Navigation and Location Based Service	10.1109/UPINLBS.2010.5654054	simulation;geography;telecommunications;remote sensing	Mobile	50.4575649177689	0.3235736415993677	179609
e012e5c1e29de5178fd3b02ee3073f310c3cf293	fusion of information from biased sensor data by particle filtering	kalman filters estimation standards target tracking atmospheric measurements particle measurements noise;atmospheric measurements;standards;particle measurements;kalman filters;wireless sensor networks kalman filters particle filtering numerical methods sensor fusion target tracking;estimation;target tracking;bearings only measurements information fusion particle filtering biased sensor data sensor network nuisance parameters estimation problem kalman filtering target tracking;noise	In this paper we address the problem of fusing information from biased sensor-data collected by a sensor network. Under the assumption that the biases of the sensors are nuisance parameters, we propose an algorithm that marginalizes them out from the estimation problem. The algorithm uses particle filtering to obtain the unknown states of the system and Kalman filtering for marginalization of the biases. We apply the proposed algorithm to the problem of target tracking using bearings-only measurements acquired by more than one sensor. The advantage of the considered method over standard particle filtering which does not assume the presence of biases is illustrated through computer simulations.	algorithm;computer simulation;kalman filter;particle filter;sensor	Mónica F. Bugallo;Ting Lu;Petar M. Djuric	2007	2007 15th European Signal Processing Conference		control engineering;computer vision;soft sensor;engineering;control theory	Robotics	53.441137186772075	3.574407802223886	179999
37cce1363916fe0402a3a69044e1adbea58753ea	split vector quantization of the lpc parameters using weighted lattice structure			crystal structure;vector quantization	K. W. Law;C. F. Chan	1993			artificial intelligence;linde–buzo–gray algorithm;pattern recognition;quantization (signal processing);vector quantization;crystal structure;computer science	Vision	47.11908694597837	-8.515453962174286	180363
8411b039daa325b43bdbd1a34167c1f43ff11fb0	electromagnetic simulator of rotating machine blades for noncontact sensor dynamic testing		Electromagnetic simulator of rotating machine blades was invented and developed in the Institute of Thermomechanics, Academy of Sciences of the Czech Republic. The device is intended for testing of dynamic properties of noncontact electromagnetic sensors (induction, magnetoresistive, and Hall effect). The device operates on the principle of generation of a shifting magnetic field simulating magnetic conditions by the passages of ferromagnetic machine blades. The device allows for great savings by eliminating the need for expensive test equipment. The device was granted a patent by the Industrial Property Office CR.	academy;built-in test equipment;dynamic testing;hall effect;mathematical induction;sensor;simulation	Pavel Procahazka	2018	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2018.2809140	simulation;hall effect;industrial property;magnetic field;magnetoresistance;dynamic testing;mathematics;electromagnetics;vibration;electrical conductor	Robotics	52.545271196954765	-9.671048547500662	180553
0fbea874dbb90c13c30ca2954b8bf962466de9ea	design and development of rolling bearing vibration signal analysis system	mechanical engineering computing;vibrations;design and development;matlab rolling bearing system development data acquisition lab view;signal analysis;vibration signal processing methods rolling bearing vibration signal analysis system labview matlab;noise reduction vibrations databases demodulation band pass filters rolling bearings feature extraction;rolling bearings;signal processing;vibrations mechanical engineering computing rolling bearings signal processing;system development;data acquisition	Taking the respective advantages of LabView and Matlab, an on-line vibration signal analysis system of rolling bearing was designed and developed. First, system scheme design was introduced. Then each module of the system was discussed. Finally, system application examples were given, which verified the convenience and effectiveness of this system.	labview;matlab;online and offline;signal processing	Wensheng Su;Fengtao Wang	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6023648	structural engineering;control engineering;computer vision;computer science;engineering;vibration;signal processing;data acquisition;engineering drawing;physics	Robotics	47.03329977853093	-2.111058754657476	180750
371dab8b35a89659318fd2adbd8b4b4fe237315a	sparse target counting and localization in sensor networks based on compressive sensing	matching pursuit algorithms;compressive sensing sensor networks target counting target localization;compressed sensing;probability;sensors;sensor localization;signal detection;greedy algorithms;argon;sparse target counting;sensor network;wireless sensor network;target counting;iterative methods;signal recovery algorithms;monitoring;sensor networks;sensor placement;compressive sensing;target localization;matching pursuit algorithms compressed sensing sparse matrices algorithm design and analysis argon sensors monitoring;matching pursuit;greedy matching pursuit algorithm;wireless sensor networks greedy algorithms iterative methods probability sensor placement signal detection;algorithm design;probability sparse target counting sensor localization compressive sensing wireless sensor networks cs greedy matching pursuit algorithm signal recovery algorithms gmp;sparse matrices;gmp;algorithm design and analysis;wireless sensor networks;cs;signal recovery	In this paper, we propose a novel compressive sensing (CS) based approach for sparse target counting and positioning in wireless sensor networks. While this is not the first work on applying CS to count and localize targets, it is the first to rigorously justify the validity of the problem formulation. Moreover, we propose a novel greedy matching pursuit algorithm (GMP) that complements the well-known signal recovery algorithms in CS theory and prove that GMP can accurately recover a sparse signal with a high probability. We also propose a framework for counting and positioning targets from multiple categories, a novel problem that has never been addressed before. Finally, we perform a comprehensive set of simulations whose results demonstrate the superiority of our approach over the existing CS and non-CS based techniques.	compressed sensing;detection theory;emoticon;gnu multiple precision arithmetic library;greedy algorithm;internationalization and localization;matching pursuit;openmp;overhead (computing);simulation;sparse matrix;whole earth 'lectronic link	Bowu Zhang;Xiuzhen Cheng;Nan Zhang;Yong Cui;Yingshu Li;Qilian Liang	2011	2011 Proceedings IEEE INFOCOM	10.1109/INFCOM.2011.5935041	mathematical optimization;wireless sensor network;computer science;theoretical computer science;machine learning	Vision	52.223650176719985	2.629372129707701	180914
a6c92102f041387eaa8ecbb94d941db8aa93363e	consensus-based joint target tracking and sensor localization		In this paper, consensus-based Kalman filtering is extended to deal with the problem of joint target tracking and sensor self-localization in a distributed wireless sensor network. The average weighted Kullback-Leibler divergence, which is a function of the unknown drift parameters, is employed as the cost to measure the discrepancy between the fused posterior distribution and the local distribution at each sensor. Further, a reasonable approximation of the cost is proposed and an online technique is introduced to minimize the approximated cost function with respect to the drift parameters stored in each node. The remarkable features of the proposed algorithm are that it needs no additional data exchanges, slightly increased memory space and computational load comparable to the standard consensus-based Kalman filter. Finally, the effectiveness of the proposed algorithm is demonstrated through simulation experiments on both a tree network and a network with cycles as well as for both linear and nonlinear sensors.	approximation algorithm;computation;computational complexity theory;dspace;discrepancy function;experiment;kalman filter;kullback–leibler divergence;loss function;nonlinear system;sensor;simulation;simultaneous localization and mapping;tree network	Lin Gao;Giorgio Battistelli;Luigi Chisci;Ping Wei	2017	2017 20th International Conference on Information Fusion (Fusion)	10.23919/ICIF.2017.8009847	computer science;wireless sensor network;control theory;machine learning;mathematical optimization;artificial intelligence;tree network;probability density function;kalman filter;network topology;signal processing;brooks–iyengar algorithm;posterior probability	Robotics	53.42285094270238	3.6390914667667706	180985
0c1703aa68de1b2e4d8dd6e290f6cc8dd43e31ba	mbitp: a map based indoor target prediction in smartphone		This paper presents MBITP, a novel method for an indoor target prediction through the sensor data which may be the Big Data. To predict target, a probability model is presented. In addition, a real-time error correction technique based on map feature is designed to enhance the estimation accuracy. Based on it, we propose an effective prediction algorithm. The practice evaluation shows that the method introduced in this paper has an acceptable performance in real-time target prediction.	smartphone	Bowen Xu;Jinbao Li	2015		10.1007/978-3-662-46248-5_28	machine learning;error detection and correction;distributed computing;computer science;big data;artificial intelligence	HCI	51.69701598383396	0.44701403348896673	181188
41c6496cfc7e3f0ad7981e89ed747d21f964e129	robust model predictive control for multiple time delay systems with polytopic uncertainty description	time delay system;description systeme;system description;uncertain systems;state feedback;espace etat;control modelo predicativo;robust control;delay system;retardo multiple;journal;model predictive control;identificacion sistema;politope;systeme incertain;lyapunov method;systeme a retard;system identification;state space method;methode espace etat;commande mpc;state space;multiple delay;control robusta;retard multiple;descripcion sistema;temps retard;delay time;sistema con retardo;espacio estado;commande robuste;sistema incierto;tiempo retardo;uncertain system;identification systeme;time delay systems;metodo espacio estado;polytope	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	analysis of algorithms;broadcast delay;francis;linear algebra;nl (complexity);primary source;simulation;state space	Baocang Ding	2010	Int. J. Control	10.1080/00207179.2010.498058	robust control;control engineering;polytope;system identification;state space;control theory;mathematics;model predictive control;algorithm	Robotics	50.87160574641738	-3.40089877785243	181620
539363476f364933d3dce1319a9aff0d92fe41a7	impact of the number of beacons in pso-based auto-localization in uwb networks	least square ls method;particle swarm optimization pso;two stage maximum likelihood tsml algorithms;auto localization;ultra wide band uwb signaling	In this paper, we focus on auto-localization of nodes in a static wireless network, under the assumption of known position of a few initial nodes, denoted as “beacons”. Assuming that Ultra Wide Band (UWB) signals are used for inter-node communications, we analyze the impact of the number of beacons on the location accuracy. Three different approaches to localization are considered, namely: the Two-Stage Maximum-Likelihood (TSML) method ; the Plane Intersection (PI) method, and Particle Swarming Optimization (PSO). Simulation results show that PSO allows to obtain accurate postion estimates with a small number of beacons, making it an attractive choice to implement effective localization algorithm.	algorithm;linear equation;mathematical optimization;nonlinear system;optimization problem;particle swarm optimization;simulation	Stefania Monica;Gianluigi Ferrari	2013		10.1007/978-3-642-37192-9_5	mathematical optimization;simulation;telecommunications;mathematics	Metrics	51.2717249977082	4.066668029798765	181882
c5f9a610aefe79b48797a88a054ea47dae8475e4	development of a 4.8-9.6 kbps relp vocoder	low data rate;baseband;vocoders baseband linear predictive coding space technology speech coding speech enhancement noise robustness acoustic waves humans telecommunications;speech coding;speech enhancement;noise robustness;linear predictive;linear predictive coding;vocoders;humans;space technology;acoustic waves;harmonic generation;telecommunications	II. BACKGROUND A new 'eiu,Lon o the Re,.s,Ldtwl Excied Lyieta)L Pnod t-ü'e. (RELPJ uoaciden. ha been imweated. The objecLüie ha been to 'ieduce tke dcta Jwe 'eqwLeed on good qaaLij 4p000h ;to 4.8 !zbpi. Re4aLt have £ncLLcwted that Lt po&Lbfe to /teniove the hoaene cwotentLy o.s-ocLat-ed w-W Iow data cvte PELP peeth. Ve'etopmen.t o a pLtch pec(ct'e. AVPCM Aee-Lduol erteode-'t and pteVin-Lna'uj Ito4LLUI, on new hansnonLo genenatLon technLquee cvte ciL4awsed. Taped demokut'icJcion3 w-Lfbe pfwjed at the con tce,kence.	data rate units;naruto shippuden: clash of ninja revolution 3;residual-excited linear prediction;vocoder	Mark Dankberg;David Y. Wong	1979		10.1109/ICASSP.1979.1170817	voice activity detection;acoustic wave;linear predictive coding;speech recognition;computer science;speech coding;baseband;space technology	Robotics	48.161533363141416	-7.543857052664311	181901
61dd5d9d6e326c6746a437df038a92a7c9afb087	distributed informative sensor determination via sparsity-cognizant matrix decomposition	wireless sensor networks covariance matrices distributed processing iterative methods matrix decomposition optimisation signal processing;optimisation;distributed processing;data model parameters distributed informative sensor determination sparsity cognizant matrix decomposition sparse matrix decomposition sensor network informative data informative sensors sensor data covariance matrix hidden sparse factors norm one regularization optimization framework distributed estimation coordinate descent iterations distributed source informative sensor;polynomials;iterative methods;sparsity;vectors;matrix decomposition;covariance matrices;signal processing;optimization;distributed processing sparsity matrix decomposition;sparse matrices;wireless sensor networks;noise;covariance matrix;sparse matrices covariance matrix matrix decomposition noise vectors polynomials optimization	A novel framework is developed that decomposes a matrix into sparse factors. The sparse matrix decomposition scheme is utilized to determine in a distributed fashion which sensors, in a sensor network, acquire informative data about phenomena of interest. A setting, where the sensor data covariance matrix consists of hidden sparse factors, is considered. The proposed sparsity-cognizant algorithm is used to determine the support of the sparse covariance factors, and subsequently identify the informative sensors. A centralized formulation is given first that relies on norm-one regularization. Then, using the notion of missing covariance entries, we obtain an optimization framework that allows distributed estimation of the unknown sparse factors. The corresponding optimization problems are tackled via simple coordinate descent iterations. Different from existing approaches, the novel utilization of covariance sparsity allows distributed source-informative sensor identification, without the need of knowing the data model parameters.	algorithm;centralized computing;coordinate descent;data model;information;iteration;manifold regularization;mathematical optimization;matrix regularization;sensor;sparse matrix	Ioannis D. Schizas	2012	2012 IEEE Statistical Signal Processing Workshop (SSP)	10.1109/SSP.2012.6319720	mathematical optimization;sparse matrix;machine learning;pattern recognition;sparse approximation;mathematics	ML	52.058250112436696	2.0476283141586116	182361
3d5bc59e8827acb960c0059fe7ee67dbb84e851e	quantization based watermarking approach with gain attack recovery	watermarking;awgn;quantization signal;quantisation signal awgn image watermarking;error analysis;indexes;awgn gain attack recovery quantization index modulation based watermarking approach watermarking channel capacity initial data loss during quantization probability density functions natural grayscale images additive white gaussian noise;robustness;watermarking quantization signal indexes robustness awgn error analysis modulation;modulation	"""A new Quantization Index Modulation-based watermarking approach is proposed in this paper. With the aim to increase capacity of the watermarking channel with noise we propose Initial Data Loss during quantization for some samples in pre-defined positions. Also, the proposed approach exploits a new form of distribution of quantized samples where samples that interpret """"0"""" and """"1"""" have differently shaped probability density functions. This creates a distinctive feature which is expressed numerically using one out of two proposed criteria. The criteria are utilized by a procedure for recovery after possible Gain Attack. Several state of the art quantization-based watermarking methods were used for comparison on a set of natural grayscale images. The superiority of the proposed method has been confirmed for different types of popular attacks."""	additive white gaussian noise;digital watermarking;distortion;grayscale;high-level programming language;modulation;numerical analysis;quantization (signal processing);rdm;software release life cycle	Yevhen Zolotavkin;Martti Juhola	2014	2014 International Conference on Digital Image Computing: Techniques and Applications (DICTA)	10.1109/DICTA.2014.7008125	database index;additive white gaussian noise;speech recognition;quantization;digital watermarking;computer science;theoretical computer science;mathematics;robustness;modulation	Vision	41.882278238823666	-9.527797910943764	182504
8fe1e619a92fd0a0e3213713eaf5493035c97131	hierarchical multi-channel audio coding based on time-domain linear prediction	hierarchical;decoding;time domain analysis;audio coding;data rate hierarchical multichannel audio coding scheme time domain linear prediction decoding complexity single channel down mixing process multichannel input signals prediction filter coefficients prediction errors prediction gain single channel communication systems algorithmic delay transmission quality;linear prediction;decoding gain delay audio coding quantization codecs;hierarchical multi channel coding linear prediction;multi channel coding;time domain analysis audio coding decoding filtering theory;filtering theory	A novel hierarchical multi-channel coding scheme is proposed which exhibits a significant decrease in decoding complexity compared to earlier proposals. The new coding scheme is based on a single channel down mixing process followed by predictions of the multichannel input signals. Symmetries in the prediction filter coefficients and the prediction errors allow for a reduced number of channels which need to be transmitted. A detailed evaluation of the achievable prediction gain and the impact of quantization on the perceived quality leads to insights into the appropriate choice of system parameters. Besides the attractive feature of being usable as a hierarchic extension to existing single channel communication systems and its very low additional algorithmic delay, the transmission quality of the proposed design also scales very well with the available data rate.	channel capacity;coefficient;data rate units;forward error correction;quantization (signal processing)	Magnus Schaefer;Peter Vary	2012	2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)		sub-band coding;electronic engineering;speech recognition;shannon–fano coding;computer science;theoretical computer science;speech coding;code-excited linear prediction	HPC	47.69271413156961	-8.6472216223882	182940
67cdd3cf3edeba53a58c52e96d8ec354e7fc5b80	time-recursive architectures and wavelet transform	discrete wavelet transforms;kernel;time recursive architecture;discrete wavelet transform;concurrent computing;sonar applications;data compression;kernel functions;transform domain adaptive filtering;discrete time systems;video compression;kernel function;discrete time;real time data;wavelet transforms;computer architecture;adaptive filters;wavelet transform;linear operator;parallel architectures;discrete transforms;discrete wavelet transform real time data compression transform domain adaptive filtering parallel time recursive computation linear operators kernel functions shift property time recursive architecture;linear operators;real time data compression;shift property;wavelet transforms discrete wavelet transforms computer architecture data compression discrete transforms adaptive filters sonar applications video compression concurrent computing kernel;adaptive filter;parallel time recursive computation;wavelet transforms adaptive filters data compression discrete time systems parallel architectures real time systems;real time systems	The time-recursive computation has been proved as a particularly useful tool in real-time data compression and in transform domain adaptive filtering, with applications in the areas of audio, radar, sonar and video. Unlike the FFT based ones, the time-recursive architectures require only local communication. Also, they are modular and regular, thus they are very appropriate for VLSI implementation and they allow high degree of parallelism. In t.his paper, we propose an architectural framework for parallel time-recursive computation. We consider a class of linear operators that consists of the discrete time, time invariant, compactly supported, but otherwise arbitrary kernel functions. We define a shift p rop erty of the linear operators and reveal its relation with the time-recursive implementation. We demonstrate the potential of the proposed framework by designing a time-recursive architecture for the Discrete Wavelet Transform. 1 I N T R O D U C T I O N In many signal processing applications the key computation consists of a mapping operator [ho h1 ... hnr-11 : z(.) -+ X ( ) , which operates on the semi-infinite sequence of scalar data z(.) and produces the sequence X ( . ) as follows: N-I X ( t ) = h,z(t + n N + I) , t = 0 , 1 , . . . . (1) n=O A time-recursive implementation of a mapping operator [hn hl . . . hN-11 is the one that. is based on an update computation of the type X ( t + 1) = U ( X ( t ) , z ( f + 1) ) . For example, if we have [h, = 1, n = 0 , 1 , . . . , N 11, then X ( t ) will be the sum of the last N values in the input stream. The recursive algorithmic implementation of this operator will be simply the computation X ( t + 1) = X ( t ) + ~ ( t + 1 ) ~ ( t N + 1). The time-recursive computation has been proved as a particularly useful tool in real-time data compression [l, 2,3] and in transform domain adaptive filtering [4, 5 , 61, with applications in the areas of audio, radar, sonar and video. There is a common infrastructure among t,he mapping o p erators that are involved in these diverse applications. The unifying feature is a shift property we discuss in the following Section. We also show how this pr0pert.y dictates t,he time-recursive architectural design. In Sect,ion 3, we design a time-recursive archit.ecture for the Discret.e Wa.velet. Transform (DWT). We conclude wit,h Sect,ion 4. 2 A R C H I T E C T U R A L FR.AMEWORK We can specify a mapping opemtor [ / i o h l . . . I t x i ] with a function f(.), for which t.he values at. t.he poiiit,s 0, I , . . . , N 1 are the prescribed coefficient,s: h,, = f (n ) , n = 0, 1 , . . . , N 1 . In t,lie sequel. we will use the term kernel function or simply kernel for t.his funct.ioii f ( .). Furthermore, we will call kerncl CJYOU~J a vect,or of kernel functions f(.) = [fo(.) f l ( . ) . . ' f . z r l ( . ) l r . Shift Property: A kernel grotrp f ( .) sati.$fies the .diift property (SP), i j it satisfie.5 the (ninti.i.i.) difierence eqiicitioii f(n 1) = Rf ( , I . ) , ) i = I . 2 . . . . . N , ( 2 ) with specified final condition f(LV), iohcrr-c. R i.5 a conafont matrix of site M x A l . Lemma 1 A recursive implementation of (I, kernel grotip f(.) is feusible zj th is kernel grotcp satisfie-s the shift I J ~ O ~ erty. Proof: (2) gives: AI-I f p ( ' i I , 1) = c r , , s , c I t ) .	adaptive filter;aortic valve insufficiency;architecture as topic;audio media;coefficient;computation (action);data compression;degree of parallelism;discrete wavelet transform;enterprise architecture framework;fast fourier transform;ions;iontophoresis;kernel;liter per hour;parallel computing;radar;real-time clock;real-time data;recursion;semiconductor industry;signal processing;software architecture;sonar;stream (computing);time-invariant system;very-large-scale integration	Emmanuel John;Baras;Jaideep Ray	1993		10.1109/ICASSP.1993.319151	data compression;kernel;adaptive filter;wavelet;mathematical optimization;discrete mathematics;s transform;harmonic wavelet transform;concurrent computing;second-generation wavelet transform;continuous wavelet transform;computer science;theoretical computer science;mathematics;wavelet packet decomposition;stationary wavelet transform;discrete wavelet transform;statistics;wavelet transform	Logic	46.09538611688208	-6.719510609901418	183026
91c0f2e684b07e72c48a4f85afbe4802c334524c	soft reconstruction of speech in the presence of noise and packet loss	desciframiento;canal con ruido;speech soft reconstruction;data transmission;multirate system;code lineaire;multiple description coding mds;erasure channel;degradation;is 641 vocoders;mobile radiocommunication;algorithm complexity;error concealment;code excited linear prediction;decodage;decoding;code excited linear prediction speech soft reconstruction packet loss decoding process speech spectrum reconstruction gsm adaptive multirate is 641 vocoders intraframe residual redundancy interframe residual redundancy source decoding packetization strategy signal domain classification;telecommunication sans fil;redundancia;transition probability;quantifier;complejidad algoritmo;correction erreur;linear predictive coding lpc;packet loss;degradacion;sistema gsm;speech spectrum reconstruction;codage source;vocodeur;line spectral frequency lsf;noisy channel;joint source channel coding jsc;interframe residual redundancy;speech enhancement redundancy decoding speech processing bandwidth degradation propagation losses bit rate mobile communication channel coding;vocodigicador;speech coding;spectrum;packet switching;canal avec bruit;probabilistic approach;conmutacion por paquete;estimacion a priori;perdida transmision;radiocommunication service mobile;speech error concealment;global system for mobile communications adaptive multirate gsm amr;systeme multicadence;perte transmission;residual redundancies;packet loss concealment plc;a priori estimation;codage predictif;joint source channel coding;linear predictive coding;gsm system;markov model;redundancy;complexite algorithme;packet loss concealment;enfoque probabilista;telecomunicacion sin hilo;approche probabiliste;error correction;linear code;transmission donnee;quantificateur;signal classification;vocoders;prediccion lineal;probabilidad transicion;codificacion predictiva;transmission loss;estimation a priori;markov models;classification signal;multiple description coding;intraframe residual redundancy;codificacion fuente canal	Exploiting the residual redundancy in a source coder output stream during the decoding process has been proven to be a bandwidth efficient way to combat the noisy channel degradations. In this paper, we consider soft reconstruction of speech spectrum, in GSM adaptive multirate and IS-641 vocoders, transmitted over a channel disturbed with noise and/or packet loss. Several schemes are presented which exploit different levels of intraframe and interframe residual redundancy for improved source decoding at the receiver. A packetization strategy is proposed which is matched to the presented error concealment units. For decoders that exploit the residual redundancy, extensive complexity has been a serious concern, especially as the quantizer bitrate increases . In this paper, a novel method is presented to construct reduced complexity algorithms. The proposed methodology is based on the classification of the signal domain and efficient approximation of the residual redundancy or the a priori transition probabilities. The presented schemes provide high quality error concealment solutions for code excited linear prediction (CELP) coders	adaptive multi-rate audio codec;algorithm;approximation;code-excited linear prediction;complexity;decoding methods;display resolution;error concealment;first-order predicate;intra-frame coding;lsf;left recursion;markov chain;markov model;multiple description coding;network packet;noisy-channel coding theorem;numerical method;quantization (signal processing);recursion (computer science);redundancy (engineering);triple modular redundancy;vocoder	Farshad Lahouti;Amir K. Khandani	2007	IEEE Transactions on Audio, Speech, and Language Processing	10.1109/TASL.2006.876874	speech recognition;telecommunications;computer science;markov model;statistics	Vision	48.86266231125843	-8.733185132731533	183155
df9e1282be053b76813a3ee04ee65819204b98e1	shape optimization of multi-chamber side inlet/outlet mufflers with reverse-flow ducts by simulated algorithm	exhaust systems;ducts;fan noise elimination;reverse flow muffler;acoustical performance;simulated annealing algorithm;reverse flow ducts;pipe flow;simulated annealing;acoustical mechanism;shape optimization;shape;multichamber side inlet outlet mufflers;optimizer;pure tones shape optimization multichamber side inlet outlet mufflers reverse flow ducts acoustical mechanism optimizer acoustical performance simulated annealing algorithm metal softening process imitation fan noise elimination;exhaust systems ducts space technology constraint optimization simulated annealing shape control computational modeling acoustical engineering mechanical engineering performance analysis;simulated annealing algorithm shape optimization reverse flow muffler;metal softening process imitation;shape control;pure tones;electron tubes;simulated annealing pipe flow shape control silencers;silencers;noise	To proficiently enhance the acoustical performance within a constrained space, the selection of an appropriate acoustical mechanism and optimizer becomes crucial. A multi-chamber side muffler hybridized with reverse-flow ducts which can visibly increase the acoustical performance is rarely addressed; therefore, the main purpose of this paper is to numerically analyze and maximize the acoustical performance of this muffler within a limited space. In this paper, a simulated annealing (SA) algorithm, a robust scheme in searching for the global optimum by imitating the softening process of metal, has been used during the optimization process. A noise elimination of a fan noise at pure tones is introduced. The optimal result in eliminating pure tone noise reveals that the STL is efficiently and precisely eliminated at the targeted frequency.	algorithm;global optimization;mathematical optimization;numerical analysis;shadow volume;shape optimization;simulated annealing;softening	Min-Chie Chiu;Ying-Chun Chang	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.34	structural engineering;acoustics;engineering;engineering drawing	DB	52.51001722756655	-7.613276094142188	183197
01f002498e29e24d47681040fadbba54cf99491a	an analysis of seydel' test function methods for nonlinear power flow equations	systeme equation;matrice jacobi;fonction test seydel;critical point;central electrica;bifurcation;point critique;performance index;bifurcacion;jacobi matrix;nonlinear systems;electric power system;sistema ecuacion;centrale electrique;power system;matriz jacobi;equation system;indexation;g 1 5;systeme non lineaire;choice of parameter;turning point;seydel test function;electrical power systems;electric power plant;fonction test;punto critico;power flow;voltage collapse;test function;nonlinear system;sistema no lineal;turning points;choix parametre;index performance;non linear system;test functions;reactive power	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	distribution (mathematics);francis;nonlinear system;primary source	Ke Chen;Anwar Hussein;Haibin Wan	2001	Int. J. Comput. Math.	10.1080/00207160108805123	nonlinear system;calculus;control theory;mathematics;electric power system;algorithm	Robotics	49.931697558219604	-3.0373201962137624	183452
18fe1b9e3e5f54ec065fbaa6ca4b765535578432	a robust and invisible watermarking of 3d triangle meshes	filigranage numerique;digital watermarking;modelizacion;simplification;ruido aleatorio;centro gravitacional;steganographie;multimedia;centre gravite;three dimensions;information security;bruit aleatoire;digital watermark;center of mass;generation maille;securite informatique;polygone;intelligence artificielle;similitude;polygon;computer security;modelisation;random noise;similarity transformation;steganography;esteganografia;polygonal meshes;seguridad informatica;filigrana digital;similarity;simplificacion;poligono;artificial intelligence;inteligencia artificial;similitud;mesh generation;modeling;triangle mesh	With the rapid development of computer multimedia, how to protect digital products from being copied, pirated and juggled has been an urgent issue in the information security field. Digital watermarking is a new method to solve the referred problems. This paper proposes a digital watermarking algorithm for three-dimension (3D) mesh models. The watermark is embedded into the host with modifying the lengths between the vertices and the centroid of models. The embedded watermark is invisible and can withstand the common attacks such as polygon mesh simplifications, addition of random noise, and similarity transforms. The validity of proposed algorithm has been confirmed with experiments.	robustness (computer science)	Wang Liu;Sheng-He Sun	2005		10.1007/11554028_123	simulation;digital watermarking;computer science;artificial intelligence;information security;theoretical computer science;polygon;mathematics;computer security;algorithm	HCI	40.12639282831883	-8.741442656379778	184218
e90e2d9d6d0922218f6b0cc27547ecd3b9d7251f	intelligibility evaluation of 4-5 kbps celp and mbe vocoders: the hermes program experiment			code-excited linear prediction;data rate units;intelligibility (philosophy);vocoder	Bruno Wery;Herman J. M. Steeneken	1993			code-excited linear prediction;speech recognition;computer science;intelligibility (communication)	HCI	47.91587919761979	-8.143577305723138	184338
41c1846ddc0ecf9a93d00abe7e4f2671dbd148fd	understanding perceptual distortion in mpeg scalable audio coding	artefacto;estensibilidad;norme telecommunication;sound quality;perceptual distortion;calidad sonora;evaluation performance;quality metric;audio coding bit rate performance evaluation testing time frequency analysis arithmetic mpeg 4 standard humans spectrogram signal analysis;low bit rate;audio signal processing;qualite sonore;egalisation;performance evaluation;arithmetic coding;frequency analysis;objective quality assessment;spectrum analysis;analyse spectre;analyse frequence;implementation;analisis espectro;aliasing;evaluacion prestacion;signal analysis;time frequency;compresion senal;analisis objetivos;equalization;analisis de senal;acoustic signal processing;code standards;scalable coding audio analysis audio coding audio quality metrics objective quality assessment perceptual distortion;compression signal;artefact;arithmetic code;velocidad de bit debil;equalisers;algorithme;asignacion bit;human subjects;allocation bit;codigo aritmetico;algorithm;distortion;audio coding;quality assessment;evaluation subjective;arithmetic codes;igualacion;traitement signal audio;telecommunication standards;signal compression;controle qualite;time frequency analysis audio coding code standards arithmetic codes equalisers distortion;traitement signal acoustique;extensibilite;scalability;code arithmetique;bit allocation;codage audiofrequence;analisis sonido;sound analysis;implementacion;quality control;subjective evaluation;audio analysis;energy equalization quality metric perceptual distortion mpeg compressed scalable audio audio coding bit slice scalable arithmetic coding motion picture experts group mpeg 4 reference software human subjective testing comparison category rating approach midrange tonal signal reng bifrequency probing time frequency decomposition suboptimal bit allocation;analyse objective;time frequency analysis;debit binaire faible;analyse signal;objective analysis;analyse son;control calidad;audio quality metrics;scalable coding;repliegue espectro	In this paper, we study coding artifacts in MPEG-compressed scalable audio. Specifically, we consider the MPEG advanced audio coder (AAC) using bit slice scalable arithmetic coding (BSAC) as implemented in the MPEG-4 reference software. First we perform human subjective testing using the comparison category rating (CCR) approach, quantitatively comparing the performance of scalable BSAC with the nonscaled TwinVQ and AAC algorithms. This testing indicates that scalable BSAC performs very poorly relative to TwinVQ at the lowest bitrate considered (16 kb/s) largely because of an annoying and seemingly random mid-range tonal signal that is superimposed onto the desired output. In order to better understand and quantify the distortion introduced into compressed audio at low bit rates, we apply two analysis techniques: Reng bifrequency probing and time-frequency decomposition. Using Reng probing, we conclude that aliasing is most likely not the cause of the annoying tonal signal; instead, time-frequency or spectrogram analysis indicates that its cause is most likely suboptimal bit allocation. Finally, we describe the energy equalization quality metric (EEQM) for predicting the relative perceptual performance of the different coding algorithms and compare its predictive ability with that of ITU Recommendation ITU-R BS.1387-1.	advanced audio coding;algorithm;aliasing;arithmetic coding;bit slicing;coefficient;data compression;data rate units;distortion;elegant degradation;encoder;image scaling;modified discrete cosine transform;moving picture experts group;scalability;spectrogram	Charles D. Creusere	2005	IEEE Transactions on Speech and Audio Processing	10.1109/TSA.2005.845817	speech recognition;time–frequency analysis;telecommunications;computer science;signal processing;statistics	SE	47.45116359352674	-9.549531302747482	184393
023d0f89ecc6aab9069a537aefab081a7a6e53f2	on an improved fpga implementation of cnn-based gabor-type filters	convergence;video streaming;gabor filters;cellular neural nets;reconfigurable architectures cellular neural networks cnns field programmable gate arrays fpgas gabor filters real time systems;finite impulse response filter field programmable gate arrays bandwidth computer architecture equations gabor filters convergence;field programmable gate arrays;frequency 60 hz improved fpga implementation cellular neural network cnn based 2d gabor type filter field programmable gate array implementation realtime applications video streams full high definition hd pixel rate convergence rate analysis fir;video streaming cellular neural nets convergence field programmable gate arrays gabor filters real time systems;real time systems	In this brief, the details of the architecture of a previously introduced improved field-programmable gate array implementation of the cellular neural network (CNN)-based 2-D Gabor-type filter are given, and the implementation results are discussed. The proposed architecture is suitable for real-time applications with high pixel rates. The prototype is capable of processing video streams up to a pixel rate of 373.2 megapixels per second (MP/s), including full-high-definition (HD) 1080p@60 (1080 × 1920 resolution, 60-Hz frame rate, and 124.4-MP/s visible pixel rate). This brief also contains convergence rate analysis results, along with some discussions on FIR and CNN-based implementation methods.	artificial neural network;cellular neural network;fastest;field-programmability;field-programmable gate array;finite impulse response;fixed-point arithmetic;gabor filter;generalized timing formula;hdmi;maximum throughput scheduling;pixel;place and route;prototype;random-access memory;rate of convergence;real-time clock;real-time computing;routing;streaming media	Evren Cesur;Nerhun Yildiz;Vedat Tavsanoglu	2012	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2012.2218471	embedded system;electronic engineering;real-time computing;convergence;computer science;field-programmable gate array	Visualization	41.68301870322446	-2.9781248135114002	184440
a810eb6f3f706b31b04a7064eee02b4ff31da36d	an soc combining a 132db qvga pixel array and a 32b dsp/mcu processor for vision applications	vision system;graphical processing unit;front end;radiation detectors;32b processor;image sensors;data representation;system on a chip;computer vision;soc qvga pixel array dsp mcu processor image contrast machine vision intra scene dynamic range optical front end data representation single chip vision system image acquisition decision making system on chip time domain logarithmic encoding variable reference voltage 32b processor graphical processing unit sram;chip;image contrast;visualization;intra scene dynamic range;image acquisition;system on chip;machine vision;pixel;single chip vision system;dynamic range;graphic processing unit;digital signal processing machine vision dynamic range digital signal processing chips lighting image analysis performance analysis decision making system on a chip time domain analysis;soc;time domain;digital signal processing chips;system on chip computer vision digital signal processing chips image sensors sram chips;sram;lighting;mcu processor;variable reference voltage;time domain logarithmic encoding;encoding;qvga pixel array;optical front end;dsp;sram chips	Key elements for machine vision are the intra-scene dynamic range of the optical front-end, and a data representation that is as independent as possible from the illumination level. Furthermore, combining an optical front-end and a processor on the same chip enables a single-chip vision system to perform image acquisition, analysis and decision-making. Approaches that enable high dynamic range are logarithmic imagers [1] and lin-log imagers [2], but they suffer from poor fixed-pattern noise (FPN) performance [1,2] and non-uniform transfer functions [2] due to the combination of linear and logarithmic domains. While multiple-exposure imagers [3] solve the FPN problem, they require post-processing to combine several frame captures. Finally the dynamic range of time-domain logarithmic imagers with fixed reference voltages [4] is limited by the maximum allowable exposure time.	data (computing);fixed-pattern noise;graphics display resolution;high dynamic range;local interconnect network;machine vision;pixel;transfer function;video post-processing	Pierre-François Ruedi;Pascal Heim;Steve Gyger;François Kaess;Claude Arm;Ricardo Caseiro;Jean-Luc Nagel;Silvio Todeschini	2009	2009 IEEE International Solid-State Circuits Conference - Digest of Technical Papers	10.1109/ISSCC.2009.4977300	system on a chip;embedded system;computer vision;electronic engineering;machine vision;computer hardware;computer science	Vision	42.98143167202181	-4.409845974564435	184447
b25f38998c0a23f214f2953086338b2a2b5cf8e9	error concealment based on mmse estimation for multimedia wireless and ip applications	estimation theory;stochastic modeling;erroneous channel output;natural integration;wireless channels;error concealment;least mean squares methods;decoding;hidden markov model;speech coding;channel estimation;integration;distributed speech recognition error concealment multimedia wireless network ip network erroneous channel output minimum mean square error estimation mmse transmission channel hidden markov model stochastic modeling natural integration wireless channel packet channel fec code;wireless channel;wireless communication;hidden markov models;forward error correction;estimation;yttrium;mmse;transmission channel;packet channel;multimedia communication;distributed speech recognition;fec code;speech recognition;ip network;ip networks;minimum mean square error estimation;hidden markov models speech recognition degradation decoding channel coding forward error correction testing ip networks mean square error methods estimation error;wireless channels estimation theory forward error correction hidden markov models integration ip networks least mean squares methods multimedia communication speech coding speech recognition;multimedia wireless network	This paper presents a framework for the error concealment of multimedia signals transmitted over wireless and IP networks. This framework is based on two elements. First, the replacements for the erroneous channel outputs are obtained from a minimum mean square error (MMSE) estimation which takes into account both the source and all the available information from the transmission channel. Then, hidden Markov models (HMMs) provide the required stochastic modeling which allows the estimation. This modeling makes it possible a natural integration of the two types of information (source and available data from the channel). This framework is developed for both, wireless channels with errors at the bit level and packet channels degraded by packet loss. In the first case, a very high performance can be obtained even without the need of soft decision or any type of channel SNR estimation. In the second case, the lack of channel outputs during packet losses must be compensated either by enhancing the source model (increasing the model order) or by introducing media-specific FEC codes which may substitute the missing packets. This second option has yielded higher performance than the first one.	ansi escape code;bit error rate;bit-level parallelism;channel (communications);elegant degradation;error concealment;forward error correction;hidden markov model;internet protocol suite;lossy compression;markov chain;mean squared error;network packet;open-source software;signal-to-noise ratio;speech recognition;stochastic modelling (insurance);transmitter	Antonio M. Peinado;Ángel M. Gómez;Victoria E. Sánchez	2008	2008 IEEE 19th International Symposium on Personal, Indoor and Mobile Radio Communications	10.1109/PIMRC.2008.4699936	estimation;speech recognition;telecommunications;computer science;yttrium;speech coding;forward error correction;estimation theory;stochastic;hidden markov model;wireless;statistics	Mobile	49.39048063800605	-8.726631809129032	184752
bc858cf51b0d7a820b2fa0d920509017ba89eec5	security in the speech cryptosystem based on blind sources separation	blind sources separation bss;time frequency domain;cryptanalysis;sparsity;cryptography;quantized levels	In this paper, an appropriate selection for the key is investigated to enhance the security level of the speech cryptosystem based on blind sources separation. In fact, if an appropriate key is not selected, the cryptosystem may be attacked and therefore each confidential signal can be recovered only from the encrypted ones. Two important conditions which are studied in this paper are the number of quantized levels for a digital key and also non-sparsity in time-frequency domain. In the case of the first condition, simulation results show that with smaller coefficient for the confidential signal in comparison with the key, the number of quantized levels for the key should be more to guarantee the security. In the case of the second condition, an algorithm is proposed to recover the confidential signal only from the encrypted signal when the key is sparse in time-frequency domain.	algorithm;coefficient;confidentiality;cryptosystem;digital signature;encryption;simulation;sparse matrix;time–frequency analysis	Ali Sadr;Raziyeh Sadat Okhovat	2014	Multimedia Tools and Applications	10.1007/s11042-014-2147-3	cryptanalysis;telecommunications;cryptography;theoretical computer science;threshold cryptosystem;computer security;statistics	Security	41.4767227913849	-9.05493756431282	185068
9f1467b1b5c8ff7ff17c18b3ebb2086f03eb88f5	vectorization of generation of fractals from z <-- z2 + c on ibm 3090/180vf	technique vectorisation;computer graphics;remplissage;filling;fractal;grafico computadora;infographie;vectorization technique;relleno	Abstract   Algebraic fractals generated from the self-squared transformation function  z  ←  z  2  +  c , where  z  and  c  are complex quantities, have been discussed extensively in the literature. The process of generating these fractal images, being iterative in nature, is computationally intensive. In this paper we propose and study three vectorization techniques for generating algebraic fractals from  z  ←  z  2  +  c , namely, use of long vectors, short vectors, and short vectors with replenishment. The speedups obtained by vectorization of all these techniques on IBM 3090-180VF, which has a vector facility, are presented. It is observed that the technique of using short vectors with replenishment is the best.	automatic vectorization;fractal	Virendrakumar C. Bhavsar;Uday G. Gujar;Nagarjuna Vangala	1993	Computers & Graphics	10.1016/0097-8493(93)90101-E	fractal;computer science;theoretical computer science;mathematics;geometry;computer graphics;algorithm;computer graphics (images)	NLP	44.652501250730914	0.7270376616243693	185246
14bd3d85d77ba778e2af8d116d75f229f5f33566	dropping convexity for faster semi-definite optimization		We study the minimization of a convex function f(X) over the set of n × n positive semi-definite matrices, but when the problem is recast as minU g(U) := f(UU >), with U ∈ Rn×r and r ≤ n. We study the performance of gradient descent on g—which we refer to as Factored Gradient Descent (Fgd)—under standard assumptions on the original function f . We provide a rule for selecting the step size and, with this choice, show that the local convergence rate of Fgd mirrors that of standard gradient descent on the original f : i.e., after k steps, the error is O(1/k) for smooth f , and exponentially small in k when f is (restricted) strongly convex. In addition, we provide a procedure to initialize Fgd for (restricted) strongly convex objectives and when one only has access to f via a first-order oracle; for several problem instances, such proper initialization leads to global convergence guarantees. Fgd and similar procedures are widely used in practice for problems that can be posed as matrix factorization. To the best of our knowledge, this is the first paper to provide precise convergence rate guarantees for general convex functions under standard convex assumptions.	convex function;convex optimization;first-order reduction;gradient descent;local convergence;rate of convergence;semiconductor industry	Srinadh Bhojanapalli;Anastasios Kyrillidis;Sujay Sanghavi	2016			mathematical optimization;combinatorics;mathematics;algorithm;statistics	ML	50.8756160786165	-0.7586115397054688	185390
654670ae9edc47c5edfaf1b97b73d6f57807bb2b	a novel quantization watermarking scheme by modulating the normalized correlation	watermarking;quantization;frequency modulation;dither modulation;bit error rate;vectors bit error rate watermarking robustness quantization frequency modulation;quantization based watermarking;quantisation signal;valumetric scaling;vectors;spread transform dither modulation quantization watermarking scheme modulated normalized correlation watermark embedding host vector random vector embedding distortion valumetric scaling;robustness;watermarking modulation quantisation signal;normalized correlation;valumetric scaling quantization based watermarking dither modulation normalized correlation;modulation	This paper presents a novel quantization based watermarking scheme. Watermark embedding is performed through modulating the normalized correlation between the host vector and a random vector with dither modulation. The watermarked signal is derived to provide the modulated normalized correlation in the sense of minimizing the embedding distortion. The proposed scheme is theoretically invariant to valumetric scaling and can resist stronger noise than the well-known spread transform dither modulation. Numerical simulations on real images show that it achieves the good imperceptibility and strong robustness against a wide range of attacks.	digital watermarking;distortion;dither;image scaling;modulation;numerical linear algebra;quantization (signal processing);simulation;whole earth 'lectronic link	Xinshan Zhu;Shuoling Peng	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288241	frequency modulation;bit error rate;quantization;telecommunications;digital watermarking;computer science;theoretical computer science;control theory;mathematics;robustness;modulation	Vision	41.83615164911089	-9.33051433047116	185818
8f742f61076afc8e837e87859871eedfc5c523f9	design of endoscopic capsule with multiple cameras	image coding;clocks;mcec prototype cameras wireless capsule endoscopy endoscopic capsule design master slave architecture bus architecture four level clock management architecture gastrointestinal tract smart image capture strategy movement sensitive control camera selection data transfer bandwidth power consumption low complexity image compressor endoscopic capsule prototype image capture strategy;wireless communication;smart image capture capsule endoscope image compression multiple cameras;ash;power demand;clocks cameras wireless communication image coding ash wireless sensor networks power demand;wireless sensor networks;cameras;medical image processing biomedical optical imaging cameras endoscopes image capture image sequences	In order to reduce the miss rate of the wireless capsule endoscopy, in this paper, we propose a new system of the endoscopic capsule with multiple cameras. A master-slave architecture, including an efficient bus architecture and a four level clock management architecture, is applied for the Multiple Cameras Endoscopic Capsule (MCEC). For covering more area of the gastrointestinal tract wall with low power, multiple cameras with a smart image capture strategy, including movement sensitive control and camera selection, are used in the MCEC. To reduce the data transfer bandwidth and power consumption to prolong the MCEC's working life, a low complexity image compressor with PSNR 40.7 dB and compression rate 86% is implemented. A chipset is designed and implemented for the MCEC and a six cameras endoscopic capsule prototype is implemented by using the chipset. With the smart image capture strategy, the coverage rate of the MCEC prototype can achieve 98% and its power consumption is only about 7.1 mW.	capsule endoscopy;chipset;compression;embedded system;embedding;gastrointestinal tract structure;peak signal-to-noise ratio;prototype;tract (literature);urinary tract infection	Yingke Gu;Xiang Xie;Guolin Li;Tianjia Sun;Dan Wang;Zheng Yin;Pengfei Zhang;Zhihua Wang	2015	IEEE Transactions on Biomedical Circuits and Systems	10.1109/TBCAS.2014.2359012	embedded system;computer vision;simulation;wireless sensor network;computer science;engineering;wireless	Mobile	44.59812714101155	-7.353010165223412	187305
9c5a0f782ce8288ea113c7634702cfdc16b3f6da	crn-based design methodology for synchronous sequential logic		With the aid of a storage-release mechanism named key-keysmith, an implementation approach based on chemical reaction networks (CRNs) for synchronous sequential logic is proposed. This design approach, which stores logic information in keysmith and releases it through key, primarily focuses on the underlying state transitions behind the required logic rather than the electronic circuit representation. Therefore, it can be uniformly and easily employed to implement any synchronous sequential logic with molecular reactions. Theoretical analysis and numerical simulations have demonstrated the robustness and universality of the proposed approach.	chemical reaction network theory;computer simulation;electronic circuit;numerical analysis;sequential logic;universal turing machine	Zhiwei Zhong;Lulu Ge;Ziyuan Shen;Xiaohu You;Chuan Zhang	2017	2017 IEEE International Workshop on Signal Processing Systems (SiPS)	10.1109/SiPS.2017.8109979	real-time computing;theoretical computer science;robustness (computer science);electronic circuit;sequential logic;design methods;computer science;logic gate	EDA	40.01515553447938	-0.11643689573856784	187864
7be1124584e9cfc45c42753a7d6cfb2b6d5a38c6	distributed bearing estimation technique using diffusion particle swarm optimisation algorithm	cramer rao lower bounds;distributed bearing estimation;dpso;cramer rao lower bounds distributed bearing estimation diffusion particle swarm optimisation algorithm maximum likelihood estimation ml estimation dpso communication overhead multiple signal classification;maximum likelihood estimation;signal classification maximum likelihood estimation particle swarm optimisation;multiple signal classification;communication overhead;signal classification;diffusion particle swarm optimisation algorithm;particle swarm optimisation;ml estimation	Bearing estimation is a well-studied problem and maximum likelihood (ML) estimation provides the best solution in terms of performance. The difficulty with ML is the multi-modal nature of the likelihood cost function. Recently, the biologically inspired particle swarm optimisation (PSO) technique has been shown to provide a good solution to ML bearing estimation as it alleviates the effects of multi-modality. In this study, the ML bearing estimation in a distributed sensor network is addressed, where each sensor node has access only to data from its neighbours. Diffusion particle swarm optimisation (DPSO) is proposed to optimise the ML function in this context. During the optimisation process each associated node shares its best estimates of the source bearings with its neighbours. As each node only communicates its best estimates and its own data with its neighbours, the communication overhead is less than the existing centralised PSO method. Diffusion learning ensures robustness to changes in network topology. Simulation results compare the performance of DPSO, centralised PSO, the benchmark centralised MUltiple SIgnal Classification bearing estimation algorithm and the appropriate Cramer–Rao lower bounds. As might be expected, there is some degradation in performance of the DPSO with respect to centralised PSO.	algorithm;benchmark (computing);centralisation;elegant degradation;loss function;mathematical optimization;modal logic;network topology;overhead (computing);particle swarm optimization;sensor node;simulation	Trilochan Panigrahi;Ganapati Panda;Bernard Mulgrew	2012	IET Wireless Sensor Systems	10.1049/iet-wss.2011.0107	mathematical optimization;engineering;machine learning;statistics	Metrics	53.109366769816596	3.9317261458700363	188138
1f6b5f7c362f5f770458a80535231bfbb7c6d285	meap: approximate optimal estimate extraction for the smc-phd filter	particle filter multi target tracking phd filter;clutter;atmospheric measurements;particle measurements;noise measurement;target tracking monte carlo methods particle filtering numerical methods probability;radio frequency;atmospheric measurements particle measurements correlation target tracking clutter radio frequency noise measurement;correlation;target tracking;iterative clustering computation approximate optimal estimate extraction smc phd filter mee multitarget tracking systems sequential monte carlo probability hypothesis density filter parallel single estimate extraction problems expected a posteriori estimator multieap estimator meap estimator	Multi-estimate extraction (MEE), also referred to as displaying tracks, lies at the core of any multi-target tracking systems, but remains a challenge for the sequential Monte Carlo implementation of the probability hypothesis density (SMC-PHD) filter. In this paper, we recall decision and association techniques to distinguish real measurements of targets from clutter and to associate particles to measurements. The MEE problem is then formulated as a family of parallel single-estimate extraction problems, where the expected a posteriori (EAP) estimator can be employed, namely the multi-EAP (MEAP) estimator. The MEAP estimator is free of iterative clustering computation, computes fast and yields accurate and reliable estimates. Classical simulation scenarios are employed to demonstrate the superiority of the MEAP estimator over existing methods in terms of fast processing speed and best estimation accuracy.	association rule learning;cluster analysis;clutter;computation;computer simulation;correspondence problem;iterative method;mobile enterprise application platform;monte carlo method;sentence extraction;simulation;tracking system	Tiancheng Li;Juan Manuel Corchado;Jesús Caja García;Javier Bajo	2016	2016 19th International Conference on Information Fusion (FUSION)		econometrics;mathematical optimization;computer science;statistics	Robotics	53.0832527749442	2.5795286426857014	188191
546f5b4c8b01c26a6571b2c890b254337fab6a5d	speech coding in mpeg-4	embedded coding;code excited linear prediction;speech coding;audio coding;object oriented	While previous MPEG Audio standards mainly were focused on the representation of audio signals close to or equal to CD quality, the new MPEG-4 Audio standard extends the range of applicability towards significantly lower bit rates. Furthermore it offers extended functionalities for the representation of natural and even synthetic audio signals in an object oriented fashion. This paper gives a brief overview on the complete audio part of the MPEG-4 standard and more detailed information on its parts related to speech coding.	speech coding	Bernd Edler	1999	I. J. Speech Technology	10.1007/BF02108645	sub-band coding;adaptive multi-rate audio codec;g.729;audio mining;extended adaptive multi-rate – wideband;linear predictive coding;speech recognition;mpeg-4 part 3;aes11;computer science;speech coding;acoustic model;multimedia;object-oriented programming;mpeg-4;code-excited linear prediction	NLP	47.58190141873966	-8.462481955448798	188298
0e5028eebc1d76a7319c84ae439f5d4b26da3f5f	stochastic inverse problems for growth models	stochastic processes inverse problems economic forecasting calculus uncertainty stochastic systems macroeconomics infinite horizon cybernetics usa councils;optimal solution;stochastic variational calculus stochastic inverse problems dynamic stochastic general equilibrium models macroeconomics business cycle analysis stochastic optimal capital growth finite horizon infinite horizon;dsge model;general equilibrium;variational techniques;capital accumulation;communication conference;stochastic optimization;standard model;inverse problem;macroeconomics;nonlinear dynamics;infinite horizon;business cycle;inverse problems stochastic calculus of variations hjb equation stochastic growth model;stochastic programming;stochastic calculus of variations;variational techniques macroeconomics stochastic programming;hjb equation;stochastic growth model;growth model;inverse problems	Modern macroeconomics is built on the foundation of nonlinear dynamic stochastic general equilibrium (DSGE) models. In particular, the stochastic growth model is one of the most widely used models in all economics, and is the standard model for business cycle analysis. After reviewing some classical results on the existence of optimal solutions to stochastic calculus of variational problems in finite and infinite horizon, we show the connexions between those kind of problems and some classical stochastic optimal capital growth. Finally, we find some first results on the indeterminacy of capital accumulation path with uncertainty, which generalize the ones obtained by Boldrin and Montrucchio [4].	calculus of variations;indeterminacy in concurrent computation;nonlinear system;population dynamics;tree accumulation	Hycham Basta	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346297	stochastic programming;mathematical optimization;continuous-time stochastic process;inverse problem;stochastic modelling;stochastic optimization;mathematical economics	Robotics	40.15293467874842	4.025954651895812	188541
0ec9c05a0b53ca7426d783c3d300c8c8191ea7de	a comparative analysis of image steganography based on dct algorithm and steganography tool to hide nuclear reactors confidential information		Steganography is the practice of concealing the communication existence by hiding the traveled message in cover media. This paper aims to study Discrete Cosine Transform (DCT) based steganography Using DC components for hiding secret bits sequentially in Least significant Bits (LSBs) (1-LSB & 2-LSB). Likewise, using low and middle frequencies to analyze their performance using PSNR (Peak Signal to Noise Ratio) and MSE (Mean Square Error). The findings indicate that the middle frequency has the larger hiding capacity and relatively better PSNR and MSE. Hence, a proposed steganographic tool based on DCT is implemented to hide confidential information about a nuclear reactor, using the sequential embedding method in the middle frequency. The findings indicate that the proposed tool supplies a relatively high embedding capacity with no visual distortion in the resultant image, whereas, enhance the security and maintains the correctness of the hidden data.	algorithm;confidentiality;discrete cosine transform;qualitative comparative analysis;steganography tools	Sahar A. El-Rahman	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2016.09.001	steganography tools;telecommunications;theoretical computer science;mathematics;computer security	Logic	40.36622657948085	-9.437865289091526	189052
4d6a05e3e3118cceb615d2ac54ee42be2ff12ef4	aor type iterations for solving preconditioned linear systems	linear system;l matrix;preconditioned linear system;aor method;iteration method	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;iteration;linear system;preconditioner;primary source	Ting-Zhu Huang;Guang-hui Cheng;David J. Evans;Xiao-yu Cheng	2005	Int. J. Comput. Math.	10.1080/00207160500112886	mathematical optimization;mathematical analysis;control theory;mathematics;iterative method;linear system;algebra	Robotics	49.548979512736715	-2.9715228460730003	189288
bf7ea393cbcc831d2f7ef28cc0028b3de3e73d89	synthetic aperture radar processing with gpgpu	new technology;paper;frequency domain analysis;synthetic aperture radar processing;general purpose graphics processing units synthetic aperture radar processing gpgpu focusing algorithm;tesla c1060;cuda;computer architecture;gpgpu;signal processing;nvidia;synthetic aperture radar radar signal processing spaceborne radar focusing military computing monitoring computer architecture arithmetic concurrent computing radar imaging;general purpose graphics processing units;radar detection;focusing algorithm;synthetic aperture radar parallel processing radar detection radar signal processing;signal processing algorithms;radar signal processing;parallel processing;synthetic aperture radar	This article focuses on methodologies with recurrent use to code examples that try to couple with the flow of the main steps of the SAR processing. The possibility to be comprehensive was prevented by the wide scenario of variations of the focusing algorithm as well as the spread of applications. The reader should look at this work as a sample of possibilities offered by this new technology and a collection of suggestions and considerations that may guide to new applications and horizons.	algorithm;dhrystone;general-purpose computing on graphics processing units;recurrent neural network	Maurizio di Bisceglie;Michele Di Santo;Carmela Galdi;Riccardo Lanari;Nadia Ranaldo	2010	IEEE Signal Processing Magazine	10.1109/MSP.2009.935383	parallel processing;computer vision;synthetic aperture radar;computer science;signal processing;frequency domain;general-purpose computing on graphics processing units;computer graphics (images)	Visualization	43.88238762921584	-3.443974624446869	189433
58df640dde17f96c63d825edcb4b938313b20421	a histogram-based cascade detector for radio tomographic localization	radio equipment;wireless sensor networks computational complexity feature extraction object detection radio direction finding radio equipment tomography;radio direction finding;wireless sensor networks receivers signal processing;computational complexity;feature extraction;single link experiment histogram based cascade detector radio tomographic localization rtl object position estimation received signal strength rss wireless sensor network wsn electronic device surveillance rescue operation smart building histogram based target feature detection strategy computational complexity;tomography;wireless sensor networks;object detection	Radio tomographic localization (RTL) is an emerging technology for estimating the position of objects by analyzing received signal strength (RSS) variation in wireless sensor networks (WSNs). This method can localize targets which do not need to carry any electronic devices or tags, so that it is of great importance in applications such as surveillance, rescue operations and smart-buildings. This paper introduces a fast and effective RTL method. In this method, we propose a histogram-based target feature and a cascaded detection strategy. This method can localize an unknown number of objects with high accuracy in different environments, and the computational complexity is low enough to be used for real-time systems. First, we present a series of single-link experiments to demonstrate the proposed target feature. Then a cascaded detection process is introduced to locate an unknown number of targets while reducing much computation. To evaluate the proposed RTL method, experiments including both outdoor and indoor environment are conducted and the performance is carefully demonstrated.	computation;computational complexity theory;experiment;rss;real-time clock;real-time computing	Yang Li;YuQian Pan;DongWei Bai;Hang Liu;Bo Yang	2013	2013 16th International Symposium on Wireless Personal Multimedia Communications (WPMC)		computer vision;wireless sensor network;telecommunications;feature extraction;computer science;key distribution in wireless sensor networks;tomography;computational complexity theory	Mobile	52.35824834544539	2.3455576154346596	189466
63ead8f7307ba624e219b23b42a7025a1f0cfc88	distributed node-specific direction-of-arrival estimation in wireless acoustic sensor networks	adaptive estimation;computational complexity;direction-of-arrival estimation;least squares approximations;microphone arrays;noise abatement;signal classification;vectors;wireless sensor networks;danse algorithm;doa estimation algorithm;ls method;music algorithm;wasn;computational complexity;distributed adaptive node-specific signal estimation algorithm;distributed node-specific direction-of-arrival estimation;distributed noise reduction algorithm;exhaustive search elimination;least-square method;linear microphone array;multiple signal classification algorithm;single common target speech source;steering vector estimation;wireless acoustic sensor network;direction-of-arrival estimation;distributed estimation;wireless sensor networks	In this paper, we study the effect of collaboration between nodes for direction of arrival (DOA) estimation in a full connected wireless acoustic sensor network (WASN) where the position of the nodes is unknown. Each node is equipped with a linear microphone array which defines a node-specific DOA with respect to a single common target speech source. We assume that the DOA estimation algorithm is operated in conjunction with a distributed noise reduction algorithm, referred to as the distributed adaptive node-specific signal estimation (DANSE) algorithm. To avoid additional data exchange between the nodes, the goal is to exploit the shared signals used in the DANSE algorithm to also improve the node-specific DOA estimation. The DOA estimation is based on the multiple signal classification (MUSIC) algorithm (if sufficient computing power is available), or a least-squares (LS) method based on a locally estimated steering vector which allows to eliminate the exhaustive search in MUSIC and results in a significantly lower computational complexity. Simulation results demonstrate that collaboration between nodes improves the performance of the DOA estimation compared to the case where the nodes operate individually, i.e. do not collaborate.	acoustic cryptanalysis;algorithm;approximation;brute-force search;centralized computing;computational complexity theory;direction of arrival;kernel density estimation;least squares;music (algorithm);microphone;noise reduction;simulation	Amin Hassani;Alexander Bertrand;Marc Moonen	2013	21st European Signal Processing Conference (EUSIPCO 2013)		electronic engineering;real-time computing;speech recognition;engineering	Robotics	50.92173441013	4.0723531882955	190319
5d407d547e1859dc067fbcb2a984aafe379d5994	watermark detection after quanization attacks	additive white gaussian noise;additive noise;maximum like lihood;image watermarking	The embedding of additive noise sequences is often used to hide information in digital audio, image or video documents. However, the embedded information might be impaired by involuntary or malicious “attacks.” This paper shows that quantization attacks cannot be described appropriately by an additive white Gaussian noise (AWGN) channel. The robustness of additive watermarks against quantization depends strongly on the distribution of the host signal. Common compression schemes decompose a signal into sub-signals (e.g., frequency coefficients) and then adapt the quantization to the characteristics of the subsignals. This has to be considered during watermark detection. A maximum likelihood (ML) detector that can be adapted to watermark sub-signals with different robustness is developed. The performance of this detector is investigated for the case of image watermark detection after JPEG compression.	additive white gaussian noise;best, worst and average case;coefficient;digital watermarking;embedded system;experiment;jpeg;norm (social);portable document format;quantization (signal processing);utility functions on indivisible goods	Joachim J. Eggers;Bernd Girod	1999		10.1007/10719724_13	additive white gaussian noise;computer science;pattern recognition;statistics	Vision	41.79284450494605	-9.455790637364352	190785
15483ea714be079e666c7869c465b8bfdc079875	sistema embebido para la detección de luz láser empleando el soft-core nios ii		A CCD or CMOS linear sensor it ́s an essential component in various applications of engineering and consume. In this work we will present the first stage of the design and development of an embedded system for monitoring the angular distribution of the intensity of a laser light. It is presented the purpose of developing this work and it is shown the first results of the system, which makes use of a linear vision sensor CCD with 3,648 pixels, this is controlled by the softcore Nios II from Altera. For the design and implementation it was used the software Quartus II and the FPGA Cyclone IV both from Altera. Only the 26% of the logic elements and 4 of the 132 embedded multipliers (3%) of the FPGA were used.	altera quartus;angularjs;cmos;charge-coupled device;cyclone;embedded system;field-programmable gate array;lagrange multiplier;linear algebra;nios embedded processor;pixel	Julio C. Sosa;Iván Dominguez-Lopez;Adrián L. García-García;J. D. Oscar Barceinas-Sánchez;Anuar Jassen	2015	Research in Computing Science		nios ii;embedded system;pixel;field-programmable gate array;software;laser;cmos;computer science	EDA	41.81600139291302	-3.8279679162530935	190802
aebea784364297d47a39eb77b6f311acd52ce0df	consensus-based sequential estimation of process parameters via industrial wireless sensor networks †	co-design;consensus-based sequential estimation;industrial wireless sensor networks	Process parameter estimation, to a large extent, determines the industrial production quality. However, limited sensors can be deployed in a traditional wired manner, which results in poor process parameter estimation in hostile environments. Industrial wireless sensor networks (IWSNs) are techniques that enrich sampling points by flexible sensor deployment and then purify the target by collaborative signal denoising. In this paper, the process industry scenario is concerned, where the workpiece is transferred on the belt and the parameter estimate is required before entering into the next process stage. To this end, a consensus-based sequential estimation (CSE) framework is proposed which utilizes the co-design of IWSN and parameter state estimation. First, a group-based network deployment strategy, together with a TDMA (Time division multiple access)-based scheduling scheme is provided to track and sample the moving workpiece. Then, by matching to the tailored IWSN, the sequential estimation algorithm, which is based on the consensus-based Kalman estimation, is developed, and the optimal estimator that minimizes the mean-square error (MSE) is derived under the uncertain wireless communications. Finally, a case study on temperature estimation during the hot milling process is provided. The results show that the estimation error can be reduced to less than 3 ∘ C within a limited time period, although the measurement error can be more than 100 ∘ C in existing systems with a single-point temperature sensor.	algorithm;conceptualization (information science);conflict (psychology);deploy;entity name part qualifier - adopted;estimation theory;fever;greater than;ibm notes;matching;manuscripts;mathematical optimization;mathematics;mean squared error;nephrogenic systemic fibrosis;network planning and design;noise reduction;population parameter;purify;requirement;siae gene;sampling (signal processing);sampling - surgical action;scheduling (computing);scheduling - hl7 publishing domain;simulation;algorithm;sensor (device)	Feilong Lin;Wenbai Li;Liyong Yuan	2018		10.3390/s18103338		Mobile	48.14056482477548	3.900377096277242	190867
290333e3627b4b7971ddcc38a04b95385dd57287	distributed data association for multi-target tracking in sensor networks	distributed data;distributed estimation;clutter;probability;radar tracking;kalman filters;multitarget tracking;tracking filters;graph matching;data association;sensor network;multiple hypothesis tracking;filtering algorithms;estimation;markov chain monte carlo methods;kalman consensus filtering;wireless sensor networks kalman filters probability sensor fusion target tracking tracking filters;joint probabilistic data association;indexation;multi target tracking;sensor nodes;multiple scan method;sensor fusion;peer to peer computing;target tracking;target tracking peer to peer computing filters state estimation sensor arrays wireless sensor networks filtering algorithms network topology routing data security;wireless sensor networks;distributed data association;multiple hypothesis tracking distributed data association multitarget tracking sensor network kalman consensus filtering multiple scan method	In this paper, we explore the problem of tracking multiple targets through a field of sensors. Each sensor node is capable of making noisy measurements of the targets¿ positions, performing on-board computation, and wirelessly transmitting information to neighboring nodes. The problem of multitarget tracking (MTT) can be decomposed into two main fusion problems: estimation and data association. Using Kalman-consensus filtering (KCF), introduced by Olfati-Saber, the authors have recently addressed distributed estimation in tracking for a single target. Data association techniques for multitarget tracking are categorized by how many time-indexed sets of measurements are made before the associations are considered ¿fixed¿. Most multitarget tracking algorithms perform the data association at a central processing node through a multiple-scan method such as multiple hypothesis tracking (MHT), or single-scan techniques such as joint probabilistic data association (JPDA), Markov Chain Monte Carlo methods (MCMC), or optimal graph matching. Here, the main contribution is to introduce data association algorithms for ¿distributed¿ multitarget tracking. A formulation of joint probabilistic data association for Kalman-Consensus Filtering is formally derived. Simulations are provided to demonstrate the effectiveness of our distributed multitarget tracking algorithm for tracking multiple maneuvering targets in the sensing environment of a sensor network with 25 nodes.	algorithm;apple multiple scan 14 display;categorization;clutter;computation;computer simulation;correspondence problem;java platform debugger architecture;kalman filter;mhtml;markov chain monte carlo;matching (graph theory);monte carlo method;on-board data handling;sensor node;transmitter;usb hub	Nils F. Sandell;Reza Olfati-Saber	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739066	computer vision;wireless sensor network;computer science;machine learning;data mining;mathematics;statistics	Vision	53.12817382575088	2.687520364549166	191126
21879f30071bcc9c2cd3c47524a36a98eb58d8a1	frequency domain linear prediction for qmf sub-bands and applications to audio coding	line spectral frequency;frequency domain linear prediction;frequency domain linear prediction fdlp;indexing terms;autoregressive model;audio coding;quadrature mirror filter;scalar quantization;perceptual evaluation of audio quality peaq;frequency domain;split vector quantization	This paper proposes an analysis technique for wide-band audio applications based on the predictability of the temporal evolution of Quadrature Mirror Filter (QMF) sub-band signals. The input audio signal is first decomposed into 64 sub-band signals using QMF decomposition. The temporal envelopes in critically sampled QMF sub-bands are approximated using frequency domain linear prediction applied over relatively long time segments (e.g. 1000 ms). Line Spectral Frequency parameters related to autoregressive models are computed and quantized in each frequency sub-band. The sub-band residuals are quantized in the frequency domain using a combination of split Vector Quantization (VQ) (for magnitudes) and uniform scalar quantization (for phases). In the decoder, the sub-band signal is reconstructed using the quantized residual and the corresponding quantized envelope. Finally, application of inverse QMF reconstructs the audio signal. Even with simple quantization techniques and without any sophisticated modules, the proposed audio coder provides encouraging results in objective quality tests. Also, the proposed coder is easily scalable across a wide range of bit-rates.	approximation algorithm;autoregressive model;quadrature mirror filter;quantization (signal processing);scalability;vector quantization	Petr Motlícek;Sriram Ganapathy;Hynek Hermansky;Harinath Garudadri	2007		10.1007/978-3-540-78155-4_22	mathematical optimization;speech recognition;index term;computer science;quadrature mirror filter;mathematics;autoregressive model;frequency domain;statistics	ML	47.78627074387105	-9.334805004107368	191245
04656646d6a40205101ca9e90e9d6c3ccf1242c3	automatic mass detection and classification in mammograms		A display controller displays an image on either of a CRT display unit and a liquid crystal display unit (LCD) having upper and lower screens in accordance with image data stored in a memory. When a CRT display unit is driven, an address generating circuit calculates at the beginning of each horizontal scanning an address of the memory corresponding to the leftmost display position on the current horizontal scanning line in accordance with the vertical position of the horizontal scanning line and the number of display positions on a horizontal scanning line, and stores data representing the address in a first register. The data in the first register is incremented in accordance with the horizontal scanning and fed to the memory to read the image data. When the LCD is driven, the address generating circuit calculates at the beginning of each horizontal scanning two addresses of the memory corresponding respectively to the left most display positions on the current horizontal scanning lines on the upper and lower screens. In this case, the first one is obtained in accordance with the vertical position of the current horizontal scanning line on the upper screen and the number of display positions on a horizontal scanning line, while the second one is obtained by adding the number of display positions on the upper screen to the calculated first address.		Ehab Mostafa;Abdel Fatah A. Hegazy;Amr Badr	2008	Egyptian Computer Science Journal		electronic engineering;computer vision;engineering;control theory;liquid-crystal display;artificial intelligence;vertical direction;pattern recognition	Logic	46.97671460738072	-4.436560929620287	191821
08c33c5f2e6c0344276b6875a62d345a58ae1dd3	architectural design and analysis of learnable self-feedback ratio-memory cellular nonlinear network (srmcnn) for nanoelectronic systems	cellular nonlinear network;non linear circuit;architectural design;evaluation performance;diseno circuito;hebbian learning;arquitectura circuito;learning algorithm;memoire associative;nanoelectronica;leakage current;performance evaluation;image processing;integrated circuit;constant leakage current;normal distribution;hebbian theory;evaluacion prestacion;circuit non lineaire;circuit design;procesamiento imagen;template cellular nonlinear network modified hebbian learning algorithm nanoelectronic ratio memory;circuit architecture;cellular networks;circuito integrado;nanoelectronic;noise generators;algorithme apprentissage;cellular neural nets;modified hebbian;digital simulation feedback hebbian learning image processing nanoelectronics normal distribution pattern recognition cellular neural nets content addressable storage leakage currents;traitement image;systeme asservi;modified hebbian learning algorithm;reseau neuronal cellulaire;feedback;retroaccion;noise level;resultant ratio memory;cellular networks pattern recognition noise level cellular neural networks hebbian theory algorithm design and analysis memory architecture associative memory noise generators signal to noise ratio;retroaction;a template weights;leakage currents;memory architecture;feature enhancement;nanoelectronique;nanoelectronics;success rate;ratio memory;architecture circuit;feedback regulation;pattern recognition;associative memory;servomecanismo;memoria asociativa;self feedback ratio memory;conception circuit;uniform distribution noise level;feedback system;cellular neural networks;signal to noise ratio;image processing cellular nonlinear network resultant ratio memory self feedback ratio memory nanoelectronic systems modified hebbian learning algorithm associative memory a template weights pattern recognition feature enhancement constant leakage current uniform distribution noise level normal distribution;content addressable storage;algoritmo aprendizaje;nanoelectronic systems	In this paper, a learnable cellular nonlinear network (CNN) with space-variant templates, ratio memory (RM), and modified Hebbian learning algorithm is proposed and analyzed. By integrating both the modified Hebbian learning algorithm with the self-feedback function and a ratio memory into CNN architecture, the resultant ratio-memory (RMCNN) is called the self-feedback RMCNN (SRMCNN) which can serve as the associative memory. It can generate the absolute weights and then transform them into the ratioed A-template weights as the ratio memories for recognizing noisy input patterns. Simulation results have shown that with the stronger feature enhancement effect, the SRMCNN under constant leakage current can store and recognize more patterns than the RMCNN. For 18 /spl times/ 18 SRMCNN, 93 noisy patterns with a uniform distribution noise level of 0.8 and a variance of normal distribution noise of 0.3 can be learned, stored, and recognized with 100% success rate. The SRMCNN has greater learning and recognition capability when the learned patterns are simpler and the noise is lower. For the learning and recognition of complicated patterns, the allowable pattern number is decreased for a 100% success rate. Simulation results have successfully verified the correct functions and better performance of SRMCNN in the pattern recognition. With high integration capability and excellent pattern association performance, the proposed SRMCNN can be applied to nanoelectronic associative-memory systems for image processing applications.	algorithm;artificial neural network;coefficient;content-addressable memory;feedback;hebbian theory;hopfield network;image processing;noise (electronics);nonlinear system;pattern recognition;real-time clock;resultant;simulation;spectral leakage	J.-L. Lai;P. C.-Y. Wu	2004	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2004.836309	embedded system;electronic engineering;hebbian theory;telecommunications;image processing;computer science;electrical engineering;artificial intelligence;machine learning;feedback;algorithm;statistics	ML	39.520145967597685	-2.432171239082993	192169
811536b217bb3bfcd52f0107473a09dcbb4ffab7	decentralized support detection of multiple measurement vectors with joint sparsity	sparse solutions;row based total energy;decentralized support detection;compressed sensing;dr lasso algorithm;wideband;vectors signal detection;wideband cognitive radio networks;spatially distributed users;signal detection;joints sparse matrices cognitive radio artificial neural networks optimization compressed sensing wideband;spectrum;consensus constraints;joints;multiple measurement vectors;artificial neural networks;joint sparsity;vectors;cognitive radio;cognitive radio network;spatial distribution;decentralized row based lasso multiple measurement vectors joint sparsity support detection;support detection;wideband cognitive radio networks decentralized support detection multiple measurement vectors joint sparsity sparse solutions sparsity structure common nonzero support signal features spatially distributed users decentralized row based lasso algorithm dr lasso algorithm distributed mmv problem penalty term row based total energy consensus constraints cooperative spectrum occupancy detection;sparsity structure;optimization;decentralized row based lasso;decentralized row based lasso algorithm;signal features;penalty term;cooperative spectrum occupancy detection;distributed mmv problem;sparse matrices;artificial neural network;common nonzero support	This paper considers the problem of finding sparse solutions from multiple measurement vectors (MMVs) with joint sparsity. The solutions share the same sparsity structure, and the locations of the common nonzero support contain important information of signal features. When the measurement vectors are collected from spatially distributed users, the issue of decentralized support detection arises. This paper develops a decentralized row-based Lasso (DR-Lasso) algorithm for the distributedMMVproblem. A penalty term on row-based total energy is introduced to enforce joint sparsity for the MMVs, and consensus constraints are formulated such that users can consent on the total energy, and hence the common nonzero support, in a decentralized manner. As an illustrative example, the problem of cooperative spectrum occupancy detection is solved in the context of wideband cognitive radio networks.	algorithm;cognitive radio;lasso;sparse matrix	Qing Ling;Zhi Tian	2011	2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2011.5946288	mathematical optimization;cognitive radio;computer science;machine learning;pattern recognition;artificial neural network	Robotics	52.02682557744183	1.8485104442354368	192233
11872830914e268c8c0bc9419686d8dd9d33df4a	a high speed asynchronous multi input pipeline for compaction and transfer of parallel simd data		Image sensors with programmable, highly parallel signal processing, so called Vision-Systems-on-Chip, perform computationally intensive tasks directly on the sensor itself. Therefore it is possible to limit the amount of output data to relevant image features only. Reading out such features presents a major challenge, since the position and number of features often is not known. Conventional synchronous buses as well as special event-based readout paths are unsuitable for such a system, since both continuous data, e.g. complete images, and sparse data, like feature coordinates, have to be transfered. A readout path based on an asynchronous pipeline is presented, which supports both readout modes with high speed. Furthermore, a method is introduced that, by serialization, allows for arbitrary data word widths without storing any control information within the data stream. The developed circuit components were measured on a proof-of-concept test chip in a 180 nm CMOS technology and were compared with implementations of asynchronous pipelines found in literature. In addition, the use of the pipeline in a Vision- System-on-Chip, which is still in production, is demonstrated.		Christoph Hoppe;Jens Döge;Peter Reichel;Patrick Russell;Andreas Reichel;Peter Schneider	2018	2018 24th IEEE International Symposium on Asynchronous Circuits and Systems (ASYNC)	10.1109/ASYNC.2018.00027	parallel computing;serialization;data stream;feature (computer vision);word (computer architecture);signal processing;image sensor;asynchronous communication;simd;computer science	Arch	42.71664195773123	-2.5258349355941125	192423
cde84dd1aaa2191551630a75c83b7772a646a6f7	high-fidelity multichannel audio coding with karhunen-loeve transform	estensibilidad;interchannel redundancy;compression algorithm;evaluation performance;circuit codeur;degradation;64 kbit s;karhunen loeve transformation;audio signal processing;canal multiple;advanced audio coding aac;coding circuit;performance evaluation;data compression;high fidelity audio coding;complexite calcul;audio bitstream;redundancia;signal audio;evaluacion prestacion;canal transmision;audio signal;karhunen loeve transform klt;mpeg 2 aac;compresion senal;narrow band;multichannel audio coding;bande etroite;transform coding;bit rate;compression signal;multiple channel;mechanical factors;algorithme;algorithm;audio coding;complejidad computacion;advanced audio coding;audio coding karhunen loeve transforms bit rate audio compression transform coding decorrelation mechanical factors computational complexity narrowband degradation;karhunen loeve transforms;redundancy;canal transmission;traitement signal audio;computational complexity;transmission channel;mpeg 2 advanced audio coding;audio signal reconstruction;circuito codificacion;banda estrecha;signal compression;multichannel audio;decorrelation;signal reconstruction;mpeg;extensibilite;scalability;compresion dato;quality scalable audio;codage audiofrequence;decorrelated channels;transformation karhunen loeve;computational complexity audio coding karhunen loeve transforms transform coding signal reconstruction;transformacion karhunen loeve;karhunen loeve transform;narrowband;audio compression;64 kbit s high fidelity audio coding multichannel audio coding karhunen loeve transform audio compression mpeg 2 advanced audio coding mpeg 2 aac interchannel redundancy decorrelated channels audio bitstream heterogeneous network computational complexity audio signal reconstruction;senal audio;compression donnee;redondance;heterogeneous network;algoritmo	A new quality-scalable high-fidelity multichannel audio compression algorithm based on MPEG-2 Advanced Audio Coding (AAC) is presented in this research. The Karhunen-Loève Transform (KLT) is applied to multichannel audio signals in the pre-processing stage to remove inter-channel redundancy. Then, signals in de-correlated channels are compressed by a modified AAC main profile encoder. Finally, a channel transmission control mechanism is used to re-organize the bitstream so that the multichannel audio bitstream has a quality scalable property when it is transmitted over a heterogeneous network. Experimental results show that, compared with AAC, the proposed algorithm achieves a better performance while maintaining a similar computational complexity at the regular bit rate of 64 kbit/sec/ch. When the bitstream is transmitted to narrow-band end users at a lower bit rate, packets of some channels can be dropped, and slightly degraded yet full-channel audio can still be reconstructed in a reasonable fashion without any additional computational cost.	advanced audio coding;algorithm;algorithmic efficiency;bitstream;computation;computational complexity theory;data compression;encoder;mpeg-2;preprocessor;scalability;surround sound	Dai Yang;Hongmei Ai;Chris Kyriakakis;C.-C. Jay Kuo	2003	IEEE Trans. Speech and Audio Processing	10.1109/TSA.2003.814375	data compression;speech recognition;telecommunications;computer science;speech coding;audio signal flow;algorithm;statistics	Mobile	47.29188797954077	-9.10420618575837	193003
03cc0d8d3417ef89648c2be984f786dde16bc5ab	investigation of galvanic-coupled intrabody communication using the human body circuit model	simplified equivalent circuit body sensor networks capacitive coupling electrode galvanic coupling intrabody communication ibc measurement setup modeling;intrabody communication;electrodes impedance skin couplings receivers integrated circuit modeling biomedical measurement;transmission;electrodes;ibc;college of science and engineering;1005 communications technologies	Intrabody Communication (IBC) is a technique that uses the human body as a transmission medium for electrical signals to connect wearable electronic sensors and devices. Understanding the human body as the transmission medium in IBC paves way for practical implementation of IBC in body sensor networks. In this study, we propose a model for galvanic coupling-type IBC based on a simplified equivalent circuit representation of the human upper arm. We propose a new way to calculate the electrode-skin contact impedance. Based on the model and human experimental results, we discuss important characteristics of galvanic coupling-type IBC, namely, the effect of tissues, anthropometry of subjects, and electrode configuration on signal propagation. We found that the dielectric properties of the muscle primarily characterize the received signal when receiver electrodes are located close to transmitter electrodes. When receiver and transmitter electrodes are far apart, the skin dielectric property affects the received signal.	anthropometry;body tissue;characteristic impedance;equivalent circuit;frequency band;galvanic isolation;information-based complexity;iron binding capacity measurement;kilohertz;megahertz;muscle;property and casualty state mandated forms attachment:find:pt:^patient:doc;quantitative impedance;social communication disorder;software propagation;transmitter (medical device);transmitter device component;upper arm;wearable computer;electrode;saw (device);sensor (device)	Behailu Kibret;MirHojjat Seyedi;Daniel T. H. Lai;Michael Faulkner	2014	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2014.2301165	telecommunications;transmission;electrode	Mobile	46.13020004885464	0.7010114917935087	193793
bc17a80f3633429c8fc372c604eb4ae282b0805b	methods for none intrusive delay measurment for audio communication over packet networks	echo cancellation;packet network;audio signal processing;perceptual domain audio communication packet network none intrusive method delay estimation tracking audio signal mdct transformed domain;mdct transformed domain;audio signal;audio communication;base station;computational complexity;discrete cosine transforms;delay estimation base stations echo cancellers added delay jitter acoustic measurements hybrid power systems acoustic distortion quality of service computational complexity;packet networks;quality of service;tracking audio signal processing delay estimation discrete cosine transforms hearing;user satisfaction;hearing;delay estimation;tracking;none intrusive method;perceptual domain	Measurement of the delay is an important and common problem in communication over packet networks. The end-to-end and the round trip delay are among the factors directly impacting the quality of service as well as the user satisfaction. Multimedia gateways or base stations that perform echo cancellation or suppression often rely on the round trip delay to enhance their performance or to reduce the computational complexity of echo processing logics. In this work, we present two none intrusive methods for delay estimation and tracking. Both methods find the delay using the actual audio signal that is sent through the network. The first approach uses the MDCT transformed domain coefficients of the signal while the second operates in a perceptual domain. Experiments illustrate that both schemes can track the end-to-end and the round trip delay under various network and signal conditions	coefficient;computational complexity theory;echo suppression and cancellation;end-to-end encryption;end-to-end principle;modified discrete cosine transform;network packet;quality of service;round-trip engineering;zero suppression	Mohammad Zad-issa;Norbert Rossello;Laurent Pilati	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262597	computer vision;speech recognition;quality of service;telecommunications;audio signal processing;computer science;processing delay;base station;audio signal;end-to-end delay;tracking;transmission delay;computational complexity theory;round-trip delay time;network delay	EDA	48.98120313796876	-7.634831744075589	194268
1458ac5bc6c16ed8c1ea366d10343631a366dc57	jacobians of genus-2 curves with a rational point of order 11	primary 11y40 11g30 14h40 14q05;elliptic curve;rational point of order 11;modular curve;jacobians;rational point;modular curves;torsion;genus 2 curves;genus 2 curve;prime number;class group	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;primary source	Nicolas Bernard;Franck Leprévost;Michael E. Pohst	2009	Experimental Mathematics	10.1080/10586458.2009.10128884	discrete mathematics;modular curve;topology;elliptic rational functions;mathematics;elliptic curve;torsion;modular elliptic curve;rational point;prime number;algebra	Robotics	49.331543849588314	-2.6279145046007826	194638
868a6503c30349d8e2a85ef34aa4caf76acff8dd	perceived audio quality for streaming stereo music	mushra;audio codec;audio quality;youtube	Users of audio-visual streaming services expect an ever increasing quality of experience. Channel bandwidth remains a bottleneck commonly addressed with lossy compression schemes for both the video and audio streams. Anecdotal evidence suggests a strongly perceived link between bit rate and quality. This paper presents three audio quality listening experiments using the ITU MUSHRA methodology to assess a number of audio codecs typically used by streaming services. They were assessed for a range of bit rates using three presentation modes: consumer and studio quality headphones and loudspeakers. Our results indicate that with consumer quality headphones, listeners were not differentiating between codecs with bit rates greater than 48 kb/s (p>=0.228). For studio quality headphones and loudspeakers aac-lc at 128 kb/s and higher was differentiated over other codecs (p<=0.001). The results provide insights into quality of experience that will guide future development of objective audio quality metrics.	advanced audio coding;anne westfall;audio engineer;audio signal processing;codec;data rate units;experiment;headphones;iso/iec 646;john d. wiley;lossy compression;loudspeaker;mason;mp3;mpeg-2;mushra;maxwell (microarchitecture);maxwell–bloch equations;octal;sound quality;streaming media;vos or openvos;libopus	Andrew Hines;Eoin Gillen;Damien Kelly;Jan Skoglund;Anil C. Kokaram;Naomi Harte	2014		10.1145/2647868.2655025	speech recognition;telecommunications;computer science;sound quality;multimedia;statistics	Metrics	46.73265233948682	-7.730860269875252	196010
83c6b3aa6caf8ea98edbc2ae347e5459d851d149	a model for vlsi implementation of cnn image processing chips using current-mode techniques	cellular neural network model;cmos integrated circuits;filtering;image recognition;image processing equipment;very large scale integration cellular neural networks image processing semiconductor device modeling integrated circuit modeling analog circuits buildings feature extraction filtering semiconductor device measurement;image processing;building block;very large scale integration;n well double metal single poly technology;cellular neural network;semiconductor device measurement;cnn image processing chips;current mode;cellular neural nets;chip;analog circuits;neural chips;compound component detection;semiconductor device modeling;feature extraction;noise filtering;1 6 micron;integrated circuit modeling;cmos integrated circuits vlsi cellular neural nets neural chips image processing equipment feature extraction image recognition;cmos imager;vlsi;1 6 micron area evaluation cnn image processing chips current mode techniques cellular neural network model preprocessing chips feature extraction noise filtering compound component detection n well double metal single poly technology;current mode techniques;cellular neural networks;experimental measurement;preprocessing chips;buildings;area evaluation	A new cellular neural network model is proposed. It allows simpler and faster VLSI implementation than previous models. Current-mode building blocks are presented for the design of CMOS image preprocessing chips (feature extraction, noise filtering, compound component detection, etc.) using the cellular neural network paradigm. Area evaluation for the new model shows a reduction of about 50% as compared to the use of current-mode techniques with conventional models. Experimental measurements of CMOS prototypes designed in a 1.6-/spl mu/m n-well double-metal single-poly technology are reported. >	image processing;very-large-scale integration	Servando Espejo-Meana;Ángel Rodríguez-Vázquez;Rafael Domínguez-Castro;Bernab&#x00E9; Linares-Barranco;José Luis Huertas	1993		10.1109/ISCAS.1993.393885	filter;embedded system;computer vision;electronic engineering;cellular neural network;image processing;computer science;electrical engineering;theoretical computer science;very-large-scale integration	EDA	39.609071906626525	-2.2483001976135135	196103
5c32ff9bb16e228674957dfd3483f1240fd4b1e2	application of interferometry in ultrasonic system for vibration	signal analysis;ultrasonic wave;system design;signal processing;fault diagnosis	Vibration signals are important state parameters for mechanical equipments’ status monitoring and fault diagnosis. In this paper, in order to overcome the limitations of the traditional vibration measurement med1ods and instrument, a new non-contacting vibration method based on ultrasonic for vibration detection in special environment was presented. The mainly researched in this paper were the circuit for ultrasonic transmitting, receiving, algorithm and the module based on LabVIEW for signal analysis and processing. New algorithm was adopted in the system design. The measurement for vibration signals, which may have higher accuracy, was based on ultrasonic wave of different frequency. Experiments were carried on for proving the theory and the result was expected, verifying the reliability and feasibility of the system.	algorithm;labview;signal processing;systems design;transmitter;verification and validation	Zhengping Liu;Shenghang Xu;Juanjuan Liu	2010		10.1007/978-3-642-18369-0_13	control engineering;electronic engineering;acoustics;engineering;ultrasonic testing	EDA	47.015969147210306	-2.0475225465895908	196213
9a83d482333a28cdba4ceb19b784517f94b54448	coupling non-linear models in object- oriented simulation: application to drives with multiple induction motors	simulation ordinateur;modelizacion;induction machine;eficacia sistema;engine;sistema de transporte;monitoring control system;etude experimentale;induction motor;performance systeme;systeme controle commande;object oriented simulation;non linear model;sistema complejo;sistema control mando;pasion;system performance;modelisation;induction motors;systeme complexe;complex system;object oriented;motor;systeme transport;oriente objet;maquina induccion;simulacion computadora;moteur;machine induction;modeling;orientado objeto;computer simulation;estudio experimental;transportation system	Object-oriented simulation is an excellent tool while treating models of complex systems. The model can be decomposed into several submodels and the structure of the simulation program can be similar to the structure of the real system. In this article the problem of simulation and control of a set of interconnected induction motors is considered. Models of such kind can be useful while working on control problems for complex mechanisms driven by multiple motors, such as belt or chain conveyers or some transport facilities. In particular, an application of the simulation system PASION™ is described. Possible applications of the model in control problems related to the system stability and performance are pointed out.	simulation	Leszek Kawecki;Stanislaw Raczynski	1998	Simulation	10.1177/003754979807000204	computer simulation;control engineering;simulation;computer science;engineering;electrical engineering;artificial intelligence;induction motor	Robotics	52.334799443761575	-6.403618099469822	196565
96f552807c8f95deab1fa2acfe2878228fb4abe9	information processing by data interrogation	time measurement;logic design;tellurium;data processing;electronic equipment testing;satisfiability;information processing;logic testing;position measurement;force measurement;information processing position measurement goniometers logic testing force measurement electronic equipment testing time measurement tellurium radar measurements sonar;radar measurements;high speed;goniometers;sonar	A data-processing technique is described in which a function is evaluated by rapid interrogation of the given data for the presence of combinations of data variables giving rise to values of the function which are of interest. Testing unlabeled measurements from several observers to find data sets which satisfy a test function is discussed as an example. For many problems the required time is much shorter than that needed when processing is carried out by a high speed general purpose machine. Logical design and equipment requirements for solution of such a problem by data interrogation are discussed.	information processing	Jack Atkin;Nathan B. Marple	1962	IRE Trans. Electronic Computers	10.1109/TEC.1962.5219351	electronic engineering;logic synthesis;data processing;information processing;goniometer;computer science;engineering;electrical engineering;data mining;tellurium;physics;quantum mechanics;sonar;time;satisfiability	HCI	47.66734039649971	-0.834967913466182	196591
b5890020d5a343a3b7787232059c10108c7f6780	optimal coding-decoding for systems controlled via a communication channel	additive white gaussian noise;networked control systems;noisy channel;network performance;channel model;channel capacity;channel signal to noise ratio;network configuration;network architecture;networked control system;signal to noise ratio;communication channels;coder decoder	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	additive white gaussian noise;automation;channel (communications);control engineering;control system;control theory;francis;intelligent control;mimo;minimum phase;mobile robot;multi-agent system;nl (complexity);primary source;robot control;signal-to-noise ratio;systems theory	Yi-wei Feng;Guo Ge	2013	Int. J. Systems Science	10.1080/00207721.2012.685202	control engineering;additive white gaussian noise;electronic engineering;network architecture;telecommunications;computer science;networked control system;engineering;mathematics;network performance;signal-to-noise ratio;channel capacity;statistics;channel	Robotics	50.89509281125077	-3.452110736368886	196986
91c6ac4ebdcd3d274b72a3907b40091fc5176345	a mathematical model of parallel information processing	information processing;mathematical model	Without Abstract	information processing;mathematical model	Andrzej Skowron	1976		10.1007/3-540-07854-1_225	computer science;mathematical model;mathematics	ML	52.111764959705326	-5.014783627108479	197434
17805bf662c80cd23535c8ecc209f13e48507377	modified mp3 encoder using complex modified cosine transform	layer 3;filter bank;spectrum;digital audio players discrete cosine transforms psychoacoustic models quantization transform coding frequency masking threshold acoustic noise psychology codecs;frequency spectrum;digital music;audio coding;window switching mp3 encoder cosine transform digital music psychoacoustic modeling digital audio perceptual coding fft computation frequency spectrum masking thresholds modified discrete cosine transform;discrete cosine transforms;fast fourier transforms;modified discrete cosine transform;filtering theory audio coding discrete cosine transforms fast fourier transforms;cosine transform;filtering theory	MPEG-1 layer-3, popularly known as MP3, has revolutionized the digital music domain. MP3 makes use of psychoacoustic modeling to achieve compression through the removal of perceptually irrelevant components of digital audio. The psychoacoustic model is the key element of perceptual coding and requires intensive FFT computation for calculating the frequency spectrum. This spectrum is used to compute masking thresholds. Thus, the original MP3 algorithm computes modified discrete cosine transform (MDCT) and FFT parallelly. The proposed algorithm is an alternative to this. We make use of complex modified discrete cosine transform (CMDCT) of the filter-bank outputs for generating MDCT coefficients as well as the frequency spectrum. This method requires fewer computations than the original method. A novel method of window switching, based on filter-bank output is used to simplify the overall algorithm. The proposed algorithm reduces the amount of computations for MP3 encoder while retaining the audio quality.	encoder;mp3	Manu Mathew;Vasudha Bhat;Shine M. Thomas;Changhoon Yim	2003		10.1109/ICME.2003.1221715	spectrum;sine and cosine transforms;fast fourier transform;frequency spectrum;transform coding;speech recognition;lapped transform;modified discrete cosine transform;digital audio;short-time fourier transform;computer science;theoretical computer science;discrete sine transform;discrete fourier transform;discrete cosine transform;filter bank;mathematics;discrete fourier transform;algorithm;network layer;discrete frequency domain	HCI	47.693013958049605	-9.187412033828066	197443
605cdd31de22b9cd38ba54d1a3871f7f2156dc03	modification of algebraic multigrid for effective gpgpu-based solution of nonstationary hydrodynamics problems	gpgpu;algebraic multigrid;nonstationary partial differential equations	We present modification of algebraic multigrid algorithm for effective GPGPU-based solution of nonstationary hydrodynamics problems. The modification is easy to implement and allows us to reduce number of times when the multigrid setup is performed, thus saving up to 50% of computation time with respect ccepted 27 August 2012 vailable online 29 August 2012	algorithm;computation;general-purpose computing on graphics processing units;multigrid method;time complexity	D. E. Demidov;D. V. Shevchenko	2012	J. Comput. Science	10.1016/j.jocs.2012.08.008	mathematical optimization;combinatorics;parallel computing;computer science;theoretical computer science;mathematics;general-purpose computing on graphics processing units;multigrid method	Logic	45.90331144537842	3.937033858777101	197466
4010e1d33d9361d648371594627da3f4c9b917f8	the convergence conditions of the psd iterative method for linear systems	sistema lineal;linear algebra;preconditionnement;iterative method;convergence theorem;g1 3;systeme equation;evans missirlis method;convergence;condicion necesaria;matrice h;psd method;precondtioned simultaneous displacement problem;the psd iterative method;preconditioning;linear system;metodo iterativo;descomposicion matricial;convergencia;sistema ecuacion;necessary condition;decomposition matricielle;matrix decomposition;methode iterative;algebre lineaire;equation system;methode evans missirlis;algebra lineal;precondicionamiento;condition necessaire;linear equations;systeme lineaire;iteration method;65f10;h matrix	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;iterative method;linear system;primary source	Da-Wei Chang	2001	Int. J. Comput. Math.	10.1080/00207160108805086	local convergence;mathematical optimization;mathematical analysis;linear algebra;calculus;mathematics;iterative method;algebra	Robotics	49.4874169509542	-2.9510600272489227	197729
768c18b79fb071d02e473719018911597ed1f104	algebraic quantization of transform coefficients for embedded audio coding	embedded coding;embedded audio coding;algebraic quantization;wavelet based wideband scalable coder;transform coding;wavelet transforms algebra audio coding;error criterion;wavelet transforms;audio coding;wavelet based wideband scalable coder algebraic quantization transform coefficients embedded audio coding error criterion;algebra;audio coding bit rate transform coding decoding bandwidth time frequency analysis wavelet transforms huffman coding vector quantization image reconstruction;algebraic quantization embedded coding transform coding;transform coefficients	This paper proposes a new quantization for transform coefficients based on algebraic quantization. The coefficients are represented by a few pulses multiplied by a unique amplitude. The coefficients to be transmitted are selected by optimizing an error criterion, that determines the signs, positions and amplitudes of the pulses. This simple quantization has been implemented in a wavelet-based wideband scalable coder, and has been proved to provide a perceptually better quality than SPIHT on speech signal and music.	coefficient;embedded system;linear algebra;scalability;set partitioning in hierarchical trees;wavelet	Mickaël De Meuleneire;Hervé Taddei;Dominique Pastor	2008	2008 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2008.4518728	wavelet;sub-band coding;transform coding;speech recognition;shannon–fano coding;quantization;harmonic vector excitation coding;variable-length code;theoretical computer science;speech coding;coding tree unit;mathematics;tunstall coding;stationary wavelet transform;discrete wavelet transform;vector quantization;wavelet transform	Robotics	47.55463322404431	-9.535548679468286	198429
796a453a26f1ca0e1f47fd3720bb8d140687d8bc	a stride towards practical 3-d device simulation-numerical and visualization considerations	simulation ordinateur;matrice eparse;dispositif semiconducteur;interfase usuario;automatic switching scheme 3d device simulation latchup analysis stride device solver message passing multiprocessor iterative matrix solvers gummel style nonlinear iteration schemes independent edge grouping scheme vector processing efficiency modified singular perturbation two carrier simulations convergence rate;estructura 3 dimensiones;convergence;latchup analysis;integrated circuit;user interface;semiconductor device;relacion convergencia;circuito integrado;taux convergence;convergence rate;spatial structure;two carrier simulations;structure 3 dimensions;iterative methods;computerized monitoring;circuit simulation;iterative matrix solvers;nonlinear iteration schemes;visualization computational modeling convergence circuit simulation poisson equations message passing central processing unit computerized monitoring condition monitoring user interfaces;visualization;computational modeling;singular perturbation;condition monitoring;integrated circuit technology;independent edge grouping scheme;semiconductor device models;message passing;automatic switching scheme;interface utilisateur;perturbation singuliere;floating point;electronic engineering computing;simulacion computadora;perturbacion singular;3d device simulation;device solver;stride;computer simulation;user interfaces;dispositivo semiconductor;vector processing efficiency;parallel processing;semiconductor device models digital simulation electronic engineering computing integrated circuit technology iterative methods parallel processing;message passing multiprocessor;gummel style;circuit integre;central processing unit;digital simulation;poisson equations;device simulation;modified singular perturbation	Absfracf-A 3-D device solver (STRIDE), capable of solving grids up to 250 000 nodes, has been developed on a message passing multiprocessor. By the use of iterative matrix solvers and Gummel style nonlinear iteration schemes, user memory per node is reduced over use of direct solvers and Newton schemes. By using an independent-edge-grouping scheme to increase the vector length to the order of the number of variables, the vector processing efficiency is significantly increased without additional floating point operations. We extend the modified-singular-perturbation (MSP) scheme to two-carrier simulations. This significantly speeds up the convergence rate of Gummel style nonlinear iterations. Physical insight gained from the MSP schemes also leads to an automatic switching scheme between various nonlinear schemes based on the monitoring of certain matrix parameters. This allows the incorporation of a previously proposed Newton-1C scheme which offers the best CPU performance for normal bipolar simulations. When combined with current convergence criterion, a set of MSP inspired convergence criterion are better able to recognize a practically converged solution. A novel global convergence scheme is also developed based on insight from MSP principles. Interactive user interface and links to graphics tools are provided to support the tool integration efforts. Application of STRIDE is demonstrated by an analysis of latchup trigger current dependence on layout arrangement.	central processing unit;graphics;iteration;latch-up;local convergence;max;message passing;multiprocessing;newton;nonlinear system;numerical analysis;rate of convergence;simulation;solver;stride of an array;stride scheduling;user interface;vector processor	Ke-Chih Wu;Goodwin R. Chin;Robert W. Dutton	1991	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.85759	computer simulation;embedded system;parallel processing;mathematical optimization;electronic engineering;parallel computing;computer science;electrical engineering;theoretical computer science;operating system;user interface;algorithm	Visualization	44.36989819697153	4.000842009546828	199110
e1a361b526de4fd8b635b17e9105781afea8ca9a	cmos-memristor dendrite threshold circuits	neural circuits;image processing;memristors;biological system modeling;inverters;analog circuits;dendrite models;computational modeling;logic gates;gates;integrated circuit modeling;neurons	Non-linear neuron models overcomes the limitations of linear binary models of neurons that have the inability to compute linearly non-separable functions such as XOR. While several biologically plausible models based on dendrite thresholds are reported in the previous studies, the hardware implementation of such non-linear neuron models remain as an open problem. In this paper, we propose a circuit design for implementing logical dendrite non-linearity response of dendrite spike and saturation types. The proposed dendrite cells are used to build XOR circuit and intensity detection circuit that consists of different combinations of dendrite cells with saturating and spiking responses. The dendrite cells are designed using a set of memristors, Zener diodes, and CMOS NOT gates. The circuits are designed, analyzed and verified on circuit boards.	artificial neuron;cmos;circuit design;diode;exclusive or;memristor;nonlinear system;printed circuit board	Askhat Zhanbossinov;Kamilya Smagulova;Alex Pappachen James	2016	2016 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2016.7803914	electronic engineering;memristor;logic gate;image processing;analogue electronics;computer science;electrical engineering;theoretical computer science;computational model	EDA	39.86822929430223	-0.9223735800258421	199596
