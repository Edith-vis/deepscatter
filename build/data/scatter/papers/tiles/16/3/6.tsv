id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
06b55fe0f1b5a2494c57eaf50ff06fcfb2d9e0ab	a human-centered approach to data privacy : political economy, power, and collective data subjects		Researchers find weaknesses in current strategies for protecting privacy in large datasets: many 'anonymized' datasets are re-identifiable, and norms for offering data subjects notice and consent overemphasize individual responsibility. Based on fieldwork with data managers in the City of Seattle, I identify ways that these conventional approaches break down in practice. Drawing on work from theorists in sociocultural anthropology, I propose that a Human-Centered Data Science move beyond concepts like dataset identifiability and sensitivity toward a broader ontology of who is implicated by a dataset, and new ways of anticipating how data can be combined and used. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored.	data science;field research;information privacy	Meg Young	2016	CoRR		social science;computer science;artificial intelligence;data science;data mining;sociology;management;social psychology;law;world wide web;computer security	ML	-72.13636812074526	-14.92898128515704	49054
624040a993a9bf3c5f8880e5c24d6594a85f3c40	25 years of science citation index - some experiences	citation index;residu;index citation;ascorbique acide derive;ascorbic acid derivatives;aminoacido;science citation index;aminoacid;residuo;residue;aminoacide;ascorbico acido derivado;indice cita	"""Science Citation Index (SCI) depends for intellectual content entirely on citations by authors, who are sometimes prodded by editors and referees. Its patchiness is therefore not surprising, but frequently it gives access to relevant and up-to-date documents not easily accessible by other means. Two contrasting """"citation families"""" are described. The first family, dealing with the various ascorbic acid derivatives having C substitution at C-2, actually retrieved very nearly all the relevant documents (other than patent specifications) that were retrieved by a CAS ONLINE substructure search. Organic chemists are clearly careful authors. The second family, dealing with amino acid residues covalently bound in soil organic matter, yielded documents having surprisingly little overlap with those retrieved by using a carefully devised Boolean """"profile"""" on the general subject index of Chemical Abstracts. This was only partly because SCI is beset by language-barrier problems to which Chemical Abstracts is immune. The SCI management might extend its journal coverage, but otherwise improvement can only come from a more serious attitude to placing references in primary publications. SCI remains a complement to, not a substitute for, other data-bases."""		Richard L. M. Synge	1990	Journal of chemical information and computer sciences	10.1021/ci00065a009	stereochemistry;mathematics;residue;operations research	Web+IR	-74.49503226794447	-20.453646726333538	49059
ffbc5bcc544b36e96b4f7f29b8577d52e0830598	secure data provenance and inference control with semantic web		This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot assume responsibility for the validity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may rectify in any future reprint. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged. Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for identification and explanation without intent to infringe. Provenance means the origin of a source, the history of ownership of a valued object or a work of art or literature. Information about provenance is especially important for works of arts, as it directly determines the value of the artwork. This also applies to both digital artifacts and results that are generated by applications. Therefore, data provenance is one kind of metadata that pertains to the derivation history of a product starting from its original sources. The provenance of a result or data object can be regarded as important as the data itself; therefore, the quality or trust one places on the data is important to the value and usage of the data. Using provenance, one can ascertain the quality of data based on its ancestral data and derivations, track back to sources of errors, allow automatic re-enactment of derivations to update data, and provide attribution of the data source. Provenance is also essential to the medical domain. Provenance can be used to drill down to the source of record, track the creation of a new version of a record, and provide an audit trail for regulatory processes. A framework for evaluating the utility and security aspects of provenance is a critical need in multiple domains. For instance, in health care, the provenance associated with a patient's medical record can be used for postdiagnosis and for verifying regulatory and health-care guidelines. Also, the provenance plays a critical part in an emergency room, …	digital artifact;photocopier;semantic web;verification and validation	Bhavani M. Thuraisingham;Tyrone Cadenhead;Murat Kantarcioglu;Vaibhav Khadilkar	2014			data web;computer science;social semantic web;data mining;database;world wide web	DB	-67.0016841720739	-16.88882937497411	49145
362f50f59a280d7cc526fb626fdf44ad382cee57	the journal coverage of web of science and scopus: a comparative analysis	web of science;research evaluation;scopus;bibliometrics;citation indexes	Bibliometric methods are used in multiple fields for a variety of purposes, namely for research evaluation. Most bibliometric analyses have in common their data sources: Thomson Reuters’ Web of Science (WoS) and Elsevier’s Scopus. The objective of this research is to describe the journal coverage of those two databases and to assess whether some field, publishing country and language are over or underrepresented. To do this we compared the coverage of active scholarly journals in WoS (13,605 journals) and Scopus (20,346 journals) with Ulrich’s extensive periodical directory (63,013 journals). Results indicate that the use of either WoS or Scopus for research evaluation may introduce biases that favor Natural Sciences and Engineering as well as Biomedical Research to the detriment of Social Sciences and Arts and Humanities. Similarly, English-language journals are overrepresented to the detriment of other languages. While both databases share these biases, their coverage differs substantially. As a consequence, the results of bibliometric analyses may vary depending on the database used. These results imply that in the context of comparative research evaluation, WoS and Scopus should be used with caution, especially when comparing different fields, institutions, countries or languages. The bibliometric community should continue its efforts to develop methods and indicators that include scientific output that are not covered in WoS or Scopus, such as field-specific and national citation indexes.	bibliometrics;citation index;database;directory (computing);qualitative comparative analysis;scopus;web of science	Philippe Mongeon;Adèle Paul-Hus	2015	Scientometrics	10.1007/s11192-015-1765-5	scopus;bibliometrics;computer science;data mining;world wide web;information retrieval	DB	-77.36878259545894	-21.936661391849995	49256
109371c7a075b8f50a02def9821ebbba3241c1d1	the legitimacy of positions in endgame databases			database	Dietmar Lippold	1997	ICGA Journal	10.3233/ICG-1997-20103	chess endgame;management science;artificial intelligence;computer science;legitimacy	DB	-66.48594245267607	-10.651761035125775	49278
65588d23abebf75bf554092b2af03bc40d0f6755	from static content to dynamic communities: the evolution of networked educational resources	nouvelles technologies de l information et de la communication ntic;community;site web;etude de cas;information source;cooperation;social sciences;developpement durable;resources;collaboration;resource materials;computer networks;educational resource;content analysis;foreign countries;social science;internet;base de donnees;world wide web;sciences sociales;source d information;enseignement;dynamic content;data protection;privacy;sustainable development;communaute;teaching;instructional materials	Five years ago the problems being addressed by major educational resources were how to locate and structure a burgeoning universe of Web sites in order to serve their subject and professional communities with useful and relevant content. Today, new challenges, demands and opportunities are emerging: the linking of content with community, static information with dynamic news. Describes the evolution of three educational resources in the social sciences (SOSIG, Biz/Ed and Regard) and their use of personal profiling, distributed contributions and RSS news channels to serve and gather information. Examines the issues that arise from changing user bases and technologies, sustainability and the need for collaboration, data protection and privacy concerns. Analyses the tensions these and other services face as they move toward a model that links the static with the dynamic, content with community.		Neil Jacobs;Lesly Huxley	2002	Online Information Review	10.1108/14684520210418356	community;the internet;content analysis;computer science;knowledge management;dynamic web page;database;data protection act 1998;multimedia;sociology;privacy;world wide web;cooperation;sustainable development;resource;collaboration	HCI	-70.95372658044435	-20.034243390216147	49441
c521244b2565f9bf56673e6b34971b2e2dee3f3d	de-identification of health data in big data using a novel bio-inspired apoptosis algorithm	apoptosis;medical records;privacy preserving;de identification;big data;bio inspired algorithm;perturbation;metaheuristic;health data	part of this journal may be reproduced or used in any form or by any means without written permission from the publisher, except for noncommercial, educational use including classroom teaching purposes. Product or company names used in this journal are for identification purposes only. Inclusion of the names of the products or companies does not indicate a claim of ownership by IGI Global of the trademark or registered trademark. The views expressed in this journal are those of the authors but not necessarily of IGI Global.	algorithm;big data;de-identification	Amine Rahmani;Abdelmalek Amine;Reda Mohamed Hamou	2015	IJOCI	10.4018/IJOCI.2015070101	big data;perturbation;computer science;artificial intelligence;apoptosis;data science;machine learning;data mining;database;world wide web;computer security;medical record;metaheuristic	Comp.	-70.8993487778254	-16.685015531908704	49579
4c5af82419b5a816ce0df7f972d9456f02ff79f6	is (web) science ready for empowerment?	ws9 sociology;web futures;evolving technologies;web science 2011;the pro human web;ws6 economics;knowledge production	The World Wide Web opens up many avenues for new research. Some of them (Web as observable phenomenon, Web as engineered technology) fall quite well within mainstream academic paradigms of research. However, this is much less so if we position the Web as a mechanism for empowerment related to social development. Informed by our W4RA field research experiences in West Africa, we review contextual as well as general issues of scientific research and scientific method if it is to be relevant to issues of empowerment.	field research;observable;web science;world wide web	Hans Akkermans;Nana Baah Gyan;Anna Bon;Wendelien Tuyp;Aman Grewal;Stéphane Boyera;Mary Allen	2011		10.1145/2527031.2527041	web accessibility initiative;web standards;engineering;knowledge management;marketing;social semantic web;management science;web intelligence;web engineering	HCI	-65.35493998604235	-10.942486258621873	49711
9adaa8ddbc32449ad4954b24f9372fbdc539d568	corrigendum: data citation in neuroimaging: proposed best practices for data identification and attribution	data sharing;bepress selected works;data repository;credit;data attribution;data citation;credit data citation data attribution data repository data sharing neuroimaging community;neuroimaging community	In our original article, we stated, “Annual DOI creation costs range from $500 (for non-degree granting departments) to $25,000 (for entire degree-granting institutions) per 1 million DOIs minted.” This is incorrect. The University of California EZID service offers annual DOI creation at $835 (for non-degree granting departments) to $2500 (for entire degree-granting institutions) per 1 million DOIs minted1. The authors apologize for the mistake. This error does not change the conclusions of the article in any way.		Leah B. Honor;Christian Haselgrove;Jean A. Frazier;David N. Kennedy	2016		10.3389/fninf.2016.00034	data quality;computer science;bioinformatics;data science;data mining;information repository;world wide web	NLP	-65.2887079909671	-17.29773412930299	49887
ada05cc2abde7c22d44919554f2b56f09482188e	teaching information system students to be entrepreneurs: a dot.com case study		This paper describes a unique entrepreneurial venture initiation class conducted in the spring 2007 semester at The Wharton School, University of Pennsylvania. The students of this class started a business together and shared in the value created. The business was a social networking Web site, www.wishfood.com, forming a community of individuals with an interest in food and wishing to share recipes. The course was designed to expose students to the process of starting a business, to teach the technical skills required, and to imbue an entrepreneurial spirit. This paper covers the structure of the course, the contributions of the students, the business timeline, and the outcomes of the course. This paper will allow a professor to replicate and learn from the successes and failures of the course.	information system	Philip Kor;Alan S. Abrahams	2007	CAIS		engineering management;knowledge management	HCI	-68.65190027779916	-23.76875404641363	49934
0d8fb2090057820a46ec19ddaa38eb1f89688c6e	some challenges to geodemographic analysis and their wider implications for the practice of giscience	systems	I have written previously in this journal about some of the ‘grand challenges’ that I think face our research community, and their implications for computer representations of environmental and urban systems. My personal interests focus upon how these challenges might be met using the tools of geographic information systems (GIS) and methods of geographic information science (Longley, 2006; and also Longley, Goodchild, Maguire, & Rhind, 2005). In this editorial I would like to apply the notion of grand challenges to research into the kinds of small area ‘geodemographic’ indicators that have been successfully used for over a quarter of a century in the world of commerce (Harris, Sleight, & Webber, 2005). There is increasing interest in the use of geodemographics in questions of effective and efficient public service delivery (Longley, 2005). What might at first appear as a specialised system of interest, I suggest, raises a number of important generic issues that are relevant to much of the readership of this journal. Geodemographics, like the GIS mainstream, is a field that is led by ‘successful’ applications, in this instance grounded largely in the commercial sector and supported only in very limited ways by fields such as applied geography and sociology. As such, it can be seen as a freestanding aspect of Thrift’s (2005) ‘knowing capitalism’, in which vast resources of information are created through commercial applications of information technologies, in ways that are largely independent of academic research. Superficially, such areas of applied activity may seem detached from the ‘grand challenges’ of curiosity driven science and social science, since their immediate overriding objectives are simply to use available technology to devise workable, practical solutions. Yet to the likes of Savage and Burrows (2007), their ‘politics of method’ suggests that they are not only as instances of the application of particular techniques, but also manifestations of the intrinsic organisation of advanced capitalist society. Viewed from this latter perspective, I want to suggest that academia needs to develop, as a minimum, an informed ‘outsider’ view of the ways in which geodemographic systems are specified, weighted and tested; and that, by extension,	apache thrift;didactic organisation;geographic information science;geographic information system;grand challenges;harris affine region detector;itil;savage	Paul A. Longley	2007	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2007.10.002	computer science;system	HCI	-76.04503125951521	-10.577145320251244	49948
02aec369db0abab439a441ddfd419e61c29a5bb8	controlling the conversation	automotive engineering;automotive electronics;control systems;automobiles;computers and society computing technology;computerised control;temperature sensors;computing technology;engine cylinders;petroleum;fuel economy;automotive engineering automobiles control systems temperature sensors force control fuel economy pollution sparks engine cylinders petroleum;sparks;consumer behaviour;computers and society;computer control;automobile industry;pollution;force control	Reader commenting forums of online newspaper sites allow newsreaders the opportunity to participate in an online conversation about the news topic at hand. By providing the forums, journalists diffuse part of their gatekeeping responsibilities to non-journalist commenters, empowering them as secondary gatekeepers to decide what content appears alongside the news. To encourage constructive dialogue, however, virtually all comment-hosting newspapers require that online reader commenters remain civil in their comments. They recognize that incivility in the forums is toxic to their brand identity and serves to antagonize, polarize and silence the very readers they are trying to attract. To combat this, newspapers have developed strategies aimed at reducing incivility, including prohibiting anonymity or disallowing the forums altogether. In reasserting their agenda-setting and gatekeeping role in discouraging incivility, newspapers appear to be adopting a new strategy, as yet unquantified. In an examination of...	computer control company	David Alan Grier	2007	Computer	10.1109/MC.2007.309	computing;pollution;computer science;control system;operating system;petroleum;consumer behaviour	DB	-68.991461266399	-15.042669668500753	50104
ebf728bdc20196f71fcf9758df7a39c53b02af11	the rent's too high: self-archive for fair online publication costs		Even in the current climate of anti-science sentiment, science remains one of the most stunning achievements of our species. The main contributors of scientific knowledge—researchers—generally aim to disseminate their findings far and wide. And yet, publishing companies have largely kept these findings behind a paywall. With digital publication technology markedly reducing cost, this enduring wall seems disproportionate and unjustified.	archive;paywall	Robert T. Thibault;Amanda MacPherson;Stevan Harnad;Amir Raz	2018	CoRR			HCI	-74.6254073689955	-15.155806364717028	50110
4ce0b23d79a04be4d9bfc0437426da45f494ec45	introduction to strategy, information, technology, economics, and society (sites) minitrack	conference paper			Eric K. Clemons;Rajiv M. Dewan;Robert J. Kauffman;Thomas A. Weber	2017			computer science	HCI	-64.82939433523897	-10.668600655299755	50114
f09e52e5d5ed370cf6ad6a66d75037cc8bc97f76	it's all over but the crying: the emotional and financial impact of internet fraud	computers;internet computer security psychology electronic mail computer crime counterfeiting psychology;electronic mail;advance fee fraud emotional impact financial impact internet fraud victimization psychological effects romance scams;socio economic effects human factors internet;psychology;psychology of fraud;counterfeiting;psychological consequences of crime cybercrime psychology of fraud;internet;boilers;psychological consequences of crime;cybercrime	Drawing from their survey on Internet fraud's emotional consequences, the authors conclude that the psychological effects of victimization are just as critical as the financial. Respondents reported that romance scams and advance fee fraud had the highest emotional impact.		David Modic;Ross J. Anderson	2015	IEEE Security & Privacy	10.1109/MSP.2015.107	the internet;computer security	Security	-70.60135274791315	-10.837622506901374	50172
780a426758f1b72d3140f09ebd38c54f0ce03ff6	the unnoticed presidential transition: whither whitehouse.gov?		is and how this transition should unfold, giving the new President a site reflecting his views and biography while preserving the content of the Clinton whitehouse.gov. We conclude with a proposal that the new whitehouse.gov staff work with the U.S. National Archives to provide perpetual Web-based archives of whitehouse.gov content.		Richard Wiggins	2001	First Monday		public relations;public administration;law;world wide web	Theory	-65.11170750847671	-15.214742485276638	50206
ea4a8e22269c0e474130f0a76be8fca5265c0921	literature core zones adjusted by impact factors	bibliometrie;analyse bibliometrique;courbe groos;scientometrics;facteur impact;periodical;impact factor;bibliometria;pertinencia;loi bradford;management by objectives;frequency of occurrence;periodique;periodico;scientometria;pertinence;scientometrie;bradfort law;acid rain;bibliometry;evaluation;bibliometric analysis;relevance;evaluacion;recherche scientifique;scientific research;investigacion cientifica;analisis bibliometrico;loi de bradford	This paper reports a study of the effect of adjusting the frequency of occurrence of journals with impact factors in the literatures of acid rain, superconductivity and management by objectives. Three different Bradford methods were used to demarcate the core-zone journals of the literatures. The effects of adjustment by impact factors created three paradigms: (1) the acid rain literature illustrated the first paradigm, where journals from the unadjusted literature were thrust forward in the adjusted literature, and no unadjusted journal fell into obscurity: (2) the superconductivity literature illustrated the second paradigm, where the most voluminous journal was also the most prestigious and led both the unadjusted and adjusted literatures; and (3) the management by objectives literature illustrated the third paradigm, where the adjustment by impact factors only churned the placement of the journals.		Terrence A. Brooks	1990	J. Information Science	10.1177/016555159001600109	management by objectives;scientific method;relevance;acid rain;scientometrics;computer science;evaluation;sociology;management;operations research;law	Logic	-75.82487756235399	-22.564749434768196	50284
83f14f410f88a18ed3eb59d2fa857c98314051b4	power and information technology: a review using metatriangulation	selected works;information technology;bepress	This study uses a metatriangulation theory building process to explore the relationships between power and information technology (IT) in a sample of 43 articles from 10 leading management and MIS journals. We explore the multiple paradigms underlying this research, describe patterns emerging from the previous power and IT studies, and recommend future directions for investigation.	programming paradigm	Carol Stoak Saunders;Traci Carte;Jon Jasperson;Henry Croes;Weijun Zheng;Brian S. Butler	2000			computer science;law;information technology	HCI	-75.34994758987933	-17.28021426241626	50367
123d278d48cc74a8b036d3bcf290fa9d09dad57f	technology, laws, and society	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias	stimulate uoparallcled human advances. However, phenomenal increases in computer system speed, storage capacity, interconnectivity, and information mobility are srriously exacerbating many problems familiar to readers of “Inside IUSKS.” Such problems diversely include maintaining privacy, ownership, and control; avoiding side effects from dependence on untrustworthy or unreliable systems and individuals; withstanding major system outages; coping with information overload: and suffering from system-induced ailments such as mental stress and physical impairment. Taking full advantage of the internetted world requires an adequate understanding of the potential consequrnces and the rigorous adoption of appropriate countermeasuresfor example, against serious losses oC data confidentiality, system integrity, and resource availability. Debate continues over whether the emerging computer and communication technologies introduce intrinsic differences with respect to how our civiliration must respond, or whether thr advances are merely incremental steps from what has preceded them. Each position has some merit in certain cases. However, there are substantive differences arising from almost instantaneous worldwide system responsiveness across arbitrary geographical sep arations, with abilities to cross-link massive and diverse databases, potential for globally impairing many remote systems simultaneously, opportunities for individual anonymity (especially in mail), and in many cases thr absence of individual accountability. Every abuse that is possible without computers can become amplified in place, time, and extent-such as financial frauds, tracking of individual actions, and highly selective personalired junk mail. Furthermore, new abuses become possible. Each community has its own suggestions for what to do about these problems: . System technologists typically see the need for better systems and networks-with increased security, reliability, and safety. For example, improved operating systems, user-tosystem and system-to-system authentication, network encryption, and privacy enhanced mail (PEM, KIPEM, etc.) can significantly increase the security attainable. The KlSKS archives suggest that we must do better in develop ing and using life-critical systems, and indeed some progress is being made in reliability and human safety. l Some legislators and lawyers see a need for laws that are more clrarly mforceable, and in borne cases more technology->prcific. lssucs raised include familiar topics such as liability, malpractice, intellectual property, financiai crimes, and whistle-blowing. In these and other areas, difficulties arise in applying the existing laws-which often were not written with all of the idiosyncrasies of the computer era in mind. Examples include remote access from another country with different laws, and definitions of what constitutes authorization and misuse. Law enforcement communities typically seek more arresu, more prosecutions, and more jail-which might become less relevant if the technology were doing its job better. Insurers also can play a constructive role, particularly if they encourage the development of systems that help to reduce the risks --not just the risks to insurers, but also the risks to the insured. . Social scientists see many needs that transcend technology and the law. Examples include restructuring our societies, providing better education, encouraging greater human interaction and cooperation generally, reducing inequities between people with access to the emerging information superhighway and everyone else, and pervasively reinforcing and encouraging ethical behavior, from cradle to grave. Such a diversity of perspectives is typical when a new technology emerges. At any one time, certain interest groups may seek economic, political, ideological, or emtional leverage. Each group may view iu goals as predominant, and may ignore the other groups. It is dangerous to belie\;e that one approach is more correct or has a higher priority than another. Each approach can contribute positively-whereas irs absence can lead (and has led) to serious consequences. Each of the three perspectives must be respected, within a coordinated effort that unities them. Consequently, these perspectives and others must evolve further so that the technology, the laws, and the social norms all become much more compatible with one another than they are now. 0	archive;authentication;authorization;computer;confidentiality;database;emergence;encryption;information overload;information superhighway;norm (social);operating system;privacy-enhanced electronic mail;reflow soldering;remote desktop software;responsiveness;system integrity;wireless security	Peter G. Neumann	1994	Commun. ACM	10.1145/175247.175262	theoretical computer science;applied mathematics;computer science	HCI	-73.03524720505972	-11.857821521671925	50389
93e9ce2eb4692ebfe0efb9119a8bcf06af63d735	book review: the information society: a study in continuity and change	information society		scott continuity	Luke Tredinnick	2005	JOLIS	10.1177/096100060503700207	social science;computer science;media studies;sociology	HCI	-64.21768677652592	-10.909310812478571	50500
129db956cf321b9f0048ba986d469856c6f35f1d	elra in the heart of a cooperative hlt world		This paper aims at giving an overview of ELRA’s rece nt activities. The first part elaborates on ELRA’s m eans of boosting the sharing Language Resources (LRs) within the HLT community thr ough its catalogues, LRE-Map initiative, as well as its work towards the integration of its LRs within the META-SHARE open in frastructure. The second part shows how ELRA helps in the development and evaluation of HLT, in particular through its numero us participations to collaborative projects for the production of resources and platforms to facilitate their production and exploi tation. A third part focuses on ELRA’s work for clea ring IPR issues in a HLT-oriented context, one of its latest initiative being its inv ol ement in a Fair Research Act proposal to promote the easy access to LRs to the widest community. Finally, the last part elaborates on rec ent actions for disseminating information and promo ting cooperation in the field, e.g. an the Language Library being launched at LREC2012 an d the creation of an International Standard LR Numbe r, a LR unique identifier to enable the accurate identification of LRs. Among the other messages ELRA will be conveyin g the attendees are the announcement of a set of freely available resources , th establishment of a LR and Evaluation forum, et c.	accessibility;identifier;interpro;lr parser;lre map;reflow soldering;unique key	Valérie Mapelli;Victoria Arranz;Matthieu Carré;Hélène Mazo;Djamel Mostefa;Khalid Choukri	2012			natural language processing;artificial intelligence;speech recognition;computer science	NLP	-64.52835811255714	-14.466114069528139	50744
4c58c69f5b84269341bd5840c43026a1838da812	popular research topics in multimedia	web of science;multimedia;citations;google scholar;acm sigmm;research topics	Multimedia has taken on a very important role in our daily life which has led to a rapid growth research on this topic. Multimedia research covers a variety of problem domains so one must examine many current popular research areas to obtain a basic understanding of current multimedia research. This allows us to understand what has been done recently and to consider what will be more important in future. In this study, we collect and analyze data from ACM Multimedia conferences from 2007 to 2011. In particular, the organized sessions (or areas) and the citation count of popular areas are examined using the Web of Science and Google Scholar. Then, the self-organizing map method is used as a visualization tool for keyword analysis in order to identify popular areas and research topics in multimedia. In addition, we also examine the consistency of the identified popular research areas and topics between the ACM Multimedia conferences and two recent journal special issues.	acm-mm;google scholar;organizing (structure);problem domain;search engine optimization;self-organization;self-organizing map;web of science;world wide web	Chih-Fong Tsai;Chihli Hung	2012	Scientometrics	10.1007/s11192-012-0932-1	computer science;multimedia;world wide web	DB	-76.05846069507302	-18.685569290230642	50792
6d13df020106f7acf22283a7de363289657e914e	a historical perspective on developing foundations iinfo(tm) information systems: iconsult(tm) and ientertain(tm) apps using idescribers(tm) information integration for iorgs(tm) information systems	cluster computing;information technology;information integration;logic in computer science;information system;cloud computing	Technology now at hand can integrate all kinds of digital information for individuals, groups, and organizations so their information usefully links together. iInfoTM information integration works by making connections including examples like the following:  A statistical connection between “being in a traffic jam” and “driving in downtown Trenton between 5PM and 6PM on a weekday.”  A terminological connection between “MSR” and “Microsoft Research.”  A causal connection between “joining a group” and “being a member of the group.”  A syntactic connection between “a pin dropped” and “a dropped pin.”  A biological connection between “a dolphin” and “a mammal”.  A demographic connection between “undocumented residents of California” and “7% of the population of California.”  A geographical connection between “Leeds” and “England.”  A temporal connection between “turning on a computer” and “joining an on-line discussion.” By making these connections, iInfo offers tremendous value for individuals, families, groups, and organizations in making more effective use of information technology. In practice, integrated information is invariably pervasively inconsistent. Therefore iInfo must be able to make connections even in the face of inconsistency. The business of iInfo is not to make difficult decisions like deciding the ultimate truth or probability of propositions. Instead it provides means for processing information and carefully recording its provenance including arguments (including arguments about arguments) for and against propositions that is used by iConsult TM and iEntertain TM apps in iOrgs TM information systems. A historical perspective on the above questions is highly pertinent to the current quest to develop foundations for privacy-friendly client-cloud computing.	causality;cloud computing;digital data;dolphin;information system;jam;microsoft research;online and offline;relevance;undocumented feature;xml:tm	Carl Hewitt	2009	CoRR		simulation;cloud computing;computer cluster;computer science;artificial intelligence;information integration;operating system;data mining;distributed computing;information technology;information system;algorithm	HCI	-70.73205142474222	-18.05534057108449	50815
64fe54daac061cb3d33f11f370d7a7b9b904677b	digital divide in information systems research: a meta-analysis and framework		This article analyzes 119 Digital Divide (DD) papers published in 60 journals between the years of 2000rnand 2016. It classifies DD research into 16 types, and found that global DD has been was studied the most.rnIt also categorized the research papers into 36 topics, and found that Computer/Internet/ICT adoptionrnand usage was the most investigated topic. Other results were: secondary data was the most usedrnmethodology, positivist approach was the most prevalent, and the U.S. was the most studied country.rnAdditionally, our research summarized and classified the antecedents and dependent variables of DD intornnine categories, and proposed a comprehensive framework. Future research and limitations are discussed.	information systems research	Prashant C. Palvia;Abdullah Oguz;Ziyue Huang;Zahra Yarmohammadi;Xiaoyu Li	2017			knowledge management;variables;the internet;computer science;meta-analysis;digital divide;positivism;information system;information and communications technology	Robotics	-76.17338961120355	-18.083486148780707	51156
fbdefd0a105e76e0754fe0439d4d196c53507e1c	library of congress recommended format specifications: encouraging preservation without discouraging creation	informacion documentacion;grupo a;ciencias sociales	The Library of Congress has a fundamental commitment to acquiring, preserving and making accessible in the long term the creative output of the nation and the world. The Library has devised the Recommended Format Specifications to enable it to identify what formats will most easily lend themselves to preservation and long‐ term access, especially with regard to digital formats. The Library is doing this to provide guidance to its staff in their work of acquiring content for its collection, but we also seek to share this with other stakeholders, from the creative community to vendors to other libraries, each of which has a need and interest in preservation and access. To ensure ongoing accuracy and relevancy, the Library of Congress will be reviewing and revising the specifications on an annual basis and welcomes feedback and input from all interested parties. Why the Library of Congress Developed the Recommended Format Specifications Throughout its history, the Library of Congress has been committed to a goal best described in its mission statement “to further the progress of knowledge and creativity for the benefit of the American people.” At its core, the Library's ability to advance the nation's progress has depended upon its collection, which in turn embodies the knowledge and creativity of the many authors, composers, journalists, artists, and scientists whose work is contained there. The quality of the collection reflects the Library's care in selecting materials and the effort it invests in preserving them and making them accessible to the American people for the long term. To build such a substantial and wide‐ranging collection and to ensure that it will be available for successive generations, the Library relies upon a wealth of expertise. In order to maximize the scope and scale of the content in the collection, the Library calls upon the knowledge in languages, subject matter and trends in publishing and content creation provided by the specialists who identify and acquire material for the Library’s collection. 1 United States Copyright Office. (2012). Best edition of published copyrighted works for the collections of the Library of Congress. Retrieved from http://www.copyright.gov/circs/circ07b.pdf But knowledge of the technical characteristics of the production of creative works is required as well. In the past, the lasting power of the collections depended exclusively upon the endurance of such materials as the paper, ink, and binding of a book; the acetate or paper coated with gelatin in a photograph; or the shellac, vinyl, and coated polyester that comprise a sound recording. Although these materials remain in use today, creators and publishers have also begun to employ a wide array of intangible digital formats, as well as continuing to change and adapt the physical formats in which they work. The Library needs to be able to identify the formats that are suitable for large‐scale acquisition and preservation for long‐term access if it is to continue to build its collection and ensure that it lasts into the future. To do this in the past, the Library of Congress has relied upon the specifications included in the copyright regulation known as the Best Edition Statement.1 This has offered clear guidance to Library of Congress staff on the hierarchy of preference between certain physical characteristics in creative works. For example, it states clearly that when it comes to printed textual matter, “hard cover rather than soft cover.” The detail in the Best Edition Statement Copyright of this contribution remains in the name of the author(s). http://dx.doi.org/10.5703/1288284315583 Collection Development         261 has been extremely useful for the Library for decades; however, it has some serious drawbacks. Since it is a regulation, the Best Edition Statement is not revised or updated frequently and there are preferences within it that no longer keep up with changes which have taken place in the creation of tangible media, such as the decline of the use of diskettes. Even more importantly, the Best Edition Statement does not address digital content at all, with the sole exception of online serials. For an institution with the broad goals and remit of the Library of Congress, having guidance that fails to address at least half of all formats in use will not work. Specifications are required that cover the whole range of content it intends to collect and that means digital content at least as much as analog. In response to this need, in 2011 the Library began a process that would lead to the development of the Recommended Format Specifications (www.loc.gov/preservation /resources/rfs/index.html). The Library began its work by examining the Best Edition Statement, which enabled it to work closely and collaboratively with its colleagues in the Copyright Office (http://www.copyright.gov/) and take advantage of their input and unique expertise. Yet it was not merely the Best Edition Statement that provided a base from which to carry out the group’s work. For digital formats, the working group took full advantage of the work done by Library of Congress staff with regard to its work on digital format sustainability (http://www .digitalpreservation.gov/formats/index.shtml) to provide it with a starting point.2 Between these two established fields of endeavor and sources of expertise, the Library had a strong basis on which to build the Recommended Format Specifications. Parameters of the Recommended Format Specifications Before discussing the specific aims the Recommended Format Specifications attempt to address, it is best to make clear what they do not 2 Library of Congress. (2014). Sustainability of digital formats: Planning for Library of Congress collections. Retrieved from http://www.digitalpreservation.gov/formats/index.shtml attempt to do. The specifications which the Library is now publishing do not replace or supersede the Best Edition Statement, which provides guidance to publishers and creators in fulfilling their obligations with regard to the registration or deposit of their works under the terms of the Copyright Law. It seeks to complement that work, building upon the knowledge gained from working with the Best Edition Statement and providing a broader set of recommendations, aimed at providing guidance and clarity in a creative world, which is rich with both potential and problems and which affords numerous competing options for content format or container. Likewise, the creation and publication of the Recommended Format Specifications is not intended to serve as an answer to all the questions raised in preserving and providing long‐ term access to creative content. They do not provide instructions for receiving this material into repositories, managing that content or undertaking the many ongoing tasks which will be necessary to maintain this content so that it may be used well into the future. Tackling each of those aspects is a project in and of itself as each form of content has a unique set of facets and nuances. These specifications provide guidance on identifying sets of formats which are not drawn so narrowly as to discourage creators from working within them, but will instead encourage creators to use them to produce works in formats which will make preserving them and making them accessible simpler. Following these specifications helps make it realistic to build, grow and save creative output for our individual and collective benefit for generations to come. Developing the Recommended Format Specifications In 2011, a working group comprised of stakeholders from across the Library was established to examine the existing Best Edition Statement and determine a structure upon which the Library could model its own specifications. The	best practice;case preservation;content format;digital data;digital recording;floppy disk;library (computing);printing;relevance;subject matter expert turing test;tangible user interface;webserver directory index	Theron Westervelt	2014	D-Lib Magazine	10.1045/september2014-westervelt	computer science;world wide web	HCI	-67.2317823928245	-19.444116248567127	51230
8ca500093076c08ca30720e6014e79967d771506	collaborating on open science: the journey of the biodiversity heritage library	global partnership;outreach;taxonomic intelligence;digital library;data reuse;open access	The Biodiversity Heritage Library, BHL http://www.biodiversitylibrary.org/ , is an established and successful digital library, formed by a global consortium of natural history libraries, with engaged and enthusiastic users. The extensive partnerships, curated content, innovative tools and services, the ease of mining the data all combine to establish an open science resource that advances scientific progress through linking, use and reuse. The aim of BHL as stated on the web page is: “Inspiring discovery through free access to biodiversity knowledge. The Biodiversity Heritage Library works collaboratively to make biodiversity literature openly available to the world as part of a global biodiversity community. BHL also serves as the foundational literature component of the Encyclopedia of Life (EOL)”. BHL and EOL are linked via taxonomic names and bibliographies. BHL is linked in a similar way to the Global Biodiversity Information Facility (GBIF) and thus has broad exposure to scientists across the globe as well as a global public.	biodiversity heritage library	Constance A. Rinaldo;Jane E. Smith	2015		10.3233/978-1-61499-562-3-15	digital library;computer science;knowledge management;world wide web	Logic	-69.7646120400282	-16.567966545722825	51287
390b8e4df05f0257467d9b47dd97f7b70a0199c0	computer-assisted stemmatology in studying paulus juusten's 16th-century chronicle catalogus et ordinaria successio episcoporum finlandensium		Medieval chronicles offer valuable source material for historians studying the Middle Ages. Like all medieval books, also chronicles were written and copied by hand, causing both unintentional errors and intentional alterations to the text. Stemmatologists are trying to recreate the family tree of the different copies. In recent years, many computer-assisted methods have emerged which several editors have already used. Computer-assisted stemmatology can offer valuable tools not only for editors but also for historians. They can also help to test traditional methods of textual criticism, point out errors in earlier historiography and create possibilities for studying cultural links and the history of books. In this article it is demonstrated how the use of different computer-assisted stemmatological methods can reveal new information concerning the manuscript tradition of a Finnish 16th-century chronicle, Paulus Juusten’s Catalogus et ordinaria successio Episcoporum Finlandensium. With the help of these methods, it can also be shown that the stemma put forward in the latest edition of the chronicle should be reconsidered. Using PAUP, RHM, and SplitsTree, it is pointed out that these methods create similar results as traditional textual criticism. These results can be obtained considerably more quickly than with traditional methods and without the subjective decision by a stemmatologist between ‘original readings and errors’. .................................................................................................................................................................................	book;family tree;phylogenetic analysis using parsimony *and other methods;splitstree;sunstone (medieval)	Marko Halonen	2016	DSH	10.1093/llc/fqv004	humanities;art;literature	Web+IR	-64.16439592121341	-21.664469313013928	51305
3463fe882540bfd4ec0ec5ae822790d0da4a8c43	a comparative study of bibliometric past performance analysis and peer judgement	analyse bibliometrique;biology;biologia;science policy;chimie;evaluation interpair;indicateur recherche;chemistry;performance analysis;quimica;national survey;evaluation;bibliometric analysis;evaluacion;research indicator;biologie	A comparison is made between two types of research past performance analysis: the results of bibliometric-indicators and the results of peer judgement. This paper focuses on two case studies: the work of Dutch National Survey Committees on Chemistry and on Biology, both compared with our bibliometric results for research groups in these disciplines at the University of Leiden. The comparison reveals a serious lack of agreement between the two types of past performance analysis. This important, science-policy relevant observation is discussed in this paper.	bibliometrics;profiling (computer programming)	Henk F. Moed;W. J. M. Burger;J. G. Frankfort;Anthony F. J. van Raan	1985	Scientometrics	10.1007/BF02016933	social science;evaluation;sociology;management;operations research	HPC	-75.79560598550981	-22.7693806306954	51595
d5b048107d0e62779c095f66ca574e2e02cf7287	research impact of general and funded papers: a citation analysis of two acm international conference proceeding series	citation analysis;highly cited papers;informacion documentacion;ciencias sociales;research funding;research impact	Purpose – The purpose of this paper is to focus on examining the research impact of papers written with and without funding. Specifically, the citation analysis method is used to compare the general and funded papers published in two leading international conferences, which are ACM SIGIR and ACM SIGKDD. Design/methodology/approach – The authors investigate the number of general and funded papers to see whether the number of funded papers is larger than the number of general papers. In addition, the total citations and the number of highly cited papers with and without funding are also compared. Findings – The analysis results of ACM SIGIR papers show that in most cases the number of funded papers is larger than the number of general papers. Moreover, the total captions, the average number of citations per paper, and the number of highly cited papers all reveal the superiority of funded papers over general papers. However, the findings are somewhat different for the ACM SIGKDD papers. This may be because A...	citation analysis	Cheng-Che Shen;Ya-Han Hu;Wei-Chao Lin;Chih-Fong Tsai;Shih-Wen Ke	2016	Online Information Review	10.1108/OIR-08-2015-0249	computer science;operations research;citation analysis;world wide web	Robotics	-77.12807337045012	-20.704475891075887	51624
dc5ddddc800549124784708aed22aa1290570a93	the planetmath encyclopedia	encyclopedias;mathematics;collaboration	The history of PlanetMath.org is discussed, tracing its inception, stabilization, and some defining challenges. Research and outreach efforts that have been conducted in the course of work on the PlanetMath project are reviewed, and the scope and reach of the resource are discussed. Recent developments are indicated briefly. Some remarks evaluating PlanetMath’s trajectory and content conclude the paper.	encyclopedias;published comment	Joseph Corneli	2011				HCI	-62.93325688816724	-16.99073864517982	51717
48c70759cec3f6c2acd830f806dea214862f42ed	bioinformatics education—perspectives and challenges out of africa	genomics;universities;internet;history 21st century;humans;computational biology;africa;history 20th century	The discipline of bioinformatics has developed rapidly since the complete sequencing of the first genomes in the 1990s. The development of many high-throughput techniques during the last decades has ensured that bioinformatics has grown into a discipline that overlaps with, and is required for, the modern practice of virtually every field in the life sciences. This has placed a scientific premium on the availability of skilled bioinformaticians, a qualification that is extremely scarce on the African continent. The reasons for this are numerous, although the absence of a skilled bioinformatician at academic institutions to initiate a training process and build sustained capacity seems to be a common African shortcoming. This dearth of bioinformatics expertise has had a knock-on effect on the establishment of many modern high-throughput projects at African institutes, including the comprehensive and systematic analysis of genomes from African populations, which are among the most genetically diverse anywhere on the planet. Recent funding initiatives from the National Institutes of Health and the Wellcome Trust are aimed at ameliorating this shortcoming. In this paper, we discuss the problems that have limited the establishment of the bioinformatics field in Africa, as well as propose specific actions that will help with the education and training of bioinformaticians on the continent. This is an absolute requirement in anticipation of a boom in high-throughput approaches to human health issues unique to data from African populations.	bioinformatics;biological science disciplines;biopolymer sequencing;genome;high-throughput computing;population;throughput;unintended consequences	Özlem Tastan Bishop;Ezekiel F. Adebiyi;Ahmed M. Alzohairy;Dean Everett;Kais Ghedira;Amel Ghouila;Judit Kumuthini;Nicola J. Mulder;Sumir Panji;Hugh-George Patterton	2015		10.1093/bib/bbu022	biology;genomics;the internet;computer science;bioinformatics;operations research	Comp.	-69.94401887966119	-16.80542559363389	51970
e3acf4588f1667452bbd2327d56e71cfd2013235	benoît mandelbrot and the self-similarity of information	z665 library science information science		mandelbrot set;self-similarity	David Bawden	2011	Journal of Documentation	10.1108/jd.2011.27867baa.001	social science;computer science	Crypto	-63.838715714836496	-11.006132672816554	52181
115d758f3d6440699053164b9c9c9d4432142b6e	a new curriculum for hardware-based network intrusion detection	system configuration;rule based;network intrusion detection;computer security;network traffic analysis;information assurance;fpgas;hardware design;hardware	We describe a new curriculum for hardware based network intrusion detection taught at college and graduate levels in a National Center of Academic Excellence in Information Assurance Education Program (CAE/IAE). The curriculum focuses the fundamental concepts of network intrusion detection mechanisms, network traffic analysis, rule-based detection logic, system configuration, and basic hardware design and experiments. This new course cultivates students with the latest development in computer security and hands-on projects for better prepared in information assurance careers.	computer security;experiment;hands-on computing;information assurance;intrusion detection system;logic programming;network traffic control;positive feedback;system configuration;traffic analysis	Dan Lo;Andy Wang;Sarah M. North;Max M. North	2011		10.1145/2016039.2016126	intrusion detection system;simulation;computer science;computer security;computer engineering	Security	-68.35897890160491	-11.24182790479983	52386
fc288ce65c904de44edea5ab119eb4646cd2f51d	a plan for ancillary copyright: original snippets		The snippets that web search engines generate for their result presentation are extracted from the retrieved web pages, reusing pieces of text that match a user’s query. Copyright owners of the retrieved web pages are typically not asked for usage rights. This long-time practice now faces increasing backlash from news publishers, legal action, and even new legislation in Germany and Spain: the so-called ancillary copyright for news publishers. This copyright law restricts the fair use of intellectual property of news publishers, allowing them to raise claims for monetary compensation when their text is reused, even within snippets. If passed at the EU level, ancillary copyright could severely impact future information system development. This paper promotes a “technological remedy”, namely, to synthesize true original snippets without text reuse.	information system;web page;web search engine	Martin Potthast;Wei-Fan Chen;Matthias Hagen;Benno Stein	2018			computer science	AI	-66.81027273140829	-19.50084069327389	52473
44128accc3ddd801461582384b797c5a9d152e15	buying computers for your school: a guide for the perplexed	physics	"""Local school districts are passing multimillion-dollar bond issues to buy technology for their schools. In Michigan, for example, Ann Arbor has just passed a $4 million bond issue; Willow Run, a neighboring community where GM just closed a 4,000-person plant, recently passed a $2 million bond issue. Plymouth-Canton, another neighboring community has bought in for $3 million. The money is there, collecting interest fortunately, waiting to be spent. Schools are girding themselves for another wave of computer buying. While buying computers is exhilarating , choosing among the variety is no mean feat. Consider then what your local neighborhood school faces: should it be Mac, IBM, or clones? What kinds of network(s)? Token-rings-are those like friendship rings? Who will service the equip-ment? What about software? Whose m ® videodisc-based curriculum is really o. worth the money? And, oh, by the way, who will help the teachers learn J what those expensive boxes are m good for? All across the U.S. essentially every school is confronting these questions. A bad decision now can make life hard for lots of folks for a long, long-time. Textbooks are purchased every l-eight years; the last major round of = computer buying was in the Apple II heyda)~ What schools buy today will, most likely, be with them in the year 2000. At least. Some schools k professional consult~ to draw up """"technolq plans."""" While the vices of someone who done that at least o before are, gener~ speaking, worth the c most schools cannot ford consultants. technology budgets c not, typically be use(pay for consultant only for """"boxes."""" Here is our cue: wc computing professi als, can make siguific contributions to q community by help our local school school district deve and implement a 1 soned, coherent techl ogy plan. I am part q group of computer fessionals in Ann Ar who are helping city's schools create b a vision for technol, in education, and a concrete plan-of-action for closure of (and revising, and revising!) that vision. As anyone who has served the public knows, the emphasis in any plan is definitely onprocess. Since it is everyone's money, everyone has a Elliot Soloway right to put in his or her two cents. The result is that it is time consuming-meeting upon meeting with all sorts of individuals in order to seek some form of consensus and buy-in. It is also frustrating-decisions are not necessarily based …"""	co-ment;coherence (physics);computer;consensus (computer science);money;plymouth;token ring;willow	Elliot Soloway	1992	Commun. ACM	10.1145/129902.129909	computer science	Theory	-65.06701593913553	-22.757708800944123	52512
8e8aa3799ff2efc387c0342d2825e5fd1c7d3e05	the mit deliberatorium: enabling large-scale deliberation about complex systemic problems	artificial intelligence collaboration diseases redundancy security business meteorology;deliberation;social networking online humanities;collaboration;large scale argumentation deliberation;artificial intelligent;large scale;redundancy;humanities;complex system;business;social networking online;diseases;artificial intelligence;large scale argumentation;humanity mit deliberatorium large scale deliberation complex systemic problems serious dysfunctions social media large scale argumentation systems;security;meteorology	Humanity now finds itself faced with a range of highly complex problems - such as climate change, the spread of disease, international security, scientific collaborations, product development, and so on - that call upon us to bring together large numbers of experts and stakeholders to deliberate collectively on a global scale. Collocated meetings can however be impractically expensive, severely limit the concurrency and thus breadth of interaction, and are prone to serious dysfunctions such as polarization and hidden profiles. Social media such as email, blogs, wikis, chat rooms, and web forums provide unprecedented opportunities for interacting on a massive scale, but have yet to realize their potential for helping people deliberate effectively, typically generating poorly-organized, unsystematic and highly redundant contributions of widely varying quality. Large-scale argumentation systems represent a promising approach for addressing these challenges, by virtue of providing a simple systematic structure that radically reduces redundancy and encourages clarity. This paper will address this important question, discussing (1) the strengths and limitations of current deliberation technologies, and (2) how large-scale argumentation can help address these limitations.	blog;chat room;concurrency (computer science);deliberatorium;email;interaction;new product development;polarization (waves);social media;wiki	Mark Klein	2011	2011 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2011.5928678	complex systems;computer science;knowledge management;artificial intelligence;information security;management science;redundancy;management;computer security;collaboration	SE	-75.10446267670632	-12.451717494819446	52717
17fb10efd99db6846d33f35ce53032489cd70f87	acm president's letter: is all the world the stage?		"""As some people have said, it's a good thing that the """"A"""" in ACM doesn't stand for """"American."""" Little by little, ACM has become more and more outward-looking, more international. The most recent evi-dences of this were the chartering of two more European chapters, the Belgian Chapter and the Greek Chapter, and the establishment by the Council of a European Region. The Council put off to a future meeting the general question of the degree of internationalization that ACM should undertake, but I want to explore some of the issues here, in the hope that we can get feedback from the membership well ahead of any Council consideration. ACM has always had foreign members. Some European and Canadian members have been very active in ACM for a very long time. Today, 68 countries are represented in the membership. The publications of ACM are found in libraries throughout the world, and contributions to all of our publications are made by people in many countries. Many of our foreign members tell me that the ACM publications are among the most important educational and research sources they have. Our foreign membership is only 9.4 percent of ourtotal membership, but it represents about 2500 people. I have always taken the view that communication between scientists has done at least as much as any other form of communication to bring the people of the world together. The more we hear about the """"brain drain"""" and the """"technology gap,"""" the more important it is to have this communication. On the other hand, there are those who say that ACM has enough problems serving and representing its American members. They say internationalization would dilute our efforts to meet large challenges in this country, e.g. our need to increase membership , our Professional Development program , the Lectureship Series, and assisting the United States government. There are problems, also, with regard to national computer societies in other countries. Are we doing them a favor by establishing a chapter in their country and thus perhaps weakening their influence ; maybe even their chance for survival? Furthermore, ACM is a member of AFIPS, the American Federation of Information Processing Societies. Does it make sense for ACM to belong to an organization which represents the United States in the International Federation for Information Processing (IFIP) and at the same time to have European chapters, a European region, and an international outlook …"""	american federation of information processing societies;international federation for information processing;internationalization and localization;library (computing);microsoft outlook for mac	Bernard A. Galler	1970	Commun. ACM	10.1145/362258.362262	computer science;operations research	Graphics	-68.10790929839705	-16.49692200530689	52751
58820b40b2a56c50e7da65b041e3ee3d074852f6	will semantic web technologies work for the development of icd-11?	international classification of diseases;united nations;world health organization;software systems;information policy;electronic health record;development process;semantic web technology;lessons learned	The World Health Organization is beginning to use Semantic Web technologies in the development of the 11th revision of the International Classification of Diseases (ICD-11). Health officials use ICD in all United Nations member countries to compile basic health statistics, to monitor health-related spending, and to inform policy makers. While previous revisions of ICD encoded minimal information about a disease, and were mainly published as books and tabulation lists, the creators of ICD-11 envision that it will become a multi-purpose and coherent classification ready for electronic health records. Most important, they plan to have ICD-11 applied for a much broader variety of uses than previous revisions. The new requirements entail significant changes in the way we represent disease information, as well as in the technologies and processes that we use to acquire the new content. In this paper, we describe the previous processes and technologies used for developing ICD. We then describe the requirements for the new development process and present the Semantic Web technologies that we use for ICD-11. We outline the experiences of the domain experts using the software system that we implemented using Semantic Web technologies. We then discuss the benefits and challenges in following this approach and conclude with lessons learned from this experience. 1 The International Classification of Diseases—A New Beginning The International Classification of Diseases (ICD) is the standard diagnostic classification developed by the World Health Organization (WHO) to encode information relevant for epidemiology, health management, and clinical use. Health officials use ICD in all United Nations member countries to compile basic health statistics, to monitor health-related spending, and to inform policy makers. ICD is one of the most important classifications used for health care all over the world. ICD is created by a large collaborative effort among international medical experts. To keep up to date with scientific findings about diseases and to address new uses of the classification, the WHO publishes revisions of the classification approximately every decade. In 2007, the WHO started work on the 11th revision of ICD (ICD-11). Our group is working closely with the WHO to support the collaborative development of ICD-11. The new requirements for ICD-11, which we describe in Section 3, call for a complete revamping of the classification representation in order to build a more solid and flexible formal foundation. ICD-11 will use OWL as the underlying representation language. The workflow for the new development process is also going to change fundamentally. The process will become a Web-based open process that is powered by collaboration and social features. This paper makes the following contributions: – We analyzed the representational and functional requirements for supporting the new collaborative workflow for the development of ICD-11 (Section 3). – We developed a customization of WebProtégé, a Web-based version of Protégé, to support distributed collaborative development of ICD-11 (Section 4). – We performed a formative evaluation of the tool (Section 5). – We analyzed lessons learned and the challenges and advantages of using Semantic Web technologies for the development of large medical terminologies (Section 6). 2 ICD History, Use, and Development ICD traces its origins to the 19th century. The initial work on disease statistics actually began in the 16th century with the London Bills of Mortality that listed the number of burials as a warning against the onset of the bubonic plague. The London Bill of Mortality enumerated 81 causes of death and it is the predecessor of international mortality classifications.1 Several governments and health organizations recognized the importance of this classification and became interested in it. In 1948, the World Health Organization (WHO) took over the responsibility for ICD and its creation and included for the first time the causes of morbidity, in addition to classifying causes of mortality.2 Since then, ICD underwent revisions approximately every decade. The current revision of ICD, ICD-10, contains more than 20,000 terms and is used in over 100 countries around the world. ICD-10 is available in the six official languages of WHO (Arabic, Chinese, English, French, Russian, and Spanish) as well as in 36 other languages [11].	book;capacitor plague;coherence (physics);compiler;encode;functional requirement;multi-purpose viewer;multiple inheritance;onset (audio);ontology (information science);protégé;resource description framework;semantic web;software system;table (information);tracing (software);web ontology language;wish list	Tania Tudorache;Sean M. Falconer;Csongor Nyulas;Natalya Fridman Noy;Mark A. Musen	2010		10.1007/978-3-642-17749-1_17	computer science;knowledge management;artificial intelligence;data science;data mining;database;world wide web;software development process;software system	Web+IR	-68.33293260404623	-19.23239262571216	52836
23d06ad88e8adfe174da5e3c73d25533aa053b77	cc2020-what it is and why you should care		"""In 2005, the ACM, in collaboration with the Association for Information Systems (AIS) and the Computer Society (IEEE-CS), published """"Computing Curricula 2005: The Overview Report"""" (CC2005)1, which was a """"Guide to Undergraduate Degree Programs in Computing"""", including undergraduate degree programs in Computer Engineering, Computer Science, Information Systems, Information Technology, and Software Engineering. This document has been widely distributed, and has been reported to be very helpful in its goal to """"provide perspective for those in academia who need to understand what the major computing disciplines are and how the respective undergraduate degree programs compare and complement each other."""" In 2015, the ACM recognized the need to update this document, and formed a task force for CC2020, intended to be a forward-looking update of the original CC2005 document. All relevant bodies of computing professionals (see Table 1) were included in a multi-national endeavor. This task force has been underway for several months, and a timeline has been set that will allow this update to be completed in 2020."""	association for information systems;computer engineering;computer science;information system;software engineering;timeline	Barry M. Lunt;MA YiselAlonzo	2018		10.1145/3241815.3241830	engineering management;curriculum;knowledge management;information system;timeline;engineering;information technology	SE	-63.71789143340838	-16.3173175577287	52864
a75aa3d029ee957f657b133ae01c85736cc8476c	looking ahead	dental assistants	'I 've always had a high profile within the RCN so a lot of people think they know me,' says Mike Hayward, shortly after taking up his new role as RCN professional nurse adviser to the acute sector. 'The thing is, very few do!'		Andreas I. Nicolaou	2004	Emergency nurse : the journal of the RCN Accident and Emergency Nursing Association	10.1016/j.accinf.2010.12.001		HCI	-64.31601500883808	-23.431832429056907	52900
19e4e9070d1c3387106e6ab3a19065a7b7e973da	concerns about the consequences of patenting on scientometric research			scientometrics	Antonio Vezzani;Alex Coad;Petros Gkotsis	2017	JASIST	10.1002/asi.23762	data mining;computer science;data science;social science	Crypto	-75.45305272487346	-18.000019016746094	52949
9c87164c99ed325ffb0992969e1353e1467c6d6e	on the utility of lay summaries and ai safety disclosures: toward robust, open research oversight		In this position paper, we propose that the community consider encouraging researchers to include two riders, a “Lay Summary” and an “AI Safety Disclosure”, as part of future NLP papers published in ACL forums that present user-facing systems. The goal is to encourage researchers–via a relatively non-intrusive mechanism–to consider the societal implications of technologies carrying (un)known and/or (un)knowable long-term risks, to highlight failure cases, and to provide a mechanism by which the general public (and scientists in other disciplines) can more readily engage in the discussion in an informed manner. This simple proposal requires minimal additional up-front costs for researchers; the lay summary, at least, has significant precedence in the medical literature and other areas of science; and the proposal is aimed to supplement, rather than replace, existing approaches for encouraging researchers to consider the ethical implications of their work, such as those of the Collaborative Institutional Training Initiative (CITI) Program and institutional review boards (IRBs).	natural language processing;open research;speculative execution	Allen Schmaltz	2018			natural language processing;knowledge management;artificial intelligence;computer science;open research	NLP	-71.65652566894858	-15.648797422615027	53034
bbc6a7e1a63b197a569bdd6b5658f9397e2b96db	an approach to facilitating communication of expert arguments through visualisation	new technology;logical framework;flexible learning;risk analysis;computer model;distributed computing;data fusion;internet technology;computational models;uncertainty analysis;argument visualization;semantic web;spatial analysis;expert judgment;nuclear waste	Many public issues, such as environmental actions, involve a large number of diverse stakeholders such as governments, corporations, organizations (e.g. NGOs), and concerned citizens. Discussions frequently become contentious as the stakeholders defend their potentially conflicting goals with various assumptions, views, and expert testimony. These issues also tend to involve a range of fields. For example, the disposition of nuclear waste includes issues of economics, science, engineering, politics, and intergenerational justice, each with large uncertainties due to dependences on indirect estimations and the long time periods involved. At the same time that these complex issues might increase in number, due to applications of new technologies, tools are being developed on the Internet to enable flexible learning, visualization, collaborative conferencing, distributed computing, and meaning‐based (semantic) context. These tools might enable improved techniques for debating and discussing these complex iss...	scientific visualization	David J. LePoire	2006	J. Inf., Comm, Ethics in Society	10.1108/14779960680000279	computer simulation;logical framework;uncertainty analysis;risk analysis;computer science;knowledge management;semantic web;data mining;sensor fusion;spatial analysis;management science;computational model;radioactive waste	NLP	-76.8562308105207	-14.042678370502074	53182
bf42dc91020fe5df5b52df6f510f3b3a07ba9584	g. midgley and a.e. ochoa-arias, editors, community operational research - or and systems thinking for community development, kluwer academic/plenum publishers, ny (2004), isbn 0-306-48335-1	operations research;community development;systems thinking	This is the recent book published in the series: Contemporary Systems Thinking, under the editorship of Robert L. Flood. Gerald Midgley is Senior Associate in the Institute of Environmental Science and Research, New Zealand, and affiliated to the Centre for Systems Studies in the Business School, University of Hull, UK. Alejandro E. Ochoa-Arias is an Associate Professor in the Centre for Interpretive Systemology, University of Los Angeles, Venezuela. This book is a collection of fourteen papers communicating the meaning of Community Operational Research. In 1986, Jonathan Rosenhead being the President of the OR Society launched the initiative to take OR into the arena of community work. This motivated an OR practice that was more participative, personally reflective and socially committed. In addition, this OR practice has also been of special importance in the development and applications of the so-called Soft OR methods. During the 1990s, the engagement in the UK with Community OR was stabilised, and in the beginnings of the 21st Century was gradually spread to other countries—most notably in the developing regions of the World. Leading Community OR writers, with international reputation in OR and Systems Thinking, have contributed to this volume that illuminates different aspects of Community OR theory and practice. 2.	gerald weinberg;international standard book number;operations research;personally identifiable information;robert	René Victor Valqui Vidal	2006	European Journal of Operational Research	10.1016/j.ejor.2005.01.001	regional science	DB	-63.571999980301314	-14.371427798184953	53189
028a48953998dd758d6e36d6f3cd57055cd686f7	the future of security nominal delivery draft, rocky mountain information security conference, 18 may 2012		Dan Geer is the CISO at In-Q-Tel and likes to list the following milestones: the X Window System and Kerberos (1988), the first information security consulting firm on Wall Street (1992), convenor of the first academic conference on electronic commerce (1995), the “Risk Management Is Where the Money Is” speech that changed the focus of security (1998), the Presidency of the USENIX Association (2000), the first call for the eclipse of authentication by accountability (2002), principal author of and spokesman for “Cyberinsecurity: The Cost of Monopoly” (2003), co-founder of SecurityMetrics. Org (2004), convener of MetriCon (2006– present), author of “Economics & Strategies of Data Security” (2008), and author of “Cybersecurity & National Policy” (2010). Creator of the Index of Cyber Security (2011) and the Cyber Security Decision Market (2011). Six times entrepreneur. Five times before Congress. dan@geer.org Good afternoon, all. Thank you for the invitation to be here today. I remind you that, as always, I speak for myself.	authentication;computer security;consultation;cyber security standards;data security;e-commerce;eclipse;information security;kerberos;money;monopoly;risk management;x window system	Dan Geer;Douglas Adams	2012	;login:			Crypto	-68.95965442382636	-10.967305766167861	53272
48e65e21719f9ec668ccb4217ea73e5fa0d6119b	transforming the structure of network interconnection and transport	computers and society;wide area network	"""Regulatory policy in telecommunications is desperately in need of midlevel theory. There is widespread consensus that regulators should try to promote competition, but there is also bitter contention about what this implies for particular industry contest. As one industry observer stated, """"Competition should be the policy. And code that enables competition should be the rule.""""1 But this same observer also argued that the Federal Communications Commission (""""FCC"""") should regulate and require AT&T to allow customers to choose the internet service provider (""""ISP"""") that furnishes service over AT&T's cable facilities.2 A pro-competition policy based solely on the premise that competition is good is fundamentally flawed, since it advocates a competition policy without analysis of the different structural possibilities for competition. Hence, """"competition"""" becomes merely a rhetorical device. Policymakers must not considerjust the costs of promoting competition, but also the profound implications on the industiy structure. This is true regardless of whether the policy to be considered is mandating sub-loop unbundling, requiring line-sharing or allowing the use of unbundled network elements (""""UNEs"""") for the provision of leased lines. Regulators must make strategic choices among different structural possibilities that will promote competition. 3 The common view that deregula-"""	business architecture;collocation;interconnection;internet;leased line;resource contention;sub-loop unbundling;web service	Douglas A. Galbi	2000	CoRR		telecommunications;computer science;operations management;management;operations research;computer security	ML	-71.41332483031742	-12.441141706217474	53274
7505574d3d1790ce8c21c034883f6fb1e859dfca	assessment of scientific profiles and capabilities of ph.d. programs in chile: a scientometric approach	america del sur;scientometrics;universite;metodologia;indicator;enseignement superieur;indicateur;amerique;south america;educational program;graduate level education;methodologie;ensenanza superior;scientometria;molecular biology;programme enseignement;indicador;scientometrie;evaluation;chili;university;evaluacion;methodology;america;universidad;programa ensenanza;internal standard;chile;amerique du sud	It is well known that the quality of a doctorate program is related to the level of involvement of its faculty in research. Thus, we worked with the hypothesis that postulates that if the in-house scientific output of the core faculty involved in a Ph.D. program can be appraised in such a manner that the achievements render quantitative and qualitative indicators, it is possible to depict profiles amenable for comparisons. We describe the methodology, that uses performance scientometric indicators, and results obtained after studying five Ph.D. programs in the field of Cell and Molecular Biology/Biochemistry in three different Chilean universities and show that the approach serves to portray the in-house capacity of each programvis a vis national and international standards.	scientometrics	Manuel Krauskopf;María Inés Vera	1997	Scientometrics	10.1007/BF02459301	scientometrics;computer science;evaluation;methodology;internal standard;operations research	HPC	-75.46556047262928	-23.50046636666932	53403
4385820cd1fa6e626f68118daf8e81f268b26048	towards efficient stabilizing code dissemination in wireless sensor networks	qa76 electronic computers computer science computer software	Copyright and reuse: The Warwick Research Archive Portal (WRAP) makes this work of researchers of the University of Warwick available open access under the following conditions. Copyright © and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners. To the extent reasonable and practicable the material made available in WRAP has been checked for eligibility before being made available.	archive	Sain Saginbekov;Arshad Jhumka	2014	Comput. J.	10.1093/comjnl/bxt110	real-time computing;computer science;operating system;database;distributed computing;computer security;algorithm	AI	-67.05135149320519	-17.5122318066519	53423
c86c146d842b88ee48cf73c2885b3eb5082cc493	reviewing the gatekeepers: a survey of referees of library journals	library science	A survey of referees of scholarly journals in librarianship was conducted to gather information on refereesu0027 practices and attitudes, their perceptions of their role in the editorial process, and background information that might reveal relevant information on experience and qualifications for serving as a referee. One hundred ninety-nine surveys were mailed to referees and 121 responses were returned. The responses indicated that half the referees do not work with a formal evaluation criteria guideline but consistently regard validity of claims and originality as the two categories on which most emphasis is placed when reviewing a manuscript. Overwhelming support was expressed for returning comments to submitting authors but a curiously high number of referees do not know if this is the journal editoru0027s practice. Furthermore, approximately 75% of the referees were uninformed by the editor of a reviewed manuscriptu0027s final disposition. The majority of referees for scholarly journals in librarianship are employed in academic libraries and schools of library and information science, hold a position of responsibility in a professional association and are successful in publishing articles in librarianship. © 1988 John Wiley u0026 Sons, Inc.		Stuart Glogoff	1988	JASIS	10.1002/(SICI)1097-4571(198811)39:6%3C400::AID-ASI3%3E3.0.CO;2-Q	library science;social science;information science;computer science;inquiry;sociology;management;operations research;law;world wide web	Logic	-74.35751330264125	-19.7395325261126	53506
183e078767a6069e8ac5f6be0e809a3aeb92e252	successful e-business systems - paypal	payment system	PayPal is an account-based system that allows anyone with an email address to send and receive online payments. This service is easy to use for customers. Members can instantaneously send money to anyone. Recipients are informed by email that they have received a payment. PayPal is also available to people in 38 countries. This paper starts with introduction to the company and its services. The information about the history and the current company situation are covered. Later some interesting and different technical issues are discussed. The Paper ends with analysis of the company and several future recommendations.	email;merchant services;money;online and offline;scalability;usability	Archil Avaliani	2004	CoRR		electronic money;computer science	ECom	-66.01002285655126	-22.587703307055307	53684
79ad163d140d9bcf42673bc7360df597e7d634e0	influence of human behavior and the principle of least effort on library and information science research	library and information science;citation context;principle of least effort	This study identified the influence of the main concepts contained in Zipf’s classic 1949 book entitled Human Behavior and the Principle of Least Effort (HBPLE) on library and information science (LIS) research. The study analyzed LIS articles published between 1949 and 2013 that cited HBPLE. The results showed that HBPLE has a growing influence on LIS research. Of the 17 cited concepts that were identified, the concept of “Zipf’s law” was cited most (64.8%), followed by “the principle of least effort” (24.5%). Although the concept of “the principle of least effort,” the focus of HBPLE, was not most frequently observed, an increasing trend was evident regarding the influence of this concept. The concept of “the principle of least effort” has been cited mainly by researchers of information behavior and served to support the citing authors’ claims. By contrast, the concept of “Zipf’s law” received the most attention from bibliometrics research and was used mainly for comparisons with other informetrics laws or research results. © 2015 Elsevier Ltd. All rights reserved.	bibliometrics;embedded system;futures studies;information behavior;informetrics;library and information science;zipf's law	Yu-Wei Chang	2016	Inf. Process. Manage.	10.1016/j.ipm.2015.12.011	computer science;information retrieval	AI	-77.23910536626111	-20.237766547702215	53830
38382a7fd31bf522735ae44c4258507381f1c20c	flocks, herds, and stories temporal coherence and the long tail	narrative;web;browsing;herds;flocks;ws92 theory of groups;ws32 architectures;web science 2011;ws1 computer science;hypertext	New media offer an unprecedented opportunity to revise our literary economy. One crucial anxiety is that we be able to find (and to publish) good work of local or specific importance, since much human knowledge is not popular. Small, low-traffic sites are thus of considerable interest to the health of the Web, though individually these sites possess small economic leverage. The challenge these sites face is increased by the noisiness of web traffic; herds, flocks, and cadres of narrative-driven fans can all increase traffic one day and eliminate it another. For large sites, this poses no problem, but for smaller sites this granularity, combined with the zero lower bound, can have catastrophic consequences both for individual publications and for the overall shape of the Web.	coherence (physics);flocking (behavior);long tail;new media;web traffic;world wide web	Mark Bernstein	2011		10.1145/2527031.2527059	simulation;engineering;operations management;communication	ECom	-74.76825905833282	-14.930725578301683	53864
c84965f1c9c96b25f2ba61e277acf3311acc5a07	water management: sacrificing normative practice subverting the traditions of water apportionment - 'whose justice? which rationality?'	water management;mirab;holistic thinking;technological development;normative practice;modernism	Since current water governance patterns mandate cooperation and partnership within and between the actors in the hydrosystems, supplementary models are necessary to distinguish the roles and the rules of indoor actions which is why we extend a theory in the frameworks of philosophy of technology. This analysis is empirically grounded on the problematic hydrosystems of a river in central Iran, Zayandehrud. Following a modernist-holistic-based analysis, it illustrates how values in the water apportionment mechanisms are being reshaped. The article by using the theory of normative practice has scrutinised the tasks and the rules of the old and new water-management systems, Mirab. Subsequently according to such philosophical theory, it has argued that the conflicts over the cases are due to interference of structural and directional norms within them.	achievement;allocation;anisotropy;coherence (physics);collective operation;concordance (publishing);conflict (psychology);droughts;engineering;holism;interference (communication);map;maxillary right central incisor abutment;norm (social);normative social influence;rationality;recommender system;revision procedure;rule (guideline);societies;tension;timeline;value (ethics);vision;xfig;interest;standards characteristics	Mehdi F. Harandi;Mahdi G. Nia;Marc J. de Vries	2015	Science and engineering ethics	10.1007/s11948-014-9593-1	psychology;social science;philosophy;computer science;engineering;sociology;management;social psychology;law;modernism	SE	-77.07526795793355	-12.207496492265191	53935
f94b44c6074de1f6241800701a1b48dd5f3a319b	book review: editor's message		phenomenon of the Internet--gives birth to a litter of social issues crying out for discussion. Publishers, especially MIT Press, continue to respond with more books than I can possibly read. I'll happily pass these along to potential reviewers. Without exactly formulating a policy, I notice that the books I offer for review seem to expire after three years. Those listed below, for instance, all have copyright dates of 1996 or later. In effect, I have developed a moving window three years wide. If a copyright does not fall within this window, I remove it from the list of available titles. What is interesting to me about this, is that I have come to think of books on the social impact of computing that are more than three years old as out of date. I may be wrong here, but imagine a book three years old discussing privacy issues on the Internet. If it has a copyright date of 1995, it was probably written in 1993 and 1994 and relies upon research completed a year or two before that. That makes it roughly contemporary with Tim Berners-Lee's development of code for the World Wide Web, and so well out of date at least gauged by the privacy issues that the Web itself raises. On the other hand, a book that I have offered for review in previous issues, Adam Drozdek's Moral Dimension of Man in the Age of Computers presumably has a longer shelf life since it addresses issues having to do with computing in general and not just with a particular implementation. Longer shelf life or not, however, no reader of Computers and Society has asked to review it and so I have removed it from the offerings. There's a lesson here at least part of which is that I have unconsciously and--to this point--uncritically accepted the whoosh of events that define computing. Was there ever a field that so brazenly drove its cart over the bones of the dead (to paraphrase William Blake)? Books that I have recently received include:	book;computer;internet;privacy;world wide web	Paul De Palma	1998	SIGCAS Computers and Society	10.1145/298972.606111	sociology;public relations	Web+IR	-63.26094034132295	-21.652947946545662	54045
48afbca6af4043cfc0ff4e149639ce2ad6322f5a	addressing the corrections crisis with software technology	software technology corrections technology reliability technology;gestion crisis;reliability;incarceration rates;justice;drugs costs turning;software engineering;prisons;carcel edificio;prison building;corrections technology;error correction;rampant overcrowding;gestion crise;reliability technology;rampant overcrowding software technology correctional facilities prisons incarceration rates;crisis management;software technology;cost benefit analysis;justicia;correctional facilities;prison bâtiment;public administration	More than 2.3 million people currently live in US prisons or jails, 25 percent of the world's total inmate population, a comparatively much higher rate than in other Western countries. Denmark only incarcerates 66 of every 100,000 citizens, compared to 760 in the US (www.kcl.ac.uk/depsta/rel/icps/worldbrief/world_brief.html). This situation results from tough sentencing policies that focus on drug use and habitual offenders. Over three decades, these policies contributed to high incarceration rates. While most states have stopped enforcing these policies, the legacy remains, with high recidivism rates perpetuating the cycle. This situation has resulted in rampant overcrowding, with facilities operating at levels above design capacity and inmates frequently housed on bunks in recreational areas. Faced with rising costs and rampant overcrowding, correctional facilities are turning to software technologies for help.		Patricia O'Hagan;Edward Hanna;Roy Sterritt	2010	Computer	10.1109/MC.2010.29	error detection and correction;cost–benefit analysis;justice;reliability;management;law;computer security;statistics	HCI	-72.12388883412537	-12.844248897984398	54174
a66caede25aa7426657e28dab1a3b692ec0650a1	university of british columbia	executive certificate;proposed interdisciplinary master;master s-level program;interdisciplinary hci institute;british columbia;largest university;new downtown campus;educational option;hci teaching;graduate degree	The University of British Columbia is the largest university in western Canada, with an enrollment of 35,000 students and offerings of both undergraduate and graduate degrees. An interdisciplinary HCI institute supports HCI teaching and research and is coordinating a proposed interdisciplinary master of science degree in HCI. A new downtown campus will offer a range of educational options in HCI, from executive certificates through master's-level programs.	columbia (supercomputer);human–computer interaction	Brian D. Fisher	2002	Interactions	10.1145/505103.505117		HCI	-63.12433438139706	-15.805664481319234	54195
4de7069dd533b7fd165bd0c05811283ba74f512c	expert internet searching	search engines;internet	LEARNED PUBLISHING VOL. 27 NO. 2 APRIL 2014 nical aspects can be viewed as both a strength and weakness. A couple of examples include discussion of data mining, and databases. Some may welcome the amount of detail and technical discussion, others may not. It seems to me that most readers of this book can pick and choose what interests them pursuant to their own individual needs. What I like most of all is that this work approaches copyright from a global perspective, and from that standpoint, it helps to tie things together because copyright is truly a global issue. Copyright and Mass Digitization is a work that should be a part of all copyright practitioners’ libraries as a valuable reference. Readers can fi nd additional information and the means to do further research via the extensive sources cited by the authors. In some instances, the footnotes read as supplementary text to the main work. I highly recommend and advise the addition of this book as a necessary piece of any copyright attorney’s or educator’s bookshelf.	data mining;database;library (computing);mass effect trilogy	Cindy Clark	2014	Learned Publishing	10.1087/20140211	the internet;internet research;computer science;sociology;internet privacy;law;world wide web;information retrieval;search engine	ML	-68.23373538484694	-22.276066034841712	54219
af5c1c2a0df787a9a3bbacf810442d1d8c2eeb4c	cwts crown indicator measures citation impact of a research group's publication oeuvre	digital library	The article “Caveats for the journal and field norm alizations in the CWTS (“Leiden”) evaluations of research performance”, published by Tobias Opthof and Loet Leydesdorff (Opthof & Leydesdorff, 2010), denoted as O&L below, deals with a subject as important as the application of so called field normalized in icators of citation impact in the assessment of research performance of individual re sea chers and research groups. Field normalization aims to account for differences in ci tation practices across scientificscholarly subject fields.	crown group;loet leydesdorff	Henk F. Moed	2010	J. Informetrics	10.1016/j.joi.2010.03.009	digital library;social science;computer science;data science;data mining;operations research;world wide web	HCI	-77.0445306674716	-21.34989322790097	54253
126b499d3b3b0ffd4b4687df549aa6ef6fda9488	characteristics shared by the scientific electronic journals of latin america and the caribbean	electronic journal;search engine;if information transfer protocols formats techniques;latin america and the caribbean;hn e journals;scholarly publishing;eb printing electronic publishing broadcasting;hi electronic media;small samples;hq web pages;hh audio visual multimedia;bi user interfaces usability;array;quality criteria;latin america;electronic publishing;latin american;user interaction;ie data and metadata structures;ig information presentation hypertext hypermedia	Our objective is to analyze the use that Latin American peer-reviewed journals make of the tools and opportunities provided by electronic publishing, particularly of those that would make them evolve to be more than “mere photocopies” of their printed counterparts. While doing these, we also set out to discover if there were any Latin American journals that use these technologies in an effective way, comparable to the most innovative journals in existence. We extracted a sample of 125 journals from the LATINDEX – Regional System of Scientific Journals of Latin America, the Caribbean, Spain and Portugal – electronic resources index, and compared along five dimensions: (1) Non-linearity, (2) use of multimedia, (3) linking to external resources (“multiple use”), (4) interactivity, and (5) use of metadata, search engines, and other added resources. We have found that very few articles in these journals (14%) used non-linear links to navigate between different sections of the article. Almost no journals (3%) featured multimedia contents. About one in every four articles (26%) published in the journals analyzed had their references or bibliographic items enriched by links that connected to the original documents quoted by the author. The most common form of interaction was user!journal, in the form of question forms (17% of journals) and new issue warnings (17% of journals). Some, however (5%) had user!user interaction, offering forums and response to published articles by the readership. About 35% of the journals have metadata within their pages, and 50% offer search engines to their users. One of the most pressing problems for these journals it the wrong use of rather simple technologies such as linking: 49% of the external resource links were mismarked in some way, with a full 24% being mismarked by spelling or layout mistakes. Latin American journals still present a number of serious limitations when using electronic resources and techniques, with text being overwhelmingly linear and underlinked, e-mail to the editors being the main means of contact, and multimedia as a scarce commodity. We selected a small sample of journals from other regions of the world, and found that they offer significantly more non-linearity (p = 0.005 < 0.1), interactive features (p = 0.005 < 0.1), use of multimedia (p = 0.04 < 0.1) and linking to external documents (p = 0.007 < 0.1). While these are the current characteristics of Latin American journals, a number of very notable exceptions speak volumes of the potential of these technologies to improve the quality of Latin American scholarly publishing.	email;interactivity;latindex;non-repudiation;nonlinear system;photocopier;printing;web search engine	Saray Córdoba;Rolando Coto	2008			computer science;latin americans;multimedia;advertising;electronic publishing;world wide web	HCI	-68.5518411450332	-21.970332381762727	54261
4c611e64fc035d11e8eab52a44c16d71574752f4	software carpentry: getting scientists to write better code by making them more productive	software engineering software development course software carpentry;undergraduate education;computation in undergraduate education;software engineering;physics education;continuing education;programming profession debugging world wide web open source software java computer science physics ethics teamwork portable computers;software development course;computer science education;software development;software engineering computer science education;software engineering physics education computation in undergraduate education continuing education;open source;software carpentry	"""For the past years, my colleagues and I have developed a one-semester course that teaches scientists and engineers the """"common core"""" of modern software development. Our experience shows that an investment of 150 hours-25 of lectures and the rest of practical work-can improve productivity by roughly 20 percent. That's one day a week, one less semester in a master's degree, or one less year for a typical PhD. The course is called software carpentry, rather than software engineering, to emphasize the fact that it focuses on small-scale and immediately practical issues. All of the material is freely available under an open-source license at www.swc.scipy.org and can be used both for self-study and in the classroom. This article describes what the course contains, and why"""	open-source license;open-source software;software development;software engineering	Greg Wilson	2006	Computing in Science & Engineering	10.1109/MCSE.2006.122	computational science;personal software process;computing;simulation;software engineering process group;computer science;social software engineering;component-based software engineering;software development;software engineering;software walkthrough;physics education;software peer review	SE	-64.19907143599346	-22.240986809013695	54394
00e30a16e7a87c382d3c3ebf4e072e365d78ab89	comparing webometric with web-independent rankings: a case study with german universities	netzwerk;bundesrepublik deutschland;korrelation;universitat;measurement;webometrics;digital library;ws3 web engineering;information network;website;federal republic of germany;link analysis;ranking;messung;web science 2011;university;ws1 computer science;correlation;szientometrie bibliometrie informetrie;prestige;network;scientometrics bibliometrics informetrics	In this paper we examine if hyperlink-based (webometric) indicators can be used to rank academic websites. Therefore we analyzed the interlinking structure of German university websites and compared our simple hyperlink-based ranking with official and web-independent rankings of universities. We found that link impact could not easily be seen as a prestige factor for universities.	hyperlink	Mark Thamm;Philipp Mayr	2011	CoRR		digital library;link analysis;webometrics;ranking;computer science;mathematics;operations research;world wide web;correlation;measurement;statistics	NLP	-76.66855965460522	-21.45359824326002	54607
5650342ddff5ab2554ad3d644017c9681af217f7	editorial: e-learning and human-computer interaction: exploring design synergies for more effective learning experiences	human computer interaction	1 ISSN 1436-4522 (online) and 1176-3647 (print). © International Forum of Educational Technology & Society (IFETS). The authors and the forum jointly retain the copyright of the articles. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear the full citation on the first page. Copyrights for components of this work owned by others than IFETS must be honoured. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from the editors at kinshuk@ieee.org. E-learning and Human-Computer Interaction: Exploring Design Synergies for more Effective Learning Experiences	human–computer interaction;international standard serial number;synergy	Alan J. Dix;Teresa Roselli;Erkki Sutinen	2006	Educational Technology & Society		knowledge management;computer science;carbon fibers;pyrolytic carbon;human–computer interaction;carbon;composite number	HCI	-64.71645410256536	-16.76711803390562	54708
dc40246677bae255fe8a75f3122773b8df5e8ca8	authorship of papers dealing with different subjects in an agricultural journal	analyse bibliometrique;agricultura;auteur;agriculture;bibliometric analysis;author;article	Themes traites par les articles publies dans le «Journal of Agricultural Research» de 1958 a 1978, comparaison selon que le signataire de lu0027article est un auteur unique ou plusieurs co-auteurs		Catherine Balog	1985	Scientometrics	10.1007/BF02020144	agriculture	Vision	-75.07379612674859	-22.36781498479519	54717
7daef3b04021b07547ad60424c6dd80af65f5ad0	improve student-edited law journals: eliminate the acceptance period		For most scholars, peer review is a necessary and valuable step to publishing research in high-quality academic journals. Submissions to peer reviewed journals are exclusive; only after a manuscript is rejected can an author submit it elsewhere, and if it is accepted, the journal will expect to publish it. These practices are largely turned upside-down at oft-criticized US student-edited law journals (Liptak, 2013). Almost without exception, these journals do not use peer or faculty review. Instead, students alone, with at most 2 years of law school experience, select and edit articles, leading to ‘an embarrassing situation deserving the smirks of disdain it gets from colleagues in the sciences and humanities’ (Austin, 1990). Student-edited law journals also allow unlimited simultaneous submissions. Hence, authors can submit an article to dozens, and if they wish even hundreds, of journals at the same time. Combined with the ease of submitting electronically, simultaneous submissions overwhelm student editors. To make matters worse, authors are provided acceptance periods during which they scramble to leverage – or ‘trade up’ – offers to publish with higher-ranked journals. The more prestigious journals, seeing that the article has received an offer, assume that it must be of reasonably high quality and quickly prioritize it for review. The lower-ranked journals are often left snubbed and empty-handed. These factors (along with the lengthiness of typical law articles) have obliged student editors to find ways to ease their burden while still publishing top articles. Their primary tactic is to rely heavily on author credentials rather than manuscript quality, leading to even more criticism. This piece provides a critical overview of submission policies at student-edited law journals and compares them to policies at literary reviews, which also generally allow simultaneous submissions and do not use peer review. The piece suggests that law journals can learn from literary reviews. Unlike law journals, literary reviews expect immediate acceptance of offers to publish. A small survey undertaken of literary reviews and the experience of a legal journal that allows simultaneous submissions but requires acceptance of offers, the highly ranked Journal of Empirical Legal Studies (JELS), indicate that authors in both fields respect immediate acceptance policies. Eliminating acceptance periods at law journals would arguably transform submissions at student-edited law journals. Authors would be forced to only submit to journals in which they would be pleased to be published (as scholars in other fields do). Put another way, eliminating the acceptance period would optimize matching between journals and manuscripts. Student editors would also receive fewer submissions, giving them more time to focus on manuscript quality. Editors would be encouraged to review manuscripts more carefully, knowing that every manuscript to which an offer was extended would be published.	credential;display resolution;expect	Stewart Manley	2017	Learned Publishing	10.1002/leap.1105	public relations;computer science;media studies;law	Security	-67.04096071949442	-20.02778994343957	54829
bc444dfe3755f5f94e070b1c760de8bc0c3bf1fe	replipri: challenges in replicating studies of online privacy		Presented at RepliCHI2013. Copyright c © 2013 for the individual papers by the papers authors. Copying permitted only for private and academic purposes. This volume is published and copyrighted by its editors. Abstract Replication of prior results has recently attracted attention and interest from the CHI community. This paper focuses on the challenges and issues faced in carrying out meaningful and valid replications of HCI studies. I attribute these challenges to two main underlying factors: (i) a domain of inquiry that simultaneously covers people, social systems, and technology; and (ii) deficiencies in result reporting and data archiving. Using examples from investigations of online privacy, I outline how these challenges manifest themselves in HCI studies. Longitudinal approaches, international collaboration, and sharing of study instruments could help address these challenges.	archive;chi;human–computer interaction;internet privacy;research data archiving;social system	Sameer Patil	2013			simulation;engineering;data mining;social psychology	HCI	-72.1302741068696	-15.03565301646844	55082
de846210da0725e27bddad6ab945a9c83ec573fc	online public access catalogues: characteristics of the literature	analyse bibliometrique;on line processing;periodique coeur;document publie;opac;distribucion geografica;country of origin;library and information science;tratamiento en linea;lengua;automated catalog;auteur;productivite auteur;autor;published document;tongue;repartition geographique;bibliometric analysis;author;productividad autor;traitement en ligne;catalogue automatise;catalogo automatizado;langue;documento publicado;geographic distribution;author productivity;analisis bibliometrico	The paper reports on the characteristics of the OPAC literature as reflected by the two editions of A Classified Bibliography on Online Public Access Catalogues which covered 769 and 1226 unique references respectively. Data was collected on the number of authors and of author productivity, language of publication, format and year of publication, and the countries of origin of the references, as well as on journal productivity. Whenever possible the data was compared with that of other similar studies of library and information science literature		Efthimis N. Efthimiadis	1990	J. Information Science	10.1177/016555159001600205	auteur theory	Crypto	-75.09616929398351	-22.60533684412974	55129
b5f6793759c372533b7cf9300d9377ec22ae651d	the internet as mass medium	internet;higher education;mass media	could not have missed the news stories about the Internet, many of which speculate about its effects on the ever-increasing number of people who are on line. Why, then, have communications researchers, historically concerned with exploring the effects of mass media, nearly ignored the Internet? With 25 million people estimated to be communicating on the Internet, should communication researchers now consider this network of networks’ a mass medium? Until recently, mass communications researchers have overlooked not only the Internet but the entire field of computer-mediated communication, staying instead with the traditional forms of broadcast and print media that fit much more conveniently into models for appropriate research topics and theories of mass communication. However, this paper argues that if mass communications researchers continue to largely disregard the research potential of the Internet, their theories about communication will become less useful. Not only will the discipline be left behind, it will also miss an opportunity to explore and rethink answers to some of the central questions of mass communications research, questions that go to the heart of the model of source-message-receiver with which the field has struggled. This paper proposes a conceptualization of the Internet as a mass medium, based on revised ideas of what constitutes a mass audience and a mediating technology. The computer as a new communication technology opens a space for scholars to rethink assumptions and categories, and perhaps even to find new insights into traditional communication technologies. tion as a whole, in order to place the new medium within the context of other mass media. Mass media researchers have traditionally organized themselves around a specific communications medium. The newspaper, for instance, is a more precisely defined area of interest than printing-pressmediated communiThis paper looks at the Internet, rather than computer-mediated communica	internet	Merrill Morris	1996	J. Computer-Mediated Communication	10.1111/j.1083-6101.1996.tb00174.x	psychology;social science;computer science;mass communication;multimedia;sociology;communication;social psychology;world wide web	Theory	-70.9971055496731	-20.67583463191599	55174
786ef0570f312f24cba7b7eccc1f5aec0adf2c98	charging for a digital library - the business model and the cost models of the medoc digital library	bibliotheque;europa;licencia;allemagne;information sources;edition electronique;project;service information;proyecto;digital library;cooperation;editor;information access;cooperacion;suscripcion;germany;business model;fijacion tarifa;tariffication;licence;edicion electronica;tarification;publisher;acces information;servicio informacion;abonnement;acceso informacion;electronic library;electronic publishing;information service;europe;projet;biblioteca;medoc multimedia electronic document;editeur;subscription;alemania;library;cost model;bibliotheque electronique	MeDoc is a German digital library project bringing together 7 developing institutions and 24 pilot user institutions as well as 12 international publishing houses. MeDoc provides uniform access to a variety of information sources and an information broker service. MeDoc ooers a range of billable digital books and journals contributed by the participating publishing houses. Operating a digital library has not only many technical but also important economical aspects. The contents of a digital library can be regarded as information merchandise just like paper books or journals bought in a book store. In order to encourage publishing houses to contribute their books and journals to digital libraries, suitable business models must be deened. New innovative cost models, like oating licenses or ne grained pay per view, become both necessary and feasible in network based digital libraries. This paper introduces the MeDoc business model and discusses various cost models and their applicability to the services of a digital library. It gives an overview of the MeDoc license and pricing policy and the applied cost models.	book;digital library;e-book;library (computing)	Michael Breu;Ricarda Weber	1997		10.1007/BFb0026739	business model;digital library;project;library;computer science;artificial intelligence;database;electronic publishing;world wide web;computer security;cooperation	DB	-71.57873880305002	-22.64418579465696	55267
679f80fc4b08fea6eb3c2ff74ae67607e12ab669	open innovation challenge in healthcare. role for education		The vision of this paper is that collaboration creates new openings for engagement of non-commercial actors, such as universities, in innovation networks on the one hand, while opening up for collaborative innovation, and getting valuable real life anchors on the other hand, all these underpinned by greater connectivity and globalization. We present our approach in re-designing the courses on medical informatics and data processing to meet these challenges by employing public Internet services and media facilitation.	html element;informatics (discipline);medical informatics;open innovation;real life;universities;web service;facilitation	Rodica Dimitriu;Diana Lungeanu;Cristina Mãnescu;Mirela Pantazi;George I. Mihalas	2015	Studies in health technology and informatics	10.3233/978-1-61499-538-8-91	open innovation;knowledge management;health care;medicine	HCI	-76.1309439691168	-15.226453148745737	55457
528e571bd64afc7201def4b0a416d8d20dcd4b8f	a new concept in protocols: verifiable computational delegation		I used to say that the only thing I can trust is what I can prove, but that was when I was a mathematician and now I’m a cryptographer  (at least part-time) and then of course that no longer holds. I have to trust for instance that factoring is difficult. It  reminds me of a conversation we had about a year ago in the Danish Security Council. Somebody was saying: you know, you don’t  know what to trust these days, I’m very careful when I’m on the phone, I never say anything important on the phone. And I  said I’m much more cautious, I simply never say anything important, you never know.  		Peter Landrock	1998		10.1007/3-540-49135-X_21	database;computer security	Crypto	-63.95401168703319	-21.172987723106967	55479
6e94b494fea42e772e130bc791f5cfc77cefcb50	accessing egypt: making myths and producing web sites in cyber-cairo	aspecto cultural;site web;portail web;information communication technology;cultivo;egipto;ethnography;egypt;accesibilidad;etnografia;usuario;conceptual model;aspect culturel;conception;utilisateur;egyptien;egypte;journal article;portal web;accessibility;web portal;culture;diseno;world wide web;design;user;sitio web;egyptian;ethnographie;cultural aspect;africa;accessibilite;web site;nueva tecnologia informacion comunicacion;technologie information communication;graphic design;afrique	From an anthropological viewpoint, “accessibility” is not so much a technological and design project as it is a cultural construction, a cognitive schema through which graphic designers and technologists imagine audiences and create appropriate graphic designs that will be “accessible” to that audience. The ethnographer's task is the specification of key actors, institutions and discourses active in the making and remaking of accessibility in a given context. In this article, we examine how Egyptian Web producers at the turn of millennium (1999–2001) sought to design Web portals that would allow the “typical” Egyptian to easily access the World Wide Web. We argue, first, that Egyptian Web producers are deeply influenced by national and international discourses that frame IT as a national mission for socioeconomic development. Second, we found that in the absence of clear definitions of the Web audience, Web producers imagined a “typical” Egyptian that contradicted their own experiences of users of the Web...	cairo	M. A. Peterson;I. Panovic	2004	The New Review of Hypermedia and Multimedia	10.1080/13614560512331325991	graphic design;user;design;web standards;computer science;conceptual model;accessibility;web accessibility;multimedia;ethnography;world wide web;culture	Web+IR	-72.19040205673132	-22.263535464472536	55534
09a0b5e5292ff8f4de33f55008ddd8fce3668d81	children of mon mot — documentation of a tira legend of the abui community (eastern indonesia)	pragmatics;art;history;law;games;interviews;documentation	In pre-literate societies, oral tradition is anchored in the landscape, linking it with its inhabitants. The first part of this paper details the documentation of a legend of the Abui community of Alor, Eastern Indonesia. It describes the relationship of the legend with landscape and its functions in the community. We recorded the first version of the legend of the Giant Snake Mon Mot in the community of Tifolafeng in 2003. We combined linguistic, anthropological, geographic, and historical methods with fine arts resulting in a multi-faceted documentation for diverse audience. We have created a range materials from illustrated books, games, to a film documentary, made the raw data available. In the second part of the paper, we lay out our strategy for integration of mechanics of telling and listening, and the mnemotechnic structure of oral tradition with the digital humanities. We also address the need of systematic research into the response of the community, which our approach allows.	book;digital humanities;documentation;faceted classification	Frantisek Kratochvil;Benidiktus Delpada;Rachel Siao;Ng Xiao Yan;Joan M. Kelly;Dang Mai Trang	2016	2016 22nd International Conference on Virtual System & Multimedia (VSMM)	10.1109/VSMM.2016.7863161	documentation;computer science;artificial intelligence;archaeology;law;pragmatics	Robotics	-65.01342568686577	-12.421939402307794	55629
f9e9b401a888e7844c77344959162b4deeb4030a	teaching knowledge organization: educator, employer and professional association perspectives	ciencia informacion;europa;conceptual knowledge;australie;oceanie;enseignement superieur;north america;occupational training;america del norte;amerique du nord;information science;amerique;biblioteconomia;organisation connaissance;bibliotheconomie;higher education;etats unis;organizacion de los conocimientos;estados unidos;association professionnelle;questionnaire survey;ensenanza superior;enquete;asociacion profesional;formacion profesional;royaume uni;united kingdom;reino unido;librarianship;continuous professional development;encuesta;europe;america;science information;professional association;survey;oceania;formation professionnelle;australia;knowledge organization;professional education	This paper describes a study of the teaching of knowledge organization in formal library/information courses. It is based on a questionnaire survey of academic institutions and professional associations in the UK, Australia and the USA, and of employers in various sectors in the UK, and supported by several in-depth interviews with educational specialists, and an analysis of the literature and of course	knowledge organization	John Morgan;David Bawden	2006	J. Information Science	10.1177/0165551506062324	professional development;gerontology;questionnaire;professional association;information science;continuing professional development;higher education;management	NLP	-74.54047314325081	-23.772088583802216	55692
5a8833aa67fbd9530a2e7070878195e07921fe50	special issue: workflow in grid systems	grid system	On 9 March 2004 the Global Grid Forum (GGF) hosted a workshop on the topic of workflow in Grid systems. Our goal in organizing this workshop was twofold. First, we wanted to survey and contextualize the very large spectrum of work already going on within the Grid research community on workflow programming and enactment [1]. Second, and perhaps more importantly, we wished to understand and to articulate the major problems that remain to be solved in this area. If the GGF community can bring some clarity to these outstanding research themes, we may be able to help focus the community on solutions. The fact that the Grid research community has such a strong desire to define the role of workflow in Grid systems may come as some surprise to people in the business world. The Workflow Management Coalition (WfMC) has existed for over 10 years and they have standard reference models, documents and a substantial industry of tools and workflow management support products. Why has the Grid community not adopted these existing standards? While it is not uncommon for the scientific community to re-invent technology rather than purchase existing solutions, there are issues involved in the technical applications of Grid systems that are unique to science and go beyond the models of workflow of the past. For example, in 1996 the WfMC defined workflow as:	grid systems corporation;organizing (structure)	Geoffrey Fox;Dennis Gannon	2006	Concurrency and Computation: Practice and Experience	10.1002/cpe.1019	semantic grid;computer science;workflow management system;drmaa;grid computing	HPC	-63.302027692544016	-17.337517988245896	55769
82240f793a7b8426d02ec46056d8be6b4c8433eb	use and mis-use of supplementary material in science publications	computational biology bioinformatics;editorial policies;algorithms;computer appl in life sciences;microarrays;bioinformatics	Supplementary material is a ubiquitous feature of scientific articles, particularly in journals that limit the length of the articles. While the judicious use of supplementary material can improve the readability of scientific articles, its excessive use threatens the scientific review process and by extension the integrity of the scientific literature. In many cases supplementary material today is so extensive that it is reviewed superficially or not at all. Furthermore, citations buried within supplementary files rob other scientists of recognition of their contribution to the scientific record. These issues are exacerbated by the lack of guidance on the use of supplementary information from the journals to authors and reviewers. We propose that the removal of artificial length restrictions plus the use of interactive features made possible by modern electronic media can help to alleviate these problems. Many journals, in fact, have already removed article length limitations (as is the case for BMC Bioinformatics and other BioMed Central journals). We hope that the issues raised in our article will encourage publishers and scientists to work together towards a better use of supplementary information in scientific publishing.	bmc bioinformatics;electronic supplementary materials;interactivity;journal;management information system;radiology information systems;scientific literature;the globe and mail;citation;mecarzole	Mihai Pop;Steven L Salzberg	2015		10.1186/s12859-015-0668-z	biology;dna microarray;computer science;bioinformatics;operations research	HPC	-67.51961720049748	-19.462466186551044	55857
dfa36ecb66c9bd05863659d675c9f20eba4aff22	a journal's impact factor is influenced by changes in publication delays of citing journals		In this article we describe another problem with journal impact factors by showing that one journal's impact factor is dependent on other journals' publication delays. The proposed theoretical model predicts a monotonically decreasing function of the impact factor as a function of publication delay, on condition that the citation curve of the journal is monotone increasing during the publication window used in the calculation of the journal impact factor; otherwise, this function has a reversed U shape. Our findings based on simulations are verified by examining three journals in the information sciences: the Journal of Informetrics, Scientometrics, and the Journal of the Association for Information Science and Technology.		Dongbo Shi;Ronald Rousseau;Liu Yang;Jiang Li	2017	JASIST	10.1002/asi.23706	information retrieval;computer science;monotone polygon;journal impact factors;scientometrics;citation;impact factor;informetrics;information science	HCI	-76.87585036913244	-20.975928748704458	55917
9b4f79e2820692935ca84f90dc8a682f9fad603b	new customers, new challenges, new structure: realigning support to survive massive growth	emergency response;queue management;information technology;help desk;oregon;support group;community networks;cost effectiveness;economies of scale;efficiency measurement;similarity function;desktop support;decentralization centralization;support function	"""The Community Network was established at Oregon State University as an efficiency measure to provide contractual desktop support. The move of information technology support functions from staff employed by individual departments to a centralized model resulted in immediate, across the board economies of scale. Nevertheless, operationally the Community Network has continued the """"departmental"""" model of support. Currently there are four main desktop support groups and each supports, for the most part, several departments of similar functionality. While this model has traditionally afforded a high comfort level among supported users, recent growth indicates that it is not the most efficient or cost effective solution. Each group performs numerous redundant functions and over time, each group has developed their own set of operational procedures. The result of this """"group independence"""" has made it difficult to respond to critical events with a quick re-shifting of technical staff. The proposed model is a phased revision from the current departmental model to a functional team based model, which eliminates many redundant functions. The first phase, centralization of the help desk and queue management functions, will help eliminate most redundancies allowing us to meet an ever-expanding customer base with fewer new staff hires. It will also provide us with a method to implement uniform operational procedures throughout the groups, giving us more flexibility in staff deployment. In the second phase the departmental teams will be restructured into functional desktop support, application support, and emergency response teams."""	centralized computing;desktop computer;liberum help desk;operational definition;software deployment;technical support	Dave Nevin;Mary A. Brock;Christian J. Sinnett	2005		10.1145/1099435.1099495	simulation;engineering;operations management;operations research	HCI	-69.44046696803059	-18.505646757313496	55932
945cf6cdeada0dc262f86b70a5f17182f237d274	guidelines for a victim: dealing with plagiarism		The subject of this article is how to deal with discovering you have been plagiarized. Each of the following challenges is explained: getting perspective on what may be a stressful and drawn-out process, proving that plagiarism occurred, gathering evidence to establish that you are the true author, dealing with (or not dealing with) the offender, working with your dean or department head to trigger formal and informal complaint mechanisms at the offender’s institution, and dealing with the editors involved.		Robert M. Davison;Malcolm Munro;Detmar W. Straub	2004	CAIS			ML	-64.29155287583245	-21.284805549193013	56004
b0cd230df59b076e2d14c7d12a0b190477495645	introduction to collaboration systems and technology track	general	Teams, Organizations, and, indeed, societies exist to create value that their stakeholders cannot create as individuals. Collaboration means joint effort toward a goal. This minitracks seeks to advance knowledge of the individual, organizational, societal, and technical issues that affect the outcomes attained through collaboration. The papers in this track cut across many application domains industry, academia, military, and government. The papers span the range of scientific enquiry, from the most theoretical to the most applied. The authors take a variety of epistemological perspectives -- logical positivist, interpretivist, criticalist, and engineering approaches all appear in this year's track. This track began a number of years ago with the increased interest in both Group Support Systems and Negotiation Support Systems minitracks. Out of this interest, the Collaboration Systems and Technology Track emerged. It consists of minitracks in eight areas.		Jay F. Nunamaker;Robert O. Briggs	2007	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2007.575		Robotics	-71.59120994486678	-15.852522198646536	56047
c962f4ad48f870246bf04b5aa1683655f9bac358	blending military chain of command with the typical it support model to support the largest dormitory in the world	deck;midshipman;commandant;usna;midshipmen computer repair center mcrc;contractor;dormitory;commandant staff it zone;remedy;web helpdesk;midshipmen information systems liaison officer mislo	"""The Commandant & Staff IT zone within the Information Technology Services Division (ITSD) at the United States Naval Academy in Annapolis, MD provides IT support to a student body of over 4400 individuals (The Brigade of Midshipmen), the Commandant and his staff, and the company officers and senior enlisted leaders responsible for governing their respective Midshipmen companies. The entire Brigade resides in Bancroft Hall, the largest dormitory in the world, which also houses the office space for the support staff and officers. A dormitory of this size presents its own particular challenges technologically as well as logistically. The IT issues presented by the Brigade of Midshipmen are resolved by a support model which includes the use of government employees, contractors, and students who are referred to as Midshipmen Information Systems Liaison Officers (MISLOs) and have been appointed by their senior officers. Using a combination of the military chain of command and ITSD's information technology support model, the Brigade of Midshipmen have all of their IT needs addressed in a timely manner. In addition to this support model, USNA began using the 3rd party application Web Help DeskTM in October of 2010. The transition from the existing RemedyTM ticketing system to a system using approvals and escalations has ensured trouble tickets don't """"fall through the cracks,"""" and are addressed in a timely manner. The use of MISLOs and Web Help Desk has greatly improved the IT process in supporting the Brigade of Midshipmen."""	academy;alpha compositing;information systems;issue tracking system;jim hall (programmer);molecular dynamics;software documentation;web help	David M. Tyler	2012		10.1145/2382456.2382491	simulation;engineering;operations management;operations research	HCI	-67.2535991429494	-16.842941046115186	56074
eea4d518440c0c34b0b0c86c5d033d620d229000	european international academic networking: a 20 year perspective	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	The European international academic networking development from a number of isolated research projects into the current powerful unified system is discussed. The repeated interplay between discipline-oriented activities and generic academic computing are considered. The relationship between the European activities and those in other regions – of course including the US, but also other regions of the world is traced. The current initiatives for Europe to remain amongst the world leaders, not only in speed of network but also in helping spread the geographic reach are discussed. Finally, some conclusions and current barriers to full network usage are presented.		Peter T. Kirstein	2004			library science;engineering;media studies;operations research	HPC	-66.9498649758868	-12.735603994993753	56305
c6d76f6291f78f3b376ad95e69232c874d99c4ac	retraction notices: who authored them?		Unlike other academic publications whose authorship is eagerly claimed, the provenance of retraction notices (RNs) is often obscured presumably because the retraction of published research is associated with undesirable behavior and consequently carries negative consequences for the individuals involved. The ambiguity of authorship, however, has serious ethical ramifications and creates methodological problems for research on RNs that requires clear authorship attribution. This article reports a study conducted to identify RN textual features that can be used to disambiguate obscured authorship, ascertain the extent of authorship evasion in RNs from two disciplinary clusters, and determine if the disciplines varied in the distributions of different types of RN authorship. Drawing on a corpus of 370 RNs archived in the Web of Science for the hard discipline of Cell Biology and the soft disciplines of Business, Finance, and Management, this study has identified 25 types of textual markers that can be used to disambiguate authorship, and revealed that only 25.68% of the RNs could be unambiguously attributed to authors of the retracted articles alone or jointly and that authorship could not be determined for 28.92% of the RNs. Furthermore, the study has found marked disciplinary differences in the different categories of RN authorship. These results point to the need for more explicit editorial requirements about RN authorship and their strict enforcement.	anti-copyright notice;archive;demarcation point;evasion (network security);incidence matrix;list of code lyoko episodes;requirement;stylometry;text corpus;web of science;world wide web	Shaoxiong Xu;Guangwei Hu	2018	Publications	10.3390/publications6010002	knowledge management;public relations;ambiguity;attribution;computer science;discipline	HCI	-74.02682723089512	-16.71776963413808	56323
bb3d6504989775181258d51a7d9a02a01667d1ad	subjectivity in object-oriented systems: workshop summary		Subjectivity in object-oriented systems is a new research area. At this, the first workshop in this area, there was much discussion of fundamental concepts and issues, as well as of perceived needs for subjectivity and models for realizing it. The discussion is summarized here, and a list of issues that were identified during the workshop is presented.		William H. Harrison;Harold Ossher;Hafedh Mili	1995	OOPS Messenger	10.1145/260111.260261	natural language processing;computer science;data science;data mining	NLP	-64.99005024660359	-13.81084010484074	56347
4257d0a788542919bd3542b0be307c3e680d75ff	the structure of scientific collaboration networks in scientometrics	analisis citas;citation analysis;scientometrics;analyse amas;frequency analysis;periodical;research field;frequence;bb bibliometric methods;sci science citation index;dato bibliografico;cooperacion cientifica;analyse citation;periodique;periodico;frecuencia;cluster analysis;scientometria;science citation index;collaborative networks;cooperation scientifique;scientometrie;social network analysis;annees 1978 2004;domaine recherche;scientific cooperation;analisis cluster;campo investigacion;bibliographic data;recherche scientifique;frequency;microstructures;scientific research;donnee bibliographique;investigacion cientifica	The structure of scientific collaboration networks in scientometrics is investigated at the level of individuals by using bibliographic data of all papers published in the international journal Scientometrics retrieved from the Science Citation Index (SCI) of the years 1978–2004. Combined analysis of social network analysis (SNA), co-occurrence analysis, cluster analysis and frequency analysis of words is explored to reveal: (1) The microstructure of the collaboration network on scientists’ aspects of scientometrics; (2) The major collaborative fields of the whole network and of different collaborative sub-networks; (3) The collaborative center of the collaboration network in scientometrics.	citation index;cluster analysis;embnet.journal;frequency analysis;scientometrics;social network analysis	Haiyan Hou;Hildrun Kretschmer;Zeyuan Liu	2007	Scientometrics	10.1007/s11192-007-1771-3	social network analysis;scientific method;microstructure;scientometrics;computer science;frequency;cluster analysis;frequency analysis;operations research;citation analysis;world wide web	ML	-75.1853287063942	-22.36108043250442	56464
c1c73b23b506a58a6598c1d3c91dd75ddee9ee8f	computers and politics in china	universal design;republic of china;ministry of education	Computers in the People's Republic of China can be described solely in terms of their size, operating speed, and other tech nical characteristics which allow easy comparison with computers throughout the world . These examples indicate that this is a particularly narrow perspective for understanding computers and computing policy in China. In this article I have attempted to cull from various sources the available technical details about computing in China . But I have attempted as well to express some of the political and social issues which are salient to a discussion of computers in that vast country . I believe that computing in China is revealing about larger issues in their society and that an understanding of Chinese priorities can teach us as much about ourselves as about the Chinese .	chinese room;computer	Andrew C. Gordon	1979	SIGCAS Computers and Society	10.1145/959310.959314	development economics;universal design;public administration;economic growth	Web+IR	-69.67501198800969	-22.125173979325222	56528
cea1104b94154b8c82686fa9612a2bce00c2c8d5	what user services staff should ask about computer ethics	computer ethics	As technology use explodes on college and university campuses, the number of violations of the campus use policy increases. Immediately, systems administrators realize that the computer use document that took one year to write and two years to get approved by the campus, does not providle the answers to many important questions. The uncertainty that system administrators feel ultimately impacts the user service SW who must deal directly with faculty, stti, and students. One anecdote from a large public university will make this relationship between imprecise computer use policies, system administrators, and user services staff clear, Indiana University first drafted a computer use policy in the late 1980s. Eighteen months later the eight-campus system finally approved the policy. The policy makes no mention of computer games per se, yet during the past academic year a major use of resources at Indiana was the playing of computer games. Students were standing in long lines waiting to use public workstations to finish homework assignments, while many workstations were being used by game players. Faculty complained that they could not log into the central systems, at the same time user system administrators suspected that many logins were being used by game players. User services staff desperately needed an interpretation of the computer use policy regarding game playing, and the system administrators were at a loss. System administrators appealed to the central administration of the computing organization for an interpretation, and received an interpret~tion that only muddied the waters. Without a clear policy to communicate and enforce, user services stafl~ were viewed as inconsistent, unfair, and incompetent. The credibility of system administrators also stiered. The origin of the problem is the fact that computer use policies cannot address all issues in a rapidlly changing technology environment. Consequently, a significant amount of interpretation of computer use policies is necessary. What issues do existing computer policies address? Leslie Burkholder, Carnegie Mellon, has content analyzed computer use policies. Disciplinary action resulting from code violation 79% Respect for the property and privacy rights of other users of the system 71% Respect for software license agreements, copyright and patent laws, etc. 66% Encroaching on other user's fair use of system resources 61% Harassing or annoying other users 58% Use of system or parts of it only for authorized purposes 58% Unauthorized lending accounts, user-ids, passwords 47% Degrading system performance 42% Use of system or parts of if only by …	acceptable use policy;authorization;end-user license agreement;leslie speaker;login;pc game;password;privacy;shattered world;software license;system administrator;workstation	Susan F. Stager	1992		10.1145/143164.143329	public relations;applied ethics;engineering ethics;knowledge management;political science;information ethics;computer ethics	Security	-65.64174108960515	-23.38478557304848	56550
f595d9aa568d8cf769a01e74a9bc1be77cc722ad	editorial: broadening the scope of ijcss				Vladimir B. Bajic;D. Petkov	2003	Int. J. Comput. Syst. Signal		knowledge management;computer science	Theory	-64.34879830281372	-12.491185116419905	56557
68fc41eb6c16e6e8912b2723fdafe4eab7c2b53e	effects of human communication on promoting the use of a web-mediated service: - research study on the japan local network system				Norihito Seki	2015		10.1007/978-3-662-48319-0_12	human communication;local area network;public relations;geography	HCI	-67.06095473146918	-10.46865660918899	56614
d980b540a8c1128a0743f25a3ac8c2abec1d2f5d	guest editorial		"""Colonel John Battelle was an early Ohio industrialist with major interests in the iron and steel industry and subsidiary interest in other metals. His son, Gordon Battelle, developed a consuming interest in industrial research mainly as a result of trying to recover zinc from ores for which the usual roasting process did not work. When Gordon Battelle died in 1923, he left his residual estate to the founding of an institute """"... for the purpose of education in connection with the encouragement of creative and research work and the making of discoveries and inventions ...."""" When his mother, Annie Norton Battelle, died in 1925, she left the bulk of her estate to the institute her son had founded. Battelle Memorial Institute opened its doors for business in 1929. Considering the origins of the institute, it is hardly surprising that the early research was concerned with iron and steel. There was, however, an early diversification into other metals which laid a foundation for future work in the industrial application of exotic metals. The institute grew substantially and steadily, gradually adding staff and facilities in chemistry, physics, and engineering. During World War II, the first involvement with atomic energy began through the Manhattan District. By then the contract research concept was well established and Battelle was working actively to solve problems for industry and government on a cost reimbursement basis. Growth continued after World War II and in the early 1950s new laboratories were started in Europe, one in Frankfurt (BF) and the other in Geneva (BG). Still later, in 1965, the Hanford Laboratories of the AEC became the Pacific Northwest Laboratories (BNW) of Battelle Memorial Institute. This addition brought Battelle essentially to its present state. The worldwide staff exceeds 6100, mainly located at the four laboratories in Columbus, Ohio; Frankfurt, Germany; Geneva, Switzerland; and Richland, Washington. This staff represents highly qualified individuals in substantially all of the academic disciplines: physical and life sciences, metallurgy, engineering, economics, social sciences, etc. In 1974, research was done for literally thousands of sponsors all over the world. Throughout the early years optics at Battelle, as at many other institutions, played primarily a service role. Microscopy, spectroscopy, metallography, and related topics were important tools, but they were not really the subjects of research. There was, of course, one well-known exception in the case of Battelle and that was Xerography. This process was invented by Chester Carlson, but research and development on it were started at Battelle in the mid1940s. This effort, which included a great deal of work on photoconductivity and electrostatic imaging, led eventually to the huge commercial success which Xerography enjoys today. However, until the arrival of the laser with its ability to produce coherent light very conveniently, and holography with its unique features, there was little extensive research in optics at Battelle. In the last 15 years, optics research has become increasingly important at Battelle and currently ranges over a wide variety of optics. Although many independent programs exist, much of the optics activity is centered around three major facilities, the Rattlesnake Mountain Observatory at BNW, the Laser Application Center at the Battelle Columbus Laboratory (BCL), and the CO2 laser facility at BF. The Rattlesnake Mountain Observatory (Fig. 1) is equip-"""		Carl L. Gardner	1999	VLSI Design	10.1155/1999/69323		ML	-64.89420841802702	-19.665708684077757	56629
49e9f76e76a0be67425ce5c1c89a9070f12052a3	humanities 2.0: documents, interpretation and intersubjectivity in the digital age	web 20;social sciences;human sciences;archaeology;collaborative methods;intersubjectivity;hermeneutics;digital humanities;epistemology;web 2 0;text interpretation;sociology	With their focus on documents, interpretation and intersubjectivity, Web 2.0 technologies have surprising analogies with philosophical hermeneutics, including the theory of text interpretation. Philosophical hermeneutics was generalised from Biblical hermeneutics by Dilthey in the 19th century and chosen as an alternative to positivism as a foundation for the epistemology and methodology of the humanities and social sciences. This article explores how Web 2.0 technologies might better meet the needs of social and human sciences than traditional information technologies that are historically bound with logical positivism. Illustrations are provided from archaeology and sociology, two social and human sciences which were early adopters of punched cards and computers.	alex st. john;capability maturity model;computer;digital humanities;independence day: resurgence;interpretation (logic);intersubjectivity;punched card;the offspring;web 2.0	Aurélien Bénel;Christophe Lejeune	2009	IJWBC	10.1504/IJWBC.2009.028090	psychology;digital humanities;social science;computer science;artificial intelligence;sociology;management;web 2.0;hermeneutics;anthropology;pedagogy	HCI	-63.46096343974246	-11.79476489389515	56664
7a0c96bd56fc6845d7b73f892993a41945fb8bc2	the wager		The PortraitPrograms Project grew out of hyperinterdisciplinarianism of the famed Gigabase Sculpture Group,l in turn stimulated by recent cutbacks in government support for the arts. The National Endowment for the Humanities and the National Science Foundation had jointly funded the Gigabase Sculpture Project to foster the literary/musical genre of composing genetic codes for novel organisms. Later, artists trained in recombinant DNA technology designed massive Brancusi-esque statues of living cytoplasmic jelly. However, Art For Art’s Sake objectives of these giblet sculptors were compromised by precautions necessary after discovery of the “Gogol’s-Theorem2 Bomb” that threatened to get loose and jam all DNA replication in the biosphere; not even viruses would have survived. After this setback, the PortraitProgram Group was born, and turned its attention to tinkering with another type of artifact, computer programs. It took as starting point the dawning awareness of crisis in the various sciences of the mind. The fundamental orthodoxy of these “cognitive sciences” identified mental states of a human	biosphere;bricolage;code;cognitive science;computer program;dawning information industry;jam;mental state;mind;recombinant dna	Christopher Cherniak	1986	AI Magazine			PL	-64.97220057004095	-20.376016797695563	56737
4b22372a25a01f3be9c8cd0642fd50fe5c6c638c	quantitative literacy: new website for federal statistics provides research opportunities				Alan R. Tupek;Cathryn S. Dippo	1997	D-Lib Magazine		computer science;data science	ML	-63.361200346911346	-10.471894981208953	56754
f45fc82f8039b953253a0725e0c8f9f5df122bf6	tsallis q-exponential describes the distribution of scientific citations—a new characterization of the impact	web of science;exponential distribution;citations;digital library;institute of scientific information;data analysis;indexation;complex systems;nonextensive entropy	In this work we have studied the research activity for countries of Europe, Latin America and Africa for all sciences between 1945 and November 2008. All the data are captured from the Web of Science database during this period. The analysis of the experimental data shows that, within a nonextensive thermostatistical formalism, the Tsallis q-exponential distribution N(c) satisfactorily describes Institute of Scientific Information citations. The data which are examined in the present survey can be fitted successfully as a first approach by applying a single curve (namely, $$N(c) \propto 1/[1+(q-1)\, c/T]^{\frac{1} {q-1}}$$ with q ≃ 4/3 for all the available citations c, T being an “effective temperature”. The present analysis ultimately suggests that the phenomenon might essentially be one and the same along the entire range of the citation number. Finally, this manuscript provides a new ranking index, via the “effective temperature” T, for the impact level of the research activity in these countries, taking into account the number of the publications and their citations.	formal system;time complexity;web of science;world wide web	Aristoklis D. Anastasiadis;Marcelo Portes de Albuquerque;Márcio Portes de Albuquerque;Diogo B. Mussi	2009	Scientometrics	10.1007/s11192-009-0023-0	exponential distribution;complex systems;digital library;computer science;data science;data mining;data analysis;world wide web;statistics	ML	-76.64736681396187	-21.412933901017798	56773
b4c4bb90bf8a28906f9e4fbeba63d7b7a8143a09	object salience in the division of labor: experimental evidence	grupo de excelencia;decomposability;settore secs p 08 economia e gestione delle imprese;administracion de empresas;experiments;economia y empresa;organization design;grupo a;division of labor	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2015, INFORMS	download;institute for operations research and the management sciences;robot	Marlo Raveendran;Phanish Puranam;Massimo Warglien	2016	Management Science	10.1287/mnsc.2015.2216	division of labour;economics;operations management;management;organizational architecture	Logic	-68.18331104675836	-15.033481080204233	57115
03d4267b9883646bc17d65cf3fa968322bf6f70a	how do people organize their desks? implications for the design of office information systems	information system;automatic classification	"""This paper describes a series of interviews focusing on the way professional and clerical office workers organize the information in their desks and offices. A number of implications for designing """"natural"""" and convenient computer-based information systems are discussed. Two principal claims are made: (1) A very important function of desk organization is to remind the user of things to do, not just to help the user find desired information. Failing to support this function may seriously impair the usefulness of electronic office systems, and explicitly facilitating it may provide an important advantage for automated office systems over their nonautomated predecessors. (2) The cognitive difficulty of categorizing information is an important factor in explaining how people organize their desks. Computer-based systems may help with this difficulty by (a) doing as much automatic classification as possible (e.g., based on access dates}, and (b) including untitled """"piles"""" of information arranged by physical location as well as explicitly titled and logically arranged """"files."""" Several other implications for the design of electronic office systems are discussed, and some differences in how people organize their desks are described."""	categorization;emoticon;failure;information systems;information system	Thomas W. Malone	1983	ACM Trans. Inf. Syst.	10.1145/357423.357430	simulation;computer science;artificial intelligence;machine learning;database;multimedia;management;world wide web;information system	HCI	-69.95408878914478	-22.06100153557867	57134
30cf8de3a1df69b864568dcb97bb126254be67cd	creative and set in their ways: challenges of security sensemaking in newsrooms		Maintaining computer security in an organization requires navigating a thorny landscape of adversaries, devices, and systems. As organizations grow more complex, integrating remote workers and networked, third-party tools, security risks multiply, and become more difficult to fully comprehend. News organizations are exemplary of this type of risk-laden workplace, as they combine the technical and complexity issues typical of bureaucratic systems with the creative, autonomous decision-making of journalists. As more industries face changing labor models, shifting to remote workers and building more of their computing needs on third-party platforms, journalists can serve as a critical early-warning population, a canaryin-the-coal-mine look at the management of cybersecurity in the future of work. As a first step towards building our social-science-based research, we took from organization theory the literature on sensemaking, to study how journalists who work in organizations “make sense” of cybersecurity. After analyzing interviews with a range of journalists with diverse priorities and obligations, and testing for an array of sensemaking frameworks, we found fragmented sensemaking to be pervasive. This is a hazardous condition for security in a networked organization, because such a framework correlates with misaligned and scattered behaviors. We conclude with a discussion of questions that emerged during this study, and propose next steps in research.	autonomous robot;complexity;computer security;entrepreneurial network;network-centric organization;organizational behavior;pervasive informatics;sensemaking	Elizabeth Anne Watkins;Mahdi N. Al-Ameen;Franziska Roesner;Kelly Caine;S Elizabeth McGregor	2017			computer science;sensemaking;management science;knowledge management	HCI	-73.50259620890269	-10.508309826899708	57210
38e8836472992f3401dfb85787838251752eb4da	u.s. academic libraries: understanding their web presence and their relationship with economic indicators	online catalogs;universities;web based indicators;webometrics;articulo;economic variables;digital collections;academic libraries;repositories	The main goal of this research is to analyze the web structure and performance of units and services belonging to U.S. academic libraries in order to check their suitability for webometric studies. Our objectives include studying their possible correlation with economic data and assessing their use for complementary evaluation purposes. We conducted a survey of library homepages, institutional repositories, digital collections, and online catalogs (a total of 374 URLs) belonging to the 100 U.S. universities with the highest total expenditures in academic libraries according to data provided by the National Center for Education Statistics. Several data points were taken and analyzed, including web variables (page count, external links, and visits) and economic variables (total expenditures, expenditures on printed and electronic books, and physical visits). The results indicate that the variety of URL syntaxes is wide, diverse and complex, which produces a misrepresentation of academic libraries’ web resources and reduces the accuracy of web analysis. On the other hand, institutional and web data indicators are not highly correlated. Better results are obtained by correlating total library expenditures with URL mentions measured by Google (r = 0.546) and visits measured by Compete (r = 0.573), respectively. Because correlation values obtained are not highly significant, we estimate such correlations will increase if users can avoid linkage problems (due to the complexity of URLs) and gain direct access to log files (for more accurate data about visits).	book;data logger;data point;e-book;library (computing);linkage (software);mediawiki;printing;random access;the 100;web presence;web resource;web server	Enrique Orduña-Malea;John J. Regazzi	2013	Scientometrics	10.1007/s11192-013-1001-0	webometrics;computer science;data mining;world wide web	Web+IR	-77.02766299508279	-21.766778716650148	57313
99bf97a785697699903164eee8b2efda6dc4ac04	the voynich manuscript is written in natural language: the pahlavi hypothesis		The late medieval Voynich Manuscript (VM) has resisted decryption and was considered a meaningless hoax or an unsolvable cipher. Here, we provide evidence that the VM is written in natural language by establishing a relation of the Voynich alphabet and the Iranian Pahlavi script. Many of the Voynich characters are upside-down versions of their Pahlavi counterparts, which may be an effect of different writing directions. Other Voynich letters can be explained as ligatures or departures from Pahlavi with the intent to cope with known problems due to the stupendous ambiguity of Pahlavi text. While a translation of the VM text is not attempted here, we can confirm the Voynich-Pahlavi relation at the character level by the transcription of many words from the VM illustrations and from parts of the main text. Many of the transcribed words can be identified as terms from Zoroastrian cosmology which is in line with the use of Pahlavi script in Zoroastrian communities from medieval times. 1 Why is Voynichese difficult? All writing systems in the world [8, 5] require some effort in acquisition and use. While for some groups of languages, difficulty and differences may be comparatively small [17], in others the complexity of the script can appear forbidding for all but a minority of scribes. Religious observance, for example, may require the adherents to continue using a script or language that no longer adapts to its language environment and that may thus tend to become ambiguous or incomprehensible. In order to retain a unique pronunciation and, supported by extensive commentaries, continuing understandability, glyphs (diacritics) from were added to letters to distinguish them, or additional letters (matres lectionis) were inserted to represent sounds (such as vowels in the consonant-based (abjad) scripts. However, such additional efforts may not be considered necessary, if the oral tradition in the community is sufficiently strong, such that the texts do not have to be extracted from the writing itself, but are rather remembered while being read. If the Voynich Manuscript (VM, MS 408 in the Beinecke Rare Book & Manuscript Library at Yale University) derives from such a tradition, the difficulty in reading it may be understandable. 1 ar X iv :1 70 9. 01 63 4v 1 [ cs .C L ] 6 S ep 2 01 7 The Voynich Manuscript (VM, MS 408 in the Beinecke Rare Book & Manuscript Library at Yale University) which is written on more than 200 vellum pages has been dated between 1404 and 1438 (University of Arizona, 2011), but its history is largely unknown until the discovery by the bookseller Voynich in 1912. Apart from a few cautious attempts, such as Ref. [3], so far little progress has been achieved in deciphering the VM nor even a decision was reached whether the VM has any meaningful content at all. Before we Our hypothesis that the VM is written in natural language, is to be evidenced by showing that the script used in the VM is directly related to Pahlavi, a writing system that was in use for several Iranian languages from before the current era at least until 900 [9]. Pahlavi is a particular case of a language that is notoriously difficult to read. It was used in medieval scriptures, commentaries, and a few other texts [2] related to Zoroastrianism, the pre-Islamic religion of Persia. Over the few centuries of the language evolution, many Pahlavi letters have coalesced, e.g. for the phonemes d, g, j, and y, only a single letters is retained in Pahlavi. Moreover, letters are usually joined in Pahlavi script and can appear thus similar to other letters: E.g., in addition to its proper meaning, a letter can be indistinguishable from as much a sixteen different phoneme or letter combinations [11]. In some words, corrupted forms of letters have become a standard that is accepted to various degrees by the scribes. In addition to Persian words, Pahlavi contains also a large number of heterograms, i.e. around a thousand, partially very common words of Aramaic origin that are meant to be read in Persian (like the Latin abbreviation i.e. is read in English as that is). Finally, as for many other ancient texts, material decay, language drift, scribe errors, unfamiliarity with the original cultural context, and, possibly, the need of the writers to hide the content from contemporary hostility, also contribute to the difficulty of reading the text. Concerning recent work on the VM, statistical approaches [1, 10, 14] that search for nonrandom features in data may be bound to fail if the target is quite random to begin with. The standard Voynich character set (EVA) [7] is not too helpful either, because it is unrelated to the phonemics, it breaks some of the letters into smaller parts, and fails to identify ligatures, all of which may further reduce the strength of the statistical analysis, cf. [19, 20, 18, 10]. In addition, the extensive 19th century literature dedicated to religious writing, see e.g. [15] was difficult to access until scanned copies became available online recently, and, finally, it may be construed that our academic habits thwart the systematic study of matters as obscure as the VM. The VM which is written on over 200 vellum pages has been dated between 1404 and 1438 (University of Arizona, 2011), but its history is largely unknown until the discovery by the bookseller Voynich in 1912. Apart from a few cautious attempts such as Ref. [3], so far no progress has been achieved in deciphering the VM nor even a decision was reached whether the VM has any meaningful content at all [18]. The present paper aims at providing evidence for the hypothesis that the VM is a readable text with an interest in itself. Our approach consists in establishing a relation between the Voynich and Pahlavi scripts (see Section 2). It will also become clear that only within a cooperation among experts in Pahlavi philology, Zoroastrianism, history of medicine, botany, astronomy and palaeography, the content of the VM can be revealed. We will provide evidence for the proposed relation between the two alphabets by a number	character encoding;cipher;cognitive philology;cryptography;glyph;human-readable medium;iranian.com;natural language;scribes;scripting language;transcription (software);voynich manuscript	J. Michael Herrmann	2017	CoRR		artificial intelligence;cipher;natural language processing;hoax;zoroastrianism;computer science;natural language;linguistics;ambiguity;alphabet;literature		-63.90281865815134	-21.530829409617375	57318
044e7399f432f332bb22f248118e8c97043ef417	strategification; synergizing efficiencies; and meetingitis: what your bosses really do	career progression;cio	Once upon a time, most people in a leadership role held some sort of functional IT expertise. Somewhere along the path to manager, director, or CIOs, many of us became meeting loving idiots along the way. Well, not really idiots, but losing touch with the daily realities of front line service could make it seem that way. Here is your opportunity to get a glimpse into the various checkpoints along the management path and the sort of competencies that must be developed by design or experience and how that impacts everyone in the organization. What do you gain along the way? What do you lose? How can you stay connected with all levels of the organization and the institution? This will also give you a glimpse into how you can connect with your universities mission in whatever role you hold. We will talk plainly of what exactly is the point of strategy, missions, visions, and the challenges facing the modern university and how that impacts YOU.		Robert Howard	2013		10.1145/2504776.2504780	simulation;engineering;operations management;management	HCI	-75.15986896197387	-10.855972754294514	57344
56666d8079a7c8ac6a9a519027716cd6ec9f2022	building common knowledge from personal historical narratives		Storytelling is a main source of information for cultural heritage. Many of our knowledge comes indeed from discussing events with other people. This paper addresses the benefits of storytelling for preserving cultural heritage. After introducing a policy for storing, harnessing and reusing personal and common narratives, it analyses the concrete impact of this storytelling policy for unleashing the information potential of the narratives.		Paulo Carvalho;Thomas Tamisier	2017		10.1007/978-3-319-66805-5_11	knowledge management;common knowledge;storytelling;narrative;cultural heritage;computer science;personal knowledge management	NLP	-69.67257809693962	-15.705965916678503	57348
a6ccba0cb24dc2c546c58fdbad5165d6effba80c	software technology issues for a us national missile defense system	missiles terrorism protection costs decision making weapons speech arm chemical technology europe;ballistic missile defense shield us national missile defense system software technology;speech;ballistic missile defense;software engineering;missiles;protection;system design;military systems;arm;long range;europe;ballistic missile defense shield;us national missile defense system;missiles software engineering military computing military systems;software technology;weapons;military computing;national missile defense;chemical technology;terrorism	The United States is currently developing a national missile defense (NMD) system designed to protect its territory from attack by strategic (long-range) ballistic missiles. In September 2000, President Clinton decided to defer the NMD deployment decision to the next president. President George W. Bush reaffirmed his administration's commitment to deploying a ballistic missile-defense shield by advocating an even larger NMD system in a speech at the National Defense University on May 1, 2001. The terrorist attacks of September 11, 2001, brought both the sense of deployment urgency for protection, and the call to transfer resources, from NMD to more likely terrorist threats. We focus exclusively on identifying and examining key technical challenges, primarily software-related, inherent to NMD.		William Yurcik;David Doss	2002	IEEE Technol. Soc. Mag.	10.1109/MTAS.2002.1010056	simulation;computer science;engineering;speech;terrorism;forensic engineering;arm architecture;law;computer security;systems design	Embedded	-69.60336671433909	-11.4146231103984	57416
2a9e564d6ed5c689fd5afeb14ed4de76b6da2246	measuring the cost of cybercrime		In this paper we present what we believe to be the first systematic study of the costs of cybercrime. It was prepared in response to a request from the UK Ministry of Defence following scepticism that previous studies had hyped the problem. For each of the main categories of cybercrime we set out what is and is not known of the direct costs, indirect costs and defence costs – both to the UK and to the world as a whole. We distinguish carefully between traditional crimes that are now ‘cyber’ because they are conducted online (such as tax and welfare fraud); transitional crimes whose modus operandi has changed substantially as a result of the move online (such as credit card fraud); new crimes that owe their existence to the Internet; and what we might call platform crimes such as the provision of botnets which facilitate other crimes rather than being used to extract money from victims directly. As far as direct costs are concerned, we find that traditional offences such as tax and welfare fraud cost the typical citizen in the low hundreds of pounds/Euros/dollars a year; transitional frauds cost a few pounds/Euros/dollars; while the new computer crimes cost in the tens of pence/cents. However, the indirect costs and defence costs are much higher for transitional and new crimes. For the former they may be roughly comparable to what the criminals earn, while for the latter they may be an order of magnitude more. As a striking example, the botnet behind a third of the spam sent in 2010 earned its owners around US$2.7m, while worldwide expenditures on spam prevention probably exceeded a billion dollars. We are extremely inefficient at fighting cybercrime; or to put it another way, cybercrooks are like terrorists or metal thieves in that their activities impose disproportionate costs on society. Some of the reasons for this are well-known: cybercrimes are global and have strong externalities, while traditional crimes such as burglary and car theft are local, and the associated equilibria have emerged after many years of optimisation. As for the more direct question of what should be done, our figures suggest that we should spend less in anticipation of cybercrime (on antivirus, firewalls, etc.) and more in response – that is, on the prosaic business of hunting down cyber-criminals and throwing them in jail. Computer Laboratory, University of Cambridge, JJ Thomson Ave, Cambridge, CB3 0FD, UK. ross.anderson@cl.cam.ac.uk UK. chris@vnworks.net University of Münster, Department of Information Systems, Leonardo-Campus 3, 48149 Münster, Germany. rainer.boehme@wi.uni-muenster.de Computer Laboratory, University of Cambridge, JJ Thomson Ave, Cambridge, CB3 0FD, UK. richard.clayton@cl.cam.ac.uk Faculty of Technology, Policy and Management, Delft University of Technology, Jaffalaan 5, 2628 BX, Delft, Netherlands. M.J.G.vanEeten@tudelft.nl School of Social Sciences, Cardiff University, Cardiff, CF10 3XQ, UK. levi@cf.ac.uk Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX 75275, USA. tylerm@smu.edu Department of Computer Science and Engineering, University of California, San Diego, CA 92093, USA. savage@cs.ucsd.edu	antivirus software;botnet;credit card fraud;cybercrime;firewall (computing);information systems;mathematical optimization;spamming;the 3-d battles of worldrunner	Ross J. Anderson;Chris Barton;Rainer Böhme;Richard Clayton;Michel van Eeten;Michael Levi;Tyler Moore;Stefan Savage	2012		10.1007/978-3-642-39498-0_12	public relations;engineering;law;computer security	Security	-70.53831459618429	-10.340083386076017	57598
bf04a72912b0fabcd60b2ba934e022fb2477f23e	scholarly publishing and open access in the nordic countries	communication scientifique;edition electronique;comunicacion cientifica;marche information;pays nordiques;politica publica;economic model;biblioteks och informationsvetenskap;nordic countries;modelo economico;modele economique;libre acceso;mercado informacion;edicion electronica;information market;open access;scientific communication;electronic publishing;public policy;libre acces;politique publique	This study examines aspects of scholarly journal publishing in the Nordic countries. On average half of Nordic journals publish online. In most Nordic countries, commercial publishers predominate; however, in Finland the majority are society publishers. The number of open access journals is low, in line with international figures. There is concern to maintain local languages in journal publishing. A majority of the journals publishing in local languages are within social science, humanities, and arts; the STM sector publishes in English. English-language publications are favoured in research assessments, international recognition, and impact, while the visibility of local-language scholarly journals in international databases is low. The Nordbib program supports Nordic scholarly journals and fosters co-operation with publishing companies and learned societies over migration to e-publishing; it also supports open access. The article discusses future challenges for journal publishing, pointing out the problems of small journal publishers and the need for co-operation between stakeholders.		Turid Hedlund;Ingegerd Rabow	2009	Learned Publishing	10.1087/2009303	public policy;econometrics;social science;economics;economic model;sociology;electronic publishing	Vision	-72.91166536928858	-21.045968079953308	57924
29f3fbf398b7553bcab2e674d97b100a8996352a	a brief historical review of the development of the distinction between data and information in the information systems literature	information system	It is a commonplace among contemporary information systems professionals that the concepts of data and information are obviously distinct and clearly understood. Through a review of the historical literature, this paper shows that, in fact, the distinction is not obvious, that it is an outgrowth of work in the information systems area, and that the distinction is not clearly understood. The paper briefly notes some of the implications of this historical development for information systems theory. This paper will be of interest primarily to academics and those with an interest in the conceptual foundations and theoretical frameworks guiding Information Systems research. Introduction: The Need for Clarity in Fundamental Concepts It is a shared set of fundamental concepts that provide the epistemic foundations of a discipline—a shared framework for understanding, investigation, and communication. Clarity in, and general agreement about, the definitions of fundamental concepts is therefore critical to the discipline. As an academic discipline, however, Information Systems is peculiar; investigation suggests that there is, in fact, surprisingly little agreement about the meanings of a surprisingly large number of fundamental terms. This may be troublesome. For example, it has been suggested that lack of attention to basic concepts may hinder communication within the discipline (Alter, 2000). Lack of consensus about the meanings of fundamental terms may be what has led one team of researchers to describe the IS discipline, following Whitley (1984), as a “fragmented adhocracy” (Banville & Landry, 1989). Within the discipline, few concepts would appear to be more fundamental than those of “data” and “information,” yet it has been observed that there is much confusion even about these core concepts (Checkland & Holwell, 1998). Despite the general lack of consensus or precision in the definitions of “data” and “information,” one characteristic that seems to be almost universally assumed is that the concepts are distinct. How they are distinguished depends on how they are individually defined, but it is almost universally agreed that “data” (whatever they may be) and “information” (whatever it is) are somehow different, i.e., that the terms have different referents. Some further assert not just that the terms are distinct but that understanding the distinction is important, even “vital” to understanding the discipline (Dock & Wetherbe, 1988; Mingers, 1995; Jessup & Velacich, 1999). This paper offers a brief historical review of the development of the distinction between “data” and “information.” Although most IS researchers now take the distinction to be natural and obvious, a review of the very early literature suggests that it is not. The distinction is, in fact, an artifact, or a development of, work in the field of IS itself or in what was known to an earlier generation of researchers as “data processing.” Scope and Significance of this Historical Review This paper is preliminary to a broader review of the core concepts of data and information as they are actually articulated and used within the discipline. It is possible to consider those concepts from any number of different and equally valid theoretical or philosophical perspectives. As a philosopher, the author was originally trained in analytic and ordinary language philosophy, and Research Methods and Epistemology of IS 2844 2003 — Ninth Americas Conference on Information Systems it is this approach to conceptual analysis rather than a body of theory that guides this analysis. Partly for reasons of space, partly because it is a perspective that has value in its own right, this paper restricts itself to the early historical development of the distinction between data and information within the IS literature. On the basis of that historical analysis, it also attempts to provide insight into several issues or questions surrounding these core concepts as follows: 1. It provides some insight into the early historical development of the discipline and its core concepts. Understanding its common historical and conceptual heritage helps to solidify and define the discipline. It has been argued that building such a cumulative tradition is essential to the development of a coherent discipline (Keen, 1980). Although there is a substantial body of historical research on the development of the computer and other information technologies, relatively little work has been done to understand the historical development of those concepts that define the Management Information Systems discipline (See Cougar, 1973; Dickson, 1981) 2. It provides a partial basis for understanding and refining the definitions of the core concepts of data and information. A cursory review of the contemporary literature will show that • there is no single, commonly accepted set of definitions for these terms; • the definitions are often articulated in ways that seem to lack conceptual rigor; • the definitions do not conform to ordinary usage. It is not essential that technical definitions of common terms conform to standard usage, although when technical usage departs from common usage there should be some justification for it, if only to avoid unnecessary confusion. However, it seems a priori that rigor and precision in the definitions of foundation concepts are desirable characteristics in any discipline. 3. When there is a lack of agreement about the definitions of fundamental terms within a discipline, one approach to resolving the issue may be to ask to what problems or concerns the language responds. That is the approach taken in this paper. In this case, we ask “What were the concerns or observations that led earlier researchers to make the distinction and to define the terms as they did?” Answering this question will not by itself resolve contemporary definitional issues; time and technological progress may have vitiated those early concerns, but the distinction, or the manner in which it is made, might continue to be valid for different reasons. 4. Such an historical review may also have practical significance. The author is attempting in a follow-up paper to show that how this distinction is articulated provides a conceptual basis for a set of frameworks or “metaphors” for understanding the IS enterprise. Thus, for example, some ways of articulating the distinction lead naturally to the understanding of IS as a production system whose raw materials are data and whose product is information; others lead to a conceptualization of the IS enterprise that is more appropriate to a distribution system. Clearly, such different metaphors may support different perceptions of the role of the IS function within an organization and may have an impact in directing research. In the recent literature, the distinction between data and information has been extended to include “knowledge” as a third category. Some authors actually include a fourth category, “wisdom” (Post & Anderson, 2000). Those concepts go beyond the scope of this research; the interested reader should see Alavi & Leidner’s (2001) review of the concept of “knowledge” as it is used in knowledge management research. Their review also briefly discusses the conceptual distinctions between data, information, and knowledge. Data Versus Information: An Historical Perspective MIS is often described (frequently to excuse some apparent or claimed deficiency) as a new or immature discipline. In fact, as a blending of interests in business systems and computer-based information technologies, a stream of literature leading to what would today be identified as MIS can be traced back for approximately fifty years, beginning very soon after the development of the contemporary stored program computer architecture. Much of this early literature is speculative. Much of it was practical and related the work of early systems designers, frequently from what were then referred to as Systems and Procedures Departments. Given the fundamental place of such concepts as “data” and “information” in the information systems enterprise—at least from a theoretical perspective, the natural assumption might be that the distinction was obvious at the outset. However, a review of Gray/Historical Development of the Distinction between Data and Information 2003 — Ninth Americas Conference on Information Systems 2845 the earliest texts suggests that no such distinction was made. What is most interesting about this is that this lack does not appear to have seriously impeded the investigation or development of information systems. For example, Richard Canning’s 1956 textbook on Electronic Data Processing for Business and Industry (Canning, 1956) makes no such distinction. In fact, it makes little use of the word “data” although it frequently speaks of “information” and “manipulations upon information.” A similar usage occurs in the accounting firm Haskins and Sells’ early Introduction to Data Processing by Electronics (1955) . This very early work, which was directed primarily to accounting professionals, uses “data” and “information” entirely interchangeably—sometimes in ways that seem unnatural to those of us who are familiar with contemporary usage, referring for example to “input information.” Haskins and Sells’ next book on the subject, Introduction to Data Processing, published in 1957 also uses the two words interchangeably; however, the Foreward includes the following intriguing assertion: “Data originates in the human mind. Data is information—a piece of intelligence.” This seems to affirm that data and information are, in fact, the same. This view was not original or unique. Initially copyrighted in 1955, Ned Chapin’s highly influential textbook, An Introduction to Automatic Computers, is possibly the earliest textbook on business computing. This work appears to explicitly deny any distinction at all between “data” and “information.” Chapin makes no distinction in the body 	alpha compositing;americas conference on information systems;angular defect;artifact (software development);assertion (software development);coherence (physics);computer architecture;conceptualization (information science);definition;electronic data processing;fundamental concepts in programming languages;information systems research;knowledge management;management information system;mind;production system (computer science);release early, release often;speculative execution;stored-program computer;systems theory;ipod	Robert Gray	2003			management science;knowledge management;information system;computer science	DB	-72.5237234685796	-17.009793416978376	57935
970481b0bc2f5c78770c00c7d6925797c95fde2f	bibliometric analysis for science policy: an evaluation of the united kingdom's research performance in ocean currents and protein crystallography	analyse bibliometrique;protein crystallography;oceanologie;citation analysis;scientific policy;science policy;analyse citation;cristalografia;research evaluation;indicateur recherche;bibliometric analysis;crystallography;politique scientifique;research indicator;oceanology;cristallographie	This paper presents the results of a study of Britain's scientific performance in the fields of ocean currents and protein crystallography carried out for the Advisory Board for the Research Councils (ABRC). Using a range of publication and citation indicators, the study aimed to explore the potential value to science policy-making of low-cost scientometric approaches to research evaluation.	bibliometrics;scientometrics	David Crouch;John Irvine;Ben R. Martin	1986	Scientometrics	10.1007/BF02017247	social science;computer science;operations research;citation analysis;world wide web	HPC	-75.49370927291022	-21.9763576026898	57997
aa0802e2940c91a3e8f8912ee5d12163b6265176	here be dragons	policy technology law security;policy;marine vehicles computer security privacy;new world;security;technology law	"""held, dragons awaited them. As further support for the flat-Earth hypothesis , anyone who ever cared to experiment either saw an obstruction in the distance or a never-ending flat expanse no matter which direction they looked. What else could the world be but flat? The 21st century """" flat world """" craze, like its predecessor, also involves India and China, but it's now the transportation of bits and not atoms that hold promise of riches. Communications networks enable the outsourcing of any task that can be conveyed and discharged by transmitting bits. For example, telephone conversations, medical images such as x-rays, and software artifacts can all be encoded using bits. Therefore, telephone customer-help centers, x-ray analysis, and software construction become candidates for outsourcing, effectively exporting jobs from one country to another and reducing costs if the new workforce is less expensive but equally expert. Today's """" flat world """" is actually as spherical as ever—it's just better connected electronically and thus metaphorically lacks obstructions. So what does all this hold for cyber-security? One consequence is obvi-ous—to the extent that bits from one place aren't obstructed from reaching any other place, attackers have an easier time launching their attacks and attacks spread more easily between machines. The modern """" flat world """" comprises sovereign countries, with their separate laws, values, and cultures. Differences in laws means that an illegal act in one country might be legal in another; differences in values and cultures means that those differences in law are unlikely to change. The multiplicity of jurisdictions with different laws, with the attendant uncertainty about which laws apply and how they will be enforced, becomes an obstruction in our """" flat world """" because bits that leave a jurisdiction you trust for one you don't might be subject to abuses that are costly to prevent or remediate. Uniform civil law, that great leveler for commerce, is absent on the international scale. Business relationships between partners only sometimes substitute. Finally, most security in the physical world is based on accountability of action. Perpetrators of offensive acts fear being caught, convicted, and punished. It's hard to argue with success, so we might contemplate the use of accountability in cyber-space. However, to do so, today's systems and networks would need to be substantially changed because they currently don't provide trustworthy attribution of action. Even if they did, the existence of multiple jurisdictions becomes problematic. …"""	computer security;here be dragons;job stream;leveler;outsourcing;robertson–seymour theorem;software construction;telecommunications network;transmitter	Fred B. Schneider	2006	IEEE Security & Privacy	10.1109/MSP.2006.68	legal aspects of computing;simulation;computer science;information security;computer security		-70.03957178789646	-12.244268571243017	58063
5ef6a6349802d002f46ce6cb3ab0de06bdb550df	ian pratt: pioneering security through virtualization		"""54 profile in computer science at Cambridge. Asked why he had chosen to stay in academia when he could have joined the workforce, Pratt backed up his decision by drawing parallels between the two: """" I got to do the best of both worlds, really, in that being at the university means you are effectively your own boss, and you're truly running a business. The business is getting money from customers, in this case typically the EPSRC [Engineering and Physical Sciences Research Council] or other organizations, and then creating deliverables, either by meeting the must-haves of the project, or—most importantly—publishing papers, """" he explained. His entrepreneurial spirit was also the main reason why he stayed on in academia after the completion of his Ph.D, an explanation that perhaps runs contrary to many common perceptions about the way the fields of computer engineering and computer science are perceived to work. """" I think actually being a faculty member and running a successful research group with sufficient funding is great training for running a small business, """" Pratt elaborated, adding that one of the things his research group did that he was very proud of was to continue the tradition of systems research being very practical at Cambridge. They invested into building real systems, getting real users, and actually measuring how those systems behaved. Pratt's research approach was atypical of the academic environment, where the sensible thing to do from an academic career point of view would have been to write papers on prototypical, half-finished systems, and then to move on. However, he stands by his research practice, and points out that if you want to have real impact, the best thing to do is to build real systems that are interesting to, and used by, other people, and only then do Ian Pratt is currently the co-founder and executive vice president of Bromium, an ambitious global computer security startup that straddles two major, albeit culturally very different, tech scenes between its Silicon Valley headquarters in Cupertino, CA, and its R&D office in Cambridge, U.K. Previously, Pratt had been a lecturer at the University of Cambridge for nearly 10 years in the Systems Research Group; the founder of a series of tech startups, including Nemesis Research and XenSource, and the chief architect on the major open source Xen virtualization project. A deep love for systems design is the common denominator that runs …"""	backup;computer engineering;computer science;computer security;hardware virtualization;knuth–morris–pratt algorithm;open-source software;parallels desktop for mac;systems design;systems theory	Adrian Scoica	2015	ACM Crossroads	10.1145/2732694	telecommunications;management;operations research	DB	-64.47639700079037	-22.279694819559253	58105
01819a93febe5cd022b8cb0772e31309b10731c0	medical misinformation on the web: mitigation or control?		"""I f you have a medical question, your are likely to find more answers than you want or need if you explore cyberspace. Like all new technologies, the world wide web has both good and bad effects. The web can enhance good medicine or promote quackery; it can transmit medical information or purvey misinformation; it can assist medical education or catalyze medical ignorance; it can be used to aid or exploit the ill. If you have cancer, a quick survey can take you to the following websites: www.kalamark.com/essiac/surest/html The Surest Ever Cancer Cure. This site provides you with information about Royal Rifes's cancer cure and Rife technologies. Rife (18881971) was a molecular biologist who believed that all life forms oscillate at specific frequencies, and he postulated that cells, viruses and bacteria could be destroyed by generating dissonant energy waves. The site notes that Rife's work was """"wickedly suppressed by a cabal of mainstream medical interests"""" but that his cure is now available. Another Rife website, www.commercialdirectory.com/health/rife.html, claims that there is now scientific evidence that Rife's technologies can cure more than 285 other health problems, including AIDS. www.healthfree.com/schulze/Alternative Medicine, Natural Healing. This website provides information from """"master herbalist"""" Richard Schulze. The site claims that Schulze has used herbs to help thousands regain their health and rid themselves of cancer, AIDS, heart disease, arthritis, diabetes, and fatigue. www.ismall.com/zheng/prorder.htm. Award l~'nning Cancer Cures. For only only $37.77 (plus $5.00 postage) you can order this book from J & H Development, Inc. www.pchiropractic.com/news.htm Chiropractor Cures Cancer. This is an article from The Chiropractic Chronicles describing Colonel William Allen's miraculous cancer cure, which he claims resulted from a chiropractic adjustment. www'cwinds'c°m/t°pages/cancer'htm Celestial Winds. This website contains information about holistic healing methods and alternative cancer treatments. If you have AIDS, you might check out the following website: home.earthlink.net/-exp7/ The Expediter. According to this site, an independent scientist has discovered EXP, a natural substance that is an AIDS cure, an HIV treatment, and an AIDS/HIV vaccine. The site also claims that EXP is an anti-aging and arthritis treatment, and it requests volunteers and investors. southernherb.com/huldbooks.htm Books by Dr. Hulda Clark. Visit this website to obtain information on how to order Dr. Hulda Clark's three books, The Cure Jbr HIV and AIDS ($19.95), The Cure Jbr all Cancers ($19.95), and The Cure fbr all Diseases ($21.95). Of course, those with cancer or AIDS might also discover the following sites: oncolink.upenn.edu Oncolink. This is a cancer website sponsored by the University of Pennsylvania Cancer Center. It provides information about frequently asked questions, disease typologies, cancer causes, cancer screening, cancer prevention, pain management, and financial issues for patients. ww.graylab.ac.uk/cancerweb.html Cancer Web. This website is sponsored by the Gray Laboratory in the United Kingdom. It provides information on cancer diagnosis, etiology, classification, treatment, research, support groups, library resources, and websites. www.cdc.nac.org/ Centers Jbr Disease Control and Prevention National AIDS Clearinghouse. This site is sponsored the Centers for Disease Control and Prevention. It provides information about HIV/AIDS prevention, treatment, research, publications, and resources. www.nih.gov/sigs/aids/ NIH Special Interest Groups AIDS Interest Group. This site is sponsored by the National Institutes of Health, and supplies a great deal of information concerning AIDS meetings and conferences, listservers, and research links. We do not need to do a thorough search of the world wide web to see that it provides consumers with a mixed-bag of medical information. Much of the information is very useful and helpful, but a great deal of information is potentially dangerous. Unproven treatments and therapies can result in injury, disfigurement, or even death. For example, a natural healer diagnosed the bump on an Idaho woman's nose as cancer, and he instructed her to apply a black herbal salve to the bump. In a few days, she was in great pain with red lines running down her cheeks. In a week, her nose (and a great deal of facial tissue) sloughed off. A failure to try proven treatments can also have tragic consequences. For example, an Oregon man died of mouth cancer after treat-"""	book;cabal;celestial coordinate system;cyberspace;disease gene identification;exptime;holism;rife;statistical classification;thermal copper pillar bump;visit;world wide web	David B. Resnik	1998	SIGCAS Computers and Society	10.1145/277351.277358	internet privacy;world wide web;computer security	Comp.	-65.76808921798268	-19.258762143595447	58120
9b920cd0781f17fbb5f539bc6c72e4d0df9ffb9d	http 404-page (not) found: recovery of decayed url citations	decay;url citations;wayback machine;half life;http 404 page not found	Study investigates the availability, persistence and half life of URL citations cited in two Indian LIS journals articles published between 2002 and 2010. This study also investigates how researchers can resurrect lapsed URL citations cited in research articles, using Wayback machine. A total of 1290 URLs cited in 472 research articles published in Indian LIS journals spanning a period of 9 years (2002–2010) were extracted. Study found that only 18.91% (1290 out of 6820) of URLs cited in these journal articles. 39.84% of URL citations were not accessible and remaining 60.15% of URL citations were still accessible. The HTTP 404 error message-“page not found” was the overwhelming message encountered and represented 54.86% of all HTTP error messages. However 51.06% URLs were recovered from HTTP 404 error message. Study also noticed that the half-life of URL citations was increased from 6.33 years to 13.85 years after recovering missing URLs from Wayback machine.	http 404;hypertext transfer protocol	B. T. Sampath Kumar;D. Vinay Kumar	2013	J. Informetrics	10.1016/j.joi.2012.09.007	half-life;computer science;internet privacy;world wide web;information retrieval	Web+IR	-66.19965812791865	-17.846411518023178	58202
56bed750de7a14acede0b84ac478e7ef7bec3ee9	citation counts and the research assessment exercise v: archaeology and the 2001 rae	libraries;europa;correlacion;analisis citas;citation analysis;universite;archaeology;litterature scientifique;analyse citation;rae research assessment exercise;university research;literatura cientifica;royaume uni;arqueologia;united kingdom;reino unido;evaluation;recherche universitaire;university;evaluacion;correlation;europe;recherche scientifique;universidad;scientific literature;scientific research;article;citation count;archeologie;investigacion cientifica;research assessment exercise	A citation study of the 692 staff that makes up unit of assessment 58 (archaeology), in the 2001 UK Research Assessment Exercise (RAE) was undertaken. Unlike earlier studies, which were obliged to make assumptions on who and what had been submitted for assessment, these were, for the ®rst time available from the RAE Web site. This study, therefore, used the speci®c submission details of authors and their publications. Using the Spearman rank-order correlation coef®cient, all results showed high statistically signi®cant correlation between the RAE result and citation counts. The results were signi®cant at 0.01 per cent. The ®ndings con®rm earlier studies. Given the comparative cost and ease of citation analysis, it is recommended that, correctly applied, it should be the initial tool of assessment for the RAE. Panel members would then exercise their judgement and skill to con®rm ®nal rankings. Introduction In this paper, we describe research on the correlation between citation counts and an of®cial 2001 assessment of research excellence in UK university archaeology departments. To assess the research performance of UK universities, the UK Higher Education Funding Councils carry out a periodic Research Assessment Exercise (RAE). The RAE is concerned with making a qualitative judgement of the research output of those university departments who submit themselves to the procedure. As part of this assessment, academic (and in some cases industrial) peers carry out a review of the published work of submitting departments over a given period of time. The departments are also assessed by other criteria, including the number of higher degree students they have, the amount of research income they have received and a general commentary on their current and future research programmes. University departments are then ranked and consequently funded by central government for their research activities, based upon the score they achieve. The RAE is carried out every ®ve years or so and is viewed by many as an expensive and contentious process. Alternatives are sometimes suggested that The Emerald Research Register for this journal is available at The current issue and full text archive of this journal is available at http://www.emeraldinsight.com/researchregister http://www.emeraldinsight.com/0022-0418.htm q Michael Norris and Charles Oppenheim. Part IV in this series can be found in Holmes and Oppenheim (2001). Archaeology and the 2001 RAE	archive;citation analysis;emerald;journal citation reports;marginal model;naruto shippuden: clash of ninja revolution 3;peer-to-patent;recommender system;robustness (computer science);while;whole earth 'lectronic link	Michael Norris;Charles Oppenheim	2003	Journal of Documentation	10.1108/00220410310698734	library science;scientific method;computer science;evaluation;sociology;citation analysis;world wide web;correlation	Web+IR	-76.13386397941535	-23.001881837600987	58290
15fcece3d554940c917813ff48ceafb50c038fab	ipct journal: a case study of an electronic journal on the internet	ipct journal;electronic journal;case study;preservation;electronic publishing;internet;comparative analysis	This article sets forth some of the background of the founding of the Interpersonal Computing and Technology Journal: An Electronic Journal for the 21st Century (IPCT-J). It also describes much of the decisionmaking process regarding IPCT-J, where the issues of credibility, accessibility, permanence, and the associated technical issues concerning dissemination over the Internet as it exists were considered. Issues of scholarship and their relationship to publication (both print and electronic) are discussed. One conclusion is that even if e-journals are less expensive, easier to access, or save time, this is not going to allow e-journals to compete with print journals if the content of the e-journal is not perceived to be of high quality. © 1994 John Wiley u0026 Sons, Inc.	internet	Mauri P. Collins;Zane L. Berge	1994	JASIS	10.1002/(SICI)1097-4571(199412)45:10%3C771::AID-ASI9%3E3.0.CO;2-7	library science;design;social science;computer science;accessibility;requirement;durability;sociology;electronic publishing;management;operations research;world wide web;preservation	ECom	-68.72000263642967	-18.01046229460842	58431
f5dc2103798c0a7d8d5c8b0236844f192c6f1211	interactive publications and the record of science	interactive content;semantic processing;data visualization;digital preservation;electronic publishing	The Proceedings of a one-day Workshop are described, in which publishers, publishing service providers, librarians, editors and authors met under the auspices of the International Council for Scientific and Technical Information (ICSTI) to survey new developments in interactive scholarly publishing, and to begin to identify the necessary infrastructure for including such interactive content within the long-term record of science.	interactivity;librarian	Brian McMahon	2010	Inf. Services and Use	10.3233/ISU-2010-0607	library science;computer science;data science;information retrieval	HPC	-63.96320775059716	-15.197266844459007	58441
0fd42fc95b8bb390827cf09784e1d0318626f79d	developing children's interest in reading	services promoting;politica bibliotecaria;text;lectura publica;livre;gender;promocion servicio;public reading;sexual differentiation;diferenciacion sexual;libro;library policy;public library;developpement collection;politique bibliotheque;desarrollo coleccion;book;lecture publique;bibliotheque publique;promotion service;children books and reading;differenciation sexe;sex roles;collection development;biblioteca publica	Librarians have always discussed methods of developing children’s interest in reading, but they have focused more on the books being read than on the act of reading. Although many touted the need to “establish the reading habit,” a closer reading of the literature reveals that this referred specifically to reading “good books,” those which socialized children into culturally acceptable sex roles. As early as 1876, articles warned of the dangers of sensational fiction for both girls and boys. By the 1940s, comic books had replaced sensational fiction as a potential “corrupting influence.” Only in the late 1950s did public librarians begin to address the new problem of a reluctance to read at all among children in general and among boys in particular. This paper will examine the effect of gender role expectations on librarians’ efforts to promote reading to children in the twentieth century. In particular it will explore the questions of whether these strategies continue to be designed to promote reading literature that reinforces society’s gender role expectations and of whether they are designed to promote reading to both boys and girls equally, or whether one group is privileged at the expense of the other. Introduction Any exploration into issues of libraries and children must begin by defining what is meant by “child.” The term has had different meanings during different periods, and is almost never defined in contemporary writings. The primary focus of this paper is what are termed “older children,” from nine to fourteen years, because research has demonstrated that the gender-based differences in reading do not appear until about Developing Children’s Interest in Reading	book;librarian;library (computing);socialization	Suzanne M. Stauffer	2007	Library Trends	10.1353/lib.2008.0011	psychology;library science;sexual differentiation;sociology;management;law;literature	HCI	-71.72700747939435	-21.131932400648882	58444
41e974aa53d4b7102976a6f75d0a4b64bced6562	staying disciplined during an interdisciplinary degree	interdisciplinary degree	"""very year, at commencement ceremonies around the world, university presidents and college deans tout the benefits of an interdisciplinary approach to pursuing a degree. Awards are typically bestowed on exceptional undergraduate students who have simultaneously double-or even triple-majored in disciplines such as fine arts, business, and computer science (CS), or exemplary graduate students who have earned a PhD under the tutelage of advisors from equally disparate programs. Exemplary, perhaps not, but I am one of these people. During the last four years at the University of Southern California, I've been a CS PhD student in the Viterbi School of Engineering. All throughout , I've been working as a graduate research assistant in the Department of Geography in the College of Letters, Arts, and Sciences, funded by grants obtained in the Department of Preventive Medicine in the Keck School of Medicine, with advisors from each. At times, I've looked at other students in my cohort and felt sure I was going down the wrong path because their CVs had peer-reviewed conference papers while mine only had a series of non-peer-reviewed """" technical reports """" and two peer-reviewed articles in non-CS journals. On more than one occasion I've had the less-than-pleasurable experience of rationalizing to myself and my advisors that what I am doing is actually CS research. Perhaps most difficult of all, I've had to mediate the scientific approaches inherent to the disciplines of my advisors while carving out a research topic and schedule amenable to all that would fly for a CS degree. Despite these challenges, I can thankfully and confidently state that my experience has been, overall , quite a positive one. My experience has imparted first-hand practical knowledge on how to identify underlying computational problems that others don't recognize, which my CS education and training has prepared me to solve or optimize. Although it was sometimes difficult to appreciate during day-long debugging sessions, the encouragement and requirement to step out of the proof-of-concept-only mold allowed me to make contributions that are actually being used by thousands of people. This exposed me to big-picture thinking, and has made me consider the scalability, reliability, and generalizability of my solutions at every turn, concepts that I hope will prepare me well for a career in either industry or academia. Equally beneficial, I now know a great deal more about potential funding sources and collaborators than I would have otherwise, having written …"""	computational problem;computer science;concurrent versions system;debugging;scalability	Daniel W. Goldberg	2009	ACM Crossroads	10.1145/1665997.1665999	internet privacy;computer science	Web+IR	-65.5205543564238	-20.109936213006943	58572
7d08b1e5b37ebe410f52ac586cb229c96d045202	the pain gods		The short story entitled “The Pain Gods” defines a future where the protagonist designs a set of contact lenses which hold the ability to allow someone to revisit their fondest memories. Present also in this futuristic world are the Pain Gods, robotic-like figures who run all government buildings and organisations. The story encapsulates the human instinct for love in direct comparison to the Pain God’s desire for innovation above all else. The story describes a future in which emotion-driven human enterprise processes may become misused in order for the mass creation of personified products.	gods;robot	Jennifer O'Connor	2016		10.3233/978-1-61499-690-3-490		HCI	-68.52931524464249	-13.714978952320195	58701
5405854ddd0a10260850141c9336d6d8a93c5132	energy flow and the organization of life	energy flow;science biology origin of life	SFI WORKING PAPER: 2006-08-029 SFI Working Papers contain accounts of scientific work of the author(s) and do not necessarily represent the views of the Santa Fe Institute. We accept papers intended for publication in peer-reviewed journals or proceedings volumes, but not papers that have already appeared in print. Except for papers by our external faculty, papers must be based on work done at SFI, inspired by an invited visit to or collaboration at SFI, or funded by an SFI grant. ©NOTICE: This working paper is included by permission of the contributing author(s) as a means to ensure timely distribution of the scholarly and technical work on a non-commercial basis. Copyright and all rights therein are maintained by the author(s). It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author's copyright. These works may be reposted only with the explicit permission of the copyright holder. www.santafe.edu	field electron emission;scientific literature	Harold J. Morowitz;Eric Smith	2007	Complexity	10.1002/cplx.20191	biology;computer science;mathematics;energy flow;physiology	PL	-64.87463637512002	-17.693656858045	58754
8700b530816f2fe386b660a6d2c92e9d444e77d9	a conversation about identity management		CG: I am part of the overall UT System Administration, an overarching organization. Our institutions are budgetarily and otherwise somewhat independent. As such, they have their own personnel offices, their own faculties, their own presidents, and so on. Their budgets are rolled up together and presented to the legislature by the folks in the office where I work. Individual institutions have roughly the same relationship to each other that Pontiac and Chevrolet do within General Motors.		Clair W. Goldsmith;Rob Kolstad	2004	;login:			Theory	-64.60012772099931	-20.490998880496598	58815
d0e79fff0dbdefb18714fbeca63b032e0af1feb2	trends in the use of isi citation databases for evaluation	isi institute for scientific information;facteur impact;factor impacto;impact factor;citation;indicador medida;evaluation;citacion;measurement indicator;evaluacion;recherche scientifique;indice hirsch;scientific research;investigacion cientifica;hirsch index;indicateur mesure	ABSTRACT#R##N#This paper explores the factors shaping the current uses of the ISI citation databases in evaluation both of journals and of individual scholars and their institutions. Given the intense focus on outcomes evaluation, in a context of increasing ‘democratization’ of metrics in today's digital world, it is easy to lose focus on the appropriate ways to use these resources, and misuse can result.	database;information sciences institute	James Pringle	2008	Learned Publishing	10.1087/095315108X288901	scientific method;economics;evaluation;sociology;operations research	DB	-75.62859613120078	-21.98616686295786	58838
b59d082a4bbd40fe77e9fea23571ee9d379c5cee	developing strategies for the information society	development strategy;public sector;information society;private sector	Much has been written about the coming Information Society and the possible benefits and problems that could accompany its evolution. However, there is no grand design for the Information Society. Its general shape, speed, and direction are being shaped by a wide variety of forces, only some of which are technological. However, an argument can be made that the lack of a coherent strategy for the evolution of the Information Society may prove dysfunctional in the long run, because it results in ambiguity, confusion, waste, and lost opportunity in both the public and private sectors. In fact, there are many strategic choices that could be taken today which would help shape the future Information Society so as to improve the prospects for overall societal benefits. Five strategic choices in the public sector and five in the private sector are offered as examples of the kinds of actions that would appear to be appropriate today to lay the groundwork for the successful evolution of the Information Society. The vast promise of the evolving Information Society has been explored frequently by social scientists and technologists. They point to the development of a new global awareness and interdependence that is being greatly stimulated by rapid communications and satellite technology. Many of them see the possibility of human intelligence being greatly expanded by the use of the computer, a political system The Information Society, Volume 1, Number 4 0197-2243/82/020339-00$02.00/0 Copyright © 1982 Crane, Russak & Company, Inc. 339 D ow nl oa de d by [ U ni ve rs ity o f C al if or ni a, S an D ie go ] at 0 1: 51 2 2 Ju ne 2 01 6	coherence (physics);interdependence	Burt Nanus	1982	Inf. Soc.	10.1080/01972243.1982.9959957	public relations;economics;public sector;management science;sociology;management;law;private sector	Web+IR	-75.336623442405	-11.121926738218226	58859
483c53b2cf5f8e78727c7ea45943e74664bad871	fractal scaling and implicit bias: a conceptual replication of correll (2008)		A racial priming article claimed that, relative to a control condition, an exotic variety of variability, called 1/ƒ noise, is altered when stereotypes impact participants’ judgments in an implicit prejudice task (Correll, 2008). However, Madurski and LeBel (2014) recently described two powerful, faithfully cloned, and apparently decisive studies that each failed to return a successful literal replication of Correll’s report. Madurski and LeBel outlined and subsequently eliminated several potential extraneous reasons for their replication failures, such as different participant demographics, participant non-compliance, poor psychometrics, and hardware discrepancies. By contrast, this article reports a successful conceptual replication of the pattern reported by Correll (cf. Schmidt, 2009). Notably, this conceptual replication required adjustments to Correll’s original method and statistical analyses. All the changes were dictated by a systems theory of 1/ƒ noise that was largely in place prior to Correll’s report (Kello, Beltz, Holden, & Van Orden, 2007; Van Orden, Holden, & Turvey, 2003; 2005). Implications for the replication debate are discussed, with emphasis on contextualizing implicit cues.	fractal;heart rate variability;literal (mathematical logic);pink noise;schmidt decomposition;systems theory	Mary Jean Amon;John G. Holden	2016			social psychology;psychology;cognitive psychology;scaling;fractal	HCI	-74.98807400688592	-15.124021979926242	58878
f602fe109e7834f2d0f12b2e796146123de10e62	firewall considerations for the it manager	network security;it management	Firewall Considerations for the IT Manager Paul A. Henry a a Senior Vice President of CyberGuard Corporation. He has more than 20 years experience with security and safety controls for high-risk environments such as nuclear power plants and industrial boiler sites. In addition, Paul has developed and managed security projects for major government and commercial organizations worldwide. Paul has written technical papers and white papers on a broad range of information security topics. He also frequently serves as a featured and keynote speaker at network security seminars and conferences worldwide. In addition to the CISSP, Paul holds many other security certifications, including MCP+I, MCSE, CCSA, CCSE, CFSA, CFSO, CISM, and CISA Published online: 21 Dec 2006.	certified information systems security professional;cybersecurity information sharing act;firewall (computing);industrial pc;information security;network security;software engineering 2004	Paul A. Henry	2005	Information Systems Security	10.1201/1086.1065898X/45654.14.5.20051101/91011.5	computer science;network security;network security policy;computer security;computer network	Security	-68.88202760030902	-10.850331216862312	59029
983e4cdb11c706e003d94b82c124f2148a3ded42	ieee region 8 in a persian market	computer science and informatics	A description is given of the events associated with decisions and actions by IEEE to close the IEEE Iran Section and impose restrictions on IEEE members in Iran from 2000 onwards. Index Terms —IEEE Policy and Procedures, IEEE Member services, IEEE Regions, IEEE Sections, IEEE Student Branches. I. IEEE AND IRAN BEFORE THE OFAC [2] INFLUENCE The Iran Section of IEEE was founded in February 1970. The first visit to Iran by an IEEE President (Arthur Stern) took place in 1975. He wrote briefly about his visit in The Institute, October 1999, page 9. The visit was before the fall of the Shah of Iran in early 1979, and subsequent formation of the Islamic Republic after return to Iran of Ayatollah Khomeini. IEEE Region 8 (R8) Director Kurt Richter visited the Section in 1991. A second visit to Iran by an IEEE President took place on 20 th February, 1999, when Ken Laker, accompanied by R8 Director Rolf Remshardt, flew to Teheran from Frankfurt, by Iran Air. They had been invited by Iran students at a Student Branch Congress in Istanbul the previous year, and the visit was approved by the Iran Section Chair, Dr. Ghaffoori-Fard. An intensive programme of university visits, etc. was arranged, and reported in The Institute as ‘IEEE Officers find Iranian engineering students ready for 21 st century’ [4]. In this report is the statement “Laker agreed to an arrangement that will help make it easier for Iranian students to enjoy the benefits of IEEE” – giving no hint of what was to happen shortly after. By then, and continuing until IEEE ordered them to close down, the IEEE Student Branches in Iran were very active and successful. Their members were largely sympathetic to and understanding of the USA, and so by enforcing sanctions, USA was indirectly risking making the future situation worse rather than better. The University of Tehran IEEE Student Branch was the first in the Section, approved by IEEE HQ in April 1996, with Regional Activities Board ratification on 14 th February 1997. II. WHAT TRIGGERED THE CONCERNS IN IEEE ABOUT	dvd region code;iranian.com	Anthony C. Davies	2013	IEEE Technol. Soc. Mag.	10.1109/MTS.2013.2259321	computer science	Visualization	-63.91036302234126	-18.759491993712928	59128
a97e0cca1a4eef4fb1f4aec6e69055c839c16734	ethics committees and irbs: boon, or bane, or more research needed?	ethics committee;keynote talk	"""Cambridge: summary of remarks in keynote talk at WECSR 2012 Institutional review boards in the USA, and ethics committees in the UK, have their roots in medical research. In the US Tuskegee scandal, black patients with syphilis were left untreated even after an effective treatment became available in the form of penicillin; in the UK Alder Hey scandal, pathologists retained body parts from deceased children without informing their parents. Yet simply having a committee of doctors review other doctors' research proposals isn't foolproof, as it disregards the differing perspectives and cultural assumptions between doctors and patients. For example, ethics committees were already well established in Britain by the time of Alder Hey, and it's not entirely obvious that a committee of half a dozen randomly-chosen white doctors in the deep south in the 1940s would have acted any differently from the Tuskegee team. The current tussle in the UK is between a medical research establishment that wants access without consent to medical records that have been """" pseudo anonymised """" in that the patients' names and addresses have been removed, and a privacy community which points out that most such records can be re-identified easily. Computer scientists know that anonymity is hard, thanks to the work of Denning, Sweeney, Dwork and others; this knowledge is slowly percolating through to the policy community via Ohm's work. Yet we have already had an incident were over eight million """" pseudo anonymised """" records were lost when a researcher's laptop was stolen; should such a haul end up on wikileaks or pastebin, we might have a scandal like Alder Hey that could damage public confidence in medical research. Could such a dilemma be fixed by ethics committee? Here is a second example. One UK university has data on the movements of millions of vehicles taken from automatic number-plate recognition cameras. This has been """" pseudo-anonymised """" by hashing the license plate numbers, yet someone who knew that a target drove on road X at time t could search for all other sightings of that vehicle. Yet the Department for Transport asserts this is no longer personal data. It follows that anyone should be able to obtain a copy using the Freedom of Information Act – and by that I mean anyone, not just any researcher working within the framework of an ethics committee. The comfort that the committee's existence gave to civil servants …"""	automatic number plate recognition;c date and time functions;computer scientist;cynthia dwork;dorothy e. denning;freedom of information act 1982;freedom of information laws by country;laptop;list of minor characters in the matrix series;pastebin;percolation theory;personally identifiable information;privacy;randomness;wikileaks	Ross J. Anderson	2012		10.1007/978-3-642-34638-5_12	computer science;internet privacy;responsible disclosure;financial cryptography;ethics committee	ML	-64.78709969683635	-20.82973876481264	59268
4f7ae0d187e3c20ad3c864ea8eaf46b3a8586a68	a network model and simulation analysis of a journal review process	network model;simulation analysis	Abstract   The manuscript review process is of special interest to two groups: academicians comtemplating the submission of a paper for publication; and, editors and publishers involved in journal publication. Two aspects of special interest are (1) the probability of successfully negotiating the various hurdles to ultimate publication, and (2) the expected time to response from the editorial offices of the journal. The purpose of this paper is to accurately portray the manuscript review process of an existing journal (not CAOR), and to provide summary statistics concerning outcome probabilities and response times. The review process is depicted as a GERT network showing outcome branching possibilities and possible paths to success or failure. The network model is simulated 1000 times to provide summary data on response times at various critical stages in the review process.	network model;simulation	Laurence J. Moore;Bernard W. Taylor;Katherine A. Cattanach	1980	Computers & OR	10.1016/0305-0548(80)90025-8	computer science;artificial intelligence;network model;mathematics;operations research	Vision	-67.14654581299251	-15.608404806056159	59278
a116e1b4ac700699faa3a57987b95f1835814849	beyond the ballot box: computer science education and social responsibility		On 2 November 2004, millions of Americans went to the polls and cast their vote for the person they felt would best determine the future of America. Young people constituted a crucial part of the deciding vote and many organizations from MTV to the presidential campaigns made considerable efforts to increase the political awareness and involvement of this demographic category, typically characterized as the 18--24 year-old voter. This attentiveness to youth participation in national politics, albeit commendable, should not begin and end on Election Day. All citizens have a responsibility to remain informed of government actions and to express their approval or disapproval though public elections, communication with their elected representatives, or participation in any number of public forums or community organizations. However, readers of this magazine have a particualr responsibility as educators of the future generation of computer and technologically literate citizens.	computer science	Eden Miller Medina	2004		10.1145/1044550.1041626	community organization;social responsibility	AI	-65.8089676246338	-20.236133046620072	59356
4e4be7ac14d1e12f47f486a8b8210a3adda6ddb8	operations research call for papers: special issue on computational economics: submission deadline: march 31, 2008	operations research	O research (OR) has a long and rich shared history with economics, dating back to seminal founders of the field who spanned both disciplines (Arrow, Bellman, Dantzig, Koopmans, Modigliani, Scarf, Raiffa, von Neumann) and through a mutual interest in both problem contexts (optimal allocation of resources, inventory management, investment planning, etc.) and methodology (optimization, decision theory, game theory, simulation, etc.). While the fields diverged beginning in the 1970s, today they are growing closer as economists have recognized a need to solve increasingly complex economics models that cannot be tackled using classical methods, and OR scholars are increasingly incorporating sophisticated economic ideas into their models to reflect modern business realities. The aim of this special issue is to provide an outlet for those working at this contemporary intersection of OR and economics. We seek papers that are of broad interest to both research communities, whether it be through applications, modeling techniques that are of mutual interest, or leading-edge methodology that can benefit researchers in both fields. Methods and applications of interest include:	computation;computational economics;operations research	Kenneth L. Judd;Garrett J. van Ryzin	2007	Operations Research	10.1287/opre.1070.0468	game theory;arrow;von neumann architecture;computational economics;operations research;management science;decision theory;computer science;resource allocation	Robotics	-70.65461094652301	-14.848488461411389	59373
094a32a992fbdda980fdef8980b053a387937e88	représentation de données et métadonnées dans une bibliothèque virtuelle pour une adéquation avec l'usager et les outils de glanage ou moissonnage scientifique		The vehicles for official knowledge, as well as university libraries, suffer from an increasingly visible lack of interest. This is due to the advent of fully digital practices. By studying the psychological and cognitive models in information retrieval initiated in the 1980s, it is possible to use these theories and apply them practically to the Information Retrieval System, taking into account the requirements of virtual libraries. New metadata standards along with modern tools that help managing references should help automating the process of scientific research. We offer a practical implementation of the given theories to test them when they are applied to the information retrieval in computer sciences. This case under study will highlight good practices in gleaning and harvesting scientific	cognitive model;computer science;information retrieval;library (computing);requirement;theory	Gérald Kembellec	2011	CoRR		cognitive model;information retrieval;data science;computer science;scientific literature;metadata;scientific method;cognition	Web+IR	-72.42997514486751	-21.106019115166823	59478
03e1d0aefb380112adf61a23f74eff4fb94060f3	geospatial technology: curricular keystone of applied geography		Research into the nature and function of curricular matters in applied geography has provided an opportunity to assess the penetration and relative importance of geospatial technology to the discipline of geography. Departments of Geography with degree programs in applied geography were surveyed to find out how important geospatial technology was in the preparation of students for meaningful jobs and careers. The Applied Geography Specialty Group of the Association of American Geographers (AAG) was also surveyed about the value of geospatial technology, as was the 95 academic programs that listed applied geography as a “program specialty” in the AAG Guide to Geography Programs in the Americas. There was a uniform agreement across these various groups that geospatial technology occupied an extremely important position in their overall course offerings, and if you are watching the workplace, such courses are not only sensible but offer critical employable skills for students upon graduation. It is widely known that geospatial technology education and training require a large commitment of departmental resources, including faculty lines, equipment expenditures, space, and technical support. A geography department and its university’s administration have to understand these unique requirements and allocate resources, more akin to a computer science department than a traditional academic unit. This reality is of immediate importance to geography departments because almost one quarter of all academic jobs advertised in geography over the last six years have been in the broad area of geospatial technology. A final conclusion to this research is a policy matter that suggests geography departments take a strong proprietorial position toward providing education in geospatial technology because other disciplines and training programs see opportunities in a rapidly expanding workplace skill and they are aggressively pursuing a niche of their own.	computer science;geomatics;keystone effect;niche blogging;requirement;technical support	Richard G. Boehm;Audrey Mohan	2010	IJAGR	10.4018/jagr.2010071602	strategic geography;geography;computer science;engineering;sociology;management;operations research;cartography	HCI	-67.20257589613472	-21.063790877419382	59501
0a9ddcc9be462b1c83a41949f4b67f8c4325bc20	building an oai-based union catalog for the national digital archives program in taiwan	archivo electronico;echelon national;escalon nacional;project;open archives;proyecto;archive;digital archive;archives ouvertes;union catalog;biblioteca electronica;taiwan;asie;archivo;electronic library;catalogue collectif;projet;system architecture;catalogo colectivo;bibliotheque electronique;electronic storage;asia;archivage electronique;national scope	On January 1st 2002, the National Science Council of Taiwan launched a National Digital Archives Program (NDAP). To share the digital collections of all the archive participants, search via a union interface, and allow the general public access to the collections, it is urgent to build a union catalog of the National Digital Archives. In this article, we define its functions and the system architecture, and explain the problems we encountered in developing the OAI-based union catalog system.		Chao-Chen Chen;Hsueh-hua Chen	2002		10.1007/3-540-36227-4_50	project;database;world wide web;systems architecture	Crypto	-71.26918665503155	-23.207606199776112	59734
da59cba358e213ec4b9fd4d4862f167c9f39fc44	live digital reference service: its present and future	offre service;information technology;look ahead;technologie information;biblioteca electronica;electronic library;tecnologia informacion;reference service;proposals;bibliotheque electronique	Digital reference is an emerging trend of traditional reference service. The paper highlights how the new face of service is evolving as a natural solution to keep pace with the multifaceted technological environment. It discusses about the basic concepts and essential elements of reference service and gives in detail the advantages, limitations and the technology base about the various established and emerging forms of digital reference.	categorization;cyberspace;email;information seeking behavior;mail (macos);mechatronics;online chat;requirement;virtual community;web service	Paul W. T. Poon	2004		10.1007/978-3-540-30544-6_73	service catalog;telecommunications;computer science;look-ahead;service design;operations research;law;information technology	Web+IR	-71.63284030199792	-23.256893477085253	59848
c51dad525134f2e4166b045ddc049b9b5005e171	journal self-citation i: overview of the journal self-citation papers - the wisdom of the is crowd				Paul Gray	2009	CAIS			Vision	-64.2560221649497	-11.92849010972324	59997
adf9c061090f18482bc532de2dc0475a85a65c1b	industrial research in india as viewed throughresearch & industry	analyse bibliometrique;sector privado;secteur public;periodical;industrie;evolucion;sector publico;industria;research industry;recherche developpement;1980 1990;public sector;activite recherche;research activity;periodique;industry;periodico;research paper;research and development;secteur prive;asie;investigacion desarrollo;recherche appliquee;bibliometric analysis;private sector;applied research;investigacion aplicada;india;asia;inde;analisis bibliometrico;evolution	The paper examines the bibliometric characteristics of industrial research activity of India. The study reveals that public-funded R&D is the major contributor of research papers, inResearch & Industry while the contribution of in-house R&D centres is lacking. Among the two industrial sectors (Chemical and Engineering), much of the R&D activity, as reflected by published papers, has been in chemical and allied industries. However, there appears to be a significant change in emphasis during the decade studied, namely a decrease in R&D activity in engineering industries with a corresponding increase in ‘miscellaneous’ industries. There is a significant increase in exploratory research. R&D and industry interface is found inadequate. Multiplicity of authorship is gradually increasing. Indian Industrial research is heavily dependent on foreign and non-patent literature.	bibliometrics	M. M. S. Karki;K. C. Garg	1995	Scientometrics	10.1007/BF02017334	evolution;public sector;management;operations research;private sector	SE	-74.9177922290361	-22.359983885418355	60082
903c89dc09caaa686c7211b0ce4fd77558101902	pattern analysis in the study of science, education and innovative activity in russian regions	cluster analysis;pattern	We describe the method of pattern analysis and the results of its application to the problem of analyzing the development of science, education and the success of innovative activity in the regions of the Russian Federation. We examine characteristics of the regions of Russia such as the level of socio-economic conditions and the potential and efficiency of science, education and innovative activity from 2007 to 2010. Also we obtain a classification of regions by the similarity of the internal structure of these indicators, construct trajectories of regional development over time, and find groups of regions carrying out similar strategies. Available online at www.sciencedirect.com	pattern recognition	Fuad Aleskerov;L. Egorova;L. Gokhberg;Alexey Myachin;G. Sagieva	2013		10.1016/j.procs.2013.05.089	management science;operations research	ML	-76.73684432343858	-18.228456287812197	60108
0817f15537091d36a74ecc7be7fb12ce5a8e4a58	which type of citation analysis generates the most accurate taxonomy of scientific and technical knowledge?		In 1965, Derek de Solla Price foresaw the day when a citation-based taxonomy of science and technology would be delineated and correspondingly used for science policy. A taxonomy needs to be comprehensive and accurate if it is to be useful for policy making, especially now that policy makers are utilizing citation-based indicators to evaluate people, institutions and laboratories. Determining the accuracy of a taxonomy, however, remains a challenge. Previous work on the accuracy of partition solutions is sparse, and the results of those studies, while useful, have not been definitive. In this study we compare the accuracies of topic-level taxonomies based on the clustering of documents using direct citation, bibliographic coupling, and co-citation. Using a set of new gold standards – articles with at least 100 references – we find that direct citation is better at concentrating references than either bibliographic coupling or co-citation. Using the assumption that higher concentrations of references denote more accurate clusters, direct citation thus provides a more accurate representation of the taxonomy of scientific and technical knowledge than either bibliographic coupling or co-citation. We also find that topic-level taxonomies, created from paper-level clustering, are far more accurate than discipline-level taxonomies based on journal clusters.	bibliographic coupling;citation analysis;cluster analysis;co-citation;sparse matrix;taxonomy (general)	Richard Klavans;Kevin W. Boyack	2017	JASIST	10.1002/asi.23734	computer science;data science;data mining;world wide web;information retrieval	HPC	-77.39771334944105	-19.82522624175823	60161
17110ad7099be13fdde1919727e3bb36dff0a07c	peter-paul verbeek, what things do: philosophical reflections on technology, agency and design - the pennsylvania state university press, university park, pennsylvania, 2005, paperback, £16.95, $25.00, isbn-10: 0271025409, isbn-13: 978-0271025407, hardback, £50.95, isbn-10: 0271025395, isbn-13: 978-		How often does one find a book on philosophy of technology that is philosophically rewarding, interesting for sociologists and suitable for teaching engineering students? Peter-Paul Verbeek’s What Things Do is such a book. In this insightful examination of the technological mediation in human action, he both poses new philosophical and societal questions, and offers a new way of bringing ethics into the practice of designing technical artifacts. By ‘‘technological mediation’’ Verbeek means to refer to the way technological artifacts co-shape human action and perception, e.g., cars co-shape the perception of distance, cell phones co-shape ways of socializing, and the microwave co-shapes eating habits and family life. As Verbeek notes in his introduction, this new way of examining such mediation is mainly based on a combination of philosophical theories about technological mediation and agency, and actor-network theory (ANT). ANT has its origins in the social network analyses done by sociologists to understand how some individuals and groups influence society. Bruno Latour [1], Michel Callon [2] and others have extended this approach to include networks of humans and artifacts, especially in the analysis of the processes by which engineers come to settle on one design rather than another in their professional work. The main body of the book is divided into three parts. Part one starts with a critical review of what Verbeek calls the ‘‘classical period’’ in the philosophy of technology, as in the work of philosophers such as Karl Jaspers and Martin Heidegger. For instance, Verbeek argues that their (transcendental) methodology only looks ‘‘backwards’’ to what must be presupposed in order to make technology possible. They try to understand technology by philosophical reflection on sociohistorical trends and metaphysical assumptions. Verbeek, however, is more	amiga reflections;artifact (software development);international standard book number;michel hénon;microwave;mobile phone;network theory;pc bruno;social network;socialization	Katinka Waelbers	2007	Science and Engineering Ethics	10.1007/s11948-007-9010-0	engineering ethics;social science;management science;sociology	HCI	-65.3118819311707	-19.317691229439085	60192
8e986c3249cfde0400e17c52f4ec54a5417ddc32	the increasing role of international cooperation in science and technology research in mexico	analyse bibliometrique;international organizations;international cooperation;paises en desarrollo;america latina;scientometrics;science and technology;pays en developpement;amerique;characteristics;collaboration scientifique;amerique latine;sci science citation index;caracteristicas;caracteristiques;estudio caso;america central;scientometria;scientometrie;etude cas;developing country;cooperacion internacional;latin america;bibliometric analysis;america;recherche scientifique;central america;scientific research;cooperation internationale;investigacion cientifica;scientific collaboration;mexique;developing countries;analisis bibliometrico;mexico;amerique centrale	Increasing importance is being given to international scientific activities, especially with regard to developing countries. In the present paper, an analysis is made of the studies published by Mexican institutions in coauthorship with foreign colleagues between 1980 and 1990, as registered in mainstream journals. Different characteristics of the collaboration are described, such as research areas, countries and institutions involved, of interest to Mexican policy makers and scientists, as well as to foreign governments and international organizations sponsoring cooperative agreements with Mexico.		Jane M. Russell	1995	Scientometrics	10.1007/BF02019172	development economics;developing country;computer science;economic growth	HPC	-75.08168381874661	-22.316416151993135	60295
d2da315cc0e2ab8cebd9428296e5d3327748b191	awardu: a formal, fair, fun program to honor it staff	employee recognition;employee retention;management	"""In 2014, we began to create an employee recognition program for about 110 employees in the Office of Information Technology at West Virginia University. Immediately after initiating the project, the Chief Information Officer announced that our unit would be merging with several others, more than doubling in size under the new name, Information Technology Services. We needed a way to not only recognize good work and good deeds in a timely fashion, but also to create a stronger sense of unity among these newly merged IT organizations with different cultures and practices.  Over six months, a large, diverse committee built a scalable, transparent, accountable, peer-judged program aimed at improving employee morale and retention. With both positive and negative examples of past, unstructured, personality-dependent programs in mind, the AwardU Committee designed a system that is fair, unbiased and inclusive. With well thought-out definitions of recognizable excellence and three categories, we have awards that anyone in ITS can win, regardless of the nature of their duties.  Determining key ITS values and principles helped us design a meaningful, rule-driven program that staff would use, appreciate and support, all within the confines of financially restrictive state ethics laws regarding employee recognition. The RockIT Awards were designed BY employees FOR employees. The program today is formal, fair and fun, complete with an awards breakfast, unique prizes and hand-poured metal trophies that travel among winners like the Stanley Cup in the NHL.  """"This program is bigger than any of us, required all of us and is made to continue without us,"""" Chairman Steven Marra told the committee after our first year. Six quarters in, we have a charter, functional data, formative notes and anecdotes we believe could help others emulate this program even as it continues to evolve."""	chief information officer;period-doubling bifurcation;scalability;stanley (vehicle)	Vicki Smith;Steven Marra	2016		10.1145/2974927.2974947	public relations;engineering;operations management;management	PL	-66.48254778197055	-21.96063869203331	60297
e0539d41446dc79b59450df83b33dc5b950cc150	a license to build (software)		Conference hotels look remarkably similar around the world. This similarity can lead you to believe you understand a problem when you don’t. I fell into this trap while trying to answer a question about my opinion on the Malaysian government’s proposal to license software engineers. After a pause, I gave a pat speech about risk control. I ran through the standard argu ments and talked about the public nature of engineering, the risks borne by communities, the rights of communities to mitigate those risks, and nally, how the software industry has chosen a di erent strategy to address risk. My words were politely received but were followed by a moment of silence long enough to remind everyone in the room that computer scientists work in a global industry that has to deal with local problems. The licensing proposal came as the Malaysian government was preparing a new ve-year economic plan. Unlike the economic plans of the old Soviet Union or those once common in India, the 2016–2020 Malaysian economic plan is closer to a corporate strategic plan. It articulates goals, identi es infrastructure investments, catalogs best practices, and outlines policy changes. It’s an aggressive document with subtle references to the successes of India and China, two countries that serve as both models and competitors for Malaysia. This proposal was originally part of a plan to expand Malaysia’s technology workforce—which had already doubled in the prior ve years—by about 30 percent between 2016 and 2020. The policymakers, or at least some of them, reasoned that requiring licensure would make software engineering jobs more prestigious. They imagined hundreds if not thousands of young workers would ock to the eld, similar to the structural engineers who built the famous Petronas Towers in Kuala Lumpur. Time and again, software developers report that they don’t have the same status a orded to product managers or nancial managers. So anyone who has spent time in the software eld knows that there’s a desperate truth behind the Malaysian reasoning, though it might not be enough to achieve the desired results. Indeed, a license might elevate a software developer’s status, but it could just as easily burden the job with additional costs that would discourage people from entering the eld. In passing judgment on this proposal, I needed to move from theory to practice, from speculative reasoning to cold, hard facts. The facts came in the form of Information Technology Professional Examination Council (ITPEC) certi cates. These certi cates aren’t licenses, but they were developed in the mid-1990s (as the software outsourcing market began to grow) to give programmers access to the Japanese software market. Run by a Japanese nonpro t, the certi cate programs are o ered in Malaysia, Vietnam, Mongolia, Thailand, Myanmar, the Philippines, and Bangladesh, but they’ve never been popular. Over 20 years, they’ve brought about 3,500 programmers to Japanese rms. Less than ve came from Malaysia. By the time the nal document was published, the Malaysian government had abandoned its plan to license software developers. As the idea passed from o ce to o ce and meeting room to meeting room, policymakers recognized that it could actually incentivize people to look for jobs in other elds. However, the government still needed a plan to expand the software-developer workforce, so it embraced a set of ideas that have been discussed in almost every meeting room in the world. They decided to promote early STEM education, build more technology incubators, fund nonstandard training programs, and encourage more joint programs between business and education.	best practice;computer scientist;es evm;job stream;make;outsourcing;programmer;software developer;software engineer;software engineering;software industry;speculative execution	David Alan Grier	2017	IEEE Computer	10.1109/MC.2017.60	sqale;mit license	SE	-64.0443678265064	-22.928861242695444	60628
ff18d2067e10cd4e0089720d5fb3b88c04545341	abstract games		"""ealm is a wonderful and unique two-person abstract strategy game. It involves capturing territory and blocking and immobilizing the other player's pieces. New pieces are generated and added to the game as the game progresses, and strategy and objectives dramatically change through the course of the game. A few rules generate a game of great complexity and depth. People new to the game play a decent game fairly soon; mastery will take a long time, as the depth of the game is gradually revealed. Individual games are quite different from each other, with different patterns requiring different strategies. Also, a small change in the number of starting pieces often results in dramatic changes in optimal playing strategy. Realm is little known or analyzed. Hence, there is great opportunity for people who like to discover game strategies; and, currently, people can not have an advantage because they have memorized some standard moves and defenses (as in Chess and Go). In this article I give a brief history of Realm, the complete rules, and a number of significant variations. Then I will discuss general playing strategy and provide the moves of a complete game. History and Development Realm was created by Phil Orbanes, with input from Sid Sackson. They, and others, had a small game company in the1970's called Gamut of Games, which released Realm. Another game of theirs was Cartel, a fun family game for four. (Cartel was later rereleased under the name """"Dallas."""") Gamut of Games went out of business, and Orbanes went to work for Parker Brothers. Orbanes did not pursue development of Realm due to a conflict of interests. My friend Stanley Levin and I love Realm, so we acquired the rights to Realm from Orbanes, to see if we could get it back on the market. We had a number of copies of Realm made up, which we sold locally and through the mail. These are now gone. The primary reason for having this version made was to have a model to try to sell the game to a company to mass-produce. Although several companies showed initial interest, we were overall unsuccessful because of a general perception of a lack of an adequate market for new abstract strategy games. We did come close to success a few times. For example, Abstract Games magazine: game strategy articles, game reviews, news :..."""	blocking (computing);the stanley parable	Michel Hirschowitz	2005				ECom	-65.40236673845469	-22.55194727209885	60669
5a8235daa4001536b83aba51f92cfe21d0fd8863	independent research of china in science citation index expanded during 1980-2011	web of science;top cited articles;y index;bibliometric;country	The study explores the characteristics of China’s independent research articles published from 1980 to 2011, based on the database of Science Citation Index Expanded. The publication outputs of seven major industrialized countries including Canada, France, Japan, Germany, Italy, the UK, and the USA were compared with China. Annual production, field performance, research emphases and trends, top articles, as well as main institutional and individual contributors by its top cited articles were analyzed. Some newly developed indicators related to words in title, author keywords,	citation index	Hui-Zhen Fu;Yuh-Shan Ho	2013	J. Informetrics	10.1016/j.joi.2012.11.005	country	DB	-76.41972600335549	-20.886072069607586	60774
4d37bae6b751c72911d60bfae8d97c9e199dbcfd	a terminology proposal	computer program;chemical engineering;memory systems;random access;association for computing machinery	It has been suggested that we need some new words in our industry. For example, consider the following two definitions of the term <italic>random access</italic>:<list><item>Access to storage under conditions in which the next position from which information is to be obtained is <italic>in no way</italic> dependent on the previous one. </item><item>Feature of certain internal memory systems, <italic>particularly magnetic drum type</italic>. </item></list> (In both cases the italics are the author's.)  of a set of publication standards suitable for use by the Association for Computing Machinery, based on the standards adopted by the Machine Computation Committee of the American Institute of Chemical Engineers. The writer, as a member of this Committee, is acting merely as agent of the Committee in presenting the following upon the request of the Editor for Standards of the ACM. This article is only a summary of the standards adopted by the AIChE; further details are contained in a pamphlet entitled “Guide to Abstracts and Manuals for Computer Program Interchange”, prepared by the Machine Computation Committee of the American Institute of Chemical Engineers.<supscrpt>1</supscrpt>	computation;computer data storage;computer program;drum memory;protologism;the machine	Fred Gruenberger	1960	Commun. ACM	10.1145/366959.366962	computer science;programming language;algorithm;random access	Graphics	-64.30434194787061	-18.39275539434854	60829
733b309edc0856194a620c334a8740cb5df5f28e	quantified self: a literature review based on the funnel paradigm		Over the last decade, increasing scholarly interest has been demonstrated by the exponential growth of published studies on the topic of Quantified-Self (QS). After 10 years of existence, it seems important to review the knowledge accumulated on QS in order to identify potential gaps and avenues for future research, especially in the IS field. We rely on a systematic literature review in the field of Information Systems with the approach recommended by Okoli and Schabram (2010). In addition, we use the paradigm funnel (Berthon et al., 2003) to structure our analysis. We find that the literature on QS covers three main domains. The technological domain has studied data mining, visualization and user behaviour. The medical domain has focused on the benefits of QS especially for health management and the social domain is more critical about the implications of QS in people’s life. Also, our analysis of the literature reveals a concentration of empirical and critical articles and few theoretical and methodological papers. Future research should fill in these gaps.	data mining;information systems;programming paradigm;quantified self;systematic review;time complexity;word lists by frequency	Jean-Francois De Moya;Jessie Pallud	2017			knowledge management;funnel;computer science	HCI	-75.73006343676671	-16.871640888940153	60897
73a080f07808f7d363aded546d029bbea8f44041	pgp whole disk encryption: blazing trails in it security at uw medicine	macintosh;encryption;protected health information;hipaa;whole disk encryption;large scale;it security;windows xp;health insurance portability and accountability act;compliance;software deployment;pgp;organizational structure;data security	The Department of Surgery at the University Of Washington School Of Medicine is faced with the challenge of providing IT security to faculty, researchers, and staff within a clinical hospital environment and at multiple sites. Many departmental faculty and staff use laptops running Windows XP and often find it necessary to travel to multiple locations throughout the day or week. Additionally, regulations such as the Health Insurance Portability and Accountability Act (HIPAA) and the Family Educational Rights and Privacy Act (FERPA) mandate the protection of protected health information (PHI) and student data that many members of the department interact with as a normal part of their work. Such data stored on departmental laptops must be secured. Concerned with data security, the department is deploying PGP Universal in order to protect this fleet of laptops with a centrally managed, whole disk encryption solution.  A centrally managed whole disk encryption solution was desired for both Windows XP and a small number of Macintosh laptops, but not available for the latter. The Department of Surgery IT Services Group (ITSG) selected PGP Universal for the Windows-based solution and monitors PGP Corporation's ongoing development of a Mac OS X whole disk encryption solution. ITSG staff tested PGP and a deployment process was developed in the hopes of avoiding technical problems. Minor installation problems that did occur were found to be the result of computing staff's deviation from installation procedures. The amount of time required to deploy the solution across the department was underestimated; the project has taken additional time for several reasons, including the difficulty in coordinating installations with a mobile workforce; a number of competing, large scale products; and possibly the ITSG organizational structure. While the use of PGP whole disk encryption has necessitated a change in behavior for both laptop users and ITSG staff, these changes are minor and can be addressed with careful planning and forethought.	computer security;data security;disk encryption;health insurance portability and accountability act;laptop;microsoft windows;operating system;pgpdisk;planning;pretty good privacy;privacy act (canada);protected health information;software deployment	Kristen Dietiker	2008		10.1145/1449956.1449964	engineering;operations management;world wide web;computer security	Security	-69.1008256002263	-14.276785977684604	61167
a700165f0ab1438c5852276b0e23be5337ff7f86	coherence and responsiveness	new model;hugh dubberly	Models help bridge the gap between observing and making---especially when systems are involved (as in designing for interaction, service, and evolution). This forum introduces new models, links them to existing models, and describes their histories and why they matter. Hugh Dubberly, Editor	responsiveness	Jared Harris;Austin Henderson	2012	Interactions	10.1145/2334184.2334199	simulation;engineering	SE	-65.19613062343814	-13.077502401379606	61168
e762b5620ed1db8f503cb6ff0a1ca2bc7ccf5538	improving remote sensing research and education in developing countries: approaches and recommendations	technology transfer;remote sensing;developing countries;capacity building	Since the 1970s, a number of different models have been used to develop basic and applied science capacities of remote sensing in developing countries. Those efforts have had varied levels of success. One of the more effective capacity building efforts is extended training workshops held within the targeted developing country institution with existing resources. The extending training format requires participant teams to complete a remote sensing project for their country in their organization. The basic science activity of developing country scientists was documented by a review of six remote sensing journals which determined that a very small percentage of remote sensing manuscript authors are from developing countries. Many developing countries have established internal remote sensing capacities but many others have not. Given the potential importance of remote sensing for natural resource assessment and monitoring as well as economic decision making, more attention must be given to assisting those countries in hardware, software, internet capacity and technical assistance.		Barry Haack;Robert A. Ryerson	2016	Int. J. Applied Earth Observation and Geoinformation	10.1016/j.jag.2015.11.003	developing country;geology;knowledge management;environmental resource management;management science;remote sensing	HCI	-71.36932693115713	-14.60853601890401	61299
e493699751fae358fd2131b994180cbe112ae446	babs2: a new phase, a new perspective in digital long-term preservation - an experience report from the bavarian state library		BABS is an acronym for Library Archiving and Access System (Bibliothekarisches Archivierungsund Bereitstellungssystem), which constitutes the infrastructure for digital long-term preservation at the Bavarian State Library (BSB). During the two-year project BABS2 funded by German Research Association (DFG) BSB focuses together with the LeibnizSupercomputing Centre (LRZ) on advancing its organizational and technical processes under the aspect of trustworthiness according to the nestor criteria catalogue. Important achievements are e.g. framing an institutional policy for digital preservation including local, regional, national tasks of a large-scale research and archive library, conducting and evaluating a survey concerning the archiving requirements of all BSB departments, documenting the ongoing archiving processes, introducing an appropriate quality management and improving the scalability of the preservation system. Additionally BSB participate in different national and international committees. This experience report sheds light on the various organizational and technical aspects which have to be taken into consideration when enhancing an existing infrastructure for digital long-term preservation.	archive;back-side bus;digital data;framing (world wide web);nestor (encryption);requirement;scalability;software documentation;trust (emotion)	Tobias Beinert;Markus Brantl;Anna Kugler	2010			library science;engineering;operations research	SE	-65.81545506327042	-15.176981353683178	61657
291ccb87357e3e588db42310c3b8e68a009540d7	data visualization in online journalism and its implications for the production process	information resources data visualisation information networks;information resources;online journalism;collaboration;data visualization visualization interviews production collaboration media;conference paper;data visualisation;data driven journalism;information networks;storyboard data visualization interactive information graphic data driven journalism online journalism attitude collaboration sketching;data visualization;new york times newsroom data based visualization online journalism production process data stories computer science data driven journalism german media companies swiss media companies american media companies grounded theory;storyboard;attitude;sketching;interactive information graphic	"""Data stories -- this buzzword links together two different disciplines: computer science and journalism. The new relationship is called data-driven journalism. The emerging product of this relationship: data-based visualization that reveals the story behind the data. However, who produces those """"data stories""""? A journalist, an information designer, a computer scientist, or a team? New formats often implicate new workflows and a new way of thinking. This paper sets data visualization in the context of online journalism by focusing on the production process. We interviewed 19 experts of German, Swiss, and American media companies: designers, programmers, and journalists. For the analysis of the interviews we used the grounded theory approach. The findings show: The crucial success factor in the production process of data-based visualization in journalism is the attitude that everyone in the team acts as a journalist -- no matter whether programmer, designer or statistician. A case study of the New York Times newsroom illustrates our findings."""	computer science;computer scientist;data visualization;digital journalism;information design;programmer;the new york times	Wibke Weber;Hannes Rall	2012	2012 16th International Conference on Information Visualisation	10.1109/IV.2012.65	human–computer interaction;computer science;technical journalism;multimedia;world wide web	HCI	-70.20971511600094	-20.41878676906791	61735
4a7871f6a2e8357c58ee058f7fef9f4cff5819ee	issues of censorship vs privacy on computer networks	computer network	In June 1990, a front-page headline in the “Houston Chronicle” announced “Computer Porno a Keystroke Away.” Joe Abernathy, the author of the article, claimed that at least one high school student with access to the Intemet for school work had stumbled across “the world’s most sophisticated pornography ring,” finding both spicy stories and explicit graphics. Furthermore, he claimed, this was not mere porn, but copyrighted porn, electronically duplicated without a license	event (computing);graphics	Joanne Costello	1991		10.1145/122898.122907	computer science;internet privacy;world wide web;computer security	Security	-63.80647605753506	-20.579792410381412	62308
7973e2b93cc8e8b310063ab8b6c44ee26575dc56	from the editors: virtually yours		"""T itling this month's editor's note """" Virtually Yours """" was irresistible—it's one of those names that's so bad you just have to use it. It reminds me of the hair salons you find in small towns: Shear Elegance, A Cut Above, you know the type. And believe it or not, hairstyling is not unrelated to the topic of this month's special report, virtual machines: they're both subject to the whims of fashion. OK, so admittedly that's a reach (and a bad one at that), but don't take my word for it, ask Mendel Rosen-blum. We did. For those of you unfamiliar with the name, among other things Rosenblum is the cofounder of VMware (the little virtual machine company recently acquired by EMC for $635 million). He joined the Queue advisory board for a recent session to help us prepare this month's special report. As he spoke, the room grew quiet, and eyes grew wide. Umm, smart guy, yep. Rosenblum was kind enough to bottle his thoughts for wider dispersion in this month's lead article, """" The Reincarnation of Virtual Machines. """" And it turns out that what's old is new again, again. One of the ideas that always comes up when thinking about virtual machines is that of separation and boundaries , the idea of a safe """" sandbox """" in which to play. This turns out to be an area of some complexity as separation isn't necessarily a hard-and-fast idea; it's perhaps better understood in terms of a spectrum. Poul-Henning Kamp and Robert Watson, the implementers of FreeBSD Jail—a server-side sandbox of sorts with a semipermeable separation model—explore this spectrum in """" Building Systems to Be Shared, Securely. """" They also take a look at why they chose the model they did for Jail and some of the trade-offs they made. Of course, building systems to permit safe and separate execution is only one reason to build a virtual machine. Another (and many of you will be familiar with this one!) is to solve the problem of what to do with old code once the hardware no longer exists. As Bob Supnik explains in """" Simulators: Virtual Machines of the Past (and Future), """" simulation, emulation, and virtualization are in many ways different sides of the same coin (and for those of you keeping track, I know there's no such thing as a three-sided coin!). Supnik is the …"""	blum axioms;emulator;freebsd;lawrence j. rosenblum;reincarnation;secure communication;server (computing);server-side;simulation;towns;virtual machine	Edward Grossman	2004	ACM Queue	10.1145/1016998.1017007	world wide web;computer science	PL	-64.12697484819023	-22.434956743509698	62329
687e2b141307df3df0fe49ccc8fc55dc78da7d4b	international cooperation of polish researchers with partners from abroad: a scientometric study	international cooperation;europa;scientometrics;policy;sciences;polonia;cambio;poland;influencia;coauthorship analysis;political aspect;ciencia;change;aspecto politico;influence;polonais;polish;scientometria;pologne;scientometrie;changement;cooperacion internacional;analyse coauteur;europe;database design;politica;polaco;politique;cooperation internationale;sci;aspect politique	Publications resulting from international cooperation and included in seven SCI annual files 1987–1989 and 1992–1995 were analyzed. It was observed that after the political changes of the turn of 1980s considerable increase in the number of publications was accompanied by the geographic development of co-authorship. Information coming from SCI 1992–1995, elaborated, completed and encoded were entered into an own database designed for analytical purposes. During these four years above 9600 papers were published in over 1600 prestige journals, of which almost 2200 publications resulted from multilateral cooperation. Altogether the foreign coauthors came from 102 countries, but over 80% of international papers were published in cooperation with the partners from 11 countries. The domestic participants came from over 200 research and educational organizations. It was found that the biggest share of papers within this multidisciplinary file represented physics (≈40%), chemistry (≈21%), and biomedical research (≈11%).	database;geforce 9 series;scientometrics	Barbara Stefaniak	1998	Scientometrics	10.1007/BF02457975	social science;scientometrics;computer science;polish;sociology;operations research;law;economic growth;database design	DB	-74.99488436328856	-21.839686145933246	62660
4ce16eb6c8c1124aa68beba17689aadcf1c87bd9	expert systems for library and information services - a review	expert systems;online searching;abstracting;bibliographic utilities;classification;library services;reference services;indexing;computer software;cataloging;library and information services;gateway systems;library automation;expert system	Abstract   Do expert systems have a place in the Library and Information Services (LIS) industry? This paper reviews the progress made so far in the areas of online information retrieval, cataloguing, abstracting, reference work, and indexing and classification. Although largely of an experimental nature, the work undertaken so far will surely pay dividends in the future, given the huge advances in computing expected in the next decade. Thus LIS professionals can look forward to the time when, assuming the more mundane tasks are done by expert systems, they will be able to concentrate on the more interesting aspects of their work and spend more time with the public they serve.	expert system	A. Morris	1991	Inf. Process. Manage.	10.1016/0306-4573(91)90009-B	search engine indexing;biological classification;computer science;artificial intelligence;data mining;world wide web;expert system;information retrieval	DB	-70.82241471272208	-22.191112254472422	62672
37e9e557985a943dcb6898585249d3911bd197b7	computing education research: basic research in computing education?		IL LU S T R A T IO N : © C A N S TO C K P H O TO -R A D IA N T S K IE S Oxford English dictionary [10] characterizes basic research as “Theoretical research aimed at discovering scientific principles and facts; opposed to applied research, which puts those principles to practical use.” OECD glossary of statistical terms [9] defines basic research in a few more words: “experimental or theoretical work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts, without any particular application or use in view.” OECD defines applied research as “...original investigation undertaken to acquire new knowledge. It is, however, directed primarily towards a specific practical aim or objective.” In natural sciences basic research is a self-evident part of the work, whereas computer science can be widely considered applied research, which seeks to develop methods that can be implemented with computers, to address practical or theoretical problems. The field is, of course, wide and some areas, for example theoretical computer science, are closer to basic research whereas others, for example. usability research, are heavily connected to applications. My own PhD work in computer science in early 1990s concerned improving the efficiency of tree-based main memory search algorithms. By that time, it did not seem very relevant to justify the work by discussing concrete applications where the new algorithms would have true significance. Theoretical improvements were sufficient, and simulation results could supplement them. Thus, I would characterize that research close to basic research. Since then, I have been working in Computing Education Research (CER), and my work has been heavily applied. Yet the question of basic research occasionally pops up. So, where does Computing Education Research (CER) lie here? Is there anything in this field that could be characterized as basic research, that is, an area of research exploited merely or mostly for the sake of understanding something (without obvious applications in mind) or for developing models or theories to present the investigated phenomena and capture their essence? Why would such work be important? The field has a long tradition of empirical work, which explores the effect of new transfer their skills to program development on their own computer? While small, this is not an insignificant issue. Autograders and third-party server-hosted environments will increasingly permeate the landscape of education delivery. As is true of any new technology, many new questions will emerge and need to be examined carefully and outside the context of product evangelists and their claims. Making education efficient is not the goal. Making it effective, better, and more meaningful is. Much research needs to be done in this arena. 	computer data storage;dictionary;glossary;mind;observable;search algorithm;server (computing);simulation;theoretical computer science;theory;usability	Lauri Malmi	2018	Inroads	10.1145/3230692	computer science	AI	-69.90966319091437	-23.383444179726347	62919
d736ffc13ddf3ff3ebf4a434906faf1ea33e63bf	who's responsible for the digital divide? public perceptions and policy implications	framing;policy;responsibility;telecommunication policy;information and communication technology;ict;fracture numerique;experiment;public perception;brecha digital;digital divide	This article may be used for research, teaching and private study purposes. Any substantial or systematic reproduction, redistribution , reselling , loan or sub-licensing, systematic supply or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material.	primary source	Dmitry Epstein;Erik C. Nisbet;Tarleton Gillespie	2011	Inf. Soc.	10.1080/01972243.2011.548695	public relations;information and communications technology;digital divide;telecommunications;computer science;sociology;management;world wide web	OS	-69.37302410769551	-15.118133759251723	62943
3a475d90b0957e9f02ed3a1311a1164fb1f39ca0	databases on optical discs and their potential in developing countries	information transfer;developing nations;developing country;information retrieval;cost effectiveness	Developing countries rely on up-to-date information from technologically advanced countries, such as the United States of America and the United Kingdom, especially in the areas of science and technology, as a means to providing help for their scientists in the transfer of technology and in research development. Optical disc technology may prove to be an alternate approach for the access of massive information storage and retrieval. Major areas of information in which optical disc databases can help are discussed	database	S. Nazim Ali	1990	JASIS	10.1002/(SICI)1097-4571(199006)41:4%3C238::AID-ASI2%3E3.0.CO;2-3	computer science;database;optical disc;developing country;developed country;science, technology and society;information transfer;information access;information technology;information policy	NLP	-69.8517520712103	-17.9021259487585	63068
aca2da489799fd59308421458454fba07a298a3f	the economics of open access publishing	selected works;bepress	This special issue of Economic Analysis and Policy is devoted to try and understand the academic publishing industry and in particular the recent move towards open access, as EAP has done in 2008. The various articles examine the motivations, the challenges and the roadblocks for authors, editors, publishers, libraries and readers. It also highlights some of the benefits of open access beyond the obvious increase in readership. Several examples from journal editors, content management providers and bibliographic data distributors are also provided.		Matthew Cockerill	2006	Inf. Services and Use		library science;political science;media studies;public administration	DB	-68.54908561161032	-17.69272399124998	63075
c9c6c7f667cdc32920603def50c1c62d0993f521	efficient method dispatch in pcl	efficient method dispatch	Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Publications Dept, ACM Inc., fax +1 (212) 869-0481, or permissions@acm.org.	dynamic dispatch;fax;like button	Gregor Kiczales;Luis Rodriguez	1990		10.1145/91556.91600	computer science	DB	-65.40110007161832	-16.596315171988493	63139
726466adf0bb452426de6d7ddadb09a5b7c7ab77	disciplinary evolution and the rise of the transdiscipline		This paper challenges readers to reflect on academic disciplines in a new way, through the lens of the theory of evolution. Indeed, how disciplines came into being has been largely left unexplored. This paper shows how the concepts of evolution can be productively applied to describe the development, creation, and diminishment of disciplines. These concepts include natural selection, speciation, parallel evolution, extinction, and heterosis, among others. The paper concludes that these forces lead to a prediction that a new form of organization, the transdiscipline, is evolving to become perhaps predominant.		Eli Cohen;Scott J. Lloyd	2014	InformingSciJ		humanities;psychology;social science;artificial intelligence	AI	-75.92488876814527	-14.49304752681714	63229
f617e66c4fc9e9e5b3fbbaccb3968cbd859b9008	application of scientometric methods to chemical research in iran: reflections on iran&#39;s current science policy	analyse bibliometrique;scientometrics;case history;document publie;politica cientifica;scientific policy;science policy;chimie;university research;historique;asie;scientometria;published document;chemistry;scientometrie;quimica;recherche universitaire;bibliometric analysis;recherche scientifique;politique scientifique;scientific research;iran;documento publicado;investigacion cientifica;asia;analisis bibliometrico;estudio historico	Following a brief historical account of the initial difficulties of introducing modern sciences, especially the Western art of independent scientific inquiry, into Iran, using data obtained from the ISI (http://access.isiproducts.com/trials) an attempt is made to analyze the apparent present successes of Iranian scientists on the international science market. Using the corresponding ISI data of the publications (1990-2003) of 24 selected young chemistry Ph.D. graduates and present faculty members at various internal academia, a quantitative and qualitative assessment (www.geocities.com/iipopescu) of their achievements has been attempted and the results related to the strengths and weaknesses of the present science policy of the country.	amiga reflections;information sciences institute;iranian.com;scientometrics	Mohamed Yalpani;Akbar Heydari;Morteza Mehrdad	2005	Scientometrics	10.1007/s11192-005-0226-y	social science;scientific method;epistemology;scientometrics;computer science;sociology;world wide web	Logic	-75.13282553273149	-22.44826298989424	63315
5ce0e74c1a5200b5e45c7e710006d7a34197ebff	speed meeting: a special session to introduce academics and professionals to each other in person and via web cast		Abstract#R##N##R##N#The opportunity for companies with universities to create joint ventures is growing with a recent focus on short-term projects – not mergers. How can those involved in research and practice meet-especially graduate student researchers seeking collaborative university, corporate or government partners? Also, according to Wired magazine (April, 2007), there is a new emphasis on transparency and sharing across companies-beyond competitive intelligence. Such change is leading to increased knowledge sharing across corporate boundaries. Can information professionals share safely ideas, not secrets, and find partners for short-term development? Information technology companies seem less interested in formal mergers than in cooperative ventures (Apple with Google, for example).#R##N##R##N##R##N##R##N#Companies and schools invited to send representatives include: #R##N##R##N##R##N##R##N#M (St Paul, Minnesota)#R##N##R##N##R##N##R##N##R##N#Invitrogen Corporation (Milwaukee, WI)#R##N##R##N##R##N##R##N##R##N#Pierce Milwaukee (Milwaukee, WI)#R##N##R##N##R##N##R##N##R##N#Amylin Pharmaceuticals, Inc. (Milwaukee, WI)#R##N##R##N##R##N##R##N##R##N#Covance (Madison, WI)#R##N##R##N##R##N##R##N##R##N#University of Wisconsin-Milwaukee#R##N##R##N##R##N##R##N##R##N#University of Wisconsin-Madison		Deborah E. Swain;Beatrice Pullium;Kris Liberman;Anne E. Rogers;Deborah Barreau;Julie Hersberger;Leona Faust;Frank Exner;Deanna Hall	2007		10.1002/meet.1450440132	social science;computer science;sociology;law;world wide web	NLP	-63.75763923795571	-17.687281464052777	63491
73e7a5195dc2c424868f689e6d3a2a26df6a3d2a	from the editor’s desk		This month, we are adding a feature to the Journal of Digital Imaging (JDI) called “Point/Counterpoint” in which invited authors explore a controversial topic from different viewpoints. This feature was developed by Paul Nagy, Ph.D., our newest Associate Editor. The debate featured in this month’s Point/Counterpoint tackles the topic of ownership of Radiology Information Technology and picture archiving and communication system. The authors debating the issue are David Channin, M.D., and George Bowers, M.B. A. You will be able to comment on this and other future topics on our blog at blogs.springer.com/jdi. The Society for Imaging and Informatics in Medicine (SIIM) and JDI are jumping into social networking on Facebook and LinkedIn. If you join Facebook at http://www.facebook.com and then search for the Society for Imaging Informatics in Medicine, you will find our fledgling group and will be allowed to join where we can exchange ideas and many solutions to day-to-day issues. If you join LinkedIn.com, you will find a nicely organized professional site where you will be able to keep in touch with many people who share your interests. One of the groups available for you to join is SIIM and another is the Certified Imaging Informatics Professional group. Of course, you will then find other groups with different interests and will enjoy them as well. I like to work in stained glass and fused glass and found several groups to join where I can share ideas and learn new techniques. We will be looking for you on the JDI Blog, on Facebook, and on LinkedIn.		Janice C. Honeyman-Buck	2009		10.1007/s10278-011-9447-1		DB	-63.641292234798925	-18.888125203289878	63495
632627a80bd2d3c26c3e56c4093958ed4d5df67f	sources of chemical information used in antibiotic certification		Because of a legislative mandate requiring the predistribution testing and certification of each batch of antibiotics produced for human use in the U.S.A., the National Center for Antibiotics Analysis (NCAA) must utilize a wide variety of techniques for establishing its official methods. Methods adapted from material submitted by the manufacturers in Forms 5 and 6, as well as from other sources, such as literature searches, the NCAA reprint collection, and cross reference file are described.	certification;cheminformatics;cross-reference	Mary Lou Andrew;Lola G. Wayland	1979	Journal of chemical information and computer sciences	10.1021/ci60017a004	medicinal chemistry;combinatorics;certification;mathematics;antibiotics	ML	-66.72468428875263	-16.420068540975763	63761
b1ec15b93c0fa0e34fda72456b14c1291fba50ee	an international constitutional moment for data privacy in the times of mass-surveillance		Recently, there have been a lot of intense discussions on how human rights treaties might apply to extraterritorial mass-surveillance programmes. In the light of an increasingly prominent role that data privacy is gaining in the UN agenda in recent months, this article aims to make an original contribution to the international data privacy discourse by scrutinizing the different approaches to customary international law formation and applying these insights to ‘data’ privacy—as opposed to a general right to privacy—to examine whether it could be considered as a binding legal principle under international law. The article argues that different perspectives on customary international law and their respective methodologies of ‘deduction’ and ‘induction’ have different implications for the analysis of data privacy. Whereas under the so-called traditionalist perspective it could be doubted that data privacy has developed into a rule of customary international law, modernist approaches lead to different conclusions. The modern theories stipulate that a steady advancement of technologies in combination with a continued emphasis on international security and the unprecedented shock that international community is undergoing because of mass-surveillance revelations and spying activities of Western and potentially other governments, constitute the circumstances or period of fundamental change—the so-called ‘international constitutional moment’, paving the path for the swift development of a new rule of customary international law—the right to data privacy. Recognizing the ‘relativity’ of the different findings and conclusions, the article favours the modern approach and infers that data privacy has indeed crystallized into a norm of customary international law. K E Y W O R D S : data privacy, surveillance, customary international law, personal data, international law formation I N T R O D U C T I O N This article aims to provide an original contribution to the international data privacy discourse by scrutinizing the different approaches to customary international law formation and applying their insights to data privacy to examine whether it could be considered as a binding legal principle under international law. Despite data privacy’s status as a fundamental right in many jurisdictions and the accelerating spread of * Fellow at the Centre for Internet & Human Rights, European University Viadrina, PF 1786, 15207 Frankfurt (Oder), Germany. E-mail: monika.zalnieriute@eui.eu; https://cihr.eu. I am grateful for their most helpful comments and insights to the anonymous reviewers, Angela Daly, Professor Lee Bygrave, Dr Christopher Kuner, Professor Giovanni Sartor and Professor Alexander Trechsel. VC The Author (2015). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com. 99 International Journal of Law and Information Technology, 2015, 23, 99–133 doi: 10.1093/ijlit/eav005 Advance Access Publication Date: 31 March 2015 Article at U niersite L aval on Sptem er 1, 2015 http://ijlirdjournals.org/ D ow nladed from data privacy legislation around the world, it is unclear if the right to data privacy—or data protection as it is called in the EU—has obtained the status of a binding rule of customary international law (CIL), or if it remains an optional obligation which states may elect to assume. This question is especially important for several interrelated reasons in light of the solid ground that data privacy has gained during the last year within the international community and in the agenda of various UN bodies that have started to take serious efforts to address the increasingly urgent issues of data privacy and extraterritorial surveillance, mass scale data collection and the interception of digital communications. First, the relationship between national security interests and/or crime prevention by various search and seizure and interception techniques, on the one hand, and the individual right to data privacy, on the other hand, has always been a complex one. It has been understood by international and national tribunals as requiring a delicate balancing test on a case-by-case basis. The status of data privacy as binding rule of CIL would bring in a new dimension into this balancing exercise by requiring the judiciary to devote serious attention to data privacy interests that might not necessarily has been granted in the past. Secondly, as currently there is no binding international—or global—treaty dealing specifically with data privacy—as opposed to privacy in general—many different existing (or non-existing) data privacy rules around the globe leave businesses uncertain, deprive individuals of meaningful protection and impair the exchange of personal data online. In this context, the extent to which data privacy has acquired recognition as a principle of CIL is an important factor (for some—even a prerequisite) in international treaty making. It would have an impact in any future treaty negotiations in the area of data privacy. Thus, it arguably affects potential cooperation models for data privacy and international data exchange on an international level (and the EU and USA in particular). Thirdly, as the title of this article suggests, the status of data privacy as CIL arguably becomes particularly significant in the times of mass-surveillance. While it is true that a systematic governmental surveillance of particular and specific part of population is not a new phenomenon and extends ‘far beyond a particular country and a particular intelligence agency’, nevertheless, the recent revelations by Edward Snowden and others about the scale of such surveillance have exceeded the public imagination and have redefined the future of governmental surveillance practices. In contrast to target-specific surveillance, which is subject to individualized proportionality tests, mass surveillance is typically understood as the pervasive surveillance of an entire population, or a substantial fraction thereof by permitting bulk access to all digital communications traffic. It has no target-specific justification, and therefore, eradicates the possibility of any individualized proportionality analysis. 1 C Kuner and others, ‘PRISM and Privacy: Will this Change Everything?’ (2013) 3 IDPL 217–19 at 217. 2 See, eg, Report by the UN Special Rapporteur on the Promotion and Protection of Human Rights and Fundamental Freedoms While Countering Terrorism, Ben Emmerson, A/69/397, <http://daccess-dds-ny.u n.org/doc/UNDOC/GEN/N14/545/19/PDF/N1454519.pdf?OpenElement/> accessed 6 January 2015, para 8. 3 See Report A/69/397, paras 12 and 13. 100 International constitutional moment for data privacy at U niersite L aval on Sptem er 1, 2015 http://ijlirdjournals.org/ D ow nladed from The technological developments enabling the bulk access to all digital communications traffic, according to well-known data privacy experts, ‘will have significant long-term impacts on data protection and privacy law around the world, and on the political, economic, and social climate for data processing’. Thus, it is in this context of the new emerging horizons of mass—as opposed to target-specific—surveillance that the status of data privacy as CIL becomes particularly fascinating. Not least because in this context, there has been much intense discussion on how human rights treaties might (or might not) apply to extraterritorial surveillance programmes, and litigation before national and regional tribunals is already pending on these matters. In this context, the status of data privacy as a binding principle under international law is also of special significance because if data privacy was actually considered to be a rule of CIL, then even without an international binding treaty on data privacy, and irrespective of whether the International Covenant on Civil and Political Rights (ICCPR) would be found applicable or not to foreign surveillance, the mass-surveillance programmes could be challenged under international law on this basis. Most of all, the status of data privacy as a binding principle under international law is particularly important in order to secure individuals rights relating to the metadata produced by individuals’ electronic communications. The processing of this information may not always be covered by privacy laws, for it might fall short of the ‘private’ dimension generally required to trigger the protection of a right to private life under the human rights treaties. The author strongly supports the view that metadata should be protected under human rights treaties and agrees with Special Rapporteur Ben Emmerson that ‘In the absence of special safeguards, there is virtually no secret dimension of a person’s private life that would withstand close metadata analysis’. However, this view might not necessarily be accepted by the courts or gain strong international support by states. Thus, the applicability of data 4 Kuner and others, ‘PRISM and Privacy’ (n 1) 217. 5 See especially the Report of the Office of the United Nations High Commissioner for Human Rights on the right to privacy in the digital age, A/HRC/27/37, <http://www.ohchr.org/EN/HRBodies/HRC/ RegularSessions/Session27/Documents/A.HRC.27.37_en.pdf/> accessed 6 January 2015; Report A/69/ 397; I Brown and D Korff, ‘Digital Freedoms in International Law’ (Global Network Initiative, 14 June 2012) <https://globalnetworkinitiative.org/sites/default/files/Digital%20Freedoms%20in%20 International%20Law_0.pdf/> accessed 7 January 2015; and the EJIL: Talk series on extraterritorial surveillance and human rights treaties by M Milanovic, A Peters, C Nyst and C Kuner, </http://www.ejiltalk.org/> accessed 7 October 2014. 6 The most famous instance being the pending case before the European Court of Human Rights Big Brother Watch and Others v United Kingdom, App No 58170/13, lodged on 4 September 2013. On national level, Privacy International w	app store;common intermediate language;definition;email;global network;information privacy;mail (macos);prism (surveillance program);personally identifiable information;pervasive informatics;privacy law;right to privacy;snowden;swift (programming language);the times;theory	Monika Zalnieriute	2015	I. J. Law and Information Technology	10.1093/ijlit/eav005	privacy law;privacy policy;information privacy;privacy by design;sociology;privacy;law;computer security	DB	-71.3405117233076	-13.023542131432583	63777
2f5dced341a1dfeb3c5f049b3315f8c4adfb2225	an identity driven escalation of commitment to negative spillovers		The technological advances of the World Wide Web led it to become a highly interactive medium on which billions of individuals share not only their information but also their thoughts and beliefs. While it is an ideal tool to bring people together and expand horizons by connecting remote communities, sadly it is also dangerously effective in spreading diseases or hate crime. Such poor awareness on how such paradoxical outcomes arise is a societal challenge. This conceptual paper focuses on concealable stigmatized identities; i.e., culturally devalued identities that are not visible to others. When acted upon they produce socially questionable activities that incur social penalties and generate (tangible and intangible) societal costs. We explain how cognitive dissonance about one’s identity refines our current understanding of the relationship between (increased) Internet access and (increased) societal negative spillovers. We offer a process model explaining how online escalation-of-commitment leads to offline negative spillovers.	information systems;interaction;internet access;knowledge spillover;online and offline;online community;privilege escalation;process modeling;reverse engineering;world wide web	Christine Abdalla Mikhaeil;Richard Baskerville	2017			escalation of commitment;labour economics;business	HCI	-75.2242322731191	-11.842807451896343	64201
3f4f312e51312f2cbe50278548d4784229f759b9	a reglobalização do estado e da sociedade em rede na era do acesso	direito estado sociedade internet globalizacao;tese doutorado;book	The aim of this work is to examine the conditions, which enable the appearance of the phenomenon of reglobalization, and its effects on State and society, which spring from changes in the way of producing economic and cultural goods. Reglobalization results from the decline of modern paradigms as well as of the perspective of neo-liberal globalization, in which the flow of information aimed solely at the free flow of capital, uncurbed by local borders and sovereignty. The environment in which this phenomenon takes place is the virtual spacecyberspaceand the pattern of organization of the institutions and of society is that of information networks. It lies, therefore, within the sphere of post-modernism, once it takes into account the development of technique, science and information technology, particularly the Internet, as constituting elements. Concerning Law and State, the elements which recuperate the concepts of Nation-state and national sovereignty were sought, through the attribution of new roles to state, such as interventional action towards information flow regulation, development of regional economies and adoption of public policies which enable, on one hand, transparency and democratization of public administration, and on the other, access to computerized networks to all sectors of society, as a means of diminishing digital exclusion and allowing full exercise of social control by the state. The right of access, in reglobalized society, is elevated to the category of fundamental right, and becomes the main challenge to be overcome in the 21st century.	internet;numerical aperture;open road tolling	Luis Carlos Cancellier de Olivo	2003				HCI	-77.07048882964195	-12.091167956498554	64339
2e710ebda7053fed5bfc433d98790467c42d1b53	governance of digital content in the era of mass participation	light web;multi agent system;mass media;copyright;journal article;multi agent systems;digital media;digital content;music industry;intellectual property right;dark web;creative commons;contract design;artist life cycle	The realm of digital media is undergoing fundamental changes as it moves from mass media to an era of mass participation. This emergence of content created by the masses requires to re-consider the conventional intellectual property rights framework. Free content and protected content co-exist (in the Dark/Light Web). We propose an alternative environment for the governance of digital content. It incorporates psychological aspects into its economics framework. Multiagent systems play an important role in order to create an infrastructure that makes the voluntary-based environment sustainable. We propose a platform based on an open contracts design that encourages voluntary payments. Peer-based reputation and recommendation mechanisms as well as socio-emotive instruments facilitate norm-adherence in this online environment. They leverage the efficiency of alternative voluntary payment models based on fairness concerns and reciprocity. The envisioned platform matches Dark Web content to consumers who value it highly, provides Dark Web content creators with a basic reward for their work and reduces the infringement of protected content in the Dark Web.	agent-based model;dark web;digital media;digital recording;emergence;fairness measure;multi-agent system;web content	Tobias Regner;Javier A. Barria;Jeremy V. Pitt;Brendan Neville	2010	Electronic Commerce Research	10.1007/s10660-010-9043-3	public relations;economics;content management;computer science;marketing;digital media;multi-agent system;music industry;multimedia;advertising;law;world wide web;computer security;intellectual property;mass media	Web+IR	-67.66809593074953	-10.167081632979713	64362
e2a1c3e11e21ced5349ef95d58b048fd6ff1fa1d	citation lag analysis in supply chain research	analisis citas;citation network;citation analysis;interdisciplinary field;difusion conocimiento;research on research;diffusion connaissance;network analysis;analyse citation;knowledge structure;knowledge dissemination;interdisciplinaire;supply chain;interdisciplinario;knowledge integration;economic development;knowledge diffusion;recherche scientifique;scientific research;investigacion cientifica	Interdisciplinary research is expected to contribute to industrial and economic development. However, due to expansion of knowledge and the fragmentation of research fields, knowledge dissemination among different research fields is rare and we need a methodology for measuring such dissemination and promoting it. In this paper, we introduce a citation lag analysis of inter- and intra-clusters extracted by citation network analysis as a new indicator to represent the speed of knowledge diffusion in subfields of a research field. A case study was performed within supply chain research to investigate knowledge integration among its subfields. Based on the analysis, we discuss knowledge structure and reciprocal influence of subfields in supply chain research. This study contributes to offering a new approach for analyzing and understanding the development of boundary spanning research.	citation network;computation;file spanning;fork (software development);journal citation reports;knowledge integration;network theory;strategic management	Hiroko Nakamura;Shinji Suzuki;Tomobe Hironori;Yuya Kajikawa;Ichiro Sakata	2011	Scientometrics	10.1007/s11192-011-0341-x	interdisciplinarity;social science;scientific method;knowledge integration;network analysis;computer science;knowledge management;supply chain;operations research;citation analysis;world wide web;economic growth	AI	-75.13825083550381	-21.64170344897102	64371
dd3609b07b3aa1ad67d9ca847f90c6c2469bbbf2	the global data protection conundrum	global scale;international data protection law;global data protection conundrum;relentless stream;greater privacy;clear path;state-sponsored attack;news story	Given the relentless stream of news stories around state-sponsored attacks, spying and cybercrime, both on a national and global scale, it is hardly surprising that international data protection laws and regulations have come under increasing scrutiny. Politicians and the public alike are calling for greater privacy, transparency and security - yet there seems to be little consensus on a clear path forward.	information privacy	Richard Moulds	2014	Network Security	10.1016/S1353-4858(14)70009-1	political science;data mining;internet privacy;computer security	Crypto	-72.7325536995258	-11.922791402580835	64430
2b6848c1fbab5c5068b6893b2f29a3d0d5c18c57	the missing link: social network analysis in migration and transnationalism		Abstract The focus on social networks in migration studies marked a significant departure of understanding. Social networks are not only a mechanism through which the migration process is patterned, but they also have broader implications for migrants and non-migrants alike. Despite the fact that the network character of migration processes has long been recognized in migration studies, for a long time, Social Network Analysis has not been applied. Taking this scholarly omission as a starting point, we seek in this special issue to discuss recent research into social networks and migration that use SNA approaches.		Basak Bilecen;Markus Gamper;Miranda Jessica Lubbers	2018	Social Networks	10.1016/j.socnet.2017.07.001	migration studies;social network analysis;transnationalism;socioeconomics;social network;social science;sociology	Metrics	-75.10242887106232	-14.120429192800826	64557
e5be2d8258f5389bb8800bda68bb2e8ec6b8c68e	"""""""all relate to art"""": the william blake archive and its web of relations."""				Michael Fox;Joseph Fletcher	2018	Digital Humanities Quarterly			NLP	-62.93912131782358	-11.717124333987915	64646
95f8a9ee796528821358fc8c913775ce5b986748	the missing piece of the puzzle: neuroinformatics at the bench		A recurring theme in our editorials has been the limited success of data sharing in practice: too few neuroscientists share their data or models. A growing number of stakeholders have become concerned about promoting data sharing, as evidenced by a recent survey by a major publisher. To improve data sharing, efforts have been made to encourage more scientists to contribute their data by giving them rewards, like the citable data paper, or by contacting them personally based on publications listing suitable data 4 and publicly listing both available and unavailable data, including non-responders. Databases containing shared neuroscience data have been made easier to use and find. But surprisingly little has been done to help motivated neuroscientists organize their data in such a way that it is ready to be shared, despite the huge opportunities for improvement. It is a sad fact that although most scientific data is acquired digitally very few research laboratories in academic environments have adopted modern data management practices. Though it may seem an improvement to the scientist involved, there is really not much difference between having data in a bunch of poorly named files on a student’s hard drive compared to having boxes with tapes or microscopy slides on a shelf. In both cases the data is not annotated, not searchable and poorly linked to the description of the experiment, which, even now, is usually still handwritten in a lab notebook. In some aspects the current situation is even worse because new problems like poor back-up and security policies and obsolescence of data formats have arisen. The solutions to poor data management seem fairly simple and can be summarized as:	backup;box;computer cluster;database;editorial;entity name part qualifier - adopted;experiment;hard disk drive;laboratory;manufacturer recognized a recurring performance failure;neuroinformatics;neuroscience discipline;policy;promotion (action);rewards;slide (glass microscope)	Erik De Schutter	2015	Neuroinformatics	10.1007/s12021-015-9268-3	neuroscience;data science	DB	-65.7600391031903	-20.711222233797457	64842
c68a3b3193029bb8e84fd59f96fdc8239174306a	exploratory analysis of the end of term web archive: comparing two collections.		This paper reports on a preliminary exploration into two web archives created from the US Federal government web during the 2008 and 2012 presidential election. These web archives were created as part of a collaborative effort by institutions from across the United States to document the transition of the executive branch of government and changes that might occur as policies and initiatives shift between administrations. This research represents the first work to compare these two web archives and document differences that exist between them.	exploratory testing;web archive	Mark Phillips;Dan Chudnov;James Jacobs	2017	TCDL Bulletin		world wide web;information retrieval;war;computer science	Web+IR	-66.9879075096678	-13.8974906370814	64848
02af862141a11684ce184a93bfc005080f41d48a	codocs: an electronic document management system supporting effective collaborative work	collaborative work;electronic document management	"""A ll of us have encountered businesses that operated as if the right hand didn't know what the left hand was doing. Or called an 800 number for information or to get something fixed and had to repeat the request and other tedious background information to two, three or even four different people. Whenever that happens, it's hard not to wonder, """" Don't these people ever talk to each other? """" But while it's easy to criticize, the old adage """" People who live in glass houses shouldn't throw stones """" is worth keeping in mind. Just about any group that takes a critical look at how it does business winds up concluding that it needs to do a better job of communicating—internally as well as to customers, clients, distributors and suppliers. That is why corporate reengineer-ing and Total Quality Management (TQM) efforts, for example, often result in the establishment of highly focused market-driven teams and workgroups, which are characterized by efficient workflow and communication processes. The essence of what members of workgroups do is known as """" collaborative """" work. Workgroup members need to overcome barriers of time zones and geography to document what's been accomplished and to update each other on progress, problems, successes and new ideas. They need to be able to brainstorm and debate with one another, even if some or most of the team aren't physically located within the same room. Communications networks and information technology are the tools that make """" working together apart """" possible, and here are just a few examples of how this is happening today: ■ Every evening, ComputerLand uses Lotus Notes software to distribute current pricing and product availability information to its sales force. The same data are also used in internal meetings of the workgroup and in sales presentations to customers. ■ Viacom, which owns and operates the cable channels MTV and Nickelodeon, links its advertising agencies to its programming centers via a private internetwork. Simultaneous use of graphics workstations and the telephone system enables artists, programmers and advertisers to match commercials to the most appropriate television timeslots. ■ In the New York City office of Chiat/Day, an advertising agency that had over $800 million in billings in 1993, about half of the employees no longer have permanent desks. Instead, when they arrive for work each day, they are assigned ROLMphone 900 wireless handsets (part of the ROLMphone …"""	brainstorm;computerland;ibm notes;information;internetworking;mind;programmer;telecommunications network;workstation	Gyu-Wan Kim;Soo-Kwon Jeong;Jae-Hoon Jeong;In-Ho Kim;Myung-Joon Lee	1999			computer science;knowledge management;document management system;database;world wide web	HCI	-65.95300975645092	-22.762735019808755	64857
74ee01e1304c41cca7ae10bc8129b9ca0dfa8647	journals at bepress: new twists on an old model	politique editoriale;edition electronique;selected works;bepress selected works;factor exito;industria informacion;economic model;online journals scholarly publishing open access;litterature scientifique;modelo economico;modele economique;information industry;literatura cientifica;estudio caso;edicion electronica;industrie information;success factor;etude cas;bepress;electronic publishing;public finance;scientific literature;politica de edicion;facteur succes;publishing policy	In recent years academic journal publishers have explored a variety of new business models. The Berkeley Electronic Press (bepress), founded by professors in 1999, now publishes 39 electronic-only journals. bepress’s own model rests on three principles: improve, but do not break, the traditional journal; allow non-subscribers to read articles as guests; and offer reasonable and sustainable prices to libraries. This model has resulted in steady growth. Even in the shifting landscape of open access, there remains a place for professional journal publishers who offer innovative improvements, traditionally qualified content, and		Irene Perciali;Aaron Edlin	2008	Learned Publishing	10.1087/095315108X288929	econometrics;economics;telecommunications;public finance;computer science;economic model;information industry;sociology;electronic publishing;operations research	Web+IR	-72.86319015855767	-20.974624668280622	64913
7863721e0f4292af67db417fe454290ccbfed069	a systematic review of sustainability and aspects of human-computer interaction		Sustainability is the term employed for the practice of ensuring that goods and services are produced in ways that do not use resources that cannot be replaced. This practice has been in focus on several different research agendas. In the area of Human-Computer Interaction, studies devoted to works investigating this matter began to appear eight years ago. It is a timely moment to look back and see how much the community has achieved. This paper provides the results of a Systematic Review carried out in four scientific databases. The selected papers were grouped considering the topics they present, the methodological approach adopted and the kind of outcomes that emerged. The results suggest that among the different methodological approaches adopted, literature reviews and criticism still form the main basis to underpin the outcomes. Moreover, climate change and energy savings were found to be the specific areas that were most researched. The results obtained make it possible to suggest opportunities for further research.	human–computer interaction;systematic review	Vânia Paula de Almeida Néris;Kamila Rios da Hora Rodrigues;Renata Firmino Lima	2014		10.1007/978-3-319-07227-2_71	human–computer interaction;goods and services;computer science;criticism;sustainability	HCI	-71.92581676219436	-17.133598458754136	64952
0115aaac22fa5e3cffdadc262dd5b084bfaf7585	welcome message from the general chairs	satellite communication	We are proud to announce a rich and well balanced program, in line with the well established reputation of WoWMoM as a friendly and interactive forum where researchers from both industry and academia can exchange UHVXOWV DQG YLVLRQV VKDSLQJ WKH IXWXUH RI ZLUHOHVV PRELOH DQG PXOWLPHGLD FRPPXQLFDWLRQV 7KLV \HDU¶V main conference is complemented by an industry track, including contributions from industry researchers and from professionals in the field, and; by a five one-day workshop series covering emerging research areas in the field of wireless, mobile and multimedia networks. The program also features two keynote speeches delivered by distinguished experts in the field, and a panel discussion. Finally, the program includes a PhD Forum, where doctoral students share work in progress and future research goals with their peers as well as more experienced colleagues, and one session dedicated to experimental demonstrations.	whole earth 'lectronic link	Mario Gerla;Enzo Mingozzi	2011		10.1109/WoWMoM.2011.5986135	telecommunications	Visualization	-62.99462641843222	-16.544787823292836	64953
1b5f7c5b3c6c63513c25f4e7fad0d5c20d1f73f4	presidential address	goals;self-esteem;close relationships;self presentation;responsiveness	This presidential address was delivered at the second world congress of the Game Theory Society held in Marseilles, July 2004.		Ehud Kalai	2008	Proceedings of the Royal Society of Medicine	10.1016/j.geb.2007.09.001		HPC	-63.27815520057679	-16.343122086889235	65191
973ef9c0b9b2c24c29243189e72394f1191d8c51	hierarchical administrative subdivision codes		"""The land area of the world is divided into countries. Most of the countries are, in turn, divided into smaller units. These units may be called states, provinces, regions, governorates, and so on. A phrase that describes them all is """"major administrative divisions of countries"""". Due to shortcomings of related de-jure standards a hierarchical set of subdivision codes, called Hierarchical Administrative Subdivision Codes (HASC), has been devised, extending in many cases to secondary administrative divisions. This is not an official standard, sanctioned by any international body. The codes are intended for internal use within a database or other computer system and not for display."""	code (cryptography);computer;data (computing);database;state (computer science);subdivision surface	Gwillim Law;Martin Hammitzsch	2013			data mining;subdivision;phrase;business	DB	-68.00327015680745	-12.701850268924725	65900
21d5551eadc78ea6c402828ffc9a23c57234503f	the genealogy of texts: manuscript traditions and textual traditions		For some time, scholars have been using computer-assisted methods to produce graphic representations of the relationships between witnesses within a textual tradition. The use of methods originally developed by evolutionary biologists has been called into question on account of the perceived lack of identity between two different disciplines. This view arises from a misunderstanding about how the methods work in relation to texts and how the resulting stemmata should be interpreted. This article refines textual critical terminology, particularly the distinction between textual traditions and manuscript traditions, in the context of the use of computer-assisted stemmatological methods to further our understanding of how these fit within the wider theoretical framework of textual criticism and scholarly editing, and makes explicit the way in which stemmata produced by using evolutionary biology software should be read. .................................................................................................................................................................................		Barbara Bordalejo	2016	DSH	10.1093/llc/fqv038	humanities;computer science;linguistics;literature	Web+IR	-64.1125995154116	-21.635428566147272	65916
80801c69dd4f1bb977fbb5678f64b9185a7922c1	the high assurance brake job - a cautionary tale in five scenes	intrusion;threat;vulnerability;dependability;terminology;security;modeling;impairment	As interest grows in the concept of assurance, the field seems to be dividing into a few distinct camps. Each approach has its strengths, but there are gaps in the coverage of each which are sometimes left unaddressed by the various proponents. By casting the discussion in terms of an analogy to a brake job, with each camp represented by a different garage, the presentation will try to raise questions and suggest directions for future work, hopefully in a humorous and memorable manner. While it is not our position that the emperor has no clothes, that does not mean that the emperor doesn't need a fashion critic occasionally a need that this presentation will attempt to fill. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advant -age and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. 1999 New Security Paradigm Workshop 9/99 Ontario, Canada © 2000 ACM 1-58113-149-610010004... $5.00	code coverage;programming paradigm	Kenneth G. Olthoff	1999		10.1145/335169.335206	systems modeling;intrusion;vulnerability;computer science;threat;information security;dependability;internet privacy;terminology;computer security	Web+IR	-68.95263206859389	-12.67528813769727	66245
1e1b90ec0ef941bf2a88ec8b32f64a4da71a6c36	a taxonomy of current approaches to systems analysis	system analysis	The discipline of systems analysis is still very young and in common with most other emerging disciplines it occasionally enters periods of radical self examination and re-thinking. The authors feel that we are in the midst of such a phase at present; new ideas abound, arguments rage, and the development of technology is a powerful impetus to the re-examination of ideas. The reason for the current turmoil in systems analysis is the emergence over the past few years of a number of new approaches or methodologies. These approaches have generally originated as academic ideas and been taken up and modified in the practising world of systems analysis. Thus there exists a confusing array of approaches. It is the purpose of this paper to examine some of the more fundamental approaches and to attempt to classify them. It is the authors' view that the approaches are not simple alternatives, but that they seek to do different things. The authors have identified six major approaches to systems analysis: (i) General Systems Theory Approach; (ii) Human Activity Systems Approach; (iii) Participative (Socio technical) Approach; (iv) Traditional (NCC, etc.) Approach; (v) Data Analysis Approach; (vi) Structured Systems (Functional) Approach. Except for the General Systems Theory Approach they are all used to some extent in the industry today. General Systems Theory is included as an approach because of its important influence on systems thinking in general and because of the contribution it has made to almost all the other identified approaches.	emergence;emoticon;neural correlates of consciousness;requirement;systems theory	Trevor Wood-Harper;Guy Fitzgerald	1982	Comput. J.	10.1093/comjnl/25.1.12	computer science;system analysis	SE	-70.68043488159924	-14.039347072393202	66450
6f06f321dc55d2270b8e15be3f1972c91a76a726	the dos and dont’s of crowdsourcing software development		In 1957, the eminent computer scientist, Edsger W. Dijkstra, sought to record his profession as “Computer Programmer” on his marriage certificate. The Dutch authorities, although probably more progressive than most, refused on the grounds that there was no such profession. Ironically, just a decade later, the term “software crisis” had been coined, as delegates at a NATO Conference in Garmisch [1] reported a common set of problems, namely that software took too long to develop, cost too much to develop, and the software which was eventually delivered did not meet user expectations. Despite the advances in technology over the past 50 years, this remains problematic, as evidenced by the following quote from the US President’s Council of Advisors on Science & Technology (PCAST) in 2012.	amazon mechanical turk;computer scientist;crowdsourcing software development;dos;programmer;software crisis;the turk	Bob Fitzgerald;Klaas-Jan Stol	2015		10.1007/978-3-662-46078-8_6	operating system;database;world wide web	SE	-64.4214877065546	-20.493714618026097	66566
1efb2afed1187c3f8927837262c597d2c804736e	global data mining: an empirical study of current trends, future forecasts and technology diffusions	bibliometric methodology;data mining;technology diffusions;research trends and forecasts	0957-4174/$ see front matter 2012 Elsevier Ltd. A doi:10.1016/j.eswa.2012.01.150 ⇑ Tel.: +886 2 27929728; fax: +886 2 29393754. E-mail addresses: simontsai@yahoo.com, 9835651 Using a bibliometric approach, this paper analyzes research trends and forecasts of data mining from 1989 to 2009 by locating heading ‘‘data mining’’ in topic in the SSCI database. The bibliometric analytical technique was used to examine the topic in SSCI journals from 1989 to 2009, we found 1181 articles with data mining. This paper implemented and classified data mining articles using the following eight categories—publication year, citation, country/territory, document type, institute name, language, source title and subject area—for different distribution status in order to explore the differences and how data mining technologies have developed in this period and to analyze technology tendencies and forecasts of data mining under the above results. Also, the paper performs the K-S test to check whether the analysis follows Lotka’s law. Besides, the analysis also reviews the historical literatures to come out technology diffusions of data mining. The paper provides a roadmap for future research, abstracts technology trends and forecasts, and facilitates knowledge accumulation so that data mining researchers can save some time since core knowledge will be concentrated in core categories. This implies that the phenomenon ‘‘success breeds success’’ is more common in higher quality publications. 2012 Elsevier Ltd. All rights reserved.	bibliometrics;course (navigation);data mining;fax;lotka's law;social sciences citation index;tree accumulation	Hsu-Hao Tsai	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.01.150	computer science;artificial intelligence;data science;data mining;operations research;statistics	ML	-76.6017715511481	-19.805550594969848	66808
5fbef9fb110e4ccdcccab7fb9a426efe07fc00d5	suitable for all ages: using reviews to determine appropriateness of products			norm (social)	Elizabeth M. Daly;Oznur Alkan;Michael J. Muller	2017			data mining;computer science	NLP	-66.23753385707239	-11.221350659070064	67228
a90ba38babfc8f644b9c3be6cd66e98e38224b74	about the editors	academic research;publishing;commissioning	Peter W. Hahn is a partner in the construction law practice group of Dinsmore & Shohl’s Columbus, Ohio, office. He advises owners and contractors on issues and liability avoidance at every phase of a construction project, from the drafting and negotiation of contracts through post-project issues and construction defect claims. He also regularly advises public authorities throughout Ohio on such topics as construction procurement, project delivery methods, contract terms, regulatory compliance, and claims. He is active in the ABA Forum on Construction Law, where he is a member of the Steering Committee for Division 13 (Government Construction). Mr. Hahn has a bachelor’s degree from the College of Wooster and a law degree from Washington University in St. Louis.	aba problem;associate of business administration;columbus memorial library;committee, drug;contract agreement;procurement;software bug;wooster collective	Helga Kuhse;Peter Singer	1989	Bioethics	10.1016/B978-0-12-810408-8.00031-6		SE	-66.65802770613402	-16.380428630805344	67233
31ea9f2903a854dc6b513420ccf22ae226024073	revisiting moor's towards a theory of privacy in the information age	community consent;charitable trust;socially responsible;data mining;computer ethics;computers and society;information age;informed consent;dna databanks;special interest group	Back in 1988, when my department chair encouraged me to pursue my interest in developing a course on the social and ethical impact of computing, I was thrilled at the prospect but had no idea how difficult it would be to find resources to support my teaching. I did some pre-Web digging and found two organizations that delivered on their promises to provide me with valuable sources of material: ACM SIGCAS (ACM's Special Interest Group for Computers and Society, and the publisher of this newsletter) and CPSR (Computer Professionals for Social Responsibility). I quickly joined each group, subscribed to each one's publications, and the rest, as they say, is history. Over the past twenty years, I have enjoyed a rich and rewarding career in the area of computer ethics and its pedagogy, and have benefited professionally and personally through my affiliation with a vibrant interdisciplinary community of computer ethics scholars. I am happy to report that Computers and Society continues to provide my students with thought-provoking material, and is now part of a large and growing body of literature.		Florence Appel	2010	SIGCAS Computers and Society	10.1145/1839994.1839999	public relations;special interest group;information age;informed consent;computer science;social responsibility;sociology;management;social psychology;law;computer security;computer ethics	HCI	-68.20070780148218	-19.918585329343745	67491
4ce9631a13d0ae8f47fe0070857f4cab405072fd	internet and distributed computing systems		Recently, a lot of companies are increasingly introducing cloud services for digital records management. The cloud services can dramatically lower the cost of archiving and managing digital records and provides a foundation for resilient management of digital records management, depending on the circumstances of the enterprise. However, due to the nature of service provided by third parties in the cloud, conflicting the nature of digital records and the intrinsic risks inherent in the cloud, many companies are reluctant to apply the cloud to their digital records management right away. In this paper, we analyze the risk factors of the digital records in the cloud services and discuss some alternative models to solve them.	archive;cloud computing;digital rights management;distributed computing	Giancarlo Fortino;A. B. M. Shawkat Ali;Mukaddim Pathan;Antonio Guerrieri;Giuseppe Di Fatta	2017		10.1007/978-3-319-97795-9		Security	-74.10334275002467	-10.051310431541847	67637
1c17f5d9c8ce2c15087fbeb1d3862a500bb6663b	document categories in the isi web of knowledge: misunderstanding the social sciences?	document categories;social sciences;review articles;thomson reuters;web of knowledge;proceedings papers	Thomson Reuter’s ISI Web of Knowledge (or ISI for short) is used in the majority of benchmarking analyses and bibliometric research projects. Therefore, it is important to be aware of the limitations of data provided by ISI. This article deals with a limitation that disproportionally affects the Social Sciences: ISI’s misclassification of journal articles containing original research into the “review” or “proceedings paper” category. I report on a comprehensive, 11 year analysis, of document categories for 27 journals in nine Social Science and Science disciplines. I show that although ISI’s “proceedings paper” and “review” classifications seem to work fairly well in the Sciences, they illustrate a profound misunderstanding of research and publication practices in the Social Sciences.	bibliometrics;information sciences institute;tps report;web of science	Anne-Wil Harzing	2012	Scientometrics	10.1007/s11192-012-0738-1	social science;computer science;data science;data mining;review article;world wide web	ML	-75.52047955485298	-18.340502943322594	67747
edc0943cd7ec7ad71fd1695b5660c950514c928f	public library response to women and their changing roles revisited	services promoting;politica bibliotecaria;mujer;text;woman;pedestrian safety;north america;service information;america del norte;poison control;amerique du nord;amerique;injury prevention;hombre;safety literature;etats unis;traffic safety;injury control;estados unidos;gender;library services;service utilisateur;home safety;promocion servicio;injury research;safety abstracts;human factors;femme;library policy;occupational safety;safety;public library;human;servicio informacion;safety research;accident prevention;violence prevention;bicycle safety;politique bibliotheque;information service;servicio usuario;user service;america;public libraries;poisoning prevention;falls;bibliotheque publique;ergonomics;promotion service;suicide prevention;homme;biblioteca publica	Updating research done in 1980, the authors survey the current status of programming for women in public libraries, concentrating on the largest U.S. public libraries. The designation of National Women’s History Month was assumed to provide a legitimizing factor that libraries could use to develop women’s programming. Many libraries have indeed developed programming for women during National Women’s History Month, but many more have planned women’s programming as part of their regular offering of programs. Women’s programming has been strengthened by a greater visibility of the diverse needs and interests of women, funding for programs for women, and greatly expanded publishing activity that continually provides new titles on women’s issues for public library collections. Women themselves have been a catalyst for programming as they have been avid users of public libraries and often the primary audience for library programs. Although librarians seem reluctant to identify their target audience by gender, they continue to develop programming that attracts more women than men. Introduction In 1980 we wrote an article for Reference & User Services Quarterly, then called RQ, entitled “Public Library Response to Women and Their Changing Roles.” In that time of wide-ranging social and personal activism we spoke as feminists and as librarians to library practitioners. Our goal was to encourage a greater public library focus on women and so called women’s issues. To that end we chronicled programs, services, and collection development and identified patterns of practice. Slightly over a quarter century later, when the women’s movement we remain part of is Public Library Response to Women and Their Changing Roles Revisited Kay Ann Cassell and Kathleen Weibel LIBRARY TRENDS, Vol. 56, No. 2, Fall 2007 (“Gender Issues in Information Needs and Services,” edited by Cindy Ingold and Susan E. Searing), pp. 303–327 © 2007 The Board of Trustees, University of Illinois 304 library trends/fall 2007 no longer a visibly active force in our society, we revisit the public library’s response to women and their changing roles. Today many women’s issues have become subsumed under larger issues. Now the focus is on single parent families and the working poor, rather than on working women. Similarly the high cost of health care is a larger issue than specialized and appropriate care for women. Concern for displaced workers has replaced concern for displaced homemakers. In the 1980s feminist bookstores were still springing up. Now, along with most independent bookstores, they are closed or closing. Consciousness raising groups are passé. Women are more likely to be in a book discussion group, many of which take place in public libraries. Then, women’s alternative presses were actively publishing. Now only a small number of these independent presses survive with any viability: Feminist Press, Seal Press, Aunt Lute, Spinsters Ink and Calyx, for example. Today young women live lives their feminist mothers could only dream about, but many disavow the feminism that won them their choices. The cooling of social activism on women’s issues is partially a result of the success of the women’s movement. We have seen some positive changes. School sports opportunities have increased for girls and women with Title IX (Blumenthal, 2006). A woman has recently been appointed the president of Harvard (Bhayani & Guehenno, 2007). Yet the issues that drove the women’s movement are far from resolved. For example, the wage gap between men and women persists (Lips, n.d.) and reproductive freedom is far from sure (NARAL, n.d.). In this current environment of aging NOW members and a decreasing activism on women’s issues, what are public libraries, some of which are now administered by the feminist activists of past years, doing to serve women? How are public libraries dealing with women-related issues? What programs and services do they offer to address the needs of women? To answer these questions we surveyed fifteen major urban public libraries and a recommended few other libraries in smaller communities regarding their public programming for women and on women-related issues, with a particular focus on National Women’s History Month. We knew that public library adult programming now typically plays a greater role in public library services than it did when we wrote our 1980 RQ article. Then the focus in public libraries was more on information services. In recent years, however, public libraries have moved from defining themselves in terms of an information role back to the educational and cultural roles popular in the first half of the twentieth century. This shift was marked by the 1990 formation of the Public Programming Office within the American Library Association. The American Library Association has had staff devoted to developing public programs in public libraries at various times in its history, but it was the availability of National Endowment for the Humanities (NEH) funding, initially for the “Let’s Talk About It” reading and discussion programs, that provided the impetus for 305 cassell & weibel/changing roles revisited this latest emphasis within the association. These programs also provided an impetus and resources for programming for women. Deborah Robertson, Director of the American Library Association’s Public Programs Office, reports that over 80 percent of U.S. public libraries are actively involved in public programming and that programming is a core service in libraries with an educational mission (D. Robertson, personal communication, November 2, 2006). These programs provide information as well as entertainment and enlightenment and have become an end in themselves as well as a “stimulus to use” as Margaret Monroe termed them (Heim, 1982). Why do we focus on National Women’s History Month? National Women’s History Month, established in the eighties, offers public libraries a familiar framework for programming. It allows them to take an approach similar to Black History Month or other heritage theme celebrations relevant to their communities. For the purposes of this investigation, we assumed that if public libraries were doing any public programming on women’s issues and women, they would likely be doing something in March when National Women’s History Month is celebrated. The roots of National Women’s History Month go back to “Women’s History Week,” first celebrated in Sonoma County, California in 1978. This public celebration was scheduled around March 8, International Women’s Day, long celebrated in Socialist countries. In 1981, the unlikely combination of Sen. Orrin Hatch (R-Utah) and then Rep. Barbara Mikulski (D-MD) co-sponsored a joint congressional resolution proclaiming a national Women’s History Week. In 1987, Congress expanded the celebration to a month, and March was declared Women’s History Month (National Women’s History Project, n.d.). At one time public library programmers might have been called radical for programming on women’s issues or for a female audience. While that is not necessarily a bad thing, it is not a position most public librarians or their libraries are comfortable with. Now that Congress has legitimized the inclusion of women in our history, public libraries theoretically should be willing to build regular and recurring programs on women, or at least on women’s history, into their schedules. The question is: are they doing this? Definition of Terms For the purposes of this article, public programming is defined as educational and cultural programs sponsored by public libraries for adult audiences. As noted above, public programming is not a new function for public libraries, but the emphasis on public programs changes with the societal role sought by public libraries. We are currently in a period where public programming is being given greater credibility as a library service. In our 1980 RQ article we defined library service to women as “services designed to meet the needs of female clientele regardless of their position on the women’s movement” and library service on women-related issues 306 library trends/fall 2007 “as services on issues arising from the women’s movement, but not necessarily directed at a female clientele and not limited to a feminist perspective” (Cassell & Weibel, 1980, p. 70). Twenty-six years later we are limiting ourselves to public programs and no longer reference the women’s movement, not because it is not important or still necessary, but rather because for most American women it is not the immediate force it once was. For the purposes of this article, we define library public programs for women as programs directed toward a female clientele. An example of today’s women-targeted activity would be the AIDS and sexually transmitted disease (STD) awareness program, with private consultations afterward, developed by a Cleveland Public Library branch in cooperation with a local women’s center (E. Leavitt & R. Antonucci, personal communication, December 12, 2006). AIDS and STD are not “women’s issues” but the program clearly targeted women as the audience. In another example of a library program for women, the Chappaqua (NY) Public Library targets women as the audience for a workshop for divorced, newly separated, and widowed women. The workshop provides information from a divorce lawyer, a financial advisor and a psychologist and has been so well received that it has become an annual event (J. Kuhn, personal communication, November 8, 2006). We define library programs on women-related issues in the same apolitical way as previously: those programs responding to issues faced predominantly by women in their societal roles, but not necessarily directed at a female client group. The San Antonio Public Library’s “Little Red Wagon,” an early literacy outreach program targeting people who work with children—caregivers, parents, and teachers—is one example. Three staff members educate the		Kay Ann Cassell;Kathleen Weibel	2007	Library Trends	10.1353/lib.2008.0006	psychology;library science;public relations;engineering;suicide prevention;human factors and ergonomics;injury prevention;sociology;public administration;management;law;world wide web;computer security;economic growth	HCI	-71.38809430325034	-21.102442473688633	67797
971648ee6522559bef3a2a51fc3bf00b3f3cd749	a new chief executive officer and executive director of acm		"""from the acm president I SOMETIMES REFLECT on what makes ACM so special, so unique as a professional society. I can easily come up with several good reasons, including the extent to which responsibility, authority , and budget control are devolved to our 37 special interest groups or the strong support we provide to our fellow volunteers in building a broad range of community service activities (the """" good works """" of ACM). But alongside or, perhaps, underlying these very visible special and unique features is the largely invisible special and unique relationship that exists between volunteer leaders and ACM headquarters staff. This is a relationship characterized by mutual respect and trust, and a deep understanding of each other's motivations , aspirations, and priorities. Not that there are no conflicts and sometimes even some tensions, but as in any healthy relationship, it is the manner in which you approach and overcome problems and challenges that matters, not the fact they may exist. What is the secret to ACM's incredible success in building its volunteer/ staff relationship? From where did it come and how do we ensure it contin-ues? This is something that has been literally decades in the making (starting well before my time as an ACM volunteer) and something that as President I feel a great responsibility to preserve and nurture. From my point of view, a watershed moment in the building of that relationship occurred in November 1998 when John White—holder of a Ph.D. in computer science, a former university professor, an industrial research lab director, and a past president of ACM, transitioned from his role as a long-standing volunteer to that of chief executive officer (the first person to hold that title) and executive director (the traditional title of someone who heads the staff of a non-profit organization). For the first time, the most senior member of staff would be someone from our technical community. What John did with that opportunity is, simply put, legendary. While previous ACM EDs contributed fundamentally and substantially to our success, John brought a different kind of experience and perspective to the position, one that in the context of computing's explosive growth in importance and ubiquity (John took up his position in the same year that Microsoft Windows 98 was released and Google was founded) could not have been more timely for our profession. Together with ACM COO Pat Ryan and the …"""	computer science;first-person (video games);john collison;microsoft windows 98;ues (cipher);watershed (image processing)	Alexander L. Wolf	2015	Commun. ACM	10.1145/2788395	management	Graphics	-63.98543417690125	-19.12867870622549	67927
05a303a9e36868d4f37149b5307929a7a57c7a8f	prelude to the panel on what makes good research in modeling & simulation	better insight;good research;numerous science;engineering discipline;basic research;fundamental strategy;major component;concept formulation;creative m;professional realm;essential component;modeling and simulation;simulation;modeling;mean squared error	Modeling and Simulation (M&S) is a unique field, which has been and continues to be influential in the development and growth of numerous science and engineering disciplines. From basic research and concept formulation to diffusion of innovations, M&S rests on fundamental strategies that not only provide guidance to scientists, but also provide explanations for the society and institutions that have stakes in the produced knowledge. We explore the essential components of the professional realm of M&S research to (1) gain better insight about the characteristics of successful and creative M&S research, (2) identify the major components of the M&S profession that need to be nurtured to enable growth and sustainment of its vitality, and (3) help facilitate explanation of the character of simulation discipline to other engineers and scientists at large.	simulation	Levent Yilmaz;Jeffrey S. Smith	2008	2008 Winter Simulation Conference		simulation;systems modeling;computer science;engineering;simulation modeling;modeling and simulation;mathematics;mean squared error;management science	Robotics	-72.83199399148006	-15.278570194968134	67940
3a095f5dc8b36326901434ded63cd439f9c785b6	real time computer applications in gambling	computers;government;law;computers real time systems cities and towns games government law;games;cities and towns;real time systems	Man's instinct to gamble is at least as old as government's need for funds. So it should come as no surprise that government has learned to regard gambling as a source of revenue, whether through direct taxation or through government-run gambling establishments. In the US recently, changing moral attitudes towards gambling as well as increasingly desperate local financing needs, have produced a surge of interest in legalized gambling. Added to these factors has been the belief that legalizing gambling is one way to fight organized crime.	computer	Burt H. Liebowitz	1974	Computer	10.1109/MC.1974.6323328	games;computer science;management;law;computer security;government	Theory	-70.68577004070468	-11.01282397615698	68058
5ea86e4f04579504193456d0833e4ce197ba9eac	a new trend of ebook confidence level in perspective aspect	media management;azw format;internet electronic publishing;public domain azw format mobile data connection profile of contingency table;confidence level;correlation consumer electronics books media visualization monitoring presses;web newspaper;economic market;profile of contingency table;wall street;amazon company;mobile data connection;financial tsunami;presses;consumer electronics;books;public domain;media;visualization;internet;monitoring;american press;electronic publishing;contingency table;ebook confidence level;telephone survey;correlation;media management ebook confidence level wall street economic market american press amazon company financial tsunami web newspaper	Since Fall 2007, the famous Lehman brothers had suffered the “ Subprime Mortgage ” and filed bankrupt, Wall Street was faced a heavy pressure immediately: financial tsunami. More over the whole economic market in the world is all linked with one another, certainly American Press is fallen down inevitably. Meanwhile, the Amazon Company has been announced a new Kindle (eBook) to compete with web newspaper since a couple years ago. In Aug. 2009, Sony has been developed a new eBook (PRS-500), and more electronic tycoons would follow especially in Taiwan. Can such new electronic devices possible save American or Taiwan media and publishers alive? and create multi-billion dollars business in the year of 2013. In our research, we collect more than 300 cases from the telephone survey during Oct., 2009 to Feb., 2010. A total of 210 cases comply with the conditions. To probe mainly into the relationship between eBook confidence level and four different groups: IT industries, Stock investors, Publishers, and Consumers in Taiwan. The profiles of contingency table were used to explore the relationship between eBooks' confidence level and different peoples, and special model were used to confirm the relationship of each other. The result is an effective method that may help to improve management qualities and push media management forward.	amazon kindle;contingency table;e-book;effective method;push technology;sony reader family	Wei-Ming Yeh	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580819	public domain;the internet;confidence interval;media;visualization;mobile telephony;contingency table;computer science;artificial intelligence;media management;electronic publishing;operations research;correlation;statistics	AI	-66.1898184809109	-22.83753376865118	68090
dc93724d88d6934a238e9c639265e611055ab8b9	the society for computer applications in radiology		THE RADIOLOGY popular press is full of articles and commentaries about the clash between advancing high technology and the need for health care reform. Cost saving has become the paramount issue in medicine. In most instances, the development or expansion of digital imaging has not led to cost savings. Considerable expenditure is needed to replace an existing film-based imaging system with a digital one. Although there may be advantages in doing that, the prospect of making this type of investment under the current economic climate is very intimidating for many radiology administrators. If we, as radiologists, are to succeed in the future practice of medicine, we will need to do so by providing the best possible consultative service in a timely manner and at reasonable cost. It is unlikely that government administrators will come to our aid and proclaim us as the true defenders of economic virtue-witness the recent attempts to deny radiologists the right to charge for the interpretation of emergency department films. Our time, as radiologists, will best be spent in developing methods to apply digital technology to achieve our goals. The application of teleradiology immediately comes to mind with regard to the emergency department situation. Similarly, advances in digital imaging, such as new applications and new imaging parameters for magnetic resonance imaging (MRI), will be of most immediate benefit to radiologists who are the medical specialists with the most training in dealing specifically with images. Neurologists and orthopedic surgeons may think that they understand MRI, but radiologists are the ones who will be advancing the imaging art. We need to prove to other physicians and administrators that we can	3d film;digital electronics;digital imaging;radiology;resonance;teleradiology	Ray F. Kilcoyne	1994	Journal of Digital Imaging	10.1007/BF03168510		Graphics	-67.50317185843952	-23.886787272213702	68119
f4674d2f06a71ad9c344ca53feb0e44c7af4e686	ethics and the safety of computer systems	databases;computer failures;safety medical diagnostic imaging databases knowledge based systems medical treatment drugs educational institutions ethics concrete computer security;drugs;social ethics;standards;medical administrative data processing;social aspects of automation;computer systems;ethics;computer security;critical system;medical information systems;medical information system;safety;ethics of virtue;social ethics standards ethics safety computer systems computer failures critical systems medical information systems ethical analysis normative ethics ethics of virtue;critical systems;social aspects of automation medical administrative data processing security of data;normative ethics;social structure;medical treatment;security of data;knowledge based systems;ethical analysis;medical diagnostic imaging;concrete	In the March 1990 issue of Computer (pp. 77-81), I wrote about the general principles on which ethics for the computer profession should be based and suggested some steps the profession could take to encourage and sustain ethical behavior among its members. As several readers have since noted quite rightly, I think more specifics are needed, especially in two areas: First, how ethical principles apply to concrete issues: second, what the IEEE should be doing, especially in the area of standards, to support ethical activity among computer professionals.		Michael C. McFarland	1991	IEEE Computer	10.1109/2.67211	ethics;concrete;meta-ethics;computer science;knowledge management;knowledge-based systems;social structure;normative ethics;management science;information ethics;management;law;computer security	Visualization	-70.95730327686172	-13.424609701317006	68126
0865e91d4f1c66477aa7ab20edb1386c1e2db891	practitioner's guide to health informatics		"""Advance Praise for Practitioners Guide to Health Informatics:\""""Dr. Braunstein has managed to take what is traditionally a dense and occasionally untranslatable topic and to frame it in an informal, conversational, and accessible style. Well done! The book begins with a carefully constructed and well referenced discussion about the healthcare system and the current regulatory climate developed to help transform it. The section on HIE is one of the most comprehensive I have seenThis book will be a terrific introduction to the field of clinical IT and clinical informatics, and is a welcomed addition to the materials we have as instructors in this field.\""""- Kevin B. Johnson, MD, MS is a Professor and Chair of Biomedical Informatics, Vanderbilt University Medical Center Dr. Braunstein has done a wonderful job of exploring a number of key trends in technology in the context of the transformations that are occurring in our health care system, and highlighting how these trends are likely to both play out and influence the evolution of current and future health IT systems.- Robert A. Greenes, MD, PhD, Ira A. Fulton Chair and Professor, Professor Biomedical Informatics, Arizona State University\""""This insightful book is a perfect primer for technologists entering the health tech field.\""""- Deborah Estrin, PhD, Professor of Computer Science, Cornell Tech, Professor of Public Health at Weill Cornell Medical College \""""Producing sharable digital data from care delivery and actually sharing it is arguably the single most important contribution health informatics can make to better healthcare in our country,\"""" is the way Dr. Braunstein starts this eminently practical yet very detailed look at what our country needs from the field of medical informatics. He has produced a minor masterpiece of analysis and explanation about the use of computers in medicine and health care delivery, one that is as useful for the informed lay person as it is for any clinical professional needing a brief overview of the field. This book should be read by everyone.\""""- David C. Kibbe, M.D., M.B.A. Director, Center for Health Information Technology, American Academy of Family Physicians, President and CEO, Co-founder DirectTrust.org"""	centralized computing;fast healthcare interoperability resources;informatics;information exchange;population;relevance	Mark L. Braunstein	2015		10.1007/978-3-319-17662-8	health administration informatics;chief medical informatics officer;health informatics;family medicine;medicine;emergency medicine	HCI	-68.25525399314827	-19.29396463010766	68189
77bb80be66da0cb125ef88148fa941b282731c30	the problems with forbidding science	legislation;voluntary standards;science regulation;substantive regulation;code of conduct;self regulation;research ethics;dual use;scientific research	Scientific research is subject to a number of regulations which impose incidental (time, place), rather than substantive (type of research), restrictions on scientific research and the knowledge created through such research. In recent years, however, the premise that scientific research and knowledge should be free from substantive regulation has increasingly been called into question. Some have suggested that the law should be used as a tool to substantively restrict research which is dual-use in nature or which raises moral objections. There are, however, some problems with using law to restrict or prohibit certain types of scientific research, including (i) the inherent imprecision of law for regulating complex and rapidly evolving scientific research; (ii) the difficulties of enforcing legal restrictions on an activity that is international in scope; (iii) the limited predictability of the consequences of restricting specific branches of scientific research; (iv) inertia in the legislative process; and (v) the susceptibility of legislators and regulators to inappropriate factors and influence. Rather than using law to restrict scientific research, it may be more appropriate and effective to use a combination of non-traditional legal tools including norms, codes of conduct, restrictions on publication, and scientist-developed voluntary standards to regulate problematic scientific research.		Gary E. Marchant;Lynda L. Pope	2009	Science and engineering ethics	10.1007/s11948-009-9130-9	psychology;public relations;research ethics;scientific method;management science;sociology;law	HPC	-73.82422072830116	-13.571015167974892	68201
7797ba2042474a4a762fc04e52ebdf5800ba0e98	a contiuum of time-sharing scheduling algorithms	overall system behavior;time-sharing scheduling algorithm;certain maturity;near future;important theoretical question;recent survey;published paper;extensive research	The study of time-sharing scheduling algorithms has now reached a certain maturity. One need merely look at a recent survey by McKinney in which he traces the field from the first published paper in 1964 to a succession of many papers during these past six years. Research which is currently taking place within the field is of the nature whereby many of the important theoretical questions will be sufficiently well answered in the very near future so as to question the justification for continuing extensive research much longer without first studying the overall system behavior.	algorithm;capability maturity model;scheduling (computing);succession;time-sharing;tracing (software)	Leonard Kleinrock	1970		10.1145/1476936.1477006	simulation;computer science;management science;operations research	Theory	-71.66852106860912	-16.954328660304885	68347
5b6abb21a5bdfd5aeac7f4e268a9d959bfe267b2	does collaboration bring high-impact studies? a preliminary study				Chao Lu;Yi Bu;Chenwei Zhang;Ying Ding;Vetle I. Torvik;Chengzhi Zhang	2017		10.1002/pra2.2017.14505401142		ECom	-64.80650227391266	-12.692898081727044	68388
abdd4f6b38382b8db4da75a45e52230c7621a0c6	internationalization of information systems research and teaching	information management	In our editorial of the December issue of BISE in 2014, we discussed standards for assessing the quality of research in our community (Bichler et al. 2014). In the second issue of 2015, we offered our thoughts on the impact of disciplinary research results on practice (Bichler et al. 2015). Whereas we received little feedback from our readers on the first issue, we have received concise positive feedback on our second issue for which we would like to express our gratitude towards the respective colleagues. In the current issue, we will articulate some thoughts about a phenomenon that we believe is the key to research and teaching in our community: Internationalization. We will contemplate several modes of internationalization and comment on them. These modes depict particular forms or varieties of exporting or importing knowledge about research or teaching contexts. Internationalization undoubtedly offers a huge potential for our community to extend its impact beyond the own geographical spheres on the one hand, and allows to import new ideas from other parts of the world that can advance our research and teaching on the other hand. Despite all these benefits, internationalization also bears the risk that our own traditions and standards become marginalized by a broader mainstream. Along this vein, we want to discuss internationalization in general, and the role that the BISE journal can play in distributing research results in areas where our community is strong. There are topics which might not (yet) be considered popular in other areas of the world but that we find important and relevant. This journal should assist us to shape our own agenda and disseminate our ideas—both within our community and beyond.	information systems research	Armin Heinzl;Robert Winter;Martin Bichler	2015	Business & Information Systems Engineering	10.1007/s12599-015-0388-y	engineering management;information technology management;information processes and technology;computer science;knowledge management;marketing;management information systems;information management;information system	DB	-71.74227510882253	-16.626709323426688	68414
7e19147f20d4c1df1cbe6b8a7d8413ea11d06ab0	extracting academic genealogy trees from the networked digital library of theses and dissertations	libraries;measurement;crowdsourcing system extracting academic genealogy trees local digital libraries academic genealogy networked digital library of theses and dissertations ndltd academic formation;digital libraries;data mining;vegetation;neuroscience;measurement vegetation libraries data mining buildings neuroscience context;etd;ndltd;academic genealogy trees;context;buildings;etd academic genealogy trees ndltd	Along the history, many researchers provided remarkable contributions to science, not only advancing knowledge but also in terms of mentoring new scientists. Currently, identifying and studying the formation of researchers over the years is a challenging task as current repositories of theses and dissertations are cataloged in a decentralized way through many local digital libraries. In this paper, we give a first step towards building a large repository that records the academic genealogy of researchers across fields and countries. We crawled data from the Networked Digital Library of Theses and Dissertations (NDLTD) and develop a framework to extract academic genealogy trees from this data and provide a series of analyses that describe the main properties of the academic genealogy trees. Our effort identified interesting findings related to the structure of academic formation, which highlight the importance of cataloging academic genealogy trees. We hope our initial framework will be the basis of a much larger crowdsourcing system.	crowdsourcing;digital library;library (computing);software repository	Wellington Dores;Fabrício Benevenuto;Alberto H. F. Laender	2016	2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)	10.1145/2910896.2910916	digital library;computer science;data science;world wide web;vegetation;measurement	HPC	-77.0733273424855	-17.67355655379064	68595
1b5686778d478b866bb9b5663c0d80b591b9a8ae	cyber science: moving from the toes to the shoulders of giants	cyber science			Thomas A. Longstaff	2010		10.1145/1852666.1852677	computer science;computer security;shoulders	Logic	-67.71309985827385	-11.038592331469411	68632
ae0ed45cd95747ca629dbc7408b2dac0b8a103df	citation analysis: a comparison of google scholar, scopus, and web of science	web of science;citation analysis;bb bibliometric methods;google scholar;library and information science;quality evaluation	When faculty members are evaluated, they are judged in part by the impact and quality of their scholarly publications. While all academic institutions look to publication counts and venues as well as the subjective opinions of peers, many hiring, tenure, and promotion committees also rely on citation analysis to obtain a more objective assessment of an author’s work. Consequently, faculty members try to identify as many citations to their published works as possible to provide a comprehensive assessment of their publication impact on the scholarly and professional communities. The Institute for Scientific Information’s (ISI) citation databases, which are widely used as a starting point if not the only source for locating citations, have several limitations that may leave gaps in the coverage of citations to an author’s work. This paper presents a case study comparing citations found in Scopus and Google Scholar with those found in Web of Science (the portal used to search the three ISI citation databases) for items published by two Library and Information Science full-time faculty members. In addition, the paper presents a brief overview of a prototype system called CiteSearch, which analyzes combined data from multiple citation databases to produce citation-based quality evaluation measures.	citation analysis;database;google scholar;information sciences institute;library and information science;prototype;scopus;web of science	Kiduk Yang;Lokman I. Meho	2006		10.1002/meet.14504301185	computer science;citation analysis;world wide web;information retrieval	Web+IR	-77.05518948097745	-21.694782335750055	68757
62734fb084c1c69b58c4a8aa41e991bc20dbd3bb	online submission and peer-review systems	communication scientifique;comunicacion cientifica;on line;en linea;articulo;editor;evaluacion interpares;submission;enquete;auteur;evaluation interpair;autor;medio ambiente electronico;electronic environment;publisher;scientific communication;en ligne;encuesta;author;survey;editeur;article;soumission;sumision;environnement electronique	We report on a research study commissioned by ALPSP (Association of Learned and Professional Society Publishers) into the current status of online submission and peer-review systems, the perceptions of these by authors, referees and editors, and the impact of their introduction on journals.	peer-to-patent	Mark Ware	2005	Learned Publishing	10.1087/095315105774648771	publishing;sociology;operations research;law;auteur theory	DB	-74.41875157638857	-22.97139173827129	69035
6ebb94aef1db3c8f7fa0b83493ecdb83d98a2111	connecting those that care: designing for transitioning, talking, belonging and escaping	g400 computer science;kiel long;g500 information systems;conference paper;eprints newcastle university;open access;professor john vines;roisin mcnaney;w200 design studies	Care provision in many nations increasingly relies on the work of informal, or non-professional, carers. Often these carers experience substantial disruptions and reductions to their own sociality, weakened social support networks and, ultimately, a heightened risk of social isolation. We describe a qualitative study, comprised of interviews, design workshops and probes, that investigated the social and community support practices of carers. Our findings highlight issues related to becoming and recognising being a carer, and feelings of being ignored by, and isolated from, others. We also note the benefits that sharing between carers can bring, and routes to coping and relaxing from the burdens of care. We conclude with design considerations for facilitating new forms of digitally mediated support that connect those that care, emphasising design qualities related to transitioning, talking, belonging and escaping.		Kiel Long;Lyndsey L. Bakewell;Roisin C. McNaney;Konstantina Vasileiou;Mark Atkinson;Manuela Barreto;Julie Barnett;Michael Wilson;Shaun W. Lawson;John Vines	2017		10.1145/3025453.3025715	simulation;human–computer interaction;management;operations research	HCI	-75.65753176220491	-11.501414119661518	69061
fd925a0d831d82b3de520b707f757469208820a4	legal aspects of multimedia in europe	legal aspect	Multimedia means multilegia. The basic copyright problem arises out of the fact that multimedia producers need to integrate a hugh quantity of copyrightable works (texts, pictures, music) in their products. This paper describes how the traditional European copyright law can cope with the requirements of the digital age. Instead of compulsory licensing, the collecting societies can manage digital licensing with consent of the rightsholders and through technical devices. The societies should work on the basis of uniform European supervision structure and via coordinating bureaus acting as clearing houses. The system of neighbouring rights however needs some extensions to guarantee sufficient protection for electronic publishers and phonograrn producers in relation to Digital Audiobroadcasting (DAB). Finally, the dogmatic classification of loading acts and electronic transmission has to be taken into account.	image;requirement	Thomas Hoeren	1995			environmental protection;environmental resource management;multimedia	AI	-69.2518190204146	-19.60124577399436	69104
7e1d6725e46a021025989d87a4f0c4b3d955d40b	research on social dimensions of information technology at nsf sbta brief update	information technology	"""t the AAAS Annual Meeting in Anaheim, California, on anuary 24, 1999, Vice-President Gore announced """"IT Squared,"""" the Clinton Administration's proposal for a $366 million, 28 percent increase in the government's investment in information technology research for fiscal year 2000. One area highlighted for support in this budget request to Congress is """"research on the economic and social implications of the Information Revolution."""" The total request for """"Ethical, Legal, and Sodal Implications and Workforce Programs"""" in several Federal agencies is $15 million; $10 million of that is proposed for NSE Currentl)4 NSF staff are busy soliciting ideas and developing announcements for research and related efforts on this complex and multi-faceted topic. One impetus for the attention to this topic is the report of the President's Information Technology Advisory Committee (PITAC), which was released around the time of the AAAS meeting. The section on sodoeconomic research and policy priorities, available at www.hpcc.gov/aclreport/ section_4.html, points to the need for understanding the sodal, economic, and policy issues assodated with information technolog$ Committee members were aware of research projects that NSF had supported, and aware that considerably more is needed in the way of data collection and analysis, and long-term, broad-based, and large-scale research, """"to realize the promise of the new technologies."""" NSF has been supporting research on these issues for some time. The editorial by Floyd Bloom, """"Just a Minute, Please,"""" in the July 9, 1999 issue of Science, demonstrates its timeliness and utility. Bloom's editorial takes a negative position about NIH Director Harold Varmus's idea for a permanent online and downloaded archive for biomedical research reports, but cites no research supporting or contesting his position. As it happens, NSF is supporting some projects related to issues of electronic communication in science. One research project, under the direction of Rob Kling at Indiana University, examines """"Scientific Communication and the Shaping of Knowledge Networks."""" This project points out that significant experimentation in communications via meetings, data archives, and documents is going on now, with different disciplines taking very different approaches. This research compares the changes between 1970-1999 in the communications structures and procedures in six scientific fields, drawing data from published and on-line sources, as well as extensive interviews with editors, forum organizers and active scientists. This kind of research has the potential to provide results that can help support useful variations and avoid wasting resources through needless experimentation or the """"one size fits all"""" approach. The AAAS Committee on Scientific Freedom, Responsibility and Law and the AAAS-ABA National Conference of Lawyers and Scientists are co-sponsoring another project that NSF is supporting. AAAS is the professional society that publishes Science. The project, under the direction of Mark Frankel, consists of a series of workshops on issues of intellectual property protections for electronic publishing in science. The project recognizes that these new technologies pose challenges to the notion of sdence as a 'public good' and asks what kind of property protections are appropriate in these new environments? The project involves key stakeholder groups from the US and abroad, and will attempt to make recommendations for a legal framework for copyright law as applied to electronic publishing in science. Surely the results from this activity will be of interest to Science editor Bloom and numerous others. Mark Frankel and the AAAS Program on Scientific Freedom, Responsibility and Law also just held a workshop on issues for research with human subjects on the Web. The Office of Protection from Research Risks at NIH supported the activity; and information on the project is available at www.aaas.org/spp/dspp/sfrl/projects/intres/main.htm Through its Division of Science Resources Studies (SRS), NSF is beginning to develop data compilations and analyses of the impact of information, communications, and computational technologies on America's quality of life. Eileen Collins is the NSF staff member who directs this effort, and information about its status can be found at www.nsf.gov/sbe/ srs/infotech/status98. Products of the work will be placed"""	aba problem;archive;bloom;experiment;fits;faceted classification;gore (segment);ibm notes;information revolution;network search engine;noise shaping;online and offline;research data archiving;scientific communication;stan frankel;world wide web	Rachelle D. Hollander	1999	SIGCAS Computers and Society	10.1145/572183.572192	computer science;data science;data mining;sociology;law;information technology	HPC	-65.08569327529565	-18.577147690822205	69261
f828a100ec2635a1d1fa901aca206565ab7b7711	what vulnerability assessment and management cybersecurity professionals think their future colleagues need to know: (abstract only)		There is a growing need for cybersecurity professionals with the knowledge, skills, and abilities (KSAs) necessary for risk and vulnerability analysis. Cybersecurity curricula should emphasize KSAs most important in cyber work. To determine which KSAs should be prioritized in curricula, we interviewed 38 cyber professionals with a specialty in vulnerability assessment and management. Interviews took place at the premier hacking conferences Black Hat and DEF CON in 2016 and 2017. Participants rated the importance of 31 KSAs taken from the National Initiative for Cybersecurity Education's Cybersecurity Workforce Framework. Of the 31 KSAs, 12 were rated as being significantly important to vulnerability assessment and management work. Half of these KSAs dealt with system and application vulnerabilities (e.g., Skills in conducting vulnerability scans and recognizing vulnerabilities). The other 6 most important KSAs concerned attacks (e.g., Knowledge of different classes of attacks), penetration testing (e.g., Skill in the use of penetration testing tools and techniques), and network protocols (e.g., Knowledge of network protocols). Overall, results suggest that vulnerability assessment students should graduate with: 1) knowledge of and skills in identifying vulnerabilities and robustness of systems and applications; 2) conceptual familiarity with classes of attacks and attack stages; 3) knowledge of and skills in penetration testing principles and tools, and 4) knowledge of network traffic and network protocols. Handouts will be provided.	black hat;communications protocol;computer security;cyber security standards;interviews;national research and education network;need to know;network traffic control;penetration test;vulnerability (computing);vulnerability database	Miriam E. Armstrong;Keith S. Jones;Akbar Siami Namin;David C. Newton	2018		10.1145/3159450.3162250	curriculum;knowledge management;hacker;need to know;communications protocol;curriculum development;robustness (computer science);computer security;computer science;vulnerability assessment;vulnerability	Security	-68.58709469176051	-11.239330483085377	69341
10df6beacbc7275c547b91beac41458fe9eeef1d	changing workplace demands: what job ads tell us	bibliotecario;especialista informacion;australie;profession;oceanie;job ads;information professional;north america;america del norte;professional competence;amerique du nord;amerique;mercado trabajo;professionnel information;etats unis;estados unidos;informacion documentacion;content analysis;enquete;offre emploi;workplace;profesion;marche travail;contratacion personal;labour market;competence professionnelle;software package;librarian;encuesta;america;perfil profesional;grupo a;bibliothecaire;information profession;recrutement personnel;staff recruitment;survey;ciencias sociales;advertisements;oceania;librarians;australia;united states of america;design methodology	Purpose This paper analyses job ads as relatively accessible indicators of the knowledge, skills and competencies required of librarians by employers. It then uses a framework provided by the literature on professional jurisdiction to examine what may be trends and shaping factors for the Library and Information Studies (LIS) profession with regard to jurisdiction in a changing information landscape. Design/methodology/approach Job ads were examined in two separate studies; one comparing job ads in Australia and the US over eight weeks in 2004, and the other looking at one month snapshots of Australian job ads in 1974, 1984, 1994 and 2004. The text from the job ads was analysed using a content analysis software package. The literature on professional jurisdiction provided an interpretive framework. Findings The Australian snapshots over time showed that there is an increasing lack of clarity about the skills and competencies required of librarians. The American job ads seemed to rank jurisdictional knowledge and professional qualifications more highly than their Australian counterparts. Interpersonal skills, behavioural characteristics and technical services skills are in demand in both countries. Originality/value In addition to reporting on the knowledge, skills and competencies required of librarians, by applying an interpretive framework from the literature on professional jurisdiction the paper exposes some of the challenges ahead for the LIS profession. Research limitations/implications This research used a small number of sources and a relatively small number of ads. It is acknowledged that job ads are only one source of information about knowledge, skills and competencies. URL: http://dx.doi.org/10.1108/00012530610677228, http://researchoutput.csu.edu.au/R/-?func=dbin-jumpfull&amp;object_id=22796&amp;local_base=GEN01-CSU01, Author Address: mkennan@csu.edu.au		Mary Anne Kennan;Fletcher T. H. Cole;Patricia Willard;Concepción S. Wilson;Linda S. Marion	2006	Aslib Proceedings	10.1108/00012530610677228	public relations;design methods;content analysis;job attitude;telecommunications;operations management;sociology;management;job analysis	Web+IR	-73.47850341669552	-21.995330758805494	69667
94d4976210b4614f622aada1380d362cfeda52f3	learning and literacies in the social world of tony hawk underground 2			social reality;underground	Elisabeth R. Hayes	2005			geography;humanities	NLP	-64.87436567398876	-10.371344752931945	69840
a2be60c0495c656b56f9575edfb11d4aa032661f	serving science while paying the bills: the history of the journal of biological chemistry online	edition electronique;north america;america del norte;amerique du nord;amerique;electronic periodical;evolucion;periodique electronique;sociedad cientifica;biochimie;editor;etats unis;estados unidos;litterature scientifique;chimie;literatura cientifica;edicion electronica;chemistry;quimica;learned society;publisher;electronic publishing;societe savante;america;bioquimica;scientific literature;editeur;periodico electronico;biochemistry;evolution	Recent developments in the publication of the Journal of Biological Chemistry (JBC) are discussed, particularly the development of the electronic version of the Journal, JBC Online, and the opportunities and challenges that this mode of publication has presented to its publisher, the American Society for Biochemistry and Molecular Biology (ASBMB) and its mission of service. Learned Publishing (2005)18, 127–130 Robert D. Simoni Serving science while paying the bills: the history of the Journal of Biological Chemistry Online 127 L E A R N E D P U B L I S H I N G V O L . 1 8 N O . 2 A P R I L 2 0 0 5 searchable discs. Charles (Chuck) Hancock and Barbara Gordon of ASBMB contracted with Lightbinders and the CD version of JBC was launched in 1993. Although the CD was a technical advance and a great improvement over storing back issues of the print version of the Journal, it had many limitations. First, it was not timely – each CD was released months after the printed issue. Additionally, librarians were not willing to substitute the CD for their print versions, even as storage, and never adopted it. By 1994, we realized that the CD version of JBC was not going to be an acceptable or sustainable adjunct or alternative to print and we began to consider other possibilities. In 1994, a fateful meeting of the Stanford University Faculty Senate brought an unexpected opportunity. During a report from the University Library Committee, always riveting, I described the dilemma that the JBC was facing with print publication and the unsatisfactory experience with the CD. After the meeting, Michael Keller, the University Librarian, suggested that it was time to consider using the Internet to publish scientific research and that the Stanford University Library would be willing to partner with ASBMB/JBC to create the first online journal. Shortly after a series of exploratory meetings, the collaboration began, with joint funding from ASBMB and Stanford University. It is a testament to the strong fiscal management and visionary leadership of ASBMB that substantial funds were available to invest in such a risky endeavour. This was the perfect collaboration since a university library system and a non-profit, society publisher share the same missions of service and information dissemination. Keller, with ASBMB as collaborator, started HighWire Press as the electronic imprint of Stanford University Library. John Sack was hired as Director of HighWire Press, and under Sack’s direction, Hancock and Gordon from ASBMB and Fran Steck and Aaron Bigman from Cadmus Journal Services set to work in January 1995 to publish JBC Online in time for a début at the ASBMB Annual Meeting in May of that year. It was a Manhattan Project-like effort, but at the ASBMB Annual Meeting in San Francisco, JBC Online was launched to the surprise, delight and amazement of several thousand meeting attendees as well as to those who had made the heroic effort.	chuck;endeavour (supercomputer);internet;librarian;library classification;printing;testament	Robert D. Simoni	2005	Learned Publishing	10.1087/0953151053584993	evolution;electronic publishing;law	Theory	-66.90411915791876	-19.933508801464622	70298
493fe25ab845b513d983ac6f6ccb831915840015	the virtual staff		Carl Hoover is the computer center director for a small liberal arts college in the Midwest. He came to this position after several years in industry and thoroughly enjoys the relatively peaceful life of an idyllic college town. He also works very hard to provide high qlmlity service from the academic and administrative computer systems of the college. In fact, he is the first director in more that 10 years who has been able to keep both the administrative and academic users reasonably happy. He has regularly received excellent performance reviews but not the increases in his staff budget that he insists would be necessary to support a professional computer center on campus. Still, Carl manages to run a reasonably tight ship. Since he has a minimal support staff, he is always on the look out for the brightest computer science students and practically Shanghais them into working for the center as student employees.	computer science;high availability	Lonny B. Winrich	1996	SIGCAS Computers and Society	10.1145/229403.229414	sociology;knowledge management;public relations	Web+IR	-65.31897383805808	-23.57820977183282	70343
cfb24b9ad6dc7e86e42dd20ea77b65c74df12b88	programming is a part time job	data processing	A lot of people are predicting the future these days. Some are saying that in five years applications programmers will be an extinct species. Others are predicting that software will become so extensive that naive users will be able to write their own programs. In any event, the future of applications programmers promises to be insecure at best. I say none of these predictions will come true. With all this advance warning, programmers and programming managers will once again find a way to survive. This is the natural behavior of anyone in danger. But I would like to suggest that we take a fresh look at the situation.  I am not chastising programmers. As their jobs are defined, they are doing what is required of them. They have not deliberately set out to make things difficult for their organizations. The fact is, however, that organizations are in some confusion as to just what good their data processing departments are doing for them. We have been trying for over 25 years to define our jobs in this field, and so far all we've managed to do is protect our own interests. What I am going to suggest here is that we challenge ourselves on this.  One of the ways I suggest we challenge ourselves is to face up to the fact that programming is not a full time job. It is 20% of a job. The remaining 80% is the topic of this paper.	job stream;programmer	Edrice Addleman	1975		10.1145/800115.803713	simulation;computer science;operations management;operations research	Web+IR	-63.04111894260779	-22.847202607221345	70362
3fcca1af373fe1bbbacdb9999f56e940dfbf8914	a gardener's experience of document work at a historic landscape site	information experience;document experience;landscape gardening;document work;documentation	Research in document work has tended to take a sociocultural perspective. Recent interest in document experience invites the consideration of document work from the perspective of an individual's lived experience. This paper reports on a holistic, single-case study of how the head gardener at Shofuso Japanese House and Garden, a historic landscape site in Philadelphia, experiences the document work involved in developing a comprehensive garden plan. A hermeneutic analysis of the data reveals how the underlying foundational values of authenticity, education and reducing ambiguity support the process of document work in this case, which involves summoning diverse knowledge, channeling the master and stepping back. This process is punctuated by organizational and historical challenges. These findings suggest that the theoretical framework of foundation-process-challenges may be used to study the lived experience of document work in other cases. Further ramifications are discussed for practice in gardening and historical document work.		Tim Gorichanaz	2016		10.1002/pra2.2016.14505301067	humanities;geography;knowledge management;management	HCI	-71.63978103318235	-19.258849524241057	70414
0bd7904f19a69224661d6ae9c20fa6d141bf08dd	finding case law on a european scale - current practice and future work		There is a growing awareness that the national judge plays a vital role in the European legal system, as is illustrated by the emergence of various initiatives for the cross-border access of national (EU-related) case law. Because these and various national systems all use their own identifiers, findability and citability are seriously hampered. This paper assesses current developments and tries to define a solution for remaining problems. A European Case Law Identifier and a central index are fundamental elements in this solution.	emergence;findability;identifier	Marc van Opijnen	2008		10.3233/978-1-58603-952-3-43		HCI	-73.14852088359925	-14.297681439158334	70463
1cba2d22adfb98c24fa4a6c3c31950bcda19daa3	tods special issues	digital library;public policy;it evaluation;fast food	The March 2004 issue of TODSshould be in your mailbox (as well as available in cyberspace, at the ACM Digital Library) around the time you receive this issue of SIGMOD Record . This issue is a first, a special issue dedicated to extended versions of SIGMOD and PODS papers from the 2002 conference. This special issue opens the topic of invited papers from conferences, and indeed, the more general topic of journal versions of conference papers. A conference paper is the scholarly equivalent of fast food: quick to read (eat), sometimes healthy for you, and undoubtably convenient. The strict page limit (10–12 pages, depending on the conference) favors topics that can be introduced, developed, and evaluated in a short amount of space. One can read several conference papers, on a wide variety of topics, in the time that it takes to read one journal article. A journal paper is the equivalent of a three-course dinner. It is allowed space (in terms of page count) to more fully examine related work, develop algorithmic or theoretical refinements to the proposed approach, and perform a more thorough evaluation of the central idea of the paper. Some topics are perfect for a conference paper. The approach is simple and thus can be described fully in just a few pages, the applicability is routine, the related work minimal, and the requisite evaluation straightforward. Other topics are better suited for a journal paper: there may be a substantial prior literature that must be summarized and the positioning of the paper explained, the approach may be complex and require careful development, the evaluation may be quite involved, with many aspects to consider. In fact, some ideas require more space than even a journal article provides (as I have remarked in these pages three years ago1). The impetus for the last two books that I wrote was exactly that: I knew that to fully discuss my ideas and the rationale behind them, a single journal article, or even two or three related articles, would not be sufficient, but the several hundred pages afforded by a book-length monograph was perfect. Then there are those ideas that work well in both conference and journal form. The conference paper is a teaser, presenting just enough of the idea and its evaluation to be interesting and to get the idea out there. The journal paper then elaborates on the idea, expounding on exactly where and in what circumstances the idea applies, identifying exactly where the benefits reside and the magnitude of those benefits, and providing a full exposition of the idea, with all necessary detail. It is this last category of papers that program chairs of SIGMOD, PODS, EDBT, and ICDT are encouraged to nominate for invitation. These nominations are evaluated by the Editor-in-Chief and a relevant Associate Editor to select those conference papers with the most potential for extension, for invitation. The invitation emphasizes the TODSprior publication policy2, summarized here.	acm transactions on database systems;algorithm;book;cyberspace;design rationale;digital library;fast food;out there;symposium on principles of database systems	Richard T. Snodgrass	2004	SIGMOD Record		public policy;digital library;computer science;multimedia	Visualization	-67.18783225326693	-19.91979476114126	70701
c11cafa19924c18c911095274a92ab483bcf8c76	the consumer product selection process in an internet age: obstacles to maximum effectiveness & policy options	entry barrier;real estate;business strategy	II. BACKGROUND.......................................................................................................................... 4 A. The Internet Has Widened the Global Marketplace ......................................................... 4 B. Shopping the Internet “Without” Middlemen Can Be Frustrating................................... 5 C. What Shoppers Want and the Value of Databases............................................................ 5 III. ENSURING ACCESS TO ALL DESIRED OPTIONS........................................................................ 7 A. Prohibiting Misleading Claims of Coverage .................................................................... 8 B. Imposing Access Rules on Dominant Firms...................................................................... 8 C. Combating Efforts to Deny Buyers Options ..................................................................... 9 1. Enabling Consumers to Employ Effective Aggregators ............................................. 9 2. Licensing and Other Government RestraintsOn Choice ........................................... 10	compiler;database;internet;purchasing;random access	Mark S. Nadel	2001	CoRR			ECom	-69.53567372852444	-15.344667634762615	70760
6d6cd563c873db3fb524aeb220acbad7737650bd	chemical information activities: what the future holds	software;base donnee;articulo sintesis;logiciel;article synthese;database;base dato;information access;cdrom;chimie;documentacion;chemistry;computer aid;quimica;acces information;logicial;asistencia ordenador;acceso informacion;review;assistance ordinateur;documentation			Stephen R. Heller	1993	Journal of Chemical Information and Computer Sciences	10.1021/ci00013a001	documentation;computer science;artificial intelligence;database;operations research	Theory	-72.60111558374443	-23.092759897662205	70828
6fb02c0c1df55ed074aa64438c2321a79301c525	building theoretical underpinnings for digital forensics research	digital forensic;digital forensics;theoretical framework;electronic evidence	In order for technical research in digital forensics to progress a cohesive set of electronic forensics characteristics must be specified. To date, although the need for such a framework has been expressed, with a few exceptions, clear unifying characteristics have not been well laid out. We begin the process of formulating a framework for digital forensics research by identifying fundamental properties and abstractions. a 2004 Elsevier Ltd. All rights reserved. KEYWORDS		Sarah Mocas	2004	Digital Investigation	10.1016/j.diin.2003.12.004	computer science;digital forensics;data mining;internet privacy;computer security	Security	-72.00242962532168	-14.264432065192931	70912
35f804fe869c18af9f592ff0fa88813310270fbb	legal issues regarding digital forensic examiners third party consent to search		This paper focuses on Federal law as it relates to consent to search relating to Fourth Amendment privacy in the practice of Digital Forensics. In particular, Digital Examiners should be aware of how decisions in Federal Court may impact their ability to acquire evidence in both civil and criminal settings. Digital Forensics, being a relatively new field, is particularly subject to change as cases and appeals are decided. This paper provides an overview of relevant case law relating to issues in Digital Forensics. More importantly, our research provides Digital Forensic Examiners (DFE), as defined by Lonardo, White, and Rea (2008, 2009), with scenarios that illustrate the various nuances when dealing with the consent to search. From issues of common authority, conflicting consent, apparent authority, and voluntary consent, our research explores court findings and applies them to practical advice and policy formation for DFEs.	application security;artificial intelligence;computer forensics;information systems;information security;management information system;mobile app;rs-232;resources, events, agents (accounting model);security management;social engineering (security);subject matter expert turing test;tom;virtual reality;web	Thomas Lonardo;Tricia Martland;Doug White;Alan Rea	2011	JDFSL		digital forensics;political science;public administration;law;computer security;computer forensics	Security	-72.58157772797006	-10.499147182351187	71269
3f574932c2db9cd176cef198d7f1f687dcaab127	for richer, for poorer, in sickness or in health...: the long-term management of personal information	personal information management;personal digital archiving;aging;information curation;pim	People are amassing large personal information stores. These stores present rich opportunities for analysis and use in matters of wealth, health, living and legacy. But these stores also bring with them new challenges for managing information across long periods of time. Hence personal information management (PIM) research increasingly must address the long term. For the seventh PIM workshop in a successful series started in 2005, we propose taking a look at personal information with exactly this longitudinal perspective. We expect the workshop to attract a range of people doing research related to PIM, HCI, personal digital archiving, aging, and the design of informational spaces for later life. Attendees will discuss issues related to storing information for the long run, how stored information can benefit a person throughout their lifetime (and into old age), and the legacy of a person's personal information.	archive;human–computer interaction;personal information management;personally identifiable information	William Jones;Victoria Bellotti;Robert G. Capra;Jesse David Dinneen;Gloria Mark;Catherine C. Marshall;Karyn Moffatt;Jaime Teevan;Maximus Van Kleek	2016		10.1145/2851581.2856481	human–computer interaction;computer science;knowledge management;personal information management;data mining;group information management;multimedia;management;world wide web;personal information manager	HCI	-67.76635752698623	-19.31482725872159	71338
886699c19395213c8e22c93165dd5bf8178d73fa	editorial: prologue and introduction	standardization;standards	his issue of Standard View is another eclectic mix of standardization, information, and generally interesting articles. As usual, it is meant to provoke, while providing a degree of information about continuing trends in standardization. I trust that you will find some parts of it useful. Apropos of continuing trends, I’d like to examine a new development in standardization-the role of provider of the Publicly Available Specification (PAS). This is of interest because Sun Microsystems recently (March 1997) submitted a proposal to the International Organization for Standardizatiodhternational Electrotechnical Committee Joint Technical Committee 1 (ISO/IEC JTC1) for recognition as a submitter of Publicly Available Specifications. This has myriad implications for the entire standardization arena. A bit of background on the PAS process is necessary. In the early 1990s, the information technology standards developing organizations (SDOs) began to hemorrhage members. As major corporations began to downsize, participation in formal standards organizations began to drop, resulting in fewer members, smaller dues payments, and a decline in startup projects. While the SDOs viewed this trend with concern, they were even more concerned and interested in the spectacular growth of consortia. There were object consortia, open consortia, alphabetic consortia, numeric consortia, and so on and so forth. All these consortia charged large fees to their members-usually the same members who composed the SDOs and were dropping participation in them. At first SDOs took the growth of consortia lightly and treated them as a passing fancy. Over time, however, consortia became firmly established, eclipsing formal SDOs in the most critical area of allmarket acceptance of public specifications, the consortia equivalent of standards. The SDOs needed to reassert their hegemony, and after much thought came up with the idea of the Publicly Available Specification (PAS). A PAS is a product of a consortium, created in accordance with the rules governing the consortium. When the consortium has completed its work and the market has accepted the specification, the consortium can submit the work to an SDOfor acceptance as a standard, if the consortium is recognized as a “Submitter of Public Specifications.” To earn this title, the consortium must answer a detailed questionnaire provided by ISO/IEC JTC1, affirming that its specifications are open, that it will support the specification, and a host of other questions concerning the consortium’s legitimacy and process. As might be expected, most consortia took one look at this process and declined to participate. Most consortia regard themselves as legitimate and do not need the “imprimatur” of IS0 to be successful in the marketplace-which was, after all, the reason that their sponsors were paying the fees. The process requirements of a consortium can be just as severe, possibly more so, as an SDO’s. Additionally, going through the steps necessary to gain the minimal advantage provided by a formally recognized IS0 standard was not, for most consortia, justifiable. As a result, the PAS Submitter program has been a dismal failure, with very few PAS submitted. And of those that were, few mattered to the general market. In the past several years, several significant technology opportunities have arisen, to which the formal groups have not been party: The World Wide Web is the property of the Internet Engineering Task Force and the World Wide Web Consortium. IS0 just recently received its first HTML submission. The standardization of ActiveX was given to a consortium within a consortium (the Active Group inside the Open Group); Netscape contributed JavaScript to ECMA for eventual I S 0 fast-track, but ignored the U.S. national body. HTTP belongs to the IETF, and HTML(the Web language variant of SGML) belongs to the W3C. Multimedia is in the IETF, and several other consortia. This phenomenon has contributed to the decline in interest in the SDOs as well. This is why Sun’s application for acceptance as a submitter of PAS is such a major event for ISO/IEC JTC1, and for I S 0 in general. It is generally understood that if Sun is accepted as a PAS provider, it will submit Java to JTCl for standardization. And Java is the prize of the decade for a standardization organization. It is new, it is interesting, it is fun, and it is proprietary. There is no way around that fact. Sun did not develop Java to create a standard, but to create a product that they could sell to make money. And when a company creates a product, they usually try to keep their competition from getting the same product. This is why there are intellectual property rights and things such as patents. The company’s ultimate intent is to sell a product that other companies can’t or won’t sell, and to make money on the transaction. Not rocket science. In Sun’s defense, Sun was encouraged to submit an application by the management of the SDOs (Sergio Mazza, President of ANSI, announced to the press that an ap-	activex;consortium;ecmascript;html;hypertext transfer protocol;iso/iec 42010;java;javascript;money;requirement;sergio verdú;service data objects;standard generalized markup language;the open group;web language;world wide web	Carl Cargill	1997	ACM StandardView	10.1145/253452.253456	knowledge management;computer science;prologue	Web+IR	-66.89657579436285	-16.819050487786733	71699
f3c8fabe141875073cd527f6c4417f77eca4ddb0	discursive formations and trans-disciplinary agendas: a response to walsham	information management system;information systems security;mis systems;information systems research;journal of it;t technology general;jit;teaching cases;information security;case studies;information science;information security systems;information technology;business information technology;security information systems;it journals;information systems management;it teaching cases;operational research society;business model;qa75 electronic computers computer science;journal of information technology teaching cases;computer information systems;jit journal;geographic information systems;information technology journal;information management;information systems journals;information systems technology;managing information systems;accounting information systems;information and management;management information systems;define information systems;strategic information systems;business information management;soft system methodology;h social sciences general;information system;health information systems;computer information technology;journal of information technology;business information systems;business systems analyst;journal information technology;it journal;management science;journal of information systems;information technology journals	W e would like to congratulate the Editors of JIT for suggesting to Geoff Walsham that he initiate a discussion in the pages of their journal on ‘Whither the IS field?’, also to Geoff for responding with a thoughtful and challenging paper (Walsham, 2012). The impact of his paper is reflected in the number of responses received and published in JIT. Some of these have argued that asking the question is itself an indication of the discipline’s malaise, part of an endless cycle of navel gazing, an activity not appropriate for a mature discipline. We disagree. All disciplines must be seen as ‘discursive formations,’ with those involved engaging in discussions regarding the directions in which things are being taken; encompassing practical, professional, and academic manifestations: Hence, this contribution to the discussion and ensuing responses. Walsham poses the question and challenge – ‘Are we making a better world with ICTs?’ The responses from Adam (2012), March and Neiderman (2012), Davidson (2012), Baskerville (2012), and to some extent Schultze (2012), assume that this refers specifically to the information systems (IS) discipline in some sense; which is understandable given that Walsham’s article is published in JIT. The ‘we’ in this case can be assumed to refer to the IS research community. In the 1950s, one of the popular TV series of the day was ‘The Lone Ranger,’ the eponymous hero was a masked man aided by his ‘trusty side-kick’ Tonto, who would now be described as a Native American. Dating from this time there is a joke that the Lone Ranger and Tonto see a horde of Indian braves bearing down on them in full battle fury. ‘Looks like we are in trouble, Tonto,’ says the Lone Ranger to his companion. ‘What do you mean “we,” white man?’ Tonto responds. So, in similar fashion, the present authors raise the question ‘What “we” Professor Walsham?’ In other words, why assume that the challenges facing IS academics and their ilk are only to be taken up within a fairly narrowly conceived view of the IS academic discipline? Walsham offers the very apposite example of ICT4D (ICT for Development) in the context of his paper, although somewhat confusingly he refers to it as a ‘subfield’ of IS; later using terms such as multidisciplinary and interdisciplinary. In fact, ICT4D exemplifies what Griselda Pollock has termed the trans-disciplinary; defined as trying ‘to hold on to both the specificity of particular ways of thinking and knowing that define disciplines, while creating the space of their productive encounter so that a different kind of knowledge emerges in the act of intersection and traverse of varied fields through which a shared concept might travel’ (Pollock, 2007). In this sense ICT4D exemplifies a key site for such encounters. Indeed, Shirin Madon in her study of E-governance in India demonstrates the problems which arise when ICT4D is regarded as a ‘subfield of IS’ or ICT in a narrow technical sense; leading to systems failures resulting from a lack of awareness of aspects such as the underlying concerns of Indian villagers, political structures, and cultural mores (Madon, 2009). Taking this perspective and using Walsham’s example of ICT4D, the term ‘we’ can and indeed should be seen as potentially encompassing a wide range of skills, interests, specializations, and disciplines brought together by those concerned with a relatively well-understood field which involves looking at the ways in which technological developments around ICTs can be brought to bear on issues around development. This is a far more complex picture, but as Richard Feynman noted it is better to	source-to-source compiler	Antony Bryant;Frank F. Land	2012	JIT	10.1057/jit.2012.15	computer science;systems engineering;engineering;knowledge management;electrical engineering;management information systems;management science;information technology;information system	NLP	-72.94212642713181	-16.63790538061231	71774
5b1ba3a7ff47daab4c716f4f6881ad9d3c93320f	speculative investors and transactions tax: evidence from the housing market	speculators;volatility	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2015, INFORMS	algorithmic trading;basic stamp;difference in differences;download;fo (complexity);institute for operations research and the management sciences;know-how trading;material design;nl (complexity);offset binary;price point;robot;speculative execution;traders;volatility	Yuming Fu;Wenlan Qian;Bernard Yeung	2016	Management Science	10.1287/mnsc.2015.2268	speculation;volatility;economics;finance;microeconomics;economy;labour economics	Logic	-68.19404625705279	-15.01340426340738	71952
ccb991cede5dc218ceafc7df76580e3a3c44e1e6	digitizing special collections: to boldly go where we've been before	gestion fonds;fondos especializados;new technology;north america;america del norte;amerique du nord;amerique;digital library;digitizing;digital libraries;collections management;biblioteca ensenanza superior;numerisation;etats unis;gestion fondos;estados unidos;stock management;biblioteca electronica;estudio caso;bibliotheque enseignement superieur;etude cas;numerizacion;electronic library;higher education library;special holdings;nevada;america;academic libraries;fonds specialise;bibliotheque electronique;design methodology	Purpose – Aims to present issues related to digitization in the context of the historical role and purpose of academic special collections.Design/methodology/approach – Presents a comparison of current issues related to digitization to historical issues related to the management of traditional print special collections.Findings – The current issues are not new. Technology has not dramatically altered the role of special collections in academic libraries.Research limitations/implications – Based on personal observation and experience and an awareness of issues, but essentially a personal viewpoint.Practical implications – May provide non‐special collections librarians with a better understanding of, or different perspective on, the popular notion of “digitizing special collections” and of special collections historically and generally.Originality/value – This is the viewpoint of an experienced head of special collections, a trained academic historian, and someone who has been involved in a number of digita...		Peter Michel	2005	Library Hi Tech	10.1108/07378830510621793	digital library;stock management;design methods;computer science;world wide web;collections management	DB	-72.65414070730152	-22.405092054030987	72043
b8f24bd0d9f561ad4c62b64a3a45d92933e9cc79	integration | innovation | inclusion: values, variables and the design of human environments	values;systems;beliefs;integration;culture;holism;environmental design;architecture	Complexity, complication, contradiction, consumption, confusion, delusion, depression. Opportunity, inspiration, ingenuity, compassion, wisdom. Our world is perplexing, our times are fast moving, and our choices are many. To find an appropriate path is a daunting yet vital challenge that confronts us as individuals, as communities, and as a civilization. How sustainable is our world? How reasonable are our behaviors? The present article is a collection of thoughts on a series of intertwined issues related to the contemporary world, its environmental dimensions, and their present-day problems. The goal is to survey the landscape through a lens of Environmental Design, to provide some perspectives, to raise some questions, and to explore systems, beliefs, and values informing and influencing actions. It is important to consider how people's belief systems influence, inform, and shape actions. This holds true in realms political, spiritual, and cultural. It also proves relevant in the ways in which we imagin...	variable (computer science)	Brian R. Sinclair	2015	Cybernetics and Systems	10.1080/01969722.2015.1038481	holism;environmental design;artificial intelligence;values;architecture;culture	AI	-76.57842852793691	-10.783045620088066	72119
f13b041af8c07d6165e0515d85901a03021bdf64	heidegger, technology and sustainability - between intentionality, accountability and empowerment		Transition is the adequate term for characterising contemporary societies. Norms and values are in transit, led by a technological revolution, which is, in itself, the tip of the iceberg of millenary social and cultural changes. Heidegger, one of the leading philosophers of the twentieth century, captured this tension between social change and innovative technology and showed that the Western civilisation was captive of ontological instances whose role was already pin-pointed by Greek Antiquity philosophy but which went underground with Modernity. The product of Heidegger’s work was a revolution in Western thought, which found echoes across all areas of society. Taking Husserl’s call for “back to the things themselves”, Heidegger’s impact has empowered the calls for more sustainable and resilient societies. Sustainability models, with its three pillars of environmental, economic and social sustainability, are directly dependent upon the role of technology and of information science in shaping current patterns of production and consumption in contemporary societies. Industrial, academic and political discourses already voice such taken for granted assumptions. Nevertheless, it is crucial to clarify and to highlight the links between economic evolution and progress, social change and the catalysing role of technology, taken as an enabler of human action.	captive portal;information science;intentionality;noise shaping	Ângela Lacerda Nobre;Rogério Duarte;Marc Jacquinet	2017		10.5220/0006372401860190	knowledge management;intentionality;accountability;computer science;sustainability;empowerment	HCI	-76.0096555459935	-11.282899856640384	72178
16534bb9d43d4e1c5451e280263996eaf5ee4e57	looking for trouble: understanding end-user security management	human computer interaction;knowledge management;security management;computer security;level of detail;security and privacy;awareness;expertise	End users are often cast as the weak link in computer security; they fall victim to social engineering and tend to know very little about security technology and policies. This paper challenges this view as derogatory and unconstructive, arguing that users, as agents of organizations, often have sophisticated strategies regarding sensitive data, and are quite cautious. Existing work on user security practice has failed to consider how users view security; this paper provides content on and analysis of end user perspectives on security management. We suggest that properly designed systems would bridge the knowledge gap (where necessary) and mask levels of detail (where possible), allowing users to manage their security needs in synchrony with the needs of the organization. The evidence for our arguments comes from a set of in-depth interviews with users with no special training on, knowledge of, or interest in computer security. We conclude with guidelines for security and privacy tools that better leverage existing users knowledge.	computer security;information security;privacy;security management;social engineering (security)	Joshua B. Gross;Mary Beth Rosson	2007		10.1145/1234772.1234786	computer security model;cloud computing security;critical security studies;security management;security through obscurity;awareness;security information and event management;security engineering;security convergence;covert channel;asset;computer science;knowledge management;level of detail;data mining;human-computer interaction in information security;security service;security testing;computer security	Security	-72.77179979467527	-10.894043663559783	72263
3ac0b40866a74c625247325f7ec55dd7cc22f921	the espoused theories of is: a study of general editorial statements	is identity;general editorial statement;espoused theory;general editorial statement ges;communication conference;lexicometric analysis;information systems is;thematic analysis;expectations;is journals	In the IS field there has been the ongoing debate about a potential identity crisis, which has led researchers to study the output of the community in order to evaluate where IS research currently is and where it could potentially be. This has resulted in various proposals for IS research ‘in practice’. This research follows a different strategy and studies what IS research is claimed to be (the espoused theories of IS). The section of IS journals’ General Editorials Statements (GES), that is, the informative section offered by most journals where they position themselves with regard to potential authors, already contains the answer. Basing our study on the AISWorld journal ranking, we collected GES for a sample of 30 IS journals for the years 1997 and 2007. We applied thematic, lexicometric, and factor analyses to the datasets of the 1997 and the 2007 GES. The results of the analyses show how the institutionalized discourse about IS research has changed over the last decade.	information;theory	François-Xavier de Vaujany;Nicolas Lesca;Vladislav V. Fomin;Claudia Löbbecke	2008			library science;social science;medicine;operations research	NLP	-74.21911969532428	-16.487022170095116	72382
7db5f0d86d788a26e535a04102872a677bf7d403	a history of cluster analysis using the classification society's bibliography over four decades		The Classification Literature Automated Search Service, an annual bibliography based on citation of one or more of a set of around 80 book or journal publications, ran from 1972 to 2012. We analyze here the years 1994 to 2011. The Classification Society’s Service, as it was termed, has been produced by the Classification Society. In earlier decades it was distributed as a diskette or CD with the Journal of Classification. Among our findings are the following: an enormous increase in scholarly production post approximately 2000; a very major increase in quantity, coupled with work in different disciplines, from approximately 2004; and a major shift also from cluster analysis in earlier times having mathematics and psychology as disciplines of the journals published in, and affiliations of authors, contrasted with, in more recent times, a “centre of gravity” in management and engineering.	cluster analysis;floppy disk	Fionn Murtagh;Michael J. Kurtz	2012	CoRR		computer science;data science;operations research;world wide web	ML	-76.63062359822804	-20.573826898644345	72383
e9d976559d53b93eef9b85522ca85e567ce5a53b	a meta-problem behind the diverse perspectives on the underrepresentation of girls in information and computing technology subjects		The percentages of girls in developing countries studying information technology subjects in the post-compulsory years of education has remained persistently low: often under 25%. This is despite the fact that this particular phenomenon has been the subject of international enquiry for over two decades. The persistence of this pattern raises questions about the extent to which the factors influencing girls’ decision making are fully understood and associated questions about the ways in which both the problem and solution are most usefully conceptualized. This paper explores the limitations of dominant ways of explaining girl’s underrepresentation in information technology courses and careers and argues the need for a more holistic approach to designing and enacting interventions. It draws particular attention to the need for ongoing research in this area which seeks to map the persistence of narrow and limiting understandings of gender that continue to thrive in contemporary IT and school contexts. Furthermore it highlights the associated need for teachers to be equipped with skills that allow them to contest and challenge these understandings while also designing IT related subjects that are engaging and relevant to girls and to boys. A Meta-Problem Behind the Diverse Perspectives on the Underrepresentation of Girls in Information and Computing Technology Subjects	holism;persistence (computer science)	Leonie Rowan	2012	IJPOP	10.4018/ijpop.2012070102	library science;human–computer interaction;computer science;multimedia	HCI	-76.77449650902894	-11.56210296442973	72482
b0944ed077a861458437dd3d956d7eb50e979abe	aconda and anaconda: social change, social responsibility, and librarianship	text;north america;america del norte;amerique du nord;amerique;social responsibility;role professionnel;biblioteconomia;socially responsible;occupational role;bibliotheconomie;information policy;libraries and society;etats unis;estados unidos;american library association;social role;cambio social;politique information;librarianship;funcion social;social change;america;role social;changement social;politica informacion;rol profesional	"""ABSTRAGT In the context of the declining legitimacy of the war in Vietnam and widespread challenges to the authority of established institutions and cultural norms, the American Library Association (ALA) was the target of criticism by a diverse coalition of librarians who asserted two broad demands; first, that the ALA expand the scope of its activities to include consideration of social and political issues that had not, to that point, been regarded as """"library"""" issues by the established leadership of the ALA; second, that the ALA democratize its structure of decision making. This challenge led to the creation of the Social Responsibilities Round Table (SRRT), which is still active as a component ofthe ALA. It also prompted the formation of two committees in response to the above demands: the Activities Committee on New Directions (ACONDA) and the Ad Hoc Activities Committee on New Directions (ANACONDA). A central concept at play in the politics of these events is the notion of """"social responsibility"""" and its meaning in time ofwar and social change. This article focuses on the discourse of the challengers to the ALA and the ALA's response through the work of ACONDA and ANACONDA to examine the contesting and contested meanings of the """"social responsibility"""" of libraries, librarianship, and the ALA. These events and this discursive struggle established an explicit professional concern for and continuing conflict over the meaning and role oflibraries and librarianship in the creation of culture that before these events had been merely implicit in professional discourse."""	anaconda;hoc (programming language);librarian;library (computing);norm (social)	Douglas Raber	2007	Library Trends	10.1353/lib.2007.0020	psychology;library science;social science;economics;philosophy;engineering;social responsibility;sociology;management;law;economic growth	HCI	-74.02781847512391	-20.551413101541495	72577
53b94212dd06a8c9a17065ece27f647ca42ba170	are there global shifts in the world science base? analysing the catching up and falling behind of world regions	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;dynamic scientific specialization;uk phd theses thesis;life sciences;revealed comparative advantage;bibliometrics;absorptive capacity in science base;uk research reports;medical journals;world regions;europe pmc;biomedical research;bioinformatics;static scientific specialization	This paper explores the changing role of world regions (North America, EU15, South EU, Central and Eastern Europe (CEE), Former-USSR, Latin America, Asia Pacific and the Middle East) in science from 1981 to 2011. We use bibliometric data extracted from Thomson Reuter’s National Science Indicators (2011) for 21 broad disciplines, and aggregated the data into the four major science areas: life, fundamental, applied and social sciences. Comparing three sub-periods (1981–1989, 1990–2000 and 2001–2011), we investigate (i) over time changes in descriptive indicators such as publications, citations, and relative impact; (ii) static specialization measured by revealed comparative advantage (RCA) in citations and papers; and (iii) dynamic specialization measured by absolute growth in papers. Descriptive results show a global shift in science largely in quantity (papers) and much less in impact (citations). We argue this should be interpreted as a shift in science’s absorptive capacity but not necessarily a shift of knowledge generation at the world science frontier, which reflects the nature of science systems operating with high inertia and path dependency in areas of their historically inherited advantages and disadvantages. In view of their common historical legacy in science we are particularly interested in the process of convergence/divergence of the catching-up/transition regions with the world frontier regions. We implement an interpretative framework to compare regions in terms of their static and dynamic specialization from 1981–1989 to 2001–2011. Again, our analysis shows that while science systems are mostly characterised by strong inertia and historically inherited (dis)advantages, Asia Pacific, Latin America and CEE show strong catching-up characteristics but largely in the absorptive capacity of science.	accidental falls;bibliometrics;convergence (action);dermox;description;european union;extraction;paper;partial template specialization;path dependence;science;social sciences;citation;emotional dependency	Slavo Radosevic;Esin Yoruk	2014		10.1007/s11192-014-1344-1	social science;bibliometrics;computer science;data mining;sociology;operations research;law;economic growth	NLP	-76.31007094301832	-19.826514527865196	72993
ec3dec649a2c09d91a0e3c00e379799b66286fcd	reflecting on the role of it and it research in healthcare: moving healthcare research into practice		Today’s healthcare organizations face challenges of unprecedented complexity, breadth and intensity. Only a fraction of new scientific discoveries enter day-to-day clinical practice. To aid in the implementation of research into practice, healthcare organizations frequently turn to technology. However, even with the aid of technology, research often fails to be fully integrated into patient treatment. Part of the reason is due to the complexity of the healthcare system, which includes patients, providers, management, and local community input, all of which are influenced by the current political and economic environment. In addition, some authors have noted that studies have often lacked a rigorous scientific approach that would aid in predicting success in future implementations. Panelists will consider how the foundation theories and research in IT, as well as information technology itself, can be used to inform and facilitate the implementation of healthcare research into practice. Participation from the audience will be encouraged. Panel Objectives This panel seeks to broaden understanding of and spark new ideas on how IT research, its foundational theories and information technology itself can aid in implementing healthcare research into practice. Questions addressed will include: 1) What theories used for IT research can aid practitioners seeking to implement researchbased evidence into practice? And 2) How can information technologies and systems themselves be used to bring research into healthcare settings? Panel Layout The panel would consist of the moderator and 3 discussants. The moderator will begin with a brief introduction to the subject and discussants and the posing of question 1 above (5 minutes). The discussants and moderator will highlight the theoretical perspectives they have used in past research or areas where their thoughts are evolving. This will take 5-7 minutes each for a total of 20-28 minutes. Discussants and the moderator will then address question 2 above for 16-20 minutes. The remainder of the time will be spent asking audience members for their perspectives on the questions posed and fielding questions for the discussants from the audience. Proposed Panelists Moderator – Priscilla A. Arling, College of Business, Butler University. Priscilla Arling studies the intersection of IT, social networks and knowledge management in the healthcare field. She has published in the International Journal of Reliable and Quality e-Healthcare, the International Journal of Healthcare Information Systems and Informatics, and the Handbook of Healthcare Delivery Systems. Her work in the area has also been presented at the Gerontological Society’s annual meeting, the Workshop on Health IT and Economics, and HICSS. Panelists who have agreed to participate: Gordon Gao – R.H. Smith School, University of Maryland Guodong (Gordon) research interests include health IT and quality transparency. Dr. Gao has been conducting pioneering work on the digitized information in transforming healthcare, including physician usage of new technology, and role of empowered patients such as online doctor ratings by patients. His research has been published in top-tier journals like Management Science, Information Systems Research, Manufacturing and Service Operations Management, and Journal of Management Information Systems. His work is also presented at the International Conference on Information Systems, the Workshop on Information Systems and Economics, the Hawaii International Conference on Systems Sciences, INFORMS. Dr. Gao initiated and cochaired the annual Workshop on Health IT and Economics (WHITE 2010-2012), held in Washington DC. His work has been funded by AHRQ. Richard Klein – College of Business and Behavioral Science, Clemson University Rich researches electronic business initiatives within the healthcare industry focusing on office-based practices use Internet-based purchasing of medical supplies as well as electronic medical records (EMR) implementations and integration with other providers’ systems. His research has been published in Decision Sciences, the European Journal of Information Systems, the Journal of Management Information Systems, MIS Quarterly, and the Journal of Operations Management. Further, Rich has presented his work at national and international conferences, including the Annual Meeting of the Academy of Management, the Americas Conference on Information Systems, the European Conference on Information Systems, and the Institute for Operations Research and the Management Sciences Annual Meeting. E. Vance Wilson – School of Business, Worcester Polytechnic Institute Vance Wilson currently chairs the Special Interest Group on Information Technology in Healthcare (SIG-Health) of the Association for Information Systems (AIS). He has served as supervising editor of the Information Systems and Healthcare Department of Communications of the AIS since 2004, and he has guest-edited special issues on e-health and health information systems in European Journal of Information Systems, e Service Journal, Information Systems Management, and the International Journal of Healthcare Technology Management. In 2009 he produced the edited book, Patient-Centered E-Health. Equipment Needs: A projector and cord to connect to a laptop to display any material needed. Panelists will provide laptops if they need them. This application is supported by the AIS Special Interest Group on IT in Healthcare (SIG-Health)	academy;americas conference on information systems;association for information systems;complexity;electronic business;european conference on information systems;european journal of information systems;excalibur: morgana's revenge;google moderator;hicss;handbook;icis;informatics;information systems journal;information systems research;institute for operations research and the management sciences;internet;knowledge management;laptop;management information systems quarterly;management information system;management science;multitier architecture;purchasing;social network;systems management;systems science;theory;video projector	Priscilla Arling;Gordon Gao;Richard Klein;E. Vance Wilson	2012			family medicine;medicine;knowledge management;nursing	DB	-63.570315847972296	-15.253040858497847	73231
55fd3f5971d907014f22a5743c2301ca907dfe97	going critical: perspective and proportion in the epistemology of rob kling	informatica;social informatics;informatique sociale;critical perspective;aspecto social;social aspect;rob kling;theoretical analysis;informatique;computer science;aspect social	One important aspect of Rob Kling's concept of computerization movements was the assumption that a commentator on such movements must adopt a critical perspective, entailing a strong inclination to view as dubious statements that are ungrounded by fact or theoretical analysis, particularly when the implications appear to benefit those making the statements. Kling's work was replete with successful instances of critical refutation, in which he challenged assumptions or statements about the nature or role of computerization and provided convincing alternative interpretations of issues at hand. Much of Rob's work delivers a powerful indictment against sloppy conjecture and hyperbolic claims regarding the glories of computerization. At the same time, some of his own assessments of implications of emerging technologies tended toward the dismissive and marginalizing, bearing weaknesses of positions he challenged in his own work. This paper identifies intellectual traps inherent in critical perspectives that can catch even acute practitioners. The objective is to help elucidate and stabilize the epistemological foundations for Rob’s critical perspective in computerization movements. 1 In deference to our close associations with Rob Kling over the years, we refer to him simply as Rob throughout this paper. We do not extend this familiarity to others. Authorship order is inversely proportional to years with Rob. 2	the globe and mail	John Leslie King;Suzanne Iacono;Jonathan Grudin	2007	Inf. Soc.	10.1080/01972240701444170	social science;computer science;sociology;management;law	Vision	-74.74802933277665	-13.927786834483584	73318
9def94f41c5e96dc017d18bd748d15c13477ece6	open data, grey data, and stewardship: universities at the privacy frontier		As universities recognize the inherent value in the data they collect and hold, they encounter unforeseen challenges in stewarding those data in ways that balance accountability, transparency, and protection of privacy, academic freedom, and intellectual property. Two parallel developments in academic data collection are converging: (1) open access requirements, whereby researchers must provide access to their data as a condition of DOI: https://doi.org/10.15779/Z38B56D489 © 2018 Christine L. Borgman. † Distinguished Professor and Presidential Chair in Information Studies, University of California, Los Angeles. This Article is based on the Tenth Annual Berkeley Law Privacy Lecture, hosted by the Berkeley Center for Law and Technology on November 16, 2017. http://christineborgman.info Full disclosure: The author is actively engaged in the University of California activities mentioned herein. She was a founding member of the UCLA Privacy and Data Protection Board, a member of the PISI Steering Committee, Co-Chair of the UCLA Data Governance Task Force, and currently is Chair of the University of California Academic Computing and Communications Committee (UCACC) (2017–2018 academic year; Vice Chair 2015–2017). In her role as a UCACC officer, she is a member of the UC Office of the President Cyber Risk Governance Committee (2015–2018). She has been a member of the Advisory Board to the Electronic Privacy Information Center (EPIC) since its founding in 1994 and served on the EPIC Board of Directors from 2010 to 2017. The opinions in this Article are her own. Acknowledgements are due to the many colleagues in the University of California who have aided, abetted, and supported these privacy initiatives: Amy Blum, Jim Chalfant, Dana Cuff, Jim Davis, Jerry Kang, David Kay, Leah Lievrouw, Gene Lucas, Maryann Martone, Joanne Miller, Jan Reiff, Sheryl Vacca, Kent Wada, Scott Waugh, Shane White, and other members of the PISI and DGTF committees. My research group at the UCLA Center for Knowledge Infrastructures provided essential critique and commentary on the Article and talk: Bernadette Boscoe, Peter Darch, Milena Golshan, Irene Pasquetto, and Michael Scroggins. Morgan Wofford provided extensive bibliographic research. James Dempsey of the Berkeley Center for Law and Technology provided detailed comments on the draft paper. Outside UC, credit is due to Marc Rotenberg and the staff at the Electronic Privacy Information Center as well as Anne Washington of George Mason University. Special thanks are due to Chris Jay Hoofnagle, Paul Schwarz, and others at the Berkeley Center for Law and Technology, whose invitation to give the Tenth Annual BCLT Privacy Lecture provided the incentive to write this Article, and to Erwin Chemerinsky (Berkeley) and Katie Shilton (University of Maryland) who provided extensive and insightful commentary as respondents to the public lecture on November 16, 2017. 366 BERKELEY TECHNOLOGY LAW JOURNAL [Vol. 33:365 obtaining grant funding or publishing results in journals; and (2) the vast accumulation of “grey data” about individuals in their daily activities of research, teaching, learning, services, and administration. The boundaries between research and grey data are blurring, making it more difficult to assess the risks and responsibilities associated with any data collection. Many sets of data, both research and grey, fall outside privacy regulations such as HIPAA, FERPA, and PII. Universities are exploiting these data for research, learning analytics, faculty evaluation, strategic decisions, and other sensitive matters. Commercial entities are besieging universities with requests for access to data or for partnerships to mine them. The privacy frontier facing research universities spans open access practices, uses and misuses of data, public records requests, cyber risk, and curating data for privacy protection. This Article explores the competing values inherent in data stewardship and makes recommendations for practice by drawing on the pioneering work of the University of California in privacy and information security, data governance, and cyber risk. 2018] OPEN DATA, GREY DATA, AND STEWARDSHIP 367	best practice;big data;blum axioms;computation;computational thinking;computer data storage;confidentiality;content format;data element;data governance;data quality;data science;data steward;digital curation;digital data;documentation;entity;experience;ftc fair information practice;gaussian blur;health insurance portability and accountability act;information privacy;information science;information security;intellectual freedom;internet of things;interoperability;irene stegun;jeremie miller;lakes of wada;langrisser schwarz;marc (archive);mason;mined;morgan;pardus;personally identifiable information;privacy by design;privileged access;requirement;samsung galaxy note 7;section 508 amendment to the rehabilitation act of 1973;social media;supra, inc.;transparency (graphic);tree accumulation;uc browser	Christine L. Borgman	2018	CoRR	10.15779/Z38B56D489	data collection;public relations;open data;accountability;privacy law;economics;information security;learning analytics;data access;data governance	DB	-65.18956352305513	-17.435488850519224	73513
2f0692ba1c7aef3065c5eee3bdd74435293ea558	artificial life: discipline or method? report on a debate held at ecal '99	computational method;simulation model;artificial life	eprints@whiterose.ac.uk https://eprints.whiterose.ac.uk/ Reuse Unless indicated otherwise, fulltext items are protected by copyright with all rights reserved. The copyright exception in section 29 of the Copyright, Designs and Patents Act 1988 allows the making of a single copy solely for the purpose of non-commercial research or private study within the limits of fair dealing. The publisher or other rights-holder may allow further reproduction and re-use of this version refer to the White Rose Research Online record for this item. Where records identify the publisher as the copyright holder, users can verify any specific terms of use on the publisher’s website.	artificial life;holder device component;html link type - copyright;legal patent;ninety nine;reuse (action);terms of service;web site	Jason Noble;Seth Bullock;Ezequiel A. Di Paolo	2000	Artificial Life	10.1162/106454600568375	simulation;computer science;artificial intelligence;simulation modeling;operations research;artificial life	AI	-66.54335095384555	-17.289639325281012	73567
96ee3e5aaf535370a39c16fcf38af95907d5ab8f	losing my revolution: how many resources shared on social media have been lost?	information technology;web archiving;digital preservation;social media;grey literature	Social media content has grown exponentially in the recent years and the role of social media has evolved from just narrating life events to actually shaping them. In this paper we explore how many resources shared in social media are still available on the live web or in public web archives. By analyzing six different event-centric datasets of resources shared in social media in the period from June 2009 to March 2012, we found about 11% lost and 20% archived after just a year and an average of 27% lost and 41% archived after two and a half years. Furthermore, we found a nearly linear relationship between time of sharing of the resource and the percentage lost, with a slightly less linear relationship between time of sharing and archiving coverage of the resource. From this model we conclude that after the first year of publishing, nearly 11% of shared resources will be lost and after that we will continue to lose 0.02% per day.	archive;embedded system;extended validation certificate;linear model;noise shaping;persistence (computer science);social media;venue (sound system)	Hany SalahEldeen;Michael L. Nelson	2012		10.1007/978-3-642-33290-6_14	social media;computer science;multimedia;grey literature;information technology;world wide web	HCI	-67.75673814550842	-21.235594653243826	73753
5969e43bc6a452b79e166b233708946d8a06d82d	cpoe and the facilitation of medication errors	medical error	Editorial 3 CPOE and the facilitation of medication errors 4 5 In March 2005, Professor Ross Koppel and col-6 leagues from the University of Pennsylvania published 7 a paper on their assessment of a commercial comput-8 er-based provider order-entry (CPOE) system that had 9 been implemented at their university hospital between 10 1997 and 2004 [1]. Their study showed that ''a leading 11 CPOE system often facilitated medication error risks, 12 with many reported to occur frequently.'' They conclud-13 ed that ''as CPOE systems are implemented, clinicians 14 and hospital must attend to errors that these systems 15 cause in addition to errors that they prevent.'' 16 The article appeared in a major clinical journal (the 17 Journal of the American Medical Association), and its con-18 clusions immediately attracted a great deal of attention, 19 both in the lay press and in academic medical circles 20 (especially in clinical venues and among biomedical infor-21 maticians). Although the JAMA article was in no way an 22 indictment of CPOE systems and was, rather, a warning 23 about some potentially unforeseen problems and a call 24 for greater care in system design and implementation, 25 many observers chose to interpret the article in a negative 26 light [2,3]. Informatics organizations responded with 27 their own analyses and opinions [4,5]. Informatics-related 28 professional discussion groups 1 were consumed with 29 analyses of the article, with thoughtful comments on 30 the study, its potential flaws or limitations, the implica-31 tions for future work, and the potential public relations 32 damage that may inadvertently have occurred due to 33 what was largely viewed as an over-reaction in the media. 34 Although I assumed that the JAMA article would 35 engender a subsequent exchange of letters in that jour-36 nal, I knew that the letter forum is limited in that obser-37 vations must be brief and the authors of the original 38 paper would also have limited space in which to re-39 spond. I accordingly invited three groups of authors, 40 all of whom are well known in the area of patient safety 41 research and its practical applications, to write commen-42 taries in response to the original article [6–8]. These arti-43 cles were then presented to the authors of the JAMA 44 article, who in turn have written a response [9]. 45 What follows, then, is a set of four papers that further 46 assess …	assumed;choose (action);focus group;hospitals, university;informatics (discipline);jama (numerical linear algebra library);paper;scientific publication;systems design;facilitation;observers	Edward H. Shortliffe	2005	Journal of biomedical informatics	10.1016/j.jbi.2005.05.007	ophthalmology;medicine;computer science	HCI	-64.65561187264603	-18.189008882425426	73776
225297432d994970ac1694663dd4f632bd33a05d	a descriptive framework for the field of data mining and knowledge discovery	zhengxin chen peng yi;document clustering;data mining;journal;grounded theory;information science computer science a descriptive framework for the field of data mining and knowledge discovery university of nebraska at omaha yong shi;descriptive framework;knowledge discovery	Despite the rapid development, the field of data mining and knowledge discovery (DMKD) is still vaguely defined and lack of integrated descriptions. This situation causes difficulties in teaching, learning, research, and application. This paper surveys a large collection of DMKD literature to provide a comprehensive picture of current DMKD research and classify these research activities into high-level categories using grounded theory approach; it also evaluates the longitudinal changes of DMKD research activities during the last decade.	data mining and knowledge discovery;high- and low-level	Yi Peng;Gang Kou;Yong Shi;Zhengxin Chen	2007	International Journal of Information Technology and Decision Making	10.1142/S0219622008003204	document clustering;computer science;artificial intelligence;data science;marketing;machine learning;data mining;grounded theory;management;operations research	ML	-75.63510250719457	-17.877386073208495	73791
0ba9502b72c3c75f0d61dc0cbc94646bd22ee39f	the dickens lexicon and its practical use for linguistic research		"""It was not until the beginning of World War II that Dr. Tadao Yamamoto first established a plan for the compilation of the Dickens Lexicon in his mind; the earliest plan of which was suggested in Studies in English Literature (Vol. XIII, No. 3, 1943). As the war situation turned progressively worse, the completion of the Lexicon was left to future efforts. He decided, however, to make an """"Introduction"""" to it in the early spring of 1944, and in the same year presented it as a doctoral thesis to the University of Tokyo under the title of Growth and System of the Language of Dickens: An Introduction to A Dickens Lexicon, for which he obtained the degree of Doctor of Literature from the University in 1946. The dissertation was first published in 1950 by Kansai University Press through the generous efforts of the late Professor Jiichi Hattori at Kansai University, and with financial support from the English Philological Society of Kansai University. In 1953 he was awarded the Japan Academy Prize for this book. The second edition and """"An index to Tadao Yamamoto’s Growth and system of the Language of Dickens: With supplementary notes & corrections"""" were published separately by the same press in 1952. The third revised edition was published by Keisuisha Publishing Company in 2003."""	academy;compiler;lexicon;tadao kasami;xiii	Masahiro Hori;Osamu Imahayashi;Tomoji Tabata;Miyuki Nishio	2010			lexicon;linguistics;computer science	NLP	-63.33267779367155	-19.7910330004593	73928
a630ae05d6646b0252862413fc5842f3fdffee64	leveraging multimedia to advance science by disseminating a greater variety of scholarly contributions in more accessible formats	video media;multimedia instruction;academic publishing;knowledge dissemination;scholarship;communication media;article;research dissemination	For the welfare of the scientific community, we are intentionally rocking the boat with regards to the way we conduct, recognize, and disseminate scholarly contributions. As a scientific community, we are doing ourselves a great disservice by ignoring the insights, artifacts, discoveries, and conversations which naturally occur in the scientific process of advancing knowledge, but which do not fit into the very narrowly defined form of print-style articles. By failing to recognize, reward, and publish the wide variety of scholarly contributions that are not well suited to the print-style article, we hinder scientific progress, devalue important and necessary contributions to science, and demotivate these types of vital contributions. Although the effectiveness of the print medium for conveying scholarly knowledge has been demonstrated by over three centuries of scientific publishing, the print-style article captures only a single form of scholarly contribution in a highly limited media format. Unfortunately, the current tenure and promotion process recognizes only this one form of scientific contribution. As a result, science at large advances inevitably only by this single type of contribution. Given the radical advances in audiovisual technologies, storage and bandwidth capacities, public virtual infrastructure, and global acceptance of user-generated open content, the time is ripe to exploit the possibility of publishing more forms of scholarly contributions in a publicly available multimedia format (e.g., video). In this paper, we provide a practical examination of the feasibility of this proposal, a model to demonstrate the sustainability of this approach, and a discussion of potential limitations.		James Eric Gaskin;Paul Benjamin Lowry;David M. Hull	2016	J. AIS		psychology;public relations;social science;epistemology;computer science;engineering;marketing;multimedia;sociology;management;social psychology;world wide web	Theory	-75.22500877915502	-15.03905557761537	73968
0a770e5de72c84114320195c326ad0a5c8aa0d81	discovering old maps online and transforming them into digital humanities resources			digital humanities;map	Petr Pridal	2014			multimedia;digital humanities;computer science	HCI	-63.23408556705794	-11.682514589827793	73991
f254b4e5015c30cffbd797b50906d2717bc6fb54	critical theory and the legitimation of library and information science			library (computing);library and information science	Gerald Benoît	2007	Inf. Res.		legitimation;social science;knowledge management;critical theory;computer science	Logic	-63.38056379679692	-11.21373266660071	74089
d56d75916e4587b24066d22cdb49673316a6ab5b	management and interaction with multimodal information content	information content	Communication is the core for cultural, scientific, economic and technological evolution of the contemporary society, its progress and innovation. Nowadays, more and more Information and Communication Technologies are emphasizing the central role of all issues connected with communication. The numerous and different ways people are using to communicate with each other, the multiplicity of features to produce and exchange information, and the relevance and pervasiveness of multimodal, mobile devices and phenomena such as Internet, are all elements that enhance the complexity of communication processes and their management. Devices supporting multimodal interaction become more and more widespread. When applied in an appropriate way, multimodal interaction provides users with a flexible, natural and robust interaction approach, allowing them to communicate in a synergistic manner using their five senses along with several communication channels. This also permits the organization to store, index, retrieve and more generally to manage a wide amount of multimodal data and information, thus, enabling people to use a multimodal dialog approach in order to access information and/or services. In this context, we have decided to contribute to the scientific debate concerning these emerging questions defining this special issue. After a very selective peer review, nine papers were selected for publication. They deal with theories and techniques concerning multimodal information retrieval, indexing, query processing and extracting features from multimodal data, multimodal interaction issues, and applications. This special issue is organized as follows. DOI 10.1007/s11042-010-0543-x	database;information retrieval;internet;mobile device;multimodal interaction;relevance;self-information;synergy;theory;dialog	Richard Chbeir;Karin Coninx;Fernando Ferri;Patrizia Grifoni	2010	Multimedia Tools and Applications	10.1007/s11042-010-0543-x	self-information;computer science;statistics	Web+IR	-70.5770750206322	-18.790197689495532	74102
cc72c1a3b262fc5b4d6cc7f93b3e28c2194db590	from engaging liaison librarians to engaging communities	outreach programs;library services;library role;college libraries;models;librarians	Anne R. Kenney is University Librarian at Cornell University; e-mail: ark3@cornell.edu. © 2015 Joan K. Lippincott, Attribution-NonCommercial (http://creativecommons.org/licenses/by-nc/3.0/) CC BY-NC. “It would be interesting to revisit UMN Libraries in three years and see how they are doing,” wrote Kara J. Malenfant in her 2010 article “Leading Change in the System of Scholarly Communication: A Case Study of Engaging Liaison Librarians for Outreach to Faculty.”1 Malenfant had documented a culture shift underway at the University of Minnesota (UMN) Libraries that focused liaison work outward toward campus engagement. In preparing this companion essay, I interviewed University Librarian Wendy Lougee, who affirmed that the forces at work then had ripened and matured at UMN. She noted that the shift described in the article had been underway for some time, so the expansion to scholarly communication was a natural extension of efforts to embrace a full spectrum of services from creation to curation. The library had earlier brought in R2 consulting to streamline workflows associated with the full spectrum of “selection to access” for monographs, moved aggressively to reconceive technical services, shifting greater investment to shelf-ready approval plans, devoted resources to developing a campus repository, and in general had embraced the concept of the diffuse library.2 These process improvements freed up capacity within existing staff to pursue other work. Within this context, the University of Minnesota became an early leader in the liaison movement, and Associate University Librarian for Academic Programs Karen Williams articulated a forceful sea change from a collections-centric to an engagement-centered model for librarianship. In the process, the campus came to view the library as a critical component in the scholarly communications infrastructure. The leadership and change process at UMN provided a strong exemplar for others to follow. Probably its most significant impact has been to influence the adoption of liaison functions at other academic libraries. At both ALA meetings in 2014, for example, approximately fifty coordinators of liaison programs from thirty-five academic research libraries met under the auspices of the Association of Research Libraries (ARL) to discuss ways to improve the liaison model.3 Similar gatherings and presentations on liaison activities have become a normal part of library conferences today. Given the fairly widespread take-up of the liaison model, what are some of the challenges that have arisen since Malenfant’s 2010 article? This essay focuses on six key issues that will affect the model moving forward.	adobe streamline;diffuse reflection;digital curation;email;librarian;library (computing);scholarly communication	Anne R. Kenney	2015	C&RL	10.5860/crl.76.3.386	multimedia;pedagogy	Security	-66.31143500730583	-20.178656733493337	74127
d645e7b8de71a1433cf8cc7efee9c5fd1863621d	network warrior - everything you need to know that wasn't on the ccna exam: covers nexus (2. ed.)			ccna	Gary A. Donahue	2011				Vision	-64.38604435116532	-12.805759837082974	74256
05ec8a30d6661647406f0dad1d6e11ca50a10251	countering bioterrorism: why smart buildings should have a code of ethics	bioterrorism;terrorism biohazards building management systems ethical aspects home automation;crime model biological attacks smart buildings ethics;biological system modeling;smart buildings;ethics;biological attacks;crime model;smart buildings biological system modeling humans contamination bioterrorism;building management systems;biohazards;humans;contamination;ethical aspects;code of ethics smart buildings ethical issues bio protection systems containment strategies group safety biological attacks occupant clinical state bioterrorism counter strategies;terrorism;home automation	This article examines some of the ethical issues that engineers face in developing bio-protection systems for smart buildings. An innovative approach based on four different containment strategies is used to identify these issues. Subsequent analysis shows that, whilst smart buildings have the potential to prioritize the safety of the group over that of individuals, the practical and ethical implementation of such containment strategies would require systems account for the uncertainty over the clinical state of each individual occupant.	british informatics olympiad;smart system;soul;while	Hervé Borrion;Timothy Mitchener-Nissen;Jonathon Taylor;Ka Man Lai	2012	2012 European Intelligence and Security Informatics Conference	10.1109/EISIC.2012.45	building management system;home automation;ethics;building automation;computer science;biological hazard;contamination;terrorism;law;computer security	HCI	-73.32526090420323	-13.20063339583519	74343
d29475f46dad72b2ba9e939caec6dd2d9162255b	interactions between libraries and technology over the past thirty years: an interview with clifford lynch 23.06.2012	information technology;librarianship history;academic libraries	Purpose – The purpose of this paper is to look back on the last 30 years of technology development for libraries. Design/methodology/approach – The paper presents an interview that took place at the American Library Association Annual Meeting in Anaheim, California. Findings – The paper reveals that many of the developments are slow. There are very few really sudden revolutions in social-scale technologies. They do not switch on quickly and cannot be sudden because the installed base is too thin. Originality/value – The paper reveals that there should be some renewed conversation about how libraries can help the public. In the early days of the internet libraries played an enormous uncredited role in teaching the adult population about the internet. There are some opportunities like that now, and one place where we are starting to see signs of it is digital preservation, not as libraries doing it for the cultural record, but helping individuals to do it for their own content.	interaction;internet;library (computing)	Clifford A. Lynch;Elke Greifeneder;Michael Seadle	2012	Library Hi Tech	10.1108/07378831211285059	computer science;sociology;management;law;information technology;world wide web	HCI	-67.74076179311747	-22.420646088461073	74408
e2fe9fa08b1c52141957c7530d16ed83c2bc9f71	open access, open source and e-theses: the development of the edinburgh research archive	these;archivo electronico;europa;description systeme;system description;theoretical framework;edition electronique;project;open archives;proyecto;and forward;biblioteca ensenanza superior;recommandation;theses;tesis;archives ouvertes;informacion documentacion;archivos abiertos;libre acceso;thesis;estudio caso;edicion electronica;bibliotheque enseignement superieur;royaume uni;open access;united kingdom;logiciel libre;reino unido;etude cas;archives management;open system;recomendacion;software libre;recommendation;descripcion sistema;development methodology;electronic publishing;higher education library;europe;projet;libre acces;acces libre;grupo a;open systems;ciencias sociales;article;electronic storage;open source software;archivage electronique;open source;design methodology	<The Theses Alive project, conducted at Edinburgh University Library, aimed to produce an E-Theses repository with a view to providing a solution which may be appropriate for other UK higher education institutions to adopt. This paper examines some of the most interesting and involved areas of that project, including what open access and open source meant for it, and how the Edinburgh Research Archive, an institutional repository of E-Theses and E-Prints, grew out of it>.	archive;open-source software	Richard Jones;Theo Andrew	2005	Program	10.1108/00330330510610555	computer science;electronic publishing;open system;management;world wide web	Web+IR	-72.82555895324556	-22.822888249586445	74448
1f525e572be4bff93e32b3b9573b38a560daeb90	'searching for my lady's bonnet: discovering poetry in the national library of australia's newspapers database'		AustLit is a major Australian cultural heritage database and the most comprehensive record of a nation’s literary history in the world. In this article we will present the successful results of a project addressing the challenge of discovering and recording creative writing published in digitized historical Australian newspapers, provided by the National Library of Australia’s Trove service. As a first step in identifying creative writing, we developed an automated method for identifying articles that are likely to be poems by searching for a number of signals embedded in articles. When this work began, AustLit contained more 10,200 bibliographical records for poems published between 1803 and 1954 (75% prior to 1900) with links to the full text in 115 different newspaper. The aim of the project was to expand this number of bibliographical records in AustLit and provide a foundation for analysing the importance of poetry in newspaper publishing of the period. Taking advantage of Ted Underwood’s (Getting Everything you Want from HathiTrust  , and Open Data ( ): The Stone and the Shell, Underwood blog posts (Both accessed 27 October 2015), 2012) work with seventeenth- and eighteenth-century full text in the HathiTrust collection, we trained a naive Bayesian classifier, modifying code from Daniel Shiffman (Bayesian Filtering.   (accessed 27 October 2015), 2008) and Paul Graham (A Plan for Spam.   (accessed 27 October 2015), 2002) and improving the quality of Optical Character Recognition (OCR) by using the overProof correction algorithm. We have been able to successfully identify large numbers of poems in the newspapers database, greatly expanding AustLit’s coverage of this important literary form. After suitable training of the classifier, we were able to successfully identify 88% of the newspaper articles that a knowledgeable human would classify as ‘poetry’. Our results have encouraged us to consider enhancing and extending the techniques to aid the identification of other forms of literature and criticism.		Kerry Kilner;Kent Fitch	2017	DSH	10.1093/llc/fqw062	library science;engineering;genealogy;world wide web	DB	-64.90225903269807	-21.357243987454368	74531
ecd56d45a0c180b059f69c82edff29f6aae72d43	recruiting content for the institutional repository: the barriers exceed the benefits	institutional repository open access copyright peer review metrics;bepress selected works;copyright;metrics;informacion documentacion;open access;ciencias sociales;institutional repository	Focus groups conducted at Carnegie Mellon reveal that what motivates many faculty to selfarchive on a website or disciplinary repository will not motivate them to deposit their work in the institutional repository. Recruiting a critical mass of content for the institutional repository is contingent on increasing awareness, aligning deposit with existing workflows, and providing value-added services that meet needs not currently being met by other tools. Faculty share concerns about quality and the payoff for time invested in publishing and disseminating their work, but disagree about metrics for assessing quality, the merit of disseminating work prior to peer review, and the importance of complying with publisher policies on open access. Bridging the differences among disciplinary cultures and belief systems presents a significant challenge to marketing the institutional repository and developing coherent guidelines for deposit.	bridging (networking);coherence (physics);contingency (philosophy)	Denise Troll Covey	2011	J. Digit. Inf.		computer science;knowledge management;world wide web;metrics	HCI	-76.86966562541433	-16.32031169914016	74850
17cecd33ca2c672b6010ee3bb4dcd06407fcb2bc	viva delay		The time delay between submission of a thesis and Viva Voce is intolerable for students. This letter tries to draw the readers' attention to the effect of choosing the right examiner, in order to reduce the Viva Voce delay.	broadcast delay;choose (action);ibm viva;polysorbate 80 10 mg/ml ophthalmic solution [viva-drops lubricating eye drops]	Hossein Yahaghi;Shahryar Sorooshian;Javad Yahaghi	2017	Science and engineering ethics	10.1007/s11948-016-9795-9		EDA	-64.09704245989536	-18.178921045269906	74948
8eac2cc660f0bf179c1a2c22a4138cf20af16f05	unicode demystified: a practical programmer's guide to the encoding standard	software internationalization;unicode name;unicode demystified;semiannual international unicode conferences;standard unicode notation;computer software;encoding standard;practical programmer;unicode code point value;unicode standard change;unicode support;unicode transformation format;unicode standard	"""From the Book:As the ecomonies of the world continue to become more connected together, and as the American computer market becomes more and more saturated, computer-related businesses are looking more and more to markets outside the United States to grow their businesses. At the same time, companies in other industries are not only beginning to do the same thing (or, in fact, have been for a long time), but are increasingly turning to computer technology, especially the Internet, to grow their businesses and streamline their operations.The convergence of these two trends means that it's no longer just an English-only market for computer software. More and more, computer software is being used not only by people outside the United States or by people whose first language isn't English, but by people who don't speak English at all. As a result, interest in software internationalization is growing in the software development community.A lot of things are involved in software internationalization: displaying text in the user's native language (and in different languages depending on the user), accepting input in the user's native language, altering window layouts to accommodate expansion or contraction of text or differences in writing direction, displaying numeric values acording to local customs, indicating events in time according to the local calendar systems, and so on.This book isn't about any of these things. It's about something more basic, and which underlies most of the issues listed above: representing written language in a computer. There are many different ways to do this; in fact, there are several for just about every language that's been represented incomputers. In fact, that's the whole problem. Designing software that's flexible enough to handle data in multiple languages (at least multiple languages that use different writing systems) has traditionally meant not just keeping track of the text, but also keeping track of which encoding scheme is being used to represent it. And if you want to mix text in multiple writing systems, this bookkeeping becomes more and more cumbersome.The Unicode standard was designed specifically to solve this problem. It aims to be the universal character encoding standard, providing unique, unambiguous representations for every character in virtually every writing system and language in the world. The most recent version of Unicode provides representations for over 90,000 characters.Unicode has been around for twelve years now and is in its third major revision, adding support for more languages with each revision. It has gained widespread support in the software community and is now supported in a wide variety of operating systems, programming languages, and application programs. Each of the semiannual International Unicode Conferences is better attended than the previous one, and the number of presenters and sessions at the Conferences grows correspondingly.Representing text isn't as straightforward as it appears at first glance: It's not merely as simple as picking out a bunch of characters and assigning numbers to them. First you have to decide what a """"character"""" is, which isn't as obvious in many writing systems as it is in English. You have to contend with things such as how to represent characters with diacrtical marks applied to them, how to represent clusters of marks that represent syllables, when differently shaped marks on the page are different """"characters"""" and when they're just different ways of writing the same """"character,"""" what order to store the characters in when they don't proceed in a straightforward manner from one side of the page to the other (for example, some characters stack on top of each other, or you have two parallel lines of characters, or the reading order of the text on the page zigzags around the line because of differences in natural reading direction), and many similar issues.The decisions you make on each of these issues for every character affect how various processes, such as comparing strings or analyzing a string for word boundaries, are performed, making them more complicated. In addition, the sheer number of different characters representable using the Unicode standard make many processes on text more complicated.For all of these reasons, the Unicode standard is a large, complicated affair. Unicode 3.0, the last version published as a book, is 1,040 pages long. Even at this length, many of the explanations are fairly concise and assume the reader already has some degree of familiarity with the problems to be solved. It can be kind of intimidating.The aim of this book is to provide an easier entree into the world of Unicode. It arranges things in a more pedagogical manner, takes more time to explain the various issues and how they're solved, fills in various pieces of background information, and adds implementation information and information on what Unicode support is already out there. It is this author's hope that this book will be a worthy companion to the standard itself, and will provide the average programmer and the internationalization specialist alike with all the information they need to effectively handle Unicode in their software.About This BookThere are a few things you should keep in mind as you go through this book: This book assumes the reader either is a professional computer programmer or is familiar with most computer-programming concepts and terms. Most general computer-science jargon isn't defined or explained here. It's helpful, but not essential, if the reader has some basic understanding of the basic concepts of software internationalization. Many of those concepts are explained here, but if they're not central to one of the book's topics, they're not given a lot of time. This book covers a lot of ground, and it isn't intended as a comprehensive and definitive reference for every single topic it discusses. In particular, I'm not repeating the entire text of the Unicode standard here; the idea is to complement the standard, not replace it. In many cases, this book will summarize a topic or attempt to explain it at a high level, leaving it to other documents (typically the Unicode standard or one of its technical reports) to fill in all the details.The Unicode standard changes rapidly. New versions come out yearly, and small changes, new technical reports, and other things happen more quickly. In Unicode's history, terminology has changed, and this will probably continue to happen from time to time. In addition, there are a lot of other technologies that use or depend on Unicode, and they are also constantly changing, and I'm certainly not an expert on every single topic I discuss here. (In my darker mo sure I'm an expert on any of them!) I have made every effort I could to see to it that this book is complete, accurate, and up to date, but I can't guarantee I've succeeded in every detail. In fact, I can almost guarantee you that there is information in here that is either outdated or just plain wrong. But I have made every effort to make the proportion of such information in this book as small as possible, and I pledge to continue, with each future version, to try to bring it closer to being fully accurate.At the time of this writing (January 2002), the newest version of Unicode, Unicode 3.2, was in beta, and thus still in flux. The Unicode 3.2 spec is schedule to be finalized in March 2002, well before this book actually hits the streets. With a few exceptions, I don't expect major changes between now and March, but they're always possible, and therefore, the Unicode 3.2 information in this book may wind up wrong in some details. I've tried to flag all the Unicode 3.2-specific information here as being from Unicode 3.2, and I've tried to indicate the areas that I think are still in the greatest amount of flux. Sample code in this book is almost always in Java. This is partially because Java is the language I personally use in my regular job, and thus the programming language I think in these days. But I also chose Java because of its increasing importance and popularity in the programming world in general and because Java code tends to be somewhat easier to understand than, say, C (or at least no more difficult). Because of Java's syntactic similarity to C and C++, I also hope the examples will be reasonable accessible to C and C++ programmers who don't also program in Java. The sample code is provided for illustrative purposes only. I've gone to the trouble, at least with the examples that can stand alone, to make sure the examples all compile, and I've tested them to make sure I didn't make any obvious stupid mistakes, but they haven't been tested comprehensively. They were also written with far more of an eye toward explaining a concept than being directly usable in any particular context. Incorporate them into your code at your own risk! I've tried to define all the jargon the first time I use it or to indicate a full explanation is coming later, but there's also a glossary at the back you can refer to if you come across an unfamiliar term that isn't defined. Numeric constants, especially numbers representing characters, are pretty much always shown in hexadecimal notation. Hexadecimal numbers in the text are always written using the 0x notation familiar to C and Java programmers. Unicode code point values are shown using the standard Unicode notation, U+1234, where """"1234"""" is a hexadecimal number of from four to six digits. In many cases, a character is referred to by both its Unicode code point value and its Unicode name: for example, """"U+0041 LATIN CAPITAL LETTER A."""" Code unit values in one of the Unicode transformation formats are shown using the 0x notation.How This Book Was ProducedAll of the examples of text in non-Latin writing systems posed quite a challenge for the production process. The bulk of this manuscript was written on a Power Macintosh G4/450 using Adobe FrameMaker 6 running on M"""	programmer;unicode	Richard T. Gillam	2002			unicode;computer science;theoretical computer science;computer graphics (images)	HCI	-63.03409228778829	-23.372315372425845	75075
266406a53d0e6832417f2e5d7f374e539a6b93a5	two problems posed by egghe	bibliometrie;anaqueleria;problema mal planteado;critical study;periodical;rangement;probleme mal pose;bibliometria;etude critique;estudio critico;modelo;periodique;periodico;shelf;ranking;ill posed problem;egghe l;bibliometrics;modele;rayonnage;ordenamiento;models	In a paper presented at the Seventh International Conference of the International Society for Scientometrics and Informetrics, Egghe (1999) proposed a simple model for the year-by-year growth of the shelf space required for a given collection of journals. The focus is on the time it takes for one or more journals to take up the predetermined shelf-space available. The main part of the paper ends with the authors proposal of two unsolved problems. Closer inspection suggests that Egghes formulation of these problems is incorrect, caused in part by invalid assumptions of independence. The correct formulation shows that the model is by no means new and that the problems are not necessarily straightforward.	computer simulation;informetrics;regular expression;scientometrics	Quentin L. Burrell	2001	Scientometrics	10.1023/A:1010571017605	ranking;bibliometrics;computer science;world wide web;statistics	Robotics	-76.44160127358103	-23.58247754749361	75076
12c8c0fad78d7ca71aeb7221b83c4dff1f34e0f4	the singapore vision: an information-based economy	building block;informal communication	The major report recently issued by the Institute of En gineers, Singapore (IES) is highlighted as a key document in the strategy to revolutionize the Singapore economy by exploit ing IT to the full within a carefully delineated local context.The National IT plan proposes seven main building blocks each with a strategic thrust which will serve as the overall impetus for the national IT movement. These are:(1) IT manpower.(2) IT culture,(3) Information communication infrastructure,(4) IT applications.(5) IT industry.(6) Climate for creativity and entrepreneurship.(7) Coordination and collaboration.Each block is examined in turn and detailed recommendations are set out.		Jim Davies	1988	J. Information Science	10.1177/016555158801400406	simulation;computer science;economic growth	AI	-66.65860124843688	-12.518343317947211	75369
cd58b7c983b477949f4ec41938e7870b47fbfa34	book review: radio in the global age				Kate Lacey	2001	New Media & Society	10.1177/14614440122226146	social science;sociology	NLP	-64.0935120647434	-10.970924518822466	75556
ca388060120f72d3fe3e12f36d5d5e27d89506fb	how computer science risks to lose its innocence, and should attempt to take responsibility		Computer science is playing a driving role in transforming today's society through information technology. In this transformation we observe power shifts increasingly strengthening centralised organisations, which are negatively perceived by many people. We outline technical questions that computer science should pay attention to in order to enable individuals in preserving their interest and to take meaningful decisions based on reliable information.	centralisation;computer science;digital revolution	Karl Aberer	2017	2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2017.319	computer science;management science;the internet;credibility;innocence;big data;information technology	DB	-74.54799854654777	-10.177407971370402	75584
f54c4d26f7398a749e78d6e50082228be8c369f7	book review		"""The primary focus of research in artificial intelligence (AI) and law has been the development of computational models of legal problem solving. Underlying this focus is the assumption that developing such models will lead both to a better understanding of the cognitive and logical basis of legal reasoning and to the construction of intelligent legal information systems (ILISs) of practical utility [McCarty 1990]. Relatively little emphasis, by contrast, has been directed to assessing the ultimate impact that emerging intelligent legal information systems technology will have on the practice of law or on society in general. Much of the reason for this neglect is that the immaturity of the field makes it difficult to anticipate precisely what successful ILISs will be like. However, analysis of the potential benefits and pitfalls of the widespread use of this technology is important, if for no other reason than to focus research in directions most likely to lead to socially beneficial and professionally acceptable applications. Computers, Artificial Intelligence and the Law, edited by Mervyn Bennun, Faculty of Law at Exeter University, is a collection of six papers that explore the interplay between computational models of legal reasoning and the institutions that such models are most likely to affect. A cautionary tone is set by the volume's introduction, which stresses that """"uncritical use of technology does not solve human problems and create a better life."""" The first chapter, AI and the Law: Proceed with Caution, by Blay Whitby, elaborates upon this theme, arguing that successful ILISs may have significant, unexpected social effects. In common with other forms of automation, ILISs may lead to 'deskilling', the replacement of skilled workers by automated systems. A second and more subtle effect is a possible shift in power from the judiciary to the legislature. While ILISs may lead to greater consistency, and therefore greater predictability in interpretation of the law, the cost of this increased consistency is a diminished role for members of the judiciary empowered to interpret the law. Thus, there is a danger that designers of ILISs may become unelected participants in the process of social and political negotiation between the legislature and the judiciary. The practical issues that arise in fielding a large-scale ILIS are the subject of a case-study by Julie Browne and Andrew Taylor of a decision support system developed for the British Department of Health and Social Security to assist adjudication officers in determining entitlement to social security benefits. J Browne and Taylor encountered a number of difficult"""	artificial intelligence;blay whitby;computation;computational model;decision support system;information system;problem solving;social security	Karl Branting	1993	Artificial Intelligence and Law	10.1007/BF00871891		AI	-70.78937515187022	-15.303196901894218	75724
c4273095956bb5fb52d0a4caa63eb65cd32495cb	a community's perspective on the status and future of peer review in software engineering		Abstract Context: Pre-publication peer review of scientific articles is considered a key element of the research process in software engineering, yet it is often perceived as not to work fully well. Objective: We aim at understanding the perceptions of and attitudes towards peer review of authors and reviewers at one of software engineering’s most prestigious venues, the International Conference on Software Engineering (ICSE). Method: We invited 932 ICSE 2014/15/16 authors and reviewers to participate in a survey with 10 closed and 9 open questions. Results: We present a multitude of results, such as: Respondents perceive only one third of all reviews to be good, yet one third as useless or misleading; they propose double-blind or zero-blind reviewing regimes for improvement; they would like to see showable proofs of (good) reviewing work be introduced; attitude change trends are weak. Conclusion: The perception of the current state of software engineering peer review is fairly negative. Also, we found hardly any trend that suggests reviewing will improve by itself over time; the community will have to make explicit efforts. Fortunately, our (mostly senior) respondents appear more open for trying different peer reviewing regimes than we had expected.	blinding (cryptography);coefficient;emoticon;experiment;icse;peer-to-peer;public key certificate;scientific literature;social capital;software engineering;surround sound	Lutz Prechelt;Daniel Graziotin;Daniel Méndez Fernández	2018	Information & Software Technology	10.1016/j.infsof.2017.10.019	peer review;software engineering;computer science;technical peer review;management science;attitude change;multitude;software technical review;knowledge management;software walkthrough	SE	-74.3925098765485	-15.685335934828117	75797
312b3f8046d55ee39c503c994e73bbc0e50192dd	freedom and information highways or how to ensure electronic democracy	information highway;electronic democracy	The information highways can be de®ned as new media, in the sense of communication infrastructures; these are networks of every kind (cables, optical ®bres, satellites, electromagnetic waves) which, due to their considerable transport capacity further reinforced by techniques known as compression, allow the almost unlimited transmission of data, voices and images in digital form. These highways appear as a vector of democracy so much so that their development leads us to foresee a great increase in the free expression of each person and a search, via multiple networks, for consensus. In a recent article, Berleur (1995) de®ned democracy as: ``the creation, the institution of political liberty insofar as it is conceived as the link between individual freedom and the will to live together, in a universalizing horizon allowing everybody access to it''. Following Habermas, the author insists on the need to recognize public spaces where the freedom of each person must be upheld in open and transparent debate. In the light of such conditions, the highways of the kind that Internet Telematics and Informatics 15 (1998) 163±180	access control;access network;call to action (marketing);columbia (supercomputer);federated identity;informatics;linear algebra;new media;open road tolling;openness;procurement;telematics	Yves Poullet	1998	Telematics and Informatics	10.1016/S0736-5853(98)00011-2	public administration;law	ML	-71.45379926528406	-12.854915598102442	75915
881c5a142104aed625086ddd3c0c530bda4f3355	rochester institute of technology bachelor of science in software engineering csee&t hall of fame nomination		In the fall of 1996, the Rochester Institute of Technology launched the first undergraduate software engineering program in the United States. The culmination of five years of planning, development, and review, the program was designed from the outset to prepare graduates for professional positions in commercial and industrial software development. From an initial class of 15, the ABET-accredited program has grown steadily over the intervening years until today the student body numbers over 580 undergraduates.	software development;software engineering	James R. Vallino	2017	2017 IEEE 30th Conference on Software Engineering Education and Training (CSEE&T)	10.1109/CSEET.2017.11	computer science;software development;nomination;software engineering;bachelor	SE	-63.75381615974365	-18.163923936568406	76086
acf8ca11f15126ca051e1318654f008d43a21ef4	software pirating and management's quagmire	software pirating;special feature	Mainframe-based data centre had very few problems with software license compliance. With the systems centralized at corporate headquarters or in large departments, under the watchful eye of its professionals, it was easy to ensure compliance and identify any infractions of the licensing agreement. There was, also, little or no need to make illegal copies of software, in an environment devoid of PCs. While a black market for software existed, the majority of organizations were in compliance with their licensing obligations.	centralized computing;data center;mainframe computer;personal computer;software license;virtual community	August Bequai	1998	Computers & Security	10.1016/S0167-4048(97)80245-3		Security	-69.13228926308274	-14.137748093919427	76287
be899b33ab4f290caed14f345b721d385b8f1d70	candidates announced for board of governors election [society news]		Herein are the position statements and biographies of the slate of candidates to lead the IEEE Communications Society. Your vote is very important to the individual candidates and to ComSoc as a whole. Ballots will be e-mailed or mailed to all ComSoc members on 30 May 2014. We encourage your careful consideration as you cast your vote for the future success of the Society. The election ends 25 July 2014. In addition to the President-Elect slate, each ballot will contain three slates for our Members-at-Large position: a) one composed of 6 candidates from NA/LA (the Americas), b) one composed of 3 candidates from EMEA, and c) one composed of 3 candidates from AP regions. All voting members may select up to 2 from the NA/LA slate, up to 1 from the EMEA slate, and up to 1 from the AP slate. The top 2 vote-getters from the NA/LA slate, the top vote-getter from the EMEA slate, and the top vote-getter from the AP slate will serve for a three-year term on the Board of Governors starting 1 January 2015.		Vijay Bhargava	2015	IEEE Communications Magazine	10.1109/MCOM.2015.7105633	telecommunications	Vision	-63.21439115543902	-18.11813199276562	76546
de0c0e168f0d2d79cc2085049edf3f715d38534a	‚mirroring' the ethics of biobanking: what analysis of consent documents can tell us?	biobanking;consent documents;ethics;europe	Biobanks have been recognized as a key research infrastructure and how to approach ethical questions has been a topic of discussion for at least a decade by now. This article explores the characteristics of donors' participation in European biobanks as reflected in the consent documents of a selection of different biobanks from various European countries. The primary aim of this study is to understand how donors are informed about their participation in biobanking. Also the paper discusses what the most important thematic issues of information are to be given to the biobank participants and how this information should be presented in the consent documents. For these purposes, we analyse consent documents from 14 biobanks in 11 countries for six ethically relevant issues: (1) model of consent, (2) scope of future research, (3) access to medical data, (4) feedback to the participants, (5) consent withdrawal, and (6) role of research ethics committee. In order to compare different trends of informing donors of human biological material and medical data, we interpret the six analysed issues in the context of respect to donor's autonomy paradigm. Although the results of the paper reflect the heterogeneity of biobank consent document policies applied in different European countries, we uncovered some trends and suggested several examples of good practices to balance the interests of the donors with those of the researchers and future patients.		Jurate Serepkaite;Zivile Valuckiene;Eugenijus Gefenas	2014	Science and engineering ethics	10.1007/s11948-013-9481-0	public relations;engineering ethics;ethics;sociology;biobank;law	HCI	-73.62555975049459	-13.432860468425584	76568
35396207586b3ffd14214f3a8eae45348ac6fbc8	how to get web presents! designing a collaborative k-12 web project	collaborative k;web project	"""I first launched the collaborative ecology project, """" A World Community of Old Trees, """" on the Web two years ago, I have received hundreds of contributions from children and adults from all over the world. Each time I opened an electronic file, I felt like I was opening a very special present! What wonderful old tree would be inside? Using """" A World Community of Old Trees """" as an example, this paper presents methods for K-12 teachers and students to design, maintain, and evaluate their own collaborative project for the WWW. For me, having a global Web project has been like hosting a party and inviting the world to join in! The purpose of this presentation is to share the excitement of the definite potential of the Web medium for global collaborative learning. """" A World Community of Old Trees """" was specifically designed to provide an open digital space for the global community to identify, write about, and document with visual images, the most extraordinary trees in their environment. The project contains three major components: the Tree Gallery, with both scanned art and Web-specific imagery and accompanying descriptive text, the Tree Museum, where references to extraordinary trees are listed in the continually growing Print Sources and Web Sources sections, and Tree Talk, which contains tree ecology facts, personal narratives, photos, participants' responses , and a built-in Comment and Survey Form about the project. For me the most wonderful section of the Tree Gallery is the Student Projects section. It showcases the wonderful art work, poetry, and stories from children, all lovingly documenting the most extraordinary trees in their worlds. It was especially exciting when these files came into my email account! When I opened them, I was greeted with beautiful tree art works, stories, and photos of children proudly standing next to their trees. Children from many parts of the world, including the United States, Canada, Lithuania, Australia, and Japan, have sent in their tree gifts for the world to share. When visitors responded to a particular student's contribution, I pasted that email directly on the bottom of their page. For example, Rosemary, an eighth grader in Australia, did research on the oldest species of tree in the world, the Wollemi Pine, and contributed both text and photos to the project. When I received an email comment on Rosemary's work, it was added to her page. Another …"""	canonical account;computer file;cut, copy, and paste;ecology;email;pine;software documentation;www;web project;world wide web	June Julian	1998		10.1145/280953.280967	web application security;web development;web modeling;data web;web analytics;web design;web standards;web navigation;social semantic web;web intelligence;project management 2.0;web 2.0	Web+IR	-64.8519812097744	-16.381102212353515	76690
4ee6252967e87ab41ca67a53a814a46571ed7934	e-prints and journal articles in astronomy: a productive co-existence	media vida;etude utilisateur;analyse bibliometrique;etude utilisation;communication scientifique;document publie;comunicacion cientifica;astronomia;user study;astronomie;estudio utilizacion;estudio usuario;litterature scientifique;literatura cientifica;published document;astrophysics data system;scientific communication;bibliometric analysis;demi vie;astronomy;half life;scientific literature;preprint;publication prealable;documento publicado;use study;analisis bibliometrico	Are the e-prints (electronic preprints) from the arXiv repository being used instead of the journal articles? In this paper we show that the e-prints have not undermined the usage of journal papers in the astrophysics community. As soon as the journal article is published, the astronomical community prefers to read the journal article and the use of e-prints through the NASA Astrophysics Data System drops to zero. This suggests that the majority of astronomers have access to institutional subscriptions and that they choose to read the journal article when given the choice. Within the NASA Astrophysics Data System they are given this choice, because the e-print and the journal article are treated equally, since both are just one click away. In other words, the e-prints have not undermined journal use in the astrophysics community and thus currently do not pose a financial threat to the publishers. We present readership data for the arXiv category ”astro-ph” and the 4 core journals in astronomy (Astrophysical Journal, Astronomical Journal, Monthly Notices of the Royal Astronomical Society and Astronomy & Astrophysics). Furthermore, we show that the half-life (the point where the use of an article drops to half the use of a newly published article) for an e-print is shorter than for a journal paper. The ADS is funded by NASA Grant NNG06GG68G. arXiv receives funding from NSF award #0404553.	1-click;astro boy;astrophysics data system;astropy;ibm notes	Edwin A. Henneken;Michael J. Kurtz;Günther Eichhorn;Alberto Accomazzi;Carolyn Stern-Grant;Donna M. Thompson;Elizabeth Bohlen;Stephen S. Murray;Paul Ginsparg;Simeon Warner	2007	Learned Publishing	10.1087/095315107779490661	half-life;preprint	Comp.	-71.19907728907617	-21.49313817316599	76756
f8e39f8d716b71fd90fad7e553dc8f93b7e0d585	message from the general chairs		To provide a forum for high quality interdisciplinary discussions on the various aspects of the convergence between communications and computer technologies, To focus on practical problems related to the design, deployment and utilization of information and networking systems; To create a congenial environment for friendships to develop and cooperation to blossom among tenants of many disciplines and from many countries.	display resolution;software deployment	I. Sanz	2005	2017 1st Cyber Security in Networking Conference (CSNet)	10.1109/ISCC.2005.100		Visualization	-62.9608869833798	-16.925122756529706	76789
084193b94925cc9aa52a5af68b414e0c415b09ab	icann and antitrust	profitability	In the late 1990s, the U.S. government ceded de facto technical and policy control over the Internet domain name system (DNS) to a private non-profit company. That company, the Internet Corporation for Assigned Names and Numbers (ICANN), operates under various contracts to the US government, and via additional contracts it has signed with registries and registrars. ICANN acts as the de facto regulator for DNS policy. In addition to technical policy coordination that prevents multiple registries from attempting to deploy colliding top-level-domains (TLDs), ICANN also engages in policies that strongly resemble traditional regulation of market structure. It decides what TLDs will be made available to users, and which registrars will be permitted to offer those TLDs for sale. And it makes those decisions at least in part based on the potential registrars' willingness to offer a package of services that includes mandatory trademark arbitration.	mandatory access control	A. Michael Froomkin;Mark A. Lemley	2001	CoRR		public relations;social science;economics;telecommunications;artificial intelligence;public economics;management;law;computer security;profitability index	Networks	-71.26349540237635	-12.413014391966477	76793
40d274700066f6d1e7126f90967992c3800d9bbc	challenges in forensic computing	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;digital evidence;tecnologias	The ever-changing nature of technology contributes to the problems encountered by experts when collecting and preparing digital evidence for courtroom presentation.		Rebecca T. Mercuri	2005	Commun. ACM	10.1145/1101779.1101796	theoretical computer science;data science;forensic science;computer science;digital evidence	Graphics	-69.58718142584816	-20.89485493018718	76914
7c9e40b40f900232b6039bd3819d43db78d538a2	domain analysis in information science: eleven approaches: traditional as well as innovative	ciencia informacion;specialized information;travailleur connaissance;dominio investigacion;information science;research field;user study;information technology;informing science;information specialisee;bibliothecaire specialise;connaissance domaine;methode;indexing and retrieval;analyse;bibliotecario especializado;artificial intelligent;domain knowledge;knowledge worker;domaine recherche;scientific communication;analysis;language for special purposes;domain analysis;science information;metodo;method;domain specificity;documentation;knowledge workers;analisis;special librarian	What kind of knowledge is needed by information specialists working in a specific subject field like medicine, sociology or music? What approaches have been used in information science to produce kinds of domain-specific knowledge? This article presents 11 approaches to domain analysis. Together these approaches make a unique competence for information specialists. The approaches are: producing literature guides and subject gateways; producing special classifications and thesauri; research on indexing and retrieving specialities; empirical user studies; bibliometrical studies; historical studies; document and genre studies; epistemological and critical studies; terminological studies, LSP (languages for special purposes), discourse studies; studies of structures and institutions in scientific communication; and domain analysis in professional cognition and artificial intelligence. Specific examples and selective reviews of literature are provided, and the strengths and drawbacks of each of these approaches are discussed. Introduction: the role of domain studies in IS Information science developed out of special librarianship and documentation, and special librarianship has an approach that has often lacked understanding from general librarianship (see Williams, 1997). I think it is important to understand this tension. Special librarians are, in my opinion, not `̀ special’’, but represent a valuable and fruitful general approach to library and information science (LIS). It is not the purpose of this article to present or discuss the relation between general librarianship and special librarianship. The core idea of the specialist library approach may be that information resources should be identified, described, organised and communicated to serve specific goals. Obviously, medical librarianship (documentation or information science) should serve people dealing with health problems. The criterion of the success of doctors is the cure of the patients. The criterion of the success of information systems is that they identify and communicate the knowledge needed for the doctors to cure the patients. I think that this view has been an implicit philosophy in documentation and information science. In my opinion even general librarianship has to cope with different domains and may well benefit from considering the domain analytic view. One cannot treat all domains as if they are fundamentally similar, and a theoretical approach to LIS should consider different discourse communities. The current issue and full text archive of this journal is available at http://www.emeraldinsight.com/0022-0418.htm The author thanks Trine Fjord Sùndergaard for drawing Figure 3. Domain analysis in information science 423 The main problem with this philosophy has been how to train professional information specialists and do research without just teaching research subject knowledge per se. An ordinary subject specialist is not a specialist in IS. The domain analytic approach (Hjùrland, 1993; Hjùrland and Albrechtsen, 1995) is an attempt to tackle this problem, and the present paper is a specification of a number of different approaches within the domain analytic view that can be used to obtain this goal. By bringing these approaches together the paper advocates a view which may have been implicit in previous literature but which has not before been set out systematically. The approaches presented here are neither exhaustive nor mutually exclusive, but an attempt is made to present the state of the art. Producing literature guides or subject gateways Literature guides may also be termed `̀ guides to information sources’’, `̀ guides to reference materials’’, `̀ how to find out about . . . ’’, `̀ pathfinders’’, `̀ subject gateways’’, etc. They are publications that list and describe the system of information resources in one or more areas. Bottle (1997, p. 213) writes: `̀ Probably the first distinct information science literature type was the literature guide. An early example was Ostwald’s Die chemische Literatur und die Organisation der Wissenschaft (Leipzig, 1919)’’. A guide is a kind of bibliography of documents in a domain, but it deviates from typical subject bibliographies. First, a guide concentrates on reference literature (bibliographies, dictionaries, encyclopaedias etc.) at the expense of primary literature. Second, a guide is typically selective (more or less so), while, for example, a bibliography of bibliographies tends to be comprehensive. There are of course many variations or sub-types of guides as of any other kind of literature. Guides can include more or less text in addition to the bibliographical entries (which should be annotated). Ideally, a guide guides the user in the management of the literature. It informs him about the strengths and weaknesses of different works, and it should provide the basis for a rational section of works to use and help the user to navigate in the ocean of literature, databases and information. It can be seen as a kind of interface between the user and the literature, and it can be seen as a kind of textbook for courses in literature searching or as a self-help book for library and information use. One could also say that a guide is an explication of what librarians do when they build collections and learn to use them in order to provide reference services. The American Library Association as well as Library Association in London has for many years published Guide to Reference Books (Balay et al., 1996) and Walford’s Guide to Reference Material (Day and Walsh, 2000) respectively. These are very comprehensive guides covering all subject areas and are considered valuable and classic sources in the library community. Examples of guides in the social sciences include Hoselitz (1970), Li (2000), Roberts (1977) and Webb (1986). The last mentioned is ambitious and worth mentioning for several reasons. Being published by American Library Association it	archive;artificial intelligence;baum–welch algorithm;bibliographic index;bibliometrics;book;cognition;coherence (physics);database;dictionary;digital library;document;documentation;domain analysis;domain-specific language;emoticon;expert system;guide (hypertext);guide to information sources;hadamard transform;handbook;information retrieval;information system;institute for operations research and the management sciences;jan dietz;librarian;library and information science;mental model;metabibliography;primary source;scientific communication;thesaurus (information retrieval);trine;unisist model	Birger Hjørland	2002	Journal of Documentation	10.1108/00220410210431136	library science;social science;epistemology;information science;computer science;knowledge management;artificial intelligence;analysis;linguistics;sociology;information technology;world wide web;information retrieval	NLP	-72.83166904425246	-19.702143647819693	76969
6456800668ba4c2a9f005c62478dbdee6ba53f16	programming on the univac 1: a woman's account	informatica;engeneering;mujer;woman;history programming;programmation;history;century 20;data processing;etats unis;estados unidos;ingenierie;femme;siecle 20;history programming eckert mauchly computer corporation workplace conditions female programmers;ingenieria;informatique;usa;programming;humans home computing employment contracts nist mathematics physics computing programming profession computer science production facilities;siglo 20	Although women's role in the computer field has been fairly well documented, their role in the programming arena has not. The author's account of her programming experience on the Universal Automatic Computer (Univac 1), for the Eckert-Mauchly Computer Corporation reveals much about the early workplace conditions - namely, a workplace surprisingly free of restrictions in an era when most married women with children did not work outside of the home.	univac i	Adele Mildred Koss	2003	IEEE Annals of the History of Computing	10.1109/MAHC.2003.1179879	programming;history;data processing;computer science;engineering;electrical engineering;artificial intelligence;management;operations research;law;algorithm	Vision	-70.89135579457663	-21.101311847032907	76973
871147283272cf265ed7661453ad0e34800027db	from russia with crypto: a political history of telegram		This paper offers a political history of Telegram, a platform that combines aspects of social networking with secure messaging, and whose vocal commitment to user privacy and freedom of expression has brought it into open conflict with a number of governments, most recently in Iran and Russia. A detailed project history traces Telegram’s roots to Pavel Durov’s ouster from Vkontakte, the social networking site he had founded, at the behest of the Kremlin. The paper then analyzes Telegram’s ideology and politics by focusing, in turn, on Telegram’s emergence in the context of Vladimir Putin’s crackdown on technologically-enabled civil society; on Pavel Durov’s cyber-libertarianism; and on Telegram’s peculiar business model. The analysis shows that while Telegram’s rhetoric emphasizes user security, privacy, and freedom of expression, the company fails to demonstrate that it actually lives up to these commitments. Rather than earning user trust through transparency and accountability, Telegram’s value proposition hinges on blind trust on Pavel Durov’s good intentions and his team’s stated credentials.	crackdown;credential;cryptography;documentation;emergence;open-source software;privacy;secure messaging;tracing (software)	Nathalie Marechal	2018			internet privacy;computer security;computer science;political history	Security	-73.00392979022807	-10.719678309192574	77024
270ab24659b910a02c0b230b77d07f5734332ca8	an information privacy culture index framework and instrument to measure privacy perceptions across nations: results of an empirical study		This work is based on research supported wholly by the National ResearchrnFoundation of South Africa (Grant Numbers: 105735)	information privacy	Adéle da Veiga	2017			internet privacy;empirical research;information privacy;business	ML	-69.40165902313537	-10.212655505704333	77133
72f03f33dd22062f7ceafb65e34f5ea4045d93a7	pikm 2011: the 4th acm workshop for ph.d. students in information and knowledge management	dissertation proposal;pikm workshop;information retrieval;acm workshop;knowledge management;interdisciplinary work;ph.d. student;global stage;wide range;database systems	The PIKM workshop gives Ph.D. students an opportunity to present their dissertation proposals at a global stage. Similarly to the CIKM, the PIKM workshop covers a wide range of topics in the areas of databases, information retrieval and knowledge management. Interdisciplinary work across these tracks is particularly encouraged.	database;information retrieval;knowledge management	Anisoara Nica;Fabian M. Suchanek	2011		10.1145/2063576.2064049	computer science;knowledge management;data science;data mining;information retrieval	Web+IR	-63.66704266733238	-16.460193230302703	77169
983b5f4aa5a1c869fff3c45a8452afbbd0fc2a07	designing government agents for constitutional compliance	pedagogical agent;state government;autonomous agent;intelligent tutor;agent systems;information design;architecture	Using autonomous agent systems to deliver U.S. federal and state government services threatens citizen civil rights protected by the U.S. Constitution. This paper examines some of these threats, focusing on issues arising from the unique qualities of agents not found in conventional software. The paper offers engineering suggestions and concludes that informed designers can produce agent systems that better protect rather than attack individual rights.	autonomous agent;autonomous robot;http 404;orwell	Carey Heckman;Alex Roetter	1999		10.1145/301136.301214	agent architecture;simulation;computer science;knowledge management;artificial intelligence;autonomous agent;architecture;multimedia;information design;intelligent agent	AI	-71.97920272582493	-10.360971546821236	77195
a0780baf34b9d81b95bcf3f5c63ca866c9ac0820	the process for organization of internet standards working group (poised)		"""This report, originally prepared in January 1993 provides a summary of the POISED WG, starting from the events leading to the formation of the WG to the end of 1992. Necessarily, this synopsis represents my own perception, particularly for the """"prehistory"""" period. Quite a few people hold strong views about both the overall sequence and specific events. My intent here is to convey as neutral a point of view as possible."""		Steve Crocker	1994	RFC	10.17487/RFC1640	engineering;operations management;genealogy;operations research	HCI	-64.57383490333277	-17.74989907825117	77309
928bd68de3fe133e249b94a4eee9a7834f042185	cyberspace - a contemporary utopia?			cyberspace	Diane Rowland	1998	Journal of Information, Law and Technology		ethnology	Crypto	-65.48096454798015	-10.371192031482908	77320
7f7c08eb0618542fc4f71863d23e350488b091ef	making it to the major leagues: career movement between library and archival professions and from small college to large university libraries	professional education;professional training;higher education;professional association;professional associations	ISSUESOF CAREER MOVEMENT AND CHANGE are examined between library and archival fields and from small colleges to large universities. Issues examined include professional education and training, initial career-planning and placement, continuing education, scouting and mentoring, job market conditions, work experience and personal skills, professional involvement, and professional association self-interest. This examination leads to five observations: 1.It is easier, in terms of career transitions, for a librarian to become an archivist than it is for an archivist to become a librarian; 2. The progression from a small college venue to a large research university is very manageable with the proper planning and experience; 3. At least three of the career elements-professional education, career-planning, and professional association self-interest-in their best moments provide a foundation that enables a future consideration of change between institutional types and professional areas and in their worst moments conspire against the midcareer professional in terms of change; 4. The elements of scouting, continuing education, work experience, and professional involvement offer the greatest assistance in career transitions; 5. Thejob market is the wildcard that either stymies or stimulates occupational development. INTRODUCTION Eleanor Gehrig once asked her husband, baseball legend Lou Gehrig, “What’s the difference between a baseball player in the high minor leagues and a man in the major leagues?” TheYankee great responded, “One step.” The answer was both simple and complex, loaded with all the pain, passion, TimothyJ. Johnson, Curator, Special Collections and Rare Books, Interim Curator, James Ford Bell Library, University of Minnesota, Twin Cities Campus, Suite 111Elmer L. Andersen Library, 222-21st Avenue South, Minneapolis, MN 55455 LIBRARY TRENDS,Vol. 50, No. 4,Spring 2002, pp. 614-630 02002 The Board of Trustees, University of Illinois JOHNSON/MAKING IT TO THE MAJOR LEAGUES 615 and perplexities of a game that has been transformed into a business and anointed as the national pastime. As a former high school baseball player who has seen at least one classmate make it into the majors, Gehrig’s answer made sense in pondering a professional path in the library and archival fields. That autobiographical and professional pondering, in both its simplicity and its complexity is examined here. What are some of the elements of that one step that might separate a player in the informational minor leagues from one in the majors? Is this distinction of the quickerstepped major leaguer valid when technology is in some sense leveling the playing field? Are there, indeed, major and minor leagues in the information world? And can a baseball player (read librarian) learn to successfully play cricket (read archivist) or vice versa? The first part of this examination requires a brief autobiographical sketch. In early 1998, I accepted an offer to join the University of Minnesota’s library staff and felt, in the process, like I had finally made it to the bibliographic big leagues. For sixteen years I had been trying to hone my game in the minors, first as a reference/instructional-services librarian in a small private college, then as the library director for that same struggling enterprise (moonlighting at the same time as a medical librarian at the local hospital), and finally as the director of archives in another, more financially secure, small college (now turned university). Now, at one of the nation’s leading research libraries, I had the chance to take all those hard-learned lessons (and more than a few pleasant experiences) to the next level. Although physically older, I was a step quicker and (I trusted) a step wiser. 1had made the one step. I had followed, for the most part, a course mapped out in graduate school. The course was simple and straightforward: I wanted to be an academic librarian who began my career in a small college library. From there I hoped to move to a midsized college or university setting (with some additional administrative responsibilities) and finally find my way to a large research university. Small college, university, multiversity: that was the plan. But even while formulating this plan I wondered if one could go straight from library school to a research university position. Other recent graduates seemed successful in jumping straight to the majors. But as graduation neared, I was still waiting on the bench. The library market for entry-level professional positions in the early 1980swas rather bleak. At the time there was only one half-time acaderjnic position available in Minnesota (where I attended library school and spent the better part of my second year lobbying to keep the school open. It was, quite possibly, my first taste of life in the major leagues.) Given that dim career-market prospect-the professional equivalent of Fenway Park’s Green Monster in left field-resumes were scattered abroad in a kind of preprofessional fungo. Eventually I secured interviews with two Chicago-area institutions: a renowned private research library and a small undergraduate college. The college interview was facilitated by informal contacts with the previous library director, much in the manner of 616 LIBRARY TRENDS/SPRING 2 0 0 2 a minor-league scout, and resulted in a successful appointment. The major leagues, in the form of the research library, became a later career goal. Two years later another scout, in the guise of a college president, appointed me as the library director. This was followed nearly three years later by yet a third scout (an historian) and an invitation to switch institutions and professions, moving from a library directorship to director of archives. At least one archivist, well-placed within the profession and serving as a consultant to the search process, was suspicious of a librarian (even one with archival training and experience) moving into a position that might be better filled by drafting from within the archival profession. Was this a case of interleague rivalry or another scout wanting to promote their own hot prospect? Working in library-rich Chicago, home to both the American Library Association and the Society of American Archivists, provided additional opportunities to make contact and establish working relationships with library and archival colleagues from a wide range of institutions. Work in professional and scholarly associations provided additional contacts. When The Chronicle OfHigher Education posted the position for curator of special collections at the University of Minnesota in the spring of 1997 Gehrig’s one-step difference to the major leagues seemed surmountable. I entered the draft process of the major leagues. It may be wise, at least for the moment, to place the baseball metaphor that has struggled through the first innings of this article on the injuredreserved list and turn to those questions of movement between library and archives professions, the transition between small college and large university, and the specific elements of career transition that seem fundamental to a discussion of midlife career transitions between institutions and across professions. These elements include, but are not limited to: professional education and training, career-planning and placement, scouting and mentoring, job market conditions, continuing education, work experience and personal skills, professional involvement, and professional association self-interest. If we accept the definition of a midcareer, seasoned professional as someone in their 40s with fifteen to twenty years of experience (St. Lifer, 1994, p. 45); and if these elements are examined both historically at the time of professional entry (for me this occurred in 1982) and at the time of professional transition (I moved into the archive profession in 1987 and returned to the library profession in 1998); and if this examination is placed within the contextual continuum of small college-large research university and libraryarchives professions, then the following observations can be made: 1. It is easier, in terms of career transitions, for a librarian to become an archivist than it is for an archivist to become a librarian. JOHNSON/MAKING I T TO THE MAJOR LEAGUES 61’7 2. The progression from a small college venue to large research university is very manageable with the proper planning and experience. 3. At least three of the career elements-professional education, careerplanning, and professional association self-interest-in their best moments provide a foundation that enables a future consideration of change between institutional types and professional areas. In their worst moments, these elements conspire against the midcareer professional in terms of change. 4. The elements of scouting, continuing education, work experience, and professional involvement offer the greatest assistance in career transitions. 5. The job market is the wildcard that either stymies or stimulates occupational development. IT IS EASIER, IN TERMS OF CAREER TRANSITIONS, FOR A LIBRARIAN TO BECOME AN ARCHIVIST THAN IT IS FOR AN ARCHIVIST TO BECOME A LIBRARIAN. There is very little in the literature (by that I mean the literature of both archives and library professions) that specifically addresses a midcareer change between the library and archives professions. But the literature is full of discussion and debate on professional education, accreditation, credentialing, and professional identity, all of which provide the backdrop for an individual’s decision to change careers. The differences between these two professions show both the gateways and the barriers that make such transitions possible or improbable, depending on the direction of professional travel. Librarians have a clearly defined “terminal” degree; archivists do not. The ALA accredits programs; the SAA does not. Oetting (1989) writes: The library profession has struggl	archive;backdrop cms;color gradient;experience;librarian;library (computing);permanent brain;perplexity;spring;triune continuum paradigm;venue (sound system);wildcard character	Timothy J. Johnson	2002	Library Trends		league;professional development;library science;work experience;archivist;professional association;higher education;pedagogy;continuing professional development;professional studies;sociology;management	HCI	-66.43203114295582	-20.13723037055801	77419
1f75c60b366dcfd7e955cfa21d43b5c5d9fa3081	the rapid evolution of scholarly communication	electronic communication;scholarly communication;research paper;rapid evolution;growth rate	Traditional journals, even those available electronicall y, are changing slowly. However, there is rapid evolution in scholarly communication. Usage is movin g to electronic formats. In some areas, it appears that electronic versions of papers are being read ab out s often as the printed journal versions. Although there are serious difficulties in comparing figures from different media, the growth rates in usage of electronic scholarly information are sufficiently high that if they continue for a few years, there will be no doubt that print versions will be eclipsed. Furthe , much of the electronic information that is accessed is outside the formal scholarly publication proce ss. There is also vigorous growth in forms of electronic communication that take advantage of the unique capabilities of the Web, and which simply do not fit into the traditional journal publishing format. This paper presents some statistics on usage of print and ele ctronic information. It also discusses some preliminary evidence about the changing patterns of us age. It appears that much of the online usage comes from new readers (esoteric research papers assi gned in undergraduate classes, for example) and often from places that do not have access to print jou rnals. Also, the reactions to even slight barriers to usage suggest that even high quality scholarly p apers are not irreplaceable. Readers are faced with a “river of knowledge” that allows them to select a mong a multitude of sources, and to find near substitutes when necessary. To stay relevant, scholar s, publishers, and librarians will have to make even larger efforts to make their material easily accessibl e.	amiga walker;archive;display resolution;finch;herb sutter;leslie speaker;librarian;library (computing);montgomery modular multiplication;printing;relevance;robby garner;scholarly communication;tom;while;world wide web;eric	Andrew M. Odlyzko	2002	Learned Publishing	10.1087/095315102753303634	social science;computer science	Web+IR	-68.51222392649962	-22.566821740377407	77739
f08284923275127e8585fc227b7262130b140072	technology-based training in large uk companies: an update	entreprise;comparative analysis;enterprise;enseignement technologique;programme de formation;etats unis;formation en cours d emploi;professional training;in service training;royaume uni;united kingdom;training program;usa;analyse comparative;technological education;formation professionnelle	This paper follows up an earlier Leverhulme-funded study of technologybased training (TBT) in UK and US companies (Hawkridge, Newton and Hall, 1988). It is based on interviews with relevant staff in five large companies in the UK: British Telecom, Ford Motor Company, Lloyds Bank, Price Waterhouse and Sainsbury's. After a short introduction, the second and third sections of the paper consider the impact of the economic climate of the early 1990s on company strategies regarding TBT and its use. The fourth section provides examples from past and current practice and notes changes in the past six years. It paints a picture of highly selective development, rather than rapid progress across a broad front. The fifth and last section discusses possible directions for the future. Introduction During the 198Os, there was widespread interest in technology-based training (TBT) among industrial and commercial companies in the UK and the US. Many purchased computer-based training, ranging from mainframe-based systems to standalone PCbased ones. Others moved into interactive video, first on cassette and then on laserdisc. Some spent large sums commissioning their own courseware, while others bought copies of generic courseware from developers and vendors. Evidence obtained during and after a study funded by the Leverhulme Trust (Hawkridge et al, 1988) showed that within Europe, the UK held a commanding lead. British companies gained this lead partly through installing ready-made US systems but also because of vigorous government support which subsidised UK developments of TBT. As part of the research behind the teaching in a new Open University course, In format ion Technology and Society, it seemed worthwhile to obtain new data and to prepare case studies of the current position regarding TBT in a sample of large UK 52 British Journal of Educational Technology Vol27 No 1 1996 companies. Using methods developed during the Leverhulme study, we interviewed one or more members of staff in one company from each of five sectors: retail, manufacturing, banking, professional services and telecommunications. The companies were British Telecom, Ford Motor Company (of Britain), Lloyds Bank, Price Waterhouse and Sainsbury’s. The case studies appear on CD-ROM in the course material. The interviews concentrated on a range of TBT issues: delivery platform: target audience for training; conduct of training needs analysis: budget and funding: policy issues and strategy; management and promotion of TBT; in-house production or purchase of generic titles: hours of training being offered and taken up: reactions of trainees; performance criteria being used to judge success of TBT: overall evaluation: projected life of current TBT and plans for the future. The firms we selected have been involved in the use of TBT, broadly defined, for almost a decade. All five have experience of ‘lower-tech’ solutions such as workbooks and fairly simple computer-based training (CBT) as well as ‘higher-tech’ interactive video and/or full-blown PC-based multimedia. British Telecom, Lloyds Bank and Sainsbury’s were included in the 1988 study, along with Ford in the USA. Although Price Waterhouse and Ford of Britain were not included in the earlier study, both companies have been using TBT since the mid-1980s. From each of the five, therefore, we were able to obtain sufficient information to describe the company’s past and current experience of TBT. We were also able to find out how the position has changed in the last six years or so and discern what is likely in the near future. In the next two sections of this paper, we first discuss the impact of the economic climate of the early 1990s on the use of TBT and then examine company strategies regarding TBT. The fourth section provides examples of past and current practice and notes changes in the past six years. The overall picture is one of highly selective development, rather than rapid progress across a broad front. Our fifth and final section discusses possible directions for the future. Impact of the economic climate The interviews took place in late 1993 and early 1994, at a time when, according to government and some business leaders, Britain was starting its climb out of the deepest recession since the Second World War. Their optimism was not yet reflected in consumer confidence and spending. Large UK companies, including the ones selected for our case studies, did not escape the effects of this recession: most went through considerable ‘downsizing’ by shedding staff and re-structuring. In the early 1990s, there were very considerable reductions in the workforce at British Telecom, Ford and Lloyds Bank, while Price Waterhouse and Sainsbury’s cut back on their recruitment of graduates. What impact did the damaging economic climate have, indirectly, on TBT in these companies? The recession affected company attitudes towards training in general, and Technology-based training in large UK companies: an update 53 towards TBT in particular. As part of its attempts to cut public expenditure, government reduced sharply the sums available to subsidise training, and the new Training and Enterprise Councils had not succeeded in restoring training expenditure to the levels of the 1980s. Despite new Training Targets being published by government, the majority of companies cut back their training departments and programmes. Across the board, older staff went, leaving behind younger staff without much experience, although more technology-literate. One possible effect of the recession may have been to improve company attitudes towards TBT, because they needed the cost savings it can deliver. In many companies, however, cash flow problems appeared to dominate: managers were very conscious of the need to avoid high-risk investments in training. TBT can involve large up-front costs if a company wants to develop its own courseware. Nobody argues against the Austin Rover figure of 100 hours investment in preparation for one hour of CBT, compared with 12 hours for one hour of conventional training (Hawkridge, Newton and Hall, 1988, p226). Other substantial up-front costs can be incurred in purchasing the hardware and software needed for TBT. Although ‘stand-up’ trainers have to be trained and then must do any necessary preparation prior to the training event, the up-front costs are small in comparison with the design and development of TBT. These high ‘front-end’ costs can be economically justified only when the courseware is used to provide training to a large number of employees, offering considerable savings over traditional training courses and the associated accommodation and travel costs. It therefore seems reasonable to assume that in smaller companies the only TBT seen as worth buying during a recession is generic, off-the-shelf courseware that will run on existing hardware and software. Even in larger companies, generic courseware may seem a better purchase than bespoke, purpose-built courseware. As well as focusing attention on training costs, the recession spurred moves towards greater efficiency and a reduction in the number of employees. Such changes increased knowledge demands on the remaining members of staff, many of whom had to become multi-skilled, with more than one job to do. These requirements, coupled with a reduced training budget, make release for external training harder to justify both on cost grounds and also because staff cannot readily be spared from the workplace. By engendering such an environment the recession may actually have encouraged the increased use of generic TBT especially of a relatively low technical specification, as this need not be expensive in upfront costs as a way of economically meeting the new training needs. The fact that some companies are reducing their internal training resources in favour of open learning (including generic TBT), may account for the claims of some vendors that their business has increased despite the recession. One further piece of evidence reflecting the negative impact of the recession on TBT lies in the changes we discovered among the TBT vendors, almost all of which are small companies that specialise in either importing and marketing US generic packages or in 54 British journal of Educationai Technology Voi27 No f 1996 producing bespoke courseware. The 198 8 vendor database proved completely inadequate as a source of current vendors when this current study was conducted, because with very few exceptions the old ones had disappeared. Some had been absorbed into other companies. Some had acquired different names. Others had simply closed down, and their former employees had developed new businesses, indicating that this is still a volatile, high risk market. Current TBT strategies in large UK companies Current large company strategies regarding TBT are mixed. They involve, on the one hand, the creation of training resource centres to house some, if not all, TBT materials, and, on the other hand, the delivery of TBT in the workplace. These strategies also combine generic TBT with bespoke development, but the latter often has a dual aim of serving in-company needs and selling on the courseware to other companies. Strategies vary with regard to in-house development and implementation: only a very few large UK companies maintain their own TBT units for these purposes, while others prefer to commission work from a range of vendors, the small specialist production companies. The emergence of training resource centres (under a variety of names) is one result of a strategy that aims at providing rich training resources, including TBT, in an appropriate environment other than the workplace but easily accessible to those whose training needs have been identified. These centres can accommodate and deliver TBT to a much higher technical specification than TBT supported by incompany networks. Ford, Lloyds Bank and Price Waterhouse already have centres in one form or a	bespoke;cd-rom;compact cassette;emergence;mainframe computer;needs analysis;newton;purchasing;requirement;rover (the prisoner);volatile memory	Elizabeth Houldsworth;David Hawkridge	1996	BJET	10.1111/j.1467-8535.1996.tb00143.x	professional development;qualitative comparative analysis;social science;sociology;management;operations research;law	Web+IR	-68.16047883349006	-20.839080543586487	77989
34ae29922206f4cb3fdde65d949a649a64099535	digital forensics: meeting the challenges of scientific evidence	digital forensics;computer forensics;trusted third party;digital evidence;reliability and validity	This paper explores three admissibility considerations for scientific evidence currently engaged in U.S. courts: reliability,  peer review and acceptance within the relevant community. Any tool used in a computer forensic investigation may be compared  against these considerations, and if found wanting, evidence derived using the tool may be restricted. The ability to demonstrate  the reliability and validity of computer forensic tools based on scientific theory is an important requirement for digital  evidence to be admissible. A trusted third party certification model is discussed as an approach for addressing this issue.  		Matthew Meyers;Marcus K. Rogers	2005		10.1007/0-387-31163-7_4	computer science;digital forensics;internet privacy;world wide web;computer security;computer forensics	NLP	-72.04902494780072	-14.423148056869275	77998
a86f4110f9b3da3985a188b45cc412e7d7e83ec6	erratum: dubois, g., et al. integrating multiple spatial datasets to assess protected areas: lessons learnt from the digital observatory for protected areas (dopa). isprs international journal of geo-information 2016, 5, 242					2017	ISPRS Int. J. Geo-Information	10.3390/ijgi6010022		DB	-63.1157080166114	-10.762423615836976	78103
002bfe0603b311cba4a57e766e5933b31bc3f226	search engine advertising: channel substitution when pricing ads to context	commerce electronique;search engine;market power;buscador;electronic commerce;comercio electronico;markets;information systems;mercado;advertising prices;search engines;ambulancia;pricing;advertising and media;localization;comercializacion;ambulance;substitut;localizacion;transporte sanitario;fijacion precios;commercialisation;lawyer;avocat;tariffication;localisation;marketing;transport sanitaire;tarification;marche;abogado;online advertising;it policy and management;information system;moteur recherche;search engine advertising;publicidad;substituto;publicite;substitute;medical transport;natural experiment;fixation prix;systeme information;electronic trade;tarificacion;advertising;sistema informacion	We explore substitution patterns across advertising platforms. Using data on the advertising prices paid by lawyers for 139 Google search terms in 195 locations, we exploit a natural experiment in ―ambulance-chaser‖ regulations across states. When lawyers cannot contact clients by mail, advertising prices per click for search engine advertisements are 5-7% higher. Therefore, online advertising substitutes for offline advertising. This substitution towards online advertising is strongest in markets with fewer customers, suggesting that the relationship between the online and offline media is mediated by the marketers’ need to target their communications. * Avi Goldfarb is Associate Professor of Marketing, Rotman School of Management, University of Toronto, 105 St George St., Toronto, ON. Tel. 416-946-8604. Email: agoldfarb@rotman.utoronto.ca. Catherine E. Tucker is Assistant Professor of Marketing, MIT Sloan School of Business, 1 Amherst St., E40-167, Cambridge, MA. Tel. 617-252-1499. Email: cetucker@mit.edu. We wish to thank Jayne Huang for excellent research assistance. We also wish to thank the review team, Chris Dellarocas, Shane Frederick, Anindya Ghose, Shane Greenstein, and seminar participants at SCECR 2007, LBS, the NET Institute conference (2008), the Fourth Workshop on Ad Auctions, and the University of Toronto for comments. We thank the NET Institute (http://www.NETinst.org) for financial support.	catherine;causality;certificate authority;channel (communications);email;google search;ip address blocking;location-based service;online advertising;online and offline;personally identifiable information;privacy law;search advertising;walter rotman;web search engine	Avi Goldfarb;Catherine Tucker	2011	Management Science	10.1287/mnsc.1100.1287	public relations;advertising campaign;online advertising;advertising research;economics;keyword advertising;native advertising;compensation methods;marketing;advertising account executive;cost per impression;advertising;search advertising;informative advertising;contextual advertising;information system;search engine	ECom	-67.3183166348329	-14.588231350726478	78320
98e01d1d88e1af306bb9709a34c80bd62796c9f5	the role of government in the evolution of the internet	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias	rom its origins as a U.S. government research project, the Internet has grown to become a major component of network infrastructure, linking millions of machines and tens of millions of users around the world. Very little of the current Internet is owned by, operated by or even controlled by governmental bodies. Most of the funding for Internet services comes directly from private sources, although the educational community in the U.S. receives most of its research funding from governmental sources. Increasingly, however, the provision of Internet communication services, regardless of use, is being handled by commercial firms on a profit-making basis. This situation raises the question as to the proper long-term role for government in the continued evolution ofthe Internet. Is the Internet now in a form where government involvement should cease in its entirety so as to allow private sector interests to determine its future trajectory? Or is there still an important role for government to play in the future? This article concludes that there are a series of important contributions for government to make and a few areas where government involvement will continue to be essential to the longterm well-being of the Internet. In fact, as the Internet continues on its commercial and international trajectory, the role of government will continue to be essential, and may expand to include more involvement by governments around the world.	internet;read-only memory;web service	Robert E. Kahn	1994	Commun. ACM	10.1145/179606.179729	knowledge management;the internet;theoretical computer science;government;computer science	Networks	-74.72158980585229	-11.409710149138625	78325
7ca3a1ce45c6151276788ce6ec7996106ef9a290	"""keynote speakers: """"transformative power of precision medicine - moving from data to diagnosis"""""""		Personalized medicine powered by data-driven insights is a monumental shift that delivers better prevention, diagnosis, and treatment at a fraction of the time and cost. We will look at some of the global disruptions that are driving the need for change and the technologies that are emerging to propel the market forward. This represents a significant opportunity for EMBS to partner with HIMSS to help steer the innovations, establish standards, and help drive this transformation.	precision medicine	Rick A. Cnossen	2018		10.1109/BSN.2018.8329642	knowledge management;precision medicine;embedded system;computer science;personalized medicine;transformative learning	NLP	-75.38335795798773	-10.910024819865358	78659
c8117950124e6517a3b7a620f90c8652d00f9ab2	introduction to the electronic government track		After several years of incubation within the Emerging Technologies Track, the former cluster of minitracks dedicated to electronic Government (e-Government, e-Gov, digital government) has matured into a self-standing Electronic Government Track at HICSS39. During those past years of incubation, an ever increasing number of quality e-Government-related submissions to HICSS have greatly helped establish this track as a premier academic platform for researchers in the field. With 55% accepted submissions from outside the US, the HICSS-based e-Government Track (like the annual EGOV sub-conferences at DEXA or the NSF-sponsored dg.o. conferences) is a truly global academic event and has provided the young field with tremendous tailwind by accelerating the scholarly exchange. It has also structured and shaped the research agenda in bringing together different research traditions. The e-Gov research tradition further distinguishes itself from other fields by seemingly more readily exploring and employing truly inter- and multidisciplinary research designs. This gives the young field a unique flavor and importance within the academic spectrum.		Hans Jochen Scholl	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.323	public relations;media;mobile telephony;computer science;information security;marketing;software engineering;database;advertising;management;world wide web	Robotics	-69.43538012742891	-17.425004754139753	78721
b340326e358adbd0ee22d9d7cb6d56c14cfe127d	intelligent information processing - chances of crowdsourcing (nii shonan meeting 2013-15)		The number of organizations adopting crowdsourcing strategies is growing at an amazing speed. While the term crowdsourcing is being increasingly used in different contexts, it is still ambiguous and lacks a clear definition. Crowdsourcing implicitely includes a social dimension. Social computing was coined in 1994 by Doug Schuler, and its current meaning was come along around the middle of 2000 due to the wisdom of crowds by James Surowiecki, referring to systems that support the gathering, representation, processing, use, and dissemination of information that is distributed across social collectivities. In this paper, we discuss the relationship between crowdsourcing and social computing and its potential social impact. We define the main components of a crowdsourcing platform and we provide a classification of challenges that can be solved through crowdsourcing.	crowdsourcing;information processing;national information infrastructure;social computing;the wisdom of crowds	Wolf-Tilo Balke;Seung-won Hwang;Takahiro Hara;Christoph Lofi	2013	NII Shonan Meet. Rep.		information retrieval;information processing;computer science;crowdsourcing	Web+IR	-70.59185914144246	-18.5757661236202	78748
e94f5063359b1f2257df111ac0c2f2b9af5e893d	data processing digest: thirty years before the masthead	computers;history;biographies;data processing;data processing history biographies;materials;canning;business;book reviews	In the fall of 1954, Richard G. Canning and Roger L. Sisson formed a consulting partnership to help businesspersons adapt their business operations to the computer. (It wasn’t the other way around for a long time!) Canning was writing a definitive book, Electronic Data Processing for Business and Industry, and had gained a reputation for innovative thinking in the new uses of computers. As he and Sisson began searching through what had been, and was being, published	computer;digest access authentication;electronic data processing;richard bird (computer scientist)	Margaret Milligan	1985	Annals of the History of Computing	10.1109/MAHC.1985.10027	history;data processing;computer science;database;genealogy;operations research	DB	-64.92397420319288	-21.568458336381887	78761
416d9a3f3ef054a4ba33b7fc0852b08a3c548b7a	information access in implicit culture framework	reordering;invalidation report;tacit knowledge;information access;transaction;collaborative filtering;hybrid broadcast	The goal of a System for Implicit Culture Support (SICS) is to establish an implicit culture phenomenon, namely when the elements of a set behave according to the culture of a generally different group of agents. Earlier work claimed that Implicit Culture support can be seen as a generalization of Collaborative Filtering. In this paper, we recall the concept of Implicit Culture, show how it is useful for automatically exploit tacit knowledge and we present an implementation of a System for Implicit Culture Support.	collaborative filtering;information access;swedish institute of computer science	Enrico Blanzieri;Paolo Giorgini;Paolo Massa;Sabrina Recla	2001		10.1145/502585.502691	computer science;knowledge management;collaborative filtering;machine learning;database	HCI	-63.98188591280273	-13.840266113766702	78882
d133795edf639db4f29018d51c7db64a85777e8a	language in isolation, and its implications for variation and change		Abstract#R##N##R##N#This article discusses some approaches to the conceptualization of isolation in sociolinguistic research. It argues that isolation is a multifaceted phenomenon with geographic, social and attitudinal implications. Based on evidence from geographically isolated speech communities (mostly islands) and socially isolated ones (so-called Sprachinseln) from around the world, it discusses their potential for variation and change studies, both in terms of synchrony (contact phenomena, language obsolescence or revival and intensification, language and identity, etc.) and diachrony, because they provide showcase scenarios to look into and reconstruct mechanisms of contact linguistics (e.g. new-dialect formation), founder effects, colonial lag, etc.		Daniel Schreier	2009	Language and Linguistics Compass	10.1111/j.1749-818X.2009.00130.x	psychology;biology;social science;linguistics;sociology;communication	NLP	-76.96070583803274	-13.887891622702133	79061
77fc5b6c5ee42380611a6715b7b7989b51f41b14	the signs of science	representation;citation analysis;critical study;sciences;analisis cita;citation index;citation;science policy;etude critique;universiteitsbibliotheek;ciencia;litterature scientifique;index citation;reference bibliographique;referencia bibliografica;estudio critico;analyse citation;literatura cientifica;indexation;scientific communication;citacion;bibliographic reference;scientific literature;sci;representacion;indice cita	Since theScience Citation Index emerged within the system of scientific communication in 1964, an intense controversy about its character has been raging: in what sense can citation analysis be trusted? This debate can be characterized as the confrontation of different perspectives on science. In this paper the citation representation of science is discussed: the way the citation creates a new reality of as well as in the world of science; the main features of this reality; and some implications for science and science policy.	citation analysis;citation index;journal citation reports;scientific communication	Paul Wouters	1998	Scientometrics	10.1007/BF02457980	social science;computer science;sociology;representation;citation analysis;world wide web	NLP	-75.00174434545568	-21.762427556299897	79085
8af3aac6701fa1ab7ba7a9e0c473437bf32b6e91	freedom of silence vs. freedom of speech: technology, law and information security	information security;computer crime;social aspects of automation;law;security of data social aspects of automation law computer crime;technological progress;denial of service;speech information security law legal factors computer crime appropriate technology protection acoustic noise noise cancellation phase noise;defending technologies freedom of silence freedom of speech information security law computer crimes phishing emails denial of service misleading speech;security of data	Freedom of silence, not having to listen to unwanted speech, is a much less debated and less well understood concept than freedom of speech. While both of these freedoms are important, there is a natural tension between them. Society must find the proper balance between such opposing forces. Technological progress has greatly enhanced the freedom of speech, and less so the freedom of silence. With this tilted balance, the implications of freedom of silence on information security are more and more apparent: computer crimes are increasingly using misleading speech, for example phishing emails and denial of service. This paper explores the implications of the freedom of silence, and evaluates technological and legal solutions. Technology-supported speech can more readily be contained by appropriate defending technologies than by legal means.	cybercrime;denial-of-service attack;email;information security;phishing	Bogdan Hoanca	2005	Proceedings. 2005 International Symposium on Technology and Society, 2005. Weapons and Wires: Prevention and Safety in a Time of Fear. ISTAS 2005.	10.1109/ISTAS.2005.1452711	public relations;political science;social psychology;computer security	Arch	-71.55209359823148	-11.92632327595211	79132
66efe29a5755e72e1793947868b97aa0fb56c315	the making of algol 68		In September 1967, Aad van Wijngaarden, the director of the Mathematical Centre in Amsterdam, asked me to join the ongoing project to define a successor to Algol 60. I had just finished 18 months in the Dutch Army, and was looking forward to the resumption of a carefree life, working on Natural Language Processing. Van Wijngaarden’s eye fell on me for a number of reasons: I was steeped in the spirit and implementation of Algol, well-versed in two-level grammars and I knew everything there was to know about operating systems and I/O, having just completed a vast Fortran program on an IBM 7094 under IBSYS that made use of all its 16 tape drives. In this way I became one of the Authors of Algol 68, and a participant in one of the formative events of our profession — the making of Algol 68. In this note I will try to give you an eyewitness account. I am not a historian, and have kept very few notes from this period, but the Informal Minutes of the Tirrenia [7] and North Berwick [8] meetings bring back many memories. Let me describe to you four parties, the Editor, the Authors, the Committee and the Computing Community, taking part in a cosmic struggle for Truth. The period is November 1967 to December 1968. The persistent Capitalization of certain important substantives in this text is entirely in keeping with the IFIP-style of those times.	algol 60;algol 68;cosmic;fortran;ibm 7090;ibm 7090/94 ibsys;input/output;international federation for information processing;natural language processing;operating system;tape drive	Cornelis H. A. Koster	1996		10.1007/3-540-62064-8_6	programming language;algol 68;computer science	OS	-63.28947903787963	-19.59462736625071	79274
66726950d756256ca479a068664ecb052b048991	tracking the evolution of the internet of things concept across different application domains		Both the idea and technology for connecting sensors and actuators to a network to remotely monitor and control physical systems have been known for many years and developed accordingly. However, a little more than a decade ago the concept of the Internet of Things (IoT) was coined and used to integrate such approaches into a common framework. Technology has been constantly evolving and so has the concept of the Internet of Things, incorporating new terminology appropriate to technological advances and different application domains. This paper presents the changes that the IoT has undertaken since its conception and research on how technological advances have shaped it and fostered the arising of derived names suitable to specific domains. A two-step literature review through major publishers and indexing databases was conducted; first by searching for proposals on the Internet of Things concept and analyzing them to find similarities, differences, and technological features that allow us to create a timeline showing its development; in the second step the most mentioned names given to the IoT for specific domains, as well as closely related concepts were identified and briefly analyzed. The study confirms the claim that a consensus on the IoT definition has not yet been reached, as enabling technology keeps evolving and new application domains are being proposed. However, recent changes have been relatively moderated, and its variations on application domains are clearly differentiated, with data and data technologies playing an important role in the IoT landscape.	as-interface;algorithm;application domain;big data;biological evolution;categorization;confluence;data mining;database;definition;digital single-lens reflex camera;divergence (computer science);exclusion;indexes;inference;inspiration function;internet of things;name;nomenclature;timeline fluoride releasing resin;vision;wiki;sensor (device)	Jorge Eduardo Ibarra Esquer;Félix F. González-Navarro;Brenda Leticia Flores Ríos;Larysa Burtseva;María Angélica Astorga Vargas	2017		10.3390/s17061379	management science;electronic engineering;search engine indexing;terminology;data mining;timeline;web of things;physical system;computer science;internet of things	AI	-73.61785304374686	-17.468381989305296	79336
f7ca68474a05bba2bb8385252ad47ff20a3e1fd0	videotex: anatomy of a failure	teletext;database access;electronic mail;viewdata;videotex;information systems	Considerable excitement has been generated in Europe and North America in videotex namely, the concept of electronic access in the home to centrally located computerized databases containing vast amounts of data. However, the public offering of such services has thus far been unsuccessful in achieving significant penetrations In the residential market. Videotex is examined in this paper to Illuminate possible reasons for its failure thus far in the residential marketplace. Comparisons are made with somewhat similar on-line systems for accessing computerized data-bases and for performlng transactions and transmitting messages to other people. The final conclusion is that most consumers simply do not have a need nor a desire to access vast computerized data-bases of general information. Videotex or any other similar system that attempts to satisfy consumer needs for information in such a fashion will surely fail. Considerable attention has been generated throughout the world in the concept of computerized public-information services. particularly as implemented about five years ago by the British Post Office in England. These services consist of a network of regional computerized data-bases which are accessed over telephone lines from terminals that utilize home TV sets for display. The content of the data-base is organized in the tree fashion, and searches through the data-base are made by pressing numbers on a hand-held numeric keypad. The information is a frame of textual and graphical content in color. These services are known generically as videotex, or viewdata, and the specific service offered by the British is called Prestel.	database;graphical user interface;mobile device;online and offline;prestel;telephone line;transmitter;videotex;viewdata	A. Michael Noll	1985	Information & Management	10.1016/0378-7206(85)90031-X	telecommunications;engineering;electrical engineering;marketing;operations management;advertising;management;world wide web	DB	-69.0062868203431	-21.813872118398347	79341
289ed61b4f82397298160756fd1129c03111b7a0	patents and standardization, part 3: commitments to license standard-essential patents under reasonable and non-discriminatory (rand) terms	standards organizations;licenses patents ieee 802 11 standard standards organizations organizations two dimensional displays;two dimensional displays;united states district court standardization license standard essential patent reasonable and nondiscriminatory term rand term;patents;licenses;organizations;ieee 802 11 standard;telecommunication industry patents standardisation	"""Many standards development organizations ask participants who hold patents that may be essential to practice a standard to agree to license those patents under """"reasonable and non-discriminatory (RAND)"""" terms. But what exactly are RAND terms? This article discusses the policy of RAND obligations, explains how disputes can arise about whether a proposed license to a standard-essential patent includes RAND terms, and explains how a particular dispute over RAND terms was resolved in a United States district court."""		Krista S. Jacobsen	2016	IEEE Communications Magazine	10.1109/MCOM.2016.7565274	organization	SE	-70.5760892779377	-13.23613340318727	79616
8636bfb28dc3a172147a4e9a42217aaca8c8e82e	rethinking sustainability in computing: from buzzword to non-negotiable limits	datorsystem;computer systems;sustainability;information systems social aspects;environmental sustainability;critical reflection;ecological sustainability;sustainable hci;limits to growth;steady state economy;collapse informatics;ecological footprint;sustainable development;systemvetenskap informationssystem och informatik med samhallsvetenskaplig inriktning	Recent years have seen a flurry of work on sustainable computing and sustainable HCI, but it is unclear whether this body of work adheres to a meaningful definition of sustainability. In this paper, we review four interlocking frameworks that together provide a rigorous foundation for what constitutes sustainability. Each consecutive framework both builds upon and can loosely be seen as a refinement of the previous framework. More specifically, we leverage prominent ecological thinking from outside of computer science to inform what sustainability means in the context of computing. To this end, we re-evaluate some recent results from the field of sustainable HCI and offer thoughts on further research in the field.	computer science;human–computer interaction;refinement (computing)	Daniel Pargman;Barath Raghavan	2014		10.1145/2639189.2639228	sustainability organizations;sustainability science;social sustainability;management science;management;sustainability	HCI	-74.98955883638352	-12.819788885608897	79783
e9a09ecf7aa83d3735a1504c633f1ddb06366bac	information seeking behavior of academic scientists		responses to a 15-minute Web-based survey. The survey questions were designed to quantify the transition to electronic communications and how this affects different aspects of information seeking. Significant changes in information seeking behavior were found, including increased reliance on web based resources, fewer visits to the library, and almost entirely electronic communication of information. The results can guide libraries and other information service organizations as they adapt to meet the needs of today's information searchers. Simple descriptive statistics are reported for the individual questions. Additionally, analysis of results is broken out by basic science and medical science departments. The survey tool and protocol used in this study have been adopted for use in a nationwide survey of the information seeking behavior of academic scientists. Introduction As we begin the twenty-first century, we are seeing a dramatic shift towards electronic communication of scientific scholarly information. While much of this was presaged during the computing revolution of the 1980s and 1990s, it has been the recent widespread adoption of Web-based electronic journals that has been the primary driver for change. The escalation of journal subscription costs and limited academic library budgets have paved the way for the electronic distribution of articles. Another significant factor in the adoption of e-articles has been the ease of finding articles on the Web via free search engines such as Google Scholar or from library-sponsored links in online catalogs and subscribed databases. The end result is that searching, retrieving and reading of scientific scholarly articles appears to be moving towards becoming completely electronic, with the only holdout being the preference by many for reading print copies. The transition to primarily electronic communication has the potential to significantly change the ways scholarly communication takes place. These changes range from the convenience of accessing electronic material on the reader's desktop, through the speed at which scholars can communicate new information, to accessibility to larger amounts of the material, and finally to the corresponding problem of sifting through larger amounts of potentially useful materials. While many disciplines of scholarly communication have been impacted, academic science appears to be one of the most affected disciplines. This is due to scientists' need to communicate results rapidly, their early adoption of technology , and their support for other types of digital content such as scientific databases (e.g., the Genbank database, as described in Brown, 2003). This article reports on a survey study designed …	accessibility;database;desktop computer;digital revolution;digital recording;genbank;google scholar;information retrieval;information seeking behavior;library (computing);privilege escalation;scholarly communication;simple features;web search engine;world wide web	Bradley M. Hemminger;Dihui Lu;K. T. L. Vaughan;Stephanie J. Adams	2007	JASIST	10.1002/asi.20686	questionnaire;social science;computer science;data mining;operations research;world wide web;information retrieval;statistics	DB	-70.6129660345141	-22.476818141277462	79787
84ef755eb4e1de711cf2c6a624ea5cda2442233e	five days at outdoor education camp without screens improves preteen skills with nonverbal emotion cues	nonverbal communication;social interaction;development;adolescent;emotion;social media	http://dx.doi.org/10.1016/j.chb.2014.05.036 0747-5632/ 2014 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/). ⇑ Corresponding author. Address: Department of Psychology, University of California, Los Angeles, 616 Via De La Paz, Pacific Palisades, CA 90272, United States. Tel.: +1 310 526 3316; fax: +1 310 230 7830. E-mail address: yaldatuhls@gmail.com (Y.T. Uhls).	casp;call to action (marketing);computer;digital media;discontinuous galerkin method;experience;fax;jolie;like button;mobile device;mobile phone;norsk data;pacific rim;roland gs;socialization	Yalda T. Uhls;Minas Michikyan;Jordan Morris;Debra Garcia;Gary W. Small;Eleni Zgourou;Patricia M. Greenfield	2014	Computers in Human Behavior	10.1016/j.chb.2014.05.036	psychology;nonverbal communication;social relation;social media;emotion;multimedia;communication;social psychology;world wide web	HCI	-63.03096090004718	-13.803800726864333	79864
f14cf267c592149a96f01934c180f36b4f72cde3	a conference on quality of work life: issues affecting the state of the art bureau of labor-management relations and cooperative programs, u.s. department of labor (1984)					1985	Robotica	10.1017/S0263574700009243		NLP	-64.63844461941677	-11.544724854591463	79967
7c8a440851ff80cc90deff809672ff0fc595da00	the next hundred years: a course		"""each system upon teachers, administrators, and the institution itself. This analysis of the direct efforts of the system on the total educational enterprise will include measures of change in the role and responsibility of the teacher attributable to the system, and assessment of teacher's and administrator's attitudes toward computer-based education, as well as measures of unintended or side effects that might result from extensive or prolonged use. In conclusion, the evaluation for the PLATO and TICCIT will address a number of fundamental issues in computer-based education. Many of those issues pertain to questions discussed above which potential users might raise concerning practical expectations. Information will also become available to answer numerous important questions about the impact of instructional technology within the educational community. The cost, technical, and educational analyses conducted by ETS will identify strengths and weaknesses for PLATO and TICCIT, and begin to assess the extent to which the promise on instructional technology has been or can be fulfilled. References l. Kerr C. (chm .) The fourth revolution : Instructional technology in higher education. New York : McGraw-Hill, 1972. Pressey, S. L. Development and appraisal of devices providing immediate automatic scoring of objective tests and concomitant self-instruction. """"Machines and Man"""" courses have proliferated across college campuses since the late 1960's .1 So far as I know, however, none has reached the enrollment totals achieved in the University of Florida course UCC 191, """"Cybernetics and Society,"""" which presently maintains a roll of 400 students per quarter during the three normal quarters ; half that figure in the summer .2 The course was the brainchild of Franklin A. Doty, then Dean of University College .3 He was increasingly bemused by the clarity-and futility-of 20th-century man's hindsight, visa -vis such machine-centered problems as : air pollution; the need for, and lack of, parking facilities ; the flight to suburbia. Many of these problems could have been avoided by adequate advance planning, reasoned Dean Doty. It was, and is, too late to find any but the most prohibitively expensive solutions to those automotive difficulties. But the Dean thought the moral was clear: if the relatively cumbersome mechanical machines of the first half of the century have complicated our lives so thoroughly in so short a time, it certainly behooves us to consider the potential societal impact of the infinitely more sophisticated cybernated devices of the second half of the century, while there is …"""	cybernetics;enterprise test software;franklin electronic publishers;kerr effect;plato (computer system);virtual instrument software architecture	Roy Lambert	1974	SIGCAS Computers and Society	10.1145/958645.958647	sociology;public relations;social science	HCI	-66.86091304197399	-22.87601165308505	80071
517aa6180f704bf8420a63a3fdccb1f49fdbf8ed	neolithic informatics: the nature of information	communication system;universals;theorie communication;information technology;technologie information;teoria comunicacion;ancient sumeria;community networks;information management;communication theory;present day;c auxiliary sciences of history general;informatics;h social sciences general;information system;tecnologia informacion;systeme information;information;sistema informacion	The term informatics is used as an umbrella term to stand for the overlapping disciplinary areas of information systems, information management and information technology. The current paper is part of a series which documents an overarching attempt to develop a clearer and more sophisticated systematics for the area. It examines one of the foundation concepts of informatics – that of information – and aims to provide a definition for this concept based upon ideas from semiotics and communication theory. For this purpose we introduce the concept of a sign-system and consider the role such a system plays in human communication. We also highlight the fundamental difference between a communication system and an information system. To help ground our discussion and provide a necessary distance from the presentday concern with digital computing and communication networks we engage with the historiography of information. We consider the use of information in Neolithic times and describe the case of clay tokens in Ancient Sumeria as one of the earliest examples of information representation and manipulation. Examination of this case allows us to propose a number of universal features of information and ‘information	computer;informatics;information management;information system;semiotics;telecommunications network;umbrella term	Paul Beynon-Davies	2009	Int J. Information Management	10.1016/j.ijinfomgt.2008.11.001	information needs;problem of universals;social science;information;engineering informatics;telecommunications;computer science;engineering;knowledge management;electrical engineering;artificial intelligence;management information systems;sociology;information quality;information management;informatics;management;information technology;world wide web;information system;communications system;communication theory	AI	-72.83774137110976	-18.46932221346545	80138
ffc9ae50a111f2ac3305effd393407f316069508	romanian online dialect atlas: data capture and presentation		The Romanian language is key to the scholarly understanding of the development of Romance languages, which has prompted the detailed study of Romanian dialects, including the critical dialects of the Crisana region in north-west Romania by Stan & Uritescu (1996, 2003, etc.; see also Uritescu 1984a, 1984b). To make the Crisana data more accessible to scholars, and to permit the application of new techniques in dialectology – such as the multidimensional scaling technique of Embleton & Wheeler (1997a,b, 2000), see below –, we have undertaken the task of digitizing the data in the hardcopy atlas. With the support of the Social Sciences and Humanities Research Council of Canada, we have engaged people, mostly graduate students in Canada and Romania, to enter the data from the maps into text files. When the data entry is complete (including the appropriate quality assessment and editing), the data will be posted to the internet for others to access. In this respect, the RODA project is similar to work done on Finnish by Embleton & Wheeler (1997b, 2000, etc.), in which a hardcopy dialect atlas of Finland has been successfully digitized. The two cases are not equivalent because of the differing formats of the hardcopy data, but valuable lessons from the one have been applied to the other. With access to the data, it is hoped that scholars generally will be able to apply information technology to the data, to better present the data and understand its significance. In a hardcopy atlas, all the information is there, in some sense. However, the relevant information for any particular user could be spread over hundreds of maps. The comparison of relationships between one map and another is difficult, and the simultaneous comparison of many maps is very difficult. Hardcopy atlases can and do provide interpretive maps (i.e. maps that pull together sets of data), but only the author/editor gets to select the relationships that are shown (and even that may be constrained by issues of size and cost).	atlas transformation language;image scaling;map;multidimensional scaling;stan;texture atlas	Sheila M. Embleton;Dorin Uritescu;Eric S. Wheeler	2007		10.1515/9783110894219.87	romanian;natural language processing;automatic identification and data capture;speech recognition;computer science;artificial intelligence	DB	-68.89777205255372	-19.96776395637413	80250
4f4f91857f75a97a9642d96d60a19ae7ae4832db	little science, big science revisited	citation analysis;empirical study;physique;linear functionals;physics;analyse citation;productivite auteur;indicateur recherche;sociology of science;research indicator;scientific knowledge;author productivity	One of the basic dependent variables in the sociology of science is the rate at which scientific knowledge advances. Sociologists of science have in the past assumed that the rate of scientific advance was a function of the number of talented people entering science. This assumption was challenged by Derek Price who argued that as the number of scientists increased the number of “high quality” scientists would increase at a slower rate. This paper reports the results of an empirical study of changes in the size of academic physics in the U. S. between 1963 and 1975. In each year we count the number of new Assistant Professors appointed in Ph. D.-granting departments. During the early 1960s there was a sharp increase in the size of entering cohorts followed by a sharp decline. A citation analysis indicates that the proportion of each cohort publishing work which was cited at least once in the first three years after appointment was relatively constant. This leads to the conclusion that the number of scientists capable of contributing to the advance of scientific knowledge through their published research is a linear function of the total number of people entering science.	citation analysis;display resolution;linear function	Stephen Cole;G. S. Meyer	1985	Scientometrics	10.1007/BF02017160	mathematics education;social science;philosophy;epistemology;computer science;data mining;mathematics;sociology;operations research;law;citation analysis;world wide web;sociology of scientific knowledge	ML	-77.23301213137488	-23.00065855406981	80345
689410f96bd1eb8c60401611a203d819d5f73355	"""""""cactus systems"""": a computer science practicum that is more than a capstone"""	computer information systems	This paper describes a project-oriented Computer Science or Computer Information Systems Practicum course. This particular course differs in several ways from other similar courses. First, it is taught outside of the normal academic year. Second, a real attempt is made to simulate the environment in which a computing professional would be expected to work. Third, all of the projects are taken from the real world and are sponsored by individuals who actually want the work done. Fourth, it has components designed to teach the students how to make informal and formal public speeches on subjects with which they are familiar. Finally, it has components designed to help the students look for jobs after graduation. This course has worked well at a major engineering school and at a small regional liberal arts school.	capstone (cryptography);computer science;management information system;simulation	Charles P. Howerton	1988		10.1145/52964.53007	simulation;computer science;software engineering;information system	Logic	-64.59229925538233	-22.82862094626756	80363
5a7442197f42cf53c1e4977616a26cd36318a28a	social networks and archival context: people and cultural heritage			social network	Daniel Pitti;Worthy Martin	2016			political science;anthropology;social network;cultural heritage	HCI	-65.35005496147282	-9.892681432359167	80367
6cc38561556aa0c59ffc03031dc7cf1169c7b537	follow the fox to renardus: an academic subject gateway service for europe	recurso internet;project;service information;union europeenne;internet resource;proyecto;cooperation;information scientifique technique;ressource internet;cooperacion;project work;biblioteca electronica;information society technologies;information culturelle;servicio informacion;projet renardus;electronic library;scientific technical information;information service;projet;informacion cientifica tecnica;european union;union europea;bibliotheque electronique	Renardus is a collaborative project of the EU's Information Society Technologies programme with partners from national libraries, university research and technology centres and subject gateways Europe-wide. Its aim is to build a single search and browse interface to existing quality-controlled European subject gateways. The project will investigate related technical, information and organisational issues, build a pilot system and develop a fully-operational broker service. This paper provides an overview of the project, work in progress and anticipated results and outlines the opportunities and benefits for future collaboration in developing the service.	guide to information sources	Lesly Huxley	2000		10.1007/3-540-45268-0_48	project;operations research;world wide web;cooperation	Crypto	-71.93378591569778	-23.160294927385785	80705
80e235ac97dbf8e4ef4b86a1cf01b7eecb3e704d	the it thesis project: a slow beginning	information technology research;document analysis;community participation;research agenda;information technology;rest of the world;graduate student	In 2009 a repository was created to hold the body of masters theses and dissertations for IT degrees across the country. Before this, there was no central location where researchers could easily access these documents. Analysis of this repository has helped propose a research agenda for the IT discipline. The themes of IT research themselves were not surprising, but gathering the research to populate the repository did yield some surprising results. Much of the work done by IT graduate students simply is not readily accessible to the rest of the world. This makes it appear as though there are less IT graduate students than we thought, and the repository is currently only populated with just over 100 theses and dissertations.  The presentation of the repository at SIGITE 2009 yielded good community support. There have been enhancements and upgrades for the repository in the last year, but we have as yet seen little community participation in the actual submission of IT research.	population	Christopher Cole;Joseph J. Ekstrom	2010		10.1145/1867651.1867662	computer science;engineering;knowledge management;electrical engineering;sociology;management;law;information technology;pedagogy	HCI	-68.71981036764222	-19.866746763024956	80771
a9fca30355dc13ac73c4906d161872c41af0aeaa	synergies, ojs, and the ontario scholars portal	array	This paper introduces the CFI-funded project Synergies: The Canadian Information Network for Research in the Social Sciences and Humanities, and two of its regional components. This four-year project is a national distributed platform with a wide range of tools to support the creation, distribution, access and archiving of digital objects such as journal articles. It will enable the distribution and use of social sciences and humanities research, as well as to create a resource and platform for pure and applied research. In short, Synergies will be a research tool and a dissemination tool that will greatly enhance the potential and impact of Social Sciences and Humanities scholarship. The Synergies infrastructure is built on two publishing platforms: Érudit and the Public Knowledge Project (PKP). This paper will present the PKP project within the broader context of scholarly communications. Synergies is also built on regional nodes, with both overlapping and unique services. The Ontario region will be presented as a case study, with particular emphasis on project integration with Scholars Portal, a digital library.	archive;digital library;synergy	Michael Eberle-Sinatra;Lynn Copeland;Rea Devakos	2008			array data structure;computer science;data science;advertising;programming language;world wide web	DB	-69.26377725346553	-16.42579140731488	80860
3942d9d06c8b58d7bed2ddc61d660e3df82d1294	library web sites in pakistan: an analysis of content	libraries;bibliotheque;site web;analisis contenido;evaluation performance;study design;performance evaluation;pakistan;evaluacion prestacion;qualite service;navigation information systems;content analysis;enquete;foreign countries;quality assessment;internet;worldwide web;asie;web sites;encuesta;sitio web;analyse contenu;public libraries;survey;biblioteca;academic libraries;library;service quality;government libraries;web site;asia;surveys;calidad servicio	Purpose – The purpose of this paper is to investigate library web sites in Pakistan, to analyse their content and navigational strengths and weaknesses and to give recommendations for developing better web sites and quality assessment studies.Design/methodology/approach – Survey of web sites of 52 academic, special, public and national libraries in Pakistan based on a 77‐item checklist.Findings – Pakistani libraries have developed web sites over the past few years but these are few in number. No directory is available to locate library web sites and no scholarly literature has been written on this topic in Pakistan. No standards for content selection were considered in developing library web sites so they lack uniformity and often miss important features.Research limitations/implications – This research includes web sites of all types of libraries in Pakistan. Web sites with at least one independent page on a parent organisation's web site are included.Originality/value – This study is the first of its ki...	library (computing)	Saima Qutab;Khalid Mahmood	2009	Program	10.1108/00330330910998075	the internet;library;content analysis;web standards;multimedia;clinical study design;law;world wide web;service quality	ML	-73.44564493920069	-23.80095272586314	80907
9a4ba291694ff68ac49f015e353d320eae26811e	the present and future of internet search		Search engines were crucial in the development of the World Wide Web. Web-based information retrieval progressed from simple word matching to sophisticated algorithms for maximizing the relevance of search results. Statistical and graph-based approaches for indexing and ranking pages, natural language processing techniques for improving query results, and intelligent agents for personalizing the search process all show great promise for enhanced performance. The evolution in search technology was accompanied by growing economic pressures on search engine companies. Unable to sustain long-term viability from advertising revenues, many of the original search engines diversified into portals that farm out their search and directory operations. Vertical portals that serve focused user communities also outsource their search services, and even directory providers began to integrate search engine technologies from outside vendors. This article brings order to the chaos resulting from the variety of search tools being offered under various marketing guises. While growing reliance on a small set of search providers is leading to less diversity among search services, Communications of AIS, Volume 5 Article 8 3 The Present and future of Internet Search by W. Lucas, W. Schiano, and K. Crosett users can expect individualized searching experiences that factor in personal information. The convergence of technology and business models also results in more narrowly defined search spaces, which will lessen the quantity of search results while improving their quality.	algorithm;directory service;information retrieval;intelligent agent;natural language processing;outsourcing;personally identifiable information;portals;relevance;web search engine;world wide web	Wendy T. Lucas;William T. Schiano;Katherine Crosett	2001	CAIS		management science;engineering;intelligent agent;search engine;search engine indexing;information retrieval;the internet;outsourcing;personally identifiable information;directory;business model	Web+IR	-69.2161138406419	-22.48620077939992	81220
e94c386eb596468325da092b2d54e488bc2d4178	prison libraries the scandinavian way: an overview of the development and operation of prison library services	bibliotheque;europa;scandinavia;new technology;text;development;library and information services to incarcerated persons global perspectives;library service;desarrollo;milieu carceral;service;paises escandinavos;developpement;medio carcelario;carceral environment;europe;public libraries;biblioteca;organizational structure;library;servicio;pays scandinaves	Economic and organizational structures are important factors that affect how, and to what extent, prisoners receive satisfactory library services. In the Scandinavian countries, the services offered are largely dependent on existing national policy. In Norway, changes in the organization and financing of prison library services over the past thirty years have led to improved service. During these years, there have also been changes to public library services, largely as the result of new technology. Such changes pose challenges to government authorities at all levels, as well as to individual prison libraries, in regard to what services should encompass and how they are provided. The development in Norway in the area of prison libraries and the challenges these libraries face are presented and compared with the prison library situation in the neighboring countries of Sweden and Denmark. The main emphasis is placed on national policy and organization, with particular focus on the positive developments of recent years in Norway. Background The prison library is often referred to as a “normal zone” for prisoners, and the services and resources offered are very important for their rehabilitation, education, and socialization. For many prisoners, the library functions as a window to the world in an otherwise monotonous existence behind the walls. The library and the librarian bring mental stimulation from the outside into the prisons in the form of literature, culture, current events, and knowledge, which provide opportunities and gateways to a richer life. However, for the library to function as the “normal” room 474 library trends/winter 2011 in the prison, fundamental economic and organizational structures must be in place. National policy, economy support, and service structure are important factors that affect how, and to what extent, prisoners receive satisfactory library services. The Scandinavian countries share many similarities as neighboring countries with small populations, situated in Northern Europe. Sweden is the largest country with 9.3 million inhabitants, followed by Denmark with 5.5 million, and Norway with 4.8 million. These countries have a long common history during which, at various times, they have been unified with each other, the last union being between Norway and Sweden, which ended in 1905. The languages are so alike that people understand each other’s spoken and written words, and there are many similarities in the respective political systems. Close cross-border cooperation also exists in many public and private sectors. Even though the Scandinavian countries may appear very similar from an international perspective, differences still exist. Population density, for example, is more than six times higher in Denmark than in the two other countries, with 128 inhabitants per square kilometer: Norway having a population density of fifteen and Sweden twenty inhabitants per square kilometer. There were approximately 14,000 prisoners in Scandinavian prisons on an average day in 2008. Just under 3,500 of these were in Norwegian prisons. These figures show a relatively low number of prisoners in the three countries compared to the incarceration rates in the rest of the world: Sweden has seventy-four prisoners per 100,000 inhabitants, Norway sixty-nine, and Denmark sixty-three. In comparison, England and Wales have 153 prisoners per 100,000 inhabitants, Germany 89, and France 96 (Walmsley, 2010). Inmates in Scandinavian prisons serve their sentences in a total of 219 facilities, including transitional housing units in Norway, with a total of 14,731 inmate places. The facilities vary greatly in size and incarceration conditions—from small entities with less than 10 places to the largest unit with 545 places, situated in Denmark. In Sweden and Norway, the largest facilities have 301 and 251 places respectively (Oslo prison is listed as a single facility with 392 places in the official statistics but consists of two separate departments, each with its own library. Halden Prison, which opened in April 2010, is now Norway’s largest prison) (Kristoffersen, 2010). One unique feature of the Norwegian prison service is that it consists of relatively small prison units, some of which have fewer than twenty-five inmates. This factor, to a large extent, determines how prison library services can be organized. The staff rate is 107 employees per 100 prisoners in Denmark, 89 per 100 prisoners in Norway, and 99 per 100 prisoners in Sweden (Kristoffersen, 2010). Differences do exist as to whether certain services are staffed by the prison’s own employees or are provided by nonprison employees. The Council of Europe publishes 475 ljødal & ra/scandinavia comparative statistics in this field for their member nations, and the 2008 statistics show that the Scandinavian countries have 1.4 to 1.6 prisoners per custodial staff member, with the average of the other nations being 3.1 (Aebi & Delgrande, 2010). The main features of the Scandinavian prisons are that they are relatively small and well-staffed, and that the rate of incarceration is low compared to other countries. The provision of library services for prison inmates has long traditions in Scandinavia. In the middle of the nineteenth century, the single-cell system was introduced; in Norway this occurred in 1851 with the opening of a new penitentiary in the nation’s capital. Inmates were now isolated from each other, and a system was developed to provide them with reading materials in order to counteract the negative effects of isolation. In Denmark in the 1860s, a library was established in the prison in Vridløse, with a teacher assigned to operate it (M. Dyrbye, personal communication, March 16, 2010). In Denmark, however, the first prison libraries consisted of small collections of pietistic religious publications from the middle of the eighteenth century. Prisoners were limited mainly to these religious and edifying works until the latter half of the nineteenth century, when a wider range of both fiction and nonfiction was made available to them. At that time, library services were still considered as a reward for good behavior, and limitations were imposed on what was made available to different groups of prisoners (Källqvist, 1970). In Håndbok over norske biblioteker (Handbook of Norwegian Libraries), published in 1924 by the Norwegian Library Association, four prison libraries are mentioned, all located in the capital city. In 1948, the number of books in Norwegian prisons totaled approximately 50,000. These collections were randomly put together and consisted partly of old books that were not of current interest. But gradually more selections from the local public library began to be provided during regular on-site visits from a librarian or through deposit collections. In Sweden in 1949, public library experts proclaimed that prison libraries belonged to the most neglected areas of modern library services (“Historik: Fängelsebibliotek” [History: Prison Libraries], 2002). In Norway, it was usually members of the clergy who were responsible for building and running the library services, while inmate workers were mainly assigned to operate lending activities and provide reader guidance (Frisvold, 1977). After the Second World War, prison libraries were gradually integrated into the service structure of the Danish public library system as part of library outreach work (M. Dyrbye, personal communication, March 16, 2010). In Norway, section 58.2 of prison regulations from 1961 state that all institutions are to have a collection of books, preferably to be administrated by a senior civil servant (Biblioteket—Det normale rommet i fengselet [The Library—A Normal Room	book;entity;handbook;librarian;library (computing);library classification;population;public library;randomness;situated;socialization;total loss	Hilde Kristin Ljødal;Erlend Ra	2011	Library Trends	10.1353/lib.2011.0010	organizational structure;library science;service;economics;library;engineering;sociology;public administration;management;law;economic growth	Metrics	-71.45042256722125	-20.597441138862763	81344
78e7fbe814497a15e60e697433bb131875c8e1a0	lost in the infinite archive: the promise and pitfalls of web archives	historical studies;information retrieval;webscraping;archive;network analysis;world wide web;digital history;web archives;article	Contemporary and future historians need to grapple with and confront the challenges posed by web archives. These large collections of material, accessed either through the Internet Archiveu0027s Wayback Machine or through other computational methods, represent both a challenge and an opportunity to historians. Through these collections, we have the potential to access the voices of millions of non-elite individuals (recognizing of course the cleavages in both Web access as well as method of access). To put this in perspective, the Old Bailey Online currently describes its monumental holdings of 197,745 trials between 1674 and 1913 as the “largest body of texts detailing the lives of non-elite people ever published.” GeoCities.com, a platform for everyday web publishing in the mid-to-late 1990s and early 2000s, amounted to over thirty-eight million individual webpages. Historians will have access, in some form, to millions of pages: written by everyday people of various classes, genders, ethnicities, and ages....	archive	Ian Milligan	2016	IJHAC	10.3366/ijhac.2016.0161	humanities;network analysis;computer science;artificial intelligence;data mining;world wide web;information retrieval;digital history	NLP	-67.83367192500046	-21.88010262458114	81634
22b40d4c8b38f63e641b97213dfc607784949caf	modeling underwater structures	sensing;autonomous robots;inertial data;modeling;3 d information	Deliberate exploitation of natural resources and excessive use of environmentally abhorrent materials have resulted in environmental disruptions threatening the life support systems. A human centric approach of development has already damaged nature to a large extent. This has attracted the attention of environmental specialists and policy makers. It has also led to discussions at various national and international conventions. The objective of protecting natural resources cannot be achieved without the involvement of professionals from multidisciplinary areas. This chapter recommends a model for the creation of knowledge-based systems for natural resources management. Further, it describes making use of unique capabilities of remote sensing satellites for conserving natural resources and managing natural disasters. It is exclusively for the people who are not familiar with the technology and who are given the task of framing policies. Modeling Underwater Structures	framing (world wide web);knowledge-based systems	Michael R. M. Jenkin;Andrew Hogue;Andrew German;Sunbir Gill;Anna Topol;Stephanie Wilson	2008	IJCINI	10.4018/jcini.2008100101	computer vision;simulation;systems modeling	HCI	-74.45884793134063	-13.22777123743518	81636
2d5740f702803fa67d57e4792a5c4c167b8aa0c8	a socio-technical perspective on e-government issues in developing countries: a scientometrics approach	challenges;analyse bibliometrique;production scientifique;paises en desarrollo;administracion electronica;systems;document publie;pays en developpement;e government research;lessons;sector;scientific production;administration electronique;electronic government;socio technical theory;published document;core e government journals;developing country;bibliometric analysis;growth pattern;e government issues topics;article;africa;scientometrics approach;documento publicado;developing countries;shape of e government literature;analisis bibliometrico	Many researchers have analyzed e-government literature as a whole or a specific area to focus on statistical methodologies, lessons learnt, or problem related to the area. However, no investigation from socio-technical perspective on e-government issues, in developing countries (DCs), has been carried out. Utilizing scientometrics approach, we analyzed and synthesized e-government (EG) literature that deals with the issues/topics in developing countries from the lens of socio-technical theory (STT). 145 articles from 7 core e-government journals published during the last decade were selected and reviewed for analyzing e-government literature related to developing countries. The growth pattern of e-government literature showed that e-government studies pertaining developing countries issues/topics have rapidly increased during the last decade; covering a range of topics/issues studied from socio-technical aspects. We found that e-government literature in developing countries has somewhat adopted a balanced approach and is moving away from a merely theoretical or conceptual bases toward an empirical foundation; however, the literature lacked depth and balance in terms of issues/topics discussed and methodologies applied. In the light of the findings, strengths, limitations, and future directions for e-government research in developing countries are discussed.	e-government;eurographics;scientometrics;sociotechnical system	Gohar Feroz Khan;Junghoon Moon;Han Woo Park;Bobby Swar;Jae Jeung Rho	2010	Scientometrics	10.1007/s11192-010-0322-5	social science;developing country;management;operations research;economic growth	HCI	-74.7573987578734	-20.491784027522026	81730
eac48b386acce52fb304ad56e2f62e794fdafd0d	why haven't we mastered alignment? the importance of the informal organization structure		1 This article was reviewed and accepted by all the senior editors, including the editor-in-chief. Articles published in future issues will be accepted by just a single senior editor, based on reviews by members of the Editorial Board. 2 Sincere thanks go to Anna Dekker and Denyse O’Leary for their assistance with this research. Funding was generously provided by the Advanced Practices Council of the Society for Information Management and by the Social Sciences and Humanities Research Council of Canada. An earlier version of this manuscript was presented at the Academy of Management Conference in Toronto, Canada, in August 2000. 3 In this article, the terms information systems (IS) and information technology (IT) are used interchangeably. 4 Regardless of whether IS services are provided internally (in a centralized, decentralized, or federal manner) or are outsourced, we assume the boundaries of the IS function can be identified. Thus, the fit between the unit(s) providing IS services and the rest of the organization can be examined. and books have been written on the subject, firms continue to demonstrate limited alignment.	academy;book;centralized computing;goto;information management;information system;outsourcing	Yolande E. Chan	2002	MIS Quarterly Executive		informal organization;knowledge management;haven;business-it alignment;engineering	ML	-67.45898624186644	-17.48340077013181	81946
05b572d5e45bf5ca90ffccbf43fdd79fa4ed3424	harry and georgie	etica;computer crime;hacking;computer hacking;ethical issues;ethics;ethical issue;computing profession;internet;ethical aspects computer crime;commercial software vulnerability;ethique;commercial software vulnerability hacking community ethical issue;hacking community;delinquency;hacking computing profession;security;delinquance;ethical aspects;delincuencia;computer hacking computer security information technology processor scheduling dogs humans computer crime horses national security programming	Hacking might occupy a special position-that gray area between the darkness and the light-because it touches not only on ethical issues but also on the very nature of computing itself. Beyond the topics under discussion, all of which concerned how to exploit the flaws of commercial software, the conference strayed from its more conventional cousins in the exhibits room. The hacking community, for good or ill, is generally not perceived as inventors puttering in their workshops, individuals who accomplish their ends by working on the edge of society. Hackers do expose software vulnerabilities, but in doing so, they can put the public at risk. They have made vendors account for their actions, but they have also extorted unwarranted concessions from firms. They indeed serve as regulators, but as regulators they are accountable to no one but themselves.	commercial software;vulnerability (computing)	David Alan Grier	2008	Computer	10.1109/MC.2008.227	hacker;juvenile delinquency;the internet;ethics;computer science;artificial intelligence;information security;software engineering;management;law;computer security	HCI	-70.7534080344043	-11.474608838390147	82047
15977573792d73e151bdb526fc94c95e41cb0308	bridging the digital divide: state government as content provider, the illinois experience	digital divide	Three National Leadership Grants (NLG) (http://www.imls.gov/grants/library/lib_nlgl.asp) from the Institute for Museum and Library Services (IMLS) provide the foundation for the Program (http://finditillinois.org) at the State Library (ISL):nntGrant One: Exporting Washington Stateu0027s (October 1998-September 1999)ntGrant Two: Find-It! Illinois (October 1999-September 2001)ntGrant Three: Metadata Tools for State Collaboration (October 1999-September 2001)ntBased on the successful Government Information Locator Service (GILS) program at the Washington State Library (WSL) (http://find-it.state.wa.us/compass), the ISL began a GILS program of its own in the fall of 1999. State-level GILS projects around the country, based at state libraries and some state archives, are distilled from the federal GILS model (http://www.gils.net/). State GILS programs provide a resource discovery methodology for electronic state government information. Each program includes components for access, organization, design, standard metadata creation, state agency Webmaster education and training, and interface development. Essentially, the state libraries and archives involved in these projects act as clearinghouses for and gateways to electronic state government information.ntGrant One, awarded to the WSL, provided the ISL and three other state libraries, (Oregon, New Hampshire, and Arizona), with the model framework for starting a GILS program. Grant Two, awarded to the ISL, provided development dollars for the fledgling ISL program Illinois. Grant Three, awarded to the WSL and contracted in part to the ISL, provides funding for the enhancement of metadata interoperability and the application of a consortial subject tree.ntIn Illinois, providing access to electronic state government content is manifest not only in the establishment of the ISL GILS program, but also in the creation of the other databases that comprise the portal. Interoperability among these virtual libraries will be enhanced by the application of a single controlled vocabulary for subject searching, called the Tree. Additionally, work is underway to establish the Jessica Tree as the standard list for state GILS programs with the goal of promoting interstate interoperable subject searching.	bridging (networking)	Anne Craig	2001	First Monday		digital divide;computer science;public administration;world wide web	HCI	-66.46858025262952	-15.07420524816767	82108
70509ee2d48f00b0b5ed1d471773f6c0d9b45b30	peer review in scholarly journals: perspective of the scholarly community - results from an international study	perspectiva;revue savante;evaluacion interpares;result;perspective;scholarly journal;enquete;evaluation interpair;resultado;resultat;encuesta;survey	This summary is extracted from the report of the same title published by the Publishing Research Council (PRC) and reproduced here by kind permission of the PRC. The full report and a shorter edited version can be found on the PRC website at http://www.publishingresearch.net/PeerReview.htm. Peer review is seen as an essential component of scholarly communication, the mechanism that facilitates the publication of primary research in academic journals. Although sometimes thought of as an essential part of the journal, it is only since the second world war that peer review has been institutionalised in the form we know it today. More recently it has come under criticism on a number of fronts: it has been said that it is unreliable, unfair and fails to validate or authenticate; that it is unstandardised and idiosyncratic; that its secrecy leads to irresponsibility on the part of reviewers; that it stifles innovation; that it causes delay in publication; and so on. Perhaps the strongest criticism is that there is a lack of evidence that peer review actually works, and a lack of evidence to indicate whether the documented failings are rare exceptions or the tip of an iceberg. The survey reported here does not attempt directly to address the question of whether or not peer review works, but instead looks in detail at the experiences and perceptions of a large group of mostly senior authors, reviewers and editors (there is of course considerable overlap between these groups). Respondents were spread by region and by field of research broadly in line with the universe of authors publishing in the journals in the Thomson Scientific database, which covers the leading peer reviewed journals. The survey presents its findings in two broad areas: attitudes to peer review and current practices in peer review.	authentication;experience;peer-to-peer;verification and validation	Mark Ware	2008	Inf. Services and Use	10.3233/ISU-2008-0568	library science;social science;sociology	DB	-76.47274202031653	-22.374864864417273	82290
2a9e105ef21c16c7e7d3c6a2a8aced17026f9612	matters of design	software company;blogcacmjason hong;cacm community;blog-cacmthe communications web site;dozen bloggers;first-rate design	http://cacm.acm.org/blogs/blog-cacm<br /><br />The <i>Communications</i> Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of <i>Communications</i>, we'll publish selected posts or excerpts.<br /><br /><b>twitter</b><br />Follow us on Twitter at http://twitter.com/blogCACM<br /><br />Jason Hong considers how software companies could effectively incorporate first-rate design into their products.	blog	Jason Hong	2011	Commun. ACM	10.1145/1897816.1897820	theoretical computer science;applied mathematics;computer science	HCI	-64.89643574491586	-16.371194769439192	82525
27499c5d1fee7629b4f582593384a9de1472fa54	cocited author retrieval online: an experiment with the social indicators literature	social indicator	Abstract#R##N##R##N#One mode of online retrieval in Scisearch or Social Scisearch involves entering pairs of authors' names believed to be jointly cited by subsequent writers and retrieving papers in which cocitations occur. Six pairs were formed with the names of four authors prominent in the social indicators movement (Bauer, Duncan, Land, and Sheldon). Documents by the four were not specified. It was thought that the pair Duncan and Land would retrieve papers in which indicator-type data would be integrated with path-analytic causal modeling. All other pairs seemed likely to retrieve a “general social indicators” literature. The 298 retrieved papers confirmed expectations. It was found that 121 papers generally cited social indicators (SI) documents by the input authors and frequently had SI language in their titles. Other signs of content also identified them as papers of the SI movement. The 177 papers retrieved on Duncan and Land generally cited causal modeling documents by the input pair and were path-analytic in nature. As expected, they were relatively “harder” than the first group of papers, although the two groups are akin and are formally linked through citations in certain papers. An additional result is that papers citing at least three of the input authors tend to be overviews of the SI movement.		Howard D. White	1981	JASIS	10.1002/asi.4630320103	library science;computer science;artificial intelligence;world wide web;information retrieval	NLP	-74.5583342580206	-20.089364850233558	82614
4c5d81bdcc583380245ec8c67d5aabcdfd34cd0f	a citation analysis of the sigcse 2007 proceedings	citation analysis;very large array;computer science education;conference proceeding	This paper identifies the most commonly cited conferences, journals and books among the 1398 citations made in the 122 publications of the SIGCSE 2007 proceedings. The SIGCSE 2007 authors cited a very large array of conferences, journals and books, but the majority are only cited within a single paper. There are only a very small set of journals and conferences cited frequently. Most books cited are concerned with technical information or are textbooks. Only 2% of books are concerned with computer science education and 23% with education in general. The picture that emerges from this citation analysis is that the SIGCSE community does not have a substantial core set of educational literature. Also, the epistemology of the SIGCSE community is primarily objectivist, with a focus on content, rather than a constructivist, student-centered focus on learning.	book;citation analysis;computer science;sigcse	Raymond Lister;Ilona Box	2008		10.1145/1352135.1352295	computer science;data science;citation analysis	AI	-69.85110425127544	-21.292696654684054	82631
b7fa9f3eb10dd46b5858a7f96c276e36f59d518e	do the right (write) thing: engaging in academic library value research		204 Last fall, ACRL published the Value of Academic Libraries Comprehensive Research Review and Report. Since then, many librarians have cited the report’s literature review; even more have commented on the variety of recommendations and the breadth of the research agenda laid out in the report. The literature review captures our past efforts to explore the return-oninvestment and impact of academic libraries; the recommendations and research agenda give direction to our future work in articulating and increasing academic library value. Although the report is a static document, the library value conversation can be dynamic. The report can serve as a foundation for a lively professional and scholarly dialogue, but how might librarians engage and develop that dialogue? Certainly, ACRL can take a role in the library value conversation; it is already doing so by commencing a major initiative around academic library value issues complete with presentations, partnerships, professional development offerings, and grant proposals. But librarians, individually and in concert with others, can also engage rigorously in the value conversation. Librarians and library science faculty can collaborate; in addition, librarians can also seek research partnerships with other higher education stakeholders including institutional researchers, higher education associations, and grant funders. Large-scale, rigorous research studies can be initiated whenever possible. Such studies are often perceived as “objective”, apolitical, and generalizable to multiple academic library contexts. They can also deliver the holy grail of “statistical significance.” However, large-scale studies represent Do the Right (Write) Thing: Engaging in Academic Library Value Research	librarian;library (computing);library science;lively kernel	Megan Oakleaf	2011	C&RL		computer science;media studies;management	HCI	-71.7329039448284	-19.108987544479767	82919
e43698664c6887be339f7d9bcd5a1ef4c84195ea	political activity and international computer networks	text processors;compiler generators;computer network;language design	"""Excerpt from a Croation email ttl.3.sag.Z: """" l-he use of the network for political and religious activities is forbidden. """" But EARN has not yet discouraged the political activism discussed here. Excerpt from a Serbian email mes-sag.5 During the August 1991 attempted coup in the Soviet-(dis?)Union, the international email networks were used to send and redistribute many political messages. This was universally seen as a clear case of network use to help good fight evil. Evil was quickly defeated, and nobody protested its vilification in all those rmail messages. The Yugoslavian situation is not so clear-cut. As the preceding excerpts (and my own visit to several parts of that country) indicate, there is considerable disagreement on the locus of good and evil, truth and lies. In both cases, many highly charged and politicized messages passed through the networks. One senior Serbian computer scientist (no< the author of the quad meb-sage), unhappy that his side is usually portrayed as evil, formally protested that European Academic Research Network (EARN) has been inappropriately used for political purposes. Have the networks been inappropriately used? Dn or should the organizations running the networks have policies on this matter? At least two important network management organizations have policies that arguably apply. Corporation for Research and Educational Networking (CREN), which manages U.S. Bitnet and CSNet, has an """" Acceptable Use Policy """" (AUP). EARN has a """" Code of Conduct """" (CC). The AUP does not explicitly deal with political activity, but contains two statements that could be interpreted in this context: (1) """" CREN networks are to facilitate the exchange of information consistent with the academic, educational and research purposes of its members """" ; (2) """" It is the responsibility of member representatives to contact the CREN Board, in writing, regarding questions of interpretation. Until such issues are resolved, questionable use should be considered 'not acceptable. """" ' Political activity, however that may be seen in the eyes of different beholders, is arguably questionable under (1). The CC is explicit. It states that Should such use be condemned or discouraged? Why should it be, or why should the effort be made to do so unless it interferes with normal network use or other reasonable restrictions? Would it have been """" right """" to have forbidden colt leagues from Moscow or Tallinn or Dubrovnik or Belgrade! from using one of their few (or perhaps only) means …"""	acceptable use policy;computer scientist;email;locus;rational clearcase	Seymour E. Goodman	1992	Commun. ACM	10.1145/129630.129640	computer architecture;compiler;computer science;theoretical computer science;compiler construction;programming language;computer network programming	Networks	-64.71096173157062	-19.767260771130328	82976
d8cb32d259396a25ab27e04b3d41acf3f482be4a	design, innovation and respect in the global south	computing;library and information sciences	The aim of this panel is to facilitate a discussion on the practice of interaction design in the Global South in the context of current global discourses on development, as particularly evidenced in the United Nations’ post-2015 development agenda. The panel will generate a thought-provoking debate based on different experiences and cultural and political reflections on designing and innovating in the Global South.	amiga reflections;experience;interaction design	José L. Abdelnour-Nocera;Chris Csikszentmihályi;Torkil Clemmensen;Christian Sturm	2015		10.1007/978-3-319-22723-8_79	computing;computer science;operating system	HCI	-77.4091778631191	-11.072262694162834	83017
adfb67da47ca49e76338c01a604f78e0e79ebdef	risk management: the economics and mor ality of safety revisited	cause of death;risk management;common value;risk communication	The introduction to the proceedings of the Royal Academy of Engineering 2006 seminar on The Economics and Morality of Safety concluded with a list of issues that were “worthy of further exploration”. I have reduced them to the following questions: • Why do moral arguments about ‘rights’ persist unresolved? • Why can risk managers not agree on a common value for preventing a fatality? • Why do governments and the media react differently to different causes of death? • Why do some institutions profess to be pursuing zero risk, knowing that achieving it is	academy;risk management	John Adams	2009		10.1007/978-1-84882-349-5_2	actuarial science;political science;socioeconomics;social psychology	AI	-68.93353400991758	-12.988885637005858	83045
273cc6c7b94fb5daab86af727786f57c16d166b6	vampire bats: trust in privacy	social network services;trust;privacy legislation ontologies data privacy law computational modeling social network services;legislation;trust privacy;application framework;trust model;privacy protection;law;privacy formalizations;computational modeling;data privacy;vampire bats;ontologies;natural science;trust formalizations;security of data;privacy;trust formalizations vampire bats privacy formalizations;policy development	Trust and privacy are ancient social concepts. Work on formalizing trust dates back to the mid-nineties, while work on formalizing privacy is in its infancy. The two concepts have a number of similarities including considerations of information type and sensitivity to inform actions, relationship between the communicating parties, and the context or purpose for communication. There are some key differences. Privacy, unlike trust, is legislated. In Canada, there are also a number of regulations, directives and policies that come along with the legislation. Trust, on the other hand, is the Wild West; almost anything goes. Early attempts at formalizing privacy have been largely restricted to P3P initiatives and other policy developments. Not only have they been largely ignored by the user community, but also because of the limited scope in application seem to fail to actually enable privacy protection. On the other hand, early trust models have taken a different approach. Instead, using a natural science approach and artificial agents, trust is circumscribed, simple and most importantly - repeatable. In the context of failed attempts at formalizing privacy through policy, learnings from trust can be utilized to advance the computational notion of privacy protection. This paper takes the work on formalizing privacy in a much needed new direction by examining the potential of an appropriate and applicable framework for privacy based on extant trust formalizations. It proposes a formalization for privacy can be based on trust, and would outline the types of privacy, examine privacy based decision-making, and explore the applicability of the agents as appropriate representations of people in the computational environment.	intelligent agent;p3p;privacy;sensitivity and specificity;virtual community	Tracy Ann Kosa	2010	2010 Eighth International Conference on Privacy, Security and Trust	10.1109/PST.2010.5593227	privacy software;natural science;information privacy;privacy by design;computer science;internet privacy;privacy;computer security	Security	-73.57007963990293	-11.086353352797452	83083
1c361467cbf085a21e851264caa819e70113b946	censorship challenges to books in scottish public libraries	intellectual freedom;sex education;books;library services;foreign countries;libraries general;reading material selection;censorship;public libraries;scotland;librarians;collection development	Censorship challenges to books in UK public libraries have received renewed attention recently, partly due to press coverage regarding libraries stocking ‘extremist’ material. Guidelines for dealing with these types of challenges and the general management of controversial material have been published; however there has been little recent research into the phenomenon of challenges to books in the UK. In light of this, the current study sought to establish the incidence of censorship challenges to books in Scottish public libraries in the years 2005-2009 and the actions taken in response to these challenges, using Freedom of Information requests submitted to Scottish local authorities. It was found that eight local authorities in Scotland had received formal censorship challenges to books, with a total of fifteen challenges throughout the country. The most common action taken in response to these challenges was for the book to be kept in stock in its original position with the rationale for this explained to the complainer, with the second most common action being taken to move the title to another section of the library. Two books were removed from the library in response to a censorship challenge. The largest numbers of challenges were made against books on the basis of sexual material. While these responses generally agree with research from other countries, the rate of challenges to books in Scottish public libraries is lower than that of North America	book;design rationale;freedom of information laws by country;incidence matrix;library (computing);public library	Kelly Taylor;David McMenemy	2013	JOLIS	10.1177/0961000611435254	library science;social science;censorship;media studies;sociology;management;law;world wide web	Security	-72.14703870336112	-20.494898514375354	83117
25012a855b0d9e26d3545ebcb067f86977ab040a	security &amp; privacy week interviews, part 2		IEEE Security &amp; Privacy met with several interesting speakers at Security &amp; Privacy Week (SPW) 2016 in Darmstadt, Germany. This issue features Susan Landau, professor of social science and policy studies at Worcester Polytechnic Institute; Farinaz Koushanfar, professor of electrical and computer engineering at the University of California, San Diego; Vesselin Popov, business development director at the University of Cambridge Psychometrics Centre; and Negar Kiyavash, professor of electrical and computer engineering at the University of Illinois at Urbana-Champaign. They discuss a variety of issues, including governments' role in individuals' privacy, hardware breaches, psychology and digital living, and data analytics and privacy.	ampersand;computer engineering;network security;privacy;susan landau	Ahmad-Reza Sadeghi;Ghada Dessouky	2016	IEEE Security & Privacy	10.1109/MSP.2016.131		Security	-63.37435531659464	-14.773721280232815	83192
8fd32b69ece7c7a1c856837317f16f32f0af87c3	"""""""new beauties"""": the design of british public library buildings in the 1960s"""	library design;text;welfare state;public libraries	In 1960 the architectural correspondent of London’s Times newspaper praised contemporary architects for having evolved what he called “new beauties”: attractive, modernist buildings created out of new techniques and approaches to style and structure. This study features a particular set of these “new beauties”: public library buildings of the 1960s, both large and small. In the 1960s, public library design finally broke free from its Victorian heritage. The new library buildings that appeared in this decade, clothed as they were in the architectural modernism of the time, reflected an age of optimism and intended modernization, when faith in the postwar welfare state was at its height, when hopes for technological and economic renewal were running high, and when the outlook of professional librarians was becoming increasingly progressive. Introduction: From Old to New In 1960 the Royal London Borough of Kensington, a salubrious district of central London, opened a new central library (Kensington designated “Royal” in 1901, fulfilling a wish by Queen Victoria to honor her birthplace) (Official Architecture, 1960, pp. 506–509). The library’s architect was Vincent Harris, who a generation earlier had designed the simplified-classical Manchester Central Library (1934). For Kensington he produced a substantial library in an “English Renaissance” style, in keeping with the Borough’s esteemed status (fig. 1). At the time, the building was the largest public library in London. The previous year, in response to the Kensington design, students from the nearby Royal College of Art had formed a protest group called Anti-Ugly Action (AUA). They had marched on the Borough’s town hall and the new library chanting “it’s an 72 library trends/summer 2011 outrage,” wielding placards saying “Fake Buildings Are A Sin” and “Britain Builds Blindly.” They held a public meeting at Kensington Town Hall to gain further support against the library’s pseudoclassical style (Daily Telegraph [1959, January 26; 1959, February 5]; Manchester Guardian [1959, February 5]).1 The AUA also involved itself in the campaign opposing the planned new library in Guilford city center, a stone-clad, neo-Georgian design—in keeping with nearby Jacobean buildings but out of step with the rise of modernism. Yet, illustrating that not everyone was a convert to modernism, the AUA was itself the subject of criticism from those who admired the Guilford Public Library plan and who lambasted the students’ preference for “acres of glass and concrete” (in the context of architecture, the words modernism and modernist are used in this article rather than the word modern, which carries the connotations of design that is merely new, up-to-date, or recent) (Mervyn, 1959). The design of Kensington Central Library was in marked contrast to the many contemporary libraries being built or planned at the time. The majority in the worlds of both libraries and architecture would have viewed the Kensington design as backward-looking, its “opulence and heaviness . . . suggest[ing] a wealth we have come to dissociate from the building of our affluent age” (Platts, 1967, p. 475). Commentary on the new library was offered by the architectural correspondent of the Times who wrote, shortly after the library was opened, that it was “a manly type of building”; it was an example, he opined, of dignified architecture, its neoclassical idiom having been “forcefully handled” by a veteran architect “who was designing important buildings in similar style almost half a century ago.” However, within this apparent compliment lurked a hidden slight. Indeed, he went on to comment that the dressing up of an admittedly well-planned, modern, steel-framed building was “somewhat ridiculous,” especially in light of how much contemporary architects had done “to evolve new beauties [my emphasis] out of new techniques and structures” (“New Library,” 1960). This study features a particular set of these modernist “new beauties” of the 1960s—public library buildings, both large and small. Breaking free of their Victorian design heritage, the new public library buildings of the “Swinging Sixties” (Sandbrook, 2006) reflected an age of optimism and modernization, when faith in the postwar welfare state was at its height and when the outlook of professional librarians was becoming more progressive. The Modernization of Britain: “White Hot” Technology and the Welfare State The election of a radical Labour government in 1945 resulted from the “equality of sacrifice” of the war years and the promise of egalitarian reconstruction that accompanied it (Addison, 1975). A welfare state was 73 “new beauties”/black forged out of the pragmatic needs of a warfare state. Writing in 1945, the industrialist and politician Ernest Simon, famous for his slum-clearing work in Manchester, expressed the belief that in twenty years Britain could be rebuilt: “Let us be inspired with enthusiasm for a great national plan of reconstruction. Let us determine to plan and build healthy and pleasant cities, the finest the world has known, and a monument to the ideals and to the efficiency of British democracy” (Simon, 1945, pp. 7, 223). In 1942, the Fabian Socialist G. D. H. Cole wrote of the “fundamental resolve to rebuild our nation in the spirit in which we [effectively] began fighting the war in 1940” (p. 12). The spirit of reconstruction spilled over into the library world. The desire to rebuild the public library system was encapsulated in a landmark survey and report in 1942, researched and authored by Lionel McColvin, Britain’s most prominent librarian of the time. In terms purely of bricks and mortar, it was recognized that “the destruction by bombs of the Central Library at Coventry, and the similar destruction elsewhere, raises the problem of rebuilding our libraries after the war . . . whether they be destroyed by enemy action or not, they will have to be moved into new buildings or radically enlarged and reconstructed in the near future” (“Library planning,” 1942). Figure 1. Kensington Central Library (1960), rear view. Reproduced with permission of the Royal Borough of Kensington and Chelsea. 74 library trends/summer 2011 However, the regeneration of Britain’s library buildings, including the central library in Coventry (more about this later), was something that had to wait for a generation after the war. The desire to build a better postwar world soon manifested itself in the construction of a welfare state comprising the nationalization of key sectors of the economy, a commitment to Keynesian demand management to avoid the mass unemployment of the past, the provision of a national health service free at the point of use, fair welfare benefits, an expanded public education system, and a large-scale program of state housing (Hill, 1993; Lowe, 2005). Regarding the last, local authorities were given new powers to clear slums and bomb-damaged areas, and expand public investment in urban regeneration as well as in the construction of entirely new settlements, the “new towns” (Maxwell, 2004, p. 1361; Saint, 1988). All this was inaugurated in six short years before the return to power, in 1951, of the Conservatives who, although scaling down government expenditure, nonetheless accepted many of the previous government’s reforms and established a consensus around the need for a welfare state of some kind (Kavanagh & Morris, 1989); even if later Conservative administrations sought always to contain it and adapt it to Conservative values (Glennerster, 1995). In design terms, the intended modernization of the nation—the aim, literally, of “building a better tomorrow” (Elwall, 2000)—had been flagged during the war by posters issued by the Army Bureau of Current Affairs, which disseminated educational material to the armed forces to prepare those serving for the postwar world. Three posters, designed by Abram Games, depicted the new Britain for which people were fighting. Each carried the image of a modernist building: a block of flats (the influential Kensal house design, 1937), a college, and a health center. In 1951 came the Festival of Britain (mainly staged on the south bank of the River Thames in London), which aimed to promote better-quality design in the redevelopment of Britain’s town and cities. The Festival, held as a “tonic to the nation” (Elwall, 2000, p. 10) at a time of severe austerity, was a key moment not only in postwar aspirations for meaningful reconstruction but also in postwar architecture, a moment “when modern design as a whole was introduced to a more or less accepting public as a matter of daily routine” (Powers 2005, p. 231). By the mid-1950s, modern architecture was no longer the exclusive interest of a small elite group of pioneers. It had won broad acceptance and even approval. Although modernism had made in-roads before the war, it was now fully established and had become a symbol of postwar reconstruction, in particular of the phase of modernization that got underway in the years approaching 1960	after the war;harris affine region detector;image scaling;librarian;library (computing);library classification;maxwell (microarchitecture);microsoft outlook for mac;mortar methods;neo geo;placard;public library;renaissance;the times;towns;victoria (3d figure);xfig	Alistair Black	2011	Library Trends	10.1353/lib.2011.0033	welfare state;psychology;library science;economics;computer science;engineering;sociology;management;law;economic growth		-64.1938168400622	-20.270471092900813	83251
2ea61b2b2fbcd56ba1bc26b148622c9a9b1b1a24	"""second commentary on """"xml and the new design regime"""""""	data model;data modelers;xml;information need;communication channels;designers	Focusing on the necessity that a communicative channel must respect the information needs and limitations of a human audience, the author asserts that those limitations prevent any channel, including XML, from achieving ultimate communication goals.	information needs;xml	Mir Haynes	2002	ACM Journal of Computer Documentation	10.1145/602364.602371	information needs;xml;data model;computer science;knowledge management;data mining;database;channel	Security	-72.49600428483264	-18.107654088970133	83299
28cd677c9c0ea2ce0e362ec0204ea6e826d3ab13	a few lessons from the mezzo project	004;static type systems side effects aliasing ownership	With Mezzo, we set out to design a new, better programming language. In this modest document, we recount our adventure: what worked, and what did not; the decisions that appear in hindsight to have been good, and the design mistakes that cost us; the things that we are happy with in the end, and the frustrating aspects we wish we had handled better.	programming language	François Pottier;Jonathan Protzenko	2015		10.4230/LIPIcs.SNAPL.2015.221	real-time computing;simulation;engineering;operations management	PL	-63.27478616057058	-23.366367626525296	83412
dff513a3654e7d215a1bafcbf4ad0ca2d17b4183	digital humanities in latin american studies: cybercultures initiative			cyberculture;digital humanities	Angelica J. Huizar	2018			latin american studies;digital humanities;media studies;political science	HCI	-63.054960031844324	-11.215934715675589	83524
63766e189bcf42b53e262a568c19be01d3facb25	recognizing the relevance of is research and broadening the appeal and applicability of future publications	selected works;bepress;is research	Highly applicable research is done not only by some IS faculty members, but also by software firms, consulting firms, and other organizations whose products and services depend on IS research they perform. The applicability of IS research done by academics is evident in the concepts and explanations in many textbooks. There should be little surprise, however, that practitioners who expect readability and direct applicability have little patience for IS publications shaped by the concerns and expectations of academia. It might be possible to broaden the acceptance and relevance of IS research publications by distributing them in both a short version designed to demonstrate relevance and a long version designed to demonstrate rigor and provide supporting details.	relevance	Steven L. Alter	2001	CAIS		social science;operations research	Web+IR	-72.92705698797378	-16.233062315119614	83547
5833a8f7e5b35d092b74acd509875dc62ace0e02	president's letter to the acm membership: the journal	executive committee;information processing	A great deal of concern has been expressed to me and to members of the Executive Committee and the Editorial Board about the new status of the Journal. Obviously, the concern is not over the $3 needed to subscribe to the Journal in the future. Those who are worried about the change, which substituted the new Computing Surveys for the Journal, see it as one more step in a process of change within ACM that has been going on for some time. They argue that the Association began as an academic, scientific, professional organization concerned with the more formal mathematical and scientific aspects of information processing, and their concern that the organization has changed character is quite legitimate.	acm computing surveys;information processing	Bernard A. Galler	1969	Commun. ACM	10.1145/362848.362849	information processing;computer science;management;operations research	Graphics	-64.74803613934301	-17.912619790197244	83828
4e688de0a41b7faa81d4b3ff8b254c0dd838ac78	agile methods in biomedical software development: a multi-site experience report	computers;agile methods;software;medical informatics;database management systems;hospitals;databases genetic;hospital information systems;software engineering;agile development;experience report;computational biology bioinformatics;support system;dynamic environment;qualitative study;agile methodologies;software development;algorithms;humans;combinatorial libraries;multicenter studies as topic;software design;computational biology;computer appl in life sciences;systems integration;programming languages;diffusion of innovation;microarrays;bioinformatics;automation	Agile is an iterative approach to software development that relies on strong collaboration and automation to keep pace with dynamic environments. We have successfully used agile development approaches to create and maintain biomedical software, including software for bioinformatics. This paper reports on a qualitative study of our experiences using these methods. We have found that agile methods are well suited to the exploratory and iterative nature of scientific inquiry. They provide a robust framework for reproducing scientific results and for developing clinical support systems. The agile development approach also provides a model for collaboration between software engineers and researchers. We present our experience using agile methodologies in projects at six different biomedical software development organizations. The organizations include academic, commercial and government development teams, and included both bioinformatics and clinical support applications. We found that agile practices were a match for the needs of our biomedical projects and contributed to the success of our organizations. We found that the agile development approach was a good fit for our organizations, and that these practices should be applicable and valuable to other biomedical software development efforts. Although we found differences in how agile methods were used, we were also able to identify a set of core practices that were common to all of the groups, and that could be a focus for others seeking to adopt these methods.	agile software development;bioinformatics;document completion status - documented;engineering;experience;informatics (discipline);iteration;iterative method;numerous;software engineer;support system;benefit;teams	David W. Kane;Moses M. Hohman;Ethan G. Cerami;Michael W. McCormick;Karl F. Kuhlmman;Jeff A. Byrd	2005	BMC Bioinformatics	10.1186/1471-2105-7-273	feature-driven development;health informatics;personal software process;verification and validation;agile unified process;extreme programming practices;agile usability engineering;computer science;bioinformatics;package development process;software development;requirement;iterative and incremental development;software construction;agile software development;software documentation;empirical process;lean software development;goal-driven software development process;software development process;software peer review	SE	-69.73402029170116	-17.207125613848024	83886
57fe2bcd1675673e661e9337687caad0655d166d	library buildings: planning and programming	library design;text	There are many books and articles dealing with planning a library building project. This article presents the need for project teams, describes their composition, and presents their role in the planning process. The role of the building consultant is outlined and the qualities desired in the building consultant presented. The space estimation process is presented, including charts of space required for selected library equipment. The building program document is described. Several examples from a building program are presented to illustrate the types of information found in these documents. The importance of inclusivity throughout the planning process is emphasized as well as the importance of including enough space for future expansion. Introduction Any library building project, whether it is a renovation of the current facility, the expansion of the current facility, or the building of a new facility is a major undertaking. For many library staff members, board members, or members of the community served by the library, it is a once in a lifetime experience. For the end result to be something that the user community will be proud of and use effectively for years to come, there must be considerable planning accomplished prior to the first shovel of earth or the first brick mortared into place. This article describes the planning process essential to the development of the desired new facility. For any building project to be successful, it needs the coordinated participation of a wide variety of individuals. A first step in this direction is the assembly of a project team. This team will operate for the life of the	automated planning and scheduling;book;chart;foremost;library;virtual community	John A. Moorman	2011	Library Trends	10.1353/lib.2011.0032	library science;computer science;systems engineering;engineering;knowledge management;management;world wide web	AI	-68.8551105128061	-23.090787742287198	84019
8073e60dae87fc8b93ebdb1290c00017a9712bef	towards a taxonomy for web observatories	web observatory;observatory models;taxonomy;web science;qa76 computer software	In this paper, we propose an initial structure to support a taxonomy for Web Observatories (WO). The work is based on a small sample of cases drawn from the work of the Web Science Trust and the Web Science Institute and reflects aspects of academic, business and government Observatories. Whilst this is early work it is hoped, by drawing broad brushstrokes at the edges of different types of Observatory, that future work based on a more systematic review will refine this model and hence refine our understanding of the nature of Observatories. We also seek here to enhance a faceted classification scheme (which is thought to be weak in the area of visualisation) through the use of simplified concept maps.	comparison and contrast of classification schemes in linguistics and metadata;concept map;faceted classification;systematic review;taxonomy (general);web science;while;world wide web	Ian C. Brown;Wendy Hall;Lisa Harris	2014		10.1145/2567948.2579212	web modeling;simulation;data science;world wide web;taxonomy	Web+IR	-74.86013427938404	-17.338103290378324	84310
3a04cde6bd0a84cf838ab372d452ebd286cf2a3a	international visibility of domestic scientific literature	bibliometrie;citation analysis;physique;publicacion internacional;publication internationale;bibliometria;analisis cita;fisica;litterature scientifique;physics;analyse citation;chimie;literatura cientifica;diffusion information;spanish;information dissemination;chemistry;quimica;bibliometrics;international publication;difusion informacion;espagnol;scientific literature;espanol	An indicator to quantify the international diffusion of domestic literature is proposed. It is based on the proportion of articles from a comprehensive domestic database covered by international specialised databases, and is applied to the fields of Physics and Chemistry. The trend to publish abroad in both fields is also introduced. These two indicators are studied for different Spanish sectors: university, research council and industry.	database;scientific literature	J. R. P. Alvarez-Ossorio;Isabel Gómez;María José Martín-Sempere	1997	J. Information Science	10.1177/016555159702300109	social science;bibliometrics;computer science;citation analysis;world wide web;spanish	DB	-75.27050189510591	-22.306840734687427	84314
2573b306d93a0bc746a4710075df85fd523cb3c2	long-term preservation of digital humanities scholarship	electronic media;multimedia;digital library;digital libraries;resource manager;resource management;digital preservation;design methodology	Purpose – To inform digital humanists about digital preservation metadata requirements and to inform digital librarians about the dynamic, multimedia content of digital humanities research and teaching resources that needs to be addressed by digital preservation initiatives.Design/methodology/approach – Literature‐based review of the issues.Findings – Tools to facilitate automatic and semi‐automatic capture, collection, and creation of digital preservation metadata are crucially needed to ensure long‐term preservation of digital humanities scholarship.Practical implications – Without tools to capture and create the majority of the metadata recommended to ensure long‐term preservation of and access to digital resources, the born‐digital multimedia resources created by humanities scholars are in danger of becoming unusable in the long term, nullifying years of scholarship and millions of dollars of investment by scholars, institutions, and funding organizations.Originality/value – Provides current informati...	digital humanities	Linda Cantara	2006	OCLC Systems & Services	10.1108/10650750610640793	digital transformation;digital humanities;digital library;digital asset management;design methods;computer science;resource management;multimedia;world wide web;electronic media	HCI	-70.34819975134954	-20.101196629171632	84501
ac035edd7edf91ab012fbcd7055f479281302f69	women and gender in the history of computing	time sharing computer systems;history;history time sharing computer systems scholarships information processing engineering profession chemical technology professional societies cultural differences computer industry computer science;computer industry;engineering profession;scholarships;information processing;computer science;professional societies;chemical technology;cultural differences	"""history of computing from 18th-century human computers to 21st-century dot-com entrepreneurs. Their experiences have differed from men's in obvious and subtle ways. For women, choosing a career in computing has often meant ignoring cultural messages about appropriate gender roles as well as overt discrimination. They have had to make the most of limited educational and job options and balance the competing demands of work and family. Yet the similarities between the sexes may be even more striking: Although women were not traditionally assumed nor encouraged to be interested in technical careers, they took up computing with competence and enthusiasm. They also brought skills in mathematics, language , organization, and interaction that were sorely needed in programming and computer science. By attending to women's experiences and their often unconventional paths into the field, we can better understand the profession itself: which skills were most vital in using early machines, how diverse people worked together to solve computing problems, and how perspectives other than engineering informed information processing. Women's historical involvement with computers has not been widely publicized, in part because historians of computing until recently have focused mainly on hardware. Men have been the inventors of machines through most of the history of computing, because women did not usually have access to the necessary training and resources. A preoccupation with hardware, therefore, has had the unintended effect of obscuring the role of women. More recent work by historians of computing has highlighted software development, academic computer science, and applications, areas in which a greater number of women can be found. For example, last year's IEEE Annals special issue on computer applications in libraries explored many aspects of computing in an area traditionally dominated by women. 1 The work of female """" computers """" doing hand calculations is also becoming well documented. 2 A number of biographical sources on women in computing are available. J.A.N. Lee's Computer Pioneers includes short biographies of several women. 3 Margaret Rossiter's series on Women Scientists in America includes information on women in computer science while providing a larger context for their experiences. 4 Kathleen Broome Williams's study of women scientists in the US Navy includes profiles of Grace Hopper and Mina Rees, and Margaret Murray's survey of female mathematicians of the 1950s and 1960s includes several who worked in computing. 5 G.L. Simons's Women in Computing, although not a history, provides a valuable snapshot of late …"""	apache mina;computer hardware;dot-com company;experience;gareth rees (software developer);hopper;human computer;information processing;keneth alden simons;library (computing);list of pioneers in computer science;mathematical optimization;snapshot (computer storage);software development;women in computing	Janet Abbate	2003	IEEE Annals of the History of Computing	10.1109/MAHC.2003.1253885	engineering management;engineering ethics;professional association;information processing;computer science;engineering;management;cultural diversity;information and computer science	HPC	-67.96274176613628	-23.646887024942274	84576
b1633e035c3db7b6b5e42e8c4b9cf05d1e145f83	the profession of user services	user service	Do you often feel like the red-headed stepchild of the computing profession, doing the tasks that the computing professionals would rather not do? You know, consulting, training, newsletters, documentation, and such. User Services is itself a profession. And even though it is a young one, it is essential, especially when dealing with the technology of computer resources. This paper presents the history of a typical User Services function wherein lies the beginnning of the stepchild relationship. But the paper doesn’t stop there; it goes on to suggest some steps we as members of the profession of User Services can take to claim our unalienable birthright.	documentation	John Major	1986		10.1145/324239.324253	public relations;knowledge management;multimedia	HCI	-65.1122312015142	-23.74213092933045	84729
f3a6e72714785f615d4f899b203d7d2f776e263b	agricultural recommendation system for crop protection		Abstract Pests in crops produce important economic loses all around the world. To deal with them without damaging people or the environment, governments have established strict legislation and norms describing the products and procedures of use. However, since these norms frequently change to reflect scientific and technological advances, it is needed to perform a frequent review of affected norms in order to update pest related information systems. This is not an easy task because they are usually human-oriented, so intensive manual labour is required. To facilitate the use of this information, this work proposes the construction of a recommendation system that facilitates the identification of pests and the selection of suitable treatments. The core of this system is an ontology that models the interactions between crops, pests and treatments.	recommender system	Javier Lacasta;Francisco J. López-Pellicer;Borja Espejo-García;Javier Nogueras-Iso;F. Javier Zarazaga-Soria	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.06.049	control engineering;environmental resource management;engineering;recommender system;manual labour;agriculture;crop protection;information system;pest analysis;legislation;crop	ECom	-73.45187552600618	-13.81299664214452	84770
bce4f4ce7c97feb66359e002c2c42466f65d537d	20 years in the life of a long-term empirical personal electronic filing study	archivo electronico;filing;empirical study;gestion document;gestion documento;espace personnel;experiencia personal;indexing;experience personnelle;file system;personal experience;indexation;espacio personal;classement;indizacion;personal space;clasificacion;electronic storage;archivage electronique;document management	This paper reports on the first 20 years of an empirical study of electronic support for filing and retrieving hardcopy documents and electronic files. A set of requirements for the ideal personal electronic filing system is documented, and the architecture of the system that is in use in the study is described. Sixty key questions associated with this topic are listed together with a summary of the answers found to date for each one. The paper concludes that electronic filing is feasible and effective, that the potential longevity of such systems introduces new challenges, and that it is time to start exploring how an electronic filing system can be used to support the acquisition, development and creation of knowledge.		Paul Wilson	2001	Behaviour & IT	10.1080/014492901317188499	search engine indexing;simulation;computer science;engineering;document management system;personal space;personal experience;multimedia;empirical research;world wide web	HCI	-72.77124485841333	-23.143927744307565	84945
22af8e58ddcc9553493f6c97c9ff02e4573d316c	guest editorial - creative design: scaffolding creative reasoning and meaningful learning		1 ISSN 1436-4522 (online) and 1176-3647 (print). © International Forum of Educational Technology & Society (IFETS). The authors and the forum jointly retain the copyright of the articles. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear the full citation on the first page. Copyrights for components of this work owned by others than IFETS must be honoured. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from the editors at kinshuk@ieee.org. Guest Editorial Creative Design: Scaffolding Creative Reasoning and Meaningful Learning	international standard serial number	Chien-Sing Lee;Janet L. Kolodner;Ashok K. Goel	2011	Educational Technology & Society			HCI	-64.75292693582392	-16.768110691598505	85010
ce3a2f19b29b72235664dc99a1fb940faea18a3a	early reactions to information growth	reader;communication scientifique;comunicacion cientifica;popularization;vulgarisation;popularizacion;information retrieval;nineteenth century;specialization;resumen;litterature scientifique;quantite information;specialisation;lecteur;literatura cientifica;diffusion information;resume;information dissemination;crecimiento;lector;croissance;scientific communication;difusion informacion;growth;cantidad informacion;abstract;scientific literature;information quantity	The expansion in the number of journals being published really took off in the nineteenth century. Between the beginning and end of that century, the problems of dealing with the spread of literature appearing consequently grew rapidly. The reactions of scientists to this included a move towards increasing specialisation in their research, and a higher level of organisation of their communication activities. In particular, ways of assisting information retrieval were developed then which became extremely important in the twentieth century. Two of these developments are examined here – the provision of abstracts for scientists and of popular articles for non-scientists. Parallels can be found between these two activities, as well as differences due to the different target audiences. It is noted that both appeared in print environment: an electronic environment may affect their futures differently.	futures and promises;information retrieval;parallels desktop for mac	Jack Meadows	2001	Scientometrics	10.1023/A:1012782408157	social science;resizing;epistemology;computer science;sociology	Web+IR	-71.48715117951382	-21.290130102013343	85019
c39470575028b5b017bac5a1075d4118d49ff366	dual approach to multiple authorship in the study of collaboration/scientific output relationship	citation analysis;scientometrics;empirical study;measurement;efficiency;analisis cita;scientific production;analyse citation;eficacia;medida;scientometria;scientometrie;productivite scientifique;efficacite;mesure;recherche scientifique;scientific research;investigacion cientifica	This paper presents an empirical study of the relations between scientific output and collaboration performed on two scales: (1) an individual scale, for members of a study model, and (2) a group scale, for three samples varying in the level of productivity. The rank approach was applied in the preparation of the study model resulting in the selection of a set of the most prolific authors. In the course of that process, multiple authorship problem was solved by a dual approach, consisting of “normal count” and “modified straight count” procedures. As shown by the analysis of collaborative patterns, either on individual or on group scales, scientific output is highly dependent on the frequency of collaboration among the same authors. Expressed as “the collaboration measure”, it might serve as an indicator in comparative analyses of scientific productivity in a given field of science.	rank (j programming language)	Nevenka Pravdic;Vesna Oluic-Vukovic	1986	Scientometrics	10.1007/BF02016774	scientific method;scientometrics;computer science;efficiency;empirical research;operations research;citation analysis;world wide web;measurement	NLP	-76.34797854359475	-22.79594182905289	85239
6877d662f7a3f4fb07deab48e9a11ce17d23b367	cepe '97: computer ethics: philosophical enquiry	computer ethics	T his conference was held with the cooperation ofACM SIGCAS as a joint venture .1. between the University of East London and the host, Erasmus Universiteit in Rotterdam (The Netherlands) on 11-13 June 1997. The conference was jointly chaired by Jeroen van den Hoven (Erasmus) and David Preston (East London). In this introduction we have attempted to summarise the papers that were available in full prior to the conference. We apologise for being unable to include a summary of those papers that arrived at or after the conference; timing made this impossible. We will however try to include this information in the December issue of Computers and Society. Whilst the papers presented did have privacy as a major theme a wide range of type and approach in the philosophical enquiry was evident. The two chairs are to publish the privacy papers in book form for Kluwer later this year and several of the others will constitute a special inaugural edition of a new journal. Frans Birrer (Univ. of Leiden) discussed three key problems in applying ethical and moral concepts and theories to IT contexts. He first identified that stretching the notion of computer ethics to encompass almost all social and political issues connected to IT leads to confusion. Secondly he believes that analytical ethical theory must be made more sensitive to sociological aspects concerning how systems and rules work in practice. Thirdly he called for a more serious examination of the role of experts. Philip Brey (Technical University Twente Netherlands) called for greater ethical consideration to be given to the design of computer systems. In his paper his analysis of computer systems are as elements of social structure, harboring design features that haCe political implications. He presented two classes of political features: user and information bias). Further he evaluated these biases in the context of a Rawlsian moral framework. the Self within an Information Age. Using Kierkegaard and Levinas as foundation she brought an array of wide literature together in a paper that seem likely to lead to future work. Switzerland) presented a model of ethical analysis and decision making for Computer Ethics. This model utilised earlier work of Moor and van den Hoven. As testimony to the model applicability Terryl and Petra discussed a real project in Central Europe. Jean Camp (Sandia National Laboratories, USA) discussed Web Security and Privacy. Taking American legal tradition as background, Jean looked at …	computer scientist;internet security;l. jean camp;privacy;social structure;switzerland;theory;while	David Preston;Jeroen van den Hoven	1997	SIGCAS Computers and Society	10.1145/270858.581264	social science;computer science;management science;sociology;law;computer ethics	DB	-68.44477811629852	-13.068837872355239	85384
e62b7fb00879f8996238496f3185416c5167e39a	digital archiving - the current state at the national archives of zimbabwe	preservation zimbabwe access;information retrieval systems art digital preservation history;bibliographies africa libraries;zimbabwean cultural institution cyber space environment digital preservation cultural heritage online access digital heritage preservation national archives of zimbabwe digital archiving system virtual drama arts community post modern environment digital heritage cultural asset	In the cyber space environment the overwhelming greater part of recently created information is digital. The carriers for recording information have progressed over time from memory to a digital copy. Technological innovations in computing science have now called for the progression from traditional formats to a variety of modern media and further deepened the challenges of digital preservation in houses of memory. In spite of advances in computer technology, African collecting institutions fall short to initiate digitization projects and online access to cultural heritage. This paper seeks to articulate the current landscape of digital heritage preservation at the National Archives of Zimbabwe and examine the barriers that have hindered the development of proficient digital archiving systems. Preservation of digital heritage is becoming important, as they are getting more and more popular in the virtual drama arts communities. In this post-modern environment digital heritage has gained full recognition as cultural assets in various countries. The paper further makes several recommendations on the policies, procedures and strategies for improving the state of digital preservation in Zimbabwean cultural institutions.	archive;color gradient;computer science;cyberspace	Amos Bishi	2015	2015 Digital Heritage	10.1109/DigitalHeritage.2015.7419534	humanities;library science;geography;cultural heritage;multimedia;cultural heritage management	HCI	-70.13837916015974	-19.926653493441318	85482
47430fa5ed547bd7e3c02b0899aa4aa898440db4	what does professional communication research have to do with social justice? intersections and sources of resistance	social sciences;context public policy resistance education writing communities;professional aspects;technical social dualism professional communication research social justice technical context scientific context engineering context apolitical myth ingroup bias;social sciences professional aspects;social justice positive deviance professional communication research researcher resistance	A brief review of literature indicates that professional communication scholars have had a complex, veiled relation with social justice. It is important to better understand the origins of that relation. After briefly contrasting the degree to which social justice has been explicitly integrated in professional communication and three related disciplines, this paper describes potential sources of resistance to incorporating social justice constructs into professional communication research. In professional communication, these sources of resistance are associated with ideologies that circulate within engineering, scientific, and technical contexts: the apolitical myth, ingroup bias, and technical-social dualism. In addition to exploring those three reasons why professional communication researchers generally avoid foregrounding social justice as an explicit component of their research, the paper also considers deviations from that norm by describing the work of pioneers who are integrating social justice in professional communication research. The implications of these pioneers will be discussed.	technical standard	Jon A. Leydens	2012	2012 IEEE International Professional Communication Conference	10.1109/IPCC.2012.6408592	social science;sociology;professional studies;management;social psychology;law	HCI	-75.50302633876557	-14.442686294438344	85521
c8a5cd42d2b23ccddb2ffb86e0433f549ac94a35	new acceleration technologies might not be fool's gold	cost function;turning;compression algorithms;acceleration;gold;internet;world wide web;propulsion;modems;space technology;acceleration gold propulsion compression algorithms internet modems world wide web space technology turning cost function	T he latest Web acceleration technologies have been likened to alchemy, turning the leaden speeds of dial-up access into the access rate “gold” called “broadband lite.” Within a few months of these products’ debut, large ISPs, wholesale resellers of network access, and smaller providers worldwide have adopted them. The battle to capture market share in the acceleration arena has been called a “two-horse race” between a product that features secret technology created by a longtime Internet entrepreneur (Propel) and another featuring a university professor’s new compression algorithm (SlipStream Data), which is widely regarded as the new gold standard in academic compression theories. Both technologies feature selective caching, enhanced compression, and optimized connections their inventors say could prove crucial to lowering costs and increasing network efficiency.	access network;algorithm;cache (computing);dial-up internet access;propel;pyrite	Greg Goth	2003	IEEE Internet Computing	10.1109/MIC.2003.1250577	data compression;gold;acceleration;the internet;simulation;propulsion;computer science;artificial intelligence;operating system;database;distributed computing;space technology;law;world wide web;computer security	DB	-67.53826952908138	-21.523927285073952	85700
b55bf8ecb59199804d395577f3e6102646f9df41	needed: binary bar mitzvahs and computer confirmations?	binary bar mitzvah;computer confirmation	"""The recent sentencing of Robert Tappan Morris for what amounts to reckless computing, prompts the question of what our society needs to do to develop a sense of responsibility among its young computer programmers. Morris, the scion of a professional family, was raised with serious attention to his moral development. His father, Robert Morris, the chief scientist for the National Security Agency's National Computer Security Center, moved the family to a farm, in part, he told the press, to teach his children responsibility : """"When you're a little kid and your assignment is to go out and feed the pigs or rabbits or pick up the eggs in the henhouse, it's a different environment,"""" he explained. """"What does that responsibility do for anybody? It presents a different view toward life."""" His efforts do not seem to have been enough where his son was concerned. Robert Tappan Morris released an untested program into a widely dispersed and heavily used set of computer communication networks called Internet. The program interfered with between 3,000 to 6,000 computers. According to a report by Cornell University, """"he was so focused on the minutiae of tactical issues that he failed to contemplate the overall potential impact of his creation."""" Cornell suspended Morris from his graduate studies, concluding that """"his behavior, ... can only be described as constituting reckless disregard."""" The alarming power of this one misplaced program is sobering. A modem is all it takes to get access to many computer networks. That access can quickly lead to many 20 actons? interconnecting networks, as Morris' program demonstrated so alarmingly. It would be far too simple to blame Robert Morris for his son's irresponsible actions. Robert Tapping Morris, as a graduate student, has reached the age our society considers to be adulthood. He is legally responsible for his acts. But has our society adequately communicated Morris' responsibilities to him? I suspect not. We could learn from some so-called """"primitive"""" societies when it comes to teaching our children how to become adult. """"Rites of passage"""" ceremonies have traditionally served to communicate the social expectation that young men and women will assume their roles as adults. Some of these rituals seem cruel, many of them bizarre , but they seem to work for the groups that use them. It is only in our """"modern"""" society that we forfeit the responsibility for rites of passage. The military services, colleges, and …"""	computer security;internet;minutiae;modem;programmer;robert;telecommunications network;vertical bar	Jay BloomBecker	1990	SIGCAS Computers and Society	10.1145/122403.122408	sociology;management science;knowledge management;binary number	Web+IR	-64.55239677750215	-22.438882257656584	85707
efbeaf16936bb0b3a58ff4d483c5e7565761f1e5	the arrival fallacy: collaborative research relationships in the digital humanities	digital scholarship;library and information science;digital humanities;article		digital humanities	Alix Keener	2015	Digital Humanities Quarterly		humanities;digital humanities;social science;computer science	HCI	-63.25681128921447	-11.304245858871758	85735
0788b101742d2c803d869c3c030c253aa7707e19	energy and society: challenges ahead	planning public policy potential energy technological innovation global warming communities security;social implications;energy transition;ethics;energy policy;social implications energy policy energy transition ethics;potential energy transition energy policy energy science energy security energy justice energy rights new energy systems energy costs greenhouse gas emissions technological innovation;social sciences energy security innovation management legislation	Barring unexpected developments, the next half century appears likely to experience a widespread transformation in the ways in which societies around the globe produce and consume energy. Enormous attention is being paid to a range of dimensions of this potential energy transition, from technological innovation to its implications for greenhouse gas emissions, energy costs, and dependence on technologies with catastrophic potential (as demonstrated by the BP oil spill and the Fukushima nuclear crisis). Yet, the broader implications of this transformation for individuals and communities have received less attention. Will the distribution of benefits and risks of new energy systems be similar or different in the future? Who will gain? Who will lose? How will ideas such as energy rights, energy justice, and energy security impact energy transitions? More subtly, how will social values, behaviors, relationships, and institutions change alongside changes in energy technologies? This panel will explore these topics in a conversation with a number of experts in energy science and policy.	value (ethics)	Timothy Kostyk;Clinton J. Andrews;Joseph R. Herkert;Clark Miller	2011	2011 IEEE International Symposium on Technology and Society (ISTAS)	10.1109/ISTAS.2011.7160603	energy engineering;energy policy;environmental resource management;political science;socioeconomics;economic growth;energy management	Arch	-75.56217163494384	-10.342646020294541	85830
db36f16943116fba9a3664e659ef515b4e63a9f6	the singularity is not near: slowing growth of wikipedia	population;wikipedia;socio technical system;resistance;logistic model;biological evolution;population growth;exponential growth;power law;growth;technological change;natural population	Prior research on Wikipedia has characterized the growth in content and editors as being fundamentally exponential in nature, extrapolating current trends into the future. We show that recent editing activity suggests that Wikipedia growth has slowed, and perhaps plateaued, indicating that it may have come against its limits to growth. We measure growth, population shifts, and patterns of editor and administrator activities, contrasting these against past results where possible. Both the rate of page growth and editor growth has declined. As growth has declined, there are indicators of increased coordination and overhead costs, exclusion of newcomers, and resistance to new edits. We discuss some possible explanations for these new developments in Wikipedia including decreased opportunities for sharing existing knowledge and increased bureaucratic stress on the socio-technical system itself.	extrapolation;overhead (computing);population dynamics;sociotechnical system;the singularity;time complexity;wikipedia	Bongwon Suh;Gregorio Convertino;Ed Huai-hsin Chi;Peter Pirolli	2009		10.1145/1641309.1641322	geography;artificial intelligence;operations research	Web+IR	-74.80997822562098	-13.981022605779007	85860
e8b52cc5f96bb8c0510a4af7beb5057bfc07650b	trusting records: legal, historical and diplomatic perspectives	records management;archives;record keeping	In undergoing this life, many people always try to do and get the best. New knowledge, experience, lesson, and everything that can improve the life will be done. However, many people sometimes feel confused to get those things. Feeling the limited of experience and sources to be better is one of the lacks to own. However, there is a very simple thing that can be done. This is what your teacher always manoeuvres you to do this one. Yeah, reading is the answer. Reading a book as this trusting records legal historical and diplomatic perspectives reprint and other references can enrich your life quality. How can it be?	experience;trust (emotion)	Caroline Williams	2002	Journal of Documentation	10.1108/jd.2002.58.1.136.14	data mining;internet privacy;world wide web	HCI	-63.823772723997834	-22.220090552520386	85977
81635f7d2e9dfa10a42e2e5bf79abe0d84b57704	judicial review in fundamental rights cases - how to provide guidance to judges?				Janneke H. Gerards	2007				AI	-66.64008650930313	-11.892297264160424	86109
110ae72fc17bdeb4650f9f4f4616bb2bbbe4ff35	economic and political issues in determining the future of the professionally managed library over the next ten years				Herbert S. White	1996			politics;political science;management	AI	-65.37196475435103	-10.665772701722002	86226
83d04370ddc68f1390d9a48b89829cbaad3bf9a7	multimedia security: the 22nd century approach	multimedia security	In this paper I will describe where I think multimedia security will be headed in the next century. Will anything useful happen in the next 100 years? Will our content feel any safer? This paper is based on the keynote address I gave at the ACM Multimedia and Security Workshop in Magdeburg, Germany on September 21, 2004. Why am I writing this paper? I am not clairvoyant! I cannot see the future! I will be long dead before we get to the 22nd century – hence I am not in trouble or wrong. I will give you my opinions and ideas.1 I will attempt to discuss various concepts in multimedia security and particularly data hiding and watermarking and predict how they will be affected in the next 100 years with respect to the impact of the technology on society, the legal aspects, and how research in this area will be driven. I will describe how data hiding and watermarking will be viewed at the dawn of the 22nd century. With respect to impact of the technology in the next 100 years, the following issues will be important:	digital watermarking;magdeburg	Edward J. Delp	2004	Multimedia Systems	10.1007/s00530-005-0193-4	cloud computing security;computer science;multimedia;internet privacy;computer network	DB	-68.7559281882282	-12.691601430010559	86238
def478653fc12389126271bd66b237307d62c950	the net as a knowledge machine: how the internet became embedded in research	scientometrics;knowledge;disciplinarity;internet;marketing;world wide web;economia y empresa	In this paper, we examine the growth of the Internet as a research topic across the disciplines, and the embedding of the Internet into the very fabric of research. While this is a trend that ‘everyone knows,’ prior to this study no work had quantified the extent to which this common sense knowledge was true, or how the embedding actually took place. Using scientometric data extracted from Scopus, we explore how the Internet has become a powerful knowledge machine which forms part of the scientific infrastructure across not just technology fields, but also right across the social sciences, sciences, and humanities.		Eric T. Meyer;Ralph Schroeder;Josh Cowls	2016	New Media & Society	10.1177/1461444816643793	social science;internet research;scientometrics;computer science;data science;marketing;multimedia;sociology;knowledge;law;world wide web	Metrics	-75.8520584305236	-16.922681882592425	86244
44ff8a33f66e4ede695e6a0b00f9919b0517f31d	initiative for indian language ir evaluation	growth rate;informa tion retrieval;sri lanka	The Indian subcontinent can be regarded as another Europe, due to its lingual diversity. Geographically, the Indian subcontinent consists of six countries, namely Pakistan, Bangladesh, Nepal, Sri Lanka, Bhutan and India. The total population in this part of the world is about 1,300 million and about 25 official languages are used by this population. Among the major languages of this region, Hindi and Bengali rank among the top ten most-spoken languages of the world. Over the past few years (2000–2007), a large volume of Indian language (IL) electronic documents have come into existence at a growth rate of 700.0 %. The need for developing IR systems to deal with this growing repository is, therefore, unquestionable. Considering this need, the Government of India has recently formed a national consortium of academic and research organizations, that has been entrusted with the task of developing a Cross Lingual Information Access (CLIA) system for Indian language content. This paper will outline the issues that will need to be addressed, and the activities of the newly formed consor-	information access	Prasenjit Majumder;Mandar Mitra;Swapan K. Parui;Pushpak Bhattacharyya	2007			geography;optometry;genealogy;traditional medicine	AI	-72.35139815290322	-20.44319573148267	86269
53ca21dbcfdf3026546c771973da4ae6e538fda0	operations research in libraries: a review of 25 years of activity	bibliotheque;science gestion;perspectiva;articulo sintesis;aplicacion;gestion;article synthese;biblioteconomia;bibliotheconomie;operations research;perspective;taxonomy of library applications of or ms;recherche operationnelle;librarianship;ejemplo;retrospective;application;review;management;example;biblioteca;investigacion operacional;library;retrospectiva;management science;libraries survey of or in libraries;exemple	Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp. JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content in the JSTOR archive only for your personal, non-commercial use.	archive;download;library (computing);operations research	Arnold Reisman;Xiaomei Xu	1994	Operations Research	10.1287/opre.42.1.34	perspective;library;mathematics;operations research	Web+IR	-73.83983268953014	-23.314636983123187	86434
4abe204940e43609883b5bd8270d3fe85101e5e8	computation and incentives in social choice (dagstuhl seminar 12101)	004;computational social choice voting incentives algorithmic game theory	Computational social choice is an active research area that combines tools#R##N#and techniques of theoretical computer science and AI with those of mathematics,#R##N#social sciences and economics. The aim of the Dagstuhl Seminar 12101 ``Computation and Incentives in Social Choice'' was to bring together the experts in these areas in order to discuss recent advances in this field and share open problems. This report collects the material presented during the course of the#R##N#seminar.	computation	Edith Elkind;Christian Klamler;Jeffrey S. Rosenschein;M. Remzi Sanver	2012	Dagstuhl Reports	10.4230/DagRep.2.3.1	social science;public economics;political science;management science	ECom	-64.91078962754645	-12.279677909951703	86435
56a3a4c7c3f838204d96dd6cd04dee51f8256ca9	the emergence of the post-digital media cloud	digital media		digital media;emergence;postdigital	Ubiquity staff	2007	Ubiquity	10.1145/1232048.1232049	computer science;digital media;law	HPC	-66.60463352539529	-9.910007682389352	86514
dd4bdd401d7f952547bfc460a32b885a97bbce3b	privacy technologies and policy		Genetic data as a category of personal data creates a number of challenges to the traditional understanding of personal data and the rules regarding personal data processing. Although the peculiarities of and heightened risks regarding genetic data processing were recognized long before the data protection reform in the EU, the General Data Protection Regulation (GDPR) seems to pay no regard to this. Furthermore, the GDPR will create more legal grounds for (sensitive) personal data (incl. genetic data) processing whilst restricting data subjects’ means of control over their personal data. One of the reasons for this is that, amongst other aims, the personal data reform served to promote big data business in the EU. The substantive clauses of the GDPR concerning big data, however, do not differentiate between the types of personal data being processed. Hence, like all other categories of personal data, genetic data is subject to the big data clauses of the GDPR as well; thus leading to the question whether the GDPR is creating a pathway for ‘big genetic data’. This paper aims to analyse the implications that the role of the GDPR as a big data enabler bears on genetic data processing and the respective rights of the data subject.	big data;gene regulatory network;general data protection regulation;information privacy;personally identifiable information;while	Erich Schweighofer;Herbert Leitold;Andreas Mitrakas;Kai Rannenberg;Gerhard Goos;Juris Hartmanis;Jan van Leeuwen;David Hutchison	2017		10.1007/978-3-319-67280-9	privacy software;information privacy;privacy by design;internet privacy;computer security;commerce	DB	-74.0646771823495	-12.147258740438172	86671
f58fcbc827b6a07ddbbce343ed1a7617f2f97703	information decompression of xinjiang travel materials	decompression;translation plus comment;translation plus explanation;translation plus supplementation;xinjiang travel materials;travel industry language translation;chinese english translation information decompression xinjiang travel materials semeiotic perspective implicit information ethnical culture geographical culture historical culture information redundancy message transmission;materials cultural differences lakes educational institutions global communication redundancy calendars;translation plus explanation xinjiang travel materials decompression translation plus comment translation plus supplementation	Previous discussions on the translation of travel materials are mainly confined to functional and semeiotic perspectives. Authors of this paper hold that Xinjiang travel materials involve implicit information related to distinguished ethnical, geographical and historical cultures which cannot be absorbed comprehensively by English-speakers who do not share the same cultural backgrounds. They try to settle the problem with application of information decompression which means to amplify information redundancy to reduce unpredictability during message transmission. Meanwhile, they take translation plus comment, translation plus supplementation and translation plus explanation as measures in decompression. To be exact, in Chinese-English translation of Xinjiang travel materials, authors of the paper decompress the original texts and release the cultural connotations by means of translation plus comment, translation plus supplementation and translation plus explanation so as to convey correct and adequate information to receivers, shorten the cultural gap and achieve effective communication. This paper tries to propose a new prospective for the translation of Xinjiang travel materials.	comment (computer programming);data compression;prospective search;redundancy (information theory);semiotics	Kaihong Yang;Shuzhen Shi	2014	2014 International Conference on Asian Language Processing (IALP)	10.1109/IALP.2014.6973479	redundancy (engineering);natural language processing;artificial intelligence;decompression;computer science	Robotics	-63.576240301233206	-21.77617007106135	87064
e31432e676711f8b32eea38e74f158c7677e766b	new algorithms for nonlinear generalized disjunctive programming: sangbum lee and ignacio e. grossmann, department of chemical engineering, carnegie mellon university, pittsburgh, pa 15213, usa	generalized disjunctive programming;chemical engineering	One system of a multisystem environment takes over log entries owned by another system of the environment. When a system owning entries on a primary log stream is inactive (or a sync point manager on the system is inactive), another system of the multisystem environment writes the log entries corresponding to the inactive system to other locations. The entries within the other locations are not owned by any system. Thus, the resource managers associated with those log entries are eligible for restarting on any system of the multisystem environment. However, all resource managers involved in a common set of transactions are to restart on the same system. The other resource managers can restart on another system. When one of the resource managers restarts on a system, the system takes back ownership of the entries associated with the common set of transactions.	algorithm;disjunctive normal form;nonlinear system	Gintaras V. Reklaitis	2003	Computers & Chemical Engineering	10.1016/S0098-1354(02)00269-7	computer science;engineering;artificial intelligence;mathematics;chemical engineering	DB	-65.60232319703918	-16.186945182433917	87114
1641478cadc4759e4a9428efb6a7bf3371c6f6b1	journal ranking by different parameters. part ii. individual or collective: which parameters are best suited for journal ranking?	bibliometrie;indicador investigacion;filing;scientometrics;seleccion documento;decision aid;periodical;selection document;estudio comparativo;parametre;sciences;document selection;bibliometria;ayuda decision;ciencia;etude comparative;parametro;parameter;periodique;periodico;parameter selection;scientometria;indicateur recherche;classement;comparative study;scientometrie;aide decision;bibliometry;research indicator;clasificacion	For the first time the impact of different ranking parameters on one and the same experimentally achieved set of 610 journals is studied. Significance of the three journal ranking parameters Selective Journal Productivity, Selective Impact, and Collectivity is established. Significant parameters cause strong re-ranking in journal rank distributions and, in the transition between individual and collective parameters, also in the shape of the comulated curves. No parameter can replace an other one, each carries essential information on the communication process. The author's concept is open for more parameters and pronounces the role of man in decision making. The connection between simple behavioral principles and scientometrics is emphasized. The holography principle and the maximum speed principle are claimed to be most promising.	experiment;holography;scientometrics	Manfred Bonitz	1990	Scientometrics	10.1007/BF02019163	artificial intelligence;data mining;operations research;parameter;statistics	Vision	-75.94768248234924	-22.591211371930033	87235
c4c31164ab8dfdb32970ca1d02fef731cca471ce	the great wall syndrome [workplace information security]	it managers;ipods;computer network security;social aspects of automation security of data;network security;lifestyle computing;security risks;pc security network security pdas ipods lifestyle computing acceptable use policy aup security risks intellectual property rights infringement vicarious liability permissions moore s law it managers;moore s law;social aspects of automation;ethical issues;great wall syndrome workplace information security;personal digital assistants computer networks universal serial bus firewire data security portable media players information security drives memory management forensics;intellectual property rights infringement;ieee computer society;permissions;pdas;intellectual property right;it management;vicarious liability;acceptable use policy aup;pc security;security of data	A 2004 survey of Fortune 100 companies by the Ponemon Institute found that insiders were responsible for roughly 70 percent of reported security breaches (Reardon, 2005). BBC News, quoting another survey by data forensics from Ibas, stated that 70 percent of staff surveyed have stolen key information from the workplace, that 72 percent of these offenders had no ethical issues with helping themselves to information that would benefit them in a new job, and that 30 percent of respondents had stolen contact data when they left an employer (2004).	forensic medicine;information security;stolen product	Michael Thelander	2005	IT Professional	10.1109/MITP.2005.126	public relations;computer science;network security;moore's law;internet privacy;management;law;computer security;intellectual property	HCI	-71.19631252820182	-10.9688927470384	87293
eea729434e6e6fba5ace2e811855d99f632b597f	topological analysis of interdisciplinary scientific journals: which journals will be the next nature or science?	data mining;cluster analysis;multidimensional scaling;bibliometrics;principle component analysis	Identifying prestigious interdisciplinary journals is very significant for researchers. By publishing research works in prestigious journals, researchers can better propagate their works and get spotlights. Even though the quality of a paper is not represented by the journal that publish the paper, it is a general concern of researchers that how to identify a set of good journals to submit their papers. Nature and Science are the two journals that have been considering as the two top interdisciplinary journals worldwide. In this paper, we propose a method for identifying journals that have the potential to become the next Nature and Science through topological analysis of interdisciplinary scientific journals using citation data. By applying three different statistical methods (i.e., Multidimensional scaling, Principal component analysis, Cluster analysis), we identified a set of journals in which PNAS has the highest possibility to become the next Nature and Science. The study showed that citation data is a powerful data to measure similarity among journals.	cluster analysis;image scaling;multidimensional scaling;principal component analysis	Yongjun Zhu;Erjia Yan;Il-Yeol Song	2015		10.1145/2811411.2811475	library science;computer science;data science;data mining	NLP	-77.17407960972494	-19.78080872031555	87410
010dc2c1ad40618333a00f333a29ae8798bc8714	health and safety and piracy: legal risk minimisation in libraries	livre electronique;bibliotheque;equipement informatique;estacion trabajo;peer to peer network;droit auteur;station travail;piratage;securite informatique;copyright;riesgos contra salud;hacking;computer security;workstation;copyright law;electronic book;sante;seguridad informatica;health and safety;libro electronico;equipo informatico;health;salud;health hazards;biblioteca;computer equipment;library;point of interest;risque sante;derecho autor	This article presents a preliminary discussion of two points of interest. Part one puts forward that libraries need to be actively aware of the health and safety issues relating to computer workstations, this awareness will allow sensible steps to be taken not just to mitigate potential liability concerns but to ensure that computer technology is accessible and also easily and comfortably used by library employees and public users of the library. Part two argues that libraries will need to be versed in the dual disciplines of computer technology and copyright law to allow librarians and the library’s computer support service to prevent copyright infringement. Libraries must distance themselves from potential piracy such as e-book, music, games and computer software downloads facilitated by the peer-topeer network. The article reviews, dissects and finally presents some tentative solutions that may mitigate the potential litigation from health and safety and piracy.	computer;e-book;librarian;library (computing);point of interest;technical support;workstation	Mark Van Hoorebeek	2004	The Electronic Library	10.1108/02640470410541624	point of interest;workstation;library;telecommunications;computer science;health;occupational safety and health;sociology;management;operations research;law;world wide web;computer security	Arch	-71.02452136242943	-21.199737954471235	87720
27ff42e42825f9ff0dca1de758d7b1e0239fa091	analysis of purchasing behavior focusing on the passage of time at a group buying site of coupon	rfm analysis;group buying site;cluster analysis;coupon;sequence analysis;the internet	In late years, the spread of Internet advances. The diffusion rate of the Internet in 2011 became 79.1%, and the Internet made generalization. With the spread of Internet, marketing technique called the flash marketing came up. As delegate of flash marketing, Group buying sites of coupon are receiving attention in Japan. But people relating to its business think that the sales are having peaked. In this study, we assume that behaviors of users using Group buying sites of coupon change by the time elapsed. By analyzing the change of their behavior, we understand the change of behavior to lead to the continued buying. As a final objective, we hope that we can give help that the sales are having peaked.	purchasing	Takuto Kobayashi;Toshikazu Yamaguchi;Yumi Asahi	2013		10.1007/978-3-642-39209-2_51	marketing;advertising;business;commerce	ECom	-66.27431219803788	-22.65264637068923	87869
e1e3f8f7c3ffb6f2617a875cd7da62fc66938e19	introduction to science gateways and science gateway frameworks		This chapter gives a short introduction to the basic architecture and functionalities of science gateways, as well as their development methods. It then briefly describes the EU FP7 SCI-BUS project that is developing a core science gateway framework called as WS-PGRADE/gUSE. A large number of various user communities have developed application-oriented science gateways by adapting and customizing the WS-PGRADE/gUSE gateway framework. The chapter also explains the vision of SCI-BUS on a collaboration-based SG instance development methodology. Finally, it gives a guide on how to read the rest of the book.		Péter Kacsuk	2014		10.1007/978-3-319-11268-8_1	library science	Logic	-66.02303795838202	-14.315386205203021	87880
58f818bdda56b845796c8bfbc4cae11e70bfff1d	the world is all grown digital.... how shall a man persuade management what to do in such times?	za4050 electronic information resources;lf individual institutions europe;za4450 databases;balanced scorecard;business model;good practice;information value;digital preservation;point of view;business performance;long term survival;z665 library science information science;institutional repository;cost model	Understanding and communicating the cost and value of digital curation activities has now been recognised by a number of projects and initiatives as a very important factor in ensuring the longterm survival of digital assets. A number of projects have developed costing models for digital preservation but there remains a major problem with information assets (digital or otherwise) in that their value is difficult to express in terms that are readily understood by all the stakeholders, especially those who might fund their preservation. This paper introduces a range of issues concerning information value and business models for sustained funding of digital preservation, with particular reference to the espida Project recently completed at the University of Glasgow. This project has developed a model of information value that builds on the Balanced Scorecard approach to business performance developed by Kaplan and Norton. This model casts information curation as an investment where current and ongoing expenditure is incurred in order to produce future returns, benefitting a range of stakeholders. In this formulation, value is seen as multifacetted and, from the point of view of the individual or organisation funding the curation, explicitly related to the funder’s strategic goals. It also recognises that benefits may only accrue over the long term and that there is a risk that information that is preserved may fail to deliver any return. Examples discussed in the paper concern the establishment of an institutional repository and the establishment of an e-thesis service for an educational institution. It concludes that a deconstruction of benefits of this kind can be more quickly and fully understood even by stakeholders not necessarily expert in the curation field. This facilitates the production of a well-constructed case that clearly articulates information value and the benefit that accrues from its curation, which in turn allows senior management or other funders to make funding decisions based on understandable information: the basic premise of good practice in management. This is a commonly understood idea and one that the espida methodology helps fulfil. 1 The title is a modification of a quote from: J.R.R. Tolkien, ‘The Lord of the Rings’, Book III, Chapter 2. The original quotation is: “The world is all grown strange.... How shall a man judge what to do in such times?” The International Journal of Digital Curation is an international journal committed to scholarly excellence and dedicated to the advancement of digital curation across a wide range of sectors. ISSN: 1746-8256 The IJDC is published by UKOLN at the University of Bath and is a publication of the Digital Curation Centre. The world is all grown digital 13	case preservation;digital asset;digital curation;digital data;international standard serial number;kaplan–meier estimator	James Currall;Claire D Johnson;Peter McKinney	2007	IJDC	10.2218/ijdc.v2i1.11	business model;computer science;knowledge management;value of information;database;management science;balanced scorecard;world wide web	HCI	-67.94871868764876	-18.451596227301412	87986
bd70a62ec4fb65070b92d60bf7aa3f4adaaacf22	understanding and transforming organisational culture		Since the introduction of computers, information systems and data have been repeatedly undermined by design flaws, weak passwords, lost media, social engineering and numerous other bad practices. These risks continue to grow with the increasing complexity and connectivity of modern business systems. But actions by people are not only the cause of incidents, they are also the means to prevent, detect and resolve them. People design, implement, operate, use and abuse information systems. And in the process they make mistakes or create weaknesses that enable criminals to steal, corrupt and manipulate information assets. Addressing these risks cannot be done through technology and process alone. It requires an understanding of the principles for understanding organizational culture, creating awareness, and changing attitudes and behaviour. This paper presents a range of observations about the nature of organizational culture, as perceived by an experienced information security director, as well as a set of practical techniques, based on psychological principles, that have been found to be effective in helping to achieve desired changes in human security behaviour.	awareness;computer;information security;information system;password strength;social engineering (security)	David Lacey	2009			knowledge management;asset (computer security);organizational culture;password;information security;business system planning;information system;social engineering (security);human security;business	HCI	-72.76500054743919	-10.863273993266983	88124
88b6ac32521f3a4d7283f6d2f181beab2e095d6e	the european union, china, and the united states in the top-1% and top-10% layers of most-frequently cited publications: competition and collaborations	citation analysis;world share;universiteitsbibliotheek;europe;china;usa;excellence	The percentages of shares of world publications of the European Union and its member states, China, and the United States have been represented differently as a result of using different databases. An analytical variant of the Web-of-Science (of Thomson Reuters) enables us to study the dynamics in the world publication system in terms of the field-normalized top-1% and top-10% most-frequently cited publications. Comparing the EU28, USA, and China at the global level shows a top-level dynamic that is different from the analysis in terms of shares of publications: the United States remains far more productive in the top-1% of all papers; China drops out of the competition for elite status; and the EU28 increased its share among the top-cited papers from 2000 to 2010. Some of the EU28 member states overtook the United States during this decade; but a clear divide remains between EU15 (Western Europe) and the Accession Countries. Network analysis shows that China was embedded in this top-layer of internationally co-authored publications. These publications often involve more than a single European nation. © 2014 Elsevier Ltd. All rights reserved.	accession number (bioinformatics);database;embedded system;world wide web	Loet Leydesdorff;Caroline S. Wagner;Lutz Bornmann	2014	J. Informetrics	10.1016/j.joi.2014.05.002	computer science;citation analysis;world wide web;china	AI	-76.41526477324427	-20.441873588096943	88129
7b6a564bd4e2845df62fd382ee9c0ede8937262c	on-line information at virginia tech	management system;standard operating procedure;research design;table of contents;indexation;software package;system development;information system;office automation	Several years ago, Virginia Polytechnic Institute and State University faced an information problem. The Administrative Handbook, the university's policy and procedures manual, was out of date and in need of revision. The problem had been discussed and many solutions considered, but the one that seemed to be the best way to solve the problem was to put the information on-line. The result was the Administrative Information System, which has been providing information for over three years now, and has spawned a number of additional systems. The AIS was not the first on-line system at Virginia Tech, but it did introduce some innovations and some new ways of looking at old problems. Virginia Tech made an early commitment to office automation with a large mainframe computer, terminals in almost every office, and a network to link the campus together. IBM's Professional Office System (PROFS) was established as the default software package for office automation, making it easy for unsophisticated computer users to work just as well as those already familiar with mainframe computer use. It was because of this commitment to office automation that the on-line Administrative Handbook was considered as a replacement for the printed version. The idea of on-line information was not a new idea, since there already was some information available on the mainframe for users who could remember the unique series of commands necessary to gain access. These “systems” consisted of the weekly employment listings posted by Employee Relations, Standard Operating Procedures from the Office of Sponsored Programs and an electronic version of the University Fact Book, with enrollment and demographic information, maintained by the Office of Institutional Research and Planning Analysis. These systems were developed using the HELP facility available on the mainframe, which avoided the necessity of programming a display management system. These systems, and a prototype system developed by the Computing Center to display the Faculty Handbook, influenced the development of the AIS. The HELP-based systems displayed simple text files on the screen. The Computing Center system did this also, after a user selected a particular section from a table of contents menu. In this “point and push” system, the user moved the cursor to a line in the table of contents (point) and pressed a key to display the text from that section (push). Because the Administrative Handbook had always been the responsibility of the Vice President for Administration, that office was assigned the task of updating the information. As a first step toward an on-line system, the various offices and departments that had information in the Administrative Handbook were directed to enter their policies and procedures into files on the mainframe. After consultation with the campus Computing Center and looking at some of the systems already on the mainframe, the task of researching, designing, and implementing the on-line system began. The initial idea of putting the policies and procedures on-line was to merge all the files a single, indexed document. As the information was gathered from the various departments, it became apparent that a monolithic document would be unmanageable. Some minor revisions could have been handled with little impact, but major revisions or additions to one section would have had a major impact on the entire document. Another discovery during the initial development stages was that a technical writer was needed to provide writing assistance and coordinate the style and format of the individual documents. Because each department involved was required to enter its own information, there were various levels of consistency in format and in the information provided. This position was filled in January 1986 and a detailed development plan was completed.	cross-reference;cursor (databases);database;document;handbook;information system;line level;mainframe computer;online and offline;printing;programmer;prototype;simpletext;single-index model;user (computing);on-line system	B. B. Harper	1989		10.1145/73760.73807	simulation;engineering;operations management;operations research	AI	-69.48876064890901	-23.723861676547493	88282
6a664a0d9192c457caa8570626205a668e6459a9	click fraud and the adverse effects of competition	engineering;click fraud modelling;search engine;competition adverse effects;cost function;search engines;technology;fraud advertising computer crime;computer science artificial intelligence;advertising economics cost function intelligent systems search engines;computer crime;market efficiency click fraud modelling competition adverse effects;adverse effect;click fraud intelligent systems social and economic computing;science technology;fraud;social and economic computing;intelligent systems;intelligent system;computer science;economics;click fraud;market efficiency;engineering electrical electronic;advertising	Modeling click fraud as a competitive strategy illustrates the motivations behind publisher behaviors and shows how it evolves and harms market efficiency.	click fraud;strategic management	Xiarong Li;Daniel Dajun Zeng;Yong Liu;Yanwu Yang	2011	IEEE Intelligent Systems	10.1109/MIS.2011.76	intelligent decision support system;computer science;computer security;search engine	ML	-70.21621756002673	-10.022825614653916	88504
61e8442fc569e970b6330dc9e0c788ad4e6992f2	a disciplinary analysis of internet science		Internet Science is an interdisciplinary field. Motivated by the unforeseen scale and impact of the Internet, it addresses Internet-related research questions in a holistic manner, incorporating epistemologies from a broad set of disciplines. Nonetheless, there is little empirical evidence of the levels of disciplinary representation within this field. This paper describes an analysis of the presence of different disciplines in Internet Science based on techniques from Natural Language Processing and network analysis. Key terms from Internet Science are identified, as are nine application contexts. The results are compared with a disciplinary analysis of Web Science, showing a surprisingly low amount of overlap between these two related fields. A practical use of the results within Internet Science is described. Finally, next steps are presented that will consolidate the analysis regarding representation of less technologically-oriented disciplines within Internet Science.	holism;internet science;natural language processing;social network analysis;web science	Clare J. Hooper;Bruna Neves;Georgeta Bordea	2015		10.1007/978-3-319-18609-2_5	library science;computer science;knowledge management;management science	Web+IR	-76.17216047292217	-17.474454693998354	88553
7eb873263ce800adbc67f47f735f010387846452	an accidental cryptologist: the brief career of genevieve young hitt	parker hitt;world war i;women in cryptology;genevieve hitt	Genevieve Young Hitt, wife of Colonel Parker Hitt, was one of the first women to perform cryptologic functions for the U.S. Army, first as an unpaid amateur during the Punitive Expedition and later as a paid cryptographer during World War I. Official documents and recently discovered family papers shed light on Mrs. Hitt’s brief career and overlooked role as a female cryptologic pioneer.	accident (philosophy);cipher;cryptanalysis;cryptography;error-tolerant design;hoc (programming language);list of cryptographers;mary tsingou;nat friedman	Betsy Rohaly Smoot	2011	Cryptologia	10.1080/01611194.2011.558982	operations research;computer security	Crypto	-63.65175901919647	-20.740225606653485	88588
43a4628e56da7e28ee5ac1f6cadb655151d08b87	health and medical informatics education: perspectives for the next decade	quality assurance;working group;health informatics;informatica biomedical;perspectiva;biomedical data processing;medical informatics;quality of education;aplicacion medical;red www;salud publica;information technology;imia;educational software program;informatique biomedicale;teleinformatica;technologie information;didacticiel;health professionals;perspective;aseguracion calidad;teleinformatique;internet;information processing;sante publique;world wide web;medical application;reseau www;quality of healthcare;programa didactico;medical informatic;tecnologia informacion;assurance qualite;remote data processing;public health;application medicale	It is argued that the progress of information processing and information technology changes our societies. Examples are given that there is a significant economic relevance of information technology for medicine and healthcare and for the quality of healthcare as well. In order to adequately pursue the goal of 'Transforming healthcare through innovative use of information technology for the 21st century' (the topic of the 6th International Conference on Health and Medical Informatics Education and of this special issue of the International Journal of Medical Informatics), health professionals are needed who are well-educated in health informatics or medical informatics, respectively. Raising the scope and the quality of education in the field of health and medical informatics would help to raise the quality and efficiency of healthcare. In this context the International Medical Informatics Association (IMIA) and its working group 1 (WG1) on Health and Medical Informatics Education can make a contribution by disseminating information and by elaborating recommendations on courses and programs in health and medical informatics. For this purpose IMIA WG1 has established a WWW site (http://www.imia.org/wg1) with information on health and medical informatics programs and courses. All teachers and institutions are encouraged to submit information about courses and programs offered and to set pointers to their own WWW sites. In addition, a mailing list was installed to facilitate communication between all persons involved in health and medical informatics education. For subscription, a message has to be sent to 'listserv@relay.urz.uni-heidelberg.de'. The body of the message should read 'SUBSCRIBE IMIA-WG1'.		Reinhold Haux	1998	International journal of medical informatics	10.1016/S1386-5056(98)00046-X	health administration informatics;chief medical informatics officer;business informatics;health informatics;public health informatics;perspective;the internet;working group;medicine;computer science;nursing;data mining;informatics;law	Visualization	-71.7777457956197	-22.57718028458271	88590
1ace89e363c6bb3821ad447318e12c8d84c1980b	technology versus privacy issues in preventing distracted driver accidents [point of view]	road accidents;text processing;government;smartphones;accidents;privacy accidents road accidents government smartphones electronic messaging;privacy	The majority of states have laws intended to combat distracted driving, but some laws cause concerns for privacy advocates. In January 2016, Vermont representative Martin LaLonde introduced a bill that would allow officers to search a driver’s phone during routine traffic stops to see if it was being used [1]. The same purported technology used by companies like Cellebrite to unlock the terrorist’s iPhone 5C without Apple’s help for the FBI’s investigation would be deployed to law enforcement on the roads. The technology available would essentially create a warrantless investigation that any police officer could carry out on site. Given previous federal court decisions, it is highly unlikely that the bill would pass Constitutional muster if enacted. The Fourth Amendment prohibits unreasonable search and seizure of “persons, houses, papers and effects.” Sure enough, in October 2013, the U.S. Supreme Court ruled that authorities cannot search cellphones or smartphones without a warrant [2]. Even a simple feature phone can store contact information, text messages, and photos and report their owner’s movement to the cellular carrier. Smartphones are miniature computers that can provide information on virtually everything about a person, from their finances to their personal relationships. Another issue is whether legislation actually has any impact. In spite of increasingly tougher laws, the problem is getting worse. Recent surveys have shown that even though 46 states prohibit texting and driving and drivers are aware that distractions are a problem, they continue to do it anyway. Think about it, when is the last time you saw someone driving their car and on the phone? If you commute, it is something you likely observe daily.	computer;feature phone;mobile phone;point of view (computer hardware company);privacy;sim lock;smartphone	Scott Schober	2016	Proceedings of the IEEE	10.1109/JPROC.2016.2550138	telecommunications;computer science;engineering;internet privacy;privacy;computer security;government	Security	-72.0061035280932	-12.813659222707841	88703
5dc1ff6cc4cf67971218a8b58f20e76d7fa227b3	welcome message from the editor-in-chief		It gives us immense pleasure to introduce to you the inaugural issue of the ICST Transactions on Complex Systems. Interdisciplinary studies on complex systems have attracted extensive interest in recent times. Such studies have made major impacts on disciplines as wide-ranging as physics, biology, economics, ecology, social sciences, computer sciences, material sciences, and electrical, mechanical and civil engineering, etc. The researches on complex systems are also generating some most exciting results at various interdisciplinary frontiers such as econophysics, socio-ecology, social media, and many more. What may be even more important is that the development of complex systems science helps equip people with the proper mindset and tools to think about and analyze the world they are living in as a connected, complex world. For example, when tackling the world energy problem, we may expect to have, in the no-sodistant future, the sufficient data and efficient tools to analyze its relationship with many other critical issues such as water, food, economics, healthcare, environment, social resilience, critical infrastructures and transportation systems, etc. Traditional “linear” approaches will be abandoned and system approaches will prevail. The complex systems science has the great potential to revolutionize the way we understand and interact with the world. ICST Transactions on Complex Systems is proud to be a part of the concerted efforts to foster the new science of complexity. It aims to provide a platform for fellow researchers around the world to exchange their observations, ideas and latest results generated from the cutting-edge researches on complex systems. It is a new open access scholarly archival journal that is committed to timely publication of high-quality original results on all aspects of complex systems theories, methodologies, modeling, analyses, and applications. Original contributions that have not been published and are not currently under consideration by any other journal or conference are solicited. All submissions will go through a rigorous peer-review process, and will be reviewed and evaluated by at least two independent expert referees. The scope of the journal includes, but is not limited to:	archive;complex systems;computer science;ecology;institute for computer sciences, social informatics and telecommunications engineering;social media;systems science;systems theory	Gaoxi Xiao	2012	EAI Endorsed Trans. Complex Systems	10.4108/trans.cs.2012.10-12.e1		DB	-63.4867539584811	-17.203331764680897	88829
0a2f64571658b9357f5197a5b0737e7c0efd1158	"""""""in the middle of difficulty lies opportunity"""" - using a case study to identify critical success factors contributing to the initiation of international collaborative projects"""	critical success factors;latin america	This paper aims to identify factors that contribute to the successful initiation of international collaborative projects that are intended to support the development of education for librarianship and information sciences. The paper, first, discusses the widespread failure to analyse the Critical Success Factors in international collaborative projects. It proposes case study methodology to identify these factors through an analysis of the decision by the European Commission’s ALFA Programme to support REVISTAS, a study of the feasibility of digitising all the Spanish and Portuguese journals in the field of librarianship and information sciences, particularly those published in Latin America. To contextualise the proposal, it discusses the development of the ‘Information Society’ in Latin America, and the key role attributed to libraries and librarians. It then examines problems that have been noted in the development of education and practice in librarianship and information sciences in the region, and in journal publishing for the profession, the availability of indexing and abstracting services, and the utility of document delivery services. It presents an outline of the author’s initial research into the underlying challenges, and outlines the development of the international partnership that will deliver the planned outcomes of the REVISTAS project. Finally, the paper analyses the issues that have contributed to the establishment of this cooperative effort, and the limitations of this	information science;librarian;library (computing)	Ian M. Johnson	2005	Education for Information			SE	-72.76432649715649	-21.97215233673804	88906
91354eaab6062174f7b217fe21d839c13241af73	a preference for pdf		When it comes to electronic formats, Communications readers prefer PDF to HTML, according to data on a year’s worth of published articles. PDF’s faithful reproduction of magazine pages appears to give it an edge. Legacy is another factor. Every article in Communications’ 52-year history is available in PDF, while HTML versions date back to 1999. Also, members are accustomed to accessing ACM’s many transactions, proceedings, and journals exclusively in PDF. The table shows how the most popular articles published over a 12-month span were accessed from the DL and Communications’ Web site. a Preference for PDf DOI:10.1145/1839676.1839681 David Roman ACM Member News	html;portable document format	David Roman	2010	Commun. ACM	10.1145/1839676.1839681	theoretical computer science;natural language processing;artificial intelligence;computer science	OS	-64.2299574446878	-17.30708142930494	89051
b7408ef1f4c3b06c12a2fe2206026b68bc11aa5a	sustainable ict: a critique from the perspective of world systems theory	human computer interaction;other earth and related environmental sciences;manniska datorinteraktion interaktionsdesign;annan geovetenskap och miljovetenskap	Even though the ICT (Information and Communication Technology) industry has historically been spared the critique of being environmentally unfriendly, society has as of late recognised the negative environmental effects of the ICT industry. However, such critique has been gradually replaced by the concept of Sustainable ICT, in which ICT is almost seen as a saviour, something with big potential of solving economic, societal and environmental issues. In this paper, our aim is to critically discuss the notion of Sustainable ICT by turning to an ecological perspective of World Systems Theory (WST). Immanuel Wallerstein, the main proponent of WST argues that the success of developed (core) countries today is a product of systematic unequal exchange of raw material, goods and labour with underdeveloped (peripheral) countries. Alf Hornborg, the Swedish Marxist ecologist, develops WST by focusing on the global distribution of environmental degradation. In this paper, we present Hornborg’s ecological WST, we apply it to ICT by means of examples from the ICT Value Chain (from materials extraction to disposal) in order to illustrate the global distribution of environmental degradation. We argue that WST is a fruitful, and critical, alternative perspective to the more optimistic view of Sustainable ICT.	systems theory;world-system;world-systems theory	Thomas Taro Lennerfors;Per Fors;Jolanda van Rooijen	2014		10.1007/978-3-662-44208-1_6	engineering;operations management;management	NLP	-76.59486086948372	-10.269493587320747	89124
07e1575333bde0c225b55d278fa6dac94ec29332	the clique problem for graphs with a few eigenvalues of the same sign		Here are the proofs of your article. • You can submit your corrections online, via e-mail or by fax. • For online submission please insert your corrections in the online correction form. Always indicate the line number to which the correction refers. • You can also insert your corrections in the proof PDF and email the annotated PDF. • For fax submission, please ensure that your corrections are clearly legible. Use a fine black pen and write the correction in the margin, not too close to the edge of the page. • Remember to note the journal title, article number, and your name when sending your response via e-mail or fax. • Check the metadata sheet to make sure that the header information, especially author names and the corresponding affiliations are correctly shown. • Check the questions that may have arisen during copy editing and insert your answers/ corrections. • Check that the text is complete and that all figures, tables and their legends are included. Also check the accuracy of special characters, equations, and electronic supplementary material if applicable. If necessary refer to the Edited manuscript. • The publication of inaccurate data such as dosages and units can have serious consequences. Please take particular care that all such details are correct. • Please do not make changes that involve only matters of style. We have generally introduced forms that follow the journal's style. Substantial changes in content, e.g., new results, corrected values, title and authorship are not allowed without the approval of the responsible editor. In such a case, please contact the Editorial Office and return his/her consent together with the proof. • If we do not receive your corrections within 48 hours, we will send you a reminder. • Your article will be published Online First approximately one week after receipt of your corrected proofs. This is the official first publication citable with the DOI. Further changes are, therefore, not possible. • The printed version will follow in a forthcoming issue. After online publication, subscribers (personal/institutional) to this journal will have access to the complete article via the DOI using the URL: http://dx.doi.org/[DOI]. If you would like to know when your article has been published online, take advantage of our free alert service. For registration and further information go to: Due to the electronic nature of the procedure, the manuscript and the original figures will only be returned …	clique problem;email;fax;goto;line number;portable document format;printing	Dmitriy S. Malyshev;Panos M. Pardalos	2015	Optimization Letters	10.1007/s11590-014-0805-z	mathematical optimization;combinatorics;discrete mathematics;mathematics;quadratic programming	Theory	-66.39611784925098	-18.69780070895138	89369
f3af706f498fee69bbfbaf1d0f83592540249215	a comparative analysis of obsolescence patterns of the u.s. geoscience literature	comparative analysis;periodicals;statistical analysis;earth science;obsolescence;library collections;citations references	Abstract#R##N##R##N#The United States (U.S.) geoscience literature is employed as a vehicle to study the phenomenon of obsolescence. Problems investigated include the classical and ephemeral aspects of subject literatures, diversity among narrowly defined literatures within broadly defined subject literatures, and the effect of literature growth on obsolescence. Comparisons are made: 1. among time-frequency bibliographs based on citation counts from each of twelve major journals published in 1969; 2. between bibliographs of three major journals for the years 1969 and 1949; and 3. between uncorrected and corrected obsolescence curves.#R##N##R##N##R##N##R##N#Each journal yields citation patterns comprised of both an ephemeral and a classical literature component. Within this framework apparent obsolescence varies across a broad spectrum, from physics/chemistry-oriented geoscience subdisciplines with relatively short “half-lives,” to those biology-oriented with relatively long “half-lives.” Obsolescence rates of traditional geoscience fields seem to vary little between 1949 and 1969 in contrast to those of fast-changing fields such as solid earth geophysics.#R##N##R##N##R##N##R##N#The relationship between obsolescence curves uncorrected and corrected for growth suggests the operation of factors that control research fronts. The effect of literature size on obsolescence, though minor for the recent literature, is more pronounced for the classical literature.		Joseph J. Kohut	1974	JASIS	10.1002/asi.4630250407	library science;qualitative comparative analysis;social science;computer science;management;operations research;world wide web;obsolescence;statistics	Crypto	-76.18967012860324	-21.55601184198239	89438
025491ca01168956c36d44e2360a96bca156f94c	"""the making of the characters of marvel's """"avengers: age of ultron"""""""			avengers: age of ultron		2015		10.1145/2745234.2773224		NLP	-64.59314058286367	-11.461622952483923	89472
b7c6d713efe45eebc68e38ad0c325287ba0f38f1	what's at issue: sex, stigma, and politics in acm publishing		Because publishing with the ACM is essentially required to advance our careers, we must examine its practices critically and constructively. To this end, we reflect on our experience working with the ACM student publication Crossroads. We encountered rigid content limitations related to sex and sexuality, preventing some contributors from foregrounding their connection to political activism, and others from publishing altogether. We explore the underlying institutional and sociopolitical problems and propose starting points for future action, including developing a transparent content approval policy and new organizations for politically-engaged computing researchers, all of which should center the leadership of marginalized individuals.		Alex A. Ahmed;Teresa Almeida;Judeth Oden Choi;Jon Pincus;Kelly Ireland	2018		10.1145/3170427.3188400	human sexuality;organizational culture;multimedia;foregrounding;universal design;social exclusion;computer science;politics;stigma (botany);media studies;publishing	HCI	-75.28029600902893	-14.757666571218778	89555
b31e0b7c68183ae3f5fe3f36b179d58f6bec9e4e	open archive initiative, publishers and scientific societies: future of publishing - next generation publishing models	open archive initiative;next generation	This panel will look into the future of publishing as a process between authoring communities such as scientific associations and publishers, i.e., non profit organizations on the one hand, and commercial enterprizes responsible for performing the production, marketing, sales and distribution of publications on the other hand.#R##N##R##N#Just recently and especially triggered by the activities of, for example the Open Archive Initiative and other similar movements, the discussion between the different stake holders in the scientific publishing process has become more intensive.#R##N##R##N#It is generally questioned whether the traditional publishing models are still valid since the advent of electronic publishing tools enable publishing from the desktop, and public distribution mechanisms like the web enable distribution at virtually no cost. These developments have produced a totally different scenario from the past.#R##N##R##N#In this context the passing of intellectual property rights from authors to publishing companies is questioned in the same way as the validity of traditional business models, pricing policies, and access regulations. On the other hand, issues like quality assurance etc. and the cost of high quality production, distribution, and maintenance of intellectual collections cannot be neglected. The members of the panel are exemplary representatives of the different stakeholders in the scientific publishing process and will report on what has been achieved so far in the discussion and on still open questions. Their presentations will include their view on which agreements have to be achieved in the future for organizing and supporting the scientific publishing process in a fair way, at the same time paving the ground for organizational innovation in other areas of publication.		Elisabeth Niggemann;Matthias Hemmje	2001		10.1007/3-540-44796-2_40	computer science;data science;world wide web	HPC	-74.86356525133598	-15.86807682792113	89653
b9675574d09f88958189dc9eb40ded1ff3034422	dokk1: co-creation and design thinking in libraries	libraries;public institutions;industry case;museums;participatory methods;human centered design;design thinking	This exhibition wants to demonstrate the role of Participatory Design principles in developing a public space like a library. The cases at the exhibition will be 1) the participatory development of Dokk1, Scandinavia's largest public library that opened in June 2015 in Aarhus and 2) the Design thinking for Libraries initiative that is done in cooperation between Chicago Public Libraries, Aarhus Public Libraries, IDEO and the Gates Foundation.	library (computing);public library	Sidsel Bech-Petersen;Lisbeth Mærkedahl;Marianne Krogbæk	2016		10.1145/2948076.2948109	engineering management;user-centered design;social science;design thinking;computer science;engineering;civil engineering;management;public institution;mechanical engineering	EDA	-64.29116661321929	-13.738745907628857	89687
9454a30f28b3ec28e59ed5516f2a7cf41612caf0	e-voting in america: current realities and future directions		This paper presents a snapshot of the current status of voting methodologies in the United States as of November 2016. The authors present the methodologies currently employed to facilitate voting including paper based and direct recording electronic systems. This is followed by a discussion of voter confidence in the election system where e-voting systems are utilized, particularly in the areas of auditing, security, influence, and human-computer interaction (HCI). The paper concludes with a brief summary of the future of e-voting, including what technology is on the horizon, and a discussion of future research directions.		Nathan Johnson;Brian M. Jones;Kyle Clendenon	2017		10.1007/978-3-319-58559-8_27	data mining;horizon;snapshot (computer storage);voting;computer science;audit	HCI	-71.75123205804462	-14.961824862250696	89938
ec28660769c4810b1398768d862960855e754685	pick your poison: pricing and inventories at unlicensed online pharmacies	online sale;pricing data;unlicensed sale;online pharmacy;licensed online pharmacy;licensed pharmacy;anonymous online marketplace;unlicensed online pharmacy;unlicensed pharmacy;certain goods;pharmacies;search engine poisoning	Electronic commerce has transformed how goods are supplied to consumers, but has also exposed weaknesses in supply regulations of certain goods, such as alcohol, weapons or prescription drugs. While licensed pharmacies have tread carefully with online sales, many enterprising operators have been selling pharmaceuticals without a license for years. Despite facing considerable adversity, unlicensed online pharmacies have managed not only to survive, but even to generate considerable revenue. In this paper, we attempt 1) to understand the economic reasons for their success, while facing stiff competition from both legal and illegal alternatives, and 2) to identify characteristics of their supply chains that could be used to disrupt illicit sales. We collected six months' worth of inventory and pricing data from 265 online pharmacies that advertise through search- engine poisoning. We compare this to data from Silk Road, an anonymous online marketplace, and from familymeds.com, a licensed online pharmacy. We discover that instead of directly competing with licensed pharmacies, unlicensed pharmacies often sell drugs that licensed pharmacies do not or cannot sell. Furthermore, unlicensed pharmacies are not only cheaper overall, but they also offer volume discounts. Clustering analysis of inventories reveals that only a few suppliers appear to cater for most unlicensed pharmacies, which suggests that cutting them off could disrupt unlicensed sales. Cross-validating our data with inventories from a random sample of 265 different pharmacies deemed ``not recommended'' by the National Association of Boards of Pharmacy shows that our results are consistent across different types of questionable vendors.	inventory;pick operating system	Nektarios Leontiadis;Tyler Moore;Nicolas Christin	2013		10.1145/2492002.2482610	public relations;spamdexing;marketing;advertising;pharmacy;world wide web	ECom	-70.74110117363666	-11.728011692460834	90084
2368a921d61bc156e3dd97053cd19373e301779d	announcing the xrds blog	xrds blog	X R D S • f a l l 2 0 1 2 • V o l . 1 9 • N o . 1 worked with the Electronic Frontier Foundation and the National Lawyers Guild among other organizations. Wolfgang Richter is a Ph.D. student at Carnegie Mellon in computer science focusing on distributed computing Systems. Wolf is developing technologies that will enable new applications in cloud computing. Dimitris Mitropoulos is a Ph.D. candidate tory posts from each of the bloggers in this issue. We hope you find them as diverse and informative as we do. By the time this issue is in your hands there should be even more posts from each of the bloggers up on the website and maybe even some new faces there as well. We’re continuing to expand the blog as well, so please write in and let us know what you think. Nominate a blogger or give feedback at eic@ xrds.acm.org. In the coming months we’ll be reaching out to ACM student chapters at universities worldwide. If you’re involved with one of these and would like to partner with XRDS, please reach out. Finally, we’re searching for help with promoting XRDS content on social networks and external blogs and news sites. If you have any interest in helping out, definitely get in touch! Strong candidates will have a background in computer science or technology and business or marketing. We’d love to hear from you!	blog;blogger;cloud computing;computer science;distributed computing;information;social network	Peter Kinnaird;Inbal Talgam-Cohen	2012	ACM Crossroads	10.1145/2331042.2331043	internet privacy;xrds;computer science	Theory	-63.87967431963587	-18.468812620141343	90113
19175eb1636c5f3516a529994043712457ad039a	eresearch bootcamp: grooming next-gen researchers	undergraduate student;high performance computer;next generation;training program;molecular dynamic;radio astronomy	The next generation of researchers are not only attempting to grasp their discipline and research areas, but also need to be well-versed in technology powered techniques for research and its dissemination a shift referred to as eResearch. The iVEC summer internship program provides an intense research training program to help undergraduate students transition into postgraduate programs and innovative industry positions. Interns are supervised by leading researchers in areas including radio astronomy, nanochemistry and molecular dynamics. More than a summer research project, the program aims to give a comprehensive indoctrination into core and emerging techniques for research. This paper describes the evolution of the internship program, the goals and methods used and a reflection on the results we are observing.	computation;computational science;google summer of code;molecular dynamics;next-generation network;supercomputer;the hub (forum);usb hub	Valerie Maxville	2010		10.1016/j.procs.2010.04.097	radio astronomy;simulation;multimedia	SE	-66.65567382907754	-13.322941396620571	90131
ff04741ce39b62ac0d3d56e2518d8a2547658f8e	special issue on qualitative approaches to e-marketing and online consumer behaviour: guest editors' introduction	qualitative approach;special issue;online consumer behaviour;guest editor	Inma Rodríguez-Ardura Gerard Ryan Ulrike Gretzel Special Issue on Qualitative Approaches to E-marketing and Online Consumer Behaviour: Guest Editors’ Introduction Journal of Theoretical and Applied Electronic Commerce Research ISSN 0718–1876 Electronic Version VOL 7 / ISSUE 2 / AUGUST 2012 / IV-V © 2012 Universidad de Talca Chile This paper is available online at www.jtaer.com DOI: 10.4067/S0718-18762012000200004	digital marketing;e-commerce;international standard serial number	Inma Rodríguez-Ardura;Gerard Ryan;Ulrike Gretzel	2012	JTAER		public relations;consumer;computer science;marketing;operating system;advertising;management;world wide web;computer security;consumer behaviour;rev;consumer-to-business	AI	-63.34068892118908	-13.616402129588021	90269
7c476b561ca980a1779c63f76974b463b2dc1322	building a business case for computer forensics	computer forensics;aspect medicolegal;securite;computer forensic;securite informatique;serveur informatique;business as usual;end of day;computer security;business case;safety;servidor informatico;information system;aspecto forense;seguridad;systeme information;forensic aspect;computer server;sistema informacion	client’s recent experience with a mysterious and unexpected crash of its servers demonstrates the value of having good information. The crash caused the loss of data to that client’s critical Accounts Payable and Accounts Receivable records that kept its banker informed of the company’s financial state. After making an initial assessment of the issue, the company inquired about the use of computer forensic services to identify the source and come up with a remedy. A week after pursuing answers through some of its product vendors produced a lot of frustration and no answers, the services of a computer forensic professional were requested. On day one, the forensic expert identified the potential source. Day two produced a confirmation of what was suspected on day one. By the end of day three, the company was back to business as usual. All of this was possible because information about the incident was available. In a previous issue, I pointed out that computers capture large amounts of information. Deleted files, revisions, and information about user activities are readily available to a computer forensic professional. Today, almost every piece of paper with information on it is or was in a digital format at one time. Events that occur on or over the computer hold key pieces of information vital in answering the what, who, when, where, and how of a particular issue. Unfortunately, most of this information is not found in plain view. Technology is every malcontent’s dream come true. It provides anonymity and allows malicious individuals to perform their actions from remote places. Are you swimming in information? If you answered “yes,” is it the right kind of information? Often, the key ingredient that makes information systems valuable is having good information. Having the right quality and quantity of information makes decisions timely, effective, and result oriented. Inquiring about a comA	computer forensics;day one;http 404;information system;malware	Kelly J. Kuchta	2000	Information Systems Security	10.1201/1086/43309.9.2.20000506/31354.7	simulation;computer science;business case;computer security;information system;server;computer forensics	Security	-70.19377716078648	-12.827797648888732	90274
f1cacc88d8f801f4a621349887e3202874d0a597	does presentation order impact choice after delay?	citations;collective outcomes;order effects;choice	Options are often presented incidentally in a sequence, but does serial position impact choice after delay, and if so, how? We address this question in a consequential real-world choice domain. Using 25 years of citation data, and a unique identification strategy, we examine the relationship between article order (i.e., position in a journal issue) and citation count. Results indicate that mere serial position affects the prominence that research achieves: Earlier-listed articles receive more citations. Furthermore, our identification strategy allows us to cast doubt on alternative explanations (i.e., editorial placement) and instead indicate that the effect is driven by psychological processes of attention and memory. These findings deepen the understanding of how presentation order impacts choice, suggest that subtle presentation factors can bias an important scientific metric, and shed light on how psychological processes shape collective outcomes.	citation;explanation	Jonah Berger	2016	Topics in cognitive science	10.1111/tops.12205	psychology;mathematics education;management science;social psychology	HCI	-75.75339832674184	-14.569544004269337	90379
fb2cf3567f23efdce5835b41b2879258c0151ea8	nominations for treasurer and council		"""The terms of office of the present Treasurer and the four members of the Council of the Mathematical Programming Society expire in August, 1977. The Constitution of the Society states """"An election for any vacancy on the Council (whose members must be individual members of the Society) will be he ld . . , for Treasurer (who may be re-elected once) or for other members of Council (who may be re-elected after an interval of two years) . . . . Names of candidates for election are submitted six months before election to the Chairman-Elect, who decides the form of the ballot."""" I shall accordingly ask several representative members of the Society to constitute a Nominating Committee, whose task will be that of selecting two candidates for the office of Treasurer and about eight candidates for the four Council seats. The present Treasurer, Freerk Lootsma, will have completed one term of office at the time of the election; the present members of the Council are Jean Abadie, Roger Fletcher, Garth McCormick, and Terry Rockafellar. I am now asking the membership to assist the Nominating Committee by suggesting candidates for these positions. Their selection will be made on the grounds of willingness to serve the Society, capability, and geographical distribution. The more information that can be provided about a prospective candidate the better, and indication of his willingness to run is important. The Committee will particularly welcome a personal expression of interest in running for office from any member of the Society. Please send any such communication, which should include the equivalent of a v i t a and any other qualifications, to the address below by January 30, 1977."""	fletcher's checksum;jean;mathematical optimization society;prospective search	Philip Wolfe	1976	Math. Program.	10.1007/BF01580376	discrete mathematics;mathematics education;mathematics	HCI	-63.291915284665386	-18.21822113412117	90384
569b7c6f600514569a426756b328c994e273c85e	"""""""the reports of my death are greatly exaggerated"""" - artificial intelligence research in accounting"""		Gray et al. (2014) examined the productivity of expert systems/artificial intelligence research in accounting and came to the conclusion that both research on and practice use of expert systems/artificial intelligence had waned since the late 1990s. In our study, we reconsider these findings based on a broader view that is ‘artificial intelligence’ centric versus ‘expert systems’ centric. The results show that while there was a bit of a lull in the late 1990s, artificial intelligence research in accounting has continued to steadily increase over the past 30 years. Further consideration of artificial intelligence techniques as embedded modules in integrated audit support systems also suggest that use by practice continues to be robust. Based on these findings, we make a call for much more research on the usability, and use, of artificial intelligence techniques in accounting domains. Contrary to earlier perceptions, the research domain remains vibrant and holds great potential for AIS researchers to take a leadership role in advancing the field.	artificial intelligence	Steve G. Sutton;Matthew Holt;Vicky Arnold	2016	Int. J. Accounting Inf. Systems	10.1016/j.accinf.2016.07.005	accounting;intelligence cycle;marketing and artificial intelligence;computer science;artificial intelligence;management;operations research;world wide web	AI	-73.14206495822664	-15.5373888015021	90426
048131e1ad17b1fc96c28db6395d888090977805	business and information systems engineering: a complementary approach to information systems - what we can learn from the past and may conclude from present reflection on the future	future;information systems;past;004 informatik;business and information systems engineering;330 wirtschaft;bise;present;critical reflection;industry connections	Special Issue Although both communities share a common object of research, the Business and Information Systems Engineering (BISE) community from the German-speaking countries and the North American Information Systems (NAIS) community have developed quite differently. In our opinion, each community has the opportunity to learn from the other's strengths to mitigate its own weaknesses. The BISE community promotes connections with industry and draws substantial funding from there. BISE researchers' topics are attractive to students and ensure the practical relevance of publications. Due to various reasons, numerous BISE researchers struggle with strong contributions to theory, research quality, and publications in top-ranked journals. While this obviously is a strength of the NAIS community, we observe that the NAIS community struggles with its industry connections and enrollment numbers. What the global IS/BISE community needs is a more intense discourse that increases mutual understanding, creates awareness for the need to complement one another, and ensures that this opportunity is seized. Organized along the history of the BISE community's main publication outlet, this paper offers insights into the community's ability to fully engage with industry and how this ability was maintained over time. Based thereon, we as BISE insiders would like to give recommendations on how the NAIS community can mitigate some of its weaknesses. These recommendations are intended to complement the valuable hints already provided by NAIS scholars. They also intend to make insights into the traditional strength of the BISE community available when discussing the global IS/BISE community's future.	information systems;systems engineering	Hans Ulrich Buhl;Günter Müller;Gilbert Fridgen;Maximilian Röglinger	2012	J. AIS		psychology;public relations;futures and promises;social science;computer science;engineering;knowledge management;marketing;management science;sociology;management;social psychology;world wide web;information system	DB	-77.19963840442115	-15.916404505629398	90510
54ef9b0a34ec93bd140fdb6ed50db964e033927f	'so wide and varied': the origins and character of british information science	history;information science;subject specialization;british;special libraries;z665 library science information science;documentation	This paper examines some characteristics of the ‘British School’ of information science. Three main forces driving the development of the new subject in Britain are identified: the documentation movement; special libraries; and the need for better treatment of scientific and technical information. Five characteristics which, taken together, distinguish the early British approach to information science from those adopted elsewhere are identified: its subject-based nature; its broad approach to information and information science; its status as an academic subject with a strong professional remit; its involvement with, but distinction from, information technology; and its involvement with memory institutions. Lessons are drawn for the future development of the information sciences.	documentation;information science;library (computing)	Lyn Robinson;David Bawden	2013	J. Information Science	10.1177/0165551513492257	social science;information processes and technology;information science;documentation;computer science;documentation science;sociology;management;world wide web;information retrieval	HPC	-72.02996797320856	-20.178249592150177	90562
172f7dfb23f2957583b0a9a8f4bfe0367a845cc5	analysis of foreign ownership in china's listed companies	banking industry;foreign ownership;developing regions	"""This paper provides an overview of the foreign ownership in the China’s listed companies. The characters are as follows: 1) It has a small proportion of shares, showing not in control position in most companies; 2) it has a strong preference for the banking industry; 3) most of them have been located in the developed regions; 4) most of them mainly come from Asia, especially from Hong Kong, Macau and Taiwan; 5) most of them have share in value-add big companies. In addition, this paper found a significant difference in big foreign shareholders of stock preference between direct and indirect investment. DOI: 10.4018/jabim.2012070107 International Journal of Asian Business and Information Management, 3(3), 56-66, July-September 2012 57 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. development of Chinese stock market in the process of opening. 2.1. The General Situation of Chinese Stock Market Chinese stock market has been unique in the history of the world capital market so far for its quick-paced development, remarkable achievements and rich contents, though it has only a short history of 20 years. 2.1.1. Rapid Expansion of Chinese Stock Market Scale The size of stock market is measured by variables such as the ratio of stock market’s capitalization relative over GDP, number of Listed Companies, number of investors and stock trading volume. Figure 1 shows that, 1) the ratio of gross value of stock market over GDP increases quickly, from 3.89% in the year of 1994 to 66.69% in the end of year of 2010, reaching a summit of 123.07% on October, 2007. 2) The number of listed companies grows quickly, from 34 companies in the year of 1992 to 2304 companies in the year of 2011, resulting in an approximately 70-fold increase. 3) The number of investors grows rapidly. Investor accounts increase from 2,166,500 to 13,909,080,000 (10 percent or more of the population of China), resulting in over 60-fold increase. 4) Stock trading volume grows rapidly, from 68.3 billion RMB in 1992 to 2,068 billion RMB in the first 11 months of 2011, resulting in an approximately 30-fold increase. 2.1.2. Institutional Investors: The Main Force in Chinese Stock Market Along with the development of twenty years, Chinese stock market has transformed from a market dominated by middle and small retail investors in the first 15 years into one experiencing the development of institutional investors especially securities investment funds in new Millennium, rapidly after 2005. End October 2011, there are 872 funds in Chinese stock market, while the proportion of the value of shares held by various institutional investors to negotiable stock market capitalization is over 71%. 2.1.3. The Construction of Chinese Multi-Level Capital Market System Nowadays, China has two organized stock markets, Shanghai security exchange (SSE) Figure 1. Chinese stock market capitalization and GDP from 1992 to 2010 9 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/analysis-foreign-ownership-chinalisted/68988?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Business, Administration, and Management. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	information management;information science;librarian;web page	Shaobo Liu;Zhuqing Yang;Dezhu Ye	2012	IJABIM	10.4018/jabim.2012070107	accounting;commerce	NLP	-66.14685314789517	-14.571016801579633	90571
f25200c7c0c69cecdfcb19a7f4a4a381dc28cd3f	digital object identifier in effective media library management - an indian perspective	digital media;world wide web;indexation;conceptual framework;information management;web based applications	There has been a need for identity across generations. It has been in the form of paper, plastic and now digital. Digital Object Identifier (DOI) is a concept that helps to identify the needs of the end-users using technology on a digital environment. DOIs can point to documents, images, sounds, video clips, parts of works, gateways, works under development, evolving works, invoice screens (e.g. order forms, invitational membership forms or pay-per-view forms), rights agreements, a page pointing to an object, even constantly changing sources like news headlines or stock quotes. Virtually anything that a URL might point to now could be handled by the DOI system. DOI makes it possible to identify the information on a digital network, and associating it with related current data. DOIs are designed for use in any digital network, not just the World Wide Web, which is only one recent aspect of the evolution of digital networks and the use of digital objects within them. DOIs can be used in open or proprietary digital networks in broadcasting, multimedia systems, or indeed any conceptual framework. DOIs can be thought of as an abstract specification, which have a reference implementation in the current Internet technologies. From a media library point of view, with so much of news flowing in a media organization, one needs to be both subject as well as system expert to identify, organize, store and also retrieve information. Many attempts have been made to organize the newspapers over the years, from bound volumes to the recent full-text newspaper database to identify the news or information. The role of digital identifiers plays a part in some ways. Though DOI may not be used in true sense, information which is collected, stored and retrieved using digital media be it CD-ROMs, tape drives or web based applications are based on certain identification which may be in the form of numbers generated by database themselves or by manual inputs. Therefore, one can easily identify the news item hosted under various categories for either modification or for effective retrieval. Another area that digital media libraries are slowly moving into helping the organization bring out eBooks to enhance, sustain and provide value-added service to their reader/ browser and also bring in some extra revenue for the organization. Therefore, this paper looks at ways effectively to organize media library in managing information, storing, retrieving, indexing, classification and overall management of news flow in a media setup and also sees a need for DOI as a tool to reach to different target audiences and end users.	cd-rom;conceptual schema;digital electronics;digital environment;digital media;gateway (telecommunications);identifier;library (computing);point of view (computer hardware company);reference implementation;tape drive;video clip;world wide web	M. Tamizhchelvan;A. C. Ganesh;S. Swaminathan	2003				Web+IR	-68.02845424907248	-23.142406121350433	90572
e854bb7fc38683594b712c05164dc7f7f14f2f48	simulation of career development in the european commission	european commission;career development;statistical data analysis;simulation;government;hb economic theory;manpower planning;application	The European Commission (the Commission) employs more than 22,000 officials who provide administrative services to the European Union. In 2003, the Commission introduced a performance appraisal and promotion system based on points that the officials earn each year. In 2006, the Commission realized that the system needed to be revised. To support the review process, the Commission invited tenders for a project to develop simulation models that it could use to project the future performance of the existing system. A team from Lancaster University won the bid and subsequently worked closely with Commission officials to develop a new system. In 2009, the stakeholders in the Commission’s performance appraisal and promotion system agreed to implement the improved system. The simulation model is unusual in the field of manpower planning because it models the consequences of appraisal-system rules. It uses novel, accurate, and efficient sampling techniques that are based on regression models of the underlying relationships in the data. The model was a crucial part of renegotiating the appraisal and promotion system and implementing a new system.	sampling (signal processing);simulation	Bhakti S. S. Onggo;Michael Pidd;Didier Soopramanien;David J. Worthington	2010	Interfaces	10.1287/inte.1100.0489	economics;computer science;engineering;artificial intelligence;marketing;operations management;management;operations research;law;government	DB	-66.65170517442355	-14.79808972738466	90758
ec541032f30efe5f363219837b0c6325527ff7be	material text, immaterial text, and the electronic environment	edition electronique;edicion electronica;medio ambiente electronico;electronic environment;electronic publishing;environnement electronique	Digital modes of editing ask us to re-examine the past century of editorial theory and to situate emerging editorial approaches within this history. Using the computer as a new textual medium has brought about a renewed interest in the conditions for representation. This article concerns itself with how books and computers, respectively, represent texts, and how critical editing mediates or organizes those representations. It was written in 1997 as a critical response to J.J. McGann's essay 'The Rationale of Hypertext'.		Kathryn Sutherland	2009	LLC	10.1093/llc/fqn033	computer science;artificial intelligence;multimedia;electronic publishing	HCI	-69.47612333848905	-20.85340445303476	90782
5b98c9a41dbe638a5337a8500450258b355bf6ac	rmit publishing: neither fish nor fowl	australie;oceanie;modele entreprise;edition electronique;industria informacion;editor;modelo empresa;politique commerciale;business model;marketing policy;information industry;edicion electronica;industrie information;publisher;electronic publishing;editeur;oceania;politica comercial;australia	In a time when university presses are struggling to survive and most require financial support from their parent institutions, RMIT Publishing – an electronic publisher from its inception in 1989 – has grown its annual sales from AU$2.8m in 2003 to an expected AU$6m in 2007. This 100% sales growth in five years has been achieved by RMIT Publishing’s unique, context-driven approach to electronic publishing. This approach has made RMIT Publishing the publisher of choice for Australian databases, aggregated scholarly content for the global market and now ‘born-digital’ publications.	database;software testing controversies	Janette Wright;Sara Hearn	2007	Learned Publishing	10.1087/095315107779490625	business model;economics;telecommunications;computer science;information industry;sociology;advertising;electronic publishing;management;operations research;law	DB	-72.48061882371547	-20.67388196245638	90854
e6658cc335a33dd0510563a2ba49e87399a8f81d	pedagogical content knowledge in computing education: a review of the research literature		ABSTRACTThis review synthesizes literature on computing pedagogical content knowledge (PCK). Shulman introduced PCK in the 1980s to describe the amalgam of knowledge teachers draw upon in their work and use of the construct is increasing in the computing education community. From a systematic search of the literature, I identified 19 articles drawn from 9 countries for review and summarize how computing PCK is conceptualized and investigated in the data set. Five conceptualizations of computing PCK were present: (a) two models of computing PCK components, (b) one model of PCK development and (c) two models focused on the metaphoric and problem-solving nature of computing. The most common research lines addressed were the nature and development of individual PCK. Mostly qualitative methods created by authors were employed. A focus on discipline-specific approaches for future computing PCK research is recommended.	scientific literature	Aleata Hubbard	2018	Computer Science Education	10.1080/08993408.2018.1509580	pedagogy;teaching method;qualitative research;computer science	NLP	-75.39711533685659	-18.400243694066038	90877
f40b1a30265cc585a6b23b8dbf3a81cd14a286ce	"""a personal history of the origins of the national association of mathematicians' """"presentations by recipients of recent ph.d.'s"""""""				Donald M. Hill	1996			genealogy;history	Vision	-63.39893232904337	-12.674000743193691	90935
a98d8684ce9936afa793ced5482f390fad8927bd	state of the art on the systems of innovation research: a bibliometrics study up to 2009	systems of innovation;innovation systems;bibliometrics	Over the last decades there has been a growing interest on developing research and formulating public policy by using the Innovation Systems approach. However, as evidenced on the academic literature there is a lack of systematic, chronological and synthesizing studies indicating how this field has evolved over time. This paper has as main objective to consolidate the state of the art of academic research on IS, based on a bibliometrics study on literature published over the past 35 years. The results are discussed under the following perspectives: general results, chronological distribution, author relevance, articles and cited references of relevance, journals relevance and institutions and countries relevance. The paper ends with a discussion of the main implications and limitations of the study.	bibliometrics;relevance	Mauricio Uriona-Maldonado;Raimundo N. M. dos Santos;Gregório Varvakis	2012	Scientometrics	10.1007/s11192-012-0653-5	social science;bibliometrics;computer science;knowledge management;data mining;world wide web	NLP	-75.83795972511992	-17.727276748726716	90937
3104cd9592aad5fefe9603f31b72bfdd4054c38d	who gets funding? let the people decide		In The Department of Mad Scientists, 1 Michael Belfiore offers a glimpse into the workings of the maverick Defense Advanced Research Projects Agency (DARPA), which is responsible for the birth of the Internet and GPS, among other amazing inventions. The small percentage of Americans who know about DARPA may have heard about it because it funds the Grand Challenge Race, with a $2 million prize for the first autonomous robot that makes it through a desert course, avoiding obstacles and following the rules. ‘‘One enormous continuing development is the exponential growth of social networking media and the increasing use of social media by companies to crowdsource ideas, mount contests to award prizes and gather audiences, and attempt to create dialogues with customers,’’ wrote Rosabeth Moss Kanter in her syndicated column toward the end of 2010. The following examples illustrate how these new types of contests can work, and provide food for thought about new possibilities for research and development funding. In 2010, Google awarded a total of $10 million to five finalists in its Project 10^100 contest, which solicited ideas for changing the world by helping as many people as possible. From 150,000 ideas submitted by people in 170 countries, Google selected 16 big ideas and let people vote for their favorites. The Pepsi Refresh Project is looking for great ideas that are going to ‘‘refresh the world.’’ As with traditional grant funding, there are specific grant cycles, applications, and categories for projects costing from $5,000 to $50,000. What is new is that the project director gets to promote his/her project through videos and social media such as Twitter and Facebook, and the projects that garner the most votes win. Pepsi awards up to $1.2 million each month for such projects. A 2011 contest sponsored by Enterprise Rent a Car was called Giving Back. It allowed visitors to its Facebook page to decide among 10 competing charities nominated by Enterprise employees. The first-place winner received $10,000, the second-place winner received $5,000, and the thirdand fourth-place winners received $2,500 each. The contest gave Enterprise Rent a Car an opportunity to promote its foundation, which gives 75% of its funds to employee-suggested charities. Talking about the Dockers ‘‘Wear the Pants’’ contest, in which entrants submitted a 400-word business plan and awards were made on the basis of votes from both community members and a panel of judges, one author offers tips for businesses wishing to engage in social media contests:	autonomous robot;awards;bookmark (world wide web);categories;charities - organization;chimeric antigen receptor;crowdsourcing;darpa grand challenge;global positioning system;gray platelet syndrome;internet;maverick framework;rule (guideline);social media;speech;time complexity;video	Brenda K. Wiederhold	2011	Cyberpsychology, behavior and social networking	10.1089/cyber.2011.1520	social psychology;public relations;psychology	AI	-63.14523657539026	-19.49400974583985	91010
5001416e0bece4fcc52b111291fedc4ed1d21981	complementary value of databases for discovery of scholarly literature: a user survey of online searching for publications in art history	search engines	Discovery of academic literature through Web search engines challenges the traditional role of specialized research databases. Creation of literature outside of academic presses and peer-reviewed publications expands the content for scholarly research within a particular field. The resulting body of literature raises the question of whether scholars prefer the perceived broader access of Web search engines or opt for the precision of field-specific research databases. Surveys of art historians indicate a complementary use of on-line search tools with a reliance on field-specific research databases to discover authoritative content. Active use of Web search engines and initiatives for open access suggest that research databases will integrate into an evolving Web-based infrastructure that supports discovery and access of scholarly literature.	database;relevance;thesaurus	Erik Nemeth	2010	C&RL		library science;data science;search engine;database;information retrieval;computer science	DB	-70.01691066379604	-22.281062335028423	91021
5bc3c849993bf7efbb38cbee4a178027f39e948c	ancient roman coin retrieval: a systematic examination of the effects of coin grade	t technology;qa75 electronic computers computer science;cj numismatics;conference item;de the mediterranean region the greco roman world	Ancient coins are historical artefacts of great significance which attract the interest of scholars, and a large and growing number of amateur collectors. Computer vision based analysis and retrieval of ancient coins holds much promise in this realm, and has been the subject of an increasing amount of research. The present work is in great part motivated by the lack of systematic evaluation of the existing methods in the context of coin grade which is one of the key challenges both to humans and automatic methods. We describe a series of methods – some being adopted from previous work and others as extensions thereof – and perform the first thorough analysis to date.		Callum Fare;Ognjen Arandjelovic	2017		10.1007/978-3-319-56608-5_32		Vision	-72.51380397342288	-15.452780553804482	91138
00b161cf45ad5d512b9079ed7aa9d946ea8558ce	a quantitative analysis of antarctic related articles in humanities and social sciences appearing in the world core journals	antarctic studies;bibliometric study;humanities and social sciences	To demonstrate the importance and the actual research situation of Antarctic studies in the humanities and social sciences, we collected data from the SSCI and A&HCI covering a period of over 100 years and focused on the number of articles published each year, major journals, types of document, authors and their countries publishing the most articles, collaboration, the major research subjects covered, and citations. Comparisons were also made with the Arctic studies to show some similarities and differences. The results suggest that the research in the fields of humanities and social sciences has been in the long-run developing without interruption over 100 years. With regard to the number of articles in high-capacity journals, Geographical Journal performs best, followed by the Petermanns Geographische Mitteilungen and Scottish Geographical Magazine. The documentation is rather scattered without a strong cohesion, while book review and article are the two most common types of document. There haven’t many stable collaborated teams on Antarctic topics. Joyner, Savours, and Beck are the three authors having the highest number of publications. USA is the most active country while the most active research institute is University of Tasmania in Australia. The Antarctic expedition has been the main theme lasted for centuries. In addition, the research in the fields of humanities and social sciences has generated a lot of high-impact articles, among which the article entitled “Chemical concentrations of pollutant lead aerosols, terrestrial dusts and sea salts in Greenland and Antarctic snow strata” enjoys the highest citation counts.	cohesion (computer science);documentation;interrupt;social sciences citation index;terrestrial television	Weina Hua;Yu Li;Shunbo Yuan	2013	Scientometrics	10.1007/s11192-013-1190-6		ML	-75.80632317823331	-20.332510923117827	91140
ca0908f2bfc4e6f0a4280520cb1fbeab008e747c	mickey, judy, colin, and me	electronic publishing;online publishing	Creating an electronic journal on the Internet is a lot more like staging a musical in a Mickey Rooney - Judy Garland film than like a business venture. The Journal of Electronic Publishing doesnu0027t pretend to be a business-in-the-making, but instead is the University of Michigan Pressu0027s basic research into e-publishing.	judy array;mickey	Judith Axler Turner	1998	First Monday		computer science;media studies;electronic publishing;world wide web	Crypto	-64.25412306363722	-16.39285235200495	91215
bb655f03f370eeb15f8dbe0e8fdd64e8a637ac30	spatial factors as contextual qualifiers of information seeking	figurative language;information sources;research reports;work environment;books;informacion documentacion;fi artikkeli aikakauslehdessa en journal article;spatial ability;grupo a;information seeking;ciencias sociales;grupo b	Introduction. This paper investigates the ways in which spatial factors have been approached in information seeking studies. The main attention was focused on studies discussing information seeking on the level of source selection and use. Method. Conceptual analysis of about 100 articles and books thematizing spatial issues of information seeking. Due to research economy, the main attention was paid to studies on everyday life information seeking. Results. Three major viewpoints were identified with regard to the degree of objectivity of spatial factors. The objectifying approach conceives of spatial factors as external and entity-like qualifiers that primarly constrain information seeking. The realistic-pragmatic approach emphasizes the ways in which the availabilty of information sources in different places such as daily work environments orient information seeking. The perspectivist approach focuses on how people subjectively assess the significance of various sources by means of spatial constructs such as information horizons. Conclusion. Spatial factors are centrally important contextual qualifiers of information seeking. There is a need to further explore the potential of the above viewpoints by relating the spatial and temporal factors of information seeking.	book;information seeking;objectivity/db	Reijo Savolainen	2006	Inf. Res.		sociology;literal and figurative language	Web+IR	-76.45751100617997	-16.47034147104744	91227
20f366b22c0f18201cd22aab6690341fa875b487	online sex shops: phenomenological, psychological, and ideological perspectives on internet sexuality	empirical research	Explosive growth in access to the Internet has created an unprecedented opportunity for the general public to acquire explicit erotic texts, images, services, and merchandise, but psychological scientists have not conceptualized antecedents or consequences of contact with Internet sexuality or conducted a significant amount of empirical research on these issues. The current analysis uses Internet sex shop sites as a case example of Internet sexuality, and offers a phenomenological exploration of the world of Internet sex shop sites, conceptualizes antecedents and consequeces of use of Internet sex shop sites from the perspective of the Sexual Behavior Sequence , and suggests a conceptually based agenda for future empirical research in this area. Discussion concludes with consideration of ideological aspects of research on Internet sex shop sites and Internet sexuality broadly conceived.	eroticism;internet	William A. Fisher;Azy Barak	2000	Cyberpsy., Behavior, and Soc. Networking	10.1089/109493100420188	psychology;medicine;computer science;sociology;psychotherapist;empirical research;social psychology	ML	-76.02584447880886	-16.580884204858048	91312
c936ee807c3cfa61e1bef19a6861fe2125070730	social networking sites	political communication	........................................................................................................... 17 PART I: The Introductory Text Chapter 1 Introduction ................................................................................ 20 1.1 Background ................................................................................................ 20 1.2 Research Purpose ....................................................................................... 22 1.3 Outline of the Dissertation ......................................................................... 23 Chapter 2 Literature Review ...................................................................... 25 Chapter 3 General Understanding of Main Concepts .............................. 34 3.1 Social Media Sites & Social Media Marketing .......................................... 34 3.2 Social Networking Sites (SNSs) ................................................................. 35 3.3 Marketing Innovation and Social Networking Sites .................................. 36 Chapter 4 Theoretical Framework ............................................................. 41 4.1 Uses and Gratifications Theory .................................................................. 41 4.2 Models of assessing the value of online ads ............................................... 44 4.3 Assessment of ad value on SNSs................................................................ 45 4.4 The Extended Conceptual Framework ....................................................... 46 4.4.1 Consumer belief factors ..................................................................... 46 4.4.2 Consumer motive ............................................................................... 50 4.4.3 Social Factors ..................................................................................... 51 Chapter 5 Methodology ............................................................................... 55 5.1 Research Paradigm ..................................................................................... 55 5.2 Research Approach..................................................................................... 57	online advertising;paradigm;social media marketing	Hossam A. Deraz	2014		10.1007/978-1-4614-6170-8_110079	library science;computer science;media studies;world wide web	HCI	-63.33712157528161	-13.530649787699094	91315
90a4f07158684e9d12818b2b4ff0da020c94d070	"""""""network neutrality"""": the meme, its cost, its future"""	internet measurement;regulation;public policy;management;venture capitalist;identity theft	"""In June 2011 I participated on a panel on network neutrality hosted at the June cybersecurity meeting of the DHS/SRI Infosec Technology Transition Council (ITTC), where """"experts and leaders from the government, private, financial, IT, venture capitalist,and academia and science sectors came together to address the problem of identity theft and related criminal activity on the Internet."""" I recently wrote up some of my thoughts on that panel, including what network neutrality has to do with cybersecurity."""	computer security;information security;internet;meme;net neutrality	Kimberly C. Claffy	2011	Computer Communication Review	10.1145/2043165.2043172	public policy;regulation;identity theft;venture capital;computer security	Networks	-69.18166986495794	-10.910150477345743	91340
3c69c8a235943bb38cf6ba9d388b7003bfe01b67	editorial pointers		COMMUNICATIONS OF THE ACM October 2007/Vol. 50, No. 10 5 IT WAS ONLY A MATTER OF TIME BEFORE OUTSOURCING branched off in so many directions it would turn back on itself. Where industry was once motivated to move production or support operations to vendors many time zones away in order to cut costs, a new trend is fast emerging that promotes such opportunities much closer to home. A growing number of companies and countries are promoting their “nearshore” advantages, still promising production cost reduction, but with all the benefits of a more convenient location. Erran Carmel and Pamela Abbott explore this trend in “Why ‘Nearshore’ Means that Distance Matters,” finding evidence that miles indeed make a difference. Where offshore vendors have long promoted location transparency, nearshore vendors argue that proximity gives clients the benefits of better communication, supervision, and coordination. Moreover, Carmel and Abbott find “the emergence of nearshoring in an industry that encourages virtual forms of working presents yet more evidence that distance still matters.”	communications of the acm;emergence;outsourcing	Diane Crawford	2007	Commun. ACM	10.1145/1290958.1290973		HCI	-66.46686279906089	-22.150326972278926	91527
c2fe67f0f6c5fb4dadb018632eb2165bbd9c1cf3	educational informatics: an emerging research agenda	informatica;ciencia informacion;europa;universite;theoretical framework;new information communication technology;information science;research agenda;biblioteconomia;library and information science;bibliotheconomie;learning environment;education technology;learning support;information and communication technology;royaume uni;united kingdom;ict in education;reino unido;librarianship;technologie education;informatique;university;nouvelle technologie information communication;enseignement;computer science;europe;educacion;sheffield;science information;recherche scientifique;universidad;scientific research;nueva tecnologia informacion comunicacion;investigacion cientifica;teaching;ensenanza	This paper discusses educational informatics as a research field and provides an overview of the scope of work in this, and closely related, areas by members of the Department of Information Studies at the University of Sheffield. Current work in Sheffield focuses on the use of information and communications technologies (ICTs) in universities and schools, seeking to understand the effects of using ICTs in educational practice on learners, teachers and learning support staff. It also seeks to develop practical knowledge of relevance to the design and facilitation of ICT-enabled learning environments. The paper highlights the interdisciplinary nature of this research, and discusses theoretical frameworks and methodological approaches that are being used by Sheffield researchers. It concludes by suggesting that library and information science has a distinctive contribution to make to the study of ICTenabled learning, and that there is a need for further discussion within the literature of this emergent field of inquiry.	emergence;informatics;information literacy;information system;library and information science;relevance;theory;ucl department of information studies	Philippa Levy;Nigel Ford;Jonathon Foster;Andrew D. Madden;David Miller;José Miguel Baptista Nunes;Maggie McPherson;Sheila Webber	2003	J. Information Science	10.1177/01655515030294006	information and communications technology;social science;scientific method;information science;computer science;sociology;informatics;management	HCI	-73.28024668539578	-22.59689791969051	91693
ed6c21a343a50a3d994a69df39b1ec9c32df5d5a	grants for libraries: a how-to-do-it manual and cd-rom, s.r. gerding, p.h. mackellar. neal-schuman publishers inc, new york (2006), isbn: 1-55570-535-9		This book is very much written by practitioners for practitioners and is aimed at an audience interested in grants and libraries, an area of increasing importance given shortages and budget cuts within the library service sector. Grants for libraries provides a range of practical tools and instruction needed to win financial awards for libraries. Practical tools include worksheets, examples, templates and checklists that take the reader through each step in the grant process cycle in an easy to follow manner. This ‘How-to-do-it Manual’ is divided into three main parts. Part I covers ‘The Grant Process Cycle’ and contains several relevant chapters covering all possible aspects of the cycle that include ‘Making the Commitment and Understanding the Process’, ‘Planning for Success’, ‘Organizing the Grant’, ‘Researching and Selecting the Right Grant’, ‘Getting Funded and Implementing the Project’ and ‘Reviewing and Continuing the Process’. Throughout this part of the book, references are made to the highly practical and useful Tool Kit and CD-ROM in which the reader can complete a variety of checklists, worksheets and templates. Part II ‘Library Grant Success Stories’ provides sixteen interesting and useful examples of funded projects relating to various size libraries from the USA that illustrate best practices. In each of the case studies, the participants reflect upon key issues such as ‘What made their proposal/project successful?’, ‘Do you have any advice for other grant seekers?’ and ‘What was the most difficult part of the grant process?’ Part III contains ‘The Grants for Libraries Took Kit and CD-ROM’ which are reproduced as Microsoft Word documents. The final part of the book contains a useful glossary of grant-related terms. Each of the chapters is written in a clear, concise and well-structured manner. For example, the chapter on ‘Planning for Success’ is particularly useful in that it contains a library planning checklist and exemplar library strategic plan to illustrate key aspects in the planning process. The final chapter in Part I of the book, ‘Answering Five Essential Questions’ contains key questions and guidance to evaluate a project’s potential for success such as ‘Does your library have the capacity to implement and support this project?’, ‘How will this grant make an impact?’, ‘Is your project sustainable?, ‘Do you have real relationships with funders and partners?’ and ‘How will you know that you’ve been successful?’. Whilst this book is directed more towards American libraries and sources of funding, it contains a wealth of information and advice that will be of interest and practical use to librarians throughout the world, facing similar challenges in securing external funding. The authors are to be congratulated in producing a highly practical, interesting and accessible book.	american libraries;best practice;cd-rom;glossary;international standard book number;librarian;library (computing);microsoft word for mac;while	Mark Stansfield	2007	Int J. Information Management	10.1016/j.ijinfomgt.2006.11.003	engineering;knowledge management;library science;cd-rom	PL	-67.8796226400734	-17.996716171417553	91995
b402c45ff37648f311023fc4ebc2b644328ad3cf	the comparative impact of scientific publications and journals: methods of measurement and graphical display	citation analysis;impact factor;sciences;analisis cita;besoin utilisateur;necesidad usuario;publicacion en serie;ciencia;analyse citation;user need;research evaluation;publication en serie;evaluation;evaluacion;serial	A method is presented to display the comparative impact of scientific publications relative to their ‘environment’ (e.g., journals). Furthermore, the method gives a new approach to the establishment of a journal's impact as measured by received citations. Moreover, in this impact measurement a differentiation between various types of publications (editorials and letters, ‘normal’ papers, reviews, etc.) can be made. It is argued that the method presented is more useful for library and research evaluation policies than the ISI impact factor.	graphical user interface;infographic;information sciences institute;scientific literature	Anthony F. J. van Raan;D. Hartmann	1987	Scientometrics	10.1007/BF02279352	computer science;evaluation;operations research;citation analysis;world wide web	HPC	-75.89878566680632	-22.602264753868866	92015
429d870732beaf0e7158980ea6fcf1151192ce29	two machine indexing projects at the catholic university of america	indexation;automation;indexing	This paper describes the application of Keyword-in-Context/KWIC/Keyword-Out-of-Context/ KWOC programs (IBM 1401-CR-02X) to indexing masters’ theses and doctoral dissertations at the Catholic University of America. Two recent (1970) computer-produced indexes, one covering 5458 masters’ theses and doctoral dissertations accepted in all schools between 1961 and 1967, inclusive, and the other covering 975 masters’ theses in nursing accepted between 1932 and 1961, are described. The machine configuration, programs, genera1 system, options within the system, card layouts, printing and binding specifications, and costs are discussed.	key word in context;printing;the machine	Fred Blum	1971	Information Storage and Retrieval	10.1016/0020-0271(71)90011-8	computer science;automation;world wide web;ibm;machine indexing;automatic indexing;search engine indexing	OS	-70.52137101451963	-23.598213612241093	92554
011a0993f1076d741328864902c665f25ae4bfa3	bibliometric analysis of the use of the term preembryo in scientific literature	scientometrics;scholarly publishing;terminology;primary literature;scientific and technical information	Our objective was to determine the prevalence of the term preembryo in the scientific literature using a bibliometric study in the Web of Science database. We retrieved data from the Web of Science from 1986 to 2005, covering a range of 20 years since the term was first published. Searches for the terms embryo, blastocyst, preimplantation embryo, and preembryo were performed. Then, Boolean operators were applied to measure associations between terms. Finally, statistical assessments were made to compare the use of each term in the scientific literature, and in specific areas where preembryo is most used. From a total of 93,019 registers, 90,888 corresponded to embryo; 8,366 to blastocyst; 2,397 to preimplantation embryo; and 172 to preembryo. The use frequency for preembryo was 2:1000. The term preembryo showed a lower cumulative impact factor (343) in comparison with the others (25,448; 5,530; and 546; respectively) in the highest scored journal category. We conclude that the term preembryo is not used in the scientific community, probably because it is confusing or inadequate. The authors suggest that its use in the scientific literature should be avoided in future publications. The bibliometric analysis confirms this statement. While preembryo hardly ever is used, terms such as preimplantation embryo and blastocyst have gained wide acceptance in publications from the same areas of study. © 2011 Wiley Periodicals, Inc.		Luis Vivanco;Blanca Bartolomé;Montserrat San-Martín;Alfredo Martínez	2011	JASIST	10.1002/asi.21505	primary source;scientometrics;computer science;data mining;linguistics;terminology;world wide web;information retrieval	HCI	-77.37715288201362	-22.00988449420823	92569
539dd76b2c19b18c4b79b01e47f96ba32e96c472	development of internet technology and norwegian participation		Ideas emerged over several years. From 1968, some fundamental techniques developed in an admirable cooperation between academic groups. The technical development was at its most active during a decade from the early 1970s in a close collaboration between ten groups, eight in the USA, one in England, and one in Norway.		Yngvar Lundh	2010		10.1007/978-3-642-23315-9_32	environmental protection;political science;media studies;operations research	Robotics	-66.05329205139651	-12.391506722785383	92604
a7415001362dac8b3ce821543bcebf19d73a48fc	office etiquette during the holidays	holidays office etiquette;holidays;behavorial science;personnel behavorial science;office etiquette;personnel	Planning Your Vacation Time Most companies balance the number of people off at one time to ensure there’s always coverage in each department or group. Sometimes, the decision is based on seniority; sometimes, leave time is granted on a first-come, firstserved basis. So, it’s important to understand your company’s policy—how does management determine who takes leave, and how are conflicts are handled? As soon as you know you’d like time off, submit your request in writing. If you work for a company that requires you to use your leave before the end of the year, take into account that many people might be requesting leave during the same time period as you, so request as early as possible. For this reason, spread out your leave across a few weeks or months if possible. Don’t try to take the last three weeks of December off. This reflects poorly on your planning capabilities. Similarly, don’t plan on taking off the week of Thanksgiving and the two weeks between Christmas and New Year’s. You need to be a team player for office coverage, so prioritize your leave request. If there’s a conflict, be flexible if you can to show you’re willing to work as a team. If you’ve already bought plane tickets, say so, but if you’re driving and can leave a day later, offer this option. If you’re just taking the time because you have to use the leave, see if you can rearrange your schedule and take it off during a different period. However, don’t make plane reservations before requesting your leave, assuming you can use the tickets as justification for vacation approval. Failing to request the leave before buying the tickets shows poor planning on your part. Also, just because you always take the day off after Thanksgiving, requesting it well in advance, don’t assume you “own” that leave day. Others might want to shop on Black Friday too.	failure	Linda Wilbanks	2013	IT Professional	10.1109/MITP.2013.97	simulation;advertising	AI	-66.57964064883271	-21.319512948077218	92681
5fe1ba1824ce4335621729e3f566c68f6b98ac17	how frequently do allegations of scientific misconduct occur in ecology and evolution, and what happens afterwards?	ecology;evolution;misconduct allegations;scientist misconduct	Scientific misconduct obstructs the advance of knowledge in science. Its impact in some disciplines is still poorly known, as is the frequency in which it is detected. Here, I examine how frequently editors of ecology and evolution journals detect scientist misconduct. On average, editors managed 0.114 allegations of misconduct per year. Editors considered 6 of 14 allegations (42.9%) to be true, but only in 2 cases were the authors declared guilty, the remaining being dropped for lack of proof. The annual rate of allegations that were probably warranted was 0.053, although the rate of demonstrated misconduct was 0.018, while the rate of false or erroneous allegations was 0.024. Considering that several cases of misconduct are probably not reported, these findings suggest that editors detect less than one-third of all fraudulent papers.	biological evolution;dropping;ecology;journal;paper	Gregorio Moreno-Rueda	2013	Science and engineering ethics	10.1007/s11948-011-9289-8	engineering ethics;forensic engineering;law	HPC	-74.25575387402594	-14.119448999097159	92684
c36964ab3c9161933361c58baa3c5babe639663a	computer networks and data sharing: a bibliography		The bibliography is broken into seven subject areas - general data structures, data description, data conversion, data management, data security, data transmission, and computer network design. Two of these areas, general data structures and data management, cover a very broad range of subjects: however, in these two areas, only entries that seem to be specially pertinent to computer networks and data sharing are included. The bibliography also contains an index of authors.	computer networks (journal)	Alvin P. Mullery	1972	RFC	10.17487/RFC0290	library science;human–computer interaction;data science	ECom	-72.40973202005627	-19.464991608790847	92848
1387edcf4f3bd2a24ed672021d87390dc4c88ebf	the social life of information (book excerpt)			the social life of information	John Seely Brown;Paul Duguid	2000	Ubiquity	10.1145/334458.334468	computer science;knowledge management	NLP	-64.57791798175262	-11.435618652263084	92977
01fe2df5b3f2a73f27ed7c1b78808fce194091aa	bibliometric study of academic interaction: it, organization, and change	business studies;interaction;social sciences;bibliometrics;organization;information technology;business administration	This paper explores the degree and nature of the research interaction between the academic fields of Information Technology, Organization, and Organizational Change. This is done so as to see if, and how, the highly digitized modern business world is reflected in related research. The paper analyses 9.669 articles published in 1995-2006 that are derived from major journals within each field. Then the articles are reviewed through the use of the bibliometric methods: frequency, cross-reference, cocitation, shared references, and network analyses. The findings detect a dearth of consistent research interaction between the fields of Information Technology, Organization, and Organizational Change. This fact is critiqued on the basis of previous practical and academic calls for interactional research. The paper provides important insights about the degree and nature of the research interaction and, in addition, recommendations and guidelines for future cross-fertilization between the academic fields are provided.	bibliometrics;cross-reference;enterprise resource planning;materiality (digital text);monolithic kernel;organizing (structure);tracing (software)	Pontus Fryk;Einar Iveroth;Olle Persson	2009			public relations;interaction;economics;bibliometrics;computer science;organization;knowledge management;change management;management;law;information technology;business studies;organizational architecture	HCI	-75.58688576782615	-17.194217604139705	93234
22bc6a142f615f32e016181368f1d14376bb9ec8	de-unifying a digital library	digital library;multimedia;unification	The University of Tasmania decided to explore using a unified digital library for all its research output: journal articles, conference papers, higher degree theses, and other types. This decision is in advance of the state of the Australian national indexing systems. The digital library also uses OAI-PMH protocols for harvesting, which one of the national repositories does not as yet. The paper describes the context, reasons for the University’s decision, consequences and outcomes, and the development of software to talk to the Australian Digital Theses Program.	digital library;the australian	Arthur H. J. Sale	2005	First Monday			HPC	-65.66484754372772	-15.084319979797462	93529
3f16547bc7d198a4426fdee0ccf24274dbe6da30	how can we measure email overload?		In times of digital information and communication technologies the overload by emails becomes more and more relevant for many employees. To reduce or even avoid this overload, companies can implement specific countermeasures as soon as they recognize the overflow their employees’ experience. But if somebody is overloaded can not be answered directly by oneself; therefore it is necessary to use suitable constructs to measure email overload. This article includes a literature review to identify constructs to measure this phenomenon. From the field of information systems 55 highly ranked journals and conferences, furthermore 24 sources from the field of psychology were included. Finally, we could identify three different constructs by Dabbish and Kraut (2006), Hogan and Fisher (2006), and Sumecki, Chipulu and Ojiako (2011) to measure email overload. Beyond that, the article focuses on the description of the development of these instruments, discusses advantages and disadvantages, and gives an outlook what should be improved in these instruments in the future.		Sebastian Kammerer;Sebastian Sprenger;Jochen Hetzenecker;Michael Amberg	2012				HCI	-73.89155989590452	-17.216667865148967	93822
1f439b0be38adce0f767d88d89f5e4602197cea0	a simple management tool for medium-sized web sites	management tool	Site management is one of the key issues in Web publishing. Whereas smaller sites can be still managed manually, large Web sites generally require a systematic approach, usually involving sophisticated tools operated by skilled personnel. Between these two extremes are medium-sized sites. Although site management tools exist for both extremes, the market coverage of the mid-size segment is somewhat sparse. In this paper we describe our own tool, aimed at small and medium sized Web sites, of some 1000 pages. It is simple to use and needs no special skills or knowledge to be operated. Yet it is powerful enough to manage a site of a small organization and to enforce a common corporate identity. We use it for management of our department site, as well as for managing contents of various on-line education projects.	google sites;online and offline;sparse matrix	Igor Fischer;Andreas Zell	2000		10.1007/978-3-540-39916-2_7	education;the internet;simulation;computer science;world wide web	Web+IR	-69.01395391949474	-18.8134446477139	93912
44a1e2acfd125621fd263c1c9b809ec2f77a6838	critique on multi-criteria assessment applied to alternative data processing systems	data processing	Context It is assumed we are discussing the applicability of multicriteria analysis to the decision made during or at the end of a feasibility study. Prior to initiation of the feasibility study, an armchair analysis of possible applications has been made and one has been selected as meriting further study or some event has triggered off the desire to consider a new system. The systems analyst has been briefed to further explore the 'feasibility' of this application and, as a result of his fact finding, he now sees a set of prima facie viable designs, from which he wishes to choose the best and explore in more detail the technical and human alternatives and side effects, as well as the economic consequences, in order to support a 'go'/ 'no go'/'postpone' decision about introducing the new system.	cdc cyber;compiler;computer keyboard;computer terminal;end-of-file;lexical analysis;pascal;side effect (computer science);structured programming;the computer journal;transportation theory (mathematics)	A. Parkin	1978	Comput. J.	10.1093/comjnl/21.2.188	data processing;computer science	HCI	-66.07072755430181	-13.662294926636466	94025
b3daac8101a08ea02c26f69319d3fb12ee3374cb	"""breathing life into """"living documents"""""""	software engineering	A multitude of sins can be hidden behind the phrase “living document.” You can submit documents that are incomplete or inconsistent as long as you promise to fix it later. In this month’s issue of Strategic Software Engineering, I want to talk about the strategic importance of being realistic about the state of knowledge, plans and documents in a project..	goto;interdependence;living document;software engineering	John D. McGregor	2006	Journal of Object Technology	10.5381/jot.2006.5.4.c2	simulation;computer science;engineering;knowledge management;data mining	SE	-64.4215252756268	-20.18396275185372	94029
4d7a843fc07f9687c28e32aaad5294d4b571b223	library school faculty strengths in data processing canadian-u.s. differences	case history;enseignement superieur;enseignant;graduate level education;data processing;bibliotheconomie;ensenanza superior;historique;royaume uni;united kingdom;reino unido;librarianship;docente;teacher	This study examined the relative strengths of faculty expertise in the field of data processing within schools of library and information science in North America. The relative strengths of Canadian versus U.S. schools, measured by reported faculty expertise, was the particular focus of the study. Data were gathered from the directory issues of the Journal of Ed~cutio~ for ~~~~a~ians~j~ for the years 19721981. Data were aggregated into two groups: (1) total faculty strength dichomotized by U.S. and Canadian schools; (2) faculty reporting expertise in data processing or automation broken down by U.S. versus Canadian. Planned comparisons using a Dunn procedure were made on each of the ten years in the study. The results of testing indicated there is a significant difference in the number of faculty reporting expertise in data processing in the two countries in four of the ten years. The differences were opposite in two of these four, however. Results of testing of overall faculty strength indicated there was no significant difference in the numbers of faculty members during the ten year period. The major conclusion of the study was that Canadian schools of library and information science have made a concerted and successful effort to increase their over& level of expertise in data processing, but without significantly adding to their faculty levels.	directory (computing);library and information science	C. D. Hurt	1985	Inf. Process. Manage.	10.1016/0306-4573(85)90025-1	data processing;computer science;medical history;database;law	DB	-76.68267797969023	-23.400211386526703	94105
26dd416d46147fcff8b913634a2dc208b46ca3d1	the spanish transition to democracy seen through the spanish database isoc	analyse bibliometrique;analisis contenido;europa;bibliographic database;sciences humaines;document publie;policy;indexing term;espana;social sciences;base donnee bibliographique;evolucion;1976 1985;ciencias humanas;changement politique;content analysis;contenu sujet;social science;etude longitudinale;estudio longitudinal;humanities;termino indizacion;published document;subject content;terme indexation;political change;sciences sociales;espagne;bibliometric analysis;analyse contenu;europe;politica;follow up study;ciencias sociales;politique;documento publicado;analisis bibliometrico;evolution;spain	The study has tried to look at the political transition through the articles published by Spanish scientists in Spanish journals of Social Sciences and Humanities. A sample of 11000 article references from a selected set of 32 journals published from 1976 till 1985, has been the basis of the analysis. This time frame has been divided into two 5 year periods in order to detect any change in the topics published. The result of the analysis has been compared with the “events” as recorded by “El Pais” a very popular newspaper, during the same 10 year period and with a set of specific articles devoted to the Spanish political transition.		Adelaida Román;Aida Méndez	1994	Scientometrics	10.1007/BF02017223	social science;content analysis;evolution	NLP	-74.90418807019462	-22.387752753739946	94138
d3808a46effadde3b550e6486915c92c0bbc0b66	retrospective: architecture of a massively parallel processor	massively parallel processor	When the company asked me to write a paper on the MPP I decided to submit it to ISCA-7. Management balked at first: why pick a conference in La Baule, France when there were so many other conferences here in the U.S.? They only agreed after I convinced them that ISCA is the best conference in computer architecture; that the chance the paper would be accepted was very low; and that I could always submit it to some other conference if ISCA-7 rejected it. Management was much surprised when the paper was accepted: to help amortize my travel expenses they had me visit a few European groups that had some interest in the MPP so my trip lasted two weeks.	amortized analysis;goodyear mpp;international symposium on computer architecture;linear algebra	Kenneth E. Batcher	1998		10.1145/285930.285937	computer science;massively parallel	EDA	-65.55996013556981	-22.262714198791762	94297
d9408c410171e59b4fd3b99d710d36ce00b558b5	wireless network security vulnerabilities and concerns	network security;wireless network;research and development;world wide web;network architecture;middle east	The dilemma of cyber communications insecurity has existed all the times since the beginning of the network communications. The problems and concerns of unauthorized access and hacking has existed form the time of introduction of world wide web communication and Internet's expansion for popular use in 1990s, and has remained till present time as one of the most important issues. The wireless network security is no exception. Serious and continuous efforts of investigation, research and development has been going on for the last several decades to achieve the goal of provision of 100 percent or full proof security for all the protocols of networking architectures including the wireless networking. Some very reliable and robust strategies have been developed and deployed which has made network communications more and more secure. However, the most desired goal of complete security has yet to see the light of the day. The latest Cyber War scenario, reported in the media of intrusion and hacking of each other's defense and secret agencies between the two super powers USA and China has further aggravated the situation. This sort of intrusion by hackers between other countries such as India and Pakistan, Israel and Middle East countries has also been going on and reported in the media frequently. The paper reviews and critically examines the strategies already in place, for wired network. Wireless Network Security and also suggests some directions and strategies for more robust aspects to be researched and deployed.	libressl;network security;vulnerability (computing)	Mushtaq Ahmad	2010		10.1007/978-3-642-17610-4_23	telecommunications;engineering;network security;security service;internet privacy;network access control;network security policy;computer security	Security	-69.13362566461429	-10.891603338718042	94453
0854e01bd62e724fd76dfda8cc6205361544808b	electronic mail: expanding library services beyond traditional boundaries	electronic mail;library service	"""Electronic mail oflers many new exciting, cost-ejjfecfive methods for serving library users. Almost every operational feature of traditwnal libra,y services can be augmented and improved by electronic mail applications. Interlibrary loan, materials requesting, reference questions are b~ """" ng streamlined by the systematic application of electronic mail. Incoming FAX documents are btz """" ng downloaded info microcomputers and transmitted across networks to other microcomputers with FAX boards, Circulafwn renewals, holds and stafus-evaluafion of holds are also ba """" ng done through electronic mail affording enhanced access services. There are other applications including the use of electronic bulletin boards to provide information to the library community of available services and timely events. Booking of varwus kinds of equipment and resources and access to """" new booy lists can be done through electronic mail. Electronic mail in effect will have major transformational impact on library opera fwns, one which will achieve anew service paradigm of electronically methodized in fegrafion. This paper looks at the current status uithin academic libray and addresses the ~ fure issues particularly with fhefocus of streamlined and enhanced services w'thin traditwnal library operations."""	email;fax;field electron emission;library (computing);microcomputer;microsoft academic search;programming paradigm;reference implementation;refinement (computing)	Stephen Foster;Daniel Ferrer	1991		10.1145/122898.122912	library science;engineering;internet privacy;world wide web	OS	-67.13992227027344	-18.458855566992547	94461
427a73e8acb696251a8ec97a2715fb1d236298ee	the healthcare singularity and the age of semantic medicine		n 1499, when portuguese explorer vasco da gama returned home after completing the first-ever sea voyage from Europe to India, he had less than half of his original crew with him— scurvy had claimed the lives of 100 of the 160 men. Throughout the Age of Discovery,1 scurvy was the leading cause of death among sailors. Ship captains typically planned for the death of as many as half of their crew during long voyages. A dietary cause for scurvy was suspected, but no one had proved it. More than a century later, on a voyage from England to India in 1601, Captain James Lancaster placed the crew of one of his four ships on a regimen of three teaspoons of lemon juice a day. By the halfway point of the trip, almost 40% of the men (110 of 278) on three of the ships had died, while on the lemon-supplied ship, every man survived [1]. The British navy responded to this discovery by repeating the experiment—146 years later. In 1747, a British navy physician named James Lind treated sailors suffering from scurvy using six randomized approaches and demonstrated that citrus reversed the symptoms. The British navy responded, 48 years later, by enacting new dietary guidelines requiring citrus, which virtually eradicated scurvy from the British fleet overnight. The British Board of Trade adopted similar dietary	code smell;randomized algorithm;ti-92 series	Michael Gillam;Craig Feied;Jonathan Handler;Eliza Moody;Ben Shneiderman;Catherine Plaisant;Mark S. Smith;John Dickason	2009			health care;family medicine;singularity;computer science		-64.25167199078403	-23.242642216271	94638
2997360e1f34ec4d508aec2aa70c3de0996abf0a	computational chemistry and cheminformatics: an essay on the future		Computers have changed the way we do science. Surrounded by a sea of data and with phenomenal computing capacity, the methodology and approach to scientific problems is evolving into a partnership between experiment, theory and data analysis. Given the pace of change of the last twenty-five years, it seems folly to speculate on the future, but along with unpredictable leaps of progress there will be a continuous evolution of capability, which points to opportunities and improvements that will certainly appear as our discipline matures.		Robert C. Glen	2012	Journal of computer-aided molecular design	10.1007/s10822-011-9501-6	computer science;management science;operations research	DB	-62.8858221097888	-21.685289079601407	94717
67f508e7d304517810fc612791e4736a3e45a33f	reverse-engineering someone else's software: is it legal?	legal applications;legislation;fair use;law legal factors reverse engineering motion pictures logic testing protection core dumps program processors licenses circuits;software engineering industrial property legislation;selected works;strict constructionist theory;legal issues;pragmatist theory;software engineering;copyrighted software;bepress;industrial property;fair use reverse engineering legal applications strict constructionist theory copyrighted software pragmatist theory;reverse engineering	The author covers the legal issues of reverse-engineering someone else's software, explaining what reverse-engineering activities the courts have found to be acceptable and what legal applications are for the knowledge you gained from reverse engineering. She also defines 'reverse engineering' and presents two theories regarding its use: the strict-constructionist theory, which holds that reverse-engineering copyrighted software is always illegal, and the pragmatist theory, which takes a much more liberal view of the fair-use privilege.<<ETX>>	reverse engineering;theory	Pamela Samuelson	1990	IEEE Software	10.1109/52.43054	computer science;engineering;software engineering;management;algorithm;reverse engineering	SE	-67.66549362591536	-16.463515441774195	94764
bc714bda99907827bac4625cc169a16f323bd26f	connecting systems for better services around special collections	informacion documentacion;grupo a;ciencias sociales	Over the last few years, several projects to improve physical and digital access to special collections have been undertaken by Leiden University Libraries in the Netherlands. These heritage collections include manuscripts, printed books, archives, maps, atlases, prints, drawings and photographs, from the Western and non-Western worlds. They are of both national and international importance. The projects were undertaken to meet two key requirements: providing better and faster service for customers when using the collections, and creating a more efficient workflow for the library staff. Their interdependencies, with regard to creating new formats for the description of graphic materials and providing digital access, led to a merger of the projects with a combined set of goals for conversion, cataloging and digitization-on-demand. This article describes the infrastructure behind these projects, and the impact of the projects on users and staff to date.		Saskia van Bergen	2014	D-Lib Magazine	10.1045/september2014-vanbergen	computer science;multimedia;world wide web;collections management	ML	-67.7943653106008	-16.68518897729353	95202
6927a0ee6555d1d289847860b310b94502c2d6ee	introduction to the special issue on the death, afterlife, and immortality of bodies and data	rituals;publics;hybridization;historicization;the internet;after death	This special issue poses questions concerning death, afterlife and immortality in the age of the Internet. It extends previous work by examining current and emerging practices of grieving and memorializing supported by new media. It suggests that people’s lives today are extended, prolonged, and ultimately transformed through the new circulations, repetitions, and recontextualizations on the Internet and other platforms. It also shows that publics are being formed and connected with in new ways, and new practices and rituals are emerging, as the traditional notions of the body are being challenged. We argue that these developments have implications for how people will be discovered and conceived of in the future. We consider possible extensions to the research presented here in terms of people, practices, and data. First, some sections of the population, in particular those who are the dying and populations in developing countries and the Global South, have largely been neglected to date. Second, practices such as (online) suicide and sacrilegious or profane behaviors remain largely uninvestigated. Third, the discussion of the management of the digital self after death has only begun. We conclude by posing further questions concerning the prospect of emerging cities of the dead.	afterlife;internet;new media;population	Connor Graham;Martin R. Gibbs;Lanfranco Aceti	2013	Inf. Soc.	10.1080/01972243.2013.777296	orbital hybridisation;the internet;telecommunications;sociology;law	HCI	-75.06712176091601	-14.094588632894629	95242
bafadf5f941188ce516e798a7e47d5eff932ce33	a descriptive analysis of the codes of ethics for educators		As organizations evolve and begin to seek more prestige and status with their clientele and society as a whole, they begin the process known as professionalization. This process encourages these organizations to acquire those identifiable characteristics, which were achieved in the professions such as medicine and law. Hart and Marshall (1992) summarized the fundamental characteristics of a profession into five specific criteria. This study examined only two of the five criteria: (a) an established code of ethics for them members of the organization, and (b) how the organization policed itself when the code was violated. The institution of education was one such group that has aspired the status of a true profession. Therefore, the problem of this study was to research what each state has done in developing and enforcing a code of ethics for its educators. However, since no single code of ethics exists which embodies the entire education profession, a more in-depth study was undertaken. Specifically, the two main objectives of this study were to examine (a) what each state has done in developing a code of ethics for it’s educators, and (b) the work the governing board/commission charged with enforcing the code and standards within each state. A qualitative research design was employed for this study, and written documents produced by states’ educational bodies or legislatures were the primary sources of data. Each state was contacted by Internet, e-mail, telephone, or mail to acquire the necessary data to answer this study’s research questions. The data collected included mainly brochures, state statutes, or downloaded version of these documents. The data provided the evidence to conclude that 23 states have enacted codes of ethics for their educators. The names of these codes and the rules or standards contained with the codes vary, but many similarities were found too. The data also supported that each state has established grounds for which an educator’s certificate could be denied, suspended, or revoked. Each state has also designated an entity to give the educator due process in enforcing the code of ethics or when grounds exist for probable cause.	code;document;email;emoticon;internet;mail (macos);primary source;public key certificate	Ken Allen Banter	2003			pedagogy;ethical code;professionalization;political science;enforcement;descriptive statistics	Web+IR	-74.04033261962876	-19.601242517276578	95396
e7d0f76a0c33af05f2e93d786eacdc7e6af9a628	how do we create more equitable, diverse, and inclusive organizations, and why does it matter? a white male's perspective		At a conference early in my scientific career, the presenter—an early-career woman— checked in with the session chair—a middle-aged male professor—to see how much time she had left before having to wrap up her talk. The session chair told her she had plenty of time, followed with “Either way, you look very pretty up there!” The misguided comment appeared to take the woman totally off-guard as she was visibly shaken for the rest of her presentation. No one in the audience, including myself, spoke up about this.		Bert J. Debusschere	2018	Computing in Science and Engineering	10.1109/MCSE.2018.011111128	knowledge management;computer science;theoretical computer science;diversity training;history of computing	HPC	-64.38899375509295	-22.81641681283671	95463
1a3478488f60851cbc0294a27e94b78daac06c24	technological expeditions and cognitive indolence [last word]		he Greely Expedition of 1881 is a harrowing tale of starvation and the death of all but six of the crew who embarked on an exploration of the Canadian Arctic. Historians and anthropologists identify poor decision-making as a central component of the tragic outcomes. In one monumental decision that seemed to lack well-thought, reasoned judgment, Lieutenant Greely ordered his troops from Fort Conger to Camp Sabine. Greely’s men deemed the move insane and foolish. Fort Conger afforded them all they needed to survive for years: plenteous game, and warm, safe shelter. Yet Greely was determined to obey orders transcribed by superiors who lacked comprehension of the emerging context. Greely’s decision would prove disastrous. Camp Sabine was a barren wasteland without purpose, provision, or protection to sustain the life of those now utterly depleted and demoralized by the perilous transfer. Greely erroneously took his orders “to-the-letter,” rather than balancing and synthesizing multifaceted elements of the context [1]. College students often graduate without apt complex-reasoning skills. When I present dilemmas with which my students must grapple, I often observe disproportionate frustration if I will not resolve dilemmas, or when I deem dualism (it’s either right or wrong) as inadequate. The literature supports my anecdotal experience; this generation seeks to have dilemmas resolved by an external societal force rather than by contending with quandaries and crafting resolutions on their own [2]. Technology that enhances decisionmaking should be applauded; there are advantageous social implications. Perhaps Greely would have averted tragedy by using predictive analytics. Yet, a cognitive foundation should be laid and well-developed within humans to cultivate the art of self-guided, self-disciplined, self-monitored, and self-corrective thinking. With such underpinnings, dualism will give way to an internal processing system of “constructed knowledge” (what’s right is contingent upon varied, multidimensional factors and certain choices are better) [3]. As technology delivers more and more algorithms and analytics to inform decisions, will we impede the development of critical reasoning? Could we create a culture of Greely-like thinking in which computer-generated guidance is unquestioningly obeyed by those lacking higher-order thinking? Perhaps we should pursue balance, leveraging technology while also designing safeguards to prevent cognitive indolence.	algorithm;computer-generated holography;contingency (philosophy);grapple;humans;mechatronics;wasteland 2	Christina Perakslis	2015	IEEE Technol. Soc. Mag.	10.1109/MTS.2015.2461195	cognitive science	HCI	-74.09071423927371	-11.116586919992944	95533
b7ef1d3ee1956482e49648895fae774208dd24f0	the wefold gateway: enabling large-scale science coopetition	logic gates pipelines proteins programmable logic arrays;gateway;casp10 wefold gateway large scale science competition critical assessment of technique protein structure prediction casp competition protein folding;proteins;proteins bioinformatics;coopetition;protein folding;protein structure prediction pipelines gateway protein folding coopetition;protein structure prediction pipelines;bioinformatics	This paper describes the WeFold gateway that provides a social and technical environment for the first large-scale attempt at collaboration within the context of the Critical Assessment of techniques for protein Structure Prediction (CASP) competition. CASP is a biennial worldwide experiment created 20 years ago to advance the field of protein folding, one of the grand challenges in modern science. The WeFold experiment was started in CASP10 (the 10th CASP) to bring together scientists from different disciplines to brainstorm online, share ideas and codes, and synergistically develop new methodologies. The goal is to positively shake up the field to stimulate breakthrough advances.	brainstorm;casp;code;grand challenges;image scaling;pipeline (computing);protein structure prediction;shake;synergy	Silvia Crivelli;Rion Dooley;Raquell Holmes;Stephen A. Mock	2013	2013 IEEE International Conference on Cluster Computing (CLUSTER)	10.1109/CLUSTER.2013.6702698	protein folding;simulation;computer science;bioinformatics	Visualization	-66.82874670613785	-13.30476183224618	95667
c9e98997e7be143c82a0d454b82ea9b8d05eb123	copyright in the networked world: plagiarism and its ambiguities	plagiarism;software tool;intellectual property;droit auteur;plagio;scientific writing;copyright;copyright law;redaccion cientifica;redaction scientifique;propiedad intelectual;plagiat;software tools;propriete intellectuelle;derecho autor;design methodology	Purpose – Libraries and scholars face more frequent problems with and decisions about plagiarism than in the past. This article aims to look at complex cases where plagiarism may have occurred. Design/methodology/approach – The method is anthropological and looks at specific cases, in which the situations are real but the actors have been fictionalised to protect identities. Findings – Plagiarism tools, while invaluable for discovering potential problems, can also expose cases where judgments depend on complex circumstances. Originality/value – The goal is to show areas where ambiguity in plagiarism cases exists.	library (computing)	Michael Seadle	2008	Library Hi Tech	10.1108/07378830810921049	design methods;computer science;artificial intelligence;sociology;management;law;world wide web;intellectual property	ML	-73.11581016886848	-19.72827613222787	95810
c85f9f67e4643479882b930f185bbb5da877fef7	scatter matters: regularities and implications for the scatter of healthcare information on the web	scatter matter;complex scatter;incomplete information;comprehensive information;huge healthcare web site;content analysis;information density;information scatter;web site;web page;healthcare information;cluster analysis;social sciences;computer science	Despite the development of huge healthcare Web sites and powerful search engines, many searchers end their searches prematurely with incomplete information. Recent studies suggest that users often retrieve incomplete information because of the complex scatter of relevant facts about a topic across Web pages. However, little is understood about regularities underlying such information scatter. To probe regularities within the scatter of facts across Web pages, this article presents the results of two analyses: (a) a cluster analysis of Web pages that reveals the existence of three page clusters that vary in information density and (b) a content analysis that suggests the role each of the above-mentioned page clusters play in providing comprehensive information. These results provide implications for the design of Web sites, search tools, and training to help users find comprehensive information about a topic and for a hypothesis describing the underlying mechanisms causing the scatter. We conclude by briefly discussing how the analysis of information scatter, at the granularity of facts, complements existing theories of information-seeking behavior.	cluster analysis;complement system proteins;crew resource management, healthcare;emoticon;information design;information seeking behavior;page (document);partial;theory;web page;web search engine;world wide web	Suresh K. Bhavnani;Frederick A. Peck	2010	Journal of the American Society for Information Science and Technology : JASIST	10.1002/asi.21217	text mining;content analysis;computer science;data science;data mining;health;cluster analysis;world wide web;information retrieval	HCI	-75.8568472979444	-17.017249449962577	96008
90f5d390631efed648bb8e365f3de9461bf5a80d	climate change research in view of bibliometrics	research assessment;geophysics;el nino southern oscillation;climate change;bibliometrics;paleoclimatology;climate modeling;global warming	This bibliometric study of a large publication set dealing with research on climate change aims at mapping the relevant literature from a bibliometric perspective and presents a multitude of quantitative data: (1) The growth of the overall publication output as well as (2) of some major subfields, (3) the contributing journals and countries as well as their citation impact, and (4) a title word analysis aiming to illustrate the time evolution and relative importance of specific research topics. The study is based on 222,060 papers (articles and reviews only) published between 1980 and 2014. The total number of papers shows a strong increase with a doubling every 5-6 years. Continental biomass related research is the major subfield, closely followed by climate modeling. Research dealing with adaptation, mitigation, risks, and vulnerability of global warming is comparatively small, but their share of papers increased exponentially since 2005. Research on vulnerability and on adaptation published the largest proportion of very important papers (in terms of citation impact). Climate change research has become an issue also for disciplines beyond the natural sciences. The categories Engineering and Social Sciences show the strongest field-specific relative increase. The Journal of Geophysical Research, the Journal of Climate, the Geophysical Research Letters, and Climatic Change appear at the top positions in terms of the total number of papers published. Research on climate change is quantitatively dominated by the USA, followed by the UK, Germany, and Canada. The citation-based indicators exhibit consistently that the UK has produced the largest proportion of high impact papers compared to the other countries (having published more than 10,000 papers). Also, Switzerland, Denmark and also The Netherlands (with a publication output between around 3,000 and 6,000 papers) perform top-the impact of their contributions is on a high level. The title word analysis shows that the term climate change comes forward with time. Furthermore, the term impact arises and points to research dealing with the various effects of climate change. The discussion of the question of human induced climate change towards a clear fact (for the majority of the scientific community) stimulated research on future pathways for adaptation and mitigation. Finally, the term model and related terms prominently appear independent of time, indicating the high relevance of climate modeling.	acclimatization;bibliometrics;categories;climate model;contribution;doubling;global warming;high-level programming language;journal;köppen climate classification;largest;natural science disciplines;paper;relevance;scientific publication;sex reassignment procedures;social sciences;switzerland;vulnerability (computing);citation	Robin Haunschild;Lutz Bornmann;Werner Marx	2016		10.1371/journal.pone.0160393	el niño southern oscillation;global warming;bibliometrics;paleoclimatology;climate change;climate model	ML	-76.28486218921776	-20.35520012278876	96323
3d300138327315de3f8cda14afc08e389685edbb	the highly cited papers of professors as an indicator of a research group's scientific performance	evaluation performance;citation analysis;scientometrics;long period;metodologia;indicator;performance evaluation;indicateur;facteur impact;factor impacto;impact factor;estudio comparativo;evaluacion prestacion;analisis cita;chercheur;science sociology;long terme;test;highly cited papers hcps;validite;individu;work team;methodologie;equipe travail;long term;ensayo;etude comparative;individual;analyse citation;research worker;essai;largo plazo;validity;validez;sociologie science;scientometria;productivite auteur;indicador;comparative study;court terme;scientometrie;equipo trabajo;productividad autor;investigator;short period;methodology;individuo;sci;corto plazo;short term;author productivity	In the first part of the paper the citations in 1986 and 1987 of 3938 papers published in 1985 by 324 research groups in the faculties of science and of medicine of eight universities in the Netherlands are analyzed. Because of the large statistical spread of (1) the number of short-term citations of papers cited equally frequently over a long period, and (2) the number of citations over a long period of papers by the same author, short-term citation scores appear to be an unreliable indicator of a research group's contribution to science. In the second part of the paper an alternative approach is presented, based on a subdivision of the 3938 papers in papers authored by professors with 0–2, 3–8, or ≥9 highly cited papers (HCPs, ≥25 citations) to their name. Very large citation score differences were found for the three categories. For example: for papers first-authored by a professor, the average number of citations per person in 1986 and 1987 for 1985 papers was for 161 professors with ≥9 HCPs a factor 14 larger than for 575 professors with only 0–2 HCPs; for papers co-authored by professors, this factor was 6.6. These findings justify the conclusion that the number of HCPs scored by the professors (and other senior scientists) during their entire career is a much more reliable predictor of the performance of a research group than the number of short-term citations of the articles published by the group within a short period. A research group's contribution to science is primarily determined by the individual scientifictalents of its members.	kerrison predictor;score bug;subdivision surface	Reinier Plomp	1994	Scientometrics	10.1007/BF02033446	gerontology;scientometrics;computer science;comparative research;methodology;short-term memory;software testing;operations research;citation analysis;world wide web;validity	ML	-76.39401281443216	-22.655515713013568	96348
b305da168a0abd1a9079e45889f4befcb1a0ceca	protecting intellectual property from digital piracy		While this is often labeled as a publisher’s problem, the reality is that piracy of intellectual property is illegal and that compromised a university network infrastructure is a problem for all. This brief paper reviews a case study of a popular illegal website, the implications of its usage, the disruption that it is causing, and what publishers are doing to manage and/or combat this illegal activity.	denial-of-service attack	Sari Frances	2018	Inf. Services and Use	10.3233/ISU-180012	intellectual property;business;commerce	SE	-70.77158015704936	-10.194225893826053	96781
9248db933bd33063195424bf6a0b762963c11759	robot companions: a legal and ethical analysis		ISSN: 0197-2243 (Print) 1087-6537 (Online) Journal homepage: http://www.tandfonline.com/loi/utis20 Robot companions: A legal and ethical analysis Andrea Bertolini & Giuseppe Aiello To cite this article: Andrea Bertolini & Giuseppe Aiello (2018) Robot companions: A legal and ethical analysis, The Information Society, 34:3, 130-140, DOI: 10.1080/01972243.2018.1444249 To link to this article: https://doi.org/10.1080/01972243.2018.1444249	international standard serial number;robot	Andrea Bertolini;Giuseppe Aiello	2018	Inf. Soc.	10.1080/01972243.2018.1444249	public relations;civil law (legal system);liability;sociology;deception;legitimacy;ranging;commission;functional approach;dehumanization	Theory	-62.94872631661028	-12.711406544009202	96814
07178363a60c9f3b51e7a020d88e91591c61c231	a study on the efficient r&d theme selection method with machine learning	technological trends prediction;machine learning;link mining;r d;patent analyses	This paper proposes an R&D theme selection method. There are various methods for the theme selection such as the patent analysis and the delphi investigation. The patents and the peer reviewed papers are frequently used as material for the theme selection. Generally, there are three phases for the R&D term selection such as the short-term R&D theme selection, the long-term R&D theme selection, and the medium-term R&D theme selection. The medium-term R&D theme selection is often aimed implementation within 5 years such as an exploratory technology theme. Since it relies on the heuristics knowledge with the technology trends, an efficient selection method is required among the business field. In this paper, we propose a method of selecting the R&D theme using combination of link mining and machine learning based on the public information. As a result, we satisfy predicting technology structure of 5 years later.	heuristic (computer science);machine learning;selection (genetic algorithm)	Masashi Shibata;Koichi Inoue;Masakazu Takahashi	2016		10.1145/2925995.2926031	engineering;data science;machine learning;data mining	Web+IR	-76.25056675270336	-16.990173768224444	97457
623269692a3b47162a78a8944c0e27fdb28f9635	determinants of faculty research productivity in information systems: an empirical analysis of the impact of academic origin and academic affiliation	information production;empirical analysis;lotka law;decision maker;loi lotka;occupational prestige;produccion de informacion;analyse correlation;ley lotka;information system;production d information;recherche scientifique;prestige professionnel;scientific research;research productivity;systeme information;analisis correlacion;investigacion cientifica;correlation analysis;sistema informacion	This manuscript provides guidance to Deans and other academic decision makers in the hiring process and dispels the validity of a widely held assumption commonly used as a decision factor in the selection process. This paper investigates: (a) whether graduates of prestigious information systems (IS) doctoral programs (graduates with high-status academic origins) are more likely to be successful in their academic careers (as measured by research productivity) than graduates of less prestigious programs, (b) whether IS faculty who are employed by esteemed universities (faculty with high-status academic affiliations) are more productive researchers than IS faculty employed by lower-status institutions, and (c) examines faculty productivity in terms of Lotka’s Law [Lotka, 1926]. The findings indicate that in the IS field, productivity does not follow a Lotka distribution. Moreover, our study also shows that academic affiliation is a significant determinant of research productivity in terms of quantity (as measured by publication counts) and quality (as measured by citation counts). Contrary to common expectations, however, the analysis shows that the status of a faculty member’s academic origin is not a significant determinant of research productivity in the field of information systems. Therefore, continued reliance on academic pedigree as a primary criterion for hiring decisions may not be justified in the IS discipline.	emoticon;information system;lotka's law	Rebecca Long;Aleta Crawford;Michael White;Kimberly Davis	2007	Scientometrics	10.1007/s11192-007-1990-7	decision-making;social science;scientific method;epistemology;computer science;sociology;occupational prestige;management;operations research;economic growth;information system	Security	-76.53127159774307	-22.830680577763687	97645
0a42908a440225a1c781bde19dccf8734c5bd302	computer software patents: a dilemma in competitive advantage it research		A significant amount of information technology (IT) research centers on the attainment of competitive advantage through the use of IT. In many cases, the use of patents to protect that IT does not receive much attention. Often studies conclude that patent protection cannot help IT to achieve such an advantage. Our research finds that many IT researchers based these conclusions predominately on two studies that are no longer relevant. This paper reviews some of that IT research and then links that research to these two dated studies. A number of reasons why researchers may continue to use the research for support of their conclusions are put forth, including lack of knowledge, research as a lagging indicator, pressure to complete research The paper offers recommendations for improving the research efforts such as using law as a reference discipline, considering the law in the reviewing process, and including legal considerations in doctoral training. We conclude with lessons learned.	software patent debate	Peter Mykytyn;Kathleen Mykytyn	2002	CAIS		economics;knowledge management;marketing;management science;competitive advantage	HCI	-73.5821430917811	-15.63765888912559	97646
e3968d42a1d1aa521d8374e000624be096230d0f	chinese journal finds 31% of submissions plagiarized	journal	Your call for more investigation into the ecology of urban habitats (see Nature doi:10.1038/ news.2010.359; 2010) is already being answered. In 1997, the US National Science Foundation’s Long-Term Ecological Research programme created urban research sites in Baltimore, Maryland, and in Phoenix, Arizona. And last year the foundation funded the Urban Long-Term Research Area Exploratory Awards with the US Forest Service to expand knowledge of urban natural resources and human interactions. These programmes attest to a coordinated and productive effort to incorporate urban research into mainstream ecology. Publications on this topic have mushroomed over the past two years: they include specialist journals (Urban Ecology, Urban Ecosystems); a ‘Cities’ special in Science (319, 739–775; 2008) and books such as Urban Herpetology, Urban Carnivores and Advances in Urban Ecology. Membership of the Urban Ecosystem Ecology section of the Ecological Society of America is growing fast — it is now the twelfth largest of 19 sections. There were 202 urban-related items presented at the society’s annual meeting last month, compared with just one in 1991. Although the number of published urban studies is still small, it is rapidly increasing. Only 0.4% of papers in nine leading ecology journals in 1993–98 dealt with cities or urban species (J. Collins et al. Am. Sci. 88, 416–425; 2000), compared with 2.5% of papers in 10 top ecology journals over the past 5 years (see go.nature.com/Lj7YAa). Urban environments were not Chinese journal finds 31% of submissions plagiarized	awards;book;carnivore;ecosystem ecology;exploratory testing;habitat;interaction;journal;largest;mandibular right second molar tooth;paper;scientific publication;urban ecosystem	Yuehong Zhang	2010	Nature	10.1038/467153d	biology	HCI	-62.98602331100091	-15.341774765520748	97948
cb1b252ed68948d77e6f02d017940e3815351cbe	using natural language processing to improve erulemaking: project highlight	notice and comment rulemaking;e government;bepress selected works;e rulemaking;document hierarchy;e rulemaking public participation in democracy e government notice and comment rulemaking;national science foundation;cluster labeling;public participation in democracy;natural language processing	This paper describes in brief Cornellu0027s interdisciplinary eRulemaking project that was recently funded (December, 2005) by the National Science Foundation.	natural language processing	Claire Cardie;Cynthia Farina;Thomas Bruce	2006		10.1145/1146598.1146651	public relations;political science;public administration	AI	-62.989527256976025	-14.600874393749754	98070
c77cc175612fc46bb6f4b93eb04d07538b4da0b5	regulation of technologies to protect copyrighted works	selected works;droit auteur;normalisation;information technology;copyright;technologie information;normalizacion;bepress;tecnologia informacion;standardization;derecho autor	C law has traditionally balanced the interests of authors, publishers, and the consuming public. The goal of this law has not been to maximize the degree of control authors or publishers can exercise over all copies or uses of their works but rather to provide enough control over works and performances to give authors and their publishers sufficient assurance that they will benefit from commercial exploitations of their works so that they will share their works with the public and thereby to promote learning [6]. One of today’s most difficult policy challenges is how to maintain the balance of existing copyright law when developing new regulations for the digital environment The Clinton administration deserves credit for its formation of a National Information Infrastructure Task Force to articulate policies necessary to enable the emergent information infrastructure to reach its potential as a communication medium. This initiative has included publication of a “White Paper” on intellectual property issues [5] containing proposals to amend copyright law to deal with the challenges posed by digital technologies. Legislation embodying these proposals is pending before the U.S. Congress (H. R. 2441 and S. 1284). The Clinton administration has submitted its major legislative proposals to the World Intellectual Property Organization as possible treaty language for a supplementary agreement (known as a protocol) to the major international copyright treaty, the Berne Convention. A diplomatic conference to give final consideration to these and other possible treaty provisions is scheduled for December 1996. This column discusses two of the White Paper’s legislative proposals: protecting the integrity of copyright management information that will soon be attached to all digital copies of copyrighted works and proscribing technologies or services useful for circumventing technological protection for copyrighted works. Both proposals need significant refinement before they are suitable for adoption as either national or international legal norms. The column also discusses more direct means of regulating reprography technologies. Negotiations are currently under way between the U.S. motion picture industry and electronic equipment manufacturers to Regulation of Technologies to Protect Copyrighted Works	digital environment;emergence;management information system;national information infrastructure;performance;refinement (computing)	Pamela Samuelson	1996	Commun. ACM	10.1145/233977.233980	telecommunications;operations research;law;information technology;standardization	DB	-68.13594475027718	-17.58065908793194	98283
55d67cf990abbf7617fbc8d8eee3221f28658aa3	renormalized impact factor	scientometrics;facteur impact;factor impacto;periodical;impact factor;information scientifique technique;periodique;periodico;scientometria;scientometrie;scientific technical information;informacion cientifica tecnica;renormalisation;renormalizacion;renormalization	Many aspects determine the quality of scientific journals. The impact factor is one of these quantitative parameters. However, the impact factor has a strong dependence on the journal discipline. This dependence forbids a direct comparison between different journals without introducing external considerations. In this paper, a renormalized impact factor, Fr, inspired in the definition of dimensionless physical parameters, is proposed. Fr allows a direct comparison among journals classified into different categories and, furthermore, the time evolution analysis of the journal's role in its field.		Ana María Ramírez;Esther Ofilia García;J. Antonio del Río	2000	Scientometrics	10.1023/A:1005600807292	renormalization;scientometrics;computer science;operations research;world wide web	Web+IR	-75.69910001739179	-21.527604046633954	98290
ec59634b14ffb5076d36964c411e969fc9ba7cbf	a computer ethics bibliography	computer ethics	"""We are grateful to Herman Tavani and his students .for putting together an extensive bibliography on the topics of computer ethics and computers & society, hi this issue we print the first part of the bibliography, the remaining parts will be published in fitture issues of the newsletter,-Ed. The enclosed bibliography includes 1240 entries and is organized into three parts. Part I, consisting of Sections 1 and 2, is intended primarily for those interested in teaching computer ethics courses. Section 1 lists computer ethics textbooks, general references, and sources dedicated to issues in teaching computer ethics. A selected list of sources on ethical theory, which some instructors may find useful as a framework for discussing ethical issues in computing, is included in Section 2. Ethical issues in the use of computers span two distinct areas-practical or applied ethics and professional or occupational ethics. This division is reflected in the grouping of sources in Parts II and III of the bibliography. Part II, made up of Sections 3 and 4, focuses on professional ethics and issues of responsibility for computer professionals. Section 3 identifies professional codes of conduct and lists sources that interpret and assess those professional codes. Sources concerned with issues of moral responsibility and legal liability for computer professionals are included in Section 4. Sections 5 through 10 make up the third and final part of the bibliography. Each section focuses on a specific issue or area in applied ethics and computing: artificial intelligence (AI) & expert systems, work, privacy, social power, computer crime, and intellectual property rights. In examining the contents of Sections 5 through 10, the reader may notice a series of transitions from the topic in the closing subsection of each major section to the main theme of the section that immediately follows. For example, the final topic of Section 5 examines issues in AI, robotics and employment, and leads into Section 6, """"Computers and Work."""" The closing topic of Section 6 deals with employee monitoring, and flows into """"Computers and Privacy,"""" the principal theme of Section 7. A similar transition process occurs in each of the remaining sections of Part III. Using the Bibliography While the arrangement of the bibliography's sections lends itself to a linear or sequential approach to the entries, users can tailor the ordering of the various subsections to suit their own particular interests. Those concerned with issues in computer crime, for …"""	artificial intelligence;closing (morphology);code;computer;cybercrime;expert system;robotics	Herman T. Tavani	1995	SIGCAS Computers and Society	10.1145/202614.202243	social science;computer science;sociology;law;computer ethics	AI	-67.7363408066905	-22.469109745259615	98394
306263b7fd966e7bb55a7db199ef3fa798e35e54	erratum to: implementation of a methodology for determining elastic properties of lipid assemblies from molecular dynamics simulations		Unfortunately, the original version of this article [1] contained an error. The incorrect version of Scheme 4 was used and Scheme 4 and 6 were also accidentally interchanged during processing. The correct schema and labelling is presented below. permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver	contain (action);license;molecular dynamics;simulation;waiver	Niklaus Johner;Daniel Harries;George Khelashvili	2016		10.1186/s12859-016-1091-9		Metrics	-66.365070560779	-17.189476105266667	98496
3a0313b883c1a142aa279500ba322ad2368b9863	linking cris to education	systeme d information de recherche;cris;current research information system;cerif	The paper contributes to the debate on the developm ent and future of the CERIF model. In particular, it provides empirical elements to three questions: (a) How are existing CRIS projects connected to educatio n systems? (b) Should the CERIF model be extended to ed ucation? (c) If so, how should this be done (entiti es, attributes, semantics)? The paper is based on a dou ble methodology, an online survey with CERIF project managers and interviews with a panel of experts fro m euroCRIS. Survey and interviews have been carried out between February and April 2012. Results are ind ecisive – so far, the connection from research management systems to education related data seems not to be a priority, neither for the project manag ers nor for euroCRIS experts. When the systems are connec ted, simple data exchange between independent data silos appears to be the solution of choice. The res ults are discussed and perspectives for euroCRIS are suggested.	emoticon;entity;eurocris;information silo	Joachim Schöpfel;Marie-José van Baelinghem;Laurent Sparrow	2012			library science;engineering;operations research;cartography	DB	-73.73398750759291	-21.425689641176607	98853
4483ca5f829812714ecfea93fe5ddc3564962292	bioone: building a sustainable alternative publishing model for non-profit publishers	communication scientifique;collaborative work;bioone;edition electronique;comunicacion cientifica;cambio;influencia;communaute savante;economic model;change;modelo economico;influence;modele economique;scholarly community;edicion electronica;travail collaboration;changement;scientific communication;electronic publishing	An account is given of the difficulties caused to smaller learned publishers and to the academic library system in the move to electronic delivery of results of scientific and medical research. BioOne, a co-operative venture of such publishers and libraries, is then described with an account of its progress to date. Learned Publishing (2003)16, 134–138 134 Heather Dalterio Joseph L E A R N E D P U B L I S H I N G V O L . 1 6 N O . 2 A P R I L 2 0 0 3 and had not amassed a rainy-day fund that could immediately help offset the cost of publishing in the online world. At the same time, another reality of the marketplace was becoming evident. While publishers began dealing with the financial pressures of operating in the dual worlds of print and electronic journals, academic libraries were facing serious financial pressures of their own. In addition to the decades-long trend of rapidly increasing serials prices, libraries now found themselves facing the prospect of having to acquire, in many cases, both the electronic and print versions of a journal. This put more pressure on already severely strained budgets. As publishers struggled to find ways to offset the cost of electronic publishing, a pricing model that charged libraries according to some version of a formula that took into account the print cost plus an additional percentage for the electronic product became commonplace. Additionally, the electronic medium and its accompanying archival concerns placed yet further new demands on library budgets, which now needed to cover the development and implementation of storage and preservation techniques for electronic journals as well as for print ones. Both the library community and the non-commercial publishing community clearly faced difficult situations, and had limited options for addressing them. In the absence of large increases to their budgets, libraries faced the prospect of having to cut expenses, forcing cancellation of subscriptions to many journals. Non-commercial publishers had the option of remaining strictly paper-based, which would result in the journal having limited usefulness to researchers compared with its electronic competitors. Limited usefulness would mean limited use, and since library acquisitions place a premium on usage, the risk of cancellation of a journal would increase. Of course, a publisher always had the option of either contracting with a vendor to create and host an electronic version of the journal or to try and develop the in-house expertise to do so, but many smaller, non-profit, operations simply did not have the capital to take on this new and significant on-going expenditure. A final option open to these publishers was to sell or license their content to a commercial entity, but this option was unappealing to many publishers (and libraries alike), as it has historically resulted in a rapid rise in the subscription price. Rather than simply surrendering to the status quo, the scientific publishing community and academic libraries began responding by attempting to create alternatives. Responses have been as varied as the participants themselves (researchers, editors, publishers, and librarians) whose needs are varied, but deeply interrelated. All recognize the need for change, and numerous independent efforts to address the issues from a variety of angles are underway, including: Supporting not-for profit publishers (BioOne, Project Euclid, etc.). Creating competition (SPARC initiatives: creating new lower-cost alternatives to high-price journals – Organic Letters, Journal of Logic Programming, Insect Science, etc.). ·Distributing peer-reviewed work for free (PubMed Central, BioMed Central, Public Library of Science). Developing & linking e-print archives (Open Archives Initiative, E-Scholarship, D-Space). Creating new community models (Columbia Earthscape, MIT CogNet). As these initiatives have evolved, one key idea has emerged: collaboration between all players in the scholarly communications community is critical to ensure the ultimate success of any alternative publishing model. One initiative in particular focuses on leveraging the strengths found in collaboration to forge an alternative. BioOne was conceived by a unique partnership of constituents of the scholarly communications community, and developed as an effort to mount a direct and sustainable disciplinespecific response to the problems outlined above. Its goal has been to build a new, co-operative, electronic publishing venture whose operating structure and business model is technically and financially viable for both the academic publishing community and the library community. Initially, BioOne a unique partnership of constituents of the scholarly communications community BioOne: building a sustainable alternative publishing model for non-profit publishers 135 L E A R N E D P U B L I S H I N G V O L . 1 6 N O . 2 A P R I L 2 0 0 3 was developed as a richly linked database of high-quality journals, representing a wide cross-section of biological sciences, that could be acquired cost effectively by libraries. BioOne’s founding organizations represent broad constituencies: The American Institute of Biological Sciences, The Greater Western Library Alliance, SPARC, The University of Kansas and Allen Press. The concept and initial operating structure of BioOne was developed by a very active volunteer Board of Directors and a Working Group consisting of representatives of these organizations, which ensure collaborative development by representing library and society interests. Additionally, important strategic partnerships with organizations that held expertise in marketing and distribution of electronic services (OCLC and Amigos Library Services) were established early in BioOne’s development to help foster awareness of BioOne’s goals (as well as access to its contents) in the worldwide library community. A unique aspect of BioOne is that collaboration is not at committee level but rather at the business level. Its principals address the economics of publishing from three perspectives (creator, purchaser and end user), and all aspects of BioOne’s operations are vetted by these groups, ensuring that consensus is reached on operational issues as diverse as content acquisition and pricing. In order to ensure that this collaborative effort could remain independent and unbiased, it was critical that an independent entity, and not one of the founding organizations, manage the project. In 2000, BioOne was established as a non-profit corporation, with a paid staff of one. BioOne provides a unique opportunity for realistic collaboration; its participants have equal input into an opportunity to actively change the current scholarly communications process by creating a different publishing model together. The collaborative model that BioOne developed benefits scholarly societies in a variety of ways. Specifically, it provides an inexpensive (in many cases, no cost) vehicle for non-commercial publishers to convert existing print journals to electronic form. Once a journal is online with BioOne, it is marketed and sold as part of the entire BioOne collection, which provides the opportunity for a publisher to receive additional incremental revenue, and the chance to remain financially viable and independent through new uses of content. BioOne also provides its publishing partners with the ability quickly to reach greatly expanded audiences. With its marketing and sales partners, BioOne has established a broad and loyal subscriber base, which publishers reach immediately upon inclusion in the database. Just as importantly, publishers who participate in BioOne have the opportunity for realistic collaboration with each other as well as the libraries that have traditionally served as their main customers. This has proven particularly effective as publishers learned lessons from the library community’s success in the formation and deployment of consortia. BioOne has been able to be very well informed of consortium arrangements, and has had good success in expanding participating publishers’ reach by working with consortia to get access to non-traditional users such as those in twoyear and community colleges. In addition to serving non-profit publishing organizations, BioOne’s business plan always takes into account its mission of equally serving two constituencies: publishers and libraries. To achieve this, it uses a pricing model based on cost recovery. This model is designed to recover costs, and thereby ensuring sustainability for publishers, by setting reasonable pricing policies tied to covering actual operating costs (rather than generating profit margins). Because BioOne is a registered non-profit entity in the United States, it is required by law to make its accounting records available to anyone who wants to access them, which helps ensure openness in reporting of expenses. The organization is specifically structured to keep operating expenses low; using outsourcing and strategic partnerships wherever possible Another key element in the business model that helped to ensure that publishers viewed BioOne as a true collaborative partner was the establishment of a revenuesharing pool for publishers. Fifty per cent of every dollar of subscription income is disBioOne has established a broad and loyal subscriber base 136 Heather Dalterio Joseph L E A R N E D P U B L I S H I N G V O L . 1 6 N O . 2 A P R I L 2 0 0 3 tributed directly to participating publishers. The other 50% covers BioOne’s operating expenses. The subscription revenue is allocated to participating publishing using a formula that is designed to create as level a playing field as possible for the variety of journals (large and small, specialty and generalist) included in the database. The revenue-sharing formula uses a calculation based on combination of pages contributed to the database and hits on the journals’ content. An independent CPA firm audits this revenue-sh	archive;bioone;columbia (supercomputer);euclid;forge;journal of logical and algebraic methods in programming;librarian;library (computing);library acquisitions;library classification;logic programming;loss of significance;openness;outsourcing;pubmed central;public library;sparc;scientific literature;software deployment	Heather Dalterio Joseph	2003	Learned Publishing	10.1087/095315103321505610	econometrics;economics;computer science;economic model;sociology;electronic publishing	DB	-67.82577724006555	-18.626350745720718	99080
6c317d2c30b15c94ad42ae7c6d8e768afc21eccc	"""""""not quite dead yet"""": the near fatal wounding of the experimental use exception and its impact on public universities"""	communications law;constitutional law	While federal legislators have given universities increased freedom to protect new inventions created at their institutions through the BayhDole Act, the judicial branch has restricted universities’ use of patented inventions to produce additional innovations. This paper discusses the problems resulting from the decision in Madey v. Duke University, which reduced the breadth and applicability of the experimental use exception defense to patent infringement claims. Limiting the accessibility of novel intellectual property to research universities jeopardizes scientific progress and weakens the educational experience. Possible solutions exist on many fronts: sovereign immunity may be an adequate defense to many infringement claims at public universities; other potential solutions may address the dilemma through the courts, supplementary legislation, or private settlement of infringement disputes. * J.D. Candidate 2005, University of Colorado School of Law; B.S. Chemical Engineering, University of Mississippi, 1997; M.S. Chemical Engineering, University of Colorado, 2000; Ph.D. Chemical Engineering, University of Colorado, 2002. The author would like to thank Ben Fernandez and Bryan Smith for their careful editing, outstanding support, and encouragement. Thanks also to the outstanding members of the JTHTL for their helpful assistance and incomparable editing skills. Finally, the author wishes to thank the fine filmmakers of MONTY PYTHON AND THE QUEST FOR THE HOLY GRAIL (Columbia Tri-Star 1975) and Phil Weiser who provided the inspiration for the title. 454 J. ON TELECOMM. & HIGH TECH. L. [Vol. 3 TABLE OF CONTENTS ABSTRACT............................................................................................ 453 INTRODUCTION................................................................................... 454 I. HISTORY OF THE EXPERIMENTAL USE EXCEPTION ............... 456 II. THE DECISION AND IMPLICATIONS OF MADEY V. DUKE UNIVERSITY ................................................................................. 458 III. THE BAYH-DOLE ACT: FRIEND OR FOE TO THE TRANSFER OF KNOWLEDGE?..................................................... 461 IV. PATENT INFRINGEMENT AND SOVEREIGN IMMUNITY........... 466 V. PROPOSAL.................................................................................... 471 A. Courts ................................................................................... 472 B. Congress ............................................................................... 473 C. Individual Parties.................................................................. 475 CONCLUSIONS ..................................................................................... 476	accessibility;columbia (supercomputer);exception handling;fisher market;hadamard transform;jason;knowledge-based systems;star trek:;supra, inc.	Jennifer Owens	2005	JTHTL			Web+IR	-67.05183853059303	-19.2830494140056	99166
96c027e212d07bb1dbbe30f7f2a54e1a6789a6e8	net neutrality vs. net neutering		Regarding the recent FCC ruling upholding Net neutrality, Yogi Berra said it best: It ainu0027t over u0027til itu0027s over.	net neutrality	Hal Berghel	2016	IEEE Computer	10.1109/MC.2016.84	law	Vision	-71.32562057397608	-12.451683397723954	99287
74b0f78a61e03d04622b3c1c2a250bf0d0c7ac86	send a boy - or dial it yourself? numbering for the information society	technologie communication;information systems;societe information;internet;telecomunicacion;numerotation;telecommunication;sociedad informacion;information society;numbering;communication technology;information system;numerotacion;tecnologia comunicacion;telecommunications	Numbering and addressing are key features of telecommunications: without them, the Global Information Society cannot exist. As the demand for new, and more innovative, services grows and the world moves towards deregulation and competition, so the pressure on numbering space increases. This article looks at basic numbering concepts and the role played by numbering in information and telecommunication policy. spite its unfortunate name, POTS provides important links: conventional voice telephony (with interactive information services), fax, email, classic dial-up online data bases, Internetand web-access, videotex (e.g. Minitel and Prestel), electronic commerce, interactive video and much more. The problem is that the old-style telephone network is both under-utilised and, yet, too slow for modern communications. As a result, all societies are confronted by new challenges arising from the convergence of information and communication technology and the growth of multi-media. Competition, liberalisation and innovation, combined with cheaper telecommunication, are seen as the spurs: especially for those applications depending on high-capacity, twoway (broadband) technologies. Digitalisation allows the transmission of both traditional and new services (voice, data or graphics) by varied methods. Some ‘old’ services using new technology are: l home banking, home shopping and voice telephony through the Internet; l email, data and web access through mobile phone networks; l online services delivered by web-TV or via satellite or cable services3. However, in discussing these technologies one must keep in mind the degree to which they are not available: over half the world’s inhabitants has never made a ’phone call, while two-thirds of telephone lines serve only 14% of the global population, with 63% of countries having no telecommunications outside urban areas4. And Manhattan contains D ow nl oa de d by G eo rg e W as hi ng to n U ni ve rs ity A t 1 7: 46 2 2 Ju ne 2 01 6 (P T )	cable internet access;database;dial-up internet access;e-commerce;e-services;email;fax;graphics;minitel;mobile phone;numbering (computability theory);online banking;pots codec;prestel;telephone line;videotex	Ralph Adam	1999	Aslib Proceedings	10.1108/EUM0000000006957	telecommunications;computer science;operations management;management;operations research;law;information system	ML	-68.83283627111759	-21.52296947965941	99410
c315d61c516b04112e32e675501382d88008533e	rhetorical differences in research article discussion sections of high- and low-impact articles in the field of chemical engineering		<italic>This study aims to delineate the rhetorical organization of research article (RA) discussion sections in an engineering discipline and explore the variations that distinguish discussion sections of high-impact and low-impact RAs.</italic> <bold>Research questions:</bold> <italic>What is the rhetorical organization of RA discussions in chemical engineering? What are the similarities and differences in the use of rhetorical moves and steps in RA discussions of high-impact and low-impact articles?</italic> <bold>Literature review:</bold> <italic>Some studies have been conducted using Swales’ move analysis with regard to the identification and textual comparisons of RA discussion sections. However, it remains to be determined whether RA discussions of the high- and low-impact articles within a single discipline display the variation in rhetorical patterns.</italic> <bold>Research methodology:</bold> <italic>A total of 40 RA discussions published between 2005 and 2015 were chosen based on five-year journal impact factor and citations of the articles in which they were published. Swales’ move analysis was used to compare rhetorical moves and steps in both sets of RA discussions.</italic> <bold>Results and discussion:</bold> <italic>The study identified the rhetorical organization of RA discussions in the field of chemical engineering. The findings indicate that discussion sections of high-impact articles tend to make use of the “comment on results” move. Explanations of the similarities and differences in the employment of moves and steps are provided. Implications of the findings are discussed.</italic>	traffic collision avoidance system	Bixi Jin	2018	IEEE Transactions on Professional Communication	10.1109/TPC.2017.2747358	bibliometrics;chemical engineering;social science;pragmatics;impact factor;computer science;rhetorical question	Visualization	-75.59557440230344	-18.962104555351146	99609
18d6c707b389c3b3bb9d9d346a15512276fbd467	government and information: the law relating to access, disclosure and their regulation, 4th edition, patrick birkinshaw, mike varney (eds.). bloomsbury professional, west sussex (2011), isbn: 978-1-84766-708-3		the Superintendent of Documents program to the Library of Congress, and the privatization of the GPO. Instead, the report directs the Congressional Research Service to award a grant or contract to the National Academy of Public Administration to conduct a study on GPO operations and additional cost saving opportunities beyond what the GPO has already instituted, and report its findings to the House and Senate Committees on Appropriations no later than one year after enactment of this Act. AALL has also actively supported the White House's Open Government Directive. AALL evaluated a plan developed by the Department of Justice (DOJ) as part of an effort coordinated by OpenTheGovernment.org. Unfortunately, the DOJ's first Open Government Plan lacked clear goals and specificity. AALL members communicated their concerns with the agency and were very pleased when DOJ released a second version that addressed many of the suggestions. With encouragement from AALL, DOJ posted its valuable digitized legislative histories online for the first time. DOJ also launched FOIA.gov, a portal for information and agency data about the Freedom of Information Act. AALL has also advocated in support of expanding protections for federal whistleblowers. It was an EPAwhistleblower that alertedmembers of the library community about the closing of the Environmental Protection Agency libraries and destruction of materials in 2006. We are pleased that House Oversight and Government Reform Committee Chairman Darrell Issa (R-CA-49) has committed to passing stronger protections for whistleblowers before the end of the 112th Congress. The panel was honored that Hudson Hollister, counsel to the House Oversight and Government Reform Committee, joined the discussion. Hollister focused his remarks on the DATA Act, which is a flagship initiative by Chairman Issa that has bipartisan support and would transform how the government makes spending information available to the public. The DATA Act builds upon the successes of the federal spending portal USASpending.gov and the recovery spending overseen by the Recovery Accountability and Transparency to create an independent board responsible for publishing and monitoring all federal spending. The RAT Board was very effective in identifying government waste, fraud, and abuse, and making sure that spending information was reported quickly and accurately to the American people. The successor to the RAT Board, the FAST board, would do the same. But the DATA Act goes further. It empowers the FAST board to promote the creation of government-wide data standards so that agency reporting of spending can be easily standardized and integrated. While these standards are directly applicable to federal spending, the unique identifiers that will come out of this process can be applied to many other efforts to catalog and extract government data. The legislation passed the Committee on Oversight and Government Reform, and is pending final passage by the House. It has also been introduced by Mark Warner in the Senate as S. 1222. The program reviewed recent executive and legislative branch efforts and provided some insight into the progress the Obama administration and Congress have made during the last few years. While several important initiatives have opened up data and improved access to government information, transparency advocates must continue to stay vigilant to ensure that our elected officials maintain their commitment to open government. Daniel Schuman The Sunlight Foundation, 1818 N Street NW Suite 300 Washington, D.C. 20036, USA E-mail address: dschuman@sunlightfoundation.com	academy;closing (morphology);directive (programming);freedom of information act 1982;freedom of information laws by country;group policy;hudson;information systems security association;international standard book number;library (computing);netware;sensitivity and specificity;unique identifier	Debbie L. Rabina	2012	Government Information Quarterly	10.1016/j.giq.2012.07.006	media studies;operations research	ML	-65.78560571891273	-18.59511526894672	99674
84e87d7b649efc1ce0dc2bbc387efec906c21960	delivering electronic texts over the web: the current and planned practices of the oxford text archive	texte electronique;diffusion de l information;textual database;encodage;sciences humaines;human sciences;tei;base de donnees textuelles;standardisation;internet;oxford;human resource;archives;metadonnee;description;electronic text;standardization	This paper is an overview of some recent developments within the Oxford Text Archive (OTA). Specifically it focuses on the use of various forms of metadata used within the OTA, including the manipulation of the TEI header, as a means of assisting in the discovery and delivery of resources from the OTA. The paper explores the use of metadata throughout the Arts and Humanities Data Service as a whole, and how this has facilitated the building of an integrated gateway to digital humanities resources. Finally there is a brief discussion on how the OTA currently provides access to its holdings via the WWW and a look at some possible future developments.	digital humanities;oxford text archive;text encoding initiative;www;world wide web	A. Morrison	1999	Computers and the Humanities	10.1023/A:1001726011322	human resources;computer science;human science;multimedia;sociology;operations research;literature;standardization	Web+IR	-71.56092794493183	-22.228708431945666	99743
cb5c2f42e3493660932ba60c3b14ab9ea26473c0	the power law model and total career h-index sequences	power law models;time series;journal;h index sequences;indexation;power law;data fitting	Three variations on the power law model proposed by Egghe are fitted to four groups of h-index time series: publication-citation data for authors, journals and universities; and patent citation data for firms. It is shown that none of the power law models yields an adequate description of total career h-index sequences.		Fred Y. Ye;Ronald Rousseau	2008	J. Informetrics	10.1016/j.joi.2008.09.002	econometrics;power law;law of total cumulance;time series;mathematics;statistics;curve fitting	Theory	-76.74588119046109	-22.593837011083238	99834
1265ad53dbac432936dc5f8262ae2ec15ab73ad4	comparative study on the academic field of artificial intelligence in china and other countries	artificial intelligence;knowledge structure;hot spot field	The strategic status and development potential of artificial intelligence attract scholars from different countries and majors to conduct in-depth research in different fields and directions, forming a complex network of research results. In the paper, we select the literature on artificial intelligence in Web of Science database since 2006, researching from the perspective of contribution rate of the literature among countries, research hot spots and frontier trends. This paper obtain the research situation, academic influence and other achievements of our country in the field of artificial intelligence and put forward a series of feasibility proposals, such as scholars in our country should break the boundaries between countries and fields and carry out cooperative research among different countries and fields.	artificial intelligence	Bo Sun;Zhixue Dong	2018	Wireless Personal Communications	10.1007/s11277-018-5243-2	computer science;china;complex network;artificial intelligence	HCI	-76.72394543743279	-18.32067267770239	100024
617d49ac9d847fb74224399173d419b5644cee8d	analytical sociology and social mechanisms by pierre demeulenaere (ed.)				Peter Davis	2011	J. Artificial Societies and Social Simulation			AI	-64.1832621313675	-10.717321577046159	100287
e21c5fc0e8bf3d483216430fbd840afe13c2e2c5	content and workflow management for library websites: case studies, holly yu (ed.), idea group inc, hershey, pa, 2005 (259pp., isbn: 1-59140-534-3, $69.95 paperback)	workflow management	The issues and challenges dealing with access to and control of information, in the subject area of Web librarianship, are valuable in many ways (e.g., FAQ’s, problems, solutions, return-on-investment, etc). The focus of these issues has, interestingly, shifted from static and dynamic Website to a customizable interface tied into the parent organization’s mission for the delivery of services and products. But, qualitative and quantitative data are hard to find. This is more so about the finer details, such as administrative, operational, and technical, based on in-house know-how (rather than outsourced operations), that are harder to find. The appearance of a book with documentation of the technical solutions, using the case study method, is a compliment that Holly Yu, California State University (CSU), deserves from such an ever eager audience— including geeks, techies, librarians, Weberians, Cyberians, Web administrators, system administrators, etc. A glance at the contents of Content and Workflow Management for Library Websites gives a complete picture:	documentation;geek;international standard book number;librarian;outsourcing;system administrator	Mohamed Taher	2007	Int J. Information Management	10.1016/j.ijinfomgt.2006.09.003	workflow;computer science;management;operations research	Web+IR	-67.60415800616698	-17.070887941005203	100602
b3b51570d2adbd7fca7773c782dd1352f93440bc	granular computing, introduction to.	granular computing	What is granular computing(GrC)? It is a shifting paradigm. Let us start with a few words about how the term was coined. In the academic year 1996-97, when Lin (this section editor) took his sabbatical leave at UC-Berkeley, Zadeh suggested granular mathematics (GrM) to be his research area. To limit the scope, Lin proposed the term granular computing [14]. What was GrC then? Zadeh had outlined it in his 1997 seminal paper [15]. While Lin took incremental approach: He mapped his neighborhood system [5] to Zadeh’s intuitive definition [12] and used it as his First GrC Model [8], [9], [10]. It may be important to point out that the concept of neighborhood systems, which was motivated from the approximate retrieval in database [7], is a generalization of topological neighborhood system that formalizes the ancient intuition of infinitesimal granules. Much progress has been achieved, since then. So this section has been organized to represent this progress and to reflect the current state of GrC. We believe in incremental approach, namely, each new step is based on solid results and move forward. So many special theories and applications are gathered. Jointly, they refelct the current state of GrC and may also implicilty hint to the ultimate goals of GrC.. To grasp the main idea from such a diverse collection of papers, a roadmap will be helpful: We suggest the reader start with the first 4 Sections of T. Y. Lin’s paper Granular Computing: Ancient Practices, Modern Theories and Future Directions. There, the readers may want to pay special attentions to the first three examples:	approximation algorithm;attention;computation (action);generalization (psychology);granular computing;granules dose form;increment;intuition;lobular neoplasia;nih roadmap initiative tag;paper;programming paradigm;theory;uc browser	Tsau Young	2009		10.1007/978-0-387-30440-3_253	chip;semiconductor;optoelectronics;printed circuit board;wafer;materials science	Web+IR	-63.77819471885409	-17.74575516009878	100853
83e580ec630c33c846740387de195847721efae0	large scale off-track betting systems	computers disk drives australia printers government legislation time factors;computers;legislation;printers;government;disk drives;time factors;australia	While legal off-track betting in North America has only been active since April 1970 (in New York), it has been available to Australians since 1966, following the installation of telephone betting in the state of Victoria.	victoria (3d figure)	Stephen L. Dunik	1974	Computer	10.1109/MC.1974.6323331	operations research;law;government	Metrics	-69.12065369102002	-11.010898332035941	100916
5a7f399363f505abadfe8cceb0c69ad3ca6d31e4	editorial: the third interfaces ranking of universities' contributions to the practice literature	third interfaces;practice literature	third interfaces;practice literature		Michael H. Rothkopf	1999	Interfaces	10.1287/inte.29.6.107		HCI	-64.1760107009598	-12.529639376068799	100981
696bee3550f865d85a0a4292435281ab6e07d0ec	the revolt against journal publishers	crise;journal publishers;communication scientifique;edicion;comunicacion cientifica;open archives;periodical;information scientifique technique;edition;publishing;editor;archives ouvertes;computer network;archivos abiertos;periodique;periodico;libre acceso;internet;open access;coste;publisher;scientific communication;scientific technical information;electronic publishing;libre acces;acces libre;informacion cientifica tecnica;crisis;academic libraries;editeur;cout	In universities, research labs and the libraries that support their work, a revolt against current journal publishing prices and policies is rapidly growing. Underlying the revolt are the new capabilities offered by computer networks, particularly the Internet, to make information easily and widely available. Research work can be posted, reviews can be processed and users can view the results, all online and at very low cost. Framed by these generous online capabilities, the spectacle of libraries unable to pay for needed journals has become unbearable. Faculty, researchers and others who depend on journals for information and professional prestige are coming to feel that their needs are not being met by current journal publishing practices. Universities have begun to realize that they no longer have to accept the terms offered by journal publishers.	internet;library (computing)	Howard Falk	2004	The Electronic Library	10.1108/02640470410533452	telecommunications;computer science;publishing;sociology;electronic publishing;management;operations research;law;world wide web	Metrics	-70.86689336503206	-21.345475379946436	101086
c76ccb10e204d7c1176ce470bac676c29057d560	research and citation impact of publications by the chemistry division at bhabha atomic research centre	self citation;analyse bibliometrique;analisis citas;citation analysis;life cycle;periodical;research field;centro investigacion;research center;delai;autocitation;analyse citation;periodique;plazo;periodico;centre recherche;chimie;etude longitudinale;estudio longitudinal;asie;auteur;autocitacion;science citation index;autor;chemistry;time lag;quimica;domaine recherche;campo investigacion;bibliometric analysis;author;follow up study;india;asia;inde;analisis bibliometrico	The paper analyses the citations to 1733 publications published during 1970–1999 by the Chemistry Division at Bhabha Atomic Research Centre, using Science Citation Index 1982–2003 as the source data. The extent of citations received, in terms of the number of citations per paper, yearwise break up of citations, domainwise citations, self-citations and citations by others, diachronous self-citation rate, citing authors, citing institutions, highly cited papers, the categories of citing documents, citing journals and distribution of citations among them etc. are determined. During 1982–2003 chemistry Division publications have received a total of 11041 citations. The average number of citations per year was 501.86. The average number of citations per publication was 6.37. The highest number of citations received were 877 in 2001. The citation rate was peaked during 1990–2003 as maximum 9145 (82.82%) citations were received during the period. Total self-citations were 3716 (33.66%) and citations by others were 7325 (66.34%). Mean diachronous self-citation rate was 36.16. Citation time lag was zero for 144 (15.52%) papers and one year for 350 (37.72%) papers. Single authored publications (168) have received 456 (4.13%) citations and 1565 multi-authored publications have received 10585 (95.87%) citations. The core citing authors were: J. P. Mittal (695) followed by V. K. Jain (524), H. Mohan (471), T. Mukherjee (307), R. M Iyer (253), H. Pal (251), J. V. Yakhmi (211), A. V. Sapre (174), D. K. Palit (161), N. M. Gupta (128), and S. K. Kulshrestha (116). Citation life cycles of four highly cited papers was discussed. The core journals citing Chemistry Division publications were: J. Phys. Chem.-A (436 citations), Chem. Phys. Lett. (372), J. Phys. Chem. (355), J. Chem. Phys. (353), J. Organomet. Chem. (285), J. Phys. Chem.-B (279), J. Photochem. Photobiol.-A (263), Langmuir (245), J. Am. Chem. Soc. (226), Physica-C (225), Radiat. Phys. Chem. (217), Inorg. Chem. (215) and Indian J. Chem.-A (207).	citation analysis;citation index;q-chem;source data	B. S. Kademani;Vijai Kumar;Ganesh Surwase;Anil Sagar;Lalit Mohan;Anil Kumar;C. R. Gaderao	2007	Scientometrics	10.1007/s11192-007-1651-x	biological life cycle;computer science;operations research;citation analysis;world wide web;auteur theory	Web+IR	-75.24448108731252	-22.050416259380693	101087
a01af5af6d1030f25f4ffa7869c947c14cd74f7c	classification and information management for patent collections: a literature review and some research questions	patent classification;patent management	Introduction #R##N##R##N# - With the growth of digital patent collections, and increased open accessibility, the ability to automatically organize these collections had become desirable. Apart from the specific efforts of offices responsible for patenting activity, many relevant discussions can be found in the literature, presenting alternative ways to organize patent collections and to explore the knowledge embedded in patent databases.#R##N##R##N# Method #R##N##R##N# - This paper identifies and discusses four problems related to the patent classification process, reviews relevant literature for the identified problems and formulates research questions for future research.#R##N##R##N# Results  #R##N##R##N# - The review finds that there is an ongoing effort to harmonize existing patent classification systems and to improve current systems, trying to develop specific techniques to retrieve the information embedded in patents and to transform it into a more usable format for users.#R##N##R##N# Conclusions #R##N##R##N# - This study contributes to the development of the field of patent management by discussing contemporary issues, open research questions and possible paths to solve related problems.	information management	Magali Meireles;Gabriela Ferraro;Shlomo Geva	2016	Inf. Res.		library science;patent visualisation;engineering;data science;data mining	DB	-73.83813316826864	-17.765770889333655	101267
c67a55a775fba6b93a6f623d92a5dbe86e478550	social media and political participation			social media	Mina Momeni	2017	New Media & Society	10.1177/1461444817728054	political communication;socioeconomics;social philosophy;social media;politics;american political science;political science;social movement	NLP	-65.56851167941241	-9.957220585132903	101490
14f590c5299b6715745c761f7cfbb4c9ff4225ca	relevance: a review of and a framework for the thinking on the notion in information science	probability;information science;logic;informing science;communication thought transfer;philosophy;relevance information retrieval	Abstract#R##N##R##N#Information science emerged as the third subject, along with logic and philosophy, to deal with relevance-an elusive, human notion. The concern with relevance, as a key notion in information science, is traced to the problems of scientific communication. Relevance is considered as a measure of the effectiveness of a contact between a source and a destination in a communication process. The different views of relevance that emerged are interpreted and related within a framework of communication of knowledge. Different views arose because relevance was considered at a number of different points in the process of knowledge communication. It is suggested that there exists an interlocking, interplaying cycle of various systems of relevances.	information science;relevance	Tefko Saracevic	1975	JASIS	10.1002/asi.4630260604	information needs;social science;information science;computer science;knowledge management;artificial intelligence;probability;logic;statistics	Logic	-73.3272161219703	-18.18538693424185	101500
95658d7751535c09fef2a0d02cd1f945dab52b5d	read all about it!: help desk newsletter informs and enlightens organization	communications;information technology;service management;help desk;statistics;newsletter;question answering	"""A successful help desk is equipped with extensive knowledge of every policy, service, and application maintained by their campus' IT organization. Without this knowledge, they would fail to provide top-notch service. But how much does a typical IT organization know about the help desk that is supporting their services? In the case of the Campus Information Technologies and Educational Services (CITES) Help Desk at the University of Illinois, the answer was unfortunately """"not much."""" The staggering quantity of interesting facts, figures, questions, answers, and anecdotes at our fingertips could fill dozens of volumes. So, we decided to record our experiences to paper (or PDF, as the case may be) in the form of a monthly newsletter.  The Help Desk distributed the first issue of The Queue in September 2008. Each published issue includes articles that help CITES understand who we are, what we do, and how we do it. Our regular rotation of features includes a monthly report highlighting our statistical breakdown of customer contacts for the month, a conversation with a service manager known as the """"Service Spotlight,"""" a biography of a Help Desk full-timer, and other timely or interesting pieces about Help Desk happenings.  The Queue has improved our transparency and opened more than a few eyes around CITES. Our colleagues' understanding of how we do business is developing, and this is helping us provide even better service to our internal and external customers alike."""	dbpedia;institute for operations research and the management sciences;operating system service management;portable document format;timer	Ryan Christopher Tucker;Nathan Carpenter	2009		10.1145/1629501.1629522	simulation;computer science;multimedia;service desk;world wide web	HCI	-63.53240870884836	-18.145582588014012	101740
a0f7863ca9c56019ea0fbf7fa202e5e08d33f8c7	digital archive policies and trusted digital repositories	digital archives;digital repository;digital libraries;digital curation;university of california;digital archive;digital repositories;digital preservation;article;policy management	The MIT Libraries, the San Diego Supercomputer Center, and the University of California San Diego Libraries are conducting the PLEDGE Project to determine the set of policies that affect operational digital preservation archives and to develop standardized means of recording and enforcing them using rules engines. This has the potential to allow for automated assessment of “trustworthiness” of digital preservation archives. We are also evaluating the completeness of other efforts to define policies for digital preservation such as the RLG/NARA Trusted Digital Repository checklist and the PREMIS metadata schema. We present our results to date. The International Journal of Digital Curation is an international journal committed to scholarly excellence and dedicated to the advancement of digital curation across a wide range of sectors. ISSN: 1746-8256 The IJDC is published by UKOLN at the University of Bath and is a publication of the Digital Curation Centre. Digital Archive Policies...93	archive;case preservation;cyberinfrastructure;digital curation;digital library;end-to-end principle;ibm notes;international standard serial number;iteration;library (computing);norm (social);san diego supercomputer center;trust (emotion)	MacKenzie Smith;Reagan Moore	2007	IJDC	10.2218/ijdc.v2i1.16	digital library;digital asset management;computer science;database;world wide web	Visualization	-65.73139366894952	-15.189558748542115	101936
83728d4f84a9905d8ffe7feb5b2cd56aac0b7320	paid content a way to electronic knowledge-based economy	information and communication technology;information society;market value;knowledge based economy	Nowadays, two the most significant concepts determining the future of the world are: information society and knowledge-based economy. Information society may be defined as a community whose collective life is organized by the wide use of the information and communication technologies, and which economy is based on knowledge. An economy is based on knowledge if the market value of dominating products and services depends mostly on knowledge, instead of resources, energy, or physical work.	paid content	Wojciech Cellary	2010		10.1007/978-3-642-15576-5_2	information and communications technology;knowledge economy;knowledge management;market value;quaternary sector of the economy;digital economy;knowledge value chain;information economy	HCI	-76.23947846266591	-10.660778370542445	102003
02c4378594cc7b66530cbc6f5576ff6b217d80da	electronic markets on self-archiving		Dear readers of Electronic Markets, Welcome to the first issue of volume 26, which includes a collection of six articles. Three articles address the special theme on BICT-based Networked Governance^, while another three are general research contributions. Prior to introducing these articles, the editorial links to the last editorial in issue 25/ 4, which discussed the reviewing process as the key element in safeguarding the quality of academic work (Alt et al. 2015a). Especially academic journals with a high impact factor feature competitive review processes, since many authors are interested in publishing their work in these journals. As indicated in Fig. 1, this is a self-reinforcing mechanism, as a large number of authors is attracted to publishing in these journals due to the importance of highly ranked publications for academic repuation and their role in academic qualification processes. Since researchers usually submit their best work to these journals and the journal’s space for accepted papers is limited, the successful papers feature a high maturity, which in turn increases the probability of becoming cited. Journals with many frequently cited articles are likely to have a higher impact factor, which again increases the incentives for authors to submit their work to the respective journal.	alt attribute;archive;capability maturity model;control-alt-delete;electronic markets;positive feedback	Rainer Alt;Carsta Militzer-Horstmann;Hans-Dieter Zimmermann	2016	Electronic Markets	10.1007/s12525-015-0215-9	economics;electronic markets;self-archiving;marketing;commerce	Web+IR	-68.38330803052739	-17.65510776124702	102072
48b2f532ceb5322b07c03b52e3c0deb9d8d443c4	of deck chairsss, suitss, and quiz shows	federal communication commission;national information infrastructure;public interest;social aspects of automation;decision maker;internet architecture;internet;marketing;decision makers internet architecture marketing based management marketing based control centralized management centralized control distributed network anarchic network public interest federal communications commission national information infrastructure;internet teletext tv broadcasting ip networks centralized control cable tv decoding information retrieval telecommunication traffic graphics;marketing internet public administration social aspects of automation;public administration	Should marketing-based, centralized management and control be forced on to a distributed and fundamentally anarchic network? It seems that those responsible for representing the public interest-specifically the Federal Communications Commission (FCC)-appear surprisingly uninterested in examining whether the public is currently being well-served by the existing Internet architecture. No-one seems to be asking the real National Information Infrastructure (NII) decision-makers the awkward questions on the public's behalf. >		John Murray	1995	IEEE Computer	10.1109/2.402084	internet architecture board;decision-making;the internet;software engineering;management;computer security	Vision	-69.5786184979903	-11.297424385757205	102155
53b7cf343d86beb1a5d8671adb44dc3998a037eb	review: new pathways in microsimulation		Review of:Dekkers, Gijs, Keegan, Marcia and ODonoghue, Cathal (2014) New Pathways in Microsimulation. Ashgate: Aldershot		Andreas Koch	2015	J. Artificial Societies and Social Simulation		management science;social science;microsimulation;media studies;sociology	AI	-63.8784898085097	-10.645181336486216	102466
9c46c49cd25205cca342200aea94579e71d847a9	from the editors	time pass;digital object;vantage point;professional life;rewarding event	"""Welcome to the last issue for this year. To paraphrase the old saying, how quickly time flies when one is having fun -- especially in the editorial role for Data Base. We continue to reap the benefits of seeing a number of projects that were already under development upon our arrival come to fruition. This special issue on e-commerce system development practices managed by Bjørn Erik Munkvold and Sandeep Purao is a fine example. The articles as a group provide good examples of how the business context can interact with the system development process. Specifically, we are able to examine both the commonality and differences for an e-commerce software development organization, startup venture for an on-line magazine business, and an on-line computer game developer.As we complete our first year, we continue to work on both operational and substantive issues. Operationally, we are in the process of creating an online tracking system for our editorial board members who now serve the same role as senior editors. Our goal in the future is to expand the system to provide information to other key stakeholders (e.g., authors and reviewers). Substantively, we continue to encourage researchers to provide either comprehensive survey reviews or framework papers covering key areas of IS. Also, in recognition of the merger of SIGCPR, a call for special section on IT personnel research is now underway with guest editors Fred Niederman and Munir Mandviwalla. We hope that our new SIGCPR members will look towards Data Base as a key outlet for their research.Yet, probably one of our most important goals we have embarked on is to emphasize the quality of Data Base articles. To that end, we are committed to publishing only theoretically grounded research (as opposed to purely descriptive works). Moreover, we firmly follow the precept of not sending out any papers for review that we do not feel have a good potential for acceptance. To date, we have increased the rejection rate at the front end to approximately 50 percent of submissions. Another significant percentage is sent back with the opportunity for the authors to improve and resubmit in the future. While the exact percentages will likely change in the future, we believe greater scrutiny at the front end should help improve the quality of published papers.Finally, in our last issue, we announced changes in our editorial board. During that entire process, we inadvertently left Elias Awad from the entire process. We traced the culprit ironically back to an incomplete """"database"""" that we used. Upon contact, Elias has indicated that he was ready to take a much-deserved break. We certainly didn't blame him since he noted that he first joined the editorial board of Data Base back in 1974. Moreover, Elias literally started with ACM and SIGBDP (now SIGMIS) in the fall of 1964 out of the University of Chicago when he was a doctoral student at Northwestern. Now, that's dedication."""	database;e-commerce;fred (chatterbot);online and offline;pc game;rejection sampling;software development;tracking system;video game developer	Wynne W. Chin;Dorothy E. Leidner	2002	DATA BASE	10.1145/590806.590807		Web+IR	-62.886600578991846	-18.90023831255202	102505
7c08141038af7df8c84a298b07ec02f0b4376dd2	designing a pattern language for surviving earthquakes		"""In this paper, we proposed the Survival Language, a pattern language to support survival when a catastrophic earthquake occurs. This proposal comes from the problem that the tragedies of earthquakes are repeated, because knowledge and wisdom on how to prepare for an earthquake and what to do during an earthquake have not been passed down sufficiently. This paper presented the four patterns of the Survival Language: """"Daily Use of Reserves,"""" """"Life over Furniture,"""" """"Evacuation Initiator,"""" and """"Kick Signal."""" In addition, we described that the Survival Language is created and used by collaborations because a pattern language has been a tool for collaboration since it was presented by Christopher Alexander."""	pattern language;scsi initiator and target	Tomoki Furukawazono;Shota Seshimo;Daiki Muramatsu;Takashi Iba	2013	CoRR		artificial intelligence;computer security	PL	-64.65558023067545	-20.032806124273186	102521
b123e642eb12fcda805f5f8cd486122300f301cf	the sharing economy: studying technology-mediated social movements		The sharing economy is a term used to describe an IT-fueled, rapidly growing social movement around collaborative consumption. This movement has the potential to significantly affect economic opportunity and broader culture. In this research- in-progress paper, we pose as a key question: how does technology mediation of the sharing economy movement change over time? What explains this change, and what difference does technology mediation make? We draw upon the concepts of technology mediation, and computerization movements, in two comparative industry case studies: car sharing, and room sharing. We outline future research steps, and begin the process of critically examining the role of IT in social movement mediation. Is the sharing economy likely to create positive new economic alternatives? Or is it simply another strategy to intensify the role of global finance in everyday life, and fuel the high rates of growth demanded by venture-backed technology startups?	sharing economy	Jonathan P. Allen	2016		10.1145/2890602.2890609	mediation (marxist theory and media studies);socioeconomics;economics;social movement;everyday life;sharing economy	HCI	-77.0103011561602	-10.414960489029822	102601
7f0661529d70395e24d4fd4e8decb2ad674cb1ca	a culture of community	social capital;interpersonal relationship	The world increasingly asks 'how do I benefit?' as opposed to 'how can I contribute?'. In an age of consumerism and the 'me' culture how can an ethos of community contribution flourish. As the SIG sees' it's numbers stable but it's student numbers converting to professional memberships decline, how can we stem the tide. It's time to think differently about what it means to be part of the SIGWEB community, we must move away from a culture of benefits to a culture of community. I think this means some pretty serious changes to how we think of ourselves as a community and entails a move to place more emphasis on social capital, the advantage created by a person's location in the relationships of the SIGWEB community. Indeed, for a community originally named 'SIGLINK' these interpersonal relationships seem even more relevant. So how to proceed? Well, I'd like to start a discussion about this topic with all members of the SIG through our 'Google--Group' URL at: http://groups.google.com/group/sigweb-community.	social capital	Simon Harper	2007	SIGWEB Newsletter	10.1145/1288104.1288105	interpersonal relationship;social capital;computer science;world wide web	HCI	-77.24311683045262	-14.629335679105226	102708
cae01efde8cfc6d0911e5befc6188cdd8704a915	specialization is harmful to computer education	computer education	"""T he other day I was advising a colleague about where his daughter might go to college to prepare for a career in computing. He was not asking about what university was best but, rather, what degree program was right for her. In explaining some of the issues, I pulled out my annual presentation to our company's college recruiters. The presentation is aimed at technical people without a strong computing background and it tells them what to look for and what to expect when they recruit people for software development and other computer related positions. It dawned on me that a good part of my presentation would not be needed if the field of computing were taught the way it was when I learned it. I have reached the conclusion that we are too specialized in computer science. In the """"old days"""" it was reasonable to expect each faculty member to understand the whole field. Today that is no longer the case, and as a result both students and employers often fred too many, too narrow options with not enough understanding on how to integrate them. Let me begin by defining the problem more carefully. Figure 1 illustrates the worst-case scenario that our recruiters face when visiting a large university. True to its medieval heritage, the university is a loose confederation of fiefdoms (known as colleges or schools) and each college has its own """"computer"""" degree(s). The departments do not cooperate, and their faculty only meet each other at faculty senate meetings or social occasions. Each department has its own events that a recruiter would need to support, held on widely different dates (or else conflicting with each other on the same dates). Each has its own curriculum, its own criteria for graduation, and its own standards for what courses a student must and may take. (I recently visited a college where students in liberal arts could not take some of the advanced computing courses in engineering and vice versa but I will leave that subject for another day.) While most universities are not quite this extreme, perhaps they only have two or three different computing degrees the problem is still one of confusion for parents, students, and potential employers. I contend that the problem is, indeed, much deeper than this. I have seen computer engineering programs in departments of computer science, departments of electrical engineering, and with joint sponsorship. Ditto, I fear, for software engineering, information science, and computer science. My general assessment below is based on what we have found while recruiting."""	computer engineering;computer science;electrical engineering;fred (chatterbot);goto;information science;loose coupling;partial template specialization;software development;software engineering;worst-case scenario	Dennis J. Frailey	1998	SIGCSE Bulletin	10.1145/292422.292423	simulation;computer science;multimedia	DB	-64.52461481716954	-22.786003100302175	102721
608ea82349770ac65900c00bef2c637bed092f3d	the landscape of giscience publications 1997-2007: an empirical investigation with latent semantic analysis	latent semantic analysis	Abstract#R##N##R##N#This article reports on an empirical study of the trends and patterns of research activities in Geographic Information Science (GIScience) during the years 1997–2007. The GIScience research priorities identified by the University Consortium of Geographic Information Science (UCGIS) were used as guidelines to examine the 985 research articles published in six well-recognized academic journals. Latent Semantic Analysis (LSA) was employed to investigate the association among the different GIScience research themes. The spatial and temporal patterns of the association between the publications and the different GIScience themes were examined to show the development of GIScience research during the study period. Furthermore, correlation analyses between the publications were conducted following the LSA results to reveal GIScience research networks, including the networks of the published articles and those formed by the research places. In this article, we applied an approach that was developed within information science to depict what GIS research activities were conducted when and where and how they connect to each other through sharing common research themes. The related findings pave the way for future efforts to describe the paradigm of GIScience as well as the pattern of GIScience research.	geographic information science;latent semantic analysis	David A. Parr;Yongmei Lu	2010	Trans. GIS	10.1111/j.1467-9671.2010.01228.x	latent semantic analysis;geography;computer science;data science;data mining	Web+IR	-75.9799442656968	-18.61305615132116	102774
7cabe642c0ca1f9ea0898b3803c71f60401f2e35	challenges in building digital libraries for the 21st century	general study;infrastructure information;electronic commerce;project;proyecto;interoperabilite;interoperabilidad;bepress selected works;distributed networks;information infrastructure;information retrieval;digital library;digital libraries;evaluation method;conception;estudio general;biblioteca electronica;operating system;digital preservation;diseno;utilisabilite;of research and development;design;evaluation;electronic library;interoperability;information system;evaluacion;usabilidad;projet;etude generale;usability;systeme information;bibliotheque electronique;infraestructura informacion;sistema informacion	"""After a decade of research and development, digital libraries are becoming operational systems and services. This paper summarizes some of the challenges required for that transition. Digital libraries as systems are converging with digital libraries as institutions, particularly as we consider the service aspects. They are enabling technologies for applications such as classroom instruction, information retrieval, and electronic commerce. Because usability depends heavily upon context, research on uses and users of digital libraries needs to be conducted in a wide array of environments. Interoperability and scaling continue to be major issues, but the problems are better understood. While technical work on interoperability and scaling continues, institutional collaboration is an emerging focus. Concerns for an information infrastructure to support digital libraries is moving toward the concept of """"cyberinfrastructure,"""" now that distributed networks are widely deployed and access is becoming ubiquitous. Appropriate evaluation methods and metrics are requirements for sustainable digital libraries that have received little attention until recently. We need to know what works and in what contexts. Evaluation has many aspects and can address a variety of goals, such as usability, maintainability, interoperability, scalability, and economic viability. Lastly, two areas that have received considerable discussion elsewhere are noted -- digital preservation and the role of information institutions such as libraries and archives."""	digital library;library (computing)	Christine L. Borgman	2002		10.1007/3-540-36227-4_1	information infrastructure;digital transformation;interoperability;design;digital library;usability;project;computer science;evaluation;database;multimedia;world wide web;computer security;information system	EDA	-71.75276400807365	-23.456360148099407	102978
3be1dbb94780a437d5326a8a65b8153bd3dac272	the scenario of brazilian health sciences in the period of 1981 to 1995	information biomedicale;america del sur;scientometrics;amerique;south america;time trend;medicina;information mapping;linear regression;bresil;biology;biologia;medecine;scientific production;biomedical information;sante;factor analysis;scientometria;informacion biomedical;correspondence analysis;scientometrie;brazil;health science;cartographie information;medicine;nuclear medicine;health;infectious disease;salud;america;biologie;amerique du sud;brasil	Ensuing a previous study of Brazilian sciences production for the period 1981–95, health sciences were taken apart for scrutiny. ISI data was obtained in an aggregate format comprising 40 health research fields recording their yearly number of papers, proportion out of the country, proportion out of the field, and impact relative to field. Simple linear regression was used to examine time trends in production and impact of research fields. A complementary variable representing growth trend was computed as the regression slope. Data were then analysed by means of Factor and Correspondence Analysis. Results allowed the production of location maps of research fields so that hierarchy and relationships among them could be examined in the form of geometric distances. It was found that health sciences represent 42% of the Brazilian scientific production and that their trends in both production and impact do not differ from other sciences taken altogether. Measurements of production were found negatively correlated with impact and factor analysis revealed that the major distinction between fields is attributable to production (64% of measurement variations against 19% due to impact). Experimental Biology & Medicine largely exceeds other fields in production, though at ordinary levels of impact. Correspondence analysis refined the study of impact allowing the identification of the best performers as Clinical Immunology & Infectious Diseases, Environmental & Social Medicine, and Radiology & Nuclear Medicine. The information provided can advise national policy makers on science & technology about priorities concerning the improvement of the country's competitiveness.	aggregate data;competitive analysis (online algorithm);complementarity (physics);correspondence analysis;factor analysis;information sciences institute;linear equation;map;radiology	Júlio Cesar Rodrigues Pereira;Maria Mercedes Loureiro Escuder	1999	Scientometrics	10.1007/BF02458470	infectious disease;scientometrics;computer science;linear regression;information mapping;health;correspondence analysis;factor analysis;statistics	HCI	-75.98016140589714	-22.48786149602801	103067
ac308c7df4fa44d38f6327d3a346e410592204d5	women's studies: bibliometric and content analysis of the formative years	academic staff;analyse bibliometrique;ciencia informacion;mujer;citation analysis;communication scientifique;woman;north america;america del norte;amerique du nord;information science;amerique;periodical;feminismo;analisis cita;hombre;etats unis;estados unidos;feminism;analyse citation;periodique;content analysis;periodico;femme;auteur;autor;human;feminisme;women;scientific communication;bibliometric analysis;author;social structure;america;science information;bibliographic standards;homme;analisis bibliometrico	Women‘s studies has emerged as a recognised academic specialty in recent years. We explored the social structure of the field by analysing bibliometrically all scholarly articles (n = 1,302) and acknowledgements (n = 595) appearing in three pioneering journals over a twenty year period. We analysed authors (n = 1,504) and acknowledgees (n = 3,252) in terms of gender. We also conducted a content analysis of all editorial statements (n = 135) published by the three journals. Our results demonstrate the highly gendered nature of the field and the incompatibility of its publicly stated objectives.	bibliometrics	Blaise Cronin;Anna Martinson;Elisabeth Davenport	1997	Journal of Documentation	10.1108/EUM0000000007196	library science;social science;content analysis;information science;computer science;social structure;sociology;citation analysis;world wide web;auteur theory	Metrics	-75.280518682573	-22.551950091562542	103078
82c69a88217ef2503dbcd80c4cc8709b02151307	understanding methodological and disciplinary differences in the data practices of academic researchers	university libraries;data management;academic libraries;article;assessment	In response to the rise of data driven research, academic libraries have expanded their research data services. Rather than adopt a blanket, “one-size fits” all model, these research data services should be provided with a detailed and nuanced understanding of their users. In this article, the authors examine how research data practices and future research needs vary by research methodology and academic discipline based on results of a locally conducted survey. With this information, academic libraries can offer targeted services to different user populations, which would be more efficient for the libraries and more useful to the researchers.	fits;library (computing);population	Travis Weller;Amalia Monroe-Gulick	2014	Library Hi Tech	10.1108/LHT-02-2014-0021	data management;computer science;knowledge management;educational assessment;statistics	HPC	-75.36948791399692	-18.18420081606297	103411
e15c4bbc2b59424a43c2ef33017d0bc342ea8b6b	thinking about innovation		In recent months, I have been increasingly struck by a desire to step aside from the sound and fury of discussions about the benefits and risks of open access (OA) and the journal business model and ask a different question: regardless of those benefits and risks, will OA (either green or gold) become a significant force, even to the stage of becoming the dominant model for scholarly journal publishing? There is, I believe, a robust framework for doing this. Instead of analysing OA in the contained world of scientific communication, we can analyse it as an example of a much wider class: that of innovations. A major reason for looking at the innovation aspects of OA (and of many other related and unrelated issues) is that this approach allows observers and participants to look more closely at the conditions that might lead an innovation to succeed or fail, rather than focusing on the immediate arguments about whether it is a good or bad thing in itself, or what risks are entailed by either disruption or stagnation. It also gives a better indication of whether OA will succeed in establishing itself or not, and some insight into what the impact will be. There are many different models of innovation, and because of that I am not even going to attempt a definition but instead will allow some of the meanings to emerge as we go along.1 It is often the ‘creative’ aspect that people first focus on: how do ideas come to be in the first place? This is still a fascinating field of study, often capturing the excitement of the ‘eureka’ moment, or the slow working-through of a multitude of ideas until the right one comes to light. Populist business writers tend to prize the creativity-focused approach, as it gives a strong narrative that can compare with the process of artistic or scientific insight, and creates heroes and villains along the way. There are, though, many other strands to innovation. At the opposite extreme from the creative process is the hard slog of implementation – choosing a good creative idea and making it work. This is less well documented, and it can sometimes be a windswept desert for those who have to live in it, where the narrative is one of journeying (or wandering) in a landscape that seems to change faster than the figures in it can progress towards a goal. Implementation can be in itself a haphazard process, and it is here that many promising innovations come to rest; although most are buried by the sand, some are rediscovered later and fit better into a changed context The problems of implementation can give those who are threatened by an innovation a false impression of the risks to their business; they observe the innovators’ struggle and conclude that it is so much against the odds that it will never succeed and therefore represents no threat to their own model. At the human level, it may also lead them to underestimate the persistence and strength of belief of those who believe the innovation will benefit them or the community in the very long term. Implementation is often the work of groups rather than individuals, and can extend over a long period, even when things are going well. Those groups are not necessarily formally organized, and some of the significant innovations in the learned publishing sector are indeed driven by communities, rather than by learned or corporate organizations. OA itself is often described as a ‘movement’, as is Creative Commons. Neither is for the benefit of a particular organization. Compare this with something like Google’s AdWords or AdSense programmes, which are intended to strengthen competitive advantage. Self-managing groups with a strong belief in their agenda can be much more persistent than formal organizations – corporate or otherwise. Despite this difference in objectives, OA, Creative Commons and Google’s AdWords are all examples of a type of innovation often categorized as ‘disruptive’.2 This is normally contrasted with ‘sustaining’ innovations, which are often incremental rather than radical and are the type of continual improvement that companies often rely on to keep ahead of very similar competitors. Google’s AdWords shows that one innovation can fit both roles, according to context: it is incremental in terms of giving Google additional competitive advantage in search 216 Hugh Look	categorization;cost per impression;denial-of-service attack;google adsense;google adwords;persistence (computer science);scientific communication	Hugh Look	2007	Learned Publishing	10.1087/095315107X205101	computer science;public relations;innovation management	Web+IR	-74.54611738603919	-12.826929735443445	103459
14d038d48d40897047c55155c99a48e2b1fb29dc	the launching of 'social choice and welfare' and the creation of the 'society for social choice and welfare'	society for social choice and welfare;b philosophy general;social choice;social choice and welfare	LSE has developed LSE Research Online so that users may access research output of the School. Copyright © and Moral Rights for the papers on this site are retained by the individual authors and/or other copyright owners. Users may download and/or print one copy of any article(s) in LSE Research Online to facilitate their private study or for non-commercial research. You may not engage in further distribution of the material or use it for any profit-making activities or any commercial gain. You may freely distribute the URL (http://eprints.lse.ac.uk) of the LSE Research Online website.	download	Maurice Salles	2005	Social Choice and Welfare	10.1007/s00355-005-0018-6	social choice theory;social work;economics;public economics;socioeconomics;social philosophy;social welfare;social change;microeconomics;social position;social;welfare economics;social policy	ECom	-67.33989670684987	-18.206403272129243	103477
3b098418b46c86cb08f1462d18fd9fb98bbe1f00	bourgeois anarchism and authoritarian democracies	democracy	Digital communication is profoundly affecting the constitution of (civil) society by drastically lowering the costs to speak across time and space with individuals and groups of any size, and by producing abundant records of all activities conducted through these media. This is accelerating two contradictory trends. On the one hand, a new breed of social organizations based on principles of weak cooperation and peer production is sharply expanding the scope of what can be achieved by civil society. These are voluntary organizations, with flat hierarchies and trust-based principles. They are focused on producing commons-based resources rather than individual property. In general, they are transformative, not revolutionary, in character. This phenomenon is termed bourgeois anarchism. On the other hand, the liberal state - in a crisis of legitimacy and under pressure from such new organizations, both peaceful (civil society) and violent (terrorism) - is reorganizing itself around an increasingly core, expanding surveillance into the capillary system of society, overriding civil liberties and reducing democratic oversight in exchange for the promise of security. This phenomenon is termed authoritarian democracies.		Felix Stalder	2008	First Monday		economics;sociology;public administration;law;democracy	Theory	-76.04234361921571	-11.217819664610612	103614
890c59b3908e3d9b9771613e7808e11f9c276b81	end of publication? open access and a new scholarly communication technology		At this time, developers of research information systems are experimenting with new tools for research outputs usage that can expand the open access to research. These tools allow researchers to record research as annotations, nanopublications or other micro research outputs and link them by scientific relationships. If these micro outputs and relationships are shared by their creators publically, these actions can initiate direct scholarly communication between the creators and the authors of the used research outputs. Such direct communication takes place while researchers are manipulating and organizing their research results, e.g. as manuscripts. Thus, researchers come to communication before the manuscripts become traditional publications. In this paper, we discuss how this pre-publication communication can affect existing research practice. It can have important consequences for the research community like the end of publication as a communication instrument, the higher level of transparency in research, changes for the Open Access movement, academic publishers, peer-reviewing and research assessment systems. We analyze a background that exists in the economics discipline for experiments with the pre-publication communication. We propose a set of experiments with already existed and new tools, which can help with exploring “the end of publication” possible impacts on the research community.	crisis (dynamical systems);experiment;information system;just-in-time compilation;organizing (structure);relational interface system;scholarly communication	Sergey I. Parinov;Victoria Antonova	2016	CoRR		computer science;multimedia;world wide web	HPC	-71.57005389990184	-18.901848496805734	103890
c6dffb0d422c85cc268f7797fadc71a756d891cf	a strategic approach to research using internet tools and resources	metodologia;multimedia;information source;source information;information retrieval;toxicologie;toxicology;methodologie;internet;recherche information;scientific communication;evaluation;recuperacion informacion;evaluacion;new information and communication technologies;methodology;toxicologia;fuente informacion	This paper describes a method for carrying out research in a multimedia environment encompassing printed, electronic and Internet based resources. The framework was used to compile a listing of toxicology information resources, as part of a larger study on the effect of new information and communication technologies on scientific communication within this field. It is likely, however, that the approach can be applied to research in any subject.	internet	Lyn Robinson	2000	Aslib Proceedings	10.1108/EUM0000000006997	the internet;computer science;evaluation;methodology;data mining;multimedia;sociology;law;world wide web	HPC	-72.71448330317426	-23.633062439575397	103926
2385db37b2bf92172daefcea572c8fd8b3dd08e5	local and global models of physics and computation	unconventional computation;newtonian schema;complex systems;field computing;principle of least action;self modifying code	eprints@whiterose.ac.uk https://eprints.whiterose.ac.uk/ Reuse Items deposited in White Rose Research Online are protected by copyright, with all rights reserved unless indicated otherwise. They may be downloaded and/or printed for private study, or other acts as permitted by national copyright laws. The publisher or other rights holders may allow further reproduction and re-use of the full text version. This is indicated by the licence information on the White Rose Research Online record for the item.	computation;computational model;computer;imperative programming;printing	Susan Stepney	2014	Int. J. General Systems	10.1080/03081079.2014.920995	self-modifying code;complex systems;computer science;principle of least action;theoretical computer science;mathematics	AI	-65.95150511587894	-16.77240050203781	104002
41fd2436469a8447e0734974b69030bbbedfb0db	bibliometric output from colombian researchers with approved projects by colciencias between 1983 and 1994	these;analyse bibliometrique;america del sur;science and technology;document publie;dominio investigacion;amerique;periodical;base donnees colbd;south america;research field;livre;colombia;tesis;educational environment;periodique;periodico;social science;thesis;productivite auteur;human resource;libro;published document;health science;colombie;domaine recherche;colciencias;bibliometric analysis;information system;productividad autor;book;america;documento publicado;geographic distribution;author productivity;analisis bibliometrico;amerique du sud	We present a characterization of bibliometric output in Colombia resulting from research projects financed by COLCIENCIAS between 1983 and 1994 in the following programs: Health Sciences; Basic Science; Energy and Mining; Agricultural Sciences; Technological, Industrial and Quality Development; Marine Sciences; Social Sciences; Education; Environment and Habitat; Electronics, Telecommunications and Information Systems. In the case of periodicals, we establish: patterns of production by author; patterns of publication in national journals vs. international journals; the effect of international collaboration in projects over publication in international journals; patterns of bibliometric production by fields of research using UNESCO classifications; a list of the most frequently used journals by Colombian researchers as vehicles to communicate their results; patterns of bibliometric production from Colombian institutions; geographical distribution of bibliometric output; and finally, a review on the mean number of authors of articles for some fields of science and technology. We present also theses production patterns for books and B.Sc., MSc. and PhD. theses using UNESCO codes of the projects. We comment on the human resources formation. It is found as a dominant behavior of the so commented patterns a low index of publication per project and a high tendency in the distribution of publications to concentrate on few actors (researchers, institutions, origin of the publication, journals, human resources). It is also found that there exists a strong concentration of bibliometric output in the program of Basic Sciences, in fields such as phytochemistry and solid state physics (super and semiconductors).	bibliometrics;book;code;habitat;information systems;semiconductor;solid-state drive	Juan Carlos Anduckia;Julián Gómez;Yuri Jack Gómez	2000	Scientometrics	10.1023/A:1005680900632	social science;human resources;operations research;information system;science, technology and society	SE	-74.80328400185924	-22.155211140827262	104027
9f3db0e93bff5238e4ce459e2efa0162f6104ac3	health-care telematics in germany: design and application of a security analysis method		Find loads of the health care telematics in germany design and application of a security analysis method book catalogues in this site as the choice of you visiting this page. You can also join to the website book library that will show you numerous books from any types. Literature, science, politics, and many more catalogues are presented to offer you the best book to find. The book that really makes you feels satisfied. Or that's the book that will save you from your job deadline.	book;telematics	Ali Sunyaev	2011				HCI	-68.76831434442457	-13.416078985833622	104084
9a985c3e0b4863aec8e11c8c662a7c6512091061	the global spread of islamism: an agent-based computer model	international relations the global spread of islamism an agent based computer model creighton university terry d clark eichman;islamic studies;morgan leigh	We use an agent-based model to model a dynamic network that considers the rate at which Islamism will spread globally. We define Islamism as the organized political trend that seeks to solve modern political problems by referencing Muslim teachings. The trend is also associated with Radical Islam or Islamic Fundamentalism and is often revolutionary and violent in nature. The model assumes that Islamism spreads from state to state based on existing relations that replicate those defining global trade and communications. Islamism must diffuse through these existing networks. Since Islamism is inimical to western liberal values such as women’s rights and social tolerance, the diffusion of Islamism is hindered by a strong commitment to western liberal values. We include all countries in the analysis, scored on the degree to which they are committed to Islamism and western liberal values.	computer simulation;numerical weather prediction	Morgan L. Eichman;James A. Rolfsen;Mark J. Wierman;John N. Mordeson;Terry D. Clark	2014		10.1007/978-3-319-02993-1_18	environmental ethics;history;performance art	Theory	-75.65061007867607	-13.258758353168647	104179
44becb95d246e7bbdd39e14e5f2ccbd78d323d5f	developing a two-dimensional categorization system for educational tasks in informatics		Computational thinking is an increasingly important focus in computer science or informatics curricula around the world, and ways of incorporating it into the school curricula are being sought. The Bebras contest on informatics, which originated 12 years ago and now involves around 50 countries, consists of short problemsolving tasks based on topics in informatics. Bebras tasks engender the development of computational thinking skills by incorporating abstraction, algorithmic thinking, decomposition, evaluation and generalization. Bebras tasks cover a range of informatics concepts including algorithms and data structures, programming, networking, databases and social and ethical issues. Having built up a substantial number of Bebras tasks over 12 years it is important to be able to categorise them so that they can be easily accessed by the Bebras community and teachers within schools. The categorization of tasks within Bebras is important as it ensures that tasks span a wide range of topics; there have been several categorization schemes suggested to date. In this paper we present a new twodimensional categorization system that takes account of computational thinking skills as well as content knowledge. Examples are given from recent tasks that illustrate the role that Bebras can play in the development of computational thinking skills.		Valentina Dagiene;Sue Sentance;Gabriele Stupuriene	2017	Informatica, Lith. Acad. Sci.		computer science;data mining;data science;categorization;engineering informatics;informatics;computational thinking	ML	-75.06604640365683	-18.430933157844994	104199
1ebfeba4f5981359a67916645a4348d8b2263fcb	risks and rewards of crowdsourcing marketplaces	human computation;crowdfunding;crowdsourcing	Crowdsourcing has become an increasingly popular means of flexibly deploying large amounts of human computational power. The present chapter investigates the role of microtask labor marketplaces in managing human and hybrid human machine computing. Labor marketplaces offer many advantages that in combination allow human intelligence to be allocated across projects rapidly and efficiently and information to be transmitted effectively between market participants. Human computation comes with a set of challenges that are distinct from machine computation, including increased unsystematic error (e.g. mistakes) and systematic error (e.g. cognitive biases), both of which can be exacerbated when motivation is low, incentives are misaligned, and task requirements are poorly communicated. We provide specific guidance to how to ameliorate these issues through task design, workforce selection, data cleaning and aggregation. Risks and Rewards of Crowdsourcing Marketplaces The present chapter focuses on the risks and rewards of using online marketplaces to enable crowdsourced human computation. We discuss the strengths and limitations of these marketplaces, with a particular emphasis on the quality of crowdsourced data collected from Amazon Mechanical Turk. Data quality is by far the most important consideration when designing computational tasks, and it can be influenced by many factors. We emphasize Mechanical Turk because it is currently one of the most popular and accessible crowdsourcing platforms and offers low barriers of entry to researchers interested in exploring the uses of crowdsourcing. In addition to describing the strengths and limitations of this platform, we provide general considerations and specific recommendations for measuring and improving data quality that are applicable across crowdsourcing markets. Crowdsourcing is the distribution of tasks to a large group of individuals via a flexible open call, in which individuals work at their own pace until the task is completed (for a more detailed definition see Estelles-Arolas & Gonzalez-Ladron-de Guevera, 2012). Crowd membership is fluid, with low barriers to entry and no minimum commitment. Individuals with heterogeneous skills, motivation, and other resources contribute to tasks in parallel. Crowdsourcing leverages the unique knowledge of individual crowd members, the sheer volume of their collective time and abilities, or both to solve problems that are difficult to solve using computers, or smaller and more structured groups. The unique strengths of groups are generally used to solve one of two basic kinds of problems. Some problems have no obvious a priori solution, but correct answers seem obvious once known (e.g. insight problems; Dominowski & Dallob, 1995) or can be verified. In these cases, crowds can generate responses from which the “best” response can be selected according to some criteria. The volume and diversity of workers with different perspectives, strategies and knowledge can lead to quick, unorthodox, and successful solutions. The Internet has furthered this approach to problem solving by creating virtual meeting places where people can post problems for others to solve. For example, Innocentive (Allio, 2004) is a website that has helped companies find solutions to technical challenges like preventing oxygen from passing through rubber, or adding fluoride powder to toothpaste without dispersing it into the air. Often solutions to these specialized, technical problems are provided by amateurs, hobbyists, or experts in apparently unrelated fields (Larkhani, 2008). Tasks that require resources beyond those available to a single individual or work group are also well-suited to crowdsourcing. The compilation of the Oxford English Dictionary is one early example of this approach. A unique feature of this dictionary is that it includes not only definitions, but also published examples of word use. Examples were collected on slips of paper by a large body of volunteers and then aggregated by editors (Winchester, 2004). Advances in machine computation have made it easier to manage projects of this scale. For example, The Open Science Collaboration coordinates the real time collaborative efforts of scientists and citizen-scientists to systematically code, replicate and communicate social scientific findings using freely available web-software (Open Science Collaboration, 2013). A subset of this broad category are tasks that are easy for people to solve, but difficult for machines to solve. These assignments are particularly amenable to crowdsourcing. In many cases, a crowd’s responses can be automatically aggregated, eliminating the need to comprehensively review responses. The volume of workers performing each task can allow ideosyncratic perspectives, strategies and knowledge to be homogenized removed through aggregation, leaving consistent performance across a task even though each individual completed only a small portion of it. Consequently, advancing machine computation has increased the applications of crowdsourcing, with the development of human-machine hybrid systems that tackle ambitious projects such as describing the contents of images in near real time (e.g., VizWiz; Bigam et al., 2010), classifying millions galaxies (Galaxy Zoo; Lintott et al., 2008), or determining the shapes that proteins fold into (Foldit; Cooper et al., 2010). Each of these projects emerged as a result of the uneven ability of machine computation to handle the various necessary task elements. While some platforms for marshaling crowds have been developed to solve specific large problems, “crowdsourcing marketplaces” have also emerged to match workers and requesters with more modest needs. The most prominent example is Mechanical Turk (MTurk), a crowdsourcing website launched by Amazon in 2005 to assist with the maintenance of its own websites (e.g. identifying duplicate products; Potin, 2007). Corporations and individuals alike use crowds recruited from MTurk to conduct human computation operations. Twitter, for instance, relies on MTurk workers to categorize search queries to make them more meaningful to other users. Machine computing can easily identify a spike in the popularity of a query (e.g., “Big Bird” in Fall 2012), but not its semantic properties. Trending queries are passed on to MTurk workers, who can easily determine that this is a result of political events (Mitt Romney’s comments in the US Presidential Debate) rather than Sesame Street. Scientists have also been quick to harness crowd computing for academic research, relying on crowds to complete a variety of time-consuming tasks including generating corpora of stimuli for machine learning experiments (Lane, Waibel, Eck, & Rottmann, 2010; Lau, Drew, & Nichols, 2009); rating and classifying words according to meaning (e.g., Li, Liu, & Agichtein, 2008); transcribing speech (Gruenstein, McGraw & Sutherland, 2009; Marge et al., 2010); proofreading text for errors (Tetreault, Filatova & Chodorow 2010); verifying citations (Molla & Santiago-Martinez, 2011) and coding observational data (e.g. Hsieh, Kraut, & Hudson, 2010). Others are experimenting with building more complex workflows, where workers collaborate on complex multi-stage projects, or in which workers are treated as agents with a plurality of diverse responses, rather than a means of measuring the average beliefs of a population (Nickerson, Sakomoto & Yu, 2011; Yu & Nickerson, 2011) Strengths of Crowdsourcing Marketplaces Transaction Cost Effectiveness. The major advantage of marketplaces is that they make crowdsourcing accessible to requesters with limited financial and technical resources. The fixed costs of crowdsourcing (servers, record keeping, technical support, etc.) can be shared by many requesters and the technical challenges can be handled by dedicated specialists. Other less tangible efficiencies are also realized through sharing a common platform. Workers only need to be recruited into the market once, reducing marketing costs. Moreover, they only need to learn how to use a single standardized interface and can share their experiences with others, making it easier for them to find, understand, and successfully complete work (Ipeirotis & Horton, 2011). Crowd Accessibility. Crowds require a certain critical mass to function. Potential workers are unlikely to invest time visiting websites unless they have a reasonable chance of finding work (a special case of a two-sided market, see Rochet & Triole, 2003). Some crowdsourcing projects, like digitizing every book in the world, or identifying all the stars in the sky, are large enough to warrant their own dedicated framework (e.g., reCaptcha; von Ahn et al., 2008). However, the majority of human computation problems are quick to complete, intermittent, or frequently change in content or required knowledge. A common market ensures a steady enough supply of tasks to help maintain a persistent crowd, even while individual requesters recruit and dismiss workers on demand. MTurk was able to achieve this scale initially by serving as a labor market for Amazon’s own in-house human computation needs. Efficient Matching and Task Completion. Microtask sites pay workers according to the tasks they complete, rather than an hourly wage. Piece rates ensure that workers are paid according to their productivity, and even assuming minimal variation in worker ability and task demands, workers should be able to sort themselves into assignments they do best (Becker & Murphy, 1992). Piece rates also benefit requesters. Since each worker proceeds at their own pace, receiving new work only when old work is completed, the completion time for a project will be driven by the average pace at which tasks are completed, as opposed to traditional methods of dividing labor that are often constrained by the pace of the slowest worker (Davis, 1965). Low Market Prices. Aside from a minimal payment to the web service (MT	crowdsourcing;human-based computation;plasma cleaning;requirement	Jesse Chandler;Gabriele Paolacci;Pam Mueller	2013		10.1007/978-1-4614-8806-4_30	simulation;engineering;knowledge management;data mining	HCI	-65.39368069699816	-23.23348486477009	104229
a7a60e678abaf9471bb5bde586aa153bcbc997c0	rethinking universal service: citizenship, consumption norms and the telephone	droit civique;consumption;justification;policy;normalisation;accesibilidad;citizenship rights consumption norms information access universal service;telephone;consumo;service masse;universal service;telecomunicacion;accessibility;consommation;telecommunication;servicio masa;normalizacion;justificacion;bulk service;telefono;politica;politique;standardization;accessibilite	"""One of the reasons the proponents of expanded universal service have not made much headway is that they have not been able to provide a coherent justification for the major resource and policy commitments it requires. The lack of consensus on the very meaning of the term """"universal service"""" has added to the confusion. This article argues that it is critically important to articulate a clear justification for universal service before we discuss what it should include and how it should be funded, the two main preoccupations of the current debate. It answers the """"why"""" question by drawing on the literature on consumption norms and citizenship rights and thereby provides a cogent justification for universal service. A clear articulation of the rationale for universal service should reduce some of the confusion in the current debate and bring greater clarity to the ongoing debate on this important public policy issue."""		Paschal Preston;Roderick Flynn	2000	Inf. Soc.	10.1080/01972240050032843	public relations;economics;consumption;telecommunications;computer science;accessibility;sociology;management;law;standardization	DB	-76.26402126385844	-12.475208791413976	104280
5a14949bcc06c0ae9eecd29b381ffce22e1e75b2	organizational learning and management information systems	organizational learning;management information system	T he articles in this issue ofDATA BASE were chosen b y Anthony G . Hopwood, who is a professor of accounting and financial reporting at the London Graduate Schoo l of Business Studies . The articles contain important ideas , Professor Hopwood wrote, of significance to all intereste d in information systems, be they practitioners or academics . The authors, with their professional affiliations at th e time, were Chris Argyris, Graduate School of Education , Harvard University; Bo Hedberg and Sten Jonsson, Department of Business Administration, University o f Gothenburg; J . Frisco den Hertog, N . V. Philips' Gloeilampenfabrieken, The Netherlands, and Michael J . Earl, Oxford Centre for Management Studies . The articles appeared originally in Accounting, Organizations and Society, a publication of which Professor Hopwood is editor-in-chief. AOS exists to monitor emergin g developments and to actively encourage new approaches and perspectives .	call of duty: black ops;information systems;management information system	Chris Argyris	1982	DATA BASE	10.1145/1017692.1017693	organizational network analysis;executive information system;organizational safety;organizational engineering;participatory management;organizational performance;organizational learning;organizational behavior and human resources;opm3;computer science;knowledge management;theory x and theory y;process management;information management;organizational space;organization development;information system;organizational behavior management	DB	-63.155304168659434	-15.176520519773009	104546
a377be9c0ae48a6233c5147a496394fb13c104ce	state of the journal		OVER the past four years the editorial board of TSE has worked to identify and address challenges and opportunities in the publication of research contributions in the field of software engineering. As we have reported in prior editorials, TSE has made consistent and substantial progress in reducing the time to review submitted manuscripts and has helped to create the successful, and growing, “journal first” publication model in software engineering. These efforts have been the product of thousands of hours of volunteer effort on the part of the dedicated editorial board and reviewer community who support TSE. Space does not allow for thanking each of them in person, but we would like to express our thanks to John Grundy and Jane Cleland-Huang who served as Associate Editor-in-Chiefs for TSE over the past four years. They have been invaluable contributors in advancing TSE. In all of our work, we have maintained the perspective that TSE serves the software engineering community. We have worked with partners at other journals, in the professional organizations, and in conference organizing committees to develop approaches that work well for the large, and complex, software engineering publication ecosystem. The steps we have made put the community in a position to move forward to create a more diverse and inclusive system for disseminating world-class research results and we hope that the entire community will work to advance our collective interests with a similar sense of service. Next up as TSE Editor-in-Chief is Professor NenadMedvidovi c. Neno’s record as a tireless contributor to the community over the past decade serving as Program co-Chair of ICSE, Steering Committee Chair of ICSE, Chair of the ACM Special Interest Group on Software Engineering (SIGSOFT), and on the editorial boards of TSE and ACM TOSEM demonstrates his deep commitment to serving the software engineering community. His experience working with the two most prominent professional organizations that sponsor conferences and journals in software engineering puts him in a unique position to address changes to publication processes and practices that our field is experiencing. Professor Medvidovi c is a world-class scholar and has been a pioneer in advancing research on architecture-based solutions to software development challenges. His experience as an accomplished and widely published author will inform his leadership of TSE and drive it to be an increasingly valuable resource for the software engineering community.	ecosystem;icse;jane (software);organizing (structure);software development;software engineering	Matthew B. Dwyer	2018	IEEE Trans. Software Eng.	10.1109/TSE.2017.2778898		SE	-63.1240517238865	-17.574321284735365	104577
8e6127bcd2cb31993c2f2ec9c5f8799c39b0c67f	flaubert, foucault, and the bibliotheque fantastique: toward a postmodern epistemology for library science,			library science	Gary P. Radford	1998	Library Trends			Logic	-62.852631646043015	-11.553506700019609	104632
b38b71b7bcd4a73c1441cd2060ebcb968ff5f0c1	brazilian scientific production in areas of biological sciences: a comparative study on the modalities of full doctorate in brazil or abroad	brazilian scientific production;brazilian doctorate brazil abroad	Know and compare the Brazilian scientific production of researchers that did full PhD in Brazil or abroad may be important to evaluate the development of science in the country. In this context, the current study was planned to verify the evolution of scientific production of researchers that concluded PhD in Brazil or abroad between 1997 and 2002. The evaluation included specifically the scientific production of PhDs in the areas of biochemistry, physiology and pharmacology during the period of 9 years after the PhD conclusion. The data were obtained from the database of CAPES (Foundation for Higher Education Development in Brazil), CNPq (National Council of Technological and Scientific Development), Lattes, Web of Science (Institute for Scientific Information (ISI) and Scival—Scopus). In terms of quantity, researchers that did full PhD in Brazil published more articles than the researchers that did it abroad. However, articles from researchers that did the PhD in Brazil were published in journals with lower impact factor and received less citation than the articles published by researchers that did PhD abroad. The results indicate that the qualitative performance of researchers that did PhD abroad was better than those who did PhD in Brazil. Consequently, the policies of Brazilian government need to be devoted to enhance the relevance of Brazilian articles in terms of scientific quality and international insertion.	relevance;scopus;web of science	Daniel Henrique Roos;Luciana Calabró;Sandra Lopes de Jesus;Diogo Onofre Souza;Nilda Vargas Barbosa;João Batista Teixeira da Rocha	2013	Scientometrics	10.1007/s11192-013-1017-5	computer science;media studies;pedagogy	HPC	-77.01440803945644	-23.356014286368257	104651
e0e1cbed15746b5ce00cb2e77ce1dfa66b103c36	the role of effects, saliencies and norms in us cyberwar doctrine		The US approach to cybersecurity implicitly rests on an effects-based logic. That is, it presumes that the key question determining how the US and others will respond to attacks is what effects they have. Whether the effects come about as a result of cyber means or kinetic means is largely irrelevant. In this article, we explore this logic further, focusing on the question of when the US should deploy cyber responses and when kinetic. We find that under a simple effects-based logic, kinetic responses will often be more effective than cyber responses, although we explain that cyber attacks that ’leave something to chance’ may be an effective deterrent under some circumstances. We next develop a richer understandings of actors’ expectations by employing the concepts of focal points and saliencies. In this framework, kinetic responses may be considered too escalatory, and therefore less attractive under many circumstances. If there are ’focal points’ emerging, under which cyber attacks are seen as qualitatively distinct from kinetic attacks, then crossing a saliency may appear escalatory, even if the actual effects of the kinetic and cyber attackes are identifical. Finally, we examine nascent norms around cyber, suggesting that the US may wish to consider promoting a norm against large scale attacks on civilian infrastructure, and evaluating the prospects for a norm against cyber attacks on nuclear command and control systems.	coat of arms;computer security;control system;critical infrastructure protection;cyberwar;focal (programming language);relevance;sagan;threat (computer);eric	Henry Farrell;Charles L. Glaser	2017	J. Cybersecurity	10.1093/cybsec/tyw015		Security	-73.04233693049925	-10.73969740199145	104746
6dbe605f7b3eae92a916da228020ebfd28237bd3	why won't the president enforce the constitution?	freedom;information technology;constitution;libertad;technologie information;controle;systeme conversationnel;liberte;interactive system;obscene indecent;sistema conversacional;control;tecnologia informacion;clinton;communication;comunicacion;check	"""I am not amused. Perhaps that is because I have been practicing law for too many years. It is my understanding that a law is a rule of the land and cannot be put aside at the wish or whim of a single person, or due to the policy of a single branch of our government. Last February, as President Clinton signed the Telecommunications Act of 1996, his own attorney general expressed the opinion that certain portions of the bill—the Comstock censorship provisions— were unconstitutional. Not to fear, however, for the president had decided that his Justice Department would not enforce these offending provisions. The Comstock amendments are not the only portions of the Act that censor the Internet. Other sections (also known as the Communications Decency Act) provide criminal penalties for transmitting 1) """" indecent """" or 2) """" patently offensive """" materials. Both may be unconstitutional. The attorney general has entered into a stipulation that her Justice Department shall not enforce either of these questionable provisions, pending judicial review of the Act. What is the legal significance for service providers and users of the net of this decision and this stipula-tion? Extremely troubling, both as a point of practi-cality and as level-headed common sense for those individuals who view our constitution as imposing duties on officials who serve our government. It is not wise to speak in a vacuum. For this reason, I digress a moment to examine parts of the Act. After the Civil War, the Comstock Act was passed for the purpose of bringing civility to a wild west growing ever more populated. Among the Act's multiple prohibitions is the transportation of any printed information discussing how to procure or induce an abortion. The Telcom Act amends this ancient and aging law to include dissemination of such information through an """" interactive computer service. """" The Telcom Act then adds two additional prohibitions by amending the Telecommunications Act of 1934. First, these amendments criminalize use of a telecommunications facility to transmit material that is """" obscene or indecent, """" with the intent to harass another person. Second, they prohibit use of an interactive computer service to transmit """" patently offensive """" material (of a sexual or scatological nature) to individuals under 18 years of age, or use of a telecommunications facility under one's control to transmit such material. The usual caveat, of determining whether something is …"""	censoring (statistics);population;printing;procurement;self-censorship;transmitter	Andrew Grosso	1996	Commun. ACM	10.1145/233977.233982	check;telecommunications;liberty;law;information technology;inherent powers;scientific control		-68.99540841389295	-18.442753683881545	104802
de02594cfa7ffca6b6cb471b4fb5b1c4ec61d25b	q&a: how has the university of phoenix managed to attract so many students?				Lisa Gualtieri	2002	eLearn Magazine	10.1145/566786.566787	simulation	ML	-63.91165571654664	-12.411658989117837	104814
184b4e3ffd896c05ed857bf6910377d4621860ae	the harmonious chromatic number of almost all trees	chromatic number	General rights Copyright and moral rights for the publications made accessible in Discovery Research Portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights. • Users may download and print one copy of any publication from Discovery Research Portal for the purpose of private study or research. • You may not further distribute the material or use it for any profit-making activity or commercial gain. • You may freely distribute the URL identifying the publication in the public portal. Take down policy If you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately and investigate your claim. A harmonious colouring of a simple graph G is a proper vertex colouring such that each pair of colours appears together on at most one edge. The harmonious chromatic number h(G) is the least number of colours in such a colouring. For any positive integer m, let Q(m) be the least positive integer k such that (*) S: m. We show that for almost all unlabelled, unrooted trees T, h(T) = Q(m), where m is the number of edges of T.	color;download;graph (discrete mathematics);graph coloring;requirement	Keith Edwards	1995	Combinatorics, Probability & Computing	10.1017/S0963548300001462	mathematics	Theory	-66.45424314754598	-18.562635090688197	104866
b0a5206e3d771a0bf89cf37bdbd78da7b63cf71d	emerging international data communications services		EXECUTIVE SUMMARY Results of a survey recently conducted by Statistics Canada suggest that many National Statistical Offices (NSOs) are in different stages of progress in migrating from a paper-based publishing regime to a web-based publishing regime, and the common theme and challenges faced by them today are to make the World Wide Web an effective medium for the on-line communication of statistics. Like many other NSOs, the Australian Bureau of Statistics (ABS) is positioning itself to use the internet as the principal channel for data communication. There are a number of strategies in place to fulfil the ABS goal of web publishing. These are: improving communication of statistics to facilitate user discovery of a. information and assessment of its fitness-for-purpose; broadcasting and proactive dissemination of information such as through b. Real Simple Syndication and email notification; improving self help; and c. writing once/publishing many times to improve the efficiency and d. consistency of released information. In this paper, the strategies and techniques used by the ABS to improve statistical communication are discussed.	email;internet;online and offline;the australian;web application;web syndication;world wide web	E. Brod	1976			control communications;long-haul communications;computer network;communications management;services computing;business	ML	-68.89804064998854	-16.971651381624277	104953
ddfb61a39c25260f4c0e8fa3448a0c44d59f4aee	a legal structure for a national medical data center	medical records;data center;social benefit	Increasingly, medical professionals are concluding that a computerized national center to contain medical records of all persons has significant medical advantages. Moreover, such a project seems to be becoming technically feasible. However, uncertainty about the adequacy of physical and legal protections of the privacy of the stored data (and the related compatibility of the system with the Fifth Amendment bar to involuntary self-incrimination) appears to be the major stumbling block at this time. Study of that aspect reveals that it is possible to achieve a level of privacy and an observance of Constitutional requirements that are entirely satisfactory on an absolute basis and especially in light of both the great social benefits in store and the degree of protection customary for the particular information involved. This article provides a blueprint of the types of legal inhibitions that should be sufficient for the purpose in view of technical measures available.	american federation of information processing societies;antivirus software;blueprint;code;data center;peterson's algorithm;privacy;relevance;requirement;stumbleupon;usb on-the-go;wafer (electronics)	Roy N. Freed	1968		10.1145/1476589.1476643	actuarial science;engineering;data mining;computer security	Security	-72.31300897695424	-12.798246456318687	104956
57ed08546625c75c449b8389ecf87049e247ff9b	the vitality of new media and religion: communicative perspectives, practices, and changing authority in spiritual organization	convergence;religion;digital media;spiritual organizing;authority;communication;globalization	We are witnessing the growth of a distinct sub-field focusing on new media and religion as the relationship between the two is not just important, it is vital. I discuss in this article how this vitality is both figurative and literal in multiple dimensions. Mediated communication brings forth and constitutes the (re)production of spiritual realities and collectivities, as well as co-enacts religious authority. In this way, new mediations grounded within older communication practices serve as the lifeblood for the evolving nature of religious authority and forms of spiritual organizing. Further research to identify diverse online and embodied religious communication practices will illuminate a richer understanding of digital religion, especially as a globally distributed phenomenon.	new media	Pauline Hope Cheong	2017	New Media & Society	10.1177/1461444816649913	psychology;authority;social science;convergence;digital media;globalization;sociology;religion;social psychology;law	HCI	-76.80038653363285	-13.62449900042794	105036
a92ba6648d9549c03f44312027c054504714a751	new cd-roms in brief		Emerald is a global publisher linking research and practice to the benefit of society. The company manages a portfolio of more than 290 journals and over 2,350 books and book series volumes, as well as providing an extensive range of online products and additional customer resources and services. Emerald is both COUNTER 4 and TRANSFER compliant. The organization is a partner of the Committee on Publication Ethics (COPE) and also works with Portico and the LOCKSS initiative for digital archive preservation.	archive;book;cd-rom;case preservation;emerald;lockss	Euro CD-Book	1998	Online Information Review	10.1108/eb024676		HCI	-67.73469370366313	-17.932184364176088	105046
b2288996988a2e2b11ea04586714d86d89794bbd	toward discovery support systems: a replication, re-examination, and extension of swanson's work on literature-based discovery of a connection between raynaud's and fish oil	information retrieval;statistical distributions;logic;comparative analysis	Don R. Swanson has undertaken a program of research to use the published medical literature as a source of discoveries. We have attempted to replicate his discovery of a connection between Raynaudu0027s disease and dietary fish oil, as well as develop computer-based searching methods that could usefully support literature-based discoveries. We have been successful in replicating Swansonu0027s discovery and have developed a method of discovery support based on the complete text of MEDLINE records. From these, we compute statistics based both on the frequency of tokens within a literature and on the number of records containing various tokens. We discuss the use of these statistics, suggesting that token and record frequencies are good indicators of literatures profitably related to some source literature, and that relative record frequencies are useful in isolating literatures with the potential of containing a discovery. © 1996 John Wiley u0026 Sons, Inc.		Michael D. Gordon;Robert K. Lindsay	1996	JASIS	10.1002/(SICI)1097-4571(199602)47:2%3C116::AID-ASI3%3E3.0.CO;2-1	document retrieval;bibliometrics;computer science;relation;artificial intelligence;operations research;logic;information retrieval;process	HCI	-77.21853469365587	-22.5584404696076	105085
54ab278e41b90acbbf991e530679bb888027953f	information history: its importance, relevance and future	ciencia informacion;history;information science;curricula;informing science;historiographie;library studies;historia;theorie information;science information;article;histoire;information theory;design methodology;teoria informacion	Purpose – The purpose of this paper is to explore the emergent field of information history (IH) and to move towards a definition of IH. Some of the more traditional historical approaches to information science are challenged in their claims to be information history. Design/methodology/approach – The historiography of the field is discussed, and an analysis of the continuing development of IH is explored. Findings – IH is a field that has been attracting increasing attention in recent years from historians and information scientists alike. Although still a relatively young area, this paper argues that IH has the potential to develop into a highly relevant and dynamic field of research. The paper concludes with a look at the future for this area of research, with some suggestions as to how IH needs to develop in order to gain the credence and recognition it deserves. Originality/value – This paper attempts to augment the debate on IH and to encourage a broader recognition of this young and dynamic field within LIS.	emergence;information history;information science;information scientist;lis;relevance	Toni Weller	2007	Aslib Proceedings	10.1108/00012530710817627	social science;design methods;information theory;information science;computer science;sociology;management;statistics	HCI	-73.86857714529361	-18.651178468809373	105217
bd1b37e429501831a405984638d69cec9cd24570	knowledge sharing for cultural heritage 2.0: prosumers in a digital agora		The word â€œprosumerâ€ indicates the mixture of the terms â€œproducerâ€ and â€œconsumerâ€ : even if the term is almost recent, prosumers were already present in the historical period of ancient Greece and Magna GrA¦cia (between the VII century b.C. and the I century A.D.). In this view, the platform Cultural Heritage 2.0 can be considered a digital â€œagoraâ€ : like the Greek square-marketplace, where there was exchange of goods and ideas, the system allows the gathering of an extensive amount of digital data and an interesting exchange of culture. The aim of this paper is to present Cultural Heritage 2.0, that offers the opportunity to mix heterogeneous contents in unusual amalgams, according to the imagination and design of the users-prosumers in the Web community.	agora	Francesca Bertacchini;Assunta Tavernise	2014	IJVCSN	10.4018/ijvcsn.2014040102	social science;archaeology;sociology;cultural heritage management;management;world wide web	HCI	-70.25993910878594	-19.55512000689239	105296
fff0608d1a1333c61a4f46d0c23d7f854c52c8d7	a welcome dialogue concerning the need for research on the effectiveness of summer library reading programs: a response to ray lyons's critique	experimental design;impact assessment;treatment effect;treatment effects;internal validity;effectiveness evaluation;summer reading programs;quasi experimental design	In his article, “Overstating Summer Reading Impact: The Dominican Study,” which appeared in PLQ 30, no. 1 (2011), library consultant Ray Lyons, who is the codeveloper and coauthor with Keith Curry Lance of LJ’s Star Rating system, published a critique of the study authored by Susan Roman, Deborah Carran, and Carole Fiore. PLQ editors provided an opportunity for the three scholars involved in the Dominican University-LIS study to reply to the article. This communication is that reply.	curry;lennard-jones potential;star (classification)	Susan Roman;Deborah T. Carran;Carole D. Fiore	2011	Public Library Quarterly	10.1080/01616846.2011.578055	psychology;internal validity;social science;economics;philosophy;epistemology;computer science;engineering;impact assessment;sociology;average treatment effect;quasi-experiment;design of experiments;management;statistics	NLP	-65.30396023455054	-13.602445127681477	105510
74decb09ccee8f81ab3e868ba4f124639f64bf3a	researching wikipedia - current approaches and new directions		Wikipedia (<http://www.wikipedia.org >), an international, multi-lingual and collaboratively produced free online encyclopedia, has experienced massive growth since its inception in 2001. The site has become the world’s single largest encyclopedia as well as one of the world’s most diverse online communities. Because of these factors, the site provides a unique view into the processes of collaborative work and the factors that go into producing encyclopedic content. To date, there has been no unified review of the current research that is taking place on and about Wikipedia, and indeed there have been few formal studies of the site, despite its growing importance. This project is a review of social science and information science studies of the site, focusing on research methods and categorizing the areas of the site that have been studied so far. Studies of Wikipedia have focused primarily on the social dynamics of contributors (such as how disputes are resolved and why contributors participate), and the content of Wikipedia (such as whether it is an accurate source), but due to the unique collaborative processes on Wikipedia these two areas are deeply intertwined.	categorization;information science;online community;social dynamics;wikipedia	Phoebe Ayers	2006		10.1002/meet.14504301252	social science;computer science;data science;sociology;world wide web;information retrieval	HCI	-77.01352068330229	-17.725158718619525	105515
08481d388cdff33531b21354120fdae7e52e3597	the story behind oncotarget? a bibliometric analysis	oncotarget;network;bibliometry;architecture;structure	Being the most proliferative journal of oncology a cancer research of the past decade, the Open Access journal Oncotarget had reached more than 20,000 publications and a relatively high impact factor score in the past years. In 2018, the journal citation report decided to withdraw the status of an impact factor journal. Since there was a large discussion in the scientific community and specific reasons for the withdrawal were not stated, this bibliometric analysis was performed to assess if Oncotarget exhibits any differences in its bibliometric structure compared to other journals. For this purpose, we used the “New Quality and Quantity Indices in Sciences” platform and analyzed 20,000 Oncotarget articles. Density equalizing mapping technique helps to construct maps of cancer research in Oncotarget and shows that it has led to a unique global landscape which is not asymmetrically dominated by the Western hemisphere but exhibits a publishing architecture with a pronounced emphasis on Chinese articles.	bibliometrics;exhibits as topic;journal citation reports;neoplasms	David Alexander Groneberg;Axel Fischer;Doris Klingelhöfer;Michael H. K. Bendels;David Quarcoo;Dörthe Brüggmann	2018	Scientometrics	10.1007/s11192-018-2949-6	data mining;library science;citation;architecture;open access journal;publishing;impact factor;computer science	Comp.	-76.32101499823081	-20.39959981147906	105608
6d1d94e6436055ca6c75ee48076cf1692b721f16	collaboration patterns and patenting in nanotechnology: exploring gender distinctions	collaboration;networks;nanotechnology			Yu Meng	2013			social science;socioeconomics;political science	HCI	-65.46534769172263	-10.214045028790503	106059
c85d9916fd5d8b525b1cec3bb2c3d64e4ff320b8	the internationalization of chinese scientific journals: a quantitative comparison of three chemical journals from china, england and japan	web of science;chemical communication;information exchange;distribution pattern;geographic distribution	Scientific journals play an important role in international academic information exchange. Their international performance can be evaluated through the comparison of the geographical distribution patterns of authors, citations and subscriptions. In this study we analyzed 3 journals, i.e., Chinese Chemical Letters (China), Chemical Communications (England) and Chemistry Letters (Japan), for their regional distribution patterns of the editorial board members, the authors database, and the citation regions, using the bibliometric method, on the basis of the Web of Science. The results show that, compared with international journals, the Chinese Chemical Letters lags behind in all aspects.	bibliometrics;information exchange;web of science;world wide web	Tianwei He;Wei Liu	2008	Scientometrics	10.1007/s11192-008-2067-y	information exchange;operations research;statistics	HPC	-75.85947084232926	-21.176119943579533	106224
a636a6946d52163fa25a3f6001dac689495aa201	security for ubiquitous computing	distributed system;system design;security and privacy;world wide web;ubiquitous computing	Ubiquitous computing, over a decade in the making, has finally graduated from whacky buzzword through fashionable research topic to something that is definitely and inevitably happening. This will mean revolutionary changes in the way computing affects our society: changes of the same magnitude and scope as those brought about by the World Wide Web. When throw-away computing capabilities are embedded in shoes, drink cans and postage stamps, security and privacy take on entirely new meanings. Programmers, engineers and system designers will have to learn to think in new ways. Ubiquitous computing is not just a wireless version of the Internet with a thousand times more computers, and it would be a naive mistake to imagine that the traditional security solutions for distributed systems will scale to the new scenario. Authentication, authorization, and even concepts as fundamental as ownership require thorough rethinking. At a higher level still, even goals and policies must be revised. One question we should keep asking is simply “Security for whom?” The owner of a device, for example, is no longer necessarily the party whose interests the device will attempt to safeguard. Ubiquitous computing is happening and will affect everyone. By itself it will never be “secure” (whatever this means) if not for the dedicated efforts of people like us who actually do the work. We are the ones who can make the difference. So, before focusing on the implementation details, let’s have a serious look at the big picture. C. Park and S. Chee (Eds.): ICISC 2004, LNCS 3506, p. 2, 2005. c © Springer-Verlag Berlin Heidelberg 2005	authentication;authorization;distributed computing;embedded system;internet;lecture notes in computer science;programmer;shoes;springer (tank);ubiquitous computing;world wide web	Frank Stajano	2002		10.1007/11496618_2	cloud computing security;computer science;internet privacy;world wide web;computer security;ubiquitous computing;systems design	HCI	-63.11059571085795	-23.895446915328726	106285
36900e9106600aa1687d6a4e6d50c86b3b5f1af0	embracing cybernetics: living legacy of the bateson research team			cybernetics	W. A. Ray;M. Simms	2016	Cybernetics and Human Knowing		cognitive science;cybernetics;social science;second-order cybernetics;sociology	Robotics	-64.73235661453344	-11.121583212530648	106299
c125a9c93e9ab89699bcb3a02e602d241c68ec56	types of open access publishers in scopus	funding model;discipline;scopus;open access;publisher	This study assessed characteristics of publishers who published 2010 open access (OA) journals indexed in Scopus. Publishers were categorized into six types; professional, society, university, scholar/researcher, government, and other organizations. Type of publisher was broken down by number of journals/articles published in 2010, funding model, location, discipline and whether the journal was born or converted to OA. Universities and societies accounted for 50% of the journals and 43% of the articles published. Professional publisher accounted for a third of the journals and 42% of the articles. With the exception of professional and scholar/researcher publishers, most journals were originally subscription journals that made at least their digital version freely available. Arts, humanities and social science journals are largely published by societies and universities outside the major publishing countries. Professional OA publishing is most common in biomedicine, mathematics, the sciences and engineering. Approximately a quarter of the journals are hosted on national/international platforms, in Latin America, Eastern Europe and Asia largely published by universities and societies without the need for publishing fees. This type of collaboration between governments, universities and/or societies may be an effective means of expanding open access publications.	categorization;scopus	David Solomon	2013	Publications	10.3390/publications1010016	library science;alternative medicine;medicine;media studies	ML	-72.07512541651137	-20.58011133049857	106390
03e1cce0d42b8e46974218f6fac1b34041109697	evaluating a european knowledge hub on climate change in agriculture: are we building a better connected community?	collaborative funding initiatives;eu research policy;climate change;co authorship networks;agriculture;interdisciplinary collaboration;knowledge hub	In order to maintain food security and sustainability of production under climate change, interdisciplinary and international collaboration in research is essential. In the EU, knowledge hubs are important funding instruments for the development of an interconnected European Research Area. Here, network analysis was used to assess whether the pilot knowledge hub MACSUR has affected interdisciplinary collaboration, using co-authorship of peer reviewed articles as a measure of collaboration. The broad community of all authors identified as active in the field of agriculture and climate change was increasingly well connected over the period studied. Between knowledge hub members, changes in network parameters suggest an increase in collaborative interaction beyond that expected due to network growth, and greater than that found in the broader community. Given that interdisciplinary networks often take several years to have an impact on research outputs, these changes within the relatively new MACSUR community provide evidence that the knowledge hub structure has been effective in stimulating collaboration. However, analysis showed that knowledge hub partners were initially well-connected, suggesting that the initiative may have gathered together researchers with particular resources or inclinations towards collaborative working. Long term, consistent funding and ongoing reflection to improve networking structures may be necessary to sustain the early positive signs from MACSUR, to extend its success to a wider community of researchers, or to repeat it in less connected fields of science. Tackling complex challenges such as climate change will require research structures that can effectively support and utilise the diversity of talents beyond the already well-connected core of scientists at major research institutes. But network research shows that this core, well-connected group are vital brokers in achieving wider integration.	academia (organization);agriculture;climate change;european union;instrument - device;peer review;social network analysis;stimulation (motivation);usb hub;interdisciplinary collaboration	Eli Rudinow Saetnan;Richard Philip Kipling	2016		10.1007/s11192-016-2064-5	agriculture;environmental resource management;socioeconomics;data mining;management science;climate change;world wide web;economic growth	AI	-76.85018745402598	-15.727553511635955	106541
72ac9b2935754ec1e2f24671bfe3a2ee3cf06034	breaking the barriers of resistance to electronic journal entry: experiences of bitoday	electronic journal;array	"""There are a number of socio-econoniicissues that are generally understood in the area of electronic publishing. Primary among these is an apparent reluctance within the academic community to accept a replacement to paper-based journals. This sits incongruously with the fact that the WWW was born at CERN primarily as a vehicle for the effective dissemination of scientific research papers. This paper focuses on research, problems and issues encountered at South Bank University in attempting to establish aBusiness Information Technology (BIT) Journal on the Internet (BlToday). It is hoped that this undertaking, which requires challenging the current academic culture on research and publication, would meet the requirements of academic staff and publicise the current and innovative academic area of BIT outside of the University. However, there are different levels of acceptance and understanding about communicating by electronic publication. This paper will thus review and highlight the main problems andissues that have been encountered in this effort to establish an electronic journal in a relatively new academic discipline. The culture of electronic publishing is opposed by a number of 'forces of resistance' (asthey may be termed in the electronic publishing environment). These forces of resistance act like barriers to entry in the electronic journal field. This paper will suggest from experience the nature and origin of these resistant forces. Two obvious resistant forces being the establishment of standardisation on publication and the difficulties on enforcing copyright upon electronic journals. However, these issues are only policy constraints and pale in significance next to the issues of initial cultural establishment of an electronic journal, which manifests itself in the form of an academic culture gap. The socio- economic forces of change in the academic world, such as diminishing budget allocation for paper based journals held in academic libraries, strongly suggests that electronic journals will become the standard and not the exception in the future. Those institutionsthat, early in this evolution, break the barriers of entry to the electronic journal field, stand to benefit in terms of establishing standards and an academic presence. Academic Institutions are still in a period of experimentation. Most people are still trying to get to grips with the basics of the \VWW and the evolutionary nature of electronic publishing mediums which offer the prospect of hyperlinks, to point to additional reference material within other academic domains, or even other electronicjournals (at no additional cost). This paper, firstly, addresses the issues that surround """"barriers to entry"""" in the electronic journals field. Secondly, the paper outlines the forces of resistance to an acceptance of electronic journal mediums and the nature and reason of such resistance. Thirdly, the paper will suggest possible solutions, and areas of further work, needed to overcome the primary forces of resistance."""		Geoffrey Elliott;Simon Polovina;Grahame Rourke;Terry Tyrell	1997			array data structure;computer science;advertising;programming language;operations research;world wide web	HCI	-67.56707182398631	-19.938196006908385	106556
a26a076bae1011cf2e919043952afc213e0fdaa9	cloud service for university e-government	computers;cyberspace;measurement;monitoring;planets;cloud computing	Cyber culture of the smart university creates the social significance of technological leadership. Internet and cyberspace change all the processes of life of each person. It is necessary to create a new market-oriented model of scientific and educational processes within the Smart Cyber University (SCU). The concept integrates the achievements of classical universities, technological cyber culture, and human desire for perfection through continuous education throughout their lives. The basis of the SCU is the structural organization of cyber physical system, focused on cloud management of the scientific and educational processes through its precise digital monitoring. The structure of the classical university includes the following components, which have to be digitized: science, education, human resources, infrastructure, relationships, management, roadmap, resources, and products. Legitimate relations are the main part of the SCU, which are based on the metric for measuring the quality of all the processes and phenomena. This makes it possible to completely eliminate corruption in the processes of resource distribution and personnel management through the metric evaluation of the activities of university departments and employees. SCU cloud services are focused on developing countries in order to help the progressive university leaders to eliminate the corruption, implement paperless technology for monitoring and management of scientific and educational processes, significantly reduce the time costs for organizing educational and scientific processes through online-cooperation. Cloud mobile management of SCU based on the metric measurement of all processes allows attracting foreign investment in scientific research, improve the quality of educational services and scientific results, the performance of the creative work of scientists and their standard of living.	cloud management;cyberspace;e-government;internet;organizing (structure);paperless office;single compilation unit	Oleksandr Mishchenko;Vugar Abdullayev;Eugenia Litvinova;Vladimir Hahanov;Svetlana Chumachenko;Anastasya Hahanova	2016	2016 IEEE East-West Design & Test Symposium (EWDTS)	10.1109/EWDTS.2016.7807660	simulation;engineering;knowledge management;management science	SE	-70.58024898220029	-16.145170560289852	107067
a728d9f256dd92f0fe84968d28f8759b2ec6dda5	teaching programming the way it works outside the classroom	teaching programming;cacm community;dozen bloggers;opportunistic programming;communications web site;blog-cacmphilip guo	The <i>Communications</i> Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of <i>Communications</i>, we'll publish selected posts or excerpts.<br /><br /><b>twitter</b><br /><b>Follow us on Twitter at http://twitter.com/blogCACM</b><br /><br /><b>http://cacm.acm.org/blogs/blog-cacm</b><br /><br />Philip Guo offers programmers 'Opportunistic Programming' tips that typically are not shared in school.	blog;programmer	Philip J. Guo	2013	Commun. ACM	10.1145/2492007.2492012	computer science;multimedia;internet privacy;world wide web	HCI	-64.90319292779505	-16.44709680687432	107229
5ead28648ca4232c8977bf52bdd5904af1032f98	visible, less visible, and invisible work: patterns of collaboration in 20th century chemistry	analisis coautor;document publie;analisis estadistico;estudio comparativo;coauthorship analysis;siecle 20eme;psychology;century 20th;acknowledgment;cooperacion cientifica;etude comparative;chimie;remerciement;statistical analysis;cooperation scientifique;analyse statistique;published document;chemistry;comparative study;philosophy;quimica;scientific cooperation;psychologie;analyse coauteur;recherche scientifique;filosofia;scientific research;philosophie;documento publicado;siglo 20;psicologia;investigacion cientifica	We chronicle the use of acknowledgments in 20th century chemistry by analyzing and classifying over 2,000 specimens covering a 100-year period. Our results show that acknowledgment has gradually established itself as a constitutive element of academic writing--one that provides a revealing insight into the structural nature of subauthorship collaboration in science. Complementary data on rates of coauthorship are also presented to highlight the growing importance of teamwork and the increasing division of labor in contemporary chemistry. The results of this study are compared with the findings of a parallel study of collaboration in both the social sciences and the humanities.		Blaise Cronin;Debora Shaw;Kathryn La Barre	2004	JASIST	10.1002/asi.10353	social science;scientific method;comparative research;statistics	HCI	-75.19976616251988	-22.27040735223897	107413
fe9e1a06454e39003163465f9f38d430ea0f6181	metrics 2.0 for science		Science 2.0 The concept Science 2.0 is a recent development designed to take advantage of the new sharing technologies and social networks of the Web 2.0 and that it is now strongly linked to the current and future research policies of the European Commission. According to ideas developed by Ben Shneiderman this Science in Transition can be described according to two groups of actions, Integrating the whole research cycle and its stakeholders, including all and both activities and people involved in them, far beyond that focusing only on the authors of papers, and Opening the whole set of data; tools, results and metrics derived from the cited research (and communication) cycle from the very first moment the information is generated. The urgent need to adapt the current set of quantitative indicators to this new concept is the reason for this poster. We intend to provide a critical analysis of the current status of the bibliometrics y related quantitative techniques for science evaluation and to introduce a new umbrella term, Metrics 2.0, for describing future scenarios for the discipline.	bibliometrics;science 2.0;social network;umbrella term;web 2.0;world wide web	Isidro F. Aguillo	2015				HCI	-75.10283641931753	-19.024314661634026	107504
924a37b5da451aac5b25d997db673bb883fd6939	the camera does the rest [book reviews]		There is a whole spectrum of books on Polaroid. One is the biography of its American-born founder Edwin Land (1909-1991). Land was a distinguished inventor even before he produced his famous camera — the first of the “instant” cameras. He was well known for inventing polarizing filters that form the basis of polarized sunglasses. The Polaroid Corporation existed before the camera. Not only a great inventor, with over 500 patents in his lifetime, he was a wonderful showman who had a flair for introducing his latest cameras at shareholders’ meetings. Other books focus on the technology of the camera as well as its influence on legal matters, patents, business, and technological developments. This book, The Camera Does the Rest, focuses on the social meaning of the Polaroid camera and explores how it changed the field of photography. The focus is on the social meaning of the Polaroid camera - how did it change photography and how are cameras being used from a social perspective.		A. David Wunsch	2018	IEEE Technology and Society Magazine	10.1109/MTS.2018.2864805	polarizing filter;engineering;public relations;multimedia;biography;shareholder;corporation;photography	Vision	-65.19450719803326	-19.164236731060317	107598
f620fa25c690b82c0ac194373324b11804f15de7	why cobol?		"""Slightly over two years ago the Short Range Committee of the Conference on Data Systems Languages (CODASYL) reported that it not only was possible to develop a general-purpose problem-oriented programming language for business-type functions but it supplied one which it christened Common Burliness Oriented Language (COBOL). Since that date many articles have appeared in various profes~ sional and trade publications, both favorable and critical. It is appropriate in this year when COBOL really comes of age that the Communications devote an issue to presenting its history, its features, its implementation, and its use. COBOL comes of age this year because it is during this year that many compilers have been or will be released for a wide variety of data processing systems, lit is useful at this time to review the history of the dew~loprnent of COBOL to appreciate the role it is destined to play in the future. The need for a common programming language was recognized by many people and organizations prior to 1959. I t was observed, however, during a brief meeting at the University of Pennsylvania in April of that year that common programming languages were being independently developed on many fronts. How these many efforts would achieve uniformity provided a stimulus for much speculation. As might be exl)eeted, each language had its advocates and critics, with the advocates extremely vocal in support. The group concluded, in effect, that applying the impending technological hardware improvements then known or foreseeable would not be possible, or at least practical, unless """"software"""" considerations achieved mQor attention. These """"software"""" considerations suggested, in particular, the development of a common programming language which would Sl:)an all data processors. In a subsequent meeting the idea was advanced that there were two or more phases to the language requirements---first a hmguage that was """"problem-oriented but machine-independent,"""" followed by a language which was """"systems-orkmted and coutputer-independent."""" The former called for a general-purpose programming language; the latter lint)lied that systems specifications eouM be written in a language significant to people as well as machines. At this meeting the CODASYL organization, consisting of a Short Range Committee to determine the possibilities of a problem-oriented machine-independent larguage, an Intermediate Range Committee to move on to 0m """"systems-oriented language,"""" and a Long Range Committee to look to the future beyond, explored the potential of merging business and scientific languages. All committees functioned under the guidance of the CODASYL Executive Committee. I t is now well known that the Short Range Group, working voluntarily for long hours in large cities and secluded hamlets, and representing a wide variety of professional views and competitive corporate philosophies, produced a language acceptable to the divergent ptfilosophies and professional backgrounds. The initial publication of COBOL, sometimes called """"CoBoL 60,"""" suggested that its deficiencies could be determined only through us(; of the language. """"file CODASYL Executive Committee realized that useful criticism and recommendations would come initially from the manu, facturers, who had now assumed the task of building the con> pliers that would l)rovide for the implemei~tation of Co~oL on their respective specific equipme~ts. In recognition of this and through experience gained to that point with the Intermediate and I,ong Range Committees, the group undertook an internal reorganization. The following two committees were estat)lished: 1. The Maintenance Committee. This committee is charged with rnaintaining the hmguage, strengthening it and expanding it. The committee is divided into two separate working entities a Users Group and a Manufacturers Group. 2. 7'he Development Committee. The blending of the Intermediate and Long Range Committees gave recognition to the fact that an acceptable and useflfl common language was now available and that the objectives for the future could best be served and met through concentration on the entire future without attempting to divide it into projected time periods. The M~dntenanee Committee, meeting as a Special Task Force, reviewed all the comments, criticisms and suggestions received from various sources as a result of the i)ublieation of COBOL This Task Force carefully screened all proposals to eliminate duplications and ambiguities, and modified the language accordingly. The updated language, published in 1961 by the Govermnent l?rinting Office, is now known as C(mOL 61. I t is not the intention of the Maintenance or Executive Committees that COBOL will be changed annually. Rather it is intended that elective features will become firm parts of the law guage and that major areas not yet covered (report writers, mass files, etc.) will be added to the language. The """"open end"""" nature of Condor, will be maintained, thereby adding features rather than making revisions. The original motivations behind the CODASYL effort (lid not intend that COBOL would be only a common language bridging a wide variety of equipment, but that it would be a powerful language providing decided advantages to the majority of users. It was likened, by one of the members of CODASYL, to a super highway in that to individual users it might not be the panacea to all problems that tire individual user might desire. To the majority of users, however, just as the super highway serves a majority of communities or drivers, it would offer rapid, efficient communication to the computer. Obviously it cannot serve all requiremeats with equal efficiency. The challenge posed by the age in which we live, to develop data with far greater precision, with automation technktues and efficiency, in time periods never previously considered practical or even possible, is one which can be met only through reducing the elapse d time between problem determination and solution. One might go on to say, reducing this time period to lJ~e optimum consistent with the state of technology in data processing. To move forward from the present position is the role of the CODASYL Development Committee. Much good work has been done by this committee, but much more remains to be accomplished. It is the fervent hope of CODASYL that everyone in the data processing community will contribute constructively to the work which remains before us. Contribute actively in its deliberation or constructively by indicating your views on its efforts. With this type of support we believe we will move forward with """"software"""" which will keep pace with Ole progress in hardware."""	alpha compositing;bridging (networking);cobol;codasyl;central processing unit;circuit complexity;compiler;data system;device driver;entity;general-purpose modeling;general-purpose programming language;hamlets;naruto shippuden: clash of ninja revolution 3;object linking and embedding;programming language for business;projection screen;requirement	Joseph F. Cunnigham	1962	Commun. ACM	10.1145/367710.367718		PL	-63.53607321466744	-19.834607682703805	107933
99585844c448d4f93c67adc3d449bbf818332b18	feedback on our editorials		In our editorials we give our perspective on the current state of the research and practice with respect to the use of models in software and systems development. In some cases we highlight what we consider to be promising new and emerging research directions, and we sometimes give our perspective on problems arising from immature and incorrect use of models. The editorials are written to stimulate discussion and encourage exploration of new areas of research in modeling software-based systems. There is some evidence that the editorials are being read by subscribers. Our editorials have been cited by young as well as established researchers. We also get comments on editorials from our readers. Writing an editorial requires some effort and thus these comments are greatly appreciated. More importantly, these comments are valuable in that they help us determine the value of the editorials and they indicate that discussions around the topics addressed are taking place in the community. We would like to enhance the role of the editorials by encouraging readers to send comments via email or write publishable letters that comment on the contents of the editorials. We encourage both positive and negative comments that include clear points of agreement or disagreement. We also encourage our readers to send in letters commenting on the contents of articles we publish. These letters will be published in a section titled “Letters to the Editors”. In summary, we strongly encourage you to send us	algorithm;comment (computer programming);email;software development process	Robert B. France;Bernhard Rumpe	2007	Software & Systems Modeling	10.1007/s10270-007-0059-7	microorganism;systems engineering;steam distillation;viricidal activity;cinnamic aldehyde;black pepper oil;computer science;terpene;citral;organic chemistry	SE	-63.20242322501708	-18.09118059031001	107986
6b2a6fe11a731f1aed5f01434b6676717114c4e4	obsolescence of computing literature	bibliometrie;informatica;analyse bibliometrique;citation analysis;metodo analisis;scientometrics;obsolescencia;bibliometria;analisis cita;litterature scientifique;analyse citation;methode analyse;operating system;literatura cientifica;estudio caso;analysis method;scientometria;scientometrie;etude cas;bibliometrics;obsolescence;informatique;bibliometric analysis;computer science;scientific literature;system management;working paper;analisis bibliometrico	A multisynchronous obsolescence study has been performed on two computing journals that publish on technical aspects of computer system management (networks and operating systems). This area of computer science is found to have a relatively high obsolescence rate (a median citation rate of four years). This rate is similar to that of fields in engineering and the technology-dependent “hard” sciences.	computer science;operating system;systems management	Sally Jo Cunningham;David Bocock	1995	Scientometrics	10.1007/BF02020423	systems management;bibliometrics;scientometrics;computer science;operations research;citation analysis;world wide web;obsolescence	Theory	-75.01747582698471	-22.431832191072196	107995
519d8ead733f0681e7d84a72acff0202dea781d0	how french research scientists are making use of electronic journals: a case study conducted at pierre et marie curie university and denis diderot university	etude utilisateur;europa;electronic journal;universite;enseignement superieur;dominio investigacion;physique;estudiante;electronic periodical;research field;french;user study;information scientifique technique;periodique electronique;estudio usuario;chercheur;graduate level education;higher education;fisica;work environment;biology;biologia;france;ile de france;physics;research worker;frances;ensenanza superior;qualitative study;chimie;student;facteur influence;francais;francia;typology;chemistry;quimica;domaine recherche;university;typologie;scientific technical information;influence factor;investigador;europe;paris;etudiant;informacion cientifica tecnica;universidad;periodico electronico;biologie;tipologia	There have been few studies to date on how French research scientists are using electronic journals in their work. Under a national programme for document digitisation in higher education and research, a qualitative study was conducted at the Jussieu Campus in Paris among 25 researchers and doctoral students and nine documentalists. The main disciplines covered were physics, chemistry and biology, with some representatives from mathematics, computer science and earth sciences. A user typology was built up, and several of the findings agree substantially with those in the (mainly Anglo-Saxon) literature, which demonstrate the importance of factors such as the discipline concerned and the immediate working environment of researchers, including equipment, local practice, and the resources that are promoted or made available. Other more subjective factors also need to be taken into account.		Annaïg Mahé;Christine Andrys;Ghislaine Chartron	2000	J. Information Science	10.1177/016555150002600502	french;linguistics;sociology	HCI	-75.17856153085263	-23.289945026265663	108094
916d78ee480cabf5d2d4d3ca684413fd62cbf0eb	digital libraries in china: progress and prospects	site web;interfase usuario;project;proyecto;user interface;service orientation;digital library;digital libraries;chine;resource manager;resource management;task difficulty;copyright protection;dificultad tarea;biblioteca electronica;difficulte tâche;descripcion;asie;open access;resource sharing;training program;service design;interface utilisateur;electronic library;navigation system;sitio web;projet;china;public libraries;description;reference service;user interfaces;web site;bibliotheque electronique;asia	Purpose – The aim of this paper is to provide an overview of Chinese digital library (DL) projects via the corresponding web sites, It also seeks to illustrate the current situation of DLs in China by offering insights into the digitization of resources, technologies and services.Design/methodology/approach – A questionnaire was designed on the basis of the definition and features of digital libraries, together with the relevant library homepages and services. Overall, ten comprehensive universities and their library web sites, five public libraries and one science library were selected for comparison and analysis focusing on the content set‐up, digital resources, navigation systems, mainstream modes, home‐grown databases construction, user instruction training programs etc. Other issues including the virtual reference, service (VRS), academic information resource portal and integrated searching system or platform, personalized service, logon and authentication are also discussed.Findings – All the select...	library (computing)	Leye Yao;Ping Zhao	2009	The Electronic Library	10.1108/02640470910947656	digital library;computer science;resource management;operating system;database;multimedia;user interface;world wide web;information retrieval	Logic	-72.12307205124567	-23.662090801503094	108115
9ff1fd492498fc5a5af9566f6638643f277c340f	subscription clubs for e-journals: indian initiatives	bibliotheque;consortium;project;library service;proyecto;electronic periodical;pricing;periodique electronique;editor;economic model;suscripcion;modelo economico;modele economique;asie;publisher;abonnement;developpement collection;infrastructure development;desarrollo coleccion;projet;biblioteca;editeur;subscription;periodico electronico;library;fixation prix;consorcio;india;collection development;asia;inde	The print journals continue to dominate both from users point of view and publishers revenue. The advent of e-publishing has brought a revolution in journal publication, subscription, access and delivery mechanism. Print journals publishing costs include high article processing costs, high production and marketing costs. E-journal production and access costs are increased further due to infrastructure, customer support, IT savvy human resources, etc. While these costs form the base, other pricing factors include number of nodes, multiple campuses, access mode, training, perpetual access, etc. A study indicates that one of the US University Science Library spends 76 % of its journals budget on titles of 10 major publishers like Elsevier, Springer, Wiley, Harcourt, Kluwer, Plenum, Blackwell, AIP, MarcelDekker and Taylor Francis. This holds good for most of STM institutions too. The dwindling library budgets and growing number of journals force libraries to form consortia for accessing e-journals. The old concept ‘consortia’ means a strategic alliance of institutions having common interests. Neither libraries nor the publishers have sufficient experience or data to determine the appropriate unit cost of information, the effective return on investment, or the most appropriate economic model for charging or paying for electronic information. There are no universally acceptable e-journals pricing and licensing models. Current pricing models for e-information, which are developing during a period of experimentation, are not sustainable. Although it can not be generalized the learned society publishers are increasingly prepared to make all their nonsubscribed journals available to consortia in return for a relatively small extra payment. Many libraries especially in developing countries are not geared up for accessing e-Journals due to various reasons including user ignorance, infrastructure and funds. While there is an urgent need for changing the mindset of librarians, users and the administrators for subscribing to ejournals in India, a satisfying note is that few forward looking libraries have made a modest beginning in forming consortia. Some initiatives include – Indian Institutes of Management for accessing bibliographic databases, CSIR Laboratories for ScienceDirect, FORSA for accessing Astronomy and Astrophysics journals, Hyderabad Knowledge Park members for J-Gate, INFLIBNET initiative for providing access to six universities for J-Gate and INDEST for ScienceDirect , IEEE Journals, few bibliographic databases for the benefit IITs and IISc. Some of the pricing and payment constraints specific to Indian libraries include inadequate funds, single point payment, rigid administrative, financial and auditing rules, problems of defining asset against payment and pay-per-view not yet acceptable _____________________________________________________________________________ * Head, ICAST, E-mail: goudar@css.nal.res.in ** Deputy Head, ICAST, E-mail: poornima@css.nal.res.in Presently on Fulbright Fellowship at GSLIS, University of Illinois Urbana-Champaign, USA E-mail: poornima@uiuc.edu E-journals and Consortia The journal has played a major role in the creation and transmission of knowledge as the primary medium of formal scholarly communication and has remained essentially unchanged in form and function for more than three centuries. The first scholarly journal, Journal des Scavans, was published in 1665, and was soon followed by the Philosophical Transactions of the Royal Society. Despite its benefits to science and scholarship, the paper journal system has been subject to much criticism due to mainly spiraling costs, lack of selectivity, problems with the peer review process and long publication delays. The developments in computers and communication networks, especially World Wide Web have facilitated creation of alternative electronic forms of the conventional paper journal. The e-publishing has brought a revolution in journals publication, subscription, access and delivery mechanism. Out of 1,50,000 serials published in the world >60,000 titles cover scholarly communications. More than 14,000 of them have their electronic versions accessible through Internet; out of which 2,000 titles are free for all. Some electronic-only journals are beginning to demonstrate and exploit the potential of the new medium. The growing archive is searchable, and in html screen form papers have hypertext links from thumbnail figures and photographs to full images, threaded links to create themes and support subject categories, and external links to a database of abstracts. Papers are also available in pdf form for local printing. The next stage should see real examples of multimedia enhancements involving sound, video and simulations, particularly in the fields of biology and medicine. Print subscriptions still continue to dominate publishers’ revenue. Some of the major ejournal databases are ScienceDirect, EBSCO databases, Kluwer online, Springer LINK, Wiley Interscience, IEEE Xplore, Institute of Physics, MCB Emerald Library, Cambridge Journals Online, Academic IDEAL, OCLC’s First Search Service, UMI’s Proquest, JSTOR, etc. The major players in the e-Journals publishing, marketing and distribution includePrimary publishers Subscription agents Aggregators Document delivery agencies Vendors E-print systems The Library Managers are required to cope up with the increasing demands of faculty, students and researchers against all odds like dwindling budget and decreasing staff. Librarians are forced to work together due to economic realities and technological possibilities paving the way for forming subscription clubs for e-journals, not just clubs but strategic alliances with broad based objectives. The consortia can be defined as a strategic alliance of institutions having common interest. The main aim of a consortium is to achieve what the members of the group cannot achieve individually. The developments in information retrieval system and faster access technologies have enabled the libraries to come together for licensing the information available in digital form.	adaptive internet protocol;archive;bibliographic database;bibliothèque de l'école des chartes;blackwell (series);computer;customer support;emerald;experiment;francis;html;hypertext;ieee xplore;information retrieval;john d. wiley;librarian;library (computing);link building;list of code lyoko episodes;mediawiki;perpetual access;point of view (computer hardware company);portable document format;printing;selectivity (electronic);simulation;software transactional memory;springer (tank);telecommunications network;theme (computing);thumbnail;video;world wide web	I. R. N. Goudar;Poornima Narayana	2002		10.1007/3-540-36227-4_35	pricing;project;library;economic model;operations research	Web+IR	-68.36543464537688	-19.982922124682748	108144
4189365a43e7a494e9c3f3f6793e2d962a647862	accessing acm/sigchi publications: open enough?		"""them to our field? But! ACM has for a while provided several ways for anyone to access publications at no cost, without the need for ACM membership and a Digital Library subscription. Let's review (for details, see: http://authors.acm.org/ main.html): • Authors may post """" pre-prints """" of their published papers—accepted, author-prepared versions—to their personal home pages, their institution's repository, any repository mandated by an agency that funded the work, and nonprofit repositories (with certain restrictions). • Authors can post Author-Izer links to the definitive version of their papers in the ACM Digital Library; these links can appear on the author's home page and their institution's repository. • Authors can pay for perpetual open access to their paper in the Digital Library. Is this enough? Does this create access for everyone we want to reach? I'm not sure. My assumption was that if you get a paper published, you naturally want to make it as widely available as possible, so you certainly will take advantage of the first two options, even if you don't have funding for the third. In January 2016, I selected 20 papers from the CHI 2015 proceedings at random, and for each paper, did a Google search with a query consisting R eaching a global community. This sounds good! Let's think a bit more about what it means for SIGCHI. Distinctive parts of our identity are that we are interdisciplinary and international. SIGCHI sponsors more than 20 conferences, with well over a thousand papers published each year. Are they reaching all the people we want them to: researchers, practitioners, and students, in computer science, the social sciences, design, and other fields, on every continent? ACM's traditional model of providing access to publications was through subscriptions—someone has to pay. For many members of our community, this isn't a problem. For example, universities in North America subscribe to the ACM Digital Library, and their students, faculty, and staff can access ACM publications for free. However, what about people we'd like to reach who aren't in this fortunate situation? They have to join ACM and subscribe to the ACM Digital Library. Costs vary and can be quite low, but they still may pose a barrier. And what about someone who isn't a member, and has no plans to be, but might come across our publications while searching—do we lose a chance to reach them, to inform them, and to introduce"""	chi;computer science;digital library;google search;home page;sigchi;while	Loren G. Terveen	2016	Interactions	10.1145/2911328	operating system;database;world wide web	Graphics	-66.29756848565029	-20.330373205761887	108360
c2cc0356a91922922be69e2f52fc64db2e20a666	the sense of security and a countermeasure for the false sense (transcript of discussion)	journal item	This talk has two parts, I think: what makes users of computer systems feel secure and a countermeasure for when that sense of security is unjustified. I'm clearly not Yuko; Yuko Murayama was actually a colleague of mine many years ago, and of Mike shortly after that, but she's unable to travel to Europe to present this paper because of the earthquake in Japan. So I'm going to do my best to explain the work that she's done.		James Malcolm	2011		10.1007/978-3-642-25867-1_21	telecommunications;computer science;operations research;computer security	Crypto	-63.75902357630759	-20.78607739302337	108389
8d0585327666f7110217d68e72c8bb7f9e4b72f2	information systems research thematics: submissions to a new journal, 1987-1992	information systems research;research themes;research questions	The flow of manuscripts through the editorial offices of an academic journal can provide valuable information both about the performance of the journal as an instrument of its field and about the structure and evolution of the field itself. We undertook an analysis of the manuscripts submitted to the journal Information Systems ResearchISR during its start-up years, 1987 through 1992, in an effort to provide a foundation for examining the performance of the journal, and to open a window on to the information systems IS field during that period. We identified the primary research question for each of 397 submissions to ISR, and then categorized the research questions using an iterative classification procedure. Ambiguities in classification were exploited to identify relationships among the categories, and some overarching themes were exposed in order to reveal levels of structure in the journal's submissions stream. We also examined the distribution of submissions across categories and over the years of the study period, and compared the structures of the submissions stream and the publication stream. We present the results with the goal of broadening the perspectives which individual members of the IS research community have of ISR and to help fuel community discourse about the nature and proper direction of the field. We provide some guidelines to assist readers in this interpretive task, and offer some observations and speculations to help launch the discussion.	information systems research	E. Burton Swanson;Neil C. Ramiller	1993	Information Systems Research	10.1287/isre.4.4.299	social science;computer science;artificial intelligence;marketing;data mining;management;social psychology;operations research;world wide web	OS	-76.26187671421499	-17.92848140286708	108407
b37fb25981f3187436d0d5507dcafe363e82ab17	ics update	cybernetics;security of data	The natal announcement for the Index of Cyber Security (ICS) first appeared in these pages one year ago. As we promised at the outset, its first birthday marked the time for a review. The ICS is composed from a survey of expert sentiment-that is to say, it asks a set of respondents what they think. Sentiment-based indices have a long history and wide acceptance; two (US) examples are the Consumer Confidence Index and the Purchasing Managers Index. Generally speaking, sentiment-based indices are vulnerable to misinformed respondents. This is conquered either by large-scale sample randomization (Consumer Confidence) or by careful selection of respondents (Purchasing Managers). The ICS goes with the latter: it gathers a composite of cybersecurity expert opinions that aren't generalizable to any description of the public at large.	computer security;purchasing	Daniel E. Geer;Mukul Pareek	2012	IEEE Security & Privacy	10.1109/MSP.2012.69	computer science;data mining;computer security	Security	-70.05822860660408	-13.502616841034037	108414
339bcc1493ad2890f93dd4bb140059660d99d554	review of computer experience and cognitive development	inventory management;cognitive development;artificial intelligent;computer experiment	"""Although considerable research bears on the question of how children develop into adults, alost all is substantially removed from the reality and complexity of actual child development. ... I find """"Computer Experience and Cognitivie Development to be a refreshing and thought-provoking reminder that explaining how childredn develop into adults is exceedingly important; exceedingly hard; exceedingly interesting; and possibly, answerable."""		Mallory Selfridge	1989	AI Magazine	10.1609/aimag.v10i2.751	simulation;computer experiment;computer science;engineering;artificial intelligence;cognitive development	AI	-63.66361190282773	-23.587040063918916	108643
cb717b366b140c790e7aef67ede554a647d2d99a	a conceptual framework for the examination of transborder data flows	international scope;developpement economique;flujo informacion;escalafon internacional;flux information;information flow;economic development;echelon international;desarrollo economico	Abstrat The inclusion of informatics supporting trans‐border data flows (TDFs) in research and action related to the New World Information Order is essential. Documents prove the fact that information has been treated by developing countries as a critical element in the establishment of a New International Economic Order. The author calls for the recognition of TDFs as an integral element of the debate over information. Such issues as free flow of information, national sovereignty, and dependent development are addressed. In the conclusion, it is argued that the International Telecommunication Union is well equipped to expand its domain of jurisdiction to TDFs in coordination with a maturing Intergovernmental Bureau for Informatics.		Jean-Luc Renaud	1986	Inf. Soc.	10.1080/01972243.1986.9960028	information flow;economics;telecommunications;sociology;public administration;management;operations research;law;economic growth	DB	-72.71678356739271	-18.417150835125398	108838
8ea43471031ea2b54ba0643635b1b23c7a225e35	the changing face of government information: providing access to the twenty first century. suhasini l. kumar, editor. binghamton, ny: haworth press, 2006, 292 pp. $29.95 (paper), isbn-13-978-0789031563	ny	Prints,” as so named on the page, is an archived collection of items considered to be “...timely and provocative materials on topics of current interest” penned and opined by individuals, both civilian and civil service. The second web site, Open the Government.org (OTG), is subtitled “Americans for Less Secrecy, More Democracy,” and “...is a coalition of journalists, consumer and good government groups, environmentalists, library groups, labor, and others united to make the federal government a more open place in order to make us safer, strengthen public trust in government and support our democratic principles.” It is guided by 16 steering committee members, including Steven Aftergood, director of POGS and underwritten by a dozen granting organizations and funds. Their statement of values http://www.openthegovernment.org/article/subarchive/63 includes every document librarian's tenet of the public's right to information held by our government. Nearly 70 coalition partners, ranging from groups at state and national levels to library and publishing organizations, have signed the statement of values and links to their websites are embedded. Formerly an information policy analyst at OMB Watch and then Deputy Director of the Office of Government Relations at ALA, Patrice McDermott is the organization's Director. The busy home page itself is three static columns, a left side navigation index frame for “About Us,” “Press Room,” “Resource Center,” “Issues,” and “Take Action,” a center section for very current, up-to-date information/items of interest , and the third beginswith button links for joining, donating and taking action, followed by calendar of relevant events by month (rather sparsely populated for most months), a link to a forum site for public commentary on a number of open government issues, concluded by a long list of “News Highlights” and “Of Interest” links dated within the last month. Graphically this site has a less polished look to it with an inordinate amount of distractingwhite space on the ride side of all its internally linking pages. Under the “Press Room” heading, “Press Releases” provides the text of OTG press releases dating from, as of this visit, 2004 to the present. “Reports, Testimony, and Letters” include the full text of the content of these categories authored or involving support by OTG relating to issues of government secrecy, again from 2004 to 2007. “Experts Directory” lists organizational contacts (names, email, and links) for issues relating to the states, national security, environmental health and safety, public trust and accountability, and democracy. “Spotlight Stories” is a short list of stories “...that highlight the human impact of open government and government secrecy.” “In the News” links to a year's worth of press mentions of OTG itself and it archives back to 2005 as well. “Of Interest” is a lengthy list of links to outside governmental and commercial publications for analyses and commentary, announcements, congress, news, reports, resources and other open government issues. Last in the press section is “Videos and Webcasts” with four productions by OTG. The “Resource Center” section on the navigation frame contains four sections: Policy, Strategy, Library, and Connect. The “Policy” page “...provides background and analysis of various policies that could restrict the public's access to government information and infringe on their right to know important information,” and links for policy and news updates (archived back to 2004), FOIA, whistleblower protection, homeland security policies, information quality act, access to judicial information, and e-government, all leading to additional pages with numerous links. A random sampling of a number of these links resulted in only one “page error” and one redirect. “Strategy” provides advice and guidance for the fight against secrecy such as advocacy basics, media coverage, long-term strategies, getting and using information, and lessons learned; it requires better policing of linkage failures as this is their own take-action section. In the “Library” is a section for “Right-to-Know Databases” which are mostly governmental in the areas of census, energy, environment, contracts and grants, labor and transportation, with very brief descriptions, for a number of sites this reviewer was previously unfamiliar with. There is also the “Bookshelf” with a few annotated titles for right to know advocates and “Citizen Engagement” internet sites for involvement in the legislative process. “Calendar” links to the previously mentioned sparsely populated event calendar which might look and work better as a simple listing by date. Finally, in “Resources,” is “Connect” with ten or so OTG partner links for email or RSS feed signups. Winding down the navigation pane is “Issues” which appear to be linkages for the categories of democracy, environmental health and safety, national security and public trust and accountability to those places within the OTG site addressing those issues elsewhere. Last is “Take Action” where you are taken to the “Action Center” to sign up and/or access information on current and previous advocacy campaigns and get recent messages from OTG as current as today. The issues of secrecy can revolve around numerous topics and subjects, agencies and individuals, whether it's declassification of documents relating to UFOs or foreign affairs, freedom of information, polygraphing, or national security. The FAS POGS appears to be more of an information dispenser/document provider while OTG takes a more proactive, call-to-action approach. POGS does need to police their links a bit better and update or eliminate inaccurate ones, but in spite of the housekeeping details, the strength of the site is its voluminous content of full-text materials. Unfortunately, a previous index is no longer maintained or available and, aside from the headings, a Google site search is the only real means of non-surfing access to POGS' wealth of material. The same is true in terms of Google's site search being the only access outside the static navigation frame on the OTG page and the link upkeep needs attention as well. OTG is a bit more forthright with joining and donation appeals than POGS and could benefit from cosmetic and internal navigational improvements. Nevertheless, as documents librarians, these are excellent sites of which to be aware, refer to patrons, and peruse for the most updated and broad ranging information and issues in government secrecy and the public's right to know.	archive;citizen science;column (database);course (navigation);dbpedia;database;declassification;drew mcdermott;e-government;email;embedded system;freedom of information act 1982;freedom of information laws by country;google search;google sites;home page;information quality;international standard book number;librarian;linkage (software);population;rss;sampling (signal processing);the fight: lights out;url redirection;usb on-the-go;web search query	Barbara Miller	2009	Government Information Quarterly	10.1016/j.giq.2008.12.012	computer science;regional science	Web+IR	-66.39837083429717	-19.37115422876217	109192
0f5a83b4a919ecfbd5e0b1520dbe20a9b0045b65	ethics of using language editing services in an era of digital communication and heavily multi-authored papers		"""Scientists of many countries in which English is not the primary language routinely use a variety of manuscript preparation, correction or editing services, a practice that is openly endorsed by many journals and scientific institutions. These services vary tremendously in their scope; at one end there is simple proof-reading, and at the other extreme there is in-depth and extensive peer-reviewing, proposal preparation, statistical analyses, re-writing and co-writing. In this paper, the various types of service are reviewed, along with authorship guidelines, and the question is raised of whether the high-end services surpass most guidelines' criteria for authorship. Three other factors are considered. First, the ease of collaboration possible in the internet era allows multiple iterations between the author(s) and the """"editing service"""", so essentially, papers can be co-written. Second, """"editing services"""" often offer subject-specific experts who comment not only on the language, but interpret and improve scientific content. Third, the trend towards heavily multi-authored papers implies that the threshold necessary to earn authorship is declining. The inevitable conclusion is that at some point the contributions by """"editing services"""" should be deemed sufficient to warrant authorship. Trying to enforce any guidelines would likely be futile, but nevertheless, it might be time to revisit the ethics of using some of the high-end """"editing services"""". In an increasingly international job market, awareness of this problem might prove increasingly important in authorship disputes, the allocation of research grants, and hiring decisions."""	awareness;collections (publication);comment (computer programming);conflict (psychology);hardware random number generator;iteration;journal;manuscripts;numerous;paper;policy;quantity;regulation;request for proposal;review [publication type];societies;funding grant;jurisdiction;research grants	George A. Lozano	2014	Science and engineering ethics	10.1007/s11948-013-9451-6	psychology;public relations;medicine;computer science;engineering;knowledge management;sociology;law;world wide web	PL	-75.34094955059064	-15.594359304292961	109227
73447ea528ae0fdb23502ae5aa4e9040266c8a63	stasis and entropy in australian videogames classification discourse	swinburne;classification;media;censorship;discourse;politics	This article analyses the discourse surrounding the classification and regulation of videogames in Australia, with particular focus on the exclusion, and subsequent introduction of an R18+ rating over the twenty-year period between 1993-2013. This article argues that this period was characterised by a remarkable entropy and stasis within classification discourse, and that the introduction of the R18+ rating was eventually achieved by pro-R18+ advocates reaffirming the perceived validity and power of the core discourse. Thus, the history of videogame classification in Australia---with or without an R18+ rating---is the history of protection of children from inappropriate content, and mistrust of an interactive media form; these arguments underpin both the exclusion of an R18+ in the early 1990s and the inclusion of an R18+ in 2012. Finally, though a close analytical exploration of the history of videogame classification in Australia, this article argues that public discourse on classification has been subject to cynical media manipulation from almost all parties involved, which has resulted in a discursive entropy that has been largely disconnected with any understanding of how videogame culture and play is enacted in an everyday sense.	distrust;interactive media	Daniel Golding	2013		10.1145/2513002.2513041	humanities;psychology;communication;social psychology	NLP	-76.03734936517775	-13.63517864650004	109369
e336376865f2c6578af1668eb78e6cb228e6e2af	transition from the triple helix to n-tuple helices? an interview with elias g. carayannis and david f. j. campbell	carayannis;transitional economy;developing economy;n tuple helix;quadruple and quintuple innovation helix;triple helix;campbell	Given the widespread use of many digitalized communication channels, knowledge production activities have rapidly become interrelated. As the term “network society” implies, knowledge-based innovation systems have been built mainly on the mediated social infrastructure, which has lead to the emergence of the N-Tuple Helix model. I wish to contribute to this special issue by offering an interview with Prof. Dr. Elias G. Carayannis and Dr. David F. J. Campbell, the two co-authors and co-creators of the Quadruple (Government, University, Industry and Civil Society) and Quintuple (Quadruple Innovation Helix plus Environment) Innovation Helix concepts that extend, expand and complement the Triple Innovation Helix rubric. This article starts with brief background information on N-Tuple Helices and concludes with some implications for developing and transitional economies.	emergence;knowledge-based systems;quadruple-precision floating-point format;social infrastructure;tuple-versioning	Han Woo Park	2013	Scientometrics	10.1007/s11192-013-1124-3	developing country;artificial intelligence;triple helix;management	Web+IR	-66.46578070596091	-12.327775452940518	109443
03b8579c071e9ee78ebb5eca49b17024ac5d2c74	a picture is worth a thousand words: an empirical study on the influence of content visibility on diffusion processes within a virtual world	computational network science;social influence;virtual goods;multilayer networks;virtual world;viral marketing	A picture is worth a thousand words: an empirical study on the influence of content visibility on diffusion processes within a virtual world Jarosław Jankowski, Piotr Bródka and Juho Hamari Faculty of Computer Science and Information Technology, West Pomeranian University of Technology, Szczecin, Poland; Department of Computational Intelligence, Wroclaw University of Technology, Wrocław, Poland; Game Research Lab, School of Information Sciences, University of Tampere, Tampere, Finland	a picture is worth a thousand words;computation;computational intelligence;computer science;information science;list of information schools;virtual world	Jaroslaw Jankowski;Piotr Bródka;Juho Hamari	2016	Behaviour & IT	10.1080/0144929X.2016.1212932	simulation;social influence;computer science;artificial intelligence;viral marketing;multimedia;management;social psychology;world wide web	AI	-63.0710250647984	-13.985258112437265	109589
89643f4da2fe959e9483308f84181471478da94e	apc forum: chubb's innovation jams				Madeline Weiss	2010	MIS Quarterly Executive			NLP	-64.34407925538484	-9.893628760342734	109758
87c79ad230905684c0f312cee77a507f885c30c3	declarations, independence, and text in the information age	special collections;text;document creation;declaration of independence;document dissemination;government involvement;independence;sacred documents;citizen opinion;exhibit older documents;primary documents;declarations;manuscriptpreservation;information age;article	The World Wide Web has presented new opportunities for the creation and dissemination of documents, especially in providing a greater power to citizens to proclaim opinions and to call for actions. There have been, of course, such documents before the Web. The Declaration of Independence was made all the more powerful, for example, because of the power of print to multiply copies and to support public readings of it as the American colonies took up arms against England. Renewed interest in the preservation of the original manuscript of the Declaration provides an opportunity to compare how, in the emerging Knowledge Age, we should consider documents and their text as well as to question what records professionals such as archivists should see as their priorities. Can we, from this time on, conceive of textual preservation in the same manner? Can we even have the same sense of primary or sacred documents as we have in the past? At the least, can we exhibit or use older documents in the same fashion as we did prior to the advent of the Web?		Richard J. Cox	1999	First Monday	10.5210/fm.v4i6.674	primary source;public relations;independence;information age;computer science;world wide web	NLP	-68.71480905881836	-20.343870732896026	110278
b206b7ed83fb9968ec12269222043d340fc4fa22	the impact of the concept of post-industrial society and information society: a citation analysis study	ciencia informacion;concept;citation analysis;multidisciplinaire;societe;information science;sociologia;analyse cocitation;influencia;conceptual analysis;analisis cita;societe postindustrielle;analisis conceptual;informacion;influence;analyse citation;societe information;multidisciplinario;drucker p;machlup f;information society;sociedad;multidisciplinary;post industrial society;sociologie;analyse conceptuelle;cocitation analysis;science information;recherche scientifique;scientific research;sociology;information;bell d;society;investigacion cientifica;concepto	A detailed quantitative, citation study is made on the concepts of Bell, Machlup, and Drucker related to the economic and social effects of the growth of information-based industries.	citation analysis	Ming-Yueh Tsay	1995	Scientometrics	10.1007/BF02017335	social science;information;information science;computer science;sociology;society;concept;law;citation analysis;world wide web	HCI	-75.03906690962343	-21.85729544913391	110463
00f580573df025706f1d0536111415601d5a67a1	digital rejoinders: time and place, hither and thither, war and peace	narrative;convergence;communications;meetings and proceedings;transmedia;book chapter;interaction;collaboration;publishing;illustration;graphics			Mikel Horl	2011			library science;human–computer interaction;computer science;multimedia	HCI	-62.98562789540585	-11.604409865252162	110471
442cebe619fb692c0bcf55c97a2800f123a9155f	letters to the editor		"""fresh i n t e r a c t i o n s / j a n u a r y + f e b r u a r y 2 0 0 6 ground to make training effective. What about better embedded assistance, such as putting password requirements (length, alphanumeric combinations) right next to the input text field? That might help, but it won't make firewall configuration easier for someone who doesn't know what a firewall is or why they should have one. Did your last computer come with a software firewall installed? And was it turned off by default? How does HCI fix that? The real challenge to HCI is to assist in identifying and prioritizing the true threats and risks, and to provide the means to mitigate those risks. If everything is so important that it requires the same level of protection, then nothing has higher or lower priority, and users become numb and careless. The costs to the human element must be addressed, or we risk losing users' attention. All risks are not the same: The likelihood of death by asteroid is far less than by auto accident, and the risk of loss of life is not equivalent to the potential loss of business advantage. Where are we with HCI and security? Where is the work to be done: in research or in practice? Do the answers to security questions lie in user education, better technological applications such as biomet-rics, smarter encryption? Add your voice to the discussion in <interactions>. The May/June 2006 issue will look at HCI and security; if you would like to contribute, please contact guest editor Ryan West at ryan.west@sas.com with your proposal. STC. In his spare time, Fred works as an information developer at IBM's Silicon Valley Lab in San Jose, California. Contact him at wfreds@acm.org. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without the fee, provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on services or to redistribute to lists, requires prior specific permission and/or a fee. Fred Sampson wrote about offshoring in his column ("""" Pushing the Envelope, """" November-December 2005). He began by posing the question """" How …"""	embedded system;encryption;firewall (computing);fred (chatterbot);human–computer interaction;password;requirement;security question	Jonathan Arnowitz;Elizabeth Dykstra-Erickson	2006	Interactions	10.1145/1109069.1109079		HCI	-64.31989351550968	-23.89683717935896	110794
0a89bc34857049494adbc7b1155384efddc6c4b1	the global virtual museum of information science & technology, a project idea		Information Science & Technology (IST) has pervasively affected our everyday life, thus becoming a proper cultural heritage of humanity. The growing curiosity about IST history has determined the creation of important collections devoted to the conservation of IST relics. Physical relics are naturally located close to their origins, but they are only one aspect of preservation and dissemination of IST history. The whole knowledge about IST history has to go beyond the local boundaries and become a globally shared and worldwide accessible heritage. Our proposal is to establish a Global Virtual Museum of IST based on a knowledge base able to manage all the information of the domain, created and updated by museum keepers and other experts, and capable of offering new enjoyment opportunities to wider public audience. It is a radical change in the idea itself of cultural heritage information management, up to now bound to the traditional cataloguing approaches.	digital history;information management;information science;information security;knowledge base	Giovanni A. Cignoni;Giovanni A. Cossu	2016		10.1007/978-3-319-49463-0_7	library science;museum informatics;human–computer interaction;engineering;multimedia	HCI	-70.14661772848666	-20.042861143166164	110829
bf3be3123245cc99f9d7cc70ee58c68d8dc43b23	service architecture, prototype description, and network implications of a personalized information grazing service	broadband networks;information delivery system;pigs;multimedia;broadband network;information retrieval;information articles;prototypes;information technology;information services broadband networks;information services;service architecture;multimedia systems;personalized interest profiles;call processing capacity transmission capacity information delivery system information filtering system service architecture personalized information grazing service passive information grazing system pigs information articles multimedia broadband network personalized interest profiles;feedback;information management;passive information grazing system;call processing capacity;information filtering system;management information systems;grazing system;prototypes multimedia systems feedback information retrieval broadband communication tv management information systems floods information technology information management;floods;tv;personalized information grazing service;broadband communication;transmission capacity	We present a Passive Information Grazing System (PIGS) which is a prototype i.fomation delivery and fikering system for casual users. In PIGS, information articles in multimedia form are electronically transmitted to users over a prototype broadband network. To assist the users in managing the potential flood of articles, PIGS selects information for individual users based on their personalized interest profiles. As users' interests change over time, their profiles could be automatically adapted using implicit and explicit feedback from users about each article. We adne and compare the network implications of several altemtive implementatwns of PIGS, with particular emphasis on transmission and call processing capacity requirements. Information technologies in general have been extremely successful in facilitating the creation and dissemination of information. They have been less successful at addressing information management problems. With the advent of high speed electronic networks capable of delivering large amounts of multimedia information to home and office, the deluge of information that we all face is likely to worsen. Our motivation in carrying out this research is twofold. Firstly, we wish to further the understanding of potential uses for public networks by users and vendors. Secondly, we wish to examine the implications of such usage on the network. This paper describes an information delivery service aimed at ameliorating this problem while at the same time allowing, and acNdy enhancing, the casual and often accidental access to information. Sections 2 and 3 discuss the motivation for our focus on passive information activities and describe our Passive Information Grazing System (PIGS) service proposal and prototype implementation. Section 4 presents a number of alternative implementations and compares their impact on the network with respect to transmission and call processing	error-tolerant design;freedom of information laws by country;information management;personalization;prototype;requirement	Howard E. Bussey;Carmen Egido;Amy Kaplan;Steven L. Rohall;Rosanna Yuan	1990		10.1109/INFCOM.1990.91356	simulation;telecommunications;computer science;multimedia;information management;information technology;world wide web;computer network;broadband networks	Mobile	-72.36418817475912	-18.042522552008176	110870
398a26a8a0267e8eebd592ecaa27b7fea4bb5550	negotiating meaning: an ant approach to the building of innovations		Feminism and Actor-Network Theory (ANT) have often been considered opposing theoretical and intellectual traditions. This paper imagines a meeting between these seemingly divergent fields and considers the theoretical and methodological challenges that ANT and feminism raise for one another. This paper examines an empirical project that calls for an engagement with both ANT and feminism. Through the lens of this empirical project, three methodological questions that an alliance between ANT and feminism would raise for any research project are considered: 1) Where does the analysis start? 2) What can be seen once the research has begun? 3) What about politics? The potential places where ANT and feminism can meet and mutually shape research on scientific practice and technological innovation are explored. In doing so, this paper moves toward an imagining of a feminist ANT. DOI: 10.4018/jantti.2012040101 2 International Journal of Actor-Network Theory and Technological Innovation, 4(2), 1-9, April-June 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. feminism and ANT are incommensurable. But perhaps, as this paper will explore, this need not be the case. This paper takes up Harding’s (2008) hopeful projection and imagines a meeting between the seemingly divergent fields of feminist scholarship and Actor-Network Theory. I will examine an empirical project that calls for an engagement with both ANT and feminism. Through the lens of this empirical project, I will consider what these diverging theoretical and methodological traditions can learn from one another. I will consider three methodological questions that an alliance between ANT and feminism would raise for any research project: 1) Where do we start our analysis? 2) What can we see once we have begun? 3) What about politics? Through these questions, I will explore how ANT and feminism challenge and potentially speak to one another.	apache ant (another neat tool);network theory	Fernando Abreu Gonçalves;José Figueiredo	2010	IJANTTI	10.4018/jantti.2010070101	knowledge management;artificial intelligence	SE	-72.53620953277412	-16.561583926460212	111091
555ed757d70a893f396406845e22d4dcb6e17243	department outreach: forging new links of communication and support	new link;department outreach	The University of Virginia’s (UVa) Information Technology and Communication (ITC) Division provides a high performance computer network and support for approximately 27,000 staff, faculty and students. ITC’S User Support Division (USD) is one of the university’s computer support providers. USD offers support by means of a centralized Help Desk, electronic mail consulting, individual in-depth technical support and the Department Outreach program.	automated planning and scheduling;centralized computing;email;freedom of information laws by country;purchasing;supercomputer;technical support;unix	Robin Lindley	1995		10.1145/219894.223029	simulation;engineering;operations management;computer security	Arch	-69.36901713316074	-18.213299169351497	111095
e327371975e16e04f17a9fce908f876d6b32e98c	culture and knowledge: hypothesis on the interpretation of post-industrial society	new technology;medio cultural;milieu culturel;information transmission;connaissance;hombre;conocimiento;knowledge;cultural environment;digital communication;theory;teoria;human;transmision informacion;transmission information;communication;comunicacion;theorie;homme	In our social and cultural environment new technologies seem to be used more as means of production and transmission of knowledge. My paper is on some of the problems which — in my opinion — are relevant in such an environment on the basis of the implications and the characteristics owing to the analogic and the digital communication.		Franco Fileni	1992	AI & SOCIETY	10.1007/BF02472790	social science;sociology;knowledge;anthropology;theory	AI	-73.46029048968421	-20.35124675536947	111155
2b20622b60f16263e03acf396340342c9abeaa7b	crossing the divide	human computer interaction;conference proceedings;journals	This essay summarizes the editor's views of publication in the field of human-computer interaction. Digital technologies have begun changing the way journal articles and conference papers are produced, reviewed, published, accessed, and used. This period of profound change presents challenges and opportunities for both new and existing channels of scientific and technical communication.	attachments;cluster analysis;freedom of information laws by country;human–computer interaction;hyperlink;robert	Jonathan Grudin	2004	ACM Trans. Comput.-Hum. Interact.	10.1145/972648.972649	human–computer interaction;computer science;operations research	Graphics	-69.42575678867377	-20.750460488316627	111233
812df5fade9128ee7ce0da953cbeb5e190524f84	shaping the ethics of an emergent field: scientists' and policymakers' representations of nanotechnologies	nanotechnologies;scientists;nanoethics;risk;policymaker;power	Nanotechnologies present significant new challenges for the study of technoethics. While they are surrounded by high expectations there is considerable uncertainty about their impact. Discussions about their likely ethical implications have often assumed that ethical issues and standpoints are relatively clear. The commonly held narrow utilitarian conception of benefits versus risks tends to overlook broader issues concerning the operation of power in problem definition, unimagined or unknown effects, and accountability. Drawing upon data from a recent UK-based study, this article examines how scientists' and policymakers' representations of nanotechnologies contribute to shaping thinking about the 'ethics' of this field. It suggests that their particular framing of the field is likely to constrain debate on a range of important matters in need of urgent deliberation, including the direction of current research efforts and whether the investments in particular lines of research are likely to bring about the promised economic and social benefits or have deleterious impacts. Overall, the study found that most of the respondents were optimistic about the perceived benefits of nanotechnologies and sought to distance their work from wider non-technical questions. Scientists and policymakers, it is argued, need to reflect much more upon their own assumptions and consider how these may influence the trajectory of technology development and public responses.	emergent;noise shaping	Alison Anderson;Alan Petersen	2010	IJT	10.4018/jte.2010081003	socioeconomics;power;risk;management science;sociology;law	NLP	-76.21557553137357	-11.07316870505617	111277
9953bf9a4ccab7613d32ce86edd40d0ed03f987f	nominees for elections and report of the acm nominating committee	organizations	The Constitution and Bylaws provide that candidates for elected offices of the ACM may also be nominated by petition of one percent of the Members who as of November 1 are eligible to vote for the nominee. Such petitions must be accompanied by a written declaration that the nominee is willing to stand for election. The number of Member signatures required for the offices of President, Vice President, Secretary/Treasurer and Members at Large, is 753. The Bylaws provide that such petitions must reach the Elections Committee before January 31. Original petitions for ACM offices are to be submitted to the ACM Elections Committee, c/o Pat Ryan, COO, ACM Headquarters, 2 Penn Plaza, Suite 701, New York, NY 10121, USA, by January 31, 2014. Duplicate copies of the petitions should also be sent to the Chair of the Elections Committee, Gerry Segal, c/o ACM Headquarters. All candidates nominated by petition are reminded of the requirements stated in the Policy and Procedures on Nominations and Elections that a candidate for high office must meet in order to serve with distinction. This document is available on: http://www.acm.org/about/ acm-policies-procedures, or copies may be obtained from Rosemary McGuinness, Office of Policy and Administration, ACM Headquarters. Statements and biographical sketches of all candidates will appear in the May 2014 issue of Communications of the ACM. The Nominating Committee would like to thank all those who helped us with their suggestions and advice.	antivirus software;communications of the acm;declaration (computer programming);requirement	CACM Staff	2014	Commun. ACM	10.1145/2541883.2541888		Graphics	-63.451765675431965	-18.651225764441268	111318
9e55d051dc3333361b60568e1371a897eb1b4a98	delay and size in hierarchical organizations	ncku 成功大學 成大 圖書館 機構典藏;dissertations and theses journal referred papers conference papers nsc reserach report patent nckur ir ncku institutional repostiory 博碩士論文 期刊論文 國科會研究報告 專利 成大機構典藏	As material and information flow through an organization, work is being performed; its very act incurs time and hence delay. It may be intuitive that, the larger an organization is, the longer the delay will be. This turns out to be not entirely true. In this paper, size and delay are found to be inversely related to each other, under certain conditions, enabling a speed-up with additional agents. Analytical relations and bounds are then developed, followed by simulations under generalized conditions. Without exception, analyses and simulations both exhibit globally optimal configurations in size and in delay.		C. C. Hsieh;T. C. Woo	2000	Int. J. Systems Science	10.1080/002077200418441	computer science;engineering;mathematics;operations research	Logic	-67.22236575083441	-19.957556665691754	111388
ff24796f4106fd1489401dafa665719614acb1be	system reliability theory: models, statistical methods, and applications		Description: A thoroughly updated and revised look at system reliability theory Since the first edition of this popular text was published nearly a decade ago, new standards have changed the focus of reliability engineering and introduced new concepts and terminology not previously addressed in the engineering literature. Consequently, the Second Edition of System Reliability Theory: Models, Statistical Methods, and Applications has been thoroughly rewritten and updated to meet current standards. To maximize its value as a pedagogical tool, the Second Edition features:-Additional chapters on reliability of maintained systems and reliability assessment of safety-critical systems-Discussion of basic assessment methods for operational availability and production regularity-New concepts and terminology not covered in the first edition-Revised sequencing of chapters for better pedagogical structure-New problems, examples, and cases for a more applied focus-An accompanying Web site with solutions, overheads, and supplementary information With its updated practical focus, incorporation of industry feedback, and many new examples based on real industry problems and data, the Second Edition of this important text should prove to be more useful than ever for students, instructors, and researchers alike.	operational availability;reliability engineering;statistical model	Eric R. Ziegel	2004	Technometrics	10.1198/tech.2004.s242	statistical theory	DB	-64.71503043573475	-18.21842168516625	111454
990d98749067caae74297cf28c62e52c8672d443	who'd phish from the summit of kilimanjaro?	own quiz answering error;marketing department;genuine material;end user;phishing emails;genuine marketeers	Phishing emails are now so convincing that even experts cannot tell what is or is not genuine; though one of my own quiz errors resulted from failing to believe that genuine marketeers could possibly be so clueless! Thus I believe that education of end users will be almost entirely ineffective and education of marketing departments – to remove “click on this” (and HTML generally) from the genuine material – is going to take some time. Providing end users with one-time passwords (pads of single-use numbers, SecureID tokens, PINs sent by mobile phone) can ensure that phishing only works when there is a real-time, Man-in-the-Middle (MITM), attack, which will immediately deter the bad guys whose technical expertise runs solely to copying websites. However, formal protocol analysis shows that only a handful of the “bag of bits” being passed around can be considered to be authenticated – and the MITM will be able to steal what they wish. Insisting on SSL (https) connections will prevent the use of random URLs for phishing websites and bring the focus back to control of the DNS. However, once the second level (fakebankname.com) is secured then the attackers will just move down a level (to bankname.plausible-second-word.com). I predict a lot of wasteful activity before the nature of DNS delegation is fully understood. Insisting on client certificates prevents MITM, but also stops me paying my gas bill from a holiday cybercafé – which is bad for business. But why do I need the same authority to pay the bill as to change the name of the gas company? A range of authentication systems is needed, chosen as the risk varies. The banks could learn from the activity monitoring systems of the credit card companies, and thus ensure that extra authentication is seldom necessary or onerous. For example, a check can be made on the IP address of incoming connections. If the session arrives from a cybercafẽ in Latvia or a web hosting rack in suburban Moscow then Mr. Jones in Acacia Avenue is not connecting directly... if he really does want to set up a new payee then perhaps he could ring the branch manager directly to confirm that he’s taking an East European holiday? To conclude; I can see no silver bullet (I can imagine success for phishing emails that ask for client certificates), and most of the proposed argentoammunition is useless once the end-user machine is compromised. Nevertheless, a blend of security improvements will freeze out all but the most competent criminals. Society may need a general solution to online security, but the banks only have to persuade the bad guys to move on to more attractive targets. However, the fixes must not be introduced one by one, allowing each to be overcome individually. What’s needed is a ‘Kilimanjaro effect’, where the security suddenly dominates the landscape and it will always seem to be a long way to the summit.	activity tracker;authentication;email;failure;html;https;jones calculus;man-in-the-middle attack;mobile phone;no silver bullet;password;phishing;rsa securid;real-time transcription;web hosting service	Richard Clayton	2005		10.1007/11507840_11	multimedia;world wide web	Security	-65.33719583804674	-22.220593166898766	111472
8d3e4cc6f4d78e0bb2fee9cbbffcbfd3bfd68ffb	the foz coa rock art case: towards a new relationship between science and policy making in portugal?	policy making;subspace constraints computer aided software engineering art investments painting industrial relations public policy research and development standards development diseases;art;archaeology;decision maker;rock paintings preservation foz coa rock art policy making portugal science public decision making system scientific expertise administrative culture peripheral european country contingent political change;government policies;art government policies archaeology;rock art	In a less-industrialised country like Portugal, the relationships between scientific expertise and the public decision-making system have been negatively marked by the low relevance assigned to science by public decision-makers and by the lack of a scientific culture in society at large. Decision-makers have shown the propensity, either to disregard scientific opinion, or to manipulate it, whenever it does not meet their political objectives. This statement is confirmed by the direction followed by science-based social and political controversies occurred in Portugal in recent years. However, in the Foz Coa rock art controversy (1994-95), pressure by Portuguese archeologists eventually led the new Government, empowered in late 1995, to lean towards their position, which favoured the preservation of the pictures, in spite of the fact that this would imply discontinuing the building up of a dam where important investments had already been made. What does this case tell us about political and administrative culture towards science in a peripheral European country, as well as about the possible consequences of contingent political change in that regard? What can be learned regarding the strategy used by scientists to put forward their claim for the rock paintings preservation? Does this case, and the decisions taken on it, announce a new era in the relationships between scientific expertise and public decision in Portugal?.		Maria Eduarda Barroso Gonçalves	1996		10.1109/ISTAS.1996.540435	political science;economy;management	NLP	-75.51743438243639	-10.463253739525287	111522
6581f3d071092b4ba60a241f3e4174c1c79493ca	the constitutive and the instrumental in social design	social dilemmas;research agenda;design research;design practice;social dilemma;research method;constitutive and instrumental design;collective action;information system;constitutional design;social design	"""Simon's <u>The Sciences of the Artificial</u> is rightly influential as a founding text in design research in the information systems field (IS). Simon's contributions in the same volume to what he calls social planning and human design - practices associated with the development of societal scale artifacts that foster a """"humane society"""" - are much less visible in IS design research. I develop and expand on some of Simon's insights here using social design projects such as IT-based civic networks as my context, drawing on a civic network development project called the Urban-net that I have tracked since its inception in 1996. I define some distinctive features of such projects and advance an institutionalist conception of actors (designers) and action. Despite noting that """"nothing is more fundamental in setting our research agenda and informing our research methods than our view of the nature of the human beings whose behavior we are studying"""" (Simon 1985; emphasis added), and despite his recognition that social planning projects often are quite different from other types of technical projects in the demands they make on actors, Simon's (1996) discussion is not moved by a sufficiently nuanced view of the designer. Apropos, and drawing on a sociological institutionalist view of social actors and action, I outline a model of two inter-related design activities: constitutive design - targeting design of the normative or institutional foundation and governance mechanisms - and instrumental design, where designers specify the system to be built within the agreed-upon normative constraints. I conclude with a brief account of the Urban-net case."""	information system;simon	Murali Venkatesh	2009		10.1145/1555619.1555638	social science;design research;political science;management science;social psychology	HCI	-76.91679436938989	-11.614062586304621	111603
729dda2e8c06aa0c326f7a44bc8db23944a19818	electronic commerce in asia: the legal, regulatory and policy issues	electronic commerce	* This paper is based substantially on this author’s article ‘Electronic Commerce Law in Asia: A Case for Convergence’. 1 Samtani Anil is a Professor of Law in the Nanyang Technological University, Singapore. He has been admitted to the Roll of Advocates and Solicitors in Singapore and to the Roll of Solicitors in England and Wales. Mr Samtani specializes in the areas of electronic commerce law, information technology law, intellectual property law and international business law. E-mail : asamtani ntu.edu.sg; Phone : (65)–7906310; Fax : (65)–7935189 2 Chris Reed, Internet Law: Text and Materials (Butterworths, 2000) at page 252. 3 This study, conducted by Professor Steve Burdon, Visiting Professor of Electronic Commerce at Sydney’s University of Technology, was presented at the World E-Commerce Forum, held in October 2000: ‘Study: Asia Emerging as E-Commerce Powerhouse’, Vol 6 Issue 44 (September 1–7, 2000) Computerworld 4. International Journal of Law and Information Technology, Vol. 9 No. 2 Oxford University Press 2001	e-commerce payment system;fax	Samtani Anil	2001	I. J. Law and Information Technology	10.1093/ijlit/9.2.93	e-commerce;computer science	DB	-62.8903239506985	-13.572523386186418	111659
c7e38305d8e4ad1ac2eebd0c6a5dc65fc4a948f1	publication behaviour and international impact: scandinavian clinical and social medicine, 1988–96	oecd countries;europa;citation analysis;sweden;scientometrics;empirical study;finlandia;danemark;noruega;publication primaire;facteur impact;factor impacto;impact factor;finlande;medicina;medicina social;analisis cita;pays nordiques;publicacion primaria;medecine sociale;medecine;nordic countries;dinamarca;suede;analyse citation;suecia;finland;norway;scientometria;primary publication;denmark;scientometrie;medicine;norvege;europe;new zealand;social medicine	The paper presents the results of an empirical study of the Danish and Nordic Publication behaviour and international impact in Clinical and Social Medicine covering the period 1988–96. As indicators are applied the international visibility of Scandinavian research output, the publication activity per capita in SCI journals, the development over time of the national citation impact in an OECD and World context, and the ratio of cited papers relative to the World. Compared toMay's analysis (1997), covering 1981–94, the analysis shows that a certain reshuffle of national positions among the OECD countries in citation impact has occurred. UK and New Zealand as well as Denmark and Sweden have lost in ranking to Finland and Belgium, both countries coming up from behind. The most interesting results concern the opposite research policy strategies displayed by Finland and Denmark which result in similar impact patterns relative to the World impact. The implications are discussed.		Peter Ingwersen;Irene Wormell	1999	Scientometrics	10.1007/BF02459606	demography;social medicine;scientometrics;computer science;economy;empirical research;citation analysis;world wide web	SE	-76.18770018015772	-22.32576414138674	111679
903d4d877868e5760d55100ec6ed5d22c63e7355	a soft system perspective on information quality (iq) in electronic commerce	electronic commerce;information quality	1 Introduction In spite of the relatively large amount of literature being put out on quality of information in web-based technologies, there is no coherent model or theory bearing on complex aspects and dimensions of information quality (IQ) in that context. This paper makes a beginning in this direction by outlining a soft system framework for understandings IQ in the domain of electronic commerce (EC) in order to improve IQ standards and perceptions by different actors. The growing attractiveness of the Internet and EC has resulted in exciting prospects for organisations to reach out for customers with minimum additional costs. Ensuring information quality (IQ) in the Web page is needed for performing effective interaction with customers through WWW. Yet, the factors that affect IQ in the Web site are unclear.	coherence (physics);e-commerce;information quality;internet;www;web page;world wide web	Mohamed G. Aboelmaged	2000			information quality;marketing;business;internet privacy	ECom	-76.9915039647809	-13.06658525421065	111701
2c9f5d028c72b51fffdec83f4ca698d14f509a52	advances in cylindrical algebraic decomposition		General rights Copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights. Take down policy If you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately and investigate your claim.	algorithm;computer algebra system;computer-aided design;linear algebra;maple;polynomial;preconditioner;quantifier (logic);time complexity	David Wilson	2014			mathematical optimization;mathematics;algorithm	AI	-66.54522411937832	-18.599997724240357	111773
affb288213c83a09b1c20460e23b9e07b6a246db	b.c. brookes and information science education: a personal note	ciencia informacion;europa;case history;information science;informing science;historique;royaume uni;united kingdom;reino unido;enseignement;europe;historica;science information;teaching;ensenanza	L'enseignement en sciences de l'information, en 1968, au Royaume Uni, a travers l'experience de l'enseignement recu de B.C. Brooks: celui-ci a promu ce domaine au rang de science deviant de l'enseignement traditionnel base sur la formation professionnelle	information science	Stephen E. Robertson	1990	J. Information Science	10.1177/016555159001600103	information science;computer science;medical history	NLP	-74.38311263832682	-23.538572235088928	111846
0064d75b1718ca12017ca595adda402badf446a7	philosophical smoke signals: theory and practice in information systems design	theory and practice;information system;information system design	"""Although the gulf between the theory and practice in Information Systems is much lamented, few researchers have offered a way forward except through a number of (failed) attempts to develop a single systematic theory for Information Systems. In this paper, we encourage researchers to re-examine the practical consequences of their theoretical arguments. By examining these arguments we may be able to form a number of more rigorous theories of Information Systems, allowing us to draw theory and practice together without undertaking yet another attempt at the holy grail of a single unified systematic theory of Information Systems. 1 Background Theory and Practice Although the foundations of Information Systems have been much debated over the last 40 years, the practical value of these debates has often been questioned (Bacon and Fitzgerald, 2001; Oettinger, 1964). This has lead to something of a gulf between Information Systems theory and practice (Farhoomand and Drury, 1999; Glass, 1996). However, if we are to address either theoretical or practical problems, we must also deal with the relationship between the two. For instance, recent papers from the 'theory' side of Information Systems research have pushed for the formation of a 'scientific' foundation for Information Systems (Farhoomand, 1987; Khazanchi and Munkvold, 2000). In one sense, pushing for a 'scientific' foundation for Information Systems is not a bad idea. The problems start when we ask, """"what kind of science might underpin Information Systems""""? In recent years, we seem to have seen a concerted push to move Information Systems to the same 'scientific foundation' as Computer Science. The wisdom of such a move is questionable. We could for example point out the scientific nature of Computer Science has been a source of active debate for over 50 years (Dijkstra, 2001; McGuffee, 2000; Proulx et al, 1996). However, a more serious criticism would be that the original impetus for creating a separate field of Information Systems was the sense the context of Computer Science and Information Systems were clearly distinct (Davis et al, 1996. For instance, in the Association for Computational Machinery (Jay et al, 1982, p. 784) argued when drawing up a curriculum for undergraduate studies, that: """"The IS curriculum teaches information system concepts and processes within two contexts, organization functions and management knowledge, and technical information systems knowledge"""""""	computation;computer science;gulf of evaluation;information systems research;information system;systems design;systems theory;yet another	David King;Chris Kimble	2005	CoRR		computer science;management science;information system	AI	-72.75845582924192	-16.7252937983961	111891
afff5c62e387a7767679ea9f3e5ea2ca3608f835	comparison of trends in the quantity and variety of science citation index (sci) literature on human pathogens between china and the united states	sci literature;variety;quantity;pathogenic microorganism;china	The proportion of pathogenic microorganisms in the microbial world is relatively small, while their threat to human health, economic development and social stability is severe. The quantity and variation of Science Citation Index (SCI) literature related to pathogenic microorganisms may reflect the level of relevant research and the degree of attention. Here we compared trends in the quantity and variety of SCI literature relating to certain important pathogenic microorganisms published by scientists from United States and China from 1996 to 2010 by searching the Science Citation Index database. The pathogenic microorganisms in this study comprise two categories of pathogens: Bacillus anthracis, Yersinia pestis, Francisella tularensis, Ebola virus, Burkholderia pseudomallei, which belong to biodefense-associated pathogens (BDAPs) and the human immunodeficiency virus (HIV), SARS coronavirus, hepatitis B virus (HBV), Mycobacterium tuberculosis, influenza virus, which belong to the commonly encountered health-threatening pathogens. Our results showed that the United States (US) published much more SCI literature on these pathogens than China. Furthermore, literature on BDAPs published by scientists from the US has increased sharply since 2002. However, the numbers of literature relating to CEHTPs from China has demonstrated a gradual increase from 1996 to 2010. Research into pathogenic microorganisms requires three balance to be achieved: investment in BDAP and CEHTP studies; basic and applied research; a faster pace of research into pathogens and fulfilling biosafety and biosecurity requirements.	citation index;requirement	Deqiao Tian;Yunzhou Yu;Yumin Wang;Tao Zheng	2012	Scientometrics	10.1007/s11192-012-0772-z	quantity;epistemology;variety;china	AI	-76.59523628602663	-20.031628656352567	112183
a8b4f8212ced92f88ced40c5553e17a2a0d25cf7	jump-start your career as a digital librarian	digital libraries;librarianship;digital librarians;librarians	The world of digital libraries is often overwhelming, and developing the skills required for a successful career in this field can be a moving target. Topics that didn’t exist in libraries until relatively recently (content management systems, web development, data curation) as well as more traditional librarian duties that intersect with developing areas (mobile reference, e-resource management) are all issues that may show up on the digital librarian’s radar. New trends and technologies emerge with startling regularity, and, for those new to digital librarianship, determining where to focus your development can feel bewildering.	content management system;data curation;digital curation;digital library;librarian;library (computing);radar;web development	Madely du Preez	2014	The Electronic Library	10.1108/EL-11-2013-0199	digital library;computer science;multimedia;world wide web	HCI	-70.57113959397856	-20.507386424595214	112191
3b33dcd203777e3391af5bf8e335e05ed311f83a	a call for research on home users' information security behaviour		The number of home computer users is increasing faster than ever. Home users’ security should be an important research topic in IS security research, not only from the perspective of protecting home users’ personal or work information on their home computers, but also because hijacked home computers have become an ideal breading ground for hackers attacking organizations, and distributing illegal or morally questionable material. Despite the importance of studying home users’ security behaviour, the primary focus of the behavioural IS security research has been on an organizational context. While this research at an organizational context is important, we argue that the “home users” context require more attention by scholars. While there are similarities between “home users’ IS security behaviour” and “employees’ compliance with IS security procedures at organizational context”, it is necessary to understand their differences, to allow research and practice on “home users security behaviour” to develop further. We argue that previous research has not paid attention to such differences. As a first step in remedying the gap in our understanding, we first theorise these differences, we consider, that there are at least nine contextual factors that may result in an individual’s behaviour inconsistency in the workplace and home, and because of this, we argue that the same theories may not explain the use of security features in home and organizational contexts. Based on this conceptualization, we present a research agenda for studying home users’ security behaviour.	computer;conceptualization (information science);information security;theory;user (computing)	Ying Li;Mikko T. Siponen	2011				HCI	-73.59310633198636	-11.709335066910725	112201
c2f2e2757cdc3cd4d694a5bc5fc1535f417839a5	code as ritualized poetry: the tactics of the transborder immigrant tool				Mark C. Marino	2013	Digital Humanities Quarterly		computer science;immigration;poetry;anthropology	Logic	-64.13254895321862	-11.598992332348995	112266
d330dd0ef4c3603c3d57f064915b7c133984970d	expanding scientific community reach based on web access data		Knowing the main characteristics of a scientific community, how it reaches all stakeholders, and understanding how individuals engage around a subject is needed in order to support decision makers to plan strategies to maintain and nurture the community. This work presents a new way of interpreting the reach of a scientific community by incorporating Web access data to the co-author network commonly considered. The case presented involves the Brazilian Human-Computer Interaction (HCI) community and the access to the website of the XV Brazilian Symposium on Human Factors in Computer Systems, the main HCI conference in Brazil. The proposed method is grounded on Organizational Semiotics and differs from the existing works because it considers a wider population than the conference authors. Inspired by the Organizational Onion, it considers three different levels of connection: Informal, Formal, and Technical. In the presented case, the reach commonly used (i.e., author-author network) counts on 257 authors while the total of people orbiting the event involved 5,432 unique visitors, in other words, the co-author network represents approximately 5% of the population orbiting the event. The presented method shows that data originated from Web accesses support a different way of representing a scientific community reach, including multiple segments that are commonly not considered as the target-audience, resulting in a more inclusive approach in the sense of considering the plurality of people orbiting an event, mediated or not by a computer. Our contribution shows a data informed approach of expanding the scientific community reach in order to characterize people orbiting the conference.		Vagner Figuerêdo de Santana;Leandro Marega Ferreira Otani	2017		10.1007/978-3-319-58524-6_38	semiotics;data science;world wide web;nature versus nurture;unique visitor;social network;population;computer science	HPC	-71.48941250333546	-17.864063012078955	112369
60f88a5edeca588847c5c62dfa165057f5e67816	global memory net: new collaboration, new activities and new potentials	science and technology;digital library;information access;interactive multimedia;biblioteca electronica;digital content;electronic library;bibliotheque electronique	In technological terms, it has been a long time since my PROJECT EMPEROR-I -a multimedia interactive videodisc project on the First Emperor of China’s famous terracotta warriors and horses in 1984. At that time, PROJECT EMPEROR-I demonstrated that multimedia technology could change the way we seek, demand, and use information. Two decade later, fueled by enormous progress in science and technology, we have come a very long way from the use of interactive multimedia technology in the workstation environment to the global networked environment. We have moved from the use of hardcopy and analog resources to digital content, which users can search, retrieve and use instantly to meet their needs over the global network with no national boundaries. We have also moved from the offering of multimedia content of one specific subject topic to the digital content of all media formats on all related subject topics to the world instantly. We are truly living in a new period of unprecedented opportunities and challenges [1]! So, in this digital era, we have witnessed the exciting convergence of content, technology, and global collaboration in the development of digital libraries [2] with great potential for providing universal information access.	digital library;digital recording;global network;information access;library (computing);workstation	Ching-chih Chen	2004		10.1007/978-3-540-30544-6_8	digital library;simulation;computer science;artificial intelligence;operating system;database;distributed computing;multimedia;interactive media;world wide web;computer security;science, technology and society	HCI	-69.95860791285295	-20.25678221031918	112465
86bd3ad32d08e093da8657883c3de9443d280820	a rationale of digital documentary editions	tei;digital editing;documentary editing;xml;scholarly editing	Publishing the diplomatic edition of a document on the web instead of in print implies a series of methodological and practical changes in the nature of the published text and in the operations to be performed by the editors. For print the choice of which features to include in the transcription is limited largely by the limits of the publishing technology. In contrast, the digital medium has proved to be much more permissive and so editors need new scholarly guidelines to establish ‘where to stop’. This article discusses a list of criteria and parameters for choosing which features to include in transcriptions. It also sketches the theoretical implications which result from the change of medium and technology. It is argued that the very definition of ‘diplomatic edition’ needs to be substantially revised if the edition is published on the web. Even more importantly, the discussion argues for the existence of a new editorial object which is generated by the changed conditions: a new publication form called the ‘digital documentary edition’ which is composed of the source, the outputs and the tools able to produce and display them. .................................................................................................................................................................................	design rationale;diplomatic bag;transcription (software)	Elena Pierazzo	2011	LLC	10.1093/llc/fqr033	xml;computer science;world wide web	Graphics	-64.35630641605205	-21.65757460281364	112466
ccc9ba0787fb3533661fccc29370d750f1feb82f	the speed of dissemination of information about the realization of the fourth passive electronic circuit element measured by google hits	fundamental variable;result list;incoming link;exponential expression;hourly scale	This paper aims to demonstrate briefly that major scientific achievements spread through the Internet according to an exponential expression until a saturation point.	electrical element;electronic circuit;internet;time complexity	Imre Mojzes;Zoltán B. Farkas	2008	Scientometrics	10.1007/s11192-008-2206-5	simulation;world wide web	DB	-68.96971019825764	-17.216430306142144	112476
9d595f0b37d3dff497f93f7431b196a98ef3a4c5	distribution of scientific productivity: ambiguities in the assignment of author rank	bibliometrie;signature analysis;scientometrics;correlacion rango;metodologia;analyse signature;analisis cuantitativo;sciences;correlation rang;bibliometria;chercheur;distribucion estadistica;methodologie;ciencia;scientific production;product distribution;research worker;distribution statistique;analyse quantitative;auteur;scientometria;productivite auteur;autor;scientometrie;bibliometrics;quantitative analysis;author;productividad autor;investigator;methodology;rank correlation;statistical distribution;author productivity	Methodological implications of four accounting procedures applied in multiple authorship treatment relating to author productivity distribution were investigated. The emphasis was given to the individual author rank and inequality pattern of data. It was found that similar pattern of inequality holds in three of the four analysed cases, in spite of the fact that significant changes were observed on the individual level. By introducing the concept of dual approach a plausible interpretation of that phenomenon was obtained.	social inequality	Nevenka Pravdic;Vesna Oluic-Vukovic	1991	Scientometrics	10.1007/BF02018151	probability distribution;econometrics;product distribution;bibliometrics;scientometrics;computer science;quantitative analysis;methodology;mathematics;operations research;auteur theory;rank correlation;statistics	ML	-76.34685606072301	-22.7620153862859	112538
e6da85294efb77ca45c42f8e922b442419120614	the authorship and country spread of operation research journals	ncku 成功大學 成大 圖書館 機構典藏;operations research;dissertations and theses journal referred papers conference papers nsc reserach report patent nckur ir ncku institutional repostiory 博碩士論文 期刊論文 國科會研究報告 專利 成大機構典藏	This paper surveys 56 internationally renowned OR journals published in 1996–2005 with regard to authorship. Our findings show that the USA was the country that contributed the largest amount, approximately one-third, of research results to OR journals. Authors tend to publish papers in their home-country journals. Journal of the Operations Research Society of Japan has the highest author concentration, with more than 85% of the authors from Japan and European Journal of Operational Research, on the contrary, has the widest country spread of its authors. The entropy measure provides a whole picture of the share of all countries, based on which the editorial policy of a journal can be adjusted.	categorization;entropy (information theory);global optimization;information sciences institute;mathematical optimization;operations research;reliability engineering;scientometrics;system safety	Chiang Kao	2008	Scientometrics	10.1007/s11192-008-1850-0	computer science;management;operations research	Crypto	-76.18311360702056	-20.493045577067594	112543
2e2dd11715e89b6f0261bcbf77e254a7220916bf	lessons amid the rubble: an introduction to post-disaster engineering and ethics [book reviews]	ethics;human factors;accidents;book reviews terrorism accidents human factors safety structural engineering disasters ethics disasters;structural engineering;safety;book reviews;disasters;terrorism	For years, engineer and author Henry Petroski has been reminding us that engineers can learn from failures as much or more than they can learn from success. The author here has taken at his word in this book. The author uses the events of September 11, 2001, as the basis for an extended and historically-informed meditation on what engineers can learn from the disaster of the World Trade Center attacks. The result is a book that can be read fruitfully by audiences as diverse as undergraduate engineers studying engineering ethics, and historians concerned about the ramifications to engineering of the failures?and successes of such atrocities. This book is much more than a critical review of the technical details of the 9/11 attacks. One of the major themes is the conflicts and even contradictions built into the profession of engineering.		Karl D. Stephan	2012	IEEE Technol. Soc. Mag.	10.1109/MTS.2012.2188702	engineering ethics;disaster;ethics;computer science;engineering;human factors and ergonomics;sociology;terrorism;operations research;law;computer security	DB	-68.77778136920196	-12.86360797666006	112551
2b0ca1e4c43dd34f51b881b1b9bcfd92517f6caa	data mining technology across academic disciplines	information science;informing science;higher education;datamining;data mining;content analysis;courses	University courses in data mining across the United States are taught primarily in departments of business, computer science/engineering, statistics, and library/information science. Faculty in each of these departments teach data mining with a unique emphasis, although there is considerable overlap relative to course offerings, terminology, technology, resources, and faculty publications. Content analysis research aims to describe in detail the range of data mining technology differences and overlap across academic disciplines.	computer science;data mining;information science	Lesley Farmer	2011		10.1145/1940761.1940830	library science;computer science;data science;data mining	ML	-72.86434438971747	-20.40866639305439	112689
421b36e390dcef0e436ce622ffa6b94724d6fe7d	digital cities		The forms that cities take, the ways they function, and the mixes and distributions of activities within them have always been influenced very strongly by the capabilities of their underlying network infrastructures. Furthermore, cities have often been transformed by the introduction of new infrastructures. It is impossible to imagine Rotterdam without its canals and connection to the North Sea, Chicago without its railroads, Los Angeles without its freeways, or any large modern city without water supply, sewage, electrical, and telephone networks. Today, a new type of network infrastructure — high speed digital telecommunications — is being overlaid on cities everywhere. Its effects will be at least as revolutionary as those of the new network infrastructures of the past. It is already causing traditional building types and neighborhood patterns to fragment, recombine, and form startling new arrangements. This process will continue and accelerate. In this paper I describe the new digital infrastructure, analyze its major spatial effects, consider some illustrative examples of the resulting fragmentation and recombination, and discuss possible design responses with particular attention to social equity and long-term sustainability. Digital cities are being developed all over the world. Digital cities integrate urban Let us ask some fundamental, practical questions about the role of digital telecommunications and ubiquitous computation in shaping our future cities. What new opportunities do these technologies provide to produce cities that are attractive, equitable, and sustainable? What unwanted side-effects must we contend with? And what strategies should architects, urban designers, and urban planners pursue to take maximum positive advantage of the potential benefits while avoiding the possible downsides?1 Network Infrastructures We can best approach these questions, I believe, by reflecting upon the roles of earlier network infrastructures — water supply and sewer systems, streets and roads, canals, railroads, electrical grids, telegraph, telephone, and broadcast systems — in forming urban structures and patterns. Most obviously, these networks augment the 1 These strategies are discussed in more detail, with extensive supporting documentation, in William J. Mitchell, City of Bits: Space, Place, and the Infobahn (MIT Press, 1994), and William J. Mitchell, E-topia: Urban Life, Jim — But Not As We Know It (MIT Press, 1999). 2 William J. Mitchell affordances of the places they serve, and so support activities that would not otherwise be possible there. Furthermore, they allow greater concentration of human activities by connecting urban locations to distant hinterlands. Thus, for example, a piped water supply system allows habitation of sites that would otherwise be too barren to support life. And, by drawing upon a far-flung catchment area, it can support a much greater population than local water resources would otherwise allow. Similarly, sewer systems disperse waste that would otherwise accumulate locally, road systems allow trade with the food-producing countryside and other cities, electrical supply systems mitigate the effects of darkness and climatic extremes, and so on. We have to consider not only the immediate effects of particular networks, but also the ways in which multiple networks interact to produce joint effects. An irrigation network might allow a desert location to produce crops, for instance, but it is also necessary to have road or rail access to get those crops to market. Water supply and transportation networks may allow population to concentrate at a location, but this population will not be sustainable unless there is also effective waste removal. As geographers and planners have long-since discovered, the interactions of these networks with patterns of land use are complex. On the one hand, construction of networks creates the possibility of new land uses at the locations served. On the other, existing land uses generate demands for network service. Urban spatial development is best understood, then, as a recursive process, unfolding over lengthy periods of time, in which network infrastructures and land-use patterns evolve by continually responding to one another. When a new type of network infrastructure emerges, it is not deployed across homogeneous terrain; it is overlaid on a spatial pattern that has developed in response to its predecessors. Typically, by creating new relationships among existing activities and introducing new activities, new network infrastructures produce significant transformations of such existing patterns. Since the industrial revolution, in particular, we have seen the effects of overlaying modern transportation, electrical supply, and telephone systems on older urban fabrics. Conversely, we have also seen the effects of removing network infrastructure or getting bypassed by it; there are numerous sad examples of towns and cities that have declined when railway or riverboat service ceased, or when interstate highways passed them by. What, then, are the effects of overlaying digital telecommunications on existing urban patterns? How will this new type of network interact with existing ones? And what sorts of transformations can we expect to result? Fragmentation and Recombination The basic function of digital telecommunications, of course, is to allow human interaction at a distance. To the extent that remote interaction successfully substitutes Designing the Digital City 3 for face-to-face, traditional requirements for adjacency among activities — the bonds that have always held buildings, neighborhoods, and cities together — are eliminated. However, only some — by no means all — such bonds are loosened or removed. You may now do your banking remotely, for example, thus eliminating the need for faceto-face interaction with a teller at a local branch bank. But, if you want to get your hair cut, you still need to go to the hairdresser’s for a face-to-face interaction. The net effect is neither decentralization of everything nor rampant centralization (as some early commentators had suggested), but a complex process of fragmentation and recombination of familiar building types and urban patterns. It is much like a chemical reaction in which some bonds are broken, others remain, new ones form, and a new compound — with interesting new properties — results. Consider, for example, the now-familiar effects of online bookselling. By making use of Web sites instead of traditional sales floors, online book retailers such as Amazon.com radically decentralize the activities of browsing and purchasing; instead of taking place in a few retail establishments at central locations, these activities are distributed to Internet-serviced desktops in huge numbers of homes and offices. The space to accommodate these activities, which had once been grouped with other retail space, now fragments and recombines with domestic space and work space. At the same time, book storage and distribution functions equally dramatically centralize. They no longer need to be clustered with browsing and purchasing, as in a traditional bookstore, but are now performed at a few national centers located at convenient air transportation hubs; this allows both economies of scale and maintenance of much larger stocks than are possible in scarce and expensive urban retail space. And backoffice functions such as billing and stock control, which reduce to manipulation of digital data, no longer need to near either the books or the customers, and can float free to wherever teleworkers are available at a price the management is willing to pay. There are implications not only for location of activities, but also for transportation demand. With old-fashioned bookstores, books were delivered in bulk to the stores (that is, to intermediate storage points), then carried away by purchasers. With online bookstores, the emphasis shifts to express package delivery from the national distribution center to widely scattered homes and workplaces. You can carry out this sort of analysis for just about any of the emerging online retailing or service industries, and the results vary according to the natures of the particular products or services offered. Books are small, high value, imperishable, and a delivery time of a day or two is generally acceptable, so national distribution centers make sense. The same goes for music CDs, videos, consumer electronics, and many drugstore items. But groceries are bulkier, less valuable, and more perishable, so they demand regional distribution centers rather than national ones, and fleets of specialized local delivery vans rather than national package express systems. Hot pizzas are even more perishable, and require nearby local production and distribution centers. On the other hand, computer software, digital music recordings, and digital videos can be delivered online (provided that the bandwidth is sufficient), so the distribution centers can be located just about anywhere there’s good network service, and telecommunication does not just restructure transportation requirements but completely substitutes for transportation. 4 William J. Mitchell Finally, we should not forget that delivery points for products and services — homes and workplaces in particular — are likely to change in response to their new roles within these systems. At the very least, they need network connections for placing orders; today, these typically take the form of PCs running Web browsers, but we are likely to see increasing use of smart appliances and closets that electronically order their own supplies, and sensor-equipped spaces that can summon medical and security services. The humble mailbox is likely to evolve into a larger and more sophisticated repository that can keep perishable goods from deteriorating and keep high-value goods secure. And home TVs, VCRs, CD players, radios, and videogame conso	centralisation;computation;crossover (genetic algorithm);digital data;digital video;documentation;electronic billing;emergence;expect;fragmentation (computing);goto;information superhighway;interaction;inventory control;mitchell corporation;noise shaping;online book;online shopping;personal computer;pipeline (unix);purchasing;recursion;requirement;software repository;spatiotemporal pattern;telecommuting;towns;unfolding (dsp implementation);videocassette recorder	Jan van Leeuwen;Toru Ishida;Katherine Isbister	2000		10.1007/3-540-46422-0		HCI	-68.48722096279099	-21.650531110807368	112771
581f74307bdae825cb9e0fc197f221c6f0d21303	patent applications of the top 500 foreign investment corporations in china	mercado economico;base donnee;technological innovation;economic market;analisis datos;intellectual property;chine;database;base dato;econometria;recherche developpement;data mining;data analysis;research and development;innovation;inversion extranjero;asie;fouille donnee;investigacion desarrollo;patents;marche economique;people s republic of china;foreign investment;analyse donnee;investissement etranger;econometrics;patente;china;innovacion;brevet;busca dato;econometrie;asia	The paper focuses on the Top 500 foreign investment corporations (FICs) in China, by conducting data mining and system searching on the data-base of patent from the State Intellectual Property Office of the People's Republic of China (SIPO). Structure of patent applications, industrial distribution of patent applications, monopolistic tendency, technological innovation of Chinese companies and directions of foreign investment are studied.	data mining;database;foreign key;top500	Yun Liu;Guo-ping Cheng;Yu Kyung Yang	2006	Scientometrics	10.1007/s11192-006-0089-x	innovation;development economics;economics;data mining;chine;economy;data analysis;economic growth;china;intellectual property	ML	-74.11151774641473	-22.736197664910804	112810
25f81f927041f307dc1ba66078540f630853e067	hartmut kliemt: philosophy and economics i. methods and models - oldenbourg, munich, 2009, x + 157 p	modeling technique;game theory;political science;political economy;social science;rational choice;decision theory;point of view;distributive justice;equilibrium analysis;government intervention	Tobin exclaimed at Nozick: “There’s nothing more dangerous than a philosopher who’s learned a little bit of economics.” To which Nozick immediately responded: “Unless it’s an economist who hasn’t learned any philosophy.” (Hutchison 1996, p. 187) Insight into the dangers which, Tobin and Nozick jointly suggest, emanate from the disjunction between philosophy and economics has prompted, among other efforts, the establishment of interdisciplinary journals and degree programs. The fact that the two disciplines (and political science) share fundamental issues, such as distributive justice, welfare, or government intervention in market processes and techniques such as equilibrium analysis (or, more recently, simulation) has always offered wide scope for productive engagement. Yet today, in contrast to the late seventeenth and the eighteenth century when philosopher–economists, such as Locke, Hume, and Smith launched modern political economy, a common language needs to be found to tap this potential. Over the past decades, decision theory and classical game theory—or, more generally, the concept of rational behavior—have emerged as lingua franca that connects philosophy and various disciplines of the social sciences with each other. Hartmut Kliemt, in the first volume of his projected two-volume text Philosophy and Economics, puts the rational choice approach, the core method of economics, into a philosophical perspective. Essentially, his argument consists of three parts: the starting point is the observation that human (inter-)action can be looked at from a participant’s or from an external observer’s point of view. In a second step, having introduced basic modeling techniques in decision and game theory, Kliemt points out limitations	hartmut neven	Nicola Maaser	2010	Social Choice and Welfare	10.1007/s00355-010-0459-4	economic interventionism;game theory;positive political theory;social science;economics;decision theory;public economics;political science;microeconomics	AI	-70.9004915407343	-14.91679404427005	112814
dac58aed391bda85df54ca46848ebad0f9121716	a research on architecture of digital publishing management system	management system	With the development of digital technology, while digital publishing provide convenience for people to access to information it also influences the management mode of traditional copyrights and challenges current copyrights system. In this context, how to protect digital copyrights and promote the healthy development of digital publishing industry through the creation, management, protection and application of copyrights have become the common concerns to the fields of management, intellectual property and digital publishing industry.	digital electronics;freedom of information laws by country;management system	Yu Tian;Jingliang Chen	2010	Computer and Information Science		digital transformation;computer science;management system	HCI	-72.50696390248653	-13.701553553501912	112836
084674b8f02736c8022afdae5efc05ddf173b612	comparative study of physics research in india and china based oninspec-physics for 1990 and 1995	analyse bibliometrique;inspec;indicator;physique;indicateur;facteur impact;factor impacto;impact factor;estudio comparativo;chine;annee 1995;fisica;annee 1990;recherche;etude comparative;physics;asie;science citation index;productivite auteur;indexation;indicador;comparative study;bibliometric analysis;productividad autor;china;investigacion;sci sciences citation index;india;author productivity;asia;inde;analisis bibliometrico	The status of physics research in India and China has been examined by using bibliometric indicators. The study is based on publication data drawn fromINSPEC-Physics for 1990 and 1995. China is ahead of India in terms of publication output. It ranks 7th in the world, whereas India is placed at 10th position. China is also ahead of India in terms of growth in its publications appearing particularly in the SCI (Science Citation Index) indexed journals. Despite its second position in publication count, India leads China in terms of average impact per paper computed using data on impact factor of the citing journals. It maintains this leading position both in 1990 and 1995. In addition, the study suggests a strategy for identifying leading areas of research in physics.	bibliometrics;citation index	S. M. Dhawan	1998	Scientometrics	10.1007/BF02457407	demography;chine;china	NLP	-75.60143581765584	-22.297723539633004	113016
76c8815c6b4c93f2a07a2d2832a45104fd05f95d	playing the feminine card: women of the early modern map trade	femmes;commerce de l impression des cartes;map printing trade;image;france;england;women;editeurs cartographiques;angleterre;map publishers;engravers;graveurs	Images of allegorical women have often appeared on maps or in atlas frontispieces as objects in need of security provided by male protectors or as the counterpoint, objects to be dominated by male possessors. Exploring the role of women in the early modern map trade initially reveals not only a similar male dominance but also similar calls for protection. Nearly 10 years ago, Alice Hudson and Mary McMichael Ritzlin produced a checklist of about 300 pre-twentieth-century women in cartography. The present work contributes to the further investigation of some of these women in the early modern map trade and studies in the allied field of book printing, and more general works on women in commercial trade provide the framework for this piece. Women in the map trade were quite cognizant of the challenges of their gender and used a feminine discourse – that is, they played the feminine card – when it served their interests. All of these women, however, participated in the male discourse of the corporate community, which entailed not only making contracts and partnerships and advertising and producing new works but also making use of the social network within the trade, as well as exploiting the patronage connections cultivated by their husbands before them.	cartography;hudson;map;mary tsingou;printing;social network	Christine M. Petto	2009	Cartographica	10.3138/carto.44.2.67	psychology;geography;computer science;image;mathematics;sociology;cartography	HCI	-65.94682208082962	-12.130674060058691	113026
5fb0b380b2a02999d33bdc4bcae198ab8e658903	personal health information-seeking: a qualitative review of the literature		This qualitative review establishes Personal Health Information-Seeking (PHIS) as a more accurate description of the patient and health education information-seeking activity commonly known as Consumer Health Information Seeking. This review introduces multiple knowledge or domain facets which need to be considered in order to understand the complexities of this behavior by providing a brief overview of key empirical and theoretical work framed around Metoyer-Duran's ethnolinguistic community information theoretical model originally published in 1991, which should guide PHIS system development.	choice behavior;community;domain analysis;freedom of information laws by country;hyaluronidase;information access;information seeking;patients;scientific publication;structure of articular surface of bone;theory	P. Zoë Stavri	2001	Studies in health technology and informatics	10.3233/978-1-60750-928-8-1484	knowledge management;medicine;information seeking	HCI	-74.63171145803128	-17.468575871229376	113088
cfd4a5f6d857659cfb949782a13f97e72a1e721e	what's the right economics for cyberspace?		DigMaster is an online experiment in the publication of archaeological materials. The intent is to test whether electronic publishing will meet several needs of the archaeological community, including a more robust presentation of archaeological data, prompt publication, and collaboration between researchers working on related excavation projects.	cyberspace	Michael H. Goldhaber	1997	First Monday		multimedia;world wide web	Crypto	-69.37924169536191	-20.780789515768504	113221
b377d38c2fb3bf7a820b768fe1bb71971a27c59f	qualitative research in information systems	information system;qualitative research;ethnography;research methodology;hermeneutics;discourse analysis;action research	Qualitative research involves the use of qualitative data, such as interviews, documents, and participant observation, to understand and explain social phenomena. As the focus of information systems research shifts from technological to managerial and organizational issues, qualitative research methods become increasingly useful. This example of living scholarship within MISQ Discoveryu0027s worldwide web archive provides an overview of qualitative research for the newcomer and a set of resources for those more experienced. The work discusses philosophical perspectives that can inform qualitative research, qualitative research methods, techniques, and modes of analysis. Links to citation lists, Internet resources, software tools, and calls for papers are also included.	information system	Liisa von Hellens;Jenine P. Beekhuyzen;Don V. Kerr	2006	Australasian J. of Inf. Systems		social science;qualitative research;discourse analysis;action research;methodology;sociology;ethnography;hermeneutics;anthropology;information system	Logic	-75.01666893723397	-17.517730162981707	113231
6ca65d1ace3a0589d3dd6371834d760874be0c5f	on commercial expert systems projects	expert system	ion level). Keep reminding that the limitations of expert systems come from the limitations of the knowledge base. Try to complete technology transfer at the end of version 1.0, especially by providing the generalization concepts to be used in version 2.0. Introducing new technologies takes time. This applies even more to AI techniques because they change relationships between groups in companies. Compromises accepted in order to maintain traditional relations will degrade the overall impact of expert systems. Better informations, better technology transfer are the right answers to this danger.	expert system;knowledge base	H. Marchand	1986	Future Generation Comp. Syst.	10.1016/0167-739X(86)90020-8	computer science;knowledge management;artificial intelligence;database;subject-matter expert;computer security;expert system	AI	-66.7124322731446	-23.744296182318216	113243
e53b938661713d85f6f2fc2cdfdccc077bf9aaff	greek national spatial data infrastructure. attempts towards design and implementation		Spatial Data Infrastructure (SDI) is a long term, evolving process without a priori known results. Different countries try to develop a National SDI (NSDI) not always with a successful outcome. Although the successes are presented thoroughly (e.g. SDI best practice), it is equally important to highlight unsuccessful efforts in order to comprehensively examine different aspects of the SDI development and to acquire a more holistic approach and integrated perspective on the subject. The first Greek NSDI effort that is presented in this paper is an example of an unfruitful first attempt. Examination and assessment of this effort, lead to interesting and hopefully constructive conclusions towards a broader understanding of the SDI development. In order to assess this first effort, we define three main periods in the Greek spatial data evolution. In this paper only the first two periods are thoroughly analyzed, since the third and most recent one is still shaping. The study of the two periods showed that people, concepts and inadequacies of the first period appeared also during the second one, forming a kind of pattern. The discussion of aspects that influenced and characterized this effort reveal the multiple difficulties and problems the Greek NSDI development had to face. This work is licensed under the Creative Commons Attribution-Non commercial Works 3.0 License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/3.0/ or send a letter to Creative Commons, 543 Howard Street, 5 th Floor, San Francisco, California, 94105, USA. DOI: 10.2902/1725-0463.2013.08.art2 International Journal of Spatial Data Infrastructures Research, 2013, Vol.8, 21-42 22	best practice;data infrastructure;holism;noise shaping	Panagiotis Tziachris;Maria Papadopoulou	2013	IJSDIR		constructive;business;best practice;management science;a priori and a posteriori;spatial data infrastructure	DB	-72.40846604310491	-16.913659637914662	113252
8adc739e442e2a6f616f47425afc3497e004923e	a critical look at the regulation of computer viruses	computers;virus;law;computer viruses;regulation	There is a witch-hunt taking place today. Without a deep understanding of the phenomena of computer viruses legislators are attempting, both nationally and internationally, to prohibit what they do not understand. The computer virus is both misunderstood as a concept and abused as a term. Despite this the rallying cry is that all viruses are evil and must be destroyed in the same way as witches were seen as evil in the middle ages. The uncritical criminalisation of computer viruses does not lead to a better society nor does it cure all the ills for which viruses are blamed. This paper is not a defence for viruses but it does explore the alternative uses of computer viruses of which a legislator should be aware and take into consideration when in the processes of defining the legal status of computer code.	computer virus	Mathias Klang	2003	I. J. Law and Information Technology	10.1093/ijlit/11.2.162	regulation;virus;computer science;sociology;operations research;law;computer virus	Arch	-71.06796534783025	-12.042172341260757	113265
349cdd9530f4c892164ede228633b5aa0ac8f9d6	unraveling the dynamics of digital library community: a social network analysis approach	info eu repo semantics conferenceobject πρακτικά συνeδρίου		digital library;social network analysis	Monica Sharma	2010	TCDL Bulletin		simulation;political science;data mining;world wide web	HPC	-65.36254470774433	-9.937934663967857	113328
3f195c8c57689128b352937f9b9162dea76ff368	a trading system for bidding multimedia contents on mobile devices		Recently, new interests on digital contents and UCC(User Created Content)s are growing fast through the heterogeneous interest environment. However, there have been many side-effects on those interests. The representative problems are perverting illegal copies and the distributions for personal valuable digital contents to unauthorized anonymous users. These decrease creation motivation of good contents by interfering with the growth of information technology industry and the content provider’s creative will. To resolve these problems, in the paper, we propose a novel auction system for multimedia contents and bidding processes. We call the system as “MobileAuction”. The system first regards the digital contents as the physical materials, and applies the concept of used goods onto digital contents. Especially, the auction system is based on mobile environment. We present new model of the auction process on digital contents by analyzing major algorithms among main auction processes. Finally, the performance evaluation shows that the main auction process algorithms indicate the time complexity of logarithm scale for insertions and searches even though we don’t focus on the performance of the presented system. Therefore, the performance of the system is not significantly influenced by the amount of contents even though the volume of contents in the system is increasing. Our main idea of the paper proposes a novel multimedia content auction system.	mobile operating system	Young-Ho Park	2011		10.1007/978-3-642-27204-2_10	multimedia;internet privacy;commerce	HCI	-67.74074284084308	-10.167684121150998	113330
53419ff8ca7372afb3a5f0ab6b68623f80c34d29	mandatory publications: an approach to kill 'lack of will' or 'lack of skill'?	fraudulent publications;mandatory publications;medical research in india;predatory journals;publishing ethics	The issue of 'mandatory publications' has generated serious flak about its usefulness among the various stakeholders. A lot of debate centers around the question of 'lack of will' or 'lack of skill' as a reason for the diminishing research interests among the medical faculty in India. In our view, it is the lack of will to publish good quality research which is to be blamed rather than the lack of skill to do good quality research.	mandatory - hl7definedroseproperty;mandatory access control;interest	Neelam Dehal;Kewal Krishan;Tanuj Kanchan;Amarjeet Singh	2018	Science and engineering ethics	10.1007/s11948-017-9903-5	public relations;management;social psychology	DB	-73.56610193589529	-15.890024264768238	114333
297bbda475d877639f36feb26f8c851443f89c17	applications of mash-ups for a digital journal	electronic journal;t technology general;za information resources;q science general;area of interest;it management	The WWW is currently experiencing a revolutionary growth due to numerous emerging tools, techniques and concepts. Digital journals thus need to transform themselves to cope with this evolution of the web. With their growing information size and access, conventional techniques for managing a journal and supporting authors and readers are becoming insufficient. Journals of the future need to provide innovative administrative tools in helping its managers to ensure quality. They also need to provide better facilities for assisting authors and readers in making decisions regarding their submission of papers and in providing novel navigational features for finding relevant publications and collaborators in particular areas of interest. In this paper, we explore an innovative solution to address these problems by using an emerging Web 2.0 technology. We explore the application of mash-ups for J.UCS the Journal of Universal Computer Science and encourage readers and authors to try out the applications (see section 11 Conclusions). J.UCS can then serve as a model for contemporary electronic journals.	computer science;mash-1;mashup (web application hybrid);programming paradigm;www;web 2.0;world wide web	Muhammad Salman Khan;Narayanan Kulathuramaiyer;Hermann A. Maurer	2008	J. UCS	10.3217/jucs-014-10-1695	information technology management;computer science;artificial intelligence;software engineering;data mining;multimedia;world wide web	DB	-69.03099614589959	-16.365876307185054	114344
0ff86f2858717f12c5b71c06703510e9566dbbc7	scientific forensics: how the office of research integrity can assist institutional investigations of research misconduct during oversight review	research misconduct;best practice;ori;public health service;analytical method;scientific forensics	The Division of Investigative Oversight within the U.S. Office of Research Integrity (ORI) is responsible for conducting oversight review of institutional inquiries and investigations of possible research misconduct. It is also responsible for determining whether Public Health Service findings of research misconduct are warranted. Although ORI findings rely primarily on the scope and quality of the institution's analyses and determinations, ORI often has been able to strengthen the original findings by employing a variety of analytical methods, often computer based. Although ORI does not conduct inquiries or investigations, it has broad authority to provide assistance to institutions at all stages of their reviews of allegations. This assistance can range from providing advice on best practices, to legal assistance, to suggestions for how best to investigate specific allegations. When asked, ORI can also conduct certain forensic analyses, such as a statistical examination of questioned digits or a simple examination of a questioned figure in Photoshop. ORI will not provide opinions or render judgment on such analyses while the institution is still conducting its investigation. Such analyses can be done without knowing much else about the case.	adjudication;adobe photoshop;assistive technology;behavior;best practice;book;computer hard disc;data collection;denial (psychology);digit structure;disk storage;forensic medicine;hard disk drive;hospital admission;pallister-hall syndrome;personal handy-phone system;protocols documentation;replication origin;review [publication type];sensor;stolen product;united states indian health service;united states office of research integrity	John E. Dahlberg;Nancy M. Davidian	2010	Science and engineering ethics	10.1007/s11948-010-9208-4	public relations;engineering ethics;scientific misconduct;medicine;economics;engineering;management;law;best practice	HCI	-72.40153923588723	-13.824228526528476	114763
11c3355b53e0f09d526fe77a35f31c694a64db91	decision-making in libraries: e-book product selection practices in u.s. academic libraries			e-book;library (computing)	Mei Zhang	2017		10.1002/pra2.2017.14505401183		PL	-62.94342256003956	-9.941753081155069	114827
1b6157ffd57bfa55be4b2fb841514cf8dc46aa6e	beyond systems: in search of poietic thinking		In pursuing the debate on technology and society, we may observe how seeing technological worlds as cultural visions enables us to reflect on the paradoxical process of viewing technology as part of a hope for a more sustainable and human-centred future, and as an instrument of surveillance, violence and catastrophes. At the same time, we wonder whether we are witnessing an historic re-materialisation within the new digital economy, dominated by the culture of standardisation and technological determinism, resulting in cognitive and material divisions. A further thinking on these arguments leads us to reflect on how self could be perceived in the ubiquitous environment, and whether selves distributed across information networks could essentially be constituted through information, and what that implies for any boundary between the self and the other. This continuing march of the intrusion of immersive technologies in our lives at times makes us feel displaced, distracted and fragmented in the cyber space, but at the same time invites us to see our identities in newly responsible, intricate and open-minded ways, opening up dimensions of diversity, plurality and contingency. This paradox is disbursing the established architecture of system thinking, and even showing strains of systemic thinking in coping with the opening of doors of new possibilities and closing of windows of freedom. There is a wide ranging concern whether prevalent intellectual architectures, organisational structures and policy institutions are geared towards coping with distributed selves, identities, affiliations, commitments and even locations. Muligan (2014) makes a case for systemic thinking as an operational framework to study the complex challenges of our century. Building upon Maturana’s concept of autopoiesis—‘the insight that all living things exist in order to exist, and create themselves’, systemic thinking seeks a balance between rationality and emotion, the object and its environment, the part and the whole, and between the self and the other. Muligan (2014) makes a case for systemic thinking in gaining insight into some of the central questions of our times such as: ‘how do you bring the parts of a system together to sense themselves as one system?; how do you encourage the people in a system to share a diagnosis of what’s wrong?; to design improvements?; to rewire the connections between the parts of a system?; and then to make the leap to a new way of doing things?’ He notes that this sort of change is always as much a question of emotion and relationships as it is of rational design. However, he says that this change can be described, and to a degree planned and managed. He further brings to our notice, ‘life ratio’, as a measure of autopoiesis. This measure tells us how much the complexity of a system is defined by itself and how much is defined by its environment. If we follow the implication of this measure, we may argue that it limits the scope of systemic thinking in the sense that it focuses on the disjunction between the object and its environment rather than on the dynamic interplay between the object and its environment, a relational conjunction between the object and what Sha (2013) calls, the ‘stuff’. There is thus a concern that when systemic thinking is subjected to measurement, it may follow a planned and managed path. In other words, in following a rule-bound path, it may fail to deal with uncertainties which may arise during the process of systems design. Instead of recognising and using uncertainties as opportunity for creative solution, the planned and rule bound path may try to eliminate them. In this scenario, we are then back to a mechanistic vision of system thinking, the well-trodden K. S. Gill (&) University of Brighton, Brighton, UK e-mail: kgillbton@yahoo.co.uk	autopoiesis;catastrophe theory;closing (morphology);cyberspace;email;humberto maturana;immersive technology;microsoft windows;partial concurrent thinking aloud;rationality;systemics;systems design;technological determinism;whole earth 'lectronic link	Karamjit S. Gill	2014	AI & SOCIETY	10.1007/s00146-014-0576-1	contingency;epistemology;self;knowledge management;esthesic and poietic;autopoiesis;systems thinking;computer science;rationality;wonder;technological determinism	HCI	-75.3749277647581	-13.252001280221453	114882
b1b8747d9c943b4724ae8c3db253849a90a25a84	a conceptual analysis of information need	conceptual analysis;information needs;besoin utilisateur;user satisfaction information;user need;fundamental concepts;evaluation;information need;information seeking	The necessary and sufficient conditions for saying that X has a need for certain information are identified. It is concluded that an information need is a condition in which certain information contributes to the achievement of a genuine or legitimate information purpose. Information need is a relationship which obtains between information and information purposes: it is not a psychological state. Implications for research and practice are drawn from the conceptual analysis.	information needs;mental state	Richard L. Derr	1983	Inf. Process. Manage.	10.1016/0306-4573(83)90001-8	information needs;computer science;information retrieval	HPC	-73.36303752845025	-18.50877633243911	115023
0f98df85bec38a94eddd6f50c258182b47154a1d	storyspace 1	maps;links;implementation;history of computing;literature;hypermedia;support;design;storyspace;fiction;hypertext	Storyspace, a hypertext writing environment, has been widely used for writing, reading, and research for nearly fifteen years. The appearance of a new implementation provides a suitable occasion to review the design of Storyspace, both in its historical context and in the context of contemporary research. Of particular interest is the opportunity to examine its use in a variety of published documents, all created within one system, but spanning the most of the history of literary hypertext.	file spanning;hypertext;storyspace	Mark Bernstein	2002		10.1145/513338.513383	design;fiction;support;hypertext;human–computer interaction;computer science;multimedia;implementation;world wide web	Web+IR	-69.4073585002985	-20.931663742079113	115104
e9582f06dc675ee1c83f2cee17be25c618a03a05	privacy, accountability, and access in the age of the personalized campaign	legal aspects;human factors;algorithms;design;management	"""In the last eight years, there has been little progress made on updating our nation's outdated and ineffective privacy laws. While the cost of data has plummeted and entire new industries have been created around storing, analyzing, and sorting large sets of data, our legislators have done little to ensure that regulation has kept up with the pace of technological progress. Instead, they have harnessed these powerful tools to advance their own interests by transforming the way they run their campaigns.  The age of the """"personalized campaign"""" is here - and voters, whether they like it or not, are now being aggressively courted based on their attributes, habits, and behaviors. There are major implications ahead for the future of the quality of our nation's democracy. As both parties engage in an arms race to gather the most information and the most sophisticated data analytics technology, a public increasingly disillusioned with politics doesn't seem to have any meaningful way to """"opt-out.""""  Without any real legal obligation to disclose what they know and how they use the personal information they collect, campaigns have successfully been able to argue that their activities constitute """"political speech."""" A term that was once a critical and valuable protection for free speech is now used as cover for political operatives to act in a non-transparent manner. Many of the same actions used by advertisers that we see as invasive or creepy are now used by the very people we trust to govern our society.  Campaigns have reasonably argued that if they were to reveal their tactics, they would be giving away a competitive advantage that could mean the difference between victory and defeat. But this raises larger questions as what new types of barriers to entry this creates for candidates. There are serious questions as to how this will effect those who are not permitted access to these vast troves of information and those who are not able to afford the types of technology needed to now compete in a modern election. It remains to be seen how this will empower incumbents or damage third party challengers outside of the mainstream of the political process.  The """"filter bubble"""" that has created a world online where each of us sees different content and information has now come to our political process. While this can allow people to hear about the issues that an algorithm thinks they care about most, it can also serve to isolate us even further along partisan lines. When politicians are only focus on telling us the things that we want to hear, it may further degrade the integrity of the entire voting process.  Four years is a long time in the world of computing, and the technological capabilities of campaigns in 2016 are sure to dwarf what we saw in the most recent election. There are new opportunities to connect with voters while trying to identify what they care about most that can lead to a more engaging, fulfilling election -- and there are ways to make voting more relevant and efficient. But it is not without consequences.  In a process where winning is everything, will campaigns finally set up and institute the proper accountability and oversight that voters deserve."""	algorithm;coat of arms;dwarf;dot-com bubble;personalization;personally identifiable information;privacy law;sorting;world online	Tarun Wadhwa	2013		10.1145/2508436.2508460	public relations;political science;management	HCI	-72.64571292130611	-12.059048247329597	115192
ea18179af1f8e03b3cc040b7be6deb95605d34bf	signs of epistemic disruption: transformations in the knowledge system of the academic journal	ict;knowledge;management;internet;bibliography;divide;knowledge systems	This article is an overview of the current state of scholarly journals, not (just) as an activity to be described in terms if its changing processes, but more fundamentally as a pivotal point in a broader knowledge system. After locating journals in what we term the process of knowledge design, the article goes on to discuss some of the deeply disruptive aspects of the contemporary moment, which not only portend potential transformations in the form of the journal, but possibly also the knowledge systems that the journal in its heritage forms has supported. These disruptive forces are represented by changing technological, economic, distributional, geographic, interdisciplinary and social relations to knowledge. The article goes on to examine three specific breaking points. The first breaking point is in business models—the unsustainable costs and inefficiencies of traditional commercial publishing, the rise of open access and the challenge of developing sustainable publishing models. The second potential breaking point is the credibility of the peer review system: its accountability, its textual practices, the validity of its measures and its exclusionary network effects. The third breaking point is post-publication evaluation, centred primarily around citation or impact analysis. We argue that the prevailing system of impact analysis is deeply flawed. Its validity as a measure of knowledge is questionable, in which citation counts are conflated with the contribution made to knowledge, quantity is valued over quality, popularity is taken as a proxy for intellectual quality, impact is mostly measured on a short timeframe, ‘impact factors’ are aggregated for journals or departments in a way that lessens their validity further, there is a bias for and against certain article types, there are exclusionary network effects and there are accessibility distortions. Add to this reliability defects—the types of citation counted as well as counting failures and distortions—and clearly the citation analysis system is in urgent need of renewal. The article ends with suggestions towards the transformation of the academic journal and the creation of new knowledge systems: sustainable publishing models, frameworks for guardianship of intellectual property, criterionreferenced peer review, greater reflexivity in the review process, incremental knowledge refinement, more widely distributed sites of knowledge production and inclusive knowledge cultures, new types of scholarly text and more reliable use metrics. Cope http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/rt/printerFriend... 1 of 1 1/26/2011 10:59 PM	accessibility;citation analysis;david cope;distortion;knowledge-based systems;proxy server;refinement (computing)	William W. Cope;Mary Kalantzis	2009	First Monday		public relations;drainage divide;computer science;knowledge management;knowledge-based systems;sociology;knowledge;bibliography;management;law;world wide web	Web+IR	-73.84603513067634	-14.803704851448733	115253
255d0ebf1a624ff674f9338806be86e18c906598	research performance indicators for university departments: a study of an agricultural university	analyse bibliometrique;impact assessment;citation analysis;performance indicator;analisis cita;litterature scientifique;behavioral science;analyse citation;estudio impacto;etude impact;impact analysis;literatura cientifica;evaluation interpair;indexation;life sciences;bibliometric analysis;scientific literature;impact study;analisis bibliometrico	The present bibliometric study extends previous work by focusing on the research performance of departments in the natural and life sciences, the social and behavioral sciences, and the humanities. The present study covers all 70 departments from one agricultural university, and several veterinary departments of a second university. The impact analysis was extended by including other types of documents than journal articles. For about a third of the departments, publications not covered in citation indexes accounted for at least 30% of the citations to their total oeuvre. To deal with different citation and publication habits in the various fields, both short-term and medium-term impact assessments were made. The commonly used three year window is not universally applicable, as our results show. The inclusion of self-citations forms an important source of error in the ratio of actual/expected impact. To cope with this, the trend and level of self-citations was compared at university level with that in a matched sample of publications. Moreover, at a departmental level, self-citation rates were used to detect departments with divergent levels of self-citation. The expected impact of journals accounted for only 18% of the variance in actual impact. Comparison of bibliometric indicators with two peer evaluations showed that the bibliometric impact analyses provided important additional information.	bibliometrics;citation index;journal citation reports;year 2000 problem	Anton J. Nederhof;R. F. Meijer;Henk F. Moed;Anthony F. J. van Raan	1993	Scientometrics	10.1007/BF02016548	computer science;impact assessment;performance indicator;operations research;citation analysis;world wide web	HCI	-76.48927961632523	-22.421778136424976	115430
9e070cefb451ed12f03ffaed0a270af81d3532b0	entering the field in qualitative field research: a rite of passage into a complex practice world	entrance;access;interpretive field research;ethnography;fieldwork;hermeneutics	The concept of ‘the field’ is significant in ethnographic research as well as qualitativ research methods more generally. However, how a field researcher enters the field is usually taken for granted after gaining access to the field. We suggest that entrance is a distinct phase of fieldwork that differs from negotiating access. Entrance is not a trivial event; rather, it is a rite of passage into a complex practice world and marks a critical field moment. Drawing on our ethnography and insights from hermeneutics and anthropology, we show that a practical understanding of the field represents a fusion of horizons where a fieldworker is thrown. The concept of thrownness highlights the fact that the fieldworkers’ own historicity and prejudices affect their entrance into the field; hence entrance into the field orientates an ethnographer in the field and influences the entire period of fieldwork that follows. Our theorizing is intended as a contribution towards advancing the discussion of qualitative research methods. ISJ-RE-1214.R2 Information Systems Journal	field research;information systems journal;plausibility structure	Hameed Chughtai;Michael D. Myers	2017	Inf. Syst. J.	10.1111/isj.12124	psychology;social science;engineering;gender studies;sociology;ethnography;management;hermeneutics;anthropology	HCI	-73.29870172485187	-16.68482750488941	115478
88da2074b106574b6c8b54ea461707b8b4127d57	toward an alternative notion of information systems ontologies: information engineering as a hermeneutic enterprise	ciencia informacion;ontologie;information science;informing science;histoire sciences;philosophy of sciences;information organization;organizacion informacion;hermeneuticas;hermeneutics;organisation information;ontologia;information system;science information;sciences history;community involvement;ontology;systeme information;philosophie des sciences;hermeneutique;history of science;sistema informacion	In this paper we discuss the construction of information systems ontologies. We summarize and discuss Barry Smith’s review of the field in the paper “Ontology”. In that essay Smith concludes with a plea for ontologies that reflect the categories of current scientific theories because they represent our best knowledge of the world. In this context, we develop an argument for a hermeneutic approach to ontologies – one compatible with the orientation introduced into information science by Winograd and Flores and that was later developed by many others. In order to do this, we argue that the literature in the philosophy and history of science supports a hermeneutic interpretation of the nature and growth of science. This, given Smith’s argument, shows the relevance of hermeneutics to the creation of information system ontologies. The problems associated with understanding and creating information systems ontologies can be addressed fruitfully only if one begins by acknowledging that databases are mechanisms for communication involving judgments and interpretations by intelligent and knowledgeable users. The main contributions of this paper are our conclusions that (1) information system ontologies should take into consideration a perspective of the philosophy and history of science and that (2) hermeneutics as construed by Gadamer constitutes a place from which we can understand the tasks of information ontologists and database users.	coppersmith–winograd algorithm;database;information engineering;information science;information system;ontology (information science);relevance;theory	Frederico T. Fonseca;James E. Martin	2005	JASIST	10.1002/asi.20099	social science;information science;computer science;ontology;data mining;history of science;hermeneutics;information system	AI	-73.2320304497757	-18.06983023532543	115604
02a52280aa2d3ef22eeb5b08d86262e55dae8510	voip: a debate over information service or telephone application in us: a new perspective in convergence era	legislation;service provider;voice over ip;emerging technology;access charge;telecom regulation;information service;voip	As new voice-over-IP (VoIP) services rapidly emerge, a debate is growing over how the emerging technology fits into the traditional telecommunications regulation and industrial schemes. The debate on VoIP has been whether VoIP traffic should be subjected to any or all of the various common carrier regulations. VoIP sparked a regulatory debate whether it is phone call service, which will have a great impact on telecom industry's business or just information service. Because of the complexity of the issue, and the intent to let the premature technology grow, the FCC has so far taken a hands-off approach taking tentative assumption that VoIP is not a telecom service. Under the provisional hand-off approach, VoIP providers are exempt from rules that govern telecom services. However, traditional service providers argue that VoIP should be classified as a telecom service and take equal responsibilities as traditional voice calls. VoIP providers counter argue that incumbent telcos can easily dominate market driving VoIP providers out of the market. They request new legislation that protects the services from being hit with access charges from entrenched telco. This paper reviews the nature of these debates, outlines the challenges faced by regulators, briefly summarizes how other countries' views may have to adapt and offer new praxis that will benefit the consumers in the long run.		Dong Hee Shin	2006	Telematics and Informatics	10.1016/j.tele.2005.04.001	public relations;telecommunications;computer science;marketing;enhanced telecom operations map;voice over ip;advertising;management;world wide web;computer security	ECom	-73.8057194064835	-12.035146402392813	115677
d727cc8992d99c268974f751d85263d7c2626f98	citation delay in interdisciplinary knowledge exchange	analyse bibliometrique;europa;knowledge flow;intercambio informacion;citation analysis;allemagne;communication scientifique;world;interdisciplinary field;comunicacion cientifica;difusion conocimiento;dominio investigacion;research field;sciences;diffusion connaissance;analisis cita;citation;delai;ciencia;germany;analyse citation;plazo;royaume uni;echange information;knowledge dissemination;information exchange;interdisciplinaire;united kingdom;time lag;reino unido;knowledge transfer;domaine recherche;scientific communication;interdisciplinario;citacion;monde;bibliometric analysis;mundo;knowledge exchange;europe;alemania;analisis bibliometrico	As part of a larger project to investigate knowledge flows between fields of science, westudied the differences in speed of knowledge transfer within and across disciplines. The agedistribution of references in three selections of articles was analysed, including almost 800.000references in journal publications of the United Kingdom in 1992, 700.000 references inpublications of Germany in 1992, and more than 11 million references in the world total ofpublications in 1998. The rate of citing documented knowledge from other disciplines appears to differ sharplyamong disciplines. For most of the disciplines the same ratio's are found in the three data sets.Exceptions show interesting differences in the interdisciplinary nature of a field in a country. Wefind a general tendency of a citation delay in case of knowledge transfer between different fieldsof science: citations to work of the own discipline show less of a time lag than citations to work ina foreign discipline. Between disciplines typical differences in the speed of incorporatingknowledge from other disciplines are observed, which appear to be relatively independent of timeand place: for each discipline the same pattern is found in the three data sets. The disciplinespecific characteristics found in the speed of interdisciplinary knowledge transfer may be point ofdeparture for further investigations. Results may contribute to explanations of differences incitation rates of interdisciplinary research.	exception handling	Ed J. Rinia;Thed N. van Leeuwen;Eppo E. W. Bruins;Hendrik G. van Vuren;Anthony F. J. van Raan	2001	Scientometrics	10.1023/A:1010589300829	interdisciplinarity;information exchange;computer science;operations research;citation analysis;world wide web	HCI	-75.29167084647716	-22.444990687203283	115690
b9fa80c2bc165723995ce5f54e1c6aec99c9b28d	reporting ethics committee approval in public administration research	research ethics;ethics reporting;ethics approval;article;public administration	While public administration research is thriving because of increased attention to social scientific rigor, lingering problems of methods and ethics remain. This article investigates the reporting of ethics approval within public administration publications. Beginning with an overview of ethics requirements regarding research with human participants, I turn to an examination of human participants protections for public administration research. Next, I present the findings of my analysis of articles published in the top five public administration journals over the period from 2000 to 2012, noting the incidences of ethics approval reporting as well as funding reporting. In explicating the importance of ethics reporting for public administration research, as it relates to replication, reputation, and vulnerable populations, I conclude with recommendations for increasing ethics approval reporting in public administration research.		Sara R. Jordan;Phillip W. Gray	2014	Science and engineering ethics	10.1007/s11948-013-9436-5	psychology;public relations;research ethics;public administration	HCI	-73.59747421423799	-15.528572432302372	115693
33a9674b4bceee126563d07a0aa6857d3440fc05	university jewels and robbers: what are they?	university jewel	Students are the most numerous participants in academic computer systems and are the greatest source of incidents involving misuse to computer resources. There are situations in which student operations on’ academic system become such that administrative and/or legal action is a prudent course of action for the academic institution. This paper explores one situation in which student action caused appropriate intervention by academic computer personnel, academic administration, and the cooperation of law enforcement. Computer support personnel are the vital first lines of awareness for their institution. It is shown how response to a specific computer incident was and should be handled to facilitate protection of the institution, protection of the individuals involved, and the proper handling of evidence required by the institution and the legal system. The paper examines awareness of vulnerabilities, evaluation of risk to the institution, exploitation of the system by a disgruntled student, and general guidance for gathering necessary evidence for proper administrative and legal action. UNIVERSITY JEWELS AND ROBBERS: .WHAT ARE THEY ? The scope of the National Information Infrastructure Act of 1996 and other supporting legislation has broadened the areas of the “information system” that can be defined as in the national interests. America’s colleges and universities contain data that is:	computer;information system;national information infrastructure;technical support;vulnerability (computing)	John R. Cordani;Kenneth Geide;Ramón A. Mata-Toledo	1997		10.1145/266064.266087	computer science;multimedia	Security	-71.8360437058771	-10.583116858580935	115764
4f3fd9478b9d6addc83be69df1987e9665b3ce3f	topical establishment leveraging literature evolution	literature evolution;topical ranking;research and development;evolutionary computation;research topics;information analysis;scientific domain;topical establishment;ralex;pagerank;evolutionary perspective;topic clusters	From an evolutionary perspective, a body of research is an evolving ecosystem, consisting of research topics subjected to a form of natural selection as topics come into existence, and thrive more or less over a variable period of time. Identifying the form of establishment of a given topic in a scientific domain, in terms of its momentum at the time of inquiry, can provide useful insights into where this topic is heading, and can facilitate effective literature research. Here we propose to identify three forms of establishment of topics, emerging from a comparison between two different methodologies in ranking papers, taking advantage of the mutual relationship between recognition of papers and recognition of topics. More specifically, by analysing the correlation between the rankings obtained by applying both methodologies, we discover thee clusters of topics, each of which is associated with a particular momentum of establishment.	course (navigation);ecosystem;evolutionary algorithm	Han Xu;Eric Martin;Ashesh Mahidadia	2014	IEEE/ACM Joint Conference on Digital Libraries		market research;data modeling;computer science;data science;mathematical model;data mining;semantics;management science;world wide web;correlation	HPC	-76.8250311278261	-18.210669315365337	115849
562bf904eaf24b0a55be305cf2545028bcfe4845	editorial: software survey section		The purpose of the Software Survey Section fn COMPUTERS & OPERATXONS RESEARCH is to encourage the open exchange of information on software programs unique to our professional field. With the rapid penetration of computers into academic .and industrial institutions has come a parallel increase in the number of scientists and researchers designing their own software. The existence of much of this software remains unknown to even those of us who could most benefit from its use. We believe that it is of vital importance to our readers that such information be made available. We believe also that a professional journal is the best place to share such information. Pour contribution would be most welcome. COMPTJTRRS & OPERATXONS RESEARa accepts no responsibility for the quality or content of these programs, but we will welcome reader feedback.	computer	Samuel J. Raff	1987	Computers & OR	10.1016/0305-0548(87)90071-2	software quality management;computer science;engineering;knowledge management;software engineering;software walkthrough;management	SE	-63.54305486218105	-17.98473851912144	115941
c20000729f068beaff5e943d2ef8f117a067f268	risks to the public in computers and related systems		Edited by Peter G. Neumann (Risks Forum Moderator and Chairman of the ACM Committee on Computers and Public Policy), plus personal contributions by others, as indicated. Opinions expressed are individual rather than organizational, and all of the usual disclaimers apply. We address problems relating to software, as well as some cases involving hardware and other circumstances that affect computer systems. To economize on space despite the enormously increasing volume of cases, we tersify many items and include online pointers to other items in the online Risks Forum, where (S i j:p) denotes SEN vol i no j page p (2001 = volume 26), and (R i j) denotes RISKS vol i number j. RISKS items generally include e-mail addresses, phone numbers, etc., for contributors, and URLs for source materials (which because of their tendency to be ephemeral are typically omitted here). Official RISKS archives are available on ftp.sri.com, cd risks, and in the UK at http:/ /catless.ncl .ac.uk/Risks/VL.IS.html [i.e., VoLume, ISsue] with nice html formatting and a search engine courtesy of Lindsay Marshall, and http: / /the.wiretapped.net /security /textfiles/risks-digest / .	apply;archive;computer hardware;cryptographic hash function;email;google moderator;html;hypertext transfer protocol;telephone number;web search engine	Peter G. Neumann	2001	ACM SIGSOFT Software Engineering Notes	10.1145/505894.505900		Web+IR	-65.89436629859789	-17.8619004934008	116052
901f8c38e2fb8ce08d3b80b14898e6f78aad0a44	characteristics and link structure of a national scholarly web space: the case of south korea	scholarly communication;south korea;scientific knowledge	This study performs a webometric analysis to explore the communication characteristics of scientific knowledge in a national scholarly Web space comprising top ranking universities and government supported research institutions in South Korea. We found significant differences in scholarly communication activity as well as linking behavior among different subspaces in addition to institutional differences. We also found the usefulness of the ADM approach in analyzing the metric data containing extreme outliers and discovered the directory model as the most appropriate. Page counts were found significantly correlated with inlinks as well as with outlinks at the directory level in the whole scholarly Web space.	backlink;directory (computing)	Young Mee Chung;So Young Yu;Yong Kwang Kim;Su Yeon Kim	2008	Scientometrics	10.1007/s11192-008-2091-y	social science;data science;data mining;world wide web;sociology of scientific knowledge	Web+IR	-77.35344424536652	-21.048403715650238	116640
0de15c0053398982a08acea8a1757cd92c33e7e5	remote locations: early scottish scenic films and geo-databases	local topicals;scenic films;scottish cinema;cinema history;journal article;cinematic cartography;geo databases;new cinema history;geographic information systems;geo database;spatial historiography;scotland;early cinema	In the field of cinema history, an increased interest in social experience and context has challenged the centrality of the film and the primacy of textual analysis. The ‘Early Cinema in Scotland, 1896–1927’ research project takes a contextual approach, using geo-database tools to facilitate collaboration. This article shows how spatially-enabled methods can also be mobilized to bring issues of representation back into a cinema history project. We argue that, when the films have not survived, their geographical descriptors as recorded by trade-press reviews and catalogues offer new avenues of analysis. The article argues that foregrounding location as a significant element in the film corpus creates a new point of interconnection between film text and context. The juxtapositions and divergences between the spatial patterns of film production and cinema exhibition are connected to pre-cinematic traditions of representation. The spatial distribution also sheds light on the differences between films made for...	database	Maria A. Vélez-Serna;John Caughie	2015	IJHAC	10.3366/ijhac.2015.0147	humanities;history;artificial intelligence;archaeology;geographic information system;sociology;world wide web;cartography;remote sensing	Vision	-70.58885526307874	-18.959258426293715	116713
4a9af91947f532c9cb9445e7581058ab8aa5e5c8	enhancement of arabic script manuscripts and documents in spanish libraries and archives: a digitization project	archives arabic manuscripts digitization digital humanities libraries;arabic script document enhancement arabic script documentary heritage spanish libraries spanish archives spanish territory arabic script manuscript enhancement;libraries portals cultural differences indexes dispersion history documentation;records management digital libraries history information dissemination	The present project (in progress) aims first to disseminate and release the Arabic script documentary heritage that is treasured in Spain within different libraries and archives and particular collection and dispersed in through the spanish territory.	archive;library (computing)	Ismael Abder-rahman Gil	2015	2015 Digital Heritage	10.1109/DigitalHeritage.2015.7419562	speech recognition;art;multimedia;literature	NLP	-66.89293722776644	-14.018722671107113	116789
4562fa427a3d53ac8751b2818774a1087d00dfa8	applying evaluation criteria to new zealand government websites	site web;search engine;oceanie;government;recommandation;conception;nueva zelandia;criterio;criterion;evaluation criteria;critere;gobierno;diseno;information gouvernementale;nouvelle zelande;recomendacion;government information;design;recommendation;evaluation;gouvernement;evaluacion;sitio web;new zealand;websites;oceania;web site	"""Criteria for the evaluation of Government web sites were adapted from Eschenfelder, Beachboard, McClure, and Wyman ((1997) Gov. Inform. Quart. 14(2), 173) and applied to a sample of """"ve websites of NZ government entities. Issues that arose in applying the criteria are examined, and lessons for designers of government websites explored. In particular, it is important that websites provide orientation information, that conditions for re-use of information be made clear, that privacy concerns be addressed, that print materials be properly adapted to the web environment, that materials be kept current, that contact details be available, that metadata be used e!ectively, that external links be made appropriately, that pages be accessible to users with disabilities, and that help information on search engines and other facilities be made available to users. 2001 Elsevier Science Ltd. All rights reserved."""	alt attribute;e-government;entity;hypertext;interaction;internet;mediawiki;norm (social);online locator service;privacy;robot;web content accessibility guidelines;web crawler;web search engine	Alastair G. Smith	2001	Int J. Information Management	10.1016/S0268-4012(01)00006-8	public relations;design;economics;engineering;knowledge management;marketing;evaluation;data mining;management;law;world wide web;government;search engine	AI	-73.10352902827158	-23.9171786624498	116800
9b05a9ad73d207b90061a571bd450349053714c2	the user non-acceptance paradigm: infosec's dirty little secret	shannon information theory;barwise seligman information theory	"""This panel will address users' perceptions and misperceptions of the risk/benefit and benefit/nuisance ratios associated with information security products, and will grope for a solution, based on the psychology of personality trait-factoring results, among other multidisciplinary approaches, to the problem of user non-acceptance of information security products. This problem has acquired a much more scientific guise when amalgamated with the psychology of personality and reinforced by reflections from the field on patterns of user behavior. A gross simplification of the main thrust of the panel is this thesis: if we start profiling the defenders rather than the offenders and do it on the basis of real science rather than very crude personality tests, then we will, at the very least, understand what is happening and possibly create a desirable profile for sysadmins, CIOs, and perhaps even CFOs. This swept-under-the-rug problem is information security's """"dirty little secret."""" No other forum is designed to address this, and it may well become yet another major conceptual and paradigmatic shift in the field, of the type initiated in the NSPWs over the last decade. We know that the panel will generate an assured considerable interest among the participants."""	amiga reflections;information security;integer factorization;level of detail;programming paradigm;thrust;yet another	Steven J. Greenwald;Kenneth G. Olthoff;Victor Raskin;Willibald Ruch	2004		10.1145/1065907.1066032	computer science;computer security	Theory	-72.90227767724647	-11.11218175267564	116844
c6e69ef2367ebe27fc424bb0500edc4899f2b24b	client\server access: satellite-atm connectivity using a knowledge management approach	satellite communication;telecommunication computing asynchronous transfer mode authorisation client server systems knowledge management satellite communication;authorisation;information technology;department of defense;knowledge management;client server systems;telecommunication computing;role based access control;knowledge management access control access protocols protection databases data security information security communication equipment information technology military communication;client server;single unit;mid earth orbit satellite communications client server access satellite atm connectivity knowledge management secure role based access control sensitive database information protection mobile secure role base access control device ms ro bac;asynchronous transfer mode	"""Secure role-based access control (SRBAC) is an entry protocol implemented to protect sensitive database information. An individual's security clearance and role description will determine what privileges they are authorized. This manuscript provides a different approach to secure RBAC designs in a post 911 environment. In order to defend the United States against enemies, foreign and domestic, it is crucial that the combat forces of the United States are equipped with the best communication equipment available. Twenty-one years of information technology experience in a military environment supports this research and contributes a design ideology that could revolutionize the way government agencies communicate. The """"mobile secure role base access control device"""" (MS-Ro-BAC) is a single unit system with the ability to instant connect to other identical devices around the world through Mid Earth Orbit Satellite (MEO) communications. The capabilities provided by the MS-Ro-BAC research would support the 'Global War on Terrorism' and increase the security of US forces and Department of Defense Personnel around the world"""	atm turbo;authorization;batman: arkham city;communications satellite;database;knowledge management;role-based access control	Terry C. House	2007	Fourth International Conference on Information Technology (ITNG'07)	10.1109/ITNG.2007.48	computer science;operating system;asynchronous transfer mode;role-based access control;authorization;law;information technology;world wide web;computer security;communications satellite;client–server model;computer network	DB	-69.65309025000796	-11.250189830757163	116911
31546c31040af819d9cd4662b9b6a62d7eced8b2	mapping the landscape of biomedical research in nigeria since 1967	analyse bibliometrique;information biomedicale;paises en desarrollo;document publie;pays en developpement;evolucion;medical science;litterature scientifique;biomedical information;annees 1967 2002;ciencia medica;literatura cientifica;auteur;informacion biomedical;autor;published document;bibliometric analysis;author;nigeria;recherche scientifique;scientific literature;scientific research;africa;documento publicado;investigacion cientifica;developing countries;analisis bibliometrico;afrique;science medicale;evolution	This article maps the biomedical literature of Nigeria by source/origin of publications and authorships from 1967 to 2002. This mapping is expected to provide crucial information to both government and others taking funding and related decisions regarding biomedical research in Nigeria. Data was collected from MEDLINE. Scientists publishing on Nigerian biomedicine have written 6,820 articles in 295 journals/sources. Only eight of the 121 local journals that published biomedical research in Nigeria during the period were included in MEDLINE’s listing (2.72%), while there were 32 (10.84%) regional and 255 (86.44%) external journals used. Local journals appeared to be more heavily used than regional and external ones. It was also shown that MEDLINE does not adequately represent Nigeria’s biomedical literature. Learned Publishing (2005)18, 200–211 Williams Nwagwu 200 W. Nwagwu L E A R N E D P U B L I S H I N G V O L . 1 8 N O . 3 J U L Y 2 0 0 5 scientific literature from the area is too costly to undertake.	medline;map;scientific literature;williams tube	Williams Nwagwu	2005	Learned Publishing	10.1087/0953151054636219	evolution	ML	-75.05513681570692	-22.530094698210455	117023
538a20764ca159516447fe3e3ecb4c9bf2e25d39	the haiti earthquake experience: a case study	inside disaster;negotiation clouds;simulation;haiti;michael gibson;documentary;propp;fold back story;zapdramatic;role play	The author summarizes his experience creating a story-based simulation from raw documentary footage taken in the aftermath of the 2010 earthquake in Haiti. The use of Propp’s typology to create a heroic framework within which to organize the material is explained. The author introduces the concept of Negotiation Clouds to improve a fold-back story structure and create meaningful agency for the user without compromising author control of the narrative.	biological anthropology;half-life 2: episode one;simulation	Michael Gibson	2010		10.1007/978-3-642-16638-9_31	social science;computer science;artificial intelligence;sociology;management;law;literature	HCI	-66.16472759032584	-11.824271758727269	117122
459b05c1b7b8816002cf6e0813c0fa15e0a42507	psychology and security: utilizing psychological and communication theories to promote safer cloud security behaviors		The managing director is confident that he has taken all of the security measures that he needs to in order to protect his company’s cloud based data—his IT manager has tested the system, the software and hardware are the best that money can buy, and employees are given excellent training in data protection. On the day that a security breach is uncovered, he is perplexed and horrified, and he begins an investigation into why the breach occurred. Eventually, he discovers that one of his management team has used the same password for their company file access as they do for an online dating account. When the online dating service was hacked a few minutes beforehand, the infiltrators gained access to the password, and matched it to the employee. The managing director is confused—the employee training provided explicitly stated that the password for the company services should be unique, so why did this happen? While technological devices and programs form the bulk of the defense mechanisms against malicious attacks and infiltrations, the human element in cloud security must also be factored into any protection strategy. The use of weak passwords and other aspects of poor security hygiene can dramatically reduce the efficacy of technological protective measures. While users may be aware of the best methods of ensuring increased security, they are not always inclined to follow these directions, particularly where they perceive the methods involved as being difficult, inconvenient, or ineffective, or if they feel that they do not have the skills required to implement the measures. This chapter examines how various theories and research in communication and psychology can help management to understand why users may not follow best practice in cloud security, and how they can encourage users to change such behaviors. The chapter describes theories such as Communication Privacy Management (CPM) Theory, Protection Motivation Theory, and Social	best practice;blog;cloud computing security;human-readable medium;information systems;information privacy;internet privacy;john d. wiley;malware;password strength;relevance;social media;spatial variability;theory;threat (computer)	Grainne Kirwan	2015		10.1016/B978-0-12-801595-7.00013-6	psychology;simulation;security through obscurity;social psychology;computer security	Security	-71.03967241762803	-10.485254436024602	117201
0f25ac6c89817b7e2d20b11fb7dfe3ade5af9acd	information 2.0: new models of information production, distribution and consumption, 2nd edition. martin de saulles		Information 2.0: New Models of Information Production, Distribution and Consumption, 2nd Edition. Martin De Saulles. London: Facet Publishing. 2015. x + 164 pages. ISBN: 978-1-78330-009-9. Price: £49.95, US$95.00.#N##N#Martin De Saulles provides a concise, yet relatively wide-ranging, overview of the enduring issues and current crises in information and communication technologies (ICT) in Information 2.0: New Models of Information Production, Distribution and Consumption . Keenly aware of the rapidly shifting landscape of ICT, his book examines the diverse types of information created and consumed today; the role of data in society, from personal uses to mass governmental and business initiatives; the history of information technology over the past half century; and the exponentially expanding networks of corporate and governmental actors that control the access and management of ICT. And throughout, he analyzes the role of librarians and information professionals in addressing these myriad ICT issues, and the new possibilities … #N##N#  green19{at}illinois.edu		Harriett E. Green	2016	DSH	10.1093/llc/fqv055	engineering;operations management;management;operations research	OS	-67.06016323598485	-12.279430951460547	117202
8cce304685c5d9ee110049b8b9a098f18740b4d4	law of international telecommunications in the united kingdom: regulation of electronic media				Verena A.-M. Wiedemann	1989				DB	-62.95384951047093	-10.305286025678255	117204
6b7de7d45ab1e7a581b1d88aa31ea9e85204427f	samuel zimmermann's gehaimnussen: the earliest cryptological book in german	anamorphic writing;samuel zimmermann;firearms;sympathetic inks;alchemical symbols;detection of broken seals;imperial city;turkish wars;non roman alphabets;concealed messages;augsburg;master gunner;chiromantic communication;roman letters written sideways;ink and paper production	This article presents the very first cryptological manual written in German in 1579. Samuel Zimmermann’s Gehaimnussen (Secrets) has gone virtually unnoticed as it was not printed separately but was included in a manual on letter writing, New Titularbüech, more specifically a compilation of hundreds of forms of address to be used in the correspondence with nobility. In Gehaimnussen, the author (a master gunner in the employ of the city of Augsburg) shows detailed but spotty knowledge of cryptological secrets that are frequently interwoven with descriptive passages ranging from the proper use of writing utensils to the production of paper all the way to a listing of alchemical symbols. There was no second edition of either part of this dual publication.	compiler;cryptography;printing	Gerhard F. Strasser	2016	Cryptologia	10.1080/01611194.2015.1093898	computer science;algorithm	NLP	-63.785595354079824	-21.076495983227503	117248
6a3e56f4ae7f9f76f552267eba93352816314d2d	participatory democracy and information and communications technology: a legal pluralist perspective	democracy;technology;legal pluralism;digital rights management;democratisation	This article explains why democracy and the important process of democratisation include but go beyond the ambit of the state and state laws, and how democracy and democratisation are both negotiated, contested, engaged with and made up by diverse state and non-state actors within plural legal orders and across multiple sites and transnational networks. This article aims to re-imagine the conception of democracy vis-àvis information and communications technology from the perspectives of demo-diversity and legal pluralism. Furthermore, the author discusses why the transnational anti-DRM campaign is a successful example of democratisation in the digital networked environment. 1. The Democratic Promise of Technology The emergence and widespread use of information and communications technologies (ICTs) like the Internet in the 1990s gave rise to optimistic visions of a more participatory and inclusive democracy. [2] The Internet was touted as a solution to the democratic deficit that was symptomatic of the twin pathologies of lack of legitimacy and representation that hobbled most liberal representative democracies around the world. [3] Nation-states undertook various technological interventions from electronic government projects to online consultations and e-voting in order to achieve the objectives of making their governments more relevant and responsive to their citizens and fostering greater political involvement and civic consciousness in the latter. [4] However, despite the considerable attention and billions of sums spent on these techno-governmental initiatives, the aim of establishing a more participatory democracy had proved to be elusive. [5] As a result, the utopian belief in a technologically-mediated and enhanced democracy was first countered by a reactionary, dystopian view of technology, [6] which was also subsequently replaced by the currently dominant reinforcement view that sees technology as offering nothing substantially new to democracy and believes ICT merely reinforces existing political and social institutions and practices. [7] This article argues that the utopian,	ambit;consciousness;digital rights management;e-government;emergence;internet;participatory monitoring;pluralism (philosophy);tandy video information system	Michael Anthony C. Dizon	2010	European Journal of Law and Technology		political science;socioeconomics;public administration	HCI	-76.57270600191391	-12.316799515192786	117260
9267e15050d00604c818782fc28be27ee7108a48	book review: cyberpower: the culture and politics of cyberspace and the internet			cyberspace	Greg Elmer	2000	New Media & Society	10.1177/1461444800002001010	social science;sociology;cyberspace;the internet;politics	Networks	-65.14549758527924	-10.634323658539966	117334
3f251c5296f2aa1c378eaed725a4ba64061e6514	focus on education [editor's remarks]	art;computational intelligence;research and development management;usa councils;technology management;computer science education;engineering management;production;europe;usa councils production art research and development management technology management engineering management computer science education computer integrated manufacturing europe advertising;weed management;computer integrated manufacturing;advertising	Welcome to another exciting year of IEEE Computational Intelligence Magazine! Four carefully-crafted issues of CIM in 2008 were packed with the inspiring and far-reaching reads from our contributing experts in chosen areas of computational intelligence. Constrained by a limited page budget, we managed to present you with only a glimpse of this technical field and its promise and future for many years to come. As we enter the end-of-the-year holiday celebrations, I want to take this opportunity to thank our editor at IEEE, Jessica Barrague. Without her tireless efforts, I would not survive in this business. After all, I am only an engineering professor and a volunteer. What a combination of two distinct identities! On behalf of the CIM Editorial Board, I want to send my best wishes to each and every one of you for a Merry Christmas and Happy New Year. It is YOU who make this adventure any more meaningful.		Gary G. Yen	2009	IEEE Comp. Int. Mag.	10.1109/MCI.2008.931523	computer science;artificial intelligence;technology management;weed control;computational intelligence;computer-integrated manufacturing;operations research	Visualization	-64.87546646496503	-21.610441279992102	117351
be56ebe1747415dfe0392de1ca7ffe943fd2b364	interview with pádraig cunningham and barry smyth		PC: We are aware that other research communities have done this kind of thing. Particularly in the information retrieval community and in the database community they have done this kind of study and we are also aware of citation type analysis, for instance, in genomics there is some famous citation analysis that has been done there. But we thought, because we belong to this small community that has several subthemes within it, and we have come to this fifteen-year milestone, it would be useful to do a systematic analysis of our community in those terms. There are some aspects of the community that we believe are unusual, particularly that some research is overlapping and that a contribution can belong to more than one theme. So that was interesting to see if we could uncover that with the type of analysis that we did.	citation analysis;information retrieval;theme (computing)	Klaus-Dieter Althoff;Kerstin Bach	2009	KI		dispersant;metallurgy;slag;ammonium;materials science;oil well;drilling fluid;spark plug	Web+IR	-70.64675750592365	-17.786685824868993	117365
8c5b81bf183b291e3bc4cc2ad3d8fe2055c54f7c	information ecology in the context of general ecology		The ecological approach studied in this paper is a new level of information studies. It allows for achieving a better understanding of information processes in society as well as more efficient creation of information processing systems. At first, in Section 2, we describe and analyze ecological studies in different areas ranging from biology to technology to sociology to knowledge and information. Then, in Section 3, we present elements of general ecology building methodological and philosophical foundation for information ecology. In Sections 4 and 5, we elaborate a concise definition of information ecology and further develop information ecology as a methodological base for information studies in general based on the concepts and principles of the general theory of information.	information ecology;information processing;information science	Mark Burgin;Yixin Zhong	2018	Information	10.3390/info9030057	computer science;information processing;information ecology;ranging;ecological psychology;ecology	ML	-73.40061904483458	-17.76412503171342	117477
bb9b741a0858016f259c72113ed83d9185698daa	sustainability through open data : examples from switzerland		Although the term “sustainability” can be traced back to as early as 1761 in forest management, it was unknown to most of the wider public two decades ago. Driven by publications of scientific evidence showing the potential impact of greenhouse gases on global climate change as well as the prediction of the end of the oil age, popular awareness of ecological challenges facing our planet has increased – today, the topic of sustainability has arrived in the mainstream (with all the downsides, such as hijacking of the term). While awareness alone is certainly not sufficient, it is a fundamental and necessary step towards the establishment of new models for economic, societal and ecologic development. In this paper we show how the Open Data movement can address some of the complex challenges that sustainable development needs to solve. Examples of software applications (“apps”) and data analyses and visualizations developed in grassroots projects at so-called “make.opendata.ch hackathons” in Switzerland will demonstrate how the Open Data movement can be part of the solution by bridging the realms of economy, ecology and society in sustainable development. 1. Sustainability through Open Data Since the beginning of the industrial revolution, human activity has mainly been motivated by narrow selfinterest and the pursuit of short-term utility maximization [1]. Many have given less attention to the longterm impacts of (at times seemingly unlimited) economic growth. Vital natural resources such as food, biodiversity, water and energy were assumed to be virtually infinitely supplied. In 2012, the oil production peak (“peak oil”) has almost been reached globally [2]. The current atmospheric concentration of CO2 has increased by 30% from its pre-industrial values [3] and will continue to rise thus accelerating global change. The essentials for life to thrive (air, land, rivers and oceans) have experienced profound alterations in many places, affecting much of the Earth’s flora and fauna. The cooccurrence of these events strongly hints at the idiomatic elephant in the room: that our current model of economic development – of “doing business” – is not sustainable. Consequently, over the last 20 years numerous researchers have ventured to find out how economic growth and social needs can be balanced with the natural environment in order to ensure that the present does not adversely affect future opportunities (temporal dimension of sustainability). Meeting this challenge is incredibly difficult, as it requires global cooperation, technological innovation, changes in predominant cultural attitudes, and long-term commitment. In what follows we would like to show how the goals of Open Data can complement the scientific and societal efforts and how Open Data proponents can make an important contribution to the sustainability movement. Collaboration Sustainable development is a global issue that requires a collaborative environment to enable and enhance cooperation between different stakeholders, from corporations, local, state and federal governments, technology and service providers to the level of individual actors. Technology for communication and collabo1 Antoine Logean, opendata.ch, antoine.logean@opendata.ch, @ecolix 2 Oleg Lavrovsky, opendata.ch, oleg.lavrovsky@opendata.ch, @loleg 3 Peter Gassner, Interactive Things, peter@interactivethings.com 4 Ralph Straumann, ralphstraumann.ch, ralph.straumann@gmail.com, @ralphstraumann	bridging (networking);ecology;expectation–maximization algorithm;global change;hackathon;page hijacking;realms;switzerland	Antoine Logean;Oleg Lavrovsky;Peter Gassner;Ralph Straumann	2012			open data;environmental resource management;environmental science;sustainability	HCI	-76.15276067318725	-10.108984353915064	117682
fca4eb44b8b2cfbca54c9c6460661b83e3173451	introducing e-gov: history, definitions, and issues		The e-Gov field (also called Electronic Government, Digital Government, Electronic Governance, and similar names) emerged in the late 1990 ́s. Since then it spurred several scientific conferences and journals. Because the field grew considerably in size, both its contents and position with respect to other research fields and disciplines need to be explained and discussed. What is e-Gov? What is e-Gov research? What does it mean for the field of Information Systems? This paper briefly sketches the short eGov history and current status, and discusses the content of the field as it appears in current research. We conclude with a discussion of e-Gov as a research field of interest both as a new application area for IS theories and methods and as a source of new insight.		Åke Grönlund;Thomas A. Horan	2005	CAIS			HCI	-72.1188097869856	-16.9883072793458	117688
033e1a889bcb447362c0f9ba6085452366b1c505	the footprint of regulation: how information systems are affecting the sources of control in a global economy	information system;information and communication technology	Whilst the issue of jurisdiction – the question of how far control extends – has always been controversial, the introduction of information and communications technologies only exacerbates the problem. The first generation of scholars to consider this question tended to see technology creating a separate space – cyberspace – with its own legal boundaries. A second generation of scholars, however, has argued that there is nothing new with cyberspace and that conflicts over boundaries have always existed in the law; as a result, they argue that technology is not as remarkable a factor as the first generation believe. By considering the case of copyright and peer–to–peer technologies together with the regulatory environments surrounding their development, use and control, this paper proposes a further refinement in the dialectics of control through technology that refines our notions of jurisdiction in an era of globalisation enabled by new technologies.	cyberspace;information system;peer-to-peer;refinement (computing);while	Prodromos Tsiavos;Ian Hosein;Edgar A. Whitley	2003				AI	-75.99086945048019	-11.758958201641681	117800
7876f0f31d09be6056962e55412a624a5230d386	reflections on how to evaluate the professional value of scientific papers and their corresponding citations		It is inevitable that the ´publish or perish´ paradigm has implications for the quality of research published because this leads to scientific output being evaluated based on quantity and not preferably on quality. The pressure to continually publish results in the creation of predatory journals acting without quality peer review. Moreover the citation records of papers do not reflect their scientific quality but merely increase the impact of their quantity. The growth of sophisticated ´push -button´ technologies allows for easier preparation of publications while facilitating ready-to-publish data. Articles can thus be compiled merely through combining various measurements, usually without thought to their significance and to what purpose they may serve. Moreover any deep-rooted theory which contravenes mainstream assumptions is not welcomed because it challenges often long-established practice. The driving force for the production of an ever growing number of scientific papers is the need for authors to be recognised in order to be seriously considered when seeking financial support. Funding and fame are distributed to scientists according to their publication and citation scores. While the number of publications is clearly a quantitative criterion, much hope has been placed on citation analysis, which promised to serve as an adequate measure of genuine scientific value, i.e. of the quality of the scientific work.	amiga reflections;citation analysis;compiler;programming paradigm;scientific literature	Jaroslav Fiala;Jirí J. Mares;Jaroslav Sesták	2017	Scientometrics	10.1007/s11192-017-2334-x	data mining;citation analysis;citation;computer science;mainstream;publication	HPC	-65.89737779818458	-20.520908302294664	118017
05105041818a158f9271275a959fe569d564c6f1	from stone knives and bearskins to mobile and cloud computing	communications;technology;technological advances;technological advances internet technology communications;internet	This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.	cloud computing	Barry Leiba	2012	IEEE Internet Computing	10.1109/MIC.2012.131	simulation;law;technology	DB	-68.27216632443601	-17.714845843485183	118033
50c89911d8c8af969c50940832f5af3bf1ba3793	research and development of digital library platform	management system;digital library;digital library architecture;research and development;systems and applications;business process	The China-US Million Book Digital Library Project (Million Book Project) is an international cooperation program between China and the US. However, one million digitized books are considered not to be the ultimate goal of the project, but a first step towards universal access to human knowledge. In particular, there are four challenges about the new way to analyze, process, operate, visualize and interact with digital media resource in this library. To tackle these challenges, North China Centre of Million Book Project (in Chinese Academy of Sciences) has initiated several innovative research projects in areas such as multimedia content analysis and retrieval, bilingual services, multimodal information presentation, and knowledge-based organization and services. In this keynote speech, we simply review our work in these areas, and argue that by technological cooperation with these innovation research topics, the project will develop a top-level digital library platform for the million book library.	academy;digital library;digital media;knowledge management;million book project;multimodal interaction	Jing Peng;Dake Wang	2004		10.1007/978-3-540-30544-6_84	digital library;computer science;management system;business process	Web+IR	-66.49756522445719	-14.174924541617786	118131
6aed2c98ce8d88393788cfe5a53e91003d4db738	open access and discovery tools: how do primo libraries manage green open access collections?	institutional repositories;discovery tools;green open access;discovery;ex libris;discoverability;open access;harvesting;visiblity;primo central index;primo	As of the end of April 2015, there are about 2,850 academic OA repositories (Green OA) of all kinds listed on OpenDOAR (http://www.opendoar.org). Scholarly OA repositories contain lots of treasures including rare or otherwise unpublished materials and articles that scholars self-archive, often as part of their institution’s mandate (Harnad 2004). But it can be hard to discover this material unless users know exactly where to look.	archive;primos	François Renaville	2015	CoRR		data mining;world wide web	HCI	-68.21805380131241	-19.38930589103596	118237
4d0b3d097ff27c90d6754a04fa888d8411994e20	is there nothing outside the tags?: towards a poststructuralist analysis of social tagging	poststructuralism;dk atira pure researchoutput researchoutputtypes contributiontojournal article;indexing;controlled languages;social sciences all;tagging	Purpose – The purpose of this paper is to explore relationships between social tagging and key poststructuralist principles; to devise and construct an analytical framework through which key poststructuralist principles are converted into workable research questions and applied to analyse Librarything tags, and to assess the validity of performing such an analysis. The research hypothesis is that tagging represents an imperfect analogy for the poststructuralist project. Design/methodology/approach – Tags from LibraryThing and from a library OPACwere compared and constrasted with Library of Congress Subject Headings (LCSH) and publishers’ descriptions. Research questions derived from poststructuralism, asked whether tags destabilise meaning, whether and how far the death of the author is expressed in tags, and whether tags deconstruct LCSH. Findings – Tags can temporarily destabilise meaning by obfuscating the structure of a word. Meaning is destabilised, perhaps only momentarily, and then it is recreated; it might resemble the original meaning, or it may not, however any attempt to make tags useful or functional necessarily imposes some form of structure. The analysis indicates that in tagging, the author, if not dead, is ignored. Authoritative interpretations are not pervasively mimicked in the tags. In relation to LCSH, tagging decentres the dominant view, but neither exposes nor judges it. Nor does tagging achieve the final stage of the deconstructive process, showing the dominant view to be a constructed reality. Originality/value – This is one of very few studies to have attempted a critical theoretical approach to social tagging. It offers a novel methodological approach to undertaking analysis based on poststructuralist theory.	folksonomy;library of congress subject headings;simulation	Helen Murphy;Pauline Rafferty	2015	Journal of Documentation	10.1108/JD-02-2013-0026	library science;search engine indexing;computer science;world wide web;information retrieval	HCI	-74.33382965495494	-19.96726160404482	118464
1fb01e327d070c1e66f897988d6892c85ba6d994	research in progress. part 2 - some preliminary insights into the information needs of the contemporary academic researcher	academic staff;etude utilisateur;etude utilisation;user study;qualitative data;information scientifique technique;estudio utilizacion;estudio usuario;chercheur;knowledge society;israel;informacion documentacion;research work;research worker;necesidad informacion;pilot project;asie;information management;besoin information;comportement utilisateur;present day;scientific technical information;user behavior;investigador;information need;recherche scientifique;grupo a;informacion cientifica tecnica;information seeking;ciencias sociales;scientific research;comportamiento usuario;use study;investigacion cientifica;asia	The second part of a two‐part paper reports the preliminary conclusions derived from the pathfinder phase of a study devoted to a reassessment of the information needs of academic researchers. Proceeding from the notion that long‐established research information needs may not have remained wholly unaffected by the changing realities of the knowledge society, this exploration of researchers' current information requirements and information seeking practices has been undertaken with a special emphasis on examining the validity of anything and everything we have customarily been holding true as to the information component of academic research work. The groundwork for the investigation has been laid down in a pilot project of seven in‐depth critical incident method‐based information needs interviews with faculty at the University of Haifa (Israel). The qualitative data thus obtained as to researchers' information needs, how they go about meeting these needs, and the barriers they encounter in the process hav...	information needs	Eti Herman	2004	Aslib Proceedings	10.1108/00012530410529495	information needs;qualitative property;scientific method;computer science;sociology;information management;operations research	HPC	-72.97636875949293	-22.129659481027733	118544
0164085bdabec1107457aa58eb1eab456f45e810	correlation between impact factor and public availability of published research data in information science and library science journals	open research data;impact factor;comunicacion de congreso;public availability;correlation;scientific journals;information science and library science	Scientists continuously generate research data but only a few of them are published. If these data were accessible and reusable, researchers could examine them and generate new knowledge. Our purpose is to determine whether there is a relationship between the impact factor and the policies concerning open availability of raw research data in journals of Information Science and Library Science (ISLS) subject category from the Web of Science database. We reviewed the policies related to public availability of papers and data sharing in the 85 journals included in the ISLS category of the Journal Citation Reports in 2012. The relationship between public availability of published data and impact factor of journals is analysed through different statistical tests. The variable “statement of complementary material” was accepted in 50 % of the journals; 65 % of the journals support “reuse”; 67 % of the journals specified “storage in thematic or institutional repositories”; the “publication of the manuscript in a website” was accepted in 69 % of the journals. We have found a 50 % of journals that include the possibility to deposit data as supplementary material, and more than 60 % accept reuse, storage in repositories and publication in websites. There is a clear positive relationship between being a top journal in impact factor ranking of JCR and having an open policy.	information science;journal citation reports;library science;software repository;web of science;world wide web	Rafael Aleixandre-Benavent;Luz Moreno;Antonia Ferrer-Sapena;Enrique Alfonso Sánchez-Pérez	2015	Scientometrics	10.1007/s11192-016-1868-7	computer science;data mining;world wide web;correlation	Comp.	-76.88512764725772	-20.121383408205144	118703
92601087550b1787c97ea1f72928cc5a6e43d7bd	the digitally extended self: a lexicological analysis of personal data	categorisation;digital persona;digital footprint;virtual self;personal data;digital mosaic;digitally extended self;informed consent;privacy;data protection act	Individual’s privacy, especially with regard to their personal data, is increasingly an area of concern as people interact with a wider and more pervasive set of digital services. Unfortunately, the terminology around personal data is used inconsistently, the concepts are unclear, and there is a poor understanding of their relationships. This is a challenge to those who need to discuss personal data in precise terms, for example legislators, academics, and service providers who seek informed consent from their users. In this paper, we present a lexicological analysis of the terms used to describe personal data, use this analysis to identify common concepts, and propose a model of the Digitally Extended Self that shows how these concepts of personal data fit together. We then validate the model against key publications and show in practice how it can be used to describe personal data in three scenarios. Our work shows that there is no clearly delineated kernel of personal data, but rather that there are layers of personal data, with different qualities, sources, and claims of ownership, that extend out from the individual and form the Digitally Extended Self.	categorization;computer scientist;data protection act 1998;information science;persona (user experience);personally identifiable information;pervasive informatics;privacy law	Brian Parkinson;David E. Millard;Kieron O'Hara;Richard Giordano	2018	J. Information Science	10.1177/0165551517706233	digital footprint;computer science;data mining;service provider;informed consent;terminology;personal information manager;data protection act 1998	HCI	-73.33644863458825	-12.550405128104531	118835
a3d63a3254374f5219cf699b6fe163262cc65a72	a hermeneutic approach to the notion of information in is	information systems;essence of information;philosophy of information;information flow;hermeneutics;information system	In the field of information systems (IS), ‘information’ is probably the most important and fundamental notion. And yet, existing studies of it seem inadequate and lacking of sufficient depth, and further work is therefore desperately in need. We adopt Hermeneutics to approach the essence of information. We describe how Hermeneutics might enable us to look at the mechanism whereby information is created and information flow takes place, and explain implications this approach might have to requirement identification in IS. Key-Words: Essence of Information, Hermeneutics, Philosophy of Information, Information Systems	information systems;information flow (information theory);information system;philosophy of information	Su-Fen Wang	2007		10.1007/978-3-540-85565-1_43	information needs;information algebra;social science;philosophy;epistemology;information quality	Security	-73.10131475006797	-18.01048214895762	118936
58cd3568f722d90accd183706076504e56a570e2	eugene garfield: brief reflections	science studies;citation linkage;epistemology;information retrival;data analytics;entrepreneurship	Eugene Garfield ubiquitous presence in scientometrics masks to some extent his influential contributions in diverse areas. Taking this as a premise for this study, the article attempts to trace Garfield’s contributions in four key domains: in data analytics, in influencing scholars involved in the study of science as an epistemic practice and a knowledge product, his engagement with scholars in developing countries and in innovation and entrepreneurship. The article however provides only a glimpse of his deep engagement in the above domains. The study concludes by arguing for scientometrics to develop strong connect with the different strands of research in science studies and other cross-disciplinary areas which pioneer like Garfield undertook through his writings, developing social networks and creating knowledge products.	amiga reflections;scientometrics;social network	Sujit Bhattacharya	2017	Scientometrics	10.1007/s11192-017-2620-7	entrepreneurship;argument;scientometrics;premise;social science;data mining;science studies;social network;developing country;computer science;data analysis	ML	-77.17316378015974	-15.349850192976234	119123
aae7a546ff49cfbd734b99c82d19d642bf644ddc	not just a matter of time: field differences and the shaping of electronic media in supporting scientific communication	field difference;electronic media;scientific communication;electronic publishing;information technology;scientific research;sciences;computer mediated communication;stable set	The shift towards the use of electronic media in scholarly communication appears to be an inescapable imperative. However, these shifts are uneven, both with respect to field and with respect to the form of communication. Different scientific fields have developed and use distinctly different communicative forums, both in the paper and electronic arenas, and these forums play different communicative roles within the field. One common claim is that we are in the early stages of an electronic revolution, that it is only a matter of time before other fields catch up with the early adopters, and that all fields converge on a stable set of electronic forums. A social shaping of technology (SST) perspective helps us to identify important social forces – centered around disciplinary constructions of trust and of legitimate communication – that pull against convergence. This analysis concludes that communicative plurality and communicative heterogeneity are durable features of the scholarly landscape, and that we are likely to see field differences in the use of and meaning ascribed to communications forums persist, even as overall use of electronic communications technologies both in science and in society as a whole increases.	converge;imperative programming;noise shaping;scholarly communication;scientific communication;social constructivism	Rob Kling;Geoffrey W. McKim	2000	JASIS	10.1002/1097-4571(2000)9999:9999%3C::AID-ASI1047%3E3.0.CO;2-T	library science;social science;computer science;evolution;sociology;electronic publishing;management;law;information technology;world wide web;electronic media	HCI	-76.39483417025089	-13.633464056848544	119151
2327f4946173f73b75a0620f2343eecf0d19acfa	critical realism and information systems: brief responses to monod and klein	critical realism;vu;h social sciences general;information system	In my paper (Mingers, Real-izing information systems: critical realism as an under pinning philosophy for information systems. Information and Organization, 2004; 14(2), doi:10.1016/j.infoandorg.2003.06.001), I put forward the case that the philosophical position known as critical realism could potentially provide a sound underpinning for information systems. This issue of Information and Organization contains two papers written in response to mine (Klein, Seeking the new and the critical in critical realism: Deja vu? Information and Organization, 2004; 14(2), doi:10.1016/j.infoandorg.2004.02.002; Monod, Einstein, Heisenberg, Kant: methodological distinctions and conditions of possibility, Information and Organization, 2004; 14(2), doi:10.1016/j.infoandorg.2003.12.001) and the editors have allowed me to make a very brief reply. # 2004 Elsevier Ltd. All rights reserved.	déjà vu;http public key pinning;information system	John Mingers	2004	Information and Organization	10.1016/j.infoandorg.2004.02.003	psychology;social science;philosophy;epistemology;artificial intelligence;critical realism;sociology;information system;cognitive science	AI	-64.84741325567626	-13.780019221345302	119297
cd81e7406660a9d99214fc702dd10294b74bc6a8	platform to publish and retrive multilinguil information on the www		Asia, today, is the fastest growing economic region in the world. With the booming economy in Asia, there is a growing demand for IT and the use of the Internet/World wide Web in the region. Although over 80% of all content presently on the Internet and World Wide Web are western-focused, a few - but growing explosively - web sites which host native languages (Chinese, Japanese, Korean) are now emerging. As more and more end-users in this region are introduced to the Internet, inevitably there will be a stronger demand for non-English information online. Star+Globe Technologies, Pte. Ltd., is a Singapore software company with a mission to be the preferred supplier of multilingual products to information providers and consumers to enable information sharing and retrieval in a multitude of languages.	www	Virgina Cha	1997	Electronic Markets	10.1080/10196789700000023	the internet;engineering;marketing;data mining;advertising;management;world wide web	Theory	-69.39626073074284	-22.268133625774514	119346
7ea9d7bc5bbaed8ae5d7e707c331a835f1a37ffb	information technology applications to cataloguing in nigerian university libraries	software;paises en desarrollo;university libraries;pays en developpement;catalogacion;raw materials;logiciel;information technology;biblioteca ensenanza superior;recommandation;automatisation;catalogage;technologie information;cataloguing;automatizacion;computer literacy;communication technologies;enquete;research and development;bibliotheque enseignement superieur;electricity generation;software development;recomendacion;logicial;recommendation;encuesta;higher education library;communication technology;cataloging;nigeria;tecnologia informacion;survey;academic libraries;africa;developing countries;afrique;design methodology;automation	Purpose – The study aims to examine the information technology used in cataloguing in Nigerian academic libraries.Design/methodology/approach – To elicit the necessary information, a four‐part questionnaire was sent to cataloguers in 33 Nigerian university libraries: 22 were returned and found usable, constituting a 66.7 per cent response.Findings – Analysis of the returned questionnaire revealed that 16 federal universities and two state universities have automated their cataloguing processes using the TINLIB software, while two others use the LC and CD‐ROM database to aid the cataloguing. Automation of the cataloguing process has increased the efficiency of the cataloguing processes in the Nigerian university libraries, which in turn has resulted in increased productivity. The high cost of maintenance of the TINLIB software was identified as the major constraint to the use of the software. Other constraints include poor computer literacy on the part of the librarians, incessant power‐cuts and lack of in...	library (computing)	A. A. Oduwole	2005	The Electronic Library	10.1108/02640470510603688	computer literacy;electricity generation;information and communications technology;developing country;design methods;computer science;software development;raw material;automation;management;operations research;law;information technology;world wide web	EDA	-73.33094202732613	-23.67857750806118	119454
854cadb5e889e44bfe5d1d649eff244cb31b39b9	electronic contracts in south africa - a comparative analysis.		"""The paper is a broad overview of the South African law on Electronic Contracts (e-contracts). It has a brief introduction to the South African Lex Informatica which covers historical evolution of Internet law on an international platform and how it has impacted on South African Law on negotiation of commercial contracts. Section 2 deals with the South African Common law and how it applied to electronic transaction prior to the enactment of the Electronic Communication Transactions Act (ECT), Act 25 2002. Section 3 then deals with statutory regime as it relates to writing and signature requirements, time and place where contract enters into effect as well as the legal recognition of Shrink Wrap, Click-Wrap and Web Wrap Agreements as regulated by the ECT. Section 4 discusses cross-border contracts, issues of jurisdiction as well as the legal principle of """" conflict of laws """" and what role it plays in electronic cross boarder transactions."""	chat room;documentation;electroconvulsive therapy;electronic data interchange;electronic funds transfer;email;fax;lex (software);mail (macos);paperless office;requirement;shrink wrap contract	Sizwe Lindelo Snail	2008	Journal of Information, Law and Technology		internet privacy;computer science	HCI	-71.36305916570441	-10.489974693775004	119515
024ed1c3e280f52e495e1c988cbb63c74f0954c2	the impact of the integrated digital library system on the cnib library	text;north america;service information;america del norte;amerique du nord;amerique;gestion de sistemas de informacion;accesibilidad;gestion des systemes d information;utilisateur defavorise;information systems management;systeme integre;sistema integrado;usuario desaventajado;canada;biblioteca electronica;low vision;malviendo;estudio caso;accessibility;malvoyance;disadvantaged user;library services for the visually impaired;etude cas;servicio informacion;electronic library;digital resources;information service;information system;america;integrated system;systeme information;accessibilite;bibliotheque electronique;sistema informacion	Technological change has been the norm for libraries serving people who are blind or otherwise print disabled. Technology is required to produce and disseminate books in various formats, and technical devices are often used as a means for a person to read the books. However, the development of digital technology combined with the evolution of the Internet has prompted significant change for library services and operations in the past few years. The CNIB Library recognized the opportunity to create more content faster, provide more choice and accessibility, and to streamline and revolutionize processes by building the Integrated Digital Library System (IDLS) in partnership with industry technology leaders. This article describes the technology of the IDLS and the impact on the organization. “For many people, technology can make things easier. For people who are blind, technology makes things possible.” — Jim Sanders, President and CEO, Canadian National Institute for the Blind Introduction Libraries have always relied on the evolution of technology to acquire, organize, and disseminate information. It can be argued that libraries serving people who are blind or otherwise print disabled are often a step ahead with technical innovation. These libraries must often produce the very materials that other libraries would purchase for their collection. In the case of libraries for the print disabled, technology is required by the library to produce that book in audio, braille, or tactile format. A person who cannot read regular print must find other means of reading; technoLIBRARY TRENDS, Vol. 55, No. 4, Spring 2007 (“Library and Information Services for Visually Impaired People,” edited by Helen Brazier and David Owen), pp. 973–993 © 2007 The Board of Trustees, University of Illinois 974 library trends/spring 2007 logical devices to magnify print, electronic braille, synthetic speech output or human-narrated audio books are current options. Finally, libraries serving people who are blind are often centralized but serving a population scattered nationally. Technology is required to support this servicedelivery model. In 1997 the CNIB laid out a road map with yearly objectives to reach the goal of fully trained staff and volunteers operating in a digital environment and producing digital products to be delivered from Web-based services as well as distributed by traditional postal methods. In 2000 CNIB developed a plan for an Integrated Digital Library System (IDLS). The reasons for this were twofold. On the one hand, CNIB’s decision could be seen as one born of necessity and survival given the cumbersome and increasingly obsolete nature of analog production and distribution technologies, upon which libraries for the blind have been dependent for the previous quarter century. However, the vision was also a result of the synchronicity of the development of digital technologies and the evolution of the Internet, which presented opportunities to dramatically improve the timely delivery of accessible content to print disabled Canadians. Such opportunities would have been unconscionable to ignore given the dearth of published material available in alternative formats and the length of time required to convert this content into alternative formats. The following principles guided the development of the IDLS: Library Service —Expand and improve choice in formats and access points —Enable independent management of library services by the end user or “client” —Decentralize service and allow for seamless community or home access to a national service —Expand content and ultimately eliminate the gap in availability between print and alternative formats Production Processes —Streamline and automate production processes and create the “single source file/multiple formats output” model —Store, archive, and preserve the collection —Adhere to international standards This article will discuss the impact of the development and implementation of the IDLS on the CNIB Library. The first section describes the service impact, the second describes the impact on book production, and the third describes in more detail the core technology. What, then, is the IDLS? What constitutes an IDLS varies from one library to the next. From the earliest conceptual stages CNIB defined its IDLS as an integrated system to handle the creation, management (ac-		Margaret McGrory;Margaret Williams;Karen Taylor;Barbara Freeze	2007	Library Trends	10.1353/lib.2007.0040	computer science;accessibility;management information systems;world wide web;information system	HCI	-69.14671649041269	-21.407553484902078	119659
16a4d8cf419debcd904a5ca4e18f91629caf6763	the multiple watermarking on digital medical image for mobility and authenticity		the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed on a computer system, for exclusive use by the purchaser of the work. Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright Law of the Publisher's location, in its current version, and permission for use must always be obtained from Springer. Permissions for use may be obtained through RightsLink at the Copyright Clearance Center. Violations are liable to prosecution under the respective Copyright Law. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. While the advice and information in this book are believed to be true and accurate at the date of publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may be made. The publisher makes no warranty, express or implied, with respect to the material contained herein.	computer;cyber-security regulation;data deduplication;microform;springer (tank)	Adiwijaya;T. A. B. Wirayuda;S. D. Winanjuar;U. Muslimah	2012		10.1007/978-3-319-00795-3_68	computer vision;digital watermarking alliance;digital watermarking;multimedia	AI	-66.70230616181709	-17.386237998095645	119688
7cf16802ea497f2a914d799f59078e8d9beafeb9	difference in the impact of open-access papers published by china and the usa	open access;altmetrics;research evaluation;country;citation analysis	We analyze the impact of open-access (OA) articles published by China and the USA by using Web of Science (WoS) data covering a period of 5 years (2011–2015), five indexes (citation and four altmetric indexes), five disciplines, and three types of articles. With regard to article type, Type I papers are those wherein the authors are all from China or the USA. Type II are those in which the first author is from China or the USA. Type III includes those in which the first author is not from China or the USA. We found that the proportion of OA papers in WoS has been growing in recent years. In terms of citations and altmetric indexes, the mean value of the USA is larger than that of China in general; Type II articles possess the highest value among all papers in the USA, whereas Type III has the highest value in China. Compared with the scenario in citations, social sciences and humanities possess larger altmetric values in China and the USA. The correlation among indicators is similar for the OA papers from China and the USA. Generally, citations cannot effectively represent the altmetric indexes. The gap between China and the USA is the largest in the altmetric attention score and Type I, and the smallest in citations and Type III. Measuring the international impact of OA papers using only citations underestimates the gap between China and the USA.	altmetrics;web of science	Siluo Yang;Xin Xing;Dietmar Wolfram	2018	Scientometrics	10.1007/s11192-018-2697-7	data mining;citation analysis;library science;altmetrics;citation;china;computer science	Web+IR	-76.81554338805648	-20.892662054545173	119731
5c2fa16d564babe1619f2efa010806373337047f	change management in information asset		We are passing through information age with lightning communication speed. Information asset storage in Cloud and retrieval in the net has become the new invisible corporate voyage into the information space. Information Assets are a valuable source of Knowledge for both Information asset creator as well as the user. These are fluid assets that change overtime based on several internal and environmental factors! This paper seeks to address these aspects of Change that impacts such “fluid” Information Assets and the need to raise up to the changing expectations of the millions of users by satisfying the ever growing information hungry businesses. Providing unreliable information and suboptimal analytical tools can destroy the user in the first instance and can lead to self-destruction as Information asset provider will find no takers in the long run. In this context this assorted information on Change management is chosen carefully and it is hoped, will benefit the reader who may be a technical expert in his field. KeywoRdS Accountability Model, Asset profiling, Change Management, Damage, Information Assets, IT Risk, Vulnerability	asset (computer security);change management (engineering);cloud computing;it risk;self-destruct;ti-92 series	Prajwal Eachempati	2017	JGIM	10.4018/JGIM.2017040105	economics;marketing;operations management;information quality;management;world wide web;economic growth;commerce	HPC	-73.73762708734556	-9.938354780073752	119806
9a5128cfa163dc10f09643a81c3dedf944f9ecb5	defining relationships between social interaction and discoverability of digital resources in memory institutions		This paper gives an overview of a research project aimed to compare and clarify the relations between social interaction and discoverability of digital resources in three types of memory institutions: libraries, archives and museums. The main research questions are: how and to what extent social interaction is related to discoverability, what are the similarities and differences across the three types of institutions within this context, and what is the role of the academic community in the process? The multi-method empirical research enhances three case studies: a library, an archive and a museum from a single country context, United Kingdom. Each case study maps the phenomenon of crowdsourcing within the organization, then the social interaction emerged in Twitter will be described on national level, and the effect will be estimated and evaluated taking into account qualitative data. Comparative analysis between the organizations concludes the research cycle. The results are expected to contribute to effective design and maintenance of a discoverable digital library, sustainable user engagement, and collaboration between the organizations.	archive;crowdsourcing;digital library;discoverability;library (computing);map	Õnne Mets	2016	TCDL Bulletin		human–computer interaction;digital library;social relation;discoverability;multimedia;computer science	HCI	-76.24637170373417	-18.469174097766505	119811
ad468bff14ada9d4dfb47aa3a3aebce9629dec36	openness and stability	trust;openness;niels bohr;stability;self confidence;sissela bok	Humanity’s desire for change but not instability is explored. In this context, it is proposed that a key ‘balancing aid’ of society is openness. Converse attributes, such as secrecy, reserve and tact, are also discussed, following the ideas of Sissela Bok. A particular interest in openness can be traced to the thought and advocacy of Niels Bohr, at the beginning of the nuclear age, when the problems were thought about mainly in terms of security. His ideas and efforts to promote an open world are reviewed in the light of subsequent developments. These developments are not restricted to nuclear matters. The qualitative proliferation of kinds of instability (perhaps combining into John Beddington’s ‘perfect storm’) is relevant. This proliferation justifies extension of Bohr’s concerns with security to the wider realm of stability. It is also proposed in this paper that Bohr’s use of the term confidence, which was an important element of his argument for an open world, requires refinement, with a distinction between confidence in others (trust) and self-confidence (necessary for openness). The paper ends with a section on ‘improving our prospects’.	bohr–einstein debates;computer security;instability;open world;openness;refinement (computing)	Alan Cottey	2015	AI & SOCIETY	10.1007/s00146-015-0592-9	stability;self-confidence;artificial intelligence;openness to experience;sociology;trustworthy computing;social psychology;law	AI	-75.73580640041703	-13.375076646355637	119892
fa66e6023121d69b9ee40b49f8d39be509ca3d69	the u.s. government printing office - marketing and publishing		Official printer and sales agent for publications of the Federal government, the U.S. Government Printing Office (GPO) receives typed and electronic manuscripts from virtually every agency of government. Either in house or through commercial procurement, GPO provides typesetting, printing, and binding services to produce finished publications. GPO also disseminates these publications through the 1400 Depository Libraries and the Superintendent of Documents Sales Program. GPO employs an hierarchical marketing system which helps assure public exposure for every sales program title, while assigning increasing levels of promotion for titles with the greatest sales potential. As a trend, GPO sees fewer consumer-oriented publications and more professional-use titles. GPO also observes a new appreciation of the value of government statistical information, and increased agency efforts to provide improved public access to this data. GPO is working with publishing agencies and information-technology suppliers to study ways of accommodating demand for electronic information dissemination.		Ralph E. Kennickell	1987	Journal of the American Society for Information Science. American Society for Information Science	10.1002/(SICI)1097-4571(198701)38:1%3C68::AID-ASI13%3E3.0.CO;2-L		Security	-67.70229067804179	-19.010343112232547	119984
ba862b4764ab3c533d7a546eb283315e82079a2d	initial findings from a three-year international case study exploring children's responses to literature in a digital library	etude utilisateur;livre electronique;etude utilisation;text;digital library;digital libraries;user study;reading;estudio utilizacion;estudio usuario;children and digital resources;hombre;literature;enfant;cuestionario;biblioteca electronica;electronic book;lecture;nino;human;internacional;libro electronico;child;electronic library;questionnaire;lectura;literatura;litterature;international;bibliotheque electronique;use study;homme	This article examines children’s responses to self-selected books in a digital library and begins to identify patterns in those responses. As part of a larger longitudinal study, the study presented here is an analysis of 241 book response forms submitted by 12 children from 4 countries: Germany, Honduras, New Zealand, and the United States. The children described most of the books they read as being funny or happy and generally rated them with four or fi ve stars (out of fi ve stars). The most commonly identifi ed types of responses were those expressing like or dislike, summarizing the text, or explaining how the book made the child feel. Two factors were identifi ed that infl uenced response patterns from the study sites: the data collection instrument and adult mediation. This research has implications for library program development related to recreational reading and for changes in the procedures for data collection in this area of research. Introduction It is important that school and public librarians understand how children respond to the literature they read not only for school but recreationally so that they can effectively develop collections and programs that address and respond to children’s interests. Library professionals serving children all over the world share this responsibility, which is amplifi ed by the need to provide effective services to increasingly diverse user communities from Emporia, Kansas, to Wellington, New Zealand. While many studies have looked at cross-national assessments of students’ school achievement in various subject areas (Forshay & Husén, 1962; Heyneman, 2004; InternaInitial Findings from a Three-Year International Case Study Exploring Children’s Responses to Literature in a Digital Library Sheri Massey, Ann Carlson Weeks, and Allison Druin LIBRARY TRENDS, Vol. 54, No. 2, Fall 2005 (“Children’s Access and Use of Digital Resources,” edited by Allison Druin), pp. 245–265 © 2005 The Board of Trustees, University of Illinois 246 library trends/fall 2005 tional Association for the Evaluation of Educational Achievement [IEA], n.d.; National Center for Education Statistics [NCES], n.d.; Purves, 1973), few studies in the library and information studies literature have investigated the responses that children have to books read aesthetically, or recreationally. Virtually no international comparative studies have been done to explore children’s responses to books read “for fun” across countries or cultures because until recently it has not been possible to provide identical collections of materials simultaneously in multiple locations. Today, however, Internet technology makes it possible for users all over the world to access the same collection of materials on demand through digital libraries. With the development of digital collections, such as the International Children’s Digital Library (ICDL), created in 2002, it is now possible to explore patterns in readers’ responses to self-selected items in multiple international settings. By exploring patterns in readers’ responses in different nations and over time, this research may begin to provide a greater understanding of children’s interactions with books selected for recreational reading. This knowledge can then be applied to the tailoring of collections and services that better meet children’s dynamic information needs. The work presented here offers a unique glimpse at international patterns in reader response and begins to address the paucity of reader-response literature in the library and information studies fi eld. This article presents the preliminary fi ndings from year one of a three-year longitudinal study designed to investigate that relationship. This research is guided by the following questions: What patterns exist in children’s responses to literature? Do variations exist by country? If so, what factors infl uence those variations? Previous Research: Reader Response Theory Reader response theory posits that every reader constructs meaning from an interaction with a literary work. This constructed meaning is greatly infl uenced by factors such as feelings, beliefs, the structure and elements of the text, and the reader’s context at the time of the interaction (Probst, 2003; Rosenblatt, 1978). Reader response theorists also hold that the reader’s response may change frequently and dramatically during an interaction with a text (Newton, Stegmeier, & Padak, 1999; Rosenblatt, 1991). This oneto-one interaction between the reader and the text is known as a “literary transaction” (Hepler & Hickman, 1982; Rosenblatt, 1978). Martinez and Roser (2003) report that, although adults and children process meaning in literature differently, young children are capable of making interpretations, thematic statements, and connections to their lives from what they read. Probst (2003) focuses on children’s responses to literature, adding that, as individuals, children bring different experiences, histories, beliefs, contexts, and purposes to the act of reading, and, therefore, their responses and interpretations of what they read will differ. Meaning, he adds, is created from the interaction between the reader and the text.	book;carlson's theorem;digital library;experience;frank rosenblatt;hadley centre for climate prediction and research;information needs;interaction;international ergonomics association;internet;librarian;library (computing);library and information science;net-centric enterprise services;newton;privacy	Sheri Massey;Ann Weeks;Allison Druin	2005	Library Trends	10.1353/lib.2006.0018	library science;questionnaire;digital library;el niño;computer science;sociology;world wide web;reading	HCI	-72.28600077318971	-21.769105012686982	120041
0f7d0d4f9fd84bd4fb57233ea8d4a20b79f838bd	web strategies for professional publishers: developing an information services portal		This paper examines how the free distribution of electronic information on the internet is rapidly changing the commercial environment for small to medium-sized print publishers, and suggests some recommendations for publishers in the process of establishing their own web strategies. It begins by addressing the concept of the ‘network economy’ and the way in which electronic networks have changed the fundamental economics of many businesses. It then suggests seven recommendations for learned and professional society publishers adapting their own business models to the web, highlighting the need to differentiate print from electronic products by building an electronic information services portal for current members and subscribers. Learned Publishing (2000)13, 83–94 Donald C. Klein Web strategies for professional publishers 83 L E A R N E D P U B L I S H I N G V O L . 1 3 N O . 2 A P R I L 2 0 0 0 trends as succinctly as I can, and then I will offer a few recommendations for publishers trying to migrate their business model to something that will allow them to thrive simultaneously in paper and electronic worlds. And finally, I will illustrate the way our company, ingenta , has responded by positioning itself to work with publishers in this new arena. Britannica and the network economy Although an older example, the Britannica experience illuminates a number of issues that are still relevant for publishers. When a company which did not even appear to be a direct competitor in the field can package together a substitute product that combines ‘almost as good’ content with a whole range of unique value-adds (searching, multimedia, easy archiving, etc.), offer it at 1/36th the cost ($50 vs. $1,800), and then deliver it with alarming speed directly to the consumer, a very fundamental paradigm shift has occurred. Business strategists Philip Evans and Thomas Wurster have looked at the Britannica experience in some detail and conclude Britannica fell victim not so much to CD-ROMs, but the new economics of electronic networks.1 Enabled primarily by PCs and increasingly by the internet itself, all products, whether goods or services, are subject to an entirely new set of economies of scale once the internetworking of information and consumers has taken hold through electronic media. And they go so far as to claim that we are entering something that they and others term the ‘network economy’, where traditional value chains are being uprooted because of the free flow of information.2 But one of the important points Evans and Wurster single out in the Britannica story is that the headless horseman rode out of a completely unexpected quarter of the forest. Britannica always knew their market positioning vis-à-vis Funk & Wagnalls, and, in fact, Britannica did create their own CD-ROM (still priced at $1,000). The real shift that caught them unawares was the constitution of a new type of consumer network which they were at a disadvantage to leverage. The majority of home PCs, each of them interconnected through common software and – most importantly – an ongoing relationship to the provider of that software, offered Microsoft entirely different economies of scale for marketing a substitute product, primarily by bundling it with other offerings. This CD-ROM example highlights two important points. First, the changes brought on by electronic media are really all about connecting people, not machines. In the Britannica example, the key to Microsoft’s success was the establishment of new types of relationships with consumers, based on their ongoing need for software. The internet itself is really only a continuation of this larger trend toward networking consumers in new types of ways. As the net links individual computers directly through open standards of electronic exchange, larger and larger networks of people are continually being opened to new types of product suppliers beyond just Microsoft or AOL. New rules for competing within these networks are being created, many of which disadvantage older ways of doing business. What used to be a source of competitive advantage can quickly become a liability, particularly anything associated with high fixed costs such as print production or a large direct sales team (Britannica had both). Second, a CD-ROM example helps us remember how potent electronic media can become as alternatives to text when bundled with the right elements. Soon, broadband access to the internet (offering roughly 2–3 times the bandwidth of T1 and available through existing cable or copper infrastructures) will allow CD-ROM-level services to be delivered directly to the home, workbench, laboratory, etc. If a major publisher can be overturned through the older, essentially broadcast distribution medium of CD-ROMs, imagine how fierce the competition is going to be on a broadband, interactive internet. Why should I go online? Given all this complexity, why should a publisher attempt to sail through uncharted waters? I will offer two reasons: first, because traditional value chains are being uprooted because of the free flow of information 84 Donald C. Klein L E A R N E D P U B L I S H I N G V O L . 1 3 N O . 2 A P R I L 2 0 0 0 it is important to establish a presence in this new arena; and second, because learned publishers already have many of the ingredients to succeed spectacularly well on the internet. The first point is really a cautionary one: you need to be careful that your primary products are not rendered obsolete. In a network economy, competitors can come from anywhere to move in on your product category. And the threat may not come from a direct substitution, as in the case of Encarta. In examining the newspaper business and the traditional bundling of news with a range of additional services such as classifieds, Evans and Wurster comment: The greatest vulnerability for newspapers is not the total substitution of a new business model but a steady erosion through a sequence of partial substitutions that will make the current business model unsustainable. As a result, many people predict that whole new value chains will soon replace the traditional links of author, editor, publisher, printer, distributor and reader. And of course we are already seeing this movement with organizations like PubMed Central, FatBrain, or the Los Alamos preprint server for physicists, which connect authors directly with readers. Being positioned to make the right partnerships in this shifting marketplace will become an increasingly important factor in the future. The second point, however, is the more important one. Learned and professional society publishers are in a very strong position to succeed online, primarily because they tend to focus on highly targeted niche groups of professionals where they have strong customer relationships. Whereas Britannica’s home users could ‘get by’ on more limited content, the professionals who rely on learned publishing content for their livelihood are much more reluctant to switch to something with lower editorial quality. These are very ‘sticky’ relationships, or what some refer to as ‘locked in’, and have a strong chance of remaining so online. Moreover, learned and professional society publishers have a unique resource: networks of authors, editors and readers who are specialists in their field. If the appropriate business model can be constructed, these networks constitute very viable platforms for building and sustaining online businesses. The trick is how best to migrate these relationships and premium content online. Seven recommendations for establishing a web strategy Of course, there are no simple answers to building a successful online strategy. But through ingenta ’s experience of working with a wide range of publishers, as well as developing our own end-user-focused services, we would like to offer some key issues which publishers may wish to explore: 1. Consider which of your content should be available free-to-use and which should have restricted-access To help draw users to your premium full text, you will need fairly large sections of your overall content portfolio which you can circulate for free on the internet, and that division often requires an institute-wide policy decision or some sort of coordinated plan. For journal publishers, the choice is often easy – abstracts and other header information are viewed for free while full text requires some sort of rights verification. For book publishers, it is hard to sum up an entire book in one abstract, while for newsletter and looseleaf publishers it is more difficult because most of the individual stories within an issue will not have readily available abstracts. These are issues publishers will need to wrestle with. Watching what competitive publishers are doing can be instructive: for example, Multex displays the first few lines of every page for free for each of the major reports they sell. 2. Consider selling electronic versions of your premium content on-demand as a starting point Migrating online, a number of pricing regimes are available.3 The debate over whether electronic media cannibalizes existing print revenue streams – broadly known as ‘channel conflict’ – is certainly not over, but we find it is disappearing. If a Learned and professional society publishers are in a very strong position to succeed online Web strategies for professional publishers 85 L E A R N E D P U B L I S H I N G V O L . 1 3 N O . 2 A P R I L 2 0 0 0 publisher is still in the early stages, one suggestion is for it to start by offering bundled access for print subscribers and in addition sell individual items to nonsubscribers as pay-per-view (PPV). The broad market base for individual article sales reachable through the internet, a process that has become increasingly compromised in the past under papyrocentric publishing systems because of the price differentials, could then become a real revenue earning opportunity given the increasing r	archive;blue waters;cd-rom;comefrom;check point go;computer;consumer network;continuation;individual computers;internet access;internetworking;multics;niche blogging;open road tolling;phase-locked loop;printer (computing);printing;programming paradigm;pubmed central;server (computing);the forest;visual instruction set;web strategy;workbench	Donald C. Klein	2000	Learned Publishing	10.1087/09531510050145399	computer science;knowledge management;world wide web	AI	-67.46962640118645	-21.474929485132172	120362
a769b3d9e9f1186ddd2f67682aace4939b113683	"""negotiating """"messy"""" research context and design through adaptive research stances: experience report"""	researcher stance;community based research;communication design;actor network theory;methodology	Researchers in communication design increasingly find themselves conducting research in their own communities. Following posthuman and critical methodologies which suggest that research sites are often shifting and messy, this experience report argues that the positionality of researchers is equally dynamic and messy. We apply these methodologies to our own experiences as community based researchers, and sketch an adaptable heuristic for thinking through messy problems that researchers inhabiting similarity positionality might leverage in order to consider the ethical challenges of researcher positionality. Research positionality often carries tacit consequences for 1) researchers' immediate and enduring relationships with individuals and institutions, 2) researchers' ethics, 3) researchers' professional disciplines, and 4) the larger communities researchers seek to improve as citizens and end-users. This report argues that the positionality of researchers who also identify as stakeholders within the institutions and communities at study has been underappreciated and poses ethical and methodological challenges that warrant exploration.	heuristic;unintended consequences	Timothy R. Amidon;W. Michele Simmons	2016		10.1145/2987592.2987622	communication design;methodology;management science;management	HCI	-76.27664224038125	-11.469640720881015	120444
0e48c75b60323acef418dbaaade1f7dd08e00554	discovering hidden relations between tor marketplaces users		The cyber threat is highly dynamic and evolves in parallel with the innovation of systems and communications, which are outside the control of government authorities and respond exclusively to business logic and free initiative, often contingent on implementation of illegal activities. In particular, the threat posed by the criminal use of the Internet goes far beyond the cybercrime, in particular with the Tor network, where black markets are shifted with the shape of renown legal marketplaces as Ebay and Amazon. Hence even common crime can benefit of new modus operandi and new routes to deliver illegal goods or services, enforcing new investigation techniques to Law Enforcement Agencies (LEAs). This paper formerly analyses the goods/services categories of fourteen Tor marketplaces and the related vendors, while the last one provides a discussion on a novel investigative technique related to PGP Keys inter-relations. In particular, with the evolution/growth of the markets, the vendors are increasingly adopting open source tools and technologies, as PGP, which can be exploited to infer information such as the established relationships between users. This public information about the keys can be used to retrace social network of entities connected by PGP relationship and apply well-established graph analysis techniques. Finally, the paper analyses the strength and weaknesses of proposed methods, depicting future research directions.	business logic;contingency (philosophy);cybercrime;entity;open-source software;pretty good privacy;social network;tor messenger	Gianluigi Me;Liberato Pesticcio;Paolo Spagnoletti	2017	2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC-PICom-DataCom-CyberSciTec.2017.93	business logic;power graph analysis;marketing;law enforcement;the internet;government;social network;business;cybercrime	Security	-73.09391120994992	-10.71583770439598	120546
361ee588b64fb10995681fa846587ad7e2373b23	online zealotry: la france du peuple virtuel	jean marie le pen;anti immigrant;jeunesse;bruno megret;national front;france;website;political extremism;internet;nationalism	The Front National, a far-Right French political party which had long been ostracized and criticized by the mainstream media, was among the first to adopt a presence on the web as a means to publicize its goals. This article outlines the party’s growth, disaffection with traditional media and its online strategy using discursive analysis of the web site over five years. The article analyzes the internet as a site of cultural negotiation between the national discourse governed by dominant political parties and the more marginalized Front National. France, a centralized government, anxious about the cultural imperialism of English, at first resisted the introduction of the internet, but later promoted it to ensure the presence of French content. The Front National contested the more mainstream notions of French citizenship and nationhood and employed the internet as a catalyst and outlet for its ‘counter-knowledge’.	centralized computing;digital footprint;internet;linear algebra;web strategy	L. Clare Bratten	2005	New Media & Society	10.1177/1461444805054116	psychology;the internet;social science;nationalism;marketing;sociology;advertising;law;world wide web	Web+IR	-71.48628661006828	-13.623857758111091	120575
855cc0fe8902120e5495b9e66e66832233aa8e9e	intellectual property protection for multimedia applications. 1. so many flavors, so little time	patents intellectual property protection multimedia applications trade secrets copyright trademarks;copyright;multimedia application;intellectual property protection;copyright multimedia computing industrial property patents;multimedia computing;patents;industrial property;intellectual property trademarks copyright protection application software virtual reality libraries spreadsheet programs patent law telephony software design	ex woke up early Sunday morning, shuffled to his front porch, picked up the paper, and began readR ing one of the front-page stories. The Lotus Development Corp. v. Borland International Inc. copyright case had recently been appealed from a federal trial court in Massachusetts. The appeals court had decided that Lotus’ user-interface command hierarchy was a “method of operation” and was not subject to copyright protection.	analog television;flavors (programming language);lotus 1-2-3;user interface	Irah H. Donner	1995	IEEE Computer	10.1109/2.391064	internet privacy;law;intangible property;computer security;intellectual property	DB	-65.57156473690966	-23.630503453793246	120623
175158ae8c1fa2bda5ccdd0fec8a40f16dd8a3cf	what would an ideal chi education look like?	ideal chi education look	What would you select if someone asked you to develop an ideal professional education in CHI’s essential subject matter? If someone were to ask me, first I would check the core CHI curriculum for computer science departments that an ACM SIGCHI committee (including professor Ron Baecker, University of Toronto, and others) put together about a decade ago when they were trying to get such curricula accepted within universities. However, the times, technology, and users have changed considerably since then. Another way to quickly assemble a set of essential topics would be to merge and purge the tables of contents for two leading handbooks of human-computer interaction published by Elsevier and by Lawrence Erlbaum Associates. With apologies to the editors and authors (including myself), I have tried to do just that, somewhat quickly and informally. I contemplated simply listing the approximately 120 topics in alphabetical order, but I have tried instead to reduce seeming repetitions, use more consistent terminology, and maintain some of the original overall organization and sequencing, which suggests the sequence of topics in a curriculum. See below for the results. Noticeable in the original tables of contents was an absence of reference to financial and travel systems, branding, marketing, semiotics, user experience, design patterns, legal issues, and professional licensing/standards (currently minimal or nonexistent in the industry). Also missing is the notion that a professional might actually have to sell her/his services: Thus, “storyselling,” portfolio preparation, and other marketing of services principles/techniques are omitted. In fact, the last of these topics often populate many Internet-based discussions and email threads, because every year there is a new crop of novice professionals who seek advice from elder mentors on everything from acquiring disability insurance to how to deal with clients who won’t pay for services rendered. If I had to disaggregate further the above topics into undergraduate and graduate subjects, well, that is a major task that many institutions have already attempted with varying degrees of success. If I were asked where might I place special emphasis, I would suggest the following: I believe different regions of the Earth, different countries, different socioeconomic-political conditions may give rise to different needs and orientations to courses of study. For example, I was impressed recently by professor Gary Marsden’s graduate-student projects at the University of Cape Town, South Africa, which focused on somewhat unique, indigenous circumstances. Graduate student projects took on objectives of assisting nutritional training for young mothers suffering from HIV/AIDS, encouraging involvement of schoolchildren with aboriginal story-	chi;computer science;design pattern;email;human–computer interaction;internet branding;population;sigchi;semiotics;subject matter expert turing test;the times;user experience design	Aaron Marcus	2005	Interactions	10.1145/1082369.1082408		Graphics	-65.16554152336012	-22.34923845692171	120692
28466782ceb1cc45cb615ded10b2845ae99d8b9d	guest editorial special issue on power quality in smart grids		? Users may download and print one copy of any publication from the public portal for the purpose of private study or research. ? You may not further distribute the material or use it for any profit-making activity or commercial gain ? You may freely distribute the URL identifying the publication in the public portal ? Take down policy If you believe that this document breaches copyright please contact us at vbn@aub.aau.dk providing details, and we will remove access to the work immediately and investigate your claim.	download;electric power quality	Josep M. Guerrero	2017	IEEE Trans. Smart Grid	10.1109/TSG.2016.2634482	embedded system;electronic engineering;engineering;electrical engineering;smart grid	Robotics	-67.08743707854885	-18.176622824621955	121023
d205c147119ab4fa5254993a43533cf7bad6a243	quality as a function of quantity in electronic brainstorming	quality quantity model;computers;quality quantity model electronic brainstorming team theory problem solving process idea quantity idea quality low cognitive load high reliability method;information systems;conference_paper;electronic brainstorming;problem solving process;computer systems;team theory;idea quantity;counting circuits;springs;group decision support systems;idea quality;low cognitive load high reliability method;computer science;problem solving information systems springs computer science counting circuits;problem solving	The quality of ideas a team generates constitutes an upper limit on the quality of the problem solving process. Much research has been done about causes of idea quantity and causes of idea quality. It has been noted by some researchers that idea quality appears to correlate with idea quantity, and several have argued that it is not necessary to go to expense and effort required to evaluate idea quality since it correlates with quantity. This paper draws on Team Theory to develop a causal link between quantity and quality, It then presents a low-cognitive-lo4 high-reliability method for evaluating idea quality. It reports on a study that addresses the question, “Will an increase in idea quantity cause more good ideas to be generated?” The results support the hypothesis that there is a modest causal connection between quantity and quality, but the data suggest other factors are far more important for determining the number of good ideas a team generates. I t concludes that researchers must continue to measure the effects of their brainstonning treatments on idea quality; it is not smcient to assume that quality will always track quantity. Other factors not accounted for by the quality-quantity model may well counter and outweigh this effect.	causal filter;causality;goto;problem solving	Robert O. Briggs;Bruce A. Reinig;Morgan M. Shepherd	1997		10.1109/HICSS.1997.665465	computer science;artificial intelligence;operations management;management science;management;information system	PL	-70.8348016416227	-15.383681549048767	121039
c8a357f83a2344bfa6417253bfa21ff11f3d3467	news track		An increasing number of users are listening to antipiracy campaigns instead of music, according to survey results from the New York-based research firm, NPD Group. When it first began tracking music deletions last May, NPD found 606,000 U.S. households eliminated music stored on their PCs. Three months later, 1.4 million households deleted all music files saved on their home computers. Moreover, the firm found the number of households acquiring digital music via peerto-peer file-sharing services declined 11% in a single month. NPD credits the ongoing anti-piracy campaign by the Recording Industry Association of America (RIAA), including its move to sue hundreds of people alleged to have illegally shared music online, claiming publicity about the move led more consumers to delete music files. In a related survey, NPD notes that consumers’ overall opinion of the recording industry is suffering significantly due to the RIAA’s tactics.	copy protection;file sharing;new product development;peer-to-peer;personal computer	Computer Staff	2004	Commun. ACM	10.1145/962081.962093		Web+IR	-66.26380019526057	-22.164772301396773	121047
66f96b725a215190b378c07cb855acd84d36aac9	lifehacker: the guide to working smarter, faster, and better, 3rd ed., a. pash, g. trapani. wiley publishing, indianapolis (2011), isbn: 978-1-118-01837-8		In the third edition of Lifehacker: The Guide to Working Smarter, aster, and Better, authors Adam Pash and Gina Trapani offer what hey call a “computer manual meets productivity book” (xxiv). To hose unfamiliar with the term, a life hack is “a workaround or hortcut that overcomes the everyday difficulties of the modern orker” (xxvii). The goal of Lifehacker—the book, the popular webite, and its weekly videos—is to “discover, test, and create shortcuts nd tricks for making modern life easier and doing things better” han before (xxiii). Through hacks, people streamline their workows, focus their attention, and perform activities that matter. Readers can peruse the book cover-to-cover or “cherry pick” rom 121 tips. Each hack begins with its skill level, platform, and ost. Although the book was written in 2011 and parts may be outated, Pash and Trapani include links, allowing readers to delve eeper into the content if they choose. Users can also visit lifeacker.com or lifehackerbook.com for updates. A previous edition from 2008 had the same chapter headings n the same order, but the new edition includes “Work Smarter on our Smart Phone.” The authors provide a myriad of actions that an be performed on Google’s Android and Apple’s iOS operating ystems. Wisely, the chapter does not rely heavily on apps, which onstantly change. Tricks to improve typing, navigation, automaion, and controlling desktops remotely are proffered, as well as ow to make “dumb phones” smarter with a few SMS-enabled ools. In the first chapter, “Control Your Email,” the authors suggest ays to limit email usage to 30 min a day through a three-folder ling system: archives, follow up, and hold. Their advice on email tiquette and management is a necessary read, especially because mail correspondence and response time shapes people’s assessent of each other in the workplace. “Organize Your Data” tackles the best way to manage the inforation emails and other data systems contain. Using big bucket oncepts for storage and retrieval, the authors suggest filing sysems that are purposely simple—be it on your computer or your ling cabinet. Also included in this chapter is a trick for creating 100 ifferent passwords with one rule, a brilliant way to keep secure on he Web while using multiple websites. Lifehacker’s forte is not the technology tips, but the chapters evoted to productivity: “Trick Yourself into Getting Done,” “Clear our Mind,” and “Firewall Your Attention.” Future editions should onsider putting these chapters at the beginning, because they	adobe streamline;advanced spaceborne thermal emission and reflection radiometer;android;archive;data system;email;firewall (computing);forte 4gl;global information network architecture;han unification;international standard book number;john d. wiley;maxima and minima;password;response time (technology);smartphone;workaround;ios	Margot Note	2014	Int J. Information Management	10.1016/j.ijinfomgt.2013.10.008		HCI	-65.32294260367294	-21.866008965490813	121153
c1d86f400afacffa0a33edb8a5c5a065fa098da9	silver bullet talks with david rice	interview;interviews computer security identity management systems;david rice;silver bullet;gary mcgraw;the monterey group;computer security;economics of security;gary mcgraw interview silver bullet economics of security david rice apple the monterey group;interviews;identity management systems;apple	Gary McGraw interviews David Rice, formerly the executive director of The Monterey Group, a strategic consulting firm that focuses its services on cybersecurity and identity management. Now the director of global security at Apple, Rice has also served as a global network vulnerability analyst for the US National Security Agency and was a special duty cryptologic officer for the US Navy. Rice wrote Geekonomics: The Real Cost of Insecure Software (Addison-Wesley, 2007) and speaks at many events around the world. Hear the full podcast at www.computer.org/silverbullet or www. cigital.com/silverbullet.	computer security;global network;identity management;no silver bullet;podcast;world wide web	Gary McGraw	2011	IEEE Security & Privacy Magazine	10.1109/MSP.2011.38	interview;computer science;operations research;computer security	Security	-68.9603343860941	-10.891660616031334	121452
69f25f2fb6ae37d9ef7e8541ebbc76b19ac49291	security surveys spring crop	it security	What does the latest round of IT security surveys have to tell us? Stephen Hinde samples, savours and pronounces. Choose an option to locate/access this article: Purchase Export		Stephen Hinde	2002	Computers & Security	10.1016/S0167-4048(02)00404-2	computer science;computer security	Crypto	-68.72645243340942	-11.124041779822717	121550
10f197a6b82ed6b52b73ba897298e98be64048ac	the art and science of user services	science and technology;turnover rate;thermodynamics;organizational structure	We are all familiar with the great advances made over the years in all areas of science and technology resulting from the application of well known laws and principles. Among such laws are the laws of conservation of energy and mass, the laws of thermodynamics, and Newton's laws of motion.  We are frequently overwhelmed by the changes confronting us daily in our user services work. We experience changes in hardware, software, organizational structure, management, personnel, user education, consulting, documentation and physical facilities. The discipline of physics takes the whole universe of ubiquitous changes in stride and integrates them into unifying principles. In the midst of an ever-changing world, physics presupposes a constancy of nature, i.e. that identical conditions give identical results; that cause and effect relationships can be determined and applied to observed phenomena.  This paper will be a light-hearted trip in analogous thinking into a different perspective of the many changes we experience in our profession.  I shall explore how we might be able to use these classical laws of physics to ease our burden of coping with the changes we encounter daily. If our activities do obey these laws in a predictable and sensible fashion, then we can use these principles to help us. For example, the fundamental law of the conservation of energy states that energy can neither be created nor destroyed. From this law we can deduce that for a given level of user services personnel staffing, a maximum amount of work (energy) can be accomplished over a given period of time. Hence, priorities are set, either implicitly or explicitly. By clearly seeing the situation, realistic goals and expectations are possible. Perhaps such phenomena as staff personnel burnout and high turnover rates might be diminished by seriously applying such techniques.	causality;documentation;newton	Robert K. Shaffer	1982		10.1145/800067.802116	simulation;engineering;operations management;management		-66.96636620301834	-22.120686751571224	121617
0f3d0ab78464818dd294f1bf9d218278ebe51124	hypermedia management in television through text processing	information management system;television;journalism;document handling;gestion document;document audiovisuel;information systems;document analysis;gestion documento;information retrieval;text processing;user needs information;production process;hypermedia;analyse documentaire;traitement document;documento audiovisual;information management;audiovisual document;analisis documental;audio visual;journalisme;document processing;information system;periodismo;documentation;tratamiento documento;design methodology;document management	Purpose – This paper aims to describe a working routine for the analysis of audio-visual documents for serving the needs of television journalists. Design/methodology/approach – A description in the form of a synthesis is given of the process by which television information must be put at the user’s disposal with a response that is both fast and exhaustive. Findings – In television, there is a need to adapt the habits and methods of documentation to the productive processes of journalists in order to attain the common goals of information retrieval and reuse of the documents. Research limitations/implications – The main drawback of using this working method lies in the intensive use of large numbers of personnel with knowledge in specific areas. Practical implications – Well-designed hypermedia management based on knowledge of the creation processes in television will allow the construction of an information management system that adds value to the documents that have been analysed and facilitates the organisation’s creation of future audio-visual products. Originality/value – It is hoped that readers use this paper in a critical spirit to adapt it to their own particular requirements, and to serve as a guide both for setting up a document/information system and for organising such departments within the TV industry.	archive;documentation;hoc (programming language);hypermedia;information management system (ims);information retrieval;information system;requirement;television	Jorge Caldera-Serrano	2008	Program	10.1108/00330330810851573	computer science;electrical engineering;database;multimedia;information management;law;world wide web;information retrieval;information system	Web+IR	-72.57244717750037	-23.04421053146757	121717
0e4caac7226ddd07c1aaf5fe0df1ca48a94eede2	ten simple rules for getting grants	financing organized;research grants;careers;financing government;careers in research;scientists;government funding of science;institutional funding of science;eyes;fund raising;research support as topic;united states government	This piece follows an earlier Editorial, ‘‘Ten Simple Rules for Getting Published’’ [1], which has generated significant interest, is well read, and continues to generate a variety of positive comments. That Editorial was aimed at students in the early stages of a life of scientific paper writing. This interest has prompted us to try to help scientists in making the next academic career step—becoming a young principal investigator. Leo Chalupa has joined us in putting together ten simple rules for getting grants, based on our many collective years of writing both successful and unsuccessful grants. While our grant writing efforts have been aimed mainly at United States government funding agencies, we believe the rules presented here are generic, transcending funding institutions and national boundaries. At the present time, US funding is frequently below 10% for a given grant program. Today, more than ever, we need all the help we can get in writing successful grant proposals. We hope you find these rules useful in reaching your research career goals.	generic drugs;government funding;leo (computer);rule (guideline);scientific publication;scientific literature;funding grant	Philip E. Bourne;Leo M. Chalupa	2006	PLoS Computational Biology	10.1371/journal.pcbi.0020012	computational biology;bioinformatics;biology;citation	ML	-65.94840865781143	-20.376673147555483	121868
bc0eee1c07b9e3e21287474f3cd45dc856dafc41	bailii, legal education and open access to law	legal information;legal education;bailii	"""The British and Irish Legal Information Institute (BAILII) entered the online legal information landscape in 2001 with charitable status 3 as a provider of UK and European judgments, and has over the past decade or so moved from a system quickly put together with any materials which could be found, to a system which provides a core resource to professionals in law. In this article we provide an overview for the law teacher of the system’s first years and we then look at whether usage in law schools has matched that of the professional, how the JISC funded Open Law project enabled development for law students, and where we might go in the future as part of the Legal Information Institute collective which operates under the ‘Free Access to Law’ banner. 4 As members of the Open Law team who sought funding, carried out the research and implemented the project, it seems to us that the project was generally successful. Our indications were that prior to Open Law the use of BAILII by students was low – it was not readily found or discussed by lecturers, was difficult to use, and generally less user friendly than it could have been. The changes implemented by Open Law appear to have changed that position 1 Queen’s University of Belfast. BAILII Trustee. 2 Associate Research Fellow, Institute of Advanced Legal Studies, University of London. 3 The formal statement to the Charity Commission on the role of BAILII is: “For the public benefit: (1) to promote the sound administration and development of the law by:(a) the provision of one or more searchable and regularly-updated internet sites on which accurately-recorded case law, primary and secondary legislation and treaties from or affecting the jurisdictions of the United Kingdom and the republic of Ireland and associated jurisdictions are maintained together with commentary analysis and the maintenance of links to similar sources in other jurisdictions and (b) such other means of providing free or inexpensive public access to legal texts and commentaries of all kinds as the trustees shall from time to time determine; and (2) to advance legal education by promoting and encouraging research in the field of legal information systems and dissemination of the useful results thereof.” www.charitycommission.gov.uk 4 See the collection, Peruginelli, G. & Ragona, M., """"Law via the Internet: Free Access, Quality of Information, Effectiveness of Rights"""", (Proc. IX International Conference """"Law via the Internet'), European Press Academic Publishing, Florence, 2009 and Greenleaf G., """"Free access to legal information, LIIs, and the Free Access to Law Movement', in Danner, R and Winterton, J (eds.) IALL International Handbook of Legal Information Management. Aldershot, Burlington VT: Ashgate, 2011."""		Philip Leith;Cynthia Fellows	2013	European Journal of Law and Technology		public relations;legal research;legal profession;political science;management;law	HCI	-68.60830211378958	-18.67795912694599	122129
a962fe01dc517e02d72ff703b63291f8985d7752	healthcare it	healthcare;electronic medical records;health it;information technology	According to the Associated Press, the Centers for Medicare and Medicaid's (CMS) website, HealthCare.gov, has been sending consumers’ personal data to private companies that specialize in advertising and analyzing Internet data for performance and marketing (1). What information is being disclosed was not immediately clear, but it could include age, income, ZIP code, and smoking status. It could also include a computer’s Internet address, which can identify a person’s name or address when combined with other information collected by sophisticated online marketing or advertising firms. “We deploy tools on the window shopping application that collect basic information to optimize and assess system performance,” said CMS’s Aaron Albright in a statement. “We believe that the use of these tools are common and represent best practices for a typical e-commerce site.” There is no evidence that personal information has been misused. But connections to dozens of third-party tech firms were documented by technology experts who analyzed HealthCare.gov and then confirmed by AP. A handful of the companies were also collecting highly specific information.		Thomas Jepsen;Sunil Mithas;Chien-Yeh Hsu;George Kraft	2010	Studies in health technology and informatics	10.1109/MITP.2010.57	multi-core processor;parallel processing;application software;computer science;knowledge management;technology management;remote patient monitoring;data mining;data security;information technology;computer security	Metrics	-71.17747664338494	-11.32042875145055	122199
429e716667c2c634873d510ec46ae91f818fbf55	using ancient wisdom for better business	better business;ancient wisdom			John Gehl	2001	Ubiquity	10.1145/501289.501290	knowledge management;computer science	Vision	-65.70015278144214	-10.396803216582523	122292
6d75b97cc01703314e623624518d25a7913cc720	legal aspects for digital preservation domain		Through the use of ontologies the communication can be improved, which, in turn, can give rise to greater reuse, sharing, transparency, and inter-operability. Every digital preservation activity must ensure the authenticity and legitimacy of the performed actions and processes. Hence to validate the correctness of our legal ontology we used a set of competency questions defined in a specific case study. The goal is to obtain a clearer taxonomical view of the necessary legal knowledge that will address the concerns of industrial use-case digital preservation stakeholders.	case preservation;correctness (computer science);digital rights management;interoperability;ontology (information science);operability;taxonomy (general)	Barbara Kolany-Raiser;Marzieh Bakhshandeh;José Luis Borbinha;Silviya-Aleksandrova Yankova	2014			multimedia;digital preservation;computer science	Logic	-72.66650358415995	-14.537090022437251	122307
84cf3c70ab7425eca97c42ec3d25cb7b3cd3b7ea	it has been a long journey - from the heart of a loyal computer society volunteer	computers;software;eic s message ieee computer society;computers editorials software industries lead marine vehicles;industries;ieee computer society;marine vehicles;lead;editorials;obituaries;eic s message	Reflecting on a four-year EIC tenure offers an opportunity to say thanks and encourage continuing volunteer involvement.		Carl K. Chang	2010	IEEE Computer	10.1109/MC.2010.352	lead;telecommunications;software engineering;management;computer security	Visualization	-63.9253935802802	-18.12239878203436	122696
882366dae2dba31a0c99e6aca3eca698b0b3a584	acm opens portal	acm opens portal	"""W orks published by ACM since its inception have been built into a special online collection known as the ACM Digital Library. Nearly half a century of pioneering concepts and fundamental research have been digitized and indexed in a variety of ways in this resource. The retrospective capture for all ACM journals, magazines, and proceedings is nearly complete; filling gaps of out-of-print issues and refining the granularity of links will continue into the future. The user community has grown rapidly over the past three years. More than 36,000 individual members of ACM subscribe. Four hundred corporate and academic libraries and consortia serve an even wider community. Moreover, the level of activity has increased exponentially. In the last 18 months alone, there have been 13 million full-text downloads from the ACM Digital Library, an average of more than 200 downloads per article. This activity has forced ACM to expand its server capacity and bandwidth several times, well ahead of anticipated upgrades. Indeed, it has been an ongoing challenge to deal with the success of this resource. Thousands of users have contributed to the quality of this resource by reporting problems they encounter, spotting errors, and making suggestions for improvements. Broad community participation of this sort is not only welcomed by ACM; it is an essential factor in the evolution and enhancement of online facilities. Thousands of scholars have sent their comments to feedback@acm.org over the past few years. These have been analyzed and have resulted in the release of the ACM Portal. The fundamental components of the ACM Portal are an enhanced version of the ACM Digital Library plus an extended bibliographic database, consisting initially of more than a quarter-million citations of core works in computing. These works are of all types (journals , proceedings, books, technical reports, theses, among others), and from all the major publishers in the discipline. The ACM Portal thus provides an Online Guide to Computing Literature and a """" reading room """" for ACM's own literature in the ACM Digital Library. The ACM Portal has been built upon an entirely new system architecture to address primary concerns expressed by users around the globe: full-text download times, general system availability and performance, particularly the response times for searching. While ACM cannot do anything about the """" last mile """" of the pipeline, it has built a more robust system of parallel processors, redundant servers, vastly increased band-width, …"""	bibliographic database;book;central processing unit;digital library;download;last mile;library (computing);server (computing);systems architecture;virtual community	John White	2001	Commun. ACM	10.1145/379300.379304	theoretical computer science;computational science;computer science	Graphics	-67.06412939194563	-20.159165639424625	122930
84e8b44683c2fa7f206ad657d1b6b804fe9d64b7	web 2.0: a basis for the second society?	e government;public sector;web 2 0;second society	Web 2.0 applications gain in importance in today's society. This development cannot be ignored by the public sector, because Web 2.0 can take the evolution of E-Government in new directions. This paper discusses the impact of (local) Web 2.0 applications on the further development of E-government. Web 2.0 applications have much potential for the public sector in terms of interaction, participation and transparency. However, examples of websites with transaction or transformation characteristics are rare. For that reason it is too early to speak about a virtual state. In order to realize these two final stages of E-Government, it is important to take into account the potential risks of Web 2.0 applications as well, like isolation, exclusion, violation of privacy and misuse of information.	e-government;virtual state;web 2.0	Johan van Wamelen;Dennis de Kool	2008		10.1145/1509096.1509169	public relations;engineering;knowledge management;ws-policy;web engineering;world wide web	Web+IR	-74.23717507365896	-10.447969391837574	122941
2e23cd0cc4e9f0078de14d8ec960725e33bd395d	risks to the public		Edited by PGN (Risks Forum Moderator, Chair of the ACM Committee on Computers and Public Policy), with contributions by others as indicated. Opinions are individual rather than organizational, with usual disclaimers implied. We address problems relating to software, hardware, people, and other circumstances relevant to computer systems. References (R i j) to the online Risks Forum denote RISKS vol i number j. Cited RISKS items generally identify contributors and sources, together with URLs. Official RISKS archives are available at www.risks.org, with nice html formatting and a search engine courtesy of Lindsay Marshall at Newcastle; http://catless.ncl.ac.uk/Risks/i.j.html; also at ftp://www.sri.com/risks .	archive;computer hardware;google moderator;html;web search engine	Peter G. Neumann	2017	ACM SIGSOFT Software Engineering Notes	10.1145/3089649.3089653		Web+IR	-65.8365788248457	-17.827945572497775	122983
91c8af205cab21066226d5b6cf24134af1d2fcc5	letter from the dark side: confessions of an applications developer	application development	The usability/development drama sometimes feels like a wrestling match that both teams despair of winning. No matter which part you play, I'll bet you'll recognize yourself or someone you know in this month's column. Tom McCoy expresses in a delightful whinge the attitudes and resentments of the development team towards the imposition of usability as an add-on, and offers suggestions for improving the communication and the overall process.<br>---Elizabeth Buie	add-ons for firefox;dark side;james l. buie;programmer;tom gruber;usability	Thomas McCoy	2002	Interactions	10.1145/581951.581960	simulation;human–computer interaction;computer science;engineering;sociology;advertising;rapid application development;management;social psychology;law	HCI	-64.66728045283637	-23.934364883380603	123049
42795f5fa0d2cfc55c1ecfeffe4fd6eb4a49c788	science authorship - product support - information consumer				Henning P. Nielsen	2006	Inf. Services and Use			HCI	-64.67593497720662	-10.3432797768656	123193
3399e7b0198a5e7de286a129e6d885e587c3f0e1	editor's message to special issue on security and privacy considering human factor		While a lot of benefits are available from social systems supported by information technology, our daily activities are exposed to various threats including cyberattack and insider’s fraudulence. Therefore, information security technology is indispensable to bolster safe electronic social systems. As a relatively new study group, Security Psychology and Trust (SPT) has advanced researches focusing on human factors in information security. Even though information security measures have been promoted from two perspectives, i.e. technology and security management, an important role is played by human factors. For example, human elements should be definitely involved in on-line authentication technology and promotion of measures in security management is affected by decision-making by human (organization). Moreover, privacy cannot be considered without any human element. Amid such background, this special issue aimed at publishing research articles which have considered not only technology but human factors such as human behavior and decision-making in relation to security and privacy. Contrary to our anxiety whether adequate number of articles is submitted for the new research area, 17 out of 31 articles submitted were selected finally. Peer review was performed according to the peer review policy of Information Processing Society, i.e. “Don’t throw gem away if you can pick up stones too.” For that reason, conditions as a result of the first peer review were politely suggested even for articles with a lot of problems to urge responses. In addition to expressing respect to reviewers’ efforts, I felt it favorable as a member of editorial committee that many authors have responded to such suggestions during a short period of time. Besides, there was such an indication that requirement as a research article including analytical method was different from the corresponding field because we asked for experts in different fields to undertake peer review. It is believed that adjustment of peer review criteria of each field is an important role of metareviewer in order to promote researches interdisciplinary fields and that continued discussion is required as well. Finally, we would like to express our great gratitude to significant efforts by reviewers, members of editorial board, and all of those involved in the Society for their peer review of various articles within a limited period of time resulting in publication as scheduled. In particular, Dr. Kanaoka (TOHO University) and Dr. Nishioka (Iwate Prefectural University) who led the edition undertook preparation in detail to smoothly administer commit-	authentication;human factors and ergonomics;information processing;information security;online and offline;peer-to-peer;privacy;security management;smoothing;social system;symmetry protected topological order	Ayako Komatsu	2016	JIP	10.2197/ipsjjip.24.1	information privacy;computer science;internet privacy;world wide web;computer security	Security	-69.8651485785627	-13.681743013681023	123288
d0f1089b69d1fb961db91ce5c441cabb210d4f28	the invisible library: paradox of the global information infrastructure	bibliotheque;infrastructure information;text;research needs;globalizacion;global information infrastructure;bepress selected works;role professionnel;information infrastructure;cooperation;research design;library development;occupational role;library research;user needs information;information access;coleccion;scholarly communication;document preservation;cooperacion;research method;library science forecasting;recherche;library services;library role;collection;biblioteca electronica;conservacion documento;col;research methodology;library policy;acces information;preservation;library science research;acceso informacion;electronic library;mondialisation;conservation document;library collections;investigacion;biblioteca;information storage and retrieval;globalization;library;bibliotheque electronique;infraestructura informacion;rol profesional	LIBRARIES ARE AN ESSENTIAL COMPONENT of a nation’s information infrastructure, yet often they are invisible to their users and other stakeholders. In the context of this special issue, the paper presents four challenges faced by libraries and proposes research designs to address each of them. The four challenges involve: 1.invisible infrastructure, 2. content and collections, 3. preservation and access, and 4. institutional boundaries. I propose a mixture of research methods that includes surveys, case studies, documentaiy analyses, and policy analyses. Only with a better understanding of these challenges can libraries find their best fit in the information infrastructure of our networked world. INTRODUCTION Computer and communication networks now encircle the globe. Despite the oft-repeated claim that half the world’s population has never made a telephone call, we receive daily television, radio, and newspaper reports filed via satellite from Afghanistan, one of the planet’s leastdeveloped countries. Many of these reports become available almost immediately on the Internet. Information technologies have become ubiquitous in the developed world and widely available elsewhere. An increasing proportion of communication and commerce takes place via computer networks. Friends, family, colleagues, and strangers rely on e-mail to maintain relationships and to transact business. Most of the activities of writing, editing, and publishing involve computers and networks regardless of whether the final product appears online or on paper, makChristine L. Borgman, Professor and Presidential Chair in Information Studies, Department of Information Studies, Graduate School of Education and Information Studies, 235 GSE&IS Bldg., Box 951520, University of California, Los Angeles, Los Angeles, G490095-1520 LIBRARYTRENDS, Vol. 51, No. 4, Spring 2003, pp. 652-674 02003 The Board of Trustees, University of Illinois BORGMAN/THE INVISIBLE LIBRARY 653 ing “electronic publishing” a misnomer. Even in the “old economy,” orders are placed, invoices are paid, and credit cards are verified and charged via computer networks. Individuals turn to the Internet as a primary source for all sorts of information-health, hobbies, homework, news, shopping, music, games, research, and general curiosity. Libraries are but one of many institutions that could no longer function without computer networks, at least in the developed world. Libraries depend upon computer networks as a means to provide access to local and remote information resources. While physical materials continue to form the core of most library collections, fewer and fewer services require that users physically enter the library building. Even artifacts such as books can be ordered online for delivery to one’s home or office. A paradox of the networked world is that as libraries become more embedded in the information infrastructure of universities, communities, governments, corporations, and other entities, the less visible they may become to their users, funders, and policy-makers. Libraries must be integral components of the information infrastructure of their organizations if they are to provide the most effective, efficient, and appropriate services to their user communities. Independence and isolation are not suitable alternatives. Historically, libraries have played key roles in information-oriented societies. Yet today, some of their roles are being duplicated by other public institutions such as archives and museums and by commercial providers of content and services. Individuals and organizations now have many information sources alternative to those provided by libraries, which would suggest that the role of libraries is shrinking. However, libraries are expanding to include a wider array of services, such as providing digital libraries and support for distance learning. Despite this broader scope, libraries exist in a competitive environment, facing greater demands for services and often with fewer resources to meet those demands. Libraries can and should play key roles in the emerging global information infrastructure. To do so, they must address a number of complex challenges. Research on these challenges will assist libraries in identifying and accomplishing their roles in a global information infrastructure. The four challenges for libraries are introduced in a recent book (Borgman, 2000).Here I extend and update those issues, frame them as research questions, and suggest methods to explore them. INFORMATIONINFRASTRUCTURE A first step in exploring the role of libraries in a global information infrastructure is to consider what is meant by “infrastructure.” Familiar phrases such as “national information infrastructure” and “global information infrastructure” are rarely accompanied by clear definitions of the underlying concepts. Star and Ruhleder (1996) were among the first to de654 LIBRARY TRENDS/SPRING 2003 scribe infrastructure as a social and technical construct. Their eight dimensions can be paraphrased as follows: An infrastructure is embedded in other structures, social arrangements, and technologies. It is transparent, in that it invisibly supports tasks. Its reach orscopemay be spatial or temporal, in that it reaches beyond a single event or a single site of practice. Infrastructure is learned as part of membmhip of an organization or group. It is linked with conventions of practice of day-to-day work. Infrastructure is the embodiment of standards, so that other tools and infrastructures can interconnect in a standardized way. It builds upon an installed base, inheriting both strengths and limitations from that base. And infrastructure becomes visible upon breakdown, in that we are most aware of it when it fails to work-when the server is down, the electrical power grid fails, or the highway bridge collapses. Integrated library systems (i.e., automated systems that support core processing functions such as acquisitions, serials, cataloging, and circulation) offer a familiar example of an infrastructure within an organization. Following Star and Ruhleder’s (1996) model, we see that integrated library systems are embedded in the work practices of libraries and depend upon certain jobs and relationships in addition to specific technologies. They support the processing of materials and resources at multiple sites and enable remote access to cataloging and other databases twenty-four hours a day. Upon joining the community, both staff and patrons learn to use the systems and to develop certain expectations of services. Integrated library systems embody national and international standards, both library-specific (e.g.,MARC, 239.50) and general technical standards (e.g., Unicode, TCP/ IP).These systems build upon an installed base-usually consisting of cataloging records, holdings records, and other records in standard formatsand established practices. When the system breaks down-for example, when library catalogs cannot be searched, or when books cannot be renewed-then the infrastructure becomes very visible. Information infrastructure is only one type of infrastructure, but one that has at least three definitions. Firstly, the term “information infrastructure” is often used as a public policy construct to include technical capabilities of the network, rights and guarantees of network services, and means for funding development and for regulating the network. Some examples are the (U.S.) National information Infrastructure Act of 1993 (National information Infrastructure: Agenda for Action, 1993), the European Union proposal for a unified European information Infrastructure (Europe and the Global Information Society, 1994), and the Group of Seven (G7) Ministerial Conference on the Information Society (1995). This last document established a framework for a global information infrastructure. A second sense of the term “information infrastructure” is as a technical framework that incorporates the Internet and its services (National Research Council, 1994). The Internet is a network of networks, linking many layers of networks within organizations, within local geographic arBORGMAN/THE INVISIBLE LIBRARY 655 eas, within countries, and within larger geographical regions. The third sense of the term “information infrastructure” is as a general framework that encompasses a nation’s networks, computers, software, information resources, developers, and producers (National Information Infrastructure: Agenda for Action 1993).In this article, the term “information infrastructure” is used in this last sense of an encompassing framework. THEROLEOF LIBRARIES IN INFORMATION INFRASTRUCTURE Libraries are inherently information institutions. They are part of a nation’s information infrastructure in the third sense of the term (above). Libraries rely heavily on computers and computer networks, at least in developed countries. They select, collect, organize, preserve, conserve, and provide access to information resources. They provide an array of information services, and may also develop and produce content. Although these characteristics suggest that libraries would be considered central to the development of information infrastructure in most countries, few policy documents about information infrastructure mention the role of institutions such as libraries, museums, or archives in providing content or services. Clearly, it is up to the library community to identify and articulate its goals in information infrastructure and to act upon them. This article addresses several of the challenges facing libraries in determining their present and future roles in their nation’s information infrastructure and in a global information infrastructure. These challenges involve the following issues: 1. Invisible infrastructure 2. Content and collections 3. Preservation and access 4. Institutional boundaries These four topics were first proposed in Borgman (2000,chapter 7). Here I extend the scope of e	archive;book;case preservation;computer;curve fitting;database;digital library;email;embedded system;entity;freedom of information laws by country;information science;internet;job stream;library (computing);national information infrastructure;primary source;server (computing);spring;technical standard;telecommunications network;ucl department of information studies;unicode	Christine L. Borgman	2003	Library Trends		library science;information infrastructure;collection;library;computer science;engineering;globalization;law;world wide web;preservation;cooperation	Web+IR	-69.01072298165654	-21.163970968734503	123296
ea27b71b8b0bb22d353a26852169868ff38fb856	the cash is in the medium, not in the machine: toward the golden moments of 3d printing	technology marketing;3d printing;form theory;golden moment	Since 3D printing technology has been available as early as in the early 19 century, the present article start from the question why this radical and probably disruptive technology has been observed as only incremental innovation for so long time. In answering this question, we assume that this incrementalization of the supposed key to the next industrial revolution occurred due to circumstances that complicated and complexed the observation, with the most important of which being that 3D printers do not print on the medium, but rather print the medium, which emerges as form. In this article, this paradox is unfolded in the form of a form-theoretical theory statement on the inherently paradox nature of observation, subsequent to which 3D printing can be observed as both form and medium. In exploring this paradox, we will show that suppliers of 3D printing solutions currently try to sell 3D printing as form, whereas demanders observe 3D printing as medium. In focussing the latter side of the distinction, we finally suggest that the key to successful 3D printing business models will be in solutions that relate observations of the technological multifunctionality of 3D printing to a social multifunctionality lens.		Steffen Roth	2018	IJMTM	10.1504/IJMTM.2018.10010484	engineering;operations management;nanotechnology	HCI	-75.62959023627535	-11.764357913356822	123588
a33a9ff098006b8debcb76664724a126f4a0767b	writing about tcp/ip: challenges and a solution		This presentation explains how TCP/lP concepts are introduced in U-M Campus Data Networking Guide, an overview document published by the University of Michigan Information Technology Division for a general audience of students, faculty, and sfaf$ The presentation shows that basic TCP/lP services-those available across platforms-must be understood bebore moving on to the specifics of network connectivity and individual software packages. FINDING A COHERENT ORGANIZATION INTRODUCTION Initial drafts of the chapter on TCP/IP access included descriptions of the TCP/IP software supported by U-M’s Information Technology Division (ITD) and a short discussion of Internet access over serial lines. Scattered throughout the chapter were definitions of TCP/IP services and concepts such as clients and servers, telnet and FTP, and PPP-terms so crucial to an understanding of TCP/IP that they needed to precede the discussion of individual software programs, rather than be mixed up in it. Widespread use of TCP/IP-the Transmission Control Protocol/Internet Protocol-is transforming the world of communications and computer networking. The community of Internet users is growing exponentially-and many of its members are new network navigators who need information about TCP/IP services. As a result, user services staffs around the country are working hard to educate their users about TCP/IP access-from workstations in offices, computer labs, and homes; as well as from campus mainframes. Even more important was the fact that users need to base their choice of a TCP/IP program on the services it offerswhether it has an FI’P client, for example, or whether it supports PPP. These concepts need to be understood before the individual programs can be introduced and described. TCP/IP’s great strength-its ability to run across many platforms-is precisely what makes it difficult to document. Variations in the way people use TCP/IP make it virtually impossible to describe all the possible combinations of hardware and software, let alone the options for network connectivity. Many new documents are required-m a time when budget restraints are forcing many colleges and universities to cut back on documentation efforts. Luckily, in the early stages of preparing the chapter, I attended a workshop taught by Teri Adams and Richard Schmalgemeier, two of my colleagues at ITD. The one-andone-half-hour workshop, titled “Overview of Popular TCP/IP Products,” began with a detailed introduction to TCP/IP services and concepts, and ended with a brief overview of supported software. Based on what I heard at the workshop, I decided to revise my chapter on TCP/IP workstation access completely. Borrowing extensively from the workshop handout, I came up with a new organization for the chapter-an outline that takes users step-by-step through what they need to know in order to select TCP/IP workstation software: This paper focuses on the organization of a chapter about TCP/lP workstation access in U-M Campus Data TCP/IP Services (e-mail, telnet, ftp, finger, lpr, ping, setclock) Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributedfor direct commercial advantage, the ACM copyright notice and the title of the publication and ifs date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.	coherent;computer lab;documentation;email;internet access;internet protocol suite;mainframe computer;need to know;ping (networking utility);point-to-point protocol;server (computing);workstation	Susan R. Harris	1993		10.1145/263814.263925	multimedia;computer science;computer network;internet protocol suite	Networks	-65.63222875122052	-21.31376900954605	123728
074b3f702b7c6b5d77240172e088dfd41d92ab00	ipv6 transit: what you need to know	tecnologia electronica telecomunicaciones;tecnologias	Matt Ryanczak has worked as a system and network administrator, primarily on Linux and on Solaris, and other UNIX platforms, for the past 17 years. Throughout his career, Matt has worked in many different facets of information technology while employed at companies ranging from OEMs to Internet service providers and space and defense vendors. He is currently employed at the American Registry for Internet Numbers, where he serves as the network operations manager.		Matt Ryanczak	2010	;login:		telecommunications;engineering;advertising;computer security	Metrics	-68.93158368253289	-10.613988290806493	123732
cdacc10320f673f0923b05b54c94bba2d048a4d4	peerj - a case study in improving research collaboration at the journal level	peer reviewed;open access	PeerJ Inc. is the Open Access publisher of PeerJ (a peer-reviewed, Open Access journal) and PeerJ PrePrints (an un-peer-reviewed or collaboratively reviewed preprint server), both serving the biological, medical and health sciences. The Editorial Criteria of PeerJ (the journal) are similar to those of PLOS ONE in that all submissions are judged only on their scientific and methodological soundness (not on subjective determinations of impact, or degree of advance). PeerJ’s peer-review process is managed by an Editorial Board of 800 and an Advisory Board of 20 (including 5 Nobel Laureates). Editor listings by subject area are at: https://peerj.com/academic-boards/subjects/ and the Advisory Board is at: https://peerj.com/academicboards/advisors/. In the context of Understanding Research Collaboration, there are several unique aspects of the PeerJ set-up which will be of interest to readers of this special issue.	database;interaction;server (computing)	Peter Binfield	2013	Inf. Services and Use	10.3233/ISU-130714	library science;medicine;operations research;world wide web	Visualization	-74.93859488155972	-19.051200520479536	123843
41d0e7e30e50f99a91f4639b3df40a6138ec481b	astronomy: topology quest	mathematics and computing;cosmology;lab life	"""across the border from Austria to West Germany — a scene rendered poignant in light of the current European refugee crisis. The ease with which Vilcek procured job offers from US colleagues is also hard to imagine now. He joined New York University as an assistant professor with no interview, a beneficiary of the US government's competitive research investments during the cold war. The final section of the book I found the most original. Here, Vilcek reverts to the story of Remicade's success, and his unexpected wealth. His first quarterly royalty payment in 1999 was just less than his annual salary as a professor; by 2005, the portion of his future royalties pledged to New York University was projected to eventually reach more than US$105 million. At first, Jan and Marica ate at restaurants and caught taxis more often; they helped family and friends, and replaced their secondhand furniture with European art-deco pieces. But they had no interest in luxury living, so as the royalties grew, they established what would become the Vilcek Foundation in 2000. They began by supporting their workplaces , the New York University School of Medicine and the Metropolitan Museum of Art. They endowed professorships, lab space, scholarships and curatorships, earning a place among the top 15 US philanthropists of 2005. After the terrorist attacks of 11 September 2001, they began to see chinks in the US welcome for foreigners. Accordingly, in 2006 they launched annual Vilcek Prizes to recognize extraordinary achievements by immigrants to the United States in biomedical science and the arts and humanities. Aware that many of their prizewinners, from cancer biologist Joan Massagué to cellist Yo-Yo Ma, were already lauded, the Vilceks established annual prizes """" for creative promise """" in 2009 to honour up-and-coming talent. Prizewinners so far have included the Iranian-American scientist Pardis Sabeti, for her work on pathogen evolution (see N. This story is told humbly, with honest insight into the deliberations between the Vilceks and generous credit to the many people who have advised them. The couple clearly delights in following the careers of the awardees. Jan Vilcek is now in his early eighties, and he mentions in Love and Science how he and Marica have made provision for the foundation to continue when they can no longer administer it. One senses that he is happy with his legacy, both scientific and benevolent. ■ O ver the past …"""	iranian.com;jan bergstra;ver (command)	Michael Blanton	2016	Nature	10.1038/530158a	astrophysics;theoretical physics;cosmology;physics	Crypto	-64.40220479725805	-20.207357523450103	123894
185e4a8d30078d63c82ea1bb3754912d331dfe3a	identity theft in electronic financial transactions the experience of the central bank of spain	central bank;identity theft	Financial fraud usually goes hand in hand with the complex problem of identity theft in financial transactions. The experience gained in the Complaints Department through the presented cases and queries includes: rnrnrnTraditional falsifications in traditional financial transactions.rnrnrnThe most innovative forms of digital identity theft, which covers numerous cases of credit card fraud and the increasingly worrying cases of online fraud, which are troublesome because of the impunity with which, in most cases, criminals operate on the Net and because of the high sums that can be defrauded.rnrnrnCases of identity theft in the process of contracting financial transactions, with harmful consequences for those impersonated, as they are unjustly ordered to pay back debts and put on different defaulter’s lists, such as the CIRBE (or the ‘Risk Information Centre’ of the Central Bank of Spain).		María Luisa García Tallón	2008		10.1007/978-3-8348-9283-6_32	identity theft;bank statement;computer science;computer security;physics	DB	-70.62686410063013	-10.054391040367538	124213
aa7fbadb1ec5679b9b118843a828266811c85dba	what exactly is proactive reference? the columbus metropolitan library system tells its story: so far	bibliotheque;politica bibliotecaria;case history;public utilities;customer service;service utilisateur;historique;reference;library policy;service public;columbus metropolitan library;politique bibliotheque;servicio usuario;information system;user service;public service;public libraries;biblioteca;servicio publico;library;systeme information;proactive reference;sistema informacion;estudio historico	ABSTRACT Proactive reference at Columbus Metropolitan Public Library means librarians abandoning their traditional chairs and desks to seek out and greet patrons as they enter reference area. This article is written to share the CML story: The goals, planning, mustering of resources, and implementation that changed how CML conducts its customer service business. The article closes with one reference staff member describing working day using the proactive reference approach. This narrative shows how the various pieces of proactive reference fit together and the rewards that the staffs receive from being part of the innovation.	columbus;proactive parallel suite	Christopher Korenowsky	2005	Public Library Quarterly	10.1300/J118v24n03_05	psychology;social science;library;computer science;engineering;marketing;sociology;management;law;world wide web;genetics;economic growth;information system	Logic	-71.67414738670841	-20.820599628726495	124321
f5ebc41cc81785deec07bb789c853ed520436923	identifier schemas and research data		This work-in-progress paper presents the methodology and preliminary results of a study that develops a model for identifier schema evaluation and examines identifier schemas currently used for data referencing in the institutional digital repositories of the members of the Association of American Universities. The study’s findings can inform librarians, repository managers, scholarly communities, and publishers about the needs and requirements for an identifier schema to help discover, aggregate, and cite data as well as the issues and problems related to current uses of identifier schemas for data.	aggregate data;identifier;librarian;requirement	Dong Joon Lee;Besiki Stvilia	2012		10.1002/meet.14504901311	computer science;unique identifier;data mining;database;world wide web;information retrieval	DB	-72.59085765827919	-19.753996208555293	124370
0b48bacb32fbf0bc4991ae3c04177133e490cfae	loyal opposition - the sociology of open source: of cults and cultures			open-source hardware	Robert L. Glass	2000	IEEE Software	10.1109/MS.2000.10027	opposition (planets);public relations;sociology	Visualization	-64.83630544070515	-10.40991315912592	124460
fb87ca09d47e26868c29f46c02db30a0591c9af4	concepts and transformation: the international journal of action research and organisational renewal	action research	This international journal, popularly known as CAT, is now in its eighth volume, and has developed a distinctive niche. As is so often in the world of academic journals, a trail-blazing title can open a field which is then taken up by larger publishers, but this only serves to demonstrate the level of active interest. CAT resembles AI & Society in that it is led and edited by a committed core group, backed by an impressive international intellectual network, but lacks a permanent long-term institutional backing. Like other small enterprises, it has to fight to stay alive. There is no room for complacency. Just as AI & Society has developed the case for human-centred systems, counteracting the tendency to take a technocentric approach to new developments in technology and society, CAT has had an equally important central mission. It has laid the foundations for the renewal of research and practice concerning organisations, and organisational development, and has presented a series of case study accounts. It has not set out to propose an orthodoxy, but to enable a process of learning from differences. Together with the associated book series Dialogues on Work and Innovation (DOWI), from John Benjamins, it has put in place a core published literature, with signposts to key works from across the conventionally described disciplines. This has required intellectual insight and formidable tenacity on the part of the first two editors in chief, firstly Hans van Beinum, and now Werner Fricke. Both engage their authors in detailed dialogue, and this has now led to spirited debates in which issues raised in one article are taken forward and explored from different perspectives, by leading international researchers, with an increasing input from the developing world. The current central debate concerns the quality of action research projects and publications, and the appropriate use of case study material. CAT and DOWI have been closely associated with national and international programmes in enterprise development and working life, publishing reflections by leading researchers. AI & Soc (2004) 18: 293–296 DOI 10.1007/s00146-003-0292-8	ai & society;amiga reflections;artificial intelligence;niche blogging	Richard Ennals	2003	AI & SOCIETY	10.1007/s00146-003-0292-8	computer science;knowledge management;action research;operations research	Visualization	-70.70727502101626	-16.415987756724952	124470
7ed3975dccf9563c65d5a5269b651fe2821ea8d3	war of the words: intellectual property laws and standardization	economic incentive;legislation;legal system;standards;intellectual property;standards industrial property legislation standardisation;standardisation;intellectual property standardization law computer industry hardware legal factors protection standards development software standards drives;industrial property;copyright intellectual property laws standardization economic forces computer industry	It is noted that, while there are strong economic forces that drive the computer industry to develop and adopt common standards, both formal and informal, there is an inherent conflict between the intellectual property laws and the concepts of standards and compatibility. Intellectual property laws are intended to create temporary monopolies and to provide economic incentives to the owners of these monopolies, while exclusive ownership of standards is inconsistent with the very idea of a common standard. It is argued that court decisions relating to these issues and the scope of copyright, in particular, are confusing and technically illiterate in many cases, since the adversarial nature of the legal system fails to present the broader industry view of the need for standards and compatibility. It is concluded that, without some concerted industry action, the results of these cases may present significant problems to the industry and may encourage litigation, rather than standardization efforts.<<ETX>>	adversary (cryptography)	G. Gervaise Davis	1993	IEEE Micro	10.1109/40.248049	intangible property;standardization;intellectual property;civil law	Logic	-71.76882719298489	-12.010742536959823	124495
e923314df8d35984a36e98e172a09c75758dfba6	following snowden: a cross-cultural study on the social impact of snowden's revelations		"""Following Snowden: a cross-cultural study on the social impact of Snowden’s revelations Kiyoshi Murata, Andrew Adams, Ana María Lara Palma, Article information: To cite this document: Kiyoshi Murata, Andrew Adams, Ana María Lara Palma, """"Following Snowden: a cross-cultural study on the social impact of Snowden’s revelations"""", Journal of Information, Communication and Ethics in Society, https://doi.org/10.1108/ JICES-12-2016-0047 Permanent link to this document: https://doi.org/10.1108/JICES-12-2016-0047"""	ana (programming language);internet;nl (complexity);privacy;snowden;three utilities problem	Kiyoshi Murata;Andrew A. Adams;Ana María Lara Palma	2017	J. Inf., Comm, Ethics in Society	10.1108/JICES-12-2016-0047	psychology;management;social psychology;operations research	DB	-63.033749408965996	-13.676468108319948	124626
db8491a459b6324cd6c8a2be94c8659c82218068	"""correction and commentary for """"ocean forecasting in terrain-following coordinates: formulation and skill assessment of the regional ocean modeling system"""" by haidvogel et al., j. comp. phys 227, pp 3595-3624"""	calculation;correction;conservation and constancy preservation;methode calcul;corrections;modelisation;modelo;terrain following coordinates;split explicit time stepping;technique calcul;regional ocean modeling;calculation methods;modele;models;regional ocean model system	0021-9991/$ see front matter 2009 Elsevier Inc doi:10.1016/j.jcp.2009.09.002 * Corresponding author. Tel.: +1 310 206 9381; fa E-mail addresses: alex@atmos.ucla.edu (A.F. Shch Although our names appear as co-authors in the above article (Haidvogel et al. (2008) [1], hereafter H2008), we were not aware of its existence until after it was published. In reading the article, we discovered that a significant portion of it ( 40%, or 10 pages) repeats three large fragments from our own previously published work, Shchepetkin and McWilliams (2005) [2] (hereafter SM2005), but now presented in such a way that the motivation for the specific algorithmic choices made in ROMS and the relations among the different model components are no longer clear. The model equations appearing in H2008, Section 2.1 (taken from an earlier article, Haidvogel et al. (2000) [3]) are not entirely consistent with the actual equations solved in the ROMS code, resulting in contradictions within H2008 itself. In our view the description in H2008 does not constitute a mathematically accurate statement about the hydrodynamic core of ROMS. The purpose of this note is to clarify and correct this, as well as to explain some of the algorithmic differences among ROMS versions now in use. 2009 Elsevier Inc. All rights reserved.	like button;read-only memory;regional ocean modeling system;word lists by frequency	Alexander F. Shchepetkin;James C. McWilliams	2009	J. Comput. Physics	10.1016/j.jcp.2009.09.002	calculation;computer science;artificial intelligence;mathematics;thermodynamics;algorithm;statistics	NLP	-74.64166655802606	-20.465280459448	124817
89cf8586bb9fa033343a89755eaaac284916c0e5	the effect of citations to collaboration networks		In this paper we investigate collaborations in computer science based on the Association for Computing and Machinery (ACM) Digital Library dataset. We have constructed two types of network of collaborations one based on all publications and a second that only considers publications with at least one citation. We compare and measure the metrics for both the networks and we show that there are slight structural changes and significant fluctuations in the ranking of authors.	british informatics olympiad	Pramod Divakarmurthy;Ronaldo Menezes	2012		10.1007/978-3-642-30287-9_19	world wide web	ML	-76.64802873909548	-20.333023325617372	124841
cda706be2976341b76349f0fd9f360770b1205a1	sigchi: strategic plans revisited	strategic plan	ing our online communication (so we will redesign our website and news bulletin, and stimulate and support digital communities and our presence on social media); we are creating a new model for relating to local chapters (including an adjunct SIGCHI membership with no fee and real benefits, and an active local-chapters committee); and we are working on developing SIGCHI’s uniqueness, reassessing our model for peer-reviewed archival knowledge (including a video venue), creating better connections between research and practice, and considering multilingual issues. We aim to establish and stabilize relations with organizations such as UPA, HFES, and IFIP, and we will continue to support geographical development (Latin America and Africa are currently high priority). We aim at transparency regarding the review process for our conferences and at reducing costs for conference participation. We will continue to take initiatives and support HCI-related education (and we voted to spend a considerable amount of money on developing a realistic vision on the worldwide exchange of knowledge in our domain). And we need all the help we can get, so volunteers may contact us right away. —Gerrit C. van der Veer President, ACM SIGCHI	acm siggraph;archive;computer-mediated communication;human–computer interaction;international federation for information processing;sigchi;social media;venue (sound system)	Gerrit C. van der Veer	2013	Interactions	10.1145/2451856.2451875	human–computer interaction;strategic planning;engineering	HCI	-63.20729767537151	-17.636901661573226	124957
f3d21c4558aa19435fc76749fd32b53cbaa01728	"""or forum - a glimpse at an operation analyst's world war ii: """"report on the combat performance of the remote control turrets of b-29 aircraft"""""""	pedestrian safety;poison control;injury prevention;grupo de excelencia;tactics strategy;defense systems;safety literature;traffic safety;injury control;home safety;injury research;history of or;safety abstracts;human factors;ciencias basicas y experimentales;matematicas;occupational safety;safety;force effectiveness;safety research;accident prevention;violence prevention;bicycle safety;grupo a;poisoning prevention;falls;ergonomics;suicide prevention	"""Alex Green was a pioneering operations analyst/researcher for the U.S. Army Air Force during World War II. His February 1945 operations analysis """"Report on the Combat Performance of the Remote Control Turrets of B-29 Aircraft"""" was classified and buried for 70 years. Stationed in the China-Burma-India theatre and addressing a problem of combat losses posed by General Curtis LeMay, Green used written reports and interviews to draw conclusions regarding direction of enemy attack on the B-29s, opposite those of a large stateside simulation study. Resulting in LeMay's changes in B-29 flight formations and frontal armaments, his report also addressed B-29 gun dispersion adjustments and modifications to the analog computer in the plane's nose. This paper examines how Green drew his conclusions under wartime conditions before digital computers. Apart from the extraordinary advances in computer technology, much of his methodology is still relevant today and a part of operations research (OR). This paper offers a window into the origins of OR and remarkable efforts of its pioneers. Language: en"""	complex system;computer;material design;mathematical model;mathematical optimization;objectivity/db;openarena;optimization problem;optimizing compiler;remote control;simulation	Alex E. S. Green;Deborah S. Green;Richard L. Francis	2015	Operations Research	10.1287/opre.2015.1359	simulation;suicide prevention;human factors and ergonomics;injury prevention;management;computer security	AI	-68.50100803830186	-13.07497107168732	125181
bd8829a081a23f4e815eff0bb9ab825739c67211	open access strategy: either-or		Our journal comes in two versions: an on-line edition and a printed edition. For the on-line edition we follow a ‘green’ open-access strategy, under which neither readers nor authors pay the costs of publishing articles with us. The only source of revenue is the printed edition. The first ten library subscriptions completely cover the costs of printing and mailing of hard-copies, with further subscriptions regarded as a legal and legitimate contribution to the support of the mathematical community in running our journal and maintaining high quality and ethical standards of our publication. Unfortunately, the mathematical community at large has only little freedom to support this model of publishing, and libraries are entangled with batch subscriptions by commercial publishers that leave them little freedom to support open access journals. And why should anyone buy the printed edition, if the on-line edition is available free of charge? The answer is simple. If they do not support us by buying the printed edition, then our open-access model will have to change, and either authors or readers will have to pay. Since we are too small to carry the associated risks, we would eventually have to choose an established publisher to take over our journal. This, however, would increase the cost of access to the articles in our journal. In the first years of AMC we published 20 papers per year, and our annual production was 250 pages. Our current target is to publish up to 30 papers per year, with a total of at least 400 pages. This brings down the page costs to under 0.50 Euros for individual subscription, and under 1.00 Euros for library subscription. Our long-term goal is to reach the page cost of about 0.50 Euros also for libraries.		Dragan Marusic;Tomaz Pisanski	2012	Ars Math. Contemp.			Networks	-66.96496089109111	-19.999355394278528	125197
57b9621c87e035af3521a3053442917451967aaa	testing the science/technology relationship by analysis of patent citations of scientific papers after decomposition of both science and technology	patent;scientific citation;scientific vector;technology map;technological domains;co-evolve;00a06;c12;c89	The relationship of scientific knowledge development to technological development is widely recognized as one of the most important and complex aspects of technological evolution. This paper adds to our understanding of the relationship through use of a more rigorous structure for differentiating among technologies based upon technological domains (defined as consisting of the artifacts over time that fulfill a specific generic function using a specific body of technical knowledge). The key findings of the work are: Firstly, a Pearson correlation of 0.564 is found between technological relatedness among technological domains based upon patents citing other patents and technological relatedness among technological domains based upon patents citing similar scientific papers. This result indicates that a large portion of technological relatedness is due to relatedness of the underlying scientific categories. Secondly, the overall structure of the links found between scientific categories and technological domains is many-to-many rather than focused indicating a science-fostered mechanism for fairly broad “spillover”: Specific technological domains cite a wide variety of scientific categories; some scientific categories are cited in a variety of domains. Thirdly, some evidence is found supporting the co-evolution of science and technology but the evidence is not strong. Prior research that identifies emerging patent clusters and independent prior research identifying emerging scientific topics show statistically significant but qualitatively weak inter-relationships between the clusters and topics. This work also offers evidence that patent cluster emergence can, but does not usually, precede the emergence of related scientific topics. The lack of clear evidence for co-evolution is interpreted as resulting from the documented complex many-to-many relationship of science categories and technological domains and is not considered evidence against co-evolution.	emergence;generic function;knowledge spillover;many-to-many;scientific literature	Fang Han;Christopher L. Magee	2018	Scientometrics	10.1007/s11192-018-2774-y	science, technology and society;data mining;data science;knowledge management;sociology of scientific knowledge;scientific citation;technological evolution;computer science;spillover effect	Web+IR	-77.06178819275193	-17.84890292559112	125219
129514d4e1890552425668720406030c1fc7781b	indicators and revenues of database production and hosting in the united kingdom	etude marche;europa;serveur documentaire;base donnee;analisis estadistico;productor;on line;en linea;analisis cuantitativo;database;base dato;industria informacion;producer;host computer;statistical analysis;information industry;analyse quantitative;royaume uni;market survey;industrie information;united kingdom;analyse statistique;reino unido;estudio mercado;quantitative analysis;producteur;en ligne;proveedor documental;europe	UK figures. What exists is an ill-assorted corpus of data from a variety of producers such as trade associations, consultancy firms and market research organisations. Often the source and nature of such data, and their methods of collection and analysis, are unrevealed. Because this basic methodological information is unavailable, data from such sources cannot be assumed to be comparable. Despite these difficulties, there does appear to be an overall convergence of the significant indicators, sufficient to provide a plausible, if rather general, picture of the state of development of the sector. Another factor is the global nature of the sector, in which-by its very nature-there is a considerable element of both transnational activity and ownership. It is for this reason we have	text corpus	Harry East;Sandra Vogel	1992	J. Information Science	10.1177/016555159201800401	market research;computer science;quantitative analysis;database;information industry;operations research;host	Web+IR	-73.30528042677848	-21.526904693738473	125357
92afcc202c45f57eb88c948242c9d955b5b3646b	the citation gap between printed and instrumental output of technological research: the case of the electron microscope	bibliometrie;use;citation analysis;critical study;search result;trabajador cientifico;sciences;performance;bibliometria;analisis cita;produit recherche;indicador medida;etude critique;resultado busqueda;ciencia;utilizacion;estudio critico;utilisation;analyse citation;electron microscope;travailleur scientifique;instrument;instrumento;bibliometry;evaluation;measurement indicator;evaluacion;rendimiento;recherche scientifique;scientific research;scientifical worker;investigacion cientifica;indicateur mesure	The merits and shortcomings of bibliometric evaluation techniques are well known; the reliability of the techniques varies according to the discipline. For technology the reliability is small. The electron microscope is a clear case of extreme mismatch between the number of citations received and the impact of the instrument in a wide area of science. The instrument is comparable to a scientific publication in the way in which it is used and referred to in the literature. In this paper we estimate the size of the citation gap, i.e. the number of citations an author misses because the results of his research are made public in the form of an instrument instead of via an article in a journal.	bibliometrics;electron;journal citation reports;printing;rational clearcase;scientific literature	W. P. Van Els;C. N. Margriet Jansz;Cornelius Le Pair	1989	Scientometrics	10.1007/BF02017462	scientific method;performance;computer science;evaluation;operations research;citation analysis;world wide web;electron microscope	Theory	-76.0671588798134	-22.621274331607523	125557
3dd91926a72ba056f5a4c329336615b01a806f4b	structural and longitudinal analysis of the knowledge base on spin-off research	spin-offs;bibliometric study;citation analysis;co-citation analysis;knowledge base	Following the dynamism in spin-off research, in this study we conduct a structural and longitudinal bibliometric analysis of a sample of 812 articles on spin-offs published in 234 journals included in the ISI Web of Knowledge over a period of three decades. The analyses do not seek to establish a new conceptualization but rather to reveal the intellectual structure of the field and how it has evolved, and the profile of the knowledge network established in the three perspectives: corporate, academic and entrepreneurial spin-offs. The diversity involved in the three streams of spin-off research signals substantial differences. Theoretically, transaction costs, agency and the resource-based view have remained a foundation of spin-off research, albeit that research has been driven more by the phenomena than by developing the theory. The more traditional focus on corporate spin-offs was followed by emphasis on academic spin-offs and more recently on entrepreneurial spin-offs. This shift has been accompanied by a more business/management theoretical orientation, replacing a more financial and taxation-based perspective underlying corporate spin-offs. This study systematizes the existing stock of knowledge and raises avenues for additional inquiry.	bibliometrics;conceptualization (information science);knowledge base;web of science	Manuel Portugal Ferreira;Nuno R. Reis;Roberta M. Paula;Cláudia Frias Pinto	2017	Scientometrics	10.1007/s11192-017-2391-1	public relations;social science;economics;knowledge management;data mining;sociology;management;economic growth	Web+IR	-76.45994825588231	-17.36114155549553	125697
ebdf9f2f4e3169c8e8049a4a28f75d0930fb60a9	the scientific impact of mexican steroid research 1935-1965: a bibliometric and historiographic analysis	history;bibliometrics;mexico	We studied steroid research from 1935 to 1965 that led to the discovery of the contraceptive pill and cortisone. Bibliometric and patent file searches indicate that the Syntex industrial laboratory located in Mexico and the Universidad Nacional Autónoma de México (UNAM) produced about 54% of the relevant papers published in mainstream journals, which in turn generated over 80% of the citations and in the case of Syntex, all industrial patents in the field between 1950 and 1965. This course of events, which was unprecedented at that time in a developing country, was interrupted when Syntex moved its research division to the US, leaving Mexico with a small but productive research group in the chemistry of natural products.	bibliometrics;document;interrupt;kill pill;luna;palo;primary channel;scientific communication;tree accumulation	Yoscelina I. Hernandez-Garcia;José Antonio Chamizo;Mina Kleiche-Dray;Jane M. Russell	2016	JASIST	10.1002/asi.23493	bibliometrics;computer science;data science;world wide web	Theory	-75.53295933438577	-20.329573471722306	125838
141d8ec91620c4bfa9cc94a9b643e74a23c318b7	sponsored search auctions: an overview of research with emphasis on game theoretic aspects	game theory;nash equilibrium;search engines;keyword auctions;sponsored search auctions;settore ing inf 03 telecomunicazioni;mechanism design	We provide a broad overview of the research that has been conducted until recently on the design of sponsored search auctions. We mainly focus on game theoretic and mechanism design aspects of these auctions, and we analyze the issues associated with each of the three participating entities, i.e., the search engine, the advertisers, and the users of the search engine, as well as their resulting behavior. Regarding the search engine, we overview the various mechanisms that have been proposed including the currently used GSP mechanism. The issues that are addressed include analysis of Nash equilibria and their performance, design of alternative mechanisms and aspects of competition among search engines. We then move on to the advertisers and discuss the problem of choosing a bidding strategy, given the mechanism of the search engine. Following this, we consider the end users and we examine how P. Maillé ( ) Institut Mines-Telecom, Telecom Bretagne, 2, rue de la châtaigneraie CS 17607, 35576 Cesson-Sévigné Cedex, France e-mail: patrick.maille@telecom-bretagne.eu E. Markakis · G.D. Stamoulis Department of Informatics, Athens University of Economics and Business, 76 Patision St., Athens 10434, Greece E. Markakis e-mail: markakis@gmail.com G.D. Stamoulis e-mail: gstamoul@aueb.gr M. Naldi Dip. di Informatica Sistemi Produzione, Università di Roma Tor Vergata, Via del Politecnico 1, 00133 Roma, Italy e-mail: naldi@disp.uniroma2.it B. Tuffin Inria Rennes Bretagne Atlantique, Campus Universitaire de Beaulieu, 35042 Rennes Cedex, France e-mail: bruno.tuffin@inria.fr Author's personal copy	entity;game theory;guardian service processor;interaction;nash equilibrium;search engine marketing;web search engine	Patrick Maillé;Evangelos Markakis;Maurizio Naldi;George D. Stamoulis;Bruno Tuffin	2012	Electronic Commerce Research	10.1007/s10660-012-9094-8	mechanism design;game theory;simulation;computer science;marketing;advertising;nash equilibrium	ECom	-67.46508616223123	-14.708362577728243	125909
4ab25ca4421d651495a53386992a761111122eaa	what to do about google?	google search engines search bias;bepress selected works	Whether it is acting as a conduit, an editor, or an advisor, the search engine should put user interests first.	web search engine	James Grimmelmann	2013	Commun. ACM	10.1145/2500129	google panda;google hacking;google penalty;paid inclusion;organic search;search engine optimization;qwant;computer science;spamdexing;google penguin;internet privacy;search analytics;world wide web;information retrieval;search engine;scraper site	Theory	-67.52287283585467	-15.034146415456362	126094
7ac4fbb2db91af4a419ae7afa31edd6c4dbdb79c	another ode to paranoia	national security;security and privacy cyberattack indexed defense scenario based defense and principle based defense information technology;information technology;nonprofit bipartisan policy;us government administration;computer security;computer viruses;cell phone networks;computer security computer crime discrete event simulation terrorism condition monitoring cellular phones us government blogs banking pharmaceuticals;malware;cyberattack;scenario based defense;security and privacy;indexation;government policies;power grid;and principle based defense;power grids;cyber shock wave;national security nonprofit bipartisan policy cyber shock wave cyberattacks us government administration cell phone networks power grids;cyberattacks;indexed defense;public administration government policies national security power grids;role play;public administration	The nonprofit Bipartisan Policy Center recently conducted Cyber ShockWave, a series of simulated cyberattacks to role play the US government's response scenarios. The simulations included an attack on US cell phone networks and power grids and a scripted series of cascading crises. Former high-level government officials played the roles of senior administration and national security officials in responding to the various events.	high- and low-level;mobile phone;paranoia;shockwave;simulation	Phillip A. Laplante;Joanna DeFranco	2010	IT Professional	10.1109/MITP.2010.82	public relations;cyber-attack;actuarial science;computer science;national security;malware;management;law;information technology;computer security;computer virus	ML	-69.49545140641592	-10.346815806716139	126109
c3fa7d7c23c5052b1e6d280ec4ddcfed0b654589	why it's not damning to define the thing		"""I have always asked my peers, what is so horrible about this attempt to Define the Damn Thing (DTDT), as it is often called? Some tout it as a waste of time. As I hope I have illustrated here, this is far from the truth. Others find that it can't be done and that creating the examples is all the clarity we need, as we can point to X and say, """" Yes, that is X and X is good. """" Yes, we've done this with Apple's iPod and iPhone for what feels like Internet centuries, but what I've noticed is that when everyone points to it and says, """" Yes! That! I want that! """" they are all talking about a different part of """" that. """" This just leads to no one knowing what X really is. This all leads me back to clarity. Every time we accept when someone uses """" usability """" when they mean """" user experience """" —or worse, vice versa—we are fighting our own cause. We are demonstrating that we cannot create the content strategy and information architecture of our own work environment. When we proclaim that Apple iTunes has a great UX at the same time we point out—almost equally fervent-been one big overlap. The problem is that while A overlaps B and B overlaps C, this does not mean that A is related to C in a meaningful way, as many would like to believe. Because the collection of disciplines that make up UX practice overlap, and often very closely, we need to have more clarity about the discreet units of the disciplines themselves. The overlap of disciplines such as HCI, information architecture, and interaction design creates confusion and complication for those who have to consume, manage, negotiate , and value our services. They can do so better if we ourselves work on creating clear, uncomplicated messages and definitions. If our true job is clarity and meaning, it is fundamental that we describe our value to others in a clear and meaningful way. Otherwise, how can we, with any integrity, claim to be good at what we do? But this goes beyond saying A = x. It is also says that A is good at being = x. Maybe B is better at being = x. This is where A and B are two solutions that lead a user through an …"""	a/ux;content strategy;definition;human–computer interaction;information architecture;interaction design;usability;user experience;x window system;ipod	Dave Malouf	2013	Interactions	10.1145/2451856.2451860	human–computer interaction;multimedia;engineering;the thing	HCI	-63.30140052895853	-23.729260211900993	126189
337cc2101b35cbf89221661e74c4a8f477e5469e	complacency is the new normal: shifting public discourse on technological acceptability [editorial]				Jeremy V. Pitt	2018	IEEE Technol. Soc. Mag.	10.1109/MTS.2018.2876101		Vision	-65.64713481311152	-11.440574107465325	126365
003b4956389aaea8517ac53c6bde847e088c71ac	charlie gere's digital culture				Mike Leggett	2003	Digital Creativity	10.1076/digc.14.4.255.27883		HCI	-64.63876885740417	-9.939383669195747	126472
111965017ac67a29bfc09b0064243a6b11fc5992	'an intensity around information': the changing face of chemical information literacy	information literacy;chemical information;chemical documentation;qd chemistry;z665 library science information science	The changing nature of chemical information literacy over 50 years is examined by a comparison of a number of guides to chemical literature and information. It is concluded that: an understanding of the world of information is the sole aspect to have remained important and essentially unchanged over time; that knowledge of sources, ability to access information and ability to organize information have been of importance throughout, but have changed their nature dramatically; and that evaluation of information has gained in importance since the advent of the World Wide Web. The link between chemical structure and corresponding substance information is the most significant threshold concept. Information literacy in chemistry is strongly subject-specific.	cheminformatics;information literacy	David Bawden;Lyn Robinson	2017	J. Information Science	10.1177/0165551515616919	social science;computer science;knowledge management;information literacy;multimedia;world wide web;information retrieval	Theory	-73.46341229782149	-19.348920689434298	126615
355bd82a4aa98a043640117dae6ccf7355c50316	new paths through the histories of digital humanities - uncovering hidden contributions to busa's index thomisticus			digital humanities	Julianne Nyhan	2015				HCI	-63.58377319805838	-11.716524139251959	126878
91159589691c956983df3e68930049b11480f5c5	the future of forensic computing	forensic computing	For how long will a single ‘‘computer expert’’ be acceptable? Computer forensic experts are bombarded with a wide assortment of diverse media and file structures to examine. This is in contrast to the more specific focus of general forensic science branches such as fingerprint analysis or DNA analysis. This article puts forward the theory that digital forensics will become more like the traditional forensic community in the future, with analysts specialising in subsets of the media and file structures encountered. At any one time, there are probably only four types of people working in the field of digital forensics: those adducing evidence, those examining forensic evidence produced by others, those involved in forensic research and those involved in identifying ways of defeating the work of the other three. Unlike almost any other forensic professional, a digital forensic analyst must combine a deep understanding of a number of wildly disparate elements in order to provide a thorough, impartial and compelling analysis of the data being examined. Among these elements are: (i) the technologies involved, (ii) the sociological behaviour of the owner(s) of the media being examined, (iii) the volume and storage mode of data and (iv) the legal framework under which the analysis is being conducted. Unfortunately, or not depending upon	dna profiling;fingerprint	Andrew Sheldon	2005	Digital Investigation	10.1016/j.diin.2005.01.005	data mining;forensic science;computer science	HCI	-71.78748047044303	-14.409073871193334	126879
31de714c17beaf4a297dd2d49466ce1ca3ee639d	"""the """"two cultures"""" dichotomy reexamined"""	aspecto cultural;synthese documentaire;documentation synthesis;sciences humaines;statut culturel;sintesis documental;sciences;information technology;ciencias humanas;aspect culturel;aspecto social;technologie information;social aspect;literature;ciencia;cultural status;estatuto cultural;humanities;dicotomia;dichotomie;tecnica;new world;dichotomy;literatura;tecnologia informacion;litterature;cultural aspect;aspect social;technique;software process;new products	"""Recent discussions on the HUMANIST conference on Bitnet are but one manifestation of concern over the relations between humanists and technologists (including scientists and business people who use technology, especially computers). Focusing on the computer as an object that both unifies and separates these two communities, the discussants have broached a number of key topics, all more or less related to C. P. Snow's dichotomy of the """"Two Cultures."""" Among the insights from this conference worth quoting is S. Richmond's distinction between the humanists' traditional concentration on the product of their research/ criticism and their new involvement with the (computer-related) process by which those products are achieved:"""	computer	Estelle M. Raben	1990	Computers and the Humanities	10.1007/BF00115033	dichotomy;social science;philosophy;computer science;sociology;information technology;literature	HPC	-73.41683803709167	-20.845033952633404	127023
dda9bacf603fc9111104c6a5240127b41f103a31	how often should a firm buy new pcs?	new pcs	A nyone who has purchased a PC in the last 10 years knows the two basic results: the day after you buy a computer the price will drop, and as soon as you choose a computer a faster model will be released. While these factors may seem painful at the time, we are consoled by noting we will be able to buy faster, cheaper machines next year. But the real crux of the problem is how often should a you buy a new computer and what level of machine should you purchase? Technological change and investment requirements driven by Moore’s Law create the patterns we observe. Several writers [2, 3, 4, 6] have examined and attempted to measure these trends. As managers recognize, we all face the consequence of these trends when we purchase a computer [1]. Should we wait? Should we buy a faster PC? Should we buy the cheapest computer available? The problem with answering these questions is that it is exceedingly difficult to estimate the need or demand for computers. Even on a broader scale, researchers have found it challenging to identify the business impact of computers and IT spending. The productivity debate illustrates these problems [5]. A fundamental result of the performance and price changes is that organizations have to buy new PCs every few years. A conse-	computer;moore's law;requirement	Gerald V. Post	1999	Commun. ACM	10.1145/301353.301391		Theory	-63.29211028727374	-22.731510768576705	127050
8a19ff50a62760e596eab23b834cedf393f9367e	interdisciplinary minor in digital forensics, security and law	cyberlaw;homeland security;digital forensics;computer forensics;electronic communication;network security;information technology;capstone course;college students;learning environment;criminal justice;curriculum;information assurance;law enforcement;health insurance portability and accountability act;digital evidence;it management;electronic evidence;public administration	Digital forensics is playing a more prominent role in law enforcement, network security, and information assurance. The field of study encompasses not just digital evidence, but also the areas of cyber law, sociology, and security to name a few. Its increasing importance is reflected in its growing role within crime investigations, civil cases and homeland security.An in-depth understanding of digital forensics will be needed by college students who will be entering the various fields within technology, business, criminal justice, law, and homeland security. Currently, many professionals in those fields are not well-prepared to understand the use and management of digital evidence - or the use of digital forensics in determining the causes of security breaches, or the avoidance of security breaches altogether.Today, many professionals are working with others from different fields - lawyers are working with IT managers, members of law enforcement are working with forensics engineers. Well, at least they are trying. Unless properly prepared, many of these professionals will not be able to communicate and work effectively with each other. Those communications will continue in their frequency and importance. The demand for forensics and investigative work by knowledgeable professionals will continue to exceed the supply available for the foreseeable future.While some topics or courses in forensics and security will be needed in a variety of majors such as criminal justice and computer science, an enhanced level of study should be provided for those wishing to have a more solid foundation in digital forensics, security and law. By having students from different disciplines participate together in a minor in digital forensics, security and law, we hope to provide a richer learning environment.The curriculum discussed contains core courses in digital forensics, security and law as well as a capstone course. The curriculum also contains individual tracks in several areas for more in-depth study outside the students chosen major. The core courses within the minor cover digital evidence and its relationship to forensics, security and the law. Many areas of law are covered within the curriculum because of the ubiquitous use of computers and the importance of such acts as Graham-Leach-Bliley Act (GLBA) of 1999, Electronic Communications Privacy Act of 1986 (ECPA), Sarbanes-Oxley (SOX), Health Insurance Portability and Accountability Act of 1996 (HIPAA) and the USA PATRIOT Act.This article describes the background and the process of developing a minor in digital forensics, security and law to better prepare those students majoring in criminal justice, information technology and computer science. This article also presents information on extending the minor to students majoring in accounting, pre-law and public administration.	capstone (cryptography);communications of the acm;computer forensics;computer science;graham scan;health insurance portability and accountability act;information assurance;james oxley;low-energy adaptive clustering hierarchy;network security;privacy act (canada)	Glenn S. Dardick;Linda K. Lau	2005		10.1145/1095714.1095797	curriculum;homeland security;criminal justice;engineering ethics;computer science;engineering;electrical engineering;digital forensics;network security;management;law;information technology;computer security;computer forensics	Security	-71.53151834268911	-10.829720368919387	127219
5235edaad49449295c570a3f32faca1294ba685b	libraries and librarianship in qatar	bibliotheque;sector privado;echelon national;biblioteca nacional;articulo sintesis;secteur public;occupational training;bibliotheque universitaire;biblioteca especializada;article synthese;biblioteconomia;sector publico;arab countries;special library;bibliotheconomie;bibliotheque scolaire;qatar;public sector;secteur prive;biblioteca escolar;escalafon nacional;asie;formacion profesional;biblioteca universitaria;public library;pays arabes;librarianship;private sector;katar;paises arabes;bibliotheque specialisee;public libraries;bibliotheque nationale;review;school library;bibliotheque publique;biblioteca;library;national library;university library;formation professionnelle;asia;biblioteca publica;national scope	The infrastructure of libraries and information cen tres in Qatar consists of a national library, 24 public libraries, 20 school libraries, h university libraries, 150 special libraries and 150 private collections. Statistics on the collections, man power and services in these libraries are presented. Private libraries and library education in Qatar are discussed in detail, while curricula, courses and credits in library education are dealt with especially thoroughly.	library science	Shaban A. Khalifa	1992	J. Information Science	10.1177/016555159201800609	digital library;library;public sector;law;world wide web;private sector	Logic	-73.86127987696774	-23.34920856514856	127426
d7b5b292581916ab74371ea3f9dcececa025de13	editorial: aaai is now the association for the advancement of artificial intelligence	artificial intelligent	"""s our world becomes smaller, scientific communities are becoming increasingly international. National scientific societies are evolving to serve their international constituencies, and in doing so, have come to reconsider their roles, their purposes, their images, their identities, their """" branding, """" and, consequently, their names. This is such an occasion for AAAI as it embarks on its second quarter century. AAAI's membership has strong international representation. The same is true of the contributors to, and attendees of, AAAI, and AAAI-sponsored, conferences, symposia, tutorials, and workshops. A large fraction of our membership and an even larger fraction of conference paper submissions are from authors based outside the U.S. Beyond the annual conferences held in North America, much of AAAI's mission, activities, and membership are not well-characterized by the label """" American. """" In short, our original name does not reflect our dual roles, national and international, in the global AI community. Following this line of reasoning, the AAAI Executive Committee recommended changing the name of our organization from the """" Amer-ican Association for Artificial Intelligence """" to the """" Association for the Advancement of Artificial Intelligence. """" This proposal drops the adjective """" American """" from the organization's name but retains the AAAI abbreviation, logo, and """" brand. """" More importantly, the mission of the organization does not change. The new name simply reflects current reality and removes potential limitations imposed by the old name as we move forward in an increasingly global scientific environment. We have consulted with many of our sibling AI societies. We have no plans to change the scope or location of our activities as a consequence of the name change. The proposal initially received enthusiastic support from the AAAI Executive Council (unanimous with one abstention), and the Strategic Planning Committee, consisting of all past presidents and current presidential officers of AAAI. We then put it to a vote of the membership , which approved the proposal. The Executive Council has subsequently unanimously endorsed the name change. The membership at large shares our enthusiasm for this exciting new face for AAAI. We have complied with the regulations governing organizations such as AAAI in carrying out this name change. I would like, in particular, to thank our Executive Director, Carol Hamilton, and all our staff, for taking on the additional burden of executing the name change proposal in addition to all their regular duties. So I am delighted …"""	artificial intelligence;hamilton's principle;logo;our world;planning	Alan K. Mackworth	2007	AI Magazine		computer science;engineering;artificial intelligence;operations research	AI	-64.62098318721898	-19.173171833424195	127440
55fecda6d31700245dc44a3902fce3d8ad828c9f	drowning in the data deluge: digital library challenges for asia	information life cycle;data deluge;information retrieval;information infrastructure;information service;closed scholarly world;research data;scholarly information;digital library challenge;scholarly communication;data management plan;networked information	"""Scholarly communication no longer consists merely of papers and publications. Research data have become valuable objects to be captured, documented, and shared. Funding agencies are requiring """"data management plans"""" for all new proposals. Libraries, universities, and research institutes are assessing how to manage those data in ways that can be leveraged for future value. But what are """"data""""? We are drowning in them without being able to define what they are. This talk will explore the shifting landscape of scholarly information, with special attention to how these shifts may influence digital libraries in Asia. Research is disseminated by many formal and informal means, not only by libraries and publishers but also by new media such as preprint repositories and tweets. Access may be faster - if one can separate signal from noise amidst the plethora of communication channels. These changes are the result of the transition from a closed scholarly world to the open Web, the shift in content and context of networked information, the shift in focus from information services for readers to those for authors, and differences between publications and data. If future scholars are to use the scholarly content of yesterday, today, and tomorrow, the digital library community must reclaim information retrieval, rethink partnerships throughout the information life cycle, share responsibility for the information infrastructure, and address policy and incentive issues."""		Christine L. Borgman	2011		10.1007/978-3-642-24826-9_1	computer science;world wide web	EDA	-70.29376321152417	-19.338557688865855	127594
e8dc5d83562e4d351d0a50702ed7ff0500a157e0	be known by the company you keep: citations — quality or chance?	self citation;economie;economia;analisis citas;citation analysis;periodical;estudio comparativo;articulo;taille;etude comparative;autocitation;analyse citation;periodique;periodico;facteur influence;analisis regresion;quality criterion;critere qualite;autocitacion;talla;comparative study;analyse regression;regression analysis;economy;influence factor;recherche scientifique;size;scientific research;factor influencia;article;investigacion cientifica;criterio calidad	We examine the determinants of five year citations to papers published in the American Economic Review and the Economic Journal. Citations are positively related to page length and position in the journal. Both of these variables are consistent with the hypothesis that citations reflect paper quality, as is the number of subsequent self-citations. However, the publication of a major paper, as judged by subsequent citations, significantly increases the citations of other papers in an issue and this indicates the importance of chance in determining citations.		John Hudson	2007	Scientometrics	10.1007/s11192-007-1671-6	scientific method;computer science;comparative research;sociology;size;operations research;citation analysis;world wide web;regression analysis;statistics	ML	-76.31408966945035	-22.432214546122747	127727
d30e3c1c4f8cc2389dea9afef1f0ed46ca2aceca	community computing and the computing community	computer network;community computing;local community;network structure	We explore briefly the historical notion of community, and indicate how technology is changing our view of what constitutes a community. We then examine the kinds of value (information, communication and service) that can be and “ought to” be delivered over computer networks, and suggest adaptations of current network structures that could deliver these values effectively and efficiently. The focus will be on the local geographical community, and on the nature of interconnections between local communities. Finally, we consider technological and social challenges inherent in providing community computing and networking. THE INDIVIDUAL’S WORLD VIEW Whatever else can be said about the universe, it is not absolute. Each of us is, in our own view, the center of it; thus it has one cente~ it has many centers; it has no center. The way you and I perceive the universe, or any part of it, will depend on our unique perspectives. We do not necessarily value the same things, and the value of a thing to us depends upon how it relates to us as individuals. In the highest sense, we would like to believe that Technology exists to serve people in the pursuit of higher human values such as knowledge, creativity, community, culture, integrity and wisdom. Technology is not an end in itself, but serves to empower, to connect, to enhance, and to assist. Even in that context, however, the role of technology is subject to personal interpretation. The value of the technology to an individual depends on that individual’s personal goals. Such goals may be subsumed in the above list, or may be more immediate goals such as to save effort, save time, make money, exert influence, or cultivate friendships. From our individual perspective, the world can be viewed as a large onion, with the self at the core. Subsequent layers might correspond to family, neighborhood, community, area, state, region, nation, and finally world. In a narrow sense, one might think of individuals interacting within alfamily; families interacting within a neighborhood; neighborhoods interacting within a community, and so on. In practice, of course, the various kinds of interactions are far more complex than this; indeed, from our individual perspective, it is we, as individuals, who interact with various amalgamations of other individuals. WHAT IS COMMUNITY? When we hear of a neighborhood, many of us automatically think of some collection of homes or other living units in geographical proximity. Indeed, that is essentially the dictionary definition of neighborhood. However, technology and Fred Rogers began a redefinition of neighborhood more than a quarter century ago, and the term has come to include mental/spiritual proximity in addition to geographical proximity. Similarly, “Community” at one time tended to connote geographical proximity (city or town), although it has also been used to indicate some more tightly-focused commonality of interest as well. We are used to hearing about a “University Community” in conjunction with an institution of higher education or a “Community of Faith” in conjunction with a church. Historically, neighborhood and community have been defined in terms of geographical boundaries, technological boundaries (such as local telephone calling area), and political boundaries. More recently, new forms of community have been defined by social boundaries, technological boundaries, and experiential boundaries. What characterizes community in the modern world, then, is lmerely some form of interdependence: perhaps a common geographic location, or common interests, or common beliefs, or common culture, or common experience. TECHNOLOGY AND COMMUNITY Technology has fostered new forms of community by dramatically diminishing the importance of the old boundI Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its akzta appea~ and notice is given that copying is by permission of the Association for Computing Machinery, to copy otherwise, or to republish, requires a fee anoYor specljic permission. 01994 ACM ISBN 0-89791-656-5/94/459940 $3.50 Meet the Shadowy Future 35 aries. Television has for years had the capacity to bring world events into our personal space in a timely and dramatic manner. However, that does not, in general, inject our person into the world space, and so does not involve us personally in a community. On the other hand, computers and particularly computer networking have had the opposite effect; they let us as individuals explore the world space and (more or less frequently) “meet” other people. This tends to make us as individuals feel we are a part of a community (whether or not we actually are). In any case, technological networking has dramatically decreased the importance of geographical proximity and other factors that used to be definitive of community, and has fostered the development of geographically and politically diverse communities formed around common interests, common beliefs, or common experiences. The Computing Community is at once the parent and the child of modem computing technology. WHAT’S OUT THERE? At times, the discussion of the marvels of “the Internet” seems to be all hyperbole and no substance. Everyone knows “the Intemet” is a Good Thing, but comparatively few can provide ready examples of benefits that have accrued directly from the existence of computer networking. Many of the arguments for acquiring new technology seem to follow the Field of Dreams philosophy, “if you build it, they will come.” In the case of technology, however, “they” sometimes seems to refer to nothing more than bucketful of bits. Clearly, none of the technology is free. Equipment costs money; transportation of data costs money; and all of it occupies a great deal of effort on the part of many different people (which, after all, money was invented to represent). Somebody has to pay for all this; and that somebody is clearly the person at the center of the universe. Let us consider, then, what resources in the various layers of the universal onion might be valuable to an individual. Personal and family resources tend to be “my own” private resources. Personal computers and software, if it’s perceived that this will somehow advance our progress toward our goals. If we make that investment, most likely we have some personal information that we store on our personal computer; such things as financial records, an inventory of our “stuff,” family history, our embryonic bestselling novel, and so on. We may buy an encyclopedia on CD-ROM, baseball statistics, or other information of interest to us. If we see good reason, we may invest in a telephone line and a modem so we can get beyond our personal space. In all these cases, we justify these expenses to ourselves, in conjunction with our other priorities. In most cases, unlike the ones to follow, information stored on personal or family computers is not intended for public access. 36 Neighborhood and community resources are available on many college and university campuses through the Campuswide Information Systems. These systems typically include such items as telephone directories, events calendars, policies and procedures, university catalogs, and other information for delivery, although some include facilities for applying for admission or getting a computer account. At present, neighborhood and community resources are available by network in only a few cities and towns, but the number is growing rapidly. Things such as local government services, community calendars, and telephone books are only a few of the features that could be included in such a system. The pattern of these two layers continues throughout the remaining layers of the universal onion. Each layer may add its own value (services) to the network, and one of the values each layer may add is access to other layers of other onions. So, for example, in an regional computing system, one might find access to other state computing systems within the region, in addition to access to information on regional resources such as the National Center for Supercomputing Applications at the University of Illinois. Examples are not difficult to come by, and we will not belabor them here. Most resources at the outer layers of the onion are things that are, or have historically been, available in other forms. Telephone directories, for instance, are routinely printed and distributed for most communities (geographical and otherwise). The cost of making these resources available via network must be borne by someone, and the benefit of doing so must justify the cost. Either the individual seeking the information will pay, or the organization supplying it will. The information or service will continue to be a viable part of the network only so long as someone benefits enough to continue footing the bill. WHAT ISA NETWORK? We need to distinguish between the structural network and the conceptual network. Structurally, a network consists of things to be connected together (“nodes”) along with cables and electronics necessary to move signals from one node to another. In our onion model, the self can be networked to the self by a standalone computer (these are of decreasing size and increasing portability, so we will not discuss the obvious counterexample of home vs. oi%ce). In many families, a single standalone computer is adequate, although some families are connecting multiple computers together via local area networks. Connections from the family environment to other layers tend to be via telephone line and modem. While this can typically connect one with any layer, the advantages of connecting to a resource within the local calling area are, in most cases, obvious.	acm/ieee supercomputing conference;algorithms for recovery and isolation exploiting semantics;cd-rom;dictionary;dreams;fred (chatterbot);freedom of information laws by country;geographic coordinate system;graphics pipeline;information systems;interaction;interdependence;international standard book number;internet;lexical definition;modem;money;national center for supercomputing applications;onion model;personal computer;personally identifiable information;printing;software portability;telephone line;television;towns;value (ethics)	J. Michael Yohe	1994		10.1145/196355.196396	utility computing;grid computing	HCI	-68.65515941907614	-20.931952298051037	127983
4ea63a693f9766ec5fe575e24fb3d72989c97f33	the individual in the new age.	legally speaking;new age	T his is a proud statement to make. In many countries, in many times, people have been persecuted for this ideal and for their attempts to live up to it. Many are still persecuted today. What worries me is the real danger that, in the age of computing and the Internet, this ideal may be quietly facing a final stand. And it may not survive. First I define what I mean by being an individual. To me, it means the right to separate myself from others, and particularly the right to stand separate from the state. It is this latter characteristic that most concerns me. We are familiar with the debate on privacy. The words “Clipper Chip,” “CALEA,” “encryption,” and “Carnivore” are hot-button topics in the computer professional community. Yet, privacy is but one aspect of what it means to be an individual. Remove privacy, and one can still be an individual, albeit at great risk of ridicule and retribution. However, remove the concept of the individual and privacy becomes meaningless: there can be no right to keep private what belongs to the state; if I am not an individual, what I am and what I do belongs not to me, but to the state. So why is this distinction important? Because it rephrases the debate. Dilution of privacy can be justified on many grounds, usually in the name of law enforcement, security, and safety; the U.S. Constitution permits “reasonable” invasions of privacy. Dilution of the individual, however, is more serious, and more rarely permitted. Witness the “beyond a reasonable doubt” standard in criminal cases. Since we are, in fact, engaged in a war over the right of the individual to remain separate from the state, we must frame the question correctly, to take back the quarter given when mere privacy is the issue.	carnivore (software);clipper chip;encryption;internet;mass effect trilogy;privacy	Andrew Grosso	2001	Commun. ACM	10.1145/379300.379325	age of majority	Security	-71.46074627002099	-12.238635816142995	128076
2e5681ef59461532e8c8f41812b366bef433372a	workshop on contextual information access, seeking and retrieval evaluation	contextual information	There are three parts to this talk – related in rather tangential ways. First, I will give a recap of an argument developed in a couple of earlier talks – at IIiX in 2008 and at the SIGIR evaluation workshop in 2009. The gist of the argument is about thinking about IR as a science, and the consequences Appears in the Proceedings of The 2nd International Workshop on Contextual Information Access, Seeking and Retrieval Evaluation (CIRSE 2010), March 28, 2010, Milton Keynes, UK. http://www.irit.fr/CIRSE/ Copyright owned by the authors. for both theory and experimentation in the field. The second makes use of some ideas from general systems theory and the notion of open systems, and applies these ideas to information retrieval and the task context of search. The third discusses the status of queries in the current search world, and suggests two new ways to think about queries.	cardiovascular and interventional radiological society of europe;gist;information access;information retrieval;open system (computing);systems theory	Bich-Liên Doan;Joemon M. Jose;Massimo Melucci;Lynda Tamine	2009		10.1007/978-3-642-00958-7_89	computer science;knowledge management;contextual inquiry;data mining;information retrieval	NLP	-63.741358697253965	-14.370434829701848	128227
a45ed7c0b97472448a97b661ec873f77eaafc04c	international collaboration in scientific research in vietnam: an analysis of patterns and impact	country effects;journal impact factor;vietnam;citation rate;bibliometrics;developing country	The present study sought to examine the trend and impact of international collaboration in scientific research in Vietnam during the period after the introduction of the a reform policy and the normalization of relations with the United States. Using the Thomson Reuters’ Web of Science data (2001–2015) we found that 77% of Vietnam’s scientific output (n = 18,044 papers) involved international collaborations, with the United States and Japan researchers being the most frequent partners. The proportion of international collaborations has decreased slightly over time at the expense of an increased rate of domestic collaborations. The rate of growth in Vietnam’s scientific output was 17% per annum, and three-quarters of the growth was associated with international collaborations rather than purely domestic production. Moreover, internationally coauthored papers received twice the average citation as domestic papers. Of note, papers with overseas corresponding author had higher citation rate than papers with domestic corresponding author. These data suggest that the vast majority of scientific papers from Vietnam was attributable to international collaboration, and this had a positive impact on the quality and visibility of Vietnam science. The data also indicate that Vietnam is in the growth phase of building up research capacity.	scientific literature;web of science	Tuan V. Nguyen;Thao P. Ho-Le;Ut V. Le	2016	Scientometrics	10.1007/s11192-016-2201-1	development economics;social science;developing country;bibliometrics;computer science;operations research;world wide web;economic growth	HPC	-77.10984298896284	-20.44844491469373	128557
2d53a48c5746e105d4fec7d9386cc31f7062953a	using free software for elastic web hosting on a private cloud	elasticity;web hosting;distributed computing;load balancing;cloud computing;free software	"""Even though public cloud providers already exist and offer computing and storage services, cloud computing is still a buzzword for scientists in various fields such as engineering, finance, social sciences, etc. These technologies are currently mature enough to leave the experimental laboratory in order to be used in real-life scenarios. To this end, the authors consider that the prime example use case of cloud computing is a web hosting service. This paper presents the architectural approach as well as the technical solution for applying elastic web hosting onto a private cloud infrastructure using only free software. Through several available software applications and tools, anyone can build their own private cloud on top of a local infrastructure and benefit from the dynamicity and scalability provided by the cloud approach. is Amazon’s Elastic Compute Cloud (EC2) (Amazon, n. d.), which even predates the term “cloud computing” (Figure 1) and can be seen as the foundation of this type of computing. Migrating to public clouds is often said to lead to lower capital expenditure, as there is no up-front cost for buying infrastructure, having floor space for it etc. Instead, the costs incurred by cloud computing relate to operational expenditure, for example if using a cloud provider with pay as you go scheme. While it is questionable that the total cost of either buying and running a server or buying capacity on demand from a cloud provider can be compared directly with each other, the whole burden of operating a data center, controlling and managing the infrastructure etc. is removed if a cloud provider is used(Golden, 2009). DOI: 10.4018/ijcac.2011040102 International Journal of Cloud Applications and Computing, 1(2), 14-28, April-June 2011 15 Copyright © 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. Exactly this lack of control over the infrastructure is what puts cloud users at risk. Richard Stallman, president of the Free Software Foundation, coined the term “carless computing”, stating that users should rather keep control over their own data and not hand data over to providers that move it to unknown servers at unknown locations (Arthur, 2010). Additionally, with public cloud providers, the problem of vendor lock-in always exists. Vendor lock-in “is the situation in which customers are dependent on a single manufacturer or supplier for some product (i.e., a good or service), or products, and cannot move to another vendor without substantial costs and/or inconvenience” (The Linux Information Project, 2006). The costs of lock-in to a customer can be severe and include, amongst others, “a substantial inconvenience and expense of converting data to other formats” and “a lack of bargaining ability to reduce prices and improve service” (The Linux Information Project, 2006). Besides the lack of control over the placement of one’s own data and vendor lock-in, other problems exist with private clouds, as with any business offer: the provider might decide that it is no longer interested in providing service to a customer, thereby disrupting the clients business, at least temporarily. This has happened, for example, to the non-profit organization WikiLeaks (Gross, 2010; MacAskill, 2010). The question is then: is there a viable alternative to public cloud providers which retains some of the flexibility one gains by moving to the cloud? And the answer to this question, luckily, is positive: yes, there is an alternative and it is building a private cloud. A private cloud is essentially the same thing as a public cloud, only hosted on a private network on one’s own physical infrastructure. Obviously, the host of a private cloud has to care about his own resources, which means that there are no upfront advantages for CAPEX. This, however, is less valid if a physical infrastructure already exists and is – either totally or partially – changed to a virtualized infrastructure. OPEX will probably be reduced when staying on one’s private cloud and not going to a public cloud, with the added advantage of having total control over the physical infrastructure, thereby avoiding the problems mentioned above. Private clouds seem to be of more and more interest, as can be seen in Figure 2. But how can one turn private, non-virtualized physical resources on one’s site into a private cloud? This transition is not too difficult, as we will demonstrate in this work. Building up this knowledge might be an up-front investment but can be cheaper in the long run, all the while keeping the advantages of a private cloud in mind. We will describe how one can turn an existing in-house cluster of physical hosts into Figure 1. Search volume of the terms “cloud computing” (blue) and “Amazon ec2” (red) according to Google Trends (Google, 2011a) 13 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/using-free-software-elastic-"""	cloud computing;real life;scalability;web hosting service	Roland Kübert;Gregory Katsaros	2011	IJCAC	10.4018/ijcac.2011040102	cloud computing security;internet hosting service;cloud computing;computer science;cloud testing;distributed computing;utility computing;internet privacy;world wide web	Web+IR	-68.96469596339966	-14.249745846490152	128596
0f439f0a8137103a332e24c334852485513d335c	report on the second semat workshop on general theory of software engineering (gtse 2013)	second semat workshop;software engineering;general theory	Software engineering needs a general theory, i.e., a theory that applies across the field and unifies existing empirical and theoretical work. General theories are common in other domains, such as physics. While many software engineering theories exist, no general theory of software engineering is evident. Consequently, this report reviews the emerging consensus on a general theory in software engineering from the Second SEMAT General Theory of Software Engineering workshop co-located with the International Conference on Software Engineering in 2013. Participants agreed that a general theory is possible and needed, should explain and predict software engineering phenomena at multiple levels, including social processes and technical artifacts, should synthesize existing theories from software engineering and reference disciplines, should be developed iteratively, should avoid common misconceptions and atheoretical concepts, and should respect the complexity of software engineering phenomena. However, several disputes remain, including concerns regarding ontology, epistemology, level of formality, and how exactly to proceed with formulating a general theory.	icse;ontology (information science);semat;software engineering;theory	Pontus Johnson;Paul Ralph;Michael Goedicke;Pan Wei Ng;Klaas-Jan Stol;Kari Smolander;Iaakov Exman;Dewayne E. Perry	2013	ACM SIGSOFT Software Engineering Notes	10.1145/2507288.2529923	computer science;engineering;software engineering;management science;management	SE	-74.0550025531966	-16.094873525023445	128650
a6f604b514eedcbfe602a25c289e65e5e4ce5a00	is citation analysis a legitimate evaluation tool?	citation analysis;measurement problem	A comprehensive discussion on the use of citation analysis to rate scientific performance and the controversy surrounding it. The general adverse criticism that citation counts include an excessive number of negative citations (citations to incorrect results worthy of attack), self-citations (citations to the works of the citing authors), and citations to methodological papers is analyzed. Included are a discussion of measurement problems such as counting citations for multiauthored papers, distinguishing between more than one person with the same last name (homographs), and what it is that citation analysis actually measures. It is concluded that as the scientific enterprise becomes larger and more complex, and its role in society more critical, it will become more difficult, expensive and necessary to evaluate and identify the largest contributors. When properly used, citation analysis can introduce a useful measure of objectivity into the evaluation process at relatively low financial cost.	citation analysis	Daryl E. Chubin;Eugene Garfield	1980	Scientometrics	10.1007/BF02016602	public relations;measurement problem;computer science;data science;data mining;citation analysis;world wide web	Logic	-74.14553387111043	-16.779880057848906	128935
7ac55433b784f95f29cbfb2fde1ec2279decf40e	mathematics 1868–2008: a bibliometric analysis	analyse bibliometrique;production scientifique;mathematics;lotka law;loi bradford;scientific production;linear functionals;loi lotka;productivite auteur;matematicas;ley bradford;ley lotka;crecimiento;gamma distribution;croissance;bibliometric analysis;productividad autor;power law;annees 1868 2008;recherche scientifique;growth;bradford law;scientific research;author productivity;mathematiques;investigacion cientifica;analisis bibliometrico	This paper presents a bibliometric analysis of the literature published in the field of mathematics from 1868 to date. The data originate from the Zentralblatt MATH database. The increase rate of publications per year reflects the growth of the mathematics community and both can well be represented by exponential or linear functions, the latter especially after the Second World War. The distribution of publications follows Bradford′s law but in contrast to many other disciplines there is no strong domination of a small number of journals. The productivity of authors follows two inverse power laws of the Lotka form with different parameters, one in the range of low productivity and the other in the range of high productivity. The average productivity has changed only slightly since the year 1870. As far as multiple authorship is concerned the distribution of the number of authors per publication can be described quite well by a Gamma Distribution. The average number of authors per publication has been increasing steadily; while it was close to 1 up to the first quarter of the last century it has now reached a value of 2 in the last few years. This means that the percentage of single-authored papers has fallen from over 95% in the years before 1930 to about 30% today.	bibliometrics;bradford's law;dominating set;fitts's law;linear function;lotka's law;period-doubling bifurcation;population dynamics;time complexity;zentralblatt math	Heinrich Behrens;Peter Luksch	2010	Scientometrics	10.1007/s11192-010-0249-x	gamma distribution;power law;social science;scientific method;computer science;mathematics;sociology;operations research;statistics	DB	-77.02909240918343	-23.007583179270632	129089
26c86dd6d4b79d80a22d6fffaec49a16cc4583f3	data representation in healthcare: a design for a freely-available openly-developed international reference terminology for healthcare	ontologies;reference terminologies;controlled health terminologies	The importance of data representation in healthcare has been of concern for centuries. In the last fifty years there has been an increasing awareness of the need for formal representations of terminological systems. We propose that terminological system development should be consensus driven and the product of iterative open refinement in order to practically serve the needs of the healthcare community. The system of development and maintenance of such a system must involve recruitment of the best and the brightest in the medical community to take responsibility for insuring the accuracy and completeness of such an effort. We suggest a method for algorithmically building a starting point for such a reference terminology. Further we suggest a distributed authoring environment that would allow domain experts to contribute regardless of their location or language. Open intellectual contribution is the necessary ingredient for a consensus based international health reference terminology.		Peter L. Elkin;Steven H. Brown;Michael J. Lincoln;Mark Pittelkow;Brent A. Bauer;Dietlind Wahner-Roedler;Rhonda Thomas;Larry Bergstrom	2003	Studies in health technology and informatics	10.3233/978-1-60750-939-4-427	knowledge management;data mining;information retrieval	SE	-72.64074264980982	-14.825408509048163	129102
ec463177b6007e05a2f1f99d66ae8ba337abe5a7	is education: the role of is in computing education	computer education;is education	Many of the readers of this column are, I hope, familiar with the Future of Computing Education Summit that took place in the Washington, D.C. area in June 2009. The Summit brought together key decision makers from all the major professional and academic societies that have an interest in computing education. The real long-term impact of the summit will depend on the success of planned follow-up action. It was, however, clear during the meeting that the summit helped key influencers within each of the organizations to learn about other players in computing education and motivated all participants to find ways to work toward the common goals of attracting high-quality students to the field and engaging them so that they complete their studies and thrive in the field as professionals. Encouraged by the summit, my focus in this column will be the role of the Information Systems community in collaborative efforts within the computing discipline and particularly computing education; general results of the Summit will be reported in a much more comprehensive way through other channels. IS was represented at the summit by three different organizations: Mary Granger represented the Association for Information Systems (AIS) as its VP for Education, Dave Chatterjee represented the Society for Information Management (SIM) as an active academic member and the President of SIM’s Atlanta Chapter, and I was involved through the ACM as one of the members of the Summit organizing committee. It was very important to have the perspectives of AIS and SIM present at the summit; many thanks belong to all participants of the meeting who volunteered their expertise, time and efforts. In general, the conversations at the Summit provided support for several general observations regarding computing education in specific and the role of Information Systems in the broader computing education community in particular. In the rest of the column, I will both outline these observations and invite IS academics to action based on them. First, academics from various computing disciplines do not generally know the fields outside their own very well; this, of course, applies also to what IS academics know and don’t know about other computing disciplines. IS as a discipline and we as individual IS experts have a lot to learn from our colleagues in computer science, computer engineering, software engineering, information technology and the various informatics fields. It is, however, very difficult to learn from other computing disciplines and help these disciplines learn from us if we do not engage actively in the work that the computing field does as a whole. I would strongly encourage the entire IS education community to find ways to collaborate not only with colleagues in IS and other business disciplines but also with colleagues in other computing disciplines. Information sharing through active collaboration can be very beneficial for all parties involved. Second, “computing” is still very much “computer science” in the minds of many of the key players in the field of computing education. This perception is slowly changing, but the only way we can move closer to a broad and inclusive perspective of computing is through active collaboration between computer scientists and representatives of other computing disciplines. Computer engineering, software engineering, and information technology have traditionally been more active in this cooperation with computer science than information systems has; it is up to us to make sure that our field is visible through the work we do for and together with the broader computing education community. Third, Information Systems has a special role as a computing discipline that brings computing together with in-depth domain understanding. Since the early days of the IS discipline, the field has been learning and teaching about	association for information systems;computer engineering;computer science;computer scientist;informatics;information management;information system;organizing (structure);software engineering	Heikki Topi	2009	SIGCSE Bulletin	10.1145/1709424.1709429	counselor education;science education;computer science;economics education;science, technology, society and environment education;higher education	HCI	-65.3871381296629	-19.89626875117091	129197
49d4cc1c660e14ad17e020fba18b97532b90f3b7	criminalizing tool building	russie;criminologie;north america;america del norte;amerique du nord;amerique;criminologia;securite informatique;etats unis;estados unidos;securite information;russia;copyright protection;computer security;eurasie;seguridad informatica;criminology;eurasia;rusia;information system;america;systeme information;sistema informacion	Abstract At DEFCON-9 the FBI arrested Dimitry Sklyarov following his presentation on eBook security, for developing and distributing a tool designed to circumvent the electronic copyright protection associated with Adobe's eBooks. This made Sklyarov the first person facing criminal charges related to the Digital Millennium Copyright Act (DMCA), which makes illegal in the United States the use, manufacture, or importation of any technology, product, or service which is primarily designed to circumvent a protective copyright control. Dimitry is a 27-year-old computer programmer and a native of Russia. He is also a Ph.D. candidate at Bauman Moscow State Technical University, whose dissertation research was the basis for ElcomSoft's Advanced E-book Proc-essor software. Dimitry is an employee of ElcomSoft. ElcomSoft is a legal company in Russia, building a product that is legal in Russia. However, Adobe and the FBI pursued the arrest because, through the Internet, the product was available in the United States.		Ralph Spencer Poore	2001	Information Systems Security	10.1201/1086/43315.10.5.20011101/31715.2	computer science;operations research;computer security;information system	Logic	-68.79078669493722	-10.376709577007855	129365
67b9113d0b3cff61cc90440dca92a4ab40afc96f	advances in network sciences via collaborative multi-disciplinary research	complex network collaborative multidisciplinary research scientific exploration research alliance international technology alliance network sciences network science collaborative technology alliance;collaboration;scientific information systems complex networks groupware network theory graphs;algorithm design and analysis collaboration mobile computing heuristic algorithms mobile communication decision making information processing;heuristic algorithms;research alliances network science;information processing;mobile communication;mobile computing;algorithm design and analysis	Network Science is the scientific exploration of the shared fundamental properties underlying different types of networks and their interactions. Two large research alliances, the International Technology Alliance in Network Sciences and the Network Science Collaborative Technology Alliance, have brought together researchers from many diverse disciplines to create fundamental advances in network science. In this paper, we discuss some of the advances made by the scientists in these two research alliances, and some of the lessons learnt as fundamental scientific advances are translated to real networks via military and commercial transitions. Since both of the alliances themselves are complex networks, some of the lessons learnt from management of these networks are also discussed briefly in this paper.	authorization;complex network;interaction;network science cta;numeric character reference	Dinesh C. Verma;Will E. Leland;Tien Pham;Ananthram Swami;Gregory H. Cirincione	2015	2015 18th International Conference on Information Fusion (Fusion)		computer science;knowledge management;management science;operations research	HPC	-66.62739300948417	-14.179785075444775	129430
a6157846fa5ed28f56843088fe220f95a2204c6c	native and generic parallel programming environments on a transputer and a powerpc platform		Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.		Alfons G. Hoekstra;Peter M. A. Sloot;Frank van der Linden;M. van Muiswinkel;J. J. J. Vesseur;Louis O. Hertzberger	1996	Concurrency - Practice and Experience	10.1002/(SICI)1096-9128(199601)8:1%3C19::AID-CPE193%3E3.0.CO;2-9	chip;time complexity;computer architecture;parallel computing;real-time computing;reactive programming;point-to-point;functional reactive programming;computer science;floating point;operating system	Web+IR	-66.31907875644784	-18.55346644545508	129431
75d0c5544d050ffe1533a2ac933979c4c9f73ff9	leading librarians: the library and paths of inquiry into leadership	leadership;evaluation methods;leaders	LIBRARIANS LEAD, IN PART, BY GUIDING scholars and students to sources of knowledge about leadership. This article explores conceptions of leadership from the perspectives of practitioners and scholars as different sources of knowledge. It illuminates the contributions that different disciplines make to understanding leadership as a multidisciplinary endeavor by elucidating questions from the perspective of relevant disciplines. The author urges librarians to apply these questions to their roles and to become leading librarians. INTRODUCTION Questions about leadership for librarians occur in two ways. First, the library is an organization and/or polity unlike any other with people playing the role of leader and also playing the role of follower. Therefore, librarians need to think about leadership in their organizational setting. Second, librarians play a key role in leading others to the sources of knowledge for understanding leadership. In regard to the first context for questions, there is little to be said. Since this author is not a librarian and has not studied leadership in libraries, he cannot contribute any specific insights into the unique organizational context of a library. It can only be suggested that, since organizational context is so important, i t is essential that the *Portions of this article were adapted with permission from the March/April 1987. Liberal Education, 73(2), published by the Association of American Colleges @ 1987 Irving J. Spitzberg,Jr., The Knowledge Company, 9726 Admiralty Drive, Silver Spring, MD 20910 LIBRARY TRENDS, Vol. 40, No. 3, Winter 1992, pp. 381-90 @ 1992 The Board of Trustees, University of Illinois 382 LIBRARY TRENDWWINTER 1992 more general questions that arise about leadership be carefully situated in the organizational culture of librarians. It is the role of the librarian as a leader of those seeking greater understanding of leadership that this article will address. In 1987, while establishing and directing the Luce Leadership Project of the Association of American Colleges, this author published an article that examined the alternative frameworks that different disciplines brought to understanding leadership and developed an extensive list of questions from different disciplinary perspectives. In this revision of the earlier article, the intention is to repeat those questions. Before doing so, the leadership role of the librarian as a guide to the scholar, the student, and the leader as he or she seeks answers to these questions will be emphasized. The librarian is uniquely qualified to help the student or scholar efficiently seek the guidance of earlier thinkers as he or she addresses questions about leadership. How the librarian should go about using hidher technical skills to contribute to the inquiry is a complex question that poses every single issue of strategy and tactic in pursuing leadership. For example, the research librarian who is familiar with the philosophical sources of analysis of leadership will have to work out a leadership strategy to inspire the very positivistic psychologist to use the literatures from the humanities or arts, which is where the hard-nosed, mathematically inclined psychologist will place philosophy. Since the psychologist will think that he or she knows more than the librarian about the literature of leadership (and often might), the librarian will be placed in the position of leading in a manner that we sometimes call “from the back of the room” or through an approach that assumes no external source of power beyond the knowledge that he or she has to offer. In order for the librarian to use her/his special familiarity with the topology of knowledge in a way that serves those seeking understanding of leadership, he or she must understand some important matters concerning leadership. To understand fully this author’s perspective, it is necessary to know that he i s skeptical about supposedly interdisciplinary inquiries. True interdisciplinarity is rare. Indeed, with the exception of some sciences such as biochemistry and biophysics, which evolved from interdisciplinary research into disciplines themselves, this author has yet to see an interdisciplinary inquiry. But there are many fields that require knowledge from many disciplines to be understood-education, cognitive science, and intercultural studes, for example. Leadership, like these multidisciplinary fields, requires fancy footwork in modes of inquiry and standards of evidence and SPITZBERG/PATHS OF INQUIRY INTO LEADERSHIP 383 argument. To admit this limitation at the start is to encourage prudence and caution, not to dismiss or belittle the value of the enterprise. The first task in a class, a course, or a program, is to develop a tentative definition of leadership and criteria about what constitutes a leader. The various literatures are full of definitions that focus upon the ability to change group behavior, the exercise of power, the valuation of authority, and the existence of followers. There is little consideration of how we use the concept in different institutional and organizational settings. And there is almost no debate about the various definitions used. In fact, this discussion assumes that we will know leadership when we see it, and that leaders are simply known. In order to impart some rigor to considering the concept, the author would pose these variations on the question, “What is leadership?”: Do leaders require followers? Does the concept of leaders have different meanings in different institutional, national, or historical settings? Does the role of leader assess its own authority? Does this authority require consent? How do power and authority relate in the concept of leadership? How do leaders actually lead? How do we assume how well they lead? A number of traditional questions were not listed-is leadership a trait, for example-because this sort of question is less than interesting and probably unanswerable. While the particular question about environment versus character is now passe, the significance of understanding the environmental features that interact with personality and character in the recruitment and success of leaders should never be underestimated. Conceptual questions seldom arise from leaders who are leading, but answers to these questions will influence how we answer more practical questions, which are the stuff of the exercise of leadership and interest those engaged in self-conscious leadership development. QUESTIONS FROM PRACTICE ARISING How are Leaders Recruited and Selected? When we look at governance systems, issues of election and selection play a significant role. These issues raise questions that can only be answered through use of an ethical framework and the careful collection of empirical data. Where do leaders come from demographically? What is the connection between recruitment and selection (or election)? Are leaders selected or self-selected? What is the impact of institutions that are self-consciously committed to a culture of leadership (for example, the military academies and Ivy League schools) on the recruitment and selection of leaders throughout society? 384 LIBRARY TRENDSIWINTER 1992 H o w Do Leaders Lead? These sorts of questions inform the approach of a number of scholars of leadership, particularly in the applied sciences. How does one learn to be a leader? Once one is anointed, what skills are necessary and what is the nature of the activity of leadership? Students in leadership courses are reading some of the thousands of biographies of leaders. While each biography describes how heroes go about the leadership business, there is a paucity of comparisons of different leaders with attention to similarities and differences of techniques of leadership. Students should be considering: Do leaders use incentives or sanctions or both? Do leaders at different times use different techniques? Does institutional setting affect leadership style and techniques? Are there techniques of leadership, such as time management, which account for its constructive exercise? How do leaders communicate? Are there important gender or ethnic differences in leadership style? What are they? Is the exercise of leadership an incremental (transactional) or discontinuous (transformational) process or both? How do standards of leadership vary according to context? What is the Relationshi@ Between Leader and Followers? To understand leaders is to understand followers. Whether one is a leader or a follower depends upon the situation and the institutional context. Lincoln was a political leader but a religious follower; he set ethical standards in the political system but was not a theological pacesetter. The leader/follower nexus can pose a series of interesting questions that can best be pursued by careful analysis of crises and decision making. What is the connection among individual characteristics, organizational features, and historical moment that casts the same individual in different roles in different settings at different moments? How does the communication system between leaders and followers work? What are the rights and duties of leaders in relation to followers and vice versa? H o w Do W e Evaluate Leadershi$ Quality? Much of the literature, while seeming to focus on the nature of leadership, in fact evaluates particular qualities of specific leaders. We need to develop detailed strategies for evaluating leadership according to standards that are set in the context of a particular organization and a society at a specific historical moment. Even with these qualifications, students of leadership can generate criteria and standards. This requires both analytical and political acumen. Understanding the quality of leadership requires an analytical framework; evaluating for purposes of improving or changing SPITZBERG/PATHS OF INQUIRY INTO LEADERSHIP 385 leadership requires political agreement in regard to all of these quest	cognitive science;consciousness;hard coding;leader election;librarian;library (computing);self-consciousness;situated;transformational grammar;type conversion;value (ethics)	Irving J. Spitzberg	1992	Library Trends			HCI	-74.38682772160944	-20.120103085186066	129478
1d958235b90271d0ead9fce797c6678ff17cb07b	international orientation, efficiency of and regard for research in east and west germany: a bibliometric investigation of aspects of technology genesis in the united germany	europa;west germany;scientometrics;allemagne;estudio comparativo;etude comparative;unification;germany;alemania republica democratica;allemagne republique democratique;scientometria;comparative study;scientometrie;east germany;allemagne republique federale;europe;recherche scientifique;scientific research;alemania;unificacion;investigacion cientifica;alemania republica federal	The efficiency of areas of science was evaluated using the DEA method. Areas achieving a maximum orientation or regard of international publication are rated as efficient. The areas of reproductive medicine, organic and inorganic chemistry in the former Federal Republic can thus be regarded as efficient areas of science. No area of scientific research in the former East Germany was able to achieve the optimum. The determinant in this connection is the adverse situation with respect to international orientation whilst no substantial difference in regard for further research could be detected between East and West German research.	bibliometrics;genesis;while	Hariolf Grupp;Sybille Hinze	1994	Scientometrics	10.1007/BF02018385	development economics;scientific method;scientometrics;computer science;unification;comparative research	HPC	-75.36669801867279	-22.237770964851567	129741
4266fd7ab562059a8b8f6f33cf6325404189d309	linguistics and intercultural communication	intercultural communication	Our times are often referred to as the ‘new world order’ with its ‘new economy’. What this means is that capitalism has been restructured on a global scale, and people of widely different cultural and linguistic backgrounds have been thrown into contact more than ever before. Cultural and linguistic contact may occur in the flows of information and mass media, as well as in the flows of actual people in migration and tourism. Given the ubiquity of cultural and linguistic contact, mergers and hybrids, it is unsurprising that there should be a strong interest in Intercultural Communication, both outside and inside academia. Linguistics as a discipline makes two key contributions to the study of Intercultural Communication. (i) It is the key contribution of discourse analysis and anthropological linguistics to take culture as empirical and cultural identity, difference and similarity as discursive constructions. (ii) Intercultural Communication by its very nature entails the use of different languages and/or language varieties and sociolinguistics, particularly bilingualism studies, illuminates the differential prestige of languages and language varieties and the differential access that speakers enjoy to them.		Ingrid Piller	2007	Language and Linguistics Compass	10.1111/j.1749-818X.2007.00012.x	psychology;linguistics;sociology;media linguistics;communication;intercultural relations	NLP	-77.07315440985798	-14.228798313587166	130098
2a47552adf46e6f0e7d8d6c3c32d9163432fc050	why foucault? new directions in educational research - by peters, michael a & besley, tina	education research			Roger Lindsay	2008	BJET	10.1111/j.1467-8535.2008.00870_12.x	psychology;social science;epistemology;sociology	Crypto	-63.33680639108382	-11.736491573223837	130338
8158803d707737282539a678f4c59c148e643221	erratum to: linguistic neighbourhoods: explaining cultural borders on wikipedia through multilingual co-editing activity		*Correspondence: anna.samoilenko@gesis.org 1GESIS Leibniz-Institute for the Social Sciences, 6-8 Unter Sachsenhausen, Cologne, 50667, Germany 2University of Koblenz-Landau, Koblenz, Germany Full list of author information is available at the end of the article Unfortunately, the original version of this article [] contained an error. Within the caption of Table  the sentence ‘The combination of all hypotheses explains most of the variation in the data (%)’ should have read ‘The combination of all hypotheses explains most of the variation in the data (%)’. Table  has been corrected in the original article and is also included correctly below.	landau–zener formula;wikipedia	Anna Samoilenko;Fariba Karimi;Daniel Edler;Jérôme Kunegis;Markus Strohmaier	2016	EPJ Data Science	10.1140/epjds/s13688-016-0076-2		ML	-63.27561066390614	-20.363393762045874	130489
d797e13487b1f05496ca7a77797ddff477e12565	book review: paul pedley, essential law for information professionals				Graham P. Cornish	2012	JOLIS	10.1177/0961000612459112	media studies;sociology	HCI	-63.33510375738864	-11.123674547769285	130498
121af142a58ad99c9756a504b9ffc9a064fd1880	the construct validity of the h-index		Emerald is a global publisher linking research and practice to the benefit of society. The company manages a portfolio of more than 290 journals and over 2,350 books and book series volumes, as well as providing an extensive range of online products and additional customer resources and services. Emerald is both COUNTER 4 and TRANSFER compliant. The organization is a partner of the Committee on Publication Ethics (COPE) and also works with Portico and the LOCKSS initiative for digital archive preservation.	archive;book;case preservation;emerald;lockss	Cameron Stewart Barnes	2016	Journal of Documentation	10.1108/JD-10-2015-0127	library science;social science;epistemology;management science;sociology;social psychology	HCI	-68.02571080250296	-17.845762731968648	130591
e9bc4d0ddbaf294c48c61e970b2ed429acc45d24	towards a scientific blockchain framework for reproducible data analysis		Publishing reproducible analyses is a long-standing and widespread challenge [1] for the scientific community, funding bodies and publishers [2, 3, 4]. Although a definitive solution is still elusive [5], the problem is recognized to affect all disciplines [6, 7, 8] and lead to a critical system inefficiency [9]. Here, we propose a blockchain-based approach to enhance scientific reproducibility, with a focus on life science studies and precision medicine. While the interest of encoding permanently into an immutable ledger all the study key information–including endpoints, data and metadata, protocols, analytical methods and all findings–has been already highlighted, here we apply the blockchain approach to solve the issue of rewarding time and expertise of scientists that commit to verify reproducibility. Our mechanism builds a trustless ecosystem of researchers, funding bodies and publishers cooperating to guarantee digital and permanent access to information and reproducible results. As a natural byproduct, a procedure to quantify scientists’ and institutions’ reputation for ranking purposes is obtained.	bitcoin;critical system;ecosystem;freedom of information laws by country;immutable object;precision medicine	Cesare Furlanello;Manlio De Domenico;Giuseppe Jurman;Nicole Bussola	2017	CoRR		precision medicine;knowledge management;data mining;computer science;science studies;metadata;inefficiency;commit;publishing;blockchain;reputation	HPC	-73.40732211077072	-14.055591902234683	130746
c22acf8c0fce40243558d6fb9e36651c85740431	requirements of text processing lexicons	satisfiability	Five years ago, Dwight Bolinger [1] wrote that efforts to represent meaning had not yet made use of the insights of lexicography. The few substantial efforts, such as those spearheaded by Olney [2,3], MelOCuk [4], Smith [5], and Simmons [6,7], made some progress, but never came to fruition. Today, lexicography and its products, the dictionaries, remain an untapped resource of uncertain value. Indeed, many who have analyzed the contents of a dictionary have concluded that it is of little value to linguistics or artificial intelligence. Because of the size and complexity of a dictionary, perhaps such a conclusion is inevitable, but I believe it is wrong. To avoid becoming irretrievably lost in the minutiae of a dictionary and to view the real potential of this resource, it is necessary to develop a comprehensive model within which a dictionaryOs detail can be tied together. When this is done, I believe one can identify the requirements for a semantic representation of an entry in the lexicon to be used in natural language processing systems. I describe herein what I have learned from this type of effort.	artificial intelligence;dictionary;lexicography;lexicon;minutiae;natural language processing;requirement	Kenneth C. Litkowski	1980	CoRR			Web+IR	-66.7048593292322	-23.559712870402144	130763
07f1da2c10058fea62daf5479572e714217dc8d9	the question of spectrum: technology, management, and regime change	transaction cost;command and control;dispute resolution;secondary market;spectrum;tragedy of the commons;technology management;spectrum management;property rights	There is general agreement that the traditional command-and-control regulation of radio spectrum by the FCC (and NTIA) has failed. There is no general agreement on which regime should succeed it. Property rights advocates take Ronald Coase’s advice that spectrum licenses should be sold off and traded in secondary markets, like any other assets. Commons advocates argue that new technologies cannot be accommodated by a licensing regime (either traditional or property rights) and that a commons regime leads to the most efficient means to deliver useful spectrum to the American public. This article reviews the scholarly history of this controversy, outlines the evolution of FCC thinking, and parses the question of property rights vs. commons into four distinct parts: new technology, spectrum uses, spectrum management, and the overarching legal regime. Advocates on both sides find much to agree about on the first three factors; the disagreement is focused on the choice of overarching regime to most efficiently and effectively make spectrum and its applications available to the American public. There are two feasible regime choices: a property rights regime and a mixed licensed/commons regime subject to regulation. The regime choice depends upon four factors: dispute resolution, transactions costs, tragedies of the commons and anticommons, and flexibility to changing technologies and demands. Each regime is described and analyzed against these four factors. With regard to pure transactions costs, commons may hold an advantage but it appears quite small. For all other factors, the property rights regime holds very substantial advantages relative to the mixed regime. I conclude that the choice comes down to markets vs. regulation as mechanism for allocating resources. * Professor, Business and Public Policy, Wharton School, University of Pennsylvania, Philadelphia, PA 19104. This research has been undertaken while the author is on scholarly leave at the Penn Law School. The author would like to thank Professor Gideon Parchomovsky (Penn Law) for his expert and very generous guidance in matters of legal scholarship, as well as Professor David J. Farber (Carnegie Mellon University), Professor Jason Johnston (Penn Law), Polk Wagner (Penn Law), Thomas Hazlett (Manhattan Institute), Evan Kwerel and John Williams (Federal Communications Commission). The Honorable Stephen F. Williams (DC Circuit Court of Appeals), Professors Chris Sanchirico (Penn Law), Phillip Weiser (UC Boulder Law), Dale Hatfield (UC Boulder Interdisciplinary Telecoms), Ellen Goodman (Rutgers-Camden Law) and the participants at the “Digital Broadband Migration: Rewriting the Telecom Act” conference at UC Boulder, Feb 13-14, 2005 contributed comments both significant and helpful, for which I am appreciative. The usual disclaimer applies.	interference (communication);jason;monopoly;parsing;rewriting;uc browser	Gerald R. Faulhaber	2005	JTHTL		reel;telecommunications;business;technology management;regime change;economic system	HCI	-66.70441191651157	-19.333866504127624	130767
b7cc536e2da4287da538f496b4a9772ad7887838	categories from scratch	universiteitsbibliotheek	Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.	category theory;computer engineering;formal specification;programmer;theoretical computer science	Raphael 'kena' Poss	2014	CoRR		computer science;artificial intelligence;mathematics;programming language;algorithm	Web+IR	-66.29055698577278	-18.56246228120226	130824
96d95d5bf86816e98e8e73223f7fa09c163f6df4	cataloging and expert systems: aacr2 as a knowledge base	expert systems;knowledge base;algorithms;expert system	A project where two expert systems were built for library cataloging is described. The main task for these systems was to choose access points, identifying main and added entries. The resulting ESSCAPE systems and the increased understanding of the cataloging process and AACR2 developed in the project are discussed. Some of the insights gained are presented under headings such as: Expert systems and cataloging, Cataloging as interpretation, The structure of AACR2. Some reflections on rule sets in general are also included. The general conclusion is that at present expert systems for cataloging can be used to produce correct bibliographic records, which might be useful in nontraditional environments. In normal library settings such systems would seem to be less meaningful, however. The research reported here was funded by grants from the Swedish Delegation for Scientific and Technical Information. The ESSCAPE project was also presented at the 51st IFLA Council and General Conference, Chicago, August 18–24, 1985. © 1989 John Wiley u0026 Sons, Inc.	expert system;knowledge base	Roland Hjerppe;Birgitta Olander	1989	JASIS	10.1002/(SICI)1097-4571(198901)40:1%3C27::AID-ASI4%3E3.0.CO;2-R	library science;computer science;data science;data mining;database;world wide web;expert system;information retrieval	AI	-72.60449637579922	-19.775372108707305	131027
3b3d3326fc24b63577f735672c18aecf6504f422	a re-examination of relevance: toward a dynamic, situational definition	ciencia informacion;systeme documentaire;articulo sintesis;information science;article synthese;information retrieval;pertinencia;besoin utilisateur;necesidad usuario;definicion;definition;user need;recherche information;pertinence;sistema recuperacion documental;document retrieval system;comportement utilisateur;cognition;cognicion;evaluation;user behavior;recuperacion informacion;relevance;evaluacion;science information;review;comportamiento usuario	Although relevance judgments are fundamental to the design and evaluation of all information retrieval systems, information scientists have not reached a consensus in defining the central concept of relevance. In this paper we ask two questions: What is the meaning of relevance? and What role does relevance play in information behavior? We attempt to address these questions by reviewing literature over the last 30 years that presents various views of relevance as topical, user-oriented, multidimensional, cognitive, and dynamic. We then discuss traditional assumptions on which most research in the field has been based and begin building a case for an approach to the problem of definition based on alternative assumptions. The dynamic, situational approach we suggest views the user-regardless of system-as the central and active determinant of the dimensions of relevance. We believe that relevance is a multidimensional concept; that it is dependent on both internal (cognitive) and external (situational) factors; that it is based on a dynamic human judgment process; and that it is a complex but systematic and mea-	cognition;information behavior;information retrieval;information scientist;relevance	Linda Schamber;Michael B. Eisenberg;Michael Sanford Nilan	1990	Inf. Process. Manage.	10.1016/0306-4573(90)90050-C	cognition;relevance;definition;information science;computer science;artificial intelligence;evaluation;law;information retrieval	Web+IR	-73.3757288885169	-18.536656746019464	131073
f5f42ccfa69d15886fd3f9902ba3e476a4051db6	foundations of security analysis and design iii: fosad 2004/2005 tutorial lectures	security analysis	Spend your few moment to read a book even only few pages. Reading book is not obligation and force for everybody. When you don't want to read, you can get punishment from the publisher. Read a book becomes a choice of your different characteristics. Many people with reading habit will always be enjoyable to read, or on the contrary. For some reasons, this foundations of security analysis and design iii fosad 20042005 tutorial lectures 1st edition tends to be the representative book in this website.		Alessandro Aldini;Roberto Gorrieri;Fabio Martinelli	2005		10.1007/11554578	software security assurance;computer security model;vulnerability;computer science;information security;security service;internet privacy;security analysis;world wide web;computer security	Logic	-68.93104555226356	-12.322730632247342	131078
5a7c49025c946622a7db9a786fca61552e31991d	deviation maps for robust and informed indoor positioning services		The ability to position and track people and assets has become increasingly widespread and important in business and personal life. The prevalent means for such tasks is signal-strength-based, prominently WiFi-based, positioning, together with GNSS positioning. The latter, however, is insufficient for the majority of indoor environments in which most of our work and personal lives takes place. Signal-strength-based positioning, though, too, is error-prone in real-life building environments, suffering from large biases induced by the often many and complex attenuating elements in the environment. Additionally, in the prevalent signal-strength-based positioning methods, which rely solely on signal pattern matching, such biases and errors are hard to assess and thus positioning quality and glitches hard to predict.  We present an approach for assessing, visualizing, and counter-acting positioning biases and impairments in signal-strength-based positioning. This approach, centered around the notion of deviation maps, aim at improving positioning quality and predictability/reliability and, at the same time, at gaining knowledge and understanding of tracking quality. We seek to understand how the tracking quality is influenced by both positioning installation and building environment, and how the former may be altered to better suit the latter. We discuss results from applying our approach in a real-world large-scale work environment, a major hospital spanning 160,000 square meters, as well as lessons learned from the underlying experimentation-driven and use-centric design process. From these lessons we also derive directions for future work.	cognitive dimensions of notations;file spanning;glitch;global positioning system;map;pattern matching;real life	Henrik Blunck;Thor S. Prentow;Sylvie Temme;Andreas Thom;Jan Vahrenhold	2017	SIGSPATIAL Special	10.1145/3124104.3124110	data mining;simulation;computer science;predictability;personal life;glitch;design process;gnss applications	HCI	-76.83640800908371	-11.646169585530549	131159
9df6b0d5e5bca8dc8b8f662d2ca16b7ba2bc3103	copyrights and author responsibilities	law protection permission legal factors desktop publishing distributed computing education;copyright protection;plagiarism material reuse author responsibilities exclusive rights fair use copyright protected material duplicate submissions simultaneous submissions engineering profession;industrial property	The issues associated with the reuse of copyrighted material are discussed by examining a number of case studies. The concepts of exclusive rights and fair use of copyright-protected material are described. An author's reuse of his or her own copyright-protected material, duplicate submissions, and simultaneous submissions are also discussed. The ways in which the engineering profession deals with plagiarism are reviewed.<<ETX>>		Harold S. Stone	1992	Computer	10.1109/2.179116	software engineering;management;law;world wide web;computer security	HCI	-67.83141567115368	-16.99819075233458	131167
6a3486987a7f35a53a6da0f96e42f50c0c922d61	how multidisciplinary is gamification research?: results from a scoping review		Gamification has been repeatedly framed as an emerging multidisciplinary research field. However, it is unclear how multidisciplinary the field actually is. To answer this question, this paper presents initial results of a broader scoping review of gamification research published between 2010 and 2016. Close to 2,000 peer-reviewed English-language journal and conference papers were identified across 11 databases and categorized by discipline. Results indicate an explosive growth of literature peaking in 2015. Early on, Information and Computing Science dominated the field, to be overtaken by the sum of other disciplines in 2013, education, economics and tourism in specific. This indicates that gamification was initially a field within computer science and HCI and has only recently become truly multi-disciplinary.	cs games;categorization;computer science;database;expectation propagation;gamification;human–computer interaction;scope (computer science)	Nicholas O'Donnell;Dennis L. Kappen;Zachary Fitz-Walter;Sebastian Deterding;Lennart E. Nacke;Daniel M. Johnson	2017		10.1145/3130859.3131412	simulation;multimedia;scientometrics;computer science;multidisciplinary approach;tourism;knowledge management	HPC	-71.42980024036915	-17.79292584143231	131370
8118b9293303c548027482d09e9ecb47dc9c4447	linked ethnographic data: from theory to practice	linked data;ethnography;mixed methods;web science	As Web Science continues to mix methods from the many disciplines that study the web, we must begin to seriously look at mixing and linking data across the Qualitative and Quantitative divide. A large difficulty in this is in modeling and archiving Qualitative data. In this paper, we outline what these difficulties are in detail with a focus on the data practices of Ethnography. We describe how linked data technologies can address these issues. We demonstrate this with a case study in modeling data from audio interviews that were taken in an ethnographic study conducted in our lab. We conclude with a discussion on future work that needs to be done to better equip researchers with these tools and methods.	archive;linked data;web science	Dominic DiFranzo;Marie Joan Kristine Gloria;James A. Hendler	2015		10.1145/2740908.2745942	human–computer interaction;computer science;linked data;data mining;multimedia;ethnography;world wide web	HCI	-71.83443249518598	-18.57686468924599	131470
78dc30474712cdcd9fd1349c9fb63506592bcd05	maximising eyeballs but facilitating cybercrime? ethical challenges for online advertising in new zealand	google;employment;marketing ethics online advertising new zealand rogue web site internet risk analysis;web sites advertising data processing computer crime ethical aspects internet risk analysis;industries;sex industry;materials;malware;marketing;tv;advertising google industries malware tv materials employment;high risk marketing advertising malware sex industry;advertising;high risk	"""Rogue websites support their operations through advertising, where advertising networks facilitate the placement of advertising banners paid for by advertisers who seek the most """"relevant"""" eyeballs. While mainstream advertisers risk harm to their brands by being associated with illicit activities on the internet, they also risk harms to users through the co-location of ads for high-risk activities, such as gambling, pornography, and scams. In this paper, we present a quantitative analysis of high risk and mainstream advertising being served to New Zealand consumers. We explore the ethical challenges facing advertisers and advertising networks in potentially facilitating cybercrime and harms to users, in the context of theories of marketing ethics. These theories can be used to explore policy and individual responses to guide ethical conduct in marketing."""	cybercrime;internet;online advertising;rogue;theory	Paul A. Watters;Maya F. Watters;Jacqueline Ziegler	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.210	public relations;advertising campaign;online advertising;advertising research;native advertising;compensation methods;computer science;share of voice;marketing;advertising account executive;malware;advertising;world wide web;contextual advertising	Mobile	-70.41781774515779	-10.322090191016732	131561
da110e4c8f555cdcbd3c4de48f012bd549bbe6a6	the state-of-the-art in biomimetics		Biomimetics is a research field that is achieving particular prominence through an explosion of new discoveries in biology and engineering. The field concerns novel technologies developed through the transfer of function from biological systems. To analyze the impact of this field within engineering and related sciences, we compiled an extensive database of publications for study with network-based information analysis techniques. Criteria included publications by year and journal or conference, and subject areas judged by popular and common terms in titles. Our results reveal that this research area has expanded rapidly from less than 100 papers per year in the 1990s to several thousand papers per year in the first decade of this century. Moreover, this research is having impact across a variety of research themes, spanning robotics, computer science and bioengineering. In consequence, biomimetics is becoming a leading paradigm for the development of new technologies that will potentially lead to significant scientific, societal and economic impact in the near future. (Some figures may appear in colour only in the online journal)	biological system;biomimetics;compiler;computer science;file spanning;programming paradigm;robotics	Nathan F. Lepora;Paul F. M. J. Verschure;Tony J. Prescott	2012		10.1007/978-3-642-31525-1_45	robot;computational biology;biomimetics;biology	DB	-70.4272805429504	-17.10292678608255	131573
026fc17ebd10329f63ebe2efe5849e22395963d8	the compassionate geek: mastering customer service for i.t. professionals by don r. crawley and paul r. senness	economic analysis;software crisis;customer service;software contract	"""I picked this book to review because of its catchy title. It was a quick read consisting of nine short chapters and six 3-5 page essays/blog posts as an appendix. While you might conclude that the main audience for the book is I.T support staff (e.g., tier 1, 2 and 3 help desk personnel), the book provides good advice on communication skills, in general. I found the second chapter to be of particular interest in that it addresses the differences in communicating with the four generations in the workforce: 1) Veterans 2) Boomers 3) Xers,and 4) Millenials Chapter 5 was on the """" Art of Listening """"-good advice for all professionals, but something a software architect should be particularly good at. While I don't consider this book a """" must read """" I did find it interesting and it did provide sound advice on how to effectively communicate when trying to help users solve their (I.T) problems. Reviewed by Will Tracz, Will@Tracz.org."""	blog;bus mastering;geek;software architect;tier 1 network	Will Tracz	2011	ACM SIGSOFT Software Engineering Notes	10.1145/1988997.2003648	customer to customer;management;customer advocacy	HCI	-66.26107133127842	-21.89836772205131	131608
f1dc8114ac946ffeeee280a97edba8b16c1b6f59	rural computing: beyond access and infrastructure		Computing tends to be associated with cities and urban areas, where innovation in Information and Communication Technologies (ICTs) is often seen as coming from and where a majority of users live. In this workshop, we seek to offer a counterpoint to CSCW and other computing disciplines' biases towards the urban and focus on ICT use and design in rural areas. In particular, our goal is to recognize rural areas not just as sites where ICT access and infrastructures need improvement, but as places of innovation and exploration that can inform a more representative and just understanding of people and users. This workshop offers a space for these conversations and to bring together and build a network of established and emerging scholars in the CSCW and adjacent communities conducting research in and about the rural.	computer-supported cooperative work	Jean Hardy;Dharma Dailey;Susan Wyche;Norman Makoto Su	2018		10.1145/3272973.3273008	rural area;knowledge management;icts;computer-supported cooperative work;information and communications technology;computer science	HCI	-76.89500074130564	-14.912126984816467	131655
0a5ee056b365c7ef649151d0aa737109ccf57f67	bibliometric analysis of english-language academic journals of china and their internationalization	analyse bibliometrique;analisis citas;citation analysis;communication scientifique;english language;comunicacion cientifica;jcr journal citation report;facteur impact;selected works;factor impacto;periodical;impact factor;natural science foundation of china;internationalization;analyse citation;periodique;periodico;intercultural communication;jcr;bepress;scientific communication;internationalisation;bibliometric analysis;recherche scientifique;scientific research;annees 2001 2005;investigacion cientifica;educational assessment;analisis bibliometrico	The internationalization of ten of China’s English-language scientific journals is analyzed based on their Impact Factor, Total Citation, JCR list rank, international paper proportion and international citation proportion. Six of these journals were financed three times by the National Natural Science Foundation of China (NNSF) between 2001–2006 and four journals maintained a higher impact factor (>1.0) in 2003–2005. The data show that though the total trend of Impact Factor and Total Citation keeps rising, their subject rank has shown a slight decrease. Moreover, the proportion of international papers and international citations do not match their JCR rank and IF: high rank journals have a low proportion of international papers (Chinese Phys Lett, Chinese Phys) and low rank journals have a high Impact Factor (Cell Res, Asian J Androl). This inconsistency may result from their insufficient internationalization either in international paper proportion (less than 20%) or in the amount of high-quality manuscripts, probably caused by their local journal title, circulation and low IF. Suggested means of improving internationalization include encouraging Chinese scientists to cite more home journals when they publish their papers in foreign journals; soliciting the submission of international co-authorships based on the unavailability of pure foreign authorship; cooperating with internationally recognized publishers to utilize their globalization platform; employing overseas scientists to recruit international papers; improving writing style and content, to enable greater accessibility to worldwide readers.	accessibility;bibliometrics;content repository api for java;internationalization and localization;journal citation reports;unavailability	Shuhua Wang;Hengjun Wang;Paul R. Weldon	2007	Scientometrics	10.1007/s11192-007-1775-z	social science;computer science;sociology;operations research;citation analysis;world wide web;internationalization	Arch	-76.12659981020866	-20.49963195287987	131727
70db96e053c96c221bfbf757de6e77a21180d883	nameless and faceless: the role of biometrics in realising quantum (in)security and (un)accountability	selected works;bepress	This chapter explores the contradictions between the claims that biometrics will boost security and prevent identity theft, and the growing evidence of how, as more biometric documents are introduced, there is increasing e-crime that threatens personal identity and security, and collective security in the e-spaces of egovernment and personal life. It considers the impact on and ethical implications for society of widening biometric applications to daily life; and for those responsible for ensuring security and accountability as traditional controls are eroded. It concludes with a series of suggestions for avoiding dystopia.	biometrics;quantum	Juliet Lodge	2013		10.1007/978-1-4471-5230-9_13	public relations;political science;internet privacy;computer security	Crypto	-74.67377724299563	-10.579751647195875	131821
267b5c7b488f987d640d4f12874e1c31c5860458	integrated information processing and the case for a national network	information processing	The various premises, which need consideration when developing a realistic and flexible information storage, retrieval and dissemination (ISRD) system, are discussed; their implication is illustrated with some examples from the development of the system at “Shell” Research, Sittingbourne,#R##N##R##N#One of the factors which will affect the satisfactory performance of an ISRD system is the ease with which relevant literature information not held in the system can be provided.#R##N##R##N#The latter part of the paper is devoted to a discussion of this problem and of a possible means of dealing with it in the not too distant future.	information processing	H. F. Dammers	1968	Information Storage and Retrieval	10.1016/0020-0271(68)90015-6	information processing;computer science;artificial intelligence;data mining;operations research;information retrieval	ML	-72.69541173708956	-18.115465325571176	131836
b8fdfdcb0314a8425cb6e423904ef5c7c13f7808	the efficient method for creating ideas; innovators marketplace as role-based game		Innovation does not mean only creating the new product or services. It is necessary to work out the strategy to lead innovations. Innovators Market Game is a method for creating new ideas by combining existent ideas. In this study, we propose the new way of creating ideas; Rolebased Innovators Market Game. In the game, players take part in the role selected from the real world. For example, journalists, government, doctors and so on. Players create the ideas based on their own roles through the communications with other players. Considering the relations among other roles, players think of ideas strategically. Generally, creating new ideas is highly hard work. By introducing the factor of game, players can create ideas efficiently. The strict rules, acting roles and communication make players more creative and imaginative. Players can discover and solve the practical problems, and improve their creative and imaginative skills through this activity.	experiment;img;printing	Teruaki Hayashi;Yukio Ohsawa	2013				HCI	-76.47556549081584	-13.437396287117338	131856
b8bc8e55e3035a53453459cad40daddfd30cb280	mix it up!: a blending of community informatics and youth services librarianship to further social justice in library and information science education		LIBRARY TRENDS, Vol. 64, No. 2, 2015 (“Social Justice in Library and Information Science and Services,” edited by Bharat Mehra), pp. 444–457. © 2015 The Board of Trustees, University of Illinois Abstract Mix IT Up! is a library and information science (LIS) education initiative blending theories and approaches in community informatics and youth services librarianship in order to further social justice agendas. It is based on collaboration with community partners who share similar interests and objectives. Prior to launching Mix IT Up!, community members identified a pressing need to engage with local youth more effectively. Mix IT Up! was developed to address this critical gap. From 2011 to 2015, Mix IT Up! enabled a broad array of community-based connections and projects related to youth advocacy and information technologies—the “IT” in the title—and provided robust opportunities for LIS students to gain experience in community engagement. Mix IT Up! serves as a model of effective practice in LIS education.	alpha compositing;community informatics;librarian;library and information science;theory	Rae-Anne Montague	2015	Library Trends		library science;public relations;management;world wide web;economic growth	HCI	-66.95045529778704	-12.796480184190422	132066
2475be333245212da853089f6aab5c6a5bb174f4	the quality of single and multiple authored papers; an unresolved problem	analyse bibliometrique;signature analysis;citation analysis;australie;oceanie;empirical study;analyse signature;cooperation;estudio comparativo;qualite;discipline;analisis cita;disciplina;cooperacion;litterature scientifique;etude comparative;analyse citation;social science;literatura cientifica;auteur;quality;autor;comparative study;bibliometric analysis;author;multiple;scientific literature;oceania;sci;calidad;australia;analisis firma;analisis bibliometrico	Evidence is examined for the repeated claim that published papers with more than one author are, on average, of higher quality than those with a single author. Among published studies it is shown that no clear conclusion can be drawn, though evidence supporting the claim is stronger in astronomy and physics than among the social sciences. An empirical study of 656 papers in four Australian science journals produced negative results. Possible reasons for the differing results, and difficulties in researching the field, are highlighted.		M. Bridgstock	1991	Scientometrics	10.1007/BF02019181	discipline;social science;comparative research;empirical research;operations research;citation analysis;auteur theory;cooperation;multiple	PL	-75.99311773221396	-22.49866134685042	132107
c834538f0f75731205d12c66298e16bca2c85f56	from cyber situational awareness to adaptive cyber defense: leveling the cyber playing field		In the cyber security landscape, the asymmetric relationship between defender and attacker tends to favor the attacker: while the defender needs to protect a system against all possible ways of breaching it, the attacker needs to identify and exploit only one vulnerable entry point in order to succeed. In this chapter, we show how we can effectively reverse such intrinsic asymmetry in favor of the defender by concurrently pursuing two complementary objectives: increasing the defender’s understanding of multiple facets of the cyber landscape – referred to as Cyber Situational Awareness (CSA) – and creating uncertainty for the attacker through Moving Target Defense (MTD) or Adaptive Cyber Defense (ACD) techniques. This chapter provides a brief overview of contributions in these areas, and discusses future research directions.		Massimiliano Albanese	2018		10.1007/978-3-030-04834-1_1	entry point;instrumental and intrinsic value;situation awareness;exploit;computer security;computer science	HCI	-73.08040937978826	-10.585517836137354	132344
e61b3c582a07f12f68b422cc5040334bcceb8a9b	trademark infringement, the internet and jurisdiction			internet	David Bainbridge	2003	Journal of Information, Law and Technology		internet privacy;the internet;trademark infringement;computer security;jurisdiction;computer science	Theory	-69.79171851278166	-10.15000226021371	132378
d31b3346d248c6b171576dfdf73f2036ccb5fa25	editorial comments: diagnostic decision support systems: how to determine the gold standard?	gold standard;decision support system	In 1996 in an editorial on evaluation of decision support systems, Miller proposed that the bottom line in evaluating clinical decision support systems (CDSSs) should be “whether the user plus the system is better than the unaided user with respect to a specified task….”1 Since 1996, several studies have examined that issue, and, yet, there is still disagreement on the way to operationalize Miller's proposition. In this issue of the Journal , Ramnarayan et al.2 describe a variety of metrics to evaluate the performance of a new pediatric diagnostic program, ISABEL. In a previous issue, Fraser et al.3 also described metrics to evaluate a heart disease program, the HDP. Both Ramnarayan et al. and Fraser et al. discussed how their measures compared with the earlier measures used by Berner et al.4 and Friedman et al.5 to evaluate other diagnostic programs.#N##N#Why should it be so difficult to agree on a reasonable metric for evaluating these systems? Those of us who have struggled with this issue in our research have come to appreciate some of the difficulties that may not be immediately obvious in the published literature, but are important to articulate. Many of these issues are not unique to the diagnostic programs, but are a challenge in evaluating any CDSS. However, diagnostic programs are particularly challenging because, as Ramnarayan et al. indicate, diagnostic programs should influence both the diagnosis and the management plans. With that in mind, and with Miller's injunction to focus on evaluating how the system and clinician work together, I would like to discuss the problems that arise with the different “gold standards” that researchers have used and also would like to offer suggestions for researchers and developers of diagnostic CDSS.#N##N#Most researchers have included in their metrics the production of the …	decision support systems, clinical;support system	Eta S. Berner	2003	Journal of the American Medical Informatics Association : JAMIA	10.1197/jamia.M1416	medicine;decision support system;gold standard;computer science;artificial intelligence;data mining;management science;operations research;statistics	NLP	-67.39675275367927	-23.44174078351187	132551
3c2cb2b3308713d5ef40ce15c41de492c53c864f	excellence in evaluation: early landmarks at the national library of medicine	lancaster f w;evaluation systeme;early experience;text;information retrieval system;almacenamiento informacion;national library of medicine;lancaster f wilfrid frederick wilfrid 1933;evaluacion sistema;informing science;carriere professionnelle;carrera profesional;career;information storage;system evaluation;stockage information;information system;information storage and retrieval;systeme information;sistema informacion	F. Wilfrid Lancaster has earned a reputation for greatness in the evaluation of information storage and retrieval systems. Many of his extensive contributions stem from his early experience with the National Library of Medicine (NLM) MEDLARS system. His evaluation of the MEDLARS Demand Search Service in 1966 and 1967 was an important landmark as one of the earliest evaluations of a computer-based retrieval system and as the first application of recall and precision measures in a large, operational database setting. In 1971, his evaluation of the MEDLARS AIM-TWX system was an important study of early online systems and their direct use by end users. This paper summarizes Lancaster’s two major evaluations of the MEDLARS system, including the information environment at the time and their impact in the field of information science. Examples of Lancaster’s other evaluation work with information retrieval systems are provided, followed by discussion of the textbooks that grew out of his evaluation experience and expertise. The article closes with comments from current and former NLM staff regarding Lancaster’s time at NLM or his influence on their own career. Introduction F. Wilfrid Lancaster established himself as a giant in the evaluation of information storage and retrieval systems early in his career, and his reputation for greatness in this arena stands today. Many of Lancaster’s extensive contributions stem from his experience with the National Library of Medicine (NLM) MEDLARS system. As one of the earliest evaluations of a computer-based retrieval system, his evaluLIBRARY TRENDS, Vol. 56, No. 4, Spring 2008 (“The Evaluation and Transformation of Information Systems: Essays Honoring the Legacy of F. W. Lancaster,” edited by Lorraine J. Haricombe and Keith Russell), pp. 859–887 (c) 2008 The Board of Trustees, University of Illinois Excellence in Evaluation: Early Landmarks at the National Library of Medicine	aim alliance;computer data storage;information systems;information retrieval;information science;medline;netware loadable module;precision and recall	Barbara A. Rapp	2008	Library Trends	10.1353/lib.0.0017	psychology;library science;computer science;engineering;sociology;management;operations research;world wide web;information retrieval;information system	Web+IR	-64.46835755780704	-14.908898229197403	132617
47fafcb709abd97d16106d01d115c0d15707cf25	emerging trends and new developments in information science: a document co-citation analysis (2009–2016)	information science;information visualization;citespace;co-citation analysis	Characterizing the structure of knowledge, the evolution of research topics, and the emergence of topics has always been an important part of information science (IS). Our previous scientometric review of IS provided a snapshot of this fast-growing field up to the end of 2008. This new study aims to identify emerging trends and new developments appearing in the subsequent 7574 articles published in 10 IS journals between 2009 and 2016, including 20,960 references. The results of a document co-citation analysis show great changes in the research topics in the IS domain. The positions of certain core topics found in the previous study, namely, information retrieval, webometrics, and citation behavior, have been replaced by scientometric indicators (H-index), citation analysis (citation performance and bibliometrics), scientific collaboration, and information behavior in the most recent period of 2009–2016. Dual-map overlays of journals show that the knowledge base of IS research has shifted considerably since 2010, with emerging topics including scientific evaluation indicators, altmetrics, science mapping and visualization, bibliometrics, citation analysis, and scientific collaboration.	algorithm;altmetrics;bibliometrics;blog;citation analysis;cluster analysis;co-citation;dual graph;emergence;flexos;information behavior;information retrieval;information seeking behavior;informetrics;java ee connector architecture;journal of the association for information science and technology;knowledge base;knowledge management;scientometrics;snapshot (computer storage);social network;timeline;webometrics	Jianhua Hou;Xiucai Yang;Chaomei Chen	2018	Scientometrics	10.1007/s11192-018-2695-9	citation analysis;data mining;citation;bibliometrics;webometrics;altmetrics;information behavior;computer science;information visualization;information science	NLP	-76.22478824507054	-18.65781698686085	133127
2cedee4e095de939e0e2afbc52fc73d17f83d527	on rob kling: the theoretical, the methodological, and the critical	social informatics;rob kling;social critique;theory;intellectual trajectory;working paper	We explore Rob Kling’s conceptual scaffolding for Social Informatics: his integration of theory, method and evidence and philosophical underpinnings and moral basis of his commitment to a critical stance towards computers and social life. He extended his focus on organizational practices and a lifelong meditation on democracy, value conflicts and social choices to the discourses of computerization and social transformation and to the education of the information professional. He came to his project through careful observation of organizational life and a critical reading of research conducted by other scholars and the rhetoric about ICTs, As Kling conceptualized it, the project of Social Informatics was to intervene in the social construction of the meaning, value, use and even design of technologies as shaped by discourse and education.	computer;information professional;social informatics	Alice Robbin;Ron Day	2006		10.1007/978-0-387-37876-3_2	psychology;social science;sociology	HCI	-75.53642573503696	-14.228222041686267	133131
8a0aa5c08c99576d4a22511312f635ba0162c8b5	a new history of aslib, 1924-1950	ciencia informacion;europa;case history;history;information science;biblioteca especializada;biblioteconomia;special library;informing science;bibliotheconomie;siecle 20eme;association professionnelle;century 20th;professional associations;historique;asociacion profesional;royaume uni;documentacion;united kingdom;reino unido;annees 1924 1950;librarianship;special libraries;information service;europe;bibliotheque specialisee;science information;professional association;siglo 20;documentation;aslib association of special libraries and information bureaux;design methodology;estudio historico;document management	Purpose – ASLIB – the Association of Special Libraries and Information Bureaux – was founded in 1924 with the aim of co‐ordinating the activities of specialist information services in the UK. This article seeks to present a new history of the first quarter‐century of the Association.Design/methodology/approach – This is a historical study based substantially on two collections of primary documents: ASLIB's own records, held at Aslib Headquarters, London; and the papers of Edith Ditmas, held at the National Library of Wales.Findings – The paper explores the origins of ASLIB, and its roots in the “science lobby” of the time; it then traces the development of ASLIB as both a “national intelligence service” for science, commerce and industry, and as a quasi‐professional association with international significance. It concludes that the first of these two functions was the Association's fundamental raison d'etre.Research limitations/implications – The research is limited to study of ASLIB in the period 1924‐19...		Dave Muddiman	2005	Journal of Documentation	10.1108/00220410510598553	library science;professional association;social science;information science;computer science;sociology;operations research;law;world wide web	Crypto	-72.16797534233642	-20.158490624337254	133150
8198e91ae540ec3eec44d4feeb423cca562d3060	is the digital talking book program meeting librarian and patron expectations?		The goal of this paper is to fill the gap in current research on the United States National Library Service for the Blind and Physically Handicapped program by surveying NLS librarians, using social informatics as the theoretical base. A 31-question survey was distributed to 111 library professionals. The questions addressed the Digital Talking Book Program, the Digital Talking Book Player, patrons, adaptive/assistive technologies, the impact of the 2008–2009 recession, and the Local Recordings program. NLS librarians and their patrons were satisfied with the player; however, both groups feel that it needs to be upgraded. Future research should survey NLS patrons and non-users of the NLS program.	daisy digital talking book;librarian	Terence Lionel Rose	2018	JOLIS	10.1177/0961000616667800	social informatics;library science;multimedia;computer science;nls	NLP	-65.88370276058195	-20.08723155258667	133258
f78494117de1b18f31ef916d89da32e917b31cc2	clark - the cybersecurity labs and resource knowledge-base - a living digital library		It is clear that in order to address the cybersecurity education and workforce crisis, the challenges are not just numerous but also inextricably linked. The least of which include a greater number of prepared faculty, effective curriculum, and infrastructure to host, use, and disseminate the curriculum. There is a demonstrated need for a cybersecurity digital library (DL) that will help address these challenges. The Cyber DL is similar to other curricular digital libraries in some respects (material quality, uptake, etc.) and unique in others (national security concerns, presence of damaging material – malware, material integrity issues, etc.).	computer security;digital library;library (computing);malware	Melissa Dark;Siddharth Kaza;Blair Taylor	2018			internet privacy;computer security;knowledge base;computer science;digital library	Security	-70.7477016125256	-10.377260293182795	133284
459bea5ae9b30adccbfc690e73182fbed38c3b54	pricing data services: pricing by minutes, by gigs, or by megabytes per second?		Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2016, INFORMS	download;institute for operations research and the management sciences;megabyte;robot	Ying-Ju Chen;Ke-Wei Huang	2016	Information Systems Research	10.1287/isre.2016.0651	pricing;variable pricing;game theory;economics;software versioning;marketing;average cost pricing;microeconomics;rational pricing;pricing schedule;psychological pricing;price discrimination;computer security;commerce	OS	-68.12801949625127	-14.979914512018887	133466
f3920f57fc15396102175214c68ec162dcf0ffa3	searching the web: can you find what you want?	search engine;business education;science and technology;distributed storage;web search engine;library of congress;indexation;world wide web;health care	The World Wide Web has revolutionized communication and information distribution, storage, and access. Its impact has been felt everywhere - e.g. science and technology, commerce and business, education, government, religion, law, entertainment, health care. Even so, there are many ways the web can be improved. We discuss what the web consists of and how it has changed, what is the size of the web, and what is covered. Results for the publicly indexable web show that the web though Terabytes in size and growing is still less than large commercial databases and the Library of Congress. Though the web started out as an academic-government endeavor, it is now primarily commerce. Furthermore, the major web search engines cover only a fraction of the publicly indexable web and appear to base their indexing strategy on the popularity of information. Since current search on the web is primarily done with the search engines, what would be the economic, political and scientific implications of these results?	database;surface web;terabyte;web search engine;world wide web	C. Lee Giles	1999		10.1145/319950.319951	web application security;web development;web analytics;web design;web search engine;business education;web accessibility initiative;web standards;computer science;data science;web navigation;social semantic web;data mining;database;web intelligence;web engineering;web 2.0;world wide web;information retrieval;search engine;health care;science, technology and society	Web+IR	-69.22699494422724	-22.43796806120538	133626
8533f8114bcea8d48f309657232632eab7b5411c	queasy: the design and implementation of a management information system for casual users	data base management systems;data dictionary directory;initialization	Currently a debate ensues over which design methods can achieve a simultaneous enhancement of casual user skill effectiveness as well as providing a suitable tool for more sophisticated users of information management systems. In this research, a classroom managerial system was designed to achieve the goal of functioning successfully for a hierarchy of user skills and needs. For the design of the system, a formalized query language was used to enhance casual user effectiveness while a relational data base structure provided the capability for more advanced query structures. In an operational test, the system functioned for a self-paced mathematics course at San Diego State University with favorable initial reactions.	database;information management;management information system;query language	Michael Andrew Christensen;Mary Anne Herndon	1978		10.1145/800127.804103	simulation;computer science;knowledge management;database	DB	-69.68312178217926	-23.900453958538158	133682
6f3b42e04352665ca914af816b02aa32e996412d	self-citations in the library and information science literature	self citation;ciencia informacion;citation analysis;type;comparative analysis;professional practice;tipo;authors;information science;pratique professionnelle;biblioteconomia;articulo;analisis cita;chercheur;library and information science;bibliotheconomie;citation;litterature scientifique;scholarly journals;analyse citation;research worker;modelo;contenu sujet;literatura cientifica;subject content;tables data;characterization;auto citation;librarianship;modele;citacion;science bibliotheque;investigator;caracterisation;library science;science information;scientific literature;article;models;caracterizacion;practica profesional;citations references;subject index terms	The purpose of this study was to determine the rate of self‐citation in the library and information science literature. A sample of 1,058 articles was examined. 50% of the articles examined contained at least one self‐citation. Articles that were reports of research, that were written by a faculty member, that addressed a theoretical topic, or that had multiple authors were all more likely to have to higher self‐citation rates. The self‐citation rate of 50% was higher than that reported in studies of self‐citation rates in the sciences and social sciences. However, the percentage of self‐citations as related to total citations of 6.6% falls between the percentage reported in the sciences and that reported in other social sciences.	library and information science	Alexandra Dimitroff;Kenning Arlitsch	1995	Journal of Documentation	10.1108/eb026942	library science;qualitative comparative analysis;social science;information science;computer science;sociology;citation analysis;type	Logic	-75.88828361547662	-22.60536865643353	133703
ebd0e3d194656c2dfb2ce888615f7fd79714070e	on the influence of growth on obsolescence	citation analysis;scientometrics;formal model;exponential model;interaction;obsolescencia;analisis cita;litterature scientifique;analyse citation;literatura cientifica;scientometria;scientometrie;crecimiento;croissance;obsolescence;interaccion;growth;scientific literature	In many papers, the influence of growth on obsolescence is studied but a formal model for such an influence has not been constructed. In this paper, we develop such a model and find different results for the synchronous and for the diachronous study. We prove that, in the synchronous case, an increase of growth implies an increase of the obsolescence, while, in the diachronous case, exactly the opposite mechanism is found. Exact proofs are given, based on the exponential models for growth as well as obsolescence. We leave open a more general theory.	mathematical model;time complexity	Leo Egghe	1993	Scientometrics	10.1007/BF02016550	interaction;scientometrics;computer science;operations research;citation analysis;world wide web;obsolescence	ML	-75.13318998112614	-21.765346403667667	133747
d71d6986ee7926b972f2316a9ddef999db3d69c7	when rights clash online: the tracking of p2p copyright infringements vs. the ec personal data directive	data protection p2p copyright infringement;bepress selected works;p2p	‘ Anti-piracy Group Broke Swedish Data Laws ’ . This was the headline to a news story published on the 10 th of June 2005 by The Local, a Swedish online news publication. As it turns out, one of Sweden’s anti-piracy groups, Antipiratbyrån (APB), in its bid to track copyright infringers, allegedly processed the personal data of Swedish peer to peer (p2p) fi le sharers in contravention of the Swedish Personal Data Act. This story is representative of the divergent perspectives that have been adopted by copyright owners and p2p fi le sharers. On one hand, a review of postings in some of the forums frequented by p2p participants indicates that some fi le sharers assume that there should be a legal rule by which copyright holders are prevented from invading their privacy. On the other hand, developments in the US go to show that the copyright holders seem to have taken the view that the fi ght against online copyright infringements should supersede all privacy considerations. There is therefore an apparent clash between two well-recognised rights, copyrights and data protection/informational privacy. The need to carefully consider this clash with a view to a possible resolution has now inspired this paper.	apb;authorization;copy protection;directive (programming);goto;information privacy;peer-to-peer;personally identifiable information;real life;right to privacy;robot	Okechukwu Benjamin Vincents	2008	I. J. Law and Information Technology	10.1093/ijlit/eam007	computer science;peer-to-peer;internet privacy;computer security	ML	-70.21125062186783	-15.129270477660024	133839
d65af85223af67eb9e6c93f82a1c233138bc3465	evolution and information	ciencia informacion;information communication;evolucion biologica;evolution biologique;sex;information science;information retrieval;sexual reproduction;sexe;informacion;communication information;biological evolution;comunicacion informacion;theorie information;science information;communication;sexo;information;information theory;evolution;teoria informacion	The association between life and information is discussed. Information is considered to be “a stimulus which expands or amends the World View of the informed”. Using this definition, the standard chain of evolutionary development is reconsidered. It is proposed that information was derived from the environment as a direct result of the evolution of organisms that used other organisms as a food source. Only with the evolution of sexual reproduction did it become necessary for organisms to be aware of others of the same species. It is argued that one of the consequences of the evolution of different sexes is that often, prospective mates had to evolve means of communication, making it possible for animals to expand their World Views by other means. Such reinterpretation of evolutionary thinking has numerous implications for the information scientist. Some of these are discussed. Introduction The term “information science” is less than fifty years old, having been coined as recently as 1955 (Wilson, 1999). As a new discipline, information science is still in the process of defining itself. This paper aims to explore links between information science and another, longer established science, that of evolutionary biology. It attempts to bring insights from evolutionary biology into information science (and vice versa). It also attempts to correct misunderstandings that evolutionary biologists have about information. The paper makes the following assumptions (derived from Meadow and Yuan, 1997) about information: . for there to be information, there must be something or someone to inform; . to be capable of “being informed”, it is necessary to have a World View; and . receipt of information results in the World View being changed. These could be summarized by defining information as a stimulus which expands or amends the World View of the informed. A further assumption is made, which is expanded on later. . If something has a World View, it, or its component parts, must be alive[1]. The Emerald Research Register for this journal is available at The current issue and full text archive of this journal is available at www.emeraldinsight.com/researchregister www.emeraldinsight.com/0022-0418.htm The author would like to thank Professor Bob Usherwood, Nigel Ford and Jared Bryson of the Department of Information Studies at Sheffield University for their support, advice, and thought-provoking comments. Evolution and information	archive;emerald;evolution;information science;information scientist;meadow;prospective search;ucl department of information studies	Andrew D. Madden	2004	Journal of Documentation	10.1108/00220410410516626	information;information theory;information science;computer science;artificial intelligence;evolution;sex;sexual reproduction;statistics		-73.001444736173	-17.688030570182416	133996
99c57359f6e429ca5f189057aec573f2e71bc395	time goes by...everything looks the same		path is similar for the majority of those in the U.S. and abroad: grade school, high school, some university-level course work. Some of us even go on to complete graduate school. If you are reading this article, you probably finished high school and college—you likely even completed an advanced degree from a respected university. School was okay for you. It got you a degree and a profession. It did what it was supposed to do. So why would someone want to change schools? In the U.S., we’ve all accepted a formulaic method of education, which generally includes a self-contained classroom in elementary school, the 52-minute classes in high school, and the big lecture halls in college. We’ve accepted that school is a certain way, and if you can’t make it in that environment, it’s your own fault. Dropouts aren’t noticeable or even worthy of notice. Yet no one ever would admit something could be wrong with the design.		Dennis Littky	2010	Interactions	10.1145/1806491.1806500		PL	-63.443855680517494	-23.684495045981734	134019
8b7d8b2d4c52fb9689ae7f1c0acb08e08bc20bf9	re-visiting paul wasserman's the new librarianship: a challenge for change			librarian	Leif Kajberg	2018	Public Library Quarterly	10.1080/01616846.2018.1511963		Logic	-63.0763234300731	-11.162256071799995	134035
41ee445d415842f20cd3b44ef035c23e6771686a	e-dossier at the dutch council of state: design, implementation and lessons learned	content management;institutional development;informing science;legal reasoning;artificial intelligent;support system;lessons learned;computer assisted legal drafting and document management;field potential;expert system;empirical research;document management	Traditionally researchers in the AI&Law community conduct research after legal reasoning, legal knowledge representation and the application of AI-based techniques for supporting legal practitioners or their clients. The focus in AI&Law research, after focusing on legal knowledge based systems has shifted to legal argumentation, which as a topic is very appealing both from a knowledge representation perspective (especially if you have a background in logics) as from a knowledge engineering perspective. However while many researchers working in the field of AI&Law focus on legal argumentation only a few actually build argumentation support systems. Even fewer researchers actually conduct empirical research aimed at supporting lawyers and judges in practical situations. This is a pity since empirical research is a requisite for building systems that are to support lawyers and judges in their daily practice. Furthermore interesting developments are going on in different legal institutions, developments that bring the application of scientific results much closer. The current situation is that only a very small number of argumentation support systems exist, e.g. Auraucaria by Reed and Rowe [1] and Argumed by Verheij [2] and even these systems are not useable in practice. For AI & Law researchers it may be disappointing to experience that the systems that are actually used and considered to be useful are much less advanced compared to the dream ware in the researchers minds. The progress made in legal content management solutions is huge. Key to the success in this field is cooperation in the field of standardization, e.g. in the CEN/Metalex working group focusing on standards for legal sources. In the SEAL project [3] that was sponsored under the European eParticipation programme three different editors for legislation drafting were tested and a first attempt to come up with an open, integrated infrastructure for supporting the legislative chain has been made. Similar approaches have been developed in the judicial domain. Recent studies such as [4], [5] and [6] show that while the use of paper based dossiers is still the common practice within juridical environments some countries have made progress into changing to electronic dossiers and supporting the legal processes using case management and work flow management solutions. Despite the clear advantages that working with completely electronic dossiers has, as is demonstrated e.g. in the Austrian Ministry for Justice [5], many organizations haven't yet turned that into their daily practice yet. Changing dossiers containing paper documents to electronic dossiers containing electronic documents seems at first sight an easy job. But when the process around the handling of paper dossiers is studied carefully, and the types of documents involved, the transformation is not as easy as it seems. Also the traditional way of dealing a paper dossier is completely different from dealing with an electronic dossier. This makes that the acceptance of an electronic dossier by lawyers and judges is sometimes hard to get. In order to meet the requirements of the lawyers and judges, one important requirement is that an electronic dossier shouldn't involve more work than a paper-based dossier. This is one of the main requirements but not the only one. In this paper the development and implementation of electronic dossiers at the Dutch Council of State is described.	artificial intelligence;as-easy-as;cen/xfs;content management system;knowledge engineering;knowledge representation and reasoning;requirement;usability;warez	G M Al Amin;Tom M. van Engers	2009		10.1145/1568234.1568268	local field potential;content management;computer science;knowledge management;artificial intelligence;document management system;management science;empirical research;operations research;expert system	AI	-67.108239000594	-23.70839511870633	134038
41547bb5a48d4b30ec1d4d3145fd7f9ec4e642e9	recruiting computer personnel at mopac - a case history -	case history;data processing	Proper recruiting for the computer programmer and systems analyst is mandatory or the continued success and even the existence of today's data processing shop. None of us can escape some attrition and if we are growing, we must find, attract, and hire the right mix of people to accomplish our objectives. This case history will cover the successful recruiting program that we have developed and are currently using. We will share some techniques of our structured recruiting program that work.	attrition (website);mopac;programmer	L. R. Cottrell	1980		10.1145/800176.809928	simulation;engineering;operations management;operations research		-68.3114914646385	-23.564223842046708	134156
f46cca4e8e7bc14ec9cbeaf8d5645ecfc2b3a6f8	welcome aboard		I have enjoyed my first six months as Executive Director of the Marion-Dillon County Board of Disabilities and Special Needs. I believe the seeds of involvement and commitment on behalf of those we serve and the agency have taken root with many of our fine staff and other stakeholders. It is in fact, “true commitment” and “sincere involvement” on the part of those who seek to improve our program that will create meaningful and lasting change in the lives of those we serve.	dillon's rolling western	Thomas Storer	1972		10.1007/3-540-07016-8_1		HCI	-65.04325314762902	-20.234517026215514	134264
35103e73486051f9c22fbee66300204ffabdcf80	the forensics aspects of event data recorders	digital forensics;civil procedure;crash reconstruction;event data recorder;evidence production	The proper generation and preservation of digital data from Event Data Recorders (EDRs) can provide invaluable evidence to automobile crash reconstruction investigations. However, data collected from the EDR can be difficult to use and authenticate, complicating the presentation of such information as evidence in legal proceedings. Indeed, current techniques for removing and preserving such data do not meet the court’s standards for electronic evidence. Experimentation with an EDR unit from a 2001 GMC Sierra pickup truck highlighted particular Journal of Digital Forensics, Security and Law, Vol. 3(3) 30 issues with repeatability of results. Fortunately, advances in the digital forensics field and memory technology can be applied to EDR analysis in order to provide more complete and usable data. The presented issues should assist in the identification and development of a model for forensically sound collection and investigation techniques for EDRs.	authentication;bluetooth;case preservation;digital data;global motion compensation;repeatability	Jeremy S. Daily;Nathan Singleton;Elizabeth Downing;Gavin Wylie Manes	2008	JDFSL	10.15394/jdfsl.2008.1044	simulation;engineering;forensic engineering;computer security	HCI	-66.97075955265747	-15.450293821604282	134535
04012ece50859ae2fbc28323a64f2c8d714838ea	should democracy online be quick, strong, or thin?	political science;statskunskap;statsvetenskap	three models representing three different democratic ideals are presented here, each providing different views of the techniques and institutional settings assumed to make the principles work in practice [6, 8]. The literature contains innumerable classifications, categorizations, typologies, and models describing variations of democracy: radical democracy, liberal democracy, participatory democracy, elitist democracy, protective democracy, pluralistic democracy, to mention a few (for examples, see [5, 6, 8]). The conceptual richness of the literature gives reason to try to find a few broad categories that simplify the picture. The three models used here—quick, strong, and thin democracy—are based on Premfors’ [10] complementary to Barber’s [2]	categorization	Joachim Åström	2001	Commun. ACM	10.1145/357489.357505	democracy;programming language;human–computer interaction;handrail;computer science	HCI	-77.37822540084225	-14.45486130816214	134605
3980a22d9f6e7ef7f14482053a5296eee35f9784	responsibilities of technologists	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias	A round the world, our lives are increasingly dependent on technology. What should be the responsibilities of technologists regarding technological and nontechnological issues? • Solving real-world problems often requires technological expertise as well as sufficient understanding of a range of economic, social, political, national, and international implications. Although it may be natural to want to decouple technology from the other issues, such problems typically cannot be solved fully by technology alone. They must be considered in the broader context. • Although experts in one area may not be qualified to evaluate detailed would-be solutions in other areas, their own experience may be sufficient to judge the conceptual merits of such solutions. For example, demonstrable practical impossibility or fundamental limitations of the concept, the existence of serious conflicts of interest of the participants, or an obvious lack of personal and systemwide integrity might be considered causes for concern. • Ideally, we need more open and interdisciplinary examinations of the underlying problems and their proposed solutions. The challenge of ensuring election system integrity illustrates these points. The election process is an end-to-end phenomenon whose integrity depends on the integrity of every step in the process. Unfortunately , each of those steps represents various potential weak links that can be compromised in many ways, accidentally and intentionally, technologically or otherwise ; each step must be safeguarded from the outset and auditable throughout the entire process. Irregularities reported in the 2004 U.S. national election span the entire process, concerning voter registration , disenfranchisement and harassment of legitimate voters, absence of provisional ballots, mishandling of absentee ballots, extensive delays in certain precincts, and problems in casting and counting ballots for e-voting as well as other modes of casting and counting votes. Some machines could not be booted. Some machines lost votes because of programming problems, or recorded more votes than voters. Some touch-screen machines reportedly altered the intended vote from one candidate to another. The integrity of the voting technologies themselves is limited by weak evaluation standards, secret evaluations that are paid for by the vendors, all-electronic systems that lack voter-verified audit trails and meaningful recountability, unaudited post-certification software changes, even runtime system or data alterations, and human error and misuse. Other risks arise from partisan vendors and election officials. Furthermore, unusually wide divergences between exit polls and unaudited results created question in certain states. All of these concerns add to uncertainties about the integrity …	booting;coupling (computer programming);end-to-end principle;human error;hyperlink;runtime system;system integrity;touchscreen	Peter G. Neumann	2005	Commun. ACM	10.1145/1042091.1042129	software engineering;theoretical computer science;computer science	Security	-72.70554342202583	-11.603918440578688	135069
523b24de69db6163c2003118ba17cb117b4635bd	consulting services and the social sciences: communication and cooperation	social science	Using the computer to process data has become so indispensable to business and government that it is now being taught in an inchoate form to nearly all social science students. The principal reason the computer has become so important is obvious: the machine makes it possible to process large quantities of data quickly, conveniently, and accurately. Thus, knowing how to use the computer is essential for social scientists because they often are employed by public officials and agencies that increasingly are being required by law and administrative necessity to collect, retrieve, analyze, and ingest vast amounts of data.		Ronn J. Hy;Peter B. Nelson;William L. Waugh	1977		10.1145/800101.803297	public relations;knowledge management;political science;management science	ML	-74.60250726767501	-11.513367763201783	135221
aac26bf252810092aacaf96c024bb1f5ce7bc499	changing of library services under e-research environment	libraries;busqueda informacion;bibliotheque;electronic media;service information;library service;information retrieval;e science;ultrasonic motor;virtual research environment;information services;data storage;remote laboratory;internet;recherche information;medio ambiente electronico;electronic environment;servicio informacion;information service;information research;recherche scientifique;china;biblioteca;scientific research;library;investigacion cientifica;design methodology;environnement electronique	Purpose – The aim of this paper is to explore the way in which e‐research is changing the nature between researchers and libraries, and to suggest how librarians can become more engaged with professional research under an e‐research environment.Design/methodology/approach – This paper takes the example of research into ultrasonic motors to investigate what can be done in current library facilities with regard to collecting and sharing data, and what should be provided in future libraries to facilitate the research of ultrasonic motors under an e‐research environment.Findings – Current libraries can facilitate professional research through retrieval of digital resources such as diverse databases, in which researchers can get information on trends, hot topics, and the main problems in order to conduct further investigations. To completely realize e‐research of professional researches, it is suggested that more extended services such as infrastructures of remote laboratories and virtual research environments...		Yajie Zhao	2009	The Electronic Library	10.1108/02640470910947683	ultrasonic motor;library;telecommunications;computer science;database;multimedia;law;world wide web;china;information retrieval;electronic media	HPC	-71.82909742907552	-23.563669037318228	135332
bd252d89a9bbb423ce63abc664c81d5b0208767f	digital humanities as a university degree: the status quo and beyond			digital humanities	Manfred Thaller;Patrick Sahle;Florence Clavaud;Tanya E. Clement;Domenico Fiormonte;Elena Pierazzo;Malte Rehbein;Geoffrey Rockwell;Susan Schreibman;Stéfan Sinclair	2012			status quo;political science;social science;digital humanities	Crypto	-63.42890678698564	-11.075566017985418	135383
cc78218e2656a2e029e173cdde2dba907f08edeb	silver bullet talks with giovanni vigna	red team;capture the flag;international capture the flag silver bullet vulnerabilities capture the flag ictf red team cyberattack security podcast;vulnerability analysis;security podcast;web security;intrusion detection;silver bullet;university of california;online discussion;vulnerabilities;malware;cyberattack;interviews;computer software;ictf;international capture the flag;interviews malware computer software	Gary McGraw interviews Giovanni Vigna, a professor of computer science at the University of California, Santa Barbara, where he works on Web security, vulnerability analysis, malware countermeasures, and intrusion detection. Vigna is also codirector of the UCSB Security Lab and a member of the Shellphish and Epic Fail hacker collectives. He cofounded Lastline (an antimalware company) and organizes the annual International Capture the Flag hacking competition (iCTF). Hear the full podcast series at www.computer.org/silverbullet. Show links, notes, and an online discussion can be found at www.cigital.com/silverbullet.	no silver bullet	Gary McGraw	2012	IEEE Security & Privacy	10.1109/MSP.2012.77	intrusion detection system;simulation;cyber-attack;interview;vulnerability;computer science;vulnerability assessment;internet security;malware;world wide web;computer security	Security	-68.66760669202365	-11.10226454470542	135544
a75cbfa6d224cf2c41c1b2941efa8aea8f329906	privacy challenges in patient-centric health information systems		Patient Health Record (PHR) systems offer great promise but raise significant philosophical, cultural, legal, and technical challenges. In hopes of furthering debate on key issues, we explain some central questions about the role, purpose, and policies associated with these systems. We also propose a framework for addressing policy questions and candidate technology that we believe may sharpen policy discussion and allow PHR systems to adhere to policies they adopt. Keywords-Privacy, policy, contextual integrity, conformance	conformance testing;health insurance portability and accountability act;information systems;privacy	Anupam Datta;Nipun Dave;John C. Mitchell;Helen Nissenbaum;Divya Sharma	2010			privacy by design;medical record;internet privacy;business;personally identifiable information;health informatics;privacy software;information privacy	Security	-73.21747349269016	-12.443668552049653	135594
9c42c6add1e284c565ccb54066080ec70bef1bc0	the state's geopolitics versus the local's concern, a case study on the land border between indonesia and timor-leste in west sector	indonesia;timor leste;arbitrary awards 1914;geopolitics;international land border;demarcation survey;treaty 1904;border line;delineation survey	One of geopolitics realizations is the establishment of international borders between countries. Indonesia has international land borders with 3 countries, including the land border with Timor-Leste.#R##N##R##N#Establishment of the international border between Indonesia and Timor-Leste was a joint mandate of the two Governments, these are the Republic of Indonesia (RI) and the Democratic Republic of Timor-Leste (RDTL) based on the Treaty 1904 and the Arbitrary Awards 1914. Joint border surveys have been in progress achieving 96% of the total length of the border lines. During the surveys there were problematic situations occurred.#R##N##R##N#A government's geopolitics is not always fortunate to immediately match with the local's concern on the land border line establishment. This is particularly happening at a certain land border line segment between Indonesia and Timor-Leste in West Sector. This paper does not describe which side is right or wrong, instead, a soft approach of solution is underlined.		Sri Handoyo	2011		10.1007/978-3-642-21928-3_22	geopolitics	NLP	-68.07533831396445	-12.728375511490057	135622
8d1719ea2434809d3218e434b1b9a38cfb76a851	interlocking editorship. a network analysis of the links between economic journals	networks;digital library;exploratory analysis;information network;network analysis;journal gatekeepers;network economics;interlocking editorship;economic journals;editorial boards	The exploratory analysis developed in this paper relies on the hypothesis that each editor possesses some power in the definition of the editorial policy of her journal. Consequently if the same scholar sits on the board of editors of two journals, those journals could have some common elements in their editorial policies. The proximity of the editorial policies of two scientific journals can be assessed by the number of common editors sitting on their boards. A database of all editors of ECONLIT journals is used. The structure of the network generated by interlocking editorship is explored by applying the instruments of network analysis. Evidence has been found of a compact network containing different components. This is interpreted as the result of a plurality of perspectives about the appropriate methods for the investigation of problems and the construction of theories within the domain of economics.	database;econlit;network theory;social network analysis	Alberto Baccini;Lucio Barabesi	2009	Scientometrics	10.1007/s11192-009-0053-7	digital library;social science;network analysis;computer science;data mining;sociology;operations research;world wide web	AI	-77.19450710243764	-18.519118953856445	135693
6d23cb2727794f2851a52438538b94fc8e34fdc8	"""commentary on f.w. horton's """"an information bill of rights"""""""		One might reasonably expect an Information Bill of Rights to state who has a right to what information 111. Only the second article of Mr. Horton’s document states that an individual has a right to certain information. The rest of the articles are policy statements designed to restrict the collection, maintenance, and distribution of information on individuals. The primary purpose of the model Information Bill of Rights is to limit and safeguard information about individuals. Thus the articles are concerned not with what information an individual has a right to obtain, but with what information on individuals others have IIO right to obtain (and how to ensure that they do not obtain it.) Maintaining that an entity (person, corporation, government) has a right to do certain things and/or not to have certain things done to it is a relatively recent phenomenon in moral theory and there are no universally agreed upon foundations for claims to political, economic, and personal rights. In brief, the historical development of rights theories began with religious “duties” to God which meant that God had a “right” to certain objects and activities from people. Next the “Divine Right of Kings” theory maintained that people had certain duties to their sovereign who, in turn, had certain rights and privileges. In the second case, the right of the sovereign was derived from the deity who delegated power to the king. The basis of the deity’s right was a combination of gratitude (we owe it to God in return for all we have received) and subservience to a power capable of enforcing its claim to have rights (might makes right). The next step in the evolution of rights occurred when	privilege (computing);theory	Diana Woodward	1987	JASIS	10.1002/(SICI)1097-4571(198703)38:2%3C130::AID-ASI7%3E3.0.CO;2-0		AI	-64.41147507264752	-20.55992594331252	135738
70910ce527cd1731b172391ce3927e7fa5269895	typology and sociodemographic characteristics of massively multiplayer online game players	online survey;massively multiplayer online game;real time strategy;role playing game;socio economic status;first person shooter;institutional repository research archive oaister;bf psychology lelektan	Typology and Sociodemographic Characteristics of Massively Multiplayer Online Game Players Katalin Nagygyörgy a , Róbert Urbán a , Judit Farkas a , Mark D. Griffiths b , Dalma Zilahy a , Gyöngyi Kökönyei a , Barbara Mervó a , Antónia Reindl a , Csilla Ágoston a , Andrea Kertész a , Eszter Harmath a , Attila Oláh a & Zsolt Demetrovics a a Eötvös Loránd University, Budapest, Hungary b Nottingham Trent University, Nottingham, UK Accepted author version posted online: 22 Jun 2012.Version of record first published: 27 Jan 2013.	biological anthropology;massively multiplayer online role-playing game;róbert szelepcsényi	Katalin Nagygyörgy;Róbert Urbán;Judit Farkas;Mark D. Griffiths;Dalma Zilahy;Gyöngyi Kökönyei;Barbara Mervó;Antónia Reindl;Csilla Ágoston;Andrea Kertész;Eszter Harmath;Attila Oláh;Zsolt Demetrovics	2013	Int. J. Hum. Comput. Interaction	10.1080/10447318.2012.702636	simulation;socioeconomic status;game mechanics;multimedia	ECom	-63.02995462261083	-13.582225186629666	135914
3efb6dccb451f79c72418ccbee9e0416731b2d7b	investigating the efficiency in oil futures market based on gmdh approach	futures market	This article has been retracted at the request of the Editor-in-Chief. Please see Elsevier Policy on Article Withdrawal ( http://www.elsevier.com/locate/withdrawalpolicy ).  Reason: This article has copied material previously published in the article “Are there exploitable inefficiencies in the futures market for oil?”, Shambora et. al.,  Energ. Econ. , 29 (2007) 18–27, doi: 10.1016/j.eneco.2005.09.004 .  As such, this article represents a severe abuse of the scientific publishing system and a clear violation of publishing ethics, and therefore must be retracted.	futures and promises;group method of data handling		2009	Expert Syst. Appl.	10.1016/j.eswa.2008.09.055	actuarial science;computer science;operations research	AI	-70.02752652339404	-12.612765388383362	136114
8f3beee588a578d9b3d70c6362c58887ef203033	a passage through science: crossing disciplinary boundaries.	bibliographic databases;text;bibliographic coupling;information retrieval;data mining;database management;database searching;interdisciplinary approach;cognitive processes;information storage and retrieval;scientific and technical information;citations references	A METHODOLOGY IS PRESENTED FOR CREATING pathways through the scientific literature following strong co-citation links. A specific path is described starting in economics and ending in astrophysics traversing 331 documents. Special attention is given to where the path crosses disciplinary boundaries and how analogy can be used to model the thought processes involved in such transitions. Implications of information pathways for retrieval, the unity of science, discovery, epistemology, and evaluation are discussed. INFORMATION AND ZNFORMATION RETRIEVAL TRANSITIONS A great deal of information science is concerned with retrieving all the documents from a database that precisely match a user’s query. In this magic bullet model of information retrieval, the documents retrieved will ideally be homogeneous in character. Such an ideal is, of course, rarely achieved. In practice, a wide array of documents of varying relevance is retrieved, resembling more an ecology of information than a uniform set. Less often under consideration is how to understand the diversity and breadth of information that most queries generate, how one topic relates to another, or the transitions from one document to another. Questions such as these naturally arise for large samples of documents and especially multidisciplinary databases. For example, a user interested in a topic such as asthma might retrieve a large number of hits and find that Henry Small, ISI, 3501Market Street, Philadelphia, PA 19104 LIBRARY TRENDS, Vol. 48, No. 1,pp. 72-108 01999 The Board of Trustees, University of Illinois SMAI,L/CROSSING DISCIPLINARY BOUNDARIES 73 some deal with treatment options, age factors, psychological aspects, hereditary tendencies, environmental factors, and so on. The question is how to make sense of this diversity. One reason questions of subject diversity do not come up more often is the tacit assumption that topics or subjects are relatively isolated and distinct from one another, each representing a more or less separate homogeneous entity. Another reason is the assumption that users’ information needs are simple and highly specific. This contrasts with the view that information seeking is more like a gradually unfolding discovery process in which the initial query is only the first step in a longjourney, each step depending on what came before (Kuhlthau, 1999). INFORMATION AND THE UNITYOF SCIENCE TRANSITIONS Earlier discussions of the unity of science (Neurath, 1938) or its modern incarnation in E.O. Wilson’s (1998) consilience, view scientific knowledge as an interconnected fabric of fields and disciplines. In the sociology of science, it is commonplace to say that a great deal of scientific and technological innovation takes place at the boundaries between disciplines (Lemaine et al., 1976) or by individuals who have crossed from one field to another. Cross-fertilization of fields is another term for this, when an idea in one field finds fertile ground in a neighboring field (Crane, 1972). Information scientists have begun to explore these issues by attempting to find unconnected subject areas which, if connected, might yield new discoveries (Swanson & Smalheiser, 1997). Attempts to visualize information spaces also address subject connections since a visualization must depict the relationships among diverse set5 of documents (White &McCain, 1997). It seems likely that future information retrieval systems based on the visual paradigm will have the equivalent of road signs telling the user what direction to travel to reach a particular topic. CITATIONS AND THE STRUCTURE OF SCIENCE One of the best ways of studying the connectedness of information is to use reference or citation links. While connections can also be established by shared vocabulary or indexing terms, a citation link represents a more direct author-selected dependency. By taking a wide-ranging sample of documents across many fields, the unity of scientific information can be examined from a global perspective. Vannevar Bush’s (1945) idea of associative information trails is a natural consequence of the unity of science and the connectedness of knowledge. Hummon and Doreian (1989) attempted to demonstrate this on a small scale by finding a critical path through a DNA citation network. Path analysis has more recently been undertaken for documents in the area of hypertext research using author co-citations (Chen & Carr, 1999). 74 LIBRAKY TKENDS/SUMMER 1999 Taking citation links as the basis o f a structural analysis of science, it is natural to suppose that it would be possible to travel from any topic or field to any other (Small, 1999) just as in the world of the Internet we might follow a series of hypertext links tu reach any desired Web site. In the abstract, this is equivalent to traversing a network, but there is no guarantee the structure is in fact connected. In science, citations are very unevenly distributed, concentrating in narrowly defined pockets which correspond roughly to specialties or invisible colleges of’researchers (Small & Griffith, 1974). The boundaries of these regions of’high density are not well defined, however. Yet the most interesting links in the chain from one end of science to the other are those which cross disciplinary boundaries. Interdisciplinary links represent a kind of intellectual leap from one domain to another. In the world of citation analysis, strong links can be established by frequent patterns of co-citation (Small, 1973) or bibliographic coupling (Kessler,1963). Co-citation links are a second order form of citation linkage that depends on the joint citing of two earlier documents by later documents. Unlike direct citation links, co-citations are nondirectional and can be weighted by frequency of occurrence. By simple “thresholding,” it is possible to identify regions of high co-citation density. Thresholding is in fact equivalent to the method of clustering called “single-linkage” (Hartigan, 1975). In a map based on co-citation clusters, an interdisciplinary link can occur when an author co-cites across the boundary of two disciplinary clusters. If the author cites predominantly into one cluster, as is often the case, the interdisciplinary co-citation reaches out beyond the author’s home cluster (see Figure 1). This reaching out or stretching can import or export methods, ideas, models, or empirical results from the author’s field to the other field. This is an act requiring a broad awareness of literature plus the creative imagination to see how the outside information fi1.s with the author’s problem domain. The author of such a paper is going out on a limb to integrate ideas from another discipline. The objective of the present study is to examine the nature of the connections that tie the scientific literature together, focusing particularly on links crossing disciplinary boundaries. The question is whether interdisciplinary transitions are gradual or abrupt or based on shared features, analogies, creative insights, or perhaps even questionable assumptions-in short, how far the author had to stretch to make the connection. In another sense it is an examination of the creative process of moving from one domain of knowledge to another. If citation relationships capture authors’ decisions or selections on what documents are relevant to a problem, paths that follow citation links may in some sense capture steps in problem-solving behavior, logical thinking, or intuition. SMAI,L/CROSSING DISCIPLINARY BOUNDARIES 75	bibliographic coupling;box counting;carr–benkler wager;citation analysis;citation network;cluster analysis;co-citation;computational astrophysics;critical path method;database;ecology;entity–relationship model;hypertext;information sciences institute;information needs;information retrieval;information science;information scientist;information seeking;leslie blackett wilson;linkage (software);problem domain;problem solving;programming paradigm;relevance;scientific literature;structural analysis;thresholding (image processing);unfolding (dsp implementation);visual paradigm for uml;vocabulary	Henry G. Small	1999	Library Trends		cognition;computer science;data science;data mining;information retrieval	Web+IR	-73.2619352889168	-19.006977273682413	136118
76515336d1c2564c4629a1fa7bd9d5743cf623e3	providing a window of opportunity for converting estore visitors	competing risk model;search engine ad;online information search;banner ad	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2016, INFORMS	download;e-commerce;institute for operations research and the management sciences;robot;window of opportunity	Amit Bhatnagar;Arun Sen;Atish P. Sinha	2017	Information Systems Research	10.1287/isre.2016.0655	web banner;computer science;marketing;advertising;world wide web;unique visitor	Robotics	-68.15706613891341	-15.030760085803168	136128
ca2cd6906d622fe68d42e54853fa57df0247311e	the tragedy of product homogeneity and knowledge non-spillovers: explaining the slow pace of energy technological progress		There is a growing body of literature mentioning the slow progress of energy technological innovation as compared to information technology (IT), but the reasons why the energy sector is perplexed by slow innovation remain unexplained. Based on a variety-expanding endogenous technological change model, this paper investigates the economic mechanism that underlines the slow pace of energy technological progress. We show that in the market equilibrium the growth rate of energy technology variety is always lower than that of IT variety, this outcome stems from both the market fundamentals where the homogeneity of end-use energy goods is less likely to harness the pecuniary externality embedded in the love-for-variety household, and the technology fundamentals where capital-intensiveness of energy technology assets inhibits the non-pecuniary technological externality associated with knowledge spillovers. We further show that the social planner allocation can raise the rate of technological progress in both energy and IT sectors, but still fails to achieve an outcome in which technological progress in the energy sector can catch up with the IT sector. Finally, using efficiency-improving revenue-neutral policy interventions that subsidize energy sectors and tax IT sectors, the decentralized market equilibrium can achieve an outcome in which both energy and IT sectors have the same rate of technological progress.		Wei Jin;ZhongXiang Zhang	2017	Annals OR	10.1007/s10479-016-2144-1	economics;public economics;economy;economic growth	NLP	-75.84897422035505	-10.13522414182818	136340
9b12b3fb80b495350f928a212b40126b5adcda57	president's column: an amia update - new directions and new opportunities		New directions with new opportunities by definition carry risk but we pursue them because of the potential for new rewards. As Robert F. Kennedy said, ‘Only those who dare to fail greatly can ever achieve greatly.’ At a time when both the science and practice of informatics are poised to exert a powerful influence on the future of healthcare, the AMIA leadership embarked on a fact-finding mission to determine more clearly the state of the association and its future direction. In service to the Board of Directors and AMIA membership and as the President and CEO of AMIA, I am charged with the responsibility of sustaining the long term growth and stability of AMIA. As part of that responsibility, I wanted to share with you—at a high level—some new directions and new opportunities for AMIA. The AMIA tag line says it best when describing the AMIA Board of Directors’ approach to governance: leadership has been very thoughtful and deliberate as ‘Informatics Professionals. Leading the Way.’ The AMIA Board invested resources in conducting research under the direction of Association Management+Marketing Resources (AMMR), a consulting and research firm specifically focused on associations. AMMR recently provided a full report to the AMIA Board of Directors that contained qualitative and quantitative information. By sharing the outcomes of the survey, the AMIA leadership’s intention is to be as transparent and accountable as possible with AMIA members and stakeholders. While much detailed information (ie, comments, suggestions, recommendations, etc) from members will remain confidential, a high level summary is available to members on our website. In the next few months we will be posting additional information concerning the strategy for the association, which will evolve as a result of your input and guidance as more specific objectives and detailed plans are outlined. The assessment included a member survey which sought to understand the views, interests, priorities, and perspectives of members and informatics professionals allied with AMIA. We had a very good response which provided a statistically significant sample and, as a result, we have confidence in the suggestions provided by respondents. The respondents shared many opinions which contributed to a rich source of ideas, thoughts, and perspectives that we believe will help us to serve members and the field better in the future. As part of the assessment, AMIA carried out two phases of research. First, we conducted a qualitative, in-depth telephone interview which included tele-focus groups and an environmental scan. This portion of the research ran from May through July 2012 and involved both current and former AMIA Board members, AMIA Committees/Working Group Chairs, members of the Academic Forum, and outside stakeholders such as non-members, former members, allied partners, and public health professionals. A second phase of research was conducted in July 2012 that included a quantitative survey which addressed member and non-member needs. It also covered all current members and those who had never joined or did not renew their AMIA membership. The AMIA leadership was heartened to see the passion reflected in the survey results for the field of informatics and for the role that the membership wants AMIA to play. It is clear that AMIA is critical in fostering the field of informatics, but we need to do more. So, what were the results?	behavior;charge (electrical);confidentiality;consultation;contain (action);focus group;high-level programming language;informatics (discipline);mental association;rewards;telephone number;television;thinking, function;web site;interest;physical hard work	Kevin M. Fickenscher	2013	Journal of the American Medical Informatics Association : JAMIA	10.1136/amiajnl-2012-001515	medicine;operations research	HCI	-74.44389380350958	-19.42294674406722	136356
1bc814404a16054cac79bd76bef23ef32d3e93fc	internet search engines: past and future	search engine;stock market;web crawler;web page importance;high power;scheduling policy	I will review the short history of Internet Search Engines from early first generation systems to the current crop of stock market darlings. Many of the underlying technology problems remain the same, but the business has become significantly more sophisticated and high-powered. I will touch on some of the economics driving the remarkable success of these services and make some predictions about future trends.	internet;web search engine	Jan O. Pedersen	2005		10.1145/1062745.1062770	simulation;computer science;web crawler;world wide web;search engine	OS	-69.15998044320891	-22.576362156286756	136362
f74fbdf338abccb996b80da46f02831ee045c9ad	successful proposal strategies for small businesses: using knowledge management to win government, private-sector, and international contracts. sixth edition (frey, r.s.) [book reviews]	writing strategies proposals small businesses;procurement;knowledge management;contracts;book reviews writing business contracts knowledge management management proposals procurement;business;writing;book reviews;management;proposals	The sixth edition of this book provides a valuable guide applicable to businesses small, medium, and large. The book contains 24 content-rich chapters, four appendices of additional resources and tools, a handy list of acronyms and abbreviations, an extensive bibliography for further reading, and a detailed index, as well as a compact disc (CD) full of usable forms and documents described in great depth in the book. Internalization and application of the tools and practices presented in this book should help any US business write successful proposals that win a variety of types of contracts both domestically and internationally. Overall, this book is an exceptional resource for companies of all sizes-not just small ones-looking to create successful proposals. One notable problem with the text is its incredible length. This book is a total of 716 pages of single-spaced text that would take approximately a week of five hours of reading per day for an employee to finish (figuring two minutes per page, plus time to peruse the CD), and it is unlikely the average employee or manager has that kind of time to spare. Another issue is that it does not provide any information for a foreign business looking to do business with the US. Though the general business advice and proposal writing strategies contained therein seem as if they would be equally applicable to an internationally-based company, a separate chapter or at least a section in Chapter 22 on such concerns would make the book more universally appealing and could enable greater international sales of it. Aside from those concerns, however, this book is a highly valuable tool crafted by an experienced professional.	handy board;knowledge management	Robert S. Frey	2013	IEEE Transactions on Professional Communication	10.1109/TPC.2013.2246358	psychology;economics;procurement;computer science;engineering;electrical engineering;operations management;linguistics;sociology;management;writing;operations research;law;literature;world wide web	Visualization	-66.43194948980316	-21.55001012320558	136477
cdb124b15002f46b726ca2cdcf888151be1356fa	all that glitters is not gold	trust;performance evaluation;technology;transparency;bitcoin;algorithm design and analysis performance evaluation;trust bitcoin transparency technology;algorithm design and analysis	B e careful with your predictions about the future: it’s a vengeful little beast and not to be trusted. Once you’ve made any prediction about the way things will be this year, next year, or even a decade from now, the future will find the weakness in your ideas. It will snatch any value you once claimed for your work and compel you to admit that your ideas weren’t to have been trusted in the first place. Dylan got exposed by the future earlier this month. In the midst of telling me about a new job, new skills, and a new city, she mentioned that she had become fascinated with Bitcoin. A real “game changer,” she called it. She especially liked Blockchain, the ledger that tracked all Bitcoin transactions. That vision became fodder for the future, when the Bitcoin exchange Mt. Gox announced that it had been drained of its assets. Apparently, the game-changing algorithm wasn’t as trustworthy as some had claimed, and it allowed an attacker to compel the Mt. Gox system to trust false transactions. The problem of trust, of course, is the problem that Bitcoin’s founder(s) were attempting to solve. Many commentators have suggested that Bitcoin was created to launder money or to create a form of currency beyond the control of nation-states, but the founding document makes no such claims. Instead, this document argued that the technology was created to correct the “inherent weaknesses of the trust-based model.” Bitcoin algorithms would replace the various mechanisms that we’ve used throughout human history to compel people to complete transactions. Indeed, “transactions that are computationally impractical to reverse,” explained the Bitcoin paper, “would protect sellers from fraud, and routine escrow mechanisms could easily be implemented to protect buyers.” When I raised Mt. Gox’s failure with Dylan, she dismissed it with an excuse commonly invoked by Bitcoin’s defenders. Mt. Gox, she claimed, “didn’t properly implement the Bitcoin model” and the problem would eventually be fixed. This argument is true as far as it goes, but it doesn’t address the bigger issue that hangs over Bitcoin: it was designed to solve a fairly narrow set of problems. It might not solve other problems that can be found in financial systems. In fact, it could actually exacerbate some. As important as the trust between buyer and seller may be, it’s only one of the problems that can beset a financial system. Speculators can manipulate markets. Thieves can defraud buyers, sellers, or both. Governments can inflate or deflate currencies to achieve their ends. Bitcoin may or may not be able to solve these issues, but it was never designed for such ends. At the moment, it can’t even protect the assets of its own exchanges. The age of information has generally been a period of tempered expectations. We create a technology to solve a specific problem and then transfer its benefits to a host of other issues. The glittering richness of our own work can be just a little too tempting. The free flow of information over the Internet has generally been good, but it doesn’t always protect us from those who wish us ill. The transparency of governments has made it harder for central institutions to defraud their citizens, but it hasn’t always made government offices more efficient. Electronic payment systems, such as Bitcoin, might reduce the cost of business transactions, but they shouldn’t be expected to solve all our economic woes.	algorithm;bitcoin;deflate;dylan;internet;open road tolling	David Alan Grier	2014	IEEE Computer	10.1109/MC.2014.79	computer science;internet privacy;transparency;world wide web;computer security;technology	Security	-71.97669401006475	-12.14052384283265	136528
febdaf49615f746d6f96a29beed4ee375591adae	the metamorphosis of the information resources budget	higher education;publishing industry;social influences	THE MAJOR DISCRETIONARY AREA of any library’s fiscal resources is the information resources budget. The fiscal crisis occurring in higher education over the past five years has led many research and academic libraries to spend large amounts of time bemoaning the fact that they are expected to do more with less. However, academic librarians must remember that change is occurring in all segments of society, technological advancements are continuing at a faster rate than anyone had thought, and the expectations of higher education are increasingly demanding. Academic libraries must adapt accordingly. Jerry Campbell (1989) once remarked that, “the budgets of academic libraries are rooted in the past” (p. 77). This position is no longer acceptable. Since the information resources budget is the major discretionary area of a library’s fiscal resources, the academic libraries must find cost-effective ways to achieve library goals through more efficient managing of this portion of the library’s budget.		Barbara G. Leonard	1994	Library Trends		library science;public relations;scientific communication;scholarly communication;electronic publishing;publishing;higher education;social influence;financial management;sociology;resource allocation	HPC	-68.65061170907694	-21.910439515823597	136581
4a4387fc6b3b3bc3fd698cf29ae9b1265f0f361a	a critical reflection on the threat from human insiders its nature, industry perceptions, and detection approaches	journal article;detection approaches;human factors;insider threats;survey reports;technical and psychological indicators	Organisations today operate in a world fraught with threats, including “script kiddies”, hackers, hacktivists and advanced persistent threats. Although these threats can be harmful to an enterprise, a potentially more devastating and anecdotally more likely threat is that of the malicious insider. These trusted individuals have access to valuable company systems and data, and are well placed to undermine security measures and to attack their employers. In this paper, we engage in a critical reflection on the insider threat in order to better understand the nature of attacks, associated human factors, perceptions of threats, and detection approaches. We differentiate our work from other contributions by moving away from a purely academic perspective, and instead focus on distilling industrial reports (i.e., those that capture practitioners’ experiences and feedback) and case studies in order to truly appreciate how insider attacks occur in practice and how viable preventative solutions may be developed.	experience;hacktivism;high- and low-level;human factors and ergonomics;insider threat;malware;microsoft script editor	Jason R. C. Nurse;Philip A. Legg;Oliver Buckley;Ioannis Agrafiotis;Gordon R. T. Wright;Monica T. Whitty;David Upton;Michael Goldsmith;Sadie Creese	2014		10.1007/978-3-319-07620-1_24	public relations;political science;social psychology;computer security	Security	-72.81669877845921	-10.964622315582627	136637
eba2ead1ebf1fc6eee3ef288094c7f6aa7e889e7	"""introduction to the """"corporate objective revisited"""" exchange"""	crossroads section;corporate objective revisited exchange	Corporate scandals and abuses of various kinds grab the headlines. Reform initiatives quickly follow outrage. The goal is to constrain our firms' ability to destroy value and lives, while at the same time enabling them to produce and deliver high-quality and profitable goods and services in a very competitive global marketplace. Less obvious but no less important, civil society is increasingly asking corporations to invest directly in social life. Regardless of their productive capabilities, firms can field requests to invest in education, health care, infrastructure, and the like. Sometimes the two ambitions seem to be quite compatible, while at other times they seem to be at odds. Leading a business that is at once socially responsive and economically competitive is a daunting managerial challenge. The theoretical challenge posed by these sometimes competing and sometimes complementary demands is no less daunting.Since the rise of the first corporations two thousand years ago, we have been trying to develop a theory of the firm that explains and guides firm behavior. Sundaram and Inkpen enter this complex and charged world to make a case for a theory of the firm grounded in the pursuit of shareholder wealth. Freeman, Wicks, and Parmar will not let their view go unchallenged. They offer a spirited reply. The exchange embodies everything our Crossroads section can be. We are proud to provide a home for this very thoughtful exchange. This is arguably the most important theoretical and practical issue confronting us today. While we gave Sundaram and Inkpen the last word, we know that the debate is far from over. Indeed, we invite others to think hard about these issues and develop their own point of view. The stakes are enormous.		James P. Walsh	2004	Organization Science	10.1287/orsc.1040.0086	psychology;public relations;social science;economics;operations management;sociology;management;law	NLP	-75.12335970376925	-11.149332644929878	136736
7181ad98a58ea9217b2e105d18f7b5163e46619f	book review: soaps, fandom and online			internet	Matthew Hills	2001	New Media & Society	10.1177/1461444801003001009	fandom;sociology;social science	HCI	-64.20415109471865	-10.788371794222495	136858
648f5c9ef79a4daacd798b2c27dd5df5c42ea4e9	returning to reality - by phillip m thompson				Sara Hammer	2013	BJET	10.1111/bjet.12096_7	media studies	Vision	-63.260040893147405	-11.442033659296348	137089
62605fc2e6fe16c0c9497ccda3381ca7d00e470a	in the data kitchen: a review (a design fiction on data science)		"""The story """"In the Data Kitchen"""" appeared online in 2017, and went viral, receiving an astonishing degree of attention for an unattributed work with obscure origins. We review this provocative fiction, discussing its evident resonance with societal concerns and ongoing discussions of big-data ethics."""	big data;data science;resonance	Michael J. Muller;Thomas Erickson	2018		10.1145/3170427.3188407	multimedia;big data;computer science;design fiction	AI	-70.58237945996717	-17.539548067837828	137282
5d603c25b1ff7d4db07a44b257b757fb326eada3	travelled roads	travelled road	Occasioned by the crash of the dot com market in early 2000, the period of overly optimistic expectation of Information and Communication technologies (ICTs) by society has also ended. All sectors of production, consumption, and dissemination of technologies have undergone (or are undergoing) a change process. Some of these changes have been inconsequential, while others have been far deeper reaching. The education sector too, has undertaken a similar introspective process which aims to understand how, as a discipline it has evolved to its current state. In keeping with this, in 2004, the inaugural conference on the History of Computing in Education (HCE1) was held in Toulouse, France. Scholars from four continents presented papers covering a broad spectrum of issues on the topics of history of (computing in education) as well as (history of computing) in education. The former topic deals with the time period when computing technology was used in and by education while the latter covers a much longer period which deals with the history of computing and the educational nature of that. The edited volume of 18 such papers compiled under the same name––History of Computing in Education––captures the essence of the historical panorama presented at the conference. The value of such a conference and this compiled volume are numerous: not only does a historical account provide an understanding of impinging factors that have led to the evolution of ICT, to a willing reader a historical account also provides ameliorative possibilities for the future. The role of teaching history of a specific field is an integral part of disciplines such as philosophy, medicine, architecture, etc., however the majority of computing graduates do not enjoy the benefits of a similar systematic study of the history of their own field. And for this, computing graduates are not better off. This sentiment is echoed vociferously by William Olle in what I deem to be the most analytic paper in the compilation. Educ Inf Technol (2008) 13:77–80 DOI 10.1007/s10639-007-9052-6	compiler;floor and ceiling functions;t. william olle	Rahul Kumar	2007	Education and Information Technologies	10.1007/s10639-007-9052-6	pedagogy;computer science	HPC	-67.29515915808737	-20.76669106365644	137489
32d7317a50b28eea05520b8b47b2ad1f4d8e8cac	structure of specialization among american population scientists	sociocultural factors;demographers;citation analysis;statistical studies;social sciences;chercheur;etats unis;demografia;estados unidos;research worker;data analysis;research methodology;studies;factor analysis;social organization;recherche scientifique;demography;scientific research;investigacion cientifica;demographie;structured data;principal component	Studies of journal citation patterns suggest that specialty areas within disciplines may be the most appro priate structural units for understanding the social organization of science. Citation studies necessarily are limited to scientists who publish, however, and studies of all members of particular disciplines would provide more general specialty structure data. Accordingly, this research applied factor analytic procedures previously used in studies of the structure of specialization among psychologists to all members of the Population Association of America. Four principal components derived from the self-designated specialties of these population scientist were rotated to a final solution by the varimax procedure and were interpreted as measuring, respectively,Social Emphasis, Geographic Emphasis, Formal Emphasis, andEpidemiological Emphasis. These results partially confirm the distinction sometimes made by population scientists between social demography and formal demography, but suggest this typology is incomplete. The results also illustrate techniques that could provide a useful alternative to citation analysis for researchers studying specialty structures in other disciplines.	biological anthropology;citation analysis;journal citation reports;partial template specialization;varimax rotation	J. M. Richards	1984	Scientometrics	10.1007/BF02025829	social science;scientific method;epistemology;data model;computer science;social organization;methodology;data mining;sociology;factor analysis;data analysis;operations research;citation analysis;world wide web;statistics;principal component analysis	ML	-76.20424975733116	-22.856995394583596	137820
29e87077bbbfed1a12be5ee8c9a7d82cce687a15	focus and perspectivism in viewing information, data, and informing: fundamental distinctions		In the theory of knowledge, Nietzsche articulated the principle of perspectivism. Using a simplified example, this paper illustrates how changing the optical perspective dramatically changes the results of observations. In the age of information, we still are far away from a reasonable consensus in viewing information and informing. Callaos and Callaos (2002) tried to integrate the disparate views into a “systemic notion of information” based on the “distributive notion of truth,” but it did not bring us closer to a more cohesive view for research and practice. Misplaced focus and ignored perspectives seem to be the root cause of failure. By placing the disparate views into a down-to-earth context of routine human-controlled operations and processes observed in nature, most of them can be clarified, explained, dispelled, or refuted. This paper articulates the most fundamental distinctions that should not be ignored when information is a significant factor that contributes to the success of operations.	abandonware;cognition;entity;entropy (information theory);information;materiality (digital text);path of least resistance;provable security;window blind	Zbigniew J. Gackowski	2012	InformingSciJ		psychology;epistemology;communication;social psychology	ML	-75.6394949159997	-14.118849083591474	137917
b5249bedec2e22229d71d45e9b9cd6ba7cc9093b	privacy compliance risks for facebook	legal aspects;social network services;social networking services;information privacy law;information privacy;risk management;computer crime;information privacy law privacy compliance risks facebook internet societal phenomenon online social network osn privacy values;computer security;internet;privacy values;data privacy;societal phenomenon;social networking online;facebook;social networking online data privacy internet risk management;privacy compliance risks;privacy facebook social network services computer security legal aspects computer crime;online social network;osn;privacy	Facebook is an Internet and societal phenomenon. In just a few years it has claimed a significant proportion of the world's population as regular users, becoming by far the most dominant Online Social Network (OSN). With its success has come a good deal of controversy, especially over privacy. Does Facebook and its kin herald a true shift in privacy values, or despite occasional reckless revelations, are most users actually as reserved as ever? We argue it's too early to draw conclusions about society as a whole from the OSN experience to date. However, Facebook in particular brings a number of compliance risks in jurisdictions that have enacted modern Information Privacy Law.	information privacy law;internet;microsoft kin;social network	Anna Johnston;Stephen Wilson	2012	IEEE Technology and Society Magazine	10.1109/MTS.2012.2185731	public relations;the internet;information privacy;computer science;internet privacy;privacy;computer security;information privacy law	Metrics	-73.18117986168127	-12.077020119794263	137996
7814a0db04f6da14c3830d622a74fdfde931cb44	context informed cross cultural collaboration in stability and support operations	national intelligence community;global communication;effects based operations ebo;cultural differences collaboration stability global communication collaborative work collaborative tools context modeling information analysis visualization government;cultural identity;context information;collaborative work;cross cultural collaboration;darpa;stability and support operations saso;nobel appeal foundation;mission independent cultural model;government;collaboration;real world peacemaking situation;defense advance research projects agency;semantic web context cross cultural collaboration cultural identity national intelligence community nobel appeal foundation real world peacemaking situation defense advance research projects agency darpa mission independent cultural model culturally independent mission model;collaborative tools;situation awareness sa;intelligence community;stability;software agents;culturally independent mission model;visualization;social sciences computing;semantic web context;semantic web;software agents military computing semantic web social sciences computing;defense advanced research project agency;conflict resolution;context modeling;information analysis;cultural models;military computing;cultural differences	"""According to Paul Collier, former Director of the Development Research group at the World Bank, 53% of all """"resolved"""" conflicts relapse within 5 years. Identity is generally at the heart of most conflicts, and identity oth individual and collective - is rooted in culture. Understanding and appreciation of the cultural identity of the parties to an emerging conflict is critical to both understanding and transforming that conflict. Unfortunately, the cultural nuances of many conflicts are overlooked when standard Western models of conflict resolution are applied. This paper describes recent research in this area conducted for the National Intelligence Community. This work was extended for use by the Nobel Appeal Foundation and applied in several real-world peacemaking situations. That work is now being extended to identify cultural """"indicators and warnings"""" to activities or proposed activities within the peacekeeping process under a new effort funded by the Defense Advance Research Projects Agency (DARPA). This environment provides a mechanism for the automatic ingestion of status information and news into a machine understandable """"situation context"""". A community of agents does partial matching of the known situation context to two semantically linked classes of models within the system: mission-independent cultural models; and culturally-independent mission models. Mission and cultural indicators and warnings (I&Ws) results and visualized for the user to interpret and react"""		Mark Hoffman;Brian P. Kettler;Terry Padgett	2005	Proceedings of the 2005 International Symposium on Collaborative Technologies and Systems, 2005.	10.1109/ISCST.2005.1553310	cultural identity;visualization;stability;computer science;knowledge management;artificial intelligence;conflict resolution;semantic web;management science;management;computer security;government;statistics;collaboration	SE	-73.70685999952626	-10.67063552617602	138039
ac03039946740c296e73c4e4d98151148e98a872	"""""""doctor smartphone"""": a dispositive analysis of the norwegian press's presentation of m-health applications"""		The rapid growth in the field of m-health has not gone unnoticed by the mainstream media in Norway. Norwegian newspapers have a strong presence and outreach and hence play an important role in shaping of the public discourse on various subjects with m-health being no exception. This article presents a Dispositive Analysis of 23 articles from 6 national newspapers concerning mobile health applications. The analysis resulted in an interpretation of the press's technology views as theories of technology, which informed the discussion in this paper. Further, the newspaper articles were understood as discursive practices and analyzed by applying the concept of dispositives. The results of the analysis suggest inclusion of Dispositive Analysis as a step in Participatory Design process as means of enriching the design practices as well as uncovering the marginalized â€˜voices' and thus addressing the call for democratization of technology.	smartphone	Margaret Machniak Sommervold	2016	IJSKD	10.4018/IJSKD.2016010101	social science;human–computer interaction;computer science;engineering;media studies;sociology;management;law	HCI	-72.11517513380377	-15.981013785188487	138209
78d54d7c85ac825bf288414d5b8e6cb365091de4	democracy and libraries: modernizing and rebuilding bulgarian libraries with us support, 1990-2014		Traditionally libraries, including and perhaps especially Bulgarian ones, are very conservative institutions. Libraries indeed have many reasons to be conservative, but this does not mean that they have been inactive. They have to find the proper modus operandi in order to act appropriately, responsibly, and for the greater good of society. Through funds, grants, and projects, Bulgarian libraries have began recovering. This is not to say, however, that they do not have more work ahead of them. The National Academic Library and Information System (NALIS) and the American Bulgarian Library Exchange (ABLE) projects helped pull libraries in Bulgaria out of the ashes and brought them into the twenty-first century. The aim of this paper is to briefly trace the development of Bulgarian libraries over the course of the last twenty-five years. Throughout this period, there were two decisive factors influencing library development: the rapid expansion of information technologies, and, at the same time, the acute social and economic crisis besetting the country that impeded its modernization of library science.	library	Dincho Krastev;Nikola Kazanski	2015	Library Trends	10.1353/lib.2015.0026	library science;engineering;sociology;management;law;economic growth	PL	-68.69123408458302	-19.778735162947974	138541
aafead0656248367e76c5f74708c05bf78c7a4a5	it's a man's job: income and the gender gap in industrial research	research and development;innovation;econometrics;economics	This study examines differences in income and job performance between women and men in creative, highly skilled jobs, tasked with achieving technological inventions. By building on data pertaining to 9,692 inventors from 23 countries, this study shows that female inventors represent only 4.2% of total inventors, and they earn about 14% less than their male peers. The gap persists even when controlling for sources of heterogeneity, the selection of inventors into types of jobs and tasks, and potential parenthood, instrumented by exploiting a source of variation related to religious practices. The income gap is not associated with differences in the quality of the inventions that female and male inventors produce. Thus, even in this human capital–intensive profession, where capabilities and education are important assets, and productivity differentials can be observed, women earn less than men, though they contribute to the development of high quality inventions as much as men do. Acknowledgements We thank the European Commission, Contract N. FP7-SSH-2007-1, for supporting the creation of the data set. Myriam Mariani acknowledges support from the Italian Ministry of University and Research (project CUP B41J12000160008). We appreciate feedback on prior drafts from Ashish Arora, Francesco Billari, Annamaria Conti, Alfonso Gambardella, Bronwyn Hall, and Dietmar Harhoff, as well as seminar participants at the Workshop “Bocconi on Women 2011” (Milan, IT), the KITES Conference 2012 (Milan, IT), the EPIP Conference 2013 (Paris, FR), colleagues at the Max Planck Institute for Innovation and Competition, and participants of the Seminar Series of the Institute of Employment Research (Nuremberg, DE). The comments of the Editors and two anonymous reviewers are gratefully acknowledged. The authors contributed equally, and their names are listed alphabetically.		Karin Hoisl;Myriam Mariani	2017	Management Science	10.1287/mnsc.2015.2357	innovation;economics;management;economic growth;labour economics	HCI	-67.74054824631544	-17.9279707604692	138543
2cf8a517bf23e0aac49ff037e635e0f1bc558e70	guest editors' introduction	guest editors	Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: http://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.	privacy	Philip K. Chan;Salvatore J. Stolfo;David H. Wolpert	1999	Machine Learning	10.1023/A:1007551004514		Web+IR	-66.43377217803182	-18.612621265300845	138584
f45d61b9dacb9fa8ea265cb2247d7810d0407132	the scientometric weight of 50 nations in 27 science areas, 1989–1993. part i. all fields combined, mathematics, engineering, chemistry and physics	analyse bibliometrique;engineering;scientometrics;macro level;productivite;indicator;indicateur;estudio comparativo;etude etat a etat;citation impact;methode;productividad;ingenierie;etude comparative;relative indicators;scientometria;niveau macro;state to state study;exact sciences;indicador;comparative study;ciencias exactas;publication output;scientometrie;ingenieria;evaluation;datafiles;bibliometric analysis;estudio estado a estado;evaluacion;productivity;recherche scientifique;metodo;scientific research;method;sciences exactes;investigacion cientifica;analisis bibliometrico	The present paper at tempts some new approaches to the presentation of bibliometric macro-level indicators. Whilst in former studies national indicators on the 5 major science fields, life sciences, physis, chemistry, engineering and mathematics (e.g., 1-4) a n d / o r 128 subfields 5 have been presented, this s tudy aims at a compromise between the two extremes. In that order the subfields have been grouped into 27 broader science areas. The assignment followed a suggestion by Grupp and Hinze 6. Data sources: All results are based on rough bibliographic data extracted from the 1989-1993 annual cumulat ions of the Science Citation Index (SCI) of the Institute for Scientific Information (ISI) which have been cleaned up and processed to indicators according to the rules of ISSRU's Scientometric Indicators Datafiles 7. Methodological remarks: The criterion for the country assignment was the first address, that is, each paper has been assigned to the country indicated in the corporate address of its first author. All papers of the article, letter, note and review type recorded in the 1989-1993 volumes of the SCI have been taken into consideration. Since the GDR ceased to exist in 1990 due to the German reunification, East German publications occurred only in the first half of the period. Therefore the country name 'Germany' covers the two German states in 1989 and 1990, then, from 1991 on, the Federal Republic of Gelmany. Only countries that have produced at least 1000 papers in all science fields in the given five-year per iod have been taken into consideration. This criterion was satisfied by 50 countries. Citation counts have been cumulated from the publication year till 1993. The following publicat ion and citation based indicators have been built.	bibliometrics;citation index;scientometrics;while	Tibor Braun;Wolfgang Glänzel;Hariolf Grupp	1995	Scientometrics	10.1007/BF02017332	productivity;method;social science;scientific method;scientometrics;computer science;evaluation;comparative research;exact science	ML	-75.44755772768288	-22.47714370079405	138714
2309e5bb22e1f069f5079e1e3d243b753d6d6248	doc and the power of things and representatives	outside in development;software documentation;user assistance;customer feedback;article peer reviewed scientific;design;communication;computer documentation;information	Social life is communication. To live in a society means sharing things. And this we do not through, but in, communication. That is how things become common, and hence how communities are formed.	microsoft word for mac	Pelle Ehn	2008		10.1145/1456536.1456543	design;information;human–computer interaction;computer science;knowledge management;multimedia;software documentation;management;world wide web	HCI	-64.63960791285432	-11.653010131372003	138870
d6c551766043b6d53fcb389679bb23ed0953f731	cultural pluralism in the context of the knowledge society ecosystem: reviews and views	knowledge society	With Huntington’s warning of a “clash of civilizations” following the end of the cold war, “cultural pluralism” has become important for enhancing world peace and supporting development. In this paper, cultural pluralism is viewed as a “knowledge society” problem, where intercultural knowledge is produced, disseminated and used within an ecosystem of mutual understanding and respect. The authors present key cultural pluralisms efforts, providing an overall picture of the issues involved. These efforts include: the 2001 United Nations (UN) resolution on dialogue among civilizations; the 2001 UN Educational, Scientific and Cultural Organization (UNESCO) declaration on cultural diversity; the 2005 Rabat conference on dialogue among cultures and civilizations; and the 2008 Madrid world conference on dialogue. In the second part of this paper, cultural pluralism issues are restructured according to the knowledge society ecosystem framework, where they are organized according to the five STOPE domains: strategy, technology, organization, people and the environment, and where they interact with the intercultural knowledge activities. The resulting cultural pluralism ecosystem framework is useful as a tool for organizing and interrelating future studies on the subject and promoting peace and development.	declaration (computer programming);ecosystem;futures studies;knowledge society;organizing (structure);pluralism (philosophy)	Saad Haj Bakry;Ali Al-Ghamdi	2011	IJKSR	10.4018/jksr.2011010106	social science;cultural analysis;computer science;knowledge management;artificial intelligence;sociology;management;law;economic growth;anthropology	HCI	-65.64076774676757	-12.036223944276141	138945
d0ed9b09bd99fd3877eee5153ae37f5a76982467	selling on, not out, the internet	selected works;bepress	The way a new communication medium develops and evolves is a complex process that includes technological, social, economic, and regulatory forces. These forces interact, pushing and pulling an innovation into obsolescence or maturity. In the United States, this interaction is strongly influenced by a media philosophy which favors private ownership and commercial exploitation. The development of U.S. media, therefore, is not completely unpredictable, as the process is controlled by profit-driven entities with predictable objectives and desires. Although individual media are unique and their fate not ultimately predetermined, this reliance upon commercialization and privatization helps direct U.S. media down a very specific path. Computer-mediated communication is the latest communication medium to enter this process of development.		David F. Donnelly	1996	J. Computer-Mediated Communication	10.1111/j.1083-6101.1996.tb00180.x	sociology	HCI	-75.17349222955055	-11.111704036224376	139082
01b9b9f85efd554e8ca9004c13a888cf12d5de64	autour du pair-à-pair : distribution de contenus, réseaux à préférences acycliques	theorie des mariages stables;p2p;stable marriages;content distribution;distribution de contenu;peer to peer	Peer-to-peer (P2P) recently emerged as a new paradigm in computer science. Due to major economic and social stakes, mostly related to content distribution, P2P has brought back to the forefront many existing research elds related to distributed systems, providing new incentives and goals. In this work, we give some keys to the understanding of the research elds related to P2P systems. After a brief survey of our work on content distribution, we consider a more theoretical subject : acyclic preference-based systems, which recently appeared as an elegant way to model many P2P unstructured or hybrid systems. The strength of these models is a self-stabilizing property that allows us to provide analytical results in addition to empirical validation.		Fabien Mathieu	2009			history;peer-to-peer;performance art	ECom	-74.15822146679454	-19.147619085082482	139094
75f368c565bcd4ba0bee570573b798f8a4cf0dbd	challenges in enabling mixed media scholarly research with multi-media data in a sustainable infrastructure		Big-scale infrastructure projects in the humanities and social sciences such as the Digital Research Infrastructure for the Arts and Humanities (DARIAH) (Edmond et al., 2017), or the Common Language Resources and Technology Infrastructure (CLARIN) (Hinrichs and Krauwer, 2014) aim to provide solutions for both preservation and access to collections and data necessary for scholarly research (Zundert, 2012). Some infrastructure projects build decentralized “atomic” software services, e.g., as in the LLS infrastructure project (Buchler et al., 2016), while others prefer to build more centralized virtual research environments, as in the European Holocaust Research Infrastructure (EHRI) (Lauer, 2014). Also, even within a single infrastructure project, these two models can coexist. This is the case of the CLARIAH infrastructure, where different approaches have been taken to date for serving different user groups, i.e., several specialized tools for linguists (Odijk, Broeder u0026 Barbiers, 2015), or a research environment (the Media Suite) that serves the scholarly needs for working with audiovisual data collections and related mixed-media contextual sources that are maintained at cultural heritage and knowledge institutions. This paper discusses the rationale and challenges behind the development of the Media Suite.		Roeland Ordelman;Carlos Martinez-Ortiz;Liliana M. Melgar Estrada;Marijn Koolen;Jaap Blom;Willem Melder;Jasmijn van Gorp;Viktor de Boer;Themistoklis Karavellas;Lora Aroyo;Thomas Poell;Norah Karrouche;Eva Baaren;Johannes Wassenaar;Julia Noordegraaf;Oana Inel	2018			software;the arts;multimedia;digital humanities;mixed media;cultural heritage;suite;engineering	HCI	-69.14576666137002	-16.389844401137477	139232
76045ed27462bdf353d78c6ef8416ca627d3119a	big data in libraries: content and policies for librarians. sponsored by the government documents special interest group at the metropolitan new york library council, october 24th, 2013. fall 2013 program, http: //libguides.metro.org/content.php?pid=126208&sid=1083556	bepress selected works;event summary big data	On October 24th, 2013 in the big conference room of the Metropolitan New York Library Council located at 57 E 11th Street in Manhattan, New York, the Government Documents Special Interest Group (GoDIG) held their Fall 2013 program, an annual event. The topic of the program was Big Data in libraries and focused on content and policies for information professional. Big Data is an all-encompassing term for datasets that are too large and complex to manipulate with standard methods or tools. There are many datasets available for purchase, but this GoDIG session focused primarily on resources freely available from governments. The program began with an introduction to GoDIG from the co-chairs Jane Cramer and Debbie Rabina. GoDIG is the oldest special interest group in the Metropolitan New York Library Council. The three core goals of the group is to “provide a forum of professional exchange and support for Depository libraries in the area” to “promote the use of government sources” and to “provide support and mentoring to early career professional and library students.” The Fall 2013 Big Data Program met all of these goals. Though this presentation was for information specialists, Big Data and freely available governmental data is for everyone. Columbia's GIS librarian, Jeremiah Trinidad-Christensen's presentation was unsurprisingly very technical, but luckily it was equally engaging. Entitled “Expanding the GIS workflow,” he explained how he helps students creating interactivemaps from spatially referenced data. To build interactive maps Trinidad-Christensen does not recommend using proprietary tools such as OpenLayers, Google Maps API, and ArcGIS Online because they offer less control and usually cost more than open source JavaScript libraries. The two open source JavaScript libraries introduced were leaflet and D3. Javascript code, Trinidad-Christensen assured us, is very straightforward and within 30 minutes a student could have their own interactive data-rich map. He views it as his role to give students the tools and to help them when they have trouble, not to create maps for them. When asked which governmental datasets were most in demand he stated, the Census, USGS National Maps, and NYC Open Data. When asked how he stays up to speed with the technology he answered that this past summer he began learning JavaScript with the goal of learning leaflet and D3. The next presenter was Margaret Smith, a Science Librarian at New York University. Her talk “15 (or so) Data Tools in 15 (or so) Minutes” was a perfect chaser to Trinidad-Christensen's highly technical talk. Where he had introduced what to do with spatially referenced data, Margaret Smith gave a quick introduction to a wide-variety of resources, many of which are free and available as web-based applications.	application programming interface;arcgis;big data;data-driven documents (d3.js);geographic information system;hypertext transfer protocol;information professional;jane (software);javascript library;leaflet;librarian;library (computing);map projection;open-source software;openlayers;web application	Helena Marvin	2014	Government Information Quarterly	10.1016/j.giq.2014.09.003	computer science;data science;public administration;world wide web	Web+IR	-64.67326608818074	-15.958258838730103	139425
bc4e0f8ab3d8af76ccfde664f7a0b90fb7ab9b4b	the fair accessor as a tool to reinforce the authenticity of digital archival information		The constant changeability of the digital environment raises a complex series of issues regarding the preservation of authentic, accessible, intelligible and reusable digital information. An implementation of the FAIR Accessor, a technology developed with the goal of delivering findable, accessible, interoperable and reusable research data, is discussed as a means of supporting archival description with the goal of ensuring its authenticity. A qualitative literature review focused on some of the main tenets of digital preservation in the fields of Information Science, Diplomatics and research data is followed by a discussion on how the core criteria of each area overlap and complement each other. It is concluded that the FAIR Accessor can assist in providing a rich archival description, ultimately helping to determine the authenticity of records.		André Pacheco	2018		10.1007/978-3-030-00066-0_31	knowledge management;interoperability;digital preservation;diplomatics;information science;computer science	HCI	-72.66596288377313	-14.690345472972366	139614
0e941e2e2c6cfcbc34f27cd2ad492db6a6de4023	foresight with delphi surveys in japan		Foresight activities are conducted in many countries, but the Japanese were the most active in this field for many years. Most of their activities are based on the Delphi methodology. They published their first Delphi study in 1971 and repeated studies every five years. There is more knowledge available on more than 30 years of foresight with the Delphi approach in Japan. This provides an excellent opportunity to examine the established foresight system with the use of some examples. The forecast of the fax machine as an example of success, and the earthquake warning as a failure are illustrated in more detail, and the question is raised why—in spite of this mixed picture—foresight with the Delphi method is regarded as useful in Japan.	embarcadero delphi	Kerstin Cuhls	2001	Techn. Analysis & Strat. Manag.	10.1080/09537320127287	simulation;economic growth	NLP	-75.39037234056896	-16.33862595568561	139664
2d3e820adbb287ed434a8b23efb4db135ff296cb	incoded counter-conduct: what the incarcerated can teach us about resisting mass surveillance	resistance;digital communications;privacy	This paper reviews penal history in order to consider forms of resistance to mass surveillance. Because experiences of surveillance are endemic to incarcerated life, identifying tactics of protest among these populations provides valuable insights for potential forms of counter-conduct in other circumstances of ubiquitous monitoring. We introduce the term incodification as a means of describing conditions of continuous surveillance ingrained into infrastructures of everyday life, even as these conditions give rise to tactics of resistance. We focus on three forms of protest: hunger strikes, alternate communication networks and viral dance videos, drawing on Foucault’s theory of askesis in order to develop our understanding of incodification. Our objective in introducing this term, and with our analysis as a whole, is to provoke and promote theoretical and activist projects that both address and subvert infrastructures of incodification.	population;telecommunications network	Jessica Lingel;Aram Sinnreich	2016	First Monday		public relations;computer science;sociology;resistance;privacy;social psychology;law;computer security	Web+IR	-72.47252401457939	-10.693198542364852	140264
3bd1d41a656c8159305ba2aa395f68f41ab84f31	entity-based opinion mining from text and multimedia		Social web analysis is all about the users who are actively engaged and generate content. This content is dynamic, reflecting the societal and sentimental fluctuations of the authors as well as the ever-changing use of language. Social networks are pools of a wide range of articulation methods, from simple ”Like” buttons to complete articles, their content representing the diversity of opinions of the public. User activities on social networking sites are often triggered by specific events and related entities (e.g. sports events, celebrations, crises, news articles) and topics (e.g. global warming, financial crisis, swine flu). With the rapidly growing volume of resources on the Web, archiving this material becomes an important challenge. The notion of community memories extends traditional Web archives with related data from a variety of sources. In order to include this information, a semantically-aware and socially-driven preservation model is a natural way to go: the exploitation of Web 2.0 and the wisdom of crowds can make web archiving a more selective and meaning-based process. The analysis of social media can help archivists select material for inclusion, while social media mining can enrich archives, moving towards structured preservation around semantic categories. In this paper, we focus on the challenges in the development of opinion mining tools from both textual and multimedia content. We focus on two very different domains: socially aware federated political archiving (realised by the national parliaments of Greece and Austria), and socially contextualized broadcaster web archiving (realised by two large multimedia broad-	archive;biconnected component;case preservation;entity;quantum fluctuation;sentiment analysis;social media mining;the wisdom of crowds;way to go;web 2.0;web archiving;web content;world wide web	Diana Maynard;Jonathon S. Hare	2015		10.1007/978-3-319-18458-6_4	web mining;text mining;data science;data mining;information retrieval	Web+IR	-70.33178659075224	-19.4778531673906	140724
c5594b06702f9fa3e5ad27629c1185d28b24735f	editor's introduction		Technical journals are usually dedicated to documenting advances in either a broad area (e.g., computer science or electrical engineering) or a specific discipline (e.g., programming languages or information theory). Office information and communication systems, however, may not be regarded as either. Instead they borrow from many other fields: database theory, artificial intelligence, behavioral psychology, organizational theory, and communications, to name a few. The very essence of this area is its interdisciplinary nature. Many significant advances are made through the novel and innovative application of knowledge from various specialties. The area may be divided into (at least) two fuzzy, overlapping sections: work in which the office itself is the object of the study, and work in which basic findings from other disciplines are applied to the office. In the former case, some facet of the office itself is being explored or emulated: behavioral, structural, information flow, and so forth. In the latter case, one can think of numerous examples of the application of knowledge from other fields: microprocessor architecture applied to work station design; naming and addressing techniques applied to the design of electronic mail systems; and database theory applied to the design of filing systems. In view of this interdisciplinary nature of work in the office systems area, it is important to have some guidelines as to when a manuscript is appropriate for the new A CM Transactions on Office Information Systems. Obviously there can be no simple rule. An excellent paper on database theory, for example, that did not advance our knowledge of office information systems would be better published elsewhere. A paper that integrated knowledge from a number of disciplines to improve our insight into office systems design would be very appropriate. Usually, defining the scope of a new journal is straightforward or even obvious; not so for TOOIS. What is missing is a useful taxonomy of the area, and I would be interested in suggestions. While it may be difficult to describe the area succinctly, there would be a large degree of consensus among workers in the area as to valid and appropriate topics: models of office information and communication flow, integrated communication systems, acceptance of technology within the workplace, workstation design, innovation in human interfaces, integration of distributed information sources, expert office systems, improved measures of productivity. Indeed, the broad range of topics included in the scope is typified by the papers in this issue; each …	artificial intelligence;computer science;database theory;electrical engineering;email;emulator;information flow (information theory);information system;information theory;microprocessor;programming language;software documentation;systems design;taxonomy (general);traffic flow (computer networking);workstation	John O. Limb	1983	ACM Trans. Inf. Syst.	10.1145/357423.357424		DB	-72.07675916289675	-18.70126046843313	140796
70d90e56cc3123c33a2f5123a4b8a1ab6d798088	immaterial transfers with material consequences	foreign exports;itar;united states international traffic in arms regulations;defence industry;foreign exports itar defense trade controls;sensitive data unlicensed communications defense trade controls united states international traffic in arms regulations defense contracts;defense contracts;sensitive data unlicensed communications;portable computers cryptography costs personnel information security data engineering communication system control maintenance engineering computer security privacy;defense trade controls;government data processing;security of data;security of data defence industry government data processing	The need for such regulations is clear, but many firms underestimate the challenges of complying with the defense trade controls embodied in the US International Traffic in Arms Regulations (ITAR). Companies hoping to enter into defense contracts must therefore redefine their basic approach to technical data because the ITARs require that they control the destinations of their communications. For example, the ITARs prohibit unlicensed communications of sensitive data to foreign destinations (another country or a foreign national)		Roland L. Trope	2006	IEEE Security & Privacy	10.1109/MSP.2006.122	computer security	Security	-70.2629063419641	-11.467695087890053	140821
5872501b392980c5a9d712a1deb33268bfa0fbaf	is internet access a human right?	internet access	In June 2009, the highest court of France, The Constitutional Council, declared internet access to be a basic human right. Many people are now campaigning to have it recognized as a human right by the United Nations, along with those human rights already recognized by the world body. The main motivation behind the campaign is the desire to close the digital divide, particularly that between rich and poor nations. However, while having internet access recognized as a human right might go some way towards addressing the digital divide issue, the theoretical case for recognition has not been clearly established. Without a solid theoretical case, recognizing something to be a human right is a misunderstanding of the nature of that something as well as of human rights. The former kind of misunderstanding may result in misdirected efforts at promoting the activity in question and the latter in a debasement of human rights. This paper will provide an account of human rights and will argue that on the basis of such account, internet access is not a human right, even though it is an important right in itself and one that enables the promotion of other human	internet access	A. T. Nuyen	2010				Security	-74.11166482606497	-14.889657587755002	141058
6a1e0e7c7b23cb59897001a9985a7e78ee5c373b	the determinants of academic career advancement: evidence from italy	universities;research evaluation;bibliometrics;favoritism;settore ing ind 35 ingegneria economico gestionale;nepotism	In this work we investigate the determinants of professors’ career advancement in Italian universities. From the analyses, it emerges that the fundamental determinant of an academic candidate’s success is not scientific merit, but rather the number of years that the candidate has belonged to the same university as the selection committee president. Where applicants have participated in research work with the president, their probability of success also increases significantly. The factors of the years of service and occurrence of joint research for the other commission members also have an effect, however of lesser weight. The specific phenomenon of nepotism, although it exists, seems less important. The scientific quality of the commission members has negligible effect on the expected outcome of the competition, and even more so the geographic location of the university calling for the competition.	geographic coordinate system;mike lesser	Giovanni Abramo;Ciriaco Andrea D'Angelo;Francesco Rosati	2018	CoRR	10.1093/scipol/scu086	public relations;social science;economics;bibliometrics;sociology;public administration;management;law;economic growth	Web+IR	-77.14813857227783	-20.427783316287695	141089
c254893e54cc41f52607944887661fc5b8c70adb	collaborative networks for a sustainable world - 11th ifip wg 5.5 working conference on virtual enterprises, pro-ve 2010, st. etienne, france, october 11-13, 2010. proceedings	universiteitsbibliotheek;collaborative networks;virtual enterprise	Collaborative Networks for a Sustainable World Aiming to reach a sustainable world calls for a wider collaboration among multiple stakeholders from different origins, as the changes needed for sustainability exceed the capacity and capability of any individual actor. In recent years there has been a growing awareness both in the political sphere and in civil society including the bu- ness sectors, on the importance of sustainability. Therefore, this is an important and timely research issue, not only in terms of systems design but also as an effort to b- row and integrate contributions from different disciplines when designing and/or g- erning those systems. The discipline of collaborative networks especially, which has already emerged in many application sectors, shall play a key role in the implemen- tion of effective sustainability strategies. PRO-VE 2010 focused on sharing knowledge and experiences as well as identi- ing directions for further research and development in this area. The conference - dressed models, infrastructures, support tools, and governance principles developed for collaborative networks, as important resources to support multi-stakeholder s- tainable developments. Furthermore, the challenges of this theme open new research directions for CNs. PRO-VE 2010 held in St.	collaborative network;international federation for information processing		2010		10.1007/978-3-642-15961-9	engineering;management science;management;operations research	HPC	-71.4582218969458	-15.601835811170401	141211
b25d212373eed6f368b8904eea45bb26d169cd4a	what motivates contributors vs. lurkers? an investigation of online feedback forums	contributors;online policy deliberation forums;it enabled public goods theory;public participation theories;construal level theory;online feedback forums;lurkers	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2015, INFORMS	download;institute for operations research and the management sciences;lurker;robot	Chee Wei Phang;Atreyi Kankanhalli;Bernard C. Y. Tan	2015	Information Systems Research	10.1287/isre.2015.0599	public relations;knowledge management;marketing;construal level theory;social psychology	ECom	-68.1948022718349	-15.022942021448433	141474
3a653033f304b6386c91545ca505b2a4eb3aea71	academic streaming in europe: report on tf-netcast.	streaming media;content delivery network;open source	TheTF-NETCAST task force was active from March 2003 to March 2004, and during this time the members worked on various aspects of streaming media related to the ultimate goal of setting up common services and infrastructures to enable netcasting of high quality content to the academic community in Europe. We report on a survey of the use of streaming media in the academic community in Europe, an open source content delivery network, and a portal for announcing live streaming events to the global academic community.	content delivery network;digital distribution;display resolution;open-source software;podcast;streaming media	Alessandro Falaschi;Dan Monster;Ivan Dolezal;Michal Krsek	2004			computer science;multimedia;streaming current;world wide web;computer network	Web+IR	-64.79339817737974	-15.479255233845262	141523
2b80354b3f767a357a0b8001e53738d764d31d1c	end to end security is not enough (transcript of discussion)		The idea behind this presentation originated when I was looking at e-voting. I was looking specifically at end-to-end systems, implementing them and considering what can go wrong. Now, there’s a bit of factionalization within e-voting research. A lot of people believe end-to-end verifiability is all you need for integrity. Then there’s a smaller faction who believe, “No, it’s more about reliability. It’s audit logs. It’s things like that.” I was giving some talks on this and one thing that came up a lot was the Estonian e-voting system. The Estonian system tends to get a lot of criticism in the literature because initially it wasn’t end-to-end verifiable, and there’s still debate about whether it is now, but on the other hand the Estonian system has some very nice things to do with logs and auditability in it, which I think maybe some other systems could learn from.		Dylan Clarke	2017		10.1007/978-3-319-71075-4_30	computer science;internet privacy;verifiable secret sharing;nice;criticism;audit;end-to-end principle;estonian	Crypto	-63.577125577616826	-21.081284667797544	141653
ba14ec468ac663922a4f212823eea01727d115ff	samuel o. idowu, walter leal filho: global practices of corporate social responsibility	corporate social responsibility	Springer have made a public commitment by publishing this substantial book, comprising chapters addressing Corporate Social Responsibility in 19 countries around the world. This is the first volume in an ongoing international publishing project, and deserves consideration for university and corporate libraries. We must expect the project to progress, as it addresses professional perspectives and innovative practices. There is much to debate. In this first volume, the contributors had not met, and this is reflected in the diversity of perspectives which are used in the country chapters. They were invited by the editors, and their chapters were subjected to international peer review among the contributors, without an attempt to impose a common language or conceptual framework. The country coverage is, perhaps inevitably, incomplete. The shared definition of Corporate Social Responsibility was minimalist, covering activities by companies beyond what is legally required. Often this is little more than corporate philanthropy. The manuscripts were submitted during 2007, and publication was at the start of 2009. During that period, the Credit Crunch and Global Economic Crisis have hit national economies and individual companies. Under pressure, companies are changing their behaviour, revealing where their priorities lie. Arguably those companies who have established separate departments to deal with Corporate Social Responsibility, typically closely linked to marketing, may find it easy to cut back on such activities. In the world of Business Schools, it has become apparent that there is now wider public concern regarding Corporate Social Responsibility. Typically there have been elective courses for undergraduates and postgraduates, while the fundamental principles of business have been relatively unchallenged. There have been suggestions that an uncritical approach to Business, for example in the numerous MBA programmes, has contributed to the economic crisis, as MBA graduates have focussed their attention on finance, at the expense, for example, of social and environmental reporting. The journal AI & Society has always operated on the principle that ‘‘Society’’ is not an afterthought, but integral to our development and application of new technologies, addressing issues of knowledge, culture and communication. The first article, in the first issue in 1987, addressed ‘‘Socially Useful Artificial Intelligence’’. We could argue that ‘‘Business’’ is no more than a metaphor which is applied to organisations, which are culturally situated in ‘‘Society’’. Such a position conflicts with the position taken by Margaret Thatcher, influenced by Milton Friedman, who are cited in the book chapter on the UK, contributed by Samuel Idowu. Thatcher argued that there is no such thing as society, only individuals and their families. Friedman stressed that the prime duty of company directors is to maximise shareholder value. On that basis, anything additional constitutes the exercise of corporate social responsibility, but might be regarded as financially and legally irresponsible. Adam Smith saw matters differently (see AI & Society 11.3–4 1997). His ‘‘The Theory of Moral Sentiments’’ in 1759 set out the context of social responsibility and mutual obligations which, in his view, underpinned the world of business which was launched in ‘‘The Wealth of Nations’’ in 1776. While stating that ‘‘prudence’’ was ‘‘of all virtues that which is most helpful to the individual, he argued that ‘‘humanity, justice, generosity, and public spirit, are the R. Ennals (&) Kingston University, Kingston, UK e-mail: richard.ennals@blueyonder.co.uk	ai & society;artificial intelligence;email;library (computing);milton abramowitz;nat friedman;situated;springer (tank);thatcher effect	Richard Ennals	2009	AI & SOCIETY	10.1007/s00146-009-0206-5	computer science;sociology;corporate social responsibility	HCI	-67.6405420777914	-18.93811503147118	141704
f3eddd150a1b96aef455e2ff44ab7b2824e65f39	finding a job	communication skills;organizations;mechanics;job	You have been offered a job as a sales representative in a Company ‘’A’’ where the base salary is $7,800 per year and the commission rate is 11.8%. There is a second Company ‘’B’’ you are considering working for. This company sells encyclopedias. You want to compare both companies in terms of your expected income. The information you got from this Company ‘’B’’ is not immediately comparable with that one from Company ‘’A’’. You need to process it to make them comparable.		Seth L Haber	2003	CAP today	10.1109/MS.2003.10023	job attitude;job rotation	Web+IR	-66.61929756131964	-21.699251964473994	141727
5a40ef82306d1c28d5e1becbb45fde11117b5ef7	nurturing young composers: morton subotnick's late-1960s studio in new york city	new york city	During the 1960s and 1970s, the best-known site in New York City for the development of new work by electronic composers was the Columbia-Princeton Electronic Music Center, founded in 1959 (Chadabe 1997; Gluck 2007a, 2007b; Holmes 2008). The well-deserved prominence of this center, however, obscures a second, highly non-institutional studio loosely affiliated with New York University’s (NYU’s) School of the Arts (later named the Tisch School of the Arts). The studio was established as composer Morton Subotnick’s (b. 1933) personal workspace, but, through his generosity and his practice of utilizing studio assistants, it provided a nurturing environment for a cadre of important young composers. Their work continued in a successor studio at NYU, following Subotnick’s departure to the newly founded California School of the Arts (CalArts). Little documentation about this studio exists, and few recordings have survived. Thus, I have conducted interviews, collecting firsthand accounts, reminiscences, and photographs, with the intention of beginning to craft a missing part of the history of electronic music in New York City. Morton Subotnick’s New York City studio was established during a transitional period in the history of electronic music (Chadabe 1997; Holmes 2008). To offer the broadest overview, the composition of tape music, originating in the late 1940s and early 1950s, continued in studios throughout the world. Computer music, initiated in the mid 1950s, was a growing field. One of the new horizons in the early and mid 1960s was live electronic music, as John Cage, Karlheinz Stockhausen, and others began to explore what had been largely a discipline rooted in studio composition. Tape music and live multimedia	columbia (supercomputer);composer;documentation;the new york times;whole earth 'lectronic link;workspace	Bob Gluck	2012	Computer Music Journal	10.1162/COMJ_a_00106	computer science	Web+IR	-63.405953673344435	-18.797061605637058	141750
a6c7e02569cd6a582c640985b82ccc1459fa7a2c	citation bias in medical journals	europa;scientometrics;north america;america del norte;amerique du nord;amerique;medicina;urology;citation;etats unis;estados unidos;medecine;scientometria;culture;scientometrie;present day;developing nations;individuality;medicine;urologia;citacion;clinical research;urologie;europe;america;recherche scientifique;scientific research;investigacion cientifica;individualite;multivariate statistical analysis	Multivariate statistical analysis of the citation profiles of urology and related journals (i.e. the relative extent to which each journal cites itself and other journals within a set) has highlighted hidden correlations. We reveal the existence of a ‘transatlantic’ rift in citation practice and of a confined discipline-oriented world which interfaces weakly with many other disciplines. We also interpret the results of our analyses in terms of basic and clinical research and examine whether there is a time-related selectivity in citation. Taken together, our results call for a serious appraisal of present-day research trends and of their evaluation. The open question is how to create a terrain that will foster original, possibly interdisciplinary, research in developed nations whilst maintaining cultural individuality.	oculus rift;selection bias;selectivity (electronic);while	Tiiu Ojasoo;Jean-Christophe Doré	1999	Scientometrics	10.1007/BF02458469	clinical research;scientometrics;law;culture	HCI	-75.25241017573184	-21.34757298878449	141791
27366bbbaf2e423447933304a15675ea8406715d	the optimization of online searches through the labelling of a dynamic, situation-dependent information need: the reference interview and online searching for undergraduates doing a social-science assignment	entrevista;modelizacion;bibliotecario;metodologia;interview;estudiante;bibliotheque universitaire;role professionnel;information retrieval;occupational role;search strategy;besoin utilisateur;necesidad usuario;satisfiability;analyse besoin;methodologie;service utilisateur;modelisation;social science;student;entretien;undergraduate student;user need;recherche information;need analysis;besoin information;biblioteca universitaria;librarian;recuperacion informacion;servicio usuario;information system;information need;methodology;user service;bibliothecaire;etudiant;modeling;academic libraries;university library;rol profesional	An important user group in academic libraries is the undergraduate student seeking information for coursework in the social sciences. With the proliferation of electronic databases, a major challenge for reference librarians is to conduct a quick and effective reference interview to determine the undergraduate's information need while also providing instruction on using the information system. The present article proposes a reference-interview strategy that will allow the reference librarian to (1) efficiently assess the information need of the undergraduate, (2) label the information need, and (3) assign the most appropriate search strategy to satisfy this need.	information needs	C. Cole;L. Kennedy;S. Carter	1996	Inf. Process. Manage.	10.1016/S0306-4573(96)00024-6	information needs;systems modeling;interview;computer science;needs analysis;methodology;multimedia;world wide web;information retrieval;information system;satisfiability	DB	-73.52226813002984	-23.892098781372678	141814
0e261657a6a7e2287c51bf5968a37949f6b97d49	zero-moment point - thirty five years of its life	humanoid robot;dynamically balanced gait;biped locomotion;zero moment point;support polygon;scientific communication;center of pressure	This paper is devoted to the permanence of the concept of Zero-Moment Point, widelyknown by the acronym ZMP. Thirty-five years have elapsed since its implicit presentation (actually before being named ZMP) to the scientific community and thirty-three years since it was explicitly introduced and clearly elaborated, initially in the leading journals published in English. Its first practical demonstration took place in Japan in 1984, at Waseda University, Laboratory of Ichiro Kato, in the first dynamically balanced robot WL-10RD of the robotic family WABOT. The paper gives an in-depth discussion of source results concerning ZMP, paying particular attention to some delicate issues that may lead to confusion if this method is applied in a mechanistic manner onto irregular cases of artificial gait, i.e. in the case of loss of dynamic balance of a humanoid robot. After a short survey of the history of the origin of ZMP a very detailed elaboration of ZMP notion is given, with a special review concerning “boundary cases” when the ZMP is close to the edge of the support polygon and “fictious cases” when the ZMP should be outside the support polygon. In addition, the difference between ZMP and the center of pressure is pointed out. Finally, some unresolved or insufficiently treated phenomena that may yield a significant improvement in robot performance are considered.	zero moment point	Miomir Vukobratovic;Branislav Borovac	2004	I. J. Humanoid Robotics	10.1142/S0219843604000083	simulation;computer science;humanoid robot;artificial intelligence;center of pressure;zero moment point	Robotics	-72.42187803955144	-17.41249290253447	141857
5ecfcc51b92c41b7c080f74b74fa73f9bb4022e8	"""personal digital archiving for journalists: a """"private"""" solution to a public problem"""		PurposernrnrnrnrnThe purpose of this paper is to encourage librarians to teach digital archiving practices to journalists as a way of giving journalists the skills they need to save their work for future use and to facilitate the preservation of journalism for posterity.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnThe author has reviewed the personal digital archiving literature and analyzed how it might be specifically tailored to the unique needs of journalists.rnrnrnrnrnFindingsrnrnrnrnrnDaily journalism has traditionally been preserved by libraries in the form of newspapers and magazines housed in library periodicals departments. Now that nearly all journalism is published online and libraries generally only have access via temporary subscriptions, libraries are prevented from doing any kind of traditional preservation work (e.g. storing copies locally). In the future, this lack of local preservation may lead to a shortage of early twenty-first century primary source material for historians.rnrnrnrnrnResearch limitations/implicationsrnrnrnrnrnThe needs of journalists do vary greatly based on the nature and format of their work and its publication venue, making it difficult to offer a single set of standards or recommendations.rnrnrnrnrnOriginality/valuernrnrnrnrnWhile personal digital archiving advocates have generally interpreted the word “personal” to be synonymous with “private,” this paper points to the need to expand the concept to include professional activities, particularly in light of the prevalence of telecommuting and freelance work arrangements, and the lack of support and training received by remote workers and independent contractors.	archive	Rachel King	2018	Library Hi Tech	10.1108/LHT-09-2017-0184	multimedia;telecommuting;economic shortage;digital preservation;computer science;newspaper;originality;journalism;digital library	Crypto	-69.20817809527883	-20.126471507215673	141925
44cfe66ad546bd689e7fddc3e4017b10f6b94f2e	message from the chair	design;human factors;general;management;theory;organizations	As some of you may know, I took over from Michael Luke as Chair of Physics, in July of last year. Mike’s will be a tough act to follow. In 2004, and at a rather young age for an academic administrator, Michael agreed to be acting chair for six months while the Department searched for a new Chair. When that search failed, Mike continued as acting chair for a further year, while the Department searched again. This time, the search committee was successful, having the wisdom to choose Mike himself. In the end, Mike served as Chair for a total of eight years, and oversaw a period of major renewal of our faculty, teaching methods, and infrastructure, while shepherding the Department through the trauma of the double-cohort, and the financial crisis of 2008, which continues to have challenging repercussions for the University.	teaching method	Stephen M. Watt	1996	ACM SIGSAM Bulletin	10.1145/231191.570103		ML	-65.15255746428602	-20.479595102990707	142031
303b250304b60f1e5a86c7c8ae075228bb325727	the role of arxiv, repec, ssrn and pmc in formal scholarly communication	arxiv;citations;repec;scholarly communication;pmc;subject repositories;scopus;open access;ssrn	Purpose – The four major Subject Repositories (SRs), arXiv, Research Papers in Economics (RePEc), Social Science Research Network (SSRN) and PubMed Central (PMC), are all important within their disciplines but no previous study has systematically compared how often they are cited in academic publications. In response, the purpose of this paper is to report an analysis of citations to SRs from Scopus publications, 2000-2013. Design/methodology/approach – Scopus searches were used to count the number of documents citing the four SRs in each year. A random sample of 384 documents citing the four SRs was then visited to investigate the nature of the citations. Findings – Each SR was most cited within its own subject area but attracted substantial citations from other subject areas, suggesting that they are open to interdisciplinary uses. The proportion of documents citing each SR is continuing to increase rapidly, and the SRs all seem to attract substantial numbers of citations from more than one discipline. Research limitations/implications – Scopus does not cover all publications, and most citations to documents found in the four SRs presumably cite the published version, when one exists, rather than the repository version. Practical implications – SRs are continuing to grow and do not seem to be threatened by institutional repositories and so research managers should encourage their continued use within their core disciplines, including for research that aims at an audience in other disciplines. Originality/value – This is the first simultaneous analysis of Scopus citations to the four most popular SRs.	pubmed central;research papers in economics;scopus	Xuemei Li;Mike Thelwall;Kayvan Kousha	2015	Aslib J. Inf. Manag.	10.1108/AJIM-03-2015-0049	library science;computer science;world wide web;information retrieval	ML	-76.90725326116402	-20.36786163572515	142444
6551b877a3f65dbaae0758fb48b8f1e29483b8c9	the new zealand parliamentary library and the wider development of parliamentary libraries over 150 years	library history;oceanie;text;service information;bibliotheque parlementaire;parliament library;legislative libraries;legislative libraries new zealand;histoire des bibliotheques;nueva zelandia;nouvelle zelande;servicio informacion;biblioteca parlamento;information service;new zealand;historia de las bibliotecas;oceania	This paper discusses the development of the New Zealand Parliamentary Library in the context of other significant parliamentary libraries in the English-speaking world. There are four phases of development in New Zealand’s 150 years, which are also observable in other parliamentary libraries. The four phases are: getting established, building a strong library collection, supporting library functions, and focusing upon Parliament. This paper tells the story of one library’s development, highlighting the influences, connections, and similarities with other well-known examples. Although the world’s parliamentary libraries take varying paths because of the different cultures, parliamentary models, and national library frameworks in which they operate, comparisons can be fruitful. Last year New Zealand’s Parliamentary Library celebrated 150 years of service to New Zealand and its Parliament. This event provided an opportunity to look at the place of the library within the country’s cultural development (Martin, 2008). It made us aware of how our library’s development follows the pattern of global parliamentary library developments and how we are different. As is the case for many parliamentary libraries, during our early years it was a struggle to create a stable base of operations and to establish enough credibility and value within Parliament to ensure an ongoing funding base. Once the library was established with fitting accommodation, a steady budget, and a growing collection, there was pressure to use these resources more widely than for parliamentarians alone. In our more recent history, we have been able to focus upon serving Parliament with a range of services that are aligned with the services provided in many other 460 library trends/spring 2010 parliamentary libraries around the world. We look at the future with confidence that our Parliament acknowledges the value of the support that we provide to parliamentary democracy. Reflecting on our own 150 years and the development path of other parliamentary libraries with which we have been involved, progress has not been steady. Politics and personalities have added mystery and drama to our development story, as they do in most parliamentary libraries. Particularly in the early stages, when the need for a parliamentary library is not yet firmly established, the style of the political leaders and their governments may have a major influence. The parliamentary librarian and other senior staff will inevitably have an impact on where resources should be focused, which strategic influences to follow, and how to deliver services. The community of parliamentary libraries is connected globally and provides a variety of development paths to observe and choose from. We listen to descriptions of our libraries and their services and to stories of innovation and try to understand what implications there may be for our own libraries. We are at many different stages of development around the world, working within different cultures, different political models, and different national library networks. The right path for one country is seldom a good map for another country, but it does help to identify the possibilities. In this paper we outline four phases of development for New Zealand’s Parliamentary Library, at the same time making comparisons with the evolution of other parliamentary libraries: • Getting established • Building a strong library collection • Supporting wider library functions • Focusing upon Parliament In the work that we have done with Pacific parliamentary libraries, and in supporting attachments and visits from parliamentary library staff from the Asia-Pacific region and some African countries, we have observed similar phases of development, although they have lasted for different lengths of time and vary in detail. These dimensions or stages of library development are usually sequential, but not always. They also interact with each other in shaping the overall development of particular libraries. The British House of Lords Library can be found at one end of the spectrum. Until relatively recently (the 1970s), it remained a small legal reference library with few staff and limited services. The reforms that brought in new members of the House of Lords have meant more sophisticated demands on reference and research services. At the other end of the spectrum is the Library of Congress, which became a national library long ago and which provided extensive reference and research services 461 fraser & martin/new zealand from an early date. New Zealand’s Parliamentary Library is an interesting case because it has moved through all the stages outlined and the interactions between stages have been important in its history. Developments in the United Kingdom, United States, and Australia In the English-speaking world, the development paths of parliamentary libraries are often strongly influenced by the impact of the Westminster and American models of parliamentary democracy (Metcalfe, 1965). The Westminster approach had its roots in the early 1800s with the formation of libraries for the two Houses at a time when Britain’s politics were elitist and nondemocratic. The House of Commons Library grew out of the specific needs of the legislature for a record of its official proceedings and papers, with the librarian soon providing a reference service (Menhennet, 2000). In the latter half of the nineteenth century, it developed its general collections and became more of a “club” library, but there was no consideration of public access or development of a national resource. A democratic or popular impulse was not associated with the library. Other library needs were catered to early on by other institutions. Britain had its Public Libraries Act (1850), which met the needs of the public, and scholars’ needs were met by the British Museum. The democratic temper of the United States led to a different direction for its legislative library. Prior to the destruction of the Library of Congress by the British in 1814, it was merely a small reference library serving the immediate purposes of the legislators (Goodrum, 1974). With the purchase of President Jefferson’s library, it immediately became a broad collection, and by mid-century access to it was opening up and exchange relationships were strengthening the collections greatly. The appointment of Ainsworth Rand Spofford as librarian in 1864 set its longterm direction as a library for legislators and a national library. Australia and New Zealand achieved parliamentary government in the same middle decade of the nineteenth century. Australia retained its federal structure and corresponding State Parliaments while New Zealand dispensed with its provincial legislatures fairly rapidly. The Australian States established parliamentary libraries in the 1850s and 1860s, about the same time as New Zealand (Gregory, 2001; Holgate, 1886a; Tillotson, 1990). In the early years some of these libraries were administered by the Clerk of the Parliament, and consisted of small collections devoted to reference services. In others, such as the Victorian and New South Wales parliamentary libraries, there were substantial collections for use by parliamentarians as well as good general collections that they could enjoy at their leisure. The public libraries that developed in both countries were subscription libraries, particularly in the main centers. An absence of strong local government institutions prevented the emergence of free public libraries 462 library trends/spring 2010 on the British model. This was especially accentuated in Australia with its highly concentrated urban populations in the capitals of the various states. State public libraries were strong and well resourced compared to the state parliamentary libraries. Establishment Phase When the need for a parliamentary library to support the work of the legislature is identified, the primary concerns are with establishing and furnishing a space, finding a budget to build a library collection, and employing appropriately qualified staff. There may be a local champion who believes passionately in the value of libraries and who personally influences some aspects of the initial development toward his or her own views of what a parliamentary library should be. Once the library is created and the collection is growing, beautiful buildings are often purposefully designed and built. Library buildings, like those of the parliament, may demonstrate a sense of national identity and the best of local craftsmanship. The parliamentary libraries that were built in the nineteenth century often have formal reading rooms of considerable grandeur and dignity. Along with suitable accommodation, the establishment phase includes securing an annual budget that will support a library collection and pay for appropriately qualified staff. Initially collection building is likely to be focused upon ensuring good access to the parliamentary information created by the legislature—the record of plenary proceedings and the stages of passing legislation. The collection may include legislation of other relevant jurisdictions, often obtained through exchanges. Among the parliamentary libraries of the world today, there are some that are in this establishment phase with uncertain budgets for staff and collections and relatively new facilities, and there are some parliaments that do not yet have a library. In New Zealand during the nineteenth century, the first concern was to create and provide a reference library for legislative purposes (Martin, 2008). Initially the needs were straightforward. Members of Parliament (MPs) wanted to be able to refer to the legislation of other countries in their own lawmaking. As the work of Parliament created publications such as bills, acts, and the official records of House transactions, legislators required good access to these materials. As the work of Parliament grew to encompass 		Moira Fraser;John E. Martin	2010	Library Trends	10.1353/lib.2010.0006	library science;engineering;sociology;management;law;world wide web		-70.20133131681784	-18.95480936424161	142585
b5757b45b71a8f80a3fb833d49038a1b2c406ed9	a critical phenomenon in a self-repair network by mutual copying	critical point;critical phenomena;percolation theory	This paper reports a critical phenomenon in a self-repair network by mutual copying. Extensive studies have been done on critical phenomena in many fields such as in epidemic theory and in percolation theory with an effort of identification of critical points. However, from the viewpoints of cleaning up a network by mutual copying, critical phenomena have not much studied. A critical phenomenon has been observed in a self-repair network. Self-repairing by mutual copying is the double-edged sword that could cause outbreaks with inappropriate parameters, and careful investigations are needed.		Yoshiteru Ishida	2005		10.1007/11552451_12	artificial intelligence;theoretical physics;mathematics;social psychology	Metrics	-75.6266801079557	-14.11883033658969	142779
276119f4c8629a350d8baa62af3c2c3266d70c1e	the earliest hebrew citation indexes	indexation;indexing;hebrew;relevance information retrieval	The invention of the citation index was credited to ShepThe citations discussed here are not to the works of ard (1873) until Shapiro described a legal citation index individuals, but to anonymous classics, mainly the Bible published in 1743. A similar index was embedded in the and Talmud. Prestige and promotion are not relevant facTalmud two centuries earlier (1546). The first Hebrew citors, as they are in modern citation analysis. Gaster tation index to a printed book is dated 1511. The earliest (1929) describes the homiletical applications of Biblical Hebrew manuscript citation index, ascribed to Maimonides, dates from the 12th century. Considerable knowlcitation indexes—use by preachers. Shimeon Brisman edge was assumed for users of these tools. The substan(personal communication, December 14, 1995) posits tial knowledge of their compilers contrasts with the semithat these indexes also served scholarly purposes, as modautomatic production of modern citation indexes. The ern ones do, but early Hebrew citation indexes are largely terms citation, quotation, reference, cross-reference, lolegal in nature. cator, and concordance are employed inconsistently in publications about Hebrew indexes. There is a lack of Jewish law is characterized by ‘‘vertical legitimation’’ citation links between the secondary literature on Hebrew (Weinreich, 1980, p. 207): Rabbinic opinions generally indexes and that of citation analysis. cite an earlier authority. This is analogous to precedent	citation analysis;citation index;compiler;concordance (publishing);cross-reference;embedded system;index (publishing);printing;secondary source	Bella Hass Weinberg	1997	JASIS	10.1002/(SICI)1097-4571(199704)48:4%3C318::AID-ASI5%3E3.0.CO;2-Z	library science;hebrew;talmud;bibliometrics;computer science;initiation;linguistics;bibliography;world wide web;information retrieval	Web+IR	-71.49452582567145	-21.590345967957735	142833
9af405f31f869c436faf0652dbc6b16ee6a8ad4f	dvs - a system for recording, archiving and retrieval of digital video in security environments		"""A customer on crutches threatens a grocery store manager with a million-dollar lawsuit, contending that he fell on the store's premises 35 days earlier. He is certain that the store's video surveillance system is an antiquated, analog-based system that keeps tapes for only up to a month, so the grocer won't have pictorial proof to dispute an older claim. He's hoping for a quick settlement based on lack of visual proof, but he's made a bad decision — the store recently implemented digital video surveillance which provides high quality images that can be accessed immediately and retained indefinitely. The store can prove the customer's injury, even if real, did not take place on its premises and the only dollar loss here is from the pocket of the opportunist. Frauds and scams such as the example above are an everyday occurrence in the retail industry. Customers boldly take items off of shelves and attempt to return those same items for a refund during a single visit. Still, by a long shot, simple pilferage remains the largest source of overall loss in retail. Perpetrators rely on and still hedge on the limitations of analog video deployments, which fall short on shelf life, searchability and image quality. With the continued adoption of digital video surveillance (DVS) solutions, many of the traditional shortcomings of analog-based, closed circuit television (CCTV) deployments have been eliminated completely. What has fueled the accelerated growth in this space, though, is the realization that DVS """" functionality """" can also provide enterprise environments with a much broader set of applications and uses. Take video analytics for example: A marketing department can now better monitor promotional campaigns and make effective in-store display adjustments based on analyzing the customer foot traffic captured on camera. Overall, what traditionally resided solely in the domain of physical security or loss prevention has now entered into the domain of overall company ROI and business analytics functions. As with any technological shift, the advent of DVS is changing organizations internally. New digital system deployments often are maintained by information technologists who treat the images as data and manage content much as they do all other corporate data. This shift of infrastructure control from physical security departments to more centralized information technology department management is the first step to enjoying the significant advantages of DVS solutions."""	analog signal;business analytics;centralized computing;closed-circuit television;descriptive video service;digital electronics;digital video;display resolution;dynamic voltage scaling;file archiver;image quality;physical security;region of interest;video content analysis	Wolfgang Herzner;Matthias Kummer;Michael Thuswald	1997			video capture;multimedia;uncompressed video;video processing;computer science	Web+IR	-67.58501208501559	-23.66891402609361	142842
e4679cb995fe5fb213038c1c552f43681de5fee9	benchmark, sample & measure		The routine I will describe was started as a PL/I routine written by Mr. Gib Scranton, at ISU, for a graduate course. The routine used much core (70-80k), and that is a commodity that is quite scarce in any installation. A second iteration was performed in Assembler F by Mr. Dana Zimmerli, an instructor and systems analyst.	assembly language;benchmark (computing);international stereoscopic union;iteration;pl/i	Anthony P. Lucido	1970	Operating Systems Review	10.1145/1232905.1232907	simulation;computer science;operations research	PL	-68.76327204671301	-23.900994076873797	143119
60303019a58a9ee0a3235648c06f6053a043ef45	reflections on information systems journal's thematic composition	cluster analysis;is research themes;quantitative literature review;is history;latent semantic analysis;is research	This article analyses the scholarly output of Information Systems Journal (ISJ) in relation to its seven peer journals in the Association for Information Systems Senior Scholars’ Basket of Eight journals (SSB8) since ISJ’s inception in 1991. To do so, cluster analyses are generated using metadata (i.e. titles, keywords and abstracts) from the articles published. The analysis results reveal commonalties and some distinguishing differences between ISJ and its peer journals. The findings illuminate that ISJ has published articles in the area of information systems development at a much higher rate than its counterparts. The analyses also illustrate that ISJ has embraced broader philosophical and methodological underpinnings than other SSB8 journals.	amiga reflections;association for information systems;cluster analysis;information systems journal;information system;software development process	James Love;Rudy Hirschheim	2016	Inf. Syst. J.	10.1111/isj.12085	latent semantic analysis;computer science;data mining;cluster analysis;information retrieval	HPC	-76.06620026787036	-18.541796186714713	143439
5538580db3c602991ff5b1b23717a2b110d81395	researchers' big data crisis; understanding design and functionality	data management	The <i>Communications</i> Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of <i>Communications</i>, we'll publish selected posts or excerpts.<br /><br /><b>twitter</b><br />Follow us on Twitter at http://twitter.com/blogCACM<br /><br />http://cacm.acm.org/blogs/blog-cacm<br /><br /><i>Michael Stonebraker issues a call to arms about research groups' data-management problems. Jason Hong discusses the nature of functionality with respect to design</i>.	big data;blog;call to arms;coat of arms;jason	Michael Stonebraker;Jason Hong	2012	Commun. ACM	10.1145/2076450.2076453	computer science;data science;internet privacy;world wide web	HCI	-65.33547586357852	-15.64442748757039	143770
b9951d3354590040898c718d60ce256f3101f863	"""rejoinder to the response to """"the scholarly capital model"""""""	journal rankings;research evaluation;scholarly capital model;ecological fallacy			Michael J. Cuellar;Hirotoshi Takeda;Richard T. Vidgen;Duane P. Truex	2016	J. AIS		individual capital;ecological fallacy;social science;statistics	ECom	-64.71101627384475	-10.857434898713601	143804
3eb5e124c1fcc36daf4804258df470966b04f9ec	assessing the usefulness of bibliometric indicators for the humanities and the social and beha vioural sciences: a comparative study	bibliometrie;use;analyse bibliometrique;indicador investigacion;critical study;sciences humaines;document publie;estudio comparativo;social sciences;bibliometria;ciencias humanas;literature;etude critique;utilizacion;estudio critico;etude comparative;utilisation;humanities;indicateur recherche;published document;comparative study;sciences sociales;bibliometry;bibliometric analysis;recherche scientifique;literatura;litterature;ciencias sociales;research indicator;scientific research;documento publicado;investigacion cientifica;analisis bibliometrico;public administration	An evaluation was made of the use of bibliometric indicators for five disciplines in the humanities (social history, general linguistics, general literature, Dutch literature, and Dutch language) and three disciplines in the social and behavioural sciences (experimental psychology, anthropology, and public administration) in the Netherlands. Articles in journals were the predominant outlet in all disciplines. Monographs and popularizing articles were more important outlets in ‘softer’ fields than in ‘harder’ ones. The enlightenment function of scholarship was especially evident in Dutch literature and language, and public administration. Only some of the humanities disciplines are locally oriented. Although many publications were written in English, only experimental psychology, general linguistics, anthropology, and genrral literature were internationally oriented regarding output media. The impact of departments differed greatly both within and between disciplines. For all disciplines, bibliometric indicators are potentially useful for monitoring international impact, as expert interviews confirmed. Especially in Dutch language, Dutch literature and public administration, ISI-citation data are not very useful for monitoring national impact.		Anton J. Nederhof;Rolf A. Zwaan;Renger E. de Bruin;P. J. Dekker	1989	Scientometrics	10.1007/BF02017063	social science;scientific method;comparative research;sociology	HCI	-74.03161212564736	-22.072180881214656	144010
8d6b162fe188dacf98baf99a651340dfb0c251f4	the 1992 profile of computer abuse in australia: part 2	computer fraud;law;computer security;australia	Analyses some of the 497 cases of computer abuse recorded by the Australian Computer Abuse Research Bureau, since its inception in 1978. Features include perpetrators and the law, and computer abuse by industry.	cybercrime	Vic Kamay;Tony Adams	1993	Inf. Manag. Comput. Security	10.1108/09685229310033360	computer fraud;computer science;law;computer security	Crypto	-69.27011709252524	-10.739879846509368	144099
e9f3a68995dde82372960df3f2459b0fa44f0bb3	a systematic analysis of duplicate records in scopus	bibliographic control guidelines;articulo;duplicate records;scopus database;bibliometric indicators overdimensionalized;indexing errors	In recent years, the Web of Science Core Collection and Scopus databases have become primary sources for conducting studies that evaluate scientific investigations. Such studies require that duplicate records be excluded to avoid errors of overrepresentation. In this line, we identify duplicate records in Scopus and examine their origins. Identifying journals with duplicate records in Scopus, selecting and downloading bibliographic journal records, and identifying and analyzing the duplicate records is the methodology adopted. Duplicate records are found when articles published in a journal are incorrectly mapped by Scopus to this journal and to a different journal from the same publisher and when there are journal title changes, orthographic differences in the presentation of a journal name, and journal name variants. In these last three cases, one bibliographic record of each duplicate is mapped to Medline coverage of Scopus. Consequently, the identified duplicates and the significant differences in the number of citations received in duplicate articles may influence bibliometric studies. Thus, there is a need for rigorous quality control guidelines to govern database managers and editors to prevent the creation of duplicates.	scopus	Juan Carlos Valderrama Zurián;Remedios Aguilar-Moya;David Melero-Fuentes;Rafael Aleixandre-Benavent	2015	J. Informetrics	10.1016/j.joi.2015.05.002	scopus;computer science;data mining;world wide web;information retrieval	NLP	-77.15919667086295	-21.872292873370444	144399
ccd1f2edd30c540176580983f4932131b54cc3d7	an approach to research in file organization	information processing systems;file organization;research methodology;information processing	Research in file organization is a problem in which the unstructured efforts of many individual researchers have not produced results commensurate with the effort expended. The paper briefly examines some of the reasons for this and suggests a structure consisting of a language and terminology for communication, a model of information processing systems and tools for studying and analyzing problems related to such systems. The ISDOS project is outlined as a coordinated approach which may serve as the beginning in the development of a satisfactory structure.	information processing	Daniel Teichroew	1971		10.1145/511285.511302	information processing;computer science;knowledge management;methodology;data mining;database;world wide web;information retrieval	SE	-70.51025541533897	-23.739602594630018	144436
d8c518e8b041f6ccebcec5c21e70be90319c36dc	the advanced identity representation (air) project: a digital humanities approach to social identity pedagogy			digital humanities	D. Fox Harrell	2013			pedagogy;digital humanities;social identity theory;political science	Vision	-63.770174341623644	-11.396089730622215	144492
435018452d8f4c403e39baad1d18a2c27f527c5c	the poetry of the lancashire cotton famine (1861-65): tracing poetic responses to economic disaster				Ruth Mather	2018			poetry;famine;ancient history;tracing;history	ML	-64.105020805072	-11.680248079642588	144516
b5535e2a23ca33bc9c08980623d12456864bbb8d	dspace: a year in the life of an open source digital repository system	distributed system;dspace;systeme reparti;ucl;open archives;digital repository;discovery;theses;conference proceedings;digital archive;archives ouvertes;grid;archivos abiertos;biblioteca electronica;digital web resources;sistema repartido;ucl discovery;rejilla;open access;logiciel libre;grille;software libre;ucl library;electronic library;book chapters;open access repository;article;bibliotheque electronique;open source software;open source;ucl research	The DSpaceTM digital repository system was released as open source software in November of 2002. In the year since then it has been adopted by a large number of research universities and other organizations world-wide that need a digital repository solution for a number of content types: research articles, gray literature, e-theses, cultural materials, scientific datasets, institutional records, educational materials, and more. The DSpace platform and its various applications are becoming better understood with experience and time. As one result of a recent meeting of the DSpace user community, we are now venturing into the territory of broad, community-based open source development and management, and gaining insights from the experience of the Apache Foundation, Global Grid Forum, and other successful open source projects about how to build open source software for the digital library domain.	dspace;digital library;open-source software;virtual community	MacKenzie Smith;Richard Rodgers;Julie Harford Walker;Robert Tansley	2004		10.1007/978-3-540-30230-8_4	digital library;computer science;database;dspace;grid;world wide web;algorithm	SE	-73.29185095561188	-22.935151556555734	144777
3f5ff7dc61e8f4426da7a16386b0aaae7972d908	a semi-automatic relevancy generation technique for data processing, education and career development	career development;department of defense;data processing;general techniques	"""""""In a rapidly changing technology such as ADP, personnel resources, in the absence of intensive training, tend to become obsolescent at the same rate as hardware resources, and a major effort is required to keep a staff current and competent."""" This conclusion was recorded by a 14 member panel appointed by President Nixon to recommend improvements in the Data Processing activities of the Department of Defense. It is particularly interesting to note that this statement was one of the panel's main recommendations as cited by Information Week (8/3/70), and COMPUTER-WORLD (8/19/70). The significance, of course, is that training costs are finally being classified along with hardware costs and we may at last be somewhere near the threshold of putting some order to the existing chaos of Data Processing education."""	automation;business requirements;computer;mind;relevance;requirement;semiconductor industry;usb on-the-go;we feel fine	J. David Benenati	1971		10.1145/1478786.1478871	engineering;operations management;management;operations research	Arch	-66.52981381286835	-21.09648560004562	144787
af5247e9d341053e4791817e64ab48c477208fba	law, bioethics and the current status of ownership, privacy, informed consent in the genomic age		"""The rise of biobanks including the related databases containing increasing amount of health information are now commonplace – found on every continent of the globe including Antarctica. Common though they may be, legal and ethical issues for collecting, storing and using the associated health/genetic information continue to perplex clinicians, researchers, law enforcement, and the lay public alike. For example, one's image or likeness is copyrightable, but not one's genome. Yet billions of dollars are being made from patented genes, patented species, private databases, and human tissues. Several health care systems now collect human DNA samples from patients through """"opt-out"""" programs, and vast collections of DNA are being assembled without compensation to donors. Now that whole genome sequencing is becoming more affordable, the bioinformatics community is rightly asking about its enduring obligations and responsibilities vis a vis genetic ownership, residual rights, privacy, and informed consent. And that’s just in the USA. Many issues are magnified when material or data are intended to cross national borders. This workshop is designed to unpack many of the issues in pragmatic detail – hopefully dispelling certain myths while offering cautionary reminders about legal and ethical obligations. The two co-chairs will lead in-depth discussion and facilitate small group exercises to emphasize these issues. A particular highlight will be a mock “House of Commons” debate where workshop participants will be asked to take positions, ask questions, and vote with their feet. In other words, this workshop is meant to be provocative, user-friendly and skill enhancing."""	biobank;bioinformatics;database;mock object;usability;whole genome sequencing	Gregory Hampikian;Eric M. Meslin	2012			biology	HCI	-67.56413884461861	-19.342293808653466	144812
1b319aed73f29254fd239f4a7869f4ce74830811	conceptualizing personal web usage in work contexts: a preliminary framework	cyberloafing;non work related internet uses;internet use;personal web usage in work contexts;internet deviant behaviors;internet addiction;problematic internet use;knowledge base	0747-5632/$ see front matter 2011 Elsevier Ltd. A doi:10.1016/j.chb.2011.07.006 ⇑ Corresponding author. E-mail address: sk2226@cornell.edu (S.J. Kim). As the internet became the primary method of task-related communication within organizations, a social phenomenon was born: internet users going online for non-work-related purposes when supposedly working. However, there is little consensus on how to conceptualize this broad range of phenomena. Not only do many conceptual terms exist in the literature without clear distinctions, but also the degree to which specific behaviors belong under each concept remains unclear. In this article, we analyze each broad concept on specific dimensions found in the literature, including formal definitions, causes, and outcomes. We then provide a typology integrating this knowledge. Based on an empirical investigation of this typology, an initial framework of personal web usage in work contexts is proposed. 2011 Elsevier Ltd. All rights reserved.	biological anthropology;formal system;internet	Sunny Jung Kim;Sahara Byrne	2011	Computers in Human Behavior	10.1016/j.chb.2011.07.006	psychology;knowledge base;computer science;knowledge management;social psychology;world wide web	HCI	-77.33427354221571	-16.835054182404566	144846
4ec09849c1a15f9fdcdb09f88fc368d600602ba5	what research and theory inspires ia/ux, and how can this change behavior and help make a political and humanitarian difference?		This session is a moderated panel discussion among senior IA/UX practitioners from the greater Washington, DC area. Its goal is to challenge and inspire the ASIST research community. Among themes the panel will discuss are: 1) how research and theory inspires client project work – what types of research is needed, and what would be considered accessible and practical research; and 2) how IA/UX (including content strategy, taxonomy, governance, etc.) can change behavior, and help make a political and humanitarian difference.	a/ux;content strategy;pc-ux;taxonomy (general)	Joseph A. Busch;Dave Cooksey;Jeff Pass;Ren Pope;Stacy Surla;Thomas Vander Wal;Lisa Welchman;Dan Willis	2017		10.1002/pra2.2017.14505401067	socioeconomics;politics;political science	HCI	-66.36879175216622	-12.04372174438728	144922
5b8cf6e42ae019fdfc92ca97087c70e5b5f6b451	it predictions for 2009	computer crime;scada systems;information security;control systems;telecommunication control;manufacturing;telecommunication computing;cables;asia;transportation	2009 shouldn't spell doom and gloom: cool, essentially free technologies will become a playground for innovation. Because you're likely to be asked to do more with less money, ask for more time to get your work done, allowing time for healthy experimentation. I think that's the best way to survive during tough times.	doom;money	Phillip A. Laplante	2008	IT Professional	10.1109/MITP.2008.126		HCI	-70.12153085495667	-12.209639155881627	145117
c5f6225182eba8cfc51c4e81b5bc52ef05652d38	lithuanian on-line periodicals on the world wide web.	world wide web			Lina Sarlauskiene	2001	Inf. Res.		computer science;multimedia;sociology;world wide web	Theory	-63.05068971530697	-11.28953814165658	145123
c253e59c7d6b540f4b81c47553a82c2b94c47075	emergent actors in world politics: how states and nations develop by lars-erik cederman			emergent;lars bak (computer programmer)	David Lazer	2001	J. Artificial Societies and Social Simulation			AI	-65.46811023200507	-10.675742825449204	145129
fe01857ebd93da30a8155caac1af5fc03c3420aa	lethal autonomous weapon systems [ethical, legal, and societal issues]		The topic of lethal autonomous weapon systems has recently caught public attention due to extensive news coverage and apocalyptic declarations from famous scientists and technologists. Weapon systems with increasing autonomy are being developed due to fast improvements in machine learning, robotics, and automation in general. These developments raise important and complex security, legal, ethical, societal, and technological issues that are being extensively discussed by scholars, nongovernmental organizations (NGOs), militaries, governments, and the international community. Unfortunately, the robotics community has stayed out of the debate, for the most part, despite being the main provider of autonomous technologies. In this column, we review the main issues raised by the increase of autonomy in weapon systems and the state of the international discussion. We argue that the robotics community has a fundamental role to play in these discussions, for its own sake, to provide the often-missing technical expertise necessary to frame the debate and promote technological development in line with the IEEE Robotics and Automation Society (RAS) objective of advancing technology to benefit humanity	automation;autonomous robot;autonomy;lethal autonomous weapon;machine learning;robotics	Ludovic Righetti;Q.-C. Pham;Raj Madhavan;Raja Chatila	2018	IEEE Robotics & Automation Magazine	10.1109/MRA.2017.2787267	engineering ethics;automation;simulation;engineering;international community;social issues;humanity;autonomy;robotics;artificial intelligence	Robotics	-64.23590192042953	-19.029939454988767	145568
a200474e6607a7ed1c432eee7df2e69c4d57bff2	electronic press: 'press-like' or 'television-like'?		A notable development of recent times has been the exponential increase of video content available on newspaper websites. The technological convergence between press and broadcasting throws into sharp relief the historically disparate regulation of the two sectors. As long as no political consensus on regulatory convergence can be reached, the question of how to distinguish between text-based and video-based media in the online domain will remain relevant. In recent times, this question has surfaced in the context of the classification of newspaper publishers’ video sites as on-demand audiovisual media services (AVMS). This article examines the contrasting positions of the UK and Austrian regulatory authorities concerning the regulation of video material on the websites of print publications. The author argues that Ofcom’s approach makes it hard to predict the mixture that would bring a hybrid service within the scope of regulation. By contrast, the Austrian approach offers a pragmatic solution to a problem that is only beginning to emerge.	digital video;emergentism;streaming media;technological convergence;text-based (computing);time complexity	Irini Katsirea	2015	I. J. Law and Information Technology	10.1093/ijlit/eav004	computer science;multimedia;sociology;law;world wide web;computer security	Metrics	-74.4435051245098	-13.343865441326155	145572
0d035288684e25cfca9400a8dee13f8ca2cb08ec	summing up approaches to the study of science and technology indicators	scientometrics;science and technology;technological innovation;empirical analysis;interdisciplinary field;technology;sciences;discipline;scientific discovery;disciplina;indicador medida;ciencia;technological progress;scientometria;interdisciplinaire;technologie;scientometrie;interdisciplinario;measurement indicator;recherche scientifique;scientific research;investigacion cientifica;indicateur mesure;tecnologia	Attempts to reduce the multiplicity and variety of the range of indicators presently used to measure science and technology to lean patterns have so far proved unsuccessful. The reason for this is the ongoing lack of an all-comprehensive theory to rationalise every aspect of intricate and as yet obscure processes such as scientific discovery and technological innovation. We ought to expect from a theory of scientific and technological progress satisfactory not only in abstract terms but also as an empirical analysis is a composition of two aspects — static and dynamic — in a few homogeneous variables.	theory	M. de Marchi;M. Rocchi	1999	Scientometrics	10.1007/BF02766294	discipline;social science;scientometrics;sociology;technology	Logic	-74.75369010076393	-20.577641659221342	145577
2e61c2488483f77f1b55f1f20ed59b86dfabde0a	opinion: stay on course with an evolution or choose a revolution in computing		The Nature of the Problem: Since the inception of personal computing in the early 80’s, the evolution of computing resources has created a myriad of software applications, programming languages, operating systems, platforms, and execution environment sensitive applications. Many of the developed hardware and software system components have come and gone before they had any longevity allowing return on investments in the technology by the market place. In some instances, the changeover in technology has met or exceeded Moore’s Law in the swiftness with which the fleeting technology has appeared only to be replaced. This has created a tremendous obsolescence in software, hardware, and people’s skills. The effect on software development has been an endless requirement for additional training and retraining of personnel on the use of new tools and software environments (as shown in Figure1). The long term effect is a dearth in efficiency of people’s time, and capital investments and the ability to use time, people, and investments to solve new and interesting problems left unchallenged.	moore's law;operating system;personal computer;programming language;software development;software system	Ramesh K. Karne;Alexander L. Wijesinha;George H. Ford	2008	SIGARCH Computer Architecture News	10.1145/1462609.1462611	artificial intelligence	Arch	-63.2940801909145	-22.920340566428408	145603
e921c91f3776356e545c005afce2f9262334db84	measuring the technical efficiency of football legends: who were real madrid's all-time most efficient players?	dea;football;sport;super efficiency	Many football players contribute to aggregate results throughout a football club’s history. However, no scientific research has pinpointed the most technically efficient players in a football club’s history considering their position on the field. The aim of this paper is to propose an output-oriented nonincreasing returns to scale super-efficiency data envelopment analysis (DEA) model in order to measure football players’ performance. The model is applied empirically to Real Madrid’s best players (white legends) from the signing of Luis Molowny to Raúl González’s departure. Results are also calculated and compared with the standard DEA in order to form the most efficient and super-efficient historical squad of Real Madrid footballers.	aggregate data;benchmark (computing);bricx command center;data envelopment analysis;hgnc;input/output;international federation of operational research societies;wikipedia	Daniel Santín	2014	ITOR	10.1111/itor.12082	simulation;operations management;sport;advertising	DB	-65.33541782526869	-14.406400309999299	145709
9b18d673567259cd79e61a41c7d097739a984c56	editorial: on the 15-year anniversary of napster - digital music as boundary object		This special issue and its range of contributions, from both emerging and established scholars with interests in digital music distribution, provides a particular and novel depth of vision, into both developments in digital music in the time since Napster, and the current issues and discussions in the field. As illustrated by the content of this issue, research is vibrant, drawn from a rich variety of disciplinary orientations, and shows especially the crucial and ongoing importance of music online, internationally and across academic communities.	napster	Raphaël Nowak;Andrew Whelan	2014	First Monday		computer science;multimedia	Theory	-71.32655940922989	-18.834126840350198	145752
3520f2baea5fb8fdf89f0f5186a2c8da0b2dcde2	towards risk minimization for novice gamblers: a ‘not so expert' system	centre for tourism and services research ctsr;decision support system;decision support systems;respubid16940;tourism activities;social benefit;risk minimization;0806 information systems;9003 tourism;gambling	Book subtitle: Proceedings of the International Conference in Amsterdam, The Netherlands, 2009. #R##N#Racing (thoroughbred, harness and greyhound) brings many visitors and economic and social benefits to regional areas in Australia. Many casual gamblers, however, have little knowledge of racing and of the fundamental rules that underpin its various forms (which, while reasonably consistent across both location and type, do differ in some respects). Thus, in this paper, we introduce a decision support system designed to assist and educate novice punters. A motive underpinning this research was a desire to produce a tool that might assist visitors wishing to experience the Australian provincial racing circuit to get the most out of their involvement.	expert system	G. Michael McGrath	2009		10.1007/978-3-211-93971-0_11	simulation;decision support system;computer science;marketing;operations management;operations research	HCI	-70.76834669566142	-14.779842591126002	145793
1c3750c87777af53efcecf967bb4e23878ff945e	a lifeboat doesn't do you any good if it's not there when you need it: open access and its place in the new electronic publishing paradigm	electronic journal;informing science;open access;array;latin america;electronic publishing;quality control	This paper draws on the results of recent research into digital publishing in Latin America sponsored by the European Commission’s ALFA programme. It outlines the growth in publishing in the region. It aims to stimulate reflection on the impact of a system in which most of the publishing is supported by institutions rather than commercial companies, and considers authors’ aspirations for their work to achieve recognition, attitudes towards peer review and other aspects of journal quality, the indexing and availability of full text journals, and the sustainability of institutionally supported publishing. Examples are drawn from publishing in the field of librarianship and information sciences on which the original research project was focused.	information science;librarian;paradigm	Ian M. Johnson	2007			quality control;computer science;latin americans;advertising;electronic publishing;programming language;operations research;world wide web	DB	-71.93771759486769	-21.771077853907773	145897
4e18835abc694e0c3460f934eb5a202c4581dbaa	unconventional systems	abortive attempt;scientific need;computer manufacturer;high-end machine;product line;compatible extension;unconventional system;high performance;foreseeable future;available equipment;party line	"""For the bulk of the past decade, the computer manufacturer has maintained the """"party line"""" that their successive models of high-end machines possessed all the performance that would be required for the foreseeable future. (This """"party line"""" alternated with abortive attempts to, in fact, build high performance, compatible extensions of the product line which turned out to be neither high performance nor compatible.) While it appears to be true that currently available equipment will for a while continue to be adequate to permit plumbing supply houses to do inventory control, it has always been outrageously false that this equipment come evens close to meeting our scientific or military needs. In these areas, we have witnessed the oft noted paradox of technological advances spurring scientific needs in such a fashion that the disparity between what is needed and what is available continues to grow. In the case at hand, this is no paradox at all in that it is only now that we can realistically envision computers of sufficient speed and capability to make it possible to start using them to solve problems with a nontrivial intellectual content."""	binocular disparity;computer;inventory control;party line (telephony);unconventional computing;while	Daniel L. Slotnick	1967		10.1145/1465482.1465559	simulation;engineering;operations management;operations research	HPC	-70.23663855005329	-13.16298944530133	146277
89a2a6814bc30c93875a1e7ca9395ee310b08d85	blogs and blogging: current trends and future directions	computer and information science;social sciences	Adopting an interdisciplinary scope, this paper presents a review of research on blogs and blogging within the social sciences and the humanities. It maps out what kind of research has been completed, how it has been performed and what gaps that might need to be filled in this relatively new area of research. More specifically, the paper will analyze all articles on blogs and blogging published until 2009 and indexed by the ISI Web of Knowledge .	blog	Anders Olof Larsson;Stefan Hrastinski	2011	First Monday		social science;multimedia;world wide web;information and computer science	Crypto	-75.7402939967941	-18.585562773083492	146281
bb24783870c532e369d68d2bb3903fba84a0c3f8	lexicography today: an annotated bibliography of the theory of lexicography		Ladislav Zgusta has, with the help of Donna Farina, performed a very valuable service for researchers into and practitioners of lexicographical theory by compiling an annotated bibliography of approximately 3,000 entries listed alphabetically by author. Each entry’s head has the following structure: name of an author (or group of authors), year of publication, title of article or book, followed by full bibliographical details, including cross references wherever necessary. An index permits the identification and referral of second/third authors to the “lead” author. A much more valuable index is the topical glossary containing getting on for a thousand descriptors, many of which offer further help in the form of fine differentiation in their listings. This glossary leads back, of course, to the main tabulation of authors. Further retrieval aids are provided in the form of the names of languages treated and referred to in the corpus of citations and innovatively a brief list of key names occurring in titles and epitomes. In terms of systematicity, presentation could hardly have been bettered. Zgusta prefaces the entire volume with a descriptive essay on the “operational parameters” of the work and the truces which occasionally make life difficult for the compiler of such a volume. It is plainly stated that ephemeral articles or “grey literature” do not rate inclusion in the list. Suitable material written in many different languages does! It is made clear, however, that “this is a bibliography of works that deal with the theory, methods, and procedures of lexicography: in other words, with all the appurtenances of the compilation of language-oriented dictionaries as well as with their study, use and criticism” (p. vii). It is always difficult for author, editor or bibliographer to draw the line that demarcates what gets into a book from what does not. In the latter category are the history of lexicography and etymological, historical and encyclopedic lexicography. A more difficult discriminator to decide upon and to operate is what to do about computational linguistics, artificial intelligence research and	artificial intelligence;bibliographer;compiler;computational linguistics;cross-reference;dictionary;discriminator;glossary;lexicography;table (information);text corpus;vii	Frank Knowles	1990	Machine Translation	10.1007/BF00713707	natural language processing;computer science;linguistics	NLP	-63.449581130377645	-20.721245750860817	146533
6af0b14754ceee9ad03d2f9a76745c3a0bd2427e	incorporating societal concerns into communication technologies	intellectual property;societal concerns;industrial property social aspects of automation information technology;information technology;government;social aspects of automation;law;communication technologies;protection;internet;data privacy;communications technology privacy protection government law intellectual property hardware open source software internet web sites;web sites;intellectual property right;content protection;communications technology;intellectual property societal concerns communication technologies information technology data privacy;industrial property;communication technology;privacy;open source software;hardware	no longer seen as just impinging upon societal concerns such as privacy. Instead, computer scientists, social scientists, and policymakers are designing and advocating the use of technologies to proactively protect or serve societal values. These include protecting minors from indecent content, protecting privacy, and protecting intellectual property rights [1]-[3]. The design of communication technologies is not autonomous; rather it is shaped by conflicting social groups [4]. As a result, communication technologies may have different properties depending upon their designers [5]. Consider the stark differences in privacy features between a university web browser funded by government grants [6], and a web browser developed by a firm dependent upon marketing revenue [7]. We focus here on how the consideration of societal concerns is affected by the institutional origins of the technology. We focus on four important institutions for the development of communication technologies. We use the term “code” to refer to the hardware and software of communica-	autonomous robot;computer scientist;privacy;value (ethics)	Rajiv C. Shah;Jay P. Kesan	2003	IEEE Technol. Soc. Mag.	10.1109/MTAS.2003.1216240	public relations;information and communications technology;computer science;internet privacy;law;information technology;computer security;intellectual property	HCI	-71.33187764819164	-10.864004201995662	146540
6745aebfa61de64880945cdcebbad28c529e7729	your magazine [from the editor's desk]		It is a real privilege and a terrific opportunity for me to start my term as IEEE Robotics and Automation Magazine (RAM) editor-in-chief with this September issue. I will serve for five years, and throughout my term, I will always rely on your opinions, criticisms, suggestions, and any other inputs that could help me to further improve your level of satisfaction as contributors and readers of the magazine. This is the IEEE Robotics and Automation Society’s (RAS’s) official magazine, which means that, as RAS members, it is your magazine—an important service that the Society provides to all of you, and to which you can help shape to fulfill your actual needs of communicat ing your research, products, and events within and outside our community. My main personal commitment and highest priority is to guarantee the fastest possible submission-to-publication time, as compatible with the quality of the review process that is required by a top robotics and automation publication like RAM. As you know, RAM guarantees rapid posting of all papers that have successfully passed the peer review process, upon completion of an additional, dedicated editing effort. Each paper, in fact, is fully edited by our professional team to give your presentation that special touch that you can easily and immediately perceive in any of our articles. RAM also devotes up to three of our four issues per year to Special Issues/Focused Sections. This means that only one issue per year is fully devoted to regular submissions, which are a significant portion of our total submissions because of the good reputation of this journal in the robotics and automation field. In other words, when submitting an article to RAM, you may have to wait a few months longer than you would for other publications to see your work printed, but the high quality of the final presentation, the unique opportunity to directly share your achievements with all of the members of our RAS community, and the top-level ranking of RAM will definitely reward your patience. In addition, as with all other IEEE publications, you have the possibility to select the Open Access option when submitting your articles. This will make the time needed for rapid posting of your papers exactly the same as the time needed for completing the Open Access publication process. I will mainly use this column to keep you up to date with the latest ongoing initiatives promoted by this magazine. I believe that RAM is the ideal laboratory and incubator of innovations for RAS publications: it has been so in the past, and I would love to keep the same level of quality as my great predecessors. I believe Stefano Stramigioli and Peter Corke, with whom I had the privilege to work as an associate editor of RAM, did an incredible job in amplifying the impact and shaping the contents of this magazine, fully inline with its scope. Real-world robotics papers, high-quality tutorials and surveys, special issues on emerging topics, and reports on the latest achievements are the typical contributions sought for publication in RAM. In addition, I am already discussing some new ideas with the editorial board and the IEEE to keep this magazine at the forefront of both robotics and automation research and publication services. You will hear about my ideas in the near future for sure! Real-world robotics	automation;display resolution;fastest;microsoft forefront;noise shaping;printing;random-access memory;robotics	Eugenio Guglielmelli	2013	IEEE Robot. Automat. Mag.	10.1109/MRA.2013.2275691	software engineering;simulation;engineering;desk;magazine	Robotics	-63.075523179657104	-19.125085003997647	147148
b6a3f7dd16c3d057f5ffbfbf5c9233a90faad6e0	tutorial on latent growth models for longitudinal data analysis		This tutorial introduces Latent Growth Modeling (LGM) as a promising new method for analyzing longitudinal data when interested in understanding the process of change over time. Given the need to go beyond cross-sectional models in IS research, explore complex longitudinal IS phenomena, and test Information Systems (IS) theories over time, LGM is proposed as a complementary method to help IS researchers propose time-dependent hypotheses and make longitudinal inferences about IS theories. The tutorial leader will explain the importance of theorizing patterns of change over time, how to propose longitudinal hypotheses, and how LGM can help test such hypotheses. All three tutorial facilitators will describe the tenets of LGM and offer guidelines for applying LGM in IS research including framing time-dependent hypotheses that can be readily tested with LGM. The three tutorial facilitators will also explain how to use LGM in SAS 9.2 with a hands-on application that will attempt to model the complex longitudinal relationship between IT and firm performance using longitudinal data from Fortune 1000 firms. The tutorial facilitators will also draw comparisons with other existing methods for modeling longitudinal data and they will also discuss the advantages and disadvantages of LGM for identifying longitudinal patterns in data. Workshop Leader Information (Please attach a copy of your resume in your email submission) Name: Paul A. Pavlou Affiliation: Temple University Postal Address: 1801 N. 13 th Street, SP201D, Philadelphia, PA, 19122 Telephone: 951-204-3583 Cell: 213-268-2259 Fax: 951-204-3583 Email: pavlou@temple.edu Additional Workshop Presenters (copy for each one) Name: Eric Zheng Affiliation: University of Texas at Dallas Postal Address: SM33, 800 W. Campbell Dr., Richardson, TX 75080 Telephone: 972-883-5914 Cell: 972-992-2158 Fax: 972-883-6910 Email: ericz@utdallas.edu Additional Workshop Presenters (copy for each one) Name: Bin Gu Affiliation: University of Texas at Austin Postal Address: 2100 Speedway, B6500, Austin, TX 78712 Telephone: 512-471-1582 Cell: 210-464-4649 Fax: 512-471-0587 Email: bin.gu@mccombs.utexas.edu Speakers' background, description of workshop, and envisioned activities during the workshop (please provide information for each speaker) Speakers’ Background Paul A. Pavlou is an Associate Professor of Management Information Systems, Marketing, and Management and a Stauffer Senior Research Fellow at the Fox School of Business and Management at Temple University. He received his Ph.D. from the University of Southern California in 2004. His research focuses on electronic commerce, information economics, online auctions, IT strategy, and research methods. His research has appeared in MISQ, ISR, JMIS, JAIS, JAMS, CACM, and Decision Sciences, among others. His work has been cited over 1,000 times by the Social Science Citation Index of the Institute of Scientific Information, and over 3,000 times by Google Scholar. Paul won several Best Paper awards for his research, including the ISR Best Paper award in 2007, the 2006 IS Publication of the Year award, the Top 5 Papers award in Decision Sciences in 2006, the Runner-Up to the Best Paper award of the 2005 Academy of Management Conference, the Best Doctoral Dissertation award of the 2004 International Conference on Information Systems (ICIS), the Best Interactive Paper award of the 2002 Academy of Management Conference, and the Best Student Paper award of the 2001 Academy of Management Conference (OCIS Division). Paul also won several Reviewer awards, including the 2009 Management Science Meritorious service award, the ‘Best Reviewer’ award of the 2005 Academy of Management Conference, and the 2003 MIS Quarterly ‘Reviewer of the Year’ award. Paul sits on the Editorial Boards of MISQ, ECRA, and DATABASE. He is currently a guest Senior Editor of a Special Issue of MISQ on “Digital Business Strategy.” Earlier he served as a guest Senior Editor of a Special Issue of MISQ on “Novel Perspectives of Trust in Information Systems” published in 2010, and as a guest Senior Editor of a Special Issue of JMIS on ‘Trust in Online Environments’ published in 2008. Eric Zheng is an associate professor in Information Systems at University of Texas at Dallas. He received his Ph.D from the Wharton School in 2003. His research interest includes business intelligence, data mining, economics of information and IT innovation. He has published papers in Management Science, MISQ, ISR, JOC, among others. Eric has been an active reviewer for almost all major journals in IS and has been AE for major conferences such as ICIS, CIST and WITS. He co-developed the SAS certificate program in business intelligence at UT Dallas and has been teaching classes on SAS and advanced modeling recently. Currently he is serving as external consultants for Yahoo!, Nielsen Netratings and Palydom on various projects including understanding users’ search behavior with sponsored search and diffusion of online games through facebook. Bin Gu is an Assistant Professor at the Mccombs School of Business, University of Texas at Austin. He received his Ph.D. from the Wharton School, University of Pennsylvania. His research focuses on electronic commerce, online social networks, information economics and IT strategy. His work has appeared in MIS Quarterly, Information Systems Research, Journal of Management Information Systems, Journal of Retailing, Decision Support Systems and others. Bin’s research won the ISR Best Paper award in 2008 and the Best Paper-in-Track Award of the 2007 International Conference on Information Systems (ICIS). Tutorial Description The tutorial will explain the importance of theorizing patterns of change in longitudinal data over time, how IS researchers can propose longitudinal hypotheses, and how LGM can help test such hypotheses. The tutorial will also describe the tenets of LGM and offer guidelines for applying LGM in IS research including framing timedependent hypotheses that can be readily tested with LGM. Moreover, the tutorial will also explain how to use LGM in SAS 9.2 with a hands-on application that will attempt to model the complex longitudinal relationship between IT and firm performance using longitudinal data from Fortune 1000 firms. The tutorial will also draw comparisons with other existing methods for modeling longitudinal data and discuss the advantages and disadvantages of LGM for identifying longitudinal patterns in data. Envisioned Activities During the Tutorial 1. Present and discuss the method of latent growth modeling for IS research 2. Demonstrate how to model common IS phenomena over time, such as understanding the longitudinal relationship between IT and firm performance 3. Demonstrate how to implement it in SAS Proc CALIS and TCALIS and other software 4. Discuss the advantages and disadvantages of LGM relative to existing tools for modeling longitudinal data. 5. Discuss and exchange ideas on the potential of LGM Special Requirements Note: Regular equipment includes a computer, projector and screen. ( ) Computers ( ) Internet Access (X) Others, Please specify: _While the tutorial does not require the participants to have a computer to actually use LGM, if the participants will have their own laptop with SAS 9.2, the tutorial facilitators will help them actually run LGM on their own computer.	academy;cross-sectional data;data mining;database;digital strategy;e-commerce;email;fax;framing (world wide web);google scholar;hands-on computing;icis;information systems research;internet access;journal of the association for information systems;lgm-30 minuteman;laptop;latent growth modeling;libre graphics meeting;management information systems quarterly;management information system;management science;ph (complexity);postal;requirement;richardson number;sas;search engine marketing;social sciences citation index;social network;theory;video projector;water industry telemetry standard;eric	Bin Gu;Paul A. Pavlou	2010			knowledge management;citation index;technology strategy;data science;computer science;information system;business intelligence;decision support system;assistant professor;management information systems;information economics	DB	-63.38880141466584	-13.810140140561836	147164
f0c462b312acb463deb971374ffeabd8f9a062ba	times of change, times of growth		Feels like ages in the past, the day that the founding of this journal was decided. It wasn’t that long ago, at the beginning of November of 2001, nor an unusual venue, the Society for Neuroscience Meeting in San Diego. But the memory of that meeting is far from the standard way to conduct business these days. Three would-be editors-in-chief (Erik De Schutter, David Kennedy, and myself) shook hands in a bar with Thomas L. Lanigan, the President of the prospective publisher (Humana Press). The encounter was brief and cordial: Mr. Lanigan tackled all substantive issues, but also stressed that his company was a rare example of successful family operation in the biomedical publishing world. Almost to reiterate these points, he was accompanied both by his wife and by the Humana managing editor (in the same spirit, his son, acting as marketing director, later attended the first few meetings of the Editorial Board). We were all certain that neuroinformatics was a field of great promise, and there was great excitement and enthusiasm for the planning of the journal, which would be launched within just 1 year. I had knownMr. Lanigan and the Humana team for quite some time as they publishedmy “Computational Neuroanatomy: Principles and Methods” book, and I knew that they would give us editors uncompromised autonomy and adequate resources to take full and effective responsibility for the scientific charge of the journal. These expectations were not betrayed, and we are truly proud of the long way the journal has come. Thomas Lanigan died last September. That same month, Humana Press was acquired by Springer, a larger publishing company that is extremely well known in the neuroscience and informatics communities. We are grateful to Humana and the Lanigan family for these very successful five years of productive collaboration. At the same time, this merger will open new opportunities for Neuroinformatics. The field is growing, and so is our journal, judging by the respect it commands among fellow scientists and by its top-ranking impact factor. However, further and sustainable growth also requires an increase in manuscript submissions and article flow. This will ensure ever greater visibility without compromising in the least the high scientific standards and the quality of the content. The switch to Springer will ensure wider circulation of our journal. Moreover, by the time this issue appears in press, the new online submission system, based on the widely adopted and familiar Editorial Manager, will be up and running. As always, Neuroinformatics solicits Original Articles, Minireviews, Commentaries, and News Items for consideration and publication. This very issue offers an exciting selection of examples of the broad-spanning field of neuroinformatics, ranging from brain imaging to neuronal morphology, from computational models to knowledge environments. By all means, this is the first journal dedicated to the establishment of the informatics infrastructure of neuroscience. Thomas Lanigan’s enthusiasm continues with our new publisher, and we hope that more and more authors will join in and contribute to developing this most powerful vision of the neuroscience of the future. Neuroinform (2007) 5:95 DOI 10.1007/s12021-007-0005-4	autonomy;cessation of life;community;computation;computational cybernetics;computational model;digital object identifier;enough enthusiasm to get things done;entity name part qualifier - adopted;file spanning;informatics (discipline);large;manuscripts;mathematical morphology;neuroanatomy;neuroinformatics;neuroscience discipline;prospective search;regulatory submission;springer (tank);venue (sound system);meeting;standards characteristics	Giorgio A. Ascoli	2007	Neuroinformatics	10.1007/s12021-007-0005-4	management;machine learning;artificial intelligence;autonomy;flow (psychology);enthusiasm;publishing;ranging;impact factor;neuroinformatics;informatics;computer science	Web+IR	-63.95903445873521	-19.015960298417344	147204
213d32c8e8a2269920b7ab02153f9743b25d17d2	microlaw-protecting hardware against competition by copyrighting it as a compilation of data	industrial property character sets;hardware books art quality control the institute editorial board quality management microprocessors parallel processing artificial intelligence computer society;copyright protection;reverse engineering copyright protection typefaces compilations;industrial property;character sets;reverse engineering	The author explains what copyright protection does not cover, stressing its limited applicability. He then discusses typefaces, which are not covered, and compilations (defined as an original selection or arrangement of preexisting materials or data), which are covered. He speculates on how the law on compilations could, in the context of reverse engineering, be used to confer copyright protection on hardware, which otherwise is not covered.<<ETX>>	compiler;reverse engineering	Richard H. Stern	1989	IEEE Micro	10.1109/40.16788	character encoding;computer science;operating system;reverse engineering	Security	-65.949374758668	-23.597982355878543	147244
4e1301faf53c929c733f7af8683ae7f60a91ba52	ict, public administration and democracy in the coming decade	coming decade;public administration	Yogi Berra was famous both as a baseball player and as a source of enigmatic epigrams which often carried a subtle truth. One of his most famous observations was that “the future ain’t what it used to be”. Translated, what Berra was saying was that our view of the future changes all the time and yesterday’s forecasts are often today’s source of wry amusement. For this reason amongst others, many academics believe that serious scholars should never attempt to write about the future or at least not beyond the short term. Longer term, events are all too likely to prove them wrong. The future is the domain of fortune tellers, tarot readers, astrologists and other non-scientific producers of “knowledge”; serious researchers should stay away from it. No empirical data about the future can be gathered and, as a consequence, it can never be investigated. Science should be about presenting adequate accounts of external reality on the basis of systematic empirical research. On the other hand academic scholarship is about theory and good theory is, inter alia, about prediction. And there is a great need for knowledge about the future. Knowledge about the future is important to strategists, technology developers, managers, politicians, policy-makers and ordinary citizens as a basis for informed decision making. In the domain of public administration, knowledge about the future is not only needed for policy-making, but also for an informed public debate about the desirability of certain trends and the need for a public response. Knowledge about global warming stands out as a type of knowledge that is desperately needed to guide our behavior and decisions. We need information about the dilemmas we may be facing in the future in order to make informed choices today about the development and use of new technologies. One problem for social scientists in general and for those that study new technologies in particular in that we are shooting at a moving target. We can study the present and the past, but when it comes to technology a question arises as to how reliable knowledge is when it comes to predicting the future.		Albert Jacob Meijer;Frank Bannister;Marcel Thaens	2012	Information Polity	10.3233/IP-120290	political science;public administration;economic growth	HCI	-65.79683970941086	-21.47176939914725	147433
31294cfc6674a2aed90efca7655534a107323ec7	legal aspects of web systems	google;copyright;contracts;ubiquitous computing contracts copyright internet patents;law;internet;patents;licenses;ubiquitous computing;law patents licenses google reverse engineering;trespass legal aspects web systems ubiquitous platform commercial activities information sharing activities legal issues copyright patents contracts;reverse engineering	The web offers a ubiquitous platform for commercial and information-sharing activities, which are realized by a broad spectrum of web systems. Not surprisingly, triggered by lawsuits, many legal aspects impacting web systems have emerged over time and they should be a concern for web systems operators, users and researchers. This paper identifies prominent legal issues relating to web systems access, content, design and code: copyright, patents, contracts, trespass, and others. Based on the identified issues we offer a number of observations on how the legal landscape has been shifting, on the role of contracts, and on the law's impact on case study research.	holism;user-generated content;virtual world;world wide web	Holger M. Kienle;Hausi A. Müller	2013	2013 15th IEEE International Symposium on Web Systems Evolution (WSE)	10.1109/WSE.2013.6642424	the internet;computer science;software engineering;database;internet privacy;law;world wide web;computer security;ubiquitous computing;reverse engineering	Embedded	-67.72191556417832	-9.891762885872215	147436
bdfa5ded0e2fcc8f40d1b1e4448dddbda4228b15	computer viruses and malware by john aycock	computer viruses	In the world of security, information is extremely valuable. Universities are the primary source of security related information with the exception of viruses and malware. For some reason, university administrators feel that teaching students about viruses and malware only to creates a larger problem. What they fail to realize is that the more people that understand the problem the more likely good solutions will be discovered. Associate Professor John Aycock and the University of Calgary in Canada took a more liberal approach to the problem: get the information to the students as early as possible. Consequently, Dr. Aycock set out to create a text book about viruses and malware. This review is about that book. This book is organized into 11 chapters. Each chapter is broken down into subchapters with specific information. It is laid out similarly to an outline. What I found unique with this book is the notes at the end of each chapter. All notes that are numbered 1-99 relate to additional material for that chapter. Notes starting at 100 are citations and references to related material. I found this type of distinction quite useful. This book is a concept book. Dr. Aycock points out in the preface that this book is not about implementation details, but on concepts. He also makes suggests that if the reader is using this book as a text book, the reader should supplement it with information regarding the latest malware issues.	computer virus;ieee john von neumann medal;malware;primary source	Michael Sanford	2010	SIGACT News	10.1145/1753171.1753184	computer science;computer virus	ML	-62.8630204300901	-20.66006574423136	147454
cae52a8f854dccb34fca3d3d2e0176c090dbf78d	to infinity and beyond: rhetorical methods in telecommunications economic policy discourse	spectrum auction;cyberspace;economic analysis;rhetorical methods;telematics;game theory;social construction;national information infrastructure;policy analysis;socio economic effects economics telecommunication government policies interactive television electronic messaging information networks frequency allocation technical presentation;territorial conceptions;transaction cost;commodity forms;political economy;electromagnetic spectrum auctions;individualism;consumer electronics;socially constructed problems;market area;public decision making;private sector policy debates;technical expertise;information networks;frequency allocation;information market;telecommunication;government policies;bargaining;electronic messaging;technical presentation;policy persuasion;bandwidth;electronic postal messages;transaction costs;private sector;exchange mechanism;economics;tv;interactive television;telecommunications economic policy discourse;h infinity control;bandwidth implications;h infinity control decision making telematics tv consumer electronics information analysis electromagnetic spectrum bandwidth game theory costs;electromagnetic spectrum;information analysis;economic policy;interactive television program content;negotiation;socio economic effects;transaction costs rhetorical methods telecommunications economic policy discourse policy analysis political economy technical expertise public decision making cyberspace commodity forms interactive television program content electronic postal messages socially constructed problems telematics national information infrastructure information market exchange mechanism policy persuasion public sector policy debates private sector policy debates electromagnetic spectrum auctions bandwidth implications territorial conceptions market area bargaining negotiation individualism;public sector policy debates	This paper proposes an interdisciplinary contribution to policy analysis with particular emphasis on the political economy of the new telecommunications. The rhetorical tropes produced by technical expertise and public decision-making suggest that new forms of policy analysis match the economic analysis challenges presented by telematics. Such policy analysis characterizes the commodity forms ranging from interactive television program content to electronic postal messages and cannot be reduced to price data. Terms such as cyberspace and national information infrastructure become important rhetorical figures in analyzing an information market that is not merely an exchange mechanism but a forum for policy persuasion. This paper examines some of the recent public and private sector policy debates regarding electromagnetic spectrum auctions and their bandwidth implications for the development of new territorial conceptions of market area. The debate over externalities should be seen as one where the problems of bargaining and negotiation are economic games which do not simply reflect individualism or transaction costs but also become complex socially constructed problems in communication.	bandwidth (signal processing);cyberspace;national information infrastructure;postal;telematics	Ann Z. Li	1996		10.1109/ISTAS.1996.541179	public relations;public economics;business;commerce	ECom	-76.93328438630562	-12.667793289308726	147503
308ea6141791880c84a3324b800e751124eb1aeb	a good man but a bad wizard. about the limits and future of transparency of democratic governments	icts;democracy;government;transparency;demystification	Computer-mediated transparency is seen as a powerful tool to attain policy goals and to transform government. This is based on the idea that transparency is something good in itself, which can be attained by using ICTs eventually improving government and citizen relations. This article claims that although transparency of government is necessary, scholars and practitioners tend to overestimate its positive effects and underestimate its negative effects. There is no reason to believe that transparency is always a good thing. Further, ICTs are not necessarily an effective means to increase transparency; there is an increased risk of information overload, cyber propaganda and inadvertent information release. Transparency might even drive citizens away from government as it gives way to a ‘gotcha’ media culture and political cynicism. Moreover, transparency has potential wide scale unforeseen and unintended consequences which eventually may affect society and economy. This is not a plea against transparency, but this article gives several pointers that the risks involved with disclosing information are much more complicated than the literature has yet fully acknowledged. This article concludes that the future of transparency may be twofold: more transparency of quantifiable performance indicators, but increased control of information flows that are at the heart of governments.	information overload;pointer (computer programming);unintended consequences;wizard (software)	Stephan Grimmelikhuijsen	2012	Information Polity	10.3233/IP-2012-000288	public relations;political science;management	Metrics	-74.04554940458955	-12.526657187403574	147615
daf87c8d2d6b3a9eb1e52c61f5ac539def78998b	the great machine theory of history	history iron software packages software engineering programming continuing education computer society heart job design computer vision;computer society;heart;history;iron;software engineering;computer vision;continuing education;job design;programming;software packages	Steve Jobs. The world of computing and computers is filled with strong individuals, who have left a lasting influence upon the field, and it is often tempting to write our histories around them. We often shape our views around the careers of Thomas J. Watson of IBM, Bill Gates at Microsoft or even Linus Torvald of Linux. This style of historical pursuit is known as the “Great Man” theory. The term was popularized by the English philosopher Thomas Carlyle in a series of lectures he delivered in 1840. Although his ideas became widely popular, the term “great man” was something of an anachronism even then. Even though a woman was the head of British state, Carlyle would not concede that a woman might be a Great Person. To avoid this difficulty, as well as a few other of Carlyle’s ideas that seem painfully dated, we will develop a great machine theory of history.1 The writers for this journal have devoted considerable time and attention to identifying great machines and great pieces of software. Such a list would certainly include John von Neumann’s computer at the Institute for Advanced Study, the ACE Pilot, the PDP 1, OS/360, Cobol 64, and the TCP Internet protocol, to name a few. This list is not intended to be exhaustive and no one should take offense if a favorite item was excluded. In interviewing computer scientists, I have often found that they cherish a certain machine or specific piece of software that would never make it onto our “great machine” list. In my own career, the Burroughs MCP operating system is far more important than it should be. It was not the first operating system I had seen, but because it’s simple, accessible, and adequately generalizable, I was able to make it a model for how an operating system should work. It was written in a high-level language, a variant of Algol called NEWP. I spent many hours poring over the source code listing to learn how it operated. For many contributors to these pages, their Great Machine or Great Software embodied just those principles: simple, accessible, yet general enough to serve as a model for later work. Although some of these products are identified with a single individual, they are in fact the product of a team. One person conceives it, another builds, a third manages, someone else finances, and a final person markets the product. The anthropologist Jared Diamond has articulated what he calls “the Anna Karenina Principle” as a tool for understanding social organizations. From Tolstoy’s great novel he quotes the opening line, “Happy families are all alike; every unhappy family is unhappy in its own way.”2 From this, he draws the lesson that all marriages (or social organizations) have to be successful at a number of things. They must get along socially, manage money well, have similar goals, and so on. Failure in any one of these areas means that the marriage will fail. Applying Diamond’s ideas to Great Machine theory, we can see at this vantage point in history, perhaps much more clearly than we could see even 10 or 20 years ago, that Great Machines and Great Software are produced by successful organizations. Our history is littered with products that failed because of bad financing, poor marketing, weak management, incomplete conception, or sloppy implementation. Great products are produced by great teams, or at least by teams on which a few members have some vision and the rest are at least adequate. This line of reasoning leads us to a somewhat negative answer to the question, What difference can an individual make? An individual can fail to meet a deadline, misguide an organization, or fail to see all the consequences of an idea. By this standard, all one individual can do is to keep a project from failing. It is, without question, an unfair way to characterize the contributions of talented men and women, but from a longer perspective on the first decades of the computer era, a perspective perhaps not gained for another hundred or so years, we will be impressed by the extent to which the design and operation of computers, software, and networks were a team effort. We will be equally impressed with the fact that these teams worked so well. Of course it is easy to make a hero of the team. When Tracy Kidder followed the development of the Data General Eagle computer in the late 1970s, he concluded that the project was successful because the designers worked well as a team. He dismisses conventional ideas about managerial control and economic motivation. Though he acknowledged that most managers would view the project as a triumph of entrepreneurial direction, Kidder states that it “seems more accurate to say that a group of engineers got excited about building a computer.” Kidder spent more than a year with the group, learning how they made their plans, did their work, and built the machine. The team consisted of young designers: “a dozen young neophytes, fresh from graduate schools of electrical engineering and computer science.” Data General management gave the team great latitude and authority in designing the computer, yet, at the same time, they demanded much. “You agreed to forsake, if The Great Machine Theory of History	ace;algol;cobol;computer science;computer scientist;eagle computer;electrical engineering;failure;high- and low-level;high-level programming language;ibm system i;linux;mcp;newp;operating system;pdp-1;thomas j. watson research center	David Alan Grier	2003	IEEE Annals of the History of Computing	10.1109/MAHC.2003.1226668	programming;computing;simulation;software engineering process group;job design;computer science;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;management;iron;computer-aided software engineering;heart;software system;computer engineering;software peer review	Theory	-64.09564600476325	-22.209427491229594	147630
f4d2228d73d104430b4102402e5b5a392f27b89c	full virtualization - bise's contribution to a vision		Some innovations, whose long history of success faded into the background in the course of time, come back in a refreshed form decades later initiated by marketing activities of some companies. In the field of information and communication technology (ICT) we can currently see a renaissance of virtualization. Already at the end of the 1960 s there had been mainframe computers originating from IBM’s family of /360 systems that used virtualization technology ready for series production. According to IBM, this was the most important product announcement in the company’s history. On a single system multiple users were able to simultaneously use independent virtual machines and thus reduce the need for additional and expensive hardware. This technological progress was not only an important foundation for IBM’s long lasting success story but also for many other companies. Just as in those days it is the economic factors that draw back the attention to virtualization today. True to the motto “Back to the Roots”, current ICT initiates a trend reversal from many decentralized back to centralized and powerful large-scale systems in order to reduce procurement, operating, and maintenance cost. In his masterwork “Summa technologiae” published in 1964, Stanislav Lem shows that more than forty years ago people dealt with virtualization not only as regards infrastructure but that also visions of an application existed which would change people’s lives. He outlined a “phantomatic machine” that allowed people who were connected to this machine to view and to experience fictitious situations, such as a balloon flight for instance. Today, these “machines” have become real and are called “cyberspace”, “virtual world”, or “virtual reality”. They are used as simulation systems, e. g. in pilot training or massive multiplayer online games such as Second Life with thousands of users. However, despite unmistakable parallels there have been some changes compared to the initial situation. Virtualization as it is being implemented today and is planned for tomorrow has left the infrastructural level long ago and has advanced to the economic and social structures of our society. Thereby, a range of topics with clear and exciting reference to business models, business processes, and their harmonized interaction with application systems and infrastructure emerges for business and information systems engineering (BISE) as a science. Moreover, virtualization also changes the relationship between man and machine and thus has an increasing impact on individuals and the social community. Where will this trend lead if we continuously advance and tap all its potential? It is these topics and issues that interest from a BISE perspective which we are trying to examine more closely with this special focus. But what is virtualization? According to the Oxford Dictionary, the term “virtual” has its etymological origins in the Latin word for “virtue”, “power”, and “capability” and means “what is possible due to aptitude or capability”. “Virtual” corresponds to the property of a non-existent entity to be equivalent to a real entity as regards form and effect. Thus, in a first approximation, virtualization is the mapping of existing structures or creation of new structures, with form and effect usually being generated with the help of information and communication systems (ICS). For BISE this particularly means detecting the economically reasonable need for action and creating the necessary prerequisites for transformation. In accordance with the approach “think big, start small” solutions are developed step by step, establishing opportunities that have to be evaluated again. The vision of full virtualization, which aims at universally mapping all the structures of our lives to ICS, could be a possible target of consequent advancement. What would the implications of this vision be for economy, society, and individuals if one thought it all the way through? The Authors	business process;centralized computing;cyberspace;dictionary;full virtualization;hardware virtualization;information system;mainframe computer;memory refresh;multi-user;order of approximation;parallels desktop for mac;procurement;renaissance;roots;second life;sensor;simulation;social structure;systems engineering;virtual machine;virtual reality;virtual world;x86 virtualization;aptitude	Hans Ulrich Buhl;Robert Winter	2009	Business & Information Systems Engineering	10.1007/s12599-008-0023-2	computer vision;simulation;computer engineering	Web+IR	-74.6996016716839	-10.989485963914987	147664
dea20b6ff38901628e54ca47606ab63b35f9b7b6	digital divide ii: global vs. local content. sponsored by sig iii	digital divide	Abstract#R##N##R##N#At ASIST 2001 conference, a digital divide panel session on issues, policies, and case studies were very well-received. This year, as a followup, three presenters will discuss how to bridge digital divide at local, regional, and global levels.		Hong A Xu;Peter Armstrong;Laura Seidel;Juan José Garcés-Iniesta;Mary Stansbury	2002		10.1002/meet.1450390163	digital divide;computer science;multimedia;world wide web	ML	-66.68844241949941	-12.66439994106146	147699
4103b8ec136ef80540713ad4cd6e4518be11b720	indices of journal citation relatedness and citation relationships among aquatic biology journals	oceanologie;citation analysis;scientometrics;isi institute for scientific information;marina;marine;oceanologia;bibliometric map;core collection;discipline;diario;analisis cita;disciplina;index;carte bibliometrique;biology;biologia;coleccion centro;journal;scisearch;analyse citation;scientometria;indice;science citation index;newspaper;scientometrie;classification automatique;automatic classification;clasificacion automatica;oceanology;biologie;collection coeur	Simple quantitative indices of pair-wise journal citation relatedness (based on the numbers of references given to and received from a journal title, which are provided by Science Citation Index database) are translated by an automatic clustering procedure into a meaningful map diagram reflecting topical relatedness of journals within a field of science. Such a map for 60 journals in marine and freshwater biology and related sciences published in 1987 reveals a tight cluster of marine biology journals quite distinct from the freshwater biology journal cluster and from the fisheries cluster. The journals within the marine biology cluster and those with strongest pair-wise links with them can be regarded as the core journals in marine biology. Indices of unilateral citation relatedness are used to obtain diagrams, which we term citograms. The citograms visualize patterns of citation relatedness of a journal (its citing and being cited). Journal self-citation can be meaningfully estimated using the bilateral index of relatedness. Self-citation is high in specialized or regional journal titles. It also appears to be quite substantial in journals of broader scope, which possibly reflect authors' subjective preferences.	aquatic ecosystem;bilateral filter;citation index;cluster analysis;diagram	Alexander I. Pudovkin;Elizabeth A. Fuseler	1995	Scientometrics	10.1007/BF02017642	discipline;social science;newspaper;scientometrics;computer science;data mining;sociology;operations research;citation analysis;world wide web	Comp.	-75.44936492113666	-22.192811769814003	147745
2d617a418ea99da797a61cb49c90f71e07395859	environmental sciences research in northern australia, 2000–2011: a bibliometric analysis within the context of a national research assessment exercise	excellence in research for australia era;q agriculture;62p12 applications to environmental and related topics;excellence in research for australia;journal article;fields of research codes;environmental sciences;northern australia;james cook university;bibliometric analysis;charles darwin university;92 biology and other natural sciences	This paper reports on a bibliometric analysis of environmental sciences research in northern Australia between 2000 and 2011. It draws on publications data for Charles Darwin University (CDU) and James Cook University (JCU) researchers to present a bibliometric profile of the journals in which they publish, the citations to their research outputs, and the key research topics discussed in the publications. Framing this analysis, the study explored the relationship between the two universities’ publications and their ‘fit’ with the environmental sciences field as defined by the Australian research assessment model, Excellence in Research for Australia (ERA). The Scopus database retrieved more records than Web of Science, although only minor differences were seen in the journals in which researchers published most frequently and the most highly cited articles. Strong growth in publications is evident in the 12 year period, but the journals in which the researchers publish most frequently differ from the journals in which the most highly cited articles are published. Many of the articles by CDU and JCU affiliated researchers are published in journals outside of the environmental sciences category as defined by Scopus and Web of Science categories and the ERA, however, the research conducted at each university aligns closely with that institution’s research priorities.	bibliometrics;control display unit;darwin;framing (social sciences);scopus;the australian;web of science	Jayshree Mamtora;Jacqueline K. Wolstenholme;Gaby Haddow	2013	Scientometrics	10.1007/s11192-013-1037-1	social science;media studies	Web+IR	-76.56432184981651	-21.016919706948993	147824
670b1ad1111e6c14dcbc376f8e9239ce0219ea2d	one for many: a metadata concept for mixed digital content at a state archive	digital content	The Landesarchiv (State Archive) of Baden-Württemberg has designed and implemented a metadata concept for digital content covering a heterogenous range of digital-born and digitised material. Special attention was given to matters of authenticity and to economic ingest and dissemination methods in line with the requirements of a public archive. This paper describes the outcome of discussions on metadata during the implementation period of the DIMAG repository. It addresses integration of the repository’s architecture with the archival classification concept, measures for long-term accessibility, the creation of adapted metadata placement, and provisions for exchange with other applications for ingest and use. The deliberately short list of metadata elements is included in this paper. Some existing standards have been evaluated under a real-use environment; this paper also introduces modifications applied to them in the project context. 1 This paper is based on the paper given by the authors at the 4th International Digital Curation Conference, December 2008; received July 2008, published October 2009. The International Journal of Digital Curation is an international journal committed to scholarly excellence and dedicated to the advancement of digital curation across a wide range of sectors. ISSN: 1746-8256 The IJDC is published by UKOLN at the University of Bath and is a publication of the Digital Curation Centre.	accessibility;archive;digital curation;digital recording;international standard serial number;requirement	Kai Naumann;Christian Keitel;Rolf Lang	2009	IJDC	10.2218/ijdc.v4i2.95	computer science;database;metadata;world wide web;meta data services;information retrieval;metadata repository	Visualization	-65.76556523015434	-15.434073518438524	147870
c083a0ec357ad1db2b476efbf303ca6309df2ad3	role of librarian in internet and world wide web environment	z665 library science information science	The transition of traditional library collections to digital or virtual collections presented the librarian with new opportunities. The Internet, Web environment and associated sophisticated tools have given the librarian a new dynamic role to play and serve the new information based society in better ways than hitherto. Because of the powerful features of Web i.e. distributed, heterogeneous, collaborative, multimedia, multi-protocol, hypermedia-oriented architecture, World Wide Web has revolutionized the way people access information, and has opened up new possibilities in areas such as digital libraries, virtual libraries, scientific information retrieval and dissemination. Not only the world is becoming interconnected, but also the use of Internet and Web has changed the fundamental roles, paradigms, and organizational culture of libraries and librarians as well. The article describes the limitless scope of Internet and Web, the existence of the librarian in the changing environment, parallelism between information science and information technology, librarians and intelligent agents, working of intelligent agents, strengths, weaknesses, threats and opportunities involved in the relationship between librarians and the Web. The role of librarian in Internet and Web environment especially as intermediary, facilitator, end-user trainer, Web site builder, researcher, interface designer, knowledge manager and sifter of information resources is also described.	digital library;heterogeneous computing;hypermedia;information retrieval;information science;intelligent agent;internet;librarian;library (computing);parallel computing;world wide web	K. Nageswara Rao;K. H. Babu	2001	InformingSciJ		library science;the internet;internet research;information science;computer science;multimedia;internet appliance;world wide web	Web+IR	-71.4245167141804	-23.25142763216582	147908
13eef7003cff879d0a1377da623d0903fdd64b30	lord of your domain, but master of none: the need to harmonize and recalibrate the domain name regime of ownership and control	domain name system;intellectual property;selected works;learning curve;nineteenth century;world wide web;bepress	The world has seen three waves of property. The fi rst hark back centuries and relate to ‘ real and personal property ’ such as land and chattel, also known as immovable and movable property. The second gained recognition around the nineteenth century and relates to propertization of the ‘ labours of the mind ’ or ‘ intellectual property ’ . The third wave came within a much shorter period and starting to gain recognition and it is what is known as ‘ virtual property ’ . The law and policy-makers have had to surmount not only a steep learning curve but also in some cases a foundation that is wrought with mistakes when it comes to the treatment that should be given to virtual property. The Domain Name System (DNS) is the best example of a form of virtual property that has given rise to challenges in law making and administration. The ‘ land grab ’ of domain names in the World Wide Web (WWW) have given rise to a virtual tsunami of registrations and this has led to the subsequent erection of levees in * Assistant Professor of Law, Singapore Management University. Executive Director, Society of International Law, Singapore. LLM in International Business Law, University College London, 2004. LLM in International & Comparative Law, Tulane University, 2001. LLB, National University of Singapore, 1996. Solicitor, England & Wales. Attorney & Counsellor at Law, New York. Advocate & Solicitor, Singapore. warrenchik@ smu.edu.sg	coherence (physics);effi;han unification;internet;money;procedural programming;requirement;super robot monkey team hyperforce go!;www;world wide web	Warren B. Chik	2008	I. J. Law and Information Technology	10.1093/ijlit/eam005	simulation;computer science;learning curve;law;world wide web;computer security;intellectual property;domain name system	DB	-64.87158175781427	-18.67494530394966	148033
3324bf4545d5e138a5bb7ee95524f45910fa73b9	"""what is """"dual use"""" research? a response to miller and selgelid"""	bioterrorism;pedestrian safety;poison control;injury prevention;weapons of mass destruction;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;security measures;engineering ethics;human factors;occupational safety;safety;safety research;accident prevention;violence prevention;humans;public policy;bicycle safety;poisoning prevention;falls;scientific research;ergonomics;development policy;suicide prevention;national research council;biomedical research	Dear editors:#R##N##R##N#The threat of terrorism has alerted many investigators, scholars, policy analysts, and politicians to the fact that the same piece of scientific research can often be used for good or malevolent purposes. The anthrax attacks in the autumn of 2001, the pursuit of weapons of mass destructions by terrorist organizations, and the publication of several articles related to enhancing the virulence of deadly pathogens, have created a sense of urgency to developing policies to regulate and control research with the potential for harm. In 2003, the National Research Council coined a term, “dual use research,” to describe the problem of preventing harmful uses of biotechnology research, and an entire literature has emerged devoted to this topic (National Research Council 2003).#R##N##R##N#In an article published in Science and Engineering Ethics in 2007, Miller and Selgelid provide an excellent overview of the ethical and political dilemmas related to dual use research in biology, some basic policy options for overseeing dual use research, and some advantages and disadvantages of these options (Miller & Selgelid 2007). They consider key issues, such as controlling access to materials and technologies, providing training for investigators, weighing the risks and benefits of publishing dual use research, and safeguarding freedom of inquiry. Though Miller and Selgelid offer many useful observations and insights, they fail to clearly define the most important term in their article—“dual use.”#R##N##R##N#A clear definition of “dual use” is necessary for effective oversight of research that can have harmful consequences. The definition should be neither too narrow nor too wide in scope. If the definition is too narrow in scope, e.g., if it focuses only on research involving a select class of biological or chemical agents, then it may encourage scientists and policymakers to overlook some types of dangerous research. One of the most controversial examples of dual use research did not involve research with dangerous microorganisms or chemicals but was an article describing a mathematical model of contaminating the U.S. milk supply (Wein & Liu 2005). The Department of Health and Human Services (DHHS) found out about the article prior to its publication in Proceedings of the National Academy of Sciences (PNAS) and asked the journal to not publish it. PNAS editors met with DHHS officials and heard their concerns about the article. They decided to publish the article despite its national security risks because, in their judgment, the benefits of publication far outweighed its risks, since the article contained information that would help public health agencies prevent or mitigate a terrorist attack (Alberts 2005). There are other types of dangerous research that might be overlooked if “dual use” is limited to particular experiments involving only dangerous microbes or chemicals, such as research that could be used to damage buildings or infrastructure, or disrupt computer networks or electric power grids.#R##N##R##N#If the definition of “dual use” is too wide in scope, however, it may be needlessly applied to relatively benign areas of science that only have a remote chance of being used by terrorists or others to cause harm. Assigning too much research to the category of “dual use” would impose additional administrative burdens on scientists, which would interfere with progress and innovation. Scientists already have to deal with sizeable administrative and regulatory burdens related research, such as approvals for human research or animal experiments, biosafety requirements, financial audits, and so on (Steneck 2007). Most scientists would not welcome the additional red tape associated with institutional or government oversight for dual use research.#R##N##R##N#The National Science Advisory Board for Biosecurity has proposed a definition of “dual use research of concern” as “research that, based on current understanding, can be reasonably anticipated to provide knowledge, products, or technologies that could be directly misapplied by others to pose a threat to public health, agriculture, plants, animals, the environment, or materiel” (National Science Advisory Board for Biosecurity 2008). While this definition is helpful, two key terms, “reasonably anticipated” and “threat”, require further clarification. What does it mean to “reasonably anticipate” an outcome? Must one believe the outcome has a non-zero chance of occurring? A 5% chance? A 10% chance? And what is a threat? Must a threat involve the loss of at least one human life? Ten lives? One hundred lives? A million dollars in economic losses? Ten million dollars? One hundred million? Questions like these must be addressed to limit the scope of the definition and apply it to specific cases.#R##N##R##N#Developing a clear and coherent definition of “dual use research” is an important task for ethics and public policy, but it is beyond the scope of this letter. Perhaps Miller and Selgelid and other scholars can tackle this problem in the future.		David B. Resnik	2009	Science and engineering ethics	10.1007/s11948-008-9104-3	psychology;public relations;scientific method;medicine;computer science;engineering;suicide prevention;human factors and ergonomics;injury prevention;sociology;management;operations research;law	Logic	-72.92115427763977	-13.516550439552931	148086
71fcd1753c5d95ee55e6c51112cd94ac973cde17	long-term digital preservation: preserving authenticity and usability of 3-d data	metadata;information technology;emulation;long term preservation;digital preservation;framework	Long-term digital preservation, the process of maintaining digital objects through time to ensure continued access, has become a crucial issue in recent years. Whilst the amount of digitised information is constantly increasing, so too is the pace of progress in information technology, resulting in obsolescence of the software and hardware required to access and view digital information. Despite many organisations recognising this threat and the resulting need for preservation action, more work is required to effectively address the issue. We present in this article a framework for the long-term digital preservation of 3-D data. This framework is based on two pertinent preservation practices, emulation and metadata which ensure that the authenticity and usability, respectively, of a preserved digital object remain intact through time. An evaluation of our framework is presented which illustrates the viability of our approach in retaining accessibility, authenticity and usability for future end users.	accessibility;anthropometry;case preservation;digital data;digital library;emergence;emulator;interaction technique;library (computing);relevance;requirement;usability;virtual artifact;while	Julie Doyle;Herna L. Viktor;Eric Paquet	2009	International Journal on Digital Libraries	10.1007/s00799-009-0051-7	emulation;computer science;software framework;multimedia;internet privacy;metadata;information technology;world wide web	HCI	-72.48072387701481	-13.763301400070613	148171
445837f78aebb0e18b133de3704aa70298e6e81e	increasing the enrollment of women in computer science	constructivism;competency based assessment;computer technology	Shari Lawrence Pfleeger The precipitous decline in women's enrollment in computer science since 1984 has to be addressed in new and creative ways. We must broaden our horizons and think of our students not only as potential compiler or operating systems designers but also as implementers of computerbased solutions to non-computing problems. There is a general trend, among women as well as men, to want to apply computing skills to a wide variety of disciplines outside the traditional software businesses. (Washington Post, 16 August 2000, Business section, p. 1). We can leverage this interest not by watering down our computer science curricula but by strengthening them and adding internships and team projects that apply skills to these outside disciplines. With such a program, a woman interested in finance might be attracted to a CS degree that enables her to intern at a brokerage house, bank, or insurance company, for example. Thus, we can expand from a degree in computing for computing's sake to computing and its place in the wider world. Such an approach appears to be successful in the UK, where departments of computing offer specializations in computer science, information science, and software engineering, often in partnership with industries that provide internships or support for team projects.	compiler;computer science;information science;operating system;software engineering;women in computing	Shari Lawrence Pfleeger;Pat Teller;Sheila E. Castaneda;Manda Wilson;Rowan Lindley	2001		10.1145/364447.364752	computing;computer science;knowledge management;constructivism	Logic	-68.12136058376262	-23.682293259256113	148513
15654bd483c5f7a3ebde28e8ec4e1bec61b952fe	book reviews		"""This work should have been noticed in these pages nearly a year ago, as it was published in June, 1896; but the reviewer has found it so crammed with interesting and important material that he has been led on to a complete study of it. Consisting as it does of nearly five hundred pages of close print, it has occupied the spare half-hours of many months in its perusal. We regard it as one of the most important works on surgery published in recent years in this country. Mr. Paget has himself had an unusually wide experience of the surgery of the chest, and he has sought with untiring industry in the medical literature of many countries for illustrations of the various surgical conditions he describes. In discussing the complications of fracture of the ribs, the author devotes a chapter to the study of surgical emphysema. We are a little astonished to find him saying, """" In simple fractures I have very seldom seen it, and have never seen"""		W.R. McKinzie	1987		10.1080/00401706.2017.1337996		HCI	-63.03671383663743	-22.533895289617504	148603
6519476dce9b984d50d2b6180d45a61431276fb9	a view from the dark side	genomics;industrial organization;plant genomics;artificial intelligence;computer hardware;economics;computational biology;biotechnology;expressed sequence tags;bioinformatics;mainframe computers	I n 1995, when I left a faculty position at the University of Pennsylvania to join the fledgling bioinformatics unit at what was then SmithKline Beecham Pharmaceuticals, the friendly jibes by academic colleagues about ‘‘going over to the Dark Side’’ were, I suspect, only half in jest. There weren’t all that many of us practicing bioinformatics at that time, and there was genuine concern that a brain drain to industry might curtail the training of a new generation. Dire talk of ‘‘eating our seed corn’’ made its way into print [1–3]. Other misgivings grew out of the first wave of human genome-wide data then arriving in profusion: the short single-pass cDNA sequences called expressed sequence tags (ESTs) that bubbled up new gene identifications seemingly on a daily basis and that appeared to be suddenly shortcircuiting the stately, hierarchical progression of the genome effort through ever-finer stages of mapping while breakthroughs in sequencing technology were labored after [4–6]. The data-management challenges arising from this heady sampling of the genome were making a strong impression, in both the public and private sectors, and the asyet-unresolved (and highly charged) question of the patentability of genes led to a land rush on intellectual property [7–9]. At the same time a surge of startups with liberal venture-capital grubstakes only increased the demand for skilled gene prospectors [10,11]. All these developments fed concerns that a reckless commercialization of the human genome would be somehow unfairly turbocharged by lavish spending and pure computational horsepower in industry, with legions of apostate academics mining the data.	academia (organization);avandia;bioinformatics;biopolymer sequencing;charge (electrical);color gradient;dark side;dosage forms;expressed sequence tags;intellectual property;sampling (signal processing)	David B. Searls	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030105	biology;genomics;computer science;bioinformatics;expressed sequence tag	Comp.	-65.39834119648836	-20.928239776332838	148860
e972c6f6db2bcaba5457d29cd8eaf1695d81ba86	presidential web sites and the georgian-russian war, 8-16 august 2008	war	During the war between Georgia and Russia, 8-16 August 2008, the Web sites of Presidents Mikheil Saakashvili and Dmitry Medvedev were used actively to promote their countries´ conflicting views on the war. This article considers the structure of the two Web sites, their use during the war and their place in the media systems of Georgia and Russia.		Robert W. Vaagan	2009	First Monday		public administration;war;law	ECom	-62.87414317961464	-13.294289182635195	149006
5901d15784f7023235f90be0228cec48f90850de	crumbs of the cookie: user profiling in customer-base analysis and behavioral targeting	behavioral targeting;internet marketing;user profiling;big data;marketing;topic models;economia y empresa;grupo a	Full terms and conditions of use: http://pubsonline.informs.org/page/terms-and-conditions This article may be used only for the purposes of research, teaching, and/or private study. Commercial use or systematic downloading (by robots or other automatic processes) is prohibited without explicit Publisher approval, unless otherwise noted. For more information, contact permissions@informs.org. The Publisher does not warrant or guarantee the article’s accuracy, completeness, merchantability, fitness for a particular purpose, or non-infringement. Descriptions of, or references to, products or publications, or inclusion of an advertisement in this article, neither constitutes nor implies a guarantee, endorsement, or support of claims made of that product, publication, or service. Copyright © 2016, INFORMS	algorithm;ar (unix);big data;central processing unit;consumer privacy;count data;cross-site cooking;digital marketing;download;institute for operations research and the management sciences;interaction;internet privacy;material design;online advertising;online shopping;parallel computing;profiling (computer programming);purchasing;requirements analysis;robot;sim lock;scalability;social network;temporal logic;triangulated irregular network;tucker decomposition;user profile;web search engine;world wide web	Michael Trusov;Liye Ma;Zainab Jamal	2016	Marketing Science	10.1287/mksc.2015.0956	behavioral targeting;big data;economics;marketing;advertising;topic model	Robotics	-68.0653212074631	-14.793520831204457	149118
5369849eb5616f73f0414a6f5befaf8d5213b872	interleaving tasks to improve performance: users maximise the marginal rate of return	interruption;interleaving;discretionary access control;multitasking;task management	NOTICE: this is the author’s version of a work that was accepted for publication in International Journal of Human-Computer Studies. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in International Journal of Human-Computer Studies, vol 71, issue 5, 2013, DOI 10.1016/j.ijhcs.2013.01.001	control system;forward error correction;marginal model	Geoffrey B. Duggan;Hilary Johnson;Petter Sørli	2012	Int. J. Hum.-Comput. Stud.	10.1016/j.ijhcs.2013.01.001	interleaving;real-time computing;human multitasking;discretionary access control;computer science;operating system;distributed computing	SE	-64.1715129148152	-16.58195581244497	149273
8123dc2da6db1c607553aa16644296732c823b56	data collection methods	methodology;science and technology	In Chapter 5 we reviewed the issues involved in selecting an appropriate research design and classified these into three categories — observation, experimentation and survey. In this chapter we are concerned primarily with the latter category and the collection of data using questionnaires, of the kind discussed in the preceding chapter, through the medium of personal interviews, mail and telephone surveys. However, the reader is reminded that the first step in developing a research design is to establish what is already known from existing published sources (the subject of Chapter 3) and that observation and experimentation will often precede any formal approach to respondents through survey research.	data collection	Richard J. Hanowski;Myra Blanco;A. Nakata;Jeffrey S. Hickman;William A. Schaudt;Maria C. Fumero;Rebecca L. Olson	1995	Hospital food & nutrition focus	10.1007/978-1-4614-6170-8_100691	data science;science, technology and society;data collection;business	NLP	-73.98785629100414	-17.818217564560154	149278
c9aa9742eb65318e220b70c6f84e654991d8eb1b	mail art: networking without technology	virtual community;networked art;ray johnson;art com electronic network;he transportation and communications;mail art;hm sociology;la mamelle;well;culture and technology;network culture	Focusing on the mail art movement and its legacy for other forms of networked art, this article looks at how historically, culture has accompanied technological change.The mail art movement provided separate but fertile ground to explore themes of disembodiment in a networked society prior to spread of digital technology. Surfacing in the 1950s and flourishing in the 1970s, at a time when computers and the internet were still largely the domain of military and government control, mail art challenged the threat of technocracy by making available metaphors and the experience of networking. Its goal of social connection inspired other networked arts, which eventually found a place among digital technology users.An unlikely but productive clash between artists and early users aided, validated and expanded the network ethos of early online social groups or ‘virtual communities’.This investigation shows how art clears the ground for social practices that technology instantiates.	computer;digital electronics;internet art;networked society	Seeta Peña Gangadharan	2009	New Media & Society	10.1177/1461444808099581	psychology;water well;social science;computer science;marketing;multimedia;sociology;world wide web	HCI	-77.42038498509966	-13.18515094388372	149331
13f3b485bc39e84aa4c37f591b971e9fba0e50d7	enterprise routing sinkholes using linux and open source tools	tecnologia electronica telecomunicaciones;tecnologias	Occasionally you'll see them on  the evening news or a photoblog�a previously forgotten septic tank or abandoned sewer line has opened up and swallowed somebody�s Volkswagen, and the puzzled owner is standing above his submerged car scratching his head. They�re called sinkholes, and the photos are amusing precisely because it�s happening to somebody else. So why would you, a sophisticated system and network administrator, want to inflict one on your enterprise?		Eric Sorenson	2006	;login:		simulation;engineering;cartography	OS	-65.14609672486006	-22.09790386024625	149435
64534c1e0748b77e9b5f52f07857c3271f1d5ef7	editorial: complex networks	complex network	This topical issue features regular submissions to Advances in Complex Systems focusing on ‘Complex Networks’ from different perspectives. They have been selected by the editors to appear together in this issue, to highlight current research trends. ‘Complex Networks’ is a booming research area for quite a few years now. Since the work of Watts and Strogatz on ‘small world networks’ published in 1998 (a paper for which Google Scholar lists 7417 citations as of 14th February 2009), a networkmania has exploded in many applied fields of science. This led to the rediscovery of various results already present in the mathematical literature on graphs. However, the increasing interest on networks also led to the rediscovery of some gems in sociology, including the work of Granovetter on social networks already published in 1973. Today, research on complex networks has expanded to various branches of science, ranging from biology to transportation, from economics to linguistics. Hence, it is becoming a truly interdisciplinary endeavor. It is worth noticing that the research in these areas is increasingly driven by available data, in addition to extending theoretical concepts to characterize these networks. The current topical issue reflects some of the recent activities. The first two papers apply the complex network approach to dynamic phenomena in molecular biology, while the next two papers focus on spatial networks. These are followed by papers focusing on economic networks and on networks describing human social interaction. Finally, the last paper demonstrates an application of the complex		Enrico Scalas;Frank Schweitzer	2009	Advances in Complex Systems	10.1142/S0219525909002118	computer science;mathematics;complex network	AI	-77.09008177737186	-18.362679890271732	149600
6fe749937964efc1021ba4ce4b70a59203082f6d	science gateways for the broader take-up of distributed computing infrastructures	science and technology	The WestminsterResearch online digital archive at the University of Westminster aims to make the research output of the University available to a wider audience. Copyright and Moral Rights remain with the authors and/or copyright owners. Users are permitted to download and/or print one copy for non-commercial private study or research. Further distribution and any use of material from within this archive for profit-making enterprises or for commercial gain is strictly forbidden.	archive;distributed computing;download	Tamás Kiss	2012	Journal of Grid Computing	10.1007/s10723-012-9245-0	computer science;management science;world wide web;science, technology and society	HPC	-67.16904033660317	-18.210515757742225	149614
40bb9169f9793d3ebd849fff43f50cbd8412793d	social engineering today: psychology, strategies and tricks	new lease;technology-based attack;past decade;latest technology;pre-internet day;technology perspective;social engineering technique	new lease;technology-based attack;past decade;latest technology;pre-internet day;technology perspective;social engineering technique	social engineering (security)	Steve Gold	2010	Network Security	10.1016/S1353-4858(10)70135-5	engineering;artificial intelligence;computer security	DB	-70.18942171457782	-10.746231593170503	149663
979e075c222652ad7f7ac9817bcea762fbf3226a	reengineering the university		new concepts. The Internet allows virtual classrooms. Digital libraries provide knowledge repositories. The Web offers up-to-date material for seminar discussions. Computer simulation substitutes for laboratories. Technology is not simply an add-on service as computers or audiovisual were before—it touches the very substance of the university, that is, knowledge development and transfer. A complete reengineering has to take place in order to retain the spirit of the university as an intellectual watering hole. The crisis in universities is both financial and structural. Most universities around the world are still largely dependent on public financing, but educational funds are drying up due to the general tightening in governmental budgets. In addition, academic research funds are also being cut. Governments frequently question the economic value of academic research. Meanwhile, companies are buying only relevant research and Universities are due for a radical restructuring. After centuries of evolu-	add-ons for firefox;code refactoring;computer simulation;digital library;information repository;internet;library (computing);watering hole attack;world wide web	Dennis Tsichritzis	1999	Commun. ACM	10.1145/303849.303867	process management;business process reengineering;business	Web+IR	-68.5315739360511	-23.671727381294712	149753
5225462b99e75fc2e3f5b8432517c8a766e3735a	collaborative networks of memory institutions in digitisation initiatives	libraries;bibliotheque;archivos;europa;museo;comparative analysis;musee;digitizing;cooperation;reseau;numerisation;cooperacion;museums;red;team working;modelo;content analysis;team work;collaborative networks;resource sharing;networking;archives;travail equipe;trabajo equipo;numerizacion;museum;modele;digital storage;europe;professional association;biblioteca;models;library;network;design methodology	Purpose – The purpose of this paper is to research the approach of memory institutions to collaboration by analysing collaboration patterns in the networks developed in digitisation initiatives.Design/methodology/approach – Qualitative and quantitative content analysis of the comments about partners and contractors made by respondents of the NUMERIC survey on the progress of digitisation in European cultural institutions was performed. Several attributes of collaborative networks of memory institutions were analysed: their size, members by type of organisation, and visibility of collaborators of particular type. Additionally, comparative analysis of collaborative networks of archives, libraries and museums was carried out.Findings – Memory institutions did not approach collaboration strategically. They exhibited a low engagement in collaboration and focused on establishing resource‐sharing networks. Many of them established networks with the institutions of the same type.Research limitations/implications ...	collaborative network	Zinaida Manzuch	2011	The Electronic Library	10.1108/02640471111141070	shared resource;qualitative comparative analysis;professional association;teamwork;design methods;library;content analysis;telecommunications;computer science;multimedia;sociology;management;operations research;world wide web;cooperation	Logic	-74.58336796619376	-21.5557221663734	149802
3cc72dc5cf2b9d29d28103d061ddc578884e3aeb	the foundation of the concept of relevance		In 1975 Tefko Saracevic declared “the subject knowledge view” to be the most fundamental perspective of relevance. This paper examines the assumptions in different views of relevance, including “the system’s view” and “the user’s view” and offers a reinterpretation of these views. The paper finds that what was regarded as the most fundamental view by Saracevic in 1975 has not since been considered (with very few exceptions). Other views, which are based on less fruitful assumptions, have dominated the discourse on relevance in information retrieval and information science. Many authors have reexamined the concept of relevance in information science, but have neglected the subject knowledge view, hence basic theoretical assumptions seem not to have been properly addressed. It is as urgent now as it was in 1975 seriously to consider “the subject knowledge view” of relevance (which may also be termed “the epistemological view”). The concept of relevance, like other basic concepts, is influenced by overall approaches to information science, such as the cognitive view and the domain-analytic view. There is today a trend toward a social paradigm for information science. This paper offers an understanding of relevance from such a social point of view.	information retrieval;information science;point of view (computer hardware company);programming paradigm;relevance	Birger Hjørland	2010	JASIST	10.1002/asi.21261	social science;computer science;knowledge management;data mining	NLP	-73.45405988623014	-17.975546580801424	149822
642076a2efa964bdb5515901c56f901b0d3fa8dd	netbill: an internet commerce system optimized for network delivered services	electronic commerce;business;prototype;public policy;protocols;privacy;world wide web;information services;information goods;computer science;internet	Netbill is a business model, set of protocols, and software implementation for commerce in information goods and other network delivered services. It has very low transaction costs for micropayments (around 1¢ for a 10¢ item), protects the privacy of the transaction, and is highly scalable. Of special interest is our new certified delivery mechanism which delivers information goods if and only if the customer has paid for them. This paper discusses the design of the NetBill protocol and our World Wide Web (WWW) prototype implementation Introduction As the explosive growth of the Internet continues, more people rely on networks for timely information. However, since most information on the Internet today is free, intellectual property owners have little incentive to make valuable information accessible through the network. There are many potential providers who could sell information on the Internet and many potential customers for that information. What is missing is an electronic commerce mechanism that links the merchants and the customers. NetBill is a business model, set of protocols, and software implementation allowing customers to pay owners and retailers of information. While NetBill will enable a market economy in information, we still expect that there will be an active exchange of free information. The market for information Porat and others have shown that information industries dominate the economy [1]. Estimates of the market for on-line information vary from $10 billion to $100 billion per year depending upon how the market is defined [2]. There are more than 15,000 databases accessible over networks. Vendors can distribute information products varying from complex software valued at thousands of dollars per copy, to journal pages or stock quotes valued at a few pennies each. A challenge for network-based electronic commerce is to keep transaction costs to a small fraction of the cost of the item. The desire to support micropayments worth only a few pennies each is a driving factor in the NetBill design. A second challenge in the information marketplace is supporting micromerchants , who may be individuals who sell relatively small volumes of information. Merchants need a simple way of doing business with customers over networks, so that the costs of setting up accounting and billing procedures are minimal. A model for micromerchants is the French Minitel system, which provides 20,000 “kiosks” offering computer-based services to Minitel users. Many of these kiosks are provided by small entrepreneurs who enter the marketplace for little more than the cost of a PC and the labor to acquire or develop valuable information. The purchase of goods over a network requires linking two transfers: the transfer of the goods from the merchant to the customer, and the transfer of money from the customer to the merchant. In the case of physical goods, a customer can order the goods and transfer money over the network, but the goods cannot be delivered over the network. Information goods have the special characteristic that both the delivery of the goods and the transfer of money can be accomplished on the same network. This allows for optimizations in the design of an electronic commerce system. A NetBill scenario Figure 1 shows NetBill’s model. A user, represented by a client computer, wishes to buy information from a merchant’s server. A NetBill server maintains accounts for both customers and merchants. These accounts are linked to conventional financial institutions. A NetBill transaction transfers the information goods from merchant to user, and debits the customer’s account and credits the merchant’s account for the value of the goods. When necessary, funds in a customer’s NetBill account can be replenished from a bank or credit card; similarly funds in a merchant’s NetBill account are made available by depositing them in the merchant’s bank account. The transfer of an information good consists of delivering bits to the customer. This bit sequence may have any internal structure, for example, the results of a database search, a page of text, or a software program. Users may be charged on a per item basis, or by a subscription allowing unlimited access, or by a number of other pricing models.	client (computing);computer program;database;e-commerce;electronic billing;internet;micropayment;minitel;money;online and offline;our world;personal computer;prototype;scalability;server (computing);www;world wide web	Marvin A. Sirbu;J. Doug Tygar	1995		10.1109/CMPCON.1995.512358		ECom	-68.25065167662888	-18.91625520644021	149923
d45da564cf2acf14df64aaed30dfa49b17eea7d1	the harvest object cache in new zealand.	harvest;caching;internet traffic;rest of the world;world wide web;new zealand	Abstract   No New Zealand government funding has ever been directed towards Internet development. The Internet in New Zealand has always been funded at least in part by charges to users. This, combined with the high cost of bandwidth to and from New Zealand, has triggered more rapid and widespread adoption of World Wide Web caching than has been seen in most countries.  This paper gives a brief history of the development of the Internet in New Zealand. It describes the use of WWW caching in New Zealand between 1993 and January 1996, concentrating particularly on the deployment of the Harvest Cache software. This software entered production use in October 1995, and less than four months later a single server using it processes the equivalent of around 5% of all Internet traffic between New Zealand and the rest of the world.  The deployment of Harvest Cache software in a number of other countries is briefly described. The results of a survey of New Zealand WWW cache users are presented, indicating that priorities are different for identifiable types of user organisation.  Issues raised by the commercialisation of international bandwidth provision are discussed, and expected development of the Harvest software is outlined.		Donald Neal	1996	Computer Networks	10.1016/0169-7552(96)00077-3	harvest;simulation;internet traffic;telecommunications;computer science;world wide web;computer security;computer network	Theory	-67.52880882894144	-13.281565997426302	150144
1ba11653b32dbf0fb08dac7be8c2b1d6c2a8f363	letters to the editor: on obtaining technical information from the federal government	trademark;copyright;patent;federal government;proprietary;software protection	concerning proprietary software packages. I agree with Fincrman's basic comment that the original letter raises two questions : (1) the free and open exchange of software packages; and (2) the availability of software descriptions referenced in professional publications. The Sun Oil Company has sold, bought, and traded such packages and has received and given some away free. A software package created by Sun Oil Company employees as part of their assigned duties represents a Sun Oil Company asset just as much as does an invention, or a design, or a trade secret, or any form of proprietary information. The decision as to whether to use this package only within Sun, or offer it for sale, or give it away to the public is a management decision that must be made in line with the company's responsibilities to its employees, stockholders, customers, and the public. It is the kind of decision that our company management makes frequently in the case of other proprietary information and the same criteria are applied. In broad terms, the proprietary information that we think might harm our competitive position if released is kept within the company • The proprietary information that we think would yield more in sale revenue than the harm we would suffer because of its use by others we offer for sale with appropriate secrecy agreements. The proprietary information whose wide use would be in the best interest of the public at large, we release for public use. We treat our proprietary software packages in this way, and we would expect other private, profit-oriented organizations to do the same. We consider proprietary software packages to be articles of commerce just as any other invention, design, piece of proprietary information, or manufactured item is. We find that software packages can be evaluated prior to sale, and we do this as a matter of course. We find that where the construction of the package is important to our use, we can arrange to examine this if we agree to suitable restrictions as to disclosure. We consider this to be hardly any different from our requirement that we evMuate the performance and general design of any machine or computer that we plan to rent or buy. With regard to the second point, the availability of software descriptions referenced in professional publications, I find myself in both agreement and limited disagreement with Finerman. I agree that a …		Currie S. Downie	1969	Commun. ACM	10.1145/363011.363022	data mining	SE	-66.80698888547366	-20.3741791916288	150158
5e91e3a719d383ac503ba017ce108df7c7ce947a	editing in jamaica 1989-1998	printing;conference volumes;journal of the geological society of jamaica;contributions to geology uwi mona	Despite changes in technology that have improved both production and the final product, small local journals still have a low profile and struggle to obtain adequate copy, in terms of both quality and quantity. My experiences as editor of two small journals in Jamaica in the 1990s provided similar problems to those that are encountered by many editors today. Endeavour to persevere, but, if you are not appreciated, be prepared to resign in order to retain your own respect. There will always be more jobs for good editors.	endeavour software project management;experience;job stream	Stephen K. Donovan	2016	Publications	10.3390/publications4020010	library science;geography;operations research	Networks	-67.32187499412285	-20.358066448970916	150256
8e49dead71f1203ca7777171a1b6af65ba8c6310	revisiting the landscape of literatures: replication and change in the use of subject collections		Paul Metz is Collection Management Assistant to the Dean for Special Projects at Virginia Tech; e-mail: pmetz@vt.edu. The author wishes to thank Eileen Hitchingham, Dean of Libraries, for her gracious suggestion that he revisit the “who uses what?” question and Debbie Averhart and Barbara Moore of the library staff for their assistance in gathering and organizing the data. Circulation data from the Virginia Tech Libraries were analyzed to determine the extent of continuity or change between the author’s study of the use of subject collections in 1982 and the present. Book circulation has declined, largely due to much less use by undergraduates. The overall profile of subject use has changed in ways traceable to changes in the population of active library users. Disciplinary groups who still rely on library monographs do so in ways strikingly similar to their behavior in 1982, and the findings strongly replicate the earlier findings that were most suggestive for library practice and the sociology of knowledge.	all things vice;email;library (computing);organizing (structure);scott continuity;self-replication;technical support;traceability	Paul Metz	2011	C&RL		psychology;library science;discipline;social science;library;computer science;media studies;sociology;data analysis;management;world wide web	HCI	-69.05598187676789	-19.46340587828386	150276
e5c3d658bf9ed37a8f916722b3349ed35f6ec3f7	the closed world: systems discourse, military strategy and post wwii american historical consciousness	sage;systems;closed system;computer systems;artificial intelligent;strategy;military systems;artificial intelligence;sdi;discourse;political culture;sci	This essay proposes a cultural and historical explanation for the American Military's fascination with computing. Three key elements of post-WWII US political culture — apocalyptic struggle with the USSR, subsuming all other conflicts: a long history of antimilitarist sentiment in American politics; and the rise of science-based military power — contributed to a sense of the world as a closed system accessible to American technological control. A developing scientific systems discourse, centrally including computer science and AI, was adopted for strategic thinking and military technology. The Strategic Computing and Strategic Defense Initiatives are discussed as contemporary examples of this conjunction.	closed system;computer science;consciousness;fascination	Paul N. Edwards	1988	AI & SOCIETY	10.1007/BF01908547	military science;strategic defense initiative;strategy;computer science;artificial intelligence;system;sociology;military theory;political culture;closed system;strategic goal;operations research;law	AI	-65.73261805002373	-12.76885923702118	150398
faa1f9dfc26c672d2efdb5327f51be8a5287d335	internet surveillance: recent u.s. developments		The U.S. Federal government has implemented both technologies and policies related to Internet surveillance. While the recent discussion tends to focus on the USA Patriot Act following the September 11 terrorist attacks, the U.S. Congress held hearings addressing Internet surveillance and Fourth Amendment protections as early as April 2000. At this point, Congress criticized the lack of oversight on the Federal Bureau of Investigationʼs Internet surveillance system, Carnivore.	carnivore (software);computer and network surveillance;internet	Juri Stratford	2004			internet privacy;the internet;business	ML	-69.44762274301218	-10.93059893673506	150412
015bcf72ee2f231c2aa2d12fc2335b703f73207c	artificial intelligence techniques and methodology	artificial intelligent	Two closely related aspects of artificial intelligence that have received comparatively little attention in the recent literature are research methodology, and the analysis of computational techniques that span multiple application areas. We believe both issues to be increasingly significant as Artificial Intelligence matures into a science and spins off major application efforts. It is imperative to analyze the repertoire of AI methods with respect to past experience, utility in new domains, extensibility, and functional equivalence with other techniques, if AI is to become more effective in building upon prior results rather than continually reinventing the proverbial wheel. Similarly, awareness of research methodology issues can help plan future research buy learning from past successes and failures. We view the study of research methodology to be similar to the analysis of operational AI techniques, but at a meta-level ; that is, research methodology analyzes the techniques and methods used by the researchers themselves, rather than their programs, to resolve issues of selecting interesting and tractable problems to investigate, and of deciding how to proceed with their investigations. A public articulation of methodological issues that typically remain implicit in the literature may provide some helpful orientation for new researchers and broaden the perspective of many AI practitioners.		Jaime G. Carbonell;Derek H. Sleeman	1982	AI Magazine	10.1609/aimag.v3i2.371	progress in artificial intelligence;computer science;engineering;artificial intelligence;management science;operations research	AI	-72.92533716026048	-15.999922911351497	150491
f201b1b6ed93a6bae14fbc1e869ab81aa7778895	information systems solutions for environmental sustainability: how can we do more?		We contend that too few information systems (IS) academics engage in impactful research that offers solutions to global warming despite the fact that climate change is one of the most critical challenges facing this generation. Climate change is a major threat to global sustainability in the 21st century. Unfortunately, from submissions of our call for papers presenting IS solutions for environmental sustainability, we found only one paper worthy of publication. Given that IS have been the major force for productivity increases in the last half-century, we suggest that IS scholars should immerse themselves in creating solutions for environmental problems. Moreover, information is a perquisite for assessing the state of the environment and making appropriate decisions to ameliorate identified problems. Indeed, the IS scholarly community needs to help create a sustainable society. While there is an emerging body of IS scholarship under the banner of green IS, we strongly believe that we need to step up these efforts. Our experience indicates that the emergence of green IS as an academic discipline is still by far too slow relative to the needs of society. Too few people are working on green IS given its importance, and fewer still are publishing papers about IS solutions that could contribute to dealing with climate change. In this editorial, we speculate on some reasons for why and explore how the IS discipline can grasp the opportunity to contribute to one of the most important societal challenges of our time. We identify the major barriers that we assert curtail the involvement of IS scholars in green IS research; namely, incentives misalignment, the low status of practice science, data analysis poverty, identification of research scope, and research methods. We discuss each barrier and propose solutions for them.	information systems	Roya Gholami;Richard T. Watson;Helen Hasan;Alemayehu Molla;Niels Bjørn-Andersen	2016	J. AIS		psychology;social science;computer science;environmental resource management;marketing;management information systems;management science;sociology;climate change;management;social psychology;internet of things	EDA	-76.15645917663916	-10.940320538552438	150711
4b5f5f63d210aaf2ecad1d5e3dcc9a2566425cd8	clinical informatics board specialty certification for physicians: a global view	biological patents;biomedical journals;text mining;europe pubmed central;informatics workforce;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;physicians;rest apis;orcids;europe pmc;biomedical research;board certification;clinical informatics;bioinformatics;literature search	Clinical informatics workforce development is a high priority for medicine. Professional board certification for physicians is an important tool to demonstrating excellence. The recent recognition of clinical informatics as a subspecialty board in the U.S. has generated interest and excitement among the U.S. informatics community. To determine the extent of similar programs in countries around the world, we performed literature searches with relevant keywords and internet searches of websites of informatics societies around the world for mentions or descriptions of certifications and reviewed publicly available sources. The U.S. certification was prominent in the recent published literature. Germany and Belgium have long-standing certifications with South Korea and Sri Lanka considering similar programs. This is the first global view of clinical informatics board certification for physicians. Training and certification for non-physician informatics professionals in allied areas are widespread. Official recognition and certification for physicians and all informatics professionals represents a key component of capacity building and a means of addressing the shortage of a skilled informatics workforce. Wider adoption of certification programs may further attracting talent and accelerate growth of the field.	board certification;description;informatics (discipline);scientific publication;societies	Adi V. Gundlapalli;William W. Greaves;Denece Kesler;Peter Murray;Charles Safran;Christoph U. Lehmann	2015	Studies in health technology and informatics	10.3233/978-1-61499-564-7-501	health administration informatics;business informatics;health informatics;public health informatics;family medicine;medicine;data mining	HCI	-71.57176931262512	-20.225150297669767	150818
c36980e0dcec3f3fceab5483422992e74da86b1f	five questions... for john seely brown				Lisa Gualtieri	2006	eLearn Magazine	10.1145/1145652.1145654	library science;knowledge management;computer science	Theory	-62.99942895217403	-10.918413109151425	150878
3472dc7cbd5a33bc0abf5f08e0441f48017faf8e	trends in scientific research in online information review. part 1. production, impact and research collaboration.		The study, based on the Web of Science, analyses 758 articles published from 2000 to 2014. Our analysis includes the publications’ output, authorship, institutional and country patterns of production, citations and collaboration. A Social Network Analysis was conducted to identify primary groups of researchers and institutions and the collaboration between countries.	social network analysis;web of science;world wide web	Rafael Aleixandre-Benavent;Carolina Navarro-Molina;Remedios Aguilar-Moya;David Melero-Fuentes;Juan Carlos Valderrama Zurián	2017	CoRR		social network analysis;data science;scientific method;knowledge management;citation;computer science	NLP	-76.7838830265647	-20.151786454555243	150941
71a6f48b9a2e5c0f630677dd63c2c62a5cf53538	viewpoint: information economics and the internet	information good;servicos de informacao;information access;internet;information economics;search cost;profitability;exponential growth;networked systems;armazenamento e recuperacao da informacao	Information economics offers insights into the dynamics of information across networked systems like the Internet. An information marketplace is different from other marketplaces because an information good is not actually consumed and can be reproduced and distributed at almost no cost. For information producers to remain profitable, they will need to minimize their exposure to competition. For example, information can be sold by charging site access rather than information access fees, or it can be bundled with other information or “versioned.” For information consumers, a variation of Malthus' law predicts that the exponential growth in information will mean that specific information will become increasingly expensive to find, because search costs will grow but human attention will remain limited. Furthemore, the low cost of creating poor-quality information on the Web means that the low-quality information may eventually swamp high-quality resources. The use of reputable information portals on the Web, or smart search technologies, may help in the short run, but it is unclear whether an “information famine” is avoidable in the longer term.	internet;viewpoint	Enrico W. Coiera	2000	JAMIA	10.1136/jamia.2000.0070215	exponential growth;the internet;search cost;information economics;data mining;information good;profitability index	ECom	-69.1991705735386	-22.455138652237704	150963
35e31f21f1acb8addfd827ad51070aa0df051d11	studies on utilizing the three famous international index systems to evaluate scientific research level of higher learning institutions	istp;citation index;combinative factor;ei;sci	Science Citation Index (SCI), The Engineering Index (EI), and Index to Scientific & Technical Proceeding (ISTP) are widely accepted and used to evaluate the scientific research level of higher learning institutions by many countries’ science and technology field currently. After research, the authors point out the blemishes in this method and put forward the problems that need to be noticed, and then, under current conditions, bring forward brand-new standards and methods to estimate research level, efficiency, and fund exploitation. One shouldn’t over-emphasize the total amount of papers collected in SCI, EI & ISTP when evaluating the scientific research level of higher learning institutions, whereas using ‘comprehensive factor’ analysis method can make it more scientific and efficient. DOI: 10.4018/978-1-4666-2782-6.ch010	binary prefix;citation index;exploit (computer security);factor analysis	Xun Liu;Changyu Huang;Wei-Liang Qian;Yong-Chang Huang	2011	IJSITA	10.4018/jsita.2011040105	computer science;data science;management;operations research	HPC	-76.85061380027435	-21.022655108873785	151139
467fbd1b7fc114663bc3dec68d8673c01cc8550a	relying on electronic journals: reading patterns of astronomers	etude utilisateur;etude utilisation;electronic journal;north america;america del norte;selected works;amerique du nord;astronomia;amerique;electronic periodical;user study;astronomie;reading;estudio utilizacion;periodique electronique;sociedad cientifica;estudio usuario;chercheur;user preferences;etats unis;estados unidos;research worker;lecture;comportement utilisateur;learned society;bepress;user behavior;societe savante;astronomy;investigador;lectura;america;periodico electronico;comportamiento usuario;use study	Surveys of the members of the American Astronomical Society identify how astronomers use journals and what features and formats they prefer. While every work field is distinct, the patterns of use by astronomers may provide a glimpse of what to expect of journal patterns and use by other scientists. Astronomers, like other scientists, continue to invest a large amount of their time in reading articles and place a high level of importance on journal articles. They use a wide variety of formats and means to get access to materials that are essential to their work in teaching, service, and research. They select access means that are convenient—whether those means be print, electronic, or both. The availability of a mature electronic journals system from their primary professional society has surely influenced their early adoption of e-journals. Introduction	high-level programming language	Carol Tenopir;Donald W. King;Peter B. Boyce;Matt Grayson;Keri-Lynn Paulson	2005	JASIST	10.1002/asi.20167	operations research;reading	HCI	-71.29715619026138	-22.491198913261965	151485
a74ba808b7d2b5aab46a928e8d43315bb7557b58	progress in documentation: museum documentation	information systems;problems;museums;international programs;records forms;cataloging;national programs;computer oriented programs;documentation	A survey of the current state of documentation practice in museums is presented. This concentrates on the broad themes of the practice, making comparisons with analogous library procedures, where appropriate. A brief introduction to museums and their organizational framework within the United Kingdom is given. With this as background, the methods of documentation used by museums are reviewed, and a survey presented of current developments on an international and national scale.	documentation	D. Andrew Roberts;Richard B. Light	1980	Journal of Documentation	10.1108/eb026691	library science;documentation;computer science;documentation science;multimedia;world wide web	SE	-71.96619169120251	-19.681392737164	151541
455f6df8f345edc43491d2a3f2d65e2c8f296693	privacy and security in public health: maintaining the delicate balance between personal privacy and population safety	bioterrorism;case report;surveillance;avian influenza;event detection;laboratory tests;influenza;protection;privacy security public healthcare health and safety surveillance protection influenza bioterrorism event detection laboratories;health and safety;security;early detection;public healthcare;privacy;public health;public health surveillance	Amidst threats of pandemic avian influenza and bioterrorist attack, public health surveillance and preparedness have never been more important. Early detection of biological events, electronic reporting of laboratory test results, efficient exchange of case reports across jurisdictions, and timely alerting of health threats are critical components of effective health protection. Essential to public health surveillance and preparedness is the timely availability of information relating to individuals¿ healthcare behaviors and clinical conditions -- posing a threat to personal privacy. Public health is challenged to maintain an optimal balance between protecting the nation¿s health and respecting the personal privacy of its citizens.	privacy	Dixie B. Baker	2006	2006 22nd Annual Computer Security Applications Conference (ACSAC'06)	10.1109/ACSAC.2006.41	public health;information privacy;computer science;information security;internet privacy;privacy;computer security	Security	-73.25178846801856	-13.180296433144921	151658
f093f5e3eb5807153d7dfe0129d1f7f2ea0fe2e8	two papers on existential graphs by charles peirce	humanidades;filosofia etica	The following two articles comprise two sets of Charles Peirce’s manuscripts, “Recent Developments of Existential Graphs and their Consequences for Logic” (MS 498, MS 499, MS 490 & S-36, 1906) and “Assurance through Reasoning” (MS 669 &MS 670, 1911), written for the National Academy of Sciences meetings in 1906 and 1911. The papers are deposited at Houghton Library, Harvard University. Only some parts of MS 470 have been published before, and in somewhat defective form. Although “Assurance” follows “Recent Developments” chronologically, given the expository style of the former it is recommended to be read before “Recent Developments”. As the title indicates, in the latter Peirce goes on to describe his latest discoveries concerning the method and the logic of existential graphs. The transcription reproduces all significant deletions that appear in the original sheets. Editorial comments and additions are given in brackets. [Alt.:] means the beginning of an alternative sequence. [Del.:] means the beginning of sections that have been crossed out. A couple of paragraph skips have been added to improve readability. In all other respects the transcriptions are diplomatic.	academy;alt attribute;existential graph;transcription (software)	Ahti-Veikko Pietarinen	2014	Synthese	10.1007/s11229-014-0498-y	philosophy	ML	-63.23567175214513	-20.282526173747062	151754
1e39a6915358cf883288d2f75fdd1b0e8ed15579	the crystallographic information file (cif)	machine readable dictionaries;crystallographic information file;file structure;archiving;crystallography	The Crystallographic Information File (CIF), owned by the International Union of Crystallography, is a file structure based on tag-value ASCII pairs with tags defined in machine-readable dictionaries. The crystallographic community publishes and archives large quantities of numeric information generated by crystal structure determinations, and CIF's acceptance was assured by its adoption as the submission format for Acta Crystallographica and by the obvious needs of the community. CIF's strength lies in its dictionaries, which define most of the concepts of crystallography; its weakness is the difficulty of writing software that exploits its full potential.	crystallographic information file	I David Brown;Brian McMahon	2006	Data Science Journal	10.2481/dsj.5.174	computer science;database;file format;world wide web;crystallographic information file	Theory	-66.84918283985178	-16.638497214997873	151837
c0d8c921313e3541952fd37afa2ff76c5aa898d6	intellectual property protection for multimedia applications, part 2: putting the pieces together	computer program;patent and trademark office;patents intellectual property protection multimedia application us patent and trademark office computer software programs floppy disk;copyright;multimedia application;intellectual property protection;multimedia computing;intellectual property protection hardware guidelines virtual reality application software prototypes resumes trademarks floppy disks;industrial property patents multimedia computing copyright;patents;industrial property	In its recently published guidelines (60 Fed. Reg. 28778, June 2, 1995), the US Patent and Trademark Office (PTO) said computer software programs stored in a tangible medium, such as a floppy disk, are patentable and must be examined to determine whether the substance of a computer-program related invention is a significant advance over prior technical achievement justifying the grant of a patent. In the past, the PTO had simply refused to examine the substance of such an invention. The PTO attributed its new approach to recent decisions by the Federal Circuit Court of Appeals, which decides all patent appeals, favoring the patenting of software-related inventions. The paper discusses the items affected and considers multimedia applications. >		Irah H. Donner	1995	IEEE Computer	10.1109/2.402101	computer science;artificial intelligence;software engineering;management;law;computer security;intellectual property	Visualization	-65.55207779582436	-23.531959569733868	151963
bd1f8147ba81bd9ad9c0d9617e6a422d8a9d84ae	webometric analysis of departments of librarianship and information science: a follow-up study	site web;ciencia informacion;especialista informacion;europa;analisis citas;citation analysis;information professional;webometrics;information science;google scholar;library and information science;informing science;statistical significance;professionnel information;web search engine;analyse citation;webometria;royaume uni;united kingdom;reino unido;evaluation;evaluacion;sitio web;europe;science information;follow up study;web site;webometrie;research assessment exercise	This paper reports an analysis of the websites of UK departments of library and information science. Inlink counts of these websites revealed no statistically significant correlation with the quality of the research carried out by these departments, as quantified using departmental grades in the 2001 Research Assessment Exercise and citations in Google Scholar to publications submitted for that Exercise. Reasons for this lack of correlation include: difficulties in disambiguating departmental websites from larger institutional structures; the relatively small amount of researchrelated material in departmental websites; and limitations in the ways that current Web search engines process linkages to URLs. It is concluded that departmental-level webometric analyses do not at present provide an appropriate technique for evaluating academic research quality, and, more generally, that standards are needed for the formatting of URLs if inlinks are to become firmly established as a tool for website analysis.		Mónica Arakaki;Peter Willett	2009	J. Information Science	10.1177/0165551508094051	webometrics;web search engine;information science;computer science;data science;evaluation;database;statistical significance;management;citation analysis;world wide web;information retrieval	Web+IR	-76.28777273217977	-22.497824718848026	152180
170de7c01b11f3028e3bc26502776fe757535226	creating a campus network without funding or a campus strategic networking plan - no kidding	network planning	At the beginning of 1993, Central Michigan University did not have a campus-wide computer network. Today, the campus has an FDDI backbone that connects eight campus buildings, and we plan to add more of the campus to the backbone over the next several years. The network was not the result of a strategic campus-wide networking plan or a university-sponsored mandate to build the network. Instead, the network creation was an outcome of the historical evolution of the university’s computing communications, changing technology needs, internal efforts to increase organizational awareness, a creative internal marketing strategy, and overcoming the prevailing campus mind-set that building the campus net couldn’t be done. Realization of the application and operational goals for the current network and hopes for further network expansion and improvements will require more innovation, judicious expenditures, a strong emphasis on user support and training, continued development of fruitful internal partnerships, continuing support of both our constituents and our administration, and perhaps a few bold organizational decisions. PROLOGUE This paper discusses how a university that only a few years ago had neither a campus network nor a great deal of money was able to get its campus backbone network started, the current status of this project, and what it will take to continue the momentum that has occurred. There were, are, k t and willl be many obstacles to this task, but it is assumed that many of the issues we have faced and addressed are similar to what other institutions are currently confronting. DEMOGRAPHICS AND HISTORY Description of institution, Central Michigan University (CMU) is a comprehensive state university with over 16,000 students, of which 89% are undergraduate and 11To are graduate. Another 10,000 students take credit and non-credit courses through the CMU College of Extended Learning at 13 Michigan regional centers, 36 centers in other states, and centers in Canada and Mexico. In 1992-93, CMU awarded 3,060 baccalaureate degrees and 620 graduate degrees through its main campus programs and an additional 1,852 degrees through its Extended Degree Program (EDP). The CMU Computer Services Department manages the university’s IBM mainframe computer, the campus backbone network, and the Computer Services South computer information center, and also serves as the liaison to our statewide regional network (Michnet), Bitnet, and the Intemet. CMU, like many of its counterparts throughout the nation, could be described as a chronically underfunded institution. Keeping pace with technology has been particularly challenging in light of the many issues that are in competition for limited resources. The university joined BITNET relatively recently, in 1988, and became a Class B member of the Internet in 1991. Between 1988 and 1993, the campus reached external networks primarily through dial-up connections to our IBM 3090 mainframe and Michnet. Most users accessed the Internet via the mainframe primarily for electronic mail although the mainframe also supported remote host access (Telnet) and file transfer (FIT). Consequently, the mainframe served indirectly as a validation server for Intemet Telnet and lWP sessions. A brief historical account of CMWS network development. The issue of dial-up lines requires an aside because there is insight to be gained here both about how this set the stage for the later development of the CMU fiber optic network backbone and about how organizational funding models influence these changes. The university installed its own telephone system in 1984. The telephone switch also provided the capability for what was, at the time, a state-ofthe-art dial-up network using Northern Telecom’s Datapath. Datapaths could provide asynchronous terminal connections Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its data appea< and notice is given that copying is by permission of the Association for Computing Machinery, to copy otherwise, or to republish, requires a fee ana!/or specific permission. 01994 ACM 0-89791-656-5/94/459940 $3.50 Meet the Shadowy Future 53 at speeds up to 19,200 bps, an excellent way for terminals to connect to a central mainframe. By the mid1980s, more and more people were using IBM PCs and Macintosh systems as terminals, adding more users who wanted to use the same dial-up lines for file transfers. Still, the 19,200 bps speed was adequate for transferring most of the types of files that users needed. One difficulty with the Datapath service was that the university had made the decision to make all of its telecommunications services self-funding, which meant that users and departments had to pay about $30/month for each Datapath. Since many of the departments didn’t have large enough budgets to pay these recurring costs, not many Datapaths were installed-few academic departments had more than one or two Datapaths which were usually located in departmental “terminal rooms.” By the late 1980s this state of affairs was becoming more of an issue as faculty and students wished to use their microcomputers as terminals to the mainframe, which still housed many useful services such as programming compilers, statistical packages, and electronic mail. This became particularly important after the university joined BITNET and provided off-campus mail and file transfer capabilities for the first time. Each year after that, usage of the mainframe increased. Electronic mail and file transfer were enabling technologies for sharing information any time and any place. It reached the point where many faculty and students wanted access to BITNET but could not afford the recurring cost of a “high speed” 19,200 bps connection. Most of those who wanted connection but couldn’t afford Datapaths found a way to purchase a modem, usually a 2,400 bps modem, often with personal funds. Computer Services provided receiving modems to the mainframe at no charge to users since, unlike the Telecommunications Department, they were supported by the general fund and had no chargebacks for basic services. This somewhat put Computer Services in the role of “good guys,” and Telecommunications were the “bad guys.” The stage was set. However, since many of the faculty and students who wanted access to the mainframe (which for many was synonymous with BITNET and Internet access) already had a low to medium speed connection, there was little impetus for developing higher speed networks. (A number of administrative staff were and still are “networked” via IBM SNA communications controllers.) These kinds of connections began to be more and more constraining as network use continued to grow, not only in size but in the capabilities of the network for multimedia data, hence, dial-up connections became more and more inadequate. Even so, it was difficult for administrators to justify the costs of networking, both because a recent mainframe conversion had already cost millions of dollars and because, for many of them, the existing communications technology seemed adequate. It was equally challenging for most faculty to grasp the importance of what we today might call relatively high speed connections, something in the 10 to 100 Mb range. Most of those who did appreciate the value of network connections saw the procurement of high-speed networking as (a) an insurmountable task for a university that couldn’t afford to provide even relatively low speed Datapath lines to them, or (b) “the university’s responsibility.” We call reason (a) the learned helplessness model, and reason (b) the cynical defeatism model since most folks who espoused that opinion didn’t really expect the university to support a distributed campus backbone network and had little confidence in the university’s commitment to technology. These two reasons are not mutually exclusive. Assessment of how the CMU network really developed. The development of a campus network requires time, money, and expertise. The issues that CMU faced, and still faces, were how to build the network infrastructure as quickly, inexpensively, and well as possible, To do this required (a) building the network user constituency, (b) cultivating all possible funding opportunities, and (c) efficiently implementing the network by developing effective functional partnerships with support personnel that were spread throughout the campus in different departments. Building the constituency for a campus network. The first strategic move was to create awareness of networks and to create momentum for change. Most of the situational variables were ripe for building a networking constituency, except the recognition of the need was nowhere near the kind of consensus that would get the ball rolling. One of the avenues we identified for increasing organizational awareness was through our Computer Services newsletter. The newsletter was distributed widely to faculty, staff, and students, and provided a means not only to inform, but to educate and “market” the importance of networking. As CMU joined BITNET and the Internet, we published numerous articles about how to use networks for important services, as well as statistics showing increasing usage of the mainframe and electronic mail. The combination of description and usage data encouraged more and more faculty to look into what benefits they could derive from networks. We offered individual and workshop assistance, customizing presentations as much as possible to the level and usage needs of the clients. We did not have a large staff to do this but they were very capable, caring, and dedicated. The other psychological ploy that we developed was to dispel the prevailing perception that developing the campus network was an insurmountable task. We reasoned that it would be a lot easier to g	campus party;chargeback;collegehumor;communications protocol;compiler;datapath;dial-up internet access;electronic data processing;email;emoticon;file transfer;hybrid fibre-coaxial;ibm 3090;ibm personal computer;information centre;internet backbone;light-weight process;list of statistical packages;mainframe computer;megabyte;microcomputer;modem;optical fiber;outsourcing;procurement;server (computing);telephone exchange;usage data	Keith R. Nelson;Joyce L. Capen	1994		10.1145/196355.196405	public relations;engineering management;construction engineering;business	Networks	-68.66389791607544	-21.38860004304933	152334
058f83c9820e20b2177bb25857958a9b9acbf7cf	the ethics of nhs computing: a terminal case	healthcare;patient care;ethical issues;computing;ethics;feminism;computer ethics;national health service;public service	Value in the British National Health Service have shifted away from patient care towards financial control. However, in the quest for “efficiency”, huge amounts of NHS money have been wasted on computer system which failed. In this paper, I draw on a case study to explore some of the ethical issues which underlie this kind of waste of resources. Issues include the gap between public pronouncements and personal experience, the chaos of which lies behind the facade of rationality, and the systematic silencing of people, usually women, who question the viability of computer systems which are created for private gain rather than public service.	computer;money;rationality	Jacqueline G. Ord	1995	AI & SOCIETY	10.1007/BF01174480	computing;ethics;computer science;law;computer ethics	ECom	-74.15715484697301	-10.17930203092295	152661
e8680112385c23aaf84d820d23db5794c0b201e7	what is social informatics and why does it matter?	social informatics;information technology	It is a field that is defined by its topic (and fundamental questions about it) rather than by a family of methods, much like urban studies or gerontology. Social informatics has been a subject of systematic analytical and critical research for the last 25 years. This body of research has developed theories and findings that are pertinent to understanding the design, development, and operation of usable information systems, including intranets, electronic forums, digital libraries and electronic journals.	digital library;information system;intranet;library (computing);relevance;social informatics;theory	Rob Kling	1999	D-Lib Magazine	10.1045/january99-kling	computer science;knowledge management;data science;data mining;information technology	HCI	-74.99766660465136	-17.971445818347078	152844
66103aa9265859b3d7910ddad8dc2a999ceba717	icann - eu can't: internet governance and europe's role in the formation of the internet corporation for assigned names and numbers (icann)	european commission;internet corporation for assigned names and numbers;internet regulation;european union	This paper analyzes the policy process that led to the formation of the Internet Corporation for Assigned Names and Numbers (ICANN), focusing on the actions of the European Commission. The analysis of the relevant documents shows the difference between the regulatory ideas in the US and the EU. The European Commission would have preferred an institutional framework with a prominent role for public actors, but had to accept the preference of the US Government, which directed the institutionalization of a private regime for the management of Internet addresses and names. Nevertheless, the Commission managed to establish itself as a major player in the emerging field of Internet governance.		Volker Leib	2002	Telematics and Informatics	10.1016/S0736-5853(01)00011-9	accounting;public relations;marketing;management;law	Logic	-71.11925919973518	-12.325282662927963	152893
d7b4b465bbff6164f4c8f8caa43d058ecd5dfc9b	book review		"""Encyclopaedias represent the highest level of codification in scientific communication. Additionally, they aim to make scientific knowledge available to the widest possible audience. The monographic series Que sais-je? has this function in France, and it is therefore a major event that one of its recent volumes is devoted to La Scientomdtrie. Our French colleagues from the Centre de Sociologie de rlnnovation at the Ecole des Mines in Paris have produced a concise introduction to scientometrics as a recently emerging field of study. The discussion in the book is elementary and didactic. Technicalities are always placed in the wider context of the programmatic aims of the field of study in general, and the work of the Parisian group in particular. For example, in the introduction the inspiring role of Derek de Solla Price is discussed. The authors emphasize that statistics are not an end in themselves, but rather a means for analyzing the collective dimension of scientific activities and the processes of knowledge generation. In the introductory first chapter, the concept of a so-called """"rose des vents"""" in the scientific communication process is explained: the five petals of this rose represent five distinct functions of scientific communication. These are: (i) scholarly communication aiming at the legitimation and certification of knowledge claims; (ii) the utilization of new knowledge in innovations; (iii) the use of knowledge in the production of public benefits; (iv) its role in education; and (v) the educative function of the media. Each of these dimensions has its own dynamics and its own criteria for the assessment of scientific communications. However, this scheme is not reflected in the organization of the remainder of the book. Instead, the primary focus in the book is on the """"internal"""" dynamics of the scientific communication process, and on the question of how this process can be monitored systematically. The importance of writing and reading in the processes of the production and reproduction of scientific knowledge is emphasized, and the possibility of tapping this circulation by developing appropriate indicators is signalled. The focus in Part One is on scientific articles and patents as the two main sources of"""	collective intelligence;elementary;emoticon;linear algebra;scholarly communication;scientific communication;scientific literature;scientometrics	Loet Leydesdorff	1994	Scientometrics	10.1007/BF02018137		AI	-74.04283317185286	-20.943159313439285	153046
11f316cd38cd74649cd536e508a9c0cbd6d32970	special issue: computational ethics and accountability		Computational Ethics and Accountability are becoming topics of increasing societal impact; in particular, on the one hand, in the context of recent advances in AI and machine-learning techniques, people and organizations accept decisions made for them by machines, be they buy-sell decisions, pre-filtering of applications, deciding which content users are presented, which personal data are shared and used by third parties, up to automated driving. In each of these application scenarios, where algorithms and machines support or even replace human decisions, ethical issues may arise. On the other hand, algorithms and machines can play the role of verifying and cross-checking compliance of human players in analyzing digital records of social interactions, for instance, in business transactions and processes, but also in following rules of conduct in online social interactions. Closing the circle, based on such checks, again automated decisions may be implied that involve ethical requirements, such as nondiscrimination and fairness. Apart from infamous “trolley problems” (Edmonds 2013), where even philosophers struggle to judge what is the “right” decision and going either way has dramatic impacts, there are more subtle everyday decisions that we now either happily delegate to machines or that are digitally recorded, which may have ethical implications: handling of personal data has to follow strict legal regulations, especially in social networks and in re-sharing personal data with businesses, (social) norms should be followed also in domains where automated agents enter interactions that were typically executed by human actors only, and fair business practices should be ensured within business processes, compliant with regulations, laws, and best practices. In all these areas, at the very least, we expect transparency and accountability from automated decision and decision support systems: that is, we should require these systems to be transparent about how they make decisions and knowing who is accountable for those decisions and their effects. Many voices demand a more responsible technology and engineering approach, such as articulated in the Copenhagen Letter (Techfestival 2017), or recent initiatives to standardize value-based ethically compliant system design, such as IEEE’s P7000 (for Ethical Life-Cycle Concerns Working Group (EMELC-WG) 2017) family of standards.	algorithm;autonomous car;best practice;business process;checking (action);closing (morphology);compliance behavior;computation;decision support systems, clinical;decision support system;execution;fairness measure;handling (psychology);interaction;jack edmonds;machine learning;personally identifiable information;regulation;requirement;rule (guideline);social network;systems design;the circle (file system);vendor information documentation;verification and validation;verifying specimen;voice;standards characteristics	Cristina Baroglio;Olivier Boissier;Axel Polleres	2018	ACM Trans. Internet Techn.	10.1145/3195835	data mining;management science;accountability;computer science	HCI	-71.23642541584246	-15.101771280794601	153177
79a939b433d2e9ace6a647c3a0ffad36c6408f45	the answer is 42 of course	security consultant;bad guy	Why is security so hard? As a security consultant, I’m glad that people feel that way, because that perception pays my mortgage. But is it really so difficult to build systems that are impenetrable to the bad guys?		Thomas Wadlow	2005	ACM Queue	10.1145/1071713.1071727	computer security	Crypto	-63.41471340983143	-23.775820867328314	153185
30f3140d94019ff72f4b7829f9667a879db733ac	issues in ethical data management		Data science holds incredible promise of improving people's lives, accelerating scientific discovery and innovation, and bringing about positive societal change. Yet, if not used responsibly, this technology can generate economic inequality, destabilize global markets and worsen systemic bias. We consider issues such as bias and violation of data privacy in data analysis. We discuss desirable properties of data analysis such as fairness, transparency, neutrality, and diversity. Our goal is to draw the attention of the computer science community to the important emerging subject of responsible data management and analysis. We present our perspective on the issue, and motivate research directions.	computer science;data science;exponent bias;fairness measure;information privacy;social inequality;transparency (graphic)	Serge Abiteboul	2017		10.1145/3131851.3131854	economic inequality;computer science;information privacy;management science;neutrality;social change;data management;transparency (graphic);systemic bias	ML	-75.81704750098453	-12.377695858872585	153268
2a5b09c9dc2f5275103be17de14d6b922fd8c489	change implications related to electronic educational resources	livre electronique;ciencia informacion;europa;gestion fonds;new information communication technology;professional competence;information science;biblioteconomia;collections management;cambio;biblioteca ensenanza superior;bibliotheconomie;gestion fondos;stock management;change;standardisation;communication skill;educational resource;electronic book;bibliotheque enseignement superieur;royaume uni;united kingdom;competence professionnelle;reino unido;libro electronico;electronic books;librarianship;changement;public space;world wide web;nouvelle technologie information communication;higher education library;ressource electronique;europe;perfil profesional;science information;academic libraries;recursos electronicos;librarians;nueva tecnologia informacion comunicacion;electronic resource	E-books are a relatively recent addition to the online electronic resources market, and commentators are still debating their efficacy. Access to e-books continues to develop, with numerous platforms available, and lack of standardisation an ongoing problem. However, there are potential advantages to e-books, including easier access, speed of publication, space-saving, and lower costs. Many university libraries are beginning to have e-books in their collections. A research project being undertaken at Liverpool John Moores University is investigating the provision of e-books in 127 academic libraries in the UK. Many academic libraries are providing access to e-book resources that are free-of-charge, and those libraries offering e-book subscriptions are using the World Wide Web for their platform. There are similar issues in the take-up of e-books to those regarding the take-up of other electronic resources, such as ejournals. These include changes in professional and management skills, such as collection development, marketing and evaluation, user education, technological skills and communication skills.	book;change management (engineering);download;e-book;high-level programming language;library (computing);liverpool;printing;requirement;world wide web	Linda Ashcroft;Chris Watts	2004	Online Information Review	10.1108/14684520410553778	stock management;information science;computer science;sociology;operations research;world wide web;standardization;collections management	HCI	-71.745662035395	-22.32633984641849	153309
92d5969bd0b3ce0a21a66efa2a2a435abb5ebfa8	new roles for libraries in supporting data-intensive research and advancing scholarly communication		This paper will explore potential roles for libraries in support of dataintensive research and inquiry. Scholars and researchers from many disciplines are using vast amounts of data to advance our understanding of both the physical nature of our world and its place in the universe, as well as to gain new insights into the behaviours of societies and individuals. Humanists are rapidly integrating newly digitised corpora, digital representations of material culture and spatial and temporal indexed data into their scholarly endeavours. Libraries have undergone significant transformation over the past several decades in confronting the “digital deluge” and integrating digital content into their holdings. However assuming additional responsibilities for managing and making large and complex data sets available and providing new tools for users presents significant challenges given limited resources. This paper examines data-intensive scholarship and suggest viable roles for libraries.	data-intensive computing;digital recording;library (computing);our world;scholarly communication;text corpus	Stephen Griffin	2013	IJHAC	10.3366/ijhac.2013.0060	humanities;computer science;knowledge management;data science;world wide web;cartography	HCI	-70.34182672769667	-19.56248365222634	153481
e2733b70c9f3ef7b3b8ac3fecf0ad2e79d0e06c1	seeking compliance nirvana	word compliance;harrowing list;mere mention;compliance nirvana	Compliance. The mere mention of it brings to mind a harrowing list of questions and concerns. For example, who is complying and with what? With so many standards, laws, angles, intersections, overlaps, and consequences, who ultimately gets to determine if you are compliant or not? How do you determine what is in scope and what is not? And why do you instantly think of an audit when you hear the word compliance?		Greg A. Nolann	2006	ACM Queue	10.1145/1160434.1160455	computer security;audit;computer science	Theory	-63.65610807057802	-23.274696549985322	153501
e3992be4ef9d10bfdca0519195fe5d47a9b52ada	preface for articles from elpub2017		The eight articles in this issue were first presented at the ELPUB2017 conference (International Conference on Electronic Publishing) that took place in Cyprus, June 6–8 2017 http://www. cyprusconferences.org/elpub2017/. The authors of these articles took advantage of the offer by IOS Press and revised their original submissions for this special issue without publication fee. 21 years ago when the ELPUB conference series first started, the term “electronic publishing” promised all manner of potential that the Web and network technologies could bring to scholarly communication, scientific research and technical innovation. Indeed, over the last two decades we have seen tremendous developments across all these domains, and at the same time our social, economical and political lives have been completely transformed. Open Science represents one such transformation, and not surprisingly, the elements that make Open Science possible, including open access, open data, open software, and other domains of open have been regular topics presented and debated at previous ELPUB conferences. However, development and diffusion of open research practices are highly uneven across disciplines and across regions. And despite the common claims that Open Science improves transparency and accountability throughout the research life cycle while democratizing the knowledge production process, empirical research and conceptual validation of these ideas has been limited. In addition, there is a growing tendency to conceptualize Open Science as a set of conditions waiting to be met, without regard for regional differences, including cultural and historical contexts of knowledge production. The theme of the ELPUB2017 conference was Expanding Perspectives on Open Science: Communities, Cultures and Diversity in Concepts and Practices. It was intended to generate discussion and debate on the potential and limitations of openness. In the original Call for Papers, we invited researchers and practitioners from diverse backgrounds to share their results and ideas towards a highly interactive forum. We also asked potential presenters to consider exploring alternative models of interaction and cocreation between scholars and citizen scientists, and the role of dissemination and publishing within these interactions. To stimulate submissions, we included these questions in the open call: Who determines the agenda and direction of emerging discourses around Open Science? How does Open Science challenge the current positions and power of players and agents in varying institutional contexts? Are we seeing a converging global view of Open Science, or are there disciplinary, regional, and other differences that are important to consider? What are the gaps between existing Open Science policies, regulatory frameworks, and implementation requirements and how should they be addressed? How do	citizen science;interaction;open research;open-source software;openness;qp state machine frameworks;requirement;scholarly communication;world wide web;ios	Leslie Chan;Fernando Loizides	2017	Inf. Services and Use	10.3233/ISU-180863		HPC	-71.51681082153434	-16.844757200249287	153703
4a1504f58bfce60ff6f3a681115c3b22ab4659be	intellectual property protection for bioinformatics and computational biology		Bioinformatics, and computational biology are two ever-growing fields that require careful attention to intellectual property rights (IPR) and strategies. The American patent system is currently going through the biggest reformation since the passage of Patent Act of 1952, and many changes apply directly to the field of biology that utilize computational intelligence. Basic IP definitions, recent IP developments, and advanced protection strategies are discussed in order to better understand the status quo of intellectual property (IP) specifically in the field of evolutionary computation, bioinformatics, and computational biology.	bioinformatics;computational biology	Dennis Fernandez;Antonia Maninang;Shumpei Kobayashi;Shashank Bhatia;Carina Kraatz	2015		10.1007/978-3-319-16483-0_9	computer science;bioinformatics;engineering	Comp.	-70.28601465302194	-17.02301123309264	153981
be241f6cee40920c0b986867a63a5be3331d53d4	scholarship in the digital age: information, infrastructure, and the internet	information technology;internet;world wide web;electronic information resources	Scholars in all fields now have access to an unprecedented wealth of online information, tools, and services. The Internet lies at the core of an information infrastructure for distributed, data-intensive, and collaborative research. Although much attention has been paid to the new technologies making this possible, from digitized books to sensor networks, it is the underlying social and policy changes that will have the most lasting effect on the scholarly enterprise. In Scholarship in the Digital Age, Christine Borgman explores the technical, social, legal, and economic aspects of the kind of infrastructure that we should be building for scholarly research in the twenty-first century.Scholarship in the Digital Age will provoke a stimulating conversation among all who depend on a rich and robust scholarly environment.	internet	Jack Meadows	2008	Journal of Documentation	10.1108/00220410810899763	internet architecture board;information infrastructure;the internet;information technology management;internet research;computer science;web navigation;sociology of the internet;multimedia;internet presence management;internet privacy;internet appliance;web intelligence;law;information technology;world wide web	HCI	-70.34322320894165	-19.358538176345764	154070
d67761c770a393d5873359773444c4602f6c1296	human software requirements engineering for computer-controlled manufacturing systems	software requirements;manufacturing system	-Computers as integral systems components determine the quality of work of operators in industrial production. This paper contributes to improving the design of man-machine systems by proposing a formal aid to human software requirements definition and design. First, the need for considering human requirements is stressed. Since technology is to be considered as 'non-deterministic', the designer is faced with a degree of freedom in his design decisions which can be and should be utilized for raising the quality of work of people operating computer-controlled man-machine systems. Then, a hierarchy of human quality criteria applicable for ergonomic judgement of work design measures is derived. Following the principle of prospective work design, these criteria must be considered as design goals just like technical and economic requirements. As a formal aid for making design decisions meeting these comprehensive requirements, the Requirements/Quality Criteria Matrix is proposed. Finally, this method of considering human requirements is illustrated by designing some man-machine interface features for operators of a hypothetical flexible manufacturing system. Introduction IN INDUSTRIAL production, an ever-increasing number of work places is influenced by computers partly or totally controlling manufacturing processes. The same is true in administrative and even private areas of work. The effects on the human operators of such automation are determined by the programs controlling the built-in computers with which the operator works in a production unit. Computer software design, therefore, plays a key role in the design of man-machine systems for work places tailored to human needs. Are we able to specify human, i.e. person-oriented, software requirements for computer-controlled manufacturing systems which are operational for software engineers to work with? I believe this to be hardly possible yet. Therefore, I want to make a contribution towards solving this problem by first indicating workable criteria for the ergonomic judgement of work design measures and then by applying a proven method of technical requirements specification engineering to these person-oriented criteria. Human criteria for man-machine systems design Requirements specification in manufacturing systems design is usually limited to specifying what the system shall do in detail * Received 31 December 1982; revised 23 May 1983. The original version of this paper was presented at the IFAC/IFIP/IFORS/IEA Conference on Analysis, Design, and Evaluation of Man-Machine Systems which was held in BadenBaden, F.R.G. during September 1982. The published proceedings of this IFAC meeting may be ordered from Pergamon Press Ltd, Headington Hill Hall, Oxford OX3 0BW, U.K. This paper was recommended for publication in revised form by editor A. Sage. t Manufacturing Technologies Program Management, Kernforschungszentrum Karlsruhe GmbH, P.O. Box 3640, D7500 Karlsruhe, Federal Republic of Germany. (functions) under the constraints of the system's final purpose (output, quality and cost of parts to be manufactured by the system). The question is whether there is any need also to consider the future human operator of the system at such an early stage. Need to consider human requirements. The development of industrial production is characterized by growing mechanization, increasing automation and work becoming more and more fragmented and hierarchically organized. The fragments of work being left to one worker require narrower ranges of skill. The content of work actually performed on site (where the workpiece is) is further reduced by taking the work planning and preparation steps away from it (separation of thinking from doing). An example of this is the conventional operation of NCmachine tools limited to machine loading and unloading and monitoring, which leads to harmful insufficient demands on the worker (Noble, 1979). To better understand such causes and effects, a number of studies were performed in Germany, a summary of which was published recently (Br6dner and Martin, 1981). Through these studies a number of social effects of automation in industrial production have become visible which cannot be ignored any longer. In general, unless countermeasures are taken consciously in the interest of the workers, further technical changes may lead to de-skilling with most workers; physical and mental strains may grow and frequently shift to the latter. The answer, therefore, is yes, there is indeed an urgent need for considering human criteria in the early phase of requirements specification. In the new German Manufacturing Technologies Support Programme, technical and social goals have therefore been determined as being of equal rank (Martin, 1980). The next question, then, is whether there are any margins of design in developing computer-controlled manufacturing systems, which could be utilized for the sake of the workers, possibly even without contradicting economic viewpoints. Idea of technological determinism overcome? People are easily led to believe that the historical path on which technology in its present shape has been developed was the only one that could have been pursued. This prejudice, commonly called technological determinism, has been refuted in one of the studies already mentioned. For highly automated production plants there is a wide margin for designing man-machine interface and the role of the operator (Mickler, 1975). Another well-known recent example of alternative technology is re-enriching the content of work of NC-machine tool operators. This is achieved by building data processing capability into the NC-control unit to allow part programming at the machine site to be done by the operator (Martin, 1981). For small batch manufacturing this is being widely used with considerable economic benefits. This shows that the new technology ofmicroelectronics can be used to correct or even reverse the historical processes of subordinating men and women to machines and eliminating initiative and control from their work, to develop instead a manufacturing technology which is subordinate to human skill and cooperates with it (CSS, 1981). Yet, the prejudice still seems to prevail, and thinking in technical alternatives and making	cascading style sheets;computer;consciousness;control unit;countermeasure (computer);human factors and ergonomics;international ergonomics association;international federation for information processing;international federation of operational research societies;job design;prospective search;requirement;requirements engineering;software design;software engineer;software quality;software requirements specification;systems design;technological determinism;user interface	Taylor Martin	1983	Automatica	10.1016/0005-1098(83)90043-2	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;business requirements;systems engineering;engineering;software design;requirement;needs analysis;system requirements specification;requirements elicitation;mathematics;requirements engineering;non-functional testing;non-functional requirement;software requirements;systems design	HCI	-64.74842280867776	-23.137955998699848	154436
c73f7f8524edd59f980306bb5775e54b3f349dd6	a citation analysis of business computing research journals	informatica;filing;citation analysis;entreprise;business computing research;business computing;journal ranking;periodical;core collection;estudio comparativo;empresa;analisis cita;systeme information gestion;coleccion centro;etude comparative;analyse citation;periodique;periodico;classement;firm;comparative study;informatique;computer science;information system;recherche scientifique;management information system;scientific research;information systems publications;clasificacion;systeme information;collection coeur;investigacion cientifica;sistema informacion;mis publications	Correspondence to: Linda Johnson, Western Kentucky University, Department of Finance and CIS, Bowling Green, KY 42101, USA. Clyde W. Holsapple holds the Rosenthal Endowed Chair in MIS, doing teaching and research in decision support systems, knowledge management, expert systems, and organizational computing. His books include Foundations of Decision Support Systems, Micro Database Management, Business Expert Systems, and The Information Jungle. His research articles span such diverse journals as Decision Sciences, Operations Research, Decision Support Systems, Datamation, IEEE-SMC, IEEE Expert, Information Systems, Expert Systems, The Computer Journal, Financial Management, and Organization Science. Dr. Holsapple is Associate Editor for Management Science and Organizational Computing, Area Editor for Decision Support Systems, and co-founder of ISDSS, the International Society for Decision Support Systems.	book;citation analysis;decision support system;expert system;information systems;information system;knowledge management;linda (coordination language);management science;operations research;the computer journal	Clyde W. Holsapple;Linda Ellis Johnson;Herman Manakyan;John Tanner	1993	Information & Management	10.1016/0378-7206(93)90072-2	scientific method;computer science;comparative research;data mining;operations research;citation analysis;world wide web;information system	DB	-74.325790440133	-22.119409517672445	154458
da31c70b34fbfc79574555220826928b99749748	the missing court of claims report: is letitia humphreys court of claims report 42?	federal government;united states of america	Between the years 1855 and 1863, the opinions or breportsQ of the United States Court of Claims were delivered to the House of Representatives for final consideration. In total, 296 cases were conveyed, but in the process, Report 42 was lost and, according to indexes of such documents, bnever received by [the] House.Q This article cites examined records of the Court of Claims, from both the United States Congressional Serial Set and original documents now in the National Archives, which support the contention that there was a completed opinion for Court of Claims Report 42 that was lost sometime during its transfer between the Court and the House. This 150-year-old case – Letitia Humphreys, Administratrix of Andrew Atkinson – was one in a long list of judicial proceedings, involving over 100 claimants, that resulted from the 1812 invasion of Florida by the United States, and that concerned the payment of interest to those compensated under the last clause of the ninth article of the 1819 Treaty of Amity, Settlement, and Limits, Between the United States of America and His Catholic Majesty. These Florida petitions were examples of early claims actions against the federal government, in many cases after decades of inaction. D 2006 Elsevier Inc. All rights reserved. 0740-624X/$ see front matter D 2006 Elsevier Inc. All rights reserved. doi:10.1016/j.giq.2006.03.003 4 Corresponding author. Fax: +1 402 472 5131. E-mail addresses: cbernholz2@unl.edu (C.D. Bernholz)8 robert.ellis@nara.gov (W.R. Ellis). 1 Fax: +1 202 219 6273. Government Information Quarterly 23 (2006) 309–324 The Court of Claims was created in 1855 and was formed in response to the ever-growing number of claim petitions that demanded far more attention than Congress could afford. Initially, claims following Independence were handled by the Treasury Department, as authorized by Congress, and distinctive administrative groups handled special claims cases like those following the War of 1812. This process led to a larger participation by Congress itself, with the creation of claims committees that assured some insulation from the constitutional questions that plagued such claims. Specifically, there were concerns that allocating claim petitions to a forum other than to Congress would violate the First Amendment right that citizens may bpetition the government for a redress of grievance.Q Further, Article I, § 9 of the Constitution required that bno money shall be drawn from the Treasury, but in consequence of appropriations made by law,Q and so Congressional supervision of claims payments was considered appropriate. However, the burden grew over time. Congress became progressively more concerned that b[n]o counsel appeared to watch and defend the interest of the Government,Q and that, with their own propensity to find it bmore convenient and more safe not to act at all upon those claims which called for much investigation, especially when the amounts involved seemed large,Q petitions carried on for years, sliding from one Congress and one standing committee to the next. The creation of the Court of Claims in 1855 addressed some of these issues. Of particular interest within this jurisdiction are the early, carry-over cases that populated the Court’s calendar. There was an immediate opportunity to respond to these petitions. The main case opinions for these first 295 proceedings were published in House of Representatives Court of Claims volumes as part of the communications between the Court and Congress. The United States Congressional Serial Set holds these cases in a suite of eighteen volumes, with the cases sequentially numbered. Further, it is worthy to note the development of reports sent to the Senate that paralleled the action of the Court and its communications with the House. The Senate Report Committee of Claims, to which was referred bAn Act making appropriations for the payment of certain claims,Q together with opinions of the Court of Claims in the cases of Samuel P. Todd, John Shaw, and Isaac Beaugrand was used to convey the Court’s findings for the three initial Court of Claims cases, Samuel P. Todd, Isadore D. Beaugrand, and John Shaw. As an indication of the delay that some of these petitions endured, Todd concerned interest on money due since the period 1812 to 1815. The Court concluded that only the original amount was due Todd, without interest, although binterest may be added if Congress should see fit to allow it.Q Beaugrand was a case involving an Ohio volunteer in the war with Mexico who petitioned for, and won a judgment, of $162.81 plus interest. Shaw requested $1000, and interest, for serving as an interpreter to translate Winnebago into French and English during the 1828 trial of nine Indians charged with murder. The principal was awarded, but interest was not. One of the ways to locate these early cases is to examine checklists or indexes that focus upon documents of that era, but it appears that there is one Court of Claims Report that is missing. The Tables of and Annotated Index to the Congressional Series of United States C.D. Bernholz, W.R. Ellis Jr. / Government Information Quarterly 23 (2006) 309–324 310	authorization;bruce ellis;document;fax;interpreter (computing);like button;list of code lyoko episodes;money;online petition;population	Charles D. Bernholz;William R. Ellis	2006	Government Information Quarterly	10.1016/j.giq.2006.03.003	majority opinion;computer science;public administration;management;law;certiorari;court of record;remand	ML	-64.62050431590409	-19.315306028875387	154537
c9bd0d22106298d00658f8468cfc7308c10140ad	time and information technology: temporal impacts on individuals, organizations and society	information technology;h social sciences general	Time has recently become a central issue of discourse in social sciences and management studies. Partly due to the advent of the new millennium, scholars in social sciences and management studies have become fascinated with the notion of time and come to appreciate its complex nature. This newly awakened interest in time can be seen in the recent conferences and journal special issues on the topic.1 In particular, much of this rising interest can be seen in an awareness of changing time in this “information age.” Information technology, recently represented by the Internet, is “transforming time,” the way time is perceived, used, managed, and disciplined. Although it is generally accepted that information technology is affecting temporal aspects of contemporary society, all too often the relationship between time and information technology fails to acknowledge the complexity of their relationship and is simply understood in terms of clichés such as “IT enables us to overcome barriers in time and space.” While one key aspect of the effect of technology on time is that many things are getting faster, we believe the accompanying changes are much more fundamental. This special issue on time and information technology aims to provide this deeper understanding , and thereby to further research and discussion on time and information technology. In this editorial, we review why we believe that time and information technology should be a focal point in understanding current changes in organizations	focal (programming language);internet	Heejin Lee;Edgar A. Whitley	2002	Inf. Soc.	10.1080/01972240290075084	social science;computer science;sociology;operations research;law;information technology	Theory	-75.07612538672859	-14.107869216691869	154764
0fe37fb03b90e70b2c51ba22bc50713e191b015f	the digital archiving of historical political cartoons: an introduction	metadata;e humanities;cartoons;crowdsourcing	Political (editorial) cartoons often capture the Zeitgeist of society and convey a message. Increasingly, historians study them to understand commentaries of past events or personalities. Visual culture as an academic subject could be greatly enhanced if this information can be digitally archived. We employ crowdsourcing to obtain valuable metadata by guiding volunteers’ feedback using an online survey with 31 targeted questions. We provide intellectual access to a set of about 300 cartoons of a single creator spanning over multiple years in a highly interactive search engine.	archive;crowdsourcing;file archiver;file spanning;web search engine;zeitgeist	Junte Zhang;Kees Ribbens;Rob Zeeman	2013			computer science;data science;multimedia;world wide web	HCI	-70.19757816771175	-20.202867280612832	155018
279d3b1888d5bd7c348a02e144cea92a90eb06e6	the responsa project: some promising future directions		We present a very brief review of some of the achievements of the Bar-Ilan Responsa Project during the period of Yaacov Choueka’s leadership and discuss some of the directions the project might consider in order to meet ongoing challenges.	computational linguistics;elegant degradation;information retrieval;query expansion;text corpus;web search engine	Moshe Koppel	2014		10.1007/978-3-642-45324-3_1	library science;engineering;operations research	NLP	-64.05529264853098	-12.541073762101213	155094
108a8ebe64f160f1f9319cebd0d8b1d0d3bbee3b	closing the pdf gap: readcube's experiments in reader-focused design		Since the publication of the first journal in 1665, scientific publishing has evolved continuously and rapidly. Driven by this evolution, the history of scholarly publishing is one of perennial growth. According to the most recent STM Report, a mosaic of more than 10,000 publishers has collectively published more than 30,000 journals, representing millions of individual articles published to date (Ware & Mabe, 2015). Despite enormous technological and societal advancement over the last three centuries, the basic mechanisms of scholarly publishing would be oddly familiar to our 17th century counterparts. Although the delivery methods have gone from pulp to digital, research stories are still encapsulated in articles, which are still peer reviewed and bundled in journals, which are still predominantly accessed through universities and other institutions. So why has the evolution of research content’s delivery vehicles lagged behind the evolution of the research story itself? Why with the recent history of content innovation does there continue to be a mismatch between the usage patterns of researchers and the products, platforms, and features offered to them? To understand this mismatch, we must look to the venerable PDF. As journal publishing went digital, the PDF was a natural choice for a format of record, providing the print journal experience in a digital wrapper. For readers, the PDF was a perfect transition between the old and the new. It provided a familiar consumption experience, combined with digital content’s unique ability to be accessed anywhere, near instantaneously. Naturally then, the PDF article was a resounding success (to the eventual chagrin of publishing innovators). However, with the Internet at publishers’ disposal, the PDF was not the ONLY way to disseminate content. With increasingly sophisticated websites and online platforms, publishers broke out of the PDF mould and began making content available in webnative HTML format. HTML provided several benefits over the PDF, largely built on the magic of hyperlinks. For instance, a reader could simply click an item of interest within an article (e.g. a citation), and the hyperlink would take them there. Similarly, new types of supplementary content could be paired with a core article text with links. The rise of supplementary material provided by authors is the perfect object lesson for the success of this idea. Historical analysis of ReadCube’s database of over 52 million articles reveals the dramatic rise of the supplement as part of the research story (Fig. 1). Twenty years ago, only a fraction of articles were paired with a supplement, while nowadays, one in five articles has supplementary content. As new containers for scholarly information beyond the article are developed, we expect to see similar growth stories replicated across these data types. In more recent years, online platform publishing has become increasingly sophisticated. New platforms like PubReader and eLife Lens have made richer HTML article experiences available, with deep hyperlinking to related resources (like figures). In a related vein, many publishers are now adding third-party	closing (morphology);digital data;digital recording;experiment;html;hyperlink;internet;portable document format;scientific literature;software transactional memory;word lens	Alex Hodgson;Lucas Schlager	2017	Learned Publishing	10.1002/leap.1084		Web+IR	-67.61071122619326	-21.528556212440918	155225
5c7fac5d73b60646cbeb3a74775c961fd3071822	cryptography during the french and american wars in vietnam		After Vietnam’s Declaration of Independence on 2 September 1945, the country had to suffer through two long, brutal wars, first against the French and then against the Americans, before finally in 1975 becoming a unified country free of colonial domination. Our purpose is to examine the role of cryptography in those two wars. Despite the far greater technological resources of their opponents, the communications intelligence specialists of the Viê.t Minh, the National Liberation Front, and the Democratic Republic of Vietnam had considerable success in both protecting Vietnamese communications and acquiring tactical and strategic secrets from the enemy. Perhaps surprisingly, in both wars there was a balance between the sides. Generally speaking, cryptographic knowledge and protocol design were at a high level at the central commands, but deployment for tactical communications in the field was difficult, and there were many failures on all sides. “Our friends...admired the determination and sacrifice coming from a small nation standing up against a colossal empire.... Our narrative was like the Biblical story of David against Goliath.” —Nguyẽ̂n Thi. B̀ınh (2013, p. 141-142)	communications protocol;cryptography;dominating set;high-level programming language;killzone: liberation;signals intelligence;software deployment	Duong Hieu Phan;Neal Koblitz	2016	Cryptologia	10.1080/01611194.2017.1292825	vietnamese;democracy;public relations;declaration of independence;communications security;theoretical computer science;cryptography;computer science;colonialism;tactical communications;signals intelligence	AI	-69.62516489172661	-12.437036653573331	155287
0e298394b256b04e8cfd0775c964e3fdfe26f43e	information system, data bases, and on-line services of the japan information center of science and technology (jicst)	science and technology;information system	The JICST information processing system consists of the data-base production system, authority file management system, bibliographic retrieval system, and printed issue compiling system. The bibliographic retrieval service based on the JICST On-line Information System (JOIS-I) has been available through leased line since 1976 and now also through dial-up line, which covers five data bases: the JICST bibliographic and on-going research information files, CA Condensates, MEDLARS, and TOXLINE files. The on-line output in Japanese kanji is also available. The newly revised JOIS-II system is now being developed.	base;compiler;database;dial device component;dial-up internet access;information processing;information processor;information system;leased line;medlars;online and offline;printing;production system (computer science);radiology information systems;revision procedure	Hisako Uchida	1979	Journal of chemical information and computer sciences	10.1021/ci60020a003	chemistry;computer science;knowledge management;information system;science, technology and society	DB	-70.03029525604904	-22.90771057125755	155325
5dfe6a48ebea031e894cc87169b657efef4d8580	information security policy's impact on reporting security incidents	medical records;incidents;deterrence;policy;information security;seriousness;security;computer abuse	The New Health Privacy Rule, effective from April 14, 2003, has made it illegal for healthcare providers and insurers to release a patient's medical records without the individual's consent [Cropper, Carol Marie. How to keep prying eyes off your medical records. Business Week November 19, 2001;130-2]. Rule provisions dictate that healthcare providers and insurers must have a written information security policy and present it to patients [Cropper, Carol Marie. How to keep prying eyes off your medical records. Business Week November 19, 2001;130-2]. This paper evaluated the utility of having such a policy by examining the reporting of computer abuse incidents and the reporting of the seriousness of computer abuse incidents in those hospitals that either have or do not have a written information security policy. The premise of this study is that for an information security policy to be effective, computer abuse incidents and the seriousness of those computer abuse incidents must be reported. For this study, there were two factors that were examined for all respondent hospitals. The first factor was the reporting of computer abuse incidents that occurred the year prior to the study. The second factor was the reporting of the seriousness of computer abuse incidents that occurred the year prior to the study. Survey instruments were distributed to hospitals of various sizes, specialties, ownership, and types. The questionnaire collected information about the reporting of computer abuse incidents and their seriousness level to determine if an information security policy is effective in influencing the reporting of each. In addition, background information was collected from each hospital to aid in the analysis of the survey results.	information security	Terry L. Wiant	2005	Computers & Security	10.1016/j.cose.2005.03.008	computer science;deterrence theory;information security;computer security;medical record	Crypto	-71.38453083267126	-10.924219896877027	155574
0dcd93fcbad96a3333cab58b1085364a4cd06e2e	using human knowledge to improve opening strategy in computer go		The opening is crucial in the game of Go. Monte-Carlo techniques do not fare well in the opening because there are far too many moves to consider. We extracted human knowledge from a database of professional games to build a book of strong opening moves. Our rst opening book only had information about full-board opening sequences (fuseki). This book was quickly exhausted during games. We therefore incorporated joseki: common local sequences that lead to outcomes satisfactory for both players, such as striking a balance between corner territory and center in uence. Both the fuseki and joseki books use transposition tables allowing us to quickly determine whether the current global or local board con guration exists in our database. We then combine these two books to use information from both databases. We present experimental results on the e ects of the three books on the program's win percentage.	book;computer go;database;monte carlo method;naruto shippuden: clash of ninja revolution 3;transposition table	Jessica Mullins;Peter Drake	2010			simulation;transposition table;computer go;computer science	DB	-64.67686770687197	-22.92697426872307	155619
7b68c519ace04e31ce67eac6fa787d7989d7a073	jstor: a case study in the recent history of scholarly communications	archivo electronico;information communication technology;case history;communication scientifique;historiography;enseignement superieur;comunicacion cientifica;jstor;case studies;electronic periodical;periodique electronique;knowledge management;higher education;scholarly communication;digital archive;informacion documentacion;influence of technology;historians;ensenanza superior;foreign countries;historique;estudio caso;almacenamiento;information management;electronic libraries;etude cas;archives management;evidence;scientific communication;scholarship;archivage;archive electronique;grupo a;electronic journals;ciencias sociales;periodico electronico;organizational development;nueva tecnologia informacion comunicacion;technologie information communication;graduate student;archival storage;design methodology;estudio historico	Purpose – To argue for the consideration from an historical perspective of technology-enabled changes in higher education. Design/methodology/approach – Uses examples from the author’s history of JSTOR as a case study. Findings – That the case of JSTOR offers evidence that technology-enabled changes in higher education will have historical interest. Research limitations/implications – Although the author presents only examples from JSTOR, historians should begin to give attention to the overall changes taking place in scholarly communications and higher education. Practical implications – Suggests further areas of research for historians, information scientists, and graduate students. Originality/value – This work should be of interest to library and information professionals, business historians, and perhaps economic historians interested in the information industries.	archive;closing (morphology);information access;information scientist;library (computing);software documentation	Roger C. Schonfeld	2005	Program	10.1108/00330330510627953	information and communications technology;social science;design methods;computer science;historiography;sociology;information management;higher education;management	HCI	-73.07331292356939	-21.944332688529403	155633
cfdbb63d1ea57c7dc038745871d6f2e3001f4460	digital humanities pedagogy: practices, principles and politics. brett d. hirsch (ed)			digital humanities	Stephen Brier	2014	LLC	10.1093/llc/fqt042	social science;media studies;sociology	NLP	-63.50817088183424	-11.408689395748516	155730
750e523e73fb736aecae294c99ea7f9a00f4a7d4	name suppression orders and web 2.0 media: the new zealand experience		Less than four and a half million New Zealanders inhabit a land mass greater than the United Kingdom with only one metropolitan centre whose population exceeds one million (TNZ, 2011). Most New Zealanders are regular Internet users and a vibrant blogging culture has developed. Consequently, people accused of crimes that attract significant public interest or opprobrium may be easily identifiable within their professional and local communities. As Mount (2006, p.439) observes, 'New Zealand is a small community, and reputations are quickly made and even more quickly destroyed.' Despite exceptions to the common law principle of open justice being statutorily restricted, name suppression in criminal proceedings appears common in New Zealand, although media reporting of high profile cases may distort perceptions of actual practice. Nevertheless, a perception that celebrities, in particular, disproportionately benefit from the privilege of name suppression is widely held enough for the Criminal Procedure (Reform and Modernisation) Bill 2010 ('the Bill') to specifically provide that being well known should not constitute an adequate ground for name suppression.	blog;distortion;new media;reputation;web 2.0;zero suppression	Jonathan Barrett	2012	European Journal of Law and Technology		psychology;public relations;advertising;world wide web	Web+IR	-67.70482483775793	-21.328045719619883	156061
38b951b9311cc7d06dcd733e162e0295b3f1155a	japan creates cyberconditions for it national revolution		firestorm on Capitol Hill this year after a classified report by the CIA’s inspector general was leaked to the media. The report concluded that CIA Director George J.Tenet and other senior officials did not adequately investigate and punish Deutch’s security violations. The report also concluded that Deutch exposed highly classified intelligence to hacker attacks by drafting memos on three unsecure home computers linked to the Internet.	computer;norton internet security	Bill Hancock	2000	Computers & Security	10.1016/S0167-4048(00)08014-7	national security	Security	-69.12968694422506	-10.937586596814514	156139
5696fc961b4241be911289d5fc369ec9eaf3d6da	cloudy ethics	cloudy ethic	Cloud Computing Manifesto As cloud computing has gained traction over the past fi ve years, many alarms about security, privacy, and intellectual property issues have sounded. There have also been serious anti-trust issues raised regarding closed platforms and who will control the cloud. To that end several companies heavily invested in cloud computing worked together to draft a document called the Open Cloud Manifesto. A draft was sent to Microsoft for review, and thus the controversy erupted. Microsoft blasted the drafters of the documents for working in secret and went public with the draft. Since that time several hundred of the who’s who in the computer industry signed on – notably missing are Microsoft, Google, and Oracle, three companies that have developed proprietary platforms. OUT OF CURIOSITY I “GOOGLED” CLOUD ETHICS to see if I could locate any writing about ethical issues related to the new tech buzz around cloud computing. A few textbooks on ethics appeared, but the web seemed strangely silent on ethical issues related to cloud computing. Digging deeper, I came across a telling controversy about the Open Cloud Manifesto, which will provide the focus for the rest of this column.	cloud computing manifesto;drafter;traction teampage	C. Dianne Martin	2011	Inroads	10.1145/2003616.2003618		Metrics	-68.1175824905962	-12.206066993477425	156298
45924a8d27e75585c3f5bcf44676752a95791511	topic modeling of research fields: an interdisciplinary perspective	statistical approaches;scientific research analysis;topic models	This paper addresses the problem of scientific research analysis. We use the topic model Latent Dirichlet Allocation [2] and a novel classifier to classify research papers based on topic and language. Moreover, we show various insightful statistics and correlations within and across three research fields: Linguistics, Computational Linguistics, and Education. In particular, we show how topics change over time within each field, what relations and influences exist between topics within and across fields, as well as what trends can be established for some of the world’s natural languages. Finally, we talk about trend prediction and topic suggestion as future extensions of this research.	computation;computational linguistics;latent dirichlet allocation;natural language;off topic;topic model	Michael J. Paul;Roxana Girju	2009			applied mathematics;computer science;data science;management science	NLP	-75.74903124759987	-18.612582176238764	156312
1ce2e7a2d2647e50b9c5f705982f6739bbd40255	laundering sexual deviance: targeting online pornography through anti-money laundering	computers;cyber pornography obscenity;anti money laundering;online pornography revenues;computer crime;internet law computer crime companies computers;companies;law;criminal justice;internet;anti money laundering cyber pornography obscenity online pornography revenues;law enforcement laundering sexual deviance targeting online pornography antimoney laundering cyber pornography english obscenity indecency laws illegal pornographic representations internet legal financial system;law internet	This paper concentrates on cyber-pornography/obscenity, which encompasses online publications or distribution of sexually explicit material in breach of the English obscenity and indecency laws. After examining the major deficiencies of the attempts to restrict illegal pornographic representations, the authors aim to highlight that the debate regarding their availability in the Internet era neglects the lucrative nature of the circulation of such material, which can be also targeted through anti-money laundering. Rising profits fuel the need to recycle the money back into the legal financial system, with a view to concealing their illegal origin. Anti-money laundering laws require disclosure of any 'suspicion' related to money laundering, thus opening another door for law enforcement to reach the criminal.	internet;money;shadow of the colossus;web content	Alex Antoniou;Gauri Sinha	2012	2012 European Intelligence and Security Informatics Conference	10.1109/EISIC.2012.29	criminal justice;the internet;law;computer security	ML	-70.75506879188103	-10.965381936645274	156334
0c63fedb5ac707957092da5aafeb41db62d8f8a3	who needs copyright?		It is a truism that the scholarly publishing industry needs copyright. The law provides a bedrock for the negotiation of contracts, both with authors and with users, and it is no surprise, therefore, that about a third of the words in Jones and Benson’s Publishing Law refer to copyright or related rights such as database rights and publishing rights. But it is also true that the whole notion of copyright is under pressure – my perception is that this pressure is greater than at any time since the late 18th century, when there was a strong move to abolish both copyright and patents by people who strongly believed in trade unrestricted by any barriers or monopoly rights. The reason for the pressure is clear enough: there is a whole new generation of people brought up on the Internet who accept or welcome its apparently anarchic philosophy of life. It has been claimed (and I see no reason to disbelieve it) that copyright infringement is the most common method of law-breaking today in Western society, even more so than breaking motoring speed limits. The analogy with motoring speed limits is apt. The reason why people break speed limits is because they perceive the law to be inconvenient and unjust, they perceive that enforcement measures such as speed cameras are simply devices to make money, they believe that speeding is not inherently dangerous, and they believe the chances of being caught are tiny. The same applies to copyright infringers. So we have to accept that a large proportion of the population believe that copyright laws do not apply to them, and that they can get away with infringement. The mere fact that rights owners complain that infringement is the most common legal offence today indicates to me that they have no confidence in copyright law as such. They show this by their increasing reliance on contract and digital rights management (DRM) systems. But there are other, arguably worthier motives for criticizing copyright. Many see copyright as a key barrier to the widespread free access to scholarly information and other information of use to the population at large. There are concerns about the allegedly high profits made by certain well-known publishers. And there are concerns that copyright owners, in response to the technological challenges posed by the Internet, have responded in a negative fashion, by pressing (largely successfully) for stronger copyright laws – stronger in terms of length of copyright term, the penalties for infringement and extension of the restricted acts, not to mention reductions in the exceptions to copyright that users have hitherto enjoyed. These changes in the law seem to me to be like fingers in the dyke; they not merely fail to deal effectively with the widespread infringement that occurs, but are also perceived by users as being negative. In short, they threaten the already fragile relationship between copyright owners and users. They also send out two curious messages: firstly, that users are enemies rather than consumers to be courted, and secondly, that new technology is a threat to established business models, rather than an opportunity to build new ones. The changes in the law have also produced anomalies, such as how to define ‘commercial’ when it comes to questions of ‘fair dealing’ in UK law and EU copyright law, and the problems that arise in balancing the exceptions to copyright for non-commercial research or private study with the need to give legal protection to so-called ‘technical protection measures’, such as DRM softwares. So what is wrong with copyright these days? The law seems to be reacting negatively to technological change rather than embracing it. There is little objective evidence that intellectual property rights (IPR) law actually helps the copyright industries – witness the recent EU report on the effect of database rights after ten years (it showed that the gap Guest Editorial 243		Charles Oppenheim	2006	Learned Publishing	10.1087/095315106778690652		AI	-72.1595032767276	-12.156485762180461	156356
a69d7af5fd4b4ee1fd28731ff9007f3d9e0d7fe3	napster: a walking copyright infringement?	legislation;legged locomotion digital audio players internet law video recording publishing neodymium job shop scheduling batteries horses;copy protection;copyright;copyright protection;legislation copyright copy protection;judicial procedure copyright infringement music publishing napster	The case of the CD music publishing industry against Napster (A&M Records, Inc v Napster, Inc, ND Calif) has now been argued before the US Court of Appeals in San Francisco and awaits decision. In a curious reversal of customary judicial procedure, the district court has now issued its opinion (“sentence first, verdict afterward”) explaining why it previously decided to order Napster to shut down operations. However, the court of appeals stayed that order in late July just hours before the order was scheduled to go into effect. Although the formal opinion is in the nature of assault and battery upon a dead horse, the opinion is nonetheless informative because it explains why the district court thought Napster’s system shouldn’t be permitted to operate.		Richard H. Stern	2000	IEEE Micro	10.1109/40.888696	computer science;computer security	DB	-65.97703935262076	-21.01667913320867	156562
4fd6cf67fbba8f7a44d675b264268289467ad779	cautionary tales from real world failures for managing security in the cyber world	information systems security;failure;catastrophic failure;bridges;body of knowledge;civil engineering;lessons learned;private information	"""Any field of endeavor benefits from a body of knowledge of failures that provide guidance on what to avoid. As a relatively young discipline whose failures can often be handled privately, information security professionals do not have access to the volume of well documented failures for analysis that more mature professions such as mechanical and civil engineering rely on. This paper examines catastrophic failures from the physical world and provides """"lessons learned"""" that can be applied in managing an information systems security program."""	information security;information system;tell-tale	Bill Naber	2010		10.1145/1940941.1940967	simulation;private information retrieval;computer science;body of knowledge;catastrophic failure;computer security	HCI	-72.49901273912874	-11.281904700779467	156571
659fa9af3343ee80e1c75bc2e327b7dc54d4c209	foreword by prof. dr. raimund klinkner, president, german logistics association (bvl), bremen		Logistics is an integral part of practically all economic processes. In the globally networked competitive arena, logistics expertise and performance capability are key success drivers: ever shorter innovation cycles result in a constant stream of new processes. Customers want more specific products and expect these products to be more rapidly available. Modern lifestyles are highly individualistic, and people are ever quicker to change their communication, consumption and working habits. The world is our market; consumers buy and sell online, and we think in terms of working lifetimes and time accounts. Technology continues to advance, and research continues to reveal new interrelationships. Lifelong learning is needed in order to keep up to speed with new developments; at the same time, the half-life of the knowledge acquired by us is decreasing. The global knowledge base doubles in size approximately every 5 years. This means innovation capability and knowledge are two of the key factors in the competitive market. Knowledge calls for constant awareness and the ability to reflect. Knowledge consists of information placed in the context of experience and deemed to be relevant. People engaged in global value added networks need to possess indepth knowledge as a basis for the development of a regular flow of innovative products and services in order to generate, maintain and extend their competitive edge. Innovation capability in the field of logistics is closely interconnected with research and development in various— above all interdisciplinary—areas of research: business management and engineering, mathematics and operations research, information science and intercultural management, to name but a few. Research findings and hands-on experience together are more than the sum of their parts. Since it was founded 30 years ago the German Logistics Association has devoted its efforts to the exchange of experience and the transfer of knowledge to the real world. Today, the focus is increasingly also on the communication of scientific insights: the new scientific journal ‘‘Logistics Research’’ provides a forum for academic research in the fields of business logistics and logistics engineering. It is a medium for contributions of the highest scientific standard: all submissions are double-blind reviewed by scientific experts. We would be happy to receive papers geared towards the further theoretical development of the fundamental principles or specific aspects of logistics and supply chain management as well as empirical contributions describing the real-world application of the latest knowledge and insights. This first edition explains how science and research help to find solutions to complex problems in a dynamic environment. The core theme of ‘‘Hypercompetition’’ profiles approaches that allow a fast and flexible network-based response to new technologies, shorter innovation cycles and the increasing pressure of international competition. I hope this journal makes for an ‘‘interesting read’’ and that it supplies new ideas and fresh stimuli.	experience;floor and ceiling functions;hands-on computing;information science;knowledge base;logistics;operations research;raimund seidel	Raimund Klinkner	2009	Logistics Research	10.1007/s12159-008-0004-3	operations management;management;operations research	Web+IR	-67.04460436926657	-12.293785037685476	156691
1f19435374ea1a543758cca634fe575ded2e78b5	incentives to innovate: improve the past or break with it?	creativity;information economics creativity copyright;theater;copy protection;boatbuilding;copyright;industries;books;digital rights management;digital rights management copy protection;permission books springs law privacy copyright protection motion pictures publishing security legal factors;permission;information economics;copyright protections;cooking;economics;theater digital rights management copyright protections cooking boatbuilding;privacy;boats	Does more expansive copyright law increase creativity by discouraging adaptations of existing work? The author discusses examples from cooking, boatbuilding, and the theater.		Michael E. Lesk	2009	IEEE Security & Privacy	10.1109/MSP.2009.125	computer science;information economics;digital rights management;creativity;privacy;computer security	Security	-70.5092577154919	-10.841251338653366	156743
a64b4d5526de350eef3d9524f770c0aa4461f29b	itsy--simplicity research in information and communication technology	simplification;community of practice;complexity theory;design engineering;information technology;community of practice simplicity simplification it it research;it research;industries;research and development;it;research and development information technology;ict community itsy european support action information technology simply works simplicity research information and communication technology;economics;information technology complexity theory design engineering communities economics industries;communities;simplicity	Basic to information and communication technology design, simplicity as a driving concept receives little formal attention from the ICT community. A recent literature review and survey of scholars, researchers, and practitioners conducted through the Information Technology Simply Works (ITSy) European Support Action reveals key findings about current perceptions of and future directions for simplicity in ICT. The Web extra at http://youtu.be/Tbp_IeY596A is an audio recording of Barry Floyd of California Polytechnic State University, San Luis Obispo, discussing current perceptions of and future directions for simplicity in information and communication technology.	world wide web	Barry D. Floyd;Steve Boßelmann	2013	Computer	10.1109/MC.2013.332	computer science;knowledge management;artificial intelligence;software engineering;management science;management;law;information technology;simplification	HCI	-71.55399918965888	-16.310960779452007	156801
5835fdd1d7e8a7c02ea00bc95caeb4d7f76ce4ca	children of the magenta	cybersecurity automation automation cybersecurity security;cybersecurity;cybersecurity automation;security;automation	T he term “children of the magenta” traces to 1997, when American Airlines captain Warren Vanderburgh said the industry has made pilots too dependent on monitoring the magenta lines on the machines that are really flying the plane (http://99percentinvisible .org/episode/children-of-the-magentaautomation-paradox-pt-1). William Langewiesche’s article analyzing the June 2009 crash of Air France flight 447 comes to this conclusion: “We are locked into a spiral in which poor human performance begets automation, which worsens human performance, which begets increasing automation” (www.vanityfair.com/news / b u s i n ess / 2 0 1 4 / 1 0 / a i rf ran ce f l ig ht -447-crash). University of Miami professor Earl Wiener proposed a set of “laws” that include every device creates its own opportunity for human error; exotic devices create exotic problems; and digital devices tune out small errors while creating opportunities for large errors. Langewiesche’s rewording of these laws is that “the effect of automation is to reduce the cockpit workload when the workload is low and to increase it when the workload is high” and that “once you put pilots on automation, their manual abilities degrade and their flightpath awareness is dulled: flying becomes a monitoring task, an abstraction on a screen, a mind-numbing wait for the next hotel.” Nadine Sarter of University of Michigan said that such “de-skilling is particularly acute among long-haul pilots with high seniority.” As Langewiesche added, “Beyond the degradation of basic skills of people who may once have been competent pilots, the fourthgeneration jets have enabled people who probably never had the skills to begin with and should not have been in the cockpit.” The situation in aviation is precisely the situation we are in with cybersecurity. Human error is rampant at all levels. There is a cacophony of calls for cybersecurity automation. The most experienced people are no longer directly solving problems hour after hour but rather superintending largely automated processes. More and more, digital devices tune out small failures, whether they be attacks, misconfigurations, version mismatches, or service disconnects. Like airplanes automated enough that anyone can fly them, anyone can ostensibly operate the digital devices that are unarguably society’s predominant risk vector. Therefore, there’s a guarantee of large errors at some future point—errors that no one still in practice will handle. When successful automation makes particular threats increasingly unlikely to appear, the interval between failure events grows longer. As the latency between failure events grows, the assumption that safety has been achieved also grows, fueling increased dependence on what is now a positive feedback loop (http://geer.tinho.net/geer.sfi.2x14.txt). Vanderburgh’s “children of the magenta” also applies to cybersecurity in another way: you shouldn’t run a cybersecurity detection and response operation via on-the-fly reprogramming of our equivalent of the Flight Management Computer. In 2013, Aviation Week editorialized that “there needs to be a new performance-based model that requires flight crews to log a minimum number of hand-flown takeoffs and departures, approaches and landings every six months, including some without autothrottles. Honing basic pilot skills is more critical to improving airline safety than virtually any other human factor” (http:// aviationweek.com/commercial-aviation /editorial-how-end-automation-dependency).	artificial intelligence;automation;computer security;elegant degradation;flight management system;human error;human factors and ergonomics;human reliability;positive feedback;threat (computer);tracing (software);warren abstract machine	Daniel E. Geer	2015	IEEE Security & Privacy	10.1109/MSP.2015.91	embedded system;computer science;information security;automation;computer security	Mobile	-69.29708226619826	-12.5790366764403	156825
c1e03c90752ed805ebe27ae0ffa33b361c2d3ef2	web 1.0 to web 2.0: an observational study and empirical evidence for the historical r(evolution) of the social web		Applications such as Twitter, Facebook or Youtube have taken the internet community by storm and have literally initiated a revolution in online communication. These social media applications are also often referred to by the general, somewhat vague but yet eloquent term – Web 2.0. The term implies a perceived second generation of World Wide Web, i.e. Web 1.0 → Web 2.0. Nevertheless the reference to a “second” version of the Web is misleading, since there wasn’t any specific technical update of the World Wide Web. Hence, this paper empirically explores social media in a historical context as it has evolved and driven a revolution in online communication over the last decade. A unique historical dataset, made available by the Wayback Machine Internet Archive project is employed in order to provide an accurate historical record of the primary web design and related elements that drove the evolution towards a more social and interactive web. This study presents a unique contribution to related academic literature.		Martin Sykora	2017	Int. J. Web Eng. Technol.	10.1504/IJWET.2017.084024	data science;world wide web	Web+IR	-69.65848554423411	-21.729464384919993	157001
9d993bc9ae10ad2fc2b6865d86418542d4790bfe	examining crowd work and gig work through the historical lens of piecework		The internet is empowering the rise of crowd work, gig work, and other forms of on--demand labor. A large and growing body of scholarship has attempted to predict the socio--technical outcomes of this shift, especially addressing three questions: begin{inlinelist} item What are the complexity limits of on-demand work?, item How far can work be decomposed into smaller microtasks?, and item What will work and the place of work look like for workers' end {inlinelist} In this paper, we look to the historical scholarship on piecework --- a similar trend of work decomposition, distribution, and payment that was popular at the turn of the nth{20} century --- to understand how these questions might play out with modern on--demand work. We identify the mechanisms that enabled and limited piecework historically, and identify whether on--demand work faces the same pitfalls or might differentiate itself. This approach introduces theoretical grounding that can help address some of the most persistent questions in crowd work, and suggests design interventions that learn from history rather than repeat it.	crowdsourcing;global information grid	Ali Alkhatib;Michael S. Bernstein;Margaret Levi	2017		10.1145/3025453.3025974	knowledge management;scholarship;the internet;human–computer interaction;computer science;psychological intervention;management	HCI	-76.99400579471467	-11.035994754704786	157226
3659e3e453242d27397309faf6d765d5a8faffcd	2nd workshop on steps to reducing unwanted traffic on the internet, sruti'06, san jose, ca, usa, july 7, 2006		Rob Thomas of Team Cymru began the workshop with a scintillating keynote address on the underground economy. Although much of the research community working on unwanted traffic issues has focused on technical aspects of various subproblems, Rob brought his direct experience with ongoing study of the underground economy dominated by the criminal elements trading in credit cards, passwords, and the like. He painted a grim picture of the underground economy and stressed the need for a closer examination of activities common in that world that are largely unknown to the research community.	internet;password	Xin Liu;Xiaowei Yang	2006				Web+IR	-69.75696378851987	-11.074982989573542	157565
d24204eea24d8af0fb7c803dbd113ddf0e11f34f	data processing project management: a practical approach for publishing a project expectations document	project manager;data processing	"""With the mounting demand for proficient personnel and the parallel increase in salaries, management is seeking ways to improve productivity in order to realize a higher return on their investment dollars. Knowing what to do, when to do it, and how to do it prevents costly retries. Given any kind of a project and 2 to N participants, there will be 2 to N views of the project. Furthermore, there are always dozens of subtle nuances floating like little puffs of smoke over every enterprise, and they are often not in agreement. It is necessary to crystallize the assumptions that each participant """"understands"""" to be the accepted expectations, resolve the conflicts, and disseminate this information to the community. This paper reflects a practical method for transforming facts and conflicts into an approved development approach and publishing the results in what will be called a Project Expectations Document."""	universal quantification	Lois Zells	1983		10.1145/1500676.1500700	public relations;knowledge management;political science;project management triangle;management	SE	-66.7156686857346	-20.78080785362191	157577
29ef0bc12765aca4d56231136d3e79dfcc1862ff	the private universe	private universe;debate rage;ntp inc.;blackberry service;blackberry maker;press time;ongoing patent infringement battle	As I type this, the debate rages on whether the BlackBerry service will cease to exist as we know it. As of press time, a judge had refused to issue an order of injunction against BlackBerry maker RIM (Research in Motion) in its ongoing patent infringement battle with NTP Inc., giving users at least another 30 days to feed their addiction.	blackberry	Charlene O'Hanlon	2006	ACM Queue	10.1145/1127854.1127856	management;law;computer security	DB	-68.66861303482844	-11.807673531633542	157724
4e6a4da8a8e4b6930dcbe900b01de6eb29466a44	is there really a conflict between privacy and personalisation?		There is growing concern about the protection of user privacy on the Internet. This is entirely understandable and long overdue. Since the advent of the web, the amount of personal information and media types which users are invited to disclose have been increasing inexorably. There are good reasons for this. Through the customisation of systems to each individual user, the provision of personal information offers significant benefits in terms of usability. Indeed, as the complexity of these systems increases, their usability becomes ever more dependent on the benefits of personalisation. There would appear to be a conflict between privacy and personalisation and a need for a balance to be struck between them – greater privacy resulting in less personalisation and vice versa. This keynote will argue that the apparent conflict is the result of a particular perspective on the problem; a perspective which assumes that the individual user is limited to a binary decision on whether or not to disclose items of personal information to all and sundry or to nobody. There are many reasons why this assumption is made, not least of which are the privacy policies of service providers which offer little or no fine tuning and frequently read more like disclaimers than guarantees. Investigation of these reasons indicates that they are not inescapable and reveals an alternative approach to the design of personalised systems in which the user can retain full control of what they disclose to whom.	internet;personalization;personally identifiable information;privacy policy;usability	Nick K. Taylor;Elizabeth Papadopoulou;Sarah Gallacher;M. Howard Williams	2011		10.1007/978-1-4614-4951-5_1	public relations;internet privacy;world wide web	Metrics	-73.53525533794091	-12.044185904409773	157887
1e2a1adca8f8fa198b3eb180d18a357bf0941831	patents on selling via the net-really?	legislation;e data corp;computer industry;companies;us patent 4 528 643;postal services;internet e data corp software industry freeny patent us patent 4 528 643;internet;permission;patents;games;licenses;video on demand;software industry;legislation patents industrial property;freeny patent;industrial property;licenses games permission companies computer industry internet postal services digital images video on demand marketing and sales;digital images;marketing and sales	E-Data Corp. is a company apparently solely in the business of trying to make a buck out of a patent that it bought. Its efforts to make the software industry salute, or at least pay attention to, its Freeny patent (US Patent 4,528,643, issued July 9, 1985) on selling software via the Internet have provoked rage, amusement, and even some actual licenses. This paper discusses E-Data's licencing efforts, the Freeny patent, and objections to the patent.		Richard H. Stern	1996	IEEE Micro	10.1109/40.540074	games;the internet;computer science;patent troll;digital image	Arch	-67.4238154602176	-16.32396336521811	158103
98297a085343f3f393b4ef295bf6626bdc2fbb86	document management and tracking system for emergency response headquarters		One problem faced by an emergency response headquarters is that emergency response procedures are not adequately documented. This lack of documentation is a major problem in testing preparedness for future emergencies. However, it is difficult to document an emergency response while actually responding to an event. The authors have attempted to resolve this issue by building a content management system with a focus on documentation created during emergency responses and on documentation that can be printed out and attached.	tracking system	Wataru Sendo;Norihisa Segawa;Jun Sawamoto;Eiji Sugino;Masato Yazawa;Shinji Akitomi	2014		10.1007/978-3-319-07857-1_45	knowledge management;management	HCI	-68.26595797899022	-16.803182448384675	158143
5fb77705e05795355b4af4adf6edcd1c5b567efa	is research perspectives: a mandate for scholarly debate	is research	“IS Research Perspectives” is a new, special section of the Journal of the Association of Information Systems (JAIS) whose overall goal is to publish debate and discussion on critical issues in IS research. Critical issues are not only issues of the day, but also perennial issues that have been with us since our founding as a field of inquiry and teaching. Refereed in accordance with the standards of the highest quality scholarly journals, these articles will be crisp forays into issues that IS professionals in the academy value and talk about in the hallways of their institutions. While most published articles will deal directly with research in the broadest sense, other activities in a professor’s life that have a pronounced bearing on research can also find a home in the section. The simple criterion is that the article must deal with critical issues that shape the research traditions, carry an underlying message for its research mission, and do this in an exciting and thought-provoking way.		Detmar W. Straub	2003	J. AIS		computer science;public administration	ML	-71.9746455287858	-16.87633496137642	158332
